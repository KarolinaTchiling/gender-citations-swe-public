FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Guo, XX
   Lin, HK
   Ma, S
   Yang, Z
   Li, HT
AF Guo, Xiaoxuan
   Lin, Haikun
   Ma, Shu
   Yang, Zhen
   Li, Hongting
TI Effect of the predictive keyboard with magnification and protrusion on
   the bare-hand input in virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Bare-hand input; Predictive keyboard; Magnification;
   Protrusion
ID TYPING SPEED; ERROR; BIOMECHANICS; USABILITY; SPACE
AB Bare-hand input, advantaged as the natural interaction, is a promising way of text input in VR. The paper proposes the predictive next-letter highlighting technology and investigates its spatial enhancement (magnification, protrusion) of the 100% correct predicted keys on bare-hand input in virtual reality. In Experiment One, the predicted keys are magnified in three levels (no magnification, medium magnification, maximum magnification). Results show that magnification can improve input performance, but excessive magnification may decrease participants' willingness to use it. In Experiment Two, the predicted keys are protruded in four levels (0 mm, 3 mm, 6 mm, 9 mm). We found that the overall input performance, especially on intrusion errors, is impaired with protrusion distance. The level of agility may be the critical factor affecting the effect of protrusion distance. In conclusion, the study found that the predicted keys with magnification are good choices for VR bare-hand inputting, especially for the low-agile person. However, the influence of protrusion distance on bare-hand input performance may vary from person to person.
C1 [Guo, Xiaoxuan; Lin, Haikun; Ma, Shu; Yang, Zhen; Li, Hongting] Zhejiang Sci Tech Univ, Dept Psychol, Hangzhou, Peoples R China.
C3 Zhejiang Sci-Tech University
RP Ma, S; Li, HT (corresponding author), Zhejiang Sci Tech Univ, Dept Psychol, Hangzhou, Peoples R China.
EM yinger198922@126.com; lihongting@vip.163.com
RI Yang, Zhen/JFK-8720-2023
OI Ma, Shu/0000-0003-2632-4209
FU Science Foundation of Zhejiang Sci-Tech University (ZSTU) [18062304-Y];
   Zhejiang Province Public Welfare Technology Research Program
   [LQ20C090010]; Youth Innovation foundation of Zhejiang Sci-Tech
   University [22062311-Y]; National Natural Science Foundation of China
   [31771224, T2192930, T2192931]
FX This work was supported by Science Foundation of Zhejiang Sci-Tech
   University (ZSTU) under Grant (No.18062304-Y), Zhejiang Province Public
   Welfare Technology Research Program (LQ20C090010), the Youth Innovation
   foundation of Zhejiang Sci-Tech University (22062311-Y), the National
   Natural Science Foundation of China under Grant (31771224, T2192930,
   T2192931).
CR Al Faraj K, 2009, LECT NOTES COMPUT SC, V5612, P3, DOI 10.1007/978-3-642-02580-8_1
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Arif AS, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P100, DOI 10.1109/TIC-STH.2009.5444533
   Bi J., 2015, J CEREAL SCI, V39, P56
   Brewster S, 2002, PERS UBIQUIT COMPUT, V6, P188, DOI 10.1007/s007790200019
   Brewster S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P159
   CHAN HS, 1993, PERCEPT MOTOR SKILL, V77, P515, DOI 10.2466/pms.1993.77.2.515
   della Gatta F, 2016, ELIFE, V5, DOI 10.7554/eLife.14972
   Dube TJ, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382882
   Fiorentino M., 2003, 13 ADM 15 INGEGRAF I
   Gkoumas A, 2016, 20TH PAN-HELLENIC CONFERENCE ON INFORMATICS (PCI 2016), DOI 10.1145/3003733.3003743
   Gong J., 2005, CHI'05 Extended Abstracts on Human Factors in Computing Systems. CHI EA'05, P1399
   Grossman T, 2004, P SIGCHI C HUM FACT, V6, P447, DOI [10.1145/985692.985749, DOI 10.1145/985692.985749]
   HART S G, 1988, P139
   Iwase H, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P594, DOI 10.1109/ROMAN.2001.981969
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174007
   Komiya K, 2017, 2017 TENTH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND UBIQUITOUS NETWORK (ICMU), P65
   Lepinski GJ, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2233
   Liang ZR, 2017, UNIVERSAL ACCESS INF, V16, P381, DOI 10.1007/s10209-016-0464-1
   Ma Z, 2015, 2015 IEEE WORLD HAPT
   MACKENZIE IS, 2003, CHI 03 HUM FACT COMP, V3, P754, DOI [DOI 10.1145/765891.765971, 10.1145/765891.765971, 10.1145/765891.765971doi.org/10.1145/765891.765971, DOI 10.1145/765891.765971DOI.ORG/10.1145/765891.765971]
   McGuffin M. J., 2005, ACM Transactions on Computer-Human Interaction, V12, P388, DOI 10.1145/1121112.1121115
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Naceri A, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00511
   Ng Adrian K. T., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P173, DOI 10.1007/978-3-319-39907-2_17
   Norman Donald A., 2010, interactions, V17, P6, DOI [DOI 10.1145/1744161.1744163, 10.1145/1744161.1744163]
   Ogawa Nami, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P519, DOI 10.1109/VR.2019.8798040
   Page Tom, 2013, Journal of Design Research, V11, P39
   Parhi P., 2006, P 8 C HUMAN COMPUTER, P203, DOI [DOI 10.1145/1152215.1152260, 10.1145/1152215.1152260]
   Pereira A, 2014, HUM FACTORS, V56, P752, DOI 10.1177/0018720813502524
   Pereira A, 2013, HUM FACTORS, V55, P557, DOI 10.1177/0018720812465005
   Rajendran VK, 2012, INTERACTION LARGE ST
   Ren G, 2016, J INTELL FUZZY SYST, V31, P2659, DOI 10.3233/JIFS-169106
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rodrigues É, 2016, UNIVERSAL ACCESS INF, V15, P393, DOI 10.1007/s10209-014-0394-8
   Schedlbauer M., 2007, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V51, P429, DOI DOI 10.1177/154193120705100501
   Sharma MK, 2013, INT C INTELLIGENT HU, DOI [10.1109/IHCI.2012.6481820, DOI 10.1109/IHCI.2012.6481820]
   Singh AK, 2018, IEEE ACCESS, V6, P24617, DOI 10.1109/ACCESS.2018.2832089
   Soukoreff RW., 2003, METRICS TEXT ENTRY R, DOI [10.1145/642611.642632, DOI 10.1145/642611.642632]
   Vienne C, 2020, IEEE ACCESS, V8, P29099, DOI 10.1109/ACCESS.2020.2972122
   Wang QJ, 2018, AUST J PSYCHOL, V70, P294, DOI 10.1111/ajpy.12200
   Wickens CD., 2019, Applied Attention Theory, DOI [DOI 10.1201/9780429059261, 10.1201/9780429059261]
   Wu C, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1352782.1352788
   Yang Z, 2019, APPL ERGON, V78, P164, DOI 10.1016/j.apergo.2019.03.006
   Zhai S., 2000, P ACM S USER INTERFA, P119, DOI DOI 10.1145/354401.354424
NR 45
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31821
EP 31838
DI 10.1007/s11042-023-15071-z
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000953336200009
DA 2024-07-18
ER

PT J
AU Mukherjee, A
   Ghosh, A
AF Mukherjee, Anupam
   Ghosh, Anupam
TI Predictive framework for crime data analysis using a hybrid logistic
   regression - support vector machine based ensemble classifier powered by
   CART (LR-SVM<SUP><i>CART</i></SUP>)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature dimension reduction; Data decomposition; Logistic regression;
   Deep learning; Decision tree; Support vector machine; Random forest;
   Ensemble classifier
ID LINK PREDICTION
AB Significant rise in illegal activity has directly impacted socioeconomic growth and quality of life. In this article, a predictive crime data analysis framework has been proposed that can resolve the problem of scalability issues and accuracy rate. This paper proposed a hybrid ensemble machine learning classifier to identify authentic crime activities. A series of experiments are used to verify the efficiency of our proposed algorithms. Three datasets of different countries are used for this experiment purpose. All the datasets are tested successfully on our proposed framework and novel ensembles classifier. The result produced by our proposed hybrid ensemble classifier mostly outperforms the performance of most of the existing machine learning approaches. This work aims to identify geospatial crime data intensity where we can anticipate the recurrence of a certain crime in the city using geospatial technology, allowing the police force to take the required precautions to avoid it.
C1 [Mukherjee, Anupam] Siliguri Inst Technol, Dept Comp Sci & Engn, SIT Campus, Siliguri 734009, West Bengal, India.
   [Ghosh, Anupam] Netaji Subhash Engn Coll, Dept Comp Sci & Engn, Kolkata 700152, W Bengal, India.
C3 Netaji Subhash Engineering College Kolkata
RP Ghosh, A (corresponding author), Netaji Subhash Engn Coll, Dept Comp Sci & Engn, Kolkata 700152, W Bengal, India.
EM anupamsit@gmail.com; anupam.ghosh@rediffmail.com
OI Ghosh, Anupam/0000-0003-2166-3957; Mukherjee, Anupam/0000-0003-2207-0643
CR Abbass Z, 2020, IEEE INT C SEMANT CO, P363, DOI 10.1109/ICSC.2020.00073
   Alves LGA, 2018, PHYSICA A, V505, P435, DOI 10.1016/j.physa.2018.03.084
   Amin MS, 2019, TELEMAT INFORM, V36, P82, DOI 10.1016/j.tele.2018.11.007
   Andresen MA, 2017, J QUANT CRIMINOL, V33, P255, DOI 10.1007/s10940-016-9295-8
   [Anonymous], DENV CRIM DAT
   [Anonymous], CHIC CRIM DAT
   Arulanandam R., 2014, P 2 AUSTR WEB C, V155, P31
   Bai Y, 2019, J INTELL MANUF, V30, P2245, DOI 10.1007/s10845-017-1388-1
   Bandekar S. R., 2020, Procedia Computer Science, V172, P122, DOI DOI 10.1016/J.PROCS.2020.05.018
   Chu X, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2201, DOI 10.1145/2882903.2912574
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Feng MC, 2019, IEEE ACCESS, V7, P106111, DOI 10.1109/ACCESS.2019.2930410
   Gill J., 2019, GEN LINEAR MODELS UN, DOI [10.4135/9781526421036, DOI 10.4135/9781526421036]
   Gupta A, 2016, INT J ADV COMPUT SC, V7, P374
   Jalil MMA, 2017, PROCEDIA COMPUT SCI, V116, P113, DOI 10.1016/j.procs.2017.10.018
   Khairuddin AR, 2020, ADV INTELL SYST COMP, V1073, P189, DOI 10.1007/978-3-030-33582-3_18
   Kim A, 2018, BMC MED GENOMICS, V11, DOI 10.1186/s12920-018-0401-7
   Kim S, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P415, DOI 10.1109/IEMCON.2018.8614828
   Lee SY, 2018, PUBLIC HEALTH, V159, P21, DOI 10.1016/j.puhe.2018.03.001
   Lekha K. Chitra, 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P1639, DOI 10.1109/ICECDS.2017.8389725
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Li YS, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105738
   Lim M, 2019, IEEE ACCESS, V7, P184797, DOI 10.1109/ACCESS.2019.2958873
   Lim M, 2020, IEEE ACCESS, V8, P16550, DOI 10.1109/ACCESS.2019.2961805
   Lin Y, 2019, J SUPERCOMPUT, V75, P3010, DOI 10.1007/s11227-017-2216-2
   Malik A, 2014, IEEE T VIS COMPUT GR, V20, P1863, DOI 10.1109/TVCG.2014.2346926
   McClendon Lawrence., 2015, MACHINE LEARNING APP, V2, DOI [DOI 10.5121/MLAIJ.2015.2101, 10.5121/mlaij.2015.2101, https://doi.org/10.5121/mlaij.2015.2101]
   Mukherjee A, 2019, INT C INN MOD SCI TE, P1004
   Palaniappan S, 2017, LECT NOTES ELECTR EN, V394, P165, DOI 10.1007/978-981-10-1540-3_17
   Panja R, 2018, APPL SOFT COMPUT, V64, P356, DOI 10.1016/j.asoc.2017.12.017
   Qasim OS, 2018, CHEMOMETR INTELL LAB, V182, P41, DOI 10.1016/j.chemolab.2018.08.016
   Ratcliffe JH, 2021, J EXP CRIMINOL, V17, P15, DOI 10.1007/s11292-019-09400-2
   Sarkar S., 2016, 2016 IEEE Annual India Conference (INDICON), P1, DOI DOI 10.1109/ICCPCT.2016.7530355
   sfgov, SAN FRANC CRIM DAT
   Uskov VL., 2020, SMART ED E LEARNING, DOI [10.1007/978-981-15-5584-8_16, DOI 10.1007/978-981-15-5584-8]
   Vural MS, 2017, NEURAL COMPUT APPL, V28, P2581, DOI 10.1007/s00521-016-2205-z
   Wang B, 2019, CHINESE ANN MATH B, V40, P949, DOI 10.1007/s11401-019-0168-y
   Wheeler AP, 2021, J QUANT CRIMINOL, V37, P445, DOI 10.1007/s10940-020-09457-7
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yin J, 2020, PREPRINT, DOI [10.20944/preprints202002.0108.v1, DOI 10.20944/PREPRINTS202002.0108.V1]
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao HM, 2019, IEEE ACCESS, V7, P99263, DOI 10.1109/ACCESS.2019.2929094
   Zhao XY, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P497, DOI 10.1145/3132847.3133024
NR 43
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35357
EP 35377
DI 10.1007/s11042-023-14760-z
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000953336200006
DA 2024-07-18
ER

PT J
AU Panda, A
AF Panda, Arnapurna
TI Orthogonal array design based multi-objective CBO and SOS algorithms for
   band reduction in hyperspectral image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orthogonal array design; Symbiotic organism search; Colliding bodies
   optimization; Adaptive penalty function method; Band selection;
   Hyperspectral image
ID SYMBIOTIC ORGANISMS SEARCH; OPTIMIZATION ALGORITHM; GENETIC ALGORITHM;
   SELECTION; PERFORMANCE
AB A hyperspectral image is taken by infrared imaging spectrometer consist of a continuous series of hundreds of bands. These bands collect spectral information across the electromagnetic spectrum. The presence of high spectral correlation among the bands have necessitated the use of dimensionality reduction in Hyperspectral image. Thus the bands which posses significant information needs to be selected and remaining noisy, correlated ones needs are rejected. In this paper the band selection task is formulated as a multi-objective optimization problem and two objective functions : Entropy and Pearson correlation coefficient are used in the analysis. The Orthogonal Array Design (OAD) is a mathematical procedure to determine few selected combinations which are effective among the total number of possible combination between vectors. It has been suitably applied in single-objective evolutionary algorithms to enhance their exploration capabilities. In this paper the OAD is hybridized with two nature inspired algorithms : Symbiotic Organisms Search (SOS) and Colliding Bodies Optimization (CBO). Resulting two algorithms termed as OAD-MOSOS and OAD-MOCBO have been applied to solve unconstrained and constrained multi-objective optimization problems. The adaptive penalty function is embodied with OAD-MOSOS and OAD-MOCBO to handle the constrained problem. Simulation results on eight benchmark functions reveal that OAD-MOSOS is accurate whereas OAD-MOCBO is computationally efficient. Both the developed algorithms are employed for band reduction in two hyperspectral images of Pavia University and Pavia Center. Simulation results reveal that in both hyperspectral images the number of retained bands using OAD-MOSOS algorithm is lowest and the clustering accuracy achieved is highest among the comparative algorithms based on MOSOS, MOCBO and NSGA-II.
C1 [Panda, Arnapurna] Sikha O Anusandhan Deemed be Univ, Inst Tech Educ & Res, Ctr Data Sci, Bhubaneswar 751030, Orissa, India.
C3 Siksha 'O' Anusandhan University
RP Panda, A (corresponding author), Sikha O Anusandhan Deemed be Univ, Inst Tech Educ & Res, Ctr Data Sci, Bhubaneswar 751030, Orissa, India.
EM ap19@iitbbs.ac.in
CR Abdullahi M, 2019, J NETW COMPUT APPL, V133, P60, DOI 10.1016/j.jnca.2019.02.005
   aviris.jpl.nasa, NASAS AIRBORNE VISIB
   Bai WL, 2017, CONTROL ENG PRACT, V61, P163, DOI 10.1016/j.conengprac.2017.02.010
   Bandaru S, 2017, EXPERT SYST APPL, V70, P119, DOI 10.1016/j.eswa.2016.10.016
   Bayraktar Z, 2011, IEEE ANTENN PROPAG M, V53, P42, DOI 10.1109/MAP.2011.6028421
   Cheng MY, 2014, COMPUT STRUCT, V139, P98, DOI 10.1016/j.compstruc.2014.03.007
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Coello CAC, 2004, IEEE T EVOLUT COMPUT, V8, P256, DOI 10.1109/tevc.2004.826067
   Coello CAC, 2018, WILEY ENCY ELECT ELE, P1
   Dai C, 2016, IEEE T CYBERNETICS, V46, P3306, DOI 10.1109/TCYB.2015.2503433
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K, 2014, IEEE T EVOLUT COMPUT, V18, P577, DOI 10.1109/TEVC.2013.2281535
   Tran DH, 2018, J COMPUT DES ENG, V5, P160, DOI 10.1016/j.jcde.2017.11.008
   Gao JW, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1JRS.8.085094
   Gao WF, 2013, IEEE T CYBERNETICS, V43, P1011, DOI 10.1109/TSMCB.2012.2222373
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Gong WY, 2008, APPL MATH COMPUT, V206, P56, DOI 10.1016/j.amc.2008.08.053
   Gong WY, 2006, LECT NOTES COMPUT SC, V4304, P709
   Gupta D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165491
   Gupta R., 2019, IEEE C EVOL COMPUTAT, V13, P103
   Hu P, 2019, IEEE GEOSCI REMOTE S, V16, P452, DOI 10.1109/LGRS.2018.2872540
   Hu YF, 2014, INT J SYST SCI, V45, P337, DOI 10.1080/00207721.2012.723053
   Jiang Zhong-Yang, 2010, Journal of Software, V21, P1296, DOI 10.3724/SP.J.1001.2010.03592
   Kaveh A, 2014, COMPUT STRUCT, V139, P18, DOI 10.1016/j.compstruc.2014.04.005
   Kaveh A, 2019, J COMPUT DES ENG, V6, P49, DOI 10.1016/j.jcde.2018.04.001
   Kumar Mohit, 2018, Computers & Electrical Engineering, V69, P395, DOI 10.1016/j.compeleceng.2017.11.018
   Kumar M, 2021, IEEE T SUST COMPUT
   Kumar M, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P257, DOI 10.1109/Confluence51648.2021.9377050
   Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006
   Lei YX, 2017, IEEE ACCESS, V5, P9699, DOI 10.1109/ACCESS.2017.2705019
   Leung YW, 2001, IEEE T EVOLUT COMPUT, V5, P41, DOI 10.1109/4235.910464
   Li XT, 2014, NEURAL COMPUT APPL, V24, P1233, DOI 10.1007/s00521-013-1354-6
   Medjahed SA, 2016, APPL SOFT COMPUT, V40, P178, DOI 10.1016/j.asoc.2015.09.045
   Pan B, 2019, IEEE T GEOSCI REMOTE, V57, P3729, DOI 10.1109/TGRS.2018.2886853
   Panda A., 2016, Proceedings of Fifth International Conference on Soft Computing for Problem Solving, P651, DOI DOI 10.1007/978-981-10-0448-3_54
   Panda A, 2019, ADV INTELL SYST, V816, P507, DOI 10.1007/978-981-13-1592-3_40
   Panda A, 2018, NEURAL PROCESS LETT, V48, P219, DOI 10.1007/s11063-017-9711-6
   Panda A, 2018, SOFT COMPUT, V22, P2429, DOI 10.1007/s00500-017-2693-5
   Panda A, 2016, IEEE C EVOL COMPUTAT, P1100, DOI 10.1109/CEC.2016.7743911
   Panda A, 2016, APPL SOFT COMPUT, V46, P344, DOI 10.1016/j.asoc.2016.04.030
   Parente M, 2019, IEEE GEOSC REM SEN M, V7, P6, DOI 10.1109/MGRS.2019.2912617
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Qin QD, 2015, COMPUT OPER RES, V60, P91, DOI 10.1016/j.cor.2015.02.008
   Rani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196474
   Satapathy SC, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-130
   Shukla UP, 2018, EXPERT SYST APPL, V97, P336, DOI 10.1016/j.eswa.2017.12.034
   Sun WW, 2019, IEEE GEOSC REM SEN M, V7, P118, DOI 10.1109/MGRS.2019.2911100
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tanabe R, 2020, IEEE T EVOLUT COMPUT, V24, P193, DOI 10.1109/TEVC.2019.2909744
   Tejani GG, 2019, EXPERT SYST APPL, V125, P425, DOI 10.1016/j.eswa.2019.01.068
   Tejani GG, 2018, KNOWL-BASED SYST, V161, P398, DOI 10.1016/j.knosys.2018.08.005
   Tran DH, 2016, KNOWL-BASED SYST, V94, P132, DOI 10.1016/j.knosys.2015.11.016
   Wang MH, 2023, ARAB J SCI ENG, V48, P11029, DOI 10.1007/s13369-021-05808-z
   Wang ZJ, 2016, IEEE C EVOL COMPUTAT, P594, DOI 10.1109/CEC.2016.7743847
   Woldesenbet YG, 2009, IEEE T EVOLUT COMPUT, V13, P514, DOI 10.1109/TEVC.2008.2009032
   Xiong GJ, 2018, APPL SOFT COMPUT, V66, P134, DOI 10.1016/j.asoc.2018.02.019
   Xiong GJ, 2014, COMPUT OPER RES, V41, P125, DOI 10.1016/j.cor.2013.07.021
   Xu Y, 2017, IEEE GEOSCI REMOTE S, V14, P554, DOI 10.1109/LGRS.2017.2658666
   Yang J, 2010, PSYCHOLOGY OF COURAGE: AN ADLERIAN HANDBOOK FOR HEALTHY SOCIAL LIVING, P1, DOI 10.1007/978-1-84996-129-5
   Yin JH, 2012, IEEE T IND INFORM, V8, P935, DOI 10.1109/TII.2012.2205397
   Zhan ZH, 2011, IEEE T EVOLUT COMPUT, V15, P832, DOI 10.1109/TEVC.2010.2052054
   Zhang MY, 2018, APPL SOFT COMPUT, V70, P604, DOI 10.1016/j.asoc.2018.06.009
   Zhang MY, 2017, IEEE C EVOL COMPUTAT, P495, DOI 10.1109/CEC.2017.7969352
   Zhang QF, 2007, IEEE T EVOLUT COMPUT, V11, P712, DOI 10.1109/TEVC.2007.892759
   Zhang Y, 2021, SWARM EVOL COMPUT, V60, DOI 10.1016/j.swevo.2020.100806
   Zhao H, 2021, IEEE T GEOSCI REMOTE
NR 66
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35301
EP 35327
DI 10.1007/s11042-023-14510-1
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000950429600004
DA 2024-07-18
ER

PT J
AU Afif, M
   Ayachi, R
   Said, Y
   Atri, M
AF Afif, Mouna
   Ayachi, Riadh
   Said, Yahia
   Atri, Mohamed
TI Deep learning-based technique for lesions segmentation in CT scan images
   for COVID-19 prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 image segmentation; Deep learning; Context aggregation network;
   CT images
ID CHEST CT
AB Since 2019, COVID-19 disease caused significant damage and it has become a serious health issue in the worldwide. The number of infected and confirmed cases is increasing day by day. Different hospitals and countries around the world to this day are not equipped enough to treat these cases and stop this pandemic evolution. Lung and chest X-ray images (e.g., radiography images) and chest CT images are the most effective imaging techniques to analyze and diagnose the COVID-19 related problems. Deep learning-based techniques have recently shown good performance in computer vision and healthcare fields. We propose developing a new deep learning-based application for COVID-19 segmentation and analysis in this work. The proposed system is developed based on the context aggregation neural network. This network consists of three main modules: the context fuse model (CFM), attention mix module (AMM) and a residual convolutional module (RCM). The developed system can detect two main COVID-19-related regions: ground glass opacity and consolidation area in CT images. Generally, these lesions are often related to common pneumonia and COVID 19 cases. Training and testing experiments have been conducted using the COVID-x-CT dataset. Based on the obtained results, the developed system demonstrated better and more competitive results compared to state-of-the-art performances. The numerical findings demonstrate the effectiveness of the proposed work by outperforming other works in terms of accuracy by a factor of over 96.23%.
C1 [Afif, Mouna; Ayachi, Riadh] Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect E E, Monastir, Tunisia.
   [Said, Yahia] Northern Border Univ, Coll Engn, Elect Engn Dept, Ar Ar, Saudi Arabia.
   [Atri, Mohamed] King Khalid Univ, Coll Comp Sci, Abha, Saudi Arabia.
C3 Universite de Monastir; Northern Border University; King Khalid
   University
RP Afif, M (corresponding author), Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect E E, Monastir, Tunisia.
EM mouna.afif@outlook.fr
RI ATRI, Mohamed/C-4069-2014; Said, Yahia/A-7333-2018; Ayachi,
   Riadh/AAU-2160-2020
OI ATRI, Mohamed/0000-0001-8528-5647; Said, Yahia/0000-0003-0613-4037;
   Ayachi, Riadh/0000-0003-4683-9592
FU Deputyship for Research and Innovation, Ministry of Education in Saudi
   Arabia [IF_2020_NBU_231]
FX AcknowledgementsThe authors extend their appreciation to the Deputyship
   for Research and Innovation, Ministry of Education in Saudi Arabia for
   funding this research work through the project number"IF_2020_NBU_231.
CR Afif M, 2022, MULTIMED TOOLS APPL, V81, P16601, DOI 10.1007/s11042-022-12577-w
   Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Amyar A, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104037
   Anjishnu Das SK, 2020, WHY COVID TESTING IS
   Ayachi R, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421500245
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cheng WS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101158
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Chung MS, 2020, EUR RADIOL, V30, P2182, DOI [10.1148/radiol.2020200230, 10.1007/s00330-019-06574-1]
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gunraj H, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.608525
   Hamghalam M, 2020, I S BIOMED IMAGING, P1499, DOI [10.1109/ISBI45749.2020.9098347, 10.1109/isbi45749.2020.9098347]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X. etal, 2020, medRxiv
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Kalane P, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102518
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Mobiny A, 2020, arXiv
   Polsinelli M, 2020, PATTERN RECOGN LETT, V140, P95, DOI 10.1016/j.patrec.2020.10.001
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saood A, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00529-5
   Shah V, 2021, EMERG RADIOL, V28, P497, DOI 10.1007/s10140-020-01886-y
   Shi F, 2021, IEEE REV BIOMED ENG, V14, P4, DOI 10.1109/RBME.2020.2987975
   Soares E., 2020, medRxiv, V10, P1
   Soleymanifard M, 2022, MULTIMED TOOLS APPL, V81, P8451, DOI 10.1007/s11042-022-12326-z
   Ter-Sarkisov A., 2020, medRxiv
   Wang CS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3170493
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Ye Z, 2020, EUR RADIOL, V30, P4381, DOI 10.1007/s00330-020-06801-0
   Zhao J., 2020, ARXIV
   Zhao W, 2020, AM J ROENTGENOL, V214, P1072, DOI 10.2214/AJR.20.22976
   Zheng CM, 2021, IEEE T MULTIMEDIA, V23, P2520, DOI 10.1109/TMM.2020.3013398
   Zou LR, 2020, NEW ENGL J MED, V382, P1177, DOI [10.1056/NEJMc2001737, 10.1148/radiol.2020200463]
NR 40
TC 8
Z9 8
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26885
EP 26899
DI 10.1007/s11042-023-14941-w
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943970200012
PM 37362746
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Usha, GP
   Alex, JSR
AF Usha, Gowri Prasood
   Alex, John Sahaya Rani
TI Speech assessment tool methods for speech impaired children: a
   systematic literature review on the state-of-the-art in Speech
   impairment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Speech sound disorders; Speech assessment tools; Speech impairments;
   Speech assessment methods; Children
ID CHILDHOOD APRAXIA; MULTILINGUAL CHILDREN; PEDIATRIC SPEECH; SOUND
   DISORDERS; CLEFT-PALATE; TONGUE-TIE; LANGUAGE; OUTCOMES; CLASSIFICATION;
   INTELLIGIBILITY
AB Speech is a powerful, natural mode of communication that facilitates effective interactions in human societies. However, when fluency or flow of speech is affected or interrupted, it leads to speech impairment. There are several types of speech impairment depending on the speech pattern and range from mild to severe. Childhood apraxia of speech (CAS) is the most common speech disorder in children, with 1 out of 12 children diagnosed globally. Significant advancements in speech assessment tools have been reported to assist speech-language pathologists diagnosis speech impairment. In recent years, speech assessment tools have also gained popularity among pediatricians and teachers who work with preschoolers. Automatic speech tools can be more accurate for detecting speech sound disorders (SSD) than human-based speech assessment methods. This systematic literature review covers 88 studies, including more than 500 children, infants, toddlers, and a few adolescents, (both male and female) (age = 0-17) representing speech impairment from more than 10 countries. It discusses the state-of-the-art speech assessment methods, including tools, techniques, and protocols for speech-impaired children. Additionally, this review summarizes notable outcomes in detecting speech impairments using said assessment methods and discusses various limitations such as universality, reliability, and validity. Finally, we consider the challenges and future directions for speech impairment assessment tool research.
C1 [Usha, Gowri Prasood; Alex, John Sahaya Rani] Vellore Inst Technol, Sch Elect Engn, Chennai 600127, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Alex, JSR (corresponding author), Vellore Inst Technol, Sch Elect Engn, Chennai 600127, India.
EM jsranialex@vit.ac.in
OI alex, john sahaya rani/0000-0003-0373-976X
CR Abaskohi A, 2022, ARXIV
   Abdou D, 2020, EGYPT J OTOLARYNGOL, V36, DOI 10.1186/s43163-020-00021-5
   Afshan A, 2017, PREDICTING CLIN EVAL, DOI [10.21437/SLaTE.2017-28, DOI 10.21437/SLATE.2017-28]
   Al-Qatab BA, 2021, IEEE ACCESS, V9, P18183, DOI 10.1109/ACCESS.2021.3053335
   Bachmann AS, 2021, J CRANIO MAXILL SURG, V49, P52, DOI 10.1016/j.jcms.2020.11.009
   Backer V, 2014, RES PAPERS
   Barrett C, 2020, FOLIA PHONIATR LOGO, V72, P152, DOI 10.1159/000500664
   Berry J, 2012, BREASTFEED MED, V7, P189, DOI 10.1089/bfm.2011.0030
   Bessell A, 2013, CLEFT PALATE-CRAN J, V50, pE1, DOI 10.1597/11-202
   Booth E, 2020, EVALUATING IMPROVING, P11
   Brendel B, 2013, CEREBELLUM, V12, P475, DOI 10.1007/s12311-012-0440-0
   Britton L, 2014, CLEFT PALATE-CRAN J, V51, P431, DOI 10.1597/13-121
   Brookes A, 2014, EARLY HUM DEV, V90, P765, DOI 10.1016/j.earlhumdev.2014.08.021
   Broome K, 2017, AM J SPEECH-LANG PAT, V26, P1011, DOI 10.1044/2017_AJSLP-16-0014
   Brumbaugh KM, 2013, LANG SPEECH HEAR SER, V44, P306, DOI 10.1044/0161-1461(2013/12-0029)
   Carter JA, 2012, J PSYCHOL AFR, V22, P155, DOI 10.1080/14330237.2012.10820514
   Chaware SH, 2021, J INT SOC PREV COMMU, V11, P469, DOI 10.4103/jispcd.JISPCD_135_21
   Chong WW, 2022, PEDIATR INT, V64, DOI 10.1111/ped.15105
   connectedspeechpathology, MUCH DOES SPEECH THE
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   Cunningham BJ, 2017, J SPEECH LANG HEAR R, V60, P447, DOI 10.1044/2016_JSLHR-L-15-0329
   Pamplona MD, 2020, INT J PEDIATR OTORHI, V138, DOI 10.1016/j.ijporl.2020.110318
   Demenko G, 2010, ARCH ACOUST, V35, P309, DOI 10.2478/v10168-010-0027-z
   Dodd B., 2014, Current Developmental Disorders Reports, V1, P189, DOI DOI 10.1007/S40474-014-0017-3
   Eadie P, 2015, DEV MED CHILD NEUROL, V57, P578, DOI 10.1111/dmcn.12635
   Ertmer DJ, 2010, J SPEECH LANG HEAR R, V53, P1075, DOI 10.1044/1092-4388(2010/09-0250)
   Esch B.E., 2010, Journal of Speech and Language Pathology Applied Behavior Analysis, V5, P166
   Fulcher A, 2012, INT J PEDIATR OTORHI, V76, P1785, DOI 10.1016/j.ijporl.2012.09.001
   Guiberson M, 2012, COMM DISORD Q, V33, P169, DOI 10.1177/1525740110384132
   Hasson N, 2013, CHILD LANG TEACH THE, V29, P57, DOI 10.1177/0265659012459526
   Hochmuth S, 2012, INT J AUDIOL, V51, P536, DOI 10.3109/14992027.2012.670731
   Hustad KC, 2010, J SPEECH LANG HEAR R, V53, P1496, DOI 10.1044/1092-4388(2010/09-0176)
   Ito Y, 2015, PEDIATR INT, V57, P222, DOI 10.1111/ped.12474
   Jacobi I, 2010, EUR ARCH OTO-RHINO-L, V267, P1495, DOI 10.1007/s00405-010-1316-x
   Jesus LMT, 2019, J SPEECH LANG HEAR R, V62, P4045, DOI 10.1044/2019_JSLHR-S-18-0301
   Kayikci MEK, 2012, ANGLE ORTHOD, V82, P14, DOI 10.2319/032911-226.1
   Kent RD, 2013, J SPEECH LANG HEAR R, V56, P178, DOI 10.1044/1092-4388(2012/12-0148)
   Khattab TZ, 2013, ANGLE ORTHOD, V83, P519, DOI 10.2319/073112-619.1
   Krishnan S, 2013, J SPEECH LANG HEAR R, V56, P1800, DOI 10.1044/1092-4388(2013/12-0206)
   Laganaro M, 2021, CLIN LINGUIST PHONET, V35, P1060, DOI 10.1080/02699206.2020.1865460
   Lehner K, 2022, CLIN LINGUIST PHONET, V36, P1093, DOI 10.1080/02699206.2021.1989490
   Liss JM, 2010, J SPEECH LANG HEAR R, V53, P1246, DOI 10.1044/1092-4388(2010/09-0121)
   Low DM, 2020, LARYNGOSCOPE INVEST, V5, P96, DOI 10.1002/lio2.354
   McFaul H, 2022, BMJ OPEN QUAL, V11, DOI 10.1136/bmjoq-2021-001761
   McKechnie J, 2018, INT J SPEECH-LANG PA, V20, P583, DOI 10.1080/17549507.2018.1477991
   McLeod S, 2017, AM J SPEECH-LANG PAT, V26, P691, DOI 10.1044/2017_AJSLP-15-0161
   McLeod S, 2013, J COMMUN DISORD, V46, P375, DOI 10.1016/j.jcomdis.2013.04.003
   McLeod S, 2013, AM J SPEECH-LANG PAT, V22, P503, DOI 10.1044/1058-0360(2012/11-0123)
   Mehta DD, 2015, FRONT BIOENG BIOTECH, V3, DOI 10.3389/fbioe.2015.00155
   Mogren Å, 2020, INT J SPEECH-LANG PA, V22, P526, DOI 10.1080/17549507.2019.1701081
   Morgan AT, 2018, J PEDIATR-US, V198, P234, DOI 10.1016/j.jpeds.2018.02.043
   Mugada V., 2018, INT J RES REV WWW IJ, V5, P241
   Mullen R, 2010, LANG SPEECH HEAR SER, V41, P44, DOI 10.1044/0161-1461(2009/08-0051)
   Murray E, 2015, J SPEECH LANG HEAR R, V58, P43, DOI 10.1044/2014_JSLHR-S-12-0358
   Nelson TL, 2020, FOLIA PHONIATR LOGO, V72, P131, DOI 10.1159/000503131
   Newbold EJ, 2013, CLIN LINGUIST PHONET, V27, P521, DOI 10.3109/02699206.2013.790479
   Ng SI, 2020, INTERSPEECH, P424, DOI 10.21437/Interspeech.2020-2148
   Overuliet GM, 2013, EUR J PAEDIATR NEURO, V17, P390, DOI 10.1016/j.ejpn.2013.01.001
   Parnandi A., 2013, P 15 INT ACM SIGACCE
   Pascoe M, 2010, S AFR J COMMUN DISOR, V57, DOI 10.4102/sajcd.v57i1.51
   Patel R, 2013, AM J SPEECH-LANG PAT, V22, P1, DOI 10.1044/1058-0360(2012/11-0134)
   Pejovic J, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11070939
   Pennington L, 2013, RES DEV DISABIL, V34, P3202, DOI 10.1016/j.ridd.2013.06.035
   Petrillo SM, 2022, NEUROL SCI, V43, P3065, DOI 10.1007/s10072-021-05651-y
   Phillips J, 2014, RES DEV DISABIL, V35, P463, DOI 10.1016/j.ridd.2013.11.020
   Jonathan LP, 2013, AM J SPEECH-LANG PAT, V22, P627, DOI 10.1044/1058-0360(2013/12-0139)
   Ravi SK, 2021, CLIN EPIDEMIOL GLOB, V12, DOI 10.1016/j.cegh.2021.100851
   researchgate, SYSTEMATIC REV INTER
   Rosenbaum S., 2016, COMMITTEE EVALUATION, DOI [10.17226/21872, DOI 10.17226/21872]
   Salunkhe Shradha, 2021, INT J SPEECH-LANG PA, V17, P06, DOI [10.26611/10141712, DOI 10.26611/10141712]
   Schölderle T, 2020, J SPEECH LANG HEAR R, V63, P1071, DOI 10.1044/2020_JSLHR-19-00114
   Schuster M, 2012, ORAL MAXILLOFAC SURG, V16, P291, DOI 10.1007/s10006-012-0340-y
   Seniów J, 2013, TOP STROKE REHABIL, V20, P250, DOI 10.1310/tsr2003-250
   Shahin M, 2015, SPEECH COMMUN, V70, P49, DOI 10.1016/j.specom.2015.04.002
   Sharma D, 2016, INDIAN J CANCER, V53, P397, DOI 10.4103/0019-509X.200676
   Shriberg LD, 2010, CLIN LINGUIST PHONET, V24, P795, DOI 10.3109/02699206.2010.503006
   Speltz ML, 2018, J PEDIATR-US, V198, P226, DOI 10.1016/j.jpeds.2018.02.076
   Stasak B, 2017, INTERSPEECH, P834, DOI 10.21437/Interspeech.2017-1223
   Stelzle F, 2010, J ORAL REHABIL, V37, P209, DOI 10.1111/j.1365-2842.2009.02047.x
   Strand EA, 2013, J SPEECH LANG HEAR R, V56, P505, DOI 10.1044/1092-4388(2012/12-0094)
   Suthar Kerul, 2022, PLOS Digit Health, V1, pe0000041, DOI 10.1371/journal.pdig.0000041
   Taylor OD, 2014, J TELEMED TELECARE, V20, P405, DOI 10.1177/1357633X14552388
   Terband H, 2019, J SPEECH LANG HEAR R, V62, P2999, DOI 10.1044/2019_JSLHR-S-CSMC7-19-0214
   Towey D, 2020, P INT COMP SOFTW APP, P1460, DOI 10.1109/COMPSAC48688.2020.00-49
   Tung LC, 2013, NEUROPSYCH DIS TREAT, V9, P87, DOI 10.2147/NDT.S40499
   Veenhuis SJG, 2021, DEV MED CHILD NEUROL, V63, P450, DOI 10.1111/dmcn.14811
   Walenski Matthew, 2017, J Speech Pathol Ther, V3, DOI 10.4172/2472-5005.1000130
   Wallace IF, 2015, PEDIATRICS, V136, pE448, DOI 10.1542/peds.2014-3889
   Wren Y, 2018, INT J LANG COMM DIS, V53, P446, DOI 10.1111/1460-6984.12371
   Wren Y, 2013, CHILD LANG TEACH THE, V29, P11, DOI 10.1177/0265659012464880
   Zarifian T, 2017, IRAN J PEDIATR, V27, DOI 10.5812/ijp.8217
   Zharkova N, 2013, CLEFT PALATE-CRAN J, V50, P76, DOI 10.1597/11-196
NR 92
TC 2
Z9 2
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 35021
EP 35058
DI 10.1007/s11042-023-14913-0
EA MAR 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943970200014
PM 37362682
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kumari, N
   Anwar, S
   Bhattacharjee, V
   Sahana, SK
AF Kumari, Nandini
   Anwar, Shamama
   Bhattacharjee, Vandana
   Sahana, Sudip Kumar
TI Visually evoked brain signals guided image regeneration using GAN
   variants
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image regeneration; Visually evoked EEG; Generative adversarial network;
   CapsGAN; Structural similarity index measure
AB Generative Adversarial Networks have recently proven to be very effective in generative applications involving images, and they are now being used to regenerate images using visually evoked brain signals. Recent neuroscience research has discovered evidence that brain-evoked data can be used to decipher how the human brain functions. Simultaneously, the latest advancement in deep learning integrated with a high-level interest in generative methods has made learning the data distribution possible and realistic images can be produced from random noise. In this work, an advanced generative adversarial method that incorporates the capsule network with the generative adversarial networks model i.e. Capsule Generative Adversarial Network is proposed to regenerate images with decoded information and formulated features from visually evoked brain signals. There are two stages in the proposed method: Encoder, for data formulation of visually evoked brain activity and the image reconstruction phase from the brain signals. The image regeneration technique has been experimentally tested on a variety of generative adversarial networks including the proposed model and the final reconstructed image samples are compared to assess the quality using various evaluation metrics. The Structural Similarity Index Measure metric for Capsule Generative Adversarial Network has achieved highest value i.e., 0.9203 and outperforms the other GAN variants and also indicates that the Capsule Generative Adversarial Network reconstructed the images similar to original images.
C1 [Kumari, Nandini] Manipal Inst Technol, Dept Data Sci & Comp Applicat, Manipal 576104, Karnataka, India.
   [Anwar, Shamama; Bhattacharjee, Vandana; Sahana, Sudip Kumar] Birla Inst Technol, Dept Comp Sci & Engn, Ranchi 835215, Jharkhand, India.
C3 Manipal Academy of Higher Education (MAHE); Birla Institute of
   Technology Mesra
RP Sahana, SK (corresponding author), Birla Inst Technol, Dept Comp Sci & Engn, Ranchi 835215, Jharkhand, India.
EM missnandinikumari@gmail.com; shamama@bitmesra.ac.in;
   vbhattacharya@bitmesra.ac.in; sudipsahana@bitmesra.ac.in
RI Bhattacharjee, Vandana/IZP-5454-2023
OI Anwar, Shamama/0000-0002-2013-7181
CR Anwar S, 2020, ARAB J SCI ENG, V45, P11103, DOI 10.1007/s13369-020-04983-9
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Berthelot D, 2017, ARXIV
   Bhat S, 2021, THE 14TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2021, P453, DOI 10.1145/3453892.3461338
   Bird JJ, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4316548
   Carlson T, 2013, J VISION, V13, DOI 10.1167/13.10.1
   Donahue J., 2016, arXiv
   Giri D, 2013, KNOWL-BASED SYST, V37, P274, DOI 10.1016/j.knosys.2012.08.011
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I, 2017, ARXIV
   Guo K, 2022, MULTIMED TOOLS APPL, V81, P5889, DOI 10.1007/s11042-021-11822-y
   Gupta A, 2019, PR MACH LEARN RES, V102, P225
   Ha KW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132854
   Hartmann KG, 2018, ARXIV
   Hassan MA, 2024, MULTIMED TOOLS APPL, V83, P15289, DOI 10.1007/s11042-021-11457-z
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huth AG, 2016, FRONT SYST NEUROSCI, V10, DOI 10.3389/fnsys.2016.00081
   Hwang SH, 2019, 2019 IEEE VTS ASIA PACIFIC WIRELESS COMMUNICATIONS SYMPOSIUM (APWCS 2019), DOI 10.1109/vts-apwcs.2019.8851631
   Im D.J., 2016, ARXIV
   Jaiswal A., 2018, P EUROPEAN C COMPUTE
   Jaiswal Ayush., 2018, Asian Conference on Computer Vision, P216
   Kavasidis I, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1809, DOI 10.1145/3123266.3127907
   Khare S, 2022, NEURAL COMPUT APPL, V34, P5979, DOI 10.1007/s00521-021-06774-1
   Kim T, 2017, PR MACH LEARN RES, V70
   Lanaras C, 2018, ISPRS J PHOTOGRAMM, V146, P305, DOI 10.1016/j.isprsjprs.2018.09.018
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Luo ZP, 2019, IOP C SER EARTH ENV, V252, DOI 10.1088/1755-1315/252/4/042127
   Majdabadi MM, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC)
   Marusaki K, 2020, ARXIV
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Odena A, 2017, PR MACH LEARN RES, V70
   Olivas-Padilla BE, 2019, APPL SOFT COMPUT, V75, P461, DOI 10.1016/j.asoc.2018.11.031
   Op de Beeck HP, 2008, J NEUROSCI, V28, P10111, DOI 10.1523/JNEUROSCI.2511-08.2008
   Palazzo S, 2017, IEEE I CONF COMP VIS, P3430, DOI 10.1109/ICCV.2017.369
   Radford A., 2015, ARXIV
   Ramos-Aguilar R, 2020, PATTERN RECOGN LETT, V133, P202, DOI 10.1016/j.patrec.2020.03.006
   Ruoyu Wang, 2019, 2019 International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM). Proceedings, P325, DOI 10.1109/AIAM48774.2019.00071
   Sabour S, 2017, ARXIV
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Seeliger K, 2018, NEUROIMAGE, V181, P775, DOI 10.1016/j.neuroimage.2018.07.043
   Shao GF, 2020, IEEE ACCESS, V8, P154691, DOI 10.1109/ACCESS.2020.3007266
   Song JK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P899
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Tirupattur P, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P950, DOI 10.1145/3240508.3240641
   Upadhyay Y., 2018, ARXIV
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yuhas R.H., 1992, Discrimination Among Semi-arid Landscape Endmembers Using the Spectral Angle Mapper (SAM) Algorithm
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2069
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 51
TC 3
Z9 3
U1 6
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32259
EP 32279
DI 10.1007/s11042-023-14769-4
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943163700002
DA 2024-07-18
ER

PT J
AU Hong, SA
   Huu, QN
   Viet, DC
   Thuy, QDT
   Quoc, TN
AF Hong, Son An
   Huu, Quynh Nguyen
   Viet, Dung Cu
   Thuy, Quynh Dao Thi
   Quoc, Tao Ngo
TI Improving image retrieval effectiveness via sparse discriminant analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval (CBIR); Relevance feedback; Sparse
   discriminant analysis; Small-class problem; Feature selection and
   extraction
ID FEATURE-SELECTION; CLASSIFICATION; REGRESSION; PROJECTION
AB The semantic gap between low-level features and high-level semantic concepts is a fundamental problem in content-based image retrieval (CBIR). To close this gap, relevant feedback is included in the CBIR. Based on the user's feedback samples, a projection matrix is learned to project samples from the multi-dimensional original space to the low-dimensional projection space, and a classifier is learned on the projection space to classify the images. However, the number of classes in the relevance feedback is very small (only two classes), which leads to low classification performance and results in poor retrieval performance. To solve this problem, we propose a novel supervised image retrieval method, called Sparse Discriminant Analysis for Image Retrieval (SDAIR). Different from existing image retrieval methods, which have low precision due to small-class size problems, SDAIR is designed to not be affected by small-class size problems. Therefore, SDAIR is potentially more suitable for image retrieval with relevant feedback, where class sizes are often very small. The experimental results on the two databases demonstrate that the proposed method obtains competitive precision compared with other content-based image retrieval methods.
C1 [Hong, Son An] Viet Hung Univ, Hanoi, Vietnam.
   [Huu, Quynh Nguyen; Viet, Dung Cu] Thuyloi Univ, 175 Tay Son, Dong Da, Hanoi, Vietnam.
   [Thuy, Quynh Dao Thi] Posts & Telecommun Inst Technol, Hanoi, Vietnam.
   [Quoc, Tao Ngo] Vietnam Acad Sci & Technol, Inst Informat Technol, Hanoi, Vietnam.
C3 Thuyloi University; Vietnam Academy of Science & Technology (VAST)
RP Huu, QN (corresponding author), Thuyloi Univ, 175 Tay Son, Dong Da, Hanoi, Vietnam.
EM sonanhongvh@gmail.com; quynhnh@tlu.edu.vn; dungcv@tlu.edu.vn;
   quynhdtt@ptit.edu.vn; nqtao@ioit.ac.vn
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2020.10]
FX AcknowledgmentsThis research is funded by Vietnam National Foundation
   for Science and Technology Development (NAFOSTED) under grant number
   102.01-2020.10".
CR Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Chen W., 2021, ARXIV
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dorfer M., 2015, arXiv, P1, DOI [10.48550/arXiv.1511.04707, DOI 10.48550/ARXIV.1511.04707]
   Dornaika F, 2021, KNOWL INF SYST, V63, P1029, DOI 10.1007/s10115-020-01535-3
   Dornaika F, 2020, NEURAL NETWORKS, V127, P141, DOI 10.1016/j.neunet.2020.04.018
   Duda R., 1973, Pattern Classification and Scene Analysis
   Duda RO., 2012, Pattern classificatio
   Fan ZZ, 2011, IEEE T NEURAL NETWOR, V22, P1119, DOI 10.1109/TNN.2011.2152852
   Hameed IM, 2021, COGENT ENG, V8, DOI 10.1080/23311916.2021.1927469
   Han N, 2018, NEURAL NETWORKS, V108, P202, DOI 10.1016/j.neunet.2018.08.003
   Hassan G, 2020, BIOMED ENG-APP BAS C, V32, DOI 10.4015/S1016237220500398
   Hassan G, 2020, IEEE ACCESS, V8, P175669, DOI 10.1109/ACCESS.2020.3026452
   Huijsmans DP, 2005, IEEE T PATTERN ANAL, V27, P245, DOI 10.1109/TPAMI.2005.30
   Huu QN, 2021, MULTIMED TOOLS APPL, V80, P15351, DOI 10.1007/s11042-020-10400-y
   Jia Y., 2014, arXiv
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Khoder A, 2021, NEURAL NETWORKS, V136, P11, DOI 10.1016/j.neunet.2020.12.025
   Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291
   Lai ZH, 2020, INT J MACH LEARN CYB, V11, P2247, DOI 10.1007/s13042-020-01113-7
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Liu ZH, 2020, MULTIMED TOOLS APPL, V79, P11993, DOI 10.1007/s11042-019-08434-y
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Sathiamoorthy S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-1941-y
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith L.I., 2002, TUTORIAL PRINCIPAL C
   Stanczyk U., 2018, Advances in Feature Selection for Dataand Pattern Recognition, Intell. Syst. Ref. Libr., DOI [10.1007/978-3-319-67588-6, DOI 10.1007/978-3-319-67588-6]
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Xiang SM, 2012, IEEE T NEUR NET LEAR, V23, P1738, DOI 10.1109/TNNLS.2012.2212721
   Yan CX, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3418284
   Zhang LN, 2016, IEEE T IMAGE PROCESS, V25, P1275, DOI 10.1109/TIP.2016.2516947
   Zhang LN, 2014, IEEE T CIRC SYST VID, V24, P346, DOI 10.1109/TCSVT.2013.2276172
   Zhou XS, 2001, PROC CVPR IEEE, P11
   Zhu RF, 2019, NEURAL NETWORKS, V111, P35, DOI 10.1016/j.neunet.2018.12.008
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 40
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30807
EP 30830
DI 10.1007/s11042-023-14748-9
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000941926100001
DA 2024-07-18
ER

PT J
AU Al-Amri, S
   Hamid, S
   Noor, NFM
   Gani, A
AF Al-Amri, Saud
   Hamid, Suraya
   Noor, Nurul Fazmidar Mohd
   Gani, Abdullah
TI A framework for designing interactive mobile training course content
   using augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Designing mobile training course content; Mobile training; Mobile
   learning; Mobile augmented reality
ID TECHNOLOGIES; CHALLENGES; PRINCIPLES; MOTIVATION; ISSUES; APP
AB Because mobile technology and the widespread usage of mobile devices have swiftly and radically evolved, several training centers have started to offer mobile training (m-training) via mobile devices. Thus, designing suitable m-training course content for training employees via mobile device applications has become an important professional development issue to allow employees to obtain knowledge and improve their skills in the rapidly changing mobile environment. Previous studies have identified challenges in this domain. One important challenge is that no solid theoretical framework serves as a foundation to provide instructional design guidelines for interactive m-training course content that motivates and attracts trainees to the training process via mobile devices. This study proposes a framework for designing interactive m-training course content using mobile augmented reality (MAR). A mixed-methods approach was adopted. Key elements were extracted from the literature to create an initial framework. Then, the framework was validated by interviewing experts, and it was tested by trainees. This integration led us to evaluate and prove the validity of the proposed framework. The framework follows a systematic approach guided by six key elements and offers a clear instructional design guideline checklist to ensure the design quality of interactive m-training course content. This study contributes to the knowledge by establishing a framework as a theoretical foundation for designing interactive m-training course content. Additionally, it supports the m-training domain by assisting trainers and designers in creating interactive m-training courses to train employees, thus increasing their engagement in m-training. Recommendations for future studies are proposed.
C1 [Al-Amri, Saud; Hamid, Suraya; Noor, Nurul Fazmidar Mohd; Gani, Abdullah] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya
RP Hamid, S (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
EM saud-alamri@hotmail.com; suraya_hamid@um.edu.my; fazmidar@um.edu.my;
   abdullahgani@ums.edu.my
RI Hamid, Suraya/JCE-1921-2023; Gani, Abdullah/C-2888-2009
CR Admin, 2021, SHIFT ELEARNING
   Al-Amri S, 2020, IEEE ACCESS, V8, P122314, DOI 10.1109/ACCESS.2020.3006712
   Al-Hunaiyyan A, 2018, J KING SAUD UNIV-COM, V30, P279, DOI 10.1016/j.jksuci.2016.12.001
   Alawani A.S. A., 2017, International Journal of Management and Applied Research, V4, P146, DOI [DOI 10.18646/2056.43, 10.18646/2056.43.17-012]
   Ally M., 2014, Increasing access through mobile learning
   Ally M, 2016, ADV EDUC TECHNOL INS, P161, DOI 10.4018/978-1-5225-0466-5.ch009
   Alsaadat K., 2017, INT J ELECT COMPUTER, V7, P2833, DOI [10.11591/ijece.v7i5.pp2833-2837, DOI 10.11591/IJECE.V7I5.PP2833-2837]
   Alsop T., 2022, STATISTA
   Andriotis, 2017, TALENT LMS BLOG
   [Anonymous], 2013, UNESCO PUBLICATIONS
   Arpaci I, 2015, BRIT J EDUC TECHNOL, V46, P699, DOI 10.1111/bjet.12160
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bacca J, 2019, AUSTRALAS J EDUC TEC, V35, P102, DOI 10.14742/ajet.4182
   Baran E, 2014, EDUC TECHNOL SOC, V17, P17
   Bryman A., 2012, How many qualitative interviews is enough? Expert voices and early career reflections, P18
   Bulagang AF., 2017, INDIAN J SCI TECHNOL, V10, P1, DOI [10.17485/ijst/2017/v10i39/119872, DOI 10.17485/IJST/2017/V10I39/119872]
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chiang THC, 2014, EDUC TECHNOL SOC, V17, P352
   Churchill D, 2016, LECT N EDUC TECHNOL, P3, DOI 10.1007/978-981-10-0027-0_1
   Classy Content Design, 2019, CONT DEV CLASS CONT
   Cochrane T, 2017, EDUC ASIA PACIF REG, V40, P25, DOI 10.1007/978-981-10-4944-6_2
   Crescente ML, 2011, J IND PROD ENG, V28, P111, DOI 10.1080/10170669.2010.548856
   Creswell J. W., 2018, QUAL INQ
   Creswell J. W., 2013, RES DESIGN QUALITATI
   DePasque S, 2015, NEUROIMAGE, V119, P175, DOI 10.1016/j.neuroimage.2015.06.046
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   ELearning Infographics, 2015, UND DIFF ELEARNING M
   ELearning Infographics, 2017, 3 LEARN THEOR INSTR
   Elias T, 2011, INT REV RES OPEN DIS, V12, P143, DOI 10.19173/irrodl.v12i2.965
   Figueredo, 2015, HDB MOBILE TEACHING, P75, DOI [10.1007/978-3-642-54146-9_87, DOI 10.1007/978-3-642-54146-9_87]
   Gedik N, 2012, COMPUT EDUC, V58, P1149, DOI 10.1016/j.compedu.2011.12.002
   Gerstein J, 2013, HANDBOOK OF MOBILE LEARNING, P268
   Haag, 2014, HDB MOBILE TEACHING, P1, DOI [10.1007/978-3-642-41981-2_61-1, DOI 10.1007/978-3-642-41981-2_61-1]
   Hedberg Hillevi, 2018, International Journal of Interactive Mobile Technologies, V12, P75, DOI 10.3991/ijim.v12i3.8404
   Huizenga J, 2009, J COMPUT ASSIST LEAR, V25, P332, DOI [10.1111/J.1365-2729.2009.00316.x, 10.1111/j.1365-2729.2009.00316.x]
   Jackson T, 2011, HANDBOOK OF AUGMENTED REALITY, P409, DOI 10.1007/978-1-4614-0064-6_19
   Jugaru, 2021, HONGKIAT
   Kearney M., 2020, Theor. Implement. Mob. Learn., P89, DOI [10.1007/978-981-15-8277-6_7, DOI 10.1007/978-981-15-8277-6_7]
   Kearney M, 2012, RES LEARN TECHNOL, V20, DOI 10.3402/rlt.v20i0.14406
   Keller JM, 2010, MOTIVATIONAL DESIGN FOR LEARNING AND PERFORMANCE: THE ARCS MODEL APPROACH, P43, DOI 10.1007/978-1-4419-1250-3_3
   Khaddage F, 2015, EDUC INF TECHNOL, V20, P625, DOI 10.1007/s10639-015-9400-x
   Knowles MS., 2020, The adult learner: The definitive classic in adult education and human resource development, V9th, DOI DOI 10.4324/9780429299612
   Ko SM, 2013, INT J HUM-COMPUT INT, V29, P501, DOI 10.1080/10447318.2012.722466
   Koole ML, 2009, ISS ONLINE EDUC, P25
   Kukulska-Hulme A., 2007, INT REV RES OPEN DIS, V8, P1, DOI DOI 10.19173/IRRODL.V8I2.356
   Kukulska-Hulme A, 2009, INT J MOB BLENDED LE, V1, P13, DOI 10.4018/jmbl.2009010102
   Kumar Basak S., 2018, E-LEARNING DIGITAL M, V15, P191, DOI [10.1177/2042753018785180, DOI 10.1177/2042753018785180]
   Kumar BA, 2019, EDUC INF TECHNOL, V24, P3537, DOI 10.1007/s10639-019-09937-9
   Kurt S., 2015, EDUC TECHNOL
   Linde AS, 2019, MIL MED, V184, P72, DOI 10.1093/milmed/usy385
   Lozano, 2018, 4 REASONS WHY AR TRA
   Madhusudhan M, 2017, DESIDOC J LIB INF TE, V37, P109, DOI 10.14429/djlit.37.2.11116
   Mahoney, 2018, LEAN LEARNING USING
   Pedro LFMG, 2018, INT J EDUC TECHNOL H, V15, DOI 10.1186/s41239-018-0091-4
   Misman J., 2021, J LANGUAGE LINGUISTI, V17, P529, DOI [10.52462/jlls.35, DOI 10.52462/JLLS.35]
   Molenda M., 2003, PERFORMANCE IMPROVEM, V42, P34, DOI DOI 10.1002/PFI.4930420508
   Muslimin MS, 2017, MALAYS J LEARN INSTR, P221
   Nincarean D, 2013, PROCD SOC BEHV, V103, P657, DOI 10.1016/j.sbspro.2013.10.385
   Oufqir Zainab, 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P599, DOI 10.1007/978-981-15-0947-6_57
   Park Y, 2011, INT REV RES OPEN DIS, V12, P78, DOI 10.19173/irrodl.v12i2.791
   Parsazadeh N, 2018, COMPUT EDUC, V120, P75, DOI 10.1016/j.compedu.2018.01.010
   Pereira ORE, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543594
   Reeves T. C., 2012, Encyclopedia of the Sciences of Learning, P1602, DOI [https://doi.org/10.1007/978-1-4419-1428-6_330, DOI 10.1007/978-1-4419-1428-6_330]
   Rikala, 2015, JYVASKYLA STUDIES CO, V220, P240
   Rosell-Aguilar F, 2017, CALICO J, V34, P243, DOI 10.1558/cj.27623
   Sharples M, 2009, TECHNOLOGY-ENHANCED LEARNING: PRINCIPLES AND PRODUCTS, P233, DOI 10.1007/978-1-4020-9827-7_14
   Shweiki S, 2021, INT J ETHICS EDUC, V6, P339, DOI 10.1007/s40889-021-00128-0
   Song D., 2014, The new landscape of mobile learning: Redesigning education in an app-based world, P120, DOI [10.4324/9780203108420, DOI 10.4324/9780203108420]
   Toprak E, 2010, TURK ONLINE J EDUC T, V9, P78
   Traxler J., 2007, INT REV RES OPEN DIS, V8, P1, DOI DOI 10.19173/IRRODL.V8I2.346
   Vaterlaus J.M., 2019, ADV METHODOLOGIES TE, P488, DOI DOI 10.4018/978-1-5225-7601-3.CH039
   Wang, 2013, LECT NOTES ELECT ENG, P797, DOI [10.1007/978-1-4471-4811-1_102, DOI 10.1007/978-1-4471-4811-1_102]
   Wang MJ, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT ENVIRONMENTS (IE), P318, DOI 10.1109/IE.2014.68
   Wohlin C, 2014, P 18 INT C EVALUATIO, DOI DOI 10.1145/2601248.2601268
   Zhang ZN, 2021, MULTIMED TOOLS APPL, V80, P575, DOI 10.1007/s11042-020-09684-x
   Zidoun Y., 2019, International Journal of Interactive Mobile Technologies, V13, P152, DOI 10.3991/ijim.v13i12.10841
NR 76
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30491
EP 30541
DI 10.1007/s11042-023-14561-4
EA FEB 2023
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000939106800001
PM 36855614
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kumar, A
   Patel, VK
AF Kumar, Alok
   Patel, Vijesh Kumar
TI Classification and identification of disease in potato leaf using
   hierarchical based deep learning convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Potato leaf; Disease detection; Median filtering technique; Noise
   removal; Intuitionistic fuzzy local binary pattern; Hierarchical deep
   learning convolutional neural network; Decision support systems
AB Agriculture is a major source of income of a nation's economy and it plays an important role in feeding mankind. Agriculturists and scientists are working hard to maximize productivity while minimizing the impact on the environment. One important aspect of smart agriculture is disease management in crops. Crops are affected by several diseases caused by pest infestation and pathogens like viruses, bacteria, and fungus. Diseases can be detected early which damage control is aided, and yield loss is avoided. In this paper, a Hierarchical Deep Learning Convolutional Neural Network (HDLCNN) is proposed to detect the diseases in the leaf. Initially, a pre-processing step is performed utilizing the Median Filtering method. This removes the noises in the image. After processing the image, an Intuitionistic Fuzzy Local Binary pattern (IFLBP) is introduced, it extracts the features of the leaf. Then the Hierarchical Deep Learning Convolutional Neural Network is used to detect and classify the disease and the Decision Support Systems help farmers implement effective treatment programs. These allow farmers to increase the efficiency of control techniques without increasing the risks. This method is evaluated and executed in the Matlab Simulink software. While compared to different methods, the proposed technique performs better performance, existing methods are VGG-INCEP, Deep CNN, Random forest methods (RF) and other Spiking neural networks (SNN) models. The accuracy, precision, recall, and F-score of the proposed method is approximately 4%, 6%, 3%, and 3.5% higher than the other existing methods. Then the specificity, sensitivity, and PSNR of the proposed method is 4.5%, 1%, and 2% higher than the existing methods. Thus utilizing this proposed HDLCNN, its performance of the method is improved and this research alerts the former. Through this the former can prevent the leaf from diseases, thus the crop of potato is improved worldwide.
C1 [Kumar, Alok; Patel, Vijesh Kumar] Bakhtiyarpur Coll Engn, Bakhtiyarpur, Bihar, India.
RP Kumar, A (corresponding author), Bakhtiyarpur Coll Engn, Bakhtiyarpur, Bihar, India.
EM alokalok005@gmail.com; vijeshkumarpatel4@gmail.com
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Abdu AM, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105660
   Abdu AM, INT J ARTIF INTELL
   Ansari MD, 2020, J INTELL SYST, V29, P19, DOI 10.1515/jisys-2016-0155
   Arjunagi S, 2020, J HEALTHC ENG
   Chouhan SS, 2021, WIRELESS PERS COMMUN, V121, P1757, DOI 10.1007/s11277-021-08734-3
   Chouhan SS, 2018, IEEE ACCESS, V6, P8852, DOI 10.1109/ACCESS.2018.2800685
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Dhivya S., 2021, Turkish Journal of Computer and Mathematics Education (TURCOMAT), V12, P3776
   Duarte-Carvajalino JM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101513
   Fulari UN, J SEYBOLD REPORT
   Ganatra N., 2020, International Journal on Emerging Technologies, V11, P1082
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Gold KM, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020286
   Griffel LM, 2018, COMPUT ELECTRON AGR, V153, P318, DOI 10.1016/j.compag.2018.08.027
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kanchanadevi B, 2020, J AMB INTEL HUM COMP, V10, P2132, DOI [10.21917/ijivp.2020.0304, DOI 10.21917/IJIVP.2020.0304]
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Kurmi Y, 2021, INF PROCESS AGR
   Liu B, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.01082
   Mukherjee A, 2020, International Journal of Scientific & Engineering Research, V11, P1905, DOI [10.14299/ijser.2020.08.12, DOI 10.14299/IJSER.2020.08.12]
   Oo Y.M., 2018, International Journal of Research and Engineering, V5, P516, DOI DOI 10.21276/IJRE.2018.5.9.4
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   Rao A, 2020, INT J ELEC ENG EDUC, DOI 10.1177/0020720920953126
   Roy D, 2020, NEURAL NETWORKS, V121, P148, DOI 10.1016/j.neunet.2019.09.010
   Saha S, 2021, COMPUT METHOD APPL M, V373, DOI 10.1016/j.cma.2020.113452
   Vidya BS, 2019, ALEX ENG J, V58, P103, DOI 10.1016/j.aej.2018.12.008
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yusof MAM., 2021, EVOL ELECT ELECT ENG, V2, P834
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
NR 32
TC 11
Z9 11
U1 7
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31101
EP 31127
DI 10.1007/s11042-023-14663-z
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000936292600003
DA 2024-07-18
ER

PT J
AU Srinivasarao, U
   Sharaff, A
AF Srinivasarao, Ulligaddala
   Sharaff, Aakanksha
TI Machine intelligence based hybrid classifier for spam detection and
   sentiment analysis of SMS messages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spam detection; Short message service; Sentiment analysis; Data
   augmentation; And feature selection
ID FEATURE-SELECTION
AB Short Message Service (SMS) on mobile phones has improved because of technological advancements and increases in content-based marketing where smart phones are frequently overburden with spam SMS. Spam messages are not important since they include virus and spyware. Several text classification methods have been suggested to address spam. However, none of these methods can guarantee a full spam-free solution since each filtering and modeling methodology has its own set of strengths and weaknesses. This paper suggests a hybrid classifier based on SMS spam classification and sentiment analysis. The datasets are pre-processed and Word2vec data augmentation is used to extract the features. Then, the features are fed to six various feature selection methods and equilibrium optimization (EO). Optimum components are then fed into a hybrid K-Nearest Neighbors (KNN) and support vector machine (SVM) classifier is to classify SMS messages. Further, to optimize the parameters of the network and to improve the accuracy, the optimization algorithm Rat Swarm Optimization (RSO) is used. Then, AFINN and SentiWordNet are used for sentiment analysis. This framework is evaluated on the three benchmark datasets; when comparing the performance of proposed method on the three dataset, spam assassin dataset achieves better spam detection accuracy of 99.82%.
C1 [Srinivasarao, Ulligaddala; Sharaff, Aakanksha] Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Srinivasarao, U (corresponding author), Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur, Chhattisgarh, India.
EM usrinivasarao.phd2018.cs@nitrr.ac.in; asharaff.cs@nitrr.ac.in
RI Srinivasarao, ulligaddala/ABK-2243-2022; Sharaff, Aakanksha/L-9995-2016
OI Srinivasarao, ulligaddala/0000-0001-9199-2700; Sharaff,
   Aakanksha/0000-0001-5499-7289
CR Abayomi-Alli O, 2019, ENG APPL ARTIF INTEL, V86, P197, DOI 10.1016/j.engappai.2019.08.024
   Abdulhamid SM, 2017, IEEE ACCESS, V5, P15650, DOI 10.1109/ACCESS.2017.2666785
   Agarwal B, 2018, INFORM PROCESS MANAG, V54, P922, DOI 10.1016/j.ipm.2018.06.005
   [Anonymous], 2016, Series Title: Communications in Computer and Information Science
   Arivoli PV., 2017, INT J ADV RES COMPUT, V8, P299, DOI [10.26483/ijarcs.v8i8.4699, DOI 10.26483/IJARCS.V8I8.4699]
   Barushka A, 2020, NEURAL COMPUT APPL, V32, P4239, DOI 10.1007/s00521-019-04331-5
   Cekik R, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113691
   Chandra Arijit, 2019, 2019 4th International Conference on Information Systems and Computer Networks (ISCON), P118, DOI 10.1109/ISCON47742.2019.9036269
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Gupta M., 2018, 2018 20th National Power Systems Conference (NPSC), P1, DOI [DOI 10.1109/NPSC.2018.8771708, 10.1109/NPSC.2018.8771708]
   Karakus BA, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4783
   Kou G, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105836
   Kumar N, 2017, INT CONF ADV COMPU, P15, DOI 10.1109/ICoAC.2017.8441495
   Labani M, 2018, ENG APPL ARTIF INTEL, V70, P25, DOI 10.1016/j.engappai.2017.12.014
   Lall S, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107697
   Lee HK, 2020, INT J CULT POLICY, V26, P544, DOI 10.1080/10286632.2019.1577401
   Li F, 2020, 2020 IEEE 30 INT WOR, P1
   Liu YQ, 2020, NEURAL PROCESS LETT, V51, P1771, DOI 10.1007/s11063-019-10185-8
   Madasu A, 2020, MULTIMED TOOLS APPL, V79, P6313, DOI 10.1007/s11042-019-08409-z
   Méndez JR, 2019, APPL SOFT COMPUT, V76, P89, DOI 10.1016/j.asoc.2018.12.008
   Naresh Kumar K. E., 2020, Emerging Trends in Electrical, Communications, and Information Technologies. Proceedings of ICECIT-2018. Lecture Notes in Electrical Engineering (LNEE 569), P117, DOI 10.1007/978-981-13-8942-9_11
   Navaney P, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE CONFLUENCE 2018 ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING, P43, DOI 10.1109/CONFLUENCE.2018.8442564
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Ordoñez AJ, 2018, INT SYMP COMP CONS, P233, DOI 10.1109/IS3C.2018.00066
   Pong-Inwong C, 2019, INT J MACH LEARN CYB, V10, P2177, DOI 10.1007/s13042-018-0800-2
   Popovac M, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P807
   Roy PK, 2020, FUTURE GENER COMP SY, V102, P524, DOI 10.1016/j.future.2019.09.001
   Sharaff Aakanksha, 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 813), P555, DOI 10.1007/978-981-13-1498-8_49
   Sharma S, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6_37
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Sisodia D. S., 2020, 2nd International Conference on Data, Engineering and Applications (IDEA), P1, DOI DOI 10.1109/IDEA49133.2020.9170720
   Sjarif NNA, 2019, PROCEDIA COMPUT SCI, V161, P509, DOI 10.1016/j.procs.2019.11.150
   Su YJ, 2020, J SUPERCOMPUT, V76, P9127, DOI 10.1007/s11227-020-03198-x
   Suleiman D, 2017, PROCEDIA COMPUT SCI, V113, P154, DOI 10.1016/j.procs.2017.08.335
   Xia T, 2020, IEEE ACCESS, V8, P82653, DOI 10.1109/ACCESS.2020.2991328
   Zainal K, 2016, INT C SOFT COMP DAT, P158
NR 38
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31069
EP 31099
DI 10.1007/s11042-023-14641-5
EA FEB 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000936292600004
DA 2024-07-18
ER

PT J
AU Mohy-eddine, M
   Guezzaz, A
   Benkirane, S
   Azrour, M
AF Mohy-eddine, Mouaad
   Guezzaz, Azidine
   Benkirane, Said
   Azrour, Mourade
TI An efficient network intrusion detection model for IoT security using
   K-NN classifier and feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network security; Intrusion detection; IoT; K-NN; Bot-IoT; Feature
   selection
ID DETECTION SYSTEM; CYBER SECURITY; INTERNET; THINGS; ENSEMBLE; ATTACKS
AB The Internet of Things (IoT) interconnects billions of sensors and actuators to serve a meaningful purpose. However, it is always vulnerable to various menaces. Thus, IoT security represents a big concern in the research field. Various tools were developed to mitigate these security issues. So, Intrusion detection systems (IDS) have gained much attention in the research community due to their critical role in maintaining network security. In this work, we integrate a network IDS (NIDS) to enhance IoT security. This paper presents a network intrusion detection model for IoT environments using a K-Nearest Neighbors (K-NN) classifier and feature selection. We built the NIDS using the K-NN algorithm to improve the IDS accuracy (ACC) and detection rate (DR). Furthermore, the principal component analysis (PCA), univariate statistical test, and genetic algorithm (GA) are used for feature selection separately to improve the data quality and select the ten best performing features. The performance evaluation of our model is performed on the Bot-IoT dataset. After applying the feature selection, the models have shown promising results regarding ACC, DR, false alarm rate (FAR), and predicting time. Our proposed model provided 99.99% ACC and maintained its superior performance for the ten selected features. Furthermore, we calculated the prediction time, as we consider it critical in building IDS for IoT, and by applying feature selection, we reduced it significantly from 51,182.22 s to under a minute. This novel model presents many advantages and reliable performances compared with previous models relying on the same dataset.
C1 [Mohy-eddine, Mouaad; Guezzaz, Azidine; Benkirane, Said] Cadi Ayyad Univ, Technol Higher Sch Essaouira, Marrakech, Morocco.
   [Azrour, Mourade] Moulay Ismail Univ Meknes, Fac Sci & Tech, STI Lab, IDMS Team, Errachidia, Morocco.
C3 Cadi Ayyad University of Marrakech; Moulay Ismail University of Meknes
RP Guezzaz, A (corresponding author), Cadi Ayyad Univ, Technol Higher Sch Essaouira, Marrakech, Morocco.
EM a.guzzaz@gmail.com
RI Mohy-eddine, Mouaad/GRR-7843-2022; MOHY-EDDINE, Mouaad/IQV-0934-2023
OI Mohy-eddine, Mouaad/0000-0003-0818-0221; MOHY-EDDINE,
   Mouaad/0000-0003-0818-0221
CR Ahmim A, 2019, IEEE INT CONF DISTR, P228, DOI 10.1109/DCOSS.2019.00059
   Al-Qaseemi SA, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P731, DOI 10.1109/FTC.2016.7821686
   Alaba FA, 2017, J NETW COMPUT APPL, V88, P10, DOI 10.1016/j.jnca.2017.04.002
   Aldweesh A, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105124
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Atkinson R, 2016, 2016 INT S NETW COMP, P1, DOI [DOI 10.1109/ISNCC.2016.7746067, 10.1109/ISNCC.2016.7746067]
   Ayo FE, 2020, INF SECUR J, V29, P267, DOI 10.1080/19393555.2020.1767240
   Azrour M., 2021, INTELLIGENT SYSTEMS, V1344, P261, DOI DOI 10.1007/978-3-030-72588-4_18
   Azrour M, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5533843
   Azrour M, 2021, BIG DATA MIN ANAL, V4, P1, DOI 10.26599/BDMA.2020.9020010
   Bamakan SMH, 2016, NEUROCOMPUTING, V199, P90, DOI 10.1016/j.neucom.2016.03.031
   Bennett KP, 1999, ADV NEUR IN, V11, P368
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Buczak AL, 2016, IEEE COMMUN SURV TUT, V18, P1153, DOI 10.1109/COMST.2015.2494502
   Chanal PM, 2020, WIRELESS PERS COMMUN, V115, P1667, DOI 10.1007/s11277-020-07649-9
   Chen JW, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106167
   DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Ferrag MA, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102419
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   García-Teodoro P, 2009, COMPUT SECUR, V28, P18, DOI 10.1016/j.cose.2008.08.003
   Ge MM, 2021, COMPUT NETW, V186, DOI 10.1016/j.comnet.2020.107784
   Gu J, 2021, COMPUT SECUR, V103, DOI 10.1016/j.cose.2020.102158
   Gu J, 2019, COMPUT SECUR, V86, P53, DOI 10.1016/j.cose.2019.05.022
   Guezzaz A., 2019, International Journal of Network Security, V21, P438
   Guezzaz A., 2021, INTELLIGENT SYSTEMS, V1344, P85
   Guezzaz A., 2017, Gen. Lett. Math., V2, P57
   Guezzaz A, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/1230593
   Guezzaz A, 2021, BIG DATA MIN ANAL, V4, P18, DOI 10.26599/BDMA.2020.9020019
   Idrissi I., 2021, IAES International Journal of Artificial Intelligence, V10, P110, DOI DOI 10.11591/IJAI.V10.I1.PP110-120
   Jabbar MA, 2017, PROCEDIA COMPUT SCI, V115, P226, DOI 10.1016/j.procs.2017.09.129
   Khalili A, 2018, INT J CRIT INFR PROT, V22, P113, DOI 10.1016/j.ijcip.2018.06.003
   Khraisat A, 2019, CYBERSECURITY, V2, DOI 10.1186/s42400-019-0038-7
   Koroniotis N, 2019, FUTURE GENER COMP SY, V100, P779, DOI 10.1016/j.future.2019.05.041
   Kuang T, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8598543
   Lee JD, 2021, CMC-COMPUT MATER CON, V67, P1537, DOI 10.32604/cmc.2021.014774
   Li L, 2010, INT CONF COMP SCI, P169, DOI 10.1109/ICCSIT.2010.5563714
   Liao HJ, 2013, J NETW COMPUT APPL, V36, P16, DOI 10.1016/j.jnca.2012.09.004
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Mebawondu JO., 2020, SCI AFR, V9
   Meidan Y, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101968
   Miller DJ, 1997, ADV NEUR IN, V9, P571
   Mukhopadhyay I, 2015, P 2015 INT C WORKSH, P1
   Noor MBM, 2019, COMPUT NETW, V148, P283, DOI 10.1016/j.comnet.2018.11.025
   Peng K, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/8267838
   Pise NN, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P593
   Rathore S, 2021, IEEE T IND INFORM, V17, P5522, DOI 10.1109/TII.2020.3040968
   Sadaf K, 2020, IEEE ACCESS, V8, P167059, DOI 10.1109/ACCESS.2020.3022855
   Sadreazami H, 2018, IEEE T SIGNAL INF PR, V4, P137, DOI 10.1109/TSIPN.2017.2749976
   Sallam AA, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P255, DOI [10.1109/cspa48992.2020.9068679, 10.1109/CSPA48992.2020.9068679]
   Sarker IH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050754
   Saxena A, 2019, ADV INTELL SYST COMP, V841, P365, DOI 10.1007/978-981-13-2285-3_43
   Sethi P, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/9324035
   Shafiq M, 2020, FUTURE GENER COMP SY, V107, P433, DOI 10.1016/j.future.2020.02.017
   Sicato JCS, 2020, J INF PROCESS SYST, V16, P975
   Tcydenova E, 2021, IEEE T INTELL TRANSP, V11
   Tufan E, 2021, IEEE ACCESS, V9, P50078, DOI 10.1109/ACCESS.2021.3068961
   Ullah I, 2021, IEEE ACCESS, V9, P103906, DOI 10.1109/ACCESS.2021.3094024
   Verma A, 2020, WIRELESS PERS COMMUN, V111, P2287, DOI 10.1007/s11277-019-06986-8
   von Solms R, 2013, COMPUT SECUR, V38, P97, DOI 10.1016/j.cose.2013.04.004
   Waskle Subhash, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P803, DOI 10.1109/ICESC48915.2020.9155656
   Wazirali R, 2020, ARAB J SCI ENG, V45, P10859, DOI 10.1007/s13369-020-04907-7
NR 62
TC 22
Z9 23
U1 8
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23615
EP 23633
DI 10.1007/s11042-023-14795-2
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000934216300001
DA 2024-07-18
ER

PT J
AU Tembhurne, JV
   Hebbar, N
   Patil, HY
   Diwan, T
AF Tembhurne, Jitendra V.
   Hebbar, Nachiketa
   Patil, Hemprasad Y.
   Diwan, Tausif
TI Skin cancer detection using ensemble of machine learning and deep
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma; Skin cancer; Deep learning; Machine learning; Contourlet
   transform
ID MELANOMA; CLASSIFICATION; BINARY
AB Skin cancer is one of the most common forms of cancer, which makes it pertinent to be able to diagnose it accurately. In particular, melanoma is a form of skin cancer that is fatal and accounts for 6 of every 7-skin cancer related death. Moreover, in hospitals where dermatologists have to diagnose multiple cases of skin cancer, there are high possibilities of false negatives in diagnosis. To avoid such incidents, there here has been exhaustive research conducted by the research community all over the world to build highly accurate automated tools for skin cancer detection. In this paper, we introduce a novel approach of combining machine learning and deep learning techniques to solve the problem of skin cancer detection. The deep learning model uses state-of-the-art neural networks to extract features from images whereas the machine learning model processes image features which are obtained after performing the techniques such as Contourlet Transform and Local Binary Pattern Histogram. Meaningful feature extraction is crucial for any image classification roblem. As a result, by combining the manual and automated features, our designed model achieves a higher accuracy of 93% with an individual recall score of 99.7% and 86% for the benign and malignant forms of cancer, respectively. We benchmarked the model on publicly available Kaggle dataset containing processed images from ISIC Archive dataset. The proposed ensemble outperforms both expert dermatologists as well as other state-of-the-art deep learning and machine learning methods. Thus, this novel method can be of high assistance to dermatologists to help prevent any misdiagnosis.
C1 [Tembhurne, Jitendra V.; Diwan, Tausif] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
   [Hebbar, Nachiketa; Patil, Hemprasad Y.] VIT Vellore Univ, Sch Elect Engn SENSE, Vellore, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Tembhurne, JV (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
EM jtembhurne@iiitn.ac.in; nachiketa.hebbar2017@vitstudent.ac.in;
   hemprasad.patil@vit.ac.in; tdiwan@iiitn.ac.in
RI Diwan, Tausif/AFN-9746-2022; Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456
CR Alquran H, 2017, IEEE JORDAN CONF APP
   American Cancer Society, 2021, KEY STAT MEL SKIN CA
   [Anonymous], 2021, KAGGLE SKIN CANC DAT
   Basly Hend, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P271, DOI 10.1007/978-3-030-51935-3_29
   Brinker TJ, 2019, EUR J CANCER, V119, P11, DOI 10.1016/j.ejca.2019.05.023
   Brinker TJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218713
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chowdhary C.L., 2022, Computer Vision and Recognition Systems: Research Innovations and Trends
   Chowdhary C. L., 2021, IET COMPUTING SERIES
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Elgamal M, 2013, INT J ADV COMPUT SC, V4, P287
   Farooq M., 2020, arXiv preprint arXiv:2003.14395
   Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473
   Gu J., 2015, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hebbar N, 2020, 2020 IEEE 4 C INFORM, P1
   Hosny KM, 2018, CAIRO INT BIOM ENG, P90, DOI 10.1109/CIBEC.2018.8641762
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ismail M. Afzal, 2021, Proceedings of International Conference on Trends in Computational and Cognitive Engineering. Proceedings of TCCE 2020. Advances in Intelligent Systems and Computing (AISC 1309), P709, DOI 10.1007/978-981-33-4673-4_58
   Jana E, 2017, 2017 IEEE INT C COMP, P1, DOI [10.1109/iccic.2017.8524554, DOI 10.1109/ICCIC.2017.8524554]
   Kawahara J, 2016, LECT NOTES COMPUT SC, V10019, P164, DOI 10.1007/978-3-319-47157-0_20
   Kingma D. P., 2014, arXiv
   Labani S, 2021, J CANCER RES THER, V17, P906, DOI 10.4103/jcrt.JCRT_785_19
   Liang H, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0993-1
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Mishra S., 2017, International Journal of Livestock Research, V7, P60, DOI DOI 10.5455/IJLR.20170415115235
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Patil HY, 2016, OPTIK, V127, P2670, DOI 10.1016/j.ijleo.2015.11.187
   Riker AI, 2010, OCHSNER J, V10, P56
   Sáez A, 2016, IEEE T MED IMAGING, V35, P1036, DOI 10.1109/TMI.2015.2506270
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71294-2
   Sharma Neha, 2018, Procedia Computer Science, V132, P377, DOI 10.1016/j.procs.2018.05.198
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soyer HP, 2000, Interactive atlas of dermoscopy
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Weese J, 2016, MED IMAGE ANAL, V33, P44, DOI 10.1016/j.media.2016.06.023
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Welch HG, 2005, BRIT MED J, V331, P481, DOI 10.1136/bmj.38516.649537.E0
   Wu J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247080
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Wu Z, 2020, ARXIV
   Wu ZY, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108212
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Ying X, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/2/022022
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhang DJ, 2017, INTEGR COMPUT-AID E, V24, P261, DOI 10.3233/ICA-170544
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TMI.2019.2893944, 10.1109/TKDE.2019.2891537]
NR 54
TC 14
Z9 14
U1 6
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27501
EP 27524
DI 10.1007/s11042-023-14697-3
EA FEB 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000937945000010
DA 2024-07-18
ER

PT J
AU Wen, MY
   Liu, LX
   Sang, QB
   Zhang, YM
AF Wen, Mingyang
   Liu, Lixiong
   Sang, Qingbing
   Zhang, Yongmei
TI Deep video quality assessment using constrained multi-task regression
   and Spatio-temporal feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep video quality assessment; Entropy; Multi-frame difference; Temporal
   masking; Multi-task learning regression
ID IMAGE
AB Many popular video quality assessment (VQA) methods usually build models by simulating the process of human visual perception and adopt a simple regression strategy to predict video quality scores. However, these methods either hardly pay enough attention to regression processing prone to misprediction, or fail to accurately understand video content containing changes of movement or sudden movements. To remedy these, we propose a full reference (FR) video quality assessment model that integrates multi-task learning regression and analysis of spatio-temporal features to conduct video quality predictions. Firstly, the model arranges each frame of the reference and distorted videos into patches and calculates their entropy values to guide the selection of frame patches. A 2D Siamese network is then applied on the selected patches to learn spatial information. To more effectively capture temporal distortions, a multi-frame difference map is computed on each distorted video. The computed multi-frame difference maps are also partitioned into patches to select half of the ones with highest entropy values as temporal features. Additionally, we incorporate the temporal masking effect to optimize the spatial error and temporal features and adopt 3D convolutional neural network (CNN) in spatio-temporal feature fusion. Following recent evidence towards quality classification and quality regression, a constrained multi-task learning regression model is designed to aggregate the quality score, using quality classification subtask to contrain and optimize quality regression main task. Finally, the video quality score is predicted through the regression branch. We have evaluated our algorithm on five public VQA databases. The experimental results have revealed that the proposed algorithm can achieve superior performance as compared with the existing VQA methods.
C1 [Wen, Mingyang; Liu, Lixiong] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
   [Sang, Qingbing] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Peoples R China.
   [Zhang, Yongmei] North China Univ Technol, Sch Informat Sci & Technol, Beijing 100144, Peoples R China.
C3 Beijing Institute of Technology; Jiangnan University; North China
   University of Technology
RP Liu, LX (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM wenmy@bit.edu.cn; lxliu@bit.edu.cn; qingbings@jiangnan.edu.cn;
   zhangym@ncut.edu.cn
RI xu, chen/JNE-5010-2023; Wang, Yuchen/JPW-9345-2023; chen,
   yanhong/JVE-0289-2024; Li, Chun/KBC-9591-2024; Zhang,
   Xiaoxi/KBP-8753-2024
FU National Natural Science Foundation of China [61672095, 61371143];
   National Key Research and Development Program Project of China
   [2020YFC0811004]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China under Grant Nos. 61672095, 61371143 and National Key
   Research and Development Program Project of China under Grant No.
   2020YFC0811004.
CR Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1333, DOI 10.1109/LSP.2017.2726542
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen PF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P834, DOI 10.1145/3394171.3413717
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Desai NP., 2022, Turk J Comput Math Educ, V13, P85
   Ghadiyaram D, 2019, IEEE T CIRC SYST VID, V29, P183, DOI 10.1109/TCSVT.2017.2768542
   Guan TX, 2023, IEEE T MULTIMEDIA, V25, P3934, DOI 10.1109/TMM.2022.3168438
   Guo JF, 2021, MULTIMED TOOLS APPL, V80, P27531, DOI 10.1007/s11042-021-10862-8
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Jiang GY, 2018, J VIS COMMUN IMAGE R, V50, P247, DOI 10.1016/j.jvcir.2017.12.001
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P224, DOI 10.1007/978-3-030-01246-5_14
   Kingma D. P., 2014, arXiv
   Laboratory of Computational Perception & Image Quality Oklahoma State University, 2013, CSIQ VID DAT
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li CF, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116064
   Li F, 2021, IEEE T CIRC SYST VID, DOI [10.1109/TCSVT.2021.3074181, DOI 10.1109/TCSVT.2021.3074181]
   Li T, 2021, IEEE T BROADCAST, V67, P438, DOI 10.1109/TBC.2020.3028335
   Li Z., 2017, Toward a Practical Perceptual Video Quality Metric
   Liu LX, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115749
   Liu LX, 2019, IEEE T MULTIMEDIA, V21, P2305, DOI 10.1109/TMM.2019.2900941
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu SL, 2022, IEEE T WIREL COMMUN, V21, P7852, DOI [10.1109/TWC.2022.3162595, 10.1109/IECON49645.2022.9968484]
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu WT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P546, DOI 10.1145/3240508.3240643
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Loh WT, 2018, MULTIMED TOOLS APPL, V77, P30791, DOI 10.1007/s11042-018-6107-1
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Luo WJ, 2016, ADV NEUR IN, V29
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   MURDOCK BB, 1962, J EXP PSYCHOL, V64, P482, DOI 10.1037/h0045106
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Rimac-Drlje S, 2010, MULTIMED TOOLS APPL, V49, P425, DOI 10.1007/s11042-009-0442-1
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Seshadrinathan K, 2011, INT CONF ACOUST SPEE, P1153
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Suchow JW, 2011, CURR BIOL, V21, P140, DOI 10.1016/j.cub.2010.12.019
   Vranjes M, 2013, SIGNAL PROCESS-IMAGE, V28, P1, DOI 10.1016/j.image.2012.10.003
   Vu P. V., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2505, DOI 10.1109/ICIP.2011.6116171
   Vu PV, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013016
   Wang CF, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P232, DOI 10.1109/MIPR.2018.00056
   Wang GC, 2022, IEEE T CIRC SYST VID, V32, P1119, DOI 10.1109/TCSVT.2021.3074181
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WESTERINK JHDM, 1995, DISPLAYS, V16, P89, DOI 10.1016/0141-9382(95)91178-5
   Wu JJ, 2019, IEEE T MULTIMEDIA, V21, P2738, DOI 10.1109/TMM.2019.2908377
   Xu MN, 2020, INT CONF ACOUST SPEE, P4447, DOI [10.1109/ICASSP40776.2020.9053031, 10.1109/icassp40776.2020.9053031]
   You JY, 2021, IEEE IMAGE PROC, P1389, DOI 10.1109/ICIP42928.2021.9506075
   Zhang Y, 2019, IEEE T CIRC SYST VID, V29, P2244, DOI 10.1109/TCSVT.2018.2868063
   Zhang Y, 2020, IEEE T NEUR NET LEAR, V31, P2716, DOI 10.1109/TNNLS.2018.2890310
NR 52
TC 0
Z9 0
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28067
EP 28086
DI 10.1007/s11042-023-14652-2
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000937944300002
DA 2024-07-18
ER

PT J
AU Gupta, S
   Kumar, P
   Tekchandani, R
AF Gupta, Swadha
   Kumar, Parteek
   Tekchandani, Rajkumar
TI A multimodal facial cues based engagement detection system in e-learning
   context using deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expressions; Engagement detection; Emotion detection; Deep
   learning; Eye-blinking; Head-movement; Real-time; Online learning
ID STUDENTS; RECOGNITION; FILTER
AB Due to the COVID-19 crisis, the education sector has been shifted to a virtual environment. Monitoring the engagement level and providing regular feedback during e-classes is one of the major concerns, as this facility lacks in the e-learning environment due to no physical observation of the teacher. According to present study, an engagement detection system to ensure that the students get immediate feedback during e-Learning. Our proposed engagement system analyses the student's behaviour throughout the e-Learning session. The proposed novel approach evaluates three modalities based on the student's behaviour, such as facial expression, eye blink count, and head movement, from the live video streams to predict student engagement in e-learning. The proposed system is implemented based on deep-learning approaches such as VGG-19 and ResNet-50 for facial emotion recognition and the facial landmark approach for eye-blinking and head movement detection. The results from different modalities (for which the algorithms are proposed) are combined to determine the EI (engagement index). Based on EI value, an engaged or disengaged state is predicted. The present study suggests that the proposed facial cues-based multimodal system accurately determines student engagement in real time. The experimental research achieved an accuracy of 92.58% and showed that the proposed engagement detection approach significantly outperforms the existing approaches.
C1 [Gupta, Swadha; Kumar, Parteek; Tekchandani, Rajkumar] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala 147001, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Gupta, S (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala 147001, Punjab, India.
EM swadhagupta15@gmail.com; parteek.bhatia@thapar.edu;
   rtekchandani@thapar.edu
OI Gupta, Swadha/0000-0001-6097-0533
CR Achour B, 2020, BIOSYST ENG, V198, P31, DOI 10.1016/j.biosystemseng.2020.07.019
   Anajemba JH, 2020, INT CONF COMM SYST, P201, DOI [10.1109/CSNT.2020.38, 10.1109/CSNT48778.2020.9115741]
   Anas ER, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 6, P88, DOI 10.5220/0006172700880095
   Artifice A. F. V. P., 2021, COMPUT COMMUN WORKIN, DOI [10.5772/intechopen.98764, DOI 10.5772/INTECHOPEN.98764]
   Azlan CA, 2020, PHYS MEDICA, V80, P10, DOI 10.1016/j.ejmp.2020.10.002
   Bargshady G, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113305
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Bhardwaj P, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107277
   Biju S. M, 2020, NOVEL PRECLASS LEARN
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Chang C, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P616, DOI 10.1145/3242969.3264986
   Chauhan S, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13081545
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Daza R, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P32, DOI 10.1145/3395035.3425257
   Dewan MAA, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-018-0080-z
   Dewan MAA, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P1895, DOI 10.1109/SmartWorld.2018.00318
   Giannopoulos P., 2018, ADV HYBRIDIZATION IN, P1, DOI DOI 10.1007/978-3-319-66790-4_1
   Goldberg P, 2021, EDUC PSYCHOL REV, V33, P27, DOI 10.1007/s10648-019-09514-z
   Gopane S, 2022, LECT NOTES NETWORKS, P183, DOI DOI 10.1007/978-981-16-5348-3_14
   Gotlieb RJM, 2021, FRONT EDUC, V5, DOI 10.3389/feduc.2020.594668
   Gupta Swadha, 2021, Emerging Technologies for Smart Cities. Select Proceedings of EGTET 2020. Lecture Notes in Electrical Engineering (LNEE 765), P139, DOI 10.1007/978-981-16-1550-4_15
   Gupta Shivam, 2018, 2018 2nd International Conference on Inventive Systems and Control (ICISC), P553, DOI 10.1109/ICISC.2018.8398861
   Gupta SK, 2019, MULTIMED TOOLS APPL, V78, P25321, DOI 10.1007/s11042-019-7651-z
   Gupta S, 2023, MULTIMED TOOLS APPL, V82, P11365, DOI 10.1007/s11042-022-13558-9
   Gupta S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P18, DOI 10.1109/ICSTM.2017.8089120
   Hasnine MN, 2021, PROCEDIA COMPUT SCI, V192, P3423, DOI 10.1016/j.procs.2021.09.115
   Herbig N, 2020, UMAP'20: PROCEEDINGS OF THE 28TH ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P88, DOI 10.1145/3340631.3394861
   Hung KC, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122010221
   Iwendi C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092559
   Javed AR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082216
   Jiang Y, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/4152816
   Kamath S, 2021, INT C MACHINE LEARNI, P34
   Kanematsu H, 2016, PROCEDIA COMPUT SCI, V96, P1619, DOI 10.1016/j.procs.2016.08.209
   Krithika LB, 2016, PROCEDIA COMPUT SCI, V85, P767, DOI 10.1016/j.procs.2016.05.264
   Lai ZY, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01779-5
   Li JJ, 2016, APPL COMPUT REV, V16, P37, DOI 10.1145/3015297.3015301
   Li S, 2021, COMPUT EDUC, V163, DOI 10.1016/j.compedu.2020.104114
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li YY, 2019, IEEE IMAGE PROC, P3312, DOI [10.1109/ICIP.2019.8803488, 10.1109/icip.2019.8803488]
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu SX, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION PROCESSING (ICIIP 2019), P472, DOI 10.1145/3378065.3378154
   Liu YY, 2018, MULTIMED TOOLS APPL, V77, P28749, DOI 10.1007/s11042-018-6017-2
   Majstorovic I, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app121910036
   Mittal M, 2019, NEUROFUZZY APPROACH, P1
   Mittal M, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00344-z
   Mittal M, 2021, ENERGIES, V14, DOI 10.3390/en14113125
   Mittal M, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3997
   Mittal M, 2017, TENCON IEEE REGION, P2864, DOI 10.1109/TENCON.2017.8228350
   Mittal M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P472, DOI 10.1109/CICN.2014.110
   Murshed M, 2019, IEEE 17TH INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP / IEEE 17TH INT CONF ON PERVAS INTELLIGENCE AND COMP / IEEE 5TH INT CONF ON CLOUD AND BIG DATA COMP / IEEE 4TH CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P80, DOI 10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00028
   Nezami OM, 2020, LECT NOTES ARTIF INT, V11908, P273, DOI 10.1007/978-3-030-46133-1_17
   Olivetti EC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010314
   Parthiban L, 2021, FUZZY INTELLIGENT SY, P27
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199538
   Ranti C, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64999-x
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Salzillo G, 2020, IEEE SYS MAN CYBERN, P328, DOI [10.1109/smc42975.2020.9283133, 10.1109/SMC42975.2020.9283133]
   Sharma A, 2019, Smart learning system based on eeg signals, P465
   Sharma S, 2015, PROCEDIA COMPUT SCI, V70, P99, DOI 10.1016/j.procs.2015.10.047
   Sheikh AA, 2021, INT CONF INFORM COMM, P146, DOI 10.1109/ICTS52701.2021.9608977
   Siriaraya P, 2022, AUTOPHAGY
   Srivastava S, 2021, RECENT TRENDS COMMUN, P151
   Su M-C, 2021, IEEE T CONSUM ELECTR
   Sumer O, 2021, ARXIV
   Thomas C, 2017, P 1 ACM SIGCHI INT W, P33, DOI DOI 10.1145/3139513.3139514
   Yan H, 2021, STEM CELL RES THER, V1754
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Zhang ZL, 2020, J EDUC COMPUT RES, V58, P63, DOI 10.1177/0735633119825575
   Zou CY, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258137
NR 73
TC 4
Z9 4
U1 8
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28589
EP 28615
DI 10.1007/s11042-023-14392-3
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000933104800001
PM 36789011
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kamble, K
   Sengupta, J
AF Kamble, Kranti
   Sengupta, Joydeep
TI A comprehensive survey on emotion recognition based on
   electroencephalograph (EEG) signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BCI; Emotion recognition; EEG; Artificial intelligence; Machine
   learning; Deep learning; DEAP; MAHNOB; SEED; SEED-IV; SEED-V; DREAMER;
   Interfaces; Musec
ID FEATURE-SELECTION; CLASSIFICATION; FEATURES; VALENCE
AB Emotion recognition using electroencephalography (EEG) is becoming an interesting topic among researchers. It has made a remarkable entry in the domain of biomedical, smart environment, brain-computer interface (BCI), communication, security, and safe driving. In the past decade, several studies have been published that viewed emotion recognition tasks in a variety of manners. Multiple algorithms have been developed to accurately capture the EEG signal and identify the emotions from such EEG signals. The advent of artificial intelligence (AI) has changed the landscape of every application including emotion recognition. Two categories of AI-based algorithms such as machine learning and deep learning algorithms are becoming popular in the emotion recognition domain. This narrative review is an attempt to provide deep insight into the AI-based techniques, their role in EEG-based emotion recognition, and their potential future possibilities in accurate emotion identification. Furthermore, this review also provides an overview of the several important topics in emotion recognition such as emotion paradigms, EEG and its processing, and the public databases.
C1 [Kamble, Kranti; Sengupta, Joydeep] Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, Nagpur 440010, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Kamble, K (corresponding author), Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, Nagpur 440010, India.
EM kmble.kranti@gmail.com
RI kamble, kranti/JMP-9951-2023
OI kamble, kranti/0000-0002-3052-8688
CR Abhang P.A., 2016, Introduction to EEG- and Speech-Based Emotion Recognition, DOI DOI 10.1016/B978-0-12-804490-2.00003-8
   Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   [Anonymous], 2015, 2015 25 INT C INFORM
   Bajaj V, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0048-y
   Balan O, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010021
   Bhattacharyya A, 2021, IEEE SENS J, V21, P3579, DOI 10.1109/JSEN.2020.3027181
   Bhattacharyya A, 2018, DIGIT SIGNAL PROCESS, V78, P185, DOI 10.1016/j.dsp.2018.02.020
   Bhattacharyya A, 2017, IEEE T BIO-MED ENG, V64, P2003, DOI 10.1109/TBME.2017.2650259
   Bhattacharyya A, 2018, NEURAL COMPUT APPL, V29, P47, DOI 10.1007/s00521-016-2646-4
   Bigirimana AD, 2016, IEEE SYS MAN CYBERN, P4429, DOI 10.1109/SMC.2016.7844928
   Chen JX, 2019, IEEE ACCESS, V7, P44317, DOI 10.1109/ACCESS.2019.2908285
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Cheng J, 2021, IEEE J BIOMED HEALTH, V25, P453, DOI 10.1109/JBHI.2020.2995767
   Cui H, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106243
   Demir F, 2021, IEEE SENS J, V21, P14923, DOI 10.1109/JSEN.2021.3070373
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P., 2003, UNMASKING FACE GUIDE
   Frantzidis CA, 2010, IEEE T INF TECHNOL B, V14, P589, DOI 10.1109/TITB.2010.2041553
   Gao ZK, 2020, NEUROCOMPUTING, V380, P225, DOI 10.1016/j.neucom.2019.10.096
   García HF, 2016, IEEE ENG MED BIO, P850, DOI 10.1109/EMBC.2016.7590834
   Garg A, 2022, MULTIMED TOOLS APPL, P1
   Gicic A, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12363
   Grühn D, 2008, BEHAV RES METHODS, V40, P512, DOI 10.3758/BRM.40.2.512
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Hill NJ, 2006, LECT NOTES COMPUT SC, V4174, P404
   HJORTH B, 1970, ELECTROEN CLIN NEURO, V29, P306, DOI 10.1016/0013-4694(70)90143-4
   Huang JM, 2017, IEEE INT C BIOINFORM, P958, DOI 10.1109/BIBM.2017.8217786
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Jenke R, 2014, IEEE T AFFECT COMPUT, V5, P327, DOI 10.1109/TAFFC.2014.2339834
   Jerritta S, 2014, J CHIN INST ENG, V37, P385, DOI 10.1080/02533839.2013.799946
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Kamble KS, 2022, IEEE SENS J, V22, P2496, DOI 10.1109/JSEN.2021.3135953
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Khare SK, 2021, IEEE SENS J, V21, P2035, DOI 10.1109/JSEN.2020.3020915
   Khare SK, 2021, IEEE T NEUR NET LEAR, V32, P2901, DOI 10.1109/TNNLS.2020.3008938
   Khare SK, 2020, APPL ACOUST, V163, DOI 10.1016/j.apacoust.2020.107234
   Khosrowabadi Reza, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4242, DOI 10.1109/ICPR.2010.1031
   Khosrowabadi Reza, 2010, P 3 INT C INF COMM T, pE102, DOI DOI 10.1109/ICT4M.2010.5971942
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Koelstra S, 2013, IMAGE VISION COMPUT, V31, P164, DOI 10.1016/j.imavis.2012.10.002
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kolodyazhniy V, 2011, PSYCHOPHYSIOLOGY, V48, P908, DOI 10.1111/j.1469-8986.2010.01170.x
   Krishna AH, 2019, IET SCI MEAS TECHNOL, V13, P375, DOI 10.1049/iet-smt.2018.5237
   Kroupi E, 2011, LECT NOTES COMPUT SC, V6975, P457, DOI 10.1007/978-3-642-24571-8_58
   Lakhan P, 2019, IEEE SENS J, V19, P9896, DOI 10.1109/JSEN.2019.2928781
   Lan ZR, 2016, VISUAL COMPUT, V32, P347, DOI 10.1007/s00371-015-1183-y
   Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521
   Li HY, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P389, DOI 10.1109/SPAC.2017.8304310
   Li R, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105080
   Li TH, 2019, I IEEE EMBS C NEUR E, P607, DOI [10.1109/NER.2019.8716943, 10.1109/ner.2019.8716943]
   Liu JM, 2018, LECT NOTES COMPUT SC, V10735, P194, DOI 10.1007/978-3-319-77380-3_19
   Liu SF, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P1, DOI [10.1109/PLASMA.2017.8496132, 10.1109/PESGM.2017.8273885, 10.1109/GSIS.2017.8077658]
   Liu W, 2022, IEEE T COGN DEV SYST, V14, P715, DOI 10.1109/TCDS.2021.3071170
   Liu W, 2016, LECT NOTES COMPUT SC, V9948, P521, DOI 10.1007/978-3-319-46672-9_58
   Liu Y., 2013, T COMPUTATIONAL SCI, P101
   Liu YS, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P302, DOI 10.1109/CW.2013.52
   Liu YJ, 2018, IEEE T AFFECT COMPUT, V9, P550, DOI 10.1109/TAFFC.2017.2660485
   Liu Y, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103927
   Maheshwari D, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104428
   Mahmoud S, 2014, LOW NOISE LOW POWER
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Murugappan M, 2013, 2013 IEEE 9TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS (CSPA), P289, DOI 10.1109/CSPA.2013.6530058
   Murugappan Murugappan, 2010, Journal of Biomedical Science & Engineering, V3, P390, DOI 10.4236/jbise.2010.34054
   Murugappan M, 2011, J MED BIOL ENG, V31, P45, DOI 10.5405/jmbe.710
   Nakisa B, 2018, EXPERT SYST APPL, V93, P143, DOI 10.1016/j.eswa.2017.09.062
   Nie D, 2011, I IEEE EMBS C NEUR E, P667, DOI 10.1109/NER.2011.5910636
   Onton Julie, 2009, Front Hum Neurosci, V3, P61, DOI 10.3389/neuro.09.061.2009
   Paithane AN, 2014, IEEE I C COMP INT CO, P962
   Pandeya YR, 2021, MULTIMED TOOLS APPL, V80, P2887, DOI 10.1007/s11042-020-08836-3
   Patel R, 2016, IEEE SENS J, V16, P6947, DOI 10.1109/JSEN.2016.2591580
   Petrantonakis PC, 2010, IEEE T AFFECT COMPUT, V1, P81, DOI 10.1109/T-AFFC.2010.7
   Plutchik R, 1980, THEORIES EMOTION
   Rached TS, 2013, BRAIN-COMPUTER INTERFACE SYSTEMS - RECENT PROGRESS AND FUTURE PROSPECTS, P253, DOI 10.5772/56227
   Razuri JG, 2013, MEX INT CONF ARTIF I, P85, DOI 10.1109/MICAI.2013.16
   Reuderink Boris, 2013, International Journal of Autonomous and Adaptive Communications Systems, V6, P45, DOI 10.1504/IJAACS.2013.050691
   Salama ES, 2018, INT J ADV COMPUT SC, V9, P329
   Salari S, 2018, 2018 6TH IRANIAN JOINT CONGRESS ON FUZZY AND INTELLIGENT SYSTEMS (CFIS), P190, DOI 10.1109/CFIS.2018.8336626
   Sangnark S, 2021, IEEE SENS J, V21, P14931, DOI 10.1109/JSEN.2021.3073040
   Sharma LD, 2021, IEEE SENS J, V21, P26931, DOI 10.1109/JSEN.2021.3120787
   Shin D, 2017, MULTIMED TOOLS APPL, V76, P11449, DOI 10.1007/s11042-016-4203-7
   Shirke B, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P991, DOI [10.1109/ccwc47524.2020.9031124, 10.1109/CCWC47524.2020.9031124]
   Siddharth, 2022, IEEE T AFFECT COMPUT, V13, P96, DOI 10.1109/TAFFC.2019.2916015
   Siuly S, 2020, IEEE T NEUR SYS REH, V28, P2390, DOI 10.1109/TNSRE.2020.3022715
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Song T, 2021, AAAI CONF ARTIF INTE
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Subasi A, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102648
   Tao W, 2023, IEEE T AFFECT COMPUT, V14, P382, DOI 10.1109/TAFFC.2020.3025777
   Taran S, 2019, NEURAL COMPUT APPL, V31, P6925, DOI 10.1007/s00521-018-3531-0
   Taran S, 2018, MEASUREMENT, V116, P68, DOI 10.1016/j.measurement.2017.10.067
   Torres E.P., 2020, INT C ADV EM TRENDS, P226
   Tuncer T, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110671
   Valenza G, 2012, IEEE T AFFECT COMPUT, V3, P237, DOI 10.1109/T-AFFC.2011.30
   Verma GK, 2014, NEUROIMAGE, V102, P162, DOI 10.1016/j.neuroimage.2013.11.007
   Wang J., 2021, Cogn. Robot., V1, P29, DOI DOI 10.1016/J.COGR.2021.04.001
   Wang XW, 2014, NEUROCOMPUTING, V129, P94, DOI 10.1016/j.neucom.2013.06.046
   Wang XW, 2011, LECT NOTES COMPUT SC, V7062, P734, DOI 10.1007/978-3-642-24955-6_87
   Wang YJ, 2013, CHIN CONT DECIS CONF, P3148
   Wenming Zheng, 2018, IEEE Transactions on Affective Computing, V9, P21, DOI 10.1109/TAFFC.2016.2563432
   Wilson GF, 2003, HUM FACTORS, V45, P635, DOI 10.1518/hfes.45.4.635.27088
   Wu M, 2017, NEURAL COMPUT, V29, P194, DOI 10.1162/NECO_a_00899
   Ying Cheng, 2010, 2010 3rd International Conference on Information Sciences and Interaction Sciences (ICIS), P363, DOI 10.1109/ICICIS.2010.5534805
   Yohanes REJ, 2012, IEEE ENG MED BIO, P2251, DOI 10.1109/EMBC.2012.6346410
   Zhang JH, 2016, IEEE SYS MAN CYBERN, P2319, DOI 10.1109/SMC.2016.7844584
   Zhao SN, 2017, IEEE T IND ELECTRON, V64, P5161, DOI 10.1109/TIE.2016.2606089
   Zheng W.-L., 2014, In 2014 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI [DOI 10.1109/ICME.2014.6890166, 10.1109/ICME.2014.6890166]
   Zheng WL, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa5a98
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zheng WM, 2017, IEEE T COGN DEV SYST, V9, P281, DOI 10.1109/TCDS.2016.2587290
NR 110
TC 22
Z9 22
U1 47
U2 121
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27269
EP 27304
DI 10.1007/s11042-023-14489-9
EA FEB 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000929402100002
DA 2024-07-18
ER

PT J
AU Ernawan, F
   Ariatmanto, D
AF Ernawan, Ferda
   Ariatmanto, Dhani
TI A recent survey on image watermarking using scaling factor techniques
   for copyright protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Embedding and extracting; Adaptive scaling factor;
   Transform domain; Robustness; Imperceptibility; Computational time
ID DISCRETE WAVELET TRANSFORM; SINGULAR-VALUE DECOMPOSITION; DCT
   COEFFICIENTS; DIGITAL IMAGES; DWT-SVD; ROBUST; SCHEME; ALGORITHM;
   SYSTEM; DOMAIN
AB This survey presented a discussion of the existing scaling factor and adaptive scaling factor in image watermarking schemes. The discussion included several issues: robustness, imperceptibility and computational time for embedding a watermark. This survey also discussed the general concept of the image watermarking, transform method, embedding region and security on the existing watermarking scheme. This paper also discussed the recent use of watermarking techniques, potential issues and available solutions in adaptive watermarking schemes. Furthermore, the performance summary of the state-of-art embedding techniques is presented and analysed for future research. This literature review became useful to researchers to know the current challenges in embedding a watermark image. This survey information can be used to design an efficient embedding watermark for copyright protection.
C1 [Ernawan, Ferda] Univ Malaysia Pahang, Coll Comp & Appl Sci, Fac Comp, Pekan 26600, Pahang, Malaysia.
   [Ariatmanto, Dhani] Univ AMIKOM, Fac Comp Sci, Ring Rd Utara Condong Catur Sleman, Yogyakarta 55283, Indonesia.
C3 Universiti Malaysia Pahang Al-Sultan Abdullah (UMPSA)
RP Ernawan, F (corresponding author), Univ Malaysia Pahang, Coll Comp & Appl Sci, Fac Comp, Pekan 26600, Pahang, Malaysia.
EM ferda1902@gmail.com
RI Ernawan, Ferda/B-4214-2012
OI Ernawan, Ferda/0000-0002-6779-1594
FU Universiti Malaysia Pahang [RDU222709, UIC221522]
FX This work was supported by Universiti Malaysia Pahang through the
   Research Grant Scheme (RDU222709 and UIC221522).
CR Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Ahmad F, 2018, SIGNAL PROCESS, V148, P322, DOI 10.1016/j.sigpro.2018.02.029
   Al-Otum H, 2018, MULTIMED TOOLS APPL, V77, P15625, DOI 10.1007/s11042-017-5138-3
   Albalawi U, 2017, MULTIMED TOOLS APPL, V76, P21303, DOI 10.1007/s11042-016-4063-1
   Ali M, 2015, EXPERT SYST APPL, V42, P2392, DOI 10.1016/j.eswa.2014.10.045
   Alshoura WH, 2020, IEEE ACCESS, V8, P43391, DOI 10.1109/ACCESS.2020.2978186
   Ansari A, 2018, OPT LASER ENG, V107, P325, DOI 10.1016/j.optlaseng.2018.03.028
   Ansari IA, 2015, P 4 INT C SOFT COMP, P209
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Cao XY, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/3219042
   Chang TJ, 2019, MULTIMED TOOLS APPL, V78, P9169, DOI 10.1007/s11042-018-6505-4
   Chaturvedi R., 2016, WATER AIR SOIL POLL, V9, P271
   Chen F, 2017, MULTIMED TOOLS APPL, V76, P9681, DOI 10.1007/s11042-016-3574-0
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Cui XC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196306
   Dappuri B, 2020, MULTIMED TOOLS APPL, V79, P31103, DOI 10.1007/s11042-020-09433-0
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   De S, 2017, COMMUNICATION DEVICE, V470
   Dey N, 2014, J MED IMAG HEALTH IN, V4, P384, DOI 10.1166/jmihi.2014.1265
   Ernawan F, 2017, Journal of Telecommunication, Electronic and Computer Engineering (JTEC), V9, P111
   Ernawan F., 2019, Int. J. Electr. Computer Eng., V9, P2185, DOI [DOI 10.11591/IJECE.V9I3.PP2185-2195, 10.11591/ijece.v9i3.pp2185-2195]
   Ernawan F, 2019, IEEE ACCESS, V7, P151985, DOI 10.1109/ACCESS.2019.2948086
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Ernawan F, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P221, DOI 10.1109/CSPA.2018.8368716
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Fang H, 2019, MULTIMED TOOLS APPL, V78, P8075, DOI 10.1007/s11042-018-6596-y
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Ghazvini M, 2017, J APPL SEC RES, V12, P260, DOI 10.1080/19361610.2017.1277878
   Giri KJ, 2017, STUD COMPUT INTELL, V660, P93, DOI 10.1007/978-3-319-44790-2_5
   Gonge SS, 2016, PROCEDIA COMPUT SCI, V89, P732, DOI 10.1016/j.procs.2016.06.046
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29229, DOI 10.1007/s11042-018-6767-x
   Gupta R, 2018, MULTIMED TOOLS APPL, V77, P19235, DOI 10.1007/s11042-017-5351-0
   Hamid M, 2016, INT C SYST SIGNALS I, P7, DOI [10.1109/IWSSIP.2016.7502755, DOI 10.1109/IWSSIP.2016.7502755]
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Hashmi MF, 2015, PROCEDIA COMPUT SCI, V46, P1626, DOI 10.1016/j.procs.2015.02.096
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hu HT, 2018, MULTIMED TOOLS APPL, V77, P26965, DOI 10.1007/s11042-018-5900-1
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P1374, DOI 10.1016/j.aeue.2016.07.011
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Keshavarzian R, 2016, AEU-INT J ELECTRON C, V70, P278, DOI 10.1016/j.aeue.2015.12.003
   Keyvanpour MR, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.040
   Khalili M, 2015, OPTIK, V126, P4367, DOI 10.1016/j.ijleo.2015.08.042
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Lang J, 2014, OPT LASER ENG, V53, P112, DOI 10.1016/j.optlaseng.2013.08.021
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mehta R, 2016, J SIGNAL PROCESS SYS, V84, P265, DOI 10.1007/s11265-015-1055-8
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Munoz-Ramirez David-Octavio, 2018, 2018 IEEE 9th International Conference on Dependable Systems, Services and Technologies (DESSERT), P619, DOI 10.1109/DESSERT.2018.8409206
   Murali P, 2018, OPTIK, V170, P242, DOI 10.1016/j.ijleo.2018.04.050
   Niu PP, 2017, MULTIMED TOOLS APPL, V76, P3403, DOI 10.1007/s11042-016-3935-8
   Parah SA, 2018, MULTIDIM SYST SIGN P, V29, P1095, DOI 10.1007/s11045-017-0490-z
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Parah SA, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS, P57, DOI 10.1109/iNIS.2015.41
   Parekh M, 2018, ADV INTELL SYST, V710, P519, DOI 10.1007/978-981-10-7871-2_50
   Pendyala M, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P498
   Peng YW, 2018, MULTIMED TOOLS APPL, V77, P7239, DOI 10.1007/s11042-017-4631-z
   Vo PH, 2017, 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P331, DOI 10.1109/NAFOSTED.2017.8108087
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Sangeetha N, 2018, OPTIK, V160, P380, DOI 10.1016/j.ijleo.2018.01.136
   Santhi V, 2017, STUD COMPUT INTELL, V660, P453, DOI 10.1007/978-3-319-44790-2_20
   Shahdoosti HR, 2018, IET IMAGE PROCESS, V12, P751, DOI 10.1049/iet-ipr.2017.0898
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P21497, DOI 10.1007/s11042-016-4006-x
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Soliman MM, 2016, NEURAL COMPUT APPL, V27, P469, DOI 10.1007/s00521-015-1868-1
   Sun L, 2018, NEURAL COMPUT APPL, V30, P2425, DOI 10.1007/s00521-016-2788-4
   Thanh TM, 2018, MULTIMED TOOLS APPL, V77, P2901, DOI 10.1007/s11042-017-4435-1
   Tagesse Takore Tamirat, 2018, 2nd International Conference on Micro-Electronics, Electromagnetics and Telecommunications, ICMEET 2016. Proceedings: LNEE 434, P51, DOI 10.1007/978-981-10-4280-5_6
   Tareef A, 2015, EXPERT SYST APPL, V42, P2224, DOI 10.1016/j.eswa.2014.09.055
   Thakral S, 2019, COMM COM INF SC, V955, P499, DOI 10.1007/978-981-13-3140-4_45
   Tyagi S., 2017, 2017 INT C INV SYST, P1, DOI [10.1109/ICISC.2017.8068743, DOI 10.1109/ICISC.2017.8068743]
   Vairaprakash S, 2018, COMPUT ELECTR ENG, V70, P826, DOI 10.1016/j.compeleceng.2017.12.029
   Vali MH, 2018, EXPERT SYST APPL, V114, P296, DOI 10.1016/j.eswa.2018.07.004
   Veni M, 2019, MULTIMED TOOLS APPL, V78, P27491, DOI 10.1007/s11042-019-7650-0
   Wan WB, 2019, IEEE ACCESS, V7, P39826, DOI 10.1109/ACCESS.2019.2906912
   Wan WB, 2016, MULTIMED TOOLS APPL, V75, P13481, DOI 10.1007/s11042-015-2853-5
   Xingyu Zhou, 2018, Mathematical Problems in Engineering, V2018, DOI 10.1155/2018/4907423
   Yadav AK, 2016, MULTIMED TOOLS APPL, V75, P9371, DOI 10.1007/s11042-016-3381-7
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
   Yuqi He, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1214, DOI 10.1109/IMCEC.2018.8469626
   Zong TR, 2016, IEEE ACCESS, V4, P1689, DOI 10.1109/ACCESS.2016.2556723
NR 96
TC 7
Z9 7
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27123
EP 27163
DI 10.1007/s11042-023-14447-5
EA FEB 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000928928900001
DA 2024-07-18
ER

PT J
AU Mishra, K
   Majhi, SK
AF Mishra, Kaushik
   Majhi, Santosh Kumar
TI A novel improved hybrid optimization algorithm for efficient dynamic
   medical data scheduling in cloud-based systems for biomedical
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical data scheduling; Load balancing; Task scheduling; Genetic
   algorithm (GA); JAYA; GAYA; Cloud computing
ID HEURISTIC ALGORITHMS; CONSOLIDATION; ENVIRONMENTS; TASKS
AB The fluctuating workloads like cloud requests and the unpredictable resource usage of Virtual machines (VMs) with variable resource characterizations might lead the servers to a non-equilibrium condition. It is thereby causing low resource utilization and the performance degradation of servers. This paper integrates a Genetic Algorithm (GA) and JAYA algorithm to propose a hybrid metaheuristic technique named GAYA for scheduling dynamically independent biomedical data (tasks) to mitigate the above challenges. JAYA is a simple yet powerful population-based parameter-less optimization technique used to surmount the limitations of GA by expediting the convergence rate. In this work, it first uniformly disperses loads (medical data) among VMs through a load balancing strategy, and second, it schedules the tasks (data) among heterogeneous resources by mapping onto the best possible VMs using the GAYA. This algorithm notably meliorated the exploration capability by creating a balance between exploration and exploitation. The efficacy of the proposed approach is evaluated in MATLAB using standard benchmark functions. A real-world dataset consisting of disparate specifications of tasks, like the ones encountered often in biomedical data, has been utilized and simulated in CloudSim to evaluate the effectiveness of the proposed approach. The proposed work has been compared with other metaheuristics and task scheduling techniques such as bird swarm optimization (BSO), GA, JAYA, and Q-learning based modified particle swarm optimization (QMPSO). The Friedman test is conducted to determine the statistical importance of the performance of the algorithms. Simulation results show significant improvement by an increase in resource utilization with 36. 74% (GA), 19.75% (JAYA), 14.31% (QMPSO) and 12.17% (GA), 9.10% (JAYA), 6.02% (QMPSO) and a reduction in makespan by 10.45% (GA), 4.35% (JAYA), 2.31% (QMPSO) and 4.17% (GA), 1.44% (JAYA), 1.03% (QMPSO) in both homogenous and heterogeneous environments respectively.
C1 [Mishra, Kaushik] GITAM Deemed be Univ, Dept Comp Sci & Engn, Visakhapatnam 530045, India.
   [Majhi, Santosh Kumar] Veer Surendra Sai Univ Technol, Dept Comp Sci & Engn, Burla 768018, India.
C3 Gandhi Institute of Technology & Management (GITAM); Veer Surendra Sai
   University of Technology
RP Mishra, K (corresponding author), GITAM Deemed be Univ, Dept Comp Sci & Engn, Visakhapatnam 530045, India.
EM kaushikmishra1991@gmail.com; smajhi_cse@vssut.ac.in
RI mishra, kaushik/KHY-8521-2024
OI MISHRA, KAUSHIK/0000-0001-9499-0727
FU All India Council for Technical Education (AICTE), New Delhi, India
   under RPS Project [8-83/FDC/RPS (POLICY-1) 2019-20]
FX This work is supported by the All India Council for Technical Education
   (AICTE), New Delhi, India under RPS Project Grant No.: 8-83/FDC/RPS
   (POLICY-1) 2019-20.
CR Abdullahi M, 2016, FUTURE GENER COMP SY, V56, P640, DOI 10.1016/j.future.2015.08.006
   Al-maamari A., 2015, Journal of Computer Engineering (IOSR-JCE), V17, P96
   [Anonymous], 2009, INT J OPEN PROBLEMS
   [Anonymous], 2014, P INT C COMMUNICATIO
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Babu LDD, 2013, APPL SOFT COMPUT, V13, P2292, DOI 10.1016/j.asoc.2013.01.025
   Ben Alla H, 2017, LECT NOTES COMPUT SC, V10542, P235, DOI 10.1007/978-3-319-68179-5_21
   Boveiri HR, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12536
   Buyya Rajkumar, 2009, 2009 International Conference on High Performance Computing & Simulation (HPCS), P1, DOI 10.1109/HPCSIM.2009.5192685
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Cho KM, 2015, NEURAL COMPUT APPL, V26, P1297, DOI 10.1007/s00521-014-1804-9
   Dam S, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION, CONTROL AND INFORMATION TECHNOLOGY (C3IT)
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Ebadifard F, 2020, 2020 6TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P177, DOI [10.1109/ICWR49608.2020.9122287, 10.1109/icwr49608.2020.9122287]
   Ebadifard F, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4368
   Feitelson D. G., 1995, Job Scheduling Strategies for Parallel Processing. IPPS'95 Workshop. Proceedings, P337
   Foster I, 2008, GCE: 2008 GRID COMPUTING ENVIRONMENTS WORKSHOP, P60
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   IBARRA OH, 1977, J ACM, V24, P280, DOI 10.1145/322003.322011
   Javanmardi S, 2014, ADV INTELL SYST, V303, P43, DOI 10.1007/978-3-319-08156-4_5
   Jena UK, 2022, J KING SAUD UNIV-COM, V34, P2332, DOI 10.1016/j.jksuci.2020.01.012
   Jeyakrishnan V, 2017, WIRELESS PERS COMMUN, V94, P2363, DOI 10.1007/s11277-016-3481-8
   Kalra M, 2015, EGYPT INFORM J, V16, P275, DOI 10.1016/j.eij.2015.07.001
   Khorsand R, 2019, SOFTWARE PRACT EXPER, V49, P1618, DOI 10.1002/spe.2737
   Liaqat M, 2019, IEEE ACCESS, V7, P145767, DOI 10.1109/ACCESS.2019.2945499
   Mell P, 2010, COMMUN ACM, V53, P50
   Milan ST, 2019, COMPUT OPER RES, V110, P159, DOI 10.1016/j.cor.2019.05.022
   Mishra Kaushik, 2021, Advances in Intelligent Computing and Communication. Proceedings of ICAC 2020. Lecture Notes in Networks and Systems (LNNS 202), P111, DOI 10.1007/978-981-16-0695-3_12
   Mishra Kaushik, 2020, International Journal of Computing and Digital Systems, V9, P201, DOI 10.12785/ijcds/090206
   Mishra K, 2022, J KING SAUD UNIV-COM, V34, P4914, DOI 10.1016/j.jksuci.2020.12.001
   Mishra K, 2021, J SUPERCOMPUT, V77, P10377, DOI 10.1007/s11227-021-03695-7
   Mishra K, 2021, OPEN COMPUT SCI, V11, P146, DOI 10.1515/comp-2020-0215
   Mohanty S, 2019, INT J INF TECHNOL WE, V14, P27, DOI 10.4018/IJITWE.2019010102
   Mustafa S, 2019, IEEE ACCESS, V7, P135256, DOI 10.1109/ACCESS.2019.2941145
   Nanduri R., 2011, Proceedings of the 2011 IEEE 3rd International Conference on Cloud Computing Technology and Science (CloudCom 2011), P724, DOI 10.1109/CloudCom.2011.112
   Gutierrez-Garcia JO, 2015, CLUSTER COMPUT, V18, P1041, DOI 10.1007/s10586-015-0460-x
   Pandey HM, 2016, 2016 6TH INTERNATIONAL CONFERENCE - CLOUD SYSTEM AND BIG DATA ENGINEERING (CONFLUENCE), P728, DOI 10.1109/CONFLUENCE.2016.7508215
   Polepally V, 2019, CLUSTER COMPUT, V22, P1099, DOI 10.1007/s10586-017-1056-4
   Prakash T., 2017, Energy Convers. Manag., V140, P34
   Rafieyan E, 2020, COMPUT IND ENG, V140, DOI 10.1016/j.cie.2020.106272
   Randles Martin, 2010, Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA 2010), P551, DOI 10.1109/WAINA.2010.85
   Rani Sunita, 2020, International Journal of Information Technology, V12, P1451, DOI 10.1007/s41870-018-0175-3
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Shojafar M, 2015, CLUSTER COMPUT, V18, P829, DOI 10.1007/s10586-014-0420-x
   socr, 2018, F DISTR TABL
   Sommer M, 2016, PR INT CONF AUTONOM, P300, DOI 10.1109/ICAC.2016.16
   Speitkamp B, 2010, IEEE T SERV COMPUT, V3, P266, DOI 10.1109/TSC.2010.25
   ULLMAN JD, 1975, J COMPUT SYST SCI, V10, P384, DOI 10.1016/S0022-0000(75)80008-0
   Wang TT, 2014, 2014 IEEE 12TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC)/2014 IEEE 12TH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING (EMBEDDEDCOM)/2014 IEEE 12TH INTERNATIONAL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING (PICOM), P146, DOI 10.1109/DASC.2014.35
   Wei W, 2018, DATABASE-OXFORD, DOI 10.1093/database/bay017
   Xu MX, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4123
   Zhang MH, 2017, IEEE INT SYMP PARAL, P885, DOI 10.1109/ISPA/IUCC.2017.00135
NR 52
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27087
EP 27121
DI 10.1007/s11042-023-14448-4
EA FEB 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000928928900002
DA 2024-07-18
ER

PT J
AU Chakraborty, M
   Chakraborty, A
   Biswas, PK
   Mitra, P
AF Chakraborty, Manashi
   Chakraborty, Aritri
   Biswas, Prabir Kumar
   Mitra, Pabitra
TI Texture aware autoencoder pre-training and pairwise learning refinement
   for improved iris recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution Neural Network (CNN); Deep learning; Iris recognition;
   Pairwise matching; Texture aware
ID SYSTEM
AB This paper presents a texture aware end-to-end trainable iris recognition system. We build upon our previous stagewise learning framework but present two key contributions: a) we propose a better autoencoding framework with a data relation loss between Gram matrix representations of input and reconstructed images. The data relation loss enables learning better texture representation which is pivotal for a texture rich dataset such as iris. Robustness of auto-encoding is further enhanced with an auxiliary denoising task. b) we design a pairwise learning architecture which subsumes the task of iris matching inside the training pipeline itself and results in significant improvement in matching performance compared to usual offline matching paradigm. On ND-IRIS-0405, CASIA.v4-Interval and IITD iris datasets our proposed model achieves better matching performance over both traditional baselines and recent deep learning paradigms. Specifically, our method yields a relative improvement of 42.30%, 64.92% and 20% in terms of equal error rates (EER) with respect to the best competing deep learning method on the respective datasets.
C1 [Chakraborty, Manashi] Indian Inst Technol Kharagpur, Adv Technol Dev Ctr, Kharagpur 721302, West Bengal, India.
   [Chakraborty, Aritri; Biswas, Prabir Kumar] Indian Inst Technol Kharagpur, Elect & Elect Commun, Kharagpur 721302, West Bengal, India.
   [Mitra, Pabitra] Indian Inst Technol Kharagpur, Comp Sci & Engn, Kharagpur 721302, West Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Chakraborty, M (corresponding author), Indian Inst Technol Kharagpur, Adv Technol Dev Ctr, Kharagpur 721302, West Bengal, India.
EM manashi.chakraborty@iitkgp.ac.in; aritrichakraborty@gmail.com;
   pkb@ece.iitkgp.ac.in; pabitra@cse.iitkgp.ac.in
FU Qualcomm Technologies, Inc. [4300045891]
FX This project was partially funded by Qualcomm Technologies, Inc. PO:
   4300045891. Any findings, results, proposition, opinions or conclusion
   written in this manuscript are those of the authors and do not
   necessarily reflect the views of the sponsors.
CR Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bowyer KW, 2016, ARXIV
   CASIA, V4 IR DAT
   Chakraborty M, 2020, IEEE IMAGE PROC, P1351, DOI 10.1109/ICIP40778.2020.9191081
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elrefaei LA, 2018, MULTIMED TOOLS APPL, V77, P14579, DOI 10.1007/s11042-017-5049-3
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   IIT-Delhi-Iris-Database, US
   Kagawade VC, 2021, MULTIMED TOOLS APPL, V80, P21615, DOI 10.1007/s11042-021-10650-4
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lahiri A, 2016, IEEE ENG MED BIO, P1340, DOI 10.1109/EMBC.2016.7590955
   Lahiri A, 2017, IEEE COMPUT SOC CONF, P794, DOI 10.1109/CVPRW.2017.110
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li RJ, 2014, LECT NOTES COMPUT SC, V8675, P305, DOI 10.1007/978-3-319-10443-0_39
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Ma L, 2004, PATTERN RECOGN, V37, P1287, DOI 10.1016/j.patcog.2004.02.001
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Masek L., 2003, THESIS U W AUSTR
   Meng QX, 2017, IEEE IJCNN, P364, DOI 10.1109/IJCNN.2017.7965877
   Minaee S, 2016, IEEE SIG PROC MED
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Othman N, 2016, PATTERN RECOGN LETT, V82, P124, DOI 10.1016/j.patrec.2015.09.002
   Paszke A, 2019, ADV NEUR IN, V32
   Rathgeb C, 2016, ADV COMPUT VIS PATT, P359, DOI 10.1007/978-1-4471-6784-6_16
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Regouid M, 2019, MULTIMED TOOLS APPL, V78, P22509, DOI 10.1007/s11042-019-7467-x
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snelgrove X, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149449
   Suk HI, 2013, LECT NOTES COMPUT SC, V8150, P583, DOI 10.1007/978-3-642-40763-5_72
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tishby N., 2000, ARXIV
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW)
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang K, 2019, IEEE T INF FOREN SEC, V14, P3233, DOI 10.1109/TIFS.2019.2913234
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Winston JJ, 2022, MULTIMED TOOLS APPL, V81, P9481, DOI 10.1007/s11042-021-11482-y
   Xingqiang Tang, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P391, DOI 10.1007/978-3-319-69923-3_42
   Yang K, 2021, IEEE WINT CONF APPL, P888, DOI 10.1109/WACV48630.2021.00093
   Zhao Z, 2017, IEEE I CONF COMP VIS, P3829, DOI 10.1109/ICCV.2017.411
   Zhou CY, 2020, MULTIMED TOOLS APPL, V79, P29021, DOI 10.1007/s11042-020-08914-6
NR 49
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25381
EP 25401
DI 10.1007/s11042-022-14284-y
EA JAN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000913487000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sun, XX
   Chen, B
   Shi, RD
   Yin, Q
   Guo, P
AF Sun, Xiaoxuan
   Chen, Bo
   Shi, RunDong
   Yin, Qian
   Guo, Ping
TI A progressively-enhanced framework to broad networks for efficient
   recognition applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Broad networks; Broad pseudoinverse learner;
   Progressively-enhanced learning
ID LEARNING-SYSTEM; CLASSIFICATION
AB Broad neural networks provide an alternative way of deep learning with a novel flatted structure, which employ a non-iterative training mechanism and exhibit high efficiency in various recognition tasks. However, such broad networks unavoidably suffer from unstable performance due to the double random mappings in the generation of feature representations and the consequent uncertainty. The existing research often neglect to explore the effect of the quality of the broaden feature representations, which is crucial for the model performance. This paper presents a progressively-enhanced framework taking broad network as basic learners (PE-BL) to address the existing issues. The basic broad learners in PE-BL are trained in sequence, and the core manipulation is to modify the primitive hidden feature representations of the current learner through the nonlinear transformation of the prediction from the previous one, so the resulting broaden representations become more discriminative. Further, PE-BL is adapted to the scenarios where only a single broad learner is employed. Finally, extensive comparative experiments on some benchmark datasets and Electroencephalogram (EEG)-based emotion recognition task verify the effectiveness of the proposed methods.
C1 [Sun, Xiaoxuan; Chen, Bo; Guo, Ping] Beijing Normal Univ, Sch Syst Sci, Beijing 100875, Peoples R China.
   [Shi, RunDong] Meituan, Beijing, Peoples R China.
   [Yin, Qian] Beijing Normal Univ, Sch Artificial Intelligence, Beijing 100875, Peoples R China.
C3 Beijing Normal University; Beijing Normal University
RP Yin, Q (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, Beijing 100875, Peoples R China.
EM sunxx@mail.bnu.edu.cn; altair@mail.bnu.edu.cn; shirundong@meituan.com;
   yinqian@bnu.edu.cn; pguo@ieee.org
RI GUO, Ping/AAG-2160-2019; Sun, xiaoxuan/JEY-0652-2023
OI GUO, Ping/0000-0002-7122-1084; 
FU National Key Research and Development Program of China [2018AAA0100203];
   NSFC [U2031136]; CAS [U2031136]
FX This work is supported in part by the National Key Research and
   Development Program of China under Grant 2018AAA0100203, and in part by
   the Joint Research Fund in Astronomy (U2031136) under cooperative
   agreement between the NSFC and CAS.
CR Bingxin Xu, 2018, 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC). Proceedings, P4243, DOI 10.1109/SMC.2018.00718
   Chen C. L. Philip, 2018, IEEE Transactions on Neural Networks and Learning Systems, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Chen CLP, 2019, IEEE T NEUR NET LEAR, V30, P1191, DOI 10.1109/TNNLS.2018.2866622
   Chu YH, 2021, NEUROCOMPUTING, V442, P236, DOI 10.1016/j.neucom.2021.01.120
   Ding WT, 2021, IEEE ACCESS, V9, P79307, DOI 10.1109/ACCESS.2021.3084610
   Duan RN, 2013, I IEEE EMBS C NEUR E, P81, DOI 10.1109/NER.2013.6695876
   Gao Q, 2020, MULTIMED TOOLS APPL, V79, P27057, DOI 10.1007/s11042-020-09354-y
   Gao ZK, 2021, IEEE T COGN DEV SYST, V13, P945, DOI 10.1109/TCDS.2020.2976112
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Guo P, 1996, J BEIJING NORMAL U N, V32, P71
   Guo P, 2020, PREPRINT, DOI [10.13140/RG.2.2.12262.45121, DOI 10.13140/RG.2.2.12262.45121]
   Guo P, 2020, PREPRINT
   Han M, 2019, IEEE T KNOWL DATA EN, V31, P1809, DOI 10.1109/TKDE.2018.2866149
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jin JW, 2021, INFORM SCIENCES, V576, P800, DOI 10.1016/j.ins.2021.06.008
   Jin JW, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9421-3
   Keshmiri S, 2017, IEEE IJCNN, P4371, DOI 10.1109/IJCNN.2017.7966409
   Kohonen T, 2001, Self-organizing Maps, DOI DOI 10.1007/978-3-642-56927-2
   Kong Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050685
   Li JP, 2018, COGN COMPUT, V10, P368, DOI 10.1007/s12559-017-9533-x
   Li Y, 2016, NEURAL INFORM PROCES, V9950, P175, DOI [10.1007/978-3-319-46681-121, DOI 10.1007/978-3-319-46681-121]
   Liang C, 2022, MULTIMED TOOLS APPL, V81, P11187, DOI 10.1007/s11042-022-12228-0
   Liu W, 2016, LECT NOTES COMPUT SC, V9948, P521, DOI 10.1007/978-3-319-46672-9_58
   Liu Z, 2021, NEUROCOMPUTING, V444, P38, DOI 10.1016/j.neucom.2021.02.059
   Liu ZL, 2021, IEEE T SYST MAN CY-S, V51, P209, DOI 10.1109/TSMC.2020.3043147
   Nakisa B, 2018, EXPERT SYST APPL, V93, P143, DOI 10.1016/j.eswa.2017.09.062
   PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schäfer D, 2018, MACH LEARN, V107, P903, DOI 10.1007/s10994-017-5694-9
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang K, 2021, IEEE T INTELL TRANSP, V22, P3303, DOI 10.1109/TITS.2020.2980555
   Wang K, 2017, MON NOT R ASTRON SOC, V465, P4311, DOI 10.1093/mnras/stw2894
   Xie RS, 2020, COMPLEX INTELL SYST, V6, P411, DOI 10.1007/s40747-020-00139-2
   Ye HL, 2021, IEEE T CYBERNETICS, V51, P4450, DOI 10.1109/TCYB.2020.2978500
   Yin QG, 2021, INT J PR ENG MAN-GT, V8, P1629, DOI 10.1007/s40684-021-00318-7
   Zhang DQ, 2006, PATTERN RECOGN, V39, P140, DOI 10.1016/j.patcog.2005.08.002
   Zhang L, 2016, INFORM SCIENCES, V367, P1094, DOI 10.1016/j.ins.2015.09.025
   Zhang L, 2022, IEEE T SYST MAN CY-S, V52, P334, DOI 10.1109/TSMC.2020.2995205
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
   Zhao HM, 2020, IEEE T CIRCUITS-I, V67, P983, DOI 10.1109/TCSI.2019.2959886
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zheng WM, 2017, IEEE T COGN DEV SYST, V9, P281, DOI 10.1109/TCDS.2016.2587290
NR 44
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24865
EP 24890
DI 10.1007/s11042-022-14087-1
EA DEC 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000899122900002
DA 2024-07-18
ER

PT J
AU Yao, RZ
   Wang, N
   Chen, P
   Ma, D
   Sheng, XJ
AF Yao, Ruizhe
   Wang, Ning
   Chen, Peng
   Ma, Di
   Sheng, Xianjun
TI A CNN-transformer hybrid approach for an intrusion detection system in
   advanced metering infrastructure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart grids; Advanced metering infrastructure; Intrusion detection
   systems; Convolutional neural network; Transformer
ID ELECTRICITY THEFT DETECTION; DEEP LEARNING APPROACH; EFFICIENT; NETWORK;
   ATTACKS; SCHEME
AB Bi-directional communication networks are the foundation of advanced metering infrastructure (AMI), but they also expose smart grids to serious intrusion risks. While previous studies have proposed various intrusion detection systems (IDS) for AMI, most have not comprehensively considered the impact of different factors on intrusions. To ensure the security of the bi-directional communication network of AMI, this paper proposes an IDS based on deep learning theory. First, the invalid features are eliminated according to the feature screening strategy based on eXtreme Gradient Boosting (XGBoost), after which the data distribution is balanced by the adaptive synthetic (ADASYN) sampling technique. Next, multi-space feature subsets based on the convolutional neural network (CNN) are constructed to enrich the spatial distribution of samples. Finally, the Transformer is used to construct feature associations and extract crucial traits, such as the temporal and fine-grained characteristics of features, to complete the identification of intrusion behaviors. The proposed IDS is tested on the KDDCup99, NSL-KDD, and CICIDS-2017 datasets, and the results show that it has high performance with accuracy of 97.85%, 91.04%, and 91.06% respectively.
C1 [Yao, Ruizhe; Wang, Ning; Chen, Peng; Ma, Di; Sheng, Xianjun] Dalian Univ Technol, Elect Informat & Elect Engn, 2 Linggong Rd, Dalian 116024, Liaoning, Peoples R China.
C3 Dalian University of Technology
RP Wang, N (corresponding author), Dalian Univ Technol, Elect Informat & Elect Engn, 2 Linggong Rd, Dalian 116024, Liaoning, Peoples R China.
EM yrzhe@mail.dlut.edu.cn; ningwang@dlut.edu.cn; PengC@mail.dlut.edu.cn;
   madi1314@mail.dlut.edu.cn; sxjun@dlut.edu.cn
CR Al-Daweri MS, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12101666
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alsharif A, 2019, IEEE INTERNET THINGS, V6, P10363, DOI 10.1109/JIOT.2019.2938776
   Alsharif A, 2019, IEEE INTERNET THINGS, V6, P3309, DOI 10.1109/JIOT.2018.2882566
   Alsharif A, 2019, IEEE ACCESS, V7, P27829, DOI 10.1109/ACCESS.2019.2900934
   Anderson JP, 1980, COMPUTER SECURITY TH, P1
   Ayub N., 2020, 2020 IEEE 23 INT MUL, P1
   Benmalek M, 2019, IEEE ENABL TECHNOL, P208, DOI 10.1109/WETICE.2019.00052
   Biswas R, 2021, MULTIMED TOOLS APPL, V80, P24147, DOI 10.1007/s11042-021-10765-8
   Choudhary S, 2020, PROCEDIA COMPUT SCI, V167, P1561, DOI 10.1016/j.procs.2020.03.367
   Das U, 2019, IEEE T PARALL DISTR, V30, P245, DOI 10.1109/TPDS.2018.2865937
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   ENGELBRECHT J, 2019, IECON 2019 45 ANN C, DOI DOI 10.1109/IECON.2019.8927476
   Gope P, 2020, COMPUT COMMUN, V152, P338, DOI 10.1016/j.comcom.2019.12.042
   Gupta N, 2021, COMPUT NETW, V192, DOI 10.1016/j.comnet.2021.108076
   Haddad Z, 2015, IEEE CONF WIREL MOB, P748, DOI 10.1109/WiMOB.2015.7348037
   Hasan MN, 2019, ENERGIES, V12, DOI 10.3390/en12173310
   He YB, 2017, IEEE T SMART GRID, V8, P2505, DOI 10.1109/TSG.2017.2703842
   Hsu C, 2021, MULTIMED TOOLS APPL
   Ibrahem M.I., 2020, 2020 International Symposium on Networks, Computers and Communications (ISNCC), P1, DOI DOI 10.1109/ISNCC49221.2020.9297246
   Ieracitano C, 2020, NEUROCOMPUTING, V387, P51, DOI 10.1016/j.neucom.2019.11.016
   Ismail M, 2020, IEEE T SMART GRID, V11, P3428, DOI 10.1109/TSG.2020.2973681
   Javaid N, 2021, J PARALLEL DISTR COM, V153, P44, DOI 10.1016/j.jpdc.2021.03.002
   Jeong J, 2020, MULTIMED TOOLS APPL, V79, P16077, DOI 10.1007/s11042-019-7262-8
   Kanna PR, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107132
   Khammassi C, 2017, COMPUT SECUR, V70, P255, DOI 10.1016/j.cose.2017.06.005
   Kim J., 2016, 2016 INT C PLATFORM, P1, DOI DOI 10.1109/PLATCON.2016.7456805
   Kong XY, 2021, INT J ELEC POWER, V125, DOI 10.1016/j.ijepes.2020.106544
   Liu GJ, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/4705982
   Nabil M, 2018, INT C PATT RECOG, P740, DOI 10.1109/ICPR.2018.8545748
   Pereira J, 2020, IEEE C EVOL COMPUTAT
   Prasad M, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105980
   Punmiya R, 2019, IEEE T SMART GRID, V10, P2326, DOI 10.1109/TSG.2019.2892595
   Rahman MA, 2021, MULTIMED TOOLS APPL, V80, P31381, DOI 10.1007/s11042-021-10567-y
   Razavi R, 2019, APPL ENERG, V238, P481, DOI 10.1016/j.apenergy.2019.01.076
   Saeed MS, 2020, ENERGIES, V13, DOI 10.3390/en13123242
   Shen YP, 2018, COMPUT J, V61, P526, DOI 10.1093/comjnl/bxx101
   Shone N, 2018, IEEE T EM TOP COMP I, V2, P41, DOI 10.1109/TETCI.2017.2772792
   Kala TS, 2021, MULTIMED TOOLS APPL, V80, P6457, DOI 10.1007/s11042-020-09804-7
   Tian C, 2021, BIG DATA ANAL CYBER, P714
   Tonyali Samet, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P550, DOI 10.1109/CCNC.2016.7444839
   Wang W, 2021, NEUROCOMPUTING, V438, P270, DOI 10.1016/j.neucom.2021.01.087
   Yan Z, 2020, 2020 IEEE INT INSTRU, P1
   Yan ZH, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3086887
   Yang HY, 2019, IEEE ACCESS, V7, P64366, DOI 10.1109/ACCESS.2019.2917299
   Yang ZT, 2018, IEEE SYST J, V12, P1015, DOI 10.1109/JSYST.2016.2580616
   Yao RZ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020626
   Yin CL, 2017, IEEE ACCESS, V5, P21954, DOI 10.1109/ACCESS.2017.2762418
   Zhang HP, 2020, COMPUT NETW, V177, DOI 10.1016/j.comnet.2020.107315
   Zhang K, 2020, ENERGIES, V13, DOI 10.3390/en13184907
   Zheng ZB, 2018, IEEE T IND INFORM, V14, P1606, DOI 10.1109/TII.2017.2785963
NR 54
TC 6
Z9 6
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19463
EP 19486
DI 10.1007/s11042-022-14121-2
EA DEC 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000893056800002
DA 2024-07-18
ER

PT J
AU Surajkanta, Y
   Pal, S
AF Surajkanta, Yumnam
   Pal, Shyamosree
TI Recognition of spherical segments using number theoretic properties of
   isothetic covers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Isothetic cover; Discrete sphere; Sphere recognition; Number theory
ID LATTICE POINTS; GENERATION; DISPLAY; SPHERES; CIRCLES
AB With the proliferation of cheap sensors and handheld devices, the amount of 3d data has grown exponentially and finds uses in the automated diagnosis of medical images, computer vision, and a host of other applications. Description and identification of geometrical primitives play an important role in computer vision and image processing. In this article, a definition of discrete spheres is given based on the dilation of euclidean spheres with a unit tetrahedron. It is shown in the article that the isothetic covers of spheres are equivalent to our definition of discrete spheres. Analysis of isothetic covers of spheres are presented, particularly its number-theoretic properties, and show that the bounding radius of isothetic cover faces is closely related to the distribution of the square number in integer intervals. Spherical segment recognition algorithms based on the number-theoretic properties of isothetic covers are proposed. Information content of the isothetic covers and computational load of the algorithm can be adjusted as per the requirements of the applications by changing the grid size. The computational complexities of the methods are determined and shows they are competitive to other related methods in the literature. The proposed methods are experimented with a large number of synthetic data to study its behavior and some of the results are presented in the article.
C1 [Surajkanta, Yumnam; Pal, Shyamosree] Natl Inst Technol, Silchar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Surajkanta, Y (corresponding author), Natl Inst Technol, Silchar, India.
EM yumnam_rs@cse.nits.ac.in; spal@cse.nits.ac.in
OI Surajkanta, Yumnam/0000-0003-3614-0980
CR ANDRES E, 1994, COMPUT GRAPH, V18, P695, DOI 10.1016/0097-8493(94)90164-3
   Andres E, 2011, LECT NOTES COMPUT SC, V6607, P235, DOI 10.1007/978-3-642-19867-0_20
   [Anonymous], IEEE Transactions on Pattern Analysis and
   BADLER NI, 1977, COMPUT VISION GRAPH, V6, P589, DOI 10.1016/S0146-664X(77)80018-X
   Bera S, 2014, ARXIV
   Bera S, 2014, LECT NOTES COMPUT SC, V8321, P49, DOI 10.1007/978-3-319-04126-1_5
   Bhowmick P, 2008, DISCRETE APPL MATH, V156, P2381, DOI 10.1016/j.dam.2007.10.022
   Bhowmick P, 2014, J MATH IMAGING VIS, V49, P98, DOI 10.1007/s10851-013-0444-5
   BISWAS SN, 1985, COMPUT VISION GRAPH, V32, P158, DOI 10.1016/S0734-189X(85)80066-9
   BRESENHAM J, 1977, COMMUN ACM, V20, P100, DOI 10.1145/359423.359432
   Brimkov VE, 2008, THEOR COMPUT SCI, V406, P24, DOI 10.1016/j.tcs.2008.07.014
   Camurri M, 2014, MACH VISION APPL, V25, P1877, DOI 10.1007/s00138-014-0640-3
   Cao MY, 2006, PATTERN RECOGN LETT, V27, P980, DOI 10.1016/j.patrec.2005.11.019
   Chamizo F, 1998, ACTA ARITH, V85, P265
   CHUNG WL, 1977, COMPUT VISION GRAPH, V6, P196, DOI 10.1016/S0146-664X(77)80012-9
   Décoret X, 2003, ACM T GRAPHIC, V22, P689, DOI 10.1145/882262.882326
   Drost B, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P398, DOI 10.1109/3DV.2015.52
   Duan J, 2014, IMVIP 2014 2014 IRIS, P28
   Fiorio C, 2006, PROC SPIE, V6066, DOI 10.1117/12.642976
   Fiorio C, 2006, LECT NOTES COMPUT SC, V4245, P425
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furukawa Y, 2009, IEEE I CONF COMP VIS, P80, DOI 10.1109/ICCV.2009.5459145
   Georgiev K, 2016, ARXIV
   Hildenbrand D, 2012, AIP CONF PROC, V1479, P27, DOI 10.1063/1.4756054
   Hsu S. Y., 1993, Computer Graphics Forum, V12, P105, DOI 10.1111/1467-8659.1220105
   Kharbat M, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P182, DOI 10.1109/AVSS.2007.4425307
   KULPA Z, 1979, COMPUT VISION GRAPH, V9, P102, DOI 10.1016/0146-664X(79)90087-X
   Li W, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175850
   Magyar A, 2007, J NUMBER THEORY, V122, P69, DOI 10.1016/j.jnt.2006.03.006
   Memis A, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON BIOMEDICAL IMAGING, SIGNAL PROCESSING (ICBSP 2018), P42, DOI 10.1145/3288200.3288205
   Montani C., 1990, SPHERES TO VOXELS CO, P327
   Pal S, 2012, J MATH IMAGING VIS, V42, P1, DOI 10.1007/s10851-011-0270-6
   Pham S., 1992, Visual Computer, V9, P1, DOI 10.1007/BF01901025
   Ren Z, 2006, ACM T GRAPHIC, V25, P977, DOI 10.1145/1141911.1141982
   Sandoval J, 2020, IIEEJ T IMAGE ELECT, V8
   Sommer C, 2020, IEEE INT CONF ROBOT, P8404, DOI [10.1109/ICRA40945.2020.9196988, 10.1109/icra40945.2020.9196988]
   Song W, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00228-8
   Stelldinger P., 2007, IMAGE DIGITIZATION I
   Surajkanta Y, 2020, INT J IMAGE GRAPH, V20, DOI 10.1142/S0219467820500114
   Sveier A, 2017, ADV APPL CLIFFORD AL, V27, P1961, DOI 10.1007/s00006-017-0759-1
   Thiery JM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2898350
   Thiery JM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508384
   Toutant Jean-Luc, 2013, Discrete Geometry for Computer Imagery. 17th IAPR International Conference, DGCI 2013. Proceedings, P265, DOI 10.1007/978-3-642-37067-0_23
   Toutant JL, 2013, DISCRETE APPL MATH, V161, P2662, DOI 10.1016/j.dam.2013.06.001
   Tsang KM, 2000, B LOND MATH SOC, V32, P679, DOI 10.1112/S0024609300007505
   Wang L, 2021, CHIN CONT DECIS CONF, P1686, DOI 10.1109/CCDC52312.2021.9601582
   Wang L, 2020, IET IMAGE PROCESS, V14, P2660, DOI 10.1049/iet-ipr.2019.1625
   Wang L, 2016, PATTERN RECOGN LETT, V83, P287, DOI 10.1016/j.patrec.2016.07.008
   WRIGHT WE, 1990, IEEE COMPUT GRAPH, V10, P60, DOI 10.1109/38.59038
   WU XL, 1987, COMPUT VISION GRAPH, V37, P331, DOI 10.1016/0734-189X(87)90041-7
   Yao CF, 1995, IEEE T VIS COMPUT GR, V1, P311, DOI 10.1109/2945.485618
NR 51
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19393
EP 19416
DI 10.1007/s11042-022-14182-3
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886859100006
DA 2024-07-18
ER

PT J
AU Wang, SS
   Chen, HY
   Sheu, ST
AF Wang, Sheng-Shih
   Chen, Hsueh-Yi
   Sheu, Shiann-Tsong
TI CoMAC: A cooperation-based multiparty audio conferencing system for
   mobile users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audioconferencing; Buffer reordering; Codec; Cooperation; Multiparty
   conferencing
ID ACOUSTIC ECHO CANCELLATION
AB The existing architectures used in the multiparty audio conferencing systems are typically categorized as either centralized or decentralized. These architectures expose a trade-off between processing latency and system capacity, namely the number of participants. This paper proposes a multiparty audio conferencing system for mobile users to improve the processing latency and system capacity. Instead of using the pure centralized or decentralized architecture, the proposed system adopts a novel cooperation-based architecture, in which only some participants are selected as the central controllers to deal with the tasks such as acoustic echo cancellation, encoding, decoding, mixing and de-mixing. The proposed system also uses a buffer reordering scheme to solve the problems of network jitters and out-of-order packets. This study analyzed the processing latency of the multiparty audio conferencing systems using the existing and proposed architectures. We also implemented these systems on diverse mobile platforms to compare the processing latency and number of participants. Performance evaluation results confirmed that the proposed cooperation-based architecture can not only reduce the processing latency but also support more participants, compared to the existing architectures.
C1 [Wang, Sheng-Shih] Lunghwa Univ Sci & Technol, Dept Elect Engn, Taoyuan, Taiwan.
   [Chen, Hsueh-Yi; Sheu, Shiann-Tsong] Natl Cent Univ, Dept Commun Engn, Taoyuan, Taiwan.
C3 National Central University
RP Wang, SS (corresponding author), Lunghwa Univ Sci & Technol, Dept Elect Engn, Taoyuan, Taiwan.
EM sswang@mail.lhu.edu.tw; xy.chen@g.ncu.edu.tw; stsheu@ce.ncu.edu.tw
OI Wang, Sheng-Shih/0000-0003-0995-9464
CR Aguirre JV, 2017, PEER PEER NETW APPL, V10, P170, DOI 10.1007/s12083-015-0415-2
   ATAL BS, 1976, IEEE T ACOUST SPEECH, V24, P201, DOI 10.1109/TASSP.1976.1162800
   Ben Khedher D, 2012, IEEE ICC, P6535, DOI 10.1109/ICC.2012.6364949
   Caiko J, 2020, 2020 IEEE 61ST ANNUAL INTERNATIONAL SCIENTIFIC CONFERENCE ON POWER AND ELECTRICAL ENGINEERING OF RIGA TECHNICAL UNIVERSITY (RTUCON), DOI 10.1109/RTUCON51174.2020.9316605
   Chang JC, 2001, IEEE INT C MULTIMEDI, P26
   Chen X., 2011, Proc. 19th ACM International Conference on Multimedia (MM '11), P493
   CHIEN Y, 2018, IEEE ACCESS, V6
   Dudman J., 2006, JISC Technology and Standards Watch
   El-Amine OM, 2021, 2021 10 INT C INTERN, P1
   Elleuch W, 2013, IEEE CONF WIREL MOB, P279, DOI 10.1109/WiMOB.2013.6673373
   Elleuch W, 2008, IEEE CONF WIREL MOB, P415, DOI 10.1109/WiMob.2008.122
   Ford B, 2005, USENIX ASSOCIATION PROCEEDINGS OF THE GENERAL TRACK: 2005 UNENIX ANNUAL TECHNICAL CONFERENCE, P179
   Fukui M, 2014, IEEE T CONSUM ELECTR, V60, P468, DOI 10.1109/TCE.2014.6937332
   Gu XH, 2008, IEEE T PARALL DISTR, V19, P515, DOI 10.1109/TPDS.2007.70766
   Hamidia M, 2012, 2012 24 INT C MICROE, P1
   Holmberg C., 2015, RFC 7478
   Huang XQ, 2021, IEEE T VEH TECHNOL, V70, P2561, DOI 10.1109/TVT.2021.3061126
   Hui-Kai Su, 2009, Proceedings of the 2009 Fifth International Joint Conference on INC, IMS and IDC, P1381, DOI 10.1109/NCM.2009.50
   Jo QH, 2009, IET SIGNAL PROCESS, V3, P205, DOI 10.1049/iet-spr.2008.0128
   Jung J, 2021, MULTIMED TOOLS APPL, V80, P35773, DOI 10.1007/s11042-020-09149-1
   Kadam P, 2021, 2021 2 GLOBAL C ADVA, P1
   Kim J, 2018, IEEE SIGNAL PROC LET, V25, P1181, DOI 10.1109/LSP.2018.2811740
   Kristanto H., 2019, 2019 IEEE GLOBAL C S, P1
   Kurtisi Z, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1381, DOI 10.1109/ICME.2008.4607701
   Li J, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P602
   Lin CHR, 2020, IMPLEMENTATION SECUR
   Opus, 2011, COMP OP COD
   Park JS, 2020, MULTIMED TOOLS APPL, V79, P16127, DOI 10.1007/s11042-019-7547-y
   Romoli L, 2017, SPEECH COMMUN, V86, P97, DOI 10.1016/j.specom.2016.11.009
   Singh K, 2001, INTERNET TELEPHONY W, P57
   Software T, 2003, TTA LOSSLESS AUDIO C
   Terriberry, 2012, 6716 RFC IETF
   Wang QY, 2021, MULTIMED TOOLS APPL, V80, P10777, DOI 10.1007/s11042-020-10230-y
   Wijayanto A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION, NETWORKS AND SATELLITE (COMNETSAT 2021), P348, DOI 10.1109/COMNETSAT53002.2021.9530780
   Yang XX, 2020, IEEE INT CONF COMMUN, P289, DOI [10.1109/ICCC49849.2020.9238930, 10.1109/iccc49849.2020.9238930]
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17999
EP 18017
DI 10.1007/s11042-022-14179-y
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000887298200001
PM 36467433
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Xu, L
   Jiang, XH
AF Xu, Li
   Jiang, Xiuhua
TI Blind image quality assessment for anchor-assisted adaptation to
   practical situations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image quality assessment; Distortion classification method;
   Pairwise preference network; Anchor-assisted regression
ID NATURAL SCENE STATISTICS
AB Directly conveying human visual perception of image quality, the mean opinion score (MOS) has traditionally been the cornerstone of blind image quality assessment (BIQA) training. However, attempt to solve the inter-dataset differences of MOS was anecdotal so far. Scores from the local raters are inevitably affected by the habits, preferences and environments at that time, leading each dataset has its own characteristics, and the absolute values will not be comparable once separated from the specific IQA dataset. Towards overcoming the limitations, we propose a BIQA approach that combines ranking and anchor-assisted regression, which can be easily adapted to different goal-oriented environments or populations. The comparison with anchors abandons the traditional practice of using one score to fit all standards, and avoids the difference between datasets in principle. We also demonstrate that a receiver-based distortion classification method can simplify the cluttered existing distortions as well as support the ranking method. Experiments have proved that our approach achieves flexible adaptation to target situations by freely replacing anchors.
C1 [Xu, Li; Jiang, Xiuhua] Commun Univ China, Informat & Telecommun Engn Inst, Beijing, Peoples R China.
   [Xu, Li; Jiang, Xiuhua] PengCheng Lab, Shenzhen, Peoples R China.
C3 Communication University of China
RP Xu, L (corresponding author), Commun Univ China, Informat & Telecommun Engn Inst, Beijing, Peoples R China.; Xu, L (corresponding author), PengCheng Lab, Shenzhen, Peoples R China.
EM xulixulii@outlook.com
OI XU, LI/0000-0002-9940-419X
FU Specialized Research Fund for the Doctoral Program of Higher Education
   of China," Research of Visual Perception for Impairments of Color
   Information in High-Definition Images" [20110018110001]
FX This work is supported by the Specialized Research Fund for the Doctoral
   Program of Higher Education of China," Research of Visual Perception for
   Impairments of Color Information in High-Definition Images"
   (No.20110018110001).
CR Bosse S, 2016, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2016.7533065
   Chen JH, 2008, LECT NOTES COMPUT SC, V5353, P894, DOI 10.1007/978-3-540-89796-5_108
   Chiu TY, 2020, PROC CVPR IEEE, P3643, DOI 10.1109/CVPR42600.2020.00370
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Fang YM, 2020, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR42600.2020.00373
   Gao F, 2015, IEEE T NEUR NET LEAR, V26, P2275, DOI 10.1109/TNNLS.2014.2377181
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Glickman M.E., 1999, Chance, V12, P21, DOI DOI 10.1080/09332480.1999.10542153
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu K, 2014, IEEE IMAGE PROC, P511, DOI 10.1109/ICIP.2014.7025102
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hosu V, 2019, PROC CVPR IEEE, P9367, DOI 10.1109/CVPR.2019.00960
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Kim J, 2019, IEEE T NEUR NET LEAR, V30, P11, DOI 10.1109/TNNLS.2018.2829819
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li YM, 2015, NEUROCOMPUTING, V154, P94, DOI 10.1016/j.neucom.2014.12.015
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu XL, 2019, IEEE T PATTERN ANAL, V41, P1862, DOI 10.1109/TPAMI.2019.2899857
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Lv YQ, 2015, IEEE IMAGE PROC, P2344, DOI 10.1109/ICIP.2015.7351221
   Ma KD, 2019, IEEE IMAGE PROC, P2344, DOI [10.1109/ICIP.2019.8803390, 10.1109/icip.2019.8803390]
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Meesters L, 2002, SIGNAL PROCESS, V82, P369, DOI 10.1016/S0165-1684(01)00177-3
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ong E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P545
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Prashnani E, 2018, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2018.00194
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang HX, 2014, PROC CVPR IEEE, P2877, DOI 10.1109/CVPR.2014.368
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xu L, 2017, IEEE T CIRC SYST VID, V27, P1833, DOI 10.1109/TCSVT.2016.2543099
   Ying ZQ, 2021, PROC CVPR IEEE, P14014, DOI 10.1109/CVPR46437.2021.01380
   Yu XX, 2019, IEEE T IMAGE PROCESS, V28, P5757, DOI 10.1109/TIP.2019.2922850
   Zoph B., 2016, INT C LEARN REPR
NR 51
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17929
EP 17946
DI 10.1007/s11042-022-14225-9
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000885231500005
DA 2024-07-18
ER

PT J
AU Catania, F
   Garzotto, F
AF Catania, Fabio
   Garzotto, Franca
TI A conversational agent for emotion expression stimulation in persons
   with neurodevelopmental disorders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Conversational technology; Speech emotion
   recognition; Computer-assisted therapy; Neurodevelopmental disorder;
   Alexithymia
ID ALEXITHYMIA; AUTISM; CHILDREN; INTELLIGENCE; COMMUNICATION;
   TECHNOLOGIES; SCIENCE; ROBOT; GAME
AB Difficulty in emotion expression and recognition is typical of the personality trait known as alexithymia, which is often observed in persons with neurodevelopmental disorders (NDD). Past research has investigated various forms of conversational technology for people with NDD, but only a few studies have explored the use of conversational agents to reduce alexithymia. This paper presents Emoty, a speech-based conversational agent designed for people with NDD to train emotional communication skills. An original characteristic of this agent is that it exploits the emotional expression power of the voice. Emoty engages users in small conversations during which they are asked to repeat sentences and express specific emotions using the appropriate vocal tone. We ran an empirical study to evaluate the usability and effectiveness of our conversational agent. The study involved 19 Italian individuals with NDD and alexithymia aged from 29 to 45 (10 women and 9 men). They used Emoty in five individual sessions over two and a half months. The results showed that two subjects encountered problems using the system because they had difficulty verbalizing the sentences and were not understood by Emoty. The others performed the assigned tasks with the agent. Their capability to express emotions with the voice consistently improved, and other benefits were observed in other social and communication skills.
C1 [Catania, Fabio; Garzotto, Franca] Politecn Milan, Dept Elect Informat & Bioengn, Via Golgi 39, I-20133 Milan, MI, Italy.
C3 Polytechnic University of Milan
RP Catania, F (corresponding author), Politecn Milan, Dept Elect Informat & Bioengn, Via Golgi 39, I-20133 Milan, MI, Italy.
EM fabio.catania@polimi.it; franca.garzotto@polimi.it
RI CATANIA, FABIO/GZG-4102-2022
OI CATANIA, FABIO/0000-0002-5403-9002
FU Politecnico di Milano within the CRUI-CARE Agreement
FX Open access funding provided by Politecnico di Milano within the
   CRUI-CARE Agreement. This research work was not funded by any
   organization or supported by funding schemes.
CR Allen A.A., 2018, Advances in Neurodevelopmental Disorders, V2, P69, DOI [DOI 10.1007/S41252-017-0041-5, 10.1007/s41252-017-0041-5]
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   [Anonymous], 2004, LEARNING STYLES PEDA
   [Anonymous], 2012, P 3 WORKSHOP CHILD C
   Askari F, 2018, STUDYING FACIAL EXPR
   BAGBY RM, 1994, J PSYCHOSOM RES, V38, P33, DOI 10.1016/0022-3999(94)90006-X
   Barbe W., 1988, Teaching through modality strengths
   BARBE WB, 1981, EDUC LEADERSHIP, V38, P378
   Bekele E, 2016, P IEEE VIRT REAL ANN, P121, DOI 10.1109/VR.2016.7504695
   Beneteau E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300473
   Berlo D K, 1987, PROCESO COMUNICACION, P173
   Bernardini S, 2014, INFORM SCIENCES, V264, P41, DOI 10.1016/j.ins.2013.10.027
   Berthoz S, 2005, EUR PSYCHIAT, V20, P291, DOI 10.1016/j.eurpsy.2004.06.013
   Boyd-graber J., 2006, CHI 2006 Proceedings, P151, DOI DOI 10.1145/1124772.1124797
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Catania F., 2020, P 2 C CONVERSATIONAL, P1
   Catania F., 2019, INT WORKSH CHATB RES, P65
   Catania F, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3564269
   Catania F, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451666
   Catania F, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P2014
   Centers for Disease Control and Prevention, 2018, AUTISM SPECTRUM DISO
   Chevalier P, 2017, LECT NOTES ARTIF INT, V10652, P546, DOI 10.1007/978-3-319-70022-9_54
   Cooper HE, 2012, Research designs: Quantitative, qualitative, neuropsychological, and biological, V2
   Costantini G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3501
   Costantino MA., 2011, Costruire libri e storie con la CAA
   Derks D, 2008, SOC SCI COMPUT REV, V26, P379, DOI 10.1177/0894439307311611
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [DOI 10.1145/2181037.2181040, 10.1145/2181037.2181040]
   Dickerson P, 2013, INTERACT STUD, V14, P297, DOI 10.1075/is.14.2.07dic
   Diederich S., 2019, P 14 INT C WIRTSCH, P1550
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Elfenbein HA, 2017, EMOTION, V17, P348, DOI 10.1037/emo0000145
   Epifânio JC, 2020, IEEE ACCESS, V8, P32802, DOI 10.1109/ACCESS.2020.2973097
   Fachantidis N, 2020, INT J DEV DISABIL, V66, P113, DOI 10.1080/20473869.2018.1495391
   Folstad A., 2020, Quality and User Experience, V5, P1, DOI DOI 10.1007/S41233-020-00033-2
   Google, GOOGL TEXT SPEECH
   Google, GOOGL SPEECH TEXT
   google, Google Dialogflow
   Granic I, 2014, AM PSYCHOL, V69, P66, DOI 10.1037/a0034857
   Grossard C, 2017, COMPUT EDUC, V113, P195, DOI 10.1016/j.compedu.2017.05.002
   Hamzah MSJ, 2014, PROCEDIA COMPUT SCI, V42, P214, DOI 10.1016/j.procs.2014.11.054
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hobert S, 2019, WIRTSCHAFTSINF, P1
   Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (AISC 927), P946, DOI 10.1007/978-3-030-15035-8_93
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Karaçam S, 2022, PROBIOTICS ANTIMICRO, V14, P995, DOI 10.1007/s12602-021-09806-3
   Kim YD, 2010, LECT NOTES ARTIF INT, V6414, P222
   Kinnaird E, 2019, EUR PSYCHIAT, V55, P80, DOI 10.1016/j.eurpsy.2018.09.004
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Kremelberg D., 2010, PRACTICAL STAT QUICK
   Laux L. F., 1996, ASSETS '96. The Second Annual ACM Conference on Assistive Technologies, P94, DOI 10.1145/228347.228363
   Lewis C., 1997, HDB HUMAN COMPUTER I, P717, DOI DOI 10.1016/B978-044481862-1.50096-0
   Li Jamy, 2020, PETRA '20: Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments, DOI 10.1145/3389189.3393738
   Light J, 2007, AUGMENT ALTERN COMM, V23, P204, DOI 10.1080/07434610701553635
   Liu XY, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101051
   Lumley MA, 2007, J PERS ASSESS, V89, P230, DOI 10.1080/00223890701629698
   Marino F, 2020, J AUTISM DEV DISORD, V50, P1973, DOI 10.1007/s10803-019-03953-x
   Mayer JD, 1999, INTELLIGENCE, V27, P267, DOI 10.1016/S0160-2896(99)00016-1
   MAYER JD, 1993, INTELLIGENCE, V17, P433, DOI 10.1016/0160-2896(93)90010-3
   Mehrabian A., 2017, Communication theory, P193
   Picorone AAM, 2014, 2014 18TH IEEE INTERNATIONAL SYMPOSIUM ON POWER LINE COMMUNICATIONS AND ITS APPLICATIONS (ISPLC), P1, DOI 10.1109/ISPLC.2014.6812337
   Mower E, 2011, IEEE INT CON MULTI
   da Silva ACN, 2018, RES PSYCHOTHER-PSYCH, V21, P83, DOI 10.4081/ripppo.2018.313
   Palestra G., 2016, P INT WORKSH SOC LEA, P1, DOI [10.1145/3005338.3005341, DOI 10.1145/3005338.3005341]
   Pennisi P, 2016, AUTISM RES, V9, P165, DOI 10.1002/aur.1527
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Razavi SZ, 2016, LECT NOTES ARTIF INT, V10011, P460, DOI 10.1007/978-3-319-47665-0_55
   Reeves B., 2009, Total engagement: How games and virtual worlds are changing the way people work and businesses compete
   Ricciardi L, 2015, J NEUROPSYCH CLIN N, V27, P179, DOI 10.1176/appi.neuropsych.14070169
   Rivers SE, 2012, J PSYCHOEDUC ASSESS, V30, P344, DOI 10.1177/0734282912449443
   Russo A, 2019, REJUV RES, V22, P109, DOI 10.1089/rej.2018.2075
   Saleh M. A., 2020, Periodicals of Engineering and Natural Sciences, V8, P1247, DOI [https://doi.org/10.21533/pen.v8i3.1457.g610, DOI 10.21533/PEN.V8I3.1457.G610]
   Sampath H., 2013, P 11 ASIA PACIFIC C, P325, DOI DOI 10.1145/2525194.2525300
   Scassellati B, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat7544
   Scherer K.R., 1987, GENEVA STUDIES EMOTI, V1, P1
   Shen SQ, 2017, HEALTH EXPECT, V20, P543, DOI 10.1111/hex.12490
   Spitale M., 2020, P 53 HAW INT C SYST, P1
   Spitale M, 2020, PROCEEDINGS OF IDC 2020, P262, DOI 10.1145/3392063.3394421
   TANAKA H, 2017, PLOS ONE, V12
   Trevisan DA, 2016, MOL AUTISM, V7, DOI 10.1186/s13229-016-0108-6
   Valencia Katherine, 2020, LNCS, P598, DOI DOI 10.1007/978-3-030-49576-3_44
   Valentine AZ, 2020, CLIN PSYCHOL REV, V80, DOI 10.1016/j.cpr.2020.101870
   Villano M, 2011, ACMIEEE INT CONF HUM, P279, DOI 10.1145/1957656.1957770
   Yao Q., 2014, Multi-sensory emotion recognition with speech and facial expression
NR 86
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12797
EP 12828
DI 10.1007/s11042-022-14135-w
EA NOV 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000880356200002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Xiang, Z
   Zhao, XB
   Fang, AQ
AF Xiang, Zheng
   Zhao, Xinbo
   Fang, Aiqing
TI Pupil center detection inspired by multi-task auxiliary learning
   characteristic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pupile center detection; Deep learning; Auxiliary characteristic;
   Multi-task learning
ID EYE-TRACKING; SYSTEM
AB Robust and accurate pupil center detection is a prerequisite for eye-tracking system. In natural environments, due to rapid illumination transformation, pupil occlusion, specular reflection, etc., existing pupil detection methods are not easy to detect the pupil center robustly and accurately. To solve this problem, inspired by the multi-task auxiliary learning characteristic of human beings, we propose a coarse-to-fine pupil center detection method. We explore the hidden relationship between multi-task auxiliary learning characteristic and the pupil detection task. Our method can be divided into two stages, i.e., coarse classification and fine regression. Firstly, in the coarse classification stage, we use multiple subtasks to assist the main task so as to improve the robustness of the model. Secondly, in the fine regression stage, we use the main task from coarse classification to assist the regression task to improve the accuracy of the model. The results of the coarse classification stage are refined to determine the final accurate pupil center. The proposed method achieves 97% detection rate on LPW with a distance error lower than 5 pixels. In addition, our method also shows the state-of-the-art results on the ExCuSe, ElSe, and PupilNet datasets. Finally, a large number of experiments are taken to verify the effectiveness and advancement of the pupil center detection method inspired by the multi-task auxiliary learning characteristic.
C1 [Xiang, Zheng] Northwestern Polytech Univ, Sch Software, Xian 710072, Peoples R China.
   [Zhao, Xinbo; Fang, Aiqing] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Zhao, Xinbo] Sci & Technol Electroopt Control Lab, Luoyang 471009, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Zhao, XB (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.; Zhao, XB (corresponding author), Sci & Technol Electroopt Control Lab, Luoyang 471009, Peoples R China.
EM zxiang@mail.nwpu.edu.cn; xbozhao@nwpu.edu.cn; aiqingf@mail.nwpu.edu.cn
RI Fang, aiqing/JGE-2871-2023
OI Fang, Aiqing/0000-0002-0425-7626
FU National Natural Science Foundation of China [61871326]; Shaanxi Natural
   Science Basic Research Program [2018JM6116]; Aviation Science Fund
   [20185153031]; Science and Technology on Electro-optic Control
   Laboratory
FX This work was supported by the National Natural Science Foundation of
   China under Grants Nos. 61871326, and the Shaanxi Natural Science Basic
   Research Program under Grants Nos. 2018JM6116, and Science and
   Technology on Electro-optic Control Laboratory Jointly funded with
   Aviation Science Fund under Grants Nos. 20185153031.
CR Chen CM, 2019, ELECTRON LIBR, V37, P680, DOI 10.1108/EL-03-2019-0059
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chinsatit W, 2017, APPL COMPUT INTELL S, V2017, DOI 10.1155/2017/8718956
   DIDDAY RL, 1975, INT J MAN MACH STUD, V7, P547, DOI 10.1016/S0020-7373(75)80032-0
   Dongheng L., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P79
   Dowiasch S, 2016, EUR ARCH PSY CLIN N, V266, P43, DOI 10.1007/s00406-014-0567-8
   Edewaard DE, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391360
   Eivazi S, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319914
   Fang A, 2020, AE NET AUTONOMOUS EV, P30
   Fang AQ, 2020, Arxiv, DOI arXiv:1912.10738
   Fang AQ, 2020, Arxiv, DOI arXiv:1912.08577
   Fang AQ, 2020, NEUROCOMPUTING, V414, P333, DOI 10.1016/j.neucom.2020.07.014
   Figueiredo GR, 2019, IEEE ENG MED BIO, P5419, DOI [10.1109/EMBC.2019.8857878, 10.1109/embc.2019.8857878]
   Fuhl W., 2016, ARXIV160104902
   Fuhl W, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P123, DOI 10.1145/2857491.2857505
   Fuhl W, 2015, LECT NOTES COMPUT SC, V9256, P39, DOI 10.1007/978-3-319-23192-1_4
   Gomolka Z, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20040986
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Javadi Amir-Homayoun, 2015, Front Neuroeng, V8, P4, DOI 10.3389/fneng.2015.00004
   Joo HJ, 2020, MULTIMED TOOLS APPL, V79, P16719, DOI 10.1007/s11042-019-08327-0
   Kang JN, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103722
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kim HC, 2020, NEUROIMAGE, V216, DOI 10.1016/j.neuroimage.2020.116617
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee GJ, 2020, MULTIMED TOOLS APPL, V79, P12939, DOI 10.1007/s11042-020-08638-7
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Lim JZ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082384
   Long XD, 2007, P ANN INT IEEE EMBS, P3331, DOI 10.1109/IEMBS.2007.4353043
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   Park H, 2016, COMPUT HUM BEHAV, V63, P796, DOI 10.1016/j.chb.2016.06.016
   Riba P, 2020, PATTERN RECOGN LETT, V134, P116, DOI 10.1016/j.patrec.2019.02.001
   Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281
   Ryan WJ, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P61, DOI 10.1145/1344471.1344487
   Santini T, 2018, COMPUT VIS IMAGE UND, V170, P40, DOI 10.1016/j.cviu.2018.02.002
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strnádelová B, 2019, APPL ARTIF INTELL, V33, P839, DOI 10.1080/08839514.2019.1646004
   Swirski L., 2012, P S EYE TRACK RES AP, P173
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Vera-Olmos FJ, 2019, INTEGR COMPUT-AID E, V26, P85, DOI 10.3233/ICA-180584
   Wang XM, 2019, COMPLEXITY, DOI 10.1155/2019/8641074
   Wang YJ, 2019, PATTERN RECOGN, V94, P196, DOI 10.1016/j.patcog.2019.05.026
   Zhang J, 2019, PATTERN RECOGN, V91, P175, DOI 10.1016/j.patcog.2019.02.024
   Zhang Y, 2018, NATL SCI REV, V5, P30, DOI 10.1093/nsr/nwx105
   Xuan Z, 2017, PATTERN RECOGN, V63, P56, DOI 10.1016/j.patcog.2016.09.007
NR 46
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40067
EP 40088
DI 10.1007/s11042-022-12278-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000872701700012
DA 2024-07-18
ER

PT J
AU Le, VH
AF Van-Hung Le
TI Deep learning-based for human segmentation and tracking, 3D human pose
   estimation and action recognition on monocular video of MADS dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MADS dataset; Deep learning; Convolutional neural network; Human
   segmentation and tracking; 3D human pose estimation; Human action
   recognition
ID CONVOLUTIONAL NETWORKS; ENSEMBLE
AB Human segmentation and tracking (HS-T) in the video often utilize person detection results. In addition, 3D human pose estimation (3D-HPE) and human activity recognition (HAR) often use human segmentation results to reduce data storage and computational time. With recent advantages of deep learning, especially using Convolutional Neural Networks (CNNs), there are excellent results in these relevant tasks. Consequently, they can be applied to building many practical applications such as sports analysis, sports scoring, health protection, teaching, and preserving traditional martial arts. In this paper, we performed a survey of relevant studies, methods, datasets, and results for HS-T, 3D-HPE, and HAR. We also deeply analyze the results of detecting persons as it affects the results of human segmentation and human tracking. The survey is performed in great detail up to source code paths. The MADS (Martial Arts, Dancing, and Sports) dataset comprises fast and complex activities. It has been published for the task of estimating human pose. However, before determining the human pose, the person needs to be detected as a segment in the video, especially the 3D human pose annotation data is different from the point cloud data generated from RGB-D images. Therefore, we have also prepared 2D human pose annotation data on the 28k images for creating 3D human pose annotation and action labeling data. Moreover, we also evaluated the MADS dataset with many recently published deep learning methods for human segmentation (Mask R-CNN, PointRend, TridentNet, TensorMask, and CenterMask) and tracking, 3D-HPE (RepNet, MediaPipe Pose, and Lifting from the Deep, V2V-PoseNet), and HAR (ST-GCN, DD-net, and PA-GesGCN) in the video. All data and published results are available.
C1 [Van-Hung Le] Tan Trao Univ, Tuyen Quang, Vietnam.
RP Le, VH (corresponding author), Tan Trao Univ, Tuyen Quang, Vietnam.
EM van-hung.le@mica.edu.vn
RI Van Hung, Le/GRJ-6400-2022
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2019.315]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2019.315.
CR Allaya N, 2010, 2010 IEEE COMPUTER S, V36, P3807, DOI [10.1007/s13277-014-3022-6, DOI 10.1007/S13277-014-3022-6]
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2019, GEOMETRIC GEOMETRIC
   [Anonymous], 2019, GEEKS FORGEEKS LINEA
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2019, LINEAR LINEAR REGRES
   [Anonymous], 2012, IEEE Signal Processing Magazine
   Bazarevsky V, 2020, Arxiv, DOI arXiv:2006.10204
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y
   Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249
   Burrus N., 2011, KINECT CALIBRATION
   Chahyati D, 2017, PROCEDIA COMPUT SCI, V124, P167, DOI 10.1016/j.procs.2017.12.143
   Chen CH, 2017, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR.2017.610
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen W, 2020, SYMMETRY
   Chen XL, 2019, IEEE I CONF COMP VIS, P2061, DOI 10.1109/ICCV.2019.00215
   Chen XP, 2019, PROC CVPR IEEE, P10887, DOI 10.1109/CVPR.2019.01115
   Chen YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13339, DOI 10.1109/ICCV48922.2021.01311
   Cheng B, 2019, ICCV COCO MAPILLARY
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   Dai JF, 2016, ADV NEUR IN, V29
   Dang Q, 2019, TSINGHUA SCI TECHNOL, V24, P663, DOI 10.26599/TST.2018.9010100
   Das Srijan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P72, DOI 10.1007/978-3-030-58545-7_5
   Ding X., 2019, Proceedings of the 2019 2nd International Conference on Signal Processing and Machine Learning, P79, DOI 10.1145/3372806.3372814
   Ding ZH, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P610, DOI 10.1109/QRS-C.2017.134
   Duan H., 2022, arXiv, DOI DOI 10.48550/ARXIV.2205.09443
   Duan H, 2021, ARXIV 210413586
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Georgakis Georgios, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P768, DOI 10.1007/978-3-030-58520-4_45
   Girshick R., 2013, IEEE Comput. Soc., P580
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gruosso M, 2021, MULTIMED TOOLS APPL, V80, P1175, DOI 10.1007/s11042-020-09425-0
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Haque MF, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P586, DOI 10.23919/elinfocom.2019.8706476
   Harshall L., 2019, UNDERSTANDING SEMANT
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Helten T, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P279, DOI 10.1109/3DV.2013.44
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Hu G, 2019, IEEE INT CON MULTI, P1216, DOI 10.1109/ICME.2019.00212
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Hung Goon Li, 2020, SN Comp. Sci., V1, P1
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Iskakov K, 2019, Arxiv, DOI arXiv:1905.05754
   Ji X., 2020, Virtual Reality Intell. Hardw., V2, P471, DOI DOI 10.1016/J.VRIH.2020.04.005
   Jocher G, 2021, HEAD PERSON DETECTIO
   Khan, 2019, Visual Object Tracking with Deep Neural Networks, DOI 10.5772/intechopen.85215
   Kim BG, 2004, PATTERN RECOGN LETT, V25, P1731, DOI 10.1016/j.patrec.2004.07.009
   Kirillov A., 2019, PointRend: Image segmentation as rendering, P9796
   Kocabas M, 2019, IEEE COMP VIS PATT R
   Kong Y, 2022, INT J COMPUT VISION, V130, P1366, DOI 10.1007/s11263-022-01594-9
   Kundu JN, 2020, AAAI CONF ARTIF INTE, V34, P11312
   Laplaza Galindo J, 2018, THESIS
   Leal-Taixe L., 2015, MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Lee Y, 2020, P IEEE CVF C COMP VI
   Lee YW, 2019, IEEE COMPUT SOC CONF, P752, DOI 10.1109/CVPRW.2019.00103
   Li C, 2022, IEEE T NEUR NET LEAR, V33, P4800, DOI 10.1109/TNNLS.2021.3061115
   Li C, 2019, PROC CVPR IEEE, P9879, DOI 10.1109/CVPR.2019.01012
   Li SJ, 2017, INT J COMPUT VISION, V122, P149, DOI 10.1007/s11263-016-0962-x
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Li WH, 2023, IEEE T MULTIMEDIA, V25, P1282, DOI 10.1109/TMM.2022.3141231
   Li YS, 2019, IEEE INT CON MULTI, P1066, DOI 10.1109/ICME.2019.00187
   Li YJ, 2019, IEEE I CONF COMP VIS, P7918, DOI 10.1109/ICCV.2019.00801
   Liang DH, 2019, IEEE COMPUT SOC CONF, P934, DOI 10.1109/CVPRW.2019.00123
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Liu F, 2020, IEEE INT SYMP PARAL, P474, DOI 10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00085
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   MingDa Li, 2020, EITCE 2020: Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering, P524, DOI 10.1145/3443467.3443809
   Moon G, 2019, IEEE I CONF COMP VIS, P10132, DOI 10.1109/ICCV.2019.01023
   Nakamura S., 2019, P ACM MULT AS, DOI [10.1145/3338533.3366569, DOI 10.1145/3338533.3366569]
   Neverova N, 2019, CORRELATED UNCERTAIN
   Nibali A, 2019, IEEE WINT CONF APPL, P1477, DOI 10.1109/WACV.2019.00162
   Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Pavllo Dario, 2018, BRIT MACHINE VISION, V41
   Qiang Nie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P102, DOI 10.1007/978-3-030-58529-7_7
   Qin ZH, 2023, ANN OPER RES, V326, P9, DOI 10.1007/s10479-021-04264-0
   Redmon J., 2018, IEEE C COMPUTER VISI
   Redmon J, 2016, Arxiv, DOI [arXiv:1612.08242, 10.48550/arXiv.1612.08242, DOI 10.48550/ARXIV.1612.08242]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren B, 2024, Arxiv, DOI arXiv:2002.05907
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Renuka J., 2021, ACCURACY PRECISION R
   Rhodin H, 2018, LECT NOTES COMPUT SC, V11214, P765, DOI 10.1007/978-3-030-01249-6_46
   Rhodin H, 2019, PROC CVPR IEEE, P7695, DOI 10.1109/CVPR.2019.00789
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanchez S. A., 2020, IOP Conference Series: Materials Science and Engineering, V844, DOI 10.1088/1757-899X/844/1/012024
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shao S, 2018, Arxiv, DOI [arXiv:1805.00123, DOI 10.48550/ARXIV.1805.00123]
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Simonyan K, 2015, IEEE INT C ICLR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh M., 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P1091
   Singh M, 2008, IEEE T CIRC SYST VID, V18, P1280, DOI 10.1109/TCSVT.2008.928888
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Song YF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1625, DOI 10.1145/3394171.3413802
   Song YF, 2019, IEEE IMAGE PROC, P1, DOI [10.1109/icip.2019.8802917, 10.1109/ICIP.2019.8802917, 10.1109/TFUZZ.2019.2910714]
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425
   Tekin Bugra, 2016, P BRIT MACH VIS C 20
   Thanh N.T., 2019, Journal on Information Technologies & Communications, V2019, P114, DOI 10.32913/mic-ict-research.v2019.n2.864
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tian ZD, 2021, IEEE T INTELL TRANSP, V22, P5566, DOI 10.1109/TITS.2020.2987909
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Tsai JK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174758
   Ul Haq E, 2020, MULTIMED TOOLS APPL, V79, P30685, DOI 10.1007/s11042-020-09579-x
   V‚ges M, 2019, Arxiv, DOI arXiv:1809.07217
   Wandt B, 2019, Arxiv, DOI arXiv:1902.09868
   Wandt Bastian, 2019, Computer Vision and Pattern Recognition (CVPR)
   Wang H., 2017, DEGREE PROJECT COMPU
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang JB, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103225
   Wang J, 2019, IEEE I CONF COMP VIS, P7770, DOI 10.1109/ICCV.2019.00786
   Wang KZ, 2020, IEEE T PATTERN ANAL, V42, P1069, DOI 10.1109/TPAMI.2019.2892452
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LY, 2019, Arxiv, DOI arXiv:1904.05512
   Wang X, 2019, CVPR19, V55, P306, DOI [10.11784/tdxbz202012073, DOI 10.11784/TDXBZ202012073]
   Wang Y, 2020, J PHYS C SERIES, V1550
   Watada J, 2010, LECT NOTES ARTIF INT, V6277, P454, DOI 10.1007/978-3-642-15390-7_47
   Willett NS, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P88, DOI 10.1145/3377325.3377505
   Wojke N, 2018, IEEE WINT CONF APPL, P748, DOI 10.1109/WACV.2018.00087
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu Y., 2019, DETECTRON2
   Xu JX, 2019, Arxiv, DOI arXiv:1910.12945
   Xu JW, 2020, PROC CVPR IEEE, P896, DOI 10.1109/CVPR42600.2020.00098
   Xu YY, 2018, IEEE SIGNAL PROC LET, V25, P1044, DOI 10.1109/LSP.2018.2841649
   Xu YK, 2019, IET COMPUT VIS, V13, P355, DOI 10.1049/iet-cvi.2018.5598
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yao R, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3391743
   Ye M, 2016, IEEE T PATTERN ANAL, V38, P1517, DOI 10.1109/TPAMI.2016.2557783
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
   Zeng AL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11416, DOI 10.1109/ICCV48922.2021.01124
   Zhang H, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3448978, 10.1145/3450626.3459830]
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhang SH, 2019, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2019.00098
   Zhang WC, 2017, IMAGE VISION COMPUT, V61, P22, DOI 10.1016/j.imavis.2017.02.002
   Zhang WC, 2014, IEEE T IMAGE PROCESS, V23, P5374, DOI 10.1109/TIP.2014.2364113
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang Z, 2015, LECT NOTES ELECTR EN, V322, P565, DOI 10.1007/978-3-319-08991-1_58
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zheng C, 2018, J ACM, V37
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zhou K, 2019, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2019.00243
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
   Zhu JG, 2018, Arxiv, DOI arXiv:1812.05770
NR 168
TC 5
Z9 5
U1 9
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20771
EP 20818
DI 10.1007/s11042-022-13921-w
EA OCT 2022
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000875925300001
DA 2024-07-18
ER

PT J
AU Rezaeenour, J
   Ahmadi, M
   Jelodar, H
   Shahrooei, R
AF Rezaeenour, Jalal
   Ahmadi, Mahnaz
   Jelodar, Hamed
   Shahrooei, Roshan
TI Systematic review of content analysis algorithms based on deep neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Natural language processing; Text mining; Recurrent neural networks;
   Machine learning; Deep learning; Data mining; Artificial neural network
ID KNOWLEDGE DISCOVERY; LSTM; CLASSIFICATION; MODEL
AB Today according to social media, the internet, Etc. Data is rapidly produced and occupies a large space in systems that have resulted in enormous data warehouses; the progress in information technology has significantly increased the speed and ease of data flow.text mining is one of the most important methods for extracting a useful model through extracting and adapting knowledge from data sets. However, many studies have been conducted based on the usage of deep learning for text processing and text mining issues. The idea and method of text mining are one of the fields that seek to extract useful information from unstructured textual data that is used very today. Deep learning and machine learning techniques in classification and text mining and their type are discussed in this paper as well. Neural networks of various kinds, namely, ANN, RNN, CNN, and LSTM, are the subject of study to select the best technique. In this study, we conducted a Systematic Literature Review to extract and associate the algorithms and features that have been used in this area. Based on our search criteria, we retrieved 130 relevant studies from electronic databases between 1997 and 2021; we have selected 43 studies for further analysis using inclusion and exclusion criteria in Section 3.2. According to this study, hybrid LSTM is the most widely used deep learning algorithm in these studies, and SVM in machine learning method high accuracy in result shown.
C1 [Rezaeenour, Jalal; Ahmadi, Mahnaz; Shahrooei, Roshan] Univ Qom, Dept Ind Engn, Qom, Iran.
   [Jelodar, Hamed] Dalhousie Univ, Fac Comp Sci, 6050 Univ Ave, Halifax, NS B3H 1W5, Canada.
C3 University of Qom; Dalhousie University
RP Rezaeenour, J (corresponding author), Univ Qom, Dept Ind Engn, Qom, Iran.
EM j.rezaee@qom.ac.ir
RI Rezaeenour, Jalal/AAG-2291-2019; shahrooei, roshan/KQV-3913-2024;
   Jelodar, Hamed/HTM-7150-2023
OI Rezaeenour, Jalal/0000-0002-3759-2607; 
CR Abdel-Nasser M, 2019, NEURAL COMPUT APPL, V31, P2727, DOI 10.1007/s00521-017-3225-z
   Aggarwal A, 2020, EAI ENDORSED TRANS S, V7, DOI 10.4108/eai.13-7-2018.163973
   Alsentzer E., 2019, arXiv
   [Anonymous], 1950, MIND, DOI 10.1093/mind/LIX.236.433
   Arase Y, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101164
   Ayre L, 2006, DATA MINING INFORM P
   Bahad P, 2019, PROCEDIA COMPUT SCI, V165, P74, DOI 10.1016/j.procs.2020.01.072
   Banerjee I, 2019, ARTIF INTELL MED, V97, P79, DOI 10.1016/j.artmed.2018.11.004
   Berahmand K, 2021, COMPUTING, V103, P2227, DOI 10.1007/s00607-021-00982-2
   Bustos O, 2020, EXPERT SYST APPL, V156, DOI 10.1016/j.eswa.2020.113464
   Cai LK, 2020, IEEE ACCESS, V8, P152183, DOI 10.1109/ACCESS.2020.3017382
   Chao ZY, 2018, J SENSORS, V2018, DOI 10.1155/2018/6184713
   Chen CW, 2020, INFORMATION, V11, DOI 10.3390/info11020106
   Chen Hanjie., 2020, P 58 ANN M ASS COMPU, P5578
   Colón-Ruiz C, 2020, J BIOMED INFORM, V110, DOI 10.1016/j.jbi.2020.103539
   Du MN, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P383, DOI 10.1145/3308558.3313545
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Gajendran S, 2020, J BIOMED INFORM, V112, DOI 10.1016/j.jbi.2020.103609
   Ghourabi A, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12090156
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Hiew JZG, 2005, ARXIV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang J., 2019, ACM INT C P SER, P39, DOI DOI 10.1145/3373509.3373573
   Hubel DH, 1962, MOST, P106
   Ingole Priyanka, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P450, DOI 10.1109/ICECA.2018.8474920
   Jelodar H, 2020, IEEE J BIOMED HEALTH, V24, P2733, DOI 10.1109/JBHI.2020.3001216
   Jurgovsky J, 2018, EXPERT SYST APPL, V100, P234, DOI 10.1016/j.eswa.2018.01.037
   Khattak Faiza Khan, 2019, J Biomed Inform, V100S, P100057, DOI 10.1016/j.yjbinx.2019.100057
   Kiran R, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113488
   Kwartler Ted., 2017, Text mining in practice, DOI [DOI 10.1002/9781119282105, 10.1002/9781119282105]
   Lee JS, 2020, WORLD PAT INF, V61, DOI 10.1016/j.wpi.2020.101965
   Lewis B., 2017, 28th Modern Artificial Intelligence and Cognitive Science Conference, MAICS 2017, P189
   Li Q, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163300
   Liu P, 2016, ARXIV160505101
   Majumder S, 2018, IEEE WORK CONF MIN S, P554, DOI 10.1145/3196398.3196424
   Mohasseb A, 2018, INFORM PROCESS MANAG, V54, P1228, DOI 10.1016/j.ipm.2018.05.001
   Moitra D, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-12229-z
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Nowak J, 2017, LECT NOTES ARTIF INT, V10246, P553, DOI 10.1007/978-3-319-59060-8_50
   Ombabi AH, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00668-1
   Onan A, 2021, COMPUT APPL ENG EDUC, V29, P572, DOI 10.1002/cae.22253
   Ozbayoglu Ahmet Murat, 2020, Applied Soft Computing, V93, DOI 10.1016/j.asoc.2020.106384
   Panda A., 2019, 2019 12 INT C CONT C, P1
   Potts C, 2014, NATURAL LANGUAGE UND
   Qiang Jiang, 2019, Proceedings of the Twelfth International Conference on Management Science and Engineering Management. Lecture Notes on Multidisciplinary Industrial Engineering (LNMUINEN), P393, DOI 10.1007/978-3-319-93351-1_32
   Vo QH, 2017, INT CONF KNOWL SYS, P24, DOI 10.1109/KSE.2017.8119429
   Rahman M, 2020, COMPUT BIOL CHEM, V88, DOI 10.1016/j.compbiolchem.2020.107329
   Rahmani AM, 2022, MULTIMED TOOLS APPL, V81, P28779, DOI 10.1007/s11042-022-12952-7
   Rao A, 2016, ARXIV
   Razzaghnoori M, 2018, COGN SYST RES, V47, P16, DOI 10.1016/j.cogsys.2017.07.002
   Reddy BK, 2018, COMPUT BIOL MED, V101, P199, DOI 10.1016/j.compbiomed.2018.08.029
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P377, DOI 10.1007/s42979-021-00765-8
   Shirvani Rouzbeh A., 2020, ARXIV, P1
   Siddharthan A, 2002, FDN STAT NATURAL LAN, DOI [10.1017/s1351324902212851, DOI 10.1017/S1351324902212851]
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Song Y, 2020, ARXIV
   Song YW, 2019, LECT NOTES COMPUT SC, V11730, P93, DOI 10.1007/978-3-030-30490-4_9
   Sorin V, 2020, J AM COLL RADIOL, V17, P639, DOI 10.1016/j.jacr.2019.12.026
   Staffs Keele, 2007, Tech. Rep.
   Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380
   Sur C, 2019, MULTIMED TOOLS APPL, V78, P32187, DOI 10.1007/s11042-019-08021-1
   Tembhurne JV, 2021, MULTIMED TOOLS APPL, V80, P6871, DOI 10.1007/s11042-020-10037-x
   Tomihira T, 2020, INT J WEB INF SYST, V16, P265, DOI 10.1108/IJWIS-09-2019-0042
   Usai A, 2018, J KNOWL MANAG, V22, P1471, DOI 10.1108/JKM-11-2017-0517
   Wahdan KA., 2020, Int. J. Electr. Comput. Eng., V10, P6629, DOI DOI 10.11591/IJECE.V10I6.PP6629-6643
   Wang CL, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2061, DOI 10.1145/3097983.3098140
   Wang HC, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106767
   WANG JH, 2018, P 30 C COMP LING SPE, P214, DOI DOI 10.2991/ICEEA-18.2018.47
   Wang X., 2016, P COL 2016 26 INT C, P2428
   Xu JC, 2020, MULTIMED TOOLS APPL, V79, P22551, DOI 10.1007/s11042-020-09063-6
   Yin W., 2017, arXiv
   Zhang JS, 2019, J SAFETY RES, V68, P187, DOI 10.1016/j.jsr.2018.11.006
   Zhang J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034497
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang PG, 2010, DATA MIN KNOWL DISC, DOI [10.1007/978-0-387-09823-4, DOI 10.1007/978-0-387-09823-4]
   Zhang WY, 2019, KNOWL-BASED SYST, V174, P194, DOI 10.1016/j.knosys.2019.03.007
   Zhang XX, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60460-1
   Zhang YZ, 2021, NEURAL NETWORKS, V133, P40, DOI 10.1016/j.neunet.2020.10.001
   Zhong BT, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101152
   Zhou Chunting, 2015, ARXIV
   Zhou P., 2016, ARXIV161106639
   Zhu YQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P802, DOI 10.1145/3343031.3350932
NR 82
TC 8
Z9 8
U1 6
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17879
EP 17903
DI 10.1007/s11042-022-14043-z
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000871318500003
PM 36313481
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Kollem, S
   Prasad, CR
   Ajayan, J
   Malathy, V
   Subbarao, A
AF Kollem, Sreedhar
   Prasad, Ch Rajendra
   Ajayan, J.
   Malathy, V
   Subbarao, Akkala
TI Brain tumor MRI image segmentation using an optimized multi-kernel FCM
   method with a pre-processing stage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial differential equation; Diffusivity function; Multi-kernel fuzzy
   c-means method; Elephant herding optimization algorithm; Adaptive
   threshold
ID ANISOTROPIC DIFFUSION; COEFFICIENT; ALGORITHM; MODEL
AB Because of the variety of shapes, locations, and image intensities, image segmentation is a more difficult endeavor in image processing. The most frequent diseases in the world are brain tumors. Therefore, brain tumor segmentation is essential in the medical field. The objective of this work is to propose image denoising and segmentation algorithms, as image segmentation is highly dependent on image denoising. The proposed image denoising algorithm is included in this article as part of the pre-processing stage. For image denoising, a novel adaptive diffusivity function based on partial differential equations is implemented. The diffusivity function's purpose is to enhance the images of brain tumors using a gradient, a Laplacian, and an adaptive threshold while also preserving image details. For image segmentation, the enhanced image is fed into an improved multi-kernel fuzzy c-means method, which then optimizes the centroid using an elephant herding optimization algorithm. Finally, it differentiates between tumor and non-tumor tissue. Images from the BRATS2020 Database were used to assess the effectiveness of the proposed approaches. When compared to conventional techniques, the proposed method performs well and proves to be an effective technique (PSNR-39.4001dBs, SSIM-99.78%, and MSE-7.4656 for image denoising; Sensitivity-98.45%, specificity-99.87%, and accuracy-99.83% for image segmentation at sigma= 20). The proposed method is developed and demonstrated in the MATLAB environment.
C1 [Kollem, Sreedhar; Prasad, Ch Rajendra; Ajayan, J.; Malathy, V] SR Univ, Sch Engn, Dept ECE, Warangal, Telangana, India.
   [Subbarao, Akkala] Maulana Azad Natl Inst Technol, Dept ECE, Bhopal, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Kollem, S (corresponding author), SR Univ, Sch Engn, Dept ECE, Warangal, Telangana, India.
EM ksreedhar446@gmail.com
RI Rajendra Prasad, Dr. Ch/AAB-1526-2021; Kollem, S/GQQ-3144-2022; Akkala,
   Subbarao/H-4473-2018
OI Rajendra Prasad, Dr. Ch/0000-0003-1644-8590; Kollem,
   S/0000-0002-9203-0404; 
CR Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Alomoush W, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03430-3
   Ananthi VP, 2016, SOFT COMPUT, V20, P4859, DOI 10.1007/s00500-015-1775-5
   BRATS2020, 2020, DAT
   Chander S, 2018, ALEX ENG J, V57, P267, DOI 10.1016/j.aej.2016.12.013
   Chao SM, 2010, PATTERN RECOGN LETT, V31, P2012, DOI 10.1016/j.patrec.2010.06.004
   Chen L, 2011, IEEE T SYST MAN CY B, V41, P1263, DOI 10.1109/TSMCB.2011.2124455
   Dhanachandra N, 2020, MULTIMED TOOLS APPL, V79, P18839, DOI 10.1007/s11042-020-08699-8
   Dougherty G., 2010, Medical Physics, V37, P948, DOI 10.1118/1.3285412
   Irum I, 2015, J Eng Sci Technol Rev, V8, P41
   Khan NU, 2014, MULTIMED TOOLS APPL, V73, P573, DOI 10.1007/s11042-013-1620-8
   Kollem Sreedhar, 2019, International Journal of Machine Learning and Computing, V9, P288, DOI 10.18178/ijmlc.2019.9.3.800
   Kollem S, 2022, INT J IMAG SYST TECH, V32, P1263, DOI 10.1002/ima.22681
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P2663, DOI 10.1007/s11042-020-09745-1
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P409, DOI 10.1007/s11042-020-09675-y
   Kollem S, 2020, INT J IMAG SYST TECH, V30, P1271, DOI 10.1002/ima.22429
   Kollem S, 2019, INT J IMAG SYST TECH, V29, P195, DOI 10.1002/ima.22302
   Krishnakumar S, 2021, J AMB INTEL HUM COMP, V12, P6751, DOI 10.1007/s12652-020-02300-8
   Kumar DM, 2021, J AMB INTEL HUM COMP, V12, P2867, DOI 10.1007/s12652-020-02444-7
   Li J, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7050395
   Li J, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091415
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Rafsanjani HK, 2016, COMPUT MATH APPL, V72, P893, DOI 10.1016/j.camwa.2016.06.005
   Rafsanjani HK, 2017, DIGIT SIGNAL PROCESS, V64, P71, DOI 10.1016/j.dsp.2017.02.004
   Ragupathy B, 2021, INT J IMAG SYST TECH, V31, P118, DOI 10.1002/ima.22498
   Reddy KRL., 2018, INT JELECTR COMPUT E, V8, P971
   Riya, 2021, COMPUT MATH APPL, V93, P106, DOI 10.1016/j.camwa.2021.03.029
   ShanmugaPriya S, 2018, DES AUTOM EMBED SYST, V22, P81, DOI 10.1007/s10617-017-9200-1
   Shi KH, 2021, J COMPUT APPL MATH, V395, DOI 10.1016/j.cam.2021.113605
   Srinivasan A, 2021, J AMB INTEL HUM COMP, V12, P3775, DOI 10.1007/s12652-019-01672-w
   Tebini S, 2016, DIGIT SIGNAL PROCESS, V48, P201, DOI 10.1016/j.dsp.2015.09.013
   Tebini S, 2016, COMPUT MATH APPL, V72, P1369, DOI 10.1016/j.camwa.2016.07.004
   Tsiotsios C, 2013, PATTERN RECOGN, V46, P1369, DOI 10.1016/j.patcog.2012.11.012
   Xu JT, 2016, SIGNAL PROCESS, V119, P80, DOI 10.1016/j.sigpro.2015.07.017
   Yuan JJ, 2016, INT J IMAGE GRAPH, V16, DOI 10.1142/S021946781650011X
   Zeng S, 2019, NEUROCOMPUTING, V335, P59, DOI 10.1016/j.neucom.2019.01.042
   Zeng S, 2018, IEEE T FUZZY SYST, V26, P1671, DOI 10.1109/TFUZZ.2017.2743679
NR 37
TC 3
Z9 3
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20741
EP 20770
DI 10.1007/s11042-022-14045-x
EA OCT 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000870100300002
DA 2024-07-18
ER

PT J
AU Kumar, R
   Pandey, S
AF Kumar, Rajneesh
   Pandey, Sachi
TI An accurate prediction of crop yield using hybrid deep capsule auto
   encoder with softmax regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crop yield prediction; Soil; Rainfall; Deep learning; Modified flamingo
   search
ID MODEL
AB Crop yield prediction is every nation's most important and difficult task. Due to the frequent climate changes, farmers struggle to achieve a high yield. This work presents an effective methodology for crop yield prediction of major crop production. In the presented methodology, crop yield is predicted by considering soil health data, crop production data and rainfall data. The input soil nutrients, weather and crop production data are processed. The input data is collected from the Uttar Pradesh (UP) region. In the first phase, the soil fertility index estimates the soil quality. In the second phase, the soil quality score and other crop yield related parameters like rainfall and crop production data are taken for further processing. Initially, the input soil health, crop production, and rainfall data are pre-processed. In the pre-processing stage, data cleaning with if-null processing and min-max normalization is used for data standardization. The features are then selected using the adaptive bald eagle search optimization (ABES) approach. Finally, the crop yield prediction of sugarcane, wheat and rice crops is obtained accurately by utilizing a hybrid deep capsule auto encoder with a softmax regression (Hybrid DCAS) model. Here, the hyper-parameter tuning of the presented deep learning model is achieved by a modified Flamingo Search (MFS) optimization approach. The overall implementation is carried out on PYTHON. The performance of the developed model is compared with other models in terms of classification and prediction performance.
C1 [Kumar, Rajneesh; Pandey, Sachi] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Modinagar, Uttar Pradesh, India.
C3 SRM Institute of Science & Technology Delhi NCR (Ghaziabad)
RP Pandey, S (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Modinagar, Uttar Pradesh, India.
EM sachipas@srmist.edu.in
RI Kumar, Dr. Rajneesh/IAN-8644-2023
OI Kumar, Dr. Rajneesh/0000-0002-4448-9456; KUMAR,
   RAJNEESH/0009-0005-9385-5845
CR Alsattar HA, 2020, ARTIF INTELL REV, V53, P2237, DOI 10.1007/s10462-019-09732-5
   [Anonymous], 2018, FAO RICE PRICE UPDAT
   Bhojani SH, 2020, NEURAL COMPUT APPL, V32, P13941, DOI 10.1007/s00521-020-04797-8
   Bouwma I, 2019, PAL ADV BIOEC-ECON, P153, DOI 10.1007/978-3-030-28642-2_9
   Dang CY, 2021, CAN J REMOTE SENS, V47, P162, DOI 10.1080/07038992.2020.1833186
   Elavarasan D, 2021, J AMB INTEL HUM COMP, V12, P10009, DOI 10.1007/s12652-020-02752-y
   Elavarasan D, 2020, IEEE ACCESS, V8, P86886, DOI 10.1109/ACCESS.2020.2992480
   Filippi P, 2019, PRECIS AGRIC, V20, P1015, DOI 10.1007/s11119-018-09628-4
   Gomez-Zavaglia A, 2020, FOOD RES INT, V134, DOI 10.1016/j.foodres.2020.109256
   Gong LY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134537
   Gopal PSM, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104968
   Gulati A., 2021, REVITALIZING INDIAN, DOI [10.1007/978-981-15-9335-2_7, DOI 10.1007/978-981-15-9335-2, 10.1007/978-981-15-9335-2]
   Hammer RG, 2020, SUGAR TECH, V22, P216, DOI 10.1007/s12355-019-00776-z
   Hu MF, 2021, LECT NOTES COMPUT SC, V12891, P519, DOI 10.1007/978-3-030-86362-3_42
   Iaksch J, 2021, J MANAG ANAL, V8, P333, DOI 10.1080/23270012.2021.1897957
   Jain S, 2018, EXPERT SYST APPL, V106, P252, DOI 10.1016/j.eswa.2018.04.008
   Joshua V, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11102068
   Khaki S, 2020, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01750
   Khaki S, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00621
   Khalil ZH, 2021, PROCEDIA COMPUT SCI, V186, P269, DOI 10.1016/j.procs.2021.04.146
   Lata S, 2019, ADV ASIAN HUM-ENV RE, P1, DOI 10.1007/978-3-030-00952-6
   Li WM, 2008, NEURAL COMPUT APPL, V17, P441, DOI 10.1007/s00521-007-0131-9
   Luo Y, 2022, FRONT PLANT SCI, V1582
   Miriyala GP, 2020, RECENT ADV COMPUTER, P145
   Nevavuori P, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104859
   Nosratabadi S, 2020, IEEE RIVF INT CONF, P137, DOI 10.1109/rivf48685.2020.9140786
   Oikonomidis A, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2031823
   Reddy D. Jayanarayana, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P1466, DOI 10.1109/ICICCS51141.2021.9432236
   Saxena S, 2019, INDIAN J EC DEV, V7
   Sharma KK, 2018, MAUSAM, V69, P599
   Sharma S., 2020, ARXIV
   Singh S., 2019, RES REV INT J MULTID, V4, P1
   Sood S, 2021, MULTIMED TOOLS APPL, V80, P27973, DOI 10.1007/s11042-021-11036-2
   Sun J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204363
   Talaviya T., 2020, Artif. Intell. Agric, V4, P58, DOI [DOI 10.1016/J.AIIA.2020.04.002, 10.1016/J.AIIA.2020.04.002]
   Wang ZH, 2021, IEEE ACCESS, V9, P88564, DOI 10.1109/ACCESS.2021.3090512
   Xi E., 2017, arXiv
   Xu XY, 2019, ECOL INDIC, V101, P943, DOI 10.1016/j.ecolind.2019.01.059
NR 38
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15371
EP 15393
DI 10.1007/s11042-022-13919-4
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863553400001
DA 2024-07-18
ER

PT J
AU Ali, S
   Sahiba, S
   Azeem, M
   Shaukat, Z
   Mahmood, T
   Sakhawat, Z
   Aslam, MS
AF Ali, Saqib
   Sahiba, Sana
   Azeem, Muhammad
   Shaukat, Zeeshan
   Mahmood, Tariq
   Sakhawat, Zareen
   Aslam, Muhammad Saqlain
TI A recognition model for handwritten Persian/Arabic numbers based on
   optimized deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OCR; Digit recognition; Deep learning method; Optimization algorithms;
   HODA database
ID DIGITS
AB Recently, artificial intelligence-based applications are universally acknowledged. Digit recognition, particularly Persian/Arabic handwritten digits, has many applications in today's commercial contexts for example office automation and document processing. However, researcher are struggling in hand-crafted digit scripts due to the presence of different digit writing patterns, cursive nature and lack of large public databases that make the feature extraction process more complex. Therefore, critical investigation is needed to reduce these challenges. In this study, a modified Deep Convolutional Neural Network (DCNN) architecture using three convolutional layers blocks based on convolution, batch normalization, pooling, fully connected and dropout regularization parameters are employed to hinder overfitting and increase generalization performance is proposed to recognize handwritten digits. Initially, digits taken from the HODA database are pre-processed using various steps including smoothing, black and white images to grayscale intensity images conversion and resizing it to a fixed dimension. Then optimal features extraction and recognition of handwritten images are done by the DCNN algorithm. In deep learning domain, optimization algorithms are considered core solution and their performances highly depends on optimization algorithm selection. In this paper, various optimization algorithms such as stochastic gradient descent (SGD), Adam, Adadelta, Adagrad, Adamax, Momentum, RMSprop and Nag are employed for the optimization of proposed DCNN. Moreover, current research also analyzes the role of different epochs to ameliorate optical character recognition (OCR) performance of Persian/Arabic handwritten digits. At the end, we also worked on finding a suitable composition of learning parameters to establish high performance DCNN architecture that conquer the loopholes of traditional methods. Results reveal that the proposed DCNN model achieves state-of-the-art performance and outperform other studies in the literature.
C1 [Ali, Saqib; Sahiba, Sana; Shaukat, Zeeshan; Sakhawat, Zareen] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Azeem, Muhammad] Univ Sialkot, Dept Informat Technol, Sialkot 51040, Punjab, Pakistan.
   [Mahmood, Tariq] Univ Educ, Div Sci & Technol, Lahore 54000, Pakistan.
   [Aslam, Muhammad Saqlain] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 32001, Taiwan.
C3 Beijing University of Technology; National Central University
RP Ali, S (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM alisaqib@emails.bjut.edu.cn; sana.sahiba@outlook.com;
   mazeem.qau@hotmail.com; zee@emails.bjut.edu.cn; tmsherazi@ue.edu.pk;
   zareen.s@hotmail.com; saqlain@g.ncu.edu.tw
RI Ali, Saqib/C-7686-2011; Mahmood, Tariq/AAQ-6709-2020; Shaukat,
   Zeeshan/AAH-5490-2019
OI Ali, Saqib/0000-0001-5170-7346; Mahmood, Tariq/0000-0002-4299-7756;
   Shaukat, Zeeshan/0000-0002-7901-6712; Aslam, Muhammad
   Saqlain/0000-0001-8039-2603
CR Ahmed AA, 2020, ADV INTELL SYST COMP, V1058, P473, DOI 10.1007/978-3-030-31129-2_43
   Al Abodi J, 2014, COMPUT ELECTR ENG, V40, P1883, DOI 10.1016/j.compeleceng.2014.04.014
   Al-wajih E, 2020, IJST-T ELECTR ENG, V44, P1633, DOI 10.1007/s40998-020-00317-5
   Alaei A, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P391, DOI 10.1109/ICAPR.2009.14
   Albelwi S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060242
   Ali S, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12101742
   Ali S, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1161-5
   AlKhateeb JH, 2014, INT CONF COMP SCI, P222, DOI 10.1109/CSIT.2014.6806004
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [Anonymous], 2012, GUIDE OCR ARABIC SCR
   Ashiquzzaman Akm, 2019, Data Management, Analytics and Innovation. Proceedings of ICDMAI 2018. Advances in Intelligent Systems and Computing (AISC 808), P299, DOI 10.1007/978-981-13-1402-5_23
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   De S, 2018, ARXIV
   Dean Jeffrey, 2012, Large scale distributed deep networks. Proceedings of the 25th International Conference on Neural Information Processing Systems. The Organization. December 38, Stateline
   Dehghanian A, 2018, 2018 6TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI 2018), P65, DOI 10.1109/ISCBI.2018.00022
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   El qacimy B, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT 2015), P241, DOI 10.1109/EITech.2015.7162979
   El-Sawy A, 2017, ADV INTELL SYST COMP, V533, P566, DOI 10.1007/978-3-319-48308-5_54
   Farahbakhsh E, 2017, IRAN CONF MACH, P265, DOI 10.1109/IranianMVIP.2017.8342362
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Hamidi M, 2010, MACH VISION APPL, V21, P969, DOI 10.1007/s00138-009-0216-9
   Hosseini-Pozveh MS, 2021, IEEE T FUZZY SYST, V29, P1133, DOI 10.1109/TFUZZ.2020.2969120
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Husnain M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132758
   Karimi H, 2015, PROCEDIA COMPUT SCI, V73, P416, DOI 10.1016/j.procs.2015.12.018
   Kavitha B., 2019, J King Saud Univ Comput Inf
   Khosravi H, 2007, PATTERN RECOGN LETT, V28, P1133, DOI 10.1016/j.patrec.2006.12.022
   Kiani K, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P1113, DOI 10.1109/KBEI.2015.7436202
   Kingma D. P., 2014, arXiv
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mohamad M'A, 2015, INT J ADV COMPUT SC, V6, P204
   Montazer GA., 2017, OPT MEM NEURAL NETW, V26, P117, DOI [10.3103/S1060992X17020060, DOI 10.3103/S1060992X17020060]
   Nanehkaran YA, 2021, J SUPERCOMPUT, V77, P13474, DOI 10.1007/s11227-021-03822-4
   Parseh MJ, 2017, INT J IMAGE GRAPH, V17, DOI 10.1142/S0219467817500127
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Protopapadakis E, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030371
   Qu ZJ, 2019, IEEE ACCESS, V7, P23210, DOI 10.1109/ACCESS.2019.2899074
   Rashnodi O., 2011, USING BOX APPROACH P, V32, P1
   Sadri J, 2016, PATTERN RECOGN, V60, P378, DOI 10.1016/j.patcog.2016.03.024
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P9083, DOI 10.1007/s11042-019-07785-w
   Safarzadeh VM, 2020, 2020 25 INT COMP C C, P1, DOI DOI 10.1109/CSICC49403.2020.9050073
   Safdari R, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P67, DOI 10.1109/RIOS.2016.7529492
   Salimi H, 2013, INT J DOC ANAL RECOG, V16, P371, DOI 10.1007/s10032-012-0195-7
   Shi ZL, 2016, NEURAL NETWORKS, V83, P21, DOI 10.1016/j.neunet.2016.07.003
   Sun YN, 2020, IEEE T NEUR NET LEAR, V31, P1242, DOI 10.1109/TNNLS.2019.2919608
   Szmigiera M, 2021, US
   Takruri M., 2014, 2014 WORLD S COMPUTE, P1
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Xie ZC, 2016, INT C PATT RECOG, P4011
   Zamani Y, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P37, DOI 10.1109/IranianMVIP.2015.7397499
   Zhan HJ, 2018, INT C PATT RECOG, P3729, DOI 10.1109/ICPR.2018.8546100
   Zhao HZ, 2019, NEURAL NETWORKS, V110, P225, DOI 10.1016/j.neunet.2018.12.009
NR 53
TC 3
Z9 3
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14557
EP 14580
DI 10.1007/s11042-022-13831-x
EA SEP 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000861190700003
DA 2024-07-18
ER

PT J
AU Agarwal, S
   Bhat, A
AF Agarwal, Shalini
   Bhat, Aruna
TI A survey on recent developments in diabetic retinopathy detection
   through integration of deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Deep learning; GAN
ID FUNDUS IMAGES; AUTOMATED DETECTION; OPTIC DISC; EXUDATE DETECTION;
   SEGMENTATION; HEMORRHAGE; NETWORK; MICROANEURYSMS; CLASSIFICATION;
   IDENTIFICATION
AB Diabetes, nowadays, is a very common disease throughout the world among people of all ages. The higher level of blood sugar in the blood more often leads to Damage to blood vessels in the retina leads to blindness if left untreated or undetected on time. Diabetic Retinopathy (DR) screening programs like retinal fundus image analysis help ophthalmologists deal with some visual impairment problems. Computer-Aided Diagnosis aims to detect the severity of DR as early as possible so that it can be handled before the occurrence of any irreversible vision loss. With the help of many advancements in artificial intelligence techniques, a highly efficient and accurate system can be designed to help medical professionals automatically diagnose DR at an early stage without any special clinical resources. This paper conducts a thorough investigation into several recent frameworks proposed based on machine learning and deep learning networks to classify non-proliferative diabetic retinopathy, exudates, hemorrhages, and micro aneurysms. Several promising pre-trained deep learning model to classify DR stages exploited by researchers, and also investigated Transfer learning on pre-trained GoogLeNet and AlexNet, VGG etc. models. It is observed that almost all public and private data sets widely available for research are imbalanced. To alleviate these issues, generative adversarial networks (GANs) and their variants were also used to generate label-preserving data. In this study, the authors also list the recently proposed GAN-based frameworks and their impact on model performance. The paper concludes with the current challenges and future directions in the early and accurate classification of the severity level of DR.
C1 [Agarwal, Shalini; Bhat, Aruna] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 110042, India.
C3 Delhi Technological University
RP Bhat, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 110042, India.
EM shaliniagarwal_phdco2k19@dtu.ac.in; anma.bhat@dtu.ac.in
RI Bhat, Aruna/GSI-4485-2022
OI Bhat, Aruna/0000-0002-5475-8664
CR Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   AbdelMaksoud E, 2022, MED BIOL ENG COMPUT, V60, P2015, DOI 10.1007/s11517-022-02564-6
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Achanta SDM, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09893-1
   Adal KM, 2018, IEEE T BIO-MED ENG, V65, P1382, DOI 10.1109/TBME.2017.2752701
   Adem K, 2019, TURK J ELECTR ENG CO, V27, P499, DOI 10.3906/elk-1804-147
   Adem K, 2018, EXPERT SYST APPL, V114, P289, DOI 10.1016/j.eswa.2018.07.053
   Amin J, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/6838976
   [Anonymous], DRIDB DATASET
   [Anonymous], Messidor Dataset
   [Anonymous], 2019, INDIAN DIABETIC RETI
   [Anonymous], Drive Dataset
   [Anonymous], ARIA DATASET
   [Anonymous], DIARETDB0 DATASET
   [Anonymous], STARE DATASET
   [Anonymous], 2016, Report of standford education
   [Anonymous], E OPHTHA DATASET
   [Anonymous], Kaggle Dataset
   Appan KP, 2018, LECT NOTES COMPUT SC, V10882, P613, DOI 10.1007/978-3-319-93000-8_70
   Arunkumar R, 2017, NEURAL COMPUT APPL, V28, P329, DOI 10.1007/s00521-015-2059-9
   Bhattacharya S, 2019, SCIENCE OF HORMESIS IN HEALTH AND LONGEVITY, P35, DOI [10.1016/B978-0-12-814253-0.00003-6, 10.1007/978-981-13-2414-7_4]
   Burlina PM, 2019, JAMA OPHTHALMOL, V137, P258, DOI 10.1001/jamaophthalmol.2018.6156
   Cao W, 2018, IEEE T NANOBIOSCI, V17, P191, DOI 10.1109/TNB.2018.2840084
   Chen K, 2021, ARXIV
   Choong K, 2022, MULTIMED TOOLS APPL, P1
   Chowdhury AR, 2019, MED BIOL ENG COMPUT, V57, P193, DOI 10.1007/s11517-018-1878-0
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Costa P, 2017, LECT NOTES COMPUT SC, V10317, P516, DOI 10.1007/978-3-319-59876-5_57
   Dai L, 2018, IEEE T MED IMAGING, V37, P1149, DOI 10.1109/TMI.2018.2794988
   Deepa V, 2019, IET IMAGE PROCESS, V13, P1341, DOI 10.1049/iet-ipr.2018.5672
   Doshi D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P261, DOI 10.1109/CAST.2016.7914977
   *EARL TREATM DIAB, 1991, OPHTHALMOLOGY, V98, P786, DOI DOI 10.1016/S0161-6420(13)38012-9
   Fan Z, 2019, IEEE T IMAGE PROCESS, V28, P2367, DOI 10.1109/TIP.2018.2885495
   Feng ST, 2020, NEUROCOMPUTING, V392, P268, DOI 10.1016/j.neucom.2018.10.098
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graham B., 2015, Diabetic Retinopathy Detection
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hasan MK, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.102001
   Hatanaka Y, 2018, PROC INT WORKSH ADV
   He WJ, 2021, INFORM FUSION, V73, P157, DOI 10.1016/j.inffus.2021.02.017
   Hernandez-Matas C., 2017, Model. Artif. Intell. Ophthalmol., V1, P16, DOI DOI 10.35119/MAIO.V1I4.42
   Hsu W, 2001, PROC CVPR IEEE, P246
   Hussain S, 2022, COMPUT METH PROG BIO, V218, DOI 10.1016/j.cmpb.2022.106732
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Kaur J, 2017, BIOCYBERN BIOMED ENG, V37, P184, DOI 10.1016/j.bbe.2016.09.002
   Khojasteh P, 2019, COMPUT BIOL MED, V104, P62, DOI 10.1016/j.compbiomed.2018.10.031
   Kolb H., 1995, Webvision: The Organization of the Retina and Visual System
   Lam C., 2018, AMIA JT SUMMITS TRAN, V2017, P147
   Lecouat B., 2018, arXiv
   Leopold HA, 2019, J IMAGING, V5, DOI 10.3390/jimaging5020026
   Li F, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.6.4
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Liao YH, 2021, BIOCYBERN BIOMED ENG, V41, P589, DOI 10.1016/j.bbe.2021.04.005
   Lokuarachchi D, 2019, 2019 IEEE 15TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2019), P43, DOI [10.1109/CSPA.2019.8696052, 10.1109/cspa.2019.8696052]
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Naqvi SAG, 2015, COMPUT BIOL MED, V64, P217, DOI 10.1016/j.compbiomed.2015.07.003
   Nguyen QH, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P103, DOI 10.1145/3380688.3380709
   Nie Dong, 2017, Med Image Comput Comput Assist Interv, V10435, P417, DOI 10.1007/978-3-319-66179-7_48
   Niu YH, 2019, AAAI CONF ARTIF INTE, P1093
   Noh KJ, 2019, COMPUT METH PROG BIO, V178, P237, DOI 10.1016/j.cmpb.2019.06.030
   Pekala M, 2019, COMPUT BIOL MED, V114, DOI 10.1016/j.compbiomed.2019.103445
   Prasad Deepthi K., 2015, 2015 IEEE Recent Advances in Intelligent Computational Systems (RAICS), P240, DOI 10.1109/RAICS.2015.7488421
   Pundikal M, 2021, MICROANEURYSMS DETEC
   Purwanithami HA, 2020, 2020 INT SEM APPL TE
   Qiao LF, 2020, IEEE ACCESS, V8, P104292, DOI 10.1109/ACCESS.2020.2993937
   Qomariah DUN, 2021, 2021 4 INT C VOCATIO
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Qureshi I, 2019, ALGORITHMS, V12, DOI 10.3390/a12010014
   Rokade P. M., 2015, INT J APPL INNOVATIO, V4, P402
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Scotland GS, 2010, BRIT J OPHTHALMOL, V94, P712, DOI 10.1136/bjo.2008.151126
   Selçuk T, 2019, MED HYPOTHESES, V129, DOI 10.1016/j.mehy.2019.109242
   Shah A, 2018, I S BIOMED IMAGING, P1454, DOI 10.1109/ISBI.2018.8363846
   Shankar K, 2020, PATTERN RECOGN LETT, V133, P210, DOI 10.1016/j.patrec.2020.02.026
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Son J, 2019, J DIGIT IMAGING, V32, P499, DOI 10.1007/s10278-018-0126-3
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Soomro TA, 2019, EXPERT SYST APPL, V134, P36, DOI 10.1016/j.eswa.2019.05.029
   Stolte S, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101742
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan JH, 2017, INFORM SCIENCES, V420, P66, DOI 10.1016/j.ins.2017.08.050
   Taylor R., 2012, Handbook of retinal screening in diabetes: diagnosis and management
   Tchinda BS., 2021, Informatics in Medicine Unlocked, V23, P100521, DOI [DOI 10.1016/J.IMU.2021.100521, 10.1016/j.imu.2021.100521]
   Ting DSW, 2016, CLIN EXP OPHTHALMOL, V44, P260, DOI 10.1111/ceo.12696
   Uribe-Valencia LJ, 2019, BIOMED SIGNAL PROCES, V51, P148, DOI 10.1016/j.bspc.2019.02.006
   Wang L, 2019, BIOMED SIGNAL PROCES, V51, P82, DOI 10.1016/j.bspc.2019.01.022
   Wang S, 2017, IEEE T BIO-MED ENG, V64, P990, DOI [10.1109/TBME.2016.2585344, 10.1109/TBME.2016.2632522]
   Wang XH, 2019, PATTERN RECOGN, V88, P331, DOI 10.1016/j.patcog.2018.11.030
   Wang XL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P465, DOI 10.1109/IRI.2018.00074
   Wang ZH, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04632-7
   Washington RE, 2014, DIABETES RES CLIN PR, V103, P504, DOI 10.1016/j.diabres.2013.12.014
   Welander Per, 2018, arXiv
   Wisaeng K, 2019, IEEE ACCESS, V7, P11946, DOI 10.1109/ACCESS.2018.2890426
   Wu J, 2019, OPT LASER TECHNOL, V110, P69, DOI 10.1016/j.optlastec.2018.07.049
   Wu YC, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P398, DOI [10.1109/ICCCBDA.2019.8725801, 10.1109/icccbda.2019.8725801]
   Xia HY, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107140
   Xu KL, 2017, MOLECULES, V22, DOI 10.3390/molecules22122054
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Yu ZK, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0682-x
   Yun WL, 2008, INFORM SCIENCES, V178, P106, DOI 10.1016/j.ins.2007.07.020
   Zhao G, 2022, LECT NOTES ELECT ENG, V805, DOI [10.1007/978-981-16-6320-8_79, DOI 10.1007/978-981-16-6320-8_79]
   Zhe Wang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P267, DOI 10.1007/978-3-319-66179-7_31
   Zhou K, 2020, I S BIOMED IMAGING, P1227, DOI [10.1109/isbi45749.2020.9098374, 10.1109/ISBI45749.2020.9098374]
   Zhou W, 2017, IEEE ACCESS, V5, P2563, DOI 10.1109/ACCESS.2017.2671918
   Zhou YK, 2021, NEUROCOMPUTING, V437, P118, DOI 10.1016/j.neucom.2020.06.143
NR 108
TC 7
Z9 7
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17321
EP 17351
DI 10.1007/s11042-022-13837-5
EA SEP 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000859866500004
DA 2024-07-18
ER

PT J
AU Dhawan, S
   Gupta, R
   Bhuyan, HK
   Vinayakumar, R
   Pani, SK
   Rana, AK
AF Dhawan, Sachin
   Gupta, Rashmi
   Bhuyan, Hemanta Kumar
   Vinayakumar, Ravi
   Pani, Subhendu Kumar
   Rana, Arun Kumar
TI An efficient steganography technique based on S<SUP>2</SUP>OA & DESAE
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep enhanced stacked autoencoder; Salp swarm optimization;
   Steganography; Binary bit-plane decomposition; Integer discrete wavelet
ID IMAGE ENCRYPTION; PERFORMANCE; ALGORITHM; OPTIMIZER
AB This paper gives a novel and efficient steganography technique based on hybrid algorithms that improves the various important parameters like PSNR, MSE, IF, capacity, security. It increases the security of the confidential data by using the encryption method and give improved quality of stego images with less error rate. This paper utilizes a grouping of wavelet domain & Salp Swarm based Optimization Algorithm (SSOA) and proposed embedding process for increasing the payload capacity. Initially, the integer discrete wavelet transform is utilized to process the cover image and DWT to extract the hidden image accurately. Furthermore, an edge localization process is proposed to localize the edge region of detail bands efficiently, which can be done by SSO Algorithm. To enhance the quality of the stego pictures, a deep enhanced stacked auto encoder (DESAE) has been proposed. The evaluation result of this technique achieves good image quality and high security. Also, it increases the payload capacity of the existing methods, which confirms the superiority of the proposed method compared to previous related techniques.
C1 [Dhawan, Sachin; Rana, Arun Kumar] Panipat Inst Engn & Technol, Samalkha, India.
   [Gupta, Rashmi] NSUT East Campus, Delhi, India.
   [Bhuyan, Hemanta Kumar] Vignans Fdn Sci Technol & Res Deemed Univ, Dept Informat Technol, Kurnool, Andhra Pradesh, India.
   [Vinayakumar, Ravi] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar 34754, Saudi Arabia.
   [Pani, Subhendu Kumar] Biju Patnaik Univ Technol, Krupajal Comp Acad, Bhubaneswar, Odisha, India.
C3 Panipat Institute of Engineering & Technology; Vignan's Foundation for
   Science, Technology & Research (VFSTR); Prince Mohammad Bin Fahd
   University
RP Vinayakumar, R (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar 34754, Saudi Arabia.
EM ersachind@gmail.com; rashmi.gupta@nsut.ac.in; hmb.bhuyan@gmail.com;
   vravi@pmu.edu.sa; skpaniindia@gmail.com; ranaanin1@gmail.com
RI Gupta, Rashmi/HLH-0461-2023; Dhawan, Sachin/AAK-9570-2021; Pani,
   Subhendu kumar/AAX-9596-2021; Gupta, Rashmi/KMY-3135-2024; kumar,
   arun/AAC-5048-2021
OI Dhawan, Sachin/0000-0003-4376-5110; Pani, Subhendu
   kumar/0000-0001-9595-0567; Gupta, Rashmi/0000-0003-3983-4638; kumar,
   arun/0000-0002-1707-1847
FU Prince Mohammad Bin Fahd University, Kingdom of Saudi Arabia; PMU
   Cybersecurity Center Research Grant (PCC-Grant), Prince Mohammad Bin
   Fahd University, Kingdom of Saudi Arabia [202222]
FX This work was supported by PMU Cybersecurity Center Research Grant
   (PCC-Grant-202222), Prince Mohammad Bin Fahd University, Kingdom of
   Saudi Arabia.
CR Bailey K., 2006, MULTIMED TOOLS APPL, V31, P327, DOI [10.1007/s11042-006-0047-x, DOI 10.1007/S11042-006-0047-X]
   Bhat S., 2019, SECURE EFFICIENT DAT, V870
   Biswas C, 2019, 2019 INT C EL COMP C, P1
   Bukhari S, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P531, DOI 10.1109/INTECH.2016.7845050
   Chaudhury S, 2017, IEEE INT WORKS MACH
   Cogranne R, 2022, IEEE T INF FOREN SEC, V17, P1328, DOI 10.1109/TIFS.2021.3111713
   Dhar PK, 2018, INT J COMPUT SCI NET, V18, P155
   Dhawan S, 2021, IEEE ACCESS, V9, P87563, DOI 10.1109/ACCESS.2021.3089357
   Dhawan S, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6448
   Dhawan S, 2021, INF SECUR J, V30, P63, DOI 10.1080/19393555.2020.1801911
   Dhawan S, 2019, PROCEEDINGS OF THE 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P885
   Febryan A., 2017, INT J APPL ENG RES, V12, P10485
   Hameed MA, 2019, IEEE ACCESS, V7, P185189, DOI 10.1109/ACCESS.2019.2960254
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hosam O., 2019, Int. J. Inf. Technol. Comput. Sci., V11, P23
   Irfan P., 2015, INT J COMPUT APPL, V123, P11, DOI DOI 10.5120/ijca2015905344
   Juhi S, 2021, 2021 INT C COMPUTATI
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Kapoor R, 2018, MEASUREMENT, V126, P134, DOI 10.1016/j.measurement.2018.05.053
   Kini NG, 2019, STUD COMPUT INTELL, V771, P539, DOI 10.1007/978-981-10-8797-4_54
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P584, DOI 10.1016/j.procs.2019.11.043
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P491, DOI 10.1016/j.procs.2019.11.059
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P503, DOI 10.1016/j.procs.2019.11.057
   Kumar S., 2019, SMART SYSTEMS IOT IN, P711
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Nipanikar SI, 2018, ALEX ENG J, V57, P2343, DOI 10.1016/j.aej.2017.09.005
   Pradhan A, 2016, 2016 INTERNATIONAL CONFERENCE ON RESEARCH ADVANCES IN INTEGRATED NAVIGATION SYSTEMS (RAINS)
   Punyani P., 2019, NEURAL NETWORKS FACI
   Saleh ME, 2016, INT J ADV COMPUT SC, V7, P390
   Sharma VK, 2017, LECT NOTE NETW SYST, V12, P353, DOI 10.1007/978-981-10-3935-5_36
   Song HT, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3546367
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Veerashetty Sachinkumar, 2021, International Journal of Computers and Applications, V43, P924, DOI 10.1080/1206212X.2019.1653011
   Zhang JM, 2022, IEEE SIGNAL PROC LET, V29, P164, DOI 10.1109/LSP.2021.3129419
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
NR 39
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14527
EP 14555
DI 10.1007/s11042-022-13798-9
EA SEP 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000859866600001
DA 2024-07-18
ER

PT J
AU Dubey, S
   Dixit, M
AF Dubey, Shradha
   Dixit, Manish
TI Recent developments on computer aided systems for diagnosis of diabetic
   retinopathy: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Diabetic retinopathy; Microaneurysms; Hemorrhages; Exudate; Retinal
   blood vessel; Optic disc; cup
ID RETINAL FUNDUS IMAGES; CONVOLUTIONAL NEURAL-NETWORKS; OPTIC DISC
   SEGMENTATION; MICROANEURYSM DETECTION; EXUDATE DETECTION; HEMORRHAGE
   DETECTION; VESSEL SEGMENTATION; GENERALIZED-METHOD; CUP SEGMENTATION;
   BLOOD-VESSELS
AB Diabetes is a long-term condition in which the pancreas quits producing insulin or the body's insulin isn't utilised properly. One of the signs of diabetes is Diabetic Retinopathy. Diabetic retinopathy is the most prevalent type of diabetes, if remains unaddressed, diabetic retinopathy can affect all diabetics and become very serious, raising the chances of blindness. It is a chronic systemic condition that affects up to 80% of patients for more than ten years. Many researchers believe that if diabetes individuals are diagnosed early enough, they can be rescued from the condition in 90% of cases. Diabetes damages the capillaries, which are microscopic blood vessels in the retina. On images, blood vessel damage is usually noticeable. Therefore, in this study, several traditional, as well as deep learning-based approaches, are reviewed for the classification and detection of this particular diabetic-based eye disease known as diabetic retinopathy, and also the advantage of one approach over the other is also described. Along with the approaches, the dataset and the evaluation metrics useful for DR detection and classification are also discussed. The main finding of this study is to aware researchers about the different challenges occurs while detecting diabetic retinopathy using computer vision, deep learning techniques. Therefore, a purpose of this review paper is to sum up all the major aspects while detecting DR like lesion identification, classification and segmentation, security attacks on the deep learning models, proper categorization of datasets and evaluation metrics. As deep learning models are quite expensive and more prone to security attacks thus, in future it is advisable to develop a refined, reliable and robust model which overcomes all these aspects which are commonly found while designing deep learning models.
C1 [Dubey, Shradha; Dixit, Manish] Madhav Inst Sci & Technol, Dept Comp Sci & Engn, Gwalior, Madhya Pradesh, India.
C3 Madhav Institute of Technology & Science
RP Dubey, S (corresponding author), Madhav Inst Sci & Technol, Dept Comp Sci & Engn, Gwalior, Madhya Pradesh, India.
EM dubeyshradha29@gmail.com; dixitmits@mitsgwalior.in
RI Dubey, Shradha/HHM-3908-2022
CR Abed S, 2016, APPL SOFT COMPUT, V49, P146, DOI 10.1016/j.asoc.2016.08.015
   Adem K, 2018, EXPERT SYST APPL, V114, P289, DOI 10.1016/j.eswa.2018.07.053
   Afroz AS, 2014, 8 INT C SOFTWARE KNO, P1, DOI [10.1109/SKIMA.2014.7083546, DOI 10.1109/SKIMA.2014.7083546]
   Agurto C, 2014, IEEE J BIOMED HEALTH, V18, P1328, DOI 10.1109/JBHI.2013.2296399
   Ai Z, 2021, FRONT NEUROINFORM, V15, DOI 10.3389/fninf.2021.778552
   Al-Diri B, 2008, IEEE ENG MED BIO, P2262, DOI 10.1109/IEMBS.2008.4649647
   Alghamdi HS., 2017, Automatic optic disc abnormality detection in fundus images: a deep learning approach, P17, DOI [10.17077/omia.1042, DOI 10.17077/OMIA.1042]
   Alshayeji M, 2017, MED BIOL ENG COMPUT, V55, P935, DOI 10.1007/s11517-016-1563-0
   Alyoubi W. L., 2020, Informatics in Medicine Unlocked, V20, DOI [DOI 10.1016/J.IMU.2020.100377, 10.1016/j.imu.2020.100377]
   Amin J, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/6838976
   Angadi S, 2015, ADV INTELL SYST, V328, P589, DOI 10.1007/978-3-319-12012-6_65
   [Anonymous], Messidor Dataset
   [Anonymous], E-Ophtha
   [Anonymous], 2016, Int J Eng Res Technol
   Arnay R, 2017, APPL SOFT COMPUT, V52, P409, DOI 10.1016/j.asoc.2016.10.026
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Atli I, 2021, ENG SCI TECHNOL, V24, P271, DOI 10.1016/j.jestch.2020.07.008
   Bai J, 2021, ARXIV
   Bala MP, 2014, INT J BIOMED ENG TEC, V15, P128, DOI 10.1504/IJBET.2014.062743
   Banerjee S, 2016, BIOCYBERN BIOMED ENG, V36, P679, DOI 10.1016/j.bbe.2016.07.001
   Benzamin A, 2018, 2018 JOINT 7TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2018 2ND INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR), P465, DOI 10.1109/ICIEV.2018.8641016
   Bharali P, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P237, DOI 10.1109/ReTIS.2015.7232884
   Bharkad S, 2017, BIOMED SIGNAL PROCES, V31, P483, DOI 10.1016/j.bspc.2016.09.009
   Bian XS, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105717
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Bria A, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103735
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Cao W, 2018, IEEE T NANOBIOSCI, V17, P191, DOI 10.1109/TNB.2018.2840084
   Carmona EJ, 2008, ARTIF INTELL MED, V43, P243, DOI 10.1016/j.artmed.2008.04.005
   Chakrabarty N, 2019, INT CONF COMPUT, DOI 10.1109/icccnt45670.2019.8944633
   Chakraborty Sabyasachi, 2020, International Journal of Information Technology, V12, P473, DOI 10.1007/s41870-019-00318-6
   Chakravarty A, 2017, COMPUT METH PROG BIO, V147, P51, DOI 10.1016/j.cmpb.2017.06.004
   Chen BZ, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107209
   Cheng Y, 2020, IFAC PAPERSONLINE, V53, P16400, DOI 10.1016/j.ifacol.2020.12.684
   Chou YH, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85703-7
   Chowdhury AR, 2019, MED BIOL ENG COMPUT, V57, P193, DOI 10.1007/s11517-018-1878-0
   Chudzik P, 2018, COMPUT METH PROG BIO, V158, P185, DOI 10.1016/j.cmpb.2018.02.016
   Dai BS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161556
   Dandapat S., 2021, ADV INTELLIGENT SYST, V1255, P235, DOI [10.1007/978-981-15-7834-2_22, DOI 10.1007/978-981-15-7834-2_22]
   Dash S, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101740
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Derwin DJ, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2019.101839
   Devaraj D, 2018, MATER TODAY-PROC, V5, P10845, DOI 10.1016/j.matpr.2017.12.372
   Devi MSS, 2021, MATER TODAY-PROC, V47, P185, DOI 10.1016/j.matpr.2021.04.070
   Díaz-Pernil D, 2016, PATTERN RECOGN LETT, V83, P99, DOI 10.1016/j.patrec.2016.04.025
   Ding L, 2020, IEEE DATAPORT, DOI [10.21227/ctgj-1367, DOI 10.21227/CTGJ-1367]
   Doshi D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P261, DOI 10.1109/CAST.2016.7914977
   Du JY, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105687
   Dubey S, 2019, COMM COM INF SC, V835, P109, DOI 10.1007/978-981-13-5992-7_9
   Dutta S, 2018, INT J GRID DISTRIB, V11, P89, DOI 10.14257/ijgdc.2018.11.1.09
   Eftekhari N, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0675-9
   Esfahani MT, 2018, Leonardo Electron J Pract Technol, V17, P233
   Fraz MM, 2017, BIOMED SIGNAL PROCES, V35, P50, DOI 10.1016/j.bspc.2017.02.012
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Fu YH, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107971
   Fumero F, 2011, COMP MED SY
   Furnkranz J, 2010, MEAN SQUARED ERROR, DOI [10.1007/978-0-387-30164-8_528, DOI 10.1007/978-0-387-30164-8_528]
   Gaikwad SS, 2017, DETECTION HEMORRHAGE
   Gayathri S, 2020, PHYS ENG SCI MED, V43, P927, DOI 10.1007/s13246-020-00890-3
   Giancardo L, 2012, MED IMAGE ANAL, V16, P216, DOI 10.1016/j.media.2011.07.004
   Godlin Atlas L, 2018, DETECTION RETINAL HE, DOI [10.4066/BIOMEDICALRESEARCH.29-18-281, DOI 10.4066/BIOMEDICALRESEARCH.29-18-281]
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Guo C, 2020, P 2020 25 INT C PATT, DOI [DOI 10.1109/ICPR48806.2021.9413346, 10.1109/ICPR48806.2021.9413346]
   Guo LY, 2015, COMPUT IND, V69, P72, DOI 10.1016/j.compind.2014.09.005
   Guo SS, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5578335
   Guo YF, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-0412-7
   Hacisoftaoglu RE, 2020, PATTERN RECOGN LETT, V135, P409, DOI 10.1016/j.patrec.2020.04.009
   Hagos MT, 2019, ARXIV
   Haloi M, 2015, ARXIV
   Hao Wu, 2020, Journal of Physics: Conference Series, V1486, DOI 10.1088/1742-6596/1486/5/052026
   Harangi B, 2015, COMPUT BIOL MED, V65, P10, DOI 10.1016/j.compbiomed.2015.07.002
   Hatanaka Y, 2018, PROC INT WORKSH ADV
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Imani E, 2016, COMPUT METH PROG BIO, V133, P195, DOI 10.1016/j.cmpb.2016.05.016
   Inbarathi R., 2014, INT J INNOVAT RES SC, V3, P1979
   Jebaseeli TJ, 2019, OPTIK, V199, DOI 10.1016/j.ijleo.2019.163328
   Jiang ZX, 2018, COMPUT MED IMAG GRAP, V68, P1, DOI 10.1016/j.compmedimag.2018.04.005
   Joshi S, 2018, BIOMED PHARMACOL J, V11, P215, DOI [10.13005/bpj/1366, DOI 10.13005/BPJ/1366]
   Kadan AB, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1349-7
   Kaggle Dataset, US
   Karkuzhali S, 2019, BIOCYBERN BIOMED ENG, V39, P753, DOI 10.1016/j.bbe.2019.07.001
   Kauppi T., 2006, Machine Vision and Pattern Recognition Research Group, V73, P1
   Kaur J, 2018, BIOCYBERN BIOMED ENG, V38, P27, DOI 10.1016/j.bbe.2017.10.003
   Kaur J, 2017, BIOCYBERN BIOMED ENG, V37, P184, DOI 10.1016/j.bbe.2016.09.002
   Khalifa Nour Eldeen M, 2019, Acta Inform Med, V27, P327, DOI 10.5455/aim.2019.27.327-332
   Khan M.A., 2019, Procedia Comput Sci, V163, P609
   Khan TM, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227566
   Khan TM, 2020, PLOS ONE DATASET, DOI [10.1371/journal.pone.0227566.t002, DOI 10.1371/JOURNAL.PONE.0227566.T002]
   Khojasteh P, 2019, BIOMED SIGNAL PROCES, V49, P240, DOI 10.1016/j.bspc.2018.12.004
   Khojasteh P, 2019, COMPUT BIOL MED, V104, P62, DOI 10.1016/j.compbiomed.2018.10.031
   Khojasteh P, 2018, BMC OPHTHALMOL, V18, DOI 10.1186/s12886-018-0954-4
   Klviinen RVJPH., 2007, Medical Image Understanding and Analysis, V2007, P61
   Korhonen J, 2012, INT WORK QUAL MULTIM, P37, DOI 10.1109/QoMEX.2012.6263880
   Kumar S, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P359, DOI 10.1109/SPIN.2018.8474264
   Kurale NG, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Kwon H, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120738
   Lahmiri S, 2017, OPT LASER TECHNOL, V96, P243, DOI 10.1016/j.optlastec.2017.05.012
   Lal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113922
   Li M, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/2028946
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Lin J, 2022, EURASIP J INF SECUR, V2022, DOI 10.1186/s13635-021-00125-2
   Linfeng Y., 2021, ARXIV
   Liu H., 2020, ARXIV, V33, P13539
   Liu Q, 2019, NEUROCOMPUTING, V359, P285, DOI 10.1016/j.neucom.2019.05.039
   Liu YQ, 2020, J DIABETES RES, V2020, DOI 10.1155/2020/8765139
   Long SC, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-00766-3
   Long SC, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/3926930
   Ma YL, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8822407
   Mahesh SP, 2010, NEW ENGL J MED, V362, P1521, DOI 10.1056/NEJMicm0909506
   Maison, 2019, Journal of Physics: Conference Series, V1376, DOI 10.1088/1742-6596/1376/1/012023
   Maninis Kevis-Kokitsi, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P140, DOI 10.1007/978-3-319-46723-8_17
   Maqsood S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113865
   Mateen M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/5801870
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   Maunz A, 2021, J PERS MED, V11, DOI 10.3390/jpm11060524
   Melo T, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.103995
   Mishra Supriya, 2020, 2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE), P515, DOI 10.1109/ICSTCEE49637.2020.9277506
   Mo J, 2018, NEUROCOMPUTING, V290, P161, DOI 10.1016/j.neucom.2018.02.035
   Mokhtari M, 2019, INFORM FUSION, V51, P30, DOI 10.1016/j.inffus.2018.10.010
   Mondal SS, 2020, PROCEDIA COMPUT SCI, V167, P2060, DOI 10.1016/j.procs.2020.03.246
   Murugan R., 2019, BIOMED PHARMACOL J, V12, P1433, DOI DOI 10.13005/bpj/1772
   Nagpal D, 2022, J KING SAUD UNIV-COM, V34, P7138, DOI 10.1016/j.jksuci.2021.06.006
   Neto LC, 2017, EXPERT SYST APPL, V78, P182, DOI 10.1016/j.eswa.2017.02.015
   Nevill CR, 2022, EYE, V36, P433, DOI 10.1038/s41433-021-01471-8
   Nguyen QH, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P103, DOI 10.1145/3380688.3380709
   Niemeijer M, 2011, IEEE T MED IMAGING, V30, P1941, DOI 10.1109/TMI.2011.2159619
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   Niu D, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P208, DOI 10.1109/SIPROCESS.2017.8124534
   Nunes S, 2013, INVEST OPHTH VIS SCI, V54, P4595, DOI 10.1167/iovs.13-11895
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Orujov F, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106452
   Paing May Phu, 2016, P BIOM ENG INT C BME, P1, DOI DOI 10.1109/BMEICON.2016.7859642
   Pak A, 2020, COGENT ENG, V7, DOI 10.1080/23311916.2020.1805144
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Parvathy E, 2017, ADV SMART COMPUT BIO, P461
   Pires R, 2019, ARTIF INTELL MED, V96, P93, DOI 10.1016/j.artmed.2019.03.009
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Prasad Deepthi K., 2015, 2015 IEEE Recent Advances in Intelligent Computational Systems (RAICS), P240, DOI 10.1109/RAICS.2015.7488421
   Qi G, 2021, ARXIV
   Qiu SL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050909
   Rahim Sarni Suhaila, 2016, Brain Inform, V3, P249, DOI 10.1007/s40708-016-0045-3
   Rajinikanth V., 2021, 2021 7 INT C BIOS IM, P1, DOI [10.1109/ICBSII51839.2021.9445134, DOI 10.1109/ICBSII51839.2021.9445134]
   Ramasamy LK, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.456
   Rani N, 2019, P 2019 GLOB C ADV TE, P1, DOI DOI 10.1109/GCAT47503.2019.8978422
   Ratanapakorn T, 2019, CLIN OPHTHALMOL, V13, P641, DOI 10.2147/OPTH.S195617
   Rathore P, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207272
   Rehman ZU, 2019, EXPERT SYST APPL, V120, P461, DOI 10.1016/j.eswa.2018.12.008
   Ren K, 2020, ENGINEERING-PRC, V6, P346, DOI 10.1016/j.eng.2019.12.012
   Revathy R., 2020, Int. J. Eng. Res. Technol. (IJERT), V09, DOI DOI 10.17577/IJERTV9IS060170
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Rodrigues LC, 2017, BIOMED SIGNAL PROCES, V36, P39, DOI 10.1016/j.bspc.2017.03.014
   Roychowdhury S, 2016, IEEE J BIOMED HEALTH, V20, P1562, DOI 10.1109/JBHI.2015.2473159
   Sahu D., 2016, INT J ENG SCI RES TE, V5, P853, DOI 10.5281/zenodo.56030
   Samanta A, 2020, PATTERN RECOGN LETT, V135, P293, DOI 10.1016/j.patrec.2020.04.026
   Sanjani SS, 2013, BLOOD VESSEL SEGMENT
   Sarathi MP, 2016, BIOMED SIGNAL PROCES, V25, P108, DOI 10.1016/j.bspc.2015.10.012
   Sathananthavathi, 2019, TELEMEDICINE TECHNOL, P57, DOI DOI 10.1016/B978-0-12-816948-3.00005-2
   Saxena G., 2020, Intell.-Based Med., V3, DOI [10.1016/j.ibmed.2020.100022, DOI 10.1016/J.IBMED.2020.100022]
   Selçuk T, 2019, MED HYPOTHESES, V129, DOI 10.1016/j.mehy.2019.109242
   Shan J, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P357, DOI 10.1109/CHASE.2016.12
   Shen Z, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113663
   Shin SY, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101556
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Sreng S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144916
   Srivastava R, 2015, IEEE ENG MED BIO, P5663
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Taibouni K, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199313
   Tamim N, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060894
   Tan NM, 2015, COMPUT MED IMAG GRAP, V40, P182, DOI 10.1016/j.compmedimag.2014.10.002
   Tang L, 2013, IEEE T MED IMAGING, V32, P364, DOI 10.1109/TMI.2012.2227119
   Tang L, 2011, IEEE T PATTERN ANAL, V33, P2245, DOI 10.1109/TPAMI.2011.69
   Tang Wan, 2015, Shanghai Arch Psychiatry, V27, P62, DOI 10.11919/j.issn.1002-0829.215010
   Thada V., 2013, Int. J. Innov. Eng. Technol, V2, P202
   Theera-Umpon N., 2019, NEURAL COMPUT APPL, V43, P1, DOI [10.1007/s10916-019-1349-7, DOI 10.1007/S10916-019-1349-7]
   Tian J, 2016, J BIOPHOTONICS, V9, P478, DOI 10.1002/jbio.201500239
   Tymchenko B, 2020, ARXIV, DOI DOI 10.1109/INOCON50539.2020.9298201
   Vakili Meysam, 2020, Performance analysis and comparison of machine and deep learning algorithms for IoT data classification, P13
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Veiga D, 2018, COMP M BIO BIO E-IV, V6, P405, DOI 10.1080/21681163.2017.1296379
   Vives-Boix V, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106094
   Vora P, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207274
   Voynov DM, 2020, COMP STUDY WHITE BOX
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang H, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105398
   Wang J, 2020, BIOMED OPT EXPRESS, V11, P927, DOI 10.1364/BOE.379977
   Wang L, 2019, BIOMED SIGNAL PROCES, V51, P82, DOI 10.1016/j.bspc.2019.01.022
   Wang Y., 2021, arXiv
   Wang Z., 2017, arXiv
   WANKHEDE PR, 2020, BIOMED PHARMACOL J, V13, P47, DOI DOI 10.13005/bpj/1859
   Wu J, 2019, OPT LASER TECHNOL, V110, P69, DOI 10.1016/j.optlastec.2018.07.049
   Wu L, 2013, WORLD J DIABETES, V4, P290, DOI 10.4239/wjd.v4.i6.290
   Xiao D, 2017, IEEE ENG MED BIO, P660, DOI 10.1109/EMBC.2017.8036911
   Xu KL, 2017, MOLECULES, V22, DOI 10.3390/molecules22122054
   Yazhini K., 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P1187, DOI 10.1109/ICIRCA48905.2020.9183240
   Yonekawa Y, 2020, J VITREORETINAL DIS, V4, P125, DOI 10.1177/2474126419893829
   Yu S, 2017, IEEE ENG MED BIO, P1744, DOI 10.1109/EMBC.2017.8037180
   Yuan X, 2021, ARTIF INTELL MED, V113, DOI 10.1016/j.artmed.2021.102035
   Zago GT, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103537
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhang XW, 2014, MED IMAGE ANAL, V18, P1026, DOI 10.1016/j.media.2014.05.004
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
   Zhao H, 2019, IEEE T MED IMAGING, V38, P46, DOI 10.1109/TMI.2018.2854886
   Zhou W, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2483137
   Zhuang J., 2018, arXiv
   Zia F, 2022, CMC-COMPUT MATER CON, V70, P2261, DOI 10.32604/cmc.2022.017820
   Zong YS, 2020, IEEE ACCESS, V8, P167225, DOI 10.1109/ACCESS.2020.3023273
NR 211
TC 5
Z9 5
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14471
EP 14525
DI 10.1007/s11042-022-13841-9
EA SEP 2022
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000859771500001
PM 36185322
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Khaldi, A
   Kafi, MR
   Boukhamla, AZE
AF Khaldi, Amine
   Kafi, Med Redouane
   Boukhamla, Akram Zine Eddine
TI Deformable model segmentation for range image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Range image; Range segmentation; Active contour
ID ROBUST; SVD; CLASSIFICATION; SCHEME; 3D
AB In this work, a range image watermarking approach is proposed. First, the image is segmented using active contours; the watermark is then integrated into the resulting contour coordinates. Three active contour methods are used to segment the range image, the obtained segmentation results allow to define the algorithm offering a good compromise between the good segmentation rate and the contour size which constitutes the watermark integration area. The imperceptibility and robustness tests performed show that the proposed scheme offers a good imperceptibility rate as well as a good structural similarity between the original and watermarked image. The watermark is resistant to several attacks commonly used in image watermarking, however, is vulnerable to compression attacks, which is common in spatial integration techniques.
C1 [Khaldi, Amine; Boukhamla, Akram Zine Eddine] Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
   [Kafi, Med Redouane] Univ Kasdi Merbah, Fac Sci & Technol, Dept Elect, Elect Engn Lab, Ouargla 30000, Algeria.
C3 Universite Kasdi Merbah Ouargla; Universite Kasdi Merbah Ouargla
RP Khaldi, A (corresponding author), Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
EM Khaldi.Amine@univ-ouargla.dz; Kafi.Redouane@univ-ouargla.dz;
   boukhamla.akram@univ-ouargla.dz
RI Kafi, Mohamed Redouane/AAT-2301-2021; Khaldi, Amine/AAV-1266-2020;
   Boukhamla, Akram Zine Eddine/AAV-1680-2020
OI Kafi, Mohamed Redouane/0000-0002-5500-0943; Khaldi,
   Amine/0000-0002-1637-9129; Boukhamla, Akram Zine
   Eddine/0000-0001-9209-7791
FU " La Direction Generale de la Recherche Scientifique et du Developpement
   Technologique (DGRSDT)" of Algeria
FX This work was supported by " La Direction Generale de la Recherche
   Scientifique et du Developpement Technologique (DGRSDT)" of Algeria.
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Abdallah EE, 2008, LECT NOTES COMPUT SC, V5112, P253, DOI 10.1007/978-3-540-69812-8_25
   Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Ahmadi SBB, 2020, MULTIMED TOOLS APPL, V79, P1075, DOI 10.1007/s11042-019-08197-6
   Amine K, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622500979
   Amine K, 2014, CYBERN INF TECHNOL, V14, P66, DOI 10.1515/cait-2014-0006
   Aparna P, 2019, IET IMAGE PROCESS, V13, P421, DOI 10.1049/iet-ipr.2018.5288
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Braiki M, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105520
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Duan YX, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163667
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Galdames FJ, 2019, CHEMOMETR INTELL LAB, V189, P138, DOI 10.1016/j.chemolab.2019.04.006
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Hassan B, 2019, IEEE ACCESS, V7, P69758, DOI 10.1109/ACCESS.2019.2919381
   Holz D, 2014, ROBOT AUTON SYST, V62, P1282, DOI 10.1016/j.robot.2014.03.013
   Hsu LY, 2019, IEEE ACCESS, V7, P107438, DOI 10.1109/ACCESS.2019.2932077
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Kahlessenane F, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02793-3
   Kahlessenane F, 2021, MULTIMED TOOLS APPL, V80, P19827, DOI 10.1007/s11042-021-10713-6
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Khaldi A., 2014, INT J IMAGING ROBOT, V12, P39
   Khaldi A., 2012, INT J SIGNAL IMAGE P, V03, P17
   Khaldi A, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103540
   Lee BR, 2002, INT CONF ACOUST SPEE, P1585
   Lee YS, 2019, SIGNAL PROCESS-IMAGE, V70, P104, DOI 10.1016/j.image.2018.09.004
   Liu YN, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115946
   Mlynarski P, 2019, COMPUT MED IMAG GRAP, V73, P60, DOI 10.1016/j.compmedimag.2019.02.001
   Moad MS, 2022, MULTIMED TOOLS APPL, V81, P44087, DOI 10.1007/s11042-022-12004-0
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Moad MS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103114
   Mothi R, 2019, MEASUREMENT, V136, P67, DOI 10.1016/j.measurement.2018.12.030
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Nuñez-Ramirez D, 2020, IEEE LAT AM T, V18, P1398, DOI 10.1109/TLA.2020.9111675
   Prasetyo H, 2020, IEEE ACCESS, V8, P69919, DOI 10.1109/ACCESS.2020.2984180
   Salah E, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621502108
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Sayah MM, 2022, MULTIMED TOOLS APPL, V81, P43613, DOI 10.1007/s11042-021-11791-2
   The University of Stuttgart, 2001, STUTTG RANG IM DAT
   Yang YY, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115907
   Yang YY, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2020.113419
   Zermi N, 2022, CYBERNET SYST, V53, P282, DOI 10.1080/01969722.2021.1983700
   Zermi N, 2021, MICROPROCESS MICROSY, V84, DOI 10.1016/j.micpro.2021.104134
   Zermi N, 2021, MULTIMED TOOLS APPL, V80, P24823, DOI 10.1007/s11042-021-10712-7
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
   Zhou SL, 2020, AUTOMAT CONSTR, V114, DOI 10.1016/j.autcon.2020.103171
NR 52
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12211
EP 12227
DI 10.1007/s11042-022-13724-z
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000855612200006
DA 2024-07-18
ER

PT J
AU Patnaik, S
AF Patnaik, Suprava
TI Speech emotion recognition by using complex MFCC and deep sequential
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion; MFCC; Emotion circumplex; 1-D CNN
ID NEURAL-NETWORKS; CLASSIFICATION; FEATURES
AB Speech Emotion Recognition (SER) is one of the front-line research areas. For a machine, inferring SER is difficult because emotions are subjective and annotation is challenging. Nevertheless, researchers feel that SER is possible because speech is quasi-stationery and emotions are declarative finite states. This paper is about emotion classification by using Complex Mel Frequency Cepstral Coefficients (c-MFCC) as the representative trait and a deep sequential model as a classifier. The experimental setup is speaker independent and accommodates marginal variations in the underlying phonemes. Testing for this work has been carried out on RAVDESS and TESS databases. Conceptually, the proposed model is erogenous towards prosody observance. The main contributions of this work are of two-folds. Firstly, introducing conception of c-MFCC and investigating it as a robust cue of emotion and there by leading to significant improvement in accuracy performance. Secondly, establishing correlation between MFCC based accuracy and Russell's emotional circumplex pattern. As per the Russell's 2D emotion circumplex model, emotional signals are combinations of several psychological dimensions though perceived as discrete categories. Results of this work are outcome from a deep sequential LSTM model. Proposed c-MFCC are found to be more robust to handle signal framing, informative in terms of spectral roll off, and therefore put forward as an input to the classifier. For RAVDESS database the best accuracy achieved is 78.8% for fourteen classes, which subsequently improved to 91.6% for gender integrated eight classes and 98.5% for affective separated six classes. Though, the RAVDESS dataset has two analogous sentences revealed results are for the complete dataset and without applying any phonetic separation of the samples. Thus, proposed method appears to be semi-commutative on phonemes. Results obtained from this study are presented and discussed in forms of confusion matrices.
C1 [Patnaik, Suprava] Kalinga Inst Ind Technol, Sch Elect, Bhubaneswar, Odisha, India.
C3 Kalinga Institute of Industrial Technology (KIIT)
RP Patnaik, S (corresponding author), Kalinga Inst Ind Technol, Sch Elect, Bhubaneswar, Odisha, India.
EM suprava.pathaikfet@kiit.ac.in
OI Patnaik, Suprava/0000-0002-7068-5960
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Alsteris LD, 2007, DIGIT SIGNAL PROCESS, V17, P578, DOI 10.1016/j.dsp.2006.06.007
   Alsteris LD, 2006, SPEECH COMMUN, V48, P727, DOI 10.1016/j.specom.2005.10.005
   Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   [Anonymous], 2011, INVESTIGATION RELATI
   [Anonymous], 2014, Math Probl Eng, DOI DOI 10.1155/2014/749604
   [Anonymous], 2014, 15 ANN C INT SPEECH
   Attabi Y, 2013, IEEE T AFFECT COMPUT, V4, P280, DOI 10.1109/T-AFFC.2013.17
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   de Pinto MG, 2020, IEEE CONF EVOL ADAPT, DOI 10.1109/eais48028.2020.9122698
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Er MB, 2020, IEEE ACCESS, V8, P221640, DOI 10.1109/ACCESS.2020.3043201
   Gaich A, 2015, INT CONF ACOUST SPEE, P216, DOI 10.1109/ICASSP.2015.7177963
   Gao YB, 2017, LECT NOTES ARTIF INT, V10654, P3, DOI 10.1007/978-3-319-70772-3_1
   Ghaleb E, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925444, 10.1109/ACII.2019.8925444]
   Golik P, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P26
   Han K, 2014, INTERSPEECH, P223
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Kate Dupuis MKP-F, 2010, TORONTO EMOTIONAL SP
   Kleinschmidt T, 2011, COMPUT SPEECH LANG, V25, P585, DOI 10.1016/j.csl.2010.09.001
   Liu Y, 2018, IEEE IMAGE PROC, P3254, DOI 10.1109/ICIP.2018.8451843
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Maly A, 2016, INT CONF ACOUST SPEE, P584, DOI 10.1109/ICASSP.2016.7471742
   McCowan I, 2011, IEEE T AUDIO SPEECH, V19, P2026, DOI 10.1109/TASL.2011.2109379
   Morgan Nelson, SPEECH AUDIO SIGNAL
   Mower E, 2011, IEEE T AUDIO SPEECH, V19, P1057, DOI 10.1109/TASL.2010.2076804
   Muthusamy H, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/394083
   Rabiner L. R., 1975, Theory and application of digital signal processing
   Rabiner Lawrence, 2010, Digital Processing of Speech Signals
   Rajak R, 2019, TENCON IEEE REGION, P301, DOI 10.1109/TENCON.2019.8929459
   Rebai I, 2017, PROCEDIA COMPUT SCI, V112, P316, DOI 10.1016/j.procs.2017.08.003
   Shahin I, 2019, IEEE ACCESS, V7, P26777, DOI 10.1109/ACCESS.2019.2901352
   Stolar M.N., 2018, BIOMED J SCI TECHNOL, V5, P1
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Tzirakis P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5089, DOI 10.1109/ICASSP.2018.8462677
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Xu C, 2012, COMM COM INF SC, V332, P541
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
NR 39
TC 11
Z9 11
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11897
EP 11922
DI 10.1007/s11042-022-13725-y
EA SEP 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000852929600006
DA 2024-07-18
ER

PT J
AU Shah, SAA
   Deng, WF
   Cheema, MA
   Bais, A
AF Shah, Syed Afaq Ali
   Deng, Weifeng
   Cheema, Muhammad Aamir
   Bais, Abdul
TI CommuNety: deep learning-based face recognition system for the
   prediction of cohesive communities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Social communities; Predictive modelling
ID NETWORK; USERS
AB Effective mining of social media, which consists of a large number of users is a challenging task. Traditional approaches rely on the analysis of text data related to users to accomplish this task. However, text data lacks significant information about the social users and their associated groups. In this paper, we propose CommuNety, a deep learning system for the prediction of cohesive networks using face images from photo albums. The proposed deep learning model consists of hierarchical CNN architecture to learn descriptive features related to each cohesive network. The paper also proposes a novel Face Co-occurrence Frequency algorithm to quantify existence of people in images, and a novel photo ranking method to analyze the strength of relationship between different individuals in a predicted social network. We extensively evaluate the proposed technique on PIPA dataset and compare with state-of-the-art methods. Our experimental results demonstrate the superior performance of the proposed technique for the prediction of relationship between different individuals and the cohesiveness of communities.
C1 [Shah, Syed Afaq Ali] Edith Cowan Univ, Ctr AI & Machine Learning, Sch Sci, Joondalup, Australia.
   [Deng, Weifeng] Univ Western Australia, Perth, WA, Australia.
   [Cheema, Muhammad Aamir] Monash Univ, Melbourne, Vic, Australia.
   [Bais, Abdul] Univ Regina, Regina, SK, Canada.
C3 Edith Cowan University; University of Western Australia; Monash
   University; University of Regina
RP Shah, SAA (corresponding author), Edith Cowan Univ, Ctr AI & Machine Learning, Sch Sci, Joondalup, Australia.
EM afaq.shah@ecu.edu.au
RI Cheema, Muhammad Ali Masood/AAC-9548-2020; Bais, Abdul/C-7422-2014
OI Shah, Syed Afaq Ali/0000-0003-2181-8445; Bais, Abdul/0000-0003-2190-348X
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], 2012, P 20 ACM INT C MULT, DOI DOI 10.1145/2393347.2393439
   Bah SM, 2020, ARRAY-NY, V5, DOI 10.1016/j.array.2019.100014
   BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560
   Dong Y, 2016, NEUROCOMPUTING, V187, P4, DOI 10.1016/j.neucom.2015.09.115
   Geron A., 2017, Hands-On Machine Learning With Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
   Guidi B, 2020, MULTIMED TOOLS APPL, V79, P33603, DOI 10.1007/s11042-019-08494-0
   Hashmi A, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P310, DOI 10.1109/ASONAM.2012.59
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Hu WP, 2020, IEEE T MULTIMEDIA, V22, P1234, DOI 10.1109/TMM.2019.2938685
   Khan MZ, 2019, IEEE ACCESS, V7, P72622, DOI 10.1109/ACCESS.2019.2918275
   Khan S., 2018, Synth. Lect. Comput. Vis., V8, P1, DOI [DOI 10.2200/S00822ED1V01Y201712COV015, 10.1007/978-3-031-01822-0]
   Kim HN, 2012, EXPERT SYST APPL, V39, P6955, DOI 10.1016/j.eswa.2012.01.022
   Kim I., 2020, P ASIAN C COMPUTER V
   Li Junnan, 2020, INT J COMPUT VISION, P1
   Li S, 2020, PROC SPIE, V11430, DOI 10.1117/12.2538184
   Liu T, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.809736
   Mohapatra D, 2019, MULTIMED TOOLS APPL, V78, P25455, DOI 10.1007/s11042-019-07745-4
   Nadeem U, 2021, INFORM SCIENCES, V580, P578, DOI 10.1016/j.ins.2021.08.093
   Oh Se Eun, 2017, arXiv
   Oro E, 2018, IEEE T MULTIMEDIA, V20, P1195, DOI 10.1109/TMM.2017.2763324
   Ortiz EG, 2014, COMPUT VIS IMAGE UND, V118, P153, DOI 10.1016/j.cviu.2013.09.004
   Pfeil U, 2009, COMPUT HUM BEHAV, V25, P643, DOI 10.1016/j.chb.2008.08.015
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Shah SAA, 2017, IEEE COMPUT SOC CONF, P601, DOI 10.1109/CVPRW.2017.88
   Shah SAA, 2016, NEUROCOMPUTING, V174, P866, DOI 10.1016/j.neucom.2015.10.004
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tseng WY, 2019, MULTIMED TOOLS APPL, V78, P18137, DOI 10.1007/s11042-018-6944-y
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xu L, 2019, IEEE T MULTIMEDIA, V21, P591, DOI 10.1109/TMM.2018.2887019
   Xu X, 2016, MULTIMED TOOLS APPL, V75, P2203, DOI 10.1007/s11042-014-2402-7
   Zhang FF, 2019, MULTIMED TOOLS APPL, V78, P14777, DOI 10.1007/s11042-018-6829-0
   Zhang N, 2015, PROC CVPR IEEE, P4804, DOI 10.1109/CVPR.2015.7299113
   Zhang ZX, 2019, IEEE T MULTIMEDIA, V21, P1289, DOI 10.1109/TMM.2018.2871949
   Zhao Z, 2018, IEEE T MULTIMEDIA, V20, P430, DOI 10.1109/TMM.2017.2740022
NR 37
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10641
EP 10659
DI 10.1007/s11042-022-13741-y
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852346600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Su, TF
AF Su, Tengfei
TI Active learning with prediction vector diversity for crop classification
   in western Inner Mongolia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active learning; Crop classification; Diversity metric; Random forest
   classifier
ID RANDOM FOREST; REGIONAL-SCALE; IMAGE-ANALYSIS; ENVIRONMENTS; AREAS; SAR
AB Sample collection is a fundamental issue in remote sensing image classification, active learning (AL) aims to solve the issue by guiding the sampling process to select the most informative samples. However, informativeness may not be enough due to it is inefficient to avoid redundant and low-representative pixels. To further improve AL performance, this work introduces a new diversity model based on the details of the classifier prediction. The probability values estimated by the classifier are used to reflect the differences between the unlabeled samples and those in the labeled training set. Through combining the proposed diversity and an existent informative metric, a new AL algorithm is developed. Such an approach is tested in a region of western Inner Mongolia. Two datasets are adopted. The experimental results validate the superiority of the proposed technique, and its average overall accuracy can reach 98.18% and 97.57% for the first and second dataset, respectively, when the number of the selected samples is between 300 and 345.
C1 [Su, Tengfei] Inner Mongolia Agr Univ, Coll Water Conservancy & Civil Engn, 306 Zhaowuda Rd, Hohhot, Peoples R China.
   [Su, Tengfei] Inner Mongolia Autonomous Reg Key Lab Big Data Re, 306 Zhaowuda Rd, Hohhot, Peoples R China.
C3 Inner Mongolia Agricultural University
RP Su, TF (corresponding author), Inner Mongolia Agr Univ, Coll Water Conservancy & Civil Engn, 306 Zhaowuda Rd, Hohhot, Peoples R China.; Su, TF (corresponding author), Inner Mongolia Autonomous Reg Key Lab Big Data Re, 306 Zhaowuda Rd, Hohhot, Peoples R China.
EM stf1987@126.com
RI 腾飞, 苏/AFQ-2053-2022
OI 腾飞, 苏/0000-0001-8284-3092
FU scientific reseach program for universities in Inner Mongolia Autonomous
   Region [NJZY22495]; national natural science foundation of China
   [61701265]; Inner Mongolia Agricultural University experimental and
   educational instrument research and development foundation [YZ2019011]
FX This work is jointly supported by the scientific reseach program for
   universities in Inner Mongolia Autonomous Region under grant number of
   NJZY22495, the national natural science foundation of China, under grant
   of 61701265, and the Inner Mongolia Agricultural University experimental
   and educational instrument research and development foundation, under
   grant of YZ2019011. The anonymous reviewers are thanked for their
   constructive and insightful comments that help improve the quality of
   this article.
CR Akar Ö, 2015, INT J REMOTE SENS, V36, P442, DOI 10.1080/01431161.2014.995276
   Alajlan N, 2014, IEEE GEOSCI REMOTE S, V11, P259, DOI 10.1109/LGRS.2013.2255258
   Belgiu M, 2018, REMOTE SENS ENVIRON, V204, P509, DOI 10.1016/j.rse.2017.10.005
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bellón B, 2018, INT J APPL EARTH OBS, V68, P127, DOI 10.1016/j.jag.2018.01.019
   Ben Amor IB, 2018, IEEE J-STARS, V11, P79, DOI 10.1109/JSTARS.2017.2751148
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Luciano ACD, 2019, INT J APPL EARTH OBS, V80, P127, DOI 10.1016/j.jag.2019.04.013
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   Geiss C, 2018, IEEE GEOSCI REMOTE S, V15, P922, DOI 10.1109/LGRS.2018.2813436
   Geiss C, 2017, IEEE J-STARS, V10, P5583, DOI 10.1109/JSTARS.2017.2748339
   Kim HO, 2014, INT J REMOTE SENS, V35, P7046, DOI 10.1080/01431161.2014.965285
   Li J, 2011, IEEE T GEOSCI REMOTE, V49, P3947, DOI 10.1109/TGRS.2011.2128330
   Li X, 2017, ADV MATH PHYS, V2017, DOI [10.1155/2017/1743789, 10.1007/s11042-016-4311-4]
   Ma AL, 2021, ISPRS J PHOTOGRAMM, V181, P279, DOI 10.1016/j.isprsjprs.2021.08.024
   Ma L, 2018, INT J REMOTE SENS, V39, P2746, DOI 10.1080/01431161.2018.1430398
   Niazmardi S, 2019, INT J REMOTE SENS, V40, P6383, DOI 10.1080/01431161.2019.1591648
   Pasolli E, 2014, IEEE T GEOSCI REMOTE, V52, P2217, DOI 10.1109/TGRS.2013.2258676
   Patra S, 2012, IEEE GEOSCI REMOTE S, V9, P497, DOI 10.1109/LGRS.2011.2172770
   Samat A, 2015, INT J APPL EARTH OBS, V35, P305, DOI 10.1016/j.jag.2014.09.019
   Setiyono TD, 2019, INT J REMOTE SENS, V40, P8093, DOI 10.1080/01431161.2018.1547457
   Stumpf A, 2014, IEEE T GEOSCI REMOTE, V52, P2492, DOI 10.1109/TGRS.2013.2262052
   Su TF, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030504
   Su TF, 2017, GISCI REMOTE SENS, V54, P354, DOI 10.1080/15481603.2016.1273438
   Sun SJ, 2015, IEEE T GEOSCI REMOTE, V53, P1746, DOI 10.1109/TGRS.2014.2347343
   Wan SA, 2019, INT J REMOTE SENS, V40, P8076, DOI 10.1080/01431161.2018.1539275
   Wang XY, 2016, INT J APPL EARTH OBS, V52, P192, DOI 10.1016/j.jag.2016.06.014
   Wang XX, 2017, IEEE T GEOSCI REMOTE, V55, P5539, DOI 10.1109/TGRS.2017.2709803
   Wang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P3071, DOI 10.1109/TGRS.2017.2650938
   Xu J, 2014, INT J REMOTE SENS, V35, P1846, DOI 10.1080/01431161.2013.879349
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Xu ZH, 2018, INT J REMOTE SENS, V39, P5568, DOI 10.1080/01431161.2018.1466083
   Xue ZH, 2018, IEEE GEOSCI REMOTE S, V15, P469, DOI 10.1109/LGRS.2018.2794980
   Zhang Z, 2016, IEEE J-STARS, V9, P640, DOI 10.1109/JSTARS.2015.2493887
NR 34
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15079
EP 15112
DI 10.1007/s11042-022-13768-1
EA SEP 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000852138100001
DA 2024-07-18
ER

PT J
AU Banerjee, A
   Banik, D
AF Banerjee, Anasua
   Banik, Debajyoty
TI Pooled hybrid-spectral for hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral imaging (HSI); Dimension reduction; Spectral and spatial;
   Hyperspectral image classification
AB Hyperspectral image is composed of many spectral bands. Due to this reason many problems crop up in the picture. The Presence of high dimension, information loss, clinging redundant information in spectral bands etc hinder at the time of hyperspectral image classification. Here we proposed Resnet Spectral Spatial ConvLstm model which is composed of 3D Convolution Neural Network together with batch normalization layers in order to extract the spectral spatial features from hyperspectral image simultaneously we added shortcut connections to get rid of vanishing gradient problem which is followed by 2D Convolution Neural Network layers to reduce the computational complexity over and above that Long Short Term Memory layer removes redundant information from an input image. Our model produced better accuracy than others' proposed models like reaching the levels of 1.62%, 0.71%, 0.16%, and 0.01% more in "kennedy space center", "Botswana", "Indian Pines" and "Pavia University" data sets respectively. The errors also decreased from time series data sets by 0.49 in "Electricity production", 0.16 in "International Airline Passenger" and 0.52 in "Production of shampoo over three years" by using our proposed model. We have uploaded the source code here .
C1 [Banerjee, Anasua; Banik, Debajyoty] Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
C3 Kalinga Institute of Industrial Technology (KIIT)
RP Banik, D (corresponding author), Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
EM anasua123.banerjee@gmail.com; debajyoty.banik@gmail.com
OI Banik, Dr. Debajyoty/0000-0002-3756-864X
CR Audebert N, 2019, IEEE GEOSC REM SEN M, V7, P159, DOI 10.1109/MGRS.2019.2912563
   Ben Hamida A, 2018, IEEE T GEOSCI REMOTE, V56, P4420, DOI 10.1109/TGRS.2018.2818945
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Chandra Padney P., 2020, Hyperspect. Rem. Sens., P429
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Fang LY, 2017, IEEE T INSTRUM MEAS, V66, P1646, DOI 10.1109/TIM.2017.2664480
   Gao QS, 2018, IEEE GEOSCI REMOTE S, V15, P78, DOI 10.1109/LGRS.2017.2774253
   Guo YH, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1346-z
   Hasanlou M, 2012, IEEE GEOSCI REMOTE S, V9, P1046, DOI 10.1109/LGRS.2012.2189547
   Hu P, 2019, IEEE GEOSCI REMOTE S, V16, P452, DOI 10.1109/LGRS.2018.2872540
   Hu W., 2019, arXiv
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Liu QS, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121330
   Liu RN, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3100407
   Liu RM, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/9962057
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Roy SK, 2020, IEEE T GEOSCI REMOTE, V58, P5277, DOI 10.1109/TGRS.2019.2961681
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Steyn T.F. J., 2011, J MANAGEMENT POLICY, V12, P105
   Veit A, 2016, ADV NEUR IN, V29
   Waske B, 2010, IEEE T GEOSCI REMOTE, V48, P2880, DOI 10.1109/TGRS.2010.2041784
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
NR 24
TC 9
Z9 9
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10887
EP 10899
DI 10.1007/s11042-022-13721-2
EA SEP 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000850418800003
DA 2024-07-18
ER

PT J
AU Moussa, O
   Khlifa, N
   Morain-Nicolier, F
AF Moussa, Olfa
   Khlifa, Nawres
   Morain-Nicolier, Frederic
TI An effective shearlet-based anisotropic diffusion technique for
   despeckling ultrasound medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speckle noise; Fast finite shearlet transform (FFST); Diffusion tensor;
   Structure tensor; Multi-scale geometric analysis; Ultrasound images
ID SPECKLE NOISE-REDUCTION; BILATERAL FILTER; WAVELET; SHRINKAGE
AB The speckle is usually described as a multiplicative noise that significantly corrupts the quality and contrast in diagnostic ultrasound imaging. Therefore, the development of an effective noise reduction technique has become a crucial issue. Furthermore, the de-noising process should maintain the relevant medical information profitable for clinical diagnostic purposes. The goal of this paper is to propose an innovative technique for speckle noise removal. The core contribution of this work is the design of a new tensor-based anisotropic diffusion technique in the Shearlet domain. The idea consists of applying a directional smoothing process that depends on the local properties of the image that retains the essential structure details and improves the automatic stopping of the diffusion in the edge direction. Experimental results on both simulated and real ultrasound images indicate considerable enhancement in terms of PSNR, SSIM and ENL values carried out from the comparison of the proposed filter with existing standard denoising filters for speckle noise. These analysis results show that the proposed filter holds the higher value of PSNR (25.37 dB) and ENL (83.12) for simulated Phantom image. The experimental results on a group of representative filtered clinical data sets also demonstrate that STAD provides better smoothing performance with higher values of ENL (74.62) as compared to the state-of-the-art speckle filters. Hence in overall, these results reveal that the proposed model gives the best combination of speckle smoothing and edge retaining.
C1 [Moussa, Olfa; Khlifa, Nawres] Univ Tunis El Manar, Lab Rech Biophys & Technol Med, Tunis 1006, Tunisia.
   [Morain-Nicolier, Frederic] Univ Reims, IUT Troyes, CReST EA 3804, Reims, France.
C3 Universite de Tunis-El-Manar; Universite de Reims Champagne-Ardenne
RP Moussa, O (corresponding author), Univ Tunis El Manar, Lab Rech Biophys & Technol Med, Tunis 1006, Tunisia.
EM olfa.moussa@gmail.com; nawres.khlifa@istmt.utm.tn;
   frederic.nicolier@univ-reims.fr
RI Khlifa, Nawres/HGF-3119-2022
OI MOUSSA, Olfa/0000-0002-0521-9381
CR Abazari R, 2018, CURR MED IMAGING REV, V14, P477, DOI 10.2174/1573405613666170405150828
   Aja-Fernández S, 2006, IEEE T IMAGE PROCESS, V15, P2694, DOI 10.1109/TIP.2006.877360
   Aja-Fernández S, 2009, IMAGE VISION COMPUT, V27, P756, DOI 10.1016/j.imavis.2008.08.002
   [Anonymous], MECS IJ INTELLIGENT
   Bhateja V, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1027, DOI 10.1109/ICACCI.2014.6968596
   Bioucas-Dias JM, 2010, IEEE T IMAGE PROCESS, V19, P1720, DOI 10.1109/TIP.2010.2045029
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Cardoso FM, 2012, ULTRASOUND MED BIOL, V38, DOI 10.1016/j.ultrasmedbio.2012.03.014
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Choudhury P., 2003, PROC EG S RENDERING, P1
   Coupé P, 2008, I S BIOMED IMAGING, P1291, DOI 10.1109/ISBI.2008.4541240
   Cui WC, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101625
   Damodaran N, 2012, ULTRASOUND MED BIOL, V38, P276, DOI 10.1016/j.ultrasmedbio.2011.10.021
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Easley GR, 2015, PROC SPIE, V9597, DOI 10.1117/12.2188816
   Easley GR, 2009, IEEE T IMAGE PROCESS, V18, P260, DOI 10.1109/TIP.2008.2008070
   Easley GR, 2009, WAVELETS 13, V7446
   El-Baz A, 2013, INT J BIOMED IMAGING, V2013, DOI [10.1155/2013/942353, 10.1155/2013/517632]
   Farneback G., 2002, POLYNOMIAL EXPANSION
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gai S, 2018, DIGIT SIGNAL PROCESS, V72, P192, DOI 10.1016/j.dsp.2017.10.006
   Flores WG, 2014, ULTRASOUND MED BIOL, V40, P2609, DOI 10.1016/j.ultrasmedbio.2014.06.005
   Goodman J. W., 2007, Speckle Phenomena in Optics: Theory and Applications
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   Hamrouni Kamel., 2006, INT ARAB J INF TECHN, V3, P118
   Hauser S, 2012, ARXIV
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jain SK, 2020, IETE TECH REV, V37, P66, DOI 10.1080/02564602.2019.1565960
   Jensen J., 1997, COMPUTER PHANTOMS SI
   Jensen J.A., 2001, Technical University of Denmark, V2800, P28
   Jomaa H, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P108, DOI 10.1109/ATSIP.2016.7523063
   Khare A, 2010, SIGNAL PROCESS, V90, P428, DOI 10.1016/j.sigpro.2009.07.008
   Khlifa N, 2009, INT J BIOMED IMAGING, V2009, DOI 10.1155/2009/506120
   Krissian K, 2007, IEEE T IMAGE PROCESS, V16, P1412, DOI 10.1109/TIP.2007.891803
   Kroon DJ, 2010, LECT NOTES COMPUT SC, V6363, P221
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Liu SQ, 2014, MULTIDIM SYST SIGN P, V25, P683, DOI 10.1007/s11045-013-0225-8
   Liu XM, 2011, BMC GENOMICS, V12, DOI 10.1186/1471-2164-12-S5-S14
   LOPES A, 1993, INT J REMOTE SENS, V14, P1735, DOI 10.1080/01431169308953999
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Moussa O, 2018, 2018 4 INT C ADV TEC, P1, DOI DOI 10.1109/ATSIP.2018.8364523
   Moussa O, 2018, COMPUT AIDED GEOM D, V67, P34, DOI 10.1016/j.cagd.2018.09.005
   Ndajah Peter, 2010, Advances in Visualization, Imaging and Simulation. 3rd WSEAS International Conference on Visualization, Imaging and Simulation (VIS 2010), P53
   Olfa M, 2014, INT IM PROC APPL SYS, P1, DOI [10.1109/IPAS.2014.7043258, DOI 10.1109/IPAS.2014.7043258]
   Olfa M, 2016, 2016 INTERNATIONAL CONFERENCE ON CONTROL, DECISION AND INFORMATION TECHNOLOGIES (CODIT), P712, DOI 10.1109/CoDIT.2016.7593650
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Patel VM, 2009, IEEE T IMAGE PROCESS, V18, P2673, DOI 10.1109/TIP.2009.2029594
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rafati M, 2015, IRAN RED CRESCENT ME, V17, DOI 10.5812/ircmj.25013
   Ramos-Llordén G, 2015, IEEE T IMAGE PROCESS, V24, P345, DOI 10.1109/TIP.2014.2371244
   Schug DA, 2011, NEURAL NETW BIOSYST
   Schultz T, 2009, MATH VIS, P263, DOI 10.1007/978-3-540-88378-4_13
   Shao DG, 2015, COMPUT METHOD BIOMEC, V18, P376, DOI 10.1080/10255842.2013.803080
   Tauber C, 2004, IEEE IMAGE PROC, P247
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tounsi Y, 2019, APPL OPTICS, V58, P7110, DOI 10.1364/AO.58.007110
   TUR M, 1982, APPL OPTICS, V21, P1157, DOI 10.1364/AO.21.001157
   Vegas-Sanchez-Ferrero G, 2010, LECT NOTES COMPUT SC, V6361, P518
   Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Wong WCK, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P820
   Yin XF, 2020, MATER EXPRESS, V10, P1317, DOI 10.1166/mex.2020.1734
   Yu F, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7530976
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/5859273
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zenere M.P., 2012, SAR Image Quality Assessment
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhou YY, 2019, BIOMED SIGNAL PROCES, V48, P104, DOI 10.1016/j.bspc.2018.09.011
NR 75
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10491
EP 10514
DI 10.1007/s11042-022-13642-0
EA SEP 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000849487500005
DA 2024-07-18
ER

PT J
AU Aslam, N
   Kolekar, MH
AF Aslam, Nazia
   Kolekar, Maheshkumar H.
TI Unsupervised anomalous event detection in videos using spatio-temporal
   inter-fused autoencoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video anomaly detection; Inter-fused autoencoder; Unsupervised learning;
   Spatio-temporal analysis
ID LOCALIZATION
AB Automatic detection, localization and interpretation of an unusual event in a sequence of video is a challenging task due to its equivocal and complex nature. The development of deep neural networks have paved the way for more efficient recognition and analysis of anomalous events in video data. With the introduction of convolutional neural network (CNN) and Long short-term memory (LSTM), the spatial and temporal features extraction became easier. In this paper, we propose an end-to-end trainable Inter-fused Autoencoder (IFA) which is designed using the assemblage of CNN and LSTM layers to detect the unwonted events in a video sequence. The proposed architecture is capable of exploiting both the spatial and temporal variation of video data. The reconstruction error is computed in terms of both MSE and PSNR for each testing video. A comparison is also carried out between MSE and PSNR to show that which assessment technique is better for a reconstructive model for recreating the video sequence. A well-optimized threshold is calculated which decides the fate of testing event i.e. either usual or unusual event. Using benchmark datasets, multiple experiments were carried out to demonstrate the efficacy of proposed architecture.
C1 [Aslam, Nazia; Kolekar, Maheshkumar H.] Indian Inst Technol Patna, Bihta, India.
   [Aslam, Nazia] IIT Patna, Video Surveillance Lab, Dept Elect Engn, Bihta 801106, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology (IIT) - Patna
RP Aslam, N (corresponding author), Indian Inst Technol Patna, Bihta, India.; Aslam, N (corresponding author), IIT Patna, Video Surveillance Lab, Dept Elect Engn, Bihta 801106, Bihar, India.
EM n.aslam921@gmail.com; mahesh@iitp.ac.in
RI Oud, Tom/KLY-5187-2024; Aslam, Nazia/AGZ-4243-2022
OI Aslam, Nazia/0000-0002-8381-9702
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Amraee S, 2018, MULTIMED TOOLS APPL, V77, P14767, DOI 10.1007/s11042-017-5061-7
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Bhatnagar S, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P357
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Chakraborty P, 2018, IEEE INT C INTELL TR, P1840, DOI 10.1109/ITSC.2018.8569426
   Cho C-J, 2018, 2018 15 IEEE INT C A, P1
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Jain Neeraj Kumar, 2019, Soft Computing: Theories and Applications. Proceedings of SoCTA 2017. Advances in Intelligent Systems and Computing (AISC 742), P569, DOI 10.1007/978-981-13-0589-4_53
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Jiang F, 2009, IEEE T IMAGE PROCESS, V18, P907, DOI 10.1109/TIP.2008.2012070
   Kim H, 2016, EXPERT SYST APPL, V45, P131, DOI 10.1016/j.eswa.2015.09.035
   Kingma D. P., 2014, arXiv
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu HH, 2013, IEEE T IND INFORM, V9, P1222, DOI 10.1109/TII.2013.2255616
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Patraucean V., 2015, arXiv
   Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Sabokrou M, 2016, ELECTRON LETT, V52, P1122, DOI 10.1049/el.2016.0440
   Shi XJ, 2015, ADV NEUR IN, V28
   Singh VK, 2022, MULTIMED TOOLS APPL, V81, P3, DOI 10.1007/s11042-021-11158-7
   Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Ullah H, 2018, NEUROCOMPUTING, V290, P74, DOI 10.1016/j.neucom.2018.02.045
   Wang G., 2019, P CVPR WORKSH, P382
   Wang L, 2018, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2018.8451070
   Wang X, 2018, INT CONF SIGN PROCES, P474, DOI 10.1109/ICSP.2018.8652354
   Xu L, 2014, ADV NEUR IN, V27
   Yan SY, 2020, IEEE T COGN DEV SYST, V12, P30, DOI 10.1109/TCDS.2018.2883368
   Yang Y, 2019, 2019 INTERNATIONAL RADAR CONFERENCE (RADAR2019), P161, DOI [10.1109/RADAR41533.2019.171361, 10.1145/3300061.3300130]
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
   Zhou Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1087
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
NR 51
TC 10
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42457
EP 42482
DI 10.1007/s11042-022-13496-6
EA SEP 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000849151100001
DA 2024-07-18
ER

PT J
AU Ahuja, U
   Singh, S
   Kumar, M
   Kumar, K
   Sachdeva, M
AF Ahuja, Umang
   Singh, Sunil
   Kumar, Munish
   Kumar, Krishan
   Sachdeva, Monika
TI COVID-19: Social distancing monitoring using faster-RCNN and YOLOv3
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Deep learning; Social distancing; Object detection; YOLO;
   F-RCNN
AB As of March 31, 2021, the Coronavirus COVID-19 was affecting 219 countries and territories worldwide, with approximately 129,574,017 confirmed cases and 2,830,220 death cases. Social isolation is the most reliable way to deal with this pandemic situation. Motivated by this notion, this paper proposes a deep learning-based technique for automating the task of monitoring social distancing using surveillance cameras. To separate humans from the background, the proposed system employs object detection models based on F-RCNN (Faster Region-based Convolutional Neural Networks) and YOLO (You Only Look Once) algorithms. In the COVID-19 environment, these models track the percentage of people who violate social distancing norms on a daily basis. The authors compared the performance of both models in experimental work using the MS COCO dataset. Many tests were carried out, and we discovered that YOLOv3 demonstrated efficient performance with balanced FPS (frames per second).
C1 [Ahuja, Umang; Singh, Sunil; Kumar, Krishan] Panjab Univ, Univ Inst Engn & Technol, Dept Informat Technol, Chandigarh, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Sachdeva, Monika] IKG Punjab Tech Univ, Dept Comp Sci & Engn, Kapurthala, Punjab, India.
C3 Panjab University; I. K. Gujral Punjab Technical University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM umangahuja1203@gmail.com; sunil32123singh@gmail.com;
   munishcse@gmail.com; k.salujauiet@gmail.com; monasach1975@gmail.com
RI KUMAR, KRISHAN/AAE-7003-2022; Kumar, Munish/P-7756-2018
OI KUMAR, KRISHAN/0000-0003-4020-4051; Kumar, Munish/0000-0003-0115-1620
CR Adolph C., 2020, MEDRXIV
   AI L, 2020, LAND NAM APR 2020 CO
   Alto, 2020, LANDING NAMED APRIL
   Anaya-Isaza A., 2021, Inform. Med. Unlocked, V26, DOI DOI 10.1016/J.IMU.2021.100723
   [Anonymous], Ambient air pollution: Pollutants
   De Vos J, 2020, TRANSP RES INTERDISC, V5, DOI 10.1016/j.trip.2020.100121
   Eshel Ran, 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Han L, 2019, COMPUT VIS MEDIA, V5, P221, DOI 10.1007/s41095-019-0132-5
   Harris M, 2020, Covid-19
   Hensley, 2020, GLOBAL NEWS
   Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9
   Indian Government, 2020, DISTR NOV COR INF PN
   Johnson CarolynY., 2020, The Washington Post
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Pearce K, 2020, What is social distancing and how can it slow the spread of COVID-19?
   Prem K, 2020, LANCET PUBLIC HEALTH, V5, pE261, DOI 10.1016/S2468-2667(20)30073-6
   Red Cross, 2020, WHAT SOC DIST MEANS
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Soures N, SIRNET UNDERSTANDING
   Tangermann, 2020, SCI ALERT FUTURISM B
   Venske R, 2020, NDR KULTUR
   W. H. Organization, 2020, WHO COR VIR COVID 19
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 27
TC 6
Z9 6
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7553
EP 7566
DI 10.1007/s11042-022-13718-x
EA AUG 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000844934700001
PM 36060226
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Tripathi, E
   Kumar, U
   Tripathi, SP
AF Tripathi, Esha
   Kumar, Upendra
   Tripathi, Surya Prakash
TI Image splicing detection system using intensity-level multi-fractal
   dimension feature engineering and twin support vector machine based
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multifractal; Twin support vector machine; Run length; Support vector
   machine; Artificial neural network; Image forensics
ID COPY-MOVE FORGERY; TRANSFORM; DWT
AB Electronic images have become an essential origin of information nowadays, the authenticity of images has become important. Several techniques used for forgery have come into existence like an intrusive method and non-intrusive method. Identification of image forgery is becoming more challenging day by day because of advancements in the processing of electronic images. Consequently, Image forensics is the core part of security applications designed to restore digital media loyalty and acceptance by revealing various methods of counterfeiting. The suggested work compares different feature extraction methods for forged images for the identification of spliced images. In classification techniques, a very difficult issue is to choose features to differentiate between classes. Various features are extracted from real and spliced images with the help of a method dependent on a spatial Gray level like Gray-Level Run Length Matrix etc. This paper describes the methodological considerations involved with the concept of multifractal analysis and with this its emphasis on the Differential Box-Counting method for fetching the Intensity-Level Multi-Fractal Dimension. Further, the research paper evaluates different state of the art in image splicing techniques, and it has been observed that Twin Support Vector Machine as classifier achieves significant efficiency with Intensity-Level Multi-Fractal Dimension as Feature extraction method as compared to other methods.
C1 [Tripathi, Esha; Kumar, Upendra; Tripathi, Surya Prakash] Dr APJ Abdul Kalam Tech Univ, Inst Engn & Technol, Lucknow, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Institute of
   Engineering & Technology Lucknow
RP Kumar, U (corresponding author), Dr APJ Abdul Kalam Tech Univ, Inst Engn & Technol, Lucknow, Uttar Pradesh, India.
EM tripathi.esha@gmail.com; ukumar@ietlucknow.ac.in
RI KUMAR, UPENDRA/HKP-0667-2023
OI KUMAR, UPENDRA/0000-0003-3792-7945
CR Agarwal S, 2018, ADV INTELL SYST, V518, P117, DOI 10.1007/978-981-10-3373-5_10
   AIZERMAN MA, 1965, AUTOMAT REM CONTR+, V25, P821
   [Anonymous], 2009, 2 INT C IM SIGN PROC
   [Anonymous], 2013, INT J ADV RES COMP C
   El-Latif E.I.A., 2019, Int. J. Comput. Netw. Inform. Secur, V11, P28, DOI 10.5815/ijcnis.2019.05.04
   Farid H, AIM1999 MIT, P1657
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Han JG, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023031
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Huang SJ, 2018, CANCER GENOM PROTEOM, V15, P41, DOI 10.21873/cgp.20063
   Jenadeleh M, 2016, J FORENSIC SCI, V61, P623, DOI 10.1111/1556-4029.13108
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kanwal Navdeep, 2019, 2019 International Conference on Automation, Computational and Technology Management (ICACTM). Proceedings, P262, DOI 10.1109/ICACTM.2019.8776709
   Kaur M, 2016, COMM COM INF SC, V625, P318, DOI 10.1007/978-981-10-2738-3_27
   Kumar Upendra, 2013, International Journal of Computer Vision and Image Processing, V3, P1, DOI 10.4018/ijcvip.2013100101
   Lahiri T., 2009, ONLINE J BIOINFORMAT, V10, P29
   Li C, 2017, NEUROCOMPUTING, V228, P29, DOI 10.1016/j.neucom.2016.04.068
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Mandelbrot BB, 1983, FRACTAL GEOMETRY NAT, P173, DOI [10.1119/1.13295, DOI 10.1119/1.13295]
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Mushtaq S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2398, DOI 10.1109/ICACCI.2014.6968386
   Pham NT, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010083
   Ng TT, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P688
   Oommen RS, 2016, PROC TECH, V24, P1452, DOI 10.1016/j.protcy.2016.05.176
   Peng XJ, 2010, NEURAL NETWORKS, V23, P365, DOI 10.1016/j.neunet.2009.07.002
   Peyer KE, 2010, IEEE INT CONF ROBOT, P96, DOI 10.1109/ROBOT.2010.5509602
   PIETRONERO L, 1986, FRACTALS PHYSICS
   Saleh SQ, 2013, LECT NOTES COMPUT SC, V8034, P416, DOI 10.1007/978-3-642-41939-3_40
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shah AK, 2018, POLITICS OF FINANCIAL RISK, AUDIT AND REGULATION: A CASE STUDY OF HBOS, P1, DOI 10.1109/ISCAS.2018.8351359
   Sharma S, 2018, OPTIK, V172, P470, DOI 10.1016/j.ijleo.2018.07.021
   Takayasu H., 1990, FRACTALS PHYS SCI
   Tomar D, 2015, EGYPT INFORM J, V16, P55, DOI 10.1016/j.eij.2014.12.003
   Tripathi Esha, 2019, 2019 International Conference on Cutting-edge Technologies in Engineering (ICon-CuTE), P81, DOI 10.1109/ICon-CuTE47290.2019.8991470
   Vapnik V, 2000, The Nature of Statistical Learning Theory, DOI [DOI 10.1007/978-1-4757-3264-1, DOI 10.1007/978-1-4757-2440-0]
   Vicsek T., 1989, Fractal Growth Phenomena, DOI [10.1142/0511, DOI 10.1142/0511]
   Vidyadharan DS, 2017, J INTELL FUZZY SYST, V32, P3177, DOI 10.3233/JIFS-169261
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Yan JD, 2016, J APPL ANAL COMPUT, V6, P1114, DOI 10.11948/2016073
NR 42
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39745
EP 39763
DI 10.1007/s11042-022-13519-2
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000840595500003
DA 2024-07-18
ER

PT J
AU Tan, YH
   Chow, LS
   Chuah, JH
   Lai, KW
AF Tan, Ying Hui
   Chow, Li Sze
   Chuah, Joon Huang
   Lai, Khin Wee
TI Diagnosis of optic neuritis using magnetic resonance images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optic neuritis; Magnetic resonance imaging (MRI); Biomedical image
   processing; Segmentation; Interpolation
ID NERVE; INTERPOLATION; MRI
AB Optic neuritis is an acute inflammation of myelin sheath that damages optic nerve while Magnetic Resonance Imaging (MRI) is one of the non-invasive alternatives to diagnose optic neuritis by measuring the mean cross-sectional area of the optic nerve. However, the extraction and analysis of optic nerve with MRI are challenging due to its discrete dimension and low spatial resolution of the MR images. This research leverages both image segmentation and interpolation to achieve better performance in MR image processing. The chosen image processing models are Level Set Method-Iterative Curvature Based Interpolation (LSM-ICBI) model and Reverse Diffusion-Level Set Method (RD-LSM) for T1 and T2 weighted images respectively. Both LSM-ICBI and RD-LSM models produce distinct optic nerve edges for the area measurement on the coronal view MR image slices. We compare the measurements of six datasets with the mean cross-sectional area of the normal optic nerves (27.51 +/- 0.83 mm(2) for T1 weighted image and 22.26 +/- 1.29 mm(2) for T2 weighted image). Our experimental results show that the accuracy of LSM-ICBI diagnosis for T1 weighted image is 83.33% while RD-LSM model achieves 66.67% in T2 weighted image.
C1 [Tan, Ying Hui; Chuah, Joon Huang] Univ Malaya, Fac Engn, Dept Elect Engn, Kuala Lumpur 50603, Malaysia.
   [Tan, Ying Hui] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
   [Chow, Li Sze] UCSI Univ, Fac Engn Technol & Built Environm, Dept Elect & Elect Engn, Cheras 56000, Malaysia.
   [Lai, Khin Wee] Univ Malaya, Fac Engn, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya; Korea Advanced Institute of Science & Technology
   (KAIST); UCSI University; Universiti Malaya
RP Chuah, JH (corresponding author), Univ Malaya, Fac Engn, Dept Elect Engn, Kuala Lumpur 50603, Malaysia.
EM jhchuah@um.edu.my
RI Lai, Khin Wee/A-2997-2011; Chuah, Joon Huang/F-9990-2010
OI Lai, Khin Wee/0000-0002-8602-0533; Chuah, Joon
   Huang/0000-0001-9058-3497; Tan, Ying Hui/0000-0002-1569-1284
CR Almansour M, 2021 IEEE EMBS INT C, P1
   Barker GJ, 2000, J NEUROL SCI, V172, pS13, DOI 10.1016/S0022-510X(99)00271-3
   Bhide A.B., 2012, INT J ADV RES COMPUT, V1, P85
   Brady MA, 2011, NATL SCI FOUND VISIT, V2
   Chow L, 2021, MAGN RESON IMAGING, V79, P76, DOI 10.1016/j.mri.2021.03.014
   Despotovic I, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/450341
   Elazab A, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/485495
   Fadnavis S., 2014, International Journal of Engineering Research and Applications, V4, P70
   Giachetti A., 2008, PROCEED BR MACH VIS, V2008, p13.1
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Hickman SJ, 2004, BRAIN, V127, P2498, DOI 10.1093/brain/awh284
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Lee M, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10120974
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Lin T-H, 2013, ASSESSING FUNCTIONAL, P189, Patent No. 3603290
   Lowell J, 2004, IEEE T MED IMAGING, V23, P256, DOI 10.1109/TMI.2003.823261
   Merickel MB, 2006, PROC SPIE, V6143, DOI 10.1117/12.657923
   Morse BS, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P227, DOI 10.1109/ICIP.1998.999013
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Salvado O, 2006, INT J BIOMED IMAGING, V2006, DOI 10.1155/IJBI/2006/92092
   Sharma A., US Patent, Patent No. [2017 9 846 937, 20179846937]
   Stunkel L, 2019, AM J NEURORADIOL, V40, P1043, DOI 10.3174/ajnr.A6057
   Toosy AT, 2014, LANCET NEUROL, V13, P83, DOI 10.1016/S1474-4422(13)70259-X
   Wei Z, 2013, IEEE T IMAGE PROCESS, V22, P4271, DOI 10.1109/TIP.2013.2271849
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhu R, 2021, MULTIMED TOOLS APPL, V80, P12991, DOI 10.1007/s11042-020-09543-9
NR 28
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41979
EP 41993
DI 10.1007/s11042-022-13520-9
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000840387900001
DA 2024-07-18
ER

PT J
AU Ullah, S
   Hussain, MT
   Yousaf, M
AF Ullah, Shamsher
   Hussain, Muhammad Tanveer
   Yousaf, Mahwish
TI QuSigS: A quantum Signcryption scheme to recover key escrow problem and
   key revocation problem in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signcryption; Quantum Signcryption; Key escrow problem; Key revocation
   problem; Cloud computing; Elliptic curve cryptography; Multimedia
   security
ID ATTRIBUTE-BASED ENCRYPTION; PUBLIC VERIFIABILITY; USER; SECRECY; POLICY
AB In recent years, cloud computing plays a vital role in IT industries. Cloud computing is the sum of software as a service (SaaS) and utility computing (hardware). Elliptic Curve Cryptography provides more efficient performance and security for a cloud environment. The usage of Attribute-Based Encryption (ABE) has escrow and revocation problems. These problems make a burden on the cloud and create access failure to the cloud users. Therefore, we use a novel signcryption technique Zheng (1997) to recover the escrow and revocation problems from the cloud/edge. We proposed "A Quantum Signcryption Scheme (QuSigS) to Recover Key Escrow Problem (KEP) (Niu et al. 2009, Zhang et al. 2015, Chen and Ma 2014) and Key Revocation Problem (KRP) (Al-Dahhan et al. Sens Multidiscipl Digit Publish Inst 19(7):1-22 2019, Li et al. IEEE Access 8:176738-176749 2020) in cloud computing". Our proposed QuSigS scheme reduced communication and computational overheads, memory storage, and execution time, at the user side and at the server side. Our applied techniques for the user side is signcryption and for the server side is unsigncryption. The efficient result calculation from (3) in percentage for the user side and server side is 16.66% for 112 bits, 13.04% for 160 bits, 16.66% for 256 bits on the user side and the server side it is 9.52% respectively. The efficiency of our scheme is 4.17% for signcryption and 9.52% for unsigncryption as compared to existing schemes.
C1 [Ullah, Shamsher] Northwestern Polytech Univ, Sch Software, Xian 710072, Shaanxi, Peoples R China.
   [Hussain, Muhammad Tanveer] Univ Management & Technol UMT, Dept Math, Lahore 54000, Pakistan.
   [Yousaf, Mahwish] Univ Sci & Technol China USTC, Sch Comp Sci & Technol, Hefei 230000, Anhui, Peoples R China.
C3 Northwestern Polytechnical University; University of Management &
   Technology (UMT); Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Ullah, S (corresponding author), Northwestern Polytech Univ, Sch Software, Xian 710072, Shaanxi, Peoples R China.
EM shamsherullah@nwpu.edu.cn
RI Ullah, Shamsher/GXN-2692-2022
OI Ullah, Shamsher/0000-0002-8726-3123; Hussain, Muhammad
   Tanveer/0000-0003-0884-3056; Ullah, Shamsher/0009-0003-6399-8461
CR Al-Dahhan RR, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071695
   Anoop MS, 2007, ELLIPTIC CURVE CRYPT
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Aymerich Francesco Maria, 2008, 2008 First International Conference on the Applications of Digital Information and Web Technologies, P113, DOI 10.1109/ICADIWT.2008.4664329
   Baek J, 2007, J CRYPTOL, V20, P203, DOI 10.1007/s00145-007-0211-0
   Barker W, 2012, TECHNICAL REPORT
   Biehl I, 2000, LECT NOTES COMPUT SC, V1880, P131
   Carroll Mariana., 2012, Cloud Computing and Services Science, P73
   Ch SA, 2015, MULTIMED TOOLS APPL, V74, P1711, DOI 10.1007/s11042-014-2283-9
   Chen JW, 2014, IEEE ICC, P3782, DOI 10.1109/ICC.2014.6883910
   Chen Q, 2020, COMPUT COMMUN, V164, P31, DOI 10.1016/j.comcom.2020.09.012
   Dangi RS., 2015, INT J COMPUT SCI INF, V6, P5284
   DES, 1999, DAT ENCR STAND
   ECC, 2014, ELLIPTIC CURVE CRYPT
   Goyal T, 2012, PROCEDIA ENGINEER, V38, P3566, DOI 10.1016/j.proeng.2012.06.412
   Hedabou M., 2004, 2004342 IACR CRYPT E, V342, P2004
   Hoyle MP, 1998, LECT NOTES COMPUT SC, V1528, P277
   Hwang RJ, 2005, APPL MATH COMPUT, V167, P870, DOI 10.1016/j.amc.2004.06.124
   Kapadia JS, 2013, IOSR J COMPUT ENG IO
   KEP, 2007, KEY
   Key, 2018, KEY CRYPT
   Kumar KS, 2013, INT J MATH COMPUT RE, V1
   Lee Shirly, 2010, Journal of Information and Communication Convergence Engineering, V8, P427
   Li L, 2020, IEEE ACCESS, V8, P176738, DOI 10.1109/ACCESS.2020.3025140
   Liu F., 2011, NIST SPEC PUBL, V500, P2011
   Maggu S, 2013, INT J ADV ENG SCI CI, P2231
   Mandal SK, 2013, INT J ENG TECHNOL, P225
   Mell P, 2010, COMMUN ACM, V53, P50
   National Institute of Standards and Technology, 2001, NIST FIPS PUB, P197
   Niu K, 2009, FIRST INTERNATIONAL WORKSHOP ON DATABASE TECHNOLOGY AND APPLICATIONS, PROCEEDINGS, P95, DOI 10.1109/DBTA.2009.48
   Oh J, 2005, LECT NOTES COMPUT SC, V3803, P290
   Parikh K, 2015, INT J GRID DISTRIB, V8, P145, DOI 10.14257/ijgdc.2015.8.1.14
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Sahana SC, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1117-x
   Selvi SSD, 2010, LECT NOTES COMPUT SC, V6402, P244, DOI 10.1007/978-3-642-16280-0_17
   Seo SH, 2014, IEEE T KNOWL DATA EN, V26, P2107, DOI 10.1109/TKDE.2013.138
   Sudha M., 2012, ADV COMPUTER SCI ITS, V1, P32
   Tanwar S, 2018, J INFORM OPTIM SCI, V39, P503, DOI 10.1080/02522667.2017.1383660
   Tripathi A, 2014, INT J EMERGING TECHN, P79
   Ullah S, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM), P51, DOI 10.1109/BIGCOM.2017.51
   Virtual Reality Society, 2017, APPL VIRTUAL REALITY
   Wang GJ, 2011, COMPUT SECUR, V30, P320, DOI 10.1016/j.cose.2011.05.006
   Xing Zhang, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P74, DOI 10.1007/978-3-319-27051-7_7
   Yang K., Proceedings of the 8th ACM SIGSAC symposium on Information, computer and communications security, 2013, P523
   Yu G, 2016, LECT NOTES COMPUT SC, V10005, P3, DOI 10.1007/978-3-319-47422-9_1
   Zhang Q, 2010, J INTERNET SERV APPL, V1, P7, DOI 10.1007/s13174-010-0007-6
   Zheng YL, 1997, LECT NOTES COMPUT SC, V1294, P165
   Zheng YL, 1998, INFORM PROCESS LETT, V68, P227, DOI 10.1016/S0020-0190(98)00167-7
   Zissis D, 2012, FUTURE GENER COMP SY, V28, P583, DOI 10.1016/j.future.2010.12.006
NR 49
TC 2
Z9 2
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36781
EP 36803
DI 10.1007/s11042-022-13502-x
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000840291300007
DA 2024-07-18
ER

PT J
AU Tsai, MF
   Chen, CH
AF Tsai, Ming-Fong
   Chen, Chiung-Hung
TI Enhancing the accuracy of a human emotion recognition method using
   spatial temporal graph convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human emotion recognition; Spatial temporal graph convolution networks;
   Human skeleton Keypoint detection
ID HEAD POSE ESTIMATION
AB Artificial intelligence technology has been widely used in human emotion recognition applications. Unlike traditional facial, semantic and brain wave technology, spatio-temporal graph convolution network technology has been shown to be useful for human emotional feature training and recognition, but is limited by the loss of subtle features in the training process caused by convolutional neural network technology. As a result, the use of spatio-temporal graph convolution network technology to identify human emotional categories has been restricted. This research paper aims to improve the accuracy of human emotion recognition methods based on spatio-temporal graphs, and uses human skeleton keypoint detection technology to calculate the degree of face swing and variation. These are used as classification features for human emotion, and are supplemented with the classification results from a spatio-temporal graph convolution network recognition model after performing a weight analysis, in order to obtain a high level of accuracy for human emotion identification. This research paper proposes an approach to the enhancement of human emotion recognition accuracy to import activities change recognition ability, efficiently identify multi-level human emotional status to strengthen artificial emotional intelligence calculation. In this research paper, we use human skeleton keypoint information as the basis for an emotion recognition framework. We carry out model training on the keypoints of the human face based on the specific degree of emotional change. Our proposed method is compared with related approaches in the literature (ST-GCN, 2S-AGCN and GCN-NAS), and we find that the accuracy of emotion recognition can be improved by 17.71%, 18.75% and 16.67%, respectively.
C1 [Tsai, Ming-Fong; Chen, Chiung-Hung] Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
C3 National United University
RP Tsai, MF (corresponding author), Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
EM mingfongtsai@gmail.com
OI Tsai, Ming-Fong/0000-0001-9046-2513
FU National United University, Taiwan
FX This research was funded by National United University, Taiwan.
CR Abate AF, 2020, PATTERN RECOGN LETT, V140, P179, DOI 10.1016/j.patrec.2020.10.003
   Abate AF, 2019, IEEE ACCESS, V7, P64256, DOI 10.1109/ACCESS.2019.2917451
   Ahmed F, 2020, IEEE ACCESS, V8, P11761, DOI 10.1109/ACCESS.2019.2963113
   Bombatkar A., 2014, INT J ENG RES APPL, P68
   Cao Y, 2021, MULTIMED TOOLS APPL, V80, P29139, DOI 10.1007/s11042-021-11136-z
   Das P, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P37
   Ferdinando H, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P112, DOI 10.5220/0006147801120118
   Fourati Nesrine, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163145
   Kashyap C., 2016, INT J ENG FUTURE TEC, V7, P18
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Li XS, 2022, MULTIMED TOOLS APPL, V81, P4821, DOI 10.1007/s11042-021-11026-4
   Ma XL, 2017, SMART INNOV SYST TEC, V53, P77, DOI 10.1007/978-981-10-2398-9_7
   MONTEPARE JM, 1987, J NONVERBAL BEHAV, V11, P33, DOI 10.1007/BF00999605
   Peng W, 2020, AAAI CONF ARTIF INTE, V34, P2669
   Piana S, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2818740
   Randhavane T., 2019, IEEE C COMPUTER VISI, P1
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Raza M, 2018, NEUROCOMPUTING, V272, P647, DOI 10.1016/j.neucom.2017.07.029
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Tsai MF, 2022, MULTIMED TOOLS APPL, V81, P7439, DOI 10.1007/s11042-022-12000-4
   Tsai MF, 2021, SOFT COMPUT, V25, P13741, DOI 10.1007/s00500-021-06038-z
   Tsai MF, 2021, IEEE ACCESS, V9, P13870, DOI 10.1109/ACCESS.2021.3052246
   Tsai MF, 2021, J SUPERCOMPUT, V77, P6676, DOI 10.1007/s11227-020-03525-2
   Tsai MF, 2020, IEEE ACCESS, V8, P220848, DOI 10.1109/ACCESS.2020.3042539
   Tsai MF, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091387
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang JR, 2020, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR42600.2020.00335
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zheng WL, 2019, IEEE T AFFECT COMPUT, V10, P417, DOI 10.1109/TAFFC.2017.2712143
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 32
TC 1
Z9 1
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11285
EP 11303
DI 10.1007/s11042-022-13653-x
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000839516800002
DA 2024-07-18
ER

PT J
AU Liang, ZN
   Liu, ZH
   Shi, HZ
   Chen, YL
   Cai, YB
   Hong, H
   Liang, YT
   Feng, YF
   Yang, YQ
   Zhang, J
   Fu, P
AF Liang, Zhuonan
   Liu, Ziheng
   Shi, Huaze
   Chen, Yunlong
   Cai, Yanbing
   Hong, Hong
   Liang, Yating
   Feng, Yafan
   Yang, Yuqing
   Zhang, Jing
   Fu, Peng
TI SPOC learner's final grade prediction based on a novel sampling batch
   normalization embedded deep neural network method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grade prediction; Class balance; SPOC; Deep neural network; Batch
   normalization
ID ALGORITHM
AB Recent years have witnessed the rapid growth of Small Private Online Courses (SPOC) which is able to highly customized and personalized to adapt variable educational requests, in which machine learning techniques are explored to summarize and predict the learners' performance, mostly focus on the final grade. However, the problem is that the final grade of learners on SPOC is generally seriously imbalance which handicaps the training of prediction model. To solve this problem, a sampling batch normalization embedded deep neural network (SBNEDNN) method is developed in this paper. First, a combined indicator is defined to measure the distribution of the data, then a rule is established to guide the sampling process. Second, the batch normalization (BN) modified layers are embedded into full connected neural network to solve the data imbalanced problem. Experimental results with other three deep learning methods demonstrate the superiority of the proposed method.
C1 [Liang, Zhuonan; Liu, Ziheng; Shi, Huaze; Chen, Yunlong; Feng, Yafan] Nanjing Univ Sci & Technol, Sch Sci, Nanjing 210094, Jiangsu, Peoples R China.
   [Cai, Yanbing; Liang, Yating; Fu, Peng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Hong, Hong] Univ Calif Davis, Dept Elect & Comp Engn, Davis, CA 95616 USA.
   [Yang, Yuqing] Nanjing Univ Finance & Econ, Off Int Cooperat & Exchanges, Nanjing 210046, Peoples R China.
   [Yang, Yuqing] Nanjing Univ Aeronaut & Astronaut, Coll Econ & Management, Nanjing 211106, Peoples R China.
   [Zhang, Jing] Jiangsu Guidgine Educ Evaluat Inc, Nanjing 210046, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology; University of California System; University of
   California Davis; Nanjing University of Finance & Economics; Nanjing
   University of Aeronautics & Astronautics
RP Fu, P (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM fupeng@njust.edu.cn
FU Undergraduate Student Out-of-class Academic Foundation of Nanjing
   University of Science and Technology; National Natural Science
   Foundation of China [61801222]; Fundamental Research Funds for the
   Central Universities [30919011230]
FX This work was in part supported by the Undergraduate Student
   Out-of-class Academic Foundation of Nanjing University of Science and
   Technology, in part supported by the National Natural Science Foundation
   of China under Grant no. 61801222, and in part supported by the
   Fundamental Research Funds for the Central Universities under Grant no.
   30919011230.
CR Ahmed MR., 2020, 2020 11 INT C COMPUT
   Brodic D, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1382, DOI 10.23919/MIPRO.2018.8400249
   Cheng X, 2020, IEEE T IND ELECTRON, V67, P3288, DOI 10.1109/TIE.2019.2913815
   Dalipi F, 2018, IEEE GLOB ENG EDUC C, P1007, DOI 10.1109/EDUCON.2018.8363340
   Fu P, 2019, CMC-COMPUT MATER CON, V59, P509, DOI 10.32604/cmc.2019.05250
   Hu Q, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'19), P76, DOI 10.1145/3303772.3303802
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Juanatas IC, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND KNOWLEDGE ECONOMY (ICCIKE' 2019), P251, DOI [10.1109/iccike47802.2019.9004386, 10.1109/ICCIKE47802.2019.9004386]
   Luo HW, 2019, P INT COMP SOFTW APP, P916, DOI 10.1109/COMPSAC.2019.00139
   Qiu L, 2018, IEEE ACCESS, V6, P71474, DOI 10.1109/ACCESS.2018.2881275
   Ran J, 2018, PROC INT C COMPUTER, P330
   Wang XH, 2020, INFORMATION, V11, DOI 10.3390/info11040201
   Yang TY, 2017, IEEE J-STSP, V11, P716, DOI 10.1109/JSTSP.2017.2700227
   Yang YQ, 2020, CMC-COMPUT MATER CON, V65, P2413, DOI 10.32604/cmc.2020.011881
   Zhang GQ, 2021, INFORM SCIENCES, V547, P498, DOI 10.1016/j.ins.2020.08.066
   Zhang GQ, 2020, IEEE T CIRC SYST VID, V30, P1065, DOI 10.1109/TCSVT.2019.2902672
   Zhu M, 2018, IEEE ACCESS, V6, P4641, DOI 10.1109/ACCESS.2018.2789428
   Zong J, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2353, DOI 10.1145/3340531.3412110
NR 18
TC 1
Z9 1
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9843
EP 9853
DI 10.1007/s11042-022-13628-y
EA AUG 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000839516900009
DA 2024-07-18
ER

PT J
AU Nabil, G
   Azzedine, B
   Mustapha, B
AF Nabil, Gherbi
   Azzedine, Bouaraba
   Mustapha, Benssalah
TI Fast and efficient variational method based on <i>G</i><SUP>0</SUP>
   distribution for SAR image despeckling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic Aperture Radar (SAR); Diffuion function; Overlapping Group
   Sparsity (OGS); Total Variation (TV)
ID SCALE-SPACE; NOISE; ENHANCEMENT; MODEL
AB Speckle noise is one of the major challenges that affects Synthetic Aperture Radar (SAR) images in view of its multiplicative nature. To deal with this issue, a new fast and effective despeckling algorithm is proposed, wich is based on a variational model incluing data fidelity and regularization terms. The G(0) distribution is considered to define the data fidelity term, whereas the regularization term is formed by a combination of the weighted second-order total variation, the Overlapping Group Sparsity (OGS), and a box constraint. Moreover, a new fast and efficient diffusion function is proposed to solve the problem of over-smoothing, and speed up the despeckling process. The obtained results show that the proposed solution can achieve a maximum value of Equivalent Number of Looks (ENL similar or equal to 189) for real SAR images, and the best CPU time consumption compared with the state-of-the-art speckle removal methods.
C1 [Nabil, Gherbi; Azzedine, Bouaraba] Ecole Mil Polytech, Radar Lab, BP 17, Algiers 16111, Algeria.
   [Mustapha, Benssalah] Ecole Mil Polytech, Signal Proc Lab, BP 17, Algiers 16111, Algeria.
C3 Ecole Military Polytechnic; Ecole Military Polytechnic
RP Nabil, G (corresponding author), Ecole Mil Polytech, Radar Lab, BP 17, Algiers 16111, Algeria.
EM gherbi.nabil.81@gmail.com; bouaraba.azzedine@mdn.dz;
   benssalah.mustapha@mdn.dz
CR Achim A, 2006, IEEE T IMAGE PROCESS, V15, P2686, DOI 10.1109/TIP.2006.877362
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cassetti J, 2021, 2021 2 CHIN INT SAR, P1, DOI DOI 10.23919/CISS51089.2021.9652326
   Cozzolino D, 2014, IEEE GEOSCI REMOTE S, V11, P524, DOI 10.1109/LGRS.2013.2271650
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   Ding M, 2019, APPL MATH COMPUT, V341, P128, DOI 10.1016/j.amc.2018.08.014
   Feng WS, 2014, IEEE T IMAGE PROCESS, V23, P1831, DOI 10.1109/TIP.2014.2308432
   Frery AC, 1997, IEEE T GEOSCI REMOTE, V35, P648, DOI 10.1109/36.581981
   Frost, 1980, LARS S, P350
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Glowinski R., 1989, Augmented Lagrangian and Operator-Splitting Methods in Nonlinear Mechanics
   Guo MQ, 2021, REMOTE SENS LETT, V12, P174, DOI 10.1080/2150704X.2020.1846820
   Karakus O, 2019, IEEE T IMAGE PROCESS, V28, P1748, DOI 10.1109/TIP.2018.2878322
   Kilany NM, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3489-2
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Liu J, 2016, NEUROCOMPUTING, V216, P502, DOI 10.1016/j.neucom.2016.07.049
   Liu PF, 2020, IET IMAGE PROCESS, V14, P862, DOI 10.1049/iet-ipr.2018.5930
   Lv XG, 2016, APPL MATH COMPUT, V289, P132, DOI 10.1016/j.amc.2016.03.029
   Massonnet D., 2008, Imaging With Synthetic Aperture Radar
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Nie XL, 2017, DIGIT SIGNAL PROCESS, V68, P44, DOI 10.1016/j.dsp.2017.05.008
   Oliveira FA, 2019, FRONT PHYS-LAUSANNE, V7, DOI 10.3389/fphy.2019.00018
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ponmani E, 2021, MULTIMED TOOLS APPL, V80, P26547, DOI 10.1007/s11042-021-10871-7
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shi JN, 2008, SIAM J IMAGING SCI, V1, P294, DOI 10.1137/070689954
   Tebini S, 2016, DIGIT SIGNAL PROCESS, V48, P201, DOI 10.1016/j.dsp.2015.09.013
   Tebini S, 2016, COMPUT MATH APPL, V72, P1369, DOI 10.1016/j.camwa.2016.07.004
   Wang RL, 2020, MULTIMED TOOLS APPL, V79, P7633, DOI 10.1007/s11042-019-08377-4
   Xu B, 2015, IEEE J-STARS, V8, P1682, DOI 10.1109/JSTARS.2014.2375359
   Zhou ZH, 2019, IEEE ACCESS, V7, P99231, DOI 10.1109/ACCESS.2019.2929364
NR 36
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5899
EP 5922
DI 10.1007/s11042-022-13472-0
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834736500005
DA 2024-07-18
ER

PT J
AU Yang, RC
   Kan, JM
AF Yang, Rongchao
   Kan, Jiangming
TI Euclidean distance-based adaptive collaborative representation with
   Tikhonov regularization for hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image (HSI) classification; Collaborative representation
   (CR); Tikhonov regularization; Euclidean distance-based adaptive (EDA)
   dictionary learning
AB In recent years, collaborative representation (CR)-based models have been widely used in hyperspectral image (HSI) classification. And many CR models utilize Tikhonov regularization term to improve the classification performance. However, this regularization term greatly increases the running time of CR models due to calculating the Euclidean distance between the test sample and all the training samples. Moreover, most of CR models utilize the training samples of all classes to represent the test sample, which may make the classes irrelevant to the test sample produce an impact on the classification performance of CR. To solve the above problems and further improve the classification performance of the CR model, a novel Euclidean distance-based adaptive (EDA) dictionary learning method is proposed in this paper, which aims to construct a subdictionary by selecting the k-nearest neighbor classes relevant to the test sample using Euclidean distance. And the EDA method is integrated into the original collaborative representation classifier (CRC) and the CRC with Tikhonov regularization (CRT) methods for HSI classification, which is denoted as EDACRC and EDACRT, respectively. The proposed methods are evaluated on the Botswana, KSC, and Salinas-A datasets, in which the classification performances and running times of these methods are analyzed and compared. The experimental results demonstrate that the proposed EDA method can not only effectively reduce the running time of the CR model with Tikhonov regularization, but also effectively eliminate some classes irrelevant to the test sample, thus improving the classification performance of the CR model.
C1 [Yang, Rongchao; Kan, Jiangming] Beijing Forestry Univ, Sch Technol, Beijing 100083, Peoples R China.
   [Yang, Rongchao; Kan, Jiangming] Key Lab State Forestry Adm Forestry Equipment & A, Beijing 100083, Peoples R China.
   [Yang, Rongchao] Chinese Acad Agr Sci, Agr Informat Inst, Beijing 100081, Peoples R China.
C3 Beijing Forestry University; Chinese Academy of Agricultural Sciences;
   Agriculture Information Institute, CAAS
RP Kan, JM (corresponding author), Beijing Forestry Univ, Sch Technol, Beijing 100083, Peoples R China.; Kan, JM (corresponding author), Key Lab State Forestry Adm Forestry Equipment & A, Beijing 100083, Peoples R China.
EM kanjm@bjfu.edu.cn
FU National Natural Science Foundation of China [32071680]; Beijing
   municipal construction project special fund - ChinaPostdoctoral Science
   Foundation [2022M713415]
FX This work was supported by the National Natural Science Foundation of
   China (No. 32071680), the Beijing municipal construction project special
   fund, and the Project funded by ChinaPostdoctoral Science Foundation
   (No. 2022M713415).
CR Akbari D, 2016, INT J REMOTE SENS, V37, P440, DOI 10.1080/01431161.2015.1129561
   Chen H, 2020, IEEE J-STARS, V13, P3164, DOI 10.1109/JSTARS.2020.3000677
   Chen X, 2017, IEEE GEOSCI REMOTE S, V14, P1121, DOI 10.1109/LGRS.2017.2699667
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Clark ML, 2018, REMOTE SENS ENVIRON, V210, P490, DOI 10.1016/j.rse.2018.03.021
   Du PJ, 2018, IEEE T GEOSCI REMOTE, V56, P4664, DOI 10.1109/TGRS.2018.2833882
   Gao QS, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060905
   Kayabol K, 2016, DIGIT SIGNAL PROCESS, V59, P106, DOI 10.1016/j.dsp.2016.08.010
   Li W, 2016, IEEE J-STARS, V9, P4178, DOI 10.1109/JSTARS.2016.2542113
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P48, DOI 10.1109/LGRS.2014.2325978
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P389, DOI 10.1109/LGRS.2014.2343956
   Li W, 2014, IEEE T GEOSCI REMOTE, V52, P477, DOI 10.1109/TGRS.2013.2241773
   Liu H, 2021, IEEE J-STARS, V14, P6624, DOI 10.1109/JSTARS.2021.3091591
   Liu JJ, 2016, IEEE T GEOSCI REMOTE, V54, P2371, DOI 10.1109/TGRS.2015.2500680
   Liu Z, 2017, IEEE GEOSCI REMOTE S, V14, P257, DOI 10.1109/LGRS.2016.2637561
   Lu T, 2017, IEEE T GEOSCI REMOTE, V55, P4398, DOI 10.1109/TGRS.2017.2691906
   Ma Y, 2018, IEEE GEOSCI REMOTE S, V15, P587, DOI 10.1109/LGRS.2018.2800080
   Su HJ, 2019, IEEE T GEOSCI REMOTE, V57, P1230, DOI 10.1109/TGRS.2018.2866190
   Sun WW, 2017, IEEE GEOSCI REMOTE S, V14, P1710, DOI 10.1109/LGRS.2017.2729940
   Tu B, 2021, IEEE GEOSCI REMOTE S, V18, P861, DOI 10.1109/LGRS.2020.2988124
   Wang B, 2013, INT CONF ACOUST SPEE, P2877, DOI 10.1109/ICASSP.2013.6638183
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Q, 2016, INT J AGR BIOL ENG, V9, P143, DOI 10.3965/j.ijabe.20160905.1707
   Yang JH, 2020, IEEE GEOSCI REMOTE S, V17, P671, DOI 10.1109/LGRS.2019.2929840
   Ye MC, 2017, IEEE T GEOSCI REMOTE, V55, P1544, DOI 10.1109/TGRS.2016.2627042
   Yuxiang Zhang, 2021, IEEE Transactions on Geoscience and Remote Sensing, V59, P9646, DOI 10.1109/TGRS.2020.3046756
   Zhang EL, 2015, IEEE GEOSCI REMOTE S, V12, P1397, DOI 10.1109/LGRS.2015.2402971
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zheng CY, 2019, PATTERN RECOGN LETT, V117, P30, DOI 10.1016/j.patrec.2018.11.005
NR 30
TC 6
Z9 6
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5823
EP 5838
DI 10.1007/s11042-022-13597-2
EA AUG 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834017600001
DA 2024-07-18
ER

PT J
AU Walia, S
   Kumar, K
   Kumar, M
AF Walia, Savita
   Kumar, Krishan
   Kumar, Munish
TI Unveiling digital image forgeries using Markov based quaternions in
   frequency domain and fusion of machine learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Decision fusion; Discrete transforms; Forgery
   detection; Fusion of classifiers; Majority voting; Markov process;
   Quaternions
ID SPLICING DETECTION; AUTHENTICATION
AB Nowadays, digital images have been manipulated for various fraudulent purposes from time to time. Therefore, proposing a detection algorithm for such manipulations has become a key interest for investigators. Digital image splicing and copy-move are among the most commonly performed forgeries and their detection is problematic. In spite of the number of accessible potential solutions for manipulation detection, the increasing number of forgery cases and their complexity necessitate the need for improved detection methods. The technique put forward in this article aims to deliver a reliable remedy for image manipulation detection. In the presented article, a novel procedure for discovering forgery in digital images is proposed with the use of quaternions that expands the distinction between probability distributions of authentic and forged images. Quaternions help in representing the image in its entirety as a vector field and discrete cosine transform is applied on the quaternion that is constructed from the color components of the image. After that, Markov features are originated from the transitional probabilities of the inter-block and intra-block correlation amongst the coefficients of the blocks along four directions. Finally, a feature vector of 648 dimensions is classified using a fusion of various classifiers. The performance of the approach is presented in terms of seven different performance metrics. The experiments are performed on three benchmark datasets viz. CoMoFoD dataset, CASIA version 1.0 and CASIA version 2.0 datasets. The proposed approach beats existing approaches over the CoMoFoD dataset and yields competitive outcomes for the CASIA version 2.0 dataset.
C1 [Walia, Savita; Kumar, Krishan] Panjab Univ, Univ Inst Engn & Technol, Chandigarh 160014, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda 151001, India.
C3 Panjab University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda 151001, India.
EM s.walia24@pu.ac.in; k.salujauiet@gmail.com; munishcse@gmail.com
RI Kumar, Munish/P-7756-2018; Kumar, Krishan/F-6049-2016; Walia, Dr.
   Savita/G-1605-2019
OI Kumar, Munish/0000-0003-0115-1620; Kumar, Krishan/0000-0001-9877-0238;
   Walia, Dr. Savita/0000-0002-8755-2873
FU Technical Education Quality Improvement Project III (TEQIP III) of the
   Ministry of Human Resource Development (MHRD), Government of India
   [P154523]
FX This work was supported by the Technical Education Quality Improvement
   Project III (TEQIP III) of the Ministry of Human Resource Development
   (MHRD), Government of India, assisted by the World Bank (Sanctioned to
   UIET, Panjab University, Chandigarh, India) under Grant P154523.
CR Barbic J., 2011, U SO CALIFORNIA, VCSCI 520, P1
   Chen W, 2007, PROC SPIE, V6505, DOI 10.1117/12.704321
   Chitroub S, 2010, INT J IMAGE DATA FUS, V1, P113, DOI 10.1080/19479830903561944
   Dong J, 2009, LECT NOTES COMPUT SC, V5450, P76, DOI 10.1007/978-3-642-04438-0_7
   Dua Shilpa, 2020, Procedia Computer Science, V171, P369, DOI 10.1016/j.procs.2020.04.038
   El-Alfy ESM, 2015, PATTERN ANAL APPL, V18, P713, DOI 10.1007/s10044-014-0396-4
   Elaskily MA, 2017, 2017 INTL CONF ON ADVANCED CONTROL CIRCUITS SYSTEMS (ACCS) SYSTEMS & 2017 INTL CONF ON NEW PARADIGMS IN ELECTRONICS & INFORMATION TECHNOLOGY (PEIT), P193, DOI 10.1109/ACCS-PEIT.2017.8303041
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Feng W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P252, DOI 10.1109/CISP.2008.61
   Gupta D.K., 2021, ADV COMMUNICATION CO, V668, DOI 10.1007/978-981-15-5341-7_82
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hashmi MF, 2015, INT J SECUR APPL, V9, P125, DOI 10.14257/ijsia.2015.9.4.13
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Hsu YF, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P28
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Hussain M, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P197, DOI 10.1109/INISTA.2014.6873618
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kantor I.L., 1989, Hypercomplex Number: An Elementary Introduction to Algebras
   Kaur A, 2018, INT CONF CONTEMP, P172
   Kaur M., 2016, Int J Multimed Ubiquitous Eng, V11, P37, DOI DOI 10.14257/IJMUE.2016.11.4.05
   Kumar M., 2021, ADV COMMUNICATION CO, P1503
   Kuncheva LI, 2003, PATTERN ANAL APPL, V6, P22, DOI 10.1007/s10044-002-0173-7
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li C, 2017, NEUROCOMPUTING, V228, P29, DOI 10.1016/j.neucom.2016.04.068
   Moxey CE, 2003, IEEE T SIGNAL PROCES, V51, P1941, DOI 10.1109/TSP.2003.812734
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Saxena A, 2021, ADV COMMUNICATION CO, P1069, DOI DOI 10.1007/978-981-15-5341-7_81
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Shi YQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P269, DOI 10.1109/ICME.2005.1521412
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Sutthiwan P, 2011, LECT NOTES COMPUT SC, V6730, P1, DOI 10.1007/978-3-642-24556-5_1
   Thirunavukkarasu V, 2018, WIRELESS PERS COMMUN, V98, P3039, DOI 10.1007/s11277-016-3941-1
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Ustubioglu B, 2016, IMAGING SCI J, V64, P215, DOI 10.1080/13682199.2016.1162922
   Walia S., 2017, INT J COMPUT INTELL, V1, P240
   Walia S., 2017, INT C NEXT GEN COMP, P469
   Walia S, 2019, AUST J FORENSIC SCI, V51, P488, DOI 10.1080/00450618.2018.1424241
   Wang W, 2010, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2010.5652660
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
NR 40
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4517
EP 4532
DI 10.1007/s11042-022-13610-8
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000832844000011
DA 2024-07-18
ER

PT J
AU Zhai, ZL
   Yao, LY
   Sun, X
   Zhang, X
AF Zhai, ZhengLi
   Yao, LuYao
   Sun, Xia
   Zhang, Xin
TI Multi-objective salient detection combining FCN and ESP modules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Fully convolutional network; Jump connection;
   ESP module
AB With the explosive growth of image data, image processing becomes more and more important. Salient object detection is one of the important research directions in image processing. At present, a variety of research methods have been used to detect salient objects, but the low-level features used by traditional salient detection methods are not robust to complex scenes. Fully Convolutional Network (FCN) shows good performance in image processing, but there are some shortcomings such as the ambiguous edge of salient object detection. To solve the problem of boundary fuzzy, a multi-objective salient detection method combining FCN and ESP (Efficient Spatial Pyramid) modules is proposed, which also uses different jump connection methods to obtain more low-level features to accurately define the boundary of multi-objective salient objects. In the experiment, we use the MITSceneParsing dataset to train and test the model. Compared with the related models in accuracy and MIOU, the results show that the improved network has higher accuracy and more accurate boundary information while ensuring that the processing time of the model does not increase.
C1 [Zhai, ZhengLi; Yao, LuYao; Sun, Xia; Zhang, Xin] Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266520, Peoples R China.
C3 Qingdao University of Technology
RP Zhai, ZL (corresponding author), Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266520, Peoples R China.
EM zzl@qut.edu.cn
RI bai, yu/KHU-2608-2024
OI Zhai, ZhengLi/0000-0001-5041-1447
FU National Natural Science Foundation of China [61502262]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61502262.
CR Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Fareed MMS, 2015, J VIS COMMUN IMAGE R, V32, P144, DOI 10.1016/j.jvcir.2015.08.002
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ling, 2019, RADIOENGINEERING, V49, P575
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Peng, 2018, RES RECOGNITION ALGO
   Wang, 2019, COMPUT APPL SOFT, V36, P214
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang X, 2016, IEEE IMAGE PROC, P1042
   Wang Y, 2019, DIANZI JISHU YINGYON, V45, P23
NR 19
TC 0
Z9 0
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4405
EP 4417
DI 10.1007/s11042-022-13607-3
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000830266300001
DA 2024-07-18
ER

PT J
AU Kumar, V
   Pathak, V
   Badal, N
   Pandey, PS
   Mishra, R
   Gupta, SK
AF Kumar, Vinod
   Pathak, Vinay
   Badal, Neelendra
   Pandey, Purnendu Shekhar
   Mishra, Rajesh
   Gupta, Sachin Kumar
TI Complex entropy based encryption and decryption technique for securing
   medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Medical image; Encryption; Decryption; Modified Arnold map
   encryption; NPCR
ID SCHEME
AB During medical picture transmission, the most pressing concern is security. Medical images must be encrypted since they are extremely sensitive. Watermarking, digital fingerprinting/signature, and encoding are some of the available image security techniques. Images and movies, for example, must be highly encrypted and decoded without losing any content information. Medical photos, for example, require extra protection, and protecting medical images is a critical issue when medical images and related patient information are transferred over public networks. This research work proposes a visual encryption strategy to secure medical pictures before being transmitted or stored in the cloud. This technique makes such pictures of unauthorized people unavailable and also maintains confidentiality, a prime safety requirement. The process made use of a pixel shuffling-based encryption technique and a secret key created from the image. In this research, we encrypted the medical image using modified Arnold Map Encryption and generated secret key values. Therefore, the image is encrypted, and henceforth it is decrypted as well. So this work gave us the encrypted image and decrypted image/original image as well. The modified Arnold Map Encryption tries to add more randomness, thus increasing the entropy of the image and thus makes it harder to decrypt. The modified Arnold Map Encryption is also compared to other algorithms such as Hyper Chaotic, Secure Hash Algorithm-13 (SHA-13), Ten Logistic Maps, Bakers Map, HenonMap, Cross Chaos Map, and 2D Logistic Map and shows better results in terms of encryption speed and Number of Pixel Change Rate (NPCR) value.
C1 [Kumar, Vinod] OP Jindal Univ, Comp Sci & Engn Dept, Raigarh 496109, Chhattisgarh, India.
   [Kumar, Vinod] Dr APJ Abdul Kalam Tech Univ, Comp Sci & Engn Dept, Lucknow 226031, Uttar Pradesh, India.
   [Pathak, Vinay] Galgotia Coll Engn & Technol, Comp Sci & Engn Dept, Greater Noida 201310, India.
   [Badal, Neelendra] Kamla Nehru Inst Technol, Comp Sci & Engn Dept, Sultanpur 228118, Uttar Pradesh, India.
   [Pandey, Purnendu Shekhar] KIET, Comp Sci & Engn Dept, Grp Inst, Ghaziabad 201206, Uttar Pradesh, India.
   [Mishra, Rajesh] Gautam Buddha Univ, Elect Engn Dept, Greater Noida 201308, India.
   [Gupta, Sachin Kumar] Shri Mata Vaishno Devi Univ, Sch Elect & Commun Engn, Katra 182320, Jammu & Kashmir, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Galgotias College of
   Engineering & Technology (GCET); Kamla Nehru Institute of Technology
   Sultanpur; KIET Group of Institutions; KIET School of Engineering &
   Technology; Gautam Buddha University; Shri Mata Vaishno Devi University
RP Kumar, V (corresponding author), OP Jindal Univ, Comp Sci & Engn Dept, Raigarh 496109, Chhattisgarh, India.; Kumar, V (corresponding author), Dr APJ Abdul Kalam Tech Univ, Comp Sci & Engn Dept, Lucknow 226031, Uttar Pradesh, India.; Gupta, SK (corresponding author), Shri Mata Vaishno Devi Univ, Sch Elect & Commun Engn, Katra 182320, Jammu & Kashmir, India.
EM vinod242306@gmail.com; vinaypathak85@gmail.com; n_badal@hotmail.com;
   shekhar.rockwell@gmail.com; rajeshmishra25@rediffmail.com;
   sachin.gupta@smvdu.ac.in
RI Gupta, Sachin Kumar/AAX-1737-2020; kumar, Dr. vinod/IWD-4711-2023
OI Gupta, Sachin Kumar/0000-0001-8270-5853; kumar, Dr.
   vinod/0000-0002-6472-9883
CR Abdmouleh MK, 2017, PROCEDIA COMPUT SCI, V112, P369, DOI 10.1016/j.procs.2017.08.026
   Aqel M.J., 2018, International Journal of Engineering & Technology, V7, P104, DOI DOI 10.14419/IJET.V7I3.13.16334
   Avudaiappan T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1053-z
   Blesswin AJ, 2013, INT CONF ADV COMPU, P560, DOI 10.1109/ICoAC.2013.6922012
   DIFFIE W, 1979, P IEEE, V67, P397, DOI 10.1109/PROC.1979.11256
   Elshamy AM, 2016, OPT QUANT ELECTRON, V48, DOI 10.1007/s11082-016-0461-x
   Ghrib T., 2021, Bull. Elect. Eng. Inform, V10, P950, DOI [10.11591/eei.v10i2.2766, DOI 10.11591/EEI.V10I2.2766]
   Groza B, 2007, NINTH INTERNATIONAL SYMPOSIUM ON SYMBOLIC AND NUMERIC ALGORITHMS FOR SCIENTIFIC COMPUTING, PROCEEDINGS, P182, DOI 10.1109/SYNASC.2007.61
   Gupta S., 2019, INT CONF COMPUT, P1, DOI DOI 10.1109/icccnt45670.2019.8944826
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   Kester Quist-Aphetsi, 2013, International Journal of Computer Network and Information Security, V5, P43, DOI 10.5815/ijcnis.2013.07.05
   Kester Q.-A., 2013, INT J EMERGING TECHN, V3, P496, DOI 10.5120/16500-5752.
   Kester QA, 2013, UKSIM EURO SYMP COMP, P293, DOI 10.1109/EMS.2013.51
   Krishnan Gopi S., 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P404, DOI 10.1109/ICSCCN.2011.6024584
   Kumar Vinod, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012075
   Kumar V, 2021, MOD PHYS LETT B, V35, DOI 10.1142/S0217984921501207
   Li WJ, 2019, J INF SECUR APPL, V47, P1, DOI 10.1016/j.jisa.2019.03.019
   Mallouli F, 2019, 2019 6TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (IEEE CSCLOUD 2019) / 2019 5TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (IEEE EDGECOM 2019), P173, DOI 10.1109/CSCloud/EdgeCom.2019.00022
   Mansouri A, 2021, VISUAL COMPUT, V37, P189, DOI 10.1007/s00371-020-01791-y
   Mohanty SN, 2020, FUTURE GENER COMP SY, V102, P1027, DOI 10.1016/j.future.2019.09.050
   Murugesan A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3990
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Prusty Agyan Kumar, 2013, 2013 International Conference on Advanced Computing and Communication Systems (ICACCS), P1, DOI 10.1109/ICACCS.2013.6938729
   Rashid Aabid, 2019, Security, Privacy, and Anonymity in Computation, Communication, and Storage. 12th International Conference, SpaCCS 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11611), P427, DOI 10.1007/978-3-030-24907-6_32
   Rohini Shrikhande, 2010, International Journal of Applied Engineering Research, V1, P536
   Sarmah DK, 2020, OPTIMIZATION MODELS, P33, DOI DOI 10.1007/978-3-030-42044-4_2
   Sharma D, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4114
   Somaraj S., 2014, INT J COMPUTER APPL, V104, P30, DOI DOI 10.5120/18184-9079
   Tahat N, 2020, J DISCRET MATH SCI C, V23, P935, DOI 10.1080/09720529.2020.1734293
   Varma C., 2018, 2018 International Conference on Current Trends towards Converging Technologies, P1
NR 30
TC 6
Z9 6
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37441
EP 37459
DI 10.1007/s11042-022-13546-z
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000830266500006
PM 35912061
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Elsaid, SA
   Alotaibi, ER
   Alsaleh, S
AF Elsaid, Shaimaa Ahmed
   Alotaibi, Esa R.
   Alsaleh, Shoroog
TI A robust hybrid cryptosystem based on DNA and Hyperchaotic for images
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid cryptosystem; DNA encryption; Henon map; Logistic map;
   Hyperchaotic
ID SEQUENCE OPERATION; ALGORITHM; CHAOS; MAP; PERMUTATION; SECURE
AB Most existent DeoxyriboNucleic Acid (DNA) based cryptosystems suffer from low processing capability and need submitting a long key. This article provides a robust cryptosystem which depends on both DNA and Hyperchaotic encryption techniques to solve the drawbacks of using DNA technique. The proposed algorithm uses a hyperchaotic system which hypers between 3D Henon map and 1D Logistic to generate a greater key space than that generated by using either one. This system has high security and efficiency to produce secret keys for diffusion in the DNA encryption. After that data is encoded exploiting the hypothesis of traditional cryptography, DNA Digital coding, and the advancements of DNA synthesis. Test results prove that the proposed algorithm has large key space (up to 10(84)) which provides a high resistance against attack of exhaustion, strong sensitivity of encryption key, and good statistical characteristics. Compared to other existing techniques, the proposed algorithm is extremely secure against differential attack and Chosen/Known plaintext attack. Also, the execution time of the proposed cryptosystem is convenient for different applications.
C1 [Elsaid, Shaimaa Ahmed; Alsaleh, Shoroog] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Elsaid, Shaimaa Ahmed] Zagazig Univ, Fac Engn, Elect & Commun Dept, Zagazig, Egypt.
   [Alotaibi, Esa R.] Air Def Forces, Riyadh, Saudi Arabia.
C3 Princess Nourah bint Abdulrahman University; Egyptian Knowledge Bank
   (EKB); Zagazig University
RP Elsaid, SA (corresponding author), Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.; Elsaid, SA (corresponding author), Zagazig Univ, Fac Engn, Elect & Commun Dept, Zagazig, Egypt.
EM saelsaid29@gmail.com
OI , shaimaa Ahmed/0000-0001-7589-5513
FU Deanship of scientific research at Princess Nourah bint Abdulrahman
   University [RGP-1440-0013]
FX This work was funded by the Deanship of scientific research at Princess
   Nourah bint Abdulrahman University, through the Research Groups Program
   Grant no. (RGP-1440-0013).
CR Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], KAGGLE DATASET CT IM
   [Anonymous], NFBS DATABASE MRI DA
   [Anonymous], CALTECH 256 DATASET
   [Anonymous], GREYSCALE SET 2 GRAY
   Awad, NEW CHAOS BASED CRYP
   Çavusoglu U, 2018, NONLINEAR DYNAM, V92, P1745, DOI 10.1007/s11071-018-4159-4
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   El-said SA, 2011, INT J SIGNAL PROCESS, V4
   El-said SA, 2010, INT J COMPUT SCI SEC, V4
   El-Said SA, 2011, INT J INTELL ENG INF, V1, P213, DOI 10.1504/IJIEI.2011.044095
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hanchinamani G., 2014, INT J COMP APPL, DOI 10.5120/16839-6690
   Hassan AKA, 2016, INT J ADV COMPUT SC, V7, P37
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Kessler G.C., An Overview of Cryptography
   Khan FA, 2017, J INTELL FUZZY SYST, V33, P3753, DOI 10.3233/JIFS-17656
   Khan JS, 2017, INFORMATICA-LITHUAN, V28, P629, DOI 10.15388/Informatica.2017.149
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Li YT, 2017, NEURAL COMPUT APPL, V28, P1405, DOI 10.1007/s00521-015-2158-7
   Liu HJ, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164925
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Maniyath S. R., 2016, COMPUSOFT, V5, P2036
   Menezes A., 1996, Cryptography
   Nichat Shubhangini P, 2013, INT J ADV RES COMPUT, V1
   Ning K, 2009, ARXIV PREPRINT ARXIV
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Rakheja P, 2019, J MOD OPTIC, V66, P799, DOI 10.1080/09500340.2019.1574037
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Sanjay K. R., 2019, J. Amb. Intell. Hum. Comput., V10, P1
   Savi MA, 2007, PHYS LETT A, V364, P389, DOI 10.1016/j.physleta.2006.11.095
   Tornea, 2013, CONTRIBUTIONS DNA CR
   Wang X., 2017, Multifunctional Land-Use Systems for Managing the Nexus of Environmental Resources, V1st ed., P11, DOI [10.1007/978-3-319-54957-62, DOI 10.1007/978-3-319-54957-62, 10.1007/978-3-319-54957-6_2, DOI 10.1007/978-3-319-54957-6_2]
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yin, 2013, ADVANC INTELL SYST C, P212, DOI [10.1007/978-3-642-37502-6_38, DOI 10.1007/978-3-642-37502-6_38]
   Yoon JW, 2010, COMMUN NONLINEAR SCI, V15, P3998, DOI 10.1016/j.cnsns.2010.01.041
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhu CJ, 2020, MULTIMED TOOLS APPL, V79, P7227, DOI 10.1007/s11042-019-08226-4
NR 52
TC 9
Z9 9
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1995
EP 2019
DI 10.1007/s11042-022-12641-5
EA JUN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000811988200002
DA 2024-07-18
ER

PT J
AU Mathias, A
   Dhanalakshmi, S
   Kumar, R
AF Mathias, Ajisha
   Dhanalakshmi, Samiappan
   Kumar, R.
TI Occlusion aware underwater object tracking using hybrid adaptive deep
   SORT-YOLOv3 approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Underwater object tracking; YOLO v3; Deep SORT;
   Long-short term memory
AB Underwater object tracking and recognition are challenging due to the distinctive characteristics of underwater environments. The water medium exhibits diffraction and scattering of light when it travels deep in the water. This results in unclear, occluded videos and images further causing challenges in interpretation. Tracking the object of interest from the consecutive frames in underwater scenarios often lead to occlusion of objects. Addressing these issues, an improved hybrid adaptive deep SORT-YOLOv3 (HADSYv3) detection and tracking scheme for occluded underwater objects is proposed. The neural network-based training model YOLOv3 is applied to extract and categorize the underwater object. An adaptive deep SORT algorithm with the long-short term memory (LSTM) based deep learning approach is used to determine the position of the objects in the underwater sequences. The proposed Hybrid Adaptive DeepSORT-YOLOv3 (HADSYv3) method incorporates both the YOLOv3 algorithm meant for object detection and the adaptive deep SORT algorithm for tracking applications. Though the deep SORT algorithm track objects in real time applications standalone, if it gets combined with suitable detection schemes, the overall efficiency can be improved by confirming all the possible detections. The proposed method is compared with other state of art underwater object recognition schemes and the occluded object detection for various view angles is evaluated quantitatively.
C1 [Mathias, Ajisha; Dhanalakshmi, Samiappan; Kumar, R.] SRM Inst Sci & Technol SRM Nagar, Coll Engn & Technol, Dept Elect & Commun Engn, Chennai 603203, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Dhanalakshmi, S (corresponding author), SRM Inst Sci & Technol SRM Nagar, Coll Engn & Technol, Dept Elect & Commun Engn, Chennai 603203, Tamil Nadu, India.
EM dhanalas@srmist.edu.in
RI Mathias, Ajisha/GZK-2660-2022; Dhanalakshmi, S./J-2073-2018
OI Mathias, Ajisha/0000-0002-2212-1490; Dhanalakshmi,
   S./0000-0002-6970-2719
CR [Anonymous], NOAA DATASET
   [Anonymous], FISH KNOWLEDGE DATA
   [Anonymous], 2014, P 3 ACM INT WORKSHOP
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Dhanalakshmi, 2013, INT REV COMPUTERS SO, V8
   Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278
   Hou GJ, 2016, J COASTAL RES, V32, P1135, DOI 10.2112/JCOASTRES-D-14-00249.1
   Hsiao YH, 2014, ECOL INFORM, V23, P13, DOI 10.1016/j.ecoinf.2013.10.002
   Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42
   Kim B, 2017, IEEE UNDERWATER TECH
   Lee D, 2012, OCEAN ENG, V48, P59, DOI 10.1016/j.oceaneng.2012.04.006
   Lee H, 2016, IEEE IMAGE PROC, P3713, DOI 10.1109/ICIP.2016.7533053
   Li X, 2015, OCEANS 2015 MTS IEEE, P1
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Mahmood A, 2016, IEEE IMAGE PROC, P519, DOI 10.1109/ICIP.2016.7532411
   Mathias A, 2021, ECOL INFORM, V66, DOI 10.1016/j.ecoinf.2021.101469
   Mathias A, 2022, CMC-COMPUT MATER CON, V70, P5251, DOI 10.32604/cmc.2022.021168
   Mathias A, 2019, OPTIK, V192, DOI 10.1016/j.ijleo.2019.06.025
   Nikolovska A, 2015, OCEANS 2015 - GENOVA, DOI 10.1109/OCEANS-Genova.2015.7271651
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Ravanbakhsh M, 2015, PHOTOGRAMM REC, V30, P46, DOI 10.1111/phor.12091
   Samiappan D, 2016, INT ARAB J INF TECHN, V13, P756
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44
   Vasamsetti S, 2018, IET COMPUT VIS, V12, P770, DOI 10.1049/iet-cvi.2017.0013
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yafei Zhu L, 2016, OCEANS 2016, DOI [10.1109/OCEANSAP.2016.7485598, DOI 10.1109/OCEANSAP.2016.7485598]
   Yan Z, 2014, IEEE GEOSCI REMOTE S, V11, P833, DOI 10.1109/LGRS.2013.2279485
   Yang HB, 2021, MICROSYST TECHNOL, V27, P1837, DOI 10.1007/s00542-019-04694-8
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhou HL, 2015, IEEE SYS MAN CYBERN, P430, DOI 10.1109/SMC.2015.86
NR 35
TC 9
Z9 10
U1 12
U2 82
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44109
EP 44121
DI 10.1007/s11042-022-13281-5
EA MAY 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000803780600004
DA 2024-07-18
ER

PT J
AU Cui, XT
   Xiao, J
   Cao, Y
   Zhu, J
AF Cui, Xiaotao
   Xiao, Jing
   Cao, Yang
   Zhu, Jia
TI Multi-grained encoding and joint embedding space fusion for video and
   text cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-grained encoding; Joint embedding space fusion; Cross-modal
   retrieval; Zero-example video retrieval
ID IMAGE
AB Video-text cross-modal retrieval is significant to computer vision. Most of existing works focus on exploring the global similarity between modalities, but ignore the influence of details on retrieval results. How to explore the correlation between different forms of data from multiple angles is a key issue. In this paper, we propose a Multi-grained Encoding and Joint Embedding Spaces Fusion (MEJESF) for video-text cross-modal retrieval. Specifically, we propose a novel dual encoding network to explore not only coarse-grained feature but also fine-grained feature of modals. At the same time, giving considerations to multiple encoding and hard sample mining, a modified pairwise ranking loss function is introduced. After that, we build two joint embedding spaces and adopt them when retrieving by fusing their scores. Experiments on two public benchmark datasets (MSR-VTT,MSVD) demonstrate that our method can obtain promising performance compared to the state-of-the-art methods in video-text cross-modal retrieval. Furthermore, our network model achieves outstanding performance in zero-example video retrieval.
C1 [Cui, Xiaotao; Xiao, Jing; Cao, Yang; Zhu, Jia] South China Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
C3 South China Normal University
RP Xiao, J (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
EM xiaojing@scnu.edu.cn
RI xiao, jing/HRB-7391-2023
FU National Natural Science Foundation of China [62177015]; Key-Area
   Research and Development Program of Guangdong Province [2019B111101001];
   Science and Technology on Information System Engineering Laboratory
   [20205250410]
FX This work was supported in part by the National Natural Science
   Foundation of China under Project No. 62177015, in part by the Key-Area
   Research and Development Program of Guangdong Province No.
   2019B111101001 and in part by the Science and Technology on Information
   System Engineering Laboratory No. WDZC 20205250410.
CR Andrew G., 2013, ICML, P1247
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen D. L., 2011, CVPR
   Chi JZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P663
   Dong, 2016, ARXIV 160406838
   Dong JF, 2019, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR.2019.00957
   Dong JF, 2018, IEEE T MULTIMEDIA, V20, P3377, DOI 10.1109/TMM.2018.2832602
   Faghri, 2017, ARXIV 170705612
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He K., IEEE I CONF COMP VIS
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   Kiros, 2014, ARXIV 14112539
   Kiros R., 2015, ADV NEURAL INFORM PR, P3294, DOI DOI 10.48550/ARXIV.1506.06726
   Li WJ, 2021, J ASSOC INF SCI TECH, V72, P46, DOI 10.1002/asi.24373
   Liu Y., 2019, ARXIV 190713487
   Markatopoulou F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P412, DOI 10.1145/3078971.3079041
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   Miech A., 2018, ARXIV 180402516
   Mithun NC, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/3206025.3206064
   Molchanov P, 2016, ARXIV 161106440
   Otani Mayu, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P651, DOI 10.1007/978-3-319-46604-0_46
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P5585, DOI 10.1109/TIP.2018.2852503
   Shen XB, 2017, IEEE T CYBERNETICS, V47, P4275, DOI 10.1109/TCYB.2016.2606441
   SOCHER R, 2010, PROC CVPR IEEE, P966, DOI DOI 10.1109/CVPR.2010.5540112
   Ueki Kazuya, 2017, TRECVID
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu R, 2015, AAAI CONF ARTIF INTE, P2346
   Xu RQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P982
   Xu X, 2020, IEEE T CYBERNETICS, V50, P2400, DOI 10.1109/TCYB.2019.2928180
   Xu X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P46, DOI 10.1145/3206025.3206033
   Xue HY, 2018, IEEE T IMAGE PROCESS, V27, P5563, DOI 10.1109/TIP.2018.2859820
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yu Y, 2018, LECT NOTES COMPUT SC, V11211, P487, DOI 10.1007/978-3-030-01234-2_29
   Yu Y, 2017, PROC CVPR IEEE, P3261, DOI 10.1109/CVPR.2017.347
   Zhang, 2017, ARXIV 171109347
   Zhang J, 2020, IEEE T CYBERNETICS, V50, P489, DOI 10.1109/TCYB.2018.2868826
   Zhuo T, 2020, IEEE T IMAGE PROCESS, V29, P237, DOI 10.1109/TIP.2019.2930152
NR 40
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34367
EP 34386
DI 10.1007/s11042-022-13048-y
EA MAY 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000802134900001
DA 2024-07-18
ER

PT J
AU Falah, A
   Pokhrel, SR
   Pan, L
   de Souza-Daw, A
AF Falah, Ahmed
   Pokhrel, Shiva Raj
   Pan, Lei
   de Souza-Daw, Anthony
TI Towards enhanced PDF maldocs detection with feature engineering: design
   challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PDF Maldoc; Concept drifts; Feature engineering; Malware evolution;
   Malware detection
AB In this paper, we perform an in-depth analysis of a large corpus of PDF maldocs to identify the key set of significantly important features and help in maldoc detection. Existing industry-based tools for the detection are inefficient and cannot prevent PDF maldocs because they are generic and depend primarily on a signature-based approach. Besides, several other methods developed by academics suffer heavily from reduced effectiveness. The feature-set using machine learning classifiers is prone to various known attacks, such as mimicry and parser confusion. Also, we discover that increasingly more malicious files i) contain evasive and obfuscated JavaScript code, ii) include hidden contents (mostly outside the objects), iii) have a corrupted document structure, and iv) usually contain short JavaScript code blocks. We utilise maldoc attacks' evolution over a decade to highlight the essential features (e.g., concept drifts) that impact detectors and classifiers.
C1 [Falah, Ahmed; Pokhrel, Shiva Raj; Pan, Lei] Deakin Univ, Melbourne, Vic, Australia.
   [de Souza-Daw, Anthony] Melbourne Polytech, Melbourne, Vic, Australia.
C3 Deakin University
RP Falah, A (corresponding author), Deakin Univ, Melbourne, Vic, Australia.
EM aa.falah@hotmail.com; shiva.pokhrel@deakin.edu.au; l.pan@deakin.edu.au;
   tonydesouza-daw@melbournepolytechnic.edu.au
RI Pan, Lei/ADH-0321-2022; Pokhrel, Shiva/L-1160-2019; Pan,
   Lei/ITT-0556-2023
OI Pan, Lei/0000-0002-4691-8330; Pokhrel, Shiva/0000-0001-5819-765X; Pan,
   Lei/0000-0002-4691-8330; Falah, Ahmed/0000-0001-6359-8570
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Adobe Systems Incorporated, 2007, JAV TM ACR AP REF
   Carlin D, 2019, COMPUT SECUR, V85, P138, DOI 10.1016/j.cose.2019.04.018
   Carmony C, 2016, NDSS, P115
   Dang H, 2017, P 2017 ACM SIGSAC C
   Ding YX, 2019, COMPUT SECUR, V87, DOI 10.1016/j.cose.2019.101574
   Ehteshamifar S, 2019, ARXIV 190105674
   Endignoux G, 2016, 2016 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2016), P126, DOI 10.1109/SPW.2016.39
   Falah A, 2021, FUTURE GENER COMP SY, V115, P314, DOI 10.1016/j.future.2020.09.015
   Falah A, 2018, COMM COM INF SC, V878, P128, DOI 10.1007/978-3-319-94421-0_10
   Jordan A, 2018, ARXIV 181012490
   Li MZ, 2017, IEEE TRUST BIG, P218, DOI 10.1109/Trustcom/BigDataSE/ICESS.2017.240
   Liu D, 2014, DEPENDABLE SYSTEMS N
   Maiorca D, 2015, INFORM SYSTEMS SECUR, P2736
   Maiorca Davide., 2013, P 8 ACM SIGSAC S INF, P119, DOI DOI 10.1145/2484313.2484327
   Metasploit, 2013, COOL PDF IM STREAM R
   Nath HV, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, INFORMATICS, COMMUNICATION AND ENERGY SYSTEMS (SPICES)
   Nissim Nir, 2016, Security Informatics, V5, DOI 10.1186/s13388-016-0026-3
   Nissim N, 2015, COMPUT SECUR, V48, P246, DOI 10.1016/j.cose.2014.10.014
   Paccanaro A, 2002, ADV NEUR IN, V14, P857
   Pontiroli SM, 2015, VIRUS B C, P126
   rndi N, 2014, SECURITY PRIVACY SP
   Scofield D, 2017, PROCEEDINGS OF THE 7TH SOFTWARE SECURITY, PROTECTION, AND REVERSE ENGINEERING WORKSHOP 2017 (SSPREW), DOI 10.1145/3151137.3151142
   Singh P, 2020, INF SECUR J, V29, P134, DOI 10.1080/19393555.2020.1723747
   Smutz C, 2012, P 28 ANN COMPUTER SE
   Smutz C, 2016, NDSS, P115
   Srndic N, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0045-0
   Wust Karl, 2017, Digital Investigation, V20, pS75, DOI 10.1016/j.diin.2017.01.009
   Xu M, 2017, USENIX SECURITY S
   Xu W, 2016, NDSS, P2124
NR 29
TC 1
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41103
EP 41130
DI 10.1007/s11042-022-11960-x
EA MAY 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000796326500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Ozcelik, IM
   Ersoy, C
AF Ozcelik, Ihsan Mert
   Ersoy, Cem
TI An SDN-aided low-latency live video streaming over HTTP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Live streaming; Low-latency; CMAF; Adaptive video bitrate control; QoE;
   DASH
AB Dynamic adaptive streaming over HTTP (DASH) is the crucial factor in the rapid penetration of over-the-top (OTT) service providers for on-demand video streaming. It can also be used for live video streaming by the OTT providers. The recent advancements of the HTTP chunked transfer, and the Common Media Application Format (CMAF) echo this tendency, which introduces the possibility to deliver a video segment by small chunks before the full segment is generated. It can deliver live latency of three seconds or less on a conventional DASH player with a small buffer capacity less than the target live latency. However, legacy bitrate adaptation mechanisms inaccurately measure the available bandwidth due to idle times between the chunks at the encoder side. To resolve this problem, we utilize the Software-Defined Networking (SDN) paradigm that directly provides the network statistics with the available bandwidth. We, then, propose an SDN-assisted bitrate adaptation mechanism for live streaming with HTTP 1.1 Chunked Transfer of CMAF packages while keeping the coexistence with the legacy DASH clients. Our SDN-based central framework asynchronously sends the video bitrate levels by continuously monitoring the background traffic flows and the available capacity for DASH clients on the same shared bottleneck link. Results show that our proposed mechanism achieves a lower video freeze rate and provides a better quality-of-experience while reducing the live latency down to about three seconds in the existence of varying background traffic.
C1 [Ozcelik, Ihsan Mert; Ersoy, Cem] Bogazici Univ, Istanbul, Turkey.
C3 Bogazici University
RP Ozcelik, IM (corresponding author), Bogazici Univ, Istanbul, Turkey.
EM mert.ozcelik@boun.edu.tr; ersoy@boun.edu.tr
RI Ersoy, Cem/G-9218-2011
OI Ersoy, Cem/0000-0001-7632-7067; Ozcelik, Ihsan Mert/0000-0002-6641-8544
CR Akamai, 2019, ULTRALOW LATENCY STR
   Bentaleb A, 2019, PROCEEDINGS OF THE 29TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'19), P7, DOI 10.1145/3304112.3325611
   Bentaleb A, 2017, IEEE T MULTIMEDIA, V19, P2136, DOI 10.1109/TMM.2017.2733344
   Cisco, 2016, WHITE PAPER CISCO VN, P2015
   Claeys M, 2014, IEEE COMMUN LETT, V18, P716, DOI 10.1109/LCOMM.2014.020414.132649
   El Essaili A, 2018, IEEE INT SYM BROADB
   Forum, 2017, DASH REF PLAYER
   FTP, 2012, COMM FLOODL IS OP SO
   Go SJY, 2019, J NETW COMPUT APPL, V132, P49, DOI 10.1016/j.jnca.2019.01.026
   He K., 2015, Proceedings of the 1st ACM SIGCOMM Symposium on Software Defined Networking Research, P25
   Jiang JY, 2018, MULTIMED TOOLS APPL, V77, P10787, DOI 10.1007/s11042-017-4917-1
   Kleinrouweler JW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092838
   Le HT, 2018, SIGNAL PROCESS-IMAGE, V65, P154, DOI 10.1016/j.image.2018.03.014
   Lindholm J, 2019, INT SPORTS LAW J, V18, P99, DOI 10.1007/s40318-019-00145-8
   Ozcelik IM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3337681
   Ozcelik IM, 2020, IEEE COMMUN LETT, P1
   Petrangeli S, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3165266
   Qian Y, 2018, 2018 IEEE GLOBAL COM, P17
   Sobhani A, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052822
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Spiteri K, 2016, IEEE INFOCOM 2016 TH, P19
   Spiteri K, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3336497
   Team M, 2012, Mininet an instant virtual network on your laptop (or other PC)
   Tirumala A, 2017, IPERF TCPUDP BANDWID
   van der Hooft J, 2018, J NETW SYST MANAG, V26, P51, DOI 10.1007/s10922-017-9407-2
   Wang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2642, DOI 10.1145/3343031.3356069
   Wei B, 2019, IEEE ACCESS, V7, P51346, DOI 10.1109/ACCESS.2019.2909399
   Yahia MB, ACM T MULTIM COMPUT, V15
   Yi G, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2622, DOI 10.1145/3343031.3356083
NR 29
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23145
EP 23162
DI 10.1007/s11042-022-12389-y
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000795177900014
DA 2024-07-18
ER

PT J
AU Xia, HY
   Wu, LY
   Lan, Y
   Li, HS
   Song, SX
AF Xia, HaiYing
   Wu, LingYu
   Lan, Yang
   Li, HaiSheng
   Song, ShuXiang
TI HRNet:A hierarchical recurrent convolution neural network for retinal
   vessel segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal vessel segmentation; Convolution neural network; U-Net; ResNet
ID MATCHED-FILTER; BLOOD-VESSELS; IMAGES; GABOR
AB The extraction of retinal vessel is of great importance in the diagnosis of fundus disease. Many approaches have been proposed for vessel segmentation. However, these models have some drawbacks. First, the encoder-decoder structures, U-Net i.e., will generate redundant information during successive convolution and sampling operations. Second, most methods only have feedforward process, and the feedback is also crucial for contextual feature representations from high to low layers. In this article, we overcome these limitations by proposing a hierarchical recurrent convolution neural network (HRNet). The proposed HRNet first integrates the advantage of the ResNet and Squeeze and Excitation (SE) to build SE-residual block in multi-scale layers, which capture the important channel-wise information and remove the redundant feature in deep network. Further, we design a hierarchical recurrent(feedback) mechanism to explore features from different upper to the lower layer by adding the output of each layer to its corresponding encoding layer iteratively. The feedback path encourages the feature reuse to improve the power of weak retinal vessel detection. Comprehensive experiments on three public retinal datasets (DRIVE, STARE and CHASE) demonstrate that the proposed HRNet is superior or equivalent to the state-of-art methods in terms of most of the indicators, including accuracy, F1-Score, sensitivity.
C1 [Xia, HaiYing; Wu, LingYu; Lan, Yang; Li, HaiSheng; Song, ShuXiang] Guangxi Normal Univ, Coll Elect Engn, 15 Yucai Rd, Guilin 541004, Peoples R China.
C3 Guangxi Normal University
RP Song, SX (corresponding author), Guangxi Normal Univ, Coll Elect Engn, 15 Yucai Rd, Guilin 541004, Peoples R China.
EM songshuxiang@mailbox.gxnu.edu.cn
FU National Natural Science Foundation of China [61762014, 61762012];
   Science and Technology Project of Guangxi [2018JJA170083, 2018JJA170089]
FX This work is supported by the National Natural Science Foundation of
   China under grant nos. 61762014 and 61762012, the Science and Technology
   Project of Guangxi under grant nos. 2018JJA170083 and 2018JJA170089.
CR Akram MU, 2013, ENG COMPUT-GERMANY, V29, P165, DOI 10.1007/s00366-011-0253-7
   Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Al-Rawi M, 2007, COMPUT METH PROG BIO, V87, P248, DOI 10.1016/j.cmpb.2007.05.012
   Al-Rawi M, 2007, COMPUT BIOL MED, V37, P262, DOI 10.1016/j.compbiomed.2006.03.003
   Alom M. Z., 2018, ARXIV 180206955
   Asadi, 2020, ARXIV
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Can A, 1999, IEEE Trans Inf Technol Biomed, V3, P125, DOI 10.1109/4233.767088
   Chang B, 2018, ARXIV 170903698
   Chen, 2017, ARXIV 170407502
   Franklin SW, 2014, APPL SOFT COMPUT, V22, P94, DOI 10.1016/j.asoc.2014.04.024
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Han D, 2017, DEEP PYRAMIDAL RESID
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Li QL, 2016, IEEE T MED IMAGING, V35, P109, DOI 10.1109/TMI.2015.2457891
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   LIU IC, 1993, IEEE T MED IMAGING, V12, P334, DOI 10.1109/42.232264
   Long J, 2015, P IEEE C COMPUTER VI, P13440
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Oliveira WS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149943
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Pinheiro Pedro., 2014, International conference on machine learning. PMLR, P82
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Poudel RPK, 2017, LECT NOTES COMPUT SC, V10129, P83, DOI 10.1007/978-3-319-52280-7_8
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Sasaki Y., 2007, Teach Tutor Mater, V1, P1
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Valipour S, 2017, IEEE WINTER C APPL C
   Visin F, 2016, P IEEE CVPRW, P4148
   Vlachos M, 2010, COMPUT MED IMAG GRAP, V34, P213, DOI 10.1016/j.compmedimag.2009.09.006
   Wang B, 2019, LECT NOTES COMPUT SC, V11764, P84, DOI 10.1007/978-3-030-32239-7_10
   Wang W, 2019, ARXIV 200106807
   Wu Y, 2018, INT C MEDICAL IMAGE, P19126, DOI [10.1007/978-3-030-00934-214, DOI 10.1007/978-3-030-00934-214]
   Wu Y, 2019, INT C MEDICAL IMAGE
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhang YS, 2018, LECT NOTES COMPUT SC, V11071, P83, DOI 10.1007/978-3-030-00934-2_10
   Zhao Y, 2015, AUTOMATED VESSEL SEG, V34
   Zhu Chengzhang, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P445
   Zhuang J., 2018, arXiv
NR 51
TC 4
Z9 4
U1 7
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39829
EP 39851
DI 10.1007/s11042-022-12696-4
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000790129700004
DA 2024-07-18
ER

PT J
AU Jung, M
   Lee, S
   Sim, ES
   Jo, MH
   Lee, YJ
   Choi, HB
   Kwon, J
AF Jung, Minjoon
   Lee, Seunghyun
   Sim, Eun Seon
   Jo, Min Ho
   Lee, Yu Jin
   Choi, Hye Bin
   Kwon, Junseok
TI Stagemix video generation using face and body keypoints detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Stagemix video; Video preprocessing
AB Playing multiple stage videos of a particular singer as if they are one is called Stagemix video. The consumption of video media has increased recently, and the demand for video editing has also increased. Stagemix videos have gained popularity in various communities, and a number of YouTubers who upload videos with cross-cuts are appearing. In this work, we introduce a novel task, Stagemix video generation. Stagemix video generation requires considerable time and skillful editing skills. To address this, we suggest a method of auto-generating Stagemix video, a novel technique that plays multiple stage videos of a particular singer as if they are one. Our novel methods automatically generate a Stagemix video and improve performance with face or body keypoints which is extracted by CNN-based extractor. Quantitative differences between frames and creation time show that our methods effectively produce a natural video.
C1 [Jung, Minjoon] Seoul Natl Univ, Seoul, South Korea.
   [Lee, Seunghyun] Univ Seoul, Seoul, South Korea.
   [Sim, Eun Seon] Konkuk Univ, Seoul, South Korea.
   [Jo, Min Ho] Sogang Univ, Seoul, South Korea.
   [Lee, Yu Jin; Choi, Hye Bin] Ewha Womans Univ, Seoul, South Korea.
   [Kwon, Junseok] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Seoul National University (SNU); University of Seoul; Konkuk University;
   Sogang University; Ewha Womans University; Chung Ang University
RP Kwon, J (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM mjjung@bi.snu.ac.kr; easter3163@naver.com; dmstjs8808@gmail.com;
   tcvl1222@gmail.com; daebaq27@gmail.com; hyebly9117@gmail.com;
   jskwon@cau.ac.kr
OI kwon, junseok/0000-0001-9526-7549
CR Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Gabeur Valentin, 2020, P EUR C COMP VIS, V12349, P214, DOI [10.48550/arXiv.2007.10639, DOI 10.48550/ARXIV.2007.10639]
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiao YF, 2018, IEEE T MULTIMEDIA, V20, P2693, DOI 10.1109/TMM.2018.2815998
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiong B, 2019, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2019.00135
   Yu Y, 2018, AAAI CONF ARTIF INTE, P7525
NR 11
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38531
EP 38542
DI 10.1007/s11042-022-13103-8
EA APR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139200004
DA 2024-07-18
ER

PT J
AU Yuan, HY
   Cheng, JP
   Wu, YR
   Zeng, ZY
AF Yuan, Haiying
   Cheng, Junpeng
   Wu, Yanrui
   Zeng, Zhiyong
TI Low-res MobileNet: An efficient lightweight network for low-resolution
   image classification in resource-constrained scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-resolution features; Image classification; Depthwise separable
   convolutions; Lightweight network
ID CONVOLUTIONAL NEURAL-NETWORK
AB The convolutional neural networks (CNNs) deployed on devices for visual image processing faces the thorny problems on high system real-time requirements and resource consumption. A high-performance Low-res MobileNet model is constructed to effectively alleviate the high computing resources and storage costs in the real-time image processing. The main works are summarized as: (1) To actively match the input of low-resolution feature map, the MobileNetV2 is further optimized by clipping to simplify the network structure and improve the efficiency of image recognition. (2) To improve the classification accuracy, the Inception structure is used to fill the Dwise layer in depthwise separable convolution to extract more abundant low-resolution features; the activation function during the process of increasing the dimension is replaced to avoid the loss of useful information; Inter-layer connection structure is adopted to strengthen the fusion of feature information between layers. (3) To reduce the network scale, the gradually decreasing expansion factors are used to remove the redundant structure of the model. Subsequently, the Low-res MobileNet is validated and evaluated through data sets of different scales. The experimental results show that this model has smaller scale, less computation and higher classification accuracy compared with other CNN models. The model has 0.36 M parameters and 25.46 M floating point of operations (FLOPs), which is easy to deploy to resource-constrained mobile and embedded devices. The model runs at 35 batches per second, and it achieves an accuracy rate of 89.38%, 71.60%, and 87.08% on CIFAR-10, CIFAR-100, and CINIC-10 datasets, respectively, which is basically suitable for real-time image classification task applied in low-resolution application scenarios.
C1 [Yuan, Haiying; Cheng, Junpeng; Wu, Yanrui; Zeng, Zhiyong] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Yuan, HY (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM yhycn@126.com
OI Yuan, Haiying/0000-0003-1602-8078
FU National Natural Science Foundation of China [61001049]; Beijing Natural
   Science Foundation [4172010]
FX This research work was supported by National Natural Science Foundation
   of China (61001049) and Beijing Natural Science Foundation (4172010).
CR Bai L, 2021, IEEE T CIRCUITS-I, V68, P704, DOI 10.1109/TCSI.2020.3038139
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Darlow Luke N, 2018, ARXIV181003505
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Howard, 2019, APPL INTELL, V50, P107
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   LIN MT, 2014, DTIP 2014 S DES TEST, P1
   Lobov SA, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00088
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Sakib S, 2021, IEEE ACCESS, V9, P26093, DOI 10.1109/ACCESS.2021.3056509
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang SM, 2019, IEEE T CYBERNETICS, V49, P2490, DOI 10.1109/TCYB.2018.2823730
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zhou N, 2021, IEEE ACCESS, V9, P5573, DOI 10.1109/ACCESS.2020.3046715
NR 34
TC 6
Z9 6
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38513
EP 38530
DI 10.1007/s11042-022-13157-8
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787130200001
DA 2024-07-18
ER

PT J
AU Shi, H
   Li, YN
   Hu, BY
   Chen, MH
   Ren, YG
AF Shi, Hui
   Li, Yanni
   Hu, Baoyue
   Chen, Meihan
   Ren, Yonggong
TI A robust and secure zero-watermarking copyright authentication scheme
   based on visual cryptography and block G-H feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermarking; Visual cryptography; LT code; G-H feature extraction;
   Robustness; Security
ID DIGITAL RIGHTS MANAGEMENT; TRANSFORM
AB Zero-watermarking is a distortion-free technique for copyright protection and has become a research hotspot in the field of digital watermarking. In the face of weak robustness and security of existing schemes, this paper proposes a robust and security zero-watermarking scheme for copyright protection using a combination of Visual Cryptography, LT Code, CRC, Block G-H feature, Arnold and timestamp authority. Firstly, the original image is applied with Visual Cryptography to generate two Visual Cryptography Shares. Then, extract the content feature from all blocks of the combined image by the improved G-H feature extraction scheme. To resist strong attacks, transition matrix is generated according to the relationship between the group feature mean and the overall feature mean. Next, the original watermarking image is encrypted by LT code and CRC. Finally, zero-watermarks are generated according to the transition matrix and encrypted watermarking. To promote security, Logistic mapping, Arnold and Visual cryptography are adopted. Experimental results demonstrate that the proposed scheme has adequate equalization and visibility as well as strong robustness against various attacks, such as Gaussian noise, Salt and pepper noise, media filtering, JPEG compressing, shearing, rotation and line offsetting. In addition to experimental results, robust theoretical analysis, security theoretical analysis and complexity analysis are presented to demonstrate the comprehensive performance.
C1 [Shi, Hui; Li, Yanni; Hu, Baoyue; Chen, Meihan; Ren, Yonggong] Liaoning Normal Univ, Comp & Informat Technol Coll, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Shi, H; Ren, YG (corresponding author), Liaoning Normal Univ, Comp & Informat Technol Coll, Dalian 116029, Peoples R China.
EM shihui_jiayou@126.com; ryg@lnnu.edu.cn
OI Shi, Hui/0000-0001-5029-7461
FU Scientific Research Program - Liaoning Provincial Education Department
   [WQ2020014]; Key Research Project of Dalian academy of social sciences
   [2020dlsky042]; Liaoning Planning Office of Philosophy and Social
   Science (CN) [L19BTQ001]; National Youth Science Foundation of China
   [61601214]
FX This work was supported by the Scientific Research Program Funded by
   Liaoning Provincial Education Department (Grant No. WQ2020014), the Key
   Research Project of Dalian academy of social sciences (Grant No.
   2020dlsky042), Liaoning Planning Office of Philosophy and Social Science
   (CN) (Grant L19BTQ001) and the National Youth Science Foundation of
   China(61601214).
CR [Anonymous], 2016, Kodak lossless true color image suite
   [Anonymous], 2016, UCID UNCOMPRESSED CO
   [Anonymous], 2016, USC-SIPI image database
   Anushiadevi R, 2021, MULTIMED TOOLS APPL, V80, P19695, DOI 10.1007/s11042-021-10729-y
   Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Blundo C, 2006, THEOR COMPUT SCI, V369, P169, DOI 10.1016/j.tcs.2006.08.008
   Bose M, 2010, DESIGN CODE CRYPTOGR, V55, P19, DOI 10.1007/s10623-009-9327-6
   Chidambaram N, 2021, MULTIMED TOOLS APPL, V80, P23359, DOI 10.1007/s11042-020-10210-2
   Dalal, 2002, P IEEE C COMP VIS PA, V2, P886
   Gao, 2020, MULTIMED TOOLS APPL, V80, P1
   Govind PVS, 2021, COMPUT ELECTR ENG, V89, DOI 10.1016/j.compeleceng.2020.106933
   Hu RW, 2021, IEEE T IMAGE PROCESS, V30, P318, DOI 10.1109/TIP.2020.3036727
   Jin LP, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0748-4
   Kang XB, 2020, MULTIMED TOOLS APPL, V79, P1169, DOI 10.1007/s11042-019-08191-y
   Khan S, 2019, J GRID COMPUT, V17, P239, DOI 10.1007/s10723-018-9459-x
   Li, 2018, MUE FUTURETECH, P565
   Li B, 2016, OPTIK, V127, P3489, DOI 10.1016/j.ijleo.2015.12.032
   Li M, 2019, MULTIMED TOOLS APPL, V78, P22727, DOI 10.1007/s11042-019-7560-1
   [林克正 Lin Kezheng], 2019, [小型微型计算机系统, Journal of Chinese Computer Systems], V40, P2662
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Rao YR., 2014, P 2014 INT C INF COM, DOI 10.1109/ICICES.2014.7034073
   Shaik A, 2018, PROCEDIA COMPUT SCI, V133, P385, DOI 10.1016/j.procs.2018.07.047
   Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062
   Thanh TM, 2017, MULTIMED TOOLS APPL, V76, P13455, DOI 10.1007/s11042-016-3750-2
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Weng SW, 2021, INFORM SCIENCES, V549, P13, DOI 10.1016/j.ins.2020.10.063
   Wu DY., 2020, ACTA OPT SINICA, V40, P85
   [肖振久 Xiao Zhenjiu], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P1
   [肖振久 Xiao Zhenjiu], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P288
   [熊祥光 Xiong Xiangguang], 2018, [自动化学报, Acta Automatica Sinica], V44, P160
   Yang HY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115747
   Ye Tian-yu, 2011, Acta Photonica Sinica, V40, P961, DOI 10.3788/gzxb20114006.0961
   [叶天语 Ye Tianyu], 2012, [光子学报, Acta Photonica Sinica], V41, P210
   Yu XY, 2019, IEEE ACCESS, V7, P115708, DOI 10.1109/ACCESS.2019.2936134
   Yuan DN., 2014, J IMAGE GRAPHICS, V03, P37
   Zhang LL, 2020, J OPTOELECTRONICS LA, V31, P94
   Zou BJ, 2018, MULTIMED TOOLS APPL, V77, P28685, DOI 10.1007/s11042-018-5995-4
NR 43
TC 4
Z9 4
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38019
EP 38051
DI 10.1007/s11042-022-13136-z
EA APR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700017
DA 2024-07-18
ER

PT J
AU Wang, Z
   Li, ZY
   Xiao, Y
   Liu, XW
   Hou, MZ
   Chen, SJ
AF Wang, Zheng
   Li, Zhaoying
   Xiao, Ying
   Liu, Xiaowei
   Hou, Muzhou
   Chen, Shuijiao
TI Three feature streams based on a convolutional neural network for early
   esophageal cancer identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Esophageal cancer (EC); Feature fusion; Convolutional neural networks
   (CNNs)
ID ENDOSCOPY; IMAGES
AB Esophageal cancer is the eighth most common cancer in the world. Currently, the incidence of esophageal cancer is increasing annually. Early detection of esophageal cancer can significantly improve the prognosis and quality of life of patients. However, detection of esophageal tumors remains a challenge because it depends on the experience, expertise and skills of the endoscopy physician. Early esophageal cancer can be easily misdiagnosed because the lesions are not obvious. Therefore, we propose a deep learning method based on a convolutional neural network (CNN) model for automatically classifying early esophageal cancer. We first process the color esophageal images by using grayscale processing, Meijering filtering and hybrid Hessian filtering before entering the network. Then, we input the processed images into the corresponding streams for feature extraction and conduct feature fusion through the add layer. Finally, the fusion features are classified and detected. We train and test the three-stream-esophageal cancer classification network (TS-ECCN) using 635 images. Macroaveraging and microaveraging, which are more suitable for measuring multiple classification problems, are used as statistical indicators to evaluate the accuracy of the model diagnosis. The areas under the receiver operating characteristic (ROC) curves (AUCs) were 0.97, 0.99 and 0.98 for classifying early cancer, cancer and normal tissue, respectively. The macroprecision, macrorecall and macro-F score of the TS-ECCN were 88.7%, 86% and 87.1%, respectively. The microprecision, microrecall and micro-F score were 89.4%. We validated the ability of a CNN-based algorithm to automatically classify early esophageal cancer from endoscopic images. This algorithm will greatly reduce the workload of endoscopists, improve the efficiency and accuracy of examinations, and become an effective means of clinical auxiliary diagnosis.
C1 [Wang, Zheng; Li, Zhaoying; Hou, Muzhou] Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.
   [Wang, Zheng] Hunan First Normal Univ, Sch Comp Sci, Changsha 410205, Peoples R China.
   [Xiao, Ying; Liu, Xiaowei; Chen, Shuijiao] Cent South Univ, Dept Gastroenterol, Xiangya Hosp, Changsha 410008, Peoples R China.
   [Xiao, Ying; Liu, Xiaowei; Chen, Shuijiao] Hunan Int Sci & Technol Cooperat Base Artificial, Changsha 410008, Peoples R China.
C3 Central South University; Hunan First Normal University; Central South
   University
RP Hou, MZ (corresponding author), Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.; Chen, SJ (corresponding author), Cent South Univ, Dept Gastroenterol, Xiangya Hosp, Changsha 410008, Peoples R China.; Chen, SJ (corresponding author), Hunan Int Sci & Technol Cooperat Base Artificial, Changsha 410008, Peoples R China.
EM houmuzhou@sina.com; shuijiaoxy@163.com
RI , houmuzhou/N-2357-2019; Wang, Zheng/GXA-0956-2022
OI , houmuzhou/0000-0001-6658-2187; Wang, Zheng/0000-0002-1343-5199
FU Scientific Research Fund of Hunan Provincial Education Department
   [20C0402]; Hunan First Normal University [XYS16N03]; Projects of the
   National Social Science Foundation of China [82073019, 82073018]
FX This work was supported by Scientific Research Fund of Hunan Provincial
   Education Department(grant number 20C0402), Hunan First Normal
   University(grant number XYS16N03) and the Projects of the National
   Social Science Foundation of China (grant number 82073019 and 82073018).
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   [Anonymous], 2010, ADV NEUR INF PROC SY
   Balasubramanian M, 2002, SCIENCE, V295
   Bang C, 2020, GEORG THIEME VERLAG, V52
   Bochkovskiy A., 2020, PREPRINT
   Boeriu A, 2015, WORLD J GASTRO ENDOS, V7, P110, DOI 10.4253/wjge.v7.i2.110
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Boughorbel S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177678
   Chen, ANN BIOMEDENG, V48
   Chen YH, 2020, J FORECASTING, V39, P986, DOI 10.1002/for.2663
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Du XX, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2018), P17, DOI 10.1145/3301506.3301540
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton G. E., 2002, Advances in Neural InformationProcessing Systems, P857
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Kandiah K, 2017, SAUDI J GASTROENTERO, V23, P75, DOI 10.4103/1319-3767.203366
   Kingma D.P., 2022, ADAM METHOD STOCHAST
   Kruskal J.B., 1978, Multidimensional scaling
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Meijering E, 2004, CYTOM PART A, V58A, P167, DOI 10.1002/cyto.a.20022
   Mönig S, 2018, ANN NY ACAD SCI, V1434, P115, DOI 10.1111/nyas.13955
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Ng CC, 2015, LECT NOTES COMPUT SC, V9005, P609, DOI 10.1007/978-3-319-16811-1_40
   Njei B, 2016, J GASTROEN HEPATOL, V31, P1141, DOI 10.1111/jgh.13289
   Olshausen BA, 2003, J COGNITIVE NEUROSCI, V15, P154, DOI 10.1162/089892903321107891
   PENNACHI Caterina Maria Pia Simoni, 2017, Arq. Gastroenterol., V54, P250, DOI [10.1590/s0004-2803.201700000-19, 10.1590/S0004-2803.201700000-19]
   Redmon J., 2018, P IEEE C COMP VIS PA
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   SHANNO DF, 1970, MATH COMPUT, V24, P647, DOI 10.2307/2004840
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sofka M, 2007, IEEE T MED IMAGING, V26, P133, DOI 10.1109/TMI.2006.889977
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Thambawita V, 2018, MEDIAEVAL 2018, V2018
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van Riel S, 2018, IEEE IMAGE PROC, P1383, DOI 10.1109/ICIP.2018.8451771
   Wang Z., J DIGIT IMAGING
   Wang Z, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107613
   Wani S, 2014, GASTROINTEST ENDOSC, V79, P224, DOI 10.1016/j.gie.2013.08.002
   Whiteman DC., 2014, Current Epidemiology Reports, V1, P138, DOI 10.1007/s40471-014-0015-3
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Xie H, 2020, NEURAL NETWORKS, V132, P477, DOI 10.1016/j.neunet.2020.09.005
   Yamaguchi J, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P317, DOI 10.1109/ITNG.2015.57
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhang S W, 2016, Zhonghua Zhong Liu Za Zhi, V38, P709, DOI 10.3760/cma.j.issn.0253-3766.2016.09.014
NR 53
TC 21
Z9 21
U1 3
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38001
EP 38018
DI 10.1007/s11042-022-13135-0
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700015
DA 2024-07-18
ER

PT J
AU Ghatak, S
   Battacharjee, D
AF Ghatak, Sanjoy
   Battacharjee, Debotosh
TI Video indexing through human face images using LGFA and window technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indexing; Facial image; EAN-8 barcode; Viola-Jones algorithm; Image
   gradient; Illumination invariant face image; LGFA
ID RETRIEVAL
AB Adaptive video monitoring settings have been extensively deployed in recent years. Smart video monitoring technology enables the acquisition and analysis of movies from various devices, as well as automatic analysis based on knowledge gathering. However, the storage capacity is restricted, and the important frames from the movie cannot be saved. Though, if the movie employs face as keyframes, it creates space and time complexity. To address this issue, the Viola-Jones Algorithm was used to detect faces from extracted keyframes in Video Indexing through Human Face Images using LGFA and the sliding window technique. The image gradient for brightness is created by integrating the sliding windowing method with LGFA, and scanning the input image horizontally takes up 70% of the facial image. As a result, Barcode as an index using the sequence table of the EAN 8 approach converts a video's human face into an EAN-8 linear video indexing barcode and thereby reducing bandwidth, storage space, and time complexity. Regular TV series video datasets, datasets of YouTube faces, and data sets of Hollywood clips were used to evaluate the proposed technique, and shown to be effective for indexing videos based on human faces.
C1 [Ghatak, Sanjoy] Sikkim Manipal Inst Technol, Staff Quater L 304, Rangpo, East Sikkim, India.
   [Battacharjee, Debotosh] Jadavpur Univ, 188 Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
C3 Sikkim Manipal University; Sikkim Manipal Institute of Technology;
   Jadavpur University
RP Ghatak, S (corresponding author), Sikkim Manipal Inst Technol, Staff Quater L 304, Rangpo, East Sikkim, India.
EM scholar.sanjoyghatak@gmail.com
CR Adeyemo J., 2018, EVOLVE A BRIDGE PROB, V674, P179, DOI [DOI 10.1007/978-3-319-69710-9_13, 10.1007/978-3-319-69710-9_13]
   Anayat S., 2020, INT J WIRELESS MICRO, V10, P39, DOI 10.5815/ijwmt.2020.04.05
   Bahroun S, 2021, IET IMAGE PROCESS, V15, P77, DOI 10.1049/ipr2.12008
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Deng Y, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0400-9
   Dong ZL, 2020, IEEE ACCESS, V8, P63421, DOI 10.1109/ACCESS.2020.2982779
   Dutta, 2021, CREATE CAOTUIB EXTRA
   Feng YA, 2019, IEEE T MULTIMEDIA, V21, P1762, DOI 10.1109/TMM.2018.2885237
   Gawande U, 2020, RECENT TRENDS COMPUT RECENT TRENDS COMPUT
   Gayathri N, 2020, INT J FUZZY SYST, V22, P1716, DOI 10.1007/s40815-020-00884-z
   Ghatak S, 2020, PAP 3 INT C COMM CIR
   Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P300, DOI 10.1080/02763869.2018.1477718
   Jacob J., 2020, Int. J. Electr. Comp. Eng., V10, P6019
   Ji LY., 2017, CHINESE MED EQUIPMEN, V38, P48
   Kratochvíl M, 2020, LECT NOTES COMPUT SC, V11962, P790, DOI 10.1007/978-3-030-37734-2_71
   Krishnaraj N, 2021, SOFTWARE PRACT EXPER, V51, P489, DOI 10.1002/spe.2834
   Li CL, 2020, J SUPERCOMPUT, V76, P7707, DOI 10.1007/s11227-020-03192-3
   Li D, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101701
   Lin FC, 2020, J SUPERCOMPUT, V76, P8473, DOI 10.1007/s11227-019-03123-x
   Naveen Kumar G. S., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 898), P751, DOI 10.1007/978-981-13-3393-4_76
   Rossetto L, 2021, IEEE T MULTIMEDIA, V23, P243, DOI 10.1109/TMM.2020.2980944
   Saritha RR, 2019, CLUSTER COMPUT, V22, pS4187, DOI 10.1007/s10586-018-1731-0
   Sauter L, 2020, LECT NOTES COMPUT SC, V11962, P760, DOI 10.1007/978-3-030-37734-2_66
   Tian HM, 2019, WORLD WIDE WEB, V22, P1325, DOI 10.1007/s11280-018-0548-3
   Ullah A, 2020, IEEE ACCESS, V8, P196529, DOI 10.1109/ACCESS.2020.3029834
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yurekli A, 2021, J AMB INTEL HUM COMP, V12, P10125, DOI 10.1007/s12652-020-02777-3
   Zhang CY, 2019, PATTERN RECOGN LETT, V123, P82, DOI 10.1016/j.patrec.2019.03.015
NR 29
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31509
EP 31527
DI 10.1007/s11042-022-12965-2
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336100001
DA 2024-07-18
ER

PT J
AU Chadha, J
   Jain, A
   Kumar, Y
AF Chadha, Jigyasa
   Jain, Aarti
   Kumar, Yogesh
TI Artificial intelligence techniques in wireless sensor networks for
   accurate localization of user in floor, building and indoor area
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational intelligence; Indoor positioning system; Regression;
   Artificial neural network; Standard scalar
ID MAGNETIC-FIELD; SYSTEM
AB An indoor positioning system (IPS) is a network of sensors that may locate persons or objects in situations when GPS and other satellite technologies are insufficient or fail. Because inside sites lack GPS signals, numerous indoor tracking systems based on inertial sensors, wireless communications, and other technologies have been proposed. The goal of this study was to create a model capable of accurately detecting users' locations during indoor localization. As a result, this study relied on factors like floor, building, and interior placement to forecast the user's position inside the building, as these criteria are intertwined. To do so, we gathered data from the UJIIndoor dataset and used data mining to pre-process it. After completing pipelining to improve the findings, the cleaned data were scaled using Min-Max, Principal Component Analysis (PCA), and Standard scalars for normalization. Finally, computational intelligence approaches were used to categorize and predict the position of floors, buildings, and users. Following the evaluation, it was discovered that the artificial neural network (ANN) obtained 90.96% accuracy for the user's floor and relative placement. On the other hand, K-nearest neighbor (KNN) has a 99% accuracy rate for building categorization. At the same time, for relative positioning, ANN has the lowest mean square error (MSE) rate of 0.70, and the lowest root mean square error (RMSE) rate of 0.84. On the other hand, the neural network has a lower value of 0.60 and 0.74 for floor classification and 0.50 and 0.80 for building classification. The computation time was also calculated, and the polynomial method using the pipelining optimization strategy came in first with a value of 1.97 s.
C1 [Chadha, Jigyasa; Jain, Aarti] Netaji Subhas Univ Technol, AIACT&R, Govt NCT Delhis, NSUT East Campus, Delhi, India.
   [Kumar, Yogesh] Ind Univ Ahmedabad, Ind Inst Technol & Engn, Ahmadabad, Gujarat, India.
C3 Netaji Subhas University of Technology; Netaji Subhas University of
   Technology (East Campus)
RP Chadha, J (corresponding author), Netaji Subhas Univ Technol, AIACT&R, Govt NCT Delhis, NSUT East Campus, Delhi, India.
EM jigyasa.chadha14@gmail.com; rtjain2001@gmail.com;
   Yogesh.arora10744@gmail.com
RI kumar, yogesh/AAD-8469-2021
OI kumar, yogesh/0000-0002-2879-0441
CR Ahmed HA, 2018, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INFORMATION MANAGEMENT AND COMMUNICATION (IMCOM 2018), DOI 10.1145/3164541.3164586
   AL-Madani B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092114
   Albanese D., 2012, mlpy: Machine Learning Python, P1
   Bitew MA, 2016, SENSOR MATER, V28, P637
   Bonifazi G, 2022, MULTIMED TOOLS APPL, V81, P141, DOI 10.1007/s11042-021-10984-z
   Bozkurt S, 2015, 2015 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA) PROCEEDINGS, P47
   Cao YX, 2019, IEEE ACCESS, V7, P124876, DOI 10.1109/ACCESS.2019.2938558
   Chang CC, 2021, J INTERNET TECHNOL, V22, P1021, DOI 10.53106/160792642021092205008
   Chiang TH, 2020, IEEE SENS J, V20, P13110, DOI 10.1109/JSEN.2020.3003404
   Nguyen DD, 2021, IEEE ACCESS, V9, P143795, DOI 10.1109/ACCESS.2021.3122011
   Dari Yohanes Erwin, 2018, International Journal of Interactive Mobile Technologies, V12, P61, DOI 10.3991/ijim.v12i1.7632
   Du ZG, 2020, IEEE ACCESS, V8, P8583, DOI 10.1109/ACCESS.2020.2964783
   Hayward SJ, 2021, CIRP J MANUF SCI TEC, V35, P968, DOI 10.1016/j.cirpj.2021.10.006
   JAIN C, 2021 6 INT C WIR COM, P363
   Khatab ZE, 2018, IEEE SENSOR LETT, V2, DOI 10.1109/LSENS.2017.2787651
   Kim M, 2020, IISE TRANS, V53, P326, DOI 10.1080/24725854.2020.1766729
   Kumar Yogesh, 2020, 2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM). Proceedings, P150, DOI 10.1109/ICCAKM46823.2020.9051502
   Kumar Y., 2019, JETIR, V6, P1
   Labinghisa BA, 2021, J SUPERCOMPUT, V77, P638, DOI 10.1007/s11227-020-03272-4
   Le Y, 2020, COMPUTATIONAL INTELL, P1
   Le YF, 2021, FRONT INFORM TECH EL, V22, P827, DOI 10.1631/FITEE.2000093
   Lima M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155013
   Mishev K, 2018, ICT INNOVATIONS, P61
   Naureen A, 2020, IEEE ACCESS, V8, P102709, DOI 10.1109/ACCESS.2020.2997723
   Orujov F, 2018, FUTURE GENER COMP SY, V89, P335, DOI 10.1016/j.future.2018.06.030
   Pajankar, 2021, PRACTICAL PYTHON DAT, DOI 10.1007/978-1-4842-6455-3_5
   Perttula A, 2014, IEEE T INSTRUM MEAS, V63, P2682, DOI 10.1109/TIM.2014.2313951
   Poulose A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010002
   RONG R, 2021 13 INT C MEAS T, P266
   Roy P, 2021, J INTELL ROBOT SYST, V101, DOI 10.1007/s10846-021-01327-z
   Seifeldin M, 2013, IEEE T MOBILE COMPUT, V12, P1321, DOI 10.1109/TMC.2012.106
   Shu YC, 2015, IEEE J SEL AREA COMM, V33, P1443, DOI 10.1109/JSAC.2015.2430274
   Subedi S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247230
   Sun YL, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/4201367
   Torres-Sospedra J, 2014, INT C INDOOR POSIT, P261, DOI 10.1109/IPIN.2014.7275492
   Varoquaux G., 2015, GetMobile: Mobile Computing and Communications, V19, P29, DOI [DOI 10.1145/2786984.2786995, 10.1145/2786984.2786995]
   Wang WX, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041090
   Wang YJ, 2021, WIREL NETW, V27, P1739, DOI 10.1007/s11276-020-02483-0
   Waskom M., 2021, Journal of Open Source Software, V6, P3021, DOI [DOI 10.21105/JOSS.03021, 10.21105/JOSS.03021]
   Wu SJ, 2017, INT J PHOTOENERGY, V2017, DOI 10.1155/2017/1504857
   Yanru Zhong, 2019, 2019 7th International Conference on Information, Communication and Networks (ICICN), P99, DOI 10.1109/ICICN.2019.8834936
   Zhang L., 2021, WIREL COMMUN MOB COM, V2021, P15
NR 42
TC 3
Z9 3
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31261
EP 31294
DI 10.1007/s11042-022-12979-w
EA APR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779229200001
DA 2024-07-18
ER

PT J
AU Parihar, AS
   Kumar, S
   Khosla, S
AF Parihar, Anil Singh
   Kumar, Shashank
   Khosla, Savya
TI S-DCNN: stacked deep convolutional neural networks for malware
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural networks; Ensemble model; Malware
   classification; Pattern recognition; Security; Transfer learning
AB Malware classification continues to be exceedingly difficult due to the exponential growth in the number and variants of malicious files. It is crucial to classify malicious files based on their intent, activity, and threat to have a robust malware protection and post-attack recovery system in place. This paper proposes a novel deep learning-based model, S-DCNN, to classify malware binary files into their respective malware families efficiently. S-DCNN uses the image-based representation of the malware binaries and leverages the concepts of transfer learning and ensemble learning. The model incorporates three deep convolutional neural networks, namely ResNet50, Xception, and EfficientNet-B4. The ensemble technique is used to combine these component models' predictions and a multilayered perceptron is used as a meta classifier. The ensemble technique fuses the diverse knowledge of the component models, resulting in high generalizability and low variance of the S-DCNN. Further, it eliminates the use of feature engineering, reverse engineering, disassembly, and other domain-specific techniques earlier used for malware classification. To establish S-DCNN's robustness and generalizability, the performance of proposed model is evaluated on the Malimg dataset, a dataset collected from VirusShare, and packed malware dataset counterparts of both Malimg and VirusShare datasets. The proposed method achieves a state-of-the-art 10-fold accuracy of 99.43% on the Malimg dataset and an accuracy of 99.65% on the VirusShare dataset.
C1 [Parihar, Anil Singh; Kumar, Shashank; Khosla, Savya] Delhi Technol Univ, Dept Comp Sci & Engn, Machine Learning Res Lab, Delhi, India.
C3 Delhi Technological University
RP Parihar, AS (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Machine Learning Res Lab, Delhi, India.
EM parihar.anil@gmail.com
RI Parihar, Anil Singh/Z-4992-2019
OI Parihar, Anil Singh/0000-0001-5339-8671
CR Alsulami B, 2018, PROCEEDINGS OF THE 2018 13TH INTERNATIONAL CONFERENCE ON MALICIOUS AND UNWANTED SOFTWARE (MALWARE 2018), P103, DOI 10.1109/MALWARE.2018.8659358
   Beek C, 2019, MCAFEE LABS THREATS
   Bhowmik A, 2021, MULTIMED TOOLS APPL, V80, P28015, DOI 10.1007/s11042-021-10964-3
   Bhowmik A, 2019, COMM COM INF SC, V1000, P104, DOI 10.1007/978-3-030-20257-6_9
   Çayir A, 2021, COMPUT SECUR, V102, DOI 10.1016/j.cose.2020.102133
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cui ZH, 2018, IEEE T IND INFORM, V14, P3187, DOI 10.1109/TII.2018.2822680
   D'Angelo G, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107234
   Gao XW, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102661
   Gibert D, 2020, COMPUT SECUR, V95, DOI 10.1016/j.cose.2020.101873
   Gibert D, 2019, J COMPUT VIROL HACKI, V15, P15, DOI 10.1007/s11416-018-0323-0
   Gupta D.K., 2021, ADV COMMUNICATION CO, V668, DOI 10.1007/978-981-15-5341-7_82
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jain M, 2020, J COMPUT VIROL HACKI, V16, P229, DOI 10.1007/s11416-020-00354-y
   Kalash M, 2018, INT CONF NEW TECHNOL
   Kaspersky, 2020, PROTECTING YOUR PERS
   Katyal S, 2018, I CONF SENS TECHNOL, P154, DOI 10.1109/ICSensT.2018.8603632
   Kaur G, 2022, IET IMAGE PROCESS, V16, P1096, DOI 10.1049/ipr2.12212
   Kolosnjaji Bojan, 2016, AI 2016: Advances in Artificial Intelligence. 29th Australasian Joint Conference. Proceedings: LNAI 9992, P137, DOI 10.1007/978-3-319-50127-7_11
   Kumar M., 2021, ADV COMMUNICATION CO, P1503
   Kumar N, 2022, MATER TECHNOL, V37, P2166, DOI [10.1080/10667857.2021.1886664, 10.1615/MultScienTechn.2021037072]
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P22977, DOI 10.1007/s11042-019-7640-2
   Liu L, 2017, FRONT INFORM TECH EL, V18, P1336, DOI 10.1631/FITEE.1601325
   Malik Aruna, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P828, DOI 10.1109/ICACCCN.2018.8748668
   Moskovitch R, 2008, LECT NOTES COMPUT SC, V5376, P204, DOI 10.1007/978-3-540-89900-6_21
   Naeem H, 2019, WIRELESS PERS COMMUN, V108, P2609, DOI 10.1007/s11277-019-06540-6
   Naeem H, 2019, COMPUT ELECTR ENG, V76, P225, DOI 10.1016/j.compeleceng.2019.03.015
   Naeem H, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P240, DOI 10.1109/ICAIBD.2018.8396202
   Narayanan BN, 2016, PROC NAECON IEEE NAT, P338, DOI 10.1109/NAECON.2016.7856826
   Nataraj L., 2011, P P ACM C COMP COMM
   Nataraj Lakshmanan, 2011, P 8 INT S VIS CYB SE, P1
   Nisa M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144966
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pascanu R, 2015, INT CONF ACOUST SPEE, P1916, DOI 10.1109/ICASSP.2015.7178304
   Saadat S, 2020, ARTIF INTELL, P191, DOI [10.1007/978-981-15-5329-5_19, DOI 10.1007/978-981-15-5329-5_19]
   Saxe J, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON MALICIOUS AND UNWANTED SOFTWARE (MALWARE), P11, DOI 10.1109/MALWARE.2015.7413680
   Saxena A, 2021, ADV COMMUNICATION CO, P1069, DOI DOI 10.1007/978-981-15-5341-7_81
   Schultz MG, 2001, P IEEE S SECUR PRIV, P38, DOI 10.1109/SECPRI.2001.924286
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Vasan D, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101748
   Venkatraman S, 2019, J INF SECUR APPL, V47, P377, DOI 10.1016/j.jisa.2019.06.006
   Verma V, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101895
   Yuan BG, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101740
   Zhang HQ, 2019, FUTURE GENER COMP SY, V90, P211, DOI 10.1016/j.future.2018.07.052
NR 45
TC 6
Z9 6
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30997
EP 31015
DI 10.1007/s11042-022-12615-7
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500016
DA 2024-07-18
ER

PT J
AU Poljicak, A
   Donevski, D
   Jelusic, PB
   Cigula, T
AF Poljicak, Ante
   Donevski, Davor
   Jelusic, Petar Branislav
   Cigula, Tomislav
TI Robust DFT watermarking method with gray component replacement masking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Gray component replacement; Print-scan; Fourier; Infra-red
ID IMAGE WATERMARKING
AB The demand for security of shared digital and printed images is increasing year after year. There is a need for a robust watermarking scheme capable of offering high detection rates for very aggressive attacks, such as a print-scan process. However, high robustness of the watermark method usually leads to perceptible visual artifacts. Therefore, in this paper, a novel DFT watermarking method with gray component replacement (GCR) masking is proposed. The watermark is additively embedded in the magnitude coefficients of the image within the Fourier domain and then masked using GCR masking to hide the artifacts introduced by embedding. Experimental results show that GCR masking is capable of completely hiding introduced artifacts and increase the visual quality of the watermarked image using both objective and subjective measures. It also outperforms similar state-of-the-art methods with respect to robustness against image attacks. The method is especially suited for printing since the watermark is hidden in the visible part of the electromagnetic spectrum but is detectable in the infra-red (IR) part of the spectrum using an IR-sensitive camera sensor.
C1 [Poljicak, Ante] Rochester Inst Technol, RIT Croatia, Zagreb, Croatia.
   [Donevski, Davor; Jelusic, Petar Branislav; Cigula, Tomislav] Univ Zagreb, Fac Graph Arts, Zagreb, Croatia.
C3 University of Zagreb
RP Poljicak, A (corresponding author), Rochester Inst Technol, RIT Croatia, Zagreb, Croatia.
EM axp11cad@rit.edu; davor.donevski@grf.unizg.hr;
   petar.branislav.jelusic@grf.unizg.hr; tomislav.cigula@grf.unizg.hr
RI Cigula, Tomislav/AAU-6510-2021; Donevski, Davor/JFA-5220-2023
OI Cigula, Tomislav/0000-0001-6901-0344; Poljicak, Ante/0000-0002-4339-448X
FU Croatian Science Foundation [DOK-2018-09-7543, UIP-2017-05-4081]
FX This research is a part of the projects DOK-2018-09-7543 and
   UIP-2017-05-4081, Development of the model for production efficiency
   increase and functionality of packaging, supported by Croatian Science
   Foundation.
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Andalibi M, 2015, IEEE T IMAGE PROCESS, V24, P5060, DOI 10.1109/TIP.2015.2476961
   [Anonymous], 2016, INT C EM TRENDS ENG
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Barten Peter G. J, 1999, Contrast sensitivity of the human eye and its effects on image quality
   Cui LH, 2011, IEEE T IMAGE PROCESS, V20, P1047, DOI 10.1109/TIP.2010.2079551
   de Queiroz R, 2005, IEEE INT C IM PROC, pI, DOI [10.1109/ICIP.2005.1529768, DOI 10.1109/ICIP.2005.1529768]
   Dixit Anuja, 2017, International Journal of Image, Graphics and Signal Processing, V9, P56, DOI 10.5815/ijigsp.2017.04.07
   GREEN P, 2002, COLOR ENG, P127
   GRUBBS FE, 1969, TECHNOMETRICS, V11, P1, DOI 10.2307/1266761
   Jimson N, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P567, DOI 10.1109/ICCONS.2018.8663122
   Kang B., 2002, NIP21, P384
   Kang H.R., 1994, P SOC PHOTO-OPT INS, V2171, P287, DOI DOI 10.1117/12.175317
   Karybali IG, 2006, IEEE T INF FOREN SEC, V1, P256, DOI 10.1109/TIFS.2006.873652
   Kisilev P, 2011, NINETEENTH COLOR AND IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, P234
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Littlewood DJ, 2002, ACM T GRAPHIC, V21, P132, DOI 10.1145/508357.508361
   Liu TY, 2010, IEEE T IMAGE PROCESS, V19, P1224, DOI 10.1109/TIP.2010.2040757
   Menendez-Ortiz A, 2019, IEEE ACCESS, V7, P132662, DOI 10.1109/ACCESS.2019.2940972
   Mestha LK., 2009, CONTROL COLOR IMAGIN, P249
   Nakamura C., 1990, Proceedings of the SPIE - The International Society for Optical Engineering, V1184, P50, DOI 10.1117/12.963897
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   OGATSU H, 1995, P SOC PHOTO-OPT INS, V2414, P123, DOI 10.1117/12.206540
   Poljicak A, 2019, ELMAR PROC, P65, DOI [10.1109/elmar.2019.8918869, 10.1109/ELMAR.2019.8918869]
   Poljicak A, 2017, ELMAR PROC, P215, DOI 10.23919/ELMAR.2017.8124471
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   SAYANAGI K, 1987, P TAGA, V39, P711
   Shapira L, 2012, COMPUT GRAPH FORUM, V31, P365, DOI 10.1111/j.1467-8659.2012.03015.x
   Sharma A, 2010, J IMAGING SCI TECHN, V54, DOI 10.2352/J.ImagingSci.Technol.2010.54.6.060504
   Sheth RK, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATION AND AUTOMATION (ICACCA 2016), P59
   Shetty P., 2019, SCI TECHNOLOGY PRINT
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   Sun BY, 2014, COLOR TECHNOL, V130, P453, DOI 10.1111/cote.12112
   Tominaga S, 1996, P SOC PHOTO-OPT INS, V2658, P253, DOI 10.1117/12.236974
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Watson A.B., 1993, DIGITAL IMAGES HUMAN, P179
   Wu Tl, 2004, NIP20, P483
   Yang L, 2006, NIP 22: 22ND INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, FINAL PROGRAM AND PROCEEDINGS, P394
NR 38
TC 3
Z9 3
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30365
EP 30386
DI 10.1007/s11042-022-12756-9
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900003
DA 2024-07-18
ER

PT J
AU Anwar, MI
   Khosla, A
AF Anwar, Md. Imtiyaz
   Khosla, Arun
TI Video fog removal using Anisotropic Total Variation de-noising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video defogging; Anisotropic Total Variation (ATV); Universal approach;
   Video enhancement
ID QUALITY ASSESSMENT; SINGLE IMAGE; CONTRAST ENHANCEMENT; VISIBILITY;
   WEATHER
AB Contrast and color of the acquired videos by a visual system are degraded under hazy and foggy weather, which will affect the real-world applications like surveillance system, unmanned vehicle and a driver assistance system. The video fog removal framework is the necessity of vision systems for outdoor real-world applications in bad weather to recover visibility. In this paper, a fog removal framework for videos has proposed for vision enhancement. The proposed framework excludes frame-wise procedure of defogging and adopts a collective approach for the estimation of atmospheric light and depth map estimation from all the video frames to minimize computational burden and to accelerate the process. Weighted Least Square (WLS) filtering and Anisotropic Total Variation (ATV) is implemeted for edge preserving and denoising, respectively. Qualitative and quantitative analysis is used for comparative study and observed the capability of sharp edge preserving. The proposed framework consists of limited number of popular quality parameters that are data driven and constants and remain same irrespective of the image under consideration.
C1 [Anwar, Md. Imtiyaz] BRA Bihar Univ, Muzaffarpur, India.
   [Khosla, Arun] NIT Jalandhar, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Anwar, MI (corresponding author), BRA Bihar Univ, Muzaffarpur, India.
EM imtiyaz.ece@gmail.com; khoslaak@nitj.ac.in
RI ANWAR, MD IMTIYAZ/AGO-7169-2022; Khosla, Arun/ACN-9018-2022
OI ANWAR, MD IMTIYAZ/0000-0003-1494-9519; Khosla, Arun/0000-0001-8571-7614
CR [Anonymous], 2012, Journal of Information Hiding and Multimedia Signal Processing
   Anwar MI, 2017, ENG SCI TECHNOL, V20, P1075, DOI 10.1016/j.jestch.2016.11.015
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Carnec M, 2008, SIGNAL PROCESS-IMAGE, V23, P239, DOI 10.1016/j.image.2008.02.003
   Chen G, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 2, PROCEEDINGS, P53, DOI 10.1109/SNPD.2007.350
   Cho Y, 2018, IEEE ROBOT AUTOM LET, V3, P2822, DOI 10.1109/LRA.2018.2843127
   Esedoglu S, 2004, COMMUN PUR APPL MATH, V57, P1609, DOI 10.1002/cpa.20045
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   ITU-T Recommendation, 2016, P 912 SUBJ VID QUAL
   John J, 2008, PROCEEDINGS OF THE 2008 7TH IEEE INTERNATIONAL CONFERENCE ON CYBERNETIC INTELLIGENT SYSTEMS, P133
   Dhara SK, 2021, IEEE T CIRC SYST VID, V31, P2076, DOI 10.1109/TCSVT.2020.3007850
   Kavanaugh K M, 1990, Int J Card Imaging, V5, P233, DOI 10.1007/BF01797840
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kumari A, 2015, AEU-INT J ELECTRON C, V69, P43, DOI 10.1016/j.aeue.2015.09.001
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Liu H, 2017, NEUROCOMPUTING, V269, P97, DOI 10.1016/j.neucom.2016.09.139
   Ma Zhong-li, 2014, Systems Engineering and Electronics, V36, P1860, DOI 10.3969/j.issn.1001-506X.2014.09.31
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Shi YY, 2013, J APPL MATH, DOI 10.1155/2013/797239
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang HP, 2012, INT CONF SIGN PROCES, P1184, DOI 10.1109/ICoSP.2012.6491788
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tripathi AK, 2012, IET IMAGE PROCESS, V6, P966, DOI 10.1049/iet-ipr.2011.0472
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie B, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.101703
   Xu Z., 2009, 2009 INT C COMP INT, P1
   Yoon I, 2012, IEEE T CONSUM ELECTR, V58, P111, DOI 10.1109/TCE.2012.6170062
   Yoshida T, 2004, IEEE IMAGE PROC, P3487
   Zheng Yi, 2010, Proceedings 2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering (ISKE 2010), P270, DOI 10.1109/ISKE.2010.5680866
NR 33
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35431
EP 35444
DI 10.1007/s11042-022-12318-z
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000777241700003
DA 2024-07-18
ER

PT J
AU Samsudin, MSR
   Abu-Bakar, SAR
   Mokji, MM
AF Samsudin, M. S. Rizal
   Abu-Bakar, Syed A. R.
   Mokji, Musa M.
TI An improved open-view human action recognition with unsupervised domain
   adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Open-view; Human action recognition; Domain adaptation
AB One of the primary concerns with open-view human action recognition (HAR) is the large differences between data distributions of the target and source views. Subsequently, such differences cause the data shift problem to occur, and hence, decreasing the performance of the system. This problem comes from the fact that real-world situation deals with unconstrained rather than constrained situations such as differences in camera resolutions, field of views, and non-uniform illumination which are not found in constrained datasets. The primary goal of this paper is to improve this open-view HAR by proposing the unsupervised domain adaptation approach. In particular, we demonstrated that the balanced weighted unified discriminant and distribution alignment (BW-UDDA) managed to handle the dataset with significant differences across views such as those found in the MCAD dataset. We showed that by using the MCAD dataset on two types of cross-view evaluations, our proposed technique outperformed other unsupervised domain adaptation methods with average accuracies of 13.38% and 61.45%. Additionally, we applied our method to a constrained multi-view IXMAS dataset and achieved an average accuracy of 90.91%. The results confirmed the superiority of the proposed technique.
C1 [Samsudin, M. S. Rizal; Abu-Bakar, Syed A. R.; Mokji, Musa M.] Univ Teknol Malaysia, Fac Engn, Sch Elect Engn, Johor Baharu, Malaysia.
C3 Universiti Teknologi Malaysia
RP Samsudin, MSR (corresponding author), Univ Teknol Malaysia, Fac Engn, Sch Elect Engn, Johor Baharu, Malaysia.
EM ms.rizal1986@graduate.utm.my; syed@fke.utm.my; musa@fke.utm.rny
OI SAMSUDIN, MOHD SHAH RIZAL/0000-0003-1215-1335
FU Ministry of Education Malaysia; University Technology Malaysia (UTM);
   Fundamental Research Scheme [R.J130000.7851.5F179]
FX The authors thank the Ministry of Education Malaysia and University
   Technology Malaysia (UTM) for their support under the Fundamental
   Research Scheme, grant number R.J130000.7851.5F179.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Cai J, 2018, IEEE T NEUR NET LEAR, V29, P4957, DOI 10.1109/TNNLS.2017.2785324
   Ciptadi A, 2014, LECT NOTES COMPUT SC, V8690, P695, DOI 10.1007/978-3-319-10605-2_45
   Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Köse N, 2017, IEEE IMAGE PROC, P3963, DOI 10.1109/ICIP.2017.8297026
   Kong Y, 2017, IEEE T IMAGE PROCESS, V26, P3028, DOI 10.1109/TIP.2017.2696786
   Kulathumani V, 2011, WVU-multi-view action recognition dataset
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822
   Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011
   Li WH, 2017, IEEE WINT CONF APPL, P187, DOI 10.1109/WACV.2017.28
   Li Y, 2019, IEEE INT CON MULTI, P688, DOI 10.1109/ICME.2019.00124
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P2416, DOI 10.1109/TCSVT.2018.2868123
   Liu Y, 2018, COMPLEXITY, DOI 10.1155/2018/5345241
   Liu ZH, 2018, INT J SYST SCI, V49, P847, DOI 10.1080/00207721.2018.1424964
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Murtaza F, 2016, IET COMPUT VIS, V10, P758, DOI 10.1049/iet-cvi.2015.0416
   Nie W, 2014, IEEE 16 INT WORKSH M, P1, DOI [10.1109/TNN.2010.2091281, DOI 10.1109/TNN.2010.2091281]
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Qadir O, 2011, IEEE C EVOL COMPUTAT, P208
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Su YT, 2019, MULTIMED TOOLS APPL, V78, P767, DOI 10.1007/s11042-018-5657-6
   Sun B., 2015, P BRIT MACH VIS C, V24, P1
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang JD, 2020, ACM T INTEL SYST TEC, V11, DOI [10.1145/3360309, 10.1177/1687814018825375]
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Wang JD, 2017, IEEE DATA MINING, P1129, DOI 10.1109/ICDM.2017.150
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Wu XX, 2015, IEEE T IMAGE PROCESS, V24, P4096, DOI 10.1109/TIP.2015.2445293
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yang Y., 2015, P 1 INT WORKSHOP DIF
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhang WJ, 2021, PLATELETS, V32, P582, DOI 10.1080/09537104.2020.1786039
   Zhang Z, 2014, IEEE T CIRC SYST VID, V24, P1663, DOI 10.1109/TCSVT.2014.2305552
   Zhang Z, 2013, PROC CVPR IEEE, P2690, DOI 10.1109/CVPR.2013.347
   Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242
   Zheng JJ, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.125
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 53
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28479
EP 28507
DI 10.1007/s11042-022-12822-2
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200003
DA 2024-07-18
ER

PT J
AU Tanhapour, M
   Safaei, AA
   Shakibian, H
AF Tanhapour, Mozhgan
   Safaei, Ali Asghar
   Shakibian, Hadi
TI Personal health record system based on social network analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Patient-centered care; Personal health record; Social networking; Social
   network analysis
ID CARE; MODEL
AB In this paper, a health social network-based PHR model denoted as HSN-PHR (Health Social Network-based Personal Health Record), is proposed as an extended version of the integrated PHR model that benefits social network analysis to model the consumers' relationships. The proposed PHR model has benefits of all existing PHR models and more compliance with PHR definition. The HSN-PHR is a heterogeneous network with three main entities (including consumers, healthcare providers, and service provider entities) and various types of relationships. Validity of the HSN-PHR is investigated through its structural analysis. Based on consumers' requirements, four networks named "Feature-mix", "Social-family", "Social-doctor" and "Social-lab" were constructed separately concerning four relationships including profile information similarity, family relationships, refer to same doctor or laboratory. Some social network features such as assortativity, transitivity, clustering coefficient, the number of communities, average shortest path and degree distribution were compared to Wiki-vote, Facebook and a small-world network. The results of social network analysis show that the assortativity coefficient in Feature-mix network was positive and greater than other HSN-PHR networks. The degree distribution diagram for Facebook, Wiki-Vote, and Social-lab was similar to the exponential diagram, while this diagram for Feature-mix, Social-doctor, Social-family and small-word network was similar to the normal distribution diagram. The proposed HSN-PHR provides the capabilities of serving as a PHR for the users. Developing such a social network improves consumers' relationships through a platform for propagating health information, news, and consumer education. Moreover, structural features analysis results in the examination of meeting the users' requirements more efficiently.
C1 [Tanhapour, Mozhgan] Tarbiat Modares Univ, Fac Med Sci, Dept Med Informat, Tehran, Iran.
   [Safaei, Ali Asghar] Alzahra Univ, Dept Comp Engn, Tehran, Iran.
   [Shakibian, Hadi] Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
C3 Tarbiat Modares University; Alzahra University; Alzahra University
RP Safaei, AA (corresponding author), Alzahra Univ, Dept Comp Engn, Tehran, Iran.
EM m.tanhapour@modares.ac.ir; aa.safaei@modares.ac.ir;
   H.shakibian@alzahra.ac.ir
RI Safaei, Ali/ABD-3920-2021
OI Safaei, Ali/0000-0003-1985-8720
FU Tarbiat Modares University
FX The study was funded by Tarbiat Modares University.
CR Abd-Alrazaq A, 2020, J. Med. Internet Res., V22, DOI [10.2196/19016, DOI 10.2196/19016]
   Abiteboul S, 1997, LECT NOTES COMPUT SC, V1186, P1
   Al-Garadi MA, 2016, J BIOMED INFORM, V62, P1, DOI 10.1016/j.jbi.2016.05.005
   Alderson DL, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046102
   Alessa A, 2018, THEOR BIOL MED MODEL, V15, DOI 10.1186/s12976-017-0074-5
   Allaert FA, 2010, STUD HEALTH TECHNOL, V155, P43, DOI 10.3233/978-1-60750-563-1-43
   Andrikopoulou E, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-028628
   Angles Renzo, 2018, Graph Data Management, Fundamental Issues and Recent Developments, P1
   [Anonymous], 2021, PATIENTSLIKEME
   [Anonymous], 2018, PEW RSCH CTR
   [Anonymous], 1994, Proceedings of the 20th International Conference on Very Large Data Bases, VLDB '94
   Anoshiravani A, 2011, J PARTICIPATORY MED, V3
   Appel, 2018, ARXIV PREPRINT ARXIV
   Bakhshandeh R, 2011, INT S COMB SEARCH, V2, P1
   Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009
   Carson MB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163861
   Center PR, 2009, SOCIAL LIFE HLTH INF
   Center PR, 2013, PEW INTERNET AM LIFE
   Corrigan J.M., 2005, Crossing the quality chasm. Building a Better Delivery System
   CureTogether, 2021, CURETOGETHER
   D'Amore JD, 2014, J AM MED INFORM ASSN, V21, P1060, DOI 10.1136/amiajnl-2014-002883
   Daglish D., 2009, PRIVACY, DOI DOI 10.1109/CONGRESS.2009.14
   Davis S, 2017, J AM MED INFORM ASSN, V24, P857, DOI 10.1093/jamia/ocw172
   Detmer D, 2008, BMC MED INFORM DECIS, V8, DOI 10.1186/1472-6947-8-45
   Dong XF, 2021, PHYSICA A, V565, DOI 10.1016/j.physa.2020.125546
   Epstein RM, 2010, HEALTH AFFAIR, V29, P1489, DOI 10.1377/hlthaff.2009.0888
   Ford EW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.4973
   Fox S., 2011, The Social Life of Health Information
   Franco-Trigo L, 2020, RES SOC ADMIN PHARM, V16, P216, DOI 10.1016/j.sapharm.2019.05.008
   Golbeck J., 2013, Analyzing the Social Web, DOI [10.1016/C2012-0-00171-8, DOI 10.1016/C2012-0-00171-8]
   Gold JD, 2007, IBM SYST J, V46, P43, DOI 10.1147/sj.461.0043
   Graves M., 1995, Proceedings of the Twenty-Eighth Hawaii International Conference on System Sciences, P32, DOI 10.1109/HICSS.1995.375353
   Groenen CJM, 2017, MIDWIFERY, V45, P50, DOI 10.1016/j.midw.2016.12.007
   Group RH, 2021, REV HLTH
   HaCohen-Kerner Y, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102102
   Han Hae-Ra, 2019, JMIR Hum Factors, V6, pe15038, DOI 10.2196/15038
   Han Xiao., 2015, Mining user similarity in online social networks: analysis, modeling and applications
   Hung M, 2020, J MED INTERNET RES, V22, DOI 10.2196/22590
   Israelson J., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P2958, DOI 10.1109/HICSS.2012.61
   JaeHo Lee, 2011, 2011 International Conference on ICT Convergence, P388, DOI 10.1109/ICTC.2011.6082623
   Khan FA, 2020, MULTIMED TOOLS APPL, V79, P8399, DOI 10.1007/s11042-018-6692-z
   Koskinen J., 2020, WELL BEING INFORM SO, P24
   Lawhon L., 2016, NEW HLTH UNION SURVE
   Lee G, 2016, TELEMED E-HEALTH, V22, P419, DOI 10.1089/tmj.2015.0137
   Lee K, 2017, PREV VET MED, V138, P113, DOI 10.1016/j.prevetmed.2017.02.001
   Leskovec J., 2014, SNAP Datasets: Stanford large network dataset collection
   Liu W., 2020, THESIS AUCKLAND U TE
   Ljubic B, 2019, J BIOMED INFORM, V93, DOI 10.1016/j.jbi.2019.103161
   Lokhandwala Sharukh., 2016, Secondary Analysis of Electronic Health Records, P3
   Lönnqvist JE, 2014, J RES PERS, V50, P98, DOI 10.1016/j.jrp.2014.03.009
   Lu YJ, 2021, JMIR MED INF, V9, DOI 10.2196/24618
   MedHelp, 2021, MEDHELP
   Menichetti J, 2016, HEALTH EXPECT, V19, P516, DOI 10.1111/hex.12299
   Mislove A. E., 2009, Online social networks: Measurement, analysis, and applications to distributed information systems
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Narducci F, 2017, INFORM SYST, V71, P111, DOI 10.1016/j.is.2017.07.005
   Nasiri S, 2013, INFORMATIK 2013 INFO
   Noldus R, 2015, J COMPLEX NETW, V3, P507, DOI 10.1093/comnet/cnv005
   Nyman E, 2020, RHEUMATOL THER, V7, P201, DOI 10.1007/s40744-020-00195-7
   Ostovari M, 2019, J AM MED INFORM ASSN, V26, P911, DOI 10.1093/jamia/ocz022
   Ozdalga E, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1994
   Park JY, 2014, TELEMED E-HEALTH, V20, P215, DOI 10.1089/tmj.2013.0192
   Pastor-Satorras R, 2015, REV MOD PHYS, V87, P925, DOI 10.1103/RevModPhys.87.925
   Pirtle B., 2011, AM J HLTH SCI AJHS, V2, P45, DOI DOI 10.19030/AJHS.V2I2.6627]
   Reti SR, 2010, J AM MED INFORM ASSN, V17, P192, DOI 10.1136/jamia.2009.000927
   Ricciardi L, 2013, HEALTH AFFAIR, V32, P376, DOI 10.1377/hlthaff.2012.1216
   Ro HJ, 2015, KOREAN J FAM MED, V36, P121, DOI 10.4082/kjfm.2015.36.3.121
   Robinson I, 2015, GRAPH DATABASES NEW, P1
   Roehrs A, 2017, J BIOMED INFORM, V71, P70, DOI 10.1016/j.jbi.2017.05.012
   Roehrs A, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.5876
   Ryu B, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.8867
   Shakibian H., 2016, INT J INFORM COMMUNI, V8, P9
   Shakibian H, 2018, PHYSICA A, V501, P248, DOI 10.1016/j.physa.2018.02.189
   Shakibian H, 2017, SCI REP-UK, V7, DOI 10.1038/srep44981
   Studeny Jana, 2014, Perspect Health Inf Manag, V11, p1e
   Swan M, 2009, INT J ENV RES PUB HE, V6, P492, DOI 10.3390/ijerph6020492
   Tang PC, 2006, J AM MED INFORM ASSN, V13, P121, DOI 10.1197/jamia.M2025
   Tanhapour Mozhgan, 2018, International Journal of Electronic Healthcare, V10, P249
   Tanhapour M., 2015, Tehran University Medical Journal, V73, P431
   Tu Y, 2020, INT J REMOTE SENS, V41, P5482, DOI 10.1080/01431161.2020.1731935
   Wager K.A., 2013, HLTH CARE INFORM SYS, V3rd
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Witry MJ, 2010, PERSPECTIVES HLTH IN, V7
   Yan L, 2015, INFORM SYST RES, V26, P496, DOI 10.1287/isre.2015.0585
   Yoo M, 2019, INFORM PROCESS MANAG, V56, P1565, DOI 10.1016/j.ipm.2018.10.001
   Young-Mason Jeanine, 2013, Clin Nurse Spec, V27, P105, DOI 10.1097/NUR.0b013e3182818fea
NR 86
TC 4
Z9 4
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27601
EP 27628
DI 10.1007/s11042-022-12910-3
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800003
DA 2024-07-18
ER

PT J
AU Zhu, JJ
   Fang, B
   Zhou, ML
   Luo, FT
   Xian, WZ
   Wang, G
AF Zhu, Jiajie
   Fang, Bin
   Zhou, Mingliang
   Luo, Futing
   Xian, Weizhi
   Wang, Gang
TI An active contour model based on adaptively variable exponent combining
   Legendre polynomial for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active contour model; Image segmentation; Legendre polynomial; Level set
   method
ID LEVEL SET EVOLUTION; DRIVEN; ENERGY
AB Images with intensity inhomogeneity and blurred boundaries are common in image segmentation tasks, which inevitably result in many difficulties in accurate image segmentation. Massive active contour models (ACMs) have been proposed to solve the problems of intensity inhomogeneity or blurred boundaries respectively. However, there is almost no way to effectively solve the above two problems at the same time, and they are sensitive to the initial contour and noise, or their segmentation speed is relatively slow. In this paper, we propose an active contour model (ACM) based on adaptively variable exponent combining Legendre polynomial (LP) for image segmentation. First, the Legendre polynomial intensity (LPI) is defined, which employs a linear combination of Legendre basis functions for region intensity approximation. Second, an adaptively LPI term is defined, which adopts an adaptively variable exponent function as an acceleration term to drive the curve to quickly evolve to the object boundaries. Third, the distance regularization term is introduced into the active contour as a regularization term to eliminate the need for reinitialization and restrict the behavior of level set function (LSF). Experimental results show that our method offers robustness to gray unevenness, noise and initial curve placement, and adaptability to low contrast and blurred boundaries and outperforms other state-of-the-art algorithms.
C1 [Zhu, Jiajie; Fang, Bin; Zhou, Mingliang; Luo, Futing; Xian, Weizhi] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
   [Zhu, Jiajie; Zhou, Mingliang; Luo, Futing; Xian, Weizhi] Univ Macau, State Key Lab Internet Things Smart City, Macau 999078, Peoples R China.
   [Wang, Gang] NingboTech Univ, Sch Comp & Data Engn, Ningbo, Peoples R China.
C3 Chongqing University; University of Macau; NingboTech University
RP Fang, B; Zhou, ML (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.; Zhou, ML (corresponding author), Univ Macau, State Key Lab Internet Things Smart City, Macau 999078, Peoples R China.
EM fb@cqu.edu.cn; zml-0913yy@163.com
RI Zhou, Mingliang/HPC-0298-2023; ZHOU, MING/JVP-2920-2024
OI Xian, Weizhi/0000-0001-5137-3542; Zhu, Jiajie/0000-0001-8673-1477
FU National Natural Science Foundation of China [61876026, 62176027,
   62102179]; General Program of National Natural Science Foundation of
   Chongqing [cstc2020jcyj msxmX0790]; Fundamental Research Funds for the
   Central Universities [2021CDJJMRH-014]; Guangxi Key Laboratory of
   Cryptography and Information Security [GCIS201905]; Human Resources and
   Social Security Bureau Project of Chongqing [cx2020073]; Huawei Project
   [H20210586]; Suzhou Institute of USTC [H20201528]; Ningbo Natural
   Science Foundation [202003N4307]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61876026, Grant 62176027 and Grant
   62102179; in part by the General Program of National Natural Science
   Foundation of Chongqing under Grant cstc2020jcyj msxmX0790; in part by
   the Fundamental Research Funds for the Central Universities under Grant
   2021CDJJMRH-014; in part by the Guangxi Key Laboratory of Cryptography
   and Information Security under Grant GCIS201905; in part by the Human
   Resources and Social Security Bureau Project of Chongqing under Grant
   cx2020073; in part by the Huawei Project under Grant H20210586; in part
   by the Suzhou Institute of USTC under Grant H20201528; in part by the
   Ningbo Natural Science Foundation under Grant 202003N4307.
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   Bernard O, 2009, IEEE T IMAGE PROCESS, V18, P1179, DOI 10.1109/TIP.2009.2017343
   Cai Q, 2018, PATTERN RECOGN, V82, P79, DOI 10.1016/j.patcog.2018.05.008
   Cardenes R, 2009, COMPUT METH PROG BIO, V96, P108, DOI 10.1016/j.cmpb.2009.04.009
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Ding KY, 2017, SIGNAL PROCESS, V134, P224, DOI 10.1016/j.sigpro.2016.12.021
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu Jun, 2019, IEEE Trans Image Process, DOI 10.1109/TIP.2019.2895460
   Gao MQ, 2019, SIGNAL PROCESS, V159, P104, DOI 10.1016/j.sigpro.2019.01.021
   Gur S, 2019, IEEE I CONF COMP VIS, P10721, DOI 10.1109/ICCV.2019.01082
   Hatamizadeh A, 2019, ARXIV COMPUTER VISIO
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   Hu F, 2020, J FUNCT SPACE, V2020, DOI 10.1155/2020/2061841
   Lee Y, 2020, P IEEE CVF C COMP VI
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2005, PROC CVPR IEEE, P430
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Manogaran G, 2018, MULTIMED TOOLS APPL, V77, P4379, DOI 10.1007/s11042-017-5515-y
   Marcos D, 2018, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR.2018.00925
   Mencattini A, 2010, IEEE T INSTRUM MEAS, V59, P2505, DOI 10.1109/TIM.2010.2057691
   Min H, 2018, IEEE T IMAGE PROCESS, V27, P5016, DOI 10.1109/TIP.2018.2848471
   Minaee S., 2020, ARXIV200105566
   Mishra AK, 2011, IEEE T PATTERN ANAL, V33, P310, DOI 10.1109/TPAMI.2010.83
   Mukherjee S, 2015, IEEE SIGNAL PROC LET, V22, P298, DOI 10.1109/LSP.2014.2346538
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Pramanik S, 2020, IEEE T INSTRUM MEAS, V69, P2722, DOI 10.1109/TIM.2019.2925879
   Pratondo A, 2016, IEEE SIGNAL PROC LET, V23, P222, DOI 10.1109/LSP.2015.2508039
   Riaz F, 2019, IEEE J BIOMED HEALTH, V23, P489, DOI 10.1109/JBHI.2018.2832455
   Samuel RDJ, 2020, MULTIMED TOOLS APPL, V79, P5225, DOI 10.1007/s11042-018-6356-z
   Sarkar R, 2015, IEEE SIGNAL PROC LET, V22, P2034, DOI 10.1109/LSP.2015.2454991
   Schick A, 2012, INT C PATT RECOG, P930
   Sforza G, 2012, IEEE T INSTRUM MEAS, V61, P1839, DOI 10.1109/TIM.2012.2192349
   Shan XY, 2020, IEEE ACCESS, V8, P43200, DOI 10.1109/ACCESS.2020.2975854
   Sida Peng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8530, DOI 10.1109/CVPR42600.2020.00856
   Tavallali P, 2019, MULTIMED TOOLS APPL, V78, P2599, DOI 10.1007/s11042-018-6385-7
   Van den Bergh M, 2015, INT J COMPUT VISION, V111, P298, DOI 10.1007/s11263-014-0744-2
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Wang L, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107297
   Wang Y, 2017, MED IMAGE ANAL, V40, P1, DOI 10.1016/j.media.2017.05.005
   Wang Z, 2019, PROC CVPR IEEE, P7492, DOI 10.1109/CVPR.2019.00768
   Wen W., 2012, MATH PROBL ENG, V2012, P1
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xiang SM, 2010, IEEE T IMAGE PROCESS, V19, P3024, DOI 10.1109/TIP.2010.2052268
   Xiang Y, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang L, 2017, MACH VISION APPL, V28, P75, DOI 10.1007/s00138-016-0805-3
   Zhang WH, 2020, IEEE T IMAGE PROCESS, V29, P57, DOI 10.1109/TIP.2019.2928134
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zheng SH, 2018, PATTERN RECOGN, V73, P144, DOI 10.1016/j.patcog.2017.08.011
NR 60
TC 0
Z9 0
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27495
EP 27522
DI 10.1007/s11042-022-12340-1
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800001
DA 2024-07-18
ER

PT J
AU Lan, CF
   Zhang, L
   Wang, YQ
   Liu, CD
AF Lan, Chaofeng
   Zhang, Lei
   Wang, YuQiao
   Liu, Chundong
TI Research on improved DNN and MultiResU_Net network speech enhancement
   effect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Low Signal-to-noise ratio; Source-to-distortion
   ratio; Multi-Resolution Cochleagram; MultiResU_Net
ID DEEP NEURAL-NETWORK; CLASSIFICATION
AB Aiming at the problem that the traditional deep learning algorithms have unsatisfactory speech enhancement effect under low Signal-to-Noise Ratio (SNR) conditions, this paper improves Deep Neural Network (DNN) and Multiresolution Residual U Network (MultiResU_Net) to discuss the speech enhancement effect. In this paper, the Minimum Mean-Square Error Short-Time Spectral Amplitude Estimator (MMSE-STSA) is used to reduce the noise of the Multi-Resolution Cochleagram (MRCG) features that including the local and global characteristics of speech and using the improved features Improved Multi-Resolution Cochleagram (I-MRCG) as the input of Skip-DNN network to build Skip-DNN speech enhancement model. The short-time Fourier transformed features of the speech signal at low SNR are used as the input of MultiResU_Net network and the output features of residual path and upsampling are rearranged by the hybrid channel to build an improved MultiResU_Net speech enhancement model. Using LibriSpeech ASR corpus, under different SNR conditions, analyze the speech enhancement effects of different network models and different features as the input of the Skip-DNN model. The experimental results show that when the SNR is -5dB, the perceptual evaluation effect of the average speech quality is better that I-MRCG is used as the feature input of the Skip-DNN model. The average short-time objective intelligibility (STOI), the average perceptual evaluation of speech quality (PESQ) and Source-to-Distortion Ratio (SDR) of the improved MultiResU_Net speech enhancement model are higher than other models. It can be seen that both the improved Skip-DNN and MultiResU_Net proposed in this paper have better speech enhancement effect, especially the improved MultiResU_Net network is more suitable for speech enhancement at low SNR.
C1 [Lan, Chaofeng; Wang, YuQiao; Liu, Chundong] Harbin Univ Sci & Technol, Coll Measurement & Commun Engn, Harbin 150080, Peoples R China.
   [Zhang, Lei] Beidahuang Ind Grp Gen Hosp, Harbin 150088, Peoples R China.
C3 Harbin University of Science & Technology
RP Lan, CF; Liu, CD (corresponding author), Harbin Univ Sci & Technol, Coll Measurement & Commun Engn, Harbin 150080, Peoples R China.; Zhang, L (corresponding author), Beidahuang Ind Grp Gen Hosp, Harbin 150088, Peoples R China.
EM lanchaofeng@hrbust.edu.cn; happyzhang68@126.com; lchd840@163.com
RI Liu, Chun Dong/P-6322-2015; Wang, Jinguo/JED-9233-2023
FU national natural science youth foundation of china [11804068]; natural
   science foundation of Heilongjiang Province [LH2020F033]
FX This research received by the national natural science youth foundation
   of china (No.11804068) and the natural science foundation of
   Heilongjiang Province (No. LH2020F033).
CR Attabi Y, 2021, CIRC SYST SIGNAL PR, V40, P2926, DOI 10.1007/s00034-020-01604-6
   Bouchair A, 2022, CIRC SYST SIGNAL PR, V41, P196, DOI 10.1007/s00034-021-01767-w
   Bulut AE, 2020, INT CONF ACOUST SPEE, P6214, DOI [10.1109/ICASSP40776.2020.9054563, 10.1109/icassp40776.2020.9054563]
   Chen H, 2021, NEURAL NETWORKS, V143, P171, DOI 10.1016/j.neunet.2021.06.003
   Chen JT, 2016, SPEECH COMMUN, V78, P1, DOI 10.1016/j.specom.2015.12.006
   Chen JIZ, 2014, 2014 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL THEORY AND APPLICATION, P14
   Choi Hyeong-Seok, 2019, INT C LEARN REPR
   Fischer T, 2021, HEARING RES, V408, DOI 10.1016/j.heares.2021.108294
   Gao T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5054, DOI 10.1109/ICASSP.2018.8461861
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Islam MS, 2020, DIGIT SIGNAL PROCESS, V100, DOI 10.1016/j.dsp.2020.102697
   Jia HR, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107666
   Jiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P2112, DOI 10.1109/TASLP.2014.2361023
   Kang TG, 2015, IEEE SIGNAL PROC LET, V22, P229, DOI 10.1109/LSP.2014.2354456
   Li LJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131586
   [刘文举 Liu Wenju], 2016, [自动化学报, Acta Automatica Sinica], V42, P819
   Park SR, 2017, INTERSPEECH, P1993, DOI 10.21437/Interspeech.2017-1465
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi W-H, 2016, MILITARY COMMUN TECH, V37, P98
   Smaragdis P, 2007, IEEE T AUDIO SPEECH, V15, P1, DOI 10.1109/TASL.2006.876726
   Tseng HW, 2015, INT CONF ACOUST SPEE, P2145, DOI 10.1109/ICASSP.2015.7178350
   Tu M, 2017, INT CONF ACOUST SPEE, P5565, DOI 10.1109/ICASSP.2017.7953221
   Tu YH, 2014, INT CONF SIGN PROCES, P532, DOI 10.1109/ICOSP.2014.7015061
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Wang Y-X, 2014, 2014 IEEE INT C AC S, P4
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961
   Weninger F, 2014, COMPUT SPEECH LANG, V28, P888, DOI 10.1016/j.csl.2014.01.001
   Williamson DS, 2016, IEEE-ACM T AUDIO SPE, V24, P483, DOI 10.1109/TASLP.2015.2512042
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Yang Q, 2020, CHIN AUTOM CONGR, P1614, DOI 10.1109/CAC51589.2020.9327668
   Zhang QY, 2021, MULTIMED TOOLS APPL, V80, P24925, DOI 10.1007/s11042-021-10905-0
NR 32
TC 0
Z9 0
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26163
EP 26184
DI 10.1007/s11042-022-12929-6
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900015
DA 2024-07-18
ER

PT J
AU Yin, FL
   Pan, YY
   Su, P
   Wang, YY
AF Yin, Fulian
   Pan, Yanyan
   Su, Pei
   Wang, Yanyan
TI Building user interest model for TV recommendation with label-based
   memory forgetting-enhancement model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ebbinghaus forgetting curve; Memory enhancement; User behavior analysis;
   User interest model; TV recommendation
ID SYSTEM
AB TV recommendation can help users find interesting TV programs, improve user experience, and solve the problem of information overload. Current TV programs only recommend through the interactive data between users and programs ignoring the important value of temporal relation, having the problem such as data sparseness. To solve these problems, we propose a user interest model for TV recommendation with Label-based Memory Forgetting-Enhancement (LMFE). This model includes LMFE model and improved index-label interest model. The former combines memory forgetting and repetitive enhancement mechanisms, which predicts user behavior under the condition of multiple viewing indicators according to TV program labels. The latter considers multiple indexes and labels to model the user interest model, where enriches user interests and enhances the effectiveness of user interest tracing. The experiments verify the accuracy of the forecast data and recommendation results by the real TV user behavior data set. We evaluate the recommendation effect of the model through eight types of classic indexes and the results show that our model has a better prediction effect than traditional models.
C1 [Yin, Fulian; Pan, Yanyan; Su, Pei; Wang, Yanyan] Commun Univ China, Coll Informat & Commun Engn, Beijing 100024, Peoples R China.
C3 Communication University of China
RP Wang, YY (corresponding author), Commun Univ China, Coll Informat & Commun Engn, Beijing 100024, Peoples R China.
EM yinfulian@cuc.edu.cn; yanyanpan@cuc.edu.cn; supeiCynthia@163.com;
   yywang@cuc.edu.cn
FU National Natural Science Foundation of China [61801440]; High-quality
   and Cutting-edge Disciplines Construction Project for Universities in
   Beijing (Internet Information, Communication University of China); State
   Key Laboratory of Media Convergence and Communication (Communication
   University of China); Fundamental Research Funds for the Central
   Universities
FX This work is supported by the National Natural Science Foundation of
   China (No. 61801440), the High-quality and Cutting-edge Disciplines
   Construction Project for Universities in Beijing (Internet Information,
   Communication University of China), State Key Laboratory of Media
   Convergence and Communication (Communication University of China), and
   the Fundamental Research Funds for the Central Universities.
CR Breese J., 1998, P 14 C UNC ART INT, P43
   Chen CM, 2008, COMPUT EDUC, V51, P624, DOI 10.1016/j.compedu.2007.06.011
   Cui H, 2013, THESIS SUN YAT SEN U
   DENNIS JE, 1981, ACM T MATH SOFTWARE, V7, P369, DOI 10.1145/355958.355966
   Ding Y, 2005, ACM CIKM INT C INF K
   Dong F, 2005, THESIS XIDIAN U
   Ebbinghaus H., 1913, Memory; a contribution to experimental psychology, Viii-viii, P1, DOI [10.1037/10011-001, DOI 10.1037/10011-001]
   Fang X, 2008, THESIS HUAZHONG U SC
   Gong WW, 2021, SOFTWARE PRACT EXPER, V51, P2337, DOI 10.1002/spe.2902
   Gui S., 2015, NEW TECHNOL LIB INF, V31, P9
   Hopkins RF, 2016, EDUC PSYCHOL REV, V28, P853, DOI 10.1007/s10648-015-9349-8
   HOUSMAN EM, 1970, IEEE T PROF COMMUN, VEW13, P78, DOI 10.1109/TEWS.1970.4322444
   Hu LM, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102142
   Kim JM, 2015, INT J WEB GRID SERV, V11, P283, DOI 10.1504/IJWGS.2015.070964
   Koychev I., 2000, PROC ECML2000 WORKSH, P39
   Lekakos G, 2008, MULTIMED TOOLS APPL, V36, P55, DOI 10.1007/s11042-006-0082-7
   Luo JG, 2009, IEEE T PARALL DISTR, V20, P59, DOI 10.1109/TPDS.2008.68
   [马力 Ma Li], 2004, [计算机科学, Computer Science], V31, P140
   Nan Z., 2012, MICROCOMPUT APPL, V028, P30
   PengLiu H, P 9 INT C COMP ENG N, P489
   Qi LY, 2022, IEEE T BIG DATA, V8, P685, DOI 10.1109/TBDATA.2020.2975587
   Qinjun X, 2014, J ELECT MEAS INSTRUM, V28, P343
   Shao H, 2010, INT C MACH VIS HUM M
   Sun JS, 2015, INFORM PROCESS MANAG, V51, P444, DOI 10.1016/j.ipm.2014.09.002
   Tang, 2016, INF STUD THEORY APPL, V39, P116
   Teng Y, 2012, THESIS E CHINA NORMA
   Wang Lin, 2017, Computer Engineering, V43, P214, DOI 10.3969/j.issn.1000-3428.2017.09.038
   Wang Q, 2014, THESIS FUDAN UNISERS
   Wang S., 2001, J COMPUT RES DEV, V38, P482
   Weisz JD, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P877
   [印桂生 Yin Guisheng], 2012, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V33, P85
   [于洪 Yu Hong], 2010, [南京大学学报. 自然科学版, Journal of Nanjing University], V46, P520
   Yu Hong-tao, 2014, Computer Engineering and Design, V35, P3367
   Zeng D., 2013, SCI MOSAIC, V000, P10
   Zh L, 2014, COMPUT KNOWL TECHNOL, V10, P67
   Zhang YC, 2010, 2010 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY AND SECURITY INFORMATICS (IITSI 2010), P777, DOI 10.1109/IITSI.2010.161
   Zhou W, 2019, INFORM PROCESS MANAG, V56, P955, DOI 10.1016/j.ipm.2019.02.002
   Zhu M, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P198, DOI 10.1109/CSE.2014.67
   ZHU X, 2020, IEEE ACCESS, V8
NR 39
TC 1
Z9 1
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26307
EP 26330
DI 10.1007/s11042-022-12718-1
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900003
DA 2024-07-18
ER

PT J
AU Rehman, HU
   Nida, N
   Shah, SA
   Ahmad, W
   Faizi, MI
   Anwar, SM
AF Rehman, Hafeez Ur
   Nida, Nudrat
   Shah, Syed Adnan
   Ahmad, Wakeel
   Faizi, Muhammad Imran
   Anwar, Syed Muhammad
TI Automatic melanoma detection and segmentation in dermoscopy images using
   deep RetinaNet and conditional random fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RetinaNet; Melanoma segmentation; Conditional Random Fields (CRF); ISIC;
   PH2; Skin cancer segmentation
ID LESION DETECTION; NETWORK
AB Melanoma is one of the major causes of death around the world and is also known as malignant skin cancer. Melanoma detection is possible at an early stage by visual inspection of the infected lesions. There are a limited number of expert dermatologists available, moreover visual inspection also has limited accuracy. Hence, diagnosis and clinical decision making can be complicated for melanoma detection. Towards this, we propose a deep learning method for automatic detection and segmentation of melanoma regions within the dermoscopic images for precise melanoma segmentation. Our method generates bounding boxes around multiple regions to precisely detect the affected regions using RetinaNet. Further, conditional random field (CRF) is applied to the detected regions for segmentation of the melanoma lesion. In particular, we perform three steps: image pre-processing, melanoma localization, and melanoma segmentation. We evaluate our proposed method on Pedro Hispano (PH)2, International Skin Imaging Collaboration (ISIC) 2017, and ISIC 2018 benchmark datasets. Our experimental findings reveal the performance supremacy of our proposed method. For instance, pixel-level sensitivity is 0.932, pixel-level specificity is 0.977, pixel-level accuracy is 0.942, dice coefficient is 0.931, and Jaccard index is 0.9187 for ISIC 2018 challenge data. Our proposed method has shown good performance against other state-of-the-art methods evaluated on the ISIC 2018 challenge dataset. We attribute this performance to deep features computation using RetinaNet for detecting melanoma region and CRF for precise segmentation of the melanoma lesion.
C1 [Rehman, Hafeez Ur; Shah, Syed Adnan; Ahmad, Wakeel; Faizi, Muhammad Imran] Univ Engn & Technol Taxila, Dept Comp Sci, Taxila, Pakistan.
   [Nida, Nudrat] Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
   [Anwar, Syed Muhammad] Univ Engn & Technol Taxila, Dept Software Engn, Taxila, Pakistan.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila; University of Engineering & Technology Taxila
RP Anwar, SM (corresponding author), Univ Engn & Technol Taxila, Dept Software Engn, Taxila, Pakistan.
EM s.anwar@uettaxila.edu.pk
RI anwar, syed/AGY-3965-2022
OI anwar, syed/0000-0002-8179-3959; /0000-0002-5453-2649; , Syed M.
   Adnan/0000-0002-0254-412X
CR Albahli S, 2020, IEEE ACCESS, V8, P198403, DOI 10.1109/ACCESS.2020.3035345
   Ale L, 2018, IEEE INT CONF BIG DA, P5197, DOI 10.1109/BigData.2018.8622025
   Aljawawdeh A, 2017, INT J ADV COMPUT SC, V8, P477
   Attia M, 2017, I S BIOMED IMAGING, P292, DOI 10.1109/ISBI.2017.7950522
   Badrinarayanan V., 2017, TPAMI, DOI DOI 10.1109/TPAMI.2016.2644615
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Bozorgtabar B, 2016, LECT NOTES COMPUT SC, V10019, P254, DOI 10.1007/978-3-319-47157-0_31
   Chen EZ, 2019, I S BIOMED IMAGING, P485, DOI [10.1109/isbi.2019.8759483, 10.1109/ISBI.2019.8759483]
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Arroyo JLG, 2014, COMPUT BIOL MED, V44, P144, DOI 10.1016/j.compbiomed.2013.11.002
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Goodall GJ, 2021, NAT REV CANCER, V21, P22, DOI 10.1038/s41568-020-00306-0
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu T, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/3846125
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Mirikharaji Z, 2018, I S BIOMED IMAGING, P877, DOI 10.1109/ISBI.2018.8363711
   Nida N, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6671498
   Nida N, 2019, INT J MED INFORM, V124, P37, DOI 10.1016/j.ijmedinf.2019.01.005
   Patino D, 2020, MELANOMA DETECTION D, V11330, P1133018
   Pennisi A, 2016, COMPUT MED IMAG GRAP, V52, P89, DOI 10.1016/j.compmedimag.2016.05.002
   Qian C, 2018, ARXIV180903917
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shvets AA, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P624, DOI 10.1109/ICMLA.2018.00100
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Ustinova E, 2016, ADV NEUR IN, V29
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166
   Zeng, 2018, RETINANET EXPLAINED
NR 34
TC 8
Z9 8
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25765
EP 25785
DI 10.1007/s11042-022-12460-8
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772731900002
DA 2024-07-18
ER

PT J
AU Khudayberdiev, O
   Zhang, JS
   Abdullahi, SM
   Zhang, S
AF Khudayberdiev, Otabek
   Zhang, Jiashu
   Abdullahi, Sani M.
   Zhang, Sheng
TI Light-FireNet: an efficient lightweight network for fire detection in
   diverse environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks (CNNs); Fire detection; Lightweight; Image
   classification; Network design; Deep learning; Diverse environments
ID CONVOLUTIONAL NEURAL-NETWORK; COLOR
AB Fire and smoke detection using deep learning have recently proven to be a robust and efficient detection approach in contrast to traditional vision-based techniques. Efforts are made by researchers to leverage this promising direction but are always faced with a trade-off between performance accuracy and model size. To tackle this, we present Light-FireNet, an enhanced lightweight, fast, and cost-effective system based on a combination of lighter convolution mechanisms inspired by Hard Swish (H-Swish), and a novel architectural design built from scratch. Experimental results and performance analysis reveal that our proposed method has 32% fewer parameters than AlexNet, 3.03 MB lighter than MobileNetV2, and achieves a better detection accuracy of 97.83%, which is higher than most existing fire detection techniques in the literature.
C1 [Khudayberdiev, Otabek; Zhang, Jiashu; Zhang, Sheng] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 610031, Peoples R China.
   [Abdullahi, Sani M.] China Three Gorges Univ, Coll Comp & Fbrinat Technol, Yichang 443002, Peoples R China.
C3 Southwest Jiaotong University; China Three Gorges University
RP Abdullahi, SM (corresponding author), China Three Gorges Univ, Coll Comp & Fbrinat Technol, Yichang 443002, Peoples R China.
EM sani@my.swjtu.edu.cn
RI Zhang, Sheng/AAE-3571-2019; Abdullahi, Sani/HLH-2485-2023;
   Khudayberdiev, Otabek/GPP-7087-2022
OI Abdullahi, Sani/0000-0003-4962-2794; 
FU National Natural Science Foundation of China [62071396]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 62071396.
CR Ajith M, 2019, IEEE ACCESS, V7, P182381, DOI 10.1109/ACCESS.2019.2960209
   Basha SHS, 2020, NEUROCOMPUTING, V378, P112, DOI 10.1016/j.neucom.2019.10.008
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Chaoxia CY, 2020, IEEE ACCESS, V8, P58923, DOI 10.1109/ACCESS.2020.2982994
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Chino DYT, 2015, SIBGRAPI, P95, DOI 10.1109/SIBGRAPI.2015.19
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dimitropoulos K, 2017, IEEE T CIRC SYST VID, V27, P1143, DOI 10.1109/TCSVT.2016.2527340
   Dunnings AJ, 2018, IEEE IMAGE PROC, P1358
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Gaur A, 2019, IEEE SENS J, V19, P3191, DOI 10.1109/JSEN.2019.2894665
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hou J, 2011, MULTIMED TOOLS APPL, V52, P45, DOI 10.1007/s11042-009-0451-0
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huttner V., 2017, 2017 LAT AM ROB S LA, P1
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ko BC, 2009, FIRE SAFETY J, V44, P322, DOI 10.1016/j.firesaf.2008.07.006
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li ZL, 2018, IEEE T IND INFORM, V14, P1146, DOI 10.1109/TII.2017.2768530
   Marbach G, 2006, FIRE SAFETY J, V41, P285, DOI 10.1016/j.firesaf.2006.02.001
   Muhammad K, 2019, IEEE T IND INFORM, V15, P3113, DOI 10.1109/TII.2019.2897594
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Qiu T, 2012, IEEE T INSTRUM MEAS, V61, P1486, DOI 10.1109/TIM.2011.2175833
   Ramachandran P., 2017, Searching for activation functions
   Roque G, 2020, IEEE ACCESS, V8, P114900, DOI 10.1109/ACCESS.2020.3003848
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma J, 2017, COMM COM INF SC, V744, P183, DOI 10.1007/978-3-319-65172-9_16
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Steffens CR, 2015, 2015 12TH LATIN AMERICAN ROBOTICS SYMPOSIUM AND 2015 3RD BRAZILIAN SYMPOSIUM ON ROBOTICS (LARS-SBR), P25, DOI 10.1109/LARS-SBR.2015.10
   Steffens CR, 2016, PROCEEDINGS OF 13TH LATIN AMERICAN ROBOTICS SYMPOSIUM AND 4TH BRAZILIAN SYMPOSIUM ON ROBOTICS - LARS/SBR 2016, P257, DOI 10.1109/LARS-SBR.2016.50
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang T, 2020, IEEE-CAA J AUTOMATIC, V7, P263, DOI 10.1109/JAS.2019.1911546
   Wu XH, 2020, MULTIMED TOOLS APPL, V79, P69, DOI 10.1007/s11042-019-08047-5
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Yang H, 2019, IEEE ACCESS, V7, P169257, DOI 10.1109/ACCESS.2019.2953558
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 50
TC 8
Z9 8
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24553
EP 24572
DI 10.1007/s11042-022-12552-5
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200001
DA 2024-07-18
ER

PT J
AU Lin-Stephens, S
   Manuguerra, M
   Bulbert, MW
AF Lin-Stephens, Serene
   Manuguerra, Maurizio
   Bulbert, Matthew W.
TI Seeing is relieving: effects of serious storytelling with images on
   interview performance anxiety
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious storytelling; Visual narrative intervention; Image; Interview
   anxiety; Performance anxiety; Minimal intervention
ID VALIDITY; FACE; INTERVENTION; DEFINITION; MODEL
AB Serious storytelling as a media genre has the potential to accentuate the benefits of narrative interventions in health and education. To inform its application, it is necessary to identify effects of sensory inputs. Here, we focus on visual stimuli and observe their effects on an anxiety condition. We examine whether serious storytelling incorporating images, a type of basic visual stimuli, may reduce interview performance anxiety. In a double-blind randomised control trial, 69 participants with matched levels of anxiety received serious storytelling interview training and were allocated to exposure (image-based preparation) and control (standard preparation) groups. A week later, participants attended individual interviews with two independent interviewers and reported their interview anxiety. Analyses revealed a positive relationship between generalised anxiety and some dimensions of interview anxiety, but serious storytelling with images predicted a reduction in interview performance anxiety (effect size at the median value of covariates on a visual analogue scale with the range 0-100: -36.7, 95% CI [-54.7, -2.5]). Low participation burden in the brief intervention was confirmed through a deductive thematic analysis. The images were analysed based on format type and origin to inform further inquiries. This study yielded empirical findings with implications of media and technology development for serious storytelling. Seeing images of experiences during interview preparation was associated with a relief of interviewees' anxiety towards interview performance, but further studies are necessary to consolidate the evidence for visual narrative applications in health and education.
C1 [Lin-Stephens, Serene] Univ Sydney, Fac Med & Hlth, Discipline Rehabil Counselling, Sydney, NSW, Australia.
   [Lin-Stephens, Serene] Macquarie Univ, Off Pro Vice Chancellor Learning & Teaching, Sydney, NSW, Australia.
   [Manuguerra, Maurizio] Macquarie Univ, Fac Sci & Engn, Dept Math & Stat, Sydney, NSW, Australia.
   [Bulbert, Matthew W.] Oxford Brookes Univ, Dept Biol & Med Sci, Oxford, England.
C3 University of Sydney; Macquarie University; Macquarie University; Oxford
   Brookes University
RP Lin-Stephens, S (corresponding author), Univ Sydney, Fac Med & Hlth, Discipline Rehabil Counselling, Sydney, NSW, Australia.; Lin-Stephens, S (corresponding author), Macquarie Univ, Off Pro Vice Chancellor Learning & Teaching, Sydney, NSW, Australia.
EM serene.lin-stephens@sydney.edu.au; maurizio.manuguerra@mq.edu.au;
   mbulbert@brookes.ac.uk
OI Lin-Stephens, Serene/0000-0002-8996-3780; Bulbert,
   Matthew/0000-0002-7313-2536
CR Adenauer H, 2011, BMC NEUROSCI, V12, DOI 10.1186/1471-2202-12-127
   American College Health Association, 2019, NAT COLL HLTH ASS
   [Anonymous], J BUS COMMUN
   Ayres J, 1998, COMMUN EDUC, V47, P1, DOI 10.1080/03634529809379106
   Bandelow B, 2015, DIALOGUES CLIN NEURO, V17, P327
   Bangerter A, 2014, J BUS PSYCHOL, V29, P593, DOI 10.1007/s10869-014-9350-0
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   BJELLAND I, 2002, J PSYCHOSOM RES, V0052
   Bouchakwa M, 2020, MULTIMED TOOLS APPL, V79, P21679, DOI 10.1007/s11042-020-08862-1
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Buckley M.R., 2000, J MANAG HIST, V6, P113, DOI DOI 10.1108/EUM0000000005329
   Budnick CJ, 2019, ANXIETY STRESS COPIN, V32, P67, DOI 10.1080/10615806.2018.1530349
   Budnick CJ, 2015, ANXIETY STRESS COPIN, V28, P71, DOI 10.1080/10615806.2014.919386
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Curtis E.K., 2011, Journal of Clinical Art Therapy, V1, P9
   Davis LS, 2020, PUBLIC UNDERST SCI, V29, P688, DOI 10.1177/0963662520945136
   Demyttenaere K, 2004, JAMA-J AM MED ASSOC, V291, P2581, DOI 10.1001/jama.291.21.2581
   Dobson C., 1983, STRESS HIDDEN ADVERS, DOI [10.1007/978-94-011-7460-2, DOI 10.1007/978-94-011-7460-2]
   Fleming ND., 1995, 1995 ANN C HIGHER ED, P308
   Fonseca MJ, 2004, LECT NOTES COMPUT SC, V3115, P500
   Garwolinska K, 2018, BRIT J GUID COUNS, V46, P340, DOI 10.1080/03069885.2017.1370693
   Glasgow RE, 2014, TRANSL BEHAV MED, V4, P26, DOI 10.1007/s13142-013-0232-1
   Goncalves OF., 2011, HDB NARRATIVE PSYCHO, P102, DOI [10.4135/9781412973496, DOI 10.4135/9781412973496]
   Gunnarsson AB, 2013, AUST OCCUP THER J, V60, P154, DOI 10.1111/1440-1630.12034
   Haines-Saah RJ, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4061
   Hamdani MR, 2014, HUM RESOUR MANAGE R, V24, P160, DOI 10.1016/j.hrmr.2013.07.002
   Hayes C, 2020, HIGH EDUC SKILL WORK, V10, P313, DOI 10.1108/HESWBL-05-2019-0068
   Housen A., 2002, ARTS LEARNING RES, V18, P99
   Hu JG, 2018, MULTIMED TOOLS APPL, V77, P32179, DOI 10.1007/s11042-018-6152-9
   Huffcutt AI, 2011, HUM RESOUR MANAGE R, V21, P353, DOI 10.1016/j.hrmr.2011.05.003
   Julian LJ, 2011, ARTHRIT CARE RES, V63, pS467, DOI 10.1002/acr.20561
   Jung JE, 2017, MULTIMED TOOLS APPL, V76, P10371, DOI 10.1007/s11042-016-3626-5
   Kleiman LS, 2010, BUS PROF COMMUN Q, V73, P291, DOI 10.1177/1080569910376536
   Kolog EA, 2018, EDUC INF TECHNOL, V23, P911, DOI 10.1007/s10639-017-9643-9
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Kwon JH, 2013, INT J HUM-COMPUT ST, V71, P978, DOI 10.1016/j.ijhcs.2013.07.003
   Latham VM., 1987, J CAREER DEV, V14, P96, DOI [10.1177/089484538701400204, DOI 10.1177/089484538701400204]
   LERNER CJ, 1979, AM J OCCUP THER, V33, P500
   Liem J., 2020, THESIS U LONDON
   Lin-Stephens S, 2018, INT J INNOV SCI MATH, V26, P25
   Lin-Stephens S, 2020, ANXIETY STRESS COPIN, V33, P281, DOI 10.1080/10615806.2020.1734575
   Lin-Stephens S, 2019, COLL UNDERGRAD LIBR, V26, P234, DOI 10.1080/10691316.2019.1674027
   Lugmayr A, 2017, MULTIMED TOOLS APPL, V76, P15707, DOI 10.1007/s11042-016-3865-5
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   Macan T, 2009, HUM RESOUR MANAGE R, V19, P203, DOI 10.1016/j.hrmr.2009.03.006
   Manuguerra M, 2020, J STAT SOFTW, V96, DOI 10.18637/jss.v096.i08
   Maurizio M, 2020, ORDINAL REGRESSION A
   McCarthy J, 2004, PERS PSYCHOL, V57, P607, DOI 10.1111/j.1744-6570.2004.00002.x
   McIlveen P, 2007, AUST PSYCHOL, V42, P226, DOI 10.1080/00050060701405592
   Mellifont D, 2016, J WORKPLACE BEHAV HE, V31, P71, DOI 10.1080/15555240.2015.1119654
   Moher D, 2010, BMJ-BRIT MED J, V340, DOI [10.1136/bmj.c869, 10.1136/bmj.c332, 10.4103/0976-500X.72352, 10.1016/j.jclinepi.2010.02.005, 10.1186/1741-7015-8-18, 10.1016/j.ijsu.2011.09.004]
   Morina N, 2014, PEERJ, V2, DOI 10.7717/peerj.337
   National Institute of Health, 2018, REH ASS TECHN
   Nowell LS, 2017, INT J QUAL METH, V16, DOI 10.1177/1609406917733847
   Posthuma RA, 2002, PERS PSYCHOL, V55, P1, DOI 10.1111/j.1744-6570.2002.tb00103.x
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Powell DM, 2018, CAN J BEHAV SCI, V50, P195, DOI 10.1037/cbs0000108
   Ralston S.M., 2003, Business Communication Quarterly, V66, P8, DOI DOI 10.1177/108056990306600303
   RUBIN DC, 1984, COGNITION, V16, P81, DOI 10.1016/0010-0277(84)90037-4
   Schneider L, 2019, INT J SELECT ASSESS, V27, P328, DOI 10.1111/ijsa.12263
   Serrano-Laguna A, 2018, MULTIMED TOOLS APPL, V77, P2849, DOI 10.1007/s11042-017-4467-6
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Sprong ME, 2019, DISABIL REHABIL-ASSI, V14, P445, DOI 10.1080/17483107.2018.1463400
   Nguyen TTT, 2018, MENT HEALTH RELIG CU, V21, P484, DOI 10.1080/13674676.2018.1499715
   Thompson CharlesP., 1996, AUTOBIOGRAPHICAL MEM
   World Health Organization, 2020, MB24 3 ANX
   World Health Organization, 2020, 6B00 GEN ANX DIS
   Young M.J., 2004, COMMUN REP, V17, P49, DOI DOI 10.1080/08934210409389373
   Zhong Baoliang, 2009, J Thorac Dis, V1, P51
   Ziller R.C., 2000, Counselling Psychology Quarterly, V13, P265, DOI DOI 10.1080/095150700300091884
NR 73
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23399
EP 23420
DI 10.1007/s11042-022-12205-7
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800025
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Sharma, VS
   Nagwanshi, KK
   Sinha, GR
AF Sharma, Vivek S.
   Nagwanshi, Kapil Kumar
   Sinha, G. R.
TI Classification of defects in photonic bandgap crystal using machine
   learning under microsoft AzureML environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photonic band gap crystals; Finite difference time domain; Fast fourier
   transform; Rustboost classifier; Neural network
ID TIME-DOMAIN FDTD; POWER SPLITTER; EFFICIENCY
AB Photonic Bandgap crystals are avidly studied because of their application of optical waveguides, optical diodes, defect mode photonic lasers, to name a few. This paper presents a comparative study of 14 bandgap crystals [13 defective and 1 without defect]. The design, simulation, and classification-based analysis of these defective crystals obtained by modifying dielectric arrangement in photonic bandgap lattice (PBG) lattice is carried out. In addition, the study of the dielectric structure of rods in the air is carried out concerning photonic bandgap for a 9 x 10 mu m wafer size. The discrete pulse components in real data, imaginary data, and intensity data were obtained using Fast Fourier Transforms and were converted to a clean dataset. With context to defective Photonic Crystal analysis and design explored the predictive and generative models for data-driven approaches. Within the predictive modeling framework, Microsoft AzureML is used to give classification performance using five different algorithms. The relative effectiveness of these algorithms has been studied. The created data have been classified using Multiclass Artificial Neural Network, Multiclass Decision Jungle, Multiclass Logistic Regression, Multiclass Random Forest, and 2-Clsaas Support Vector Machine classifiers. The Multiclass Decision Jungle and Multiclass Random Forest exhibit the maximum accuracy of 91.01% and 91.20%, respectively, while the other three algorithms give the classification accuracy of 87.5%.
C1 [Sharma, Vivek S.] Loknete Gopinathji Munde Inst Engn Educ Res, Dept Math, Nasik 422002, Maharashtra, India.
   [Nagwanshi, Kapil Kumar] ASET Amity Univ Rajasthan, Dept Comp Sci Engn, Jaipur, Rajasthan, India.
   [Sinha, G. R.] Myanmar Inst Informat Technol, Dept Elect & Commun Engn, Mandalay, Myanmar.
RP Nagwanshi, KK (corresponding author), ASET Amity Univ Rajasthan, Dept Comp Sci Engn, Jaipur, Rajasthan, India.
EM vivek.sharma.math@gmail.com; dr.kapil@ieee.org; drgrsinha@ieee.org
RI Nagwanshi, Kapil Kumar/W-4185-2019
OI Nagwanshi, Kapil Kumar/0000-0003-3133-978X
CR [Anonymous], 2019, ML STUDIO CLASSIC MU
   [Anonymous], 2018, ARXIV181105660
   Azar MTH, 2018, FREQUENZ, V72, P79, DOI 10.1515/freq-2016-0265
   Baba T, 1997, IEEE J SEL TOP QUANT, V3, P808, DOI 10.1109/2944.640635
   Bacanin N, 2021, J REAL-TIME IMAGE PR, V18, P1085, DOI 10.1007/s11554-021-01106-x
   Bayindir M, 2001, PHYS REV B, V64, DOI 10.1103/PhysRevB.64.195113
   Bollimuntha RC, 2018, ADV FORMULATIONS APP
   Braun PV, 2006, ADV MATER, V18, P2665, DOI 10.1002/adma.200600769
   Chantakit T, 2014, APPL PHYS A-MATER, V117, P547, DOI 10.1007/s00339-014-8701-z
   Chen GH, 2013, J NONLINEAR OPT PHYS, V22, DOI 10.1142/S0218863513500124
   Chow E, 2001, OPT LETT, V26, P286, DOI 10.1364/OL.26.000286
   Christensen T, 2020, NANOPHOTONICS-BERLIN, V9, P4183, DOI 10.1515/nanoph-2020-0197
   DeCost B, 2021, ARXIV210601829
   Faloutsos C, 2012, MOR KAUF D, P393
   Ge DH, 2017, IOP CONF SER-MAT SCI, V170, DOI 10.1088/1757-899X/170/1/012005
   Hussein HME, 2018, OPT COMMUN, V411, P175, DOI 10.1016/j.optcom.2017.11.043
   Jindal P, 2018, OPTOELECTRON INSTRUM, V54, P576, DOI 10.3103/S8756699018060067
   Kalra Y, 2008, PRAMANA-J PHYS, V70, P153, DOI 10.1007/s12043-008-0013-4
   Lakshminarayanan V, 2012, MATH OPTICS CLASSICA
   Liu F, 2009, COMPUT GRAPH FORUM, V28, P127, DOI 10.1111/j.1467-8659.2008.01305.x
   Maka T, 2003, PROG EL RES, V41, P307, DOI 10.2528/PIER02010894
   Nagwanshi K, 2020, DATASET DEFECTIVE PH
   Nagwanshi KK, 2020, MODERN OPTIMIZATION METHODS FOR SCIENCE, ENGINEERING AND TECHNOLOGY, DOI 10.1088/978-0-7503-2404-5ch8
   Nagwanshi KK, 2020, INT J INTELL ENG INF, V8, P117
   Noda S, 2003, ROADMAP PHOTONIC CRY, P13, DOI 10.1007/978-1-4757-3716-5_2
   Rawat A, 2023, IETE J RES, V69, P2897, DOI 10.1080/03772063.2021.1907231
   Robinson S, 2014, AIP CONF PROC, V1620, P131, DOI 10.1063/1.4898231
   Selvaraja S.K., 2018, EMERGING WAVEGUIDE T, DOI DOI 10.5772/INTECHOPEN.77150
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Singh L.K, 2021, Multidisciplinary Functions of Blockchain Technology in AI and IoT Applications, P137
   Sullivan D, 2013, EXAMPLES ELECTROMAGN, P113
   Sullivan D, 2013, ONE DIMENSIONAL SIMU, P1
   Taflove A., 2000, COMPUTATIONAL ELECTR
   Xie T, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.145301
   YABLONOVITCH E, 1987, PHYS REV LETT, V58, P2059, DOI 10.1103/PhysRevLett.58.2059
   YEE KS, 1992, IEEE T ANTENN PROPAG, V40, P1068, DOI 10.1109/8.166532
   Yee KS, 1997, IEEE T ANTENN PROPAG, V45, P354, DOI 10.1109/8.558651
   Yonekura J, 1999, J LIGHTWAVE TECHNOL, V17, P1500, DOI 10.1109/50.779177
   Zhang Y, 2006, OPT EXPRESS, V14, P5723, DOI 10.1364/OE.14.005723
NR 39
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21887
EP 21902
DI 10.1007/s11042-022-11899-z
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770205800007
DA 2024-07-18
ER

PT J
AU Mirbeygi, M
   Mahabadi, A
   Ranjbar, A
AF Mirbeygi, Mohaddeseh
   Mahabadi, Aminollah
   Ranjbar, Akbar
TI Speech and music separation approaches-a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic-based sensing; Speech and music separation; Environmental
   sound; Big acoustic data; Multimedia tools
ID BLIND SOURCE SEPARATION; SINGING VOICE SEPARATION; BIG DATA;
   NEURAL-NETWORK
AB With the growth of acoustic data in the development of multimedia tools, mobile phones and the Internet of Multimedia Things (IoMT), recent studies exploit different models of machine hearing capable of capturing sounds, classification and separating them in different types of speech, music and environmental sounds. The separation of speech, music, and environmental sounds plays an important role in the automatic machine hearing to develop future applications for big acoustic data (BAD) processing. This paper critically reviews the various approaches and methods adopted in speech and music separation, and highlights how the algorithms and techniques can help machine hearing applications. First, we describe the main sound characteristics and features in order to discuss the approaches for separating sounds into speech and music in order to categorize the related literature. Next, we present the processing of voice, speech and music separately, and we explain machine hearing to analyze existing information approaches. Subsequently, we explain a new BAD model and the set of challenges that music and speech processing research algorithms should focus on and required novel items to big data processing in the future. Finally, all existing metrics and data sets are discussed and required future metrics and data sets for BAD in order to experiment and evaluate with new multimedia applications presented, with the conclusion of the future directions are discussed.
C1 [Mirbeygi, Mohaddeseh; Mahabadi, Aminollah] Shahed Univ, Comp Engn Dept, Tehran, Iran.
   [Mirbeygi, Mohaddeseh; Mahabadi, Aminollah; Ranjbar, Akbar] Shahed Univ, Acoust Res Ctr, Tehran, Iran.
   [Ranjbar, Akbar] Shahed Univ, Elect Engn Dept, Tehran, Iran.
C3 Shahed University; Shahed University; Shahed University
RP Mahabadi, A (corresponding author), Shahed Univ, Comp Engn Dept, Tehran, Iran.; Mahabadi, A (corresponding author), Shahed Univ, Acoust Res Ctr, Tehran, Iran.
EM mahabadi@shahed.ac.ir; am@ipm.ir
CR Abu Arqub O, 2020, SOFT COMPUT, V24, P12501, DOI 10.1007/s00500-020-04687-0
   Abu Arqub O, 2017, SOFT COMPUT, V21, P7191, DOI 10.1007/s00500-016-2262-3
   Aïssa-El-Bey A, 2007, EURASIP J AUDIO SPEE, DOI 10.1155/2007/85438
   Ajmera J, 2002, INT CONF ACOUST SPEE, P297
   Alías F, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050143
   Amodei D, 2016, PR MACH LEARN RES, V48
   Barchiesi D, 2015, IEEE SIGNAL PROC MAG, V32, P16, DOI 10.1109/MSP.2014.2326181
   Beerends JG, 2016, J AUDIO ENG SOC, V64, P784, DOI 10.17743/jaes.2016.0034
   Burute H., 2015, INT J COMPUT APPL, V129, P22
   Burute H, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P166, DOI 10.1109/ICATCCT.2015.7456876
   Chachada S, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.12
   Chan TS, 2015, INT CONF ACOUST SPEE, P718, DOI 10.1109/ICASSP.2015.7178063
   Chien JT, 2016, IEEE-ACM T AUDIO SPE, V24, P185, DOI 10.1109/TASLP.2015.2502141
   Cichocki A., 2009, NONNEGATIVE MATRIX T, DOI 10.1002/9780470747278
   Dafforn KA, 2016, MAR FRESHWATER RES, V67, P393, DOI 10.1071/MF15108
   Delic V, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4368036
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Driedger J, 2015, INT CONF ACOUST SPEE, P126, DOI 10.1109/ICASSP.2015.7177945
   Duan SF, 2014, ARTIF INTELL REV, V42, P637, DOI 10.1007/s10462-012-9362-y
   Dubey H, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P78, DOI 10.1109/CHASE.2016.46
   Dugan, 2015, ARXIV150903591
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   Févotte C, 2018, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-3-319-73031-8_1
   Févotte C, 2015, EUR SIGNAL PR CONF, P464, DOI 10.1109/EUSIPCO.2015.7362426
   Gauen K, 2017, ASIA S PACIF DES AUT, P99, DOI 10.1109/ASPDAC.2017.7858303
   Goel P, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), P403, DOI 10.1109/CICT.2016.85
   Grondin F, 2016, IEEE INT CONF ROBOT, P1650, DOI 10.1109/ICRA.2016.7487306
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Han JY, 2011, INT CONF ACOUST SPEE, P33
   Hobson-Webb LD, 2017, MUSCLE NERVE, V56, P375, DOI 10.1002/mus.25621
   Holmes, 2021, DEFINING VOICE DESIG
   Hossain MS, 2016, MOBILE NETW APPL, V21, P753, DOI 10.1007/s11036-016-0685-9
   Hsu CL, 2012, IEEE T AUDIO SPEECH, V20, P1482, DOI 10.1109/TASL.2011.2182510
   Huang PS, 2012, INT CONF ACOUST SPEE, P57, DOI 10.1109/ICASSP.2012.6287816
   Hurley N, 2005, IEEE WRK SIG PRO SYS, P442, DOI 10.1109/SIPS.2005.1579909
   Igarashi Y, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P464, DOI 10.1109/IIH-MSP.2013.121
   Ikemiya Y, 2016, IEEE-ACM T AUDIO SPE, V24, P2084, DOI 10.1109/TASLP.2016.2577879
   Ikemiya Y, 2015, INT CONF ACOUST SPEE, P574, DOI 10.1109/ICASSP.2015.7178034
   Khonglah BK, 2016, DIGIT SIGNAL PROCESS, V48, P71, DOI 10.1016/j.dsp.2015.09.005
   Kune R, 2017, SOFTWARE PRACT EXPER, V47, P455, DOI 10.1002/spe.2425
   Kune R, 2016, SOFTWARE PRACT EXPER, V46, P79, DOI 10.1002/spe.2374
   Lagrange M, 2008, IEEE T AUDIO SPEECH, V16, P278, DOI 10.1109/TASL.2007.909260
   Le Roux J, 2015, INT CONF ACOUST SPEE, P66, DOI 10.1109/ICASSP.2015.7177933
   Li F, 2018, EUR SIGNAL PR CONF, P1920, DOI 10.23919/EUSIPCO.2018.8553584
   Li SN, 2016, ISPRS J PHOTOGRAMM, V115, P119, DOI 10.1016/j.isprsjprs.2015.10.012
   Li YP, 2007, IEEE T AUDIO SPEECH, V15, P1475, DOI 10.1109/TASL.2006.889789
   Li Yipeng., 2006, ISMIR, V176, P179
   Liutkus A, 2012, INT CONF ACOUST SPEE, P53, DOI 10.1109/ICASSP.2012.6287815
   Lyon RF, 2010, IEEE SIGNAL PROC MAG, V27, P131, DOI 10.1109/MSP.2010.937498
   Mai YD, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P1400, DOI 10.1109/ICCSNT.2015.7490990
   McFee B, 2012, P 21 INT C WORLD WID, P909, DOI [DOI 10.1145/2187980, 10.1145/2187980.2188222]
   McLeod A, 2016, J NEW MUSIC RES, V45, P17, DOI 10.1080/09298215.2015.1136650
   McLoughlin Ian., 2009, APPL SPEECH AUDIO PR
   Meneghesso, 2017, APPLICATIONS, V2
   Mimilakis SI, 2021, EUR SIGNAL PR CONF, P1412, DOI 10.23919/Eusipco47968.2020.9287352
   Mirbeygi M, 2021, SPEECH COMMUN, V126, P22, DOI 10.1016/j.specom.2020.12.003
   Miyazaki K, 2019, IEEJ T ELECTR ELECTR, V14, P340, DOI 10.1002/tee.22868
   Mohammed A, 2007, RADIOENGINEERING, V16, P96
   Mowlavi, 2008, SPARSE SINUSOIDAL SI, P469
   Muller M., 2015, Fundamentals of Music Processing. Audio, Analysis, Algorithms, Applications, DOI [10.1007/978-3-319-21945-5, DOI 10.1007/978-3-319-21945-5]
   Munoz-Exposito J. E., 2006, 2006 14 EUR SIGN PRO
   Munoz-Exposito J.E., 2005, P ISMIR, V5, P16
   Nugraha AA, 2018, SIGNALS COMMUN TECHN, P157, DOI 10.1007/978-3-319-73031-8_7
   Ozerov A, 2005, IEEE WORK APPL SIG, P90, DOI 10.1109/ASPAA.2005.1540176
   Ozerov A, 2007, IEEE T AUDIO SPEECH, V15, P1564, DOI 10.1109/TASL.2007.899291
   Ozerov A, 2012, IEEE T AUDIO SPEECH, V20, P1118, DOI 10.1109/TASL.2011.2172425
   Pikrakis A, 2014, EUR SIGNAL PR CONF, P616
   Pulkki V., 2015, Communication acoustics: an introduction to speech, audio and psychoacoustics
   Puy G, 2017, INT CONF ACOUST SPEE, P1, DOI 10.1109/ICASSP.2017.7951786
   Radhakrishnan R, 2005, IEEE WORK APPL SIG, P158, DOI 10.1109/ASPAA.2005.1540194
   Rafii, 2013, INT SOC MUSIC INF RE, V10, P645
   Rafii Z., 2012, Proceedings of the 13th International Society for Music Information Retrieval Conference, ISMIR 2012, P583
   Rafii Z, 2015, INT CONF ACOUST SPEE, P271, DOI 10.1109/ICASSP.2015.7177974
   Rafii Z, 2014, IEEE-ACM T AUDIO SPE, V22, P1884, DOI 10.1109/TASLP.2014.2354242
   Rafii Z, 2013, IEEE T AUDIO SPEECH, V21, P71, DOI 10.1109/TASL.2012.2213249
   Rafii Z, 2011, INT CONF ACOUST SPEE, P221
   Rafii Z, 2011, INT CONF ACOUST SPEE, P217
   Rajapakse M, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P53, DOI 10.1109/MMMC.2005.44
   Rao V, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1135
   Reginer L, 2012, IEEE INT C ACOUSTICS, P1685
   Rickard S, 2007, SIGNALS COMMUN TECHN, P217, DOI 10.1007/978-1-4020-6479-1_8
   Roads Curtis., 1997, MUSICAL SIGNAL PROCE
   Rossing TD., 2007, Springer handbook of acoustics, V1
   Rumsey Francis., 2009, Sound and Recording, V6
   Sagiroglu S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P42
   Sarasola X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9153140
   Sell Gregory, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2489, DOI 10.1109/ICASSP.2014.6854048
   Sprechmann Pablo., 2012, ISMIR, P67
   Stanev M, 2016, P SPEECH PROS, P222
   Synder David, 2015, ARXIV151008484
   Tandra A, 2020, IEEE-ACM T AUDIO SPE, V28, P976, DOI 10.1109/TASLP.2020.2977776
   Taniguchi T, 2008, SPEECH COMMUN, V50, P547, DOI 10.1016/j.specom.2008.03.007
   Toroghi, 2016, BLIND SPEECH SEPARAT
   Tsai WH, 2014, IEEE INT CONGR BIG, P276, DOI 10.1109/BigData.Congress.2014.138
   Tsipas N, 2017, MULTIMED TOOLS APPL, V76, P25603, DOI 10.1007/s11042-016-4315-0
   Ullo SL, 2020, IEEE ACCESS, V8, P124055, DOI 10.1109/ACCESS.2020.3006082
   Vacher M, 2007, 4 IEEE C SPEECH TECH, P135
   Vallin, 2016, ARXIV160301824
   Vaseghi, 2008, ADV DIGITAL SIGNAL P, P29
   Vaseghi S., 2007, MULTIMEDIA SIGNAL PR
   Verma Jai Prakash., 2016, International Journal on Soft Computing, Artificial Intelligence and Applications, V5, P41, DOI [10.5121/ijscai.2016.5105, DOI 10.5121/IJSCAI.2016.5105]
   Vincent E, 2005, BSS_EVAL Toolbox User Guide-Revision 2.0
   Virtanen T., 2008, Proc. ITRW on Statistical and Perceptual Audio Processing (SAPA 2008), P17
   VIRTANEN T, 2000, THESIS TAMPERE U TEC
   Wolfe J., 2002, P 7 INT C MUS PERC C, P10
   Wu XD, 2014, IEEE T KNOWL DATA EN, V26, P97, DOI 10.1109/TKDE.2013.109
   Xu, 2017, 28 IEEE IR SIGN SYST, P1
   Zeremdini Jihen, 2015, Brain Inform, V2, P155
   Zhang ZC, 2021, NEUROCOMPUTING, V453, P896, DOI 10.1016/j.neucom.2020.08.069
NR 109
TC 4
Z9 4
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21155
EP 21197
DI 10.1007/s11042-022-11994-1
EA MAR 2022
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500010
DA 2024-07-18
ER

PT J
AU Pal, T
   Bhattacharjee, D
AF Pal, Tannistha
   Bhattacharjee, Debotosh
TI Visibility enhancement of fog degraded images using adaptive defogging
   function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive defogging function (ADF); ImageDehazing; SAMEER TU dataset;
   Qualitative evaluation
ID VISION ENHANCEMENT; RESTORATION; FUSION; WEATHER
AB In the field of image processing, analyzing fog-affected images is challenging, as their visibility is degraded. In the absence of state-of-the-art image processing techniques to mitigate the impact of high-density fog, an adaptive-function-based image-defogging technique is proposed in this paper. The proposed technique accurately enhances such degraded images by adjusting the contrast and brightness based on a suitable threshold operator. The images are subsequently characterized as foggy or non-foggy on the basis of objective evaluation. The experimental results have proven that the proposed method achieves superior performance in terms of qualitative evaluation on non-reference metric (i.e., in terms of e = 0.468, sigma = 0, r = 1.8857) and reference metric (i.e. in terms of MSE = 1580, PSNR = 19.2126, NCC = 0.4873, SC = 0.4684, MD = 60, NAE = 0.2229) compared with nine state-of-the-art dehazing methods. Furthermore, based on the average computational time achieved by the proposed method (0.36 s using a test set of 2000 images), it can be highly suitable for real-time applications.
C1 [Pal, Tannistha] Natl Inst Technol Agartala NITA, Dept Comp Sci & Engn, Agartala 799046, India.
   [Bhattacharjee, Debotosh] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala; Jadavpur University
RP Pal, T (corresponding author), Natl Inst Technol Agartala NITA, Dept Comp Sci & Engn, Agartala 799046, India.
EM tannisthapaul@gmail.com; debotosh@ieee.org
RI Bhattacharjee, Debotosh/L-8521-2015; Bhattacharjee, Debotosh/Q-4065-2019
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Pal, Tannistha/0000-0002-1317-7599
FU Society of Applied Microwave Electronics Engineering & Research
   (SAMEER), IIT Bombay, India [SMR/PD(R)/NER/2012-13/Thermography]
FX The work depicted here has been funded in part by the Grant no:
   SMR/PD(R)/NER/2012-13/Thermography,Dated 22/03/2013 from the Society of
   Applied Microwave Electronics Engineering & Research (SAMEER), IIT
   Bombay, India.
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   [Anonymous], 2012, P IEEE INT C SIGN PR, DOI DOI 10.1109/ISPCC.2012.6224342
   Ansia S, 2015, PROCEDIA COMPUT SCI, V46, P12, DOI 10.1016/j.procs.2015.01.042
   Anwar MI, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P198, DOI 10.1109/ICSCCC.2018.8703365
   Anwar MI, 2017, ENG SCI TECHNOL, V20, P1075, DOI 10.1016/j.jestch.2016.11.015
   Anwar MI, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSC), P233, DOI 10.1109/ICSPCom.2015.7150653
   Deng G, 2009, IEEE T IMAGE PROCESS, V18, P1135, DOI 10.1109/TIP.2009.2016796
   Enesi I., 2012, 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), P636, DOI 10.1109/CISIS.2012.179
   Fang FM, 2020, IEEE T MULTIMEDIA, V22, P2537, DOI 10.1109/TMM.2019.2958755
   Galdran A, 2015, SIAM J IMAGING SCI, V8, P1519, DOI 10.1137/15M1008889
   Gibson KB, 2013, IEEE IMAGE PROC, P714, DOI 10.1109/ICIP.2013.6738147
   Guo JM, 2017, IEEE T IMAGE PROCESS, V26, P4217, DOI 10.1109/TIP.2017.2706526
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Heng Zhang, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P759, DOI 10.1109/ISDEA.2010.312
   Hiramatsu T, 2008, IEEE IMAGE PROC, P3160, DOI 10.1109/ICIP.2008.4712466
   Huang J, 2017, APPL OPTICS, V56, P9686, DOI 10.1364/AO.56.009686
   Kang M, 2020, MULTIDIM SYST SIGN P, V31, P431, DOI 10.1007/s11045-019-00670-7
   Kim SE, 2020, IEEE T IMAGE PROCESS, V29, P1985, DOI 10.1109/TIP.2019.2948279
   Kumari A, 2021, IEEE ACCESS, V9, P48131, DOI 10.1109/ACCESS.2021.3068446
   Kumari A, 2014, ANNU IEEE IND CONF
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Li JY, 2010, INT CONF SIGN PROCES, P801, DOI 10.1109/ICOSP.2010.5655931
   Li Y, 2014, LECT NOTES COMPUT SC, V8690, P174, DOI 10.1007/978-3-319-10605-2_12
   Liu Y, 2017, IEEE ACCESS, V5, P8890, DOI 10.1109/ACCESS.2017.2710305
   Lu ZW, 2020, IEEE SIGNAL PROC LET, V27, P665, DOI 10.1109/LSP.2020.2985570
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan Srinivasa G., 2004, THESIS COLUMBIA U
   Pal, 2019, RECENT ADV COMPUT SC, V13, P1, DOI [10.2174/2213275912666190819105422, DOI 10.2174/2213275912666190819105422]
   Pal T, 2015, ADV INTELLIGENT SYST, V335, P325, DOI [10.1007/978-81-322-2217-0_28, DOI 10.1007/978-81-322-2217-0_28]
   Pal T, 2018, INT CONF COMPUT
   Pal T, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2583, DOI 10.1109/TENCON.2016.7848504
   Pal T, 2015, PROCEDIA COMPUT SCI, V46, P1676, DOI 10.1016/j.procs.2015.02.108
   Sakarya O, 2015, ACSIS-ANN COMPUT SCI, V5, P1049, DOI 10.15439/2015F222
   Salazar-Colores S, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0447-2
   Salazar-Colores S, 2019, IEEE T IMAGE PROCESS, V28, P2357, DOI 10.1109/TIP.2018.2885490
   Salazar-Colores S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043022
   Sridhar S., 2016, DIGITAL IMAGE PROCES
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Wang D, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.4.043106
   Wang WC, 2017, NEUROCOMPUTING, V238, P365, DOI 10.1016/j.neucom.2017.01.075
   Wang Y., 2010, P IEEE INT C INT C I, V2, P789, DOI DOI 10.1109/ISDEA.2010.141
   Xiao JS, 2020, NEUROCOMPUTING, V389, P108, DOI 10.1016/j.neucom.2020.01.007
   Yadav Sumit Kr, 2020, 2020 IEEE Region 10 Conference (TENCON), P444, DOI 10.1109/TENCON50793.2020.9293825
   Zhai YS, 2007, INT C WAVEL ANAL PAT, P522
   Zhang Hongkun, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P803, DOI 10.1109/CISP.2011.6100354
   Zou Xing, 2011, 2011 4th International Symposium on Computational Intelligence and Design, P99, DOI 10.1109/ISCID.2011.126
   Zubaidy, 2013, TELKOMNIKA INDONES J, V11, DOI [10.11591/telkomnika.v11i8.2872, DOI 10.11591/TELKOMNIKA.V11I8.2872]
NR 54
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35317
EP 35347
DI 10.1007/s11042-022-12182-x
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000770061500001
DA 2024-07-18
ER

PT J
AU Begum, N
   Mustafa, AS
AF Begum, Nazmin
   Mustafa, A. Syed
TI A novel approach for multimodal facial expression recognition using deep
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Face expression; Deep learning; Convolutional neural
   networks
AB Nowadays, digital protection has become greater prominence for daily digital activities. It's far vital for people to keep new passwords in their minds and carry additional playing cards with themselves. Such practices but are getting much less stable and realistic, as a consequence leading to a growing interest in techniques associated with biometrics systems. Biometrics structures keep the bodily residences of humans in electronic surroundings and enable them to be recognized by using the stored electronic records while needed. Several different face recognition and authentication methods had been proposed. However, most of the implementation is done using Principal Component Analysis(PCA) and measuring the recognition costs. In our work we propose a new approach for fast face recognition by applying deep learning techniques. We look at the outcome of recognition subject to the various components of the face and the eyes, mouth, nose, and brow. Distinctive features are extracted from the face, which is achieved using GreyLevel CoOccurrenceMatrix(GLCM). The GLCM method is a useful feature for feature extraction because of its excessive overall stabilizing local comparison. Lastly, dataset training and feature classification of the facial data's are carried out using Multi-Class Artificial neuralnetworks(MCANN) and Adaboost in which every distinctive face within the database is distinguished. Later the facial identification tool is tested on four groups of databases, AT&T, YALE B, VGG, and CASIA. In the end, we will apply analysis to measure accuracy and precision.
C1 [Begum, Nazmin; Mustafa, A. Syed] Visvesvaraya Technol Univ, HKBK Coll Engn, Dept ISE, Bengaluru, Karnataka, India.
C3 Visvesvaraya Technological University
RP Begum, N (corresponding author), Visvesvaraya Technol Univ, HKBK Coll Engn, Dept ISE, Bengaluru, Karnataka, India.
EM nazmeen.meher@gmail.com
RI MUSTAFA, SYED/JMR-3491-2023
OI MUSTAFA, SYED/0000-0001-9588-9452
CR [Anonymous], 2008, PROC INT C MACHINE L
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   El-Sayed MA, 2013, INT J ADV COMPUT SC, V4, P11
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sudeep, 2018, 4 INT C COMP COMM CO
   Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747
   Zhang N., 2007, Tech. Rep. 07-49, P7
NR 9
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18521
EP 18529
DI 10.1007/s11042-022-12238-y
EA MAR 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300011
DA 2024-07-18
ER

PT J
AU Hu, YC
   Liu, JS
   Lo, CC
   Wu, CM
   Chen, Y
AF Hu, Yu-Chen
   Liu, Jain-Shing
   Lo, Chun-Chi
   Wu, Chang-Ming
   Chen, Yu
TI Grayscale image coding using optimal pixel grouping and adaptive
   multi-grouping division block truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image coding; Block truncation coding; Multi-grouping block truncation
   coding; Optimal pixel grouping
ID DATA HIDING SCHEME; TAMPER DETECTION; BTC
AB An efficient grayscale image coding scheme based on block truncation coding (BTC) is proposed. The optimal pixel grouping mechanism and the multi-grouping division process are employed in the proposed scheme. An entropy-based indicator generation mechanism is employed to generate the block indicators of different groups. In addition, an optional bit rate reduction mechanism for dynamic block division is designed. Simulation results verify that significant image quality gain is acquired by the proposed scheme compared to the state-of-art image coding methods based on BTC. Meanwhile, a lower bit rate is consumed by the proposed scheme.
C1 [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
   [Liu, Jain-Shing; Lo, Chun-Chi] Providence Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Wu, Chang-Ming] Chung Yuan Christian Univ, Dept Elect Engn, Taoyuan 32023, Taiwan.
   [Chen, Yu] Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Peoples R China.
C3 Providence University - Taiwan; Providence University - Taiwan; Chung
   Yuan Christian University; Fujian University of Technology
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
EM ychu@pu.edu.tw; chhliu@pu.edu.tw; cclo@pu.edu.tw; cmwu@cycu.edu.tw;
   chen@fjut.edu.cn
RI Hu, Yu-Chen/AAT-5264-2020; Hui, Yu/JOZ-3598-2023
OI Hu, Yu-Chen/0000-0002-5055-3645; 
FU Ministry of Science and Technology, Taiwan, R.O.C.
   [106-2410-H-126-006-MY2, 108-2410-H-020-MY2]
FX This research was partially supported by the Ministry of Science and
   Technology, Taiwan, R.O.C. under contracts 106-2410-H-126-006-MY2 and
   108-2410-H-020-MY2.
CR Bhardwaj R, 2021, MULTIMED TOOLS APPL, V80, P26161, DOI 10.1007/s11042-021-10722-5
   Chang IC, 2015, SIGNAL PROCESS, V108, P376, DOI 10.1016/j.sigpro.2014.09.036
   CHEN DP, 1990, IEEE T COMMUN, V38, P2137, DOI 10.1109/26.64656
   Chen W.-L., 2014, INT J SIGNAL PROCESS, V7, P65, DOI DOI 10.14257/IJSIP.2014.7.1.07
   Chen YY, 2023, COMPLEX INTELL SYST, V9, P2699, DOI 10.1007/s40747-021-00391-0
   Chuang JC, 2019, MULTIMED TOOLS APPL, V78, P35537, DOI 10.1007/s11042-019-08193-w
   Daga, 2018, P 2 INT C DIG SIGN P
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Hemida O, 2020, MULTIMED TOOLS APPL, V79, P18695, DOI 10.1007/s11042-020-08727-7
   Hu YC, 2008, IMAGING SCI J, V56, P254, DOI 10.1179/174313108X2995.14
   Hu YC, 2013, OPTO-ELECTRON REV, V21, P137, DOI 10.2478/s11772-013-0078-6
   Hu YC, 2011, OPTO-ELECTRON REV, V19, P104, DOI 10.2478/s11772-010-0073-0
   Hu YC, 2013, IMAGING SCI J, V61, P80, DOI 10.1179/1743131X11Y.0000000043
   Hu YC, 2003, ELECTRON LETT, V39, P1377, DOI 10.1049/el:20030884
   Hu YC, 2003, OPT ENG, V42, P1964, DOI 10.1117/1.1576776
   Hu YC, 1999, IEEE T CONSUM ELECTR, V45, P310, DOI 10.1109/30.793414
   Hu YC, 2017, MULTIMED TOOLS APPL, V76, P15435, DOI 10.1007/s11042-016-3847-7
   Hu YC, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.9.093104
   Hu YC, 2013, SIGNAL PROCESS, V93, P2432, DOI 10.1016/j.sigpro.2013.03.034
   Hui Z, 2020, MULTIMED TOOLS APPL, V79, P24241, DOI 10.1007/s11042-020-09015-0
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P32239, DOI 10.1007/s11042-019-07997-0
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin YH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091974
   Liu, 2018, P 3 INT C COMP COMM
   Lo CC, 2014, INT J SECUR APPL, V8, P301, DOI 10.14257/ijsia.2014.8.2.31
   Ma, 1991, IEEE INT S CIRC SYST
   Ma KK, 1996, OPT ENG, V35, P213, DOI 10.1117/1.600891
   NASIOPOULOS P, 1991, IEEE T COMMUN, V39, P1245, DOI 10.1109/26.134014
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   RAO YVR, 1995, IEEE T COMMUN, V43, P2010, DOI 10.1109/26.387439
   Tsai P, 2008, FUND INFORM, V87, P447
   Tsou CC, 2008, IMAGING SCI J, V56, P217, DOI 10.1179/174313108X281335
   WU YY, 1992, IEEE J SEL AREA COMM, V10, P952, DOI 10.1109/49.139000
   Xiang ZY, 2019, MULTIMED TOOLS APPL, V78, P7895, DOI 10.1007/s11042-018-6030-5
NR 35
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17937
EP 17958
DI 10.1007/s11042-022-12680-y
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000001
DA 2024-07-18
ER

PT J
AU Ranganath, A
   Senapati, MR
   Sahu, PK
AF Ranganath, Abadhan
   Senapati, Manas Ranjan
   Sahu, Pradip Kumar
TI A novel pixel range calculation technique for texture classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractal dimension; Texture classification; Local binary pattern; Pixel
   range calculation; Multi fractal Spectrum; Gliding box
ID LOCAL BINARY PATTERNS; GRAY-SCALE; FEATURES; GLCM; LACUNARITY;
   DESCRIPTOR; IMAGES
AB In this article, a fractal base method has been implemented as a texture descriptor. As, fractal deals with self-similarity, the proposed method is able to find the similarity of local patterns of various images of similar group and discriminate the images of dissimilar patterns. Images are converted to binary images by using the concept of local binary pattern. In this paper we have proposed a new approach for texture classification called Pixel Range Calculation (PRC) method, which has been implemented by converting the color images to gray images. Four benchmarking datasets, such as, ALOT (Amsterdam Library Of Textures), UMD (University of MarylanD), KTH-TIPS2b (Kungliga Tekniska Hogskolan-Textures under varying Illumination, Pose and Scale) and UIUC (University of Illinois at Urbana-Champaign) has been used for our experimental purpose. The proposed method along with two state of art method namely, Gliding Box Method (GBM) and Multi Fractal Spectrum (MFS) has been implemented and tested on the above-mentioned datasets. The experimental results based on the classification accuracy show the PRC technique of fractal dimension estimation method out performs the GBM and MFS. It has been observed that the computational complexity of PRC method is much less than other two state of art methods.
C1 [Ranganath, Abadhan; Senapati, Manas Ranjan; Sahu, Pradip Kumar] Veer Surendra Sai Univ Technol, Dept Informat Technol, Burla, Sambalpur, India.
C3 Veer Surendra Sai University of Technology
RP Sahu, PK (corresponding author), Veer Surendra Sai Univ Technol, Dept Informat Technol, Burla, Sambalpur, India.
EM aranganath_phdit@vssut.ac.in; manassena@gmail.com; pksahu_it@vssut.ac.in
RI Ranganath, Abadhan/HKO-6680-2023
OI Ranganath, Abadhan/0000-0002-9556-5084
FU Veer Surendra Sai University of Technology, India
FX The authors acknowledge the support given by Veer Surendra Sai
   University of Technology, India under TEQIP-III.
CR ALLAIN C, 1991, PHYS REV A, V44, P3552, DOI 10.1103/PhysRevA.44.3552
   ALOT, TEXT DAT
   Anantrasirichai N, 2013, I S BIOMED IMAGING, P1332
   Brodatz texture dataset, SIPI IMAGE DATABASE
   Bu XY, 2019, PATTERN RECOGN, V91, P34, DOI 10.1016/j.patcog.2019.02.003
   Dash S, 2018, EGYPT INFORM J, V19, P133, DOI 10.1016/j.eij.2018.01.003
   EICHMANN G, 1988, COMPUT VISION GRAPH, V41, P267, DOI 10.1016/0734-189X(88)90102-8
   GAGNEPAIN JJ, 1986, WEAR, V109, P119, DOI 10.1016/0043-1648(86)90257-7
   Gupta Y, 2020, MULTIMED TOOLS APPL, V79, P32195, DOI 10.1007/s11042-020-09676-x
   Hall-Beyer M, 2017, INT J REMOTE SENS, V38, P1312, DOI 10.1080/01431161.2016.1278314
   Ji H, 2013, IEEE T IMAGE PROCESS, V22, P286, DOI 10.1109/TIP.2012.2214040
   Kang XD, 2017, IEEE T GEOSCI REMOTE, V55, P7140, DOI 10.1109/TGRS.2017.2743102
   KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8
   Khmag A, 2018, VISUAL COMPUT, V34, P575, DOI 10.1007/s00371-017-1362-0
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Kim SC, 2007, PATTERN RECOGN, V40, P1207, DOI 10.1016/j.patcog.2006.09.012
   KIRKBY MJ, 1983, EARTH SURF PROC LAND, V8, P287, DOI 10.1002/esp.3290080310
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu CX, 2017, VISUAL COMPUT, V33, P769, DOI 10.1007/s00371-017-1380-y
   Liu L, 2019, IEEE T IMAGE PROCESS, V28, P3910, DOI 10.1109/TIP.2019.2903300
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu XW, 2003, IEEE T IMAGE PROCESS, V12, P661, DOI 10.1109/TIP.2003.812327
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Quan YH, 2017, COMPUT VIS IMAGE UND, V165, P85, DOI 10.1016/j.cviu.2017.10.008
   Quan YH, 2014, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2014.28
   Quan YH, 2014, IMAGE VISION COMPUT, V32, P250, DOI 10.1016/j.imavis.2014.02.004
   Raju P, 2019, MULTIMED TOOLS APPL, V78, P18419, DOI 10.1007/s11042-018-7145-4
   Ranganath A, 2021, VISUAL COMPUT, V37, P635, DOI 10.1007/s00371-020-01829-1
   Ranganath A, 2017, IEEE INT ADV COMPUT, P678, DOI [10.1109/IACC.2017.0142, 10.1109/IACC.2017.133]
   SARKAR N, 1994, IEEE T SYST MAN CYB, V24, P115, DOI 10.1109/21.259692
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   Wang JM, 2019, SIGNAL IMAGE VIDEO P, V13, P163, DOI 10.1007/s11760-018-1341-6
   Xing ZK, 2020, MULTIMED TOOLS APPL, V79, P12007, DOI 10.1007/s11042-019-08566-1
   Xu Y., 2006, 2006 IEEE COMP SOC C, P1932
   Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Zhao XC, 2019, IEEE T MULTIMEDIA, V21, P1694, DOI 10.1109/TMM.2018.2890362
NR 42
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17639
EP 17667
DI 10.1007/s11042-022-12186-7
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900002
DA 2024-07-18
ER

PT J
AU Adapa, S
   Enireddy, V
AF Adapa, Srinivas
   Enireddy, Vamsidhar
TI RETRACTED: Human character identification using facial features and
   optimised deep convolutional neural network (Retracted Article)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Human character; WBF; DCRNN; Sanguine; Choleric; Phlegmatic;
   Melancholic; Viola-Jones algorithm
ID FACE SHAPE
AB Human character is the collection of actions, qualities and habits, which differentiate one individual from the other. In humans, characters are the inborn features and it is responsible for every human behaviors or activity is done in the environment. The identification of the original character of an individual is complex. To extract effective features and constructing a novel robust classifier still remains a major challenge in this area. In this work, the authors aimed at developing a deep learning-based human character identification model using facial features. Initially, preprocessing takes place by weighted bilateral filter (WBF) to swipe up the unwanted distortions, scarcities and the background of an image. Along with this, the feature extraction process is agonized to extract the facial feature to precisely classify the character based on the Viola-Jones algorithm (VJA). Based on facial features, the character of the person can be identified with the deep learning approaches. Thus, this work mainly focused on identifying the human characters based on the deep convolutional neural network-Rain fall optimization (DCRNN) model under four strategies namely, Sanguine (oblong face), Choleric (square face), Phlegmatic (heart face) and Melancholic (round face) with high accuracy and efficiency. The performance of the proposed model is finally validated with existing methods of CNN, DCNN, inception CNN, SVM, SVM-RBF, SVM-LF, KNN and PNN in terms of accuracy, precision, recall, specificity, f-measure, MAE, RMSE and PCC. The proposed model procures a performance of 96%, 94%, 98%, 95%, 0.07, 0.15 and 94% respectively due to the incorporation of RFO with DCNN model for fine tuning and diminishing the error functions. Along with this, the statistical analysis of Wilcoxon and Friedman test are also evaluated and attains a best outcome.
C1 [Adapa, Srinivas; Enireddy, Vamsidhar] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Adapa, S (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
EM srinivas2804@gmail.com; enireddy.vamsidhar@gmail.com
RI ENIREDDY, VAMSIDHAR/S-2920-2018
OI ENIREDDY, VAMSIDHAR/0000-0001-6082-7497
CR Akhtar S, 2020, HUMAN PHYS HAIAT ESS
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Alzahrani T., 2019, 2019 INT C INT SYST, P1
   Alzahrani T, 2021, COMPUTATION, V9, DOI 10.3390/computation9050054
   Bansode N., 2016, Int J Comput Sci Issue (IJCSI), V13, P24, DOI DOI 10.20943/IJCSI-201602-2431
   Chen Y, 2021, ARXIV210406885
   Chen Z, 2017, BEHAV INFORM TECHNOL, V36, P839, DOI 10.1080/0144929X.2017.1304994
   Fischer JM, 2011, PHILOS PHENOMEN RES, V82, P381, DOI 10.1111/j.1933-1592.2010.00458.x
   Gavrilescu M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0211-4
   Goodacre CJ, 2020, J PROSTHODONT, V29, P594, DOI 10.1111/jopr.13215
   Hassin R, 2000, J PERS SOC PSYCHOL, V78, P837, DOI 10.1037/0022-3514.78.5.837
   Kaushal V, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3070645
   Pasupa K, 2019, EXPERT SYST APPL, V120, P14, DOI 10.1016/j.eswa.2018.11.011
   Petpairote C, 2018, IET COMPUT VIS, V12, P252, DOI 10.1049/iet-cvi.2017.0352
   Rahmat Romi Fadillah, 2018, IOP Conference Series: Materials Science and Engineering, V420, DOI 10.1088/1757-899X/420/1/012095
   Sano T, 2020, IEEE ROMAN, P159, DOI [10.1109/ro-man47096.2020.9223574, 10.1109/RO-MAN47096.2020.9223574]
   Sarakon P, 2014, 2014 7TH BIOMEDICAL ENGINEERING INTERNATIONAL CONFERENCE (BMEICON)
   Schwartz CE, 1996, DEV PSYCHOPATHOL, V8, P527, DOI 10.1017/S0954579400007252
   Setyadi AD, 2015, 2015 International Electronics Symposium (IES), P263, DOI 10.1109/ELECSYM.2015.7380852
   Sukumaran A, 2021, MULTIMED TOOLS APPL, V80, P25689, DOI 10.1007/s11042-021-10710-9
   Sun JK, 2022, IEEE T KNOWL DATA EN, V34, P2348, DOI 10.1109/TKDE.2020.3008774
   Sunhem W, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P390, DOI 10.1109/ICACI.2016.7449857
   Tio A. E., 2019, Face Shape Classification Using Inception V3
   Vikram K, 2017, INT CONF ADVAN COMPU
   Wolffhechel K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107721
   Wu GM, 2020, IET IMAGE PROCESS, V14, P1840, DOI 10.1049/iet-ipr.2018.6272
   Wulansari Z., 2021, JOSAR J STUDENTS ACA, V6, P33
   Zafar A., 2016, Graphics Interface Conference, P183
   Zhang T, 2017, INT J AUTOM COMPUT, V14, P386, DOI 10.1007/s11633-017-1085-8
   Zul MI, FACE SHAPE IDENTIFIC
NR 33
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31197
EP 31197
DI 10.1007/s11042-022-12009-9
EA MAR 2022
PG 1
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000763256600022
DA 2024-07-18
ER

PT J
AU Li, GQ
   Song, HJ
   Mitrouchev, P
AF Li, Guiqin
   Song, Haoju
   Mitrouchev, Peter
TI Surface feature detection and identification based on image processing
   for communication backplane
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Communication backplane; Surface feature detection; Image
   identification; Adaptive median filtering; Support vector machine
ID FEATURE-EXTRACTION; IMPROVED SIFT
AB As the infrastructure of telecommunication service, communication-based station equipment directly affects the stable operation of the entire communication network. Therefore, detecting and identifying the features of communication backplane is of great significance. A feature detection method based on image identification is proposed here, which can simplify the complexity of extracting and recognizing the surface features on communication backplane with fewer images. The preprocessing of communication backplane image is solved with a space domain enhancement method based on point operation and an improved adaptive median filter. The feature of communication backplane image is extracted based on the Scale-invariant feature transform (SIFT) algorithm and the Support vector machine (SVM) classifier is trained according to the image and class features to implement the automatic identification of communication backplane. The experimental results show that the proposed method has good identification accuracy thus allows effective identification of the types of communication backplane surface features.
C1 [Li, Guiqin; Song, Haoju] Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, Shanghai 200444, Peoples R China.
   [Mitrouchev, Peter] Univ Grenoble Alpes, G SCOP, F-38030 Grenoble, France.
C3 Shanghai University; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA);
   Centre National de la Recherche Scientifique (CNRS)
RP Li, GQ (corresponding author), Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, Shanghai 200444, Peoples R China.
EM leeching@shu.edu.cn
RI Song, Haoju/IXB-8430-2023
OI Song, Haoju/0000-0003-3764-7062; Li, Guiqing/0000-0003-3620-5895
CR Boutaba R, 2018, J INTERNET SERV APPL, V9, DOI 10.1186/s13174-018-0087-2
   Chen HY, 2020, J INTELL MANUF, V31, P453, DOI 10.1007/s10845-018-1458-z
   Chu HH, 2016, INT J ADV MANUF TECH, V86, P3007, DOI 10.1007/s00170-015-8334-1
   Din IU, 2019, MULTIMED TOOLS APPL, V78, P30241, DOI 10.1007/s11042-018-6943-z
   Ding F, 2019, MULTIMED TOOLS APPL, V78, P8225, DOI 10.1007/s11042-018-6807-6
   Fu WL, 2014, IEEE T CYBERNETICS, V44, P1459, DOI 10.1109/TCYB.2013.2286611
   Galan U, 2019, INT J ADV MANUF TECH, V101, P317, DOI 10.1007/s00170-018-2933-6
   Jin R, 2017, MULTIMED TOOLS APPL, V76, P5927, DOI 10.1007/s11042-015-2694-2
   Kim D, 2019, TELECOMMUN SYST, V71, P517, DOI 10.1007/s11235-018-0525-2
   Kuo YL, 2015, INT J FUZZY SYST, V17, P67, DOI 10.1007/s40815-015-0005-8
   Li CR, 2018, LECT NOTES COMPUT SC, V11068, P487, DOI 10.1007/978-3-030-00021-9_44
   Lu LY, 2018, APPL INTELL, V48, P2393, DOI 10.1007/s10489-017-1087-9
   Lyu YD, 2017, CHINESE J ELECTRON, V26, P345, DOI 10.1049/cje.2017.01.028
   Min YZ, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0241-y
   Monno S., 2018, INT C INT NETW COLL, P47
   Ofir N, 2020, IEEE T PATTERN ANAL, V42, P894, DOI 10.1109/TPAMI.2019.2892134
   Remeseiro B, 2019, INT J ADV MANUF TECH, V105, P3761, DOI 10.1007/s00170-019-03819-7
   Ren RX, 2018, IEEE T CYBERNETICS, V48, P929, DOI 10.1109/TCYB.2017.2668395
   Rey-Otero I, 2016, J MATH IMAGING VIS, V56, P554, DOI 10.1007/s10851-016-0657-5
   Shi ZH, 2019, MULTIMED TOOLS APPL, V78, P1017, DOI 10.1007/s11042-018-6082-6
   Wei XK, 2020, IEEE T INTELL TRANSP, V21, P947, DOI 10.1109/TITS.2019.2900385
   Xu K, 2019, J AMB INTEL HUM COMP, V10, P3297, DOI 10.1007/s12652-018-1055-1
   Yu ZY, 2017, LECT NOTES COMPUT SC, V10528, P417, DOI 10.1007/978-3-319-68345-4_37
   Zhang H, 2018, COMM COM INF SC, V924, P443, DOI 10.1007/978-981-13-2384-3_41
   Zhang XN, 2023, MULTIMED TOOLS APPL, V82, DOI 10.1007/s11042-019-7340-y
NR 25
TC 1
Z9 2
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10589
EP 10606
DI 10.1007/s11042-022-12143-4
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700011
DA 2024-07-18
ER

PT J
AU Vijh, S
   Saraswat, M
   Kumar, S
AF Vijh, Surbhi
   Saraswat, Mukesh
   Kumar, Sumit
TI Automatic multilevel image thresholding segmentation using hybrid
   bio-inspired algorithm and artificial neural network for histopathology
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Multi-level image thresholding; Lion optimization; Cat
   swarm optimization; Artificial neural network
ID OPTIMIZATION ALGORITHM; NUCLEI; CLASSIFICATION
AB Automated medical imagining is growing rapidly for advanced clinical treatment and intervention in medical diagnosis. The segmentation of nuclei in digital histopathology is considered the most crucial aspect in diagnosis and evaluating the severity of disease. Therefore, in this paper, an automated nuclei segmentation method has been introduced for the histopathological images. The proposed segmentation method uses a new hybrid algorithm of lion optimization and cat swarm optimization to provide an optimal threshold value for efficient multi-level image thresholding segmentation. Moreover, a new fitness function using Otsu's function and Yager's entropy has also been presented for robust results. Extensive simulations are examined to determine the performance of the proposed hybrid algorithm. Firstly, evaluation on CEC 2017 benchmark suite are performed using three quality metrics, namely average fitness value, peak signal-to-noise ratio, and structural similarity index. Secondly, for the performance analysis of developed segmentation method, two Histopathological data sets are used, namely breast Histopathological images and lung Histopathological images. Furthermore, to find the optimum number of clusters, artificial neural network has been used and its performance is measured in terms of the accuracy, sensitivity, and specificity. The classifier returned an accuracy of 71.4%, sensitivity of 93.23%, and specificity of 93.12% for breast Histopathological images. For lung Histopathological images, the accuracy, sensitivity, and specificity were 66.17%, 89.53%, and 90.62% respectively. Moreover, the proposed method is also validated using the ground truth images, acquired from expert pathologist, by calculating dice coefficient and Jaccard coefficient. The findings and observation show that the proposed algorithm provides promising and significant result.
C1 [Vijh, Surbhi] Amity Univ, ASET, Noida, India.
   [Saraswat, Mukesh] Jaypee Inst Informat Technol, Noida, India.
   [Kumar, Sumit] Amity Univ, Noida, India.
C3 Amity University Noida; Jaypee Institute of Information Technology
   (JIIT); Amity University Noida
RP Kumar, S (corresponding author), Amity Univ, Noida, India.
EM surbhivijh428@gmail.com; saraswatmukesh@gmail.com;
   sumitkumarbsr19@gmail.com
RI Kumar, Sumit/HHS-8959-2022; kumar, sumit/AAZ-5668-2021
OI kumar, sumit/0000-0002-0205-8412
CR Abd El Aziz M, 2018, STUD COMPUT INTELL, V730, P23, DOI 10.1007/978-3-319-63754-9_2
   Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abdolhoseini M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38813-2
   Cruz-Roa AA, 2013, LECT NOTES COMPUT SC, V8150, P403, DOI 10.1007/978-3-642-40763-5_50
   Almezeini N, 2017, INT J ADV COMPUT SC, V8, P77
   [Anonymous], 2012, INT J ENG TECHNOL
   Bansal P, 2019, SOFT COMPUT, V23, P12331, DOI 10.1007/s00500-019-03773-2
   Belsare A., 2012, Signal & Image Processing, V3, P23, DOI DOI 10.5121/SIPIJ.2012.3403
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhardwaj R, 2019, PERVASIVE MOB COMPUT, V58, DOI 10.1016/j.pmcj.2019.05.010
   Boothalingam R, 2018, EVOL INTELL, V11, P31, DOI 10.1007/s12065-018-0168-y
   Bosnacki D, 2019, COMPUT BIOL SER, V30, P453, DOI 10.1007/978-3-030-17297-8_17
   Cetin M, 2019, 2019 SCIENT M EL, P1
   Chu SC, 2007, INT J INNOV COMPUT I, V3, P163
   Crawford B, 2016, LECT NOTES COMPUT SC, V9786, P220, DOI 10.1007/978-3-319-42085-1_17
   Dhal KG, 2019, PATTERN RECOGN IMAGE, V29, P344, DOI 10.1134/S1054661819030052
   Duraisamy Sathya P., 2010, Journal of Intelligent Learning Systems and Applications, V2, P126, DOI 10.4236/jilsa.2010.23016
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   García-Lamont F, 2020, PATTERN ANAL APPL, V23, P59, DOI 10.1007/s10044-018-0729-9
   Geetha K, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12508
   Ghosh M., 2010, 2010 International Conference on Systems in Medicine and Biology (ICSMB), P409, DOI 10.1109/ICSMB.2010.5735414
   Ghosh M, 2013, 2013 INDIAN CONFERENCE ON MEDICAL INFORMATICS AND TELEMEDICINE (ICMIT 2013), P13, DOI 10.1109/IndianCMIT.2013.6529400
   Gu SK, 2018, SOFT COMPUT, V22, P811, DOI 10.1007/s00500-016-2385-6
   Guo, 2015, OPEN AUTOM CONTROL S, V1, P7
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Huang X, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317864
   Ilea DE, 2008, IEEE T IMAGE PROCESS, V17, P1926, DOI 10.1109/TIP.2008.2001047
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Jayaraman V., 2019, J. AmbientIntell. Humanized Comput., P1, DOI [10.1007/s12652-019-01193-6, DOI 10.1007/S12652-019-01193-6]
   Jothi AA, 2016, APPL SOFT COMPUT, V46, P652, DOI 10.1016/j.asoc.2016.02.030
   Jothi JAA, 2017, ARTIF INTELL REV, V48, P31, DOI 10.1007/s10462-016-9494-6
   Jothi JAA, 2015, ADV INTELL SYST, V325, P835, DOI 10.1007/978-81-322-2135-7_88
   Kate Vandana, 2020, Social Networking and Computational Intelligence. Proceedings of SCI-2018. Lecture Notes in Networks and Systems (LNNS 100), P207, DOI 10.1007/978-981-15-2071-6_17
   Khan A, 2013, MULTIMED TOOLS APPL, V64, P331, DOI 10.1007/s11042-012-1003-6
   Kirti AS, 2020, NATURE INSPIRED COMP, V323
   Lai CC., 2004, INT J HYBRID INTELL, V1, P143
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   Lei XJ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P692, DOI 10.1109/ICNC.2008.822
   Li LG, 2017, INFORMATION, V8, DOI 10.3390/info8010016
   Manic K. S., 2016, Indian J Sci Technol, V9, DOI [10.17485/fist/2016/v9i12/89949, DOI 10.17485/IJST/2016/V9I12/89949]
   Masood A, 2015, IEEE ENG MED BIO, P781, DOI 10.1109/EMBC.2015.7318478
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   Olorunda O, 2008, IEEE C EVOL COMPUTAT, P1128, DOI 10.1109/CEC.2008.4630938
   Ozturk Saban, 2018, Procedia Computer Science, V132, P40, DOI 10.1016/j.procs.2018.05.057
   Purohit AD., 2017, INT J COMPUTER SCI M, V6, P267
   Rajakumar BR, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2116, DOI 10.1109/CEC.2014.6900561
   Rusu M, 2017, EUR RADIOL, V27, P4209, DOI 10.1007/s00330-017-4813-0
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Samantaa S, 2013, MULTILEVEL THRESHOLD
   Shu J, 2020, BIOINFORMATICS, V36, P3225, DOI 10.1093/bioinformatics/btaa107
   Shu J, 2013, IEEE ENG MED BIO, P5445, DOI 10.1109/EMBC.2013.6610781
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Tang Ying-gan, 2007, Control and Decision, V22, P202
   Tian AQ, 2020, PROCESSES, V8, DOI 10.3390/pr8030356
   Veta M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070221
   Vijh S, 2020, LECT NOTE DATA ENG, V32, P171, DOI 10.1007/978-3-030-25797-2_8
   Vishnoi Susheela, 2019, 2019 4th International Conference on Information Systems and Computer Networks (ISCON), P728, DOI 10.1109/ISCON47742.2019.9036184
   Wang B, 2012, SCI CHINA INFORM SCI, V55, P2369, DOI 10.1007/s11432-012-4548-0
   Wu G., 2017, Problem definitions and evaluation criteria for the CEC 2017 competition on constrained real-parameter optimization
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   YAGER RR, 1995, INFORM SCIENCES, V82, P147, DOI 10.1016/0020-0255(94)00030-F
   Yang YB, 2000, PATTERN RECOGN, V33, P787, DOI 10.1016/S0031-3203(99)00094-1
   Yazdani M, 2016, J COMPUT DES ENG, V3, P24, DOI 10.1016/j.jcde.2015.06.003
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
NR 68
TC 14
Z9 14
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4979
EP 5010
DI 10.1007/s11042-022-12168-9
EA FEB 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000756332700032
DA 2024-07-18
ER

PT J
AU Jia, DY
   Zhang, CW
   Wu, NK
   Zhou, JL
   Guo, ZG
AF Jia, Dongyao
   Zhang, Chuanwang
   Wu, Nengkai
   Zhou, Jialin
   Guo, Zhigang
TI Autofocus algorithm using optimized Laplace evaluation function and
   enhanced mountain climbing search algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microscope imaging; Autofocus; Mountain climbing search
AB In the field of digital imaging systems, autofocus plays increasingly a vital role as a key technology. Autofocus poses a great challenge due to nosiy background and slow focusing speed. This paper presents a new focusing algorithm based on improved Laplacian operator and mountain-climb search algorithm. The clear image after focusing is more different in gray scale than the image without focusing, an image definition evaluation function combining local variance and Laplacian operator is proposed. Learning from the advantages of two-stage recognition in deep learning image recognition, an two-stage search algorithm based on mountain-climb search is designed to better fit the focusing curve near the extreme value of focusing evaluation function, improved mountain-climb search algorithm is divided into rough focusing and fine focusing. The method of rough focusing is used to determine a small focus area, and then fine focusing based on function approximation can greatly improve the efficiency of focus position.The experimental results indicate that this algorithm in this paper is superior to the traditional algorithm in time and accuracy, and the time of the autofocus is reduced by 76%.
C1 [Jia, Dongyao; Zhang, Chuanwang; Wu, Nengkai; Zhou, Jialin; Guo, Zhigang] Beijing Jiaotong Univ, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Guo, ZG (corresponding author), Beijing Jiaotong Univ, Beijing, Peoples R China.
EM dyjia@bjtu.edu.cn; 438436692@qq.com; 19111054@bjtu.edu.cn;
   17120204@bjtu.edu.cn; 2601046208@qq.com
CR Bahy RM, 2021, J PHYS C SERIES, V1
   Chen J-L, 2011, GOOGLE PATENTS
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   Hong YZ, 2016, MULTIMED TOOLS APPL, V75, P10807, DOI 10.1007/s11042-015-2792-1
   Ishikawa A, 2006, GOOGLE PATENTS
   Jia ADY, 2020, NEUROCOMPUTING, V411, P112, DOI 10.1016/j.neucom.2020.06.006
   Jia DY, 2020, IEEE ACCESS, V8, P64891, DOI 10.1109/ACCESS.2020.2984657
   Jiang M., 2017, OPTO ELECT J, V44, P749
   Lee SY, 2008, IEEE T CIRC SYST VID, V18, P1237, DOI 10.1109/TCSVT.2008.924105
   Li LD, 2017, IEEE T MULTIMEDIA, V19, P1030, DOI 10.1109/TMM.2016.2640762
   Lilin Her, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P93, DOI 10.1109/ICIVC47709.2019.8980980
   Liu SX, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0368-5
   Mo, 2013, RES AUTOFOCUSING TEC
   Moscaritolo M, 2009, IEEE T MED IMAGING, V28, P1703, DOI 10.1109/TMI.2009.2019755
   Price JH, 1998, GOOGLE PATENTS
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Weng Y, 2020, J OPT TECHNOL+, V87, P224, DOI 10.1364/JOT.87.000224
   [谢小甫 Xie Xiaofu], 2011, [光电工程, Opto-Electronic Engineering], V38, P84
   Y-f L., 2010, APPL RES COMPUTERS, V27, P1534
   Yang S-h, 2009, COMPUT ENG APPL, V45
   Yang Zhang, 2020, ICDSP 2020: Proceedings of the 2020 4th International Conference on Digital Signal Processing, P56, DOI 10.1145/3408127.3408194
   Yao Y, 2006, PROC SPIE, V6246, DOI 10.1117/12.664751
   Yazdanfar S, 2008, OPT EXPRESS, V16, P8670, DOI 10.1364/OE.16.008670
   Yoon HS, 2009, INT J ADV MANUF TECH, V43, P287, DOI 10.1007/s00170-008-1706-z
   [张丰收 Zhang Fengshou], 2017, [光学技术, Optical Technology], V43, P234
   Zhao Zhi-bin, 2010, Chinese Journal of Liquid Crystals and Displays, V25, P863
NR 27
TC 4
Z9 4
U1 8
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10299
EP 10311
DI 10.1007/s11042-022-12191-w
EA FEB 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800016
DA 2024-07-18
ER

PT J
AU Bansal, P
   Gehlot, K
   Singhal, A
   Gupta, A
AF Bansal, Priti
   Gehlot, Kshitiz
   Singhal, Abhishek
   Gupta, Abhishek
TI Automatic detection of osteosarcoma based on integrated features and
   feature selection using binary arithmetic optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Osteosarcoma; Whole slide images; Binary arithmetic optimization
   algorithm; Integrated features; EfficientNet-B0; Xception
ID GREY WOLF OPTIMIZER; CLASSIFICATION; DIAGNOSIS; SEGMENTATION; MELANOMA;
   NETWORK; IMAGES; TUMOR; DEEP
AB Osteosarcoma is one of the most common malignant bone tumors mostly found in children and teenagers. Manual detection of osteosarcoma requires expertise and it is a labour-intensive process. If detected on time, the mortality rate can be reduced. With the advent of new technologies, automatic detection systems are used to analyse and classify medical images, which reduces the dependency on experts and leads to faster processing. In this paper, an automatic detection system: Integrated Features-Feature Selection Model for Classification (IF-FSM-C) to detect osteosarcoma from the high-resolution whole slide images (WSIs) is proposed. The novelty of the proposed approach is the use of integrated features obtained by fusion of features extracted using traditional handcrafted (HC) feature extraction techniques and deep learning models (DLMs) namely EfficientNet-B0 and Xception. To further improve the performance of the proposed system, feature selection (FS) is performed. Here, two binary variants of recently proposed Arithmetic Optimization Algorithm (AOA) known as BAOA-S and BAOA-V are proposed to perform FS. The selected features are given to a classifier that classifies the WSIs into Viable tumor (VT), Non-viable tumor (NVT) and non-tumor (NT). Experiments are performed to compare the performance of proposed IF-FSM-C to the classifiers which use HC or deep learning features alone as well as state-of-the-art methods for osteosarcoma detection. The best overall accuracy of 96.08% is obtained when integrated features extracted using HC techniques and Xception are used. The overall accuracy is enhanced to 99.54% after applying BAOA-S for FS. Further, the application of BAOA-S for FS reduces the number of features with the best model having only 188 features compared to 2118 features if no FS is applied.
C1 [Bansal, Priti] Netaji Subhas Univ Technol, Dept Informat Technol, New Delhi, India.
   [Gehlot, Kshitiz; Singhal, Abhishek] Netaji Subhas Inst Technol, Dept Informat Technol, New Delhi, Dwarka, India.
   [Gupta, Abhishek] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra, Jammu & Kashmir, India.
C3 Netaji Subhas University of Technology; Netaji Subhas University of
   Technology; Shri Mata Vaishno Devi University
RP Gupta, A (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra, Jammu & Kashmir, India.
EM bansalpriti79@gmail.com; kshitizg99@gmail.com;
   abhisheksinghal.18199@gmail.com; abhishekgupta10@yahoo.co.in
RI Gupta, Abhishek/O-3016-2019
OI Gupta, Abhishek/0000-0002-8592-9964
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Abdel-Basset M, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112824
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Al-Tashi Q, 2020, IEEE ACCESS, V8, P106247, DOI 10.1109/ACCESS.2020.3000040
   Almaraz-Damian JA, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040484
   Altameem T, 2020, NEURAL COMPUT APPL, V32, P805, DOI 10.1007/s00521-018-04005-8
   Anisuzzaman, 2020, DEEP LEARNING STUDY
   Arora S, 2019, EXPERT SYST APPL, V116, P147, DOI 10.1016/j.eswa.2018.08.051
   Arunachalam HB, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210706
   Arunachalam HB, 2017, BIOCOMPUT-PAC SYM, P195, DOI 10.1142/9789813207813_0020
   Bakheet S, 2017, COMPUTATION, V5, DOI 10.3390/computation5010004
   Bansal P, 2021, INT J HEALTHC INF SY, V16, P73, DOI 10.4018/IJHISI.20210401.oa4
   Bansal P, 2020, SOFT COMPUT, V24, P15463, DOI 10.1007/s00500-020-04877-w
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Bisla D, 2019, IEEE COMPUT SOC CONF, P2720, DOI 10.1109/CVPRW.2019.00330
   Cao ZT, 2019, BMC MED IMAGING, V19, DOI 10.1186/s12880-019-0349-x
   Chen CX., 2013, CHINESE J BIOMED ENG, V22, P70
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding C, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P147, DOI 10.1109/ICDM.2002.1183897
   El-kenawy ESM, 2020, IEEE ACCESS, V8, P179317, DOI 10.1109/ACCESS.2020.3028012
   El-Kenawy EM, 2020, IEEE ACCESS, V8, P107635, DOI 10.1109/ACCESS.2020.3001151
   Elgamal ZM, 2020, IEEE ACCESS, V8, P186638, DOI 10.1109/ACCESS.2020.3029728
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Goode Adam, 2013, J Pathol Inform, V4, P27, DOI 10.4103/2153-3539.119005
   Hasan AM, 2019, IEEE ACCESS, V7, P79959, DOI 10.1109/ACCESS.2019.2922691
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu P, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105746
   Jia HJ, 2021, J MED IMAG HEALTH IN, V11, P871, DOI 10.1166/jmihi.2021.3421
   Kayal EB, 2020, SIGNAL IMAGE VIDEO P, V14, P727, DOI 10.1007/s11760-019-01599-x
   Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104, DOI 10.1109/ICSMC.1997.637339
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Kleinerman RA, 2005, J CLIN ONCOL, V23, P2272, DOI 10.1200/JCO.2005.05.054
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leavey P, 2019, CANC IMAGING ARCH
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li YP, 2019, BIOMED OPT EXPRESS, V10, P4999, DOI 10.1364/BOE.10.004999
   Lindsey BA, 2017, RHEUMATOL THER, V4, P25, DOI 10.1007/s40744-016-0050-2
   Mafarja M, 2019, EXPERT SYST APPL, V117, P267, DOI 10.1016/j.eswa.2018.09.015
   Mirabello L, 2009, CANCER-AM CANCER SOC, V115, P1531, DOI 10.1002/cncr.24121
   Mishra R, 2018, J COMPUT BIOL, V25, P313, DOI 10.1089/cmb.2017.0153
   Mishra R, 2017, LECT N BIOINFORMAT, V10330, P12, DOI 10.1007/978-3-319-59575-7_2
   Nasor M, 2021, IET IMAGE PROCESS, V15, P1310, DOI 10.1049/ipr2.12106
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qureshi Mohammad Naved, 2018, Procedia Computer Science, V132, P534, DOI 10.1016/j.procs.2018.05.006
   Rahmawaty M, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (IBIOMED): EMPOWERING BIOMEDICAL TECHNOLOGY FOR BETTER FUTURE, P84
   Rashedi E, 2010, NAT COMPUT, V9, P727, DOI 10.1007/s11047-009-9175-3
   Samet H, 2006, FDN MULTIDIMENSIONAL
   Shankar K, 2021, COMPLEX INTELL SYST, V7, P1277, DOI 10.1007/s40747-020-00216-6
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thaher T, 2020, ALGO INTELL SY, P251, DOI 10.1007/978-981-32-9990-0_12
   Wang HZ, 2010, COMPUT VIS IMAGE UND, V114, P731, DOI 10.1016/j.cviu.2010.02.001
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yadav D, 2018, IEEE COMPUT SOC CONF, P685, DOI 10.1109/CVPRW.2018.00099
   Zhang R, 2018, COMPUT MED IMAG GRAP, V63, P1, DOI 10.1016/j.compmedimag.2018.01.006
NR 61
TC 29
Z9 29
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8807
EP 8834
DI 10.1007/s11042-022-11949-6
EA FEB 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000752200300001
PM 35153620
OA Green Submitted, Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Al-Safi, H
   Munilla, J
   Rahebi, J
AF Al-Safi, Haedar
   Munilla, Jorge
   Rahebi, Javad
TI Patient privacy in smart cities by blockchain technology and feature
   selection with Harris Hawks Optimization (HHO) algorithm and machine
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy; Disease data; Blockchain; Security; Medical data; Machine
   learning
ID HEALTH-CARE
AB A medical center in the smart cities of the future needs data security and confidentiality to treat patients accurately. One mechanism for sending medical data is to send information to other medical centers without preserving confidentiality. This method is not impressive because in treating people, the privacy of medical information is a principle. In the proposed framework, the opinion of experts from other medical centers for the treatment of patients is received and consider the best therapy. The proposed method has two layers. In the first layer, data transmission uses blockchain. In the second layer, blocks related to patients' records analyze by machine learning methods. Patient records place in a block of the blockchain. Block of patient sends to other medical centers. Each treatment center can recommend the proposed type of treatment and blockchain attachment and send it to all nodes and treatment centers. Each medical center receiving data of the patients, then predicts the treatment using data mining methods. Sending medical data between medical centers with blockchain and maintaining confidentiality is one of the innovations of this article. The proposed method is a binary version of the HHO algorithm for feature selection. Another innovation of this research is the use of majority voting learning in diagnosing the type of disease in medical centers. Implementation of the proposed system shows that the blockchain preserves data confidentiality of about 100%. The reliability and reliability of the proposed framework are much higher than the centralized method. The result shows that the accuracy, sensitivity, and precision of the proposed method for diagnosing heart disease are 92.75%, 92.15%, and 95.69%, respectively. The proposed method has a lower error in diagnosing heart disease from ANN, SVM, DT, RF, AdaBoost, and BN.
C1 [Al-Safi, Haedar; Munilla, Jorge; Rahebi, Javad] Malaga Univ, Dept Telecommun Engn, Malaga, Spain.
   [Al-Safi, Haedar; Munilla, Jorge; Rahebi, Javad] Istanbul Ayvansaray Univ, Dept Software Engn, Istanbul, Turkey.
C3 Istanbul Topkapi University
RP Rahebi, J (corresponding author), Malaga Univ, Dept Telecommun Engn, Malaga, Spain.; Rahebi, J (corresponding author), Istanbul Ayvansaray Univ, Dept Software Engn, Istanbul, Turkey.
EM haeder.emad.84@gmail.com; munilla@ic.uma.es;
   cevatrahebi@ayvansaray.edu.tr
RI Alsafi, Haedar Emad/AAE-1640-2022
OI Alsafi, Haedar Emad/0000-0001-9146-7762
CR Adanur B, 2020, SIG PROCESS COMMUN, DOI 10.1109/siu49456.2020.9302168
   Ahmad RW, 2021, INT J MED INFORM, V148, DOI 10.1016/j.ijmedinf.2021.104399
   Ahmed S, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/6621540
   Al-Rahlawee ATH, 2021, MULTIMED TOOLS APPL, V80, P28217, DOI 10.1007/s11042-021-10860-w
   Alqaralleh Bassam A. Y., 2024, Personal and Ubiquitous Computing, V28, P17, DOI 10.1007/s00779-021-01543-2
   Alsarori FA, 2020, INT J COMPUT INT SYS, V13, P1507, DOI 10.2991/ijcis.d.200915.003
   Azbeg K., 2021, IRBM, DOI 10.1016/j.irbm.2021.05.003
   Balasubramanian S, 2021, TECHNOL FORECAST SOC, V165, DOI 10.1016/j.techfore.2020.120536
   Baucas Marc Jayson, 2021, IEEE Networking Letters, V3, P52, DOI 10.1109/LNET.2021.3070270
   Albargathe SMBK, 2021, MULTIMED TOOLS APPL, V80, P2565, DOI 10.1007/s11042-020-09646-3
   Fu S., 2020, INT S SEC PRIV SOC N, P278
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   Gul MJ, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103524
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hussien HM, 2021, J IND INF INTEGR, V22, DOI 10.1016/j.jii.2021.100217
   Iqbal N, 2021, IEEE ACCESS, V9, P8069, DOI 10.1109/ACCESS.2021.3049325
   Kim M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102913
   Kondababu A., 2021, Materials Today: Proceedings
   Latif S, 2021, J IND INF INTEGR, V21, DOI 10.1016/j.jii.2020.100190
   Liu X, 2020, IEEE J BIOMED HEALTH, V24, P2177, DOI 10.1109/JBHI.2020.2999497
   Ma ZR, 2019, INFORM SCIENCES, V496, P225, DOI 10.1016/j.ins.2019.05.025
   Abdulhamid IMA, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/5345923
   Mohsin AH, 2021, MULTIMED TOOLS APPL, V80, P14137, DOI 10.1007/s11042-020-10284-y
   Mora H, 2021, COMPUT HUM BEHAV, V122, DOI 10.1016/j.chb.2021.106854
   Muhammad G, 2021, IEEE NETWORK, V35, P74, DOI 10.1109/MNET.011.2000326
   Peral J, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12176768
   Rawat D.B., 2020, Journal of Cybersecurity and Privacy, V1, P4, DOI DOI 10.3390/JCP1010002
   Shynu PG, 2021, IEEE ACCESS, V9, P45706, DOI 10.1109/ACCESS.2021.3065440
   Tandon A, 2020, COMPUT IND, V122, DOI 10.1016/j.compind.2020.103290
   Veeramakali T, 2021, J SUPERCOMPUT, V77, P9576, DOI 10.1007/s11227-021-03637-3
   Zhang LM, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6649640
   Zhang XF, 2021, EURASIP J WIREL COMM, V2021, DOI 10.1186/s13638-020-01883-2
NR 32
TC 14
Z9 15
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8719
EP 8743
DI 10.1007/s11042-022-12164-z
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751584600005
PM 35153619
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ali, AM
   Mohammed, AA
AF Ali, Ari M.
   Mohammed, Aree A.
TI Improving classification accuracy for prostate cancer using noise
   removal filter and deep learning technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prostate cancer; MRI; Binary classification; Median filter; And 2d-CNN
ID AIDED DIAGNOSIS; SYSTEM; CNN
AB Prostate Cancer (PCa) can be considered as the second cause of death among men all over the world. Different techniques based on deep learning have been proposed for accurate PCa detection using Magnetic Resonance Imaging (MRI) images. In this research work, an accurate 2d CNN-based Convolutional Neural Network (CNN) model is developed and implemented for PCa binary classification (0 for Benign and 1 for Malignant).The paper is aimed at improving the classification accuracy in two phases. The first one is to use image pre-processing algorithms such as (DICOM to jpg format, image resizing and labeling, adding noise, and noise removal by median filter). The second improvement is achieved by increasing the dataset size. The dataset of 20 patients were used which consist of 15 patients (3249 MRI slices) with cancerous tumor and 3 patients without cancer (1751 MRI slices). To evaluate the performance accuracy of the proposed approach, 30% of the dataset is used for the test and validation while 70% used for the training. The accuracy is found based on the Area under Curve (AUC) of Receiver Operating Characteristic (ROC). Test results indicate that the AUC is 0.98 without pre-processing whereas its value increased to 0.9993 with pre-processing using epoch iteration = 60 and the total dataset images.
C1 [Ali, Ari M.] Sulaimani Polytech Univ, Tech Coll Informat, Dept Informat Technol, KRG, Sulaimani, Iraq.
   [Mohammed, Aree A.] Univ Sulaimani, Dept Comp Sci, Coll Sci, Sulaimani, Krg, Iraq.
   [Mohammed, Aree A.] Univ Halabja, Coll Sci, Dept Comp Sci, Halabja, KRG, Iraq.
C3 Sulaimani Polytechnic University; University of Sulimanyah
RP Mohammed, AA (corresponding author), Univ Sulaimani, Dept Comp Sci, Coll Sci, Sulaimani, Krg, Iraq.; Mohammed, AA (corresponding author), Univ Halabja, Coll Sci, Dept Comp Sci, Halabja, KRG, Iraq.
EM aree.ali@univsul.edu.iq
CR Abbasi AA, 2020, COGN NEURODYNAMICS, V14, P523, DOI 10.1007/s11571-020-09587-5
   Abraham Bejoy, 2019, Informatics in Medicine Unlocked, V17, P150, DOI 10.1016/j.imu.2019.100256
   Aldoj N, 2020, EUR RADIOL, V30, P1243, DOI 10.1007/s00330-019-06417-z
   Bhattacharjee S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9152969
   Celik Y, 2020, PATTERN RECOGN LETT, V133, P232, DOI 10.1016/j.patrec.2020.03.011
   Chaddad A, 2020, IEEE ACCESS, V8, P167767, DOI 10.1109/ACCESS.2020.3023902
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Duran-Lopez L, 2020, IEEE ACCESS, V8, P128613, DOI 10.1109/ACCESS.2020.3008868
   Imani F, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217205
   Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779
   Khoun-Jahan H, 2019, 2019 INT C WIR TECHN, P1
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lemaître G, 2015, COMPUT BIOL MED, V60, P8, DOI 10.1016/j.compbiomed.2015.02.009
   Liu SF, 2017, PROC SPIE, V10134, DOI 10.1117/12.2277121
   Liu Y, 2017, I S WORLD WIREL MOBI
   Liu ZY, 2021, FUTURE GENER COMP SY, V114, P358, DOI 10.1016/j.future.2020.08.015
   Minz A, 2017, IEEE INT ADV COMPUT, P701, DOI [10.1109/IACC.2017.0146, 10.1109/IACC.2017.137]
   Pinckaers H, 2021, IEEE T MED IMAGING, V40, P1817, DOI 10.1109/TMI.2021.3066295
   Saba T, 2020, J INFECT PUBLIC HEAL, V13, P1274, DOI 10.1016/j.jiph.2020.06.033
   Salehi Ahmad Waleed, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P156, DOI 10.1109/ICOSEC49089.2020.9215402
   Shao W, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101919
   Shirazi AZ, 2018, MED BIOL ENG COMPUT, V56, P721, DOI 10.1007/s11517-017-1721-z
   Suhas S., 2018, INT J COMPUTER APPL, V179, P17, DOI 10.5120/ijca2018915777
   Torre LA, 2018, CA-CANCER J CLIN, V68, P284, DOI 10.3322/caac.21456
   Union for International Cancer Control (UICC), 2020, EST NUMB NEW CAS 202
   de Vente C, 2021, IEEE T BIO-MED ENG, V68, P374, DOI 10.1109/TBME.2020.2993528
   Yoo S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55972-4
NR 28
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8653
EP 8669
DI 10.1007/s11042-022-12102-z
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751246700007
DA 2024-07-18
ER

PT J
AU Chithra, PL
   Sathya, K
AF Chithra, P. L.
   Sathya, K.
TI CAPTCHAs against meddler image identification based on a convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hue; Icon; Montage; Meddler; XGB-MANFA; Anthromorph
ID HUMANS
AB To strengthen personal identity security through a password, the CAPTCHA authenticates the human user. In this, text-based Hue Icon Montage (HIM) and image-based Hue Icon Montage Click on meddler image and color (HIMC) CAPTCHA are displayed on a panel with a grid of images called a photomontage that contains a set of image groups that each holds six images. Fake facial images (Meddler images) are created by compositing human and animal images called ANTHROMORPH images to create CAPTCHA images against the threat of deep learning. The main contribution to this paper consists of 1) a novel CAPTCHA created with meddler images. 2) this work apply to test whether these images are strong or identified by the machine, the latest manipulated face convolution neural network MANFA framework with Xtreme Gradient Boosting (XGB-MANFA) to overcome the imbalanced dataset problem. 3) A voluminous meddler image dataset (ANTHROMORPH) is created, collected, and validated. This model produces higher security because the success probability rate of HIM and HIMC against brute-force attacks is 3.960 x 10(-21). Further, the robustness of meddler images against artificial machine attacks is verified using the XGB-MANFA network, which produces only 26% accuracy that ensures the strength against machine attacks. A user study was conducted to measure the usability of HIM and HIMC CAPTCHAs with 112 participants. The proposed model's effectiveness, efficiency, learnability, and user satisfaction scores were 0.16, 10.70, 8.40, and 8.62, respectively. The experimental result outperforms well than the existing CAPTCHAs like KCAPTCHA, reCAPTCHA, farett-gender, farett-gender and age.
C1 [Chithra, P. L.; Sathya, K.] Univ Madras, Dept Comp Sci, Chennai, Tamil Nadu, India.
C3 University of Madras
RP Chithra, PL (corresponding author), Univ Madras, Dept Comp Sci, Chennai, Tamil Nadu, India.
EM chitrasp2001@yahoo.com
RI karunanithi, sathya/AAV-9252-2020
FU University of Madras (India) [GCCO/URF/Comp. Science/2019-20/323]
FX We would like to thank all the participants who contributed to carry out
   the experimental study successfully. This work has been funded by the
   University of Madras (India) under University Research Fellow Grant No;
   GCCO/URF/Comp. Science/2019-20/323.
CR Aleksa A, 2011, PLAYTHRUCAPTCHA
   [Anonymous], 2018, CHANGEFACES APPL
   [Anonymous], 2014, CRIMEWARE BOTS
   [Anonymous], 2005, P SIGCHI C HUM FACT
   [Anonymous], 2018, ONLINE OCR TOOL
   [Anonymous], 2018, ONLINE OCR SPACE TOO
   Basso A, 2010, HANDBOOK OF INFORMATION AND COMMUNICATION SECURITY, P273, DOI 10.1007/978-3-642-04117-4_15
   Bendale SB., 2011, P INT C WORKSH EM TR, DOI [10.1145/1980022.1980153, DOI 10.1145/1980022.1980153]
   Bigham JP., 2009, P 27 INT C HUM FACT, DOI [10.1145/1518701.1518983, DOI 10.1145/1518701.1518983]
   Bursztein E, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P125
   Bursztein E, 2010, P IEEE S SECUR PRIV, P399, DOI 10.1109/SP.2010.31
   Chew M, 2003, P SOC PHOTO-OPT INS, V5010, P305, DOI 10.1117/12.479682
   Chithra PL, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107133
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Gao H., 2013, P 2013 ACM SIGSAC C, P1075, DOI DOI 10.1145/2508859.2516732
   Guerar M, 2018, COMPUT SECUR, V78, P255, DOI 10.1016/j.cose.2018.06.007
   Hidalgo JMG, 2011, ADV COMPUT, P109, DOI [10.1016/b978-0-12-385510-7.00003-5, DOI 10.1016/B978-0-12-385510-7.00003-5]
   Ince IF, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P1057, DOI 10.1109/ICCIT.2009.105
   Irvine Valerie, 2013, EDMEDIA INNOVATE LEA, P1385
   Hernández-Castro CJ, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101758
   Kuo-Feng Hwang, 2012, 2012 International Symposium on Biometrics and Security Technologies (ISBAST 2012), P1, DOI 10.1109/ISBAST.2012.17
   Lupkowski P, 2008, 2008 INTERNATIONAL MULTICONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY (IMCSIT), VOLS 1 AND 2, P299
   Nikiforov I., 2010, WORDPRESS KEYCAPTCHA
   Ouyang ZY, 2021, COMPUT SECUR, V103, DOI 10.1016/j.cose.2021.102178
   Roshanbin N, 2013, J WEB ENG, V12, P1
   Schryen G, 2016, COMPUT SECUR, V60, P95, DOI 10.1016/j.cose.2016.03.007
   Sheskin DJ., 2003, HDB PARAMETRIC NONPA, DOI [10.1201/9781420036268, DOI 10.1201/9781420036268]
   Shi CH, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1391, DOI 10.1145/3372297.3417258
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   Wang J, 2019, MATH BIOSCI ENG, V16, P5851, DOI 10.3934/mbe.2019292
   Yan J, 2008, CCS'08: PROCEEDINGS OF THE 15TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P543
   Zhang XH, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01160-8
NR 32
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8633
EP 8652
DI 10.1007/s11042-022-11961-w
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751246700009
DA 2024-07-18
ER

PT J
AU Tang, ZC
   Li, XT
   Xia, D
   Hu, YD
   Zhang, LT
   Ding, J
AF Tang, Zhichuan
   Li, Xintao
   Xia, Dan
   Hu, Yidan
   Zhang, Lingtao
   Ding, Jun
TI An art therapy evaluation method based on emotion recognition using EEG
   deep temporal features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Art therapy; Effect evaluation; Emotion recognition; EEG; Deep temporal
   features
ID TERM MOOD REPAIR; MODEL; CLASSIFICATION; SCALE
AB Self-assessment methods are widely used in art therapy evaluation, but emotional recognition methods using physiological signals' features are more objectively and accurately. In this study, we proposed an electroencephalogram (EEG)-based art therapy evaluation method that could evaluate the therapeutic effect based on the emotional changes before and after the art therapy. Twelve participants were recruited in a two-step experiment (emotion stimulation step and drawing therapy step), and their EEG signals and self-assessment scores were collected. The self-assessment model (SAM) was used to obtain and label the actual emotional states; the long short-term memory (LSTM) network was used to extract the deep temporal features of EEG to recognize emotions. Further, the classification performances in different sequence lengths, time-window lengths and frequency combinations were compared and analyzed. The results showed that emotion recognition models with LSTM deep temporal features achieved the better classification performances than the state-of-the-art methods with non-temporal features; the classification accuracies in high-frequency bands (alpha, beta, and gamma bands) were higher than those in low-frequency bands (delta and theta bands); there was a highest emotion classification accuracy (93.24%) in 10-s sequence length, 2-s time-window length and 5-band frequency combination. Our proposed method could be used for emotion recognition effectively and accurately, and was an objective approach to assist therapists or patients in evaluating the effect of art therapy.
C1 [Tang, Zhichuan; Li, Xintao; Xia, Dan; Hu, Yidan; Zhang, Lingtao; Ding, Jun] Zhejiang Univ Technol, Ind Design Inst, Hangzhou 310023, Peoples R China.
   [Tang, Zhichuan] Zhejiang Univ, Modern Ind Design Inst, Hangzhou 310007, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University
RP Tang, ZC (corresponding author), Zhejiang Univ Technol, Ind Design Inst, Hangzhou 310023, Peoples R China.; Tang, ZC (corresponding author), Zhejiang Univ, Modern Ind Design Inst, Hangzhou 310007, Peoples R China.
EM ttzzcc@zju.edu.cn
OI Tang, Zhichuan/0000-0002-1730-1120
FU Philosophy and Social Science Planning Fund Project of Zhejiang Province
   [22NDJC007Z]; Zhejiang Provincial Natural Science Foundation of China
   [LY20F020028]; Key Research and Development Program of Zhejiang Province
   [2022C03148]; Fundamental Research Funds for the Provincial Universities
   of Zhejiang [GB201901006]
FX This work was supported by the Philosophy and Social Science Planning
   Fund Project of Zhejiang Province (22NDJC007Z), the Zhejiang Provincial
   Natural Science Foundation of China (LY20F020028), the Key Research and
   Development Program of Zhejiang Province (2022C03148), and the
   Fundamental Research Funds for the Provincial Universities of Zhejiang
   (GB201901006).
CR Adamos DA, 2016, INFORM SCIENCES, V343, P94, DOI 10.1016/j.ins.2016.01.005
   Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671
   Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   Bar-Sela G, 2007, PSYCHO-ONCOLOGY, V16, P980, DOI 10.1002/pon.1175
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bhattacharya J, 2002, COGNITIVE BRAIN RES, V13, P179, DOI 10.1016/S0926-6410(01)00110-0
   Bradley M.M., 1998, International affective digitized sounds (IADS): Stimuli, instruction manual and affective ratings
   Chen W., 2018, P 2018 SIAM INT C DA, P279
   Chen Y., 2021, MATH PROBL ENG, V2021, P1
   CURRAN SL, 1995, PSYCHOL ASSESSMENT, V7, P80, DOI 10.1037/1040-3590.7.1.80
   Czamanski-Cohen J, 2016, ART PSYCHOTHER, V51, P63, DOI 10.1016/j.aip.2016.08.006
   Dalebroux A, 2008, MOTIV EMOTION, V32, P288, DOI 10.1007/s11031-008-9105-1
   Deiters DD, 2013, J BEHAV THER EXP PSY, V44, P143, DOI 10.1016/j.jbtep.2012.09.001
   Drake JE, 2011, ART THER, V28, P26, DOI 10.1080/07421656.2011.557032
   Fage C, 2019, COMPUT EDUC, V131, P1, DOI 10.1016/j.compedu.2018.12.003
   Frantzidis CA, 2010, IEEE T INF TECHNOL B, V14, P589, DOI 10.1109/TITB.2010.2041553
   Gao Q, 2020, MULTIMED TOOLS APPL, V79, P27057, DOI 10.1007/s11042-020-09354-y
   George EM, 2011, NEUROPSYCHOLOGIA, V49, P1083, DOI 10.1016/j.neuropsychologia.2011.02.001
   Goldstein LB, 1997, STROKE, V28, P307, DOI 10.1161/01.STR.28.2.307
   Goldstein TR, 2009, PSYCHOL AESTHET CREA, V3, P232, DOI 10.1037/a0015343
   Goshvarpour A, 2017, BIOMED J, V40, P355, DOI 10.1016/j.bj.2017.11.001
   Haeyen S, 2018, PERSONAL MENT HEALTH, V12, P3, DOI 10.1002/pmh.1379
   Haiblum-Itskovitch S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00968
   Hongyu Sun, 2010, Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P4105, DOI 10.1109/CISP.2010.5648081
   Hsu Yu Liang., 2017, IEEE Transactions on Affective Computing, P1
   Hwang S, 2020, I WINT C BRAIN-COMP, P99, DOI 10.1109/bci48061.2020.9061624
   Jalilifard A, 2016, IEEE ENG MED BIO, P845, DOI 10.1109/EMBC.2016.7590833
   Jiang HP, 2020, CMC-COMPUT MATER CON, V65, P1453, DOI 10.32604/cmc.2020.011793
   Kim SK, 2018, NEUROCOMPUTING, V275, P1393, DOI 10.1016/j.neucom.2017.09.081
   Klimova B, 2017, CURR ALZHEIMER RES, V14, P1264, DOI 10.2174/1567205014666170713161422
   Lang P. J., 1997, NIMH CTR STUDY EMOTI, V1, P39
   Li M, 2018, TECHNOL HEALTH CARE, V26, pS509, DOI 10.3233/THC-174836
   Lusebrink V., 2004, Art Therapy, DOI [10.1080/07421656.2004.10129496, DOI 10.1080/07421656.2004.10129496]
   Mohammadi Z, 2017, NEURAL COMPUT APPL, V28, P1985, DOI 10.1007/s00521-015-2149-8
   Moon SE, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2556, DOI 10.1109/ICASSP.2018.8461315
   Musha T, 2000, CYBERPSYCHOL BEHAV, V3, P441, DOI 10.1089/10949310050078904
   Nie D, 2011, I IEEE EMBS C NEUR E, P667, DOI 10.1109/NER.2011.5910636
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pesso-Aviv T, 2014, ART PSYCHOTHER, V41, P293, DOI 10.1016/j.aip.2014.04.005
   Rahman MA, 2020, EGYPT INFORM J, V21, P23, DOI 10.1016/j.eij.2019.10.002
   Ramirez R, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00354
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salama ES, 2018, INT J ADV COMPUT SC, V9, P329
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Takahashi K, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P95, DOI 10.1109/ROMAN.2004.1374736
   Vice RM, 2003, HANDBOOK OF ART THERAPY, P5
   Vijayan AE, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P587, DOI 10.1109/CICT.2015.24
   Wang CH, 2016, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON ADVANCED MATERIALS FOR SCIENCE AND ENGINEERING (IEEE-ICAMSE 2016), P581
   Webb TL, 2012, PSYCHOL BULL, V138, P775, DOI 10.1037/a0027600
   Withers, 2006, NZ J COUNSEL, V2006
   Xu Ya, 2010, Journal of Electronics (China), V27, P8, DOI 10.1007/s11767-009-0094-3
   Yang H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214736
   Yin Z, 2017, IFAC PAPERSONLINE, V50, P6940, DOI 10.1016/j.ifacol.2017.08.1220
   Yinger OS, 2014, CHILD ADOL PSYCH CL, V23, P535, DOI 10.1016/j.chc.2013.03.003
   Yoo SK., 2005, NEURAL NETWORK BASED, P818
   Zeng ZH, 2005, PROC CVPR IEEE, P967
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 58
TC 3
Z9 3
U1 12
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7085
EP 7101
DI 10.1007/s11042-022-12002-2
EA JAN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746354000002
DA 2024-07-18
ER

PT J
AU Xia, ZY
   Zhang, WY
   Duan, HC
   Wang, JR
   Wei, XY
AF Xia, Ziyun
   Zhang, Wenyin
   Duan, Huichuan
   Wang, Jiuru
   Wei, Xiuyuan
TI Fragile watermarking scheme in spatial domain based on prime number
   distribution theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermark; Fragile watermarking; Prime number distribution; Hash
   algorithm
AB Fragile digital watermarking is mainly used for digital content authentication, which is of great significance for protecting information security. A novel fragile spatial watermarking scheme based on prime number distribution theory is proposed in this paper. Firstly, 54 approximate pixel sets are constructed according to the prime number distribution in [0,255]. Secondly, the embedding of watermark information is achieved by pixel replacement in the approximate pixel set, while the MD5 hashing algorithm is used in the embedding process to ensure the security of the scheme. The experimental results show that the proposed watermarking scheme has better performance compared with the existing methods. It is not only robust to common image processing operations such as additive noise, rotation, sharpening and etc., but also has good invisibility, fragility, high capacity and low computational cost.
C1 [Xia, Ziyun; Duan, Huichuan] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Shandong, Peoples R China.
   [Xia, Ziyun; Zhang, Wenyin; Wang, Jiuru; Wei, Xiuyuan] Linyi Univ, Sch Informat Sci & Engn, Linyi 276000, Shandong, Peoples R China.
   [Wei, Xiuyuan] Linyi Univ, Inst Biochem Anal, Linyi 276000, Shandong, Peoples R China.
C3 Shandong Normal University; Linyi University; Linyi University
RP Duan, HC (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Shandong, Peoples R China.; Zhang, WY (corresponding author), Linyi Univ, Sch Informat Sci & Engn, Linyi 276000, Shandong, Peoples R China.
EM zhangwenyin@lyu.edu.cn; hcduan@sdnu.edu.cn
FU Key Research and Development Program of Shandong Province
   [2019GNC106027, 2019JZZY010134]; Natural Science Foundation of Shandong
   Province [ZR2020MF058]
FX This work was partially supported by the Key Research and Development
   Program of Shandong Province (2019GNC106027, 2019JZZY010134), and the
   Natural Science Foundation of Shandong Province (ZR2020MF058).
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA., 2014, INT SOC OPTICS PHOTO, V9120
   Abraham J, 2016, J KING SAUD UNIV-COM
   Aditya BP, 2019, INT J IMAGE GRAPH, V19, DOI 10.1142/S0219467819500153
   akhmawati, INT SEM RES INF TECH
   [Anonymous], 2021, J PHYS C SERIES, V1730
   Barbarani V, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9111224
   Barbarani V, 2020, INT J THEOR PHYS, V59, P2425, DOI 10.1007/s10773-020-04512-2
   Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Cotti, 2020, INT MATH RES NOT
   Fouque PA, 2019, IEEE T INFORM THEORY, V65, P1307, DOI 10.1109/TIT.2018.2859045
   Hamidi M., 2019, HYBRID BLIND ROBUST
   Hemida O, 2019, MULTIMED TOOLS APPL, V78, P12373, DOI 10.1007/s11042-018-6664-3
   Kristyan S, 2017, AIP CONF PROC, V1863, DOI 10.1063/1.4992696
   Li Z., 2019, J INFORM SECURITY RE
   Ly M., 2020, PRIME NUMBER FUNCTIO
   Ma Z., 1903, SURVEY NEWMANNS PROO, V2021, P1
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P24107, DOI 10.1007/s11042-016-4186-4
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Pihlaja J., 2020, ABSTRACT PRIME NUMBE
   Richter F K., 2020, ARXIV PREPRINT ARXIV
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   TANAKA K, 1990, P 1990 IEEE MIL COMM, P216
   Machado JT, 2020, COMMUN NONLINEAR SCI, V83, DOI 10.1016/j.cnsns.2019.105128
   Tian L, 2020, MULTIMED TOOLS APPL, P1
   Tirkel Andrew Z., 1995, DICTA, V95
   Wenqing L., 2018, J GEOMATICS SCI TECH
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zichen L, 2019, J INFORM SECURITY RE
NR 31
TC 5
Z9 5
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6477
EP 6496
DI 10.1007/s11042-021-11704-3
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742319000006
DA 2024-07-18
ER

PT J
AU Lal, N
   Kumar, S
AF Lal, Nidhi
   Kumar, Shishupal
TI An emergency event detection approach in real-time for efficient vehicle
   safety in Smart City
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Energy; Wireless sensor network; Performance
   analysis
AB Nowadays, the Internet of things (IoT) provides various services to drivers by equipped with smart devices. In this regard, the next generation of vehicles collaborates with the features of IoT to provide safety and security on the roads. To achieve this, it is equipped with short-range communication advances and establishes Vehicle-to-Vehicle (V2V) connectivity. The standardized V2V connectivity and communication are termed in IEEE 802.11p. Later, an alternative named (LTE-V2V) has been introduced. However, both technologies are only concerned with the continuous broadcast of information and cooperative awareness. It only takes information from one vehicle in a text way and sends it to another. In this regard, efficient and satisfactory safety is not provided by these technologies for the analysis of real-time road traffic monitoring. Therefore in this paper, we proposed a solution by providing real-time information on road conditions and traffic scenarios to the drivers. We utilized the capturing of images of road conditions by the positioned cameras and Global Positioning System (GPS) to extract the information regarding vehicle and camera position. The proposed work provides better security rather than a message-passing system in V2V communication. The drivers in our anticipated scenarios can extract and see a clear view of road conditions by the use of captured videos/images. Our proposed solution copes well with moderate traffic conditions and provides a high satisfaction score. The simulation results show that our proposed work can achieve high performance in the provision of providing safety compared to other schemes introduced in this field.
C1 [Lal, Nidhi; Kumar, Shishupal] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur IIIT Nagpur, Nagpur, Maharashtra, India.
RP Lal, N (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur IIIT Nagpur, Nagpur, Maharashtra, India.
RI Lal, Nidhi/AFK-7639-2022
OI Lal, Nidhi/0000-0001-6935-3005
CR Alsarhan A, 2018, IEEE T INTELL TRANSP, V19, P3496, DOI 10.1109/TITS.2017.2784548
   [Anonymous], P 22 INT C KNOWL BAS
   Bellavista P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030822
   Cecchini G, 2017, 2017 5TH IEEE INTERNATIONAL CONFERENCE ON MODELS AND TECHNOLOGIES FOR INTELLIGENT TRANSPORTATION SYSTEMS (MT-ITS), P80, DOI 10.1109/MTITS.2017.8005625
   Djahel S, 2015, 2015 INTERNATIONAL SYMPOSIUM ON NETWORKS, COMPUTERS AND COMMUNICATIONS (ISNCC 2015)
   Dogru N, 2018, 2018 15TH LEARNING AND TECHNOLOGY CONFERENCE (L&T), P40, DOI 10.1109/LT.2018.8368509
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Joy J, 2018, INTERNET TECHNOL LET, V1, DOI 10.1002/itl2.16
   Khekare GS, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P302, DOI 10.1109/iMac4s.2013.6526427
   Ksiksi A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P165, DOI 10.1109/SmartCity.2015.65
   Meghana S, 2018, LECT NOTES ELECTR EN, V472, P481, DOI 10.1007/978-981-10-7395-3_54
   Mezher AM, 2017, IEEE T VEH TECHNOL, V66, P10611, DOI 10.1109/TVT.2017.2715719
   Nafi N. S., 2012, 2012 Australasian Telecommunication Networks and Applications Conference (ATNAC 2012), DOI 10.1109/ATNAC.2012.6398066
   Qiu H, 2018, IEEE T VEH TECHNOL, V67, P1909, DOI 10.1109/TVT.2017.2771623
   Barba CT, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P902, DOI 10.1109/IVS.2012.6232229
NR 15
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6373
EP 6388
DI 10.1007/s11042-021-11834-8
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000741624700001
DA 2024-07-18
ER

PT J
AU Biswas, M
   Rahaman, S
   Ahmadian, A
   Subari, K
   Singh, PK
AF Biswas, Mainak
   Rahaman, Saif
   Ahmadian, Ali
   Subari, Kamalularifin
   Singh, Pawan Kumar
TI Automatic spoken language identification using MFCC based time series
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spoken language identification; Indian languages; Mel frequency cepstral
   coefficients; Time series features; Feature selection; FRESH algorithm;
   Artificial neural network
AB Spoken Language Identification (SLID) is a fairly well researched field. It has already been established as a significant first step in all multilingual speech recognition systems. With the rise in ASR technologies in recent years, the importance of SLID has become undeniable. In this work, we propose a model for the recognition of Indian and foreign languages. With the goal of making our model robust to noise from everyday life, we augment our data with noise of varying loudness taken from diverse environments. From the MFCC time series of this augmented data, we extract aggregated macro-level features, and perform feature selection using the FRESH (FeatuRe Extraction based on Scalable Hypothesis tests) algorithm. This helps us obtain a set of features that are relevant to this problem. This filtered set is used to train an Artificial Neural Network. The model is then tested on three standard datasets. Firstly, from the IIT-M IndicTTS speech database, six languages are selected, and an accuracy of 99.93% is obtained. Secondly, the IIIT-H Indic speech database consisting of seven languages is used, and an accuracy of 99.94% is recorded. Lastly, eight languages from the VoxForge dataset are also used, and we achieve an accuracy of 98.43%. The promising results obtained lead us to believe that these features are suitable for capturing language specific characteristics of speech. Hence, we propose that they can be used as standard features for the task of SLID.
C1 [Biswas, Mainak; Rahaman, Saif; Singh, Pawan Kumar] Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
   [Ahmadian, Ali] Natl Univ Malaysia, Inst IR 4 0, Ukm Bangi 43600, Selangor, Malaysia.
   [Ahmadian, Ali] Near East Univ, Dept Math, Mersin 10, Nicosia, Trnc, Turkey.
   [Subari, Kamalularifin] Univ Teknol Malaysia, Fac Sci Social & Humanities, Skudai 81310, Johor Bahru, Malaysia.
C3 Jadavpur University; Universiti Kebangsaan Malaysia; Near East
   University; Universiti Teknologi Malaysia
RP Singh, PK (corresponding author), Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
EM mainak.biswas.dbl@gmail.com; saifrahaman500@gmail.com;
   ahmadian.hosseini@gmail.com; p-arifin@utm.my; pawansingh.ju@gmail.com
RI Ahmadian, Ali/N-3697-2015; SINGH, PAWAN KUMAR/E-3408-2013; Subari,
   Kamalularifin/AAY-2872-2020
OI Ahmadian, Ali/0000-0002-0106-7050; SINGH, PAWAN
   KUMAR/0000-0002-9598-7981; Biswas, Mainak/0000-0002-0003-4054
CR Abadi Martin, 2016, arXiv
   Ajibola Alim S., 2018, From Natural to Artificial Intelligence - Algorithms and Applications, P3, DOI DOI 10.5772/INTECHOPEN.80419
   Albadr MAA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194770
   Anjana JS, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Baby A, 2016, RES IND LANG
   Barai Bidhan, 2019, Advanced Computing and Systems for Security. Advances in Intelligent Systems and Computing (AISC 883), P125, DOI 10.1007/978-981-13-3702-4_8
   Benjamini Y, 2001, ANN STAT, V29, P1165
   Biswas M., 2021, MACHINE LEARNING INT, P311
   Christ M., 2016, ARXIV161007717, DOI DOI 10.48550/ARXIV.1610.07717
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Delgado-Bonal A, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060541
   Draghici Alexandra, 2020, AM '20: Proceedings of the 15th International Conference on Audio Mostly, P253, DOI 10.1145/3411109.3411123
   Garain A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114416
   Gazeau Valentin, 2018, International Journal of Information Technology and Computer Science, V10, P11, DOI 10.5815/ijitcs.2018.08.02
   Ghosh, 2020, RANKED 100 MOST SPOK
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Guptal M, 2017, DES AUT CON, DOI [10.1145/3061639.3062212, 10.1109/TEL-NET.2017.8343484]
   Heracleous P, 2018, EUR SIGNAL PR CONF, P2265, DOI 10.23919/EUSIPCO.2018.8553347
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Jog AH, 2018, 2018 15 IEEE IND COU, P1, DOI [10.1109/INDICON45594.2018.8987167, DOI 10.1109/INDICON45594.2018.8987167]
   Kingma D.P., 2014, ARXIV14126980
   Korkut C, 2020, COMP DEEP LEARNING M, P223
   Krishna DN, 2020, IDENTIFICATION INDIA
   Kumar, 2017, ON WEIGHT INITIALIZA
   Lopez-Moreno Ignacio, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5337, DOI 10.1109/ICASSP.2014.6854622
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Manchala S, 2014, INT J SPEECH TECHNOL, V17, P99, DOI 10.1007/s10772-013-9209-1
   Martin A, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P165
   McFee B, 2020, LIBROSA LIBROSA 0 7
   Mermelstein P., 1976, HANDWORTERBUCH PATTE, P311
   Mukherjee H, 2020, MULTIMED TOOLS APPL, V79, P34913, DOI 10.1007/s11042-019-08553-6
   Mukherjee H, 2020, INT J MACH LEARN CYB, V11, P1, DOI 10.1007/s13042-019-00928-3
   Mukherjee H, 2019, NEURAL COMPUT APPL, V31, P8483, DOI 10.1007/s00521-019-04468-3
   Padi B, 2020, IEEE-ACM T AUDIO SPE, V28, P1223, DOI 10.1109/TASLP.2020.2983580
   Prahallad K, 2012, IIIT H INDIC SPEECH
   Revay, 2019, MULTICLASS LANGUAGE
   Sarthak, 2019, LECT NOTES COMPUT SC, V11912, P252, DOI 10.1007/978-3-030-34255-5_17
   Stoica P., 2005, Spectral Analysis of Signals
   Strang G, 2005, LINEAR ALGEBRA, P211
   Titus A, 2020, IMPROVING LANGUAGE I
   van der Merwe, 2020, ARXIVABS201203775
NR 42
TC 13
Z9 13
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9565
EP 9595
DI 10.1007/s11042-021-11439-1
EA JAN 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000737741900001
DA 2024-07-18
ER

PT J
AU Ng, WWY
   Li, JY
   Tian, X
   Wang, H
AF Ng, Wing W. Y.
   Li, Jiayong
   Tian, Xing
   Wang, Hui
TI Bit-wise attention deep complementary supervised hashing for image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-level; Complementary hashing; Image retrieval; Deep hashing
ID BINARY-CODES; FEATURES; SEARCH; GRAPH
AB Deep hashing is effective and efficient for large-scale image retrieval. Most of existing deep hashing methods train a single hash table by utilizing the output of the penultimate fully-connected layer of a convolutional neural network as the deep feature of images. They concentrate on the semantic information but neglect the fine-grain image structure. To address this issue, this paper proposes an advanced image hashing method, Bit-wise Attention Deep Complementary Supervised Hashing (BADCSH). It is an end-to-end system that trains a sequence of hash tables in a boosting manner, each of which is trained by correcting errors caused by all previous ones. Features from different levels of the network are used to train different hash tables. The hash table trained with features at one level reveals a level of semantic content of the image, while the hash table trained with features at a lower level contains structural information of the image that makes up the semantic content. Moreover, the hash layer is used as an embedded layer of the network to generate hash codes. A dense attention layer is added to the hash layer to treat various hash bits differently, in order to reduce hash code redundancy and maximize overall similarity preservation. Finally, the hash tables trained on different levels of features are fused by weights computed based on their respective performance. Experiments on three real-world image databases demonstrate that the proposed method achieves the best performance among state-of-the-art comparative hashing methods.
C1 [Ng, Wing W. Y.; Li, Jiayong; Tian, Xing] South China Univ Technol, Guangdong Prov Key Lab Computat Intelligence & Cy, Comp Sci & Engn, Guangzhou, Peoples R China.
   [Wang, Hui] Ulster Univ, Sch Comp, Jordanstown, North Ireland.
C3 South China University of Technology; Ulster University
RP Tian, X (corresponding author), South China Univ Technol, Guangdong Prov Key Lab Computat Intelligence & Cy, Comp Sci & Engn, Guangzhou, Peoples R China.
EM xingtian@scut.edu.cn
RI TIAN, XING/L-8374-2018
OI TIAN, XING/0000-0002-7546-1018; Ng, Wing W. Y./0000-0003-0783-3585;
   Wang, Hui/0000-0003-2633-6015
FU National Natural Science Foundation of China [61876066]; 67th Chinese
   Postdoctoral Science Foundation [2020M672631]; Guangdong Province
   Science and Technology Plan Project (Collaborative Innovation and
   Platform Environment Construction) [2019A050510006]; Guangdong Science
   and Technology Plan [2018B050502006]; EU [700381]
FX This work is supported by National Natural Science Foundation of China
   under Grant 61876066, the 67th Chinese Postdoctoral Science Foundation
   (2020M672631), Guangdong Province Science and Technology Plan Project
   (Collaborative Innovation and Platform Environment Construction)
   2019A050510006, Guangdong Science and Technology Plan Project
   2018B050502006, and the EU Horizon 2020 Programme (700381, ASGARD).
CR [Anonymous], 2016, IJCAI
   [Anonymous], 2009, NIPS
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2009, NEURIPS
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Gu SM, 2013, INT CONF MACH LEARN, P108, DOI 10.1109/ICMLC.2013.6890453
   Hu D, 2019, IEEE T MULTIMEDIA, V21, P973, DOI 10.1109/TMM.2018.2866771
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jing CC, 2019, IEEE T MULTIMEDIA, V21, P782, DOI 10.1109/TMM.2018.2866222
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kafai M, 2014, IEEE T MULTIMEDIA, V16, P1090, DOI 10.1109/TMM.2014.2305633
   Kang C, 2019, IEEE T MULTIMEDIA, V21, P1563, DOI 10.1109/TMM.2018.2883868
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Kim S, 2012, LECT NOTES COMPUT SC, V7576, P538, DOI 10.1007/978-3-642-33715-4_39
   Kim S, 2013, INT CONF ACOUST SPEE, P3123, DOI 10.1109/ICASSP.2013.6638233
   Kong WH, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P45, DOI 10.1145/2348283.2348293
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li J, 2019, WEIGHTED MULTIDEEP R
   Li P, 2013, NEUROCOMPUTING, V120, P83, DOI 10.1016/j.neucom.2012.07.053
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Lin J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2266
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Lv YM, 2015, IEEE T MULTIMEDIA, V17, P1225, DOI 10.1109/TMM.2015.2437712
   Ma L, 2017, IEEE T MULTIMEDIA, V19, P2545, DOI 10.1109/TMM.2017.2703089
   Ng WWY, 2020, NEUROCOMPUTING, V399, P171, DOI 10.1016/j.neucom.2020.02.046
   Norouzi M.E., 2011, ICML
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song DJ, 2015, IEEE I CONF COMP VIS, P1922, DOI 10.1109/ICCV.2015.223
   Tiakas E, 2013, IEEE T MULTIMEDIA, V15, P1415, DOI 10.1109/TMM.2013.2247989
   Tiana X, 2019, NEUROCOMPUTING
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   Tolias G., 2015, ARXIV151105879
   Tzelepi M, 2017, NEUROCOMPUTING
   Venters C, 2000, REV CONTENT BASED IM
   Wang DX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2291
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang XF, 2017, LECT NOTES COMPUT SC, V10111, P70, DOI 10.1007/978-3-319-54181-5_5
   Wang Y., 2019, IEEE T MULTIMEDIA
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Wu CX, 2013, IEEE T KNOWL DATA EN, V25, P1380, DOI 10.1109/TKDE.2012.76
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225
   Zhang J, 2018, IEEE T MULTIMEDIA, V20, P2400, DOI 10.1109/TMM.2018.2804763
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhang Z., 2019, IEEE T MULTIMEDIA
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
   Zheng Liang, 2016, arXiv preprint arXiv
NR 67
TC 7
Z9 9
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 927
EP 951
DI 10.1007/s11042-021-11494-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8O9DG
UT WOS:000926130400002
DA 2024-07-18
ER

PT J
AU Jin, YS
   Ma, MH
   Zhu, YN
AF Jin, Yunshui
   Ma, Minhua
   Zhu, Yongning
TI A comparison of natural user interface and graphical user interface for
   narrative in HMD-based augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented Reality (AR); Head Mounted Display (HMD); Interactive
   narrative; Presence; Natural User Interface (NUI); Narrative engagement;
   HoloLens; Game experience
ID VIRTUAL AGENTS; EXPERIENCE
AB Over the years, the various mediums available for storytelling have progressively expanded, from spoken to written word, then to film, and now to Virtual Reality (VR) and Augmented Reality (AR). In 2016, the cutting-edge Head-Mounted Display (HMD) AR Microsoft HoloLens was released. However, though it has been several years, the quality of the user experience with narration using HMD-based AR technology has been rarely discussed. The present study explored interactive narrative in HMD-based AR regarding different user interfaces and their influence on users' presence, narrative engagement and reflection. Inspired by an existing exhibition at the National Holocaust Centre and Museum in the U.K., a HoloLens narrative application, entitled The AR Journey, was developed by the authors using two different interaction methods, Natural User Interface (NUI) and Graphical User Interface (GUI), which were used to perform an empirical study. As revealed from the results of the between-subject design experiment, NUI exhibited statistically significant advantages in creating presence for users without 3D Role Playing Game (RPG) experience, and GUI was superior in creating presence and increasing narrative engagement for users with 3D RPG experience. As indicated by the results of the interviews, the overall narrative experience in HMD-based AR was acceptable, and the branching narrative design was engaging. However, HoloLens hardware issues, as well as virtuality and reality mismatch, adversely affected user experience. Design guidelines were proposed according to the qualitative results.
C1 [Jin, Yunshui; Zhu, Yongning] Tongji Univ, Shanghai, Peoples R China.
   [Ma, Minhua] Falmouth Univ, Falmouth, Cornwall, England.
C3 Tongji University
RP Zhu, YN (corresponding author), Tongji Univ, Shanghai, Peoples R China.
EM jinyunshui@tongji.edu.cn; m.ma@falmouth.ac.uk; yzhu@tongji.edu.cn
OI Ma, Minhua/0000-0001-7451-546X
FU National Key Research and Development Program of China [2018YFB1004903]
FX This work was funded partially by the National Key Research and
   Development Program of China (2018YFB1004903). We would like to thank
   Louise Stafford and Claudia Reese at the National Holocaust Centre and
   Museum for their support during this study.
CR AlexanderZook StephenLee-Urban, 2012, P INT C FDN DIG GAM, P164, DOI DOI 10.1145/2282338.2282371
   Aylett RS, 2005, LECT NOTES ARTIF INT, V3661, P305
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barba E, 2010, IEEE INT S MIX AUG
   Bartsch A, 2014, J MEDIA PSYCHOL-GER, V26, P125, DOI 10.1027/1864-1105/a000118
   Bartsch A, 2012, MEDIA PSYCHOL, V15, P267, DOI 10.1080/15213269.2012.693811
   Billinghurst M, 2010, HUMAN-CENTRIC INTERFACES FOR AMBIENT INTELLIGENCE, P281, DOI 10.1016/B978-0-12-374708-2.00011-5
   Botella CM, 2005, CYBERPSYCHOL BEHAV, V8, P162, DOI 10.1089/cpb.2005.8.162
   Bowman D. A., 2006, INT J VIRTUAL REAL, V5, P3, DOI [10.20870/IJVR.2006.5.2.2683, DOI 10.20870/IJVR.2006.5.2.2683]
   Brondi R, 2015, LECT NOTES COMPUT SC, V9353, P169, DOI 10.1007/978-3-319-24589-8_13
   Busselle R, 2009, MEDIA PSYCHOL, V12, P321, DOI 10.1080/15213260903287259
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Cavazza M, 2003, LECT NOTES ARTIF INT, V2792, P231
   Chinara C, 2018, SMPTE 2017 ANN TECHN, P1
   Christopoulos D, 2011, 2011 3 INT C GAM VIR, P84
   Danilicheva P, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P333, DOI 10.1109/CW.2009.57
   Dow S., 2006, P ACM SIGCHI INT C A, V1, P28, DOI [10.1145/1178823.1178858, DOI 10.1145/1178823.1178858]
   Evans G, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262626
   Falcao C, 2015, PROCEDIA MANUF, V3, P5490, DOI 10.1016/j.promfg.2015.07.697
   Funk M, 2017, IOT'17: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS, P142, DOI [10.1145/3131542.3131559, 10.1145/3131542.3140267]
   Geslin E., 2011, Journal of CyberTherapy Rehabilitation, V4, P489
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Gupta S, 2019, TEI'19: PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P65, DOI 10.1145/3294109.3295635
   Hammady R, 2020, MULTIMED TOOLS APPL, V79, P3465, DOI 10.1007/s11042-019-08026-w
   Hand S., 2009, Computers in Entertainment, V7, P1, DOI [10.1145/1594943.1594951, DOI 10.1145/1594943.1594951]
   Hanna MG, ARCH PATHOL LAB MEDA
   Ishii H, 2008, COMMUN ACM, V51, P32, DOI 10.1145/1349026.1349034
   Jenkins H., 2004, Computer, V44, P53, DOI [10.1109/MC.2004.1293712, DOI 10.1109/MC.2004.1293712]
   Jin Yunshui., 2020, Virtual, P249, DOI DOI 10.1007/978-3-030-49698-2_17
   Juan MC, 2005, IEEE COMPUT GRAPH, V25, P31, DOI 10.1109/MCG.2005.143
   Jui-Feng Weng, 2011, 2011 11th IEEE International Conference on Advanced Learning Technologies (ICALT 2011), P336, DOI 10.1109/ICALT.2011.104
   Kearsley G., 1998, Educational Technology, V38, P20
   Koenitz H, 2012, INT C INT STOR
   Larsen M, 2018, J SCREENWRITING, V9, P73, DOI 10.1386/josc.9.1.73_1
   MacIntyre B, 2003, P INT C TECHN INT DI, P230, DOI DOI 10.1109/ISAR.2001.970538
   Marschner L, 2015, INT J PSYCHOPHYSIOL, V97, P85, DOI 10.1016/j.ijpsycho.2015.05.007
   Moreno E., 2001, CAST, P21
   Moser C., 2014, NARRATIVE CONTROL PL, P622
   Moser C, 2015, INT J HUM-COMPUT INT, V31, P146, DOI 10.1080/10447318.2014.986639
   Murray J.T., 2018, Telltale Hearts: Encoding cinematic choice-based adventure games
   Nisi V, 2004, LECT NOTES COMPUT SC, V3105, P132
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   Pausch R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P13, DOI 10.1145/258734.258744
   Rafii T, 2014, GOOGLE PATENTS
   Rembowska-Pluciennik M, 2018, LANG LIT, V27, P159, DOI 10.1177/0963947018788519
   Riedl Mark., 2003, P 2 INT JOINT C AUTO, P741
   Riedl MO, 2008, International Transactions on Systems Science and Applications, V4, P23
   Riedlinger U, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3020023
   Roth D., 2019, Proceedings of Mensch Und Computer 2019, P21, DOI DOI 10.1145/3340764.3340797
   Saldana J., 2016, CODING MANUAL QUALIT, DOI DOI 10.1017/CBO9781107415324.004
   Salter A, 2016, IEEE INT CONF SERIOU
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   Shafer DM, 2011, PRESENCE-TELEOP VIRT, V20, P591, DOI 10.1162/PRES_a_00084
   Shilkrot R, 2014, INT SYM MIX AUGMENT, P35, DOI 10.1109/ISMAR-AMH.2014.6935436
   Smagorinsky P, 2014, CAMBRIDGE HANDBOOK OF THE LEARNING SCIENCES, 2ND EDITION, P605
   Smith SR, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P3, DOI 10.1109/3DUI.2009.4811198
   Song QL, 2012, PHYSCS PROC, V33, P1798, DOI 10.1016/j.phpro.2012.05.287
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Studio A, 2017, INTRO FRAGMENTS
   Taylor N, 2015, ME LEE IDENTIFICATIO
   Vosmeer M, 2017, LECT NOTES COMPUT SC, V10690, P221, DOI 10.1007/978-3-319-71027-3_18
   Vuforia, 2021, AREA TARGETS
   Wither J., 2010, Proceedings of the 2010 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH). Science and Technology, P39, DOI 10.1109/ISMAR-AMH.2010.5643295
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zhang L, 2021, IEEE T CLOUD COMPUT, V9, P1117, DOI [10.1109/TCC.2019.2903254, 10.1109/vs-games.2019.8864531]
   Zielke MA, 2017, 2017 IEEE 5th International Conference on Serious Games and Applications for Health (SeGAH), P1, DOI [10.1109/SeGAH.2017.7939285, DOI 10.1109/SEGAH.2017.7939285]
NR 66
TC 13
Z9 13
U1 10
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5795
EP 5826
DI 10.1007/s11042-021-11723-0
EA DEC 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000736409100002
PM 34980945
OA Bronze, Green Published, Green Accepted
DA 2024-07-18
ER

PT J
AU Huang, P
   Zhu, SH
   Wang, DS
   Liang, ZW
AF Huang, Pan
   Zhu, Songhao
   Wang, Dongsheng
   Liang, Zhiwei
TI Cross-modality person re-identication with triple-attentive feature
   aggregation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Local feature; Hybrid weighted attention;
   Two-stream network
ID REIDENTIFICATION; NETWORK
AB Cross-modal person re-identification between the visible (RGB) modality and infrared (IR) modality is extremely important for nighttime surveillance applications. In addition to the cross-modal differences caused by different camera spectra, RGB-IR person re-identification is also affected by the large cross-modal and intra-modal variations caused by different camera views and person poses. On the other hand, existing VI-ReID works tend to learn global representations with limited discriminative power and weak robustness to noisy images. In this paper, we propose a novel three-attentional aggregation (TAANet) learning method by mining intra-modal hierarchical and cross-modal graph-level contextual cues of VI-ReID. We propose an intra-modal hybrid weight attention module, which extracts distinguished local aggregated features by mining channel and local feature relationships. To enhance robustness to noisy samples, we introduce an improved triple loss combined with a center loss that takes into account the distance between the different classes closest to the sample, allowing a certain distance to be maintained between classes and improving the discrimination of features. Extensive experiments show that TAANet outperforms state-of-the-art methods in a variety of settings.
C1 [Huang, Pan; Zhu, Songhao; Wang, Dongsheng; Liang, Zhiwei] Nanjing Univ Posts & Telecommun, Coll Automat & Artificial Intelligence, Nanjing 210046, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Zhu, SH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat & Artificial Intelligence, Nanjing 210046, Peoples R China.
EM zhush@njupt.edu.cn
FU Natural Science Foundation of Nanjing University of Posts and
   Telecommunications [NY219107]; National Natural Science Foundation of
   China [52170001]
FX This work is supported by Natural Science Foundation of Nanjing
   University of Posts and Telecommunications under No. NY219107, and
   National Natural Science Foundation of China under No. 52170001.
CR [Anonymous], 2006, 2006 IEEE COMP SOC C
   Bak S, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P175, DOI 10.1109/AVSS.2014.6918664
   Basaran E, 2020, EFFICIENT FRAMEWORK, P1
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Cho YJ, 2016, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2016.151
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Han CC, 2020, IEEE T CIRC SYST VID, V30, P3433, DOI 10.1109/TCSVT.2019.2957467
   Hao Y, 2019, AAAI CONF ARTIF INTE, P8385
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang YK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P365, DOI 10.1145/3343031.3350994
   Jiang JG, 2020, NEUROCOMPUTING, V406, P59, DOI 10.1016/j.neucom.2020.03.109
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Liu HJ, 2021, IEEE T MULTIMEDIA, V23, P4414, DOI 10.1109/TMM.2020.3042080
   Liu HJ, 2020, NEUROCOMPUTING, V398, P11, DOI 10.1016/j.neucom.2020.01.089
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mang Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P229, DOI 10.1007/978-3-030-58520-4_14
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun LC, 2018, IEEE ACCESS, V6, P12587, DOI 10.1109/ACCESS.2018.2803789
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic P., 2017, P 5 INT C LEARN REPR
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Xin Jin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P735, DOI 10.1007/978-3-030-58571-6_43
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yang X, 2018, IEEE T IMAGE PROCESS, V27, P791, DOI 10.1109/TIP.2017.2765836
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2020, IEEE T IMAGE PROCESS, V29, P9387, DOI 10.1109/TIP.2020.2998275
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Yuan Y, 2020, NEUROCOMPUTING, V378, P387, DOI 10.1016/j.neucom.2019.10.083
   Zhang JA, 2019, IET COMPUT VIS, V13, P428, DOI [10.1049/iet-cvi.2018.5402, 10.1109/IPDPS.2019.00053]
   Zhang Yan, 2018, P ICLR
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao YB, 2019, IET IMAGE PROCESS, V13, P2897, DOI 10.1049/iet-ipr.2019.0699
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
NR 63
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4455
EP 4473
DI 10.1007/s11042-021-11739-6
EA DEC 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000728448300001
DA 2024-07-18
ER

PT J
AU Gupta, S
   Sharma, DK
   Ranta, S
AF Gupta, Sandipan
   Sharma, Dileep Kumar
   Ranta, Shivani
TI A new hybrid image enlargement method using singular value decomposition
   and cubic spline interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enlargement; Singular value decomposition; Cubic spline
   interpolation; Feature interpolation
ID SUPER RESOLUTION; ALGORITHM; SUPERRESOLUTION
AB In this research, a new image enlargement scheme is proposed which is based on a hybrid combination of singular value decomposition (SVD) and the cubic spline interpolation method. The proposed scheme uses interpolation on SVD feature matrices which transfer the detailed information of lower dimension image to the higher dimension image in an efficient manner. Initially, the low-resolution image is split into two feature matrices and a weight matrix using SVD. These feature matrices are used in the cubic spline interpolation to find the intensity of intermediate pixels of the enlarged image. The step length of the interpolation function is optimized by the maximization of signal to noise ratio. The feature matrices obtained after the optimized interpolation are employed in the reconstruction of the output image. The proposed methodology is also applied to reconstruct the compressed images by taking a few most dominating eigenvectors of the interpolated images. The presented scheme is compared with three standard interpolation techniques visually and using entropy, signal to noise ratio, peak signal to noise ratio, and root mean square error as the performance measures. The results of the proposed work show superior visual performance and better SVD features transfer in the enlarged images as compared to the other schemes.
C1 [Gupta, Sandipan; Ranta, Shivani] Eternal Univ, Dept Math, Baru Sahib, Himachal Prades, India.
   [Sharma, Dileep Kumar] Eternal Univ, Dept Elect & Telecommun Engn, Baru Sahib, Himachal Prades, India.
RP Ranta, S (corresponding author), Eternal Univ, Dept Math, Baru Sahib, Himachal Prades, India.
EM shivaniranta26@gmail.com
OI Sharma, Dr. Dileep Kumar/0000-0003-3881-1944
CR Karim SAA, 2020, IEEE ACCESS, V8, P115621, DOI 10.1109/ACCESS.2020.3002387
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Cao FL, 2020, NEURAL NETWORKS, V132, P394, DOI 10.1016/j.neunet.2020.09.017
   Chen HG, 2016, SIGNAL PROCESS-IMAGE, V43, P68, DOI 10.1016/j.image.2016.01.007
   Chen MJ, 2005, IMAGE VISION COMPUT, V23, P791, DOI 10.1016/j.imavis.2005.05.005
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Chuah CS, 2001, PATTERN RECOGN, V34, P2383, DOI 10.1016/S0031-3203(00)00157-6
   Fanaee F, 2019, SIGNAL IMAGE VIDEO P, V13, P79, DOI 10.1007/s11760-018-1330-9
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   HONG ZQ, 1991, PATTERN RECOGN, V24, P211, DOI 10.1016/0031-3203(91)90063-B
   Huang JJ, 2015, IEEE T IMAGE PROCESS, V24, P3232, DOI 10.1109/TIP.2015.2440751
   Hung KW, 2015, SIGNAL PROCESS-IMAGE, V39, P26, DOI 10.1016/j.image.2015.07.003
   Kasiri S, 2020, SIGNAL IMAGE VIDEO P, V14, P1525, DOI 10.1007/s11760-020-01698-0
   Kola DGR, 2021, IET BIOMETRICS, V10, P207, DOI 10.1049/bme2.12012
   Lee YJ, 2015, APPL MATH COMPUT, V269, P569, DOI 10.1016/j.amc.2015.07.086
   Leng JL, 2013, COMPUT MATH APPL, V66, P1, DOI 10.1016/j.camwa.2013.04.026
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li YL, 2021, DIGIT SIGNAL PROCESS, V109, DOI 10.1016/j.dsp.2020.102913
   Liu XM, 2011, IEEE T IMAGE PROCESS, V20, P3455, DOI 10.1109/TIP.2011.2150234
   Majhi M, 2021, MULTIMED TOOLS APPL, V80, P7271, DOI 10.1007/s11042-020-10005-5
   Qiao P, 2017, SIGNAL PROCESS-IMAGE, V58, P258, DOI 10.1016/j.image.2017.08.005
   Rajevenceltha J, 2021, SIGNAL IMAGE VIDEO P, V15, P547, DOI 10.1007/s11760-020-01775-4
   Rufai AM, 2014, DIGIT SIGNAL PROCESS, V24, P117, DOI 10.1016/j.dsp.2013.09.008
   Shamsolmoali P, 2019, IMAGE VISION COMPUT, V88, P9, DOI 10.1016/j.imavis.2019.03.006
   Veerakumar T, 2014, SIGNAL IMAGE VIDEO P, V8, P159, DOI 10.1007/s11760-013-0517-3
   Vijayalakshmi D, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00305-3
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Xi S, 2019, MULTIMED TOOLS APPL, V78, P4545, DOI 10.1007/s11042-018-6062-x
   Xu CE, 2020, MULTIMED TOOLS APPL, V79, P9435, DOI 10.1007/s11042-019-07776-x
   Yang X, 2021, MULTIMED TOOLS APPL, V80, P7063, DOI 10.1007/s11042-020-09958-4
   Zhang KB, 2020, APPL INTELL, V50, P4325, DOI 10.1007/s10489-020-01787-0
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhou D, 2012, IET IMAGE PROCESS, V6, P627, DOI 10.1049/iet-ipr.2011.0534
   Zhou DY, 2022, VISUAL COMPUT, V38, P119, DOI 10.1007/s00371-020-02007-z
NR 35
TC 7
Z9 7
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4241
EP 4254
DI 10.1007/s11042-021-11767-2
EA DEC 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000725909900001
DA 2024-07-18
ER

PT J
AU Tuncer, T
   Aydemir, E
   Ozyurt, F
   Dogan, S
AF Tuncer, Turker
   Aydemir, Emrah
   Ozyurt, Fatih
   Dogan, Sengul
TI A deep feature warehouse and iterative MRMR based handwritten signature
   verification method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep feature warehouse; Iterative MRMR; Signature verification; Deep
   learning; Feature engineering
ID RECOGNITION; GENERATION; NETWORK
AB Offline handwritten signature verification has been widely used for document forensics and biometrics, and it is a popular issue. Deep learning models have commonly been used to solve this problem. This research has two aims, and they are to present a high accuracy hybrid classification model for forensics and to collect and share a new handwritten signature dataset to contribute document forensics. In this paper, a novel deep signature verification model is presented. This method has three fundamental phases and they are deep feature generation using transfer learning, iterative minimum redundancy maximum relevance (IMRMR) feature selection, and classification phases. In the deep feature extraction phase, 13 pre-trained widely preferred convolutional neural networks (CNN) are selected. These are utilized as feature generators and 1000 features are extracted from each network. By merging the generated features, a feature vector with a length of 13,000 is created. This feature generation network is named Deep Feature Warehouse (DFW) since it uses 13 pre-trained deep feature extractors in the transfer learning model. The most valuable features of the DFW are selected by the proposed IMRMR method and the selected features are forwarded to the classifier. To test the proposed DFW and IMRMR based verification method, we collected a handwritten signature dataset and CEDAR dataset to obtain comparative results. The proposed DFW and ImRMR based document classification method reached 97.16 % classification accuracy on the collected dataset and 100 % accuracy on the CEDAR dataset. We have used two datasets to demonstrate the general classification ability of our proposal. The calculated results and findings obviously demonstrate the effectiveness of the proposed DFW and ImRMR image verification model. According to the results, our model has general success (it has developed on two datasets), and it is a lightweight machine learning model since it uses transfer learning for feature extraction.
C1 [Tuncer, Turker; Dogan, Sengul] Firat Univ, Coll Technol, Dept Digital Forens Engn, Elazig, Turkey.
   [Aydemir, Emrah] Sakarya Univ, Coll Management, Dept Management Informat, Sakarya, Turkey.
   [Ozyurt, Fatih] Firat Univ, Coll Engn, Dept Software Engn, Elazig, Turkey.
C3 Firat University; Sakarya University; Firat University
RP Tuncer, T (corresponding author), Firat Univ, Coll Technol, Dept Digital Forens Engn, Elazig, Turkey.
EM turkertuncer@firat.edu.tr; emrahaydemir@sakarya.edu.tr;
   fatihozyurt@firat.edu.tr; sdogan@firat.edu.tr
RI TUNCER, Turker/W-4846-2018; Özyurt, Fatih/W-4385-2018; DOGAN,
   Sengul/W-4854-2018; Aydemir, Emrah/AAV-6372-2021
OI Özyurt, Fatih/0000-0002-8154-6691; DOGAN, Sengul/0000-0001-9677-5684;
   Aydemir, Emrah/0000-0002-8380-7891
CR Abikoye O.C., 2011, Int. J. Comput. Appl., V35, P44
   Agam G, 2007, IEEE T INF FOREN SEC, V2, P430, DOI 10.1109/TIFS.2007.902675
   BOUGUETTAYA A., 2019, International Journal of Informatics and Applied Mathematics, V2, P28
   Çalik N, 2019, NEUROCOMPUTING, V359, P1, DOI 10.1016/j.neucom.2019.03.027
   Daramola S.A., 2010, Int. J. Comput. Appl., V10, P17
   Dey S., 2017, Pattern Recognition Letters
   Diaz M, 2018, IEEE T CYBERNETICS, V48, P228, DOI 10.1109/TCYB.2016.2630419
   Diaz M, 2017, IEEE T PATTERN ANAL, V39, P951, DOI 10.1109/TPAMI.2016.2560810
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Erkmen B, 2010, IEEE T NEURAL NETWOR, V21, P667, DOI 10.1109/TNN.2010.2040751
   Eskander GS, 2013, IET BIOMETRICS, V2, P169, DOI 10.1049/iet-bmt.2013.0024
   Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981
   Ferrer MA, 2012, IEEE T INF FOREN SEC, V7, P966, DOI 10.1109/TIFS.2012.2190281
   Frias-Martinez E, 2006, ENG APPL ARTIF INTEL, V19, P693, DOI 10.1016/j.engappai.2005.12.006
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Ismail MA, 2000, PATTERN RECOGN, V33, P1727, DOI 10.1016/S0031-3203(99)00047-3
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Karouni A, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.027
   Khoshdeli M, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P105, DOI 10.1109/BHI.2017.7897216
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1995, P INT C ART NEUR NET, V60, P53
   Maiorana E, 2010, IEEE T SYST MAN CY A, V40, P525, DOI 10.1109/TSMCA.2010.2041653
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Ozyurt F, 2020, J SUPERCOMPUT, V76, P8413, DOI 10.1007/s11227-019-03106-y
   Ozyurt F, 2020, SOFT COMPUT, V24, P8163, DOI 10.1007/s00500-019-04383-8
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ruiz V, 2020, NEUROCOMPUTING, V374, P30, DOI 10.1016/j.neucom.2019.09.041
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Senol C, 2005, LECT NOTES COMPUT SC, V3733, P524
   Sheng WG, 2015, IEEE T SYST MAN CY-S, V45, P1205, DOI 10.1109/TSMC.2015.2389768
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srihari SN, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P161, DOI 10.1109/IWFHR.2004.61
   Suryani D, 2017, PROCEDIA COMPUT SCI, V116, P621, DOI 10.1016/j.procs.2017.10.025
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tolosana R, 2015, IEEE ACCESS, V3, P478, DOI 10.1109/ACCESS.2015.2431493
   Vivaracho-Pascual C, 2017, NEUROCOMPUTING, V248, P57, DOI 10.1016/j.neucom.2016.11.080
   Vivaracho-Pascual C, 2016, PATTERN RECOGN, V55, P1, DOI 10.1016/j.patcog.2016.02.007
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao HH, 2020, GRANULAR COMPUT, V5, P411, DOI 10.1007/s41066-019-00158-6
NR 45
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3899
EP 3913
DI 10.1007/s11042-021-11726-x
EA NOV 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722157500004
DA 2024-07-18
ER

PT J
AU Yu, NN
   Li, JJ
   Hua, Z
AF Yu, Nana
   Li, Jinjiang
   Hua, Zhen
TI Detail enhancement decolorization algorithm based on rolling guided
   filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rolling guide filter; Gray scale; Detail enhancement
AB An important goal of color image gray-scale is to keep the edge details of the original color image as much as possible. In many cases, the degree of feature discrimination is maintained, but in some cases, edge details are still lost or blurred. Therefore, this paper first uses an improved non-linear global mapping grayscale method to grayscale the color image, and then proposes a grayscale image detail enhancement algorithm based on rolling guided filtering. The method in this paper is to enhance the edge details of the grayscale image by rolling guided filter processing on the basis of the grayscale image. In addition, the rolling-guided filter is a local linear model with better edge retention characteristics, which can overcome the defect that other filters are prone to gradient flips on the edges where the gray level of the image changes sharply, causing the image to appear "false edges". The experimental results show that when the traditional method loses or blurs the detailed features, the method in this paper can maintain better detailed features.
C1 [Yu, Nana; Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
RI Hua, Zhen/ABG-8734-2021; Hua, Zhen/AGN-6068-2022
FU National Natural Science Foundation of China [61772319, 62002200,
   61976125, 61976124]; Shandong Natural Science Foundation of China
   [ZR2017MF049]
FX The authors acknowledge the National Natural Science Foundation of China
   (Grant nos. 61772319, 62002200, 61976125, 61976124), and Shandong
   Natural Science Foundation of China (Grant no. ZR2017MF049).
CR Ancuti Cosmin, 2019, 2019 IEEE International Conference on Image Processing (ICIP). Proceedings, P3242, DOI 10.1109/ICIP.2019.8803485
   Ancuti CO, 2011, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2011.5995414
   Ancuti C, 2018, IEEE ACCESS, V6, P64071, DOI 10.1109/ACCESS.2018.2876373
   Ancuti C, 2016, IEEE IMAGE PROC, P4107, DOI 10.1109/ICIP.2016.7533132
   [Anonymous], 2011, 2011 INT JOINT C BIO
   Cai BL, 2018, IEEE IMAGE PROC, P2810, DOI 10.1109/ICIP.2018.8451303
   Chan SH, 2017, IEEE T IMAGE PROCESS, V26, P5107, DOI 10.1109/TIP.2017.2731208
   Chen SK, 2020, IEEE ACCESS, V8, P82819, DOI 10.1109/ACCESS.2020.2988284
   Du H, 2015, IEEE T IMAGE PROCESS, V24, P434, DOI 10.1109/TIP.2014.2380172
   Guan XD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010060
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu J, 2020, SIGNAL PROCESS-IMAGE, V86, DOI 10.1016/j.image.2020.115874
   Ji ZP, 2016, VISUAL COMPUT, V32, P1621, DOI 10.1007/s00371-015-1145-4
   Jian LH, 2018, FUTURE GENER COMP SY, V83, P310, DOI 10.1016/j.future.2018.01.039
   Kang XD, 2018, IEEE T GEOSCI REMOTE, V56, P4346, DOI 10.1109/TGRS.2018.2815588
   Khan TM, 2017, IEEE T IMAGE PROCESS, V26, P2116, DOI 10.1109/TIP.2017.2671781
   Kim Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618507
   Li CL, 2019, IEEE ACCESS, V7, P163395, DOI 10.1109/ACCESS.2019.2952545
   Li YW, 2019, IEEE ACCESS, V7, P91912, DOI 10.1109/ACCESS.2019.2927032
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liang Z, 2021, NEUROCOMPUTING, V425, P160, DOI 10.1016/j.neucom.2020.03.091
   Lien CY, 2020, IEEE ACCESS, V8, P64278, DOI 10.1109/ACCESS.2020.2984688
   Liu QG, 2019, VISUAL COMPUT, V35, P205, DOI 10.1007/s00371-017-1464-8
   Liu QG, 2019, INFORM FUSION, V46, P114, DOI 10.1016/j.inffus.2018.05.007
   Liu QG, 2017, IEEE T IMAGE PROCESS, V26, P5772, DOI 10.1109/TIP.2017.2745104
   Liu QG, 2017, IEEE T CIRC SYST VID, V27, P1856, DOI 10.1109/TCSVT.2016.2555779
   Liu QG, 2015, IEEE T IMAGE PROCESS, V24, P2889, DOI 10.1109/TIP.2015.2423615
   Liu SG, 2019, IEEE T MULTIMEDIA, V21, P2461, DOI 10.1109/TMM.2019.2903413
   Makinen Ymir, 2019, 2019 IEEE International Conference on Image Processing (ICIP). Proceedings, P185, DOI 10.1109/ICIP.2019.8802964
   Porikli f, 2019, IEEE C COMP VIS PATT, P1
   Sirichotedumrong W., 2018, IEEE INT C MULTIMEDI, P1
   Subramani B, 2020, COLOR RES APPL, V45, P644, DOI 10.1002/col.22502
   Tao YZ, 2018, IEEE T CYBERNETICS, V48, P1406, DOI 10.1109/TCYB.2017.2695655
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang JG, 2019, IEEE ACCESS, V7, P181284, DOI 10.1109/ACCESS.2019.2959705
   Wang W, 2020, IEEE T IMAGE PROCESS, V29, P1776, DOI 10.1109/TIP.2019.2939946
   Wang W, 2018, IEEE T IMAGE PROCESS, V27, P5464, DOI 10.1109/TIP.2018.2855424
   Wibowo EP., 2017, TELKOMNIKA TELECOMMU, V15, P471, DOI [10.12928/telkomnika.v15i1.4291, DOI 10.12928/TELKOMNIKA.V15I1.4291]
   Xie YT, 2019, LECT NOTES COMPUT SC, V11134, P476, DOI 10.1007/978-3-030-11024-6_37
   Yangping W., 2018, J ENG SCI TECHNOL RE, V11, P180, DOI DOI 10.25103/JESTR.111.22
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang YP, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P33, DOI 10.1109/SIPROCESS.2016.7888218
NR 42
TC 4
Z9 4
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2711
EP 2731
DI 10.1007/s11042-021-11677-3
EA NOV 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714312500001
DA 2024-07-18
ER

PT J
AU Singh, A
   Sethi, G
   Kalra, GS
AF Singh, Amandeep
   Sethi, Gaurav
   Kalra, G. S.
TI Amalgamation of ROAD-TGM and progressive PCA using performance booster
   method for detail persevering image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Denoising; Salt and pepper noise; Median filters; Rank-ordered absolute
   Differences Trimmed Global Mean Filter (ROAD-TGM); Progressive PCA
   evaluation parameters
ID PRINCIPAL COMPONENT ANALYSIS; WEIGHTED MEDIAN FILTERS; HIGH-DENSITY
   SALT; PEPPER NOISE; REMOVAL; EFFICIENT; ALGORITHM; GRAYSCALE; WAVELET;
   SPARSE
AB This paper presents a two-stage sequential method for noisy grayscale and color images. At first proposed method enhances the accuracy of the noise detection stage by using spatial domain filter rank-order absolute difference trimmed global mean (ROAD-TGM) along with transform domain-based progressive principle component analysis (PPCA) method. Then the performance booster algorithm is used to ensure the proximity of restored value to the original value. Quite often in real-world applications images are corrupted with Salt & Pepper noise, strip lines artifact and Blotches artifact. We observed the proposed method is capable of removing the above-mentioned noises and artifacts with comparatively better accuracy. The proposed method uses the progressive PCA for its dimension reduction ability and local information of image restored by ROAD-TGM to provide enhanced noise detection performance. Before noise removal, a performance booster algorithm eliminates noisy values by using sequential hard thresholding and estimates the tentative original values automatically. Then algorithm decides the suitable value for the restoration of noise pixel by using a structural similarity index (SSIM) to ensure the proximity of the restored image to the original image. The proposed algorithm is tested on a standard set of color and grayscale images to ensure the versatility of the proposed algorithm. The experiment shows that the proposed algorithm achieves high denoising performance for noise and artifact while maintaining the visually important details.
C1 [Singh, Amandeep; Sethi, Gaurav] Lovely Profess Univ, Sch Elect & Elect Engn, Jalandhar, Punjab, India.
   [Kalra, G. S.] CT Inst Engn, Dept Elect & Commun Engn, Management, Jalandhar, Punjab, India.
C3 Lovely Professional University
RP Singh, A (corresponding author), Lovely Profess Univ, Sch Elect & Elect Engn, Jalandhar, Punjab, India.
EM amansandhu6788@gmail.com
OI Singh, Dr. Amandeep/0000-0001-5706-760X
CR [Anonymous], MISCELLANEOUS USC VI, V3
   [Anonymous], 2018, IMAGE OPERATORS
   Aspandi D, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104189
   Bai T, 2015, IET IMAGE PROCESS, V9, P162, DOI 10.1049/iet-ipr.2014.0286
   Chandel R., 2013, Int J Adv Res Comput Sci Softw Eng, V3, P198
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   DAIYAN GM, 2012, 2012 INT C INFORMATI, V18, P565
   Dosselmann R, 2011, SIGNAL IMAGE VIDEO P, V5, P81, DOI 10.1007/s11760-009-0144-1
   Elad M., 2006, IEEE COMPUTER SOC C, V1, P895, DOI 10.1109/CVPR.2006.142
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Erkan U, 2019, IEEE ACCESS, V7, P167847, DOI 10.1109/ACCESS.2019.2953924
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Fang J, 2021, J SYST ENG ELECTRON, V32, P81, DOI 10.23919/JSEE.2021.000009
   Fei X, 2018, MULTIMED TOOLS APPL, V77, P23353, DOI 10.1007/s11042-018-5676-3
   Gavaskar RG, 2019, IEEE T IMAGE PROCESS, V28, P779, DOI 10.1109/TIP.2018.2871597
   Gupta V, 2013, NIRMA UNIV INT CONF
   GURNEYCHAMPION O, 2019, PHYS MED BIOL, V64
   Hong JJ, 2010, INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2010), P713
   Isma Irum Muhammad Sharif, 2015, J. appl. res. technol, V13, P79
   Kalra GS, 2016, MULTIMED TOOLS APPL, V75, P4467, DOI 10.1007/s11042-015-2484-x
   Kamarujjaman S, 2014, NEW DECISION BASED A, DOI 10.1109/ICDCCom.2014.7024689
   Kang XD, 2017, IEEE T GEOSCI REMOTE, V55, P7140, DOI 10.1109/TGRS.2017.2743102
   Karthik B, 2021, J AMB INTEL HUM COMP, V12, P3901, DOI 10.1007/s12652-020-01737-1
   Karthikeyan P, 2016, J COMMUN TECHNOL EL+, V61, P963, DOI 10.1134/S1064226916080064
   Kim DG, 2021, IEEE ACCESS, V9, P6438, DOI 10.1109/ACCESS.2020.3048181
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   KOKARAM AC, 1995, IEEE T IMAGE PROCESS, V4, P1496, DOI 10.1109/83.469931
   Kondo K, 2002, IEEE IMAGE PROC, P321
   Lei L, 2021, MULTIMED TOOLS APPL, V80, P15135, DOI 10.1007/s11042-021-10516-9
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li B, 2016, NEUROCOMPUTING, V175, P704, DOI 10.1016/j.neucom.2015.10.115
   Li C, 2019, MULTIMED TOOLS APPL, V78, P23117, DOI 10.1007/s11042-019-7625-1
   Liu J, 2004, LECT NOTES COMPUT SC, V3173, P768
   Liu SH, 2018, MULTIMED TOOLS APPL, V77, P23009, DOI 10.1007/s11042-018-5735-9
   Liu XW, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108247
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Ma RJ, 2020, IEEE T IMAGE PROCESS, V29, P3927, DOI 10.1109/TIP.2020.2965294
   Manikandan S, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/485921
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Münch B, 2009, OPT EXPRESS, V17, P8567, DOI 10.1364/OE.17.008567
   Ponomarenko A., 2011, Plant Heal. Instr, P1
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rakhshanfar M, 2020, J REAL-TIME IMAGE PR, V17, P1183, DOI 10.1007/s11554-019-00868-9
   Randen Trygve, 2007, BRODATZ TEXTURES
   Sebastian K., 2019, AUST J ELECT ELECT E, V16, P345, DOI [10.1080/1448837X.2019.1670535, DOI 10.1080/1448837X.2019.1670535]
   Singh A, 2020, IEEE ACCESS, V8, P112985, DOI 10.1109/ACCESS.2020.3003874
   Singh V, 2018, IEEE T FUZZY SYST, V26, P3170, DOI 10.1109/TFUZZ.2018.2805289
   SUN T, 1994, SIGNAL PROCESS, V35, P213, DOI 10.1016/0165-1684(94)90212-7
   Vaswani N, 2018, P IEEE, V106, P1359, DOI 10.1109/JPROC.2018.2844126
   Veerakumar T, 2019, CIRC SYST SIGNAL PR, V38, P2630, DOI 10.1007/s00034-018-0984-4
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Xiao XL, 2019, IEEE T NEUR NET LEAR, V30, P2028, DOI 10.1109/TNNLS.2018.2872541
   Xie HQ, 2021, IEEE T BIO-MED ENG, V68, P1074, DOI 10.1109/TBME.2020.3013491
   Yang GA, 2019, IEEE ACCESS, V7, P88243, DOI 10.1109/ACCESS.2019.2924674
   Yous H, 2019, J VIS COMMUN IMAGE R, V59, P486, DOI 10.1016/j.jvcir.2019.02.005
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang L, 2021, TSINGHUA SCI TECHNOL, V26, P736, DOI 10.26599/TST.2021.9010021
   Zhang MH, 2020, PATTERN ANAL APPL, V23, P135, DOI 10.1007/s10044-018-0762-8
   Zhao WZ, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2916976
   Zhao WZ, 2018, IEEE ACCESS, V6, P6303, DOI 10.1109/ACCESS.2017.2780985
   Zhou LY, 2020, MULTIMED TOOLS APPL, V79, P7543, DOI 10.1007/s11042-019-08531-y
   Zhou P, 2021, IEEE T IND ELECTRON, V68, P622, DOI 10.1109/TIE.2020.2967708
   Zhou XC, 2021, IEEE ACCESS, V9, P27601, DOI 10.1109/ACCESS.2021.3058120
NR 65
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1719
EP 1742
DI 10.1007/s11042-021-11426-6
EA OCT 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000705144700001
DA 2024-07-18
ER

PT J
AU Zhang, CF
AF Zhang, Chengfang
TI Multifocus image fusion using a convolutional elastic network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multifocus image fusion; Convolutional elastic network; Artificial
   texture; Edge information; Spatial continuity
ID PERFORMANCE; TRANSFORM
AB The aim of multifocus image fusion is to fuse two or more partially focused images into one fully focused image. To overcome the problem of a limited depth of field and blurred imaging of objects beyond the depth of field in optical imaging systems, a multifocus image fusion method based on a convolutional elastic network is proposed. Each source image is first decomposed into a base layer and a detail layer using the fast Fourier transform. Then, the convolutional elastic network performs fusion of the detail layers while applying the "choose-max" fusion rule to the base layers. Finally, the fused image is reconstructed by a two-dimensional inverse discrete Fourier transform. To verify the effectiveness of the proposed algorithm, we applied it and seven other popular methods to sets of multifocus images. The experimental results show that the proposed method overcomes the shortcomings of low spatial resolution and ambiguity in multifocus image fusion and achieves better contrast and clarity. In terms of both subjective visual effects and objective indicators, the performance of our method is optimal in comparation with other state-of-the-art fusion methods.
C1 [Zhang, Chengfang] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610039, Peoples R China.
   [Zhang, Chengfang] Sichuan Police Coll, Ctr Lab & Equipment, Luzhou 646000, Peoples R China.
C3 Sichuan University; Sichuan Police College
RP Zhang, CF (corresponding author), Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610039, Peoples R China.; Zhang, CF (corresponding author), Sichuan Police Coll, Ctr Lab & Equipment, Luzhou 646000, Peoples R China.
EM chengfangzhang@scpolicec.edu.cn
RI zhang, chengfang/AAB-5298-2022
OI Zhang, Chengfang/0000-0003-0123-4995
FU Sichuan Science and Technology Program [2020YFS0351]; Luzhou Science and
   Technology Program; Scientific Research Project of Sichuan Public
   Security Department [201917]
FX This work was supported by the Sichuan Science and Technology Program
   (No.2020YFS0351), Luzhou Science and Technology Program (No.2019-SYF-34)
   and Scientific Research Project of Sichuan Public Security Department
   (No. 201917). We thank AJE (www.aje.com) for its linguistic assistance
   during the preparation of this manuscript.
CR Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chai Y, 2012, OPTIK, V123, P569, DOI 10.1016/j.ijleo.2011.02.034
   Gao Z., 2016, OPTIK INT J LIGHT EL, V121305
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu FQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5632
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Nirmalraj S, 2020, ICT EXPRESS
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qiu CH, 2020, MICROSC RES TECHNIQ, V83, P35, DOI 10.1002/jemt.23385
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Wang PW, 2008, INT CONF SIGN PROCES, P965, DOI 10.1109/ICOSP.2008.4697288
   Wang Q, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P469, DOI 10.1016/B978-0-12-372529-5.00017-2
   Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260
   Xing CD, 2020, NEUROCOMPUTING, V402, P437, DOI 10.1016/j.neucom.2020.04.002
   Xing CD, 2019, IMAGE VISION COMPUT, V90, DOI 10.1016/j.imavis.2019.08.010
   Xinxiang LI., 2019, INTELL COMPUT APPL, V13, P24
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B., 2006, IEEE T IMAGE PROCESS, V15, P3736
   Yang B, 2014, OPTIK, V125, P4881, DOI 10.1016/j.ijleo.2014.04.036
   Yang Y, 2011, PROCEDIA ENGINEER, V24, P177, DOI 10.1016/j.proeng.2011.11.2622
   Yin HT, 2011, OPT ENG, V50, DOI 10.1117/1.3584840
   Zhang C, 2020, 1 INT C AGR ITIOTICT
   Zhang C., 2020, INT J WAVELETS MULTI, V11
   Zhang C, 2020, 3 INT C WIR COMM APP
   Zhang CF, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.5.051402
   Zhang CF, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.1.013043
   Zhang Lei, 2015, Optics and Precision Engineering, V23, P810, DOI 10.3788/OPE.20152303.0810
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 35
TC 1
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1395
EP 1418
DI 10.1007/s11042-021-11362-5
EA OCT 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000702800000003
DA 2024-07-18
ER

PT J
AU Durdu, A
AF Durdu, Ali
TI A new reversible low-distortion steganography method that hides images
   into RGB images with low loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Steganography; High-capacity; Lossy; Reversible;
   Low-distortion
ID SIGNIFICANT-BIT SUBSTITUTION; PIXEL
AB In this study, a new high-capacity, low-distortion, and reversible data hiding method based on RGB that hides color images inside color images is proposed. The proposed method divides the 24-bit image into 8-bit (1byte) meaningful segments, and the first most important 4 bits of the 8-bit data are hidden directly while the less important negligible 4-bit is not hidden and it is completed by rounding at approximate value through the function. The first 4 bits hidden in extraction are combined with the 4 bits from the function to retrieve 1 byte of information. In this way, since the 8-bit data is reduced to 4 bits, the method performs lossy hiding. Since the size of the data reduces by half owing to this method, it offers twice the capacity compared to the traditional LSB methods. When the same amount of data is hidden, the method creates lower distortion in the cover image than traditional LSB methods. Peak signal to noise ratio (PSNR) and structural similarity quality criterion (SSIM), which are frequently used in the literature, are used to measure the image quality of the proposed method. The test results showed that the proposed method achieved twice as much capacity in comparison to the traditional LSB method, higher efficiency than the studies in the literature, and higher PSNR and SSIM values as undetectable are obtained.
C1 [Durdu, Ali] Social Sci Univ Ankara, Fac Polit Sci, Dept Management Informat Syst, Ankara, Turkey.
C3 Ankara Sosyal Bilimler Universitesi; Ankara University
RP Durdu, A (corresponding author), Social Sci Univ Ankara, Fac Polit Sci, Dept Management Informat Syst, Ankara, Turkey.
EM ali.durdu@asbu.edu.tr
RI Durdu, Ali/GSI-8406-2022
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Chan CS, 2009, FUND INFORM, V96, P49, DOI 10.3233/FI-2009-166
   Chen BL, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102664
   Duan XT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247253
   Durdu A, 2016, THESIS SAKARYA U
   Durdu A, 2007, THESIS SAKARYA U
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Islam MR, 2021, INF SECUR J, V30, P359, DOI 10.1080/19393555.2020.1854902
   Kalaichelvi V, 2021, J AMB INTEL HUM COMP, V12, P7235, DOI 10.1007/s12652-020-02398-w
   Karakus S, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109691
   Khan S, 2021, MULTIMED TOOLS APPL, V80, P17045, DOI 10.1007/s11042-020-09652-5
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu HH, 2020, KSII T INTERNET INF, V14, P4537, DOI 10.3837/tiis.2020.11.016
   Mandal J. K., 2012, 2 INT C COMP SCI ENG
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Saran N, 2013, CANKAYA U J SCI ENG, V10, P17
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Swain G, 2016, MULTIMED TOOLS APPL, V75, P13541, DOI 10.1007/s11042-015-2937-2
   Tuncer T, 2018, MULTIMED TOOLS APPL, V77, P21463, DOI 10.1007/s11042-017-5569-x
   Wang YT, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164685
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang CY, 2015, ADV INTELL SYST COMP, V329, P145, DOI 10.1007/978-3-319-12286-1_15
NR 30
TC 3
Z9 3
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 953
EP 973
DI 10.1007/s11042-021-11405-x
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698137200002
DA 2024-07-18
ER

PT J
AU Alkhammash, EH
AF Alkhammash, Eman H.
TI Trustworthy smart city systems using refinement and Event-B Theories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event-B; Smart City Systems; Safety and security; Data refinement
AB Smart city systems do not only handle information but also handle many critical aspects of citizens' lives, including automobiles, healthcare, banking, etc. Smart city systems need to be both safe and secure systems. Therefore, this paper uses formal methods to develop safe and secure systes for smart city. However, because the creation of formal models is considered a difficult task that requires experience in modeling and a strong mathematical background, many techniques and patterns should be introduced to simplify the construction of formal models to make them more accessible for the development of systems, especially for systems pertaining to smart city services. In this paper, we propose an approach that uses Event-B theories to support data refinement and reduce the burden of proof for constructing Event-B formal models based on reused modeling components. In particular, we develop Event-B theories for common data structures based on pointers that could be used as patterns to carry out the refinement of abstract data structures, such as sets, lists and sequences. These data structures can offer solutions for the management of smart city services. We applied the proposed approach to construct Event-B models for task lists in a real-time operating system (FreeRTOS) to evaluate our approach. We successfully were able to model five task lists in FreeRTOS and developing data refinement levels without the need of spending long time in modeling or re-carrying any proofs.
C1 [Alkhammash, Eman H.] Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, POB 11099, At Taif 21944, Saudi Arabia.
C3 Taif University
RP Alkhammash, EH (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, POB 11099, At Taif 21944, Saudi Arabia.
EM Eman.kms@tu.edu.sa
RI Alkhammash, Eman/V-7020-2018
FU Taif University Researchers Supporting Project, Taif University, Taif,
   Saudi Arabia [TURSP-2020/292]
FX This work was supported by Taif University Researchers Supporting
   Project number (TURSP-2020/292), Taif University, Taif, Saudi Arabia.
CR Abrial Jean-Raymond, 2010, International Journal on Software Tools for Technology Transfer, V12, P447, DOI 10.1007/s10009-010-0145-y
   Abrial J R, 2010, Modeling in Event-B: system and softeng
   Alkhammash E, 2014, THESIS U SOUTHAMPTON
   Alkhammash EH, 2017, 15 MODELING GUIDELIN
   Alkhammash E, 2020, SOFT COMPUT, V24, P11095, DOI 10.1007/s00500-020-04688-z
   Barry R., 2010, USING FREERTOS REAL, V1st
   Butler CM, 2010, MATH EXTENSION EVENT
   Fu CY, 2018, INT CONF SOFTW ENG, P260, DOI 10.1109/ICSESS.2018.8663926
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   Iliasov A, 2010, LECT NOTES COMPUT SC, V6371, P50, DOI 10.1007/978-3-642-15898-8_4
   Iqbal Z, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718815845
   Jarrar A, 2018, COMPLEX ADAPT SYST M, V6, DOI 10.1186/s40294-018-0056-4
   Joochim T, 2010, TIMING DIAGRAMS REQU
   Lacinák M, 2017, PROCEDIA ENGINEER, V192, P522, DOI 10.1016/j.proeng.2017.06.090
   Latif Saba, 2019, 2019 International Conference on Frontiers of Information Technology (FIT), P304, DOI 10.1109/FIT47737.2019.00064
   Latif S., 2018, INT C COMP MATH ENG, P1, DOI DOI 10.1109/ICOMET.2018.8346327
   Latif S, 2019, 2019 13 INT C MATH, P1
   Latif S, 2018, 2018 12TH INTERNATIONAL CONFERENCE ON MATHEMATICS, ACTUARIAL SCIENCE, COMPUTER SCIENCE AND STATISTICS (MACS)
   Latif S, 2018, INT CONF FRONT INFO, P7, DOI 10.1109/FIT.2018.00009
   Li C, 2018, INT J CLOUD APPL COM, V8, P32, DOI 10.4018/IJCAC.2018070103
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li Q., 2003, REAL TIME CONCEPTS E
   Mammar A, 2017, INT J SOFTW TOOLS TE, V19, P167, DOI 10.1007/s10009-015-0391-0
   Predut S, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1541, DOI 10.1109/HPCC/SmartCity/DSS.2018.00253
   Rehman A, 2018, 2018 12TH INTERNATIONAL CONFERENCE ON MATHEMATICS, ACTUARIAL SCIENCE, COMPUTER SCIENCE AND STATISTICS (MACS)
   Ristvej J, 2020, MOBILE NETW APPL, V25, P836, DOI 10.1007/s11036-020-01524-4
   Romanovsky A., 2013, Industrial Deployment of System Engineering Methods
   Singh Neeraj Kumar, 2015, Digital Human Modeling. Applications in Health, Safety, Ergonomics and Risk Management: Ergonomics and Health. 6th International Conference, DHM 2015, held as part of HCI International 2015. Proceedings: LNCS 9185, P387, DOI 10.1007/978-3-319-21070-4_39
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Villanueva FJ, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P445, DOI 10.1109/IMIS.2013.80
   Santana EFZ, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3124391
NR 31
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 615
EP 636
DI 10.1007/s11042-021-11301-4
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695787100006
DA 2024-07-18
ER

PT J
AU Mehta, D
   Bhatti, D
AF Mehta, Darshan
   Bhatti, Dharmendra
TI Blind image steganography algorithm development which resistant against
   JPEG compression attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete cosine transform (DCT); JPEG compression; Image steganography;
   Robust; Imperceptibility; Payload; NCC; SSIM; BER; PSNR; Quality factor
ID WATERMARKING TECHNIQUE; SCHEME
AB Digital image steganography is now one of the effective methods for exchanging confidential information over the public network. One of the major challenges is to protect secret data embedded in to image against JPEG compression. This paper introduces a new method for image steganography which immune to JPEG compression with 100% retrieval rate of secret information up to 8192 bits payload with maintaining good Imperceptibility. The proposed algorithm is developed using DC coefficients of Discrete Cosine Transform (DCT) technique that resistant against lossy JPEG compression attack. The proposed algorithm can belong to the image realization steganography in which instead of actually embedding secret information directly to the cover image, key is derived with the combination of secret message and cover image and then the key is embed in the MSBs of the DC values in the selected blocks of DCT. The simulation test environment is used to perform a number of experiments on a standard dataset and to compare results with existing research. Standard parameters such as PSNR, Payload, BPP, SSIM and NCC are considered to evaluate the performance of the proposed algorithm. Efficiency of proposed work has been corroborated by conducting different experiments on various types of other attacks as well. Our proposed algorithm is surviving under JPEG compression attack for any quality factor range from 10 to 90.
C1 [Mehta, Darshan] VNSGU, UCCC, Surat, India.
   [Mehta, Darshan] VNSGU, SPBCBA, Surat, India.
   [Mehta, Darshan] VNSGU, SDHG Coll BCA & IT, Surat, India.
   [Bhatti, Dharmendra] Uka Tarsadia Univ, Bardoli, India.
C3 Veer Narmad South Gujarat University; Veer Narmad South Gujarat
   University; Veer Narmad South Gujarat University; UKA Tarsadia
   University
RP Mehta, D (corresponding author), VNSGU, UCCC, Surat, India.; Mehta, D (corresponding author), VNSGU, SPBCBA, Surat, India.; Mehta, D (corresponding author), VNSGU, SDHG Coll BCA & IT, Surat, India.
EM dmmehta83@gmail.com; dgbhatti@utu.ac.in
CR Abdullah W., 2016, AM SCI RES J ENG TEC, V24, P131
   [Anonymous], 2018, IMAGEPROCESSINGPLACE
   [Anonymous], 2018, SIPI USC EDU STANDAR
   Bairagi Anupam Kumar, 2014, 2013 16th International Conference on Computer and Information Technology (ICCIT), P81, DOI 10.1109/ICCITechn.2014.6997309
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Cabeen K., IMAGE COMPRESSION DI
   Chen BJ, 2020, KSII T INTERNET INF, V14, P366, DOI 10.3837/tiis.2020.01.020
   Ernawan F, 2017, INT CONF INTERNET, P92, DOI 10.23919/ICITST.2017.8356354
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Jagadeesh B., 2016, NOVEL APPROACH ROBUS
   Kang X, 2017, NOVEL HYBRID DCT SVD
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Mokhnache S., 2018, Int J Appl Eng Res., V13, P1900
   Nagalinga R., 2015, ROBUST DIGITAL IMAGE
   Nair K, 2015, INT J COMPUT APPL, V975, P8887
   Najih MNM, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS), P47, DOI 10.1109/ICICOS.2017.8276336
   Pal AK, 2019, INT ARAB J INF TECHN, V16, P116
   Paunwala M., 2012, DCT WATERMARKING APP, P1
   Rachmawanto EH., 2017, J Appl Intell Syst, V2, P1, DOI [10.33633/jais.v2i1.1330, DOI 10.33633/JAIS.V2I1.1330]
   Rawat S, 2012, OPT COMMUN, V285, P2563, DOI 10.1016/j.optcom.2012.01.067
   Sari CA, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTER SCIENCE AND INFORMATICS (EECSI), P183
   Singh S, 2014, TRANSFORM DOMAIN TEC
   Singh S., 2011, INT J SYST SIMUL, V5, P45
   Sleit A, 2012, IMAGING SCI J, V60, P29, DOI 10.1179/1743131X11Y.0000000010
   Tarhouni N, 2018, COMPUT SCI RES NOTES, V2802, P78, DOI 10.24132/CSRN.2018.2802.11
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Yesilyurt M, 2013, ELEKTRON ELEKTROTECH, V19, P47, DOI 10.5755/j01.eee.19.4.2015
   Yoonki Choi, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P216, DOI 10.1109/ICIP.1999.822887
   Zhang Y, 2016, SECUR COMMUN NETW, V9, P2957, DOI 10.1002/sec.1502
   Zhang Y, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P461, DOI 10.1109/ARES.2015.53
   Zheng YP, 2017, ITM WEB CONF, V12, DOI 10.1051/itmconf/20171201033
   Zhu Z, 2019, ROBUST STEGANOGRAPHY, DOI [10.1109/ACCESS.2019.2953504, DOI 10.1109/ACCESS.2019.2953504]
NR 33
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 459
EP 479
DI 10.1007/s11042-021-11351-8
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695102000001
DA 2024-07-18
ER

PT J
AU Sharma, H
   Jalal, AS
AF Sharma, Himanshu
   Jalal, Anand Singh
TI Image captioning improved visual question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual question answering (VQA); Image captioning; Computer vision (CV);
   Natural language processing (NLP)
ID ATTENTION
AB Both Visual Question Answering (VQA) and image captioning are the problems which involve Computer Vision (CV) and Natural Language Processing (NLP) domains. In general, computer vision models are effectively utilized to represent visual contents. While NLP algorithms are used to represent the sentences. In recent years, VQA and image captioning tasks are tackled independently although they require similar type of algorithms. In this paper, a joint relationship between these two tasks is established and exploited. We present an image captioning based VQA model that uses the knowledge learnt from the image captioning task and transfers that knowledge to VQA task. We integrate the image captioning module into the VQA model by fusing the features obtained from captioning model and the attention-based visual feature. The experimental results demonstrate the improvement in the answer generation accuracy by a margin 3.45 % on VQA 1.0, 3.33% on VQA 2.0 and 1.73% on VQA-CP v2 datasets over the state-of-the-art VQA models.
C1 [Sharma, Himanshu; Jalal, Anand Singh] GLA Univ Mathura, Dept Comp Engn & Applicat, Mathura, India.
C3 GLA University
RP Sharma, H (corresponding author), GLA Univ Mathura, Dept Comp Engn & Applicat, Mathura, India.
EM himanshu.sharma@gla.ac.in; asjalal@gla.ac.in
OI Jalal, Anand/0000-0002-7469-6608; Sharma, Himanshu/0000-0002-3745-7616
CR Agrawal A., 2016, P C EMP METH NAT LAN, P1955
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12
   [Anonymous], 2015, ARXIV151105676
   [Anonymous], 2015, CoRR
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Chen K., 2015, Abc-cnn: An attention based convolutional neural network for visual question answering
   Chen Long, 2020, P IEEE CVF C COMP VI
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Das A, 2017, COMPUT VIS IMAGE UND, V163, P90, DOI 10.1016/j.cviu.2017.10.001
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gao LL, 2020, NEUROCOMPUTING, V391, P227, DOI 10.1016/j.neucom.2018.11.102
   Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu Ronghang, 2020, 2020 IEEE CVF C COMP, P9992, DOI DOI 10.1109/CVPR42600.2020.01001
   Jiang H., 2020, IEEE CVF C COMP VIS, DOI 10.1109/CVPR42600.2020.01028
   Jun SH, 2017, ICEC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, DOI 10.1145/3154943.3154947
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kazemi V., 2017, ARXIV170403162
   Kazemzadeh S., 2014, EMNLP, P787, DOI DOI 10.3115/V1/D14-1086
   King DB, 2015, ACS SYM SER, V1214, P1
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu F, 2020, IEEE T PATTERN ANAL, V42, P460, DOI 10.1109/TPAMI.2018.2880185
   Liu Y, 2021, IEEE T CYBERNETICS, V51, P5585, DOI 10.1109/TCYB.2020.2988896
   Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Mishra A., 2019, 2019 INT C DOC AN RE, P947, DOI DOI 10.1109/ICDAR.2019.00156
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Ren Mengye, 2015, NIPS, P2953
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sharma A, 2019, COMPUT COMMUN, V148, P115, DOI 10.1016/j.comcom.2019.09.009
   Sharma Himanshu, 2020, 2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC), P325, DOI 10.1109/PARC49193.2020.236619
   Sharma H, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104165
   Sharma H, 2020, MOD PHYS LETT B, V34, DOI 10.1142/S0217984920503157
   Shevchenko V, 2020, ARXIV200501239
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang JB, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107075
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang Peng, 2015, ARXIV151102570
   Wang X., 2020, CVPR, P10126, DOI DOI 10.1109/CVPR42600.2020.01014
   Wu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1029, DOI 10.1145/3240508.3240640
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang JF, 2019, NEUROCOMPUTING, V328, P56, DOI 10.1016/j.neucom.2018.03.078
   Yang XS, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3313873
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Yu NG, 2019, IEEE T IMAGE PROCESS, V28, P2743, DOI 10.1109/TIP.2018.2889922
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang WF, 2020, INFORM FUSION, V55, P116, DOI 10.1016/j.inffus.2019.08.009
   Zhu XQ, 2022, MINIM INVASIV THER, V31, P262, DOI 10.1080/13645706.2020.1780452
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 75
TC 21
Z9 22
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34775
EP 34796
DI 10.1007/s11042-021-11276-2
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000693494700005
DA 2024-07-18
ER

PT J
AU Tan, DW
   Lu, YL
   Yan, XH
   Li, LL
AF Tan, Dingwei
   Lu, Yuliang
   Yan, Xuehu
   Li, Longlong
TI BAT: real-time inaudible sound capture with smartphones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Covert channels; Speaker-microphone communication; Inaudible sound;
   Air-gapped; Data exfiltration
AB People tend to store important information on air-gapped devices and believe that the information is safe. But in recent years, more and more methods have been proposed to exfiltrate information from an air-gapped system. The methods of breaking through air-gapped can be divided into electromagnetic, thermal, acoustic and optical covert channels. Acoustic covert channels are studied by many researchers and no researchers have focused on real-time communication using inaudible sound. In this paper we propose BAT, a novel real-time bidirectional communication system. By using sounds, BAT enables unobtrusive speaker-microphone data communication without affecting the primary audio-hearing experience of users. We first design a real-time covert communication system using inaudible frequencies. It can be implemented on off-the-shelf smartphones. Compared with other methods, our method is completely using inaudible frequencies and real-time covert communication is realized. Experiments show that BAT can achieve high decoding rate and better imperceptibility in various environments. The designed program BAT is highly practical.
C1 [Tan, Dingwei; Lu, Yuliang; Yan, Xuehu; Li, Longlong] Natl Univ Def Technol, Hefei 230037, Peoples R China.
C3 National University of Defense Technology - China
RP Yan, XH (corresponding author), Natl Univ Def Technol, Hefei 230037, Peoples R China.
EM publicLuYL@126.com; ictyanxuehu@163.com
RI Yan, Xuehu/AAG-1718-2022; Yan, Xuehu/AFK-3139-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720; Li,
   Longlong/0000-0001-7390-3647
FU National Science Foundation of China [:61602491]
FX This work is supported by the National Science Foundation of China
   (Grant Number:61602491)
CR [Anonymous], 2003, ISO2262003, V33, P802
   Deshotels L, 2014, US C OFF TECHN
   Guri Mordechai, 2017, Detection of Intrusions and Malware, and Vulnerability Assessment. 14th International Conference, DIMVA 2017. Proceedings: LNCS 10327, P161, DOI 10.1007/978-3-319-60876-1_8
   Guri M, 2017, PRIVACY SECURITY TRU
   Guri M., 2018, ODINI ESCAPING SENSI
   Guri M., 2017, AIR JUMPER COVERT AI
   Guri M, 2018, 2018 IEEE CONFERENCE ON DEPENDABLE AND SECURE COMPUTING (DSC), P188
   Guri M, 2017, LECT NOTES COMPUT SC, V10493, P98, DOI 10.1007/978-3-319-66399-9_6
   Guri M, 2015, 2015 IEEE 28TH COMPUTER SECURITY FOUNDATIONS SYMPOSIUM CSF 2015, P276, DOI 10.1109/CSF.2015.26
   Guri M, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON MALICIOUS AND UNWANTED SOFTWARE: THE AMERICAS (MALWARE), P58, DOI 10.1109/MALWARE.2014.6999418
   Hanspach M., 2014, arXiv preprint arXiv:1406.1213, P1
   Hyewon Lee, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P2407, DOI 10.1109/INFOCOM.2015.7218629
   Kuhn MG, 1998, LECT NOTES COMPUT SC, V1525, P124
   Li L, 2019, EXFILTRATING DATA SC
   Madhavapeddy A, 2005, IEEE PERVAS COMPUT, V4, P55, DOI 10.1109/MPRV.2005.50
   Mirsky Y., 2017, HVACKER BRIDGING AIR
   Nandakumar R, 2013, ACM SIGCOMM COMP COM, V43, P63, DOI 10.1145/2534169.2486037
   Nittala AS, 2015, ACM SIGCH S ENG INT
   Rra C, 1978, BR J IND MED, V35, P82
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Wicker S.B., 1999, Reed-Solomon codes and their applications
   Zhou M, 2019, IEEE T MOBILE COMPUT, V18, P560, DOI 10.1109/TMC.2018.2842771
   Zhou Z., 2017, EXFILTRATION DATA AI
NR 23
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33313
EP 33327
DI 10.1007/s11042-021-11372-3
EA AUG 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000685605200002
DA 2024-07-18
ER

PT J
AU Balaha, HM
   Ali, HA
   Youssef, EK
   Elsayed, AE
   Samak, RA
   Abdelhaleem, MS
   Tolba, MM
   Shehata, MR
   Mahmoud, MR
   Abdelhameed, MM
   Mohammed, MM
AF Balaha, Hossam Magdy
   Ali, Hesham Arafat
   Youssef, Esraa Khaled
   Elsayed, Asmaa Elsayed
   Samak, Reem Adel
   Abdelhaleem, Mohammed Samy
   Tolba, Mohammed Mosa
   Shehata, Mahmoud Ragab
   Mahmoud, Mahmoud Refa'at
   Abdelhameed, Mariam Mahmoud
   Mohammed, Mostafa Mahmoud
TI Recognizing arabic handwritten characters using deep learning and
   genetic algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic Handwritten Character Recognition (AHCR); Convolutional Neural
   Networks (CNN); Deep Learning (DL); Genetic Algorithms (GA); Learning
   Optimization; Transfer Learning (TF)
ID SLANT CORRECTION; RECOGNITION; IMAGE; SKEW; CLASSIFICATION;
   SEGMENTATION; DROPOUT
AB Automated techniques for Arabic content recognition are at a beginning period contrasted with their partners for the Latin and Chinese contents recognition. There is a bulk of handwritten Arabic archives available in libraries, data centers, historical centers, and workplaces. Digitization of these documents facilitates (1) to preserve and transfer the country's history electronically, (2) to save the physical storage space, (3) to proper handling of the documents, and (4) to enhance the retrieval of information through the Internet and other mediums. Arabic handwritten character recognition (AHCR) systems face several challenges including the unlimited variations in human handwriting and the leakage of large and public databases. In the current study, the segmentation and recognition phases are addressed. The text segmentation challenges and a set of solutions for each challenge are presented. The convolutional neural network (CNN), deep learning approach, is used in the recognition phase. The usage of CNN leads to significant improvements across different machine learning classification algorithms. It facilitates the automatic feature extraction of images. 14 different native CNN architectures are proposed after a set of try-and-error trials. They are trained and tested on the HMBD database that contains 54,115 of the handwritten Arabic characters. Experiments are performed on the native CNN architectures and the best-reported testing accuracy is 91.96%. A transfer learning (TF) and genetic algorithm (GA) approach named "HMB-AHCR-DLGA" is suggested to optimize the training parameters and hyperparameters in the recognition phase. The pre-trained CNN models (VGG16, VGG19, and MobileNetV2) are used in the later approach. Five optimization experiments are performed and the best combinations are reported. The highest reported testing accuracy is 92.88%.
C1 [Balaha, Hossam Magdy; Ali, Hesham Arafat; Youssef, Esraa Khaled; Elsayed, Asmaa Elsayed; Samak, Reem Adel; Abdelhaleem, Mohammed Samy; Tolba, Mohammed Mosa; Shehata, Mahmoud Ragab; Mahmoud, Mahmoud Refa'at; Abdelhameed, Mariam Mahmoud; Mohammed, Mostafa Mahmoud] Mansoura Univ, Fac Engn, Comp & Syst Engn Dept, Mansoura, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University
RP Balaha, HM (corresponding author), Mansoura Univ, Fac Engn, Comp & Syst Engn Dept, Mansoura, Egypt.
EM hossam.m.balaha@mans.edu.eg; h_arafat_ali@mans.edu.eg
RI Balaha, Hossam Magdy/Z-1960-2018; Ali, Hesham Arfafat/U-6362-2019
OI Balaha, Hossam Magdy/0000-0002-0686-4411; Ali, Hesham
   Arfafat/0000-0001-6675-7987; Hassan, Asmaa El-Sayed/0000-0002-4042-5519
CR Abuhaiba ISI, 1998, COMPUT VIS IMAGE UND, V71, P19, DOI 10.1006/cviu.1997.0629
   Acharya J, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P1, DOI 10.1109/ICCNC.2015.7069284
   Ahmed R, 2020, LECT NOTES ARTIF INT, V11691, P457, DOI 10.1007/978-3-030-39431-8_44
   Aiquan Yuan, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P125, DOI 10.1109/DAS.2012.61
   Akhand M. A. H., 2016, International Journal of Image, Graphics and Signal Processing, V8, P40, DOI 10.5815/ijigsp.2016.09.06
   Al-Helali BM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3060620
   Al-Shaher AA, 2003, PATTERN RECOGN, V36, P2805, DOI 10.1016/S0031-3203(03)00139-0
   Al-Taani AT, 2010, J PATTERN RECOGNIT R, V5, P23, DOI 10.13176/11.217
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ali AAA, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P187, DOI 10.1109/ICIIP47207.2019.8985839
   AlKhateeb JH, 2011, PATTERN RECOGN LETT, V32, P1081, DOI 10.1016/j.patrec.2011.02.006
   Althobaiti H, 2017, 2017 51ST ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS)
   Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   Amin A, 2003, PATTERN RECOGN LETT, V24, P3187, DOI 10.1016/j.patrec.2003.08.004
   Amin A., 1997, HDB CHARACTER RECOGN, P397, DOI [10.1142/ 9789812830968_ 0015, DOI 10.1142/9789812830968_0015]
   [Anonymous], 2014, INT J HYBRID INFORM
   [Anonymous], 2002, PRIK CIFED
   [Anonymous], 2009, Scholarpedia
   [Anonymous], 2004, Comput. Appl. Softw.
   Athoillah M., 2019, KINETIK GAME TECHNOL, V4, P99, DOI [10.22219/kinetik.v4i2.724, DOI 10.22219/KINETIK.V4I2.724]
   Bafjaish SS., 2020, INDONES J ELECT ENG, V17, P516, DOI [10.11591/ijeecs.v17.i1.pp516-523, DOI 10.11591/IJEECS.V17.I1.PP516-523]
   Bai JF, 2014, IEEE IMAGE PROC, P2560, DOI 10.1109/ICIP.2014.7025518
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P3011, DOI 10.1007/s00521-020-05137-6
   Baldi P., 2012, P ICML WORKSH UNS TR, P37, DOI [10.5555/3045796.3045801., DOI 10.1561/2200000006, 10.1561/2200000006]
   Bengio Yoshua, 2015, ARXIV
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bisong E., 2019, BUILDING MACHINE LEA, DOI [DOI 10.1007/978-1-4842-4470-8_7, DOI 10.1007/978-1-4842-4470-87, 10.1007/978-1-4842-4470-8]
   Bradski G., 2008, KAEHLER
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Christlein Vincent, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1090, DOI 10.1109/ICDAR.2019.00177
   CHUA LO, 1993, IEEE T CIRCUITS-I, V40, P147, DOI 10.1109/81.222795
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Cogswell M., 2015, ARXIV PREPRINT ARXIV
   Dai YC, 2018, INT C PATT RECOG, P3604, DOI 10.1109/ICPR.2018.8546066
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duan KB, 2003, LECT NOTES COMPUT SC, V2709, P125
   El-Desouky A. I., 1991, Third International Conference on Software Engineering for Real Time Systems (Conf. Publ. No.344), P212
   El-Sawy A, 2017, ADV INTELL SYST COMP, V533, P566, DOI 10.1007/978-3-319-48308-5_54
   ElAdel A, 2015, PROC INT C TOOLS ART, P807, DOI 10.1109/ICTAI.2015.119
   Elarian Y, 2019, INT J ADV COMPUT SC, V10, P406
   Elarian Y, 2015, PROC INT CONF DOC, P896, DOI 10.1109/ICDAR.2015.7333891
   ELLEUCH M, 2015, SYST SIGN DEV SSD 20, P1
   Elzobi M, 2013, INT J DOC ANAL RECOG, V16, P295, DOI 10.1007/s10032-012-0190-z
   Farooq F, 2005, PROC INT CONF DOC, P267, DOI 10.1109/ICDAR.2005.191
   Firdaus FI, 2017, 2017 INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY (SIET), P392, DOI 10.1109/SIET.2017.8304170
   Gardiner Alan., 1916, J EGYPT ARCHAEOL, V3, P1
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grahl J, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P397
   Ham FM, 1996, IEEE T BIO-MED ENG, V43, P425, DOI 10.1109/10.486263
   Hamalainen W., 2006, CLASS NP NP COMPLETE
   Hara K, 2015, IEEE IJCNN, P1, DOI DOI 10.1109/IJCNN.2015.7280578
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He MJ, 2015, PROC INT CONF DOC, P61, DOI 10.1109/ICDAR.2015.7333726
   Hesterman JY, 2010, IEEE T NUCL SCI, V57, P1077, DOI 10.1109/TNS.2010.2045898
   Heutte L., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P210, DOI 10.1109/ICPR.1996.546819
   Hifny Y, 2019, IEEE SIGNAL PROC LET, V26, P1421, DOI 10.1109/LSP.2019.2933721
   HIROSE Y, 1991, NEURAL NETWORKS, V4, P61, DOI 10.1016/0893-6080(91)90032-Z
   Howard A. G., 2017, arXiv
   Huang G, 2016, ARXIV 160806993
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Javed F., 2013, The Criterion, V4, P1
   Jiang Y, 2018, LECT NOTES ARTIF INT, V10947, P198, DOI 10.1007/978-3-319-93843-1_15
   Junker M., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P713, DOI 10.1109/ICDAR.1999.791887
   Kar R, 2019, IMAGING SCI J, V67, P159, DOI 10.1080/13682199.2019.1574368
   Karim A., 2019, J U BABYLONFORPURE A, V27, P1, DOI DOI 10.29196/JUBPAS.V27I1.2060
   Kaye, 2003, MAJOR LANGUAGES S AS, P144
   Kef M, 2016, PATTERN ANAL APPL, V19, P1041, DOI 10.1007/s10044-015-0500-4
   Khuman YLK, 2021, MATER TODAY-PROC, V37, P2666, DOI 10.1016/j.matpr.2020.08.522
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma D. P., 2014, arXiv
   Kingma D.P., 2016, ADV NEURAL INFORM PR, P4107
   Kumar T., 2010, Int J Comput Appl, V7, P7, DOI DOI 10.5120/1140-1493
   Lamtougui H, 2020, 2020 INT C INTELLIGE, P1, DOI DOI 10.1109/ISCV49265.2020.9204214
   Lawgali A., 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P255
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Liang YD, 2016, NEUROCOMPUTING, V194, P340, DOI 10.1016/j.neucom.2016.02.046
   Liu B, 2018, IEEE T GEOSCI REMOTE, V56, P1909, DOI 10.1109/TGRS.2017.2769673
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Marler RT, 2010, STRUCT MULTIDISCIP O, V41, P853, DOI 10.1007/s00158-009-0460-7
   McMahan HB, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1222
   Miikkulainen R, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, P293, DOI 10.1016/B978-0-12-815480-9.00015-3
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Motawa D, 1997, PROC INT CONF DOC, P625, DOI 10.1109/ICDAR.1997.620580
   Motwani MC, 2004, SURVEY IMAGE DENOISI
   Mozaffari S, 2005, PROC INT CONF DOC, P819, DOI 10.1109/ICDAR.2005.72
   Mukkamala Mahesh Chandra, 2017, ARXIV170605507
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Naz S, 2016, EDUC INF TECHNOL, V21, P1225, DOI 10.1007/s10639-015-9377-5
   Nwankpa C., 2018, ARXIV181103378
   Pak I., 2018, INNOVATIVE COMPUTING, V741, P167, DOI [DOI 10.1007/978-3-319-66984-7_10, 10.1007/978-3-319-66984-7_10]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parvez MT, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431222
   Pedamonti D, 2018, ARXIV180402763
   POON PW, 1995, COMPUT OPER RES, V22, P135, DOI 10.1016/0305-0548(93)E0024-N
   Pratihar DilipKumar., 2013, SOFT COMPUTING FUNDA
   Retso, 2013, OXFORD HDB ARABIC LI, V422, P450
   Ruder S., 2016, ARXIV
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahlol A, 2014, NOVEL METHOD RECOGNI
   Sandler Mark, 2018, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2018.00474, DOI 10.1109/CVPR.2018.00474]
   Saravanan C, 2010, INT C COMPUT ENG APP, P196, DOI 10.1109/ICCEA.2010.192
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Schmitt LM, 2001, THEOR COMPUT SCI, V259, P1, DOI 10.1016/S0304-3975(00)00406-0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sen Maitra D, 2015, PROC INT CONF DOC, P1021, DOI 10.1109/ICDAR.2015.7333916
   Set, PRECISION RECALL F1, V16, P12
   Shams M, 2020, INT J ADV COMPUT SC, V11, P144
   Simard PY, 2003, PROC INT CONF DOC, P958
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P, 2016, ADV INTELL SYST, V434, P551, DOI 10.1007/978-81-322-2752-6_54
   Slavík P, 2001, IEEE T PATTERN ANAL, V23, P323, DOI 10.1109/34.910885
   Soman ST, 2013, NATL CONF COMMUN
   Sonka M., 1993, Image Processing, Analysis and Machine Vision, P56, DOI [DOI 10.1007/978-1-4899-3216-7_4, 10.1007/978-1-4899-3216-7_4]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun CM, 1997, PROC INT CONF DOC, P142, DOI 10.1109/ICDAR.1997.619830
   Tato A., 2018, IMPROVING ADAM OPTIM
   Vorontsov E, 2017, PR MACH LEARN RES, V70
   WALLER RA, 1969, J AM STAT ASSOC, V64, P1484, DOI 10.2307/2286085
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Ward R, 2019, PR MACH LEARN RES, V97
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   WITTEN IH, 1994, P IEEE, V82, P878, DOI 10.1109/5.286192
   Wright William., 2011, GRAMMAR ARABIC LANGU
   Wu CP, 2014, INT CONF FRONT HAND, P291, DOI 10.1109/ICFHR.2014.56
   Wu HB, 2015, NEURAL NETWORKS, V71, P1, DOI 10.1016/j.neunet.2015.07.007
   Wu V, 1999, IEEE T PATTERN ANAL, V21, P1224, DOI 10.1109/34.809116
   Xiang T, 2007, IEEE C EVOL COMPUTAT, P3341, DOI 10.1109/CEC.2007.4424903
   Xiong H, 2006, IEEE T KNOWL DATA EN, V18, P304, DOI 10.1109/TKDE.2006.46
   Yang WJ, 2015, PATIENT PREFER ADHER, V9, P551, DOI 10.2147/PPA.S78871
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang C., 2018, A study on overfitting in deep reinforcement learning
   Zhong ZY, 2015, PROC INT CONF DOC, P96, DOI 10.1109/ICDAR.2015.7333733
   Zhong ZY, 2015, PROC INT CONF DOC, P846, DOI 10.1109/ICDAR.2015.7333881
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 136
TC 29
Z9 29
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32473
EP 32509
DI 10.1007/s11042-021-11185-4
EA JUL 2021
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679762700006
DA 2024-07-18
ER

PT J
AU Ahuja, B
   Vishwakarma, VP
AF Ahuja, Bhawna
   Vishwakarma, Virendra P.
TI Deterministic multikernel extreme learning machine with fuzzy feature
   extraction for pattern classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern classification; ELM; KELM; MKL; Deterministic learning; Fuzzy
   feature extraction
ID FACE RECOGNITION; FUNCTION APPROXIMATION; REGRESSION; NORMALIZATION;
   NETWORKS; MATRICES; DOMAIN
AB In this paper a novel multikernel deterministic extreme learning machine (ELM) and its variants are developed for classification of non-linear problems. Over a decade ELM is proved to be efficacious learning algorithms, but due to the non-deterministic and single kernel dependent feature mapping proprietary, it cannot be efficiently applied to real time classification problems that require invariant output solution. We address this problem by analytically calculation of input and hidden layer parameters for achieving the deterministic solution and exploiting the data fusion proficiency of multiple kernel learning. This investigation originates a novel deterministic ELM with single layer architecture in which kernel function is aggregation of linear combination of disparate base kernels. The weight of kernels depends upon perspicacity of problem and is empirically calculated. To further enhance the performance we utilize the capabilities of fuzzy set to find the pixel-wise coalition of face images with different classes. This handles the uncertainty involved in face recognition under varying environment condition. The pixel-wise membership value extracts the unseen information from images up to significant extent. The validity of the proposed approach is tested extensively on diverse set of face databases: databases with and without illumination variations and discrete types of kernels. The proposed algorithms achieve 100% recognition rate for Yale database, when seven and eight images per identity are considered for training. Also, the superior recognition rate is achieved for AT & T, Georgia Tech and AR databases, when compared with contemporary methods that prove the efficacy of proposed approaches in uncontrolled conditions significantly.
C1 [Ahuja, Bhawna; Vishwakarma, Virendra P.] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Sect-16C,Dwarka, New Delhi 110078, India.
C3 GGS Indraprastha University
RP Vishwakarma, VP (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Sect-16C,Dwarka, New Delhi 110078, India.
EM Bhawna17.ahuja@gmail.com; virendravishwa@rediffmail.com
OI Vishwakarma, Virendra P./0000-0003-4276-8766
CR Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahuja Bhawna, 2020, 2020 6th International Conference on Signal Processing and Communication (ICSC), P91, DOI 10.1109/ICSC48311.2020.9182760
   Ahuja B, 2019, 2019 12 INT C CONT C, P1
   Ahuja B, 2018, INT J APPL PATTERN R, V5, P330
   Aiolli F, 2015, NEUROCOMPUTING, V169, P215, DOI 10.1016/j.neucom.2014.11.078
   Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212
   Chen L, 2005, PATTERN RECOGN, V38, P799, DOI 10.1016/j.patcog.2004.11.003
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Deng CW, 2020, IEEE T CYBERNETICS, V50, P2781, DOI 10.1109/TCYB.2018.2886580
   Deng WY, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P389, DOI 10.1109/CIDM.2009.4938676
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Evgeniou T, 2005, J MACH LEARN RES, V6, P615
   Fan XC, 2021, IEEE T MOBILE COMPUT, V20, P2154, DOI 10.1109/TMC.2020.2976936
   Feng GR, 2009, IEEE T NEURAL NETWOR, V20, P1352, DOI 10.1109/TNN.2009.2024147
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guo P., 2018, ARXIV180507828
   Guo P, 2001, ADV NEURAL NETWORKS
   Han F, 2006, NEUROCOMPUTING, V69, P2369, DOI 10.1016/j.neucom.2006.02.013
   Han HG, 2014, NEUROCOMPUTING, V128, P128, DOI 10.1016/j.neucom.2013.01.057
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Huang GB, 2006, IEEE T CIRCUITS-II, V53, P187, DOI 10.1109/TCSII.2005.857540
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2008, NEUROCOMPUTING, V71, P576, DOI 10.1016/j.neucom.2007.07.025
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang ZY, 2017, IEEE T CYBERNETICS, V47, P920, DOI 10.1109/TCYB.2016.2533424
   Jian YL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061434
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Kim DJ, 2008, IEEE T FUZZY SYST, V16, P874, DOI 10.1109/TFUZZ.2008.924344
   Klir G., 1995, Fuzzy sets and fuzzy logic, V4
   Li S.Z., 2005, Handbook of Face Recognition
   Li XD, 2016, NEURAL COMPUT APPL, V27, P175, DOI 10.1007/s00521-014-1709-7
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Liu XW, 2015, NEUROCOMPUTING, V149, P253, DOI 10.1016/j.neucom.2013.09.072
   Lu CB, 2019, MEMET COMPUT, V11, P27, DOI 10.1007/s12293-017-0236-3
   Martínez-Martínez JM, 2011, NEUROCOMPUTING, V74, P3716, DOI 10.1016/j.neucom.2011.06.013
   Miche Y, 2010, IEEE T NEURAL NETWOR, V21, P158, DOI 10.1109/TNN.2009.2036259
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   RAO CR, 1971, SANKHYA SER A, V33, P289
   Rong HJ, 2009, IEEE T SYST MAN CY B, V39, P1067, DOI 10.1109/TSMCB.2008.2010506
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Vishwakarma VP, 2015, INT J MACH LEARN CYB, V6, P17, DOI 10.1007/s13042-013-0182-4
   Wang YG, 2011, NEUROCOMPUTING, V74, P2483, DOI 10.1016/j.neucom.2010.11.030
   Wong CM, 2018, IEEE T NEUR NET LEAR, V29, P757, DOI 10.1109/TNNLS.2016.2636834
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   Xu D, 2010, INT CONF COMP SCI, P1, DOI 10.1109/ICCSIT.2010.5563584
   Yang HQ, 2011, IEEE T NEURAL NETWOR, V22, P433, DOI 10.1109/TNN.2010.2103571
   Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904
   ZADEH LA, 1988, COMPUTER, V21, P83, DOI 10.1109/2.53
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou CJ, 2013, OPTIK, V124, P5599, DOI 10.1016/j.ijleo.2013.04.108
   Zhu QY, 2005, PATTERN RECOGN, V38, P1759, DOI 10.1016/j.patcog.2005.03.028
   Zhuang Jinfeng, 2011, JMLR Proceedings, V15, P909
   Zong WW, 2011, LECT NOTES ARTIF INT, V6752, P263, DOI 10.1007/978-3-642-21538-4_26
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
   Zong WW, 2011, NEUROCOMPUTING, V74, P2541, DOI 10.1016/j.neucom.2010.12.041
   Zou CM, 2016, IEEE T IMAGE PROCESS, V25, P3287, DOI 10.1109/TIP.2016.2567077
NR 68
TC 7
Z9 7
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32423
EP 32447
DI 10.1007/s11042-021-11097-3
EA JUL 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679633200003
DA 2024-07-18
ER

PT J
AU Chhikara, S
   Kumar, R
AF Chhikara, Sonam
   Kumar, Rajeev
TI Image steganalysis with entropy hybridized with chaotic grasshopper
   optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Entropy; Grasshopper optimization; Particle swarm
   optimization; Chaotic maps
ID FEATURE-SELECTION; ALGORITHM; HEURISTICS; NETWORK
AB We propose a hybrid grasshopper optimizer to reduce the size of the feature set in the steganalysis process using information theory and other stochastic optimization techniques. This paper results from the stagnancy of local minima and slow convergence rate by the grasshopper algorithm in optimization problems. Therefore, we enhance the grasshopper optimization (GOA) performance with chaotic maps to make it Chaotic GOA (CGOA). Then, we combine the CGOA with adaptive particle swarm optimization (APSO) to make it Chaotic Particle-Swarm Grasshopper Optimization Algorithm (CPGOA). Next, we use the proposed optimizer with entropy to find the best feature subset of the original Subtractive Pixel Adjacency Model (SPAM) and Spatial Rich Model (SRM) feature set. Finally, the proposed technique is experimented with to detect the spatial domain steganography with different embedding rates on the BOSSbase 1.01 grayscale image database. The results show the improved results from the proposed hybrid optimizer compared to the original GOA and other state-of-the-art feature selection methods in steganalysis.
C1 [Chhikara, Sonam; Kumar, Rajeev] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Kumar, R (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM rajeevkumar.cse@gmail.com
RI Kumar, Rajeev/I-3506-2019
OI Kumar, Rajeev/0000-0001-5545-6919; Kumar, Rajeev/0000-0003-0233-6563
CR Abdulla AA, 2015, THESIS U BLUCK
   Abid Y, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON ENERGY CONSERVATION AND EFFICIENCY (ICECE), P1
   Bansal S, 2020, ARTIF INTELL REV, V53, P5589, DOI 10.1007/s10462-020-09829-2
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Burke EK, 2013, J OPER RES SOC, V64, P1695, DOI 10.1057/jors.2013.71
   Chen XC, 2006, INT C PATT RECOG, P1107
   Chhikara RR, 2018, INT J MACH LEARN CYB, V9, P821, DOI 10.1007/s13042-016-0610-3
   Chhikara RR, 2016, INT J MACH LEARN CYB, V7, P1195, DOI 10.1007/s13042-015-0448-0
   Chhikara S, 2020, ACTA CYBERN, V24, P593, DOI 10.14232/actacyb.279174
   Chhikara S, 2020, MULTIMED TOOLS APPL, V79, P29723, DOI 10.1007/s11042-020-09328-0
   Christaline JA, 2017, J COMPUT SCI-NETH, V21, P182, DOI 10.1016/j.jocs.2017.06.014
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1279, DOI 10.1109/ICME.2000.871000
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guettari N, 2016, IEEE IMAGE PROC, P2742, DOI 10.1109/ICIP.2016.7532858
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Jackson J.E., 1991, A user's guide to principal components, DOI DOI 10.1002/0471725331
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kumar R, 2011, APPL SOFT COMPUT, V11, P5120, DOI 10.1016/j.asoc.2011.05.047
   Kumar R, 2010, APPL SOFT COMPUT, V10, P711, DOI 10.1016/j.asoc.2009.08.037
   Lafferty P, 2004, PROC SPIE, V5561, P145, DOI 10.1117/12.559896
   Leach KN, 2002, SE SYM SYS THRY, P239, DOI 10.1109/SSST.2002.1027042
   Lejiang Guo, 2011, Journal of Networks, V6, P815, DOI 10.4304/jnw.6.5.815-822
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li YY, 2014, NEUROCOMPUTING, V134, P132, DOI 10.1016/j.neucom.2012.12.068
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Mageshkumar C, 2019, CLUSTER COMPUT, V22, P435, DOI 10.1007/s10586-018-2242-8
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Pathak Y, 2019, MULTIMED TOOLS APPL, V78, P1473, DOI 10.1007/s11042-018-6155-6
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Raidl GR, 2006, LECT NOTES COMPUT SC, V4030, P1
   Saha S, 2013, APPL SOFT COMPUT, V13, P2812, DOI 10.1016/j.asoc.2012.06.021
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Shi YQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P269, DOI 10.1109/ICME.2005.1521412
   Ting T. O., 2015, RECENT ADV SWARM INT, P71, DOI [10.1007/ 978-3-319-13826-8_4, DOI 10.1007/978-3-319-13826-8_4]
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Yang XS, 2013, COMPUT OPER RES, V40, P1616, DOI 10.1016/j.cor.2011.09.026
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Zhan ZH, 2009, IEEE T SYST MAN CY B, V39, P1362, DOI 10.1109/TSMCB.2009.2015956
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhao XX, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P84, DOI 10.1109/WKDD.2009.105
   Zou DK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1365, DOI 10.1109/ICME.2006.262792
NR 61
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31865
EP 31885
DI 10.1007/s11042-021-11118-1
EA JUL 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000675334700002
DA 2024-07-18
ER

PT J
AU Wei, HY
   Zhang, T
   Zhang, L
AF Wei, Hongyu
   Zhang, Tao
   Zhang, Liang
TI GMSK-SLAM: a new RGB-D SLAM method with dynamic areas detection towards
   dynamic environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic environments; SLAM; GMS algorithm; Moving areas detection
ID ROBUST; VERSATILE; FEATURES
AB As a research hotspot in the field of robotics, Simultaneous localization and mapping (SLAM) has made great progress in recent years, but few SLAM algorithms take dynamic or movable targets in the scene into account. In this paper, a robust new RGB-D SLAM method with dynamic area detection towards dynamic environments named GMSK-SLAM is proposed. Most of the existing related papers use the method of directly eliminating the whole dynamic targets. Although rejecting dynamic objects can increase the accuracy of robot positioning to a certain extent, this type of algorithm will result in the reduction of the number of available feature points in the image. The lack of sufficient feature points will seriously affect the subsequent precision of positioning and mapping for feature-based SLAM. The proposed GMSK-SLAM method innovatively combines Grid-based Motion Statistics (GMS) feature points matching method with K-means cluster algorithm to distinguish dynamic areas from the images and retain static information from dynamic environments, which can effectively increase the number of reliable feature points and keep more environment features. This method can achieve a highly improvements on localization accuracy in dynamic environments. Finally, sufficient experiments were conducted on the public TUM RGB-D dataset. Compared with ORB-SLAM2 and the RGB-D SLAM, our system, respectively, got 97.3% and 90.2% improvements in dynamic environments localization evaluated by root-mean-square error. The empirical results show that the proposed algorithm can eliminate the influence of the dynamic objects effectively and achieve a comparable or better performance than state-of-the-art methods.
C1 [Wei, Hongyu; Zhang, Tao; Zhang, Liang] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
   [Wei, Hongyu; Zhang, Tao; Zhang, Liang] Minist Educ, Key Lab Microinertial Instrument & Adv Nav Techno, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Zhang, T (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.; Zhang, T (corresponding author), Minist Educ, Key Lab Microinertial Instrument & Adv Nav Techno, Nanjing 210096, Peoples R China.
EM zhangtao22@seu.edu.cn
FU National Natural Science Foundation of China [52071080]; Fundamental
   Research Funds for the Central Universities [2242021K1G008]; Remaining
   funds cultivation project of National Natural Science Foundation of
   Southeast University [9S20172204]
FX This work was supported in part by National Natural Science Foundation
   of China 52071080, Fundamental Research Funds for the Central
   Universities under Grant 2242021K1G008, Remaining funds cultivation
   project of National Natural Science Foundation of Southeast University
   under Grant 9S20172204.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bahraini MS, 2018, MECHATRONICS, V49, P105, DOI 10.1016/j.mechatronics.2017.12.002
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Fang YQ, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P1197, DOI 10.1109/ICCSE.2009.5228464
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258
   Klein George, 2007, P1
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777
   Lee SJ, 2019, INT J CONTROL AUTOM, V17, P2597, DOI 10.1007/s12555-018-0790-6
   Li JN, 2016, MULTIMED TOOLS APPL, V75, P8675, DOI 10.1007/s11042-015-2780-5
   Liu GH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173714
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacQueen J, 1965, P 5 BER S MATH STAT, P281
   Mu XK, 2020, IEEE ACCESS, V8, P465, DOI 10.1109/ACCESS.2019.2961762
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Oh S, 2015, MULTIMED TOOLS APPL, V74, P6413, DOI 10.1007/s11042-014-2093-0
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saputra MRU, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177853
   Sharma K, 2018, MULTIMED TOOLS APPL, V77, P7955, DOI 10.1007/s11042-017-4694-x
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012
   Wang R, 2019, REMOTE SENS-BASEL, V11
   Wrobel, 2001, MULTIPLE VIEW GEOMET
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691
   Zhang W, 2018, NEUROCOMPUTING, V275, P781, DOI 10.1016/j.neucom.2017.09.012
NR 41
TC 13
Z9 14
U1 9
U2 90
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31729
EP 31751
DI 10.1007/s11042-021-11168-5
EA JUL 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000674550000005
DA 2024-07-18
ER

PT J
AU Jang, YT
   Hsieh, PS
AF Jang, Yu-Teng
   Hsieh, Pei-Shan
TI Understanding consumer behavior in the multimedia context: incorporating
   gamification in VR-enhanced web system for tourism e-commerce
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia technology adoption; Gamification; Electronic commerce; User
   behavior; Partial least squares (PLS)
ID PERCEIVED VALUE; MEDIA RICHNESS; VIRTUAL-REALITY; SELF-EFFICACY;
   CO-CREATION; SATISFACTION; EXPERIENCE; IMPACT; MODEL; FLOW
AB This study aims to investigate how gamification and virtual reality (VR)-enhanced web services can be integrated to influence consumer behavior in the context of tourism e-commerce. A gamified VR-enhanced tourism web system (VRTWS) was designed and developed for this investigation, while a research framework with 12 hypotheses was proposed and empirically tested by adopting PLS-SEM approach to analyze 208 valid data collected from survey. The results reveal that both Enjoyment and Activation in Gamification significantly and positively affected Media Richness. Additionally, Media Richness significantly and positively affected both Usefulness and Ease of Use in using VR technology with gamification. Also, a user's Perceived Value is not only positively affected by Usefulness and Ease of Use but also Interactivity and Immersion in a gamified VRTWS. Immersion was found to be positively affected by Presence. Through the positive effect on Satisfaction, user's Perceived Value had positive effect on the Intention toward adoption. The proposed gamified VRTWS and the study results with implications are expected to be referenced by the researchers and practitioners for managing incorporation of gamification into designing, developing, and managing their VR-enhanced service in tourism e-commerce.
C1 [Jang, Yu-Teng; Hsieh, Pei-Shan] Tunghai Univ, Dept Business Adm, Taichung, Taiwan.
C3 Tunghai University
RP Jang, YT (corresponding author), Tunghai Univ, Dept Business Adm, Taichung, Taiwan.
EM ytjackyjang@thu.edu.tw; psh1983@thu.edu.tw
OI Jang, Yu-Teng Jacky/0000-0002-9993-5775; Hsieh,
   Pei-shan/0000-0001-7031-5006
CR Abdel-Hadi A, 2012, PROCD SOC BEHV, V50, P11, DOI 10.1016/j.sbspro.2012.08.011
   Agogué M, 2015, CREAT INNOV MANAG, V24, P415, DOI 10.1111/caim.12138
   Airbnb, 2019, AIRBNB VAC RENT HOM
   Ali F, 2016, J HOSP MARKET MANAG, V25, P449, DOI 10.1080/19368623.2015.1019172
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   Aratuo DN, 2019, TOURISM MANAGE, V70, P333, DOI 10.1016/j.tourman.2018.09.004
   Ashraf AR, 2016, ELECTRON COMMER R A, V20, P69, DOI 10.1016/j.elerap.2016.10.001
   Belanche D, 2012, J RETAIL CONSUM SERV, V19, P124, DOI 10.1016/j.jretconser.2011.11.001
   Biocca Frank, 2013, COMMUNICATION AGE VI
   Bojanic D. C., 1996, Journal of Hospitality & Leisure Marketing, V4, P5, DOI 10.1300/J150v04n01_02
   Brackett LK, 2001, J ADVERTISING RES, V41, P23, DOI 10.2501/JAR-41-5-23-32
   Cao KJ, 2016, J DESTIN MARK MANAGE, V5, P283, DOI 10.1016/j.jdmm.2016.01.005
   Carlson JR, 1999, ACAD MANAGE J, V42, P153, DOI 10.2307/257090
   Chalhoub E, 2016, GYNECOL SURG, V13, P419, DOI 10.1007/s10397-016-0986-9
   Charfi AA, 2014, INT J ONLINE MARKET, V4, P17, DOI 10.4018/IJOM.2014100102
   Chen JH, 2018, ELECTRON COMMER R A, V27, P118, DOI 10.1016/j.elerap.2017.12.009
   Chen KC, 2008, DECIS SUPPORT SYST, V45, P822, DOI 10.1016/j.dss.2008.02.002
   Chin WW, 2003, INFORM SYST RES, V14, P189, DOI 10.1287/isre.14.2.189.16018
   Chniti N A., 2015, International Journal of Innovation and Scientific Research, V16, P514
   Choi JH, 2014, ANN REHABIL MED-ARM, V38, P485, DOI 10.5535/arm.2014.38.4.485
   Chung N, 2015, TECHNOL FORECAST SOC, V96, P130, DOI 10.1016/j.techfore.2015.03.004
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, DOI DOI 10.1037/10516-164
   DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dennis AR, 1998, INFORM SYST RES, V9, P256, DOI 10.1287/isre.9.3.256
   do Valle PO, 2016, J TRAVEL RES, V55, P695, DOI 10.1177/0047287515569779
   Ducoffe R.H., 1995, Journal of Current Issues & Research in Advertising, V17, P1, DOI [DOI 10.1080/10641734.1995.10505022, 10.1080/10641734.1995.10505022]
   Elliott MT, 1998, J ADVERTISING RES, V38, P29
   Eppmann R, 2018, J INTERACT MARK, V43, P98, DOI 10.1016/j.intmar.2018.03.002
   Expedia, 2018, GEN MOV DEEP MULT TR
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Gale B., 1994, MANAGING CUSTOMER VA
   Gefen D., 2000, J ASSOC INF SYST, V1, DOI [10.17705/1jais.00008, DOI 10.17705/1JAIS.00008]
   Gefen D, 2005, COMMUN ASSOC INF SYS, V16, P91, DOI 10.17705/1CAIS.01605
   Gilmore JamesH., 2007, Authenticity: What Consumers Really Want
   Gostin LO, 2020, JAMA-J AM MED ASSOC, V323, P2137, DOI 10.1001/jama.2020.5460
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Hair JF Jr, 2017, ADV ISSUES PARTIAL L
   Hair JF, 2014, EUR BUS REV, V26, P106, DOI 10.1108/EBR-10-2013-0128
   Hakak S, 2019, COMPUT ELECTR ENG, V74, P22, DOI 10.1016/j.compeleceng.2019.01.002
   Harwood T, 2015, J SERV MARK, V29, P533, DOI 10.1108/JSM-01-2015-0045
   Hasan B, 2006, INFORM MANAGE-AMSTER, V43, P565, DOI 10.1016/j.im.2005.11.005
   Heinrichs JH., 2008, AM J BUSINESS RES AJ, V1, P21
   Hosseini M, 2016, IEEE INT SYM MULTIM, P107, DOI [10.1109/ISM.2016.45, 10.1109/ISM.2016.0028]
   Hsieh JJPA, 2008, MIS QUART, V32, P97
   Hsu MH, 2004, DECIS SUPPORT SYST, V38, P369, DOI 10.1016/j.dss.2003.08.001
   Hua N, 2016, INT J CONTEMP HOSP M, V28, P2052, DOI 10.1108/IJCHM-05-2015-0247
   Insights, 2019, VIRT REAL STAT
   Islam M., 2013, YANG S B RES IDENTIF, P39
   Jacob C, 2010, INT J TOUR RES, V12, P303, DOI 10.1002/jtr.773
   Jalil NAA, 2015, PROC ECON FINANC, V37, P538, DOI 10.1016/S2212-5671(16)30162-9
   Jang YT, 2015, MULTIMED TOOLS APPL, V74, P159, DOI 10.1007/s11042-013-1430-z
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jung Timothy., 2016, INFORM COMMUNICATION, P621, DOI [DOI 10.1007/978-3-319-28231-2_45, 10.1007/978-3-319-28231-245, DOI 10.1007/978-3-319-28231-245]
   Kalinauskas M., 2014, Social Technologies, P62, DOI DOI 10.13165/ST-14-4-1-05
   Ketchen DJ, 2013, LONG RANGE PLANN, V46, P184, DOI 10.1016/j.lrp.2013.01.002
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Kim YJ, 2014, COMPUT HUM BEHAV, V33, P256, DOI 10.1016/j.chb.2014.01.015
   Klook, 2019, KLOOK TRAV ACT TOURS
   Larcker D.F., 1980, DECISION SCI, V11, P121, DOI DOI 10.1111/J.1540-5915.1980.TB01130.X
   조방현, 2004, [Korean Journal of Sport Studies, 한국체육학회지], V43, P179
   Lee WJ, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020806
   Legris P, 2003, INFORM MANAGE-AMSTER, V40, P191, DOI 10.1016/S0378-7206(01)00143-4
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Li JY, 2015, ASIA PAC J TOUR RES, V20, P1451, DOI 10.1080/10941665.2014.998249
   Lim J, 2018, COMPUT HUM BEHAV, V85, P360, DOI 10.1016/j.chb.2018.04.024
   Lim KH, 2000, MIS QUART, V24, P449, DOI 10.2307/3250969
   Lin TTC, 2016, INT J MOB COMMUN, V14, P99, DOI 10.1504/IJMC.2016.075019
   Liu SH, 2009, COMPUT EDUC, V52, P599, DOI 10.1016/j.compedu.2008.11.002
   Liu YP, 2009, J ADVERTISING, V38, P53, DOI 10.2753/JOA0091-3367380204
   Lohtia R, 2003, J ADVERTISING RES, V43, P410, DOI 10.1017/S0021849903030459
   Ltifi M, 2018, MANAGE DECIS, V56, P2291, DOI 10.1108/MD-09-2017-0869
   Maity M, 2018, J BUS RES, V87, P36, DOI 10.1016/j.jbusres.2018.02.003
   Martel E., 2015, MULDNER K DIVING HEA
   McMillan SJ, 2002, J ADVERTISING, V31, P29, DOI 10.1080/00913367.2002.10673674
   McQuail D., 1987, Mass communication theory: An introduction
   MITCHELL AA, 1981, J MARKETING RES, V18, P318, DOI 10.2307/3150973
   Mütterlein J, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P1407
   Murray D., 2002, Sport Management Review, V5, P25, DOI 10.1016/S1441-3523(02)70060-0
   Novak TP, 2000, MARKET SCI, V19, P22, DOI 10.1287/mksc.19.1.22.15184
   OLIVER RL, 1980, J MARKETING RES, V17, P460, DOI 10.2307/3150499
   PARASURAMAN A, 1988, J RETAILING, V64, P12
   Patterson PG, 1997, INT J SERV IND MANAG, V8, P414, DOI 10.1108/09564239710189835
   Payne AF, 2008, J ACAD MARKET SCI, V36, P83, DOI 10.1007/s11747-007-0070-0
   Petrick J. F., 2002, Journal of Travel Research, V41, P38
   Rafaeli S., 1988, ADV COMMUNICATION SC, P110
   RAHI S, 2019, INT J INF LEARN TECH
   Riedl MO, 2008, International Transactions on Systems Science and Applications, V4, P23
   Ringle CM, 2012, MIS QUART, V36, pIII
   Saarijärvi H, 2013, EUR BUS REV, V25, P6, DOI 10.1108/09555341311287718
   Saeed KA, 2008, INFORM MANAGE-AMSTER, V45, P376, DOI 10.1016/j.im.2008.06.002
   Saeed Nauman, 2009, Advanced Learning, P233
   Scharl A, 2005, ELECTRON COMMER R A, V4, P159, DOI 10.1016/j.elerap.2004.10.006
   Schierz PG, 2010, ELECTRON COMMER R A, V9, P209, DOI 10.1016/j.elerap.2009.07.005
   Shavitt S, 1998, J ADVERTISING RES, V38, P7
   Sigala M, 2017, CURR ISSUES TOUR, V20, P346, DOI 10.1080/13683500.2014.982522
   Skadberg Y. X., 2004, Information Technology and Tourism, V7, P147
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sweeney JC, 2001, J RETAILING, V77, P203, DOI 10.1016/S0022-4359(01)00041-0
   Tenenhaus M, 2005, COMPUT STAT DATA AN, V48, P159, DOI 10.1016/j.csda.2004.03.005
   Teo HH, 2003, INT J HUM-COMPUT ST, V58, P281, DOI 10.1016/S1071-5819(03)00008-9
   Unity Technologies, 2020, Unity real-time development platform
   Vatanparast R., 2007, INT J MOBIL MARKETIN, V2, P21
   WEBSTER J, 1993, COMPUT HUM BEHAV, V9, P411, DOI 10.1016/0747-5632(93)90032-N
   Weibel D, 2008, COMPUT HUM BEHAV, V24, P2274, DOI 10.1016/j.chb.2007.11.002
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   World Travel & Tourism Council (WTTC), 2018, Travel and tourism economic impact Cameroon
   Wu LW, 2019, J RETAIL CONSUM SERV, V49, P253, DOI 10.1016/j.jretconser.2019.04.003
   Wu SI, 2008, TOURISM MANAGE, V29, P221, DOI 10.1016/j.tourman.2007.03.020
   Xu DJJ, 2006, J COMPUT INFORM SYST, V47, P9
   Yoo WS, 2010, J RETAIL CONSUM SERV, V17, P89, DOI 10.1016/j.jretconser.2009.10.003
   ZEITHAML VA, 1985, J MARKETING, V49, P33, DOI 10.2307/1251563
   Zhu GX, 2019, ELECTRON COMMER R A, V38, DOI 10.1016/j.elerap.2019.100887
NR 113
TC 14
Z9 14
U1 11
U2 115
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29339
EP 29365
DI 10.1007/s11042-021-11149-8
EA JUN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000665677500001
PM 34188604
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Yao, RZ
   Du, SY
   Wan, T
   Cui, WT
   Yang, Y
   Jing, Y
   Li, C
AF Yao, Runzhao
   Du, Shaoyi
   Wan, Teng
   Cui, Wenting
   Yang, Yang
   Jing, Yang
   Li, Ce
TI Robust registration algorithm based on rational quadratic kernel for
   point sets with outliers and noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rigid registration; Iterative closest point; Rational quadratic kernel;
   Outliers and noise
AB This paper proposes a new rigid registration algorithm based on the rational quadratic kernel to align point sets with outliers and noise. First of all, the multi-source point sets may contain a lot of outliers and noise and the traditional registration algorithm cannot handle the outliers and noise efficiently, this paper introduces the rational quadratic kernel to the rigid registration problem, which can resist outliers and suppress noise to improve the registration accuracy. Secondly, based on the new registration model, we present an iterative closest point (ICP) algorithm and use Lagrange multiplier and the singular value decomposition (SVD) to compute the rigid transformation. Moreover, the effect of the parameter is discussed detailly and a useful parameter control method is introduced to increase the accuracy and robustness of registration. A series of experiments on simulations and real data demonstrate that the proposed algorithm is more precise and robust than other algorithms.
C1 [Yao, Runzhao; Du, Shaoyi; Wan, Teng; Cui, Wenting] Xi An Jiao Tong Univ, Coll Artificial Intelligence, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
   [Yang, Yang; Jing, Yang] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
   [Li, Ce] Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Gansu, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University; Lanzhou University
   of Technology
RP Du, SY (corresponding author), Xi An Jiao Tong Univ, Coll Artificial Intelligence, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
EM dushaoyi@gmail.com
RI jing, yang/JDV-8487-2023; Yao, Runzhao/KBR-3537-2024
OI Du, Shaoyi/0000-0002-7092-0596
FU National Natural Science Foundation of China [61971343, 61627811,
   61866022]; Fundamental Research Funds for the Central Universities
FX This work is supported by the National Natural Science Foundation of
   China under Grant Nos. 61971343, 61627811 and 61866022, and the
   Fundamental Research Funds for the Central Universities under Grant No.
   xzy022020052.
CR Ahmed SM, 2019, COMPUT VIS IMAGE UND, V183, P20, DOI 10.1016/j.cviu.2019.03.008
   Alliez P, 2002, ACM T GRAPHIC, V21, P347, DOI 10.1145/566570.566588
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Balakrishnan G, 2019, IEEE T MED IMAGING, V38, P1788, DOI 10.1109/TMI.2019.2897538
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Ding L, 2019, PROC CVPR IEEE, P8642, DOI 10.1109/CVPR.2019.00885
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Du SY, 2020, PATTERN RECOGN LETT, V132, P91, DOI 10.1016/j.patrec.2018.06.028
   Du SY, 2015, NEUROCOMPUTING, V157, P187, DOI 10.1016/j.neucom.2015.01.019
   Dym N, 2019, IEEE I CONF COMP VIS, P1628, DOI 10.1109/ICCV.2019.00171
   Ferrante E, 2017, MED IMAGE ANAL, V39, P101, DOI 10.1016/j.media.2017.04.010
   Fiocco M, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P47, DOI 10.1109/3DIM.2005.60
   Genton MG, 2002, J MACH LEARN RES, V2, P299, DOI 10.1162/15324430260185646
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Jian B, 2005, IEEE I CONF COMP VIS, P1246
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Kalman D., 1996, Coll. Math. J, V27, P2, DOI [DOI 10.1080/07468342.1996.11973744, 10.1080/07468342.1996.11973744]
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lu WX, 2019, IEEE I CONF COMP VIS, P12, DOI 10.1109/ICCV.2019.00010
   Ma JY, 2018, IEEE T GEOSCI REMOTE, V56, P4435, DOI 10.1109/TGRS.2018.2820040
   Ma WP, 2017, IEEE GEOSCI REMOTE S, V14, P3, DOI 10.1109/LGRS.2016.2600858
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nüchter A, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P419
   Pais GD, 2020, PROC CVPR IEEE, P7191, DOI 10.1109/CVPR42600.2020.00722
   Phillips JM, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427
   Ren MJ, 2017, IEEE T INSTRUM MEAS, V66, P414, DOI 10.1109/TIM.2016.2636538
   Sun J, 2020, IEEE T IND ELECTRON, V67, P10931, DOI 10.1109/TIE.2019.2962433
   Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558
   Vapnik, 2000, NATURE STAT LEARNING, DOI [DOI 10.1007/978-1-4757-3264-1, 10.1080/00401706.1996.10484565, DOI 10.1080/00401706.1996.10484565]
   Vapnik VN., 1999, TECHNOMETRICS, V41, P371
   Vongkulbhisal J, 2018, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2018.00316
   Wan T, 2022, IEEE T NEUR NET LEAR, V33, P3547, DOI 10.1109/TNNLS.2021.3053274
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yang H, 2019, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2019.00175
   Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184
   Yang Y, 2020, IEEE SYST J, V14, P852, DOI [10.1007/s13198-019-00887-6, 10.1109/JSYST.2019.2900336]
   Ye YX, 2017, IEEE T GEOSCI REMOTE, V55, P2941, DOI 10.1109/TGRS.2017.2656380
   Zhang X, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1187, DOI 10.1109/ROBIO.2013.6739625
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
   Zi Jian Yew, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11821, DOI 10.1109/CVPR42600.2020.01184
NR 43
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27925
EP 27945
DI 10.1007/s11042-021-10851-x
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655178700001
DA 2024-07-18
ER

PT J
AU Wang, FS
   Wang, C
   Yin, SS
   He, JJ
   Sun, FM
   Zhang, JX
AF Wang, Fasheng
   Wang, Chang
   Yin, Shuangshuang
   He, Jianjun
   Sun, Fuming
   Zhang, Junxing
TI AMTSet: a benchmark for abrupt motion tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Abrupt motion; Benchmark; Dataset
ID VISUAL TRACKING; CORRELATION FILTER; OBJECT TRACKING
AB Since the OTB100 benchmark dataset is released, it has been widely used in a large number of researches on object tracking for performance evaluation. However, the existing datasets are insufficient to evaluate trackers in handling different challenging factors. In this paper, we present the first dataset and benchmark for tracking objects with abrupt motion (AMTSet). The dataset consists of 50 videos of special scenes from our real life, such as camera switching, sudden dynamic change, low frame rate video, etc., which are quite challenging in object tracking. Boundary boxes over 10K frames are marked manually, and all of them are manually labelled for common attributes of object tracking, such as scale variation, illumination variation, occlusion, motion blur, etc. We benchmark the dataset on 36 representative trackers and rank them according to the tracking conditions and results. Furthermore, we propose an evaluation measure for object tracking to better highlight the performances of the trackers against abrupt motion. Our goal is to supplement the existing baseline datasets and provide researchers with more perfect baseline data in order to better evaluate the performance of different trackers.
C1 [Wang, Fasheng; Wang, Chang; Yin, Shuangshuang; He, Jianjun; Sun, Fuming; Zhang, Junxing] Dalian Minzu Univ, Sch Informat & Commun Engn, Dalian, Peoples R China.
C3 Dalian Minzu University
RP Sun, FM (corresponding author), Dalian Minzu Univ, Sch Informat & Commun Engn, Dalian, Peoples R China.
EM sunfuming@dlnu.edu.cn
RI Sun, Fuming/HGT-8610-2022; Sun, Fuming/HKN-9901-2023; Zhang,
   Junxing/AAS-1002-2020
OI Zhang, Junxing/0000-0003-4176-0914
FU National Natural Science Foundation of China [61972068, 61976042];
   Liaoning Baiqianwan Talent Program, Dalian Science Foundation for Young
   Scholars [2017RQ151]; Innovative Talents Project of Liaoning
   Universities [LR2019020]
FX This work was supported by National Natural Science Foundation of China
   (No. 61972068, 61976042), Liaoning Baiqianwan Talent Program, Dalian
   Science Foundation for Young Scholars (No. 2017RQ151), Innovative
   Talents Project of Liaoning Universities (No. LR2019020).
CR [Anonymous], 2005, P IEEE INT WORKSHOP
   [Anonymous], 2017, P IEEE INT C COMP VI
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Feng W, 2019, IEEE T IMAGE PROCESS, V28, P3232, DOI 10.1109/TIP.2019.2895411
   Fu CH, 2020, IEEE T GEOSCI REMOTE, V58, P8940, DOI 10.1109/TGRS.2020.2992301
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Gupta M, 2017, IEEE T SYST MAN CY-S, V47, P1415, DOI 10.1109/TSMC.2016.2616343
   Hadfield S., 2014, EUR C COMP VIS ECCV, P777
   Han R.Z., 2018, Proceedings of the 2018 IEEE International Symposium on Circuits and Systems (ISCAS), P1
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques J, 2012, LNCS, P702, DOI DOI 10.1007/978-3-642-33765-9_50
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2020, IEEE T IMAGE PROCESS, V29, P7045, DOI 10.1109/TIP.2020.2997521
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lin ZH, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2019), P765, DOI 10.1109/ICMCCE48743.2019.00176
   Liu JC, 2013, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2013.239
   Lu H., 2019, ONLINE VISUAL TRACKI, DOI [10.1007/978-981-13-0469-9, DOI 10.1007/978-981-13-0469-9]
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6
   Pan SW, 2015, SENSORS-BASEL, V15, P8232, DOI 10.3390/s150408232
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Shreesha S., 2020, 2020 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER), P252, DOI 10.1109/DISCOVER50404.2020.9278101
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Wang N, 2013, P ADV NEURAL INFORM
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Zhang S, 2015, IEEE SENS J, V15, P2679, DOI 10.1109/JSEN.2014.2382174
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
   Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180
NR 64
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4711
EP 4734
DI 10.1007/s11042-021-10947-4
EA MAY 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000650816400005
DA 2024-07-18
ER

PT J
AU Ponmani, E
   Saravanan, P
AF Ponmani, E.
   Saravanan, P.
TI Image denoising and despeckling methods for SAR images to improve image
   enhancement performance: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SAR images; Despeckling; Filters; Transforms; Deep learning
ID BAYESIAN WAVELET SHRINKAGE; SPECKLE REDUCTION; VARIATIONAL MODEL;
   ADAPTIVE THRESHOLD; EDGE-DETECTION; TRANSFORM; REMOVAL; FILTER;
   ALGORITHM; DOMAIN
AB The synthetic aperture radar (SAR) images are playing an essential role in remote sensing. Various types of internal, external, and environmental noise are affecting the SAR images. Coherent speckle noise is the primary source of noise in SAR images. Such noise can be removed by using a single filter or combination of filters and transform signals. SAR image denoising has been attracting the attention of researchers for the past three decades. The target area and application type are influencing the choice of denoising method. In this paper, the basics of SAR imaging, steps in the pipeline of SAR despeckling process, filters like Lee filter, Frost filter, Kuan Filter and Gamma Maximum a posteriori (MAP) filter, various state of the art despeckling methods and deep learning approaches for SAR despeckling are discussed. Five transforms for despeckling are discussed with literature. The data sets from different radars, the applications, area of importance, and the quality metrics used to evaluate the despeckling quality are discussed in detail that has been available in the literature of the past two decades.
C1 [Ponmani, E.; Saravanan, P.] Sastra Deemed Univ, Sch Comp, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Ponmani, E (corresponding author), Sastra Deemed Univ, Sch Comp, Thanjavur, India.
EM ponmanie@gmail.com
OI Palani, Saravanan/0000-0002-3679-2113
CR Aiazzi B, 1998, IEEE T GEOSCI REMOTE, V36, P1466, DOI 10.1109/36.718850
   Amirmazlaghani M, 2012, IEEE T GEOSCI REMOTE, V50, P5024, DOI 10.1109/TGRS.2012.2195321
   Argenti F, 2002, IEEE T GEOSCI REMOTE, V40, P2363, DOI 10.1109/TGRS.2002.805083
   Argenti F, 2012, IEEE GEOSCI REMOTE S, V9, P13, DOI 10.1109/LGRS.2011.2158798
   Bamler R, 2000, SURV GEOPHYS, V21, P147, DOI 10.1023/A:1006790026612
   Bhateja V, 2015, MEASUREMENT, V74, P246, DOI 10.1016/j.measurement.2015.07.024
   Bhuiyan MIH, 2007, IEEE T CIRC SYST VID, V17, P500, DOI 10.1109/TCSVT.2006.888020
   Borran MJ, 2001, INT CONF ACOUST SPEE, P3925, DOI 10.1109/ICASSP.2001.940702
   Chierchia G, 2017, INT GEOSCI REMOTE SE, P5438, DOI 10.1109/IGARSS.2017.8128234
   Cozzolino D., 2019, IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium. Proceedings, P5117, DOI 10.1109/IGARSS.2019.8897761
   Cozzolino D, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12061006
   Dai M, 2004, IEEE T GEOSCI REMOTE, V42, P1642, DOI 10.1109/TGRS.2004.831231
   Damseh RR, 2016, IEEE INT SYMP CIRC S, P1002, DOI 10.1109/ISCAS.2016.7527412
   Deledalle CA, 2017, IEEE T IMAGE PROCESS, V26, P4389, DOI 10.1109/TIP.2017.2713946
   Deshmukh PR, 2011, REDUCTION SPECKLE NO
   Di Martino G, 2016, IEEE J-STARS, V9, P2131, DOI 10.1109/JSTARS.2016.2543303
   Di Martino G, 2014, IEEE T GEOSCI REMOTE, V52, P1596, DOI 10.1109/TGRS.2013.2252907
   Dong Y, 2001, IEEE T GEOSCI REMOTE, V39, P851, DOI 10.1109/36.917910
   Farhangi N, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0244-3
   Ferraioli G, 2019, JOINT URB REMOTE SEN, DOI 10.1109/jurse.2019.8809042
   Ferreira AD, 2000, INT GEOSCI REMOTE SE, P642, DOI 10.1109/IGARSS.2000.861657
   Forte A., 1988, Conference Proceedings. 18th European Microwave Conference 88, P699
   Foucher S, 2001, IEEE T IMAGE PROCESS, V10, P49, DOI 10.1109/83.892442
   Foucher S., 2008, IGARSS 2008 2008 IEE, V1
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gao F, 2016, IEEE T GEOSCI REMOTE, V54, P3025, DOI 10.1109/TGRS.2015.2510161
   Gao F, 2016, CHINESE J ELECTRON, V25, P100, DOI 10.1049/cje.2016.01.016
   Gleich D, 2009, IEEE T IMAGE PROCESS, V18, P2167, DOI 10.1109/TIP.2009.2023729
   Gragnaniello D, 2015, INT GEOSCI REMOTE SE, P2378, DOI 10.1109/IGARSS.2015.7326287
   Guan J, 2019, BLIND SAR IMAGE DESP
   Gui YC, 2018, REMOTE SENS LETT, V9, P857, DOI 10.1080/2150704X.2018.1492170
   GUO H, 1994, IEEE IMAGE PROC, P75, DOI 10.1109/ICIP.1994.413278
   Hazarika D, 2016, PROCEDIA COMPUT SCI, V87, P148, DOI 10.1016/j.procs.2016.05.141
   Hazarika D, 2016, PROCEDIA COMPUT SCI, V87, P140, DOI 10.1016/j.procs.2016.05.140
   Holbek-Hanssen E, 1989, 12 CAN S REM SENS GE, V2, P755
   Ji J, 2016, CHINESE J ELECTRON, V25, P786, DOI 10.1049/cje.2016.06.040
   Jidesh P, 2018, COMPUT ELECTR ENG, V70, P631, DOI 10.1016/j.compeleceng.2017.09.013
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Lam E, 2018, SPECKLE SUPPRESSION
   LEE JS, 1981, COMPUT VISION GRAPH, V15, P380, DOI 10.1016/S0146-664X(81)80018-4
   Li HC, 2013, IEEE T GEOSCI REMOTE, V51, P2388, DOI 10.1109/TGRS.2012.2211366
   Li JY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242921
   Li Y, 2011, IEEE T GEOSCI REMOTE, V49, P3105, DOI 10.1109/TGRS.2011.2121072
   Liu J, 2016, NEUROCOMPUTING, V216, P502, DOI 10.1016/j.neucom.2016.07.049
   Liu SQ, 2017, IEEE T GEOSCI REMOTE, V55, P2985, DOI 10.1109/TGRS.2017.2657602
   Liu SQ, 2016, LECT NOTES ELECTR EN, V386, P221, DOI 10.1007/978-3-662-49831-6_23
   Ma XS, 2020, IEEE T GEOSCI REMOTE, V58, P8807, DOI 10.1109/TGRS.2020.2990978
   Mancini P, 1989, IEE C SYNTH AP RAD
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Molina DE, 2010, IEEE GEOSCI REMOTE S, V7, P73, DOI 10.1109/LGRS.2009.2020698
   Moussa O, 2018, COMPUT AIDED GEOM D, V67, P34, DOI 10.1016/j.cagd.2018.09.005
   MuraliMohanBabu Y, 2015, PROCEDIA COMPUT SCI, V70, P69, DOI 10.1016/j.procs.2015.10.038
   Nasri M, 2009, NEUROCOMPUTING, V72, P1012, DOI 10.1016/j.neucom.2008.04.016
   Nie XL, 2017, DIGIT SIGNAL PROCESS, V68, P44, DOI 10.1016/j.dsp.2017.05.008
   Nie XL, 2016, IEEE T IMAGE PROCESS, V25, P2620, DOI 10.1109/TIP.2016.2552402
   Ojha C, 2015, INT GEOSCI REMOTE SE, P2461, DOI 10.1109/IGARSS.2015.7326308
   Ozcan C, 2016, IEEE GEOSCI REMOTE S, V13, P115, DOI 10.1109/LGRS.2015.2499445
   Qiu F., 2004, Giscience & Remote Sensing, V41, P244, DOI DOI 10.2747/1548-1603.41.3.244
   Rajan J, 2006, LECT NOTES COMPUT SC, V4338, P184
   Ranjani JJ, 2011, IEEE GEOSCI REMOTE S, V8, P552, DOI 10.1109/LGRS.2010.2089780
   Ranjani JJ, 2010, IEEE T GEOSCI REMOTE, V48, P2723, DOI 10.1109/TGRS.2010.2041241
   Sameen MI, 2016, INT J REMOTE SENS, V37, P2358, DOI 10.1080/01431161.2016.1176273
   Simonyan K., 2014, 14091556 ARXIV
   Singh P, 2018, ENG SCI TECHNOL, V21, P589, DOI 10.1016/j.jestch.2018.05.009
   Sivaranjani R, 2019, APPL SOFT COMPUT, V76, P671, DOI 10.1016/j.asoc.2018.12.030
   Solbo S, 2004, IEEE T GEOSCI REMOTE, V42, P711, DOI 10.1109/TGRS.2003.821885
   Solbo S, 2004, INT J REMOTE SENS, V25, P1019, DOI 10.1080/0143116031000150040
   Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5
   Subrahmanyam GRKS, 2008, IEEE T IMAGE PROCESS, V17, P1969, DOI 10.1109/TIP.2008.2002160
   Sveinsson JR, 2003, IEEE T GEOSCI REMOTE, V41, P2404, DOI 10.1109/TGRS.2003.817844
   Swamy PMS, 2016, OPTIK, V127, P634, DOI 10.1016/j.ijleo.2015.10.057
   Tabassum N, 2018, DIGIT SIGNAL PROCESS, V74, P43, DOI 10.1016/j.dsp.2017.11.013
   Tang X, 2019, INT J DIGIT EARTH, V12, P354, DOI 10.1080/17538947.2018.1447032
   Tupin F, 2020, SAR2SAR SELF SUPERVI
   Vishwakarma A., 2015, INT J SCI RES, V4, P415
   Vitale S, 2021, IEEE T GEOSCI REMOTE, V59, P9336, DOI 10.1109/TGRS.2020.3034852
   Vitale S, 2019, INT GEOSCI REMOTE SE, P9494, DOI [10.1109/IGARSS.2019.8899245, 10.1109/igarss.2019.8899245]
   Wang J, 2018, SAR IMAGE DESPECKLIN, P81
   Wang P., 2017, 2017 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2017.8007930
   Woo H, 2016, IEEE SIGNAL PROC LET, V23, P1557, DOI 10.1109/LSP.2016.2605818
   Wu Y, 2019, PRACTICAL SOLUTION S
   Xia HT, 2018, OPT LASER ENG, V107, P71, DOI 10.1016/j.optlaseng.2018.03.014
   Xie H, 2002, IEEE T GEOSCI REMOTE, V40, P2196, DOI 10.1109/TGRS.2002.802473
   Xie H, 2002, INT GEOSCI REMOTE SE, P321, DOI 10.1109/IGARSS.2002.1025027
   Xu LL, 2014, IEEE T GEOSCI REMOTE, V52, P6858, DOI 10.1109/TGRS.2014.2304298
   Xu ZH, 2018, DIGIT SIGNAL PROCESS, V73, P72, DOI 10.1016/j.dsp.2017.10.017
   Yang W, 2019, JOINT URB REMOTE SEN, P1
   Yun S, 2012, IEEE T IMAGE PROCESS, V21, P2523, DOI 10.1109/TIP.2012.2185942
   Zhang J, 2020, IEEE GEOSCI REMOTE S, V17, P1363, DOI 10.1109/LGRS.2019.2943961
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang Q, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020196
NR 91
TC 11
Z9 11
U1 3
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26547
EP 26569
DI 10.1007/s11042-021-10871-7
EA MAY 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000647348900001
DA 2024-07-18
ER

PT J
AU Aziz, ZFR
   Bhatti, NEE
   Mahmood, HS
   Zia, MHM
AF Aziz, Zafar
   Bhatti, Naeem
   Mahmood, Hasan
   Zia, Muhammad
TI Video anomaly detection and localization based on appearance and motion
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Anomaly localization; Motion model; Appearance model
ID ABNORMAL EVENT DETECTION; SWARM INTELLIGENCE
AB In this paper, we present an approach to detect and localize anomalies in the surveillance videos. Precise detection, modeling the normality in a context and dealing with false alarms are the major challenges to cope with while performing detection and localization of anomalies. We propose appearance and motion models to detect an anomalous event at the frame level in a video. In the anomalous frames, we localize the anomaly using appearance and connected component analysis cues. The proposed appearance model utilizes the mask-rcnn for scene semantic analysis. The proposed motion model constructs frame descriptors based on the histograms of the intensity difference maps of the consecutive video frames. A one class support vector machine (OCSVM) is used to detect motion based anomalous event. In order to eliminate the false alarms of anomaly detection and localization emerging due to camera jitter and object movements in unlikely motion regions of a video frame, we exploit the connected component analysis. Experiments on the Avenue and UMN datasets reveal that the proposed approach achieves high accuracy and outperforms the existing methods.
C1 [Aziz, Zafar; Bhatti, Naeem; Mahmood, Hasan; Zia, Muhammad] Quaid I Azam Univ, Dept Elect, Islamabad 45320, Pakistan.
C3 Quaid I Azam University
RP Bhatti, NEE (corresponding author), Quaid I Azam Univ, Dept Elect, Islamabad 45320, Pakistan.
EM nbhatti@qau.edu.pk
OI Aziz, Zafar/0009-0005-7367-9565
CR Amraee S, 2018, SIGNAL IMAGE VIDEO P, V12, P1115, DOI 10.1007/s11760-018-1267-z
   Anjum N, 2008, IEEE T CIRC SYST VID, V18, P1555, DOI 10.1109/TCSVT.2008.2005603
   [Anonymous], 2015, Anomaly detection in crowded scenes using dense trajectories
   Aydin I, 2015, EXPERT SYST APPL, V42, P938, DOI 10.1016/j.eswa.2014.08.026
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Das D, 2018, INT CONF IND INF SYS, P40
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Devanne M, 2017, PATTERN RECOGN, V61, P222, DOI 10.1016/j.patcog.2016.07.041
   Ding F, 2018, INT J ROBOT AUTOM, V33, P474, DOI 10.2316/Journal.206.2018.5.206-0061
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Gritai A, 2008, 2008 IEEE C COMP VIS, P1
   Gutoski M., 2017, P 13 BRAZ C COMP INT
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hu X, 2016, IET COMPUT VIS, V10, P258, DOI 10.1049/iet-cvi.2015.0271
   Vu H, 2017, LECT NOTES ARTIF INT, V10234, P641, DOI 10.1007/978-3-319-57454-7_50
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Ko T, 2008, IEEE APP IMG PAT, P84
   Li NN, 2015, NEUROCOMPUTING, V155, P309, DOI 10.1016/j.neucom.2014.12.064
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Loy CC, 2011, PATTERN RECOGN, V44, P117, DOI 10.1016/j.patcog.2010.07.023
   Lu C, 2013, AVENUE DATASET AVENU
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Marsden M, 2016, IEEE IMAGE PROC, P918, DOI 10.1109/ICIP.2016.7532491
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Murugan BS, 2019, COMPUT ELECTR ENG, V75, P146, DOI 10.1016/j.compeleceng.2019.02.017
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Qasim T, 2019, PATTERN RECOGN LETT, V128, P220, DOI 10.1016/j.patrec.2019.09.003
   Ravanbakhsh M, 2019, IEEE WINT CONF APPL, P1896, DOI 10.1109/WACV.2019.00206
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Sebe N, 2015, COMPUT VIS IMAGE UND, DOI DOI 10.1016/J.CVIU.2016.10.010
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Srinivasan A, 2019, MULTIMED TOOLS APPL, V78, P7713, DOI 10.1007/s11042-018-6348-z
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tran Hanh, 2017, P BRIT MACH VIS C
   Ullah H, 2018, NEUROCOMPUTING, V290, P74, DOI 10.1016/j.neucom.2018.02.045
   Wang J, 2016, COMPUT VIS IMAGE UND, V144, P177, DOI 10.1016/j.cviu.2015.08.010
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhou Joey Tianyi, 2019, IEEE T INFORM FORENS
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
NR 47
TC 5
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25875
EP 25895
DI 10.1007/s11042-021-10921-0
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000643186000002
DA 2024-07-18
ER

PT J
AU Liu, JL
   Zhang, M
   Tong, XJ
   Wang, Z
AF Liu, JinLong
   Zhang, Miao
   Tong, Xiaojun
   Wang, Zhu
TI Image compression and encryption algorithm based on compressive sensing
   and nonlinear diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Compressive sensing; Image compression and encryption
AB Compressive sensing is widely used to image compression and encryption algorithms due to its high efficiency, but the existing algorithms have some flaws and insufficiency such as low reconstruction quality, small key space and weak security. Therefore, in this paper, a novel 5D chaotic system is proposed, which has larger key space and more complex key stream. According to the proposed 5D chaotic system, an image compression and encryption algorithm based on compressive sensing and nonlinear diffusion is proposed. In addition, in order to improve the image reconstruction quality of compressive sensing, an algorithm is proposed in this paper to optimize the measurement matrix of compressive sensing. Theoretical analysis shows that the proposed 5D chaotic system is chaotic and it shows many superior properties. The algorithm proposed to optimize the measurement matrix is also proved effective for reconstruction quality. The simulation results show that our algorithm has advantages in compression performance, key sensitivity, key space and time complexity, and it can also resist statistical attack and other common attacks.
C1 [Liu, JinLong; Zhang, Miao; Tong, Xiaojun; Wang, Zhu] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai, Peoples R China.
C3 Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai, Peoples R China.
EM tong_xiaojun@163.com
FU National Natural Science Foundation of China [61902091]; Shandong
   Provincial Natural Science Foundation [ZR2019MF054]; Fundamental
   Research Funds for the Central Universities [HIT.NSRIF.2020099];
   Foundation of Science and Technology on Information Assurance Laboratory
   [KJ-17-004]; Foundation of China Academy of Space Technology, Weihai
   University [WT-TXYY/ WLZDFHJY003]
FX This work was supported by the following projects and foundations: the
   National Natural Science Foundation of China (No.61902091), project
   ZR2019MF054 supported by Shandong Provincial Natural Science Foundation
   and the Fundamental Research Funds for the Central Universities
   (HIT.NSRIF.2020099), the Foundation of Science and Technology on
   Information Assurance Laboratory (No.KJ-17-004), Equip Pre-research
   Projects of 2018 supported by Foundation of China Academy of Space
   Technology (No. WT-TXYY/ WLZDFHJY003), 2017 Weihai University
   Co-construction Project.
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA., 2014, STEGO QUALITY ENHANC
   Anees A, 2014, COMMUN NONLINEAR SCI, V19, P3106, DOI 10.1016/j.cnsns.2014.02.011
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen ZQ, 2008, CHAOS SOLITON FRACT, V38, P1187, DOI 10.1016/j.chaos.2007.01.058
   Gan HP, 2018, SIGNAL PROCESS-IMAGE, V68, P129, DOI 10.1016/j.image.2018.06.004
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Kumar A, 2014, INT J RECENT DEV ENG, V2
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Song YJ, 2019, NONLINEAR DYNAM, V95, P2235, DOI 10.1007/s11071-018-4689-9
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Zeng L, 2015, CIRC SYST SIGNAL PR, V34, P797, DOI 10.1007/s00034-014-9873-7
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu SQ, 2019, MULTIMED TOOLS APPL, V78, P20855, DOI 10.1007/s11042-019-7405-y
NR 33
TC 27
Z9 28
U1 10
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25433
EP 25452
DI 10.1007/s11042-021-10884-2
EA APR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640862600003
DA 2024-07-18
ER

PT J
AU Pal, S
   Pramanik, PKD
   Choudhury, P
AF Pal, Saurabh
   Pramanik, Pijush Kanti Dutta
   Choudhury, Prasenjit
TI Enhanced metadata modelling and extraction methods to acquire contextual
   pedagogical information from e-learning contents for personalised
   learning systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-learning; Educational metadata; IEEE LOM; Online learning; Educational
   recommendation system; Java ontology; Contextual learning; Learning
   difficulty; Learning time; Interactivity
AB To make online learning systems (OLSs) effective, it is important to make sure that the learners get the learning objects (LOs) according to their pedagogical suitability and requirements. To assess the suitability of an LO, sufficient information of it is required to be available. These information can be specified as metadata of the document. But there is a dearth of metadata defined for educational documents. Existing standard metadata models like IEEE LOM and others are promising but lack in capturing some crucial learning and pedagogical aspects of LOs. In this paper, we propose a new metadata model that has extended the IEEE LOM to provide an extensive set of metadata for LOs. The proposed metadata seem adequate to describe the contextual learning and pedagogical information of any text and web document based LO. But only specifying the metadata is not sufficient; they need to be extracted from a learning content automatically so that these information can be used by the learners and the OLSs and the educational recommendation systems. Automated extraction of metadata from e-learning contents is a non-trivial task. In view of that, we have provided extraction mechanisms for each of the specified metadata, separately. The experimental results show that the proposed extraction methods are quite accurate in identifying and retrieving the different educational metadata. The statistical inferences of the automated and manual extractions are found to have substantial similarities for each of the extracted metadata element.
C1 [Pal, Saurabh; Pramanik, Pijush Kanti Dutta; Choudhury, Prasenjit] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Pramanik, PKD (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
EM pijushjld@yahoo.co.in
RI Choudhury, Prasenjit/AAV-1942-2020; Choudhury, Prasenjit/ABD-1141-2021;
   Dutta Pramanik, Pijush Kanti/N-8941-2018; Pal, Saurabh/AAZ-7650-2021
OI Choudhury, Prasenjit/0000-0001-6687-3056; Dutta Pramanik, Pijush
   Kanti/0000-0001-9438-9309; Pal, Saurabh/0000-0002-9053-4617
CR Anderson L. W., 2001, A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives
   Aoki K, 2000, TAXONOMY INTERACTIVI
   Dey A. K., 2020, CATA, P264, DOI [10.29007/fn7b, DOI 10.29007/FN7B]
   EF Education First (, 2020, 3000 MOST COMMON WOR
   Flesch, 2005, WRITE PLAIN ENGLISH, DOI [DOI 12094308/HTTP://WWW.MANG.CANTERBURY.AC.NZ/WRITING_GUIDE/WRITING/FLESCH.SHTML, 12094308/http://www.mang.canterbury.ac.nz/writing_guide/writing/flesch.shtml]
   Flynn P, 2007, LECT NOTES COMPUT SC, V4822, P327
   IEEE Computer Society, 2002, 1484121 IEEE STANDAR
   IEEE Computer Society, 2002, IEEE STD 1484121 200
   Jebali B, 2013, P INT C EL ENG SOFTW, P1, DOI DOI 10.1109/ICEESA.2013.6578408
   Jensen J.F., 1998, Nodicom Review, V19, P185
   Kawtrakul A, 2005, P INT ADV DIG LIB C, P1
   Laurel Brenda., 1986, Toward the Design of a Computer-Based Interactive Fantasy System
   Laurel Brenda., 2013, Computers as Theatre, VSecond
   Le DN, 2020, FRONTIERS INTELLIGEN
   Marinai Simone, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P251, DOI 10.1109/ICDAR.2009.232
   Mukhopadhyay Moutan, 2020, ICIIT 2020: Proceedings of the 2020 5th International Conference on Intelligent Information Technology, P107, DOI 10.1145/3385209.3385231
   Nam TJ, 2009, INT J INTERACT DES M, V3, P147, DOI 10.1007/s12008-009-0069-5
   Othman N, 2010, PROCD SOC BEHV, V7, P652, DOI 10.1016/j.sbspro.2010.10.088
   Pal Saurabh, 2019, International Journal of Web-Based Learning and Teaching Technologies, V14, P26, DOI 10.4018/IJWLTT.2019100102
   Pal S, 2019, EDUC INF TECHNOL, V24, P3243, DOI 10.1007/s10639-019-09926-y
   Pramanik P. K. D., 2017, P 4 INT C ADV COMP C, P1, DOI DOI 10.1109/ICACCS.2017.8014613
   Pramanik PKD, 2019, IEEE ACCESS, V7, P182113, DOI 10.1109/ACCESS.2019.2958684
   Rafaeli S., 1988, ADV COMMUNICATION SC, P110
   Rogers E.M., 1986, COMMUNICATION TECHNO
   Rouse M., 2014, TechTarget
   Sedig K., 2012, JMPT, V3, P12
   SkillSoft, 2018, EXPERTISE LEVEL
   Steuer J., 1995, Communication in the age of virtual reality
   Xiaoyu Tang, 2010, Proceedings 2010 IEEE 2nd Symposium on Web Society (SWS 2010), P346, DOI 10.1109/SWS.2010.5607427
   Yilmazel O, 2004, ACM-IEEE J CONF DIG, P241, DOI 10.1145/996350.996405
   Youmin Zhang, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1344, DOI 10.1109/FSKD.2012.6234139
NR 31
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25309
EP 25366
DI 10.1007/s11042-020-10380-z
EA APR 2021
PG 58
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640862600006
DA 2024-07-18
ER

PT J
AU Wang, YX
   Li, GJ
   Ma, L
AF Wang, YongXiong
   Li, Guangjun
   Ma, Li
TI A sparse focus framework for visual fine-grained classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained visual recognition; Sparse focus framework; Network
   sparsity; Network pruning
ID ATTENTION; NETWORK
AB The location of discriminative features and reduction of model complexity are the two main research directions in fine-grained image classification. The manual annotation of object is very labor-intensive, and the commonly used model compression methods usually reduce the classification accuracy while compressing the model. In this paper, we propose a Sparse Focus Framework(SFF) based on Bilinear Convolutional Neural Network(BCNN), which includes self-focus module and sparse scaling factors. The focus module like the focus function of human beings automatically locates the object from background without manual labeling, and only a small amount of computing resources are occupied in the guaranteed accuracy. The sparse scaling factor for each channel can evaluate the importance of feature channels, which is adopted in pruning of channels. The large number of parameters and calculations in the fine-grained classification model can been effectively reduced by pruning method adopted in our network, which can obtain a sparse structure to prevent overfitting while maintaining classification performance. Our experimental results show that our model obtains accuracy of 90.2%, 84.5% and 92.0% on FGVC-aircraft, Stanford dogs and Stanford cars, respectively. Compared with the highest classification accuracy obtained by the same classification network B-CNN[D,D], the accuracy gains with 6.1%, 4.1% and 1.4% respectively. Moreover, the channel-level sparsity effectively reduces 30% of the network parameters and nearly 13% of the computation.
C1 [Wang, YongXiong; Li, Guangjun; Ma, Li] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Wang, YX (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
EM wyxiong@usst.edu.cn
RI Yuan, Yu/KBQ-0606-2024
OI Wang, Yongxiong/0000-0002-3242-0857
FU National Natural Science Foundation of China [61673276]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61673276.
CR [Anonymous], 1990, Adv Neural Inform Process Syst.
   Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812
   Chatfield K, 2014, ARXIV 14053531
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Cheng J, 2018, FRONT INFORM TECH EL, V19, P64, DOI 10.1631/FITEE.1700789
   Cheng Z, 2020, MULTIMED TOOLS APPL, V79, P31283, DOI 10.1007/s11042-020-09556-4
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5
   Dubey A, 2018, ADV NEUR IN, V31
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Gao Y, 2020, AAAI CONF ARTIF INTE, V34, P10818
   Garbin C, 2020, MULTIMED TOOLS APPL, V79, P12777, DOI 10.1007/s11042-019-08453-9
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han S, 2015, ADV NEUR IN, V28
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu CF, 2020, IEEE T IND ELECTRON, V67, P10922, DOI 10.1109/TIE.2019.2962437
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang T, 2020, MULTIMED TOOLS APPL
   Khosla A., 2011, P IEEE C COMP VIS PA, V2
   Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li HR, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106593
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu CB, 2020, AAAI CONF ARTIF INTE, V34, P11555
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Luo W, 2020, IEEE SIGNAL PROC LET, V27, P1545, DOI 10.1109/LSP.2020.3020227
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi WW, 2019, IEEE T NEUR NET LEAR, V30, P683, DOI 10.1109/TNNLS.2018.2852721
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun GL, 2020, AAAI CONF ARTIF INTE, V34, P12047
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Vedaldi A., 2013, Technical report
   Wang, 2016, ESANN 2017 P, P589
   Wang WQ, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11081033
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Wen W, 2016, ADV NEUR IN, V29
   Xiao LX, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511399
   Xu ZB, 2010, SCI CHINA INFORM SCI, V53, P1159, DOI 10.1007/s11432-010-0090-0
   Yang YD, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091939
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Zhang GH, 2018, LECT NOTES ARTIF INT, V10956, P134, DOI 10.1007/978-3-319-95957-3_15
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhang SD, 2020, NEUROCOMPUTING, V410, P363, DOI 10.1016/j.neucom.2020.06.041
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhou H, 2016, LECT NOTES COMPUT SC, V9908, P662, DOI 10.1007/978-3-319-46493-0_40
   Zilei, 2016, J IMAGE GRAPH
NR 58
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25271
EP 25289
DI 10.1007/s11042-021-10872-6
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640469900002
DA 2024-07-18
ER

PT J
AU Lin, YH
   Hu, YC
   Chen, WL
   Acharya, B
AF Lin, Yu-Hsiu
   Hu, Yu-Chen
   Chen, Wu-Lin
   Acharya, Biswaranjan
TI Reversible self-verifying and self-recovering technique for color image
   demosaicking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color filter array; Image demosaicking; Tamper detection; Image
   recovery; Block truncation coding; Reversibility preserving
AB This paper develops an integrity protection technique based on image demosaicking. To provide the reversible property, the rebuilt components in color pixels are used for secret data embedding. The random value and the hashed result of the most significant high-order bits of the color components are employed to generate the authentication code for each rebuilt component. In addition, the optimal single bit map block truncation coding (OSBMBTC) technique is adopted for generating recovery codes. A block-based image recovery procedure is designed to reconstruct the modified areas. Experimental results reveal that the illegally tampered objects in the test images can be found in these tests even when 87.5% pixels are modified. From the results, the image quality of the recovery image is acceptable when 50% of pixels are modified. Moreover, the demosaicked image can be reversibly constructed when the embedded image is not tampered.
C1 [Lin, Yu-Hsiu] Natl Taipei Univ Technol, Grad Inst Automat Technol, Taipei 106344, Taiwan.
   [Hu, Yu-Chen; Chen, Wu-Lin] Providence Univ, Dept Comp Sci & Informat Management, 200 Sec 7 Taiwan Blvd, Taichung 43301, Taiwan.
   [Acharya, Biswaranjan] KIIT Deemed Be Univ, Sch Comp Engn, Bhubaneswar, Odisha, India.
C3 National Taipei University of Technology; Providence University -
   Taiwan; Kalinga Institute of Industrial Technology (KIIT)
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200 Sec 7 Taiwan Blvd, Taichung 43301, Taiwan.
EM yhlin@ntut.edu.tw; ychu@pu.edu.tw; wlchen@pu.edu.tw;
   acharyabiswa85@gmail.com
RI Lin, Yu-Hsiu/AAD-8974-2020; Hu, Yu-Chen/AAT-5264-2020; Hui,
   Yu/JOZ-3598-2023; Acharya, Biswaranjan/AAL-1977-2020
OI Hu, Yu-Chen/0000-0002-5055-3645; Acharya,
   Biswaranjan/0000-0002-6506-9207; Lin, Yu-Hsiu/0000-0002-1407-2262
FU Ministry of Science and Technology, Taiwan, R.O.C.
   [106-2410-H-126-006-MY2, 108-2410-H-020-MY2]
FX This research was partially supported by the Ministry of Science and
   Technology, Taiwan, R.O.C. under contracts 106-2410-H-126-006-MY2 and
   108-2410-H-020-MY2.
CR Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Chan CS, 2011, PATTERN RECOGN LETT, V32, P1679, DOI 10.1016/j.patrec.2011.07.023
   Chuang JC, 2020, MULTIMED TOOLS APPL, V79, P28189, DOI 10.1007/s11042-020-09325-3
   Chuang JC, 2013, INT J SECUR APPL, V7, P209, DOI 10.14257/ijsia.2013.7.6.22
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Hong W, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115666
   Hong W, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212802
   Hong W, 2018, MULTIMED TOOLS APPL, V77, P4677, DOI 10.1007/s11042-017-4899-z
   Hong WE, 2017, SIGNAL PROCESS-IMAGE, V58, P111, DOI 10.1016/j.image.2017.07.001
   Hu YC, 2008, IMAGING SCI J, V56, P254, DOI 10.1179/174313108X2995.14
   Hu YC, 2013, OPTO-ELECTRON REV, V21, P137, DOI 10.2478/s11772-013-0078-6
   Hu Y. C., 2014, P 2014 INT C INF TEC
   Hu YC, 2004, J ELECTRON IMAGING, V13, P871, DOI 10.1117/1.1785158
   Hu YC, 2016, FUTURE GENER COMP SY, V62, P92, DOI 10.1016/j.future.2016.04.001
   Hu YC, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.9.093104
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Hua KL, 2016, J VIS COMMUN IMAGE R, V38, P230, DOI 10.1016/j.jvcir.2016.03.004
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Liu, 2018, P 14 INT C INT INF H
   Liu XL, 2017, SMART INNOV SYST TEC, V63, P313, DOI 10.1007/978-3-319-50209-0_38
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Lo CC, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.3.033003
   Menon D, 2011, SIGNAL PROCESS-IMAGE, V26, P518, DOI 10.1016/j.image.2011.04.003
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P503, DOI 10.1109/TCSVT.2003.813422
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Sarkar D, 2020, MULTIMED TOOLS APPL, V79, P17761, DOI 10.1007/s11042-020-08669-0
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Tsou CC, 2008, IMAGING SCI J, V56, P217, DOI 10.1179/174313108X281335
   Wu CM., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P13, DOI [10.14257/ijsip.2014.7.5.02, DOI 10.14257/IJSIP.2014.7.5.02]
   Wu WC, 2016, J VIS COMMUN IMAGE R, V38, P18, DOI 10.1016/j.jvcir.2016.02.005
   Xiang ZY, 2019, MULTIMED TOOLS APPL, V78, P7895, DOI 10.1007/s11042-018-6030-5
   Yao H, 2020, J REAL-TIME IMAGE PR, V17, P41, DOI 10.1007/s11554-019-00904-8
NR 35
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24949
EP 24968
DI 10.1007/s11042-021-10914-z
EA APR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700002
DA 2024-07-18
ER

PT J
AU Pour, AK
   Seng, WC
   Palaiahnakote, S
   Tahaei, H
   Anuar, NB
AF Khaksar Pour, Amin
   Chaw Seng, Woo
   Palaiahnakote, Shivakumara
   Tahaei, Hamid
   Anuar, Nor Badrul
TI A survey on video content rating: taxonomy, challenges and open issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computer vision; Video content rating; Violence
   detection; Pornography detection; Substance abuse detection
ID VIOLENCE DETECTION; OPTICAL-FLOW; DEEP; PORNOGRAPHY; CLASSIFICATION;
   RECOGNITION; REPRESENTATIONS; PREDICTION; NETWORKS; MOVIES
AB Rating a video based on its content is one of the most important solutions to classify videos for audience age groups. In this regard, Film content rating and TV programmes rating are the only two most common rating systems which have been accomplished by the professional committees. However, due to the huge number of short videos shared in social media, it is impossible to review and rate their contents manually by a committee. Therefore, a proper solution is by utilizing computer vision capabilities to analyze the video content and rate it. Automatic Video Content Rating (VCR) system rates a short video to classify it for audience age groups. Inspired by the current manually film and TV programmes rating systems, VCR depends on five main components that comprise violence, profanity language, nudity, pornography, and substance abuse. To date, several reviews and survey papers have addressed advancements and innovations in video content analysis such as violence, nudity, and pornography detection. However, the lack of a comprehensive survey paper to investigate a VCR system and explain taxonomy, challenges, and open issues is discovered; thus, this study is undertaken. In this paper, in addition, to fill this gap, we review deep learning studies related to the relevant subjects of VCR. Moreover, we have investigated recently published works related to VCR based on the audio, static visual and, motion visual aspects of a video. Furthermore, related current datasets are investigated as well as the performances of published models in these datasets are compared. Finally, the challenges and the future of VCR are discussed.
C1 [Khaksar Pour, Amin; Chaw Seng, Woo; Palaiahnakote, Shivakumara; Anuar, Nor Badrul] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Tahaei, Hamid] Xiamen Univ Malaysia, Sch Elect & Comp Technol, Sepang, Malaysia.
C3 Universiti Malaya; Xiamen University Malaysia Campus
RP Pour, AK; Anuar, NB (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
EM amin.khaksar@gmail.com; badrul@um.edu.my
RI Palaiahnakote, Shivakumara/ITU-6488-2023; Khaksar Pour,
   Amin/AGZ-6436-2022; Anuar, Nor Badrul/B-3101-2010; Woo, Chaw
   Seng/C-1058-2010; Palaiahnakote, Shivakumara/B-6261-2013
OI Khaksar Pour, Amin/0000-0001-8569-0837; Anuar, Nor
   Badrul/0000-0003-4380-5303; Woo, Chaw Seng/0000-0001-6576-5061; Tahaei,
   Hamid/0000-0002-9878-9171
FU Faculty of Computer Science & Information Technology, University of
   Malaya under project (Geran Penyelidikan Fakulti) [GPF018D-2019]
FX This research is supported by the Faculty of Computer Science &
   Information Technology, University of Malaya under project (Geran
   Penyelidikan Fakulti) GPF018D-2019.
CR Abbas Q, 2018, MULTIMED TOOLS APPL, V77, P20415, DOI 10.1007/s11042-017-5438-7
   Acar E, 2016, NEUROCOMPUTING, V208, P225, DOI 10.1016/j.neucom.2016.05.050
   Accattoli S, 2020, APPL ARTIF INTELL, V34, P329, DOI 10.1080/08839514.2020.1723876
   Akram, 2018, INT J COMPUTER SCI E, V5
   Algarni AD, 2020, MULTIMED TOOLS APPL, V79, P13403, DOI 10.1007/s11042-020-08616-z
   Ali A, 2017, ADV INTELL SYST, V549, P130, DOI 10.1007/978-3-319-51281-5_14
   Amazon, 2020, INTERNET MOVIE DATAB
   [Anonymous], 2020, MULTIMED TOOLS APPL
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Ayadi A, 2019, PROCEDIA COMPUT SCI, V159, P572, DOI 10.1016/j.procs.2019.09.212
   Ben Mabrouk A, 2017, PATTERN RECOGN LETT, V92, P62, DOI 10.1016/j.patrec.2017.04.015
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Caetano C, 2016, NEUROCOMPUTING, V213, P102, DOI 10.1016/j.neucom.2016.03.099
   Caetano C, 2014, EUR SIGNAL PR CONF, P1681
   Chen F, 2019, MULTIMED TOOLS APPL, V78, P4673, DOI 10.1007/s11042-018-6601-5
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Demarty C-H, 2014, P MEDIAEVAL 2014 WOR
   Demarty CH, 2014, INT WORK CONTENT MUL
   Demarty CH, 2015, MULTIMED TOOLS APPL, V74, P7379, DOI 10.1007/s11042-014-1984-4
   Gangwar Abhishek, 2017, 8th International Conference on Imaging for Crime Detection and Prevention (ICDP 2017), P37
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   Gibert D, 2020, J NETW COMPUT APPL, V153, DOI 10.1016/j.jnca.2019.102526
   Gupta O, 2018, J NETW COMPUT APPL, V116, P1, DOI 10.1016/j.jnca.2018.05.003
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu T, 2020, MULTIMED TOOLS APPL, V79, P9161, DOI 10.1007/s11042-020-08733-9
   Karamizadeh S, 2017, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON COMPUTER MODELING AND SIMULATION (ICCMS 2018), P33, DOI 10.1145/3177457.3177484
   Kaushal M, 2018, APPL SOFT COMPUT, V70, P423, DOI 10.1016/j.asoc.2018.05.023
   Keslassy, 2016, CONSERVATIVE GROUP F
   Kim E, 2019, EXPERT SYST APPL, V128, P214, DOI 10.1016/j.eswa.2019.03.042
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Lenhart A., 2015, TEENS SOCIAL MEDIA T
   Li B, 2020, SIGNAL IMAGE VIDEO P, V14, P1245, DOI 10.1007/s11760-020-01665-9
   Liu YN, 2016, SIGNAL PROCESS, V120, P761, DOI 10.1016/j.sigpro.2015.01.001
   Liu YZ, 2017, IEEE GLOB CONF SIG, P1397, DOI 10.1109/GlobalSIP.2017.8309191
   Liu YZ, 2014, FUTURE GENER COMP SY, V31, P69, DOI 10.1016/j.future.2012.08.012
   Mahmoodi J, 2019, EXPERT SYST APPL, V127, P121, DOI 10.1016/j.eswa.2019.02.032
   Moreira D, 2019, INFORM FUSION, V45, P307, DOI 10.1016/j.inffus.2018.03.001
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   Moustafa MN, 2015, ARXIV151108899V1CSCC
   MPAA, 2010, CLASS RAT RUL
   Nie L, 2016, J NETW COMPUT APPL, V76, P16, DOI 10.1016/j.jnca.2016.10.006
   Nurhadiyatna A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P106, DOI 10.1109/IC3INA.2017.8251749
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Ofcom, 2018, Children and Parents: Media Use and Attitudes Report 2018
   Ou XY, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3057733
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Prates RM, 2019, COMPUT ELECTR ENG, V78, P343, DOI 10.1016/j.compeleceng.2019.08.001
   Ribeiro PC, 2016, COMPUT VIS IMAGE UND, V144, P121, DOI 10.1016/j.cviu.2015.11.001
   Short MB, 2012, CYBERPSYCH BEH SOC N, V15, P13, DOI 10.1089/cyber.2010.0477
   Soon FC, 2019, SIGNAL IMAGE VIDEO P, V13, P111, DOI 10.1007/s11760-018-1335-4
   Sorin V, 2020, J AM COLL RADIOL, V17, P639, DOI 10.1016/j.jacr.2019.12.026
   Steven, 2014, MOVIE RATINGS GERMAN
   Subetha T, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Sun YC, 2018, NEUROCOMPUTING, V297, P33, DOI 10.1016/j.neucom.2018.02.028
   Tahaei H, 2020, J NETW COMPUT APPL, V154, DOI 10.1016/j.jnca.2020.102538
   Teeni-Harari T, 2019, REGULATORY LITERACY, V88
   The British Board of Film Classification, 2016, BBFCS CLASSIFICATION
   Thrasher JF, 2014, INT J DRUG POLICY, V25, P267, DOI 10.1016/j.drugpo.2013.09.004
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   TV Parental Guidelines Monitoring Board, 2018, TV PARENTAL GUIDELIN
   Ullah FUM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112472
   Villani S, 2001, J AM ACAD CHILD PSY, V40, P392, DOI 10.1097/00004583-200104000-00007
   Vitorino P, 2018, J VIS COMMUN IMAGE R, V50, P303, DOI 10.1016/j.jvcir.2017.12.005
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Xu M, 2004, LECT NOTES COMPUT SC, V3333, P566
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   YouTube, 2018, YOUTUBE CONTENT RATI
   Yu HS, 2018, NEUROCOMPUTING, V304, P82, DOI 10.1016/j.neucom.2018.03.037
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang QC, 2019, J NETW COMPUT APPL, V129, P1, DOI 10.1016/j.jnca.2018.12.012
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P98, DOI 10.1016/j.patrec.2017.08.021
   Zhang WS, 2018, J NETW COMPUT APPL, V103, P239, DOI 10.1016/j.jnca.2017.09.001
   Zhang XW, 2021, INFORM SCIENCES, V557, P302, DOI 10.1016/j.ins.2019.05.023
NR 76
TC 3
Z9 4
U1 5
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24121
EP 24145
DI 10.1007/s11042-021-10838-8
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000635061800003
DA 2024-07-18
ER

PT J
AU Medeghri, H
   Sabeur, SA
AF Medeghri, Hadjira
   Sabeur, Sid Ahmed
TI Anatomic compartments extraction from diffusion medical images using
   factorial analysis and K-means clustering methods: a combined analysis
   tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diffusion medical images; K-means clustering; Factor analysis; Anatomic
   compartments extraction
ID WATER DIFFUSION; BRAIN; MODEL; MRI
AB Currently, diffusion medical imaging is used for the exploration and diagnosis of brain anatomy in clinical practice. Several methods for the extraction of biological compartments of the brain have emerged in recent years. These mainly include, k-means clustering and factorial analysis based methods. In this work, we have developed a tool where these two approaches are combined for more advanced extractions of human brain anatomic compartments. The results show that the failure of one method within the extraction process can be rapidly recovered by the other one, leading to more reliable and efficient medical diagnoses.
C1 [Medeghri, Hadjira; Sabeur, Sid Ahmed] Univ Sci & Technol Oran, Fac Phys, Lab Etud Phys Mat, BP 1505 El Mnaouer, Oran 31000, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf
RP Sabeur, SA (corresponding author), Univ Sci & Technol Oran, Fac Phys, Lab Etud Phys Mat, BP 1505 El Mnaouer, Oran 31000, Algeria.
EM sidsabeur@gmail.com
FU MHESR Algeria [B00L02UN310220180006]
FX This work is support by a research grant from MHESR Algeria ref.
   B00L02UN310220180006.
CR [Anonymous], 2013, Learning Python
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   BAMBER JC, 1986, ULTRASONICS, V24, P41, DOI 10.1016/0041-624X(86)90072-7
   Benali, 1994, STUDIES CLASSIFICATI, DOI 10.1007/978-3-642-51175-2_72
   BENALI H, 1993, PHYS MED BIOL, V38, P1065, DOI 10.1088/0031-9155/38/8/005
   Bharathi D, 2013, ADV INTELL SYST, V177, P905
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Brugières P, 2004, AM J NEURORADIOL, V25, P692
   Carter R., 2014, The human brain book: An illustrated guide to its structure, function, and disorders
   Dhawan A.P., 2008, PRINCIPLES ADV METHO
   Fuster, 2015, MICCAI WORKSH MUN GE, DOI 10.1007/978-3-319-28588-7
   Grassi DC, 2018, ARQ NEURO-PSIQUIAT, V76, P189, DOI [10.1590/0004-282x20180007, 10.1590/0004-282X20180007]
   Hall DJ, 1965, 699616 NTIS AD STANF
   Isa IS, 2015, PROCEDIA COMPUT SCI, V60, P760, DOI 10.1016/j.procs.2015.08.231
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jayaraman S., 2009, DIGITAL IMAGE PROCES
   Jones DK., 2011, DIFFUSION MRI THEORY
   Le Bihan D, 2013, RADIOLOGY, V268, P318, DOI 10.1148/radiol.13130420
   Le Bihan D, 2012, NEUROIMAGE, V61, P324, DOI 10.1016/j.neuroimage.2011.11.006
   LEBIHAN D, 1986, RADIOLOGY, V161, P401, DOI 10.1148/radiology.161.2.3763909
   LEBIHAN D, 1985, CR ACAD SCI II, V301, P1109
   Lim J.S, 1990, 2 DIMENSIONAL SIGNAL
   Melhem ER, 2002, AM J ROENTGENOL, V178, P3, DOI 10.2214/ajr.178.1.1780003
   Moraru L, 2017, AIP CONF PROC, V1796, DOI 10.1063/1.4972383
   Muller A. C., 2016, Introduction to Machine Learning with Python: A Guide for Data Scientists
   Natali F, 2019, J R SOC INTERFACE, V16, DOI 10.1098/rsif.2019.0186
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Rekik, 2011, TSSD TRANS 6
   Steinhaus H, 1956, B ACAD POL SCI, V4, P801
   STEJSKAL EO, 1965, J CHEM PHYS, V42, P288, DOI 10.1063/1.1695690
   SZAFER A, 1995, MAGNET RESON MED, V33, P697, DOI 10.1002/mrm.1910330516
   TORREY HC, 1956, PHYS REV, V104, P563, DOI 10.1103/PhysRev.104.563
   Wang L, 2008, ELECTR ENG JPN, V163, P37, DOI 10.1002/eej.20486
   Wellner P. D., 1993, EPC93110 EUROPARC
NR 34
TC 3
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 23949
EP 23962
DI 10.1007/s11042-021-10846-8
EA MAR 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000634300400001
DA 2024-07-18
ER

PT J
AU Shi, DM
   Tang, HY
AF Shi, Dongmei
   Tang, Hongyu
TI Face recognition algorithm based on self-adaptive blocking local binary
   pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Local binary pattern; Convolutional neural network;
   Mobile learning; Image
ID REPRESENTATION; SCALE
AB Face recognition is a common means of identity authentication. Mobile learning platform login technology has developed from user name and password to face recognition. In order to improve effectively the rate of face recognition, this paper proposes a kind of face recognition algorithm based on self-adaptive blocking local binary pattern (LBP) and dual channel convolutional neural network (CNN) with different convolution kernels. Firstly, the Gamma correction, the Mallet wavelet filtering and normalization are used to preprocess the face image. The face image is decomposed and reconstructed by 2-layer Mallet wavelet to filter out the interference signal effectively. Although the general LBP operator extracts the overall texture and contour features of the face image, the distribution of the bright spot, dark spot and other micro details cannot be fully characterized. In order to solve this problem, integral projection is introduced to project the image horizontally and vertically. The extreme points of the projection represent the texture mutation points of the face image in the horizontal and vertical directions. These extreme points are used as the boundary of the image blocking, and the LBP value of the face image is extracted by the self-adaptive blocking strategy. Combining the features of k-nearest neighbor classifier and softmax, a k-softmax classification method is proposed to classify and recognize the face image labels. After two channel network structure training, this method is tested on Yale, ORL, extended Yale B and self-built face databases by five experiments, comparing with other face recognition algorithms. The results show that the proposed method based on SAB-LBP and dual channel CNN has high recognition rate and computational efficiency.
C1 [Shi, Dongmei] Suzhou Coll Informat Technol, Dept Comp Sci, Suzhou, Peoples R China.
   [Tang, Hongyu] Zhenjiang Coll, Sch Elect & Informat, Zhenjiang, Jiangsu, Peoples R China.
RP Tang, HY (corresponding author), Zhenjiang Coll, Sch Elect & Informat, Zhenjiang, Jiangsu, Peoples R China.
EM t_redrain@163.com
FU Jiangsu Natural Science Foundation of China [BK20191225]; Scientific
   Research Project of Suzhou College of Information Technology [2018YK03];
   Jiangsu Province Colleges and Universities Innovation and
   Entrepreneurship [201914256010Y]
FX This work was supported in part by the Jiangsu Natural Science
   Foundation of China (Project No. BK20191225),the Scientific Research
   Project of Suzhou College of Information Technology (Project No.
   2018YK03) and the Jiangsu Province Colleges and Universities Innovation
   and Entrepreneurship. Training Program (Project No. 201914256010Y).
CR Ahmad Radzi S., 2014, International journal of engineering and Technology, V6, P44
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alahmadi A, 2020, PATTERN ANAL APPL, V23, P673, DOI 10.1007/s10044-019-00818-y
   [Anonymous], 2015, BRIT MACH VIS C
   Bah, 2020, ARRAY, DOI 10.1016/j.array100014
   Chen WS, 2020, J CHIN INST ENG, V43, P451, DOI 10.1080/02533839.2020.1751724
   CHEN ZL, SIG PROCESS IMAGE CO
   Deng WH, 2017, PATTERN RECOGN, V66, P63, DOI 10.1016/j.patcog.2016.11.023
   Dong Y., 2014, ARXIV PREPRINT ARXIV
   Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438
   Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453
   Kas M, 2020, MULTIMED TOOLS APPL, V79, P375, DOI 10.1007/s11042-019-08049-3
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Li Y, 2017, RECENT PATENTS COMPU, V10, P101
   Li ZM, 2016, INT J WAVELETS MULTI, V14, DOI 10.1142/S0219691316500351
   Liu WY, 2016, PR MACH LEARN RES, V48
   Murtaza M, 2014, INT ARAB J INF TECHN, V11, P149
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Singh R, 2008, PATTERN RECOGN, V41, P880, DOI 10.1016/j.patcog.2007.06.022
   Sun Y, 2016, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR.2016.525
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang J, 2014, IEEE T CYBERNETICS, V44, P2368, DOI 10.1109/TCYB.2014.2307067
   Wang MH, 2020, NEURAL COMPUT APPL, V32, P13843, DOI 10.1007/s00521-020-04792-z
   Wang Y., 2018, ACTA AUTOMATICA SINI, V44, P69
   Wei MH, 2020, INT J INTELL COMPUT, V13, P207, DOI 10.1108/IJICC-02-2020-0017
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Zhang Q, 2020, MATH BIOSCI ENG, V17, P1578, DOI 10.3934/mbe.2020082
   Zhou DX, 2018, MULTIMED TOOLS APPL, V77, P18957, DOI 10.1007/s11042-017-5319-0
   Zhou LJ, 2020, MULTIMED TOOLS APPL, V79, P675, DOI 10.1007/s11042-019-08157-0
   Zhou Lijian., 2016, J INFORM HIDING MULT, V7, P1092
NR 34
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 23899
EP 23921
DI 10.1007/s11042-021-10825-z
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000633749600001
DA 2024-07-18
ER

PT J
AU Malathkar, NV
   Soni, SK
AF Malathkar, Nithin Varm
   Soni, Surender Kumar
TI High compression efficiency image compression algorithm based on
   subsampling for capsule endoscopy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Capsule endoscopy; DPCM; Subsampling; Uniform quantization; YUV colour
   space
AB In this paper, a simple image compression algorithm is proposed for wireless capsule endoscopy. The proposed algorithm consists of new simplified YUV colour space, corner clipping, uniform quantization, subsampling, differential pulse code modulation and Golomb Rice code. Simplified YUV colour space is proposed based on special nature of endoscopic images and provide good results. The quantization and subsampling are used as lossy compression techniques and fixed Golomb-Rice code is used to encode residual value obtained after differential pulse code modulation operation. Here performance of different combination of quantization and subsampling techniques are analyzed based combination along with the proposed compression algorithm provides compression ratio of 89.3% and peak signal noise ratio of 45.1. the proposed algorithm provided better results as compared to various reported algorithms in literature in term of CR and PSNR.
C1 [Malathkar, Nithin Varm] MREC Autonomous, Dept Elect & Commun Engn, Hyderabad, TS, India.
   [Soni, Surender Kumar] NIT Hamirpur, Dept Elect & Commun Engn, Hamirpur, HP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Malathkar, NV (corresponding author), MREC Autonomous, Dept Elect & Commun Engn, Hyderabad, TS, India.
EM nithinvarma.a3@gmail.com
RI soni, surender/AAD-9998-2022
OI Soni, Surender Kumar/0000-0003-1181-4299
FU government of India
FX The authors are grateful to government of India for the financial
   support through Visvesvaraya Ph.D scheme grant
CR Alam Mohammad Wajih, 2017, IEEE Rev Biomed Eng, V10, P26, DOI 10.1109/RBME.2017.2757013
   Chen XK, 2009, IEEE T BIOMED CIRC S, V3, P11, DOI 10.1109/TBCAS.2008.2006493
   Dung LR, 2008, 2008 IEEE BIOMEDICAL CIRCUITS AND SYSTEMS CONFERENCE - INTELLIGENT BIOMEDICAL SYSTEMS (BIOCAS), P61, DOI 10.1109/BIOCAS.2008.4696874
   Fante KA, 2016, CIRC SYST SIGNAL PR, V35, P1677, DOI 10.1007/s00034-015-0136-z
   Gu Y., 2017, INT C BIOM CIRC BIOM, P103
   Khan TH, 2014, SENSORS-BASEL, V14, P20779, DOI 10.3390/s141120779
   Khan TH, 2014, SIGNAL PROCESS-IMAGE, V29, P345, DOI 10.1016/j.image.2013.12.001
   Khan TH, 2012, IEEE INT SYMP CIRC S, P2203, DOI 10.1109/ISCAS.2012.6271727
   Khan TH, 2011, VLSI DES, DOI 10.1155/2011/343787
   Khan TH, 2013, J REAL-TIME IMAGE PR, V8, P5, DOI 10.1007/s11554-011-0208-7
   Khan TH, 2011, IEEE T CIRC SYST VID, V21, P1534, DOI 10.1109/TCSVT.2011.2163985
   Li Siqing, 2017, Journal of Shanghai Jiaotong University (Science), V22, P156, DOI 10.1007/s12204-017-1815-7
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin MC, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/257095
   Mohammed SK, 2017, IEEE ACCESS, V5, P13823, DOI 10.1109/ACCESS.2017.2726997
   Turcza P, 2019, J REAL-TIME IMAGE PR, V16, P1425, DOI 10.1007/s11554-016-0653-4
   Turcza P, 2017, BIOMED SIGNAL PROCES, V38, P1, DOI 10.1016/j.bspc.2017.04.006
   Turcza P, 2013, IEEE J BIOMED HEALTH, V17, P1046, DOI 10.1109/JBHI.2013.2266101
   Turcza P, 2011, SENSOR ACTUAT A-PHYS, V172, P552, DOI 10.1016/j.sna.2011.09.026
   Wahid K, 2008, IEEE IJCNN, P2761, DOI 10.1109/IJCNN.2008.4634186
   Wu J, 2009, IEEE ENG MED BIO, P3727, DOI 10.1109/IEMBS.2009.5334819
   Xiang X, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2194032
   Xie X, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/82160
   Xie X, 2006, IEEE J SOLID-ST CIRC, V41, P2390, DOI 10.1109/JSSC.2006.882884
NR 24
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22163
EP 22175
DI 10.1007/s11042-021-10808-0
EA MAR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631790800005
DA 2024-07-18
ER

PT J
AU Miguel, EC
   Silva, CM
   Coelho, FC
   Cunha, IFS
   Campos, SVA
AF Miguel, Eliseu C.
   Silva, Cristiano M.
   Coelho, Fernando C.
   Cunha, Italo F. S.
   Campos, Sergio V. A.
TI Construction and maintenance of P2P overlays for live streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE P2P network; Overlay management; Live streaming; Flash crowd; Free rider
ID FLASH CROWD; SYSTEMS
AB P2P live streaming requires low latency and low media discontinuity to provide users good quality of experience. When peers are connected to a large number of partners, the communication overhead increases and sophisticated overlay maintenance strategies are required to maintain undisrupted media distribution. In order to deal with these challenges, we present the Peer Classification for Partnership Constraints technique for building and managing P2P overlays for live streaming. The proposed algorithm defines classes of peers based on their contribution to video chunk distribution. Classes are used to constrain partnerships among peers. The number of potential partners in each class is constrained, avoiding competition for partnerships between high-cooperation and low-cooperation peers. Since each peer has a given number of slots dedicated to high-cooperation and low-cooperation peers, we guarantee that the network keeps operating, even when incorporating a considerable share of free riders. The strategy is simple, significantly reducing system complexity. Moreover, it can also be used in conjunction with other strategies devised in the literature for greater gains in efficiency. Experiments show that our Peer Classification for Partnership Constraints technique allows a streaming system to handle 50% of free riders under flash crowd events with low latency and discontinuity.
C1 [Miguel, Eliseu C.] Univ Fed Alfenas, Dept Ciencia Comp DCC UNIFAL MG, Alfenas, Brazil.
   [Silva, Cristiano M.] Univ Fed Sao Joao Del Rei, Dept Tecnol DTECH UFSJ, Sao Joao Del Rei, Brazil.
   [Coelho, Fernando C.; Cunha, Italo F. S.; Campos, Sergio V. A.] Univ Fed Minas Gerais, Dept Ciencia Comp DCC UFMG, Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Alfenas; Universidade Federal de Sao Joao
   del-Rei; Universidade Federal de Minas Gerais
RP Miguel, EC (corresponding author), Univ Fed Alfenas, Dept Ciencia Comp DCC UNIFAL MG, Alfenas, Brazil.
EM eliseu.miguel@unifal-mg.edu.br; cristiano@ufsj.edu.br;
   fccoelho@dcc.ufmg.br; cunha@dcc.ufmg.br; scampos@dcc.ufmg.br
OI Miguel, Eliseu Cesar/0000-0003-3183-7439
FU CNPq (Conselho Nacional de Desenvolvimento Cientifico e Tecnologico)
   [303933/2017-8]; CAPES (CoordenacAo de Aperfeicoamento de Pessoal de
   Nivel Superior); FAPEMIG (FundacAo de Amparo a Pesquisa do Estado de
   Minas Gerais) [APQ-02145-18]
FX This research was partially funded by the CNPq (Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico) grant 303933/2017-8, CAPES
   (CoordenacAo de Aperfeicoamento de Pessoal de Nivel Superior), and
   FAPEMIG (FundacAo de Amparo a Pesquisa do Estado de Minas Gerais) grant
   APQ-02145-18.
CR Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   [Anonymous], 2014, MULTIMEDIA SYST
   [Anonymous], 2010, P IEEE GLOBECOM
   [Anonymous], 2019, The Paper
   [Anonymous], 2009, P 8 INT C PEER TO PE
   Budhkar S, 2019, OVERLAY MANAGEMENT S
   Campos SV, 2013, SBRC SALAO FERRAMENT
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chen YS, 2014, IEEE ACM T NETWORK, V22, P1106, DOI 10.1109/TNET.2013.2272056
   Chung TY, 2011, INT C PAR DISTRIB SY, P823, DOI 10.1109/ICPADS.2011.2
   Cohen B., 2003, WORKSH EC PEER TO PE
   da Silva APC, 2008, IEEE INT CONF PEER, P279, DOI 10.1109/P2P.2008.38
   Felber P, 2005, LECT NOTES COMPUT SC, V3460, P343
   Fortuna R., 2010, P IEEE P2P 2010
   Guarnieri T, 2017, IEEE GLOB COMM CONF
   Guerraoui R, 2010, LECT NOTES COMPUT SC, V6452, P313, DOI 10.1007/978-3-642-16955-7_16
   Jain S, 2013, ACM SIGCOMM COMP COM, V43, P3, DOI 10.1145/2534169.2486019
   Kumar R, 2007, IEEE INFOCOM SER, P919, DOI 10.1109/INFCOM.2007.112
   Li B, 2008, IEEE INFOCOM SER, P1705
   Li B, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.339
   Liao X., 2006, P IEEE INFOCOM, P1
   Liu FM, 2012, IEEE T PARALL DISTR, V23, P1227, DOI 10.1109/TPDS.2011.283
   Lobb RJ, 2009, NOSSDAV 09: 18TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P31
   Locher T, 2007, LECT NOTES COMPUT SC, V4731, P388
   Locher T, 2009, NOSSDAV 09: 18TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P121
   Magharei N, 2014, IEEE ACM T NETWORK, V22, P244, DOI 10.1109/TNET.2013.2257840
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Olivier Jeremy, 2013, IEEE Int Conf Rehabil Robot, V2013, P6650495, DOI 10.1109/ICORR.2013.6650495
   Payberah A. H., 2011, Proceedings 2011 10th International Symposium on Parallel and Distributed Computing (ISPDC 2011), P153, DOI 10.1109/ISPDC.2011.31
   Payberah AH, 2012, COMPUTING, V94, P621, DOI 10.1007/s00607-012-0195-y
   Piatek M, 2010, NSDI 10, P6
   Piatek M, 2009, PITFALLS ISP FRIENDL
   PlanetLab, 2009, OPEN PLATFORM DEVELO
   Ren D, 2008, IEEE INFOCOM SER, P1732
   Ruckert, 2015, P IEEE IFIP NETW C, P1
   Santos C. M., 2020, INT C INNOVATION INT, P1, DOI [10.1109/3ICT51146.2020.9311950, DOI 10.1109/3ICT51146.2020.9311950]
   Schlinker B, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P418, DOI 10.1145/3098822.3098853
   Shahriar I, 2016, INT CONF COMPUT NETW, P729
   Simoni G, 2014, IEEE INT CONF PEER
   Traverso S, 2012, IEEE INT CONF PEER, P13
   Traverso S, 2015, IEEE ACM T NETWORK, V23, P741, DOI 10.1109/TNET.2014.2307157
   Ullah I, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P920
   Venkataraman V, 2006, PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P2, DOI 10.1109/ICNP.2006.320193
   Wichtlhuber M, 2014, 2014 IFIP NETWORKING CONFERENCE
   Wu H., 2011, 30 IEEE INT PERFORMA, P1
   Wu HB, 2012, IEEE IPCCC, P360, DOI 10.1109/PCCC.2012.6407778
   Yap KK, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P432, DOI 10.1145/3098822.3098854
   Zhao BQ, 2009, IEEE INT CONF PEER, P271, DOI 10.1109/P2P.2009.5284548
NR 48
TC 7
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20255
EP 20282
DI 10.1007/s11042-021-10604-w
EA MAR 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625344700001
DA 2024-07-18
ER

PT J
AU Smiatacz, M
   Wiszniewski, B
AF Smiatacz, Maciej
   Wiszniewski, Bogdan
TI Just look at to open it up: A biometric verification facility for
   password autofill to protect electronic documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document encryption; Automatic password generation; Biometric identity
   verification; Reactive documents; Natural user interface
ID FACE-RECOGNITION; FISHERFACES; EIGENFACES
AB Electronic documents constitute specific units of information, and protecting them against unauthorized access is a challenging task. This is because a password protected document may be stolen from its host computer or intercepted while on transfer and exposed to unlimited offline attacks. The key issue is, therefore, making document passwords hard to crack. We propose to augment a common text password authentication interface to encrypted documents with a biometric facial identity verification providing highly personalized security mechanism based on pseudo-identities. In consequence the encrypted document can be unlocked with the legitimate user's face, while for everyone else stays encrypted with a hard to crack text password. This paper makes two contributions: (1) The proposed scheme enables password autofill without referring to any external service, which significantly limits the possibilities of an attack by adversaries when opening, reading and editing the protected document, (2) By the adoption of biometric verification techniques enabling fine-tuning of false acceptance and false rejection rates, it provides for responsible adaptation to users.
C1 [Smiatacz, Maciej; Wiszniewski, Bogdan] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Dept Intelligent Interact Syst, Pomorskie, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Wiszniewski, B (corresponding author), Gdansk Univ Technol, Fac Elect Telecommun & Informat, Dept Intelligent Interact Syst, Pomorskie, Poland.
EM macsmiat@pg.edu.pl; bogwiszn@pg.edu.pl
OI Wiszniewski, Bogdan/0000-0002-5798-0252
FU National Science Center in Poland [DEC1-2011/01/B/ST6/06500, N N516
   367936]
FX This work was supported in part by the National Science Center in Poland
   under grants DEC1-2011/01/B/ST6/06500 and N N516 367936
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Al Maqbali F, 2016, LECT NOTES COMPUT SC, V9895, P245, DOI 10.1007/978-3-319-45931-8_16
   [Anonymous], 2017, EasyFit-distribution fitting soft-ware-customer testimonials
   [Anonymous], 2008, PROC BIOSIG BIOMETRI
   [Anonymous], 2011, 24745 ISOIEC
   [Anonymous], 2016, 2016 INT C SIGNAL PR
   [Anonymous], 2019, P MACHINE LEARNING R
   Apple Inc, MANAGE PASSWORDS USI
   Arora, 2015, CORR ARXIV 151105653
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Biddle R, 2011, IEEE T INF FOREN SEC, V6, P970, DOI 10.1109/TIFS.2011.2116781
   Bishop M., 2018, COMPUTER SECURITY
   Das AK, 2019, P 7 INT C SMART COMP, P1
   Ding L, 2012, IEEE SIGNAL PROC LET, V19, P721, DOI 10.1109/LSP.2012.2215586
   Eastlake D., 2005, 4086 RFC, DOI [10.17487/RFC4086, DOI 10.17487/RFC4086]
   Flor^encio D., 2014, 28 LARGE INSTALLATIO, P35
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Godlewska M, 2010, LECT NOTES COMPUT SC, V6068, P244
   Gomez-Barrero M, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101700
   Guo GB, 2018, INFORM SCIENCES, V436, P56, DOI 10.1016/j.ins.2018.01.019
   Horsch M, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P30, DOI 10.1109/ARES.2015.23
   Hosseinzadeh S, 2018, INFORM SOFTWARE TECH, V104, P72, DOI 10.1016/j.infsof.2018.07.007
   Jeong, 2019, 2019 CHI C HUM FACT
   Karimian N, 2017, IEEE T BIO-MED ENG, V64, P1400, DOI 10.1109/TBME.2016.2607020
   Kissell J, 2019, TAKE CONTROL YOUR PA
   Kolakowska A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14209-y
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lim MH, 2016, IEEE T CYBERNETICS, V46, P1065, DOI 10.1109/TCYB.2015.2423271
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Ma J, 2014, P IEEE S SECUR PRIV, P689, DOI 10.1109/SP.2014.50
   Maclean R, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT AND INNOVATIVE COMPUTING APPLICATIONS (ICONIC), P316
   Maqbali F.A., 2017, P INT CARNAHAN C SEC, P1
   Marky K, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P786, DOI 10.1145/3267305.3274127
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Poon CCY, 2006, IEEE COMMUN MAG, V44, P73, DOI 10.1109/MCOM.2006.1632652
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ravi KVR, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL I, PROCEEDINGS, P540, DOI 10.1109/ICCIMA.2007.178
   Razavi A, 2019, ADV NEUR IN, V32
   Ross B, 2005, USENIX Association Proceedings of the 14th USENIX Security Symposium, P17
   Selvakumar AAL, 2009, I C COMM SOFTW NET, P588, DOI 10.1109/ICCSN.2009.50
   Siciarek J, 2011, PROCEDIA COMPUT SCI, V4, P668, DOI 10.1016/j.procs.2011.04.070
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Smiatacz M, 2013, ADV INTELL SYST, V226, P187, DOI 10.1007/978-3-319-00969-8_18
   Smiatacz M, 2012, METROL MEAS SYST, V19, P257, DOI 10.2478/v10178-012-0022-y
   Solar Designer, 2013, JOHN RIPPER
   STEUBE J., 2018, HASHCAT
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Walkenbach J., 2015, Excel 2016 Bible
   Wang Y, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P197, DOI 10.1109/CTS.2014.6867564
   Weir M, 2009, P IEEE S SECUR PRIV, P391, DOI 10.1109/SP.2009.8
   Wheeler DL, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P157
   Whittlesey M., 2019, Spherical Geometry and its Applications
   Yoon S, 2015, 2015 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC), P1171, DOI 10.1109/ICTC.2015.7354766
   Zhang WM, 2019, IEEE T PATTERN ANAL, V41, P611, DOI 10.1109/TPAMI.2018.2803179
   Zhao, 2017, U.S. Patent, Patent No. [8411909B1, 8411909]
NR 60
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20089
EP 20124
DI 10.1007/s11042-021-10533-8
EA MAR 2021
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612900007
OA hybrid
DA 2024-07-18
ER

PT J
AU Ramesh, S
   Sasikala, S
   Paramanandham, N
AF Ramesh, S.
   Sasikala, S.
   Paramanandham, Nirmala
TI Segmentation and classification of brain tumors using modified median
   noise filter and deep learning approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor classification; Deep learning; Machine learning; MIGMF;
   MLE-KPCA; VGG16
AB The most vital challenge for a radiologist is locating the brain tumors in the earlier stage. As the brain tumor grows rapidly, doubling its actual size in about twenty-five days. If not dealt properly, the affected person's survival rate usually does no longer exceed half a year. This can rapidly cause dying. For this reason, an automatic system is desirable for locating brain tumors at the early stage. In general, when compared to computed tomography (CT), magnetic resonance image (MRI) scans are used for detecting the diagnosis of cancerous and noncancerous tumors. However, while MRI scans acquisition, there is a chance of appearing noise such as speckle noise, salt & pepper noise and Gaussian noise. It may degrade classification performance. Hence, a new noise removal algorithm is proposed, namely the modified iterative grouping median filter. Further, Maximum likelihood estimation-based kernel principal component analysis is proposed for feature extraction. A deep learning-based VGG16 architecture has been utilized for segmentation purposes. Experimental results have shown that the proposed algorithm outperforms the well-known techniques in terms of both qualitative and quantitative evaluation.
C1 [Ramesh, S.] Vignan Fdn Sci Technol & Res, Guntur, Andhra Pradesh, India.
   [Sasikala, S.] Kongu Engn Coll, Dept ECE, Erode, Tamil Nadu, India.
   [Paramanandham, Nirmala] Vellore Inst Technol, Sch Elect Engn, Chennai, Tamil Nadu, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Kongu
   Engineering College; Vellore Institute of Technology (VIT); VIT Chennai
RP Paramanandham, N (corresponding author), Vellore Inst Technol, Sch Elect Engn, Chennai, Tamil Nadu, India.
EM drsr_ece@vignan.ac.in; sasikalapriyaadarsan@gmail.com;
   nirmalavp.ece@gmail.com
RI S, Ramesh/ABA-5102-2020; SUBRAMANIYAM, SASIKALA/AAT-9973-2021;
   SUBRAMANIYAM, SASIKALA/AAL-4982-2020
OI S, Ramesh/0000-0002-1369-3200; SUBRAMANIYAM,
   SASIKALA/0000-0002-2564-6014; SUBRAMANIYAM, SASIKALA/0000-0002-2564-6014
CR Abd-Ellah MK, 2016, INT C MICROELECTRON, P73, DOI 10.1109/ICM.2016.7847911
   Abdullah N, 2011, 2011 IEEE INT C IM S
   Aborisade D., 2014, ENERGY, V2, P10
   Aja-Fernández S, 2008, IEEE T IMAGE PROCESS, V17, P1383, DOI 10.1109/TIP.2008.925382
   Anisha K.K., 2011, Int. J. Multimed. Appl., V3, P93
   Bachoc F, 2019, ELECTRON J STAT, V13, P2921, DOI 10.1214/19-EJS1587
   Balasubramanian G, 2016, IMAGING SCI J, V64, P241, DOI 10.1080/13682199.2016.1168144
   Balasubramanian G, 2016, AEU-INT J ELECTRON C, V70, P471, DOI 10.1016/j.aeue.2016.01.013
   Basu S, 2006, LECT NOTES COMPUT SC, V4190, P117
   Bernal J, 2019, ARTIF INTELL MED, V95, P64, DOI 10.1016/j.artmed.2018.08.008
   Bhowmik MK, 2017, J IMAGE GRAPHICS JOI
   Çaliskan A, 2018, TEH VJESN, V25, P679, DOI 10.17559/TV-20171220221947
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chang Y, 2020, IEEE T INSTRUM MEAS, V69, P2707, DOI 10.1109/TIM.2019.2925881
   Chanu PR, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1057-8
   Chen JY, 2019, IET IMAGE PROCESS, V13, P946, DOI 10.1049/iet-ipr.2018.6331
   Chen QQ, 2017, IET IMAGE PROCESS, V11, P709, DOI 10.1049/iet-ipr.2016.0692
   Chinnu A, 2015, International Journal of Computer Science and Information Technologies, V6, P1505
   Cui SG, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/4940593
   Deepa B, 2015, 2015 IEEE INT C COMP
   Geng L, 2019, COMPUT ASSIST SURG, V24, P27, DOI 10.1080/24699322.2019.1649071
   González-Hidalgo M, 2018, APPL SOFT COMPUT, V63, P167, DOI 10.1016/j.asoc.2017.11.030
   Güler I, 2008, J MED SYST, V32, P229, DOI 10.1007/s10916-008-9127-y
   Gurusamy R, 2017, CMC-COMPUT MATER CON, V53, P91
   Hamuda E, 2016, COMPUT ELECTRON AGR, V125, P184, DOI 10.1016/j.compag.2016.04.024
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang K, 2008, IEEE T IMAGE PROCESS, V17, P1709, DOI 10.1109/TIP.2008.2001050
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Jafari M, 2020, 2020 IEEE 17 INT S B
   Jin LG, 2008, OPT ENG, V47, DOI 10.1117/1.2891297
   Karki MV, 2017, ARXIV PREPRINT ARXIV
   Kaur T, 2019, 2019 INT C INF TECHN
   Khalifa I, 2012, INT J COMPUT APPL, V47
   Khan S, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0502-z
   Lahmiri S, 2018, BIOMED ENG LETT, V8, P29, DOI 10.1007/s13534-017-0051-2
   Lin PH, 2016, J DISP TECHNOL, V12, P344, DOI 10.1109/JDT.2015.2487559
   Lu CT, 2012, PATTERN RECOGN LETT, V33, P1287, DOI 10.1016/j.patrec.2012.03.025
   Lu JJ, 2008, KNOWL-BASED SYST, V21, P887, DOI 10.1016/j.knosys.2008.03.051
   Lu JM, 2008, INT J IMAGE GRAPH, V8, P25, DOI 10.1142/S0219467808002952
   Madhukumar S, 2015, EGYPT J RADIOL NUC M, V46, P475, DOI 10.1016/j.ejrnm.2015.02.008
   Mafi M, 2017, ROUTL STUD NEW MEDIA
   Magudeeswaran V, 2017, 2017 INT C I SMAC IO
   Maheswari D., 2010, Computer Science and Engineering, V2, P1359
   Mathew AR, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P1766, DOI 10.1109/ICICICT1.2017.8342838
   Mathew AR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P75, DOI 10.1109/CSPC.2017.8305810
   Menon N, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P6, DOI 10.1109/ICCSP.2015.7322635
   Morchid M, 2014, PATTERN RECOGN LETT, V49, P33, DOI 10.1016/j.patrec.2014.05.020
   Mújica-Vargas D, 2017, INTELL DATA ANAL, V21, P739, DOI 10.3233/IDA-170885
   Murugan K, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1124-1
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Naik J, 2014, INT J COMPUT SCI NET, V14, P87
   Nguyen C., 2013, Random forest classifier combined with feature selection for breast cancer diagnosis and prognostic, DOI DOI 10.4236/JBISE.2013.65070
   Oh KT, 2020, J DIGIT IMAGING, V33, P816, DOI 10.1007/s10278-020-00321-5
   Oo SZ, 2014, Int J Res Eng Technol, V3, P367
   Palani DS, 2012, INT C COMP SCI ENG A
   Qin K, 2011, COMPUT MATH APPL, V62, P2824, DOI 10.1016/j.camwa.2011.07.048
   Ramesh S, 2020, SEGMENTATION CLASSIF
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   Ruba T., 2020, BIOMED PHARMACOL J, V13, P1227, DOI DOI 10.13005/bpj/1991
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Saritas M.M., 2019, International journal of intelligent systems and applications in engineering, V7, P88, DOI 10.18201/ijisae.2019252786
   Sarwinda D, 2013, INT C ADV COMP SCI I, P329, DOI 10.1109/ICACSIS.2013.6761597
   Shan ZY, 2002, NEUROIMAGE, V17, P1587, DOI 10.1006/nimg.2002.1287
   Sharma M, 2012, INT J ADV COMPUT RES, V2
   Shasidhar M, 2011, 2011 INT C COMM SYST
   Shehab L.H., 2020, Journal of King Saud University-Engineering Sciences, DOI 10.1016/j.jksues.2020.06.001
   Sheshadri HS, 2015, 2015 INT C EM RES EL
   Subramani T, 2019, BRAIN TUMOR SEGMENTA
   Sun LB, 2015, COMPUT STAT DATA AN, V84, P54, DOI 10.1016/j.csda.2014.11.007
   Thanh DNH, 2020, MULTIMED TOOLS APPL, V79, P21013, DOI 10.1007/s11042-020-08887-6
   Toprak Abdullah, 2006, J Med Syst, V30, P465, DOI 10.1007/s10916-006-9031-2
   Varuna Shree N, 2018, Brain Inform, V5, P23, DOI 10.1007/s40708-017-0075-5
   Vasanth K, 2020, J AMBIENT INTELL HUM, P1
   Verma S, 2013, P 3 INT C TRENDS INF
   Villar SA, 2017, J MATH IMAGING VIS, V58, P130, DOI 10.1007/s10851-016-0694-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong KP, 2005, TOP BIOMED ENGN, V2, P111
   Xie S.-y., 2009, 2009 INT JOINT C NEU
   Xu Y, 2007, NEUROCOMPUTING, V70, P1056, DOI 10.1016/j.neucom.2006.09.005
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
   Zhang YD, 2019, J MED IMAG HEALTH IN, V9, P2012, DOI 10.1166/jmihi.2019.2692
NR 81
TC 29
Z9 29
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11789
EP 11813
DI 10.1007/s11042-020-10351-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200003
DA 2024-07-18
ER

PT J
AU Sun, ZY
   Ye, JY
   Wang, TQ
   Jiang, L
   Li, Y
AF Sun, Zhiyong
   Ye, Junyong
   Wang, Tongqing
   Jiang, Li
   Li, Yang
TI Exploiting interaction of fine and coarse features and attribute
   co-occurrence for person attribute recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attribute recognition; Correlation feature; Intraperson attribute loss
AB Person attribute recognition, i.e., the prediction of a fixed set of semantic attributes given an image of a person, becomes an important topic in the field of computer vision. Recently, methods based on convolutional neural networks have shown outstanding performance in this area. They usually employ a CNN network to mine the shared feature representation followed by several layers for attribute classification. To improve the representation ability of the model, many methods element-add or concatenate coarse and fine feature maps to fuse information at different feature levels. However, these methods didn't fully exploit the interaction of multi-level convolutional feature maps for person attribute analysis and not consider the correlation of attributes for the same person. In this paper, we introduce a kind of correlation feature, which exploits the high order interaction of coarse and fine feature maps to capture the robust feature representation from multi-level convolution layers as the image representation for person attribute recognition. Moreover, we propose an intraperson attribute loss to explicitly model the correlation of attributes for the same person. We experiment our proposed model on CIFAR-10 dataset, Berkeley Human Attributes dataset, PA-100 K dataset, and experimental results show the better performance of the feature representation and the effectiveness of intra-person attribute loss.
C1 [Sun, Zhiyong; Ye, Junyong; Wang, Tongqing] Chongqing Univ, Minist Educ, Key Lab Optoelect Technol & Syst, Chongqing 400044, Peoples R China.
   [Jiang, Li] Yangtze Normal Univ, Sch Elect Informat Engn, Chongqing 408100, Peoples R China.
   [Li, Yang] Nanjing Pioneer Awareness Informat Technol Co Ltd, Nanjing 210019, Peoples R China.
C3 Chongqing University; Yangtze Normal University
RP Ye, JY (corresponding author), Chongqing Univ, Minist Educ, Key Lab Optoelect Technol & Syst, Chongqing 400044, Peoples R China.
EM 20100801016@cqu.edu.cn; ygyocr@cqu.edu.cn
RI wang, tong/HTR-5412-2023; junyong, ye/E-5576-2010
OI junyong, ye/0000-0001-8864-9987
CR [Anonymous], 2008, P 16 ACM INT C MULT, DOI [DOI 10.1145/1459359.1459470, DOI 10.1145/1459359.1459470.11.P]
   [Anonymous], 2018, ARXIV180809102
   [Anonymous], 2015, Neural Networks (IJCNN), 2015 International Joint Conference on
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Chen A, 2017, BASE PRETRAINED MODE
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Diba A, 2016, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR.2016.387
   Dong Q, 2017, IEEE WINT CONF APPL, P520, DOI 10.1109/WACV.2017.64
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2015.284
   Guo H, 2019, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2019.00082
   Guo H, 2017, PATTERN RECOGN LETT, V94, P38, DOI 10.1016/j.patrec.2017.05.012
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Honari S, 2016, PROC CVPR IEEE, P5743, DOI 10.1109/CVPR.2016.619
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Lee CY, 2018, IEEE T PATTERN ANAL, V40, P863, DOI 10.1109/TPAMI.2017.2703082
   Li DW, 2018, IEEE INT CON MULTI
   Li DW, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P111, DOI 10.1109/ACPR.2015.7486476
   Li YN, 2016, LECT NOTES COMPUT SC, V9910, P684, DOI 10.1007/978-3-319-46466-4_41
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu W., 2015, ARXIV150604579
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Mishkin D, 2015, ARXIV ABS151106422, P1
   Qin YX, 2020, IEEE T IND INFORM, V16, P6324, DOI 10.1109/TII.2019.2963434
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Sharma G., 2013, 2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI DOI 10.1109/CVPR.2013.90
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sudowe P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P329, DOI 10.1109/ICCVW.2015.51
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang J, 2017, IEEE I CONF COMP VIS, P2612, DOI [10.1109/ICCV.2017.283, 10.1109/ICCV.2017.65]
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang L., 2016, P BRIT MACHINE VISIO, DOI DOI 10.5244/C.30.81
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhao X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3177
   Zheng Liang, 2016, ARXIV
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
NR 46
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11887
EP 11902
DI 10.1007/s11042-020-10108-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200007
DA 2024-07-18
ER

PT J
AU Quintanar-Reséndiz, AL
   Rodríguez-Santos, F
   Pichardo-Méndez, JL
   Delgado-Gutiérrez, G
   Ramírez, OJ
   Vázquez-Medina, R
AF Quintanar-Resendiz, Ana L.
   Rodriguez-Santos, Francisco
   Pichardo-Mendez, Josue L.
   Delgado-Gutierrez, Guillermo
   Jimenez Ramirez, Omar
   Vazquez-Medina, Ruben
TI Capture device identification from digital images using Kullback-Leibler
   divergence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photographic cameras (07; 68; +m); Forensic science (89; 20; Mn); Image
   processing algorithms (07; 05; Pj); Statistical mechanics (05; 20; -y);
   Statistics (02; 50; -r)
ID PHOTO RESPONSE NONUNIFORMITY; SOURCE CAMERA IDENTIFICATION; INFORMATION;
   MODEL
AB It is proposed a forensic method for the capture device identification from digital images, which requires two elements: i) a digital image subject to controversy named disputed image and ii) a set of eligible capture devices with which the disputed image could have been shot. In order to define a device statistical fingerprint, a set of reference digital images is produced for each eligible capture device. The device statistical fingerprint is estimated averaging the statistical distribution of the photo response non-uniformity (PRNU) signal extracted from each set of reference digital images. Then, a comparison based on Kullback-Leibler divergence (KLD) is performed between the statistical fingerprint for each capture device and the statistical distribution of the PRNU signal extracted from the disputed image. Considering that KLD is a non-symmetric measure, the capture device, for which the smallest KLD has been estimated, will be chosen such as the one that shot the disputed image. The effectiveness of the proposed method was estimated by using a case study, which includes eight eligible capture devices, each of which shot thirty reference images and twenty disputed images. Then, the performance of the proposed method was like the performance of the methods that use peak-to-correlation energy as the discrimination criterion when they were applied to the case study. Finally, the proposed method offers two advantages; it reduces the processing time when the PRNU signal is extracted from digital image and it avoids the aberration produced by the lens into the PRNU signal.
C1 [Quintanar-Resendiz, Ana L.; Vazquez-Medina, Ruben] Inst Politecn Nacl, CICATA Queretaro, Cerro Blanco 141, Queretaro 76090, Mexico.
   [Rodriguez-Santos, Francisco; Pichardo-Mendez, Josue L.; Delgado-Gutierrez, Guillermo; Jimenez Ramirez, Omar] Inst Politecn Nacl, ESIME Unidad Culhuacan, Santa Ana 1000, Coyoacan 04430, Cdmx, Mexico.
C3 Instituto Politecnico Nacional - Mexico; Instituto Politecnico Nacional
   - Mexico
RP Vázquez-Medina, R (corresponding author), Inst Politecn Nacl, CICATA Queretaro, Cerro Blanco 141, Queretaro 76090, Mexico.
EM aquintanarr1600@alumno.ipn.mx; fcordz1@hotmail.com;
   josuelobsang@gmail.com; guidegu@gmail.com; ojimenezr@ipn.mx;
   ruvazquez@ipn.mx
RI VAZQUEZ-MEDINA, RUBEN/C-5081-2015; Quintanar Reséndiz, Ana
   Laura/ABE-1397-2021; Rodriguez-Santos, Francisco/ABE-1398-2021
OI VAZQUEZ-MEDINA, RUBEN/0000-0002-6210-4097; Quintanar Reséndiz, Ana
   Laura/0000-0003-2376-5949; Rodriguez-Santos,
   Francisco/0000-0002-6612-6250
FU Consejo Nacional de Ciencia y Tecnologia (CONACyT-Mexico) [CVU-746317,
   CVU-377075]; Instituto Politecnico Nacional (IPN-Mexico) [SIP-20210023,
   SIP-20210208]
FX This work was supported by the Consejo Nacional de Ciencia y Tecnologia
   (CONACyT-Mexico) [Grant numbers: CVU-746317 (A. L. Quintanar-Resendiz)
   and CVU-377075 (F. Rodriguez-Santos)] and the Instituto Politecnico
   Nacional (IPN-Mexico) [Grant number: SIP-20210023 (R. Vazquez-Medina)
   and SIP-20210208 (O. Jimenez-Ramirez)].
CR Al-Zarouni, 2006, AUSTR DIG FOR C P
   [Anonymous], 2006, Multimedia Security Technologies for Digital Rights, chapter Passive-Blind Image Forensics
   [Anonymous], 2009, IS TSPIE ELECT IMAGI
   Bayram S, 2008, DIGIT INVEST, V5, P49, DOI 10.1016/j.diin.2008.06.004
   Behare M. S., 2019, P IEEE 3 INT C EL CO, P731
   Ben Hamza A, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY - PROCEEDINGS, P257
   Ben-David A, 2015, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2015/06/051
   Bondi L, 2019, IEEE T INF FOREN SEC, V14, P608, DOI 10.1109/TIFS.2018.2859587
   Cha S.-H., 2007, Int. J. Math. Models Methods Appl. Sci., V1, P300
   Chen C, 2017, IEEE IMAGE PROC, P1512, DOI 10.1109/ICIP.2017.8296534
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen M, 2007, PROC SPIE, V6505, DOI 10.1117/12.703370
   Choi KS, 2006, OPT EXPRESS, V14, P11551, DOI 10.1364/OE.14.011551
   Choi KS, 2006, PROC SPIE, V6069, DOI 10.1117/12.649775
   Cooper AJ, 2013, FORENSIC SCI INT, V226, P132, DOI 10.1016/j.forsciint.2012.12.018
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Dang, 2006, SP 800 86 GUIDE INTE
   de la Republica S, 2019, GACETA LXIV1SPR 21 G
   Falkner, 2019, ISOLATING LENS EFFEC, V51, pS132
   Filler T, 2008, IEEE IMAGE PROC, P1296
   Fischer A, 2013, PROC SPIE, V8665, DOI 10.1117/12.2004348
   Fridrich, 2007, 2007 IEEE INT C IM P
   Fridrich J., 2013, Digital Image Forensics, P179
   Gilbert H, 2004, LECT NOTES COMPUT SC, V3006, P175
   Gisolf F, 2014, FORENSIC SCI INT, V244, P222, DOI 10.1016/j.forsciint.2014.08.034
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Goljan M, 2011, IEEE T INF FOREN SEC, V6, P227, DOI 10.1109/TIFS.2010.2099220
   Goljan M, 2009, LECT NOTES COMPUT SC, V5450, P454, DOI 10.1007/978-3-642-04438-0_38
   He Y, 2003, IEEE T SIGNAL PROCES, V51, P1211, DOI 10.1109/TSP.2003.810305
   Ji SP, 2021, IEEE T GEOSCI REMOTE, V59, P3816, DOI 10.1109/TGRS.2020.3020804
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Khader M, 2011, LECT NOTES COMPUT SC, V6636, P444, DOI 10.1007/978-3-642-21073-0_39
   Khader M, 2011, IEEE T INF TECHNOL B, V15, P681, DOI 10.1109/TITB.2011.2159806
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Kurosawa K., 1999, P 1999 INT C IM PROC, P537
   Law, 2019, AS PAC SIGN INF PROC, P2019
   Li BC, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21020189
   Li CT, 2012, IEEE T CIRC SYST VID, V22, P260, DOI 10.1109/TCSVT.2011.2160750
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Li RZ, 2018, PATTERN RECOGN, V74, P556, DOI 10.1016/j.patcog.2017.09.027
   Long M, 2019, MULTIMED TOOLS APPL, V78, P489, DOI 10.1007/s11042-017-5101-3
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Matthews R, 2019, DIGIT INVEST, V28, P139, DOI 10.1016/j.diin.2019.02.002
   Mehrish A, 2018, SIGNAL PROCESS-IMAGE, V66, P30, DOI 10.1016/j.image.2018.04.013
   Meij C, 2018, DIGIT INVEST, V24, P142, DOI 10.1016/j.diin.2018.02.005
   Moungla, 2020, 2020 INT WIR COMM MO
   NYCE, 2013, TECHN INF MET AN FOR
   Perez-Gonzalez, 2020, ARXIV ORG ELECT ENG
   Qiao T, 2017, SIGNAL PROCESS-IMAGE, V52, P74, DOI 10.1016/j.image.2016.12.011
   Qin JH, 2019, IEEE ACCESS, V7, P171372, DOI 10.1109/ACCESS.2019.2955452
   Roy A, 2017, IEEE COMPUT SOC CONF, P1848, DOI 10.1109/CVPRW.2017.231
   Saber A.H., 2020, Advances in Science, Technology and Engineering Systems Journal, V5, P361
   Saito S, 2017, IEEE T INF FOREN SEC, V12, P2026, DOI 10.1109/TIFS.2017.2692683
   Sencar HT, 2009, STAT SCI INTERDISC R, V3, P325
   Seshadri S, 2020, ADV INTELL SYST COMP, V944, P246, DOI 10.1007/978-3-030-17798-0_21
   Silva J, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P2299, DOI 10.1109/ISIT.2006.261977
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Thakur R, 2020, FORENSIC SCI INT, V312, DOI 10.1016/j.forsciint.2020.110311
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P250, DOI 10.1109/TIP.2013.2290596
   Thai TH, 2012, EUR SIGNAL PR CONF, P1747
   van Erven T, 2014, IEEE T INFORM THEORY, V60, P3797, DOI 10.1109/TIT.2014.2320500
   Van LT, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P883
   Van Lanh T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P16
   Vazquez-Medina R, 2008, THESIS UAM IZTAPALAP
   Vidyasagar M, 2010, IEEE DECIS CONTR P, P948, DOI 10.1109/CDC.2010.5716982
   Wang JW, 2019, J INF SECUR APPL, V44, P1, DOI 10.1016/j.jisa.2018.11.002
   Xu BC, 2016, NEUROCOMPUTING, V207, P131, DOI 10.1016/j.neucom.2016.05.012
   Yang S, 2020, IEEE CVF C COMP VIS, P2020
   Zeng H, 2020, IEEE ACCESS, V8, P18874, DOI 10.1109/ACCESS.2020.2968855
   Zhang WW, 2019, MULTIMED TOOLS APPL, V78, P20113, DOI 10.1007/s11042-019-7288-y
   Zhao YH, 2019, MULTIMED TOOLS APPL, V78, P8247, DOI 10.1007/s11042-018-6809-4
NR 72
TC 6
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19513
EP 19538
DI 10.1007/s11042-021-10653-1
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622668700004
DA 2024-07-18
ER

PT J
AU Singh, N
   Bhandari, AK
   Kumar, IV
AF Singh, Neha
   Bhandari, Ashish Kumar
   Kumar, Immadisetty Vinod
TI Fusion-based contextually selected 3D Otsu thresholding for image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-level segmentation; 1D; 2D; 3D Otsu; Image fusion; Local contrast;
   Image thresholding
ID PARTICLE SWARM OPTIMIZATION; ALGORITHM; ENTROPY; HISTOGRAM
AB Image segmentation is a method of subdividing an image into numerous meaningful regions or objects, which shows the image more informative for further analysis. Thresholding based methods are extensively used for image segmentation due to its easy implementation and low computational cost. However, histogram-based thresholding techniques are unable to deliberate three-dimensional contextual information of the image for optimum thresholds. In this paper, energy-curve is coupled with 3D Otsu function. Furthermore, in order to increase the quality of the processed image, a simple and effectual approach is proposed by using the concept of fusion, grounded on local contrast. The presentation of 3D Otsu algorithm is described to be poor when dealt with between-class variances over the aid of 3D histogram. To alleviate this limitation, the perception of the energy curve has been used to derive pixel intensity values and spatial information. Energy curve can help to recover the excellence of the thresholded image as it computes not only the value of the pixel but also its vicinity. The proposed energy based 3D Otsu with fusion (3D-Otsu Energy Fusion) method uses exhaustive search process to determine the optimal threshold values. The proposed technique produces better-processed results as compared to rest methods.
C1 [Singh, Neha; Bhandari, Ashish Kumar; Kumar, Immadisetty Vinod] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
EM nehasingh0910@gmail.com; bhandari.iiitj@gmail.com;
   vinodkumar9576@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019; Singh, Neha/JED-4558-2023
OI Bhandari, Ashish Kumar/0000-0001-9842-8125; Singh,
   Neha/0000-0001-7214-7392
CR Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   BHANDARI AK, 2019, IEEE T SYST MAN CYBE
   Bhandari AK, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106243
   Bhandari AK, 2020, IEEE T INSTRUM MEAS, V69, P1871, DOI 10.1109/TIM.2019.2922516
   Bhandari AK, 2020, IEEE-CAA J AUTOMATIC, V7, P200, DOI 10.1109/JAS.2019.1911843
   Bhandari AK, 2019, MULTIMED TOOLS APPL, V78, P35733, DOI 10.1007/s11042-019-08195-8
   Bhandari AK, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105570
   Chen Q, 2010, SIGNAL PROCESS, V90, P44, DOI 10.1016/j.sigpro.2009.05.015
   Chen XH, 2017, IET IMAGE PROCESS, V11, P860, DOI 10.1049/iet-ipr.2016.1070
   Cheriet M, 1998, IEEE T IMAGE PROCESS, V7, P918, DOI 10.1109/83.679444
   Deng G, 2009, IEEE T IMAGE PROCESS, V18, P1135, DOI 10.1109/TIP.2009.2016796
   Feng YC, 2017, DIGIT SIGNAL PROCESS, V60, P186, DOI 10.1016/j.dsp.2016.08.003
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   Hao D, 2017, SIGNAL IMAGE VIDEO P, V11, P1411, DOI 10.1007/s11760-017-1101-z
   Jing Xiao-jun, 2003, Acta Electronica Sinica, V31, P1281
   JOURLIN M, 1989, J MICROSC-OXFORD, V156, P33, DOI 10.1111/j.1365-2818.1989.tb02904.x
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Mozaffari MH, 2017, IET IMAGE PROCESS, V11, P605, DOI 10.1049/iet-ipr.2016.0489
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   Oliver DL, 2018, SPRINGER HANDB AUDIT, V65, P1, DOI 10.1007/978-3-319-71798-2_1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2016, APPL SOFT COMPUT, V47, P76, DOI 10.1016/j.asoc.2016.05.040
   Pare S, 2019, IEEE-CAA J AUTOMATIC, V6, P1471, DOI 10.1109/JAS.2017.7510697
   Sarkar S, 2013, IEEE T IMAGE PROCESS, V22, P4788, DOI 10.1109/TIP.2013.2277832
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sha CS, 2016, J VIS COMMUN IMAGE R, V41, P339, DOI 10.1016/j.jvcir.2016.10.013
   Sthitpattanapongsa P, 2011, LECT NOTES COMPUT SC, V7087, P358
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xue JH, 2011, IEEE T IMAGE PROCESS, V20, P2392, DOI 10.1109/TIP.2011.2114358
   Zhang J, 2008, 2008 INTERNATIONAL MULTISYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS), P102, DOI 10.1109/IMSCCS.2008.14
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou DG, 2016, IET IMAGE PROCESS, V10, P608, DOI 10.1049/iet-ipr.2015.0773
NR 37
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19399
EP 19420
DI 10.1007/s11042-021-10706-5
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622245500003
DA 2024-07-18
ER

PT J
AU Maqsood, R
   Bajwa, UI
   Saleem, G
   Raza, RH
   Anwar, MW
AF Maqsood, Ramna
   Bajwa, Usama Ijaz
   Saleem, Gulshan
   Raza, Rana Hammad
   Anwar, Muhammad Waqas
TI Anomaly recognition from surveillance videos using 3D convolution neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomalous activity recognition; 3DConvNets; Spatial augmentation;
   Spatial annotation
AB Anomalous activity recognition deals with identifying the patterns and events that vary from the normal stream. In a surveillance paradigm, these events range from abuse to fighting and road accidents to snatching, etc. Due to the sparse occurrence of anomalous events, anomalous activity recognition from surveillance videos is a challenging research task. The approaches reported can be generally categorized as handcrafted and deep learning-based. Most of the reported studies address binary classification i.e. anomaly detection from surveillance videos. But these reported approaches did not address other anomalous events e.g. abuse, fight, road accidents, shooting, stealing, vandalism, and robbery, etc. from surveillance videos. Therefore, this paper aims to provide an effective framework for the recognition of different real-world anomalies from videos. This study provides a simple, yet effective approach for learning spatiotemporal features using deep 3-dimensional convolutional networks (3D ConvNets) trained on the University of Central Florida (UCF) Crime video dataset. Firstly, the frame-level labels of the UCF Crime dataset are provided, and then to extract anomalous spatiotemporal features more efficiently a fine-tuned 3D ConvNets is proposed. Findings of the proposed study are twofold 1) There exist specific, detectable, and quantifiable features in UCF Crime video feed that associate with each other 2) Multiclass learning can improve generalizing competencies of the 3D ConvNets by effectively learning frame-level information of dataset and can be leveraged in terms of better results by applying spatial augmentation. The proposed study extracted 3D features by providing frame level information and spatial augmentation to a fine-tuned pre-trained model, namely 3DConvNets. Besides, the learned features are compact enough and the proposed approach outperforms significantly from state of art approaches in terms of accuracy on anomalous activity recognition having 82% AUC.
C1 [Maqsood, Ramna; Bajwa, Usama Ijaz; Saleem, Gulshan; Anwar, Muhammad Waqas] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 KM Def Rd Off Raiwind Rd, Lahore, Pakistan.
   [Raza, Rana Hammad] Natl Univ Sci & Technol NUST NUST PNEC, Habib Ibrahim Rehmatullah Rd, Sindh, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Bajwa, UI (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 KM Def Rd Off Raiwind Rd, Lahore, Pakistan.
EM usamabajwa@cuilahore.edu.pk
RI Anwar, Muhammad Naseem/IAM-7949-2023
OI Anwar, Muhammad Naseem/0000-0002-4759-0656; Bajwa,
   Usama/0000-0001-5755-1194; Anwar, Muhammad Waqas/0000-0002-7822-8983
FU National Center of Big Data and Cloud Computing (NCBC); HEC of Pakistan
FX We acknowledge partial support from the National Center of Big Data and
   Cloud Computing (NCBC) and HEC of Pakistan for conducting this research.
CR Alun CF, 2019, PILOT STUDY DETECTIN
   Andrei Z, 2020, ANOMALOUS BEHAV DATA
   Bansod S, 2019, J INTELL FUZZY SYST, V36, P1967, DOI 10.3233/JIFS-169908
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cui XD, 2015, IEEE-ACM T AUDIO SPE, V23, P1469, DOI 10.1109/TASLP.2015.2438544
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Farooq MU, 2017, INT J ADV COMPUT SC, V8, P270
   Gao HB, 2018, IEEE T IND INFORM, V14, P4224, DOI 10.1109/TII.2018.2822828
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Huynh-The T, 2020, IEEE T IND INFORM, V16, P3100, DOI 10.1109/TII.2019.2910876
   Jamadandi Adarsh, 2020, Smart Computing Paradigms: New Progresses and Challenges. Proceedings of ICACNI 2018. Advances in Intelligent Systems and Computing (AISC 766), P41, DOI 10.1007/978-981-13-9683-0_5
   Kim B, 2018, INT J FUZZY LOG INTE, V18, P245, DOI 10.5391/IJFIS.2018.18.4.245
   Koppikar U., 2019, INT C INT COMP COMM, P333
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li ZY, 2020, IEEE ACCESS, V8, P25531, DOI 10.1109/ACCESS.2020.2970497
   Luo HB, 2018, AUTOMAT CONSTR, V94, P282, DOI 10.1016/j.autcon.2018.06.007
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mohammadi S, 2015, 2015 12TH INTERNATIONAL IRANIAN SOCIETY OF CRYPTOLOGY CONFERENCE ON INFORMATION SECURITY AND CRYPTOLOGY (ISCISC), P6, DOI 10.1109/ISCISC.2015.7387890
   Narkhede Sarang, 2018, Towards Data Science, V26, P220
   Newsam S, 2019, VIS C BMVC
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Shah AK, 2018, POLITICS OF FINANCIAL RISK, AUDIT AND REGULATION: A CASE STUDY OF HBOS, P1, DOI 10.1109/ISCAS.2018.8351359
   Sigurdsson GA, 2017, IEEE I CONF COMP VIS, P2156, DOI 10.1109/ICCV.2017.235
   Singh D, 2019, IEEE T INTELL TRANSP, V20, P879, DOI 10.1109/TITS.2018.2835308
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   SVCL, 2013, UCSD ANOMALY DETECTI
   Tian YC, 2019, IEEE T PATTERN ANAL, V41, P2146, DOI 10.1109/TPAMI.2018.2849374
   Um T. T., 2017, P 19 ACM INT C MULTI, P216, DOI DOI 10.1145/3136755.3136817
   University of Central Florida, 2020, ABNORMAL CROWD BEHAV
   University of Central Florida, 2011, REAL WORLD ANOMALY D
   Varghese Elizabeth B., 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P296, DOI 10.1007/978-3-030-04375-9_25
   Vishnu VCM, 2018, CLUSTER COMPUT, V21, P135, DOI 10.1007/s10586-017-0974-5
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Yu S, 2017, MULTIMED TOOLS APPL, V76, P13367, DOI 10.1007/s11042-016-3768-5
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
   Zhango W., 2010, IEEE ACCESS REMOTE S, V8, P48451
NR 42
TC 29
Z9 32
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18693
EP 18716
DI 10.1007/s11042-021-10570-3
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425100001
DA 2024-07-18
ER

PT J
AU Saktheeswari, M
   Balasubramanian, T
AF Saktheeswari, M.
   Balasubramanian, T.
TI Multi-layer tree liquid state machine recurrent auto encoder for thyroid
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Liquid state machine; Spiking neural network; Auto encoder; Multi class
   imbalance data
AB The proposed work presents thyroid detection strategy by addressing the various challenges faced when raw data is applied to complex neural network like structure. The authors present a Multi-Layer Tree Liquid State Machine Recurrent Auto encoder for the detection of the thyroid nodules. The tree based architecture prevents the loss of original information from dataset when applied to machine learning models like neural network. Liquid State Machine (LSM) prevents the loss of temporal feature of the data from the dataset. The multi layered architecture of the proposed system helps to classify the thyroid stage accurately. The classification rate of the proposed strategy increased when compared to other techniques where the aspect of dataset is not considered.
C1 [Saktheeswari, M.] Dept Comp Sci & Applicat, Uthangarai, Tamil Nadu, India.
   [Saktheeswari, M.] Periyar Univ, Dept Comp Sci, Salem 636011 11, Tamil Nadu, India.
   [Balasubramanian, T.] Sri Vidya Mandir Arts & Sci Coll, Dept Comp Sci & Applicat, Uthangarai, Tamil Nadu, India.
C3 Periyar University
RP Saktheeswari, M (corresponding author), Dept Comp Sci & Applicat, Uthangarai, Tamil Nadu, India.; Saktheeswari, M (corresponding author), Periyar Univ, Dept Comp Sci, Salem 636011 11, Tamil Nadu, India.
EM saktheeswarisvmc5@gmail.com
RI Balasubramanian, T/AIC-9723-2022
OI Balasubramanian, T/0000-0002-5325-6953
CR Ahmad W, 2018, SOFT COMPUT, V22, P5377, DOI 10.1007/s00500-018-3045-9
   Baccour L, 2018, EXPERT SYST APPL, V99, P115, DOI 10.1016/j.eswa.2018.01.025
   Chandel Khushboo, 2016, CSI Transactions on ICT, V4, P313, DOI 10.1007/s40012-016-0100-5
   Chandra Shekar K., 2019, Innovations in Computer Science and Engineering. Proceedings of the Sixth ICICSE 2018. Lecture Notes in Networks and Systems (LNNS 74), P9, DOI 10.1007/978-981-13-7082-3_2
   Gallicchio C, 2013, NEUROCOMPUTING, V101, P319, DOI 10.1016/j.neucom.2012.08.017
   Hayashi Y, 2017, KNOWL-BASED SYST, V131, P170, DOI 10.1016/j.knosys.2017.06.011
   Kheradpisheh S. R., 2018, CORR
   Kongsorot Y, 2019, INT J MACH LEARN CYB, V10, P979, DOI 10.1007/s13042-017-0776-3
   Kulkarni S, 2013, APPL SOFT COMPUT, V13, P3628, DOI 10.1016/j.asoc.2013.04.007
   Li LN, 2012, J MED SYST, V36, P3327, DOI 10.1007/s10916-012-9825-3
   Mahajan P., 2014, ADV COMM COMP TECHN, P1, DOI DOI 10.1109/EIC.2015.7230721
   Maysanjaya IMD, 2015, 2015 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA), P89, DOI 10.1109/ISITIA.2015.7219959
   Mohamad S, 2018, NEURAL NETWORKS, V98, P1, DOI 10.1016/j.neunet.2017.10.004
   Parry Z, 2017, ANAEST INTENS CARE M, V18, P488
   Pineda J. J., 2019, ENDOCRINOLOGIA DIABE
   Poudel P, 2019, IEEE ACCESS, V7, P79354, DOI 10.1109/ACCESS.2019.2923547
   Raghuwanshi BS, 2018, APPL SOFT COMPUT, V73, P1026, DOI 10.1016/j.asoc.2018.10.011
   Raisinghani S, 2019, INT C ADV COMP DAT S, P140, DOI DOI 10.1007/978-981-13-9939-8_13
   Rajole BN, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P202, DOI 10.1109/ICECA.2017.8203671
   Selvathi D., 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P836, DOI 10.1109/ICSCCN.2011.6024666
   Shankar K, 2020, J AMB INTEL HUM COMP, V11, P1821, DOI 10.1007/s12652-018-1161-0
   Sollini M, 2018, EUR J RADIOL, V99, P1, DOI 10.1016/j.ejrad.2017.12.004
   Tahir MAU, 2019, IEEE ACCESS, V7, P71013, DOI 10.1109/ACCESS.2019.2915611
   Tama BA, 2019, ARTIF INTELL REV, V51, P355, DOI 10.1007/s10462-017-9565-3
   Tanveer M, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105617
   Zhang XY, 2015, APPL INTELL, V42, P544, DOI 10.1007/s10489-014-0610-5
NR 26
TC 7
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17773
EP 17783
DI 10.1007/s11042-020-10243-7
EA FEB 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617417600002
DA 2024-07-18
ER

PT J
AU Shrestha, G
   Alsadoon, A
   Prasad, PWC
   Al-Dala'in, T
   Alrubaie, A
AF Shrestha, Ganesh
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Dala'in, Thair
   Alrubaie, Ahmad
TI A novel enhanced energy function using augmented reality for a bowel:
   modified region and weighted factor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Visualization; Computer-aided diagnosis; Gastroscopy;
   Colonoscopy
AB The popularity of augmented reality in medical application is rising exponentially over time, especially in the medical sector. It possesses a greater possibility in the reduction of surgical risks by raising visual awareness during the operation. Incorrect representation or inadequate detail on target region or delay in processing time may result in serious consequences. Also, the absence of a proper mechanism to handle occlusions like nerves, vessels or medical equipment may affect the performance. Therefore, this research aims to improve the visualization accuracy of bowel region and reduce the processing time. a novel enhanced energy function using augmented reality for bowel is proposed. The proposed system targets the modified region and weighted factor that encompasses the power of the combined region and dense cue with longterm and accurate augmented reality display mechanism. The system is capable of providing detailed visual output by precisely placing the model developed using the CT images of the target object, over the live video. Also, by applying the least square approach, the system is capable of addressing larger deformation and occlusion that appears during the surgical procedure providing the most accurate display. The feature tracking and tracking recovery components help the entire visualization procedure to stay on track by automatically registering and re-registering the surface whenever required. The proposed system capable of running image registration without human involvement and it can even decide when to trigger the reregistration process whenever required. The results from the proposed system has minimized the overlay error by a larger number. We validated the system with different sets of samples from endoscopy. The dataset included the samples from the bowel region from people with three different age groups. The overlay error accuracy was 0.24777px, and the performance was 44fps. The proposed system is concentrated on the overlay accuracy and the processing time. This study has addressed the shortcoming of the previous systems regarding manual registration and rigid assumptions.
C1 [Shrestha, Ganesh; Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; University of New South Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Bergen T, 2016, IEEE J BIOMED HEALTH, V20, P304, DOI 10.1109/JBHI.2014.2384134
   Carl B, 2019, ACTA NEUROCHIR, V161, P2181, DOI 10.1007/s00701-019-04005-0
   Chen F, 2017, IEEE T MED IMAGING, V36, P685, DOI 10.1109/TMI.2016.2635673
   Chen L, 2018, COMPUT METH PROG BIO, V158, P135, DOI 10.1016/j.cmpb.2018.02.006
   Chu YK, 2018, BIOMED OPT EXPRESS, V9, P5205, DOI 10.1364/BOE.9.005205
   Deib G, 2018, J NEUROINTERV SURG, V10, P1187, DOI 10.1136/neurintsurg-2017-013649
   Eccles Cynthia L, 2016, Adv Radiat Oncol, V1, P43, DOI 10.1016/j.adro.2016.01.001
   Edgcumbe P, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.021216
   Gao QH, 2019, MULTIMED TOOLS APPL, V78, P15079, DOI 10.1007/s11042-018-6905-5
   Hanna MG, 2018, ARCH PATHOL LAB MED, V142, P638, DOI 10.5858/arpa.2017-0189-OA
   Kahl F, 2011, IEEE I CONF COMP VIS, P255, DOI 10.1109/ICCV.2011.6126250
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kolmogorov V, 2015, IEEE T PATTERN ANAL, V37, P919, DOI 10.1109/TPAMI.2014.2363465
   Kosterhon M, 2017, OPER NEUROSURG, V13, P297, DOI 10.1093/ons/opw017
   Lawonn K, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13322
   Lee D, 2018, ANN SURG TREAT RES, V95, P297, DOI 10.4174/astr.2018.95.6.297
   Liu J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219174
   Pepe A, 2019, J DIGIT IMAGING, V32, P1008, DOI 10.1007/s10278-019-00272-6
   Peterlík I, 2018, MED IMAGE ANAL, V45, P24, DOI 10.1016/j.media.2017.12.006
   Puerto-Souza GA, 2013, IEEE INT CONF ROBOT, P5384, DOI 10.1109/ICRA.2013.6631349
   Randhawa S, 2021, MULTIMED TOOLS APPL, V80, P4729, DOI 10.1007/s11042-020-09900-8
   Shen JB, 2017, IEEE T IMAGE PROCESS, V26, P4911, DOI 10.1109/TIP.2017.2722691
   Shen JB, 2014, IEEE T CIRC SYST VID, V24, P1088, DOI 10.1109/TCSVT.2014.2302545
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Wang JC, 2014, IEEE T BIO-MED ENG, V61, P1295, DOI 10.1109/TBME.2014.2301191
   Wang R, 2018, IEEE J BIOMED HEALTH, V22, P1540, DOI 10.1109/JBHI.2017.2770214
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
NR 27
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17893
EP 17922
DI 10.1007/s11042-021-10606-8
EA FEB 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617415000008
DA 2024-07-18
ER

PT J
AU Solmaz, S
   Van Gerven, T
AF Solmaz, Serkan
   Van Gerven, Tom
TI Automated integration of extract-based CFD results with AR/VR in
   engineering education for practitioners
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational fluid dynamics; Virtual reality; Augmented reality;
   Engineering education; System architecture; Scientific visualization
ID INTERACTIVE FLOW SIMULATION; AUGMENTED REALITY; VISUALIZATION; DYNAMICS;
   ENVIRONMENT; TECHNOLOGY; PLATFORM; FIRE
AB Computational fluid dynamics (CFD) simulations can provide meaningful technical content in engineering education, broad engineering and business. However, computationally demanding data production and complex data processing environments of CFD simulations turn them into esoteric tools for potential non-expert users. This consequently limits applications and communications of CFD simulations and results. Augmented and virtual reality (AR/VR) technologies are opening new gates for visualization and interaction techniques. Despite the many recent attempts, the literature lacks an inclusive system development procedure for CFD simulations with AR/VR. The present study proposes a component-oriented system architecture to generate dedicated workflows for any kind of AR/VR environment supported by CFD simulations. The study further explores the potential of data processing options throughout the preparation of the simulation dataset with AR/VR. An automated data coupling strategy is additionally introduced to ease multiplatform integration. We provide an integration strategy with simple, easy-to-implement, end-to-end, automated and free-to-use utilities that the practitioners can readily pursue.
C1 [Solmaz, Serkan; Van Gerven, Tom] Katholieke Univ Leuven, Dept Chem Engn, Celestijnenlaan 200F, B-3001 Leuven, Belgium.
C3 KU Leuven
RP Van Gerven, T (corresponding author), Katholieke Univ Leuven, Dept Chem Engn, Celestijnenlaan 200F, B-3001 Leuven, Belgium.
EM tom.vangerven@kuleuven.be
RI ; Van Gerven, Tom/B-5806-2015
OI Solmaz, Serkan/0000-0001-5431-4038; Van Gerven, Tom/0000-0003-2051-5696
FU European Union's EU Framework Programme for Research and Innovation
   Horizon 2020 [812716]; Marie Curie Actions (MSCA) [812716] Funding
   Source: Marie Curie Actions (MSCA)
FX This project has received funding from the European Union's EU Framework
   Programme for Research and Innovation Horizon 2020 under Grant Agreement
   812716. This publication reflects only the author's view exempting the
   community from any liability. Project website: https://charming-etn.eu/.
CR Badías A, 2019, INT J NUMER METH ENG, V120, P125, DOI 10.1002/nme.6127
   Berger M, 2015, PROCEDIA COMPUT SCI, V51, P2913, DOI 10.1016/j.procs.2015.05.476
   Bergonzi L, 2019, Comput Aided Des Appl, V16, P1195, DOI [10.14733/cadaps.2019.1195-1208, DOI 10.14733/CADAPS.2019.1195-1208]
   Blach R, 1998, FUTURE GENER COMP SY, V14, P167, DOI 10.1016/S0167-739X(98)00019-3
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   DeAngelis E., 2019, EUR C COMP CONSTR JU, P435, DOI DOI 10.35490/EC3.2019.142
   Dong SY, 2013, ADV ENG SOFTW, V55, P45, DOI 10.1016/j.advengsoft.2012.09.001
   Duque EP., 2016, 54 AIAA AER SCI M SA
   El Beheiry M, 2019, J MOL BIOL, V431, P1315, DOI 10.1016/j.jmb.2019.01.033
   Fukuda T, 2019, J COMPUT DES ENG, V6, P179, DOI 10.1016/j.jcde.2018.05.007
   García-Hernández RJ, 2019, COMPUT PHYS COMMUN, V237, P230, DOI 10.1016/j.cpc.2018.11.013
   Ge W, 2019, COMPUT CHEM ENG, V126, P68, DOI 10.1016/j.compchemeng.2019.03.042
   Gianni D., 2014, Modeling and Simulation-Based Systems Engineering Handbook
   Grabmaier S., 2017, P 2017 COSMOL C ROTT
   Ham Y, 2013, ENERG BUILDINGS, V63, P15, DOI 10.1016/j.enbuild.2013.02.054
   Hamilton ER, 2016, TECHTRENDS, V60, P433, DOI 10.1007/s11528-016-0091-y
   Harwood ARG, 2019, ADV ENG SOFTW, V133, P39, DOI 10.1016/j.advengsoft.2019.04.003
   Harwood ARG, 2018, ADV ENG SOFTW, V115, P363, DOI 10.1016/j.advengsoft.2017.10.005
   Harwood ARG, 2017, ADV ENG SOFTW, V104, P38, DOI 10.1016/j.advengsoft.2016.11.005
   He ZW, 2019, IEEE ACCESS, V7, P22532, DOI 10.1109/ACCESS.2019.2893919
   Horton BK, 2019, SOFTWAREX, V9, P112, DOI 10.1016/j.softx.2019.01.009
   Huang JM, 2019, COMPUT APPL ENG EDUC, V27, P921, DOI 10.1002/cae.22125
   Huang ZP, 2014, MULTIMED TOOLS APPL, V71, P1283, DOI 10.1007/s11042-012-1273-z
   Inoue T, 2018, 9 INT C COMP METH IC
   Julin A, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8050221
   Jung K, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9020075
   Karmonik C, 2018, J DIGIT IMAGING, V31, P26, DOI 10.1007/s10278-017-9991-4
   Kim M, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10051362
   Kim RW, 2019, BIOSYST ENG, V188, P243, DOI 10.1016/j.biosystemseng.2019.10.024
   Kirby A., 2018 AIAA AEROSPACE, DOI DOI 10.2514/6.2018-1171
   Lai JWM, 2019, COMPUT EDUC, V133, P27, DOI 10.1016/j.compedu.2019.01.010
   Lau K-K, 2017, An introduction to component-based software development, DOI [10.1142/10486, DOI 10.1142/10486]
   Lemahieu W, 2018, Principles of Database Management: The Practical Guide to Storing, Managing and Analyzing Big and Small Data, DOI [10.1017/9781316888773, DOI 10.1017/9781316888773]
   Li JH, 2015, CHEM ENG J, V278, P541, DOI 10.1016/j.cej.2014.10.005
   Li Wenkai., 2017, Multimodal Technol Inter, V1, P17, DOI [DOI 10.3390/MTI1030017, 10.3390/mti1030017]
   Lin JR, 2019, AUTOMAT CONSTR, V103, P26, DOI 10.1016/j.autcon.2019.02.007
   Martin PG, 2019, SPRINGER THESES-RECO, P251, DOI [10.1109/EXPAT.2019.8876516, 10.1007/978-3-030-17191-9_10]
   Moloney J, 2020, ARCHIT SCI REV, V63, P441, DOI 10.1080/00038628.2019.1675138
   Natephra W, 2017, BUILD ENVIRON, V124, P194, DOI 10.1016/j.buildenv.2017.08.004
   Quam DJ, 2015, J BIOMECH ENG-T ASME, V137, DOI 10.1115/1.4029017
   Salehi V., 2019, Comput. Aided. Des. Appl, V16, P243, DOI [10.14733/cadaps.2019.243-255, DOI 10.14733/CADAPS.2019.243-255]
   Sastry L., 1998, Virtual Reality, V3, P235, DOI 10.1007/BF01408704
   Schilling A., 2016, INT C WEB3D TECHN, P109
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Slotnick J, 2013, CFD Vision 2030 Study: a Path to Revolutionary Computational Aerosciences
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Su SM, 2020, COMPUT SCI ENG, V22, P27, DOI 10.1109/MCSE.2020.2971188
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Tamura Y, 2016, PLASMA FUSION RES, V11, DOI 10.1585/pfr.11.2406060
   Wasfy TM, 2001, ADV ENG SOFTW, V32, P717, DOI 10.1016/S0965-9978(01)00020-5
   Wheeler G, 2018, HEALTHC TECHNOL LETT, V5, P148, DOI 10.1049/htl.2018.5064
   Woods J. W., 2006, MULTIDIMENSIONAL SIG
   Xu Z, 2014, ADV ENG SOFTW, V68, P1, DOI 10.1016/j.advengsoft.2013.10.004
   Xu Z, 2020, AUTOMAT CONSTR, V109, DOI 10.1016/j.autcon.2019.102995
   Yan JY, 2020, BUILDINGS-BASEL, V10, DOI 10.3390/buildings10120229
   Yu Y, 2017, SHIPS OFFSHORE STRUC, V12, P873, DOI 10.1080/17445302.2017.1293762
   Zhang FQ, 2020, MULTIMED TOOLS APPL, V79, P16683, DOI 10.1007/s11042-019-08002-4
   Zhao SL, 2019, J HYDROINFORM, V21, P671, DOI 10.2166/hydro.2019.101
   Zhao Y, 2018, P 23 CAADRIA C LEARN, P369
   Zhu YH, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8010004
NR 61
TC 12
Z9 12
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14869
EP 14891
DI 10.1007/s11042-021-10621-9
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000614681600002
DA 2024-07-18
ER

PT J
AU Hemdan, EE
   Manjaiah, DH
AF Hemdan, Ezz El-Din
   Manjaiah, D. H.
TI An efficient digital forensic model for cybercrimes investigation in
   cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Cybercrimes; Digital forensics; Cloud forensics; And VM
   snapshot
AB In recent times, cloud computing adopted numerous organizations and enterprises for offering services with securely certifying that cloud providers against illegitimate activities. However, cost-effective forensics design and implementation for support the cloud-based cybercrimes investigation. To build cloud architecture support forensics is a significant and complex issue such as voluminous intricate legal, organizational, and technical defies due to the virtualization, distributing, and dynamic nature of cloud systems. Therefore, this paper presents an efficient Cloud Forensics Investigation Model (CFIM) to investigate cloud crimes in a forensically sound and timely fashion. Besides, the proposed system supports the concept of Forensic as a Service (FaaS) that provide innumerable benefits of conducting digital forensics through using Forensic Server on the cloud side. The investigational results proved that the proposed system can assist the digital investigators in their mission of investigation of cybercrimes in the cloud in a proficient manner.
C1 [Hemdan, Ezz El-Din] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
   [Manjaiah, D. H.] Mangalore Univ, Dept Comp Sci, Mangalore, India.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Mangalore University
RP Hemdan, EE (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
EM ezzvip@yahoo.com; manju@mangaloreuniversity.ac.in
CR Alqahtany S, 2016, CLUSTER COMPUT, V19, P439, DOI 10.1007/s10586-015-0509-x
   [Anonymous], 2015, CLOUD COMP CLOUD 201
   Barrett Diane, 2010, Syngress
   Chen, 2014, MATH PROBL ENG, V2014, P1
   DYKSTRA J., 2011, J NETWORK FORENSICS, V3, P19
   Dykstra J, 2013, DIGIT INVEST, V10, pS87, DOI 10.1016/j.diin.2013.06.010
   Grance, 2014, DRAFT NISTIR
   Hemdan E-D., 2018, CFIM BUILDING NEW CL, P545
   Hemdan EE-D., 2015, INT J INNOVATIVE RES, V3, P1
   Hirwani, 2012, P INT C SEC MAN SAM
   Jeong, 2015, J APPL MATH
   Kebande VR, 2014, INT C DIG SEC FOR DI
   Liu SQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4892
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Manjaiah, 2015, P 1 INT C COMP COMM
   Manjaiah, 2017, 2017 INT C CIRC POW
   Olivier, 2011, INFORM COMPUTER SECU
   Povar D, 2014, COMM COM INF SC, V467, P341
   Rani DR, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Ruan K., 2011, ADV DIGITAL FORENSIC, VVII, P35
   Ruan KY, 2013, DIGIT INVEST, V10, P34, DOI 10.1016/j.diin.2013.02.004
   Server VMware, 2008, U VMR CONTR VIRT MAC
   Sherman A., 2012, ACQUIRING FORENSIC E
   Simou S, 2015, RISKS SECURITY INTER, P177
   Xu Q, 2013, MATH PROBL ENG, V2013
   Xu QZ, 2019, CLUSTER COMPUT, V22, pS2731, DOI 10.1007/s10586-017-1436-9
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Zafarullah Z., 2011, Proceedings of the 2011 Frontiers of Information Technology (FIT 2011), P110, DOI 10.1109/FIT.2011.28
NR 28
TC 7
Z9 7
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14255
EP 14282
DI 10.1007/s11042-020-10358-x
EA JAN 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400004
DA 2024-07-18
ER

PT J
AU Shang, JX
   Guan, HP
   Liu, Y
   Bi, HB
   Yang, LN
   Wang, MH
AF Shang, Jinxia
   Guan, Hua-Ping
   Liu, Yun
   Bi, Hongbo
   Yang, Lina
   Wang, Minghui
TI A novel method for vehicle headlights detection using salient region
   segmentation and PHOG feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle headlight detection; Local saliency detection; ROI segmenting;
   SVM classifier
ID OBJECT DETECTION; HISTOGRAMS; COLOR
AB In this paper, we explore an issue that is to detect vehicle headlights from the nighttime traffic surveillance images with highly reflections. In the night, reflections on the road (water) surface, vehicles bodies, or some reflective objects (such as lane markings, traffic signs) will interfere the headlight detection seriously. Although the existing methods have achieved good results, however, most of them failed to detect the headlight when headlights are far from camera. In order to solve the issue, we propose a novel method for vehicle headlights detection. The proposed method makes full use of the brightness and gradient information of the headlights in the night. First, we propose an effective region-of-interest (ROI) segmentation method which is based on multi-scale local saliency detection. The method pre-serve faint or small-sized objects and retain the original shape of the object to the greatest extent. Then, we compute the pyramid histogram of oriented gradients (PHOG) features, which are used to train support vector machine (SVM) classifier. Finally, the extracted bright blocks are classified according to the pre-trained SVM classifier. Experimental results and quantitative evaluations in different scenes demonstrate that our proposed method can achieve a better result compared with previous methods.
C1 [Shang, Jinxia; Wang, Minghui] Sichuan Univ, Coll Comp Sci, Chengdu, Peoples R China.
   [Guan, Hua-Ping] Fujian Normal Univ, Fuzhou, Peoples R China.
   [Liu, Yun] Southwest Univ, Coll Artificial Intelligence, Chongqing, Peoples R China.
   [Bi, Hongbo; Yang, Lina] Northeast Petr Univ, Daqing, Heilongjiang, Peoples R China.
C3 Sichuan University; Fujian Normal University; Southwest University -
   China; Northeast Petroleum University
RP Yang, LN (corresponding author), Northeast Petr Univ, Daqing, Heilongjiang, Peoples R China.
EM shangjinxia@126.com; 80552102@qq.com; jsjliuyun@gmail.com;
   bhbdq@126.com; 2567598474@qq.com; wangminghui_papers@163.com
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Adeloye D, 2014, 2013 MOTOR VEHICLE C
   Alcantarilla PF, 2008, IEEE INT VEH SYM, P104
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2016, IEEE INTELL SYST
   [Anonymous], 2014, BMVC
   [Anonymous], 2017, IEEE T INTELL TRANSP
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arróspide J, 2013, IEEE T IMAGE PROCESS, V22, P2286, DOI 10.1109/TIP.2013.2249080
   Berger Ivo, 2018, COMPUTER SECURITY ES, P85, DOI 10.1007/978-3-030-12786-2_6
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Chen JZ, 2019, J VIS COMMUN IMAGE R, V60, P149, DOI 10.1016/j.jvcir.2019.02.026
   Chen JZ, 2018, J VIS COMMUN IMAGE R, V50, P270, DOI 10.1016/j.jvcir.2017.12.006
   Chen L., 2017, IEEE T INTELL TRANSP, V99, P1
   Chen YL, 2011, IEEE T IND ELECTRON, V58, P2030, DOI 10.1109/TIE.2010.2055771
   Chun-Ping GE, 2012, VALUE ENG
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Fan D. P., 2018, PROC CVPR IEEE
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   FANG Zi-wen, 1999, ACTA ARMAMENTARH, V20, P255
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Geng L, 2016, J T SYST ENG INFORM
   Hajimolahoseini H, 2014, IET COMPUT VIS, V8, P535, DOI 10.1049/iet-cvi.2013.0267
   Jazayeri A, 2011, IEEE T INTELL TRANSP, V12, P583, DOI 10.1109/TITS.2011.2113340
   Jung m, 2013, EFFECTIVE METHOD HEA, V126, P384
   Kosaka N, 2015, IEEE T INTELL TRANSP, V16, P2599, DOI 10.1109/TITS.2015.2413971
   Laugier C, 2000, COLOR MODELING SPHER
   Lee I, 2002, INT CONF ACOUST SPEE, P3712
   Li P, 2019, SALIENCY DETECTION V
   Liu Y., 2018, DNA DEEPLY SUPERVISE, V1, P13
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Piccardi M, 1999, VEHICLE DETECTION DA
   Robert K, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P1, DOI 10.1109/AVSS.2009.98
   TAKTAK R, 1994, IEEE IMAGE PROC, P296, DOI 10.1109/ICIP.1994.413579
   Tang C, 2017, INT S INT TRANSP SMA
   Tian B, 2017, IEEE T INTELL TRANSP
   Tsai LW, 2007, IEEE T IMAGE PROCESS, V16, P850, DOI 10.1109/TIP.2007.891147
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Viola P, 2019, ARXIV PREPRINT ARXIV
   Woo H, 2015, INT J MOL SCI, V16, P9017, DOI 10.3390/ijms16049017
   Xu M, 2019, ARXIV PREPRINT ARXIV
   Zhang W, 2012, IEEE T INTELL TRANSP, V13, P140, DOI 10.1109/TITS.2011.2165338
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhou J., 2013, RES J APPL SCI ENG T, V5, P3037, DOI [10.19026/rjaset.5.4620, DOI 10.19026/RJASET.5.4620]
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou QH, 2015, International Symposium 2015: Common Development of Sports and Modern Society, P1
   ZWEIG MH, 1993, CLIN CHEM, V39, P561
NR 51
TC 5
Z9 5
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22821
EP 22841
DI 10.1007/s11042-020-10501-8
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000610019400005
DA 2024-07-18
ER

PT J
AU Zhang, YX
   Zhang, JG
   Xu, SB
AF Zhang, Yixuan
   Zhang, Jiguang
   Xu, Shibiao
TI A hybrid convolutional architecture for accurate image manipulation
   localization at the pixel-level
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manipulation localization; Top-down detection; Bottom-up segmentation;
   DenseCRFs
AB Advanced image processing techniques can easily edit images without leaving any visible traces, making manipulation detection and localization for forensics analysis a challenging task. Few studies can simultaneously locate tampered objects accurately and refine contours of tampered regions effectively. In this study, we propose an effective and novel hybrid architecture, named Pixel-level Image Tampering Localization Architecture (PITLArc), which integrates the advantages of top-down detection-based methods and bottom-up segmentation-based methods. Moreover, we provide a typical fusion implementation of our proposed hybrid architecture on one outstanding detection-based method (two-stream faster region-based convolutional neural network (RGB-N)) and two segmentation-based methods (Multi-Scale Convolution Neural Networks (MSCNNs) and Dual-domain Convolutional Neural Networks (DCNNs)) to evaluate the effectiveness of the proposed architecture. The three methods can be integrated into our proposed PITLArc to significantly improve their performance. Other detection and segmentation algorithms (not limited to the three aforementioned methods) can also be integrated into our architecture to improve their performance. Moreover, a Dense Conditional Random Fields (DenseCRFs)-based post-processing method is introduced to further optimize the details of tampered regions. Experiments validate the effectiveness of the proposed architecture.
C1 [Zhang, Yixuan] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Zhang, Yixuan] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Zhang, Jiguang; Xu, Shibiao] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Information Engineering,
   CAS; Chinese Academy of Sciences; Institute of Automation, CAS
RP Xu, SB (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
EM shibiao.xu@nlpr.ia.ac.cn
FU NSFC [U1636102, U1736214, 61802393, 61872356]; National Key Technology
   RD Program [2016QY15Z2500]; Project of Beijing Municipal Science &
   Technology Commission [Z181100002718001]
FX This work was supported by NSFC under U1636102, U1736214, 61802393 and
   61872356, National Key Technology R&D Program under 2016QY15Z2500, and
   Project of Beijing Municipal Science & Technology Commission under
   Z181100002718001.
CR [Anonymous], PYDENSECRFS
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Cozzolino D, 2016, IEEE INT WORKS INFOR
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Kakar P, 2010, IEEE INT CON MULTI, P486, DOI 10.1109/ICME.2010.5582562
   Koltun V, EFFICIENT INFERENCE
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P1240, DOI 10.1109/TIFS.2017.2656823
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu YQ, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P85, DOI 10.1145/3206004.3206010
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Rao Y, 2016, IEEE INT WORKS INFOR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P25027, DOI 10.1007/s11042-018-5756-4
   Zhao MH, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2815608
   Zhou AN, 2018, IEEE CONF COMM NETW
NR 34
TC 4
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23377
EP 23392
DI 10.1007/s11042-020-10211-1
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000610019400012
DA 2024-07-18
ER

PT J
AU Suresh, M
   Sam, IS
AF Suresh, Meenu
   Sam, I. Shatheesh
TI Exponential fractional cat swarm optimization for video steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Cat swarm optimization; Lifting wavelet transform;
   Fractional concept; Exponential parameters
ID IMAGE STEGANOGRAPHY; H.264/AVC VIDEO; WATERMARKING; SCHEME; DOMAIN
AB In this paper, an effective method named Exponential Fractional-Cat Swarm Optimization (Exponential Fractional-CSO) along with multi-objective cost function is proposed. The proposed method is designed by integrating the CSO with the fractional concept based on the Exponential parameters. Initially, an input video is selected from the database from which frames are generated. Key frames are chosen among the frames using the contourlet transform and Structural Similarity Index Measure (SSIM). Regions are formed on the selected key frames through the help of grid lines. Once the regions are formed, optimal regions are ascertained with the help of the proposed optimization algorithm along with multi-objective cost functions to hide the secret data. During the embedding process, the secret data is hidden in the optimal region using the lifting wavelet transform (LWT). The embedded video is then transmitted through the network to reach its intended receiver. The experimental results reveal that the proposed Exponential Fractional-CSO obtained a maximal correlation of 0.9931 by considering the frames, maximal Peak Signal-to-Noise Ratio (PSNR) of 89.70 dB and MSE of 0.00006 respectively. Hence, the proposed method shows greater effectiveness of hiding the secret data in the video sequence along with data security.
C1 [Suresh, Meenu] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
   [Sam, I. Shatheesh] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept PG Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Suresh, M (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM meenupillai1988@gmail.com; shatheeshsam@yahoo.com
CR Bahrami M, 2018, STUD COMPUT INTELL, V720, P9, DOI [10.1007/978-981-10-5221-7_2, 10.1007/978-3-319-72929-9_2]
   Banharnsakun A, 2018, MULTIMED TOOLS APPL, V77, P27491, DOI 10.1007/s11042-018-5933-5
   Bhaladhare PR., 2014, Adv Comput Eng, V2014, P1, DOI [DOI 10.1155/2014/396529, 10.1155/2014/396529]
   Chan PW, 2005, IEEE T CIRC SYST VID, V15, P1638, DOI 10.1109/TCSVT.2005.856932
   Feng Y, 2017, NEURAL COMPUT APPL, V28, P1619, DOI 10.1007/s00521-015-2135-1
   Goldberg D.E., 1998, GENETIC ALGORITHMS M
   Gurunathan K, 2020, MULTIMED TOOLS APPL, V79, P3893, DOI 10.1007/s11042-019-7471-1
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jain DS, 2016, VIDEO STEGANOGRAPHY, P7
   JALALI A, MULTIMED TOOLS APPL
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Khadam U., 2020, WIREL COMMUN MOB COM, V2020, P1
   Li Y, 2019, MULTIMED TOOLS APPL, V78, P8535, DOI 10.1007/s11042-018-6942-0
   Liu CL, 2019, IEEE ACCESS, V7, P108866, DOI 10.1109/ACCESS.2019.2933531
   LIU S, COGN SYST RES, V59, P207
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Montes de Oca MA, 2009, IEEE T EVOLUT COMPUT, V13, P1120, DOI 10.1109/TEVC.2009.2021465
   Moon SK, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P660, DOI 10.1109/ICIIP.2013.6707677
   Noda H, 2004, IEEE IMAGE PROC, P2147
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Pradhan PM, 2012, EXPERT SYST APPL, V39, P2956, DOI 10.1016/j.eswa.2011.08.157
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   SONG G, 2020, IEEE ACCESS, V8
   Stanescu D, 2007, SACI 2007: 4TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS, PROCEEDINGS, P241, DOI 10.1109/SACI.2007.375518
   Suresh M, 2022, J KING SAUD UNIV-COM, V34, P3489, DOI 10.1016/j.jksuci.2020.08.007
   Suresh M, 2020, MULTIMED TOOLS APPL, V79, P27023, DOI 10.1007/s11042-020-09330-6
   Suresh M, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P877, DOI 10.1109/ICCONS.2018.8662920
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Tsai YS, 2011, INFORM SCIENCES, V181, P3188, DOI 10.1016/j.ins.2011.03.017
   Wagdarikar AMU, 2019, J INTELL SYST, V28, P873, DOI 10.1515/jisys-2017-0264
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Xiph, DERF S TEST MEDIA CO
   Xue YM, 2019, SIGNAL PROCESS-IMAGE, V76, P22, DOI 10.1016/j.image.2019.04.012
   Yang HJ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P955, DOI 10.1109/ICME.2004.1394360
   Younus ZS, 2020, J INTELL SYST, V29, P1216, DOI 10.1515/jisys-2018-0225
   YunXia Liu, 2012, Journal of Software, V7, P1059, DOI 10.4304/jsw.7.5.1059-1065
NR 38
TC 5
Z9 5
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13253
EP 13270
DI 10.1007/s11042-020-10395-6
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776300007
DA 2024-07-18
ER

PT J
AU Pang, LL
   Tew, YQ
   Wong, K
   Bin Ayub, MN
AF Pang, LieLin
   Tew, Yiqi
   Wong, KokSheik
   Bin Ayub, Mohamad Nizam
TI CUPSEED-A combined use of prediction syntax elements to embed data in
   SHVC video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CUPSEED; Data embedding; Prediction syntax element; SHVC
AB With the rapid advancement in digital technologies, video rises to become one of the most effective communication tools that continues to gain popularity and importance. As a result, various proposals are put forward to manage videos, and one of them is data embedding. Essentially, data embedding inserts data into the video to serve a specific purpose, including proof of ownership via watermark, covert communication in steganography, and authentication via fragile watermark. However, most conventional methods embed data by using only one type of syntax element defined in the video coding standard, which may suffer from large bit rate overhead, quality degradation, or low payload. Therefore, this work aims to explore the combined use of multiple prediction syntax elements in SHVC for the purpose of data embedding. Specifically, the intra prediction mode, motion vector predictor, motion vector difference, merge mode and coding block structure are collectively manipulated to embed data. The experimental results demonstrate that, in comparison to the conventional single-venue data embedding methods, the combined use of prediction syntax elements can achieve higher payload while preserving the perceptual quality with minimal bit rate variation. In the best case scenario, a total of 556.1 kbps is embedded into the video sequence PartyScene with a drop of 0.15 dB in PSNR while experiencing a bit rate overhead of 7.4% when all prediction syntax elements are utilized altogether. A recommendation is then put forward to choose specific types of syntax element for data embedding based on the characteristics of the video.
C1 [Pang, LieLin; Bin Ayub, Mohamad Nizam] Univ Malaya, Kuala Lumpur, Malaysia.
   [Tew, Yiqi] Tunku Abdul Rahman Univ Coll, Kuala Lumpur, Malaysia.
   [Wong, KokSheik] Monash Univ, Sch Informat Technol, Subang Jaya, Selangor, Malaysia.
   [Wong, KokSheik] Monash Univ, Adv Engn Platform, Subang Jaya, Selangor, Malaysia.
C3 Universiti Malaya; Tunku Abdul Rahman University College (TAR UC);
   Monash University; Monash University Malaysia; Monash University; Monash
   University Malaysia
RP Wong, K (corresponding author), Monash Univ, Sch Informat Technol, Subang Jaya, Selangor, Malaysia.; Wong, K (corresponding author), Monash Univ, Adv Engn Platform, Subang Jaya, Selangor, Malaysia.
EM adpangll@siswa.um.edu.my; yiqi@tarc.edu.my; wong.koksheik@monash.edu;
   nizam_ayub@um.edu.my
RI AYUB, MOHAMAD NIZAM/B-9023-2010; Tew, Yiqi/AAR-1026-2020; Wong,
   KokSheik/B-9796-2011
OI Tew, Yiqi/0000-0002-9395-2937; Wong, KokSheik/0000-0002-4893-2291; Ayub,
   Mohamad Nizam/0000-0003-2504-0810
FU Advanced Engineering Platform's Cluster Funding [AEP-2020-Cluster-04];
   Monash University Malaysia, Malaysia
FX This work was supported by the Advanced Engineering Platform's Cluster
   Funding (account number AEP-2020-Cluster-04), Monash University
   Malaysia, Malaysia.
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   [Anonymous], 2017, SHM
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Bross Benjamin, 2014, HIGH EFFICIENCY VIDE
   Buhari AM, 2016, SIGNAL PROCESS-IMAGE, V47, P86, DOI 10.1016/j.image.2016.06.003
   Fang DY, 2006, IEEE INT SYMP CIRC S, P1422
   Guan Z., 2020, 2020 IEEE INT C MULT, P1
   Jia-Ji Wang, 2015, Journal of Software, V10, P213
   Konyar MZ, 2020, SIGNAL IMAGE VIDEO P, V14, P897, DOI 10.1007/s11760-019-01621-2
   Van LP, 2015, IEEE IMAGE PROC, P3610, DOI 10.1109/ICIP.2015.7351477
   Nguyen CV, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P81
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pang L., 2019, P IEEE INT C SIGN IN, P1
   Pang LL, 2019, IEEE IMAGE PROC, P4050, DOI [10.1109/icip.2019.8803422, 10.1109/ICIP.2019.8803422]
   Pang LL, 2017, ASIAPAC SIGN INFO PR, P1190, DOI 10.1109/APSIPA.2017.8282210
   Shanableh T, 2018, MULTIMED TOOLS APPL, V77, P8939, DOI 10.1007/s11042-017-4787-6
   Sheng Q, 2016, LECT NOTES COMPUT SC, V10039, P63, DOI 10.1007/978-3-319-48671-0_6
   Tew Y, 2018, MULTIMED TOOLS APPL, V77, P24165, DOI 10.1007/s11042-018-5611-7
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Universit?t-Hannover, 2013, TEST SEQ
   Wong K, 2020, IEICE T INF SYST, VE103D, P2, DOI 10.1587/transinf.2019MUI0001
   Xiph, 2013, DERFS COLL
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Xu J., 2015, Journal of Computational Information Systems, V11, P5587, DOI DOI 10.12733/JCIS15121
   Yang J, 2018, MULTIMED TOOLS APPL, V77, P11979, DOI 10.1007/s11042-017-4844-1
   Yang YY, 2019, MULTIMED TOOLS APPL, V78, P8423, DOI 10.1007/s11042-018-6859-7
NR 30
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13121
EP 13142
DI 10.1007/s11042-020-10359-w
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607369000003
PM 33456316
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Bouibed, ML
   Nemmour, H
   Chibani, Y
AF Bouibed, Mohamed Lamine
   Nemmour, Hassiba
   Chibani, Youcef
TI SVM-based writer retrieval system in handwritten document images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dissimilarity learning; HOG; GLBP; LDF; RLF; SVM
ID IDENTIFICATION; PATTERN
AB Digital libraries include huge amount of information that are continuously increasing with the need of storing various kinds of handwritten documents such as administrative forms, and cultural heritage manuscripts. Therefore, new emerging techniques such as writer retrieval are used to facilitate information extraction from archived documents. Basically, a writer retrieval system is composed of two main steps that are feature generation and dissimilarity measure. To achieve a robust retrieval, we propose the use of an SVM classifier trained to automatically separate intra-writer features from inter-writer features. For feature generation, we investigate the effectiveness of the Histogram of Oriented Gradients, Gradient Local Binary Patterns, and Local Difference Features. Experiments are conducted on three benchmark datasets. The results obtained evince a satisfactory performance of SVM, which can give better results than the state of the art.
C1 [Bouibed, Mohamed Lamine; Nemmour, Hassiba; Chibani, Youcef] Univ Sci & Technol Houari Boumediene USTHB, Lab Ingn Syst Intelligents & Communicants LISIC, Fac Elect & Comp Sci FEI, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Bouibed, ML (corresponding author), Univ Sci & Technol Houari Boumediene USTHB, Lab Ingn Syst Intelligents & Communicants LISIC, Fac Elect & Comp Sci FEI, Algiers, Algeria.
EM mbouibed@usthb.dz; hnemmour@usthb.dz; ychibani@usthb.dz
OI Bouibed, Mohamed Lamine/0000-0002-4932-3463
CR Arab Naouel, 2020, 2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP), P266, DOI 10.1109/CCSSP49278.2020.9151688
   Atanasiu V, 2011, PROC INT CONF DOC, P628, DOI 10.1109/ICDAR.2011.132
   Bouadjenek N, 2016, APPL SOFT COMPUT, V46, P980, DOI 10.1016/j.asoc.2015.10.021
   Bouadjenek N, 2015, PROC INT CONF DOC, P1116, DOI 10.1109/ICDAR.2015.7333934
   Bouibed Mohamed Lamine, 2020, 2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP), P248, DOI 10.1109/CCSSP49278.2020.9151717
   Bouibed ML, 2017, 3 INT C EL ENG CONTR, P537
   Bouibed ML, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113023
   Bouibed ML, 2018, INT CONF INFO SCI, P252, DOI 10.1109/ICIST.2018.8426179
   Bouillard Martin, 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8087376
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dey S, 2016, LECT NOTES COMPUT SC, V10029, P574, DOI 10.1007/978-3-319-49055-7_51
   Djeddi C, 2013, PATTERN RECOGN LETT, V34, P1196, DOI 10.1016/j.patrec.2013.03.020
   Fiel S., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P145, DOI 10.1109/DAS.2012.99
   Fiel S, 2015, LECT NOTES COMPUT SC, V9257, P26, DOI 10.1007/978-3-319-23117-4_3
   Fiel S, 2013, PROC INT CONF DOC, P545, DOI 10.1109/ICDAR.2013.114
   Hmood Ali K., 2018, Pattern Recognition and Image Analysis, V28, P569, DOI 10.1134/S1054661818040028
   Jebril Noor A., 2018, Pattern Recognition and Image Analysis, V28, P321, DOI 10.1134/S1054661818020141
   Jiang N, 2013, IEEE INT SYMP CIRC S, P978, DOI 10.1109/ISCAS.2013.6572012
   Kholmatov A, 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117473
   Kleber F, 2013, PROC INT CONF DOC, P560, DOI 10.1109/ICDAR.2013.117
   Louloudis G, 2011, PROC INT CONF DOC, P1475, DOI 10.1109/ICDAR.2011.293
   Mahmoud SA, 2012, INT CONF FRONT HAND, P449, DOI 10.1109/ICFHR.2012.224
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouamane A., 2015, Pattern Recognition and Image Analysis, V25, P603
   Platt JC, 2000, ADV NEUR IN, P61
   Serdouk Y, 2015, 2015 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA) PROCEEDINGS, P216
   Shirdhonkar MS, 2011, COMM COM INF SC, V205, P108
   Vapnik V, 2000, The Nature of Statistical Learning Theory, DOI [DOI 10.1007/978-1-4757-3264-1, DOI 10.1007/978-1-4757-2440-0]
   Zhang JQ, 2016, NEUROCOMPUTING, V184, P176, DOI 10.1016/j.neucom.2015.07.141
NR 32
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22629
EP 22651
DI 10.1007/s11042-020-10162-7
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000607369100012
DA 2024-07-18
ER

PT J
AU Alma'aitah, WZ
   Talib, AZ
   Osman, MA
AF Alma'aitah, Wafa' Za'al
   Talib, Abdullah Zawawi
   Osman, Mohd Azam
TI Towards adaptive structured Dirichlet smoothing model for digital
   resource objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dirichlet smoothing model; Digital resource objects; Retrieval model
ID LANGUAGE MODELS
AB Digital resource objects (DRO) are among the most valuable resources that store the accumulated knowledge of humankind. Nowadays, many organisations aim to make these resources available to users. Basically, Dirichlet smoothing (DS) model is widely used to retrieve DRO documents. DS model uses a smoothing parameter mu which plays a strong role in finding the value of the unseen terms to avoid zero probability value. For documents of equal length, the value of mu is set as a constant value although its value depends on the length of a document. In DROs, almost all documents are of different length, and each metadata unit in a document also has a different length. Hence, it is not appropriate to predefine the mu parameter with a constant value and uses it for different search space. This leads to difficulty in accessing and retrieving the DRO documents. To solve fixed smoothing-parameter value problem in DRO's retrieval, and make DROs more accessible, Adaptive Dirichlet Smoothing (ADS) and Adaptive Structured Dirichlet Smoothing (ASDS) models are proposed to improve the performance of the DRO's retrieval by estimating the smoothing parameter automatically. The proposed ASDS model comprises the ADS model together with an existing DS model. Experimental results on CHiC2013 collections show that the proposed models have the ability to retrieve the most relevant results (documents or metadata units) related to a particular query and reduce the zero-probability values compared with state-of-the-art traditional methods particularly on DROs. Moreover, t-test result is used to prove that the performance of the proposed models is statistically significant.
C1 [Alma'aitah, Wafa' Za'al] Hashemite Univ, Dept Basic Sci, Fac Sci, Zarqa, Jordan.
   [Talib, Abdullah Zawawi; Osman, Mohd Azam] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
C3 Hashemite University; Universiti Sains Malaysia
RP Alma'aitah, WZ (corresponding author), Hashemite Univ, Dept Basic Sci, Fac Sci, Zarqa, Jordan.
EM wafaa_maitah@hu.edu.jo
RI Osman, Mohd Azam/E-4676-2012; Talib, Abdullah Zawawi/B-7390-2018;
   AlMa'aitah, wafa'/AAC-8989-2022
OI AlMa'aitah, wafa'/0000-0001-5183-1654
CR Abdulmutalib N, 2008, INT WORKSHOP DATABAS, P9, DOI 10.1109/DEXA.2008.33
   Alma'aitah WZ, 2020, ARTIF INTELL REV, V53, P3621, DOI 10.1007/s10462-019-09773-w
   Alma'aitah WZ, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), P256, DOI 10.1109/JEEIT.2019.8717374
   Alma'aitah WZ, 2019, INT J ADV TRENDS COM, V8, P6
   Alma'aitah WZ, 2019, INT J ENG ADV TECHNO, V9, P4
   Almasri M, 2013, CORIA
   ALMasri M, 2014, LECT NOTES COMPUT SC, V8870, P136, DOI 10.1007/978-3-319-12844-3_12
   Alnaied A., 2020, EGYPTIAN INFORM J
   [Anonymous], 2015, THESIS
   [Anonymous], 2014, Statistical analysis with missing data. Vol
   Azzopardi L, 2007, P 1 INT C THEOR INF, P65
   Berger A, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P222, DOI 10.1145/312624.312681
   Biyik MV, 2020, PRIM HEALTH CARE RES, V21, DOI 10.1017/S1463423620000389
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boban I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124316
   Brocks H., 2001, Research and Advanced Technology for Digital Libraries. 5th European Conference, ECDL 2001. Proceedings (Lecture Notes in Computer Science Vol.2163), P37
   Bruza P, 2003, P 26 ANN INT ACM SIG, P419
   Camara A, 2020, DIAGNOSING BERT RETR, P605
   Candela L., 2007, The DELOS Digital Library Reference Model - Foundations for Digital Libraries
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Cechinel C, 2009, COMM COM INF SC, V46, P60
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Chengxiang Zhai, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P403, DOI 10.1145/502585.502654
   Chengxiang Zhai, 2001, SIGIR Forum, P334
   Cummins R, 2015, ACM T INFORM SYST, V33, DOI 10.1145/2746231
   Darwish K, 2007, TEXT SPEECH LANG TEC, V38, P245
   Duris F., 2018, Journal of Statistical Distributions and Applications, V5, P2
   Hatano K., 2002, Database and Expert Systems Applications. 13th International Conference, DEXA 2002. Proceedings (Lecture Notes in Computer Science Vol.2453), P758
   He B., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P465, DOI 10.1145/1076034.1076114
   Jinxi Xu, 2001, SIGIR Forum, P105
   Jungmaier J, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P3560
   Krasakis A. M., 2020, ARXIV200803717
   Lafferty J., 2001, SIGIR, P111, DOI DOI 10.1145/383952.383970
   Laitang C, 2013, P 10 C OP RES AR INF, P41
   Lavrenko V., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P175
   Losada DE, 2008, INFORM RETRIEVAL, V11, P109, DOI 10.1007/s10791-007-9040-x
   Lv Y, 2009, P 32 INT ACM SIGIR C
   Lv YH, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P299
   Manning P, 2013, INTRO DRUGS POPULAR, P10
   Mataoui M., 2015, MOD SIM APPL OPT ICM, P1
   Mei Q., 2007, WWW, DOI DOI 10.1145/1242572.1242596
   Nallapati R., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P383, DOI 10.1145/584792.584855
   Ogawa K, 2016, NTCIR, P186
   Ogilvie P., 2003, P 1 INEX WORKSH P IN EV XML RETR WOR, P12
   Parikh N, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1137, DOI 10.1145/2505515.2505721
   Ponte JM, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
   Rahimi R, 2020, INFORM RETRIEVAL J, P1
   Si L., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P391, DOI 10.1145/584792.584856
   Singhal A, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P34, DOI 10.1145/312624.312645
   Smucker M. D., 2005, IR445 U MASS AMH DEP
   Strohman T., 2005, P INT C INT AN, V2, P2
   Wang JM, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102342
   Wang YQ, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P1163, DOI 10.1109/ICYCS.2008.56
   Winther O, 2020, METHOD SYSTEM INFORM
   Witten I. H., 2002, Research and Advanced Technology for Digital Libraries. 6th European Conference, ECDL 2002. Proceedings (Lecture Notes in Computer Science Vol.2458), P390
   Xu B, 2020, SOFT COMPUT, V24, P1707, DOI 10.1007/s00500-019-03998-1
   Xu JX, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P254
   Zhai C, 2002, THESIS
   Zhai C, 2008, SYNTHESIS LECT HUMAN, V1, P1, DOI [DOI 10.2200/S00158ED1V01Y200811HLT001, 10.2200/S00158ED1V01Y200811HLT001]
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
NR 60
TC 1
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12175
EP 12194
DI 10.1007/s11042-020-10305-w
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606296900001
DA 2024-07-18
ER

PT J
AU Ilhan, I
AF Ilhan, Ilhan
TI A cross-platform test tool for digital image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Cross-platform; Mobile device; Test tool; Real time
   image
ID FILTER; NOISE; COLOR
AB Image processing is one of the current research topics widely used in different engineering fields. Therefore, it is taught as a lesson under different names in various engineering departments. In-class applications are usually done through programs that depend on desktop platforms such as Windows, Linux or MacOS. These platforms, which self or its camera are fixed, can only take real time images with limited mobility. It is difficult to apply image processing algorithms for real time images and make comparisons. In this study, a cross-platform test tool for image processing was developed. This tool can work on desktop platforms such as Windows and MacOS, as well as mobile platforms such as Android and IOS. Thanks to mobile platform support, the real time images can be taken anytime and anywhere. The basic image processing operations can be performed on recorded or real time images. The resulting images can be recorded. Thus, a test environment is provided to apply and compare different methods and algorithms.
C1 [Ilhan, Ilhan] Necmettin Erbakan Univ, Dept Mechatron Engn, Konya, Turkey.
C3 Necmettin Erbakan University
RP Ilhan, I (corresponding author), Necmettin Erbakan Univ, Dept Mechatron Engn, Konya, Turkey.
EM ilhan@erbakan.edu.tr
RI ilhan, ilhan/V-3688-2017
OI ilhan, ilhan/0000-0002-8567-8798
CR Adlakha D., 2016, INT J SCI ENG RES, V7, P4
   Al-amri S., 2010, International Journal on Computer Science and Engineering, V2, P804
   [Anonymous], 2013, INT J EMERGING SCI E
   [Anonymous], 2017, IJSRSET
   Ayala M, 2010, COMPUT APPL ENG EDUC, V18, P213, DOI 10.1002/cae.20171
   Badamchizadeh M. A., 2004, Proceedings. Third International Conference on Image and Graphics, P27
   Bhardwaj S, 2012, PROC TECH, V4, P220, DOI 10.1016/j.protcy.2012.05.033
   Cadík M, 2008, COMPUT GRAPH FORUM, V27, P1745
   CRIMMINS TR, 1985, APPL OPTICS, V24, P1438, DOI 10.1364/AO.24.001438
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Fisher R., 2004, IMAGE PROCESSING LEA
   Golagani SC, 2012, ASEE ANNU CONF EXPO
   Gonzalez RC., 1977, DIGITAL IMAGE PROCES, P451, DOI DOI 10.1109/CVPR.2014.81
   Gupta G., 2011, Int. J. Soft Comput. Eng. (IJSCE), V1, P304
   Ilhan I, 2016, COMPUT APPL ENG EDUC, V24, P744, DOI 10.1002/cae.21747
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khan NU, 2010, IEEE SYS MAN CYBERN, P3735, DOI 10.1109/ICSMC.2010.5641838
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Kuk JG, 2011, LECT NOTES COMPUT SC, V6495, P513, DOI 10.1007/978-3-642-19282-1_41
   Lalitha M., 2013, Int. J. Sci. Res, V2, P348
   lhan, 2019, 3 INT SCI VOC STUD C
   Maini R., 2010, J COMPUT, V2, DOI DOI 10.48550/ARXIV.1003.4053
   Manohar KM, 2016, INT J ADV RES COMPUT, V5
   Mashor M.Y., 2000, International Journal of the computer, the Internet and Management, V8, P50, DOI DOI 10.1080/00207179208934272
   MatWorks Company, IM PROC TOOLB
   Mu KN, 2016, OPTIK, V127, P4794, DOI 10.1016/j.ijleo.2016.01.017
   NAIK D, 2014, INT J COMPUTER SCI I, V5, P3289
   National Instruments Corporation, IM PROC TOOLK
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Pise S, 2017, INT J INNOV RES COMP, V5, P4026
   Ravi S., 2013, P 2 NAT C VLSI SIGN
   Russ J.C., 1995, The Image Processing Handbook, Vsecond
   Shrivakshan G., 2012, INT J COMPUT SCI ISS, V9, P269
   Skinner M, 2015, THESIS
   Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089
   Thakur P, 2016, INT J INNOV ENG TECH
   Vala Hetal J., 2013, INT J ADV RES COMPUT, V2, P387, DOI DOI 10.1007/S11548-009-0389-8
NR 38
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12249
EP 12273
DI 10.1007/s11042-020-10417-3
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606296900004
DA 2024-07-18
ER

PT J
AU ElAraby, ME
   Shams, MY
AF ElAraby, M. E.
   Shams, M. Y.
TI Face retrieval system based on elastic web crawler over cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web crawler; Cloud computing; Face extraction; PCA; KNN; Facial image
ID ARCHITECTURE; IMAGES
AB The web pages are considered as the main source of the available and provided information that is characterized by variation in its content. The facial recognition plays a key role in knowledge management and identity authentication systems. Although the rapid advance of the web technologies and face recognition systems, the improvement of real-time performance is still the bottleneck. The main objective of this study is to propose a real-time face retrieval system as a service over cloud computing based on a web face crawler. The proposed architecture ensures that the total response time is reduced and the resource utilization is optimized. The web crawlers fetch web pages and extract images in elastic storage over the cloud. Then the collected images are used to extract human faces and to prepare the faces images by succeeding phases to be ready for recognition and identifying the matched face of the collection. The proposed service depends on Principle Component Analysis (PCA) algorithm for feature extraction and dimensionality reduction. Furthermore, K-Nearest Neighbors (KNN) is used to classify the crawled facial images over cloud resources. The experimental results investigated that an enhancement of crawling speed is achieved by increasing the crawler instances. Moreover, the accuracy is enhanced in the face recognition based on the Euclidean over other metrics such as Manhattan and Cosine dissimilarity.
C1 [ElAraby, M. E.] Beni Suef Univ, Fac Comp & Artificial Intelligence, Bani Suwayf, Egypt.
   [Shams, M. Y.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33511, Egypt.
C3 Egyptian Knowledge Bank (EKB); Beni Suef University; Egyptian Knowledge
   Bank (EKB); Kafrelsheikh University
RP ElAraby, ME (corresponding author), Beni Suef Univ, Fac Comp & Artificial Intelligence, Bani Suwayf, Egypt.
EM mohamed.elaraby@fcis.bsu.edu.eg
RI ELAraby, mohamed/GZK-3983-2022; Shams, Mahmoud Y./AAM-9251-2020
OI Shams, Mahmoud Y./0000-0003-3021-5902
CR Amazon, 2020, AWS AM EC2
   Amazon RDS, 2020, AM REL DAT SERV
   [Anonymous], 2001, Proceedings of the Tenth Conference on World Wide Web, DOI [10.1145/371920.371960, DOI 10.1145/371920.371960]
   [Anonymous], 2008, P 17 INT C WORLD WID
   Bahrami M, 2015, 2015 IEEE 16TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P158, DOI 10.1109/IRI.2015.33
   Bahrami M, 2015, INT CONF INTELL NEXT, P216, DOI 10.1109/ICIN.2015.7073834
   Bahurupi S.P., 2012, INT J ENG ADV TECHNO, V1, P91
   Boldi P, 2004, SOFTWARE PRACT EXPER, V34, P711, DOI 10.1002/spe.587
   Borade SN, 2016, EFFECT DISTANCE MEAS, P569
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P16411, DOI 10.1007/s11042-018-7028-8
   ElAraby ME, 2019, J INTELL FUZZY SYST, V37, P1233, DOI 10.3233/JIFS-182683
   ElAraby ME, 2018, ARAB J SCI ENG, V43, P8111, DOI 10.1007/s13369-018-3241-z
   Fang YC, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3403964
   Gens F., 2009, NEW IDC IT CLOUD SER
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Heydon A., 1999, World Wide Web, V2, P219, DOI 10.1023/A:1019213109274
   Hsieh JM, 2010, NSDI 7 USENIX C NETW, P329
   Inzinger C, 2014, 2014 IEEE 8TH INTERNATIONAL SYMPOSIUM ON SERVICE ORIENTED SYSTEM ENGINEERING (SOSE), P13, DOI 10.1109/SOSE.2014.9
   Khan MA, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112925
   Lin FC, 2020, J SUPERCOMPUT, V76, P8473, DOI 10.1007/s11227-019-03123-x
   Mika P, 2008, IEEE INTELL SYST, V23, P82, DOI 10.1109/MIS.2008.94
   Moreno-Vozmediano R, 2013, IEEE INTERNET COMPUT, V17, P18, DOI 10.1109/MIC.2012.69
   Nguyen HM, 2018, LECT NOTES ARTIF INT, V10752, P539, DOI 10.1007/978-3-319-75420-8_51
   NIST-National Institute of Standards and Technology, 2020, NIST CLOUD COMP PROG
   Ortiz EG, 2014, COMPUT VIS IMAGE UND, V118, P153, DOI 10.1016/j.cviu.2013.09.004
   Poon B, 2011, INT J MACH LEARN CYB, V2, P245, DOI 10.1007/s13042-011-0023-2
   Rodriguez-Vaamonde S, 2015, IEEE T PATTERN ANAL, V37, P1274, DOI 10.1109/TPAMI.2014.2366761
   Shams M.Y., 2017, J. Inf. Hiding Multim. Signal Process, V8, P702
   Suchitra S, 2020, MULTIMED TOOLS APPL, V79, P24825, DOI 10.1007/s11042-020-09219-4
   University of California, IRV UCI
   Wang DY, 2014, IEEE T KNOWL DATA EN, V26, P166, DOI 10.1109/TKDE.2012.240
   Wang J, 2013, PATTERN RECOGN, V46, P230, DOI 10.1016/j.patcog.2012.07.030
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Xu SH, 2014, BIOINFORMATICS, V30, P104, DOI 10.1093/bioinformatics/btt571
   Zhang DS, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P928
NR 35
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11723
EP 11738
DI 10.1007/s11042-020-10271-3
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700026
DA 2024-07-18
ER

PT J
AU Khare, A
   Khare, M
   Srivastava, R
AF Khare, Ashish
   Khare, Manish
   Srivastava, Richa
TI Shearlet transform based technique for image fusion using median fusion
   rule
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi model image fusion; Shearlet transform; Median based fusion; Multi
   resolution analysis
ID WAVELET TRANSFORM; QUALITY
AB Image fusion is a challenging research area which is useful in various image processing applications. Image fusion integrates information from multiple source images into a single composite image for better visual quality and information content than any of its source images. In the present paper, we have proposed a new median based image fusion algorithm using nonsubsampled shearlet transform. Nonsubsampled shearlet transform is a powerful multiscale geometrical analysis (MGA) tool having rich mathematical structure, high directionality, anisotropy and shift-invariance features. Due to these features nonsubsampled shearlet transform can efficiently capture information of the source images in its coefficient sets. The coefficient sets of the source images are fused by using a new median based fusion rule. Median is an important statistical measurement, which is enriched with two outstanding properties that are edge preserving and robustness against noise. Hence, median based fusion rule increases the quality of fused image. The proposed fusion rule is simple and easy to understand. Strength of the proposed fusion method is verified visually as well as quantitatively by comparing it with different state of the art methods. We have performed experiments on three different types of images (medical, remote sensing and multifocus). Results of the experiments confirm that the proposed method outperform in comparison with other state-of-the-art fusion methods visually as well as quantitatively in terms of different quantitative performance measures such as entropy, standard deviation, edge strength, fusion factor, and running time.
C1 [Khare, Ashish; Srivastava, Richa] Univ Allahabad, Dept Elect & Commun, Prayagraj, India.
   [Khare, Manish] Dhirubhai Ambani Inst Informat & Commun Technol I, Gandhinagar, India.
C3 University of Allahabad; Dhirubhai Ambani Institute of Information &
   Communication Technology
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Prayagraj, India.
EM khare@allduniv.ac.in; mkharejk@gmail.com; gaur.richa@gmail.com
RI Khare, Ashish/D-4566-2012; Khare, Manish/AAF-4582-2019
OI Khare, Manish/0000-0002-2296-2732
CR Abdipour M, 2016, COMPUT ELECTR ENG, V51, P74, DOI 10.1016/j.compeleceng.2016.03.011
   Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Blum R.S., 2005, MULTISENSOR IMAGE FU
   Borwonwatanadelok P, 2009, ICECT: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMPUTER TECHNOLOGY, PROCEEDINGS, P77, DOI 10.1109/ICECT.2009.94
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chaudhary V, 2018, SIGNAL IMAGE VIDEO P, V12, P271, DOI 10.1007/s11760-017-1155-y
   Chen CH, 2015, CHEM ENGINEER TRANS, V46, P277, DOI 10.3303/CET1546047
   Chibani Y, 2006, ISPRS J PHOTOGRAMM, V60, P306, DOI 10.1016/j.isprsjprs.2006.05.001
   Clevers JGPW, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P67, DOI 10.1016/B978-0-12-372529-5.00004-4
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Daubechies I., 1992, 10 LECT WAVELETS
   Deng H, 2011, 2011 INTERNATIONAL CONFERENCE ON SOCIAL SCIENCES AND SOCIETY (ICSSS 2011), VOL 3, P32
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Easley GR, 2009, IEEE T IMAGE PROCESS, V18, P260, DOI 10.1109/TIP.2008.2008070
   Fernandes FCA, 2003, IEEE T SIGNAL PROCES, V51, P1825, DOI 10.1109/TSP.2003.812841
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   He CT, 2010, PROCEDIA ENGINEER, V7, P280, DOI 10.1016/j.proeng.2010.11.045
   Hill P., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P487
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Jinju J, 2019, ENG SCI TECHNOL, V22, P715, DOI 10.1016/j.jestch.2019.01.004
   Khaleghi B, 2013, INFORM FUSION, V14, P28, DOI 10.1016/j.inffus.2011.08.001
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li S, 2010, INT J IMAGE DATA FUS, V1, P47, DOI 10.1080/19479830903562009
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2002, PATTERN RECOGN LETT, V23, P985, DOI 10.1016/S0167-8655(02)00029-6
   Li X, 2020, J AMBIENT INTELLIGEN, DOI [10.1007/s12652-020-02293-4], DOI 10.1007/S12652-020-02293-4]]
   Liu XB, 2019, INT J THEOR PHYS, V58, P734, DOI 10.1007/s10773-018-3971-4
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Miao Q., 2013, NEW ADV IMAGE FUSION, P113
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Moonon AU, 2015, SENS IMAGING, V16, DOI 10.1007/s11220-015-0106-3
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Nikolov S., 2001, WAVELETS SIGNAL IMAG, P213
   Rockinger O, 1998, P SOC PHOTO-OPT INS, V3374, P378, DOI 10.1117/12.327135
   Romeny BMH, 1996, P 4 INT C VIS BIOM C, P1
   Shi WZ, 2005, INT J APPL EARTH OBS, V6, P241, DOI 10.1016/j.jag.2004.10.010
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Srivastava Richa, 2016, International Journal of Image, Graphics and Signal Processing, V8, P64, DOI 10.5815/ijigsp.2016.10.08
   Srivastava R, 2015, IMAGING SCI J, V63, P408, DOI 10.1179/1743131X15Y.0000000025
   Srivastava R, 2016, IET COMPUT VIS, V10, P513, DOI 10.1049/iet-cvi.2015.0251
   Srivastava R, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P263, DOI 10.1109/ICIEV.2012.6317395
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   VETTERLI M, 1992, IEEE T SIGNAL PROCES, V40, P2207, DOI 10.1109/78.157221
   Vetterli M, 2003, BEYOND WAVELETS, P1
   Vishwakarma A, 2018, MULTIMED TOOLS APPL, V77, P32013, DOI 10.1007/s11042-018-6254-4
   Wang KP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082169
   Wang L, 2014, INFORM FUSION, V19, P20, DOI 10.1016/j.inffus.2012.03.002
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Yadav SP, 2020, MED BIOL ENG COMPUT, V58, P669, DOI 10.1007/s11517-020-02136-6
   Yang HY, 2014, NEURAL NETWORKS, V57, P152, DOI 10.1016/j.neunet.2014.06.007
   Yang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/579341
   Yi S, 2009, IEEE T IMAGE PROCESS, V18, P929, DOI 10.1109/TIP.2009.2013082
   Yin F, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/3020461
   Zheng YF, 2009, FUSION: 2009 12TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOLS 1-4, P1060
NR 63
TC 12
Z9 13
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11491
EP 11522
DI 10.1007/s11042-020-10184-1
EA JAN 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700006
DA 2024-07-18
ER

PT J
AU Pinto, J
   Jain, P
   Kumar, T
AF Pinto, Joey
   Jain, Pooja
   Kumar, Tapan
TI A content based image information retrieval and video thumbnail
   extraction framework using SOM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; CBVR; SOM; Clustering; Image-search; Information retrieval; Image
   retrieval; Video retrieval thumbnail-extraction
ID FEATURES; SIFT
AB Searching an image or a video in a huge volume of graphical data is a tedious time-consuming process. If this search is performed using the conventional element matching technique, the complexity of the search will render the system useless. To overcome this problem, the current paper proposes a Content-Based Image Retrieval (CBIR) and a Content-Based Video Retrieval (CBVR) technique using clustering algorithms based on neural networks. Neural networks have proved to be quite powerful for dimensionality reduction due to their parallel computations. Retrieval of images in a large database on the basis of the content of the query image has been proved fast and efficient through practical results. Two images of the same object, but taken from different camera angles or have rotational and scaling transforms is also matched effectively. In medical domain, CBIR has proved to be a boon to the doctors. The tumor, cancer etc can be easily deducted comparing the images with normal to the images with diseases. Java and Weka have been used for implementation. The thumbnails extracted from the video facilitates the video search in a large videos database. The unsupervised nature of Self Organizing Maps (SOM) has made the software all the more robust.
C1 [Pinto, Joey] Indian Inst Informat Technol, Comp Sci & Engn, Kota, India.
   [Jain, Pooja; Kumar, Tapan] Indian Inst Informat Technol, Nagpur, Maharashtra, India.
RP Jain, P (corresponding author), Indian Inst Informat Technol, Nagpur, Maharashtra, India.
EM poojaalld@yahoo.com
RI Jain, Tapan Kumar/HGE-0667-2022; Pinto, Joey/AAA-5408-2022; Jain,
   Pooja/L-4523-2016
OI Jain, Tapan Kumar/0000-0003-0255-0084; Jain, Pooja/0000-0002-4216-7787
FU Indian Institute of Information Technology, Nagpur
FX The authors would like to acknowledge the organization Indian Institute
   of Information Technology, Nagpur, for giving the necessary support for
   carrying out the research work.
CR Abu Abbas O, 2008, INT ARAB J INF TECHN, V5, P320
   Ansari Aasif., 2015, International Journal of Computer Applications, V112, P13
   Bautista PA, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.5.056013
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Grabner M, 2006, LECT NOTES COMPUT SC, V3851, P918
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   He P, 2012, ASIA COMMUN PHOTON, DOI 10.1117/12.905678
   Nguyen TKH, 2014, 2014 IEEE FAIBLE TENSION FAIBLE CONSOMMATION (FTFC)
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Park SB, 2004, PATTERN RECOGN LETT, V25, P287, DOI 10.1016/j.patrec.2003.10.015
   Prasad JD, 2013, J ATMOS SCI
   Rosten E., 2005, ICCV
   Sakr NA, 2016, COMPUT ELECTR ENG, V54, P522, DOI 10.1016/j.compeleceng.2016.04.015
   Sima AA, 2013, REMOTE SENS-BASEL, V5, P2037, DOI 10.3390/rs5052037
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Yang Y, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P183, DOI 10.1109/DICTA.2009.36
NR 26
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16683
EP 16709
DI 10.1007/s11042-020-10227-7
EA JAN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000605548700011
DA 2024-07-18
ER

PT J
AU Maurya, R
   Singh, N
   Jindal, T
   Pathak, VK
   Dutta, MK
AF Maurya, Ritesh
   Singh, Neha
   Jindal, Tanu
   Pathak, Vinay Kumar
   Dutta, Malay Kishore
TI Computer-aided automatic transfer learning based approach for analysing
   the effect of high-frequency EMF radiation on brain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drosophila melanogaster; Radiofrequency electromagnetic radiation;
   Segmentation; Pre-trained convolution neural networks; Support vector
   machine
ID EXPOSURE; TUMORS
AB An electromagnetic field radiations (EMF) emanating from the cell phones affect the brain and other organs in living organisms. Therefore, the objective of the present study is to examine whether the EMF radiations affect the brain cells or not, using the transfer learning-based methodology. The observations made in the present study are based on our experiment with the Drosophila melanogaster. The microscopic brain-images of drosophila, (should be read as micro-images) exposed to and not exposed to the high-frequency EMF radiations were acquired for the analysis purposed. The comprehensive set of features were extracted from the micro-images in EMF-exposed and Non-exposed class drosophila using the pre-trained convolution neural networks (CNNs). Further, the support Vector Machine (SVM) has been used to find an optimal hyperplane in higher dimensional feature space which separates the feature representations of the micro-images from both the classes. The % accuracy of SVM in classifying the features extracted from the micro-images from both the classes using the pre-trained VGG19 network is 87.3% for the 5-fold cross-validation. The discrimination in feature sets extracted from the micro-images signifies that the EMF radiations have affected the drosophila brain cells. Experimental results reveal that the prolonged exposure to EMF radiations might have affected the drosophila brain which approves the assumed hypothesis.
C1 [Maurya, Ritesh; Dutta, Malay Kishore] Dr APJ Abdul Kalam Tech Univ New Campus, Ctr Adv Studies, Lucknow 226031, Uttar Pradesh, India.
   [Singh, Neha; Jindal, Tanu] Amity Inst Environm Toxil Safety & Management, Noida, India.
   [Pathak, Vinay Kumar] Dr APJ Abdul Kalam Tech Univ New Campus, Lucknow 226031, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Centre for Advanced
   Studies (CAS, AKTU); Amity University Noida; Dr. A.P.J. Abdul Kalam
   Technical University (AKTU)
RP Dutta, MK (corresponding author), Dr APJ Abdul Kalam Tech Univ New Campus, Ctr Adv Studies, Lucknow 226031, Uttar Pradesh, India.
EM ritesh@cas.res.in; neha.singh.0574@gmail.com; tjindal@amity.edu;
   vinay@vpathak.in; mkd@cas.res.in
OI Dutta, Malay Kishore/0000-0003-2462-737X; MAURYA,
   RITESH/0000-0002-5664-0328
CR Adebayo EA, 2019, J KING SAUD UNIV SCI, V31, P813, DOI 10.1016/j.jksus.2018.11.007
   Banik PP, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113211
   Borjali A, 2020, J ORTHOP RES, V38, P1465, DOI 10.1002/jor.24617
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2018, NATURE INSPIRED COMP, DOI 10.1007/978-981-10-6747-1_9
   Dawud AM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4629859
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhungel N, 2015, LECT NOTES COMPUT SC, V9349, P605, DOI 10.1007/978-3-319-24553-9_74
   Gao ZM, 2017, IEEE J BIOMED HEALTH, V21, P416, DOI 10.1109/JBHI.2016.2526603
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Jeong YJ, 2015, CURR ALZHEIMER RES, V12, P481
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Khurana VG, 2009, SURG NEUROL, V72, P205, DOI 10.1016/j.surneu.2009.01.019
   Kim JH, 2019, BIOMOL THER, V27, P265, DOI 10.4062/biomolther.2018.152
   Kishore GK, 2019, J CLIN DIAGN RES, V13, DOI 10.7860/JCDR/2019/39681.12630
   Liu TYA, 2020, J NEURO-OPHTHALMOL, V40, P178, DOI 10.1097/WNO.0000000000000827
   Lopes UK, 2017, COMPUT BIOL MED, V89, P135, DOI 10.1016/j.compbiomed.2017.08.001
   Mausset-Bonnefont AL, 2004, NEUROBIOL DIS, V17, P445, DOI 10.1016/j.nbd.2004.07.004
   Morgan LL, 2015, INT J ONCOL, V46, P1865, DOI 10.3892/ijo.2015.2908
   Okatan DÖ, 2018, TOXICOL IND HEALTH, V34, P693, DOI 10.1177/0748233718781292
   Ouadah NS, 2018, J NEURO-ONCOL, V140, P539, DOI 10.1007/s11060-018-03012-y
   Pandey UB, 2011, PHARMACOL REV, V63, P411, DOI 10.1124/pr.110.003293
   Razavinasab M, 2016, TOXICOL IND HEALTH, V32, P968, DOI 10.1177/0748233714525497
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101821
   Wyde ME, 2018, BIOELECTROMAGNETICS, V39, P190, DOI 10.1002/bem.22116
   Xue Y, 2019, IEEE T MED IMAGING, V38, P2632, DOI 10.1109/TMI.2019.2907093
NR 31
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13713
EP 13729
DI 10.1007/s11042-020-10204-0
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000604479100002
DA 2024-07-18
ER

PT J
AU Kong, FY
   Zhou, YF
   Chen, G
AF Kong, Fanyu
   Zhou, Yufeng
   Chen, Gang
TI Multimedia data fusion method based on wireless sensor network in
   intelligent transportation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data fusion; Sensor network; Intelligent transportation system; Fusion
   accuracy; Bandwidth allocation; Perception process; Vehicle recognition
AB In order to realize the ubiquitous perception of urban traffic system integration, a universal technology architecture supporting multiple heterogeneous access, universalization and tailoring is needed to realize the interconnection and interoperability of perception systems in different application scenarios. Based on the analysis of typical application scenarios in traffic field and the performance characteristics of wireless and wired sensor networks, a method of bandwidth allocation for network resources in urban traffic application environment is proposed in this paper, especially in the scenario of high-speed train movement, in order to improve the transmission efficiency of wireless sensor networks. An information matching method for sensor networks is proposed. The correlation among multi-sensors is used to fuse the monitoring information in the coverage area of the sensing system, which is helpful to improve the resolution and accuracy of the system. The theory is applied to vehicle type recognition in traffic flow detection. The simulation results show that the proposed data fusion scheme has obvious advantages over the similar LEACH protocol in terms of energy consumption and fusion accuracy of common nodes.
C1 [Kong, Fanyu; Zhou, Yufeng] Chongqing Technol & Business Univ, Chongqing Engn Technol Res Ctr Dev Informat Manag, Chongqing 400067, Peoples R China.
   [Zhou, Yufeng] Nanjing Univ Aeronaut & Astronaut, Postdoctoral Res Stn Management Sci & Engn, Nanjing 211106, Jiangsu, Peoples R China.
   [Chen, Gang] Chongqing Univ, Coll Architecture & Urban Planning, Chongqing 400045, Peoples R China.
C3 Chongqing Technology & Business University; Nanjing University of
   Aeronautics & Astronautics; Chongqing University
RP Kong, FY (corresponding author), Chongqing Technol & Business Univ, Chongqing Engn Technol Res Ctr Dev Informat Manag, Chongqing 400067, Peoples R China.
EM kongkongry22@163.com
RI ZHOU, yf/IAO-5497-2023; sun, rong/JRX-7214-2023; CHEN, AN/KFT-3370-2024;
   Zhou, Yujie/HZI-3990-2023
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Arikumar KS, 2017, ONL INT C GREEN ENG, P1
   Baccarelli E, 2014, IEEE WIREL COMMUN, V21, P20, DOI 10.1109/MWC.2014.6882292
   Chen S., 2016, J AGR MECH RES, V91, P7648
   Chen X, 2015, PROCEEDINGS 2015 SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND ENGINEERING APPLICATIONS ISDEA 2015, P551, DOI 10.1109/ISDEA.2015.142
   Dai Zhifeng, 2015, Computer Engineering, V41, P198, DOI 10.3969/j.issn.1000-3428.2015.03.038
   Fei Xianju, 2016, Journal of Jilin University (Science Edition), V54, P575, DOI 10.13413/j.cnki.jdxblxb.2016.03.30
   [黄海平 Huang Haiping], 2014, [电子与信息学报, Journal of Electronics & Information Technology], V36, P2364
   Hui C., 2014, CHINESE J SENSORS AC, V27, P664
   Izadi D, 2015, SENSORS-BASEL, V15, P2964, DOI 10.3390/s150202964
   Ji S., 2016, J SUPERCOMPUT, V74, P1
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Liu LG, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0793-z
   Luo X, 2015, INT J CONTROL AUTOM, V13, P539, DOI 10.1007/s12555-014-0309-8
   Reliability BO., 2014, J SENSORS, V2014, P1
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Tan CL, 2017, J TROP MED-US, V2017, P1, DOI 10.1155/2017/7946123
   Tan N. D., 2015, ADV INTELLIGENT SYST, V326, P61
   Venkatesh V, 2017, INT S INT SYST TECHN, P14
   Xiao L., 2016, J COMPUT THEOR NANOS, V13, P9515
   Yang Z, 2014, APPL MECH MATER, V577, P873, DOI 10.4028/www.scientific.net/AMM.577.873
   Zou TY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112555
NR 22
TC 17
Z9 17
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35195
EP 35207
DI 10.1007/s11042-019-7614-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900027
DA 2024-07-18
ER

PT J
AU Wendling, L
   Debled-Rennesson, I
   Nasser, H
AF Wendling, L.
   Debled-Rennesson, I.
   Nasser, H.
TI Multilevel polygonal descriptor matching defined by combining discrete
   lines and force histogram concepts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Conference on Recent Trends in Image Processing and
   Pattern Recognition (RTIP2R)
CY DEC 21-22, 2018
CL Solapur, INDIA
DE Discrete lines; Force histogram; Polygonal representation; Multilevel
   structure
AB A new method allowing to describe shapes from a set of polygonal curves using a relational descriptor is proposed in this paper. An approach based on discrete lines at several increasing widths is run on the contour of an object to provide a multi-level polygonal representation from accurate description to more and more rough aspects. On each polygon, a force histogram is calculated to define a relational feature signature following a set of directions integrating both spatial relation organization and disparities of the shape in a same distribution. Three different matching schemes are proposed to compare multilevel distributions: global representation, level to level following extracted maxima. This new method is fast and a first experimental study achieved on a common database shows its good behavior.
C1 [Wendling, L.] Univ Paris 05, LIPADE, 45 Rue St Peres, F-75270 Paris, France.
   [Debled-Rennesson, I.; Nasser, H.] Univ Lorraine, LORIA, UMR 7503, F-54506 Vandoeuvre Les Nancy, France.
C3 Universite Paris Cite; Universite de Lorraine
RP Wendling, L (corresponding author), Univ Paris 05, LIPADE, 45 Rue St Peres, F-75270 Paris, France.
EM Laurent.Wendling@parisdescartes.fr
OI Wendling, Laurent/0000-0003-1091-5995
CR Baird H.S., 2014, Handbook of Document Image Processing and Recognition, P63, DOI DOI 10.1007/978-0-85729-859-1_43
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Bernier T, 2003, PATTERN RECOGN, V36, P1711, DOI 10.1016/S0031-3203(02)00352-7
   Cordella L. P., 2000, International Journal on Document Analysis and Recognition, V3, P73, DOI 10.1007/s100320000036
   Debled-Rennesson I, 2006, COMPUT GRAPH-UK, V30, P30, DOI 10.1016/j.cag.2005.10.007
   Debled-Rennesson I., 1981, ELECT LETT COMPUT VI, V5, P98
   Dilip K, 2012, DIGITAL IMAGE PROCES
   Dosch P., 2000, International Journal on Document Analysis and Recognition, V3, P102, DOI 10.1007/PL00010901
   DUBOIS D, 1987, PATTERN RECOGN LETT, V6, P251, DOI 10.1016/0167-8655(87)90085-7
   Duckham M, 2008, PATTERN RECOGN, V41, P3224, DOI 10.1016/j.patcog.2008.03.023
   Hilaire X, 2006, IEEE T PATTERN ANAL, V28, P890, DOI 10.1109/TPAMI.2006.127
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Janssen RDT, 1997, COMPUT VIS IMAGE UND, V65, P38, DOI 10.1006/cviu.1996.0484
   Kerautret B, 2012, IEEE T PATTERN ANAL, V34, P2379, DOI 10.1109/TPAMI.2012.38
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim W-Y, 1999, TR1501
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P222, DOI 10.1109/91.236554
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   MAES M, 1991, PATTERN RECOGN, V24, P433, DOI 10.1016/0031-3203(91)90056-B
   Matsakis P, 1999, IEEE T PATTERN ANAL, V21, P634, DOI 10.1109/34.777374
   MATSAKIS P, 1998, THESIS U P SABATIER
   Matsakis P, 2010, STUD FUZZ SOFT COMP, V256, P49
   MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387
   Nasser H, 2018, J COMPUT SYST SCI, V95, P177, DOI 10.1016/j.jcss.2017.07.007
   Nguyen TP, 2011, PATTERN RECOGN, V44, P32, DOI 10.1016/j.patcog.2010.06.022
   Rusiñol M, 2010, PATTERN ANAL APPL, V13, P321, DOI 10.1007/s10044-009-0161-2
   Santosh KC, 2018, MED BIOL ENG COMPUT, V56, P1447, DOI 10.1007/s11517-018-1786-3
   Santosh KC, 2014, INT J DOC ANAL RECOG, V17, P61, DOI 10.1007/s10032-013-0205-4
   Santosh KC, 2012, PATTERN RECOGN LETT, V33, P331, DOI 10.1016/j.patrec.2011.09.040
   Santosh K.C., 2018, Document Image Analysis: Current Trends and Challenges in Graphics Recognition
   Santosh KC., 2015, WILEY ENCY ELECT ELE, P1
   Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396
   Song JQ, 2002, IEEE T PATTERN ANAL, V24, P1048, DOI 10.1109/TPAMI.2002.1023802
   Tabbone S., 2003, International Journal on Document Analysis and Recognition, V6, P115, DOI 10.1007/s10032-003-0105-0
   Tabbone S, 2003, LECT NOTES COMPUT SC, V2886, P184
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Vacavant A, 2013, COMPUT VIS IMAGE UND, V117, P438, DOI 10.1016/j.cviu.2012.07.006
   Wendling L, 2008, LECT NOTES COMPUT SC, V5342, P947, DOI 10.1007/978-3-540-89689-0_98
   Yang S, 2005, IEEE T PATTERN ANAL, V27, P278, DOI 10.1109/TPAMI.2005.38
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 40
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34701
EP 34715
DI 10.1007/s11042-019-7531-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900002
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Guo, YR
   Sun, R
   Liu, ZQ
   Guo, D
AF Zhao, Ye
   Guo, Yanrong
   Sun, Rui
   Liu, Zhengqiong
   Guo, Dan
TI Unsupervised video summarization via clustering validity index
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Frame selection; Representative selection;
   Clustering validity index
AB Although lots of the prior works have been proposed to solve the representative selection problem of video summarization, the main difficulty is still left for determining the optimal representatives' number of the raw videos that are not annotated. In this paper, we propose an unsupervised video summarization method by motion-based frame selection and a novel clustering validity indexes to determine the optimal representatives of the original video. The proposed framework segments shots and selects candidate frames by evaluating their forward and backward motion and can automatically select representatives to highlight all the significant visual properties. Shots are segmented uniformly and the frame with the largest motion is extracted in each segmentation to form the video candidate frame subset. Then Affinity Propagation combined with the validity index is used to automatically select the optimal representatives from the candidate frame subset. Our experimental result on several benchmark datasets demonstrates the robustness and effectiveness of our proposed method.
C1 [Zhao, Ye; Guo, Yanrong; Sun, Rui; Liu, Zhengqiong; Guo, Dan] Hefei Univ Technol, Hefei 230601, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Zhao, Y (corresponding author), Hefei Univ Technol, Hefei 230601, Anhui, Peoples R China.
EM zhaoye@hfut.edu.cn
OI Zhao, Ye/0000-0002-8180-4697
CR Ben Said A, 2017, PATTERN ANAL APPL, V20, P21, DOI 10.1007/s10044-015-0453-7
   Bezdek JC, 2016, IEEE T FUZZY SYST, V24, P1500, DOI 10.1109/TFUZZ.2016.2540063
   Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624
   Bharill N, 2014, IEEE INT FUZZY SYST, P1526, DOI 10.1109/FUZZ-IEEE.2014.6891591
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dimitriadou E, 2002, PSYCHOMETRIKA, V67, P137, DOI 10.1007/BF02294713
   Dudoit S, 2002, GENOME BIOL, V3
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Kapp AV, 2007, BIOSTATISTICS, V8, P9, DOI 10.1093/biostatistics/kxj029
   Lin P-L, 2016, INT C MACH LEARN CYB, P2160
   Liu XL, 2015, IEEE T CYBERNETICS, V45, P2461, DOI 10.1109/TCYB.2014.2374755
   Luo CZ, 2016, IEEE T MULTIMEDIA, V18, P40, DOI 10.1109/TMM.2015.2495248
   Ma MY, 2017, IEEE INT CON MULTI, P637, DOI 10.1109/ICME.2017.8019387
   Mahasseni B, 2017, PROC CVPR IEEE, P2982, DOI 10.1109/CVPR.2017.318
   Meng JJ, 2018, IEEE T IMAGE PROCESS, V27, P2134, DOI 10.1109/TIP.2017.2789332
   Panda R, 2017, IEEE I CONF COMP VIS, P3677, DOI 10.1109/ICCV.2017.395
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Tasdemir K, 2011, IEEE T SYST MAN CY B, V41, P1039, DOI 10.1109/TSMCB.2010.2104319
   Varini P, 2017, IEEE T MULTIMEDIA, V19, P2832, DOI 10.1109/TMM.2017.2705915
   Wang M, 2017, IEEE T KNOWL DATA EN, V29, P1101, DOI 10.1109/TKDE.2017.2654445
   Wang M, 2016, IEEE T KNOWL DATA EN, V28, P1864, DOI 10.1109/TKDE.2016.2535367
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Xu R, 2012, IEEE T SYST MAN CY B, V42, P1243, DOI 10.1109/TSMCB.2012.2188509
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhang YZ, 2017, IEEE T CIRC SYST VID, V27, P1340, DOI 10.1109/TCSVT.2016.2539638
   Zhao Y, 2016, NEUROCOMPUTING, V172, P48, DOI 10.1016/j.neucom.2014.09.095
   Zheng YN, 2017, TRANSP LETT, V9, P1, DOI 10.1080/19427867.2015.1131943
   [周世兵 Zhou Shibing], 2011, [计算机科学, Computer Science], V38, P225
NR 33
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33417
EP 33430
DI 10.1007/s11042-019-7582-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000006
DA 2024-07-18
ER

PT J
AU Maeda, K
   Takahashi, S
   Ogawa, T
   Haseyama, M
AF Maeda, Keisuke
   Takahashi, Sho
   Ogawa, Takahiro
   Haseyama, Miki
TI Deterioration level estimation via neural network maximizing
   category-based ordinally supervised multi-view canonical correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Within-class divergence; Ordinal scale; Canonical
   correlation; Deterioration level estimation
ID CLASSIFICATION
AB A deterioration level estimation method via neural network maximizing category-based ordinally supervised multi-view canonical correlation is presented in this paper. This paper focuses on real world data such as industrial applications and has two contributions. First, a novel neural network handling multi-modal features transforms original features into features effectively representing deterioration levels in transmission towers, which are one of the infrastructures, with consideration of only correlation maximization. It can be realized by setting projection matrices maximizing correlations between multiple features into weights of hidden layers. That is, since the proposed network has only a few hidden layers, it can be trained from a small amount of training data. Second, since there exist diverse characteristics and an ordinal scale in deterioration levels, the proposed method newly derives category-based ordinally supervised multi-view canonical correlation analysis (Co-sMVCCA). Co-sMVCCA enables estimation of effective projection considering both within-class divergence and the ordinal scale between classes. Experimental results showed that the proposed method realizes accurate deterioration level estimation.
C1 [Maeda, Keisuke; Haseyama, Miki] Hokkaido Univ, Off Inst Res, Sapporo, Hokkaido, Japan.
   [Takahashi, Sho] Hokkaido Univ, Fac Engn, Sapporo, Hokkaido, Japan.
   [Ogawa, Takahiro] Hokkaido Univ, Fac Informat Sci & Technol, Sapporo, Hokkaido, Japan.
C3 Hokkaido University; Hokkaido University; Hokkaido University
RP Maeda, K (corresponding author), Hokkaido Univ, Off Inst Res, Sapporo, Hokkaido, Japan.
EM maeda@lmd.ist.hokudai.ac.jp; stakahashi@eng.hokudai.ac.jp;
   ogawa@lmd.ist.hokudai.ac.jp; miki@ist.hokudai.ac.jp
OI Ogawa, Takahiro/0000-0001-5332-8112; Maeda, Keisuke/0000-0001-8039-3462
FU JSPS KAKENHI [JP20K19856, JP17H01744]; Grants-in-Aid for Scientific
   Research [20K19856] Funding Source: KAKEN
FX This work was partly supported by JSPS KAKENHI Grant Numbers JP20K19856
   and JP17H01744. In this research, we utilized the data that were
   provided by Tokyo Electric Power Company Research Institute.
CR Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Allouch A, 2017, IEEE SENS J, V17, P4231, DOI 10.1109/JSEN.2017.2702739
   Andrew G., 2013, ICML, P1247
   [Anonymous], 2009, P TRANSM DISTR C EXP
   [Anonymous], 2018, ARXIV181108615
   [Anonymous], COMMUNICATION
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Donahue J, 2014, PR MACH LEARN RES, V32
   Fan D.-P., 2019, ARXIV190706781
   Gao YQ, 2018, COMPUT-AIDED CIV INF, V33, P748, DOI 10.1111/mice.12363
   Gopalakrishnan K, AGRAWAL CRACK DAMAGE
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang GB, 2004, IEEE IJCNN, P985
   Im J, 2017, INT CONF UBIQ ROBOT, P922
   Ji HK, 2016, J VIS COMMUN IMAGE R, V40, P393, DOI 10.1016/j.jvcir.2016.06.012
   Jonsson P, 2015, IEEE SENS J, V15, P1641, DOI 10.1109/JSEN.2014.2364854
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kasahara JYL, 2018, IEEE ROBOT AUTOM LET, V3, P2616, DOI 10.1109/LRA.2018.2820178
   Lee G, 2015, IEEE T MED IMAGING, V34, P284, DOI 10.1109/TMI.2014.2355175
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Maeda H, 2018, COMPUT-AIDED CIV INF, V33, P1127, DOI 10.1111/mice.12387
   Maeda K, 2017, J COMPUT CIVIL ENG, V31, DOI 10.1061/(ASCE)CP.1943-5487.0000686
   Maeda K, 2019, COMPUTER AIDED CIVIL
   Maeda K, 2019, IEEE IMAGE PROC, P919, DOI [10.1109/icip.2019.8803038, 10.1109/ICIP.2019.8803038]
   Maeda K, 2018, IEEE J-STSP, V12, P633, DOI 10.1109/JSTSP.2018.2849593
   PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1
   Peng JL, 2015, MULTIMED TOOLS APPL, V74, P4469, DOI 10.1007/s11042-013-1817-x
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   SCHMIDT WF, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P1, DOI 10.1109/ICPR.1992.201708
   Sun TK, 2007, INT C WAVEL ANAL PAT, P1283
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang H, 2019, CHIN CONTR CONF, P8750, DOI [10.23919/chicc.2019.8866322, 10.23919/ChiCC.2019.8866322]
   Woo S., 2016, INT SYSMPOSIUM NONDE, V2, P293
   Yan BF, 2014, J COMPUT CIVIL ENG, V28, DOI 10.1061/(ASCE)CP.1943-5487.0000293
   Yeh YR, 2014, IEEE T IMAGE PROCESS, V23, P2009, DOI 10.1109/TIP.2014.2310992
   Yu Y, 2018, IEEE INT SYM MULTIM, P188, DOI 10.1109/ISM.2018.00-11
   Yu Y, 2019, IEEE T NEUR NET LEAR, V30, P1250, DOI 10.1109/TNNLS.2018.2856253
   Yuan YH, 2017, MULTIMED TOOLS APPL, V76, P731, DOI 10.1007/s11042-015-3070-y
   Yuan YH, 2014, PATTERN RECOGN, V47, P3907, DOI 10.1016/j.patcog.2014.06.016
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
NR 46
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23091
EP 23112
DI 10.1007/s11042-020-10040-2
EA NOV 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000591138700001
DA 2024-07-18
ER

PT J
AU Shantkumari, M
   Uma, SV
AF Shantkumari, M.
   Uma, S. V.
TI Grape leaf segmentation for disease identification through adaptive
   Snake algorithm model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf disease; Segmentation; Adaptive Snake model
AB Fruits are the eminent export agriculture product for any country, especially grape, it is used for making wines and developing raisins. Moreover, Viticulture has proven to be one of the highly profitable industry from the economic point of view. However, in viticulture grape quality should be of top-notch quality, moreover throughout the research it is observed that grape quality is degraded mainly due to the plant disease. In past several researcher have tried their efforts to detect the early identification of disease. Segmentation plays bigger role identifying the disease, Hence in this paper we propose an Adaptive Snake Model for segmentation and region identification. ASA (Adaptive Snake Model) is two phase segmentation model namely common segmentation and absolute segmentation. Through common segmentation, we achieve the fast segmentation and through the absolute segmentation, we achieve the better accuracy. Moreover for evaluation of Adaptive Snake Algorithm two standard dataset i.e. PlantLevel and PlantVillage dataset, for further evaluation we have compared with various state-of-art technique in terms of various performance metric such as PSNR, Dice, Manhattan, Recall and Jaccard. Adaptive Snake Algorithm performs better than the other existing methodology.
C1 [Shantkumari, M.] VTU RRC, Belagavi, Karnataka, India.
   [Uma, S. V.] RNSIT, Bangalore, Karnataka, India.
C3 Visvesvaraya Technological University
RP Shantkumari, M (corresponding author), VTU RRC, Belagavi, Karnataka, India.
EM shantkumarim@rediffmail.com; umakeshav2000@gmail.com
RI V, Uma S/AAE-8882-2021
OI V, Uma S/0000-0002-2389-011X
CR [Anonymous], 2012, Int. J. Comput. Sci. Telecommun
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cerutti G, 2011, LECT NOTES COMPUTER
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Couprie C, 2009, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2009.5459284
   Dornbusch T, 2010, COMPUT ELECTRON AGR, V70, P217, DOI 10.1016/j.compag.2009.10.009
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FLORY RE, 1985, P IEEE, V73, P613, DOI 10.1109/PROC.1985.13188
   Gao H, 2001, IEEE T CIRC SYST VID, V11, P1273, DOI 10.1109/76.974681
   Goeau H, 2011, IMAGE CLEF2011 WORKI
   Grand-Brochier M, 2015, IEEE T IMAGE PROCESS, V24, P1549, DOI 10.1109/TIP.2015.2400214
   Guo W, 2013, COMPUT ELECTRON AGR, V96, P58, DOI 10.1016/j.compag.2013.04.010
   Jmour Nadia, 2018, 2018 International Conference on Advanced Systems and Electric Technologies (IC_ASET), P397, DOI 10.1109/ASET.2018.8379889
   Kaur R, 2015, 2015 IEEE 3RD INTERNATIONAL CONFERENCE ON MOOCS, INNOVATION AND TECHNOLOGY IN EDUCATION (MITE), P135, DOI 10.1109/MITE.2015.7375303
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Kurtz C, 2012, PATTERN RECOGN, V45, P685, DOI 10.1016/j.patcog.2011.07.017
   Larese M, 2012, LEGUME IDENTIFICATIO, P447, DOI [10.1007/978-3-642-33275-3_55, DOI 10.1007/978-3-642-33275-3_55]
   Li SX, 2010, IMAGE VISION COMPUT, V28, P424, DOI 10.1016/j.imavis.2009.06.012
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mao HanPing Mao HanPing, 2008, Transactions of the Chinese Society of Agricultural Engineering, V24, P136
   Meunkaewjinda A, 2008, ECTI-CON 2008: PROCEEDINGS OF THE 2008 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P513, DOI 10.1109/ECTICON.2008.4600483
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Patil SS, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN ADVANCED COMPUTING (ICCTAC)
   Qin F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168274
   Ran Yu-gang, 2012, Journal of Computer Applications, V32, P752, DOI 10.3724/SP.J.1087.2012.00752
   SKLANSKY J, 1978, IEEE T SYST MAN CYB, V8, P237, DOI 10.1109/TSMC.1978.4309944
   Sonka M., 1993, IMAGE PROCESSING ANA
   Tian YW, 2012, PHYSCS PROC, V33, P743, DOI 10.1016/j.phpro.2012.05.130
NR 29
TC 12
Z9 13
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8861
EP 8879
DI 10.1007/s11042-020-09853-y
EA NOV 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000586377600005
DA 2024-07-18
ER

PT J
AU Jacob, IJ
   Betty, P
   Darney, PE
   Raja, S
   Robinson, YH
   Julie, EG
AF Jacob, I. Jeena
   Betty, P.
   Darney, P. Ebby
   Raja, S.
   Robinson, Y. Harold
   Julie, E. Golden
TI Biometric template security using DNA codec based transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature transformation; Biometric template; DNA based codec;
   Fingerprint; Z pattern generation
AB Feature transformation is the most primary step in biometric template protection whose effectiveness is directly dependent upon the test and trained samples. The minutiae points are segregated to retrieve the attributes with the singular point data to enlarge the secure user template. The user fingerprint information could be revealed to produce the secured template with the help of the fingerprint image. An attempt of feature transformation is experimented in this paper by DNA based encoding methodology. The general formation of the proposed technique is constructed from the Biometric data to generate the feature extraction; the Z pattern generation is used for implementing the transformation and produced the DNA codec. The evaluation of each step in the proposed scheme is theoretically evaluated and experimented with. The revocability, diversity and the security parameters are analyzed and compared with the relevant methods using the images from FVC2004 dataset that the accuracy for biometric template is achieved through the enhanced recognition rate. The complexity and the performance of the proposed method proved challenging to the state of art techniques.
C1 [Jacob, I. Jeena] GITAM Univ, Dept Comp Sci & Engn, GITAM Sch Technol, Bengaluru Campus, Bengaluru, Karnataka, India.
   [Betty, P.] Kumaraguru Coll Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Darney, P. Ebby] SCAD Coll Engn & Technol, Dept Elect & Elect Engn, Tirunelveli, Tamil Nadu, India.
   [Raja, S.] Amrita Coll Engn & Technol, Dept Math, Nagarcoil, Tamil Nadu, India.
   [Robinson, Y. Harold] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Julie, E. Golden] Anna Univ, Dept Comp Sci & Engn, Reg Campus, Tirunelveli, India.
C3 Gandhi Institute of Technology & Management (GITAM); Kumaraguru College
   of Technology; Vellore Institute of Technology (VIT); VIT Vellore; Anna
   University; Anna University of Technology Tirunelveli
RP Robinson, YH (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM jeni.neha@gmail.com; berylbetty@gmail.com; pebbydamey@gmail.com;
   nellairajaa@yahoo.com; yhrobinphd@gmail.com; goldenjuliephd@gmail.com
RI Jacob, I.Jeena/AAE-8426-2020; S, RAJA/N-8506-2014; Darney,
   Ebby/HSC-0295-2023; ROBINSON, HAROLD/A-1545-2016
OI Jacob, I.Jeena/0000-0001-6706-1017; ROBINSON,
   HAROLD/0000-0002-4881-7103; Darney, Ebby/0000-0002-2559-3442; S,
   RAJA/0000-0003-1281-9948; P, Betty/0000-0001-7289-7783
CR Ali SS, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P801, DOI 10.1109/SPIN.2015.7095438
   Ali SS, 2017, COMPUTE'17: PROCEEDINGS OF THE 10TH ANNUAL ACM INDIA COMPUTE CONFERENCE, P91, DOI 10.1145/3140107.3140113
   [Anonymous], 2017, BIOMETRIC AUTHENTICA
   [Anonymous], 2007, TECHNICAL REPORT
   [Anonymous], TECH REP
   [Anonymous], 2015, FORTIFYING PATTERN R
   Rúa EA, 2012, IEEE T INF FOREN SEC, V7, P269, DOI 10.1109/TIFS.2011.2168213
   Atighehchi K, 2019, FUTURE GENER COMP SY, V101, P819, DOI 10.1016/j.future.2019.07.022
   Balaji Subramanian, 2019, Ingenierie des systemes d'information, V24, P481, DOI 10.18280/isi.240504
   Balaji S, 2019, COMPUT STAND INTER, V66, DOI 10.1016/j.csi.2019.103358
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   Ferrara M, 2012, IEEE T INF FOREN SEC, V7, P1727, DOI 10.1109/TIFS.2012.2215326
   Ganapathi II, 2018, IET BIOMETRICS, V7, P519, DOI 10.1049/iet-bmt.2018.5064
   Ghammam L, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P316, DOI 10.1109/CW.2018.00065
   Hill C. J., 2001, THESIS
   Iyappan GanapathiIyyakutti, 2019, PROC BIOSIG 2019, P1
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Krishnan RS, 2020, WIREL NETW, V26, P1275, DOI 10.1007/s11276-019-02151-y
   Lee HG, 2007, LECT NOTES COMPUT SC, V4642, P557
   Nandakumar K, 2007, IEEE T INF FOREN SEC, V2, P744, DOI 10.1109/TIFS.2007.908165
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Robinson YH, 2019, WIRELESS PERS COMMUN, V104, P1149, DOI 10.1007/s11277-018-6074-x
   Rosenberger C, 2018, ICISSP: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P216, DOI 10.5220/0006550502160224
   Sandhya M, 2015, INT CONF BIOMETR, P386, DOI 10.1109/ICB.2015.7139100
   Selwal A., 2016, PERSPECT SCI, V8, P705, DOI DOI 10.1016/j.pisc.2016.06.065
   Sutcu Y, 2007, IEEE T INF FOREN SEC, V2, P503, DOI 10.1109/TIFS.2007.902022
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Uludag U, 2004, PROC SPIE, V5306, P622, DOI 10.1117/12.530907
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Wang S, 2013, J INEQUAL APPL, DOI 10.1186/1029-242X-2013-81
   Wong WJ, 2013, PATTERN RECOGN LETT, V34, P1221, DOI 10.1016/j.patrec.2013.03.039
   Yang WC, 2014, PATTERN RECOGN, V47, P1309, DOI 10.1016/j.patcog.2013.10.001
   Zhang L, 2009, LECT NOTES COMPUTER, V5702, DOI 10.1007/978-3-642-03767-2_17
NR 39
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7547
EP 7566
DI 10.1007/s11042-020-10127-w
EA OCT 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858300003
DA 2024-07-18
ER

PT J
AU Marandi, YMH
   Sajedi, H
   Pirasteh, S
AF Marandi, Yasaman Mashhadi Hashem
   Sajedi, Hedieh
   Pirasteh, Sepehr
TI A novel method to musicalize shape and visualize music and a novel
   technique in music cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Musical notation; Synesthesia; Music cryptography; Graphical notation;
   Composition
ID SYNESTHESIA
AB Since many years ago, musicians have composed music based on the images that they have had in their minds. On the other hand, music affects people's imagination while hearing it. This research provides a method that can transform shape to music and music to shape. This method defines musical notations for horizontal, diagonal and vertical line segments, filled circle and curve with different colors, which are the basis of many shapes in transforming shapes into music. Then these primary mappings are generalized to more complex forms to transform any shape. Moreover, music can be transformed into shape by this method. For this transformation, primary musical notations such as simple notes, notes joined by a legato, notes with a staccato, notes joined by a legato and have crescendo or decrescendo and notes with an accent or a trill are defined. These primary musical notations are generalized to more complex forms to transform any music into shape. Also, the method of this research can be used in music cryptography. It employs mapping of notes in a twelve-tone equal musical system into shapes and mappings of shapes with an equal line width and different colors into music.
C1 [Marandi, Yasaman Mashhadi Hashem; Sajedi, Hedieh] Univ Tehran, Sch Math Stat & Comp Sci, Coll Sci, Tehran, Iran.
   [Pirasteh, Sepehr] Cent Michigan Univ, Sch Mus, Coll Arts & Media, Mt Pleasant, MI 48859 USA.
C3 University of Tehran; Central Michigan University
RP Sajedi, H (corresponding author), Univ Tehran, Sch Math Stat & Comp Sci, Coll Sci, Tehran, Iran.
EM marandi.yasaman@ut.ac.ir; hhsajedi@ut.ac.ir; pirasls@cmich.edu
OI sajedi, hedieh/0000-0003-4782-9222
CR [Anonymous], 2012, SELTZ BEND DENT
   Apel W., 2003, The Harvard dictionary of music
   Berman G, 1999, LEONARDO, V32, P15, DOI 10.1162/002409499552957
   Boenn G., 2018, Computational models in rhythm and meter
   Burk P, 2011, PREFACE ARCH VERSION
   Calude CS, 2013, TEXTS THEORETICAL CO
   Campen V, 2010, CRETIEN HIDDEN SENSE
   Chuang M.-C., 2013, International Journal of Music Education, V31, P394, DOI DOI 10.1177/0255761413489082
   Fornari J, 2011, REV EIMAS
   Goldreich O., 2019, FDN CRYPTOGRAPHY PRO, P411
   Güçlütürk Y, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00674
   HALPERN AR, 1982, AM J PSYCHOL, V95, P31, DOI 10.2307/1422658
   Isaacson EJ, 2005, P ISMIR 2005 6 INT C
   Kennedy Michael., 2004, The Concise Oxford Dictionary of Music
   Kumar C., 2015, International Journal of Multimedia and Ubiquitous Engineering, V10, P187
   Kumar C, 2015, INT J SECUR APPL, V9, P237, DOI 10.14257/ijsia.2015.9.1.23
   Lamaute N, 2016, P STUD FAC RES DAY C
   London J, 2019, ATTEN PERCEPT PSYCHO, V81, P2461, DOI 10.3758/s13414-019-01722-7
   Mark L, 2014, P ANN INT WORKSH DAT
   Milhaud D, 2018, S BAY CHAMBER MUSIC
   Nikitin N, 2017, 4 INT RES C INF TECH
   Patterson RD, 2010, SPRINGER HANDB AUDIT, V36, P13, DOI 10.1007/978-1-4419-6114-3_2
   Percino G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115255
   Plack C. J., 2006, Pitch: neural coding and perception, V24
   Pryer A, 2011, OXFORD COMPANION
   Puckette M., 1996, P 2 INTERCOLLEGE COM, P37
   Qadir A.M., 2019, 2019 7TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSICS AND SECURITY (ISDFS), P1
   Rodrguez-Gonzalez S, 2018, INT JOINT C SOCO 18, V771
   Sams E, 1979, CRYPTOLOGIA, V3, P193, DOI 10.1080/0161-117991854052
   Sams E, 2016, MUSICAL CRYPTOGRAPHY
   Seaberg M., 2011, Tasting the universe: People who see colors in words and rainbows in symphonies
   Shmulevich Ilya., 2000, Rhythm Perception and Production, P239
   Smith SM, 1997, VISUALIZATION '97 - PROCEEDINGS, P499, DOI 10.1109/VISUAL.1997.663931
   Stokley SR, 2018, Historic Look on Color Theory
   Strayer HopeR., 2013, Musical Offerings, V4, P1, DOI DOI 10.15385/JM0.2013.4.1.1
   Tesla N, 2007, STRANGE LIFE N TESLA, V1
   Thul E, 2008, RHYTHM COMPLEXITY ME
   Tucker G.M., 2011, The Oxford Companion to Music
   Vuust P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01111
   Wei CC, 2015, IEEE SYS MAN CYBERN, P2015, DOI 10.1109/SMC.2015.351
   Xing BX, 2019, IEEE ACCESS, V7, P136378, DOI 10.1109/ACCESS.2019.2942073
   Yastrebtsev V, 1999, RIMSKY KORSAKOVS COL, V1908, P39
NR 42
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7451
EP 7477
DI 10.1007/s11042-020-09962-8
EA OCT 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584568100001
DA 2024-07-18
ER

PT J
AU Pillai, KGR
   Radhakrishnan, K
   Ramakrishnan, D
   Yesudhas, HR
   Eanoch, GJ
   Kumar, R
   Long, HV
   Son, L
AF Pillai, Karthik Ganesh Ramaswamy
   Radhakrishnan, Kanthavel
   Ramakrishnan, Dhaya
   Yesudhas, Harold Robinson
   Eanoch, Golden Julie
   Kumar, Raghvendra
   Long, Hoang Viet
   Son, Le Hoang
TI Compression based clustering technique for enhancing accuracy in web
   scale videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Mining; Web scale environment; Block detection; Animated
   video; SVM classification
ID REPRESENTATION; EXTRACTION
AB Detection and clustering of commercial advertisements plays an important role in multimedia indexing also in the creation of personalized user content. In existing methodologies, the mining techniques were text, image, audio retrieval based on knowledge based environment and commercial video retrieval based on rule-based algorithms, logo-based algorithms, recognition based methods. The quality video with enhanced accuracy has been detected using the automated commercial and general program for video detection technique. The clustering technique implements the clustering process for the entire video to the frames and the required main frames are depended on the total amount of frames. The key frames are extracted from the video sequences and the duplicate key frames are eliminated from the video sequences. The video compression feature has been optimized using hybrid end-to-end compression technique to extract the features and reconstruct the video frames. The main encoding algorithm performs the optimization to produce the encoded frames and it is further compressed using the additional encoding algorithm. The performance results show that the proposed technique has the improved performances in terms of MSE, PSNR, SSIM, compression ratio and the computation time which is compared with the related techniques.
C1 [Pillai, Karthik Ganesh Ramaswamy] SCAD Coll Engn & Technol, Dept Comp Sci & Engn, Tirunelveli, India.
   [Radhakrishnan, Kanthavel; Ramakrishnan, Dhaya] King Khalid Univ, Dept Comp Engn, Abha, Saudi Arabia.
   [Yesudhas, Harold Robinson] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Eanoch, Golden Julie] Anna Univ Reg Campus, Dept Comp Sci & Engn, Tirunelveli, India.
   [Kumar, Raghvendra] GIET Univ, Comp Sci & Engn Dept, Gunupur, Odisha, India.
   [Long, Hoang Viet] Ton Duc Thang Univ, Inst Computat Sci, Div Computat Math & Engn, Ho Chi Minh City, Vietnam.
   [Long, Hoang Viet] Ton Duc Thang Univ, Fac Math & Stat, Ho Chi Minh City, Vietnam.
   [Son, Le Hoang] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
C3 King Khalid University; Vellore Institute of Technology (VIT); VIT
   Vellore; Anna University; GIET University; Ton Duc Thang University; Ton
   Duc Thang University; Vietnam National University Hanoi
RP Long, HV (corresponding author), Ton Duc Thang Univ, Inst Computat Sci, Div Computat Math & Engn, Ho Chi Minh City, Vietnam.; Long, HV (corresponding author), Ton Duc Thang Univ, Fac Math & Stat, Ho Chi Minh City, Vietnam.
EM hoangvietlong@tdt.edu.vn
RI ; ROBINSON, HAROLD/A-1545-2016
OI Hoang Son, Le/0000-0001-6356-0046; ROBINSON, HAROLD/0000-0002-4881-7103
CR Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Agustsson E., 2020, P IEEE CVF C COMP VI, P8503
   Bapu J Joshua, 2019, EARTH SCI INFORM, P1
   Borji A, 2014, arXiv Prepr, Patent No. 14115878
   Bruhn A, 2003, LECT NOTES COMPUT SC, V2756, P222
   Djelouah A, 2019, IEEE I CONF COMP VIS, P6430, DOI 10.1109/ICCV.2019.00652
   Dönderler ME, 2005, MULTIMED TOOLS APPL, V27, P79, DOI 10.1007/s11042-005-2715-7
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   Fallahpour M, 2014, IEEE T INSTRUM MEAS, V63, P1057, DOI 10.1109/TIM.2014.2299371
   Fan JP, 2001, J ELECTRON IMAGING, V10, P895, DOI 10.1117/1.1406944
   Feng JY, 2017, IEEE INT CONF MOB CL, P9, DOI 10.1109/MobileCloud.2017.9
   Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953
   Nguyen GN, 2019, INT J MACH LEARN CYB, V10, P1, DOI 10.1007/s13042-017-0691-7
   Long HV, 2019, COMPUT IND ENG, V127, P687, DOI 10.1016/j.cie.2018.11.007
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Jha S, 2019, MEASUREMENT, V134, P762, DOI 10.1016/j.measurement.2018.11.006
   Kaur S, 2019, J INDIAN SOC REMOTE, V47, P427, DOI 10.1007/s12524-019-00946-2
   Khedr M, 2007, I C WIREL COMM NETW, P480, DOI 10.1109/WICOM.2007.126
   Koprulu M, 2004, INFORM SCIENCES, V160, P131, DOI 10.1016/j.ins.2003.08.011
   Kostavelis I, 2012, IEEE T MANAG ENG, P12
   Son LH, 2019, APPL INTELL, V49, P172, DOI 10.1007/s10489-018-1262-7
   Lin JP, 2020, PROC CVPR IEEE, P3543, DOI 10.1109/CVPR42600.2020.00360
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Lu Z, 2017, INT CONF ACOUST SPEE, P1857, DOI 10.1109/ICASSP.2017.7952478
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Meinhardt-Llopis E, 2013, IMAGE PROCESS ON LIN, V3, P151, DOI 10.5201/ipol.2013.20
   Robinson YH, 2019, WIRELESS PERS COMMUN, V104, P1149, DOI 10.1007/s11277-018-6074-x
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sevilmis T, 2008, IMAGE VISION COMPUT, V26, P1384, DOI 10.1016/j.imavis.2008.01.001
   Shishido H, 2019, J VIS COMMUN IMAGE R, V62, P68, DOI 10.1016/j.jvcir.2019.04.010
   Singh N, 2020, ENG COMPUT-GERMANY, V36, P185, DOI 10.1007/s00366-018-00696-8
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sushma B, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101940
   Tiwari AK, 2017, SIGNAL PROCESS-IMAGE, V53, P73, DOI 10.1016/j.image.2017.01.010
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Yang Y, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115982
   Yildirim Y, 2013, IEEE T KNOWL DATA EN, V25, P47, DOI 10.1109/TKDE.2011.189
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhu XB, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107619
NR 42
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7077
EP 7101
DI 10.1007/s11042-020-10062-w
EA OCT 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583495900001
DA 2024-07-18
ER

PT J
AU Flotynski, J
AF Flotynski, Jakub
TI Creating explorable extended reality environments with semantic
   annotations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extended reality; 3D Web; Exploration; Reasoning; Queries; Semantic web;
   Ontologies; Annotations
ID 3D CONTENT; REPRESENTATION; ONTOLOGY
AB The main element of extended reality (XR) environments is behavior-rich 3D content consisting of objects that act and interact with one another as well as with users. Such actions and interactions constitute the evolution of the content over time. Multiple application domains of XR, e.g., education, training, marketing, merchandising, and design, could benefit from the analysis of 3D content changes based on general or domain knowledge comprehensible to average users or domain experts. Such analysis can be intended, in particular, to monitor, comprehend, examine, and control XR environments as well as users' skills, experience, interests and preferences, and XR objects' features. However, it is difficult to achieve as long as XR environments are developed with methods and tools that focus on programming and 3D modeling rather than expressing domain knowledge accompanying content users and objects, and their behavior. The main contribution of this paper is an approach to creating explorable knowledge-based XR environments with semantic annotations. The approach combines description logics with aspect-oriented programming, which enables knowledge representation in an arbitrary domain as well as transformation of available environments with minimal users' effort. We have implemented the approach using well-established development tools and exemplify it with an explorable immersive car showroom. The approach enables efficient creation of explorable XR environments and knowledge acquisition from XR.
C1 [Flotynski, Jakub] Poznan Univ Econ & Business, Niepodleglosci 10, PL-61875 Poznan, Poland.
C3 Poznan University of Economics & Business
RP Flotynski, J (corresponding author), Poznan Univ Econ & Business, Niepodleglosci 10, PL-61875 Poznan, Poland.
EM flotynski@kti.ue.poznan.pl
RI Flotyński, Jakub/IWU-8229-2023
OI Flotyński, Jakub/0000-0001-5104-2022
CR [Anonymous], 2015, SEM TRIN
   [Anonymous], 2018, LEAP MOT DOC
   [Anonymous], 2012, ARXIV12014089
   [Anonymous], 2015, LECT NOTES BUSINESS, DOI DOI 10.1007/978-3-319-19027-3
   [Anonymous], 2009, Encyclopedia of Database Systems, DOI DOI 10.1007/978-0-387-39940-91318
   Autodesk, 2020, 3DS MAX
   Autodesk, 2020, MOT BUILD
   Ben Ellefi M, 2019, ONTOLOGY BASED WEB T
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Brickley D., 2014, FOAF Vocabulary Speci cation
   Chmielewski J, 2014, MULTIMED TOOLS APPL, V69, P773, DOI 10.1007/s11042-012-1125-x
   Chu Y-L, 2012, APPL VIRTUAL REALITY, P171
   De Troyer Olga, 2007, Virtual Reality, V11, P89, DOI 10.1007/s10055-006-0058-y
   De Troyer O., 2007, Tutorials, posters, panels and industrial contributions at the 26th international conference on Conceptual modeling-Volume 83, V83, P3
   Divakaran A., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P29
   Drap P, 2017, IN SY AP IN WE HC, V10577, P3, DOI 10.1007/978-3-319-70407-4_1
   Facebook Technologies, 2018, OCULUS RIFT
   Flotynski J, 2018, LECT NOTES COMPUT SC, V10851, P589, DOI 10.1007/978-3-319-95282-6_42
   Flotynski J, 2017, COMPUT GRAPH FORUM, V36, P329, DOI 10.1111/cgf.13083
   Flotynski J, 2016, GRAPH MODELS, V88, P23, DOI 10.1016/j.gmod.2016.07.001
   Flotynski Jakub, 2013, 1 INT C BUILDING EXP, P63
   Flotyski J, 2014, P 5 DOCT C COMP EL I
   Flotyski J, 2013, P 5 JOINT VIRT REAL
   Flotyski J, 2019, INT C 3D IMM IC3D DE
   Garcia-Rojas A, 2006, P 1 INT WORKSH SHAP, P63
   Gownder J., 2016, Breakout vendors: Virtual and augmented reality"
   Gutiérrez M, 2007, VISUAL COMPUT, V23, P207, DOI 10.1007/s00371-006-0093-4
   ISO, 2015, 15938132015 ISOIEC
   Kalogerakis E, 2006, P IEEE VIRT REAL ANN, P43, DOI 10.1109/VR.2006.41
   Lugrin JL, 2009, THESIS
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Nowak A, 2018, WEB3D 2018: THE 23RD INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3208806.3208832
   Pellens B., 2009, P 6 AUSTR C INT ENT, P1
   Perez-Gallardo Y, 2017, INTEL SYST REF LIBR, V120, P137, DOI 10.1007/978-3-319-51905-0_7
   Pozna University of Economics and Business, 2018, VIRT CAR SHOWR
   Rabattu PY, 2015, J BIOMED SEMANT, V6, DOI 10.1186/s13326-015-0034-0
   Semiodesk GmbH, 2015, SEM TINYVIRTUOSO
   Sikos L., 2017, Description Logics in Multimedia Reasoning
   Sikos LF., 2017, P 22 INT C 3D WEB TE, P1
   Trellet M, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2018-0004
   Trellet M, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P48, DOI 10.1109/IMMERSIVE.2016.7932383
   Vasilakis G, 2010, INT J SOFTW ENG KNOW, V20, P739, DOI 10.1142/S0218194010004773
   W3C, 2017, X3D
   W3C, 2014, RDF
   W3C, 2012, WEB ONT LANG, V2
   W3C, 2013, SPARQL
   W3C, 2014, RDFS
   W3C, 2012, OWL
   Walczak K, 2015, WEB3D 2015, P123, DOI 10.1145/2775292.2775311
   Web3D Consortium, 2019, X3D ONT SEM WEB
   Welty C, 2006, FRONT ARTIF INTEL AP, V150, P226
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
NR 53
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6959
EP 6989
DI 10.1007/s11042-020-09772-y
EA OCT 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000581569500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, L
   Wang, GD
   Hou, GJ
AF Chen, Lei
   Wang, Guodong
   Hou, Guojia
TI Multi-scale and multi-column convolutional neural network for crowd
   density estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Density map; Multi-channels; Dilated
   convolution
AB In order to accurately identify objects of different sizes, we propose an efficient Multi-Scale and Multi-Column Convolutional Neural Network (MSMC) to estimate the crowd density. On the one hand, the ground truth is generated based on the existed label information. On the other hand, the image is fed into our model to find the relationship between the ground truth and the predicted density map. The network is composed of three components: feature extraction, feature fusion and feature regression. First, VGG16 is utilized for faster feature extraction. Second, different sizes layers from VGG16 are fused, which helps the detection of objects with different sizes. Third, we apply multi-channel convolution to further solve the issue of multi-sizes. After the fusion block, the dilated convolution is employed to strengthen the receptive field without increasing the amount of parameters. In the crowd density estimation, the combination of multiple sizes and multiple channels enhances the ability of receiving information, improves the mapping ability of the original image and the density map, and promotes the accuracy of crowd density estimation. In this paper, the test results of the ShanghaiTech Dataset and UCF_CC_50 Dataset are provided in the Experiment section, which shows that the proposed method makes an excellent performance in both accuracy and robustness.
C1 [Chen, Lei; Wang, Guodong; Hou, Guojia] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
C3 Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
EM doctorwgd@gmail.com
FU Natural Science Foundation of Shandong Province, China [ZR2019MF050,
   ZR2019BF042]; National Natural Science Foundation of China [61901240]
FX The research work is supported by the Natural Science Foundation of
   Shandong Province, China (No. ZR2019MF050, ZR2019BF042), National
   Natural Science Foundation of China (No. 61901240).
CR Aich S., 2019, P IEEE C COMP VIS PA, P73
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deb D, 2018, IEEE COMPUT SOC CONF, P308, DOI 10.1109/CVPRW.2018.00057
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Hu SY, 2020, MULTIMED TOOLS APPL, V79, P1427, DOI 10.1007/s11042-019-08241-5
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li K., 2021, Machine Learning for Predictive Analysis, V2020, P529, DOI 10.1201/9781351003827-2
   Li M, 2008, INT C PATT RECOG, P1998
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu XL, 2018, PROC CVPR IEEE, P7661, DOI 10.1109/CVPR.2018.00799
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmoud H, 2020, DEEP LEARNING COMPUT
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17
   Revathi T, 2020, SOFT COMPUTING PROBL, P531
   Sam DB, 2018, 32 AAAI C AI
   Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shi ML, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON INDUSTRIAL ARTIFICIAL INTELLIGENCE (IAI 2019), DOI 10.1109/iciai.2019.8850794
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P1057, DOI 10.1007/s11042-019-08208-6
   Wang YJ, 2019, MULTIMED TOOLS APPL, V78, P19945, DOI 10.1007/s11042-019-7377-y
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Yu F., 2015, ARXIV
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang C, 2016, IEEE T MULTIMEDIA, V18, P1048, DOI 10.1109/TMM.2016.2542585
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 48
TC 7
Z9 7
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6661
EP 6674
DI 10.1007/s11042-020-10002-8
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000580398000001
DA 2024-07-18
ER

PT J
AU Zhu, R
   Li, XF
   Zhang, XL
   Xu, XW
AF Zhu, Rui
   Li, Xiongfei
   Zhang, Xiaoli
   Xu, Xiaowei
TI MRI enhancement based on visual-attention by adaptive contrast
   adjustment and image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MRI image enhancement; Tissue attenuation; Visual-attention; Image
   quality; Image fusion
ID HISTOGRAM EQUALIZATION; MEDICAL IMAGES; SINGLE-IMAGE; ALGORITHM;
   OPTIMIZATION; ILLUMINATION; SCHEME; INDEX
AB Motivation: Medical image enhancement is a crucial part to improve the quality of the images. The excellent visual effects and image quality can help doctors make quick diagnoses. Among medical images, Magnetic Resonance Imaging (MRI) images play a vital role in clinical diagnosis. Its imaging principle highlights the human tissue part ignoring the boundary information sometimes. Moreover, some imaging results lose details in visual due to the low contrast and the quality of the images. To overcome these limitations, we propose an MRI enhancement method based on visual-attention by means of contrast adjustment and illumination component preservation. Description: The proposed framework includes image generation and image fusion to tackle the limitation of a single image. First, we assume an MRI image composed of tissues and details. We design an adaptive attenuation weight matrix based on the input MRI image according to a new definition of pixel energy. Then, an illumination-preserving image is introduced into the model for the attenuated image as compensation. Finally, an effective image fusion decision map calculation method is devised to create an enhanced MRI image with higher contrast and better perceptual quality. Results and conclusion: The experimental results show that it is a more effective enhancement method which has better performance on most of the objective evaluation metrics and stability than other 14 methods as well as maintains the balance between contrast and illumination of enhanced MRI images.
C1 [Zhu, Rui; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Zhu, Rui; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Xu, Xiaowei] Univ Arkansas, Dept Informat Sci, Little Rock, AR 72204 USA.
C3 Jilin University; Jilin University; University of Arkansas System;
   University of Arkansas Little Rock; University of Arkansas Fayetteville
RP Zhang, XL (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.; Zhang, XL (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM zhangxiaoli@jlu.edu.cn
RI Zhang, Xiaoli/ABC-2210-2021
OI Zhu, Rui/0000-0002-6037-6515
FU National Natural Science Foundation of China [61272209, 61801190];
   Natural Science Foundation of Jilin Province [20180101055JC];
   Outstanding Young Talent Foundation of Jilin Province [20180520029JH];
   China Postdoctoral Science Foundation [2017M611323]; Industrial
   Technology Research and Development Funds of Jilin Province
   [2019C054-3]; "Thirteenth Five-Year Plan" Scientific Research Planning
   Project of Education Department of Jilin Province [JJKH20200997KJ,
   JJKH20200678KJ]; Fundamental Research Funds for the Central
   Universities, JLU
FX This study was funded by National Natural Science Foundation of China
   under Grant 61272209 and Grant 61801190, the Natural Science Foundation
   of Jilin Province under Grant 20180101055JC, the Outstanding Young
   Talent Foundation of Jilin Province under Grant 20180520029JH, the China
   Postdoctoral Science Foundation under Grant 2017M611323, the Industrial
   Technology Research and Development Funds of Jilin Province under Grant
   2019C054-3, the "Thirteenth Five-Year Plan" Scientific Research Planning
   Project of Education Department of Jilin Province under Grant
   JJKH20200997KJ and Grant JJKH20200678KJ and the Fundamental Research
   Funds for the Central Universities, JLU.
CR Agarwal M, 2018, PROCEDIA COMPUT SCI, V125, P149, DOI 10.1016/j.procs.2017.12.021
   Baumgartner CF, 2017, FULLY CONVOLUTIONAL
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chaudhary P, 2018, ADV INTELL SYST COMP, V632, P585, DOI 10.1007/978-981-10-5520-1_53
   Chaudhry H, 2018, MULTIMED TOOLS APPL, V77, P15485, DOI 10.1007/s11042-017-5126-7
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen Y, 2020, JOURNAL OF AMBIENT I
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Daniel E, 2016, COMPUT BIOL MED, V71, P149, DOI 10.1016/j.compbiomed.2016.02.011
   Deng H, 2016, SCI REP-UK, V6, DOI 10.1038/srep35760
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Figueiredo MAT, 2007, IEEE T IMAGE PROCESS, V16, P2980, DOI 10.1109/TIP.2007.909318
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fu KR, 2017, IEEE T MULTIMEDIA, V19, P1531, DOI 10.1109/TMM.2017.2679898
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Gong T, 2017, ENG APPL ARTIF INTEL, V62, P405, DOI 10.1016/j.engappai.2016.10.004
   Hait E, 2019, IEEE T IMAGE PROCESS, V28, P880, DOI 10.1109/TIP.2018.2872630
   Hossain Md Foisal, 2010, 2010 IEEE/ICME International Conference on Complex Medical Engineering. CME 2010, P58, DOI 10.1109/ICCME.2010.5558871
   Huang CC, 2019, IEEE T IMAGE PROCESS, V28, P127, DOI 10.1109/TIP.2018.2865637
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jabeen A, 2016, IEEE SENS J, V16, P7534, DOI 10.1109/JSEN.2016.2600483
   Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099
   Koay CG, 2006, J MAGN RESON, V179, P317, DOI 10.1016/j.jmr.2006.01.016
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lerga J, 2018, IMAGING SCI J, V66, P372, DOI 10.1080/13682199.2018.1486561
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li YC, 2016, OPTIK, V127, P1326, DOI 10.1016/j.ijleo.2015.07.177
   Lin SCF, 2015, COMPUT ELECTR ENG, V46, P356, DOI 10.1016/j.compeleceng.2015.06.001
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P9033, DOI 10.1007/s11042-017-5277-6
   Mahmood A, 2019, IEEE ACCESS, V7, P161584, DOI 10.1109/ACCESS.2019.2951468
   Muniyappan S, 2019, MULTIMED TOOLS APPL, V78, P6487, DOI 10.1007/s11042-018-6355-0
   Muslim HSM, 2019, COMPUT MATH ORGAN TH, V25, P108, DOI 10.1007/s10588-018-9274-8
   Nandal A, 2018, IET SIGNAL PROCESS, V12, P514, DOI 10.1049/iet-spr.2017.0272
   Ni L, 2011, INT C PAR DISTRIB SY, P534, DOI 10.1109/ICPADS.2011.89
   Oktay O., 2017, IEEE T MED IMAGING, V37, P384, DOI DOI 10.1109/TMI.2017.2743464
   Park JS, 2019, MULTIMED TOOLS APPL, V78, P20263, DOI 10.1007/s11042-019-7384-z
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Ren X., 2018, P IEEE INT S CIRC SY, P1, DOI [10.1109/IS CAS.2018.8351427., DOI 10.1109/ISCAS.2018.8351427]
   Sadad T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061900
   Singh B.B., 2017, INT J COMPUT APPL, V167, P0975
   Starck JL, 2003, IEEE T IMAGE P
   Tanaka M, 2019, I SYMP CONSUM ELECTR, DOI DOI 10.1109/icce.2019.8662059
   Tian QC, 2018, SIGNAL PROCESS, V153, P210, DOI 10.1016/j.sigpro.2018.07.022
   Toor AA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072131
   Wang SH, 2018, IEEE T IMAGE PROCESS, V27, P938, DOI 10.1109/TIP.2017.2771449
   Wang YF, 2016, NEUROCOMPUTING, V177, P373, DOI 10.1016/j.neucom.2015.10.124
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xie YX, 2016, MULTIMED TOOLS APPL, V75, P14367, DOI 10.1007/s11042-016-3358-6
   Xu C, 2019, MULTIMED TOOLS APPL, V79, P1
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P18043, DOI 10.1007/s11042-017-4444-0
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2012, IEEE IMAGE PROC, P1473, DOI 10.1109/ICIP.2012.6467149
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zheng H, 2018, IEEE ACCESS, V6, P57856, DOI 10.1109/ACCESS.2018.2873484
   Zhou F, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/3969152
   Zhou T, 2019, IEEE T MED IMAGING, V38, P2411, DOI 10.1109/TMI.2019.2913158
   Zhou T, 2019, HUM BRAIN MAPP, V40, P1001, DOI 10.1002/hbm.24428
NR 68
TC 7
Z9 7
U1 2
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 12991
EP 13017
DI 10.1007/s11042-020-09543-9
EA OCT 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000574727600008
DA 2024-07-18
ER

PT J
AU Kumar, G
   Keserwani, P
   Roy, PP
   Dogra, DP
AF Kumar, Gautam
   Keserwani, Prateek
   Roy, Partha Pratim
   Dogra, Debi Prosad
TI Logo detection using weakly supervised saliency map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Saliency map; GrabCut; Logo detection;
   Weakly supervised
ID NETWORKS
AB Box level annotation of a large number of logo images for training purpose of typical deep learning architecture is highly challenging. Thus, a method that can detect the logo with the help of training to remove box-level annotations can be helpful. In this paper, we present a method of logo detection that utilizes weakly supervised learning of Convolutional Neural Network (CNN) to generate a deep saliency map. The saliency map is generated from the back-propagated response of the CNN trained with the classification task. The saliency map produces responses for the regions of logos. GrabCut segmentation method has been applied then to obtain the bounding box corresponding to the logo class predicted by the CNN for a given image. AlexNet, CaffeNet, and VGGNet deep architectures has been fine-tuned for the classification purpose. The framework is further utilized for detection through a back-propagated saliency map. The performance of the proposed methodology has been validated on the FlickrLogos-32 logo benchmark dataset. The proposed method outperforms the state-of-the-art baseline fully supervised methods with mean average precision (mAP) of 75.83%.
C1 [Kumar, Gautam; Keserwani, Prateek; Roy, Partha Pratim] Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttar Pradesh, India.
   [Dogra, Debi Prosad] IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Bhubaneswar
RP Kumar, G (corresponding author), Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttar Pradesh, India.
EM gautamkumar72@gmail.com; pkeserwani@cs.iitr.ac.in; proy.fcs@iitr.ac.in;
   dpdogra@iitbbs.ac.in
RI Roy, Partha/J-2168-2019
FU DST-SERB [SB/S3/EECE/099/2016]
FX The authors would like to acknowledge the support of DST-SERB. The
   Project ID is SB/S3/EECE/099/2016.
CR Alaei A, 2016, COMPUT SCI REV, V22, P47, DOI 10.1016/j.cosrev.2016.09.002
   [Anonymous], 2015, ARXIV151002131
   [Anonymous], 2014, WORKSHOP INT C LEARN
   [Anonymous], 2010, IEEE T SIGNAL PROCES
   [Anonymous], 2009, P 17 ACM INT C MULTI, DOI DOI 10.1145/1631272.1631361
   Bhunia AK, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106965
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Biswas C, 2014, THESIS
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Candemir S, 2013, I S BIOMED IMAGING, P1473
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Cheng Ming-Ming., 2011, Image, V2, P9
   Chong TT, 2014, EUR C COMP VIS, V86, P431
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao K, 2009, IEEE INT CON MULTI, P322, DOI 10.1109/ICME.2009.5202500
   Gao RW, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114539
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoi S.C.H., 2015, IEEE T PATT AN MACH, V46, P2403
   Inseop Na, 2013, International Journal of Contents, V9, P6, DOI 10.5392/IJoC.2013.9.1.006
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kalantidis Y, 2011, P 1 ACM INT C MULT R, P20
   Keserwani Prateek, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P987, DOI 10.1109/ICDAR.2019.00162
   Kleban J, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1077, DOI 10.1109/ICME.2008.4607625
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lin Y, 2014, SALIENCY DETECTION D
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Pham TD, 2003, PATTERN RECOGN, V36, P3023, DOI 10.1016/S0031-3203(03)00125-0
   Pigou L, 2018, INT J COMPUT VISION, V126, P430, DOI 10.1007/s11263-016-0957-7
   Plath N., 2009, P 26 ANN INT C MACH, P817, DOI DOI 10.1145/1553374.1553479
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romberg S., 2011, P 1 ACM INT C MULT R, P1
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rusinol Marcal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P111, DOI 10.1109/ICDAR.2009.103
   Salakhutdinov, 2015, ARXIV151104119
   Sanyal S., 2007, Proc. of 15th ACM International conference on Multimedia, P166
   Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107003
   Su H, 2017, IEEE INT CONF COMP V, P270, DOI 10.1109/ICCVW.2017.41
   Su H, 2017, IEEE WINT CONF APPL, P530, DOI 10.1109/WACV.2017.65
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tang PP, 2017, NEUROCOMPUTING, V236, P113, DOI 10.1016/j.neucom.2016.08.110
   Tang P, 2018, LECT NOTES COMPUT SC, V11215, P370, DOI 10.1007/978-3-030-01252-6_22
   Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang HF, 2010, CHIN CONTR CONF, P2712
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Xing LJ, 2019, IEEE I CONF COMP VIS, P9125, DOI 10.1109/ICCV.2019.00922
   Yang K, 2019, IEEE I CONF COMP VIS, P8371, DOI 10.1109/iccv.2019.00846
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang SS, 2018, IEEE T PATTERN ANAL, V40, P973, DOI 10.1109/TPAMI.2017.2700460
   Zhang YF, 2014, LECT NOTES COMPUT SC, V8485, P805, DOI 10.1007/978-3-319-08010-9_86
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu G, 2007, PROC INT CONF DOC, P864
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
NR 67
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4341
EP 4365
DI 10.1007/s11042-020-09813-6
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573766700006
DA 2024-07-18
ER

PT J
AU Bhattacharya, R
   Malakar, S
   Ghosh, S
   Bhowmik, S
   Sarkar, R
AF Bhattacharya, Rajdeep
   Malakar, Samir
   Ghosh, Soulib
   Bhowmik, Showmik
   Sarkar, Ram
TI Understanding contents of filled-in <i>Bangla</i> form images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Form processing; Text non-text separation; Touching component
   separation; Alphanumeric separation; Bangla script
ID TEXT SEPARATION; HANDWRITTEN; RECOGNITION
AB With a wide variety of forms being generated in different organizations daily, efficient and quick retrieval of information from these forms becomes a pressing need. The data on these forms are imperative to any commercial or professional purpose and thus, efficient retrieval of this data is important for further processing of the same. An automatic form processing system retrieves the content of a filled-in form image for useful storage of the same. Despite a large population of the world speaking in Bangla, to the best of our knowledge, there is no significant research work found in literature which deals with form data written in Bangla. To bridge this research gap, in the present scope of the work, we have developed a system that addresses four important aspects of processing of form data written using Bangla script. Our work has primarily been divided into four major modules: touching component separation, text non-text separation, handwritten printed text separation and alphabet numeral separation. The vital problem of touching component separation has been addressed using a novel rule-based method. For text non-text separation, handwritten printed text separation and alphabet numeral separation, we have used a machine learning based approach using feature engineering where the model for each case has been finalized after exhaustive experiments. Further, in each of the last three modules, we have applied some new features along with some existing features to appropriately tune the modules to obtain optimum results. Notably, we have also prepared a self-made database of filled-in forms. To create different training models, first the filled-in form images are binarized, and then different types of components are colored uniquely to obtain images which act as the ground truth for our reference. Evaluation of modules on the said database produces reasonably satisfactory results considering the complexity of the research problem. The code along with some filled-in sample form images and their respective ground truth images are provided in the link https://github.com/rajdeep-cse17/Form_Processing..
C1 [Bhattacharya, Rajdeep; Ghosh, Soulib; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata, India.
   [Bhowmik, Showmik] Ghani Khan Choudhury Inst Engn & Technol, Dept Comp Sci & Engn, Malda, India.
C3 Jadavpur University
RP Malakar, S (corresponding author), Asutosh Coll, Dept Comp Sci, Kolkata, India.
EM rajdeep.cse17@gmail.com; malakarsamir@gmail.com; ghoshsoulib@gmail.com;
   showmik.cse@gmail.com; raamsarkar@gmail.com
RI Malakar, Samir/A-8021-2017; Sarkar, Ram/AAX-3822-2020; Bhowmik,
   Showmik/M-4248-2017
OI Malakar, Samir/0000-0003-4217-2372; Sarkar, Ram/0000-0001-8813-4086; 
CR [Anonymous], 2013, ARXIV13034614
   Antonacopoulos A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1132, DOI 10.1109/ICDAR.1995.602119
   Bhowmik S, 2018, INT J DOC ANAL RECOG, V21, P1, DOI 10.1007/s10032-018-0296-z
   Bhowmik S, 2017, ADV INTELL SYST, V458, P507, DOI 10.1007/978-981-10-2035-3_52
   Chatelain C, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P93, DOI 10.1109/IWFHR.2004.11
   Dutly N, 2019, PROC INT CONF DOC, P20, DOI 10.1109/ICDARW.2019.10033
   FUKUSHIMA K, 1991, IEEE T NEURAL NETWOR, V2, P355, DOI 10.1109/72.97912
   Garlapati BM, 2017, UKSIM INT CONF COMP, P50, DOI 10.1109/UKSim.2017.37
   Garz A, 2011, EUR SIGNAL PR CONF, P1259
   Ghosh S, 2018, WORKSH DOC AN REC, P27
   Ghosh S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4040057
   Hamrouni S, 2014, LECT NOTES COMPUT SC, V8814, P387, DOI 10.1007/978-3-319-11758-4_42
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jana P, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P226, DOI 10.1109/CALCON.2017.8280729
   Khan T, 2020, PROCEDIA COMPUT SCI, V167, P1889, DOI 10.1016/j.procs.2020.03.208
   Khan T, 2019, MULTIMED TOOLS APPL, V78, P32159, DOI 10.1007/s11042-019-08028-8
   Koch G, 2003, PROC INT CONF DOC, P369
   Kosaraju Sai Chandra, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1029, DOI 10.1109/ICDAR.2019.00168
   Koyama J, 2008, IEEE IMAGE PROC, P1021, DOI 10.1109/ICIP.2008.4711931
   Kuhnke K., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P811, DOI 10.1109/ICDAR.1995.602025
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Majumder Bodhisattwa Prasad, 2020, P 58 ANN M ASS COMP, P6495, DOI 10.18653/v1/2020.acl-main.580
   Malakar S, 2021, NEURAL COMPUT APPL, V33, P449, DOI 10.1007/s00521-020-04981-w
   Malakar S, 2013, PROC TECH, V10, P831, DOI 10.1016/j.protcy.2013.12.428
   Mandal R, 2012, INT C PATT RECOG, P533
   Milewski RJ, 2009, INT J DOC ANAL RECOG, V11, P203, DOI 10.1007/s10032-008-0077-1
   Neelima KB, 2020, J CRIT REV, V7, P134
   Oyedotun OK, 2016, APPL INTELL, V45, P198, DOI 10.1007/s10489-015-0753-z
   Ozturk Saban, 2018, Procedia Computer Science, V132, P40, DOI 10.1016/j.procs.2018.05.057
   Patil U., 2012, INT J EMERGING TECHN, V2, P590
   Peng XJ, 2013, INT J DOC ANAL RECOG, V16, P1, DOI 10.1007/s10032-011-0179-z
   Rahal N, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), P145, DOI 10.1109/ASAR.2018.8480221
   Rasmussen LV, 2012, J AM MED INFORM ASSN, V19, pE90, DOI 10.1136/amiajnl-2011-000182
   Safonov IV, 2019, DOCUMENT IMAGE PROCE, P107, DOI DOI 10.1007/978-3-030-05342-0_5
   Sah AK, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P64, DOI 10.1109/CALCON.2017.8280697
   Sahare P, 2019, IETE TECH REV, V36, P341, DOI 10.1080/02564602.2018.1475266
   Sahare P, 2018, ARAB J SCI ENG, V43, P8159, DOI 10.1007/s13369-018-3365-1
   Seuret M, 2014, INT CONF FRONT HAND, P423, DOI 10.1109/ICFHR.2014.77
   Shih FY, 1996, IEEE T SYST MAN CY B, V26, P797, DOI 10.1109/3477.537322
   Xue WY, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P193, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00043
   Zatelli P, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8120586
NR 42
TC 8
Z9 8
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3529
EP 3570
DI 10.1007/s11042-020-09751-3
EA SEP 2020
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572039400005
DA 2024-07-18
ER

PT J
AU Wu, HY
   Cai, T
   Liu, YX
   Luo, D
   Zhang, ZA
AF Wu, Huiyue
   Cai, Tong
   Liu, Yingxin
   Luo, Dan
   Zhang, Zhian
TI Design and development of an immersive virtual reality news application:
   a case study of the SARS event
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive journalism; Virtual reality; User experience; Media effects
ID JOURNALISM; EXPERIENCE; CREDIBILITY; ATTITUDES; EMPATHY
AB In recent years, virtual reality (VR) technologies have been applied to the field of journalism, where the concept of immersive VR news has been proposed. However, despite the fanfare, strong response, and sensational effect caused by its advent, immersive VR news remains a novel journalism paradigm that faces new challenges in its production process. Currently, there is a lack of a unified design framework, and, since most studies in this area have focused on non-interactive VR news, the understanding of the effects of more interactive VR technologies on the news consumer remains inadequate. In this study, we propose a more practical design framework for immersive VR news products. Following this framework, we designed a VR news application and conducted user evaluation in terms of media effects and user experience. Based on the experimental findings, which demonstrated that non-interactive VR news products resulted in a distracting user experience and less immersion, while interactive VR news offered improved media effects and user experience, we then derived concrete design guidelines for immersive VR news design. Finally, we highlight that this study provides a theoretical and practical reference framework for the further study of VR news.
C1 [Wu, Huiyue; Cai, Tong; Liu, Yingxin; Luo, Dan; Zhang, Zhian] Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Peoples R China.
   [Wu, Huiyue; Zhang, Zhian] Guangdong Key Lab Big Data Anal & Simulat Publ Op, Guangzhou, Peoples R China.
C3 Sun Yat Sen University
RP Wu, HY (corresponding author), Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Peoples R China.; Wu, HY (corresponding author), Guangdong Key Lab Big Data Anal & Simulat Publ Op, Guangzhou, Peoples R China.
EM wuhuiyue@mail.sysu.edu.cn
OI Wu, Huiyue/0000-0001-7027-518X
FU National Natural Science Foundation of China [61772564]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61772564.
CR [Anonymous], ELEMENTS JOURNALISM
   Bardoel J., 2001, AUSTR JOURNALISM REV, V23, P91
   BASS AZ, 1969, JOURNALISM QUART, V46, P69, DOI 10.1177/107769906904600110
   BRANDT RB, 1976, J PHILOS, V73, P429, DOI 10.2307/2025781
   Bruns A., 2009, Gatewatching: Collaborative online news production
   Chia SC, 2006, J COMMUN, V56, P585, DOI 10.1111/j.1460-2466.2006.00302.x
   Chung CJ, 2012, J COMPUT-MEDIAT COMM, V17, P171, DOI 10.1111/j.1083-6101.2011.01565.x
   Cronen V.E., 1995, CONSEQUENTIALITY COM, P17
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Dominguez Eva., 2017, Frontiers in Digital Humanities, V4, DOI [10.3389/fdigh.2017.00010, DOI 10.3389/FDIGH.2017.00010]
   Donohue G.A., 1972, Current perspectives in mass communication research, P41
   Fico F., 2004, Mass Communication Society, V7, P301, DOI [DOI 10.1207/S15327825MCS0703_3, 10.1207/s15327825mcs0703_3]
   Hardee Gary M., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P679, DOI 10.1007/978-3-319-39907-2_65
   Hardee GaryM., 2017, FRONTIERS ICT, V4, P21, DOI [DOI 10.3389/FICT.2017.00021, 10.3389/fict.2017.00021]
   Heinderyckx F., 2016, Communication and Media, VXI, P29, DOI [DOI 10.5937/COMMAN11-10306, 10.5937/comman11-10306]
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jones S., 2017, Journal of Media Practice, V18, P171
   Kalyanaraman S, 2006, J COMMUN, V56, P110, DOI 10.1111/j.1460-2466.2006.00006.x
   Kang S, 2019, DIGIT JOURNAL, V7, P294, DOI 10.1080/21670811.2018.1504624
   Kang Y, 2009, J COMPUT-MEDIAT COMM, V14, P328, DOI 10.1111/j.1083-6101.2009.01443.x
   Kourmousi N., 2017, SOCIAL SCI, V6, P1
   KRUGMAN HE, 1965, PUBLIC OPIN QUART, V29, P349, DOI 10.1086/267335
   Laws ALS, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00028
   Laws ALS, 2020, DIGIT JOURNAL, V8, P213, DOI 10.1080/21670811.2017.1389286
   Lin JL, 2014, COMPUT HUM BEHAV, V36, P129, DOI 10.1016/j.chb.2014.03.054
   Luther CA, 2009, J COMMUN, V59, P279, DOI 10.1111/j.1460-2466.2009.01416.x
   Mabrook R, 2019, JOURNALISM STUD, V20, P2096, DOI 10.1080/1461670X.2019.1568203
   McGloin R, 2015, J COMMUN, V65, P280, DOI 10.1111/jcom.12148
   MEYER P, 1988, JOURNALISM QUART, V65, P567, DOI 10.1177/107769908806500301
   Neisser U., 1967, COGNITION REALITY PR
   Nielsen SL, 2021, JOURNALISM, V22, P2637, DOI 10.1177/1464884919869399
   Park N, 2010, J COMMUN, V60, P40, DOI 10.1111/j.1460-2466.2009.01440.x
   Paterson C, 2008, MEDIEKULTUR J MED CO, V24, P3
   Perry D., 2002, THEORY RES MASS COMM, V2nd
   Rath RA, 2015, VIRTUAL REALITY JOUR
   Reese SD, 2001, JOURNALISM MASS COMM, V78, P641, DOI 10.1177/107769900107800402
   Reis AB, 2018, DIGIT JOURNAL, V6, P1090, DOI 10.1080/21670811.2018.1502046
   SHAW EF, 1973, JOURNALISM QUART, V50, P306, DOI 10.1177/107769907305000213
   Shin D, 2019, INFORM COMMUN SOC, V22, P1212, DOI 10.1080/1369118X.2017.1411519
   Shin D, 2018, NEW MEDIA SOC, V20, P2800, DOI 10.1177/1461444817733133
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Shoemaker Pamela J., 2009, Gatekeeping theory, DOI DOI 10.4324/9780203931653
   Sirkkunen E., 2016, Proceedings of the 20th international academic mindtrek conference, P297, DOI DOI 10.1145/2994310.2994353
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Tse A., 2017, P 2017 CHI C HUM FAC, P2967, DOI DOI 10.1145/3027063.3053225
   Van Damme K, 2019, JOURNALISM STUD, V20, P2053, DOI 10.1080/1461670X.2018.1561208
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   White A, 5 PRINCIPLES ETHICAL
   White DM, 1950, JOURNALISM QUART, V27, P383, DOI 10.1177/107769905002700403
   Wondra JD, 2015, PSYCHOL REV, V122, P411, DOI 10.1037/a0039252
NR 50
TC 11
Z9 11
U1 6
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2773
EP 2796
DI 10.1007/s11042-020-09863-w
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570041000001
PM 32958995
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Mirbolouk, S
   Valizadeh, M
   Amirani, MC
   Choukali, MA
AF Mirbolouk, Sedighe
   Valizadeh, Morteza
   Amirani, Mehdi Chehel
   Choukali, Mohammad Amin
TI A fuzzy histogram weighting method for efficient image contrast
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Fuzzy system; Histogram weighting; Fuzzy clustering
ID FACE RECOGNITION; EQUALIZATION; ALGORITHM; SYSTEM; FRAMEWORK
AB Image contrast enhancement is an important step in digital image processing applications. In this paper, we present an efficient contrast enhancement approach, which employs a histogram weighting method based on fuzzy system. It is able to enhance the contrast of input images while preserving their details. The proposed method divides the histogram of the original image into three sub-histograms using Fuzzy clustering. The obtained sub-histograms are weighted based on the Mamdani Fuzzy inference system, and then they are summed to generate a new histogram. The produced histogram is modified to reduce undesirable effects of its spikes and pits. Finally, the enhanced image is obtained by equalization of the modified histogram. The Mamdani fuzzy inference system assigns an appropriate dynamic range to each input interval of gray levels (sub-histogram), hence enhancing the image details. Experimental results for different types of images verified the merit of the proposed method in terms of preservation the input image details and improving its contrast.
C1 [Mirbolouk, Sedighe; Valizadeh, Morteza; Amirani, Mehdi Chehel; Choukali, Mohammad Amin] Urmia Univ, Dept Elect & Comp Engn, Orumiyeh, Iran.
C3 Urmia University
RP Valizadeh, M (corresponding author), Urmia Univ, Dept Elect & Comp Engn, Orumiyeh, Iran.
EM mo.valizadeh@urmia.ac.ir
RI valizadeh, morteza/AAM-1447-2020; Mirbolouk, Sedighe/GXV-6023-2022;
   Chehel Amirani, Mehdi/AGL-1681-2022
OI Chehel Amirani, Mehdi/0000-0002-5179-9831
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   [Anonymous], 2009, J BIOMED OPT
   [Anonymous], FUZZY SETS THEIR APP
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Bereta M, 2013, J VIS COMMUN IMAGE R, V24, P1213, DOI 10.1016/j.jvcir.2013.08.004
   Casaca W, 2014, PATTERN RECOGN LETT, V36, P36, DOI 10.1016/j.patrec.2013.08.023
   Celik T, 2012, IEEE T IMAGE PROCESS, V21, P145, DOI 10.1109/TIP.2011.2162419
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen ZY, 2006, IEEE T IMAGE PROCESS, V15, P2290, DOI 10.1109/TIP.2006.875204
   Cheng F. C., 2013, J DISP TECHNOL, V9, P44, DOI DOI 10.1109/JDT.2012.2226234
   Choukali MA, 2020, MULTIDIM SYST SIGN P, V31, P299, DOI 10.1007/s11045-019-00666-3
   Eng HL, 2008, IEEE T CIRC SYST VID, V18, P196, DOI 10.1109/TCSVT.2007.913960
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Gonzalez R., 2002, THRESHOLDING DIGITAL, P595
   Grima MA, 2000, NEUROFUZZY MODELLING
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Hasikin K., 2012, 2012 UKSim 14th International Conference on Computer Modelling and Simulation (UKSim), P371, DOI 10.1109/UKSim.2012.60
   He XD, 2003, INFORM SOFTWARE TECH, V45, P663, DOI 10.1016/S0950-5849(03)00058-2
   Huang SC, 2014, IEEE T IMAGE PROCESS, V23, P4426, DOI 10.1109/TIP.2014.2348869
   Huang SJ, 2014, OPT LASER ENG, V52, P123, DOI 10.1016/j.optlaseng.2013.07.001
   Icen Dand Gunay S, 2019, APPL SOFT COMPUT
   Iqbal MZ, 2013, IEEE GEOSCI REMOTE S, V10, P451, DOI 10.1109/LGRS.2012.2208616
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Li M, 2014, SIGNAL PROCESS, V99, P17, DOI 10.1016/j.sigpro.2013.12.011
   Liao PS, 2001, J INF SCI ENG, V17, P713
   LIU K, 1993, PROCEEDINGS OF THE 32ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-4, P1743, DOI 10.1109/CDC.1993.325487
   Magudeeswaran V, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/891864
   Mahmood A, 2019, IEEE ACCESS, V7, P161584, DOI 10.1109/ACCESS.2019.2951468
   Meshgini S, 2013, COMPUT ELECTR ENG, V39, P727, DOI 10.1016/j.compeleceng.2012.12.011
   Monjezi M, 2009, INT J ROCK MECH MIN, V46, P1273, DOI 10.1016/j.ijrmms.2009.05.005
   Muslim HSM, 2019, COMPUT MATH ORGAN TH, V25, P108, DOI 10.1007/s10588-018-9274-8
   Olugu EU, 2012, EXPERT SYST APPL, V39, P375, DOI 10.1016/j.eswa.2011.07.026
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panetta K, 2011, IEEE T SYST MAN CY B, V41, P460, DOI 10.1109/TSMCB.2010.2058847
   Riaz MM, 2013, IEEE RAD CONF
   Shanmugavadivu P, 2016, NEUROCOMPUTING, V171, P719, DOI 10.1016/j.neucom.2015.07.015
   Shanmugavadivu P, 2014, COMPUT ELECTR ENG, V40, P757, DOI 10.1016/j.compeleceng.2013.06.013
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Sulochana S., 2011, INT J COMPUT APPL, V35, P1
   Takagi T, 1993, IEEE T SYST, P116
   Tang JR, 2014, COMPUT ELECTR ENG, V40, P86, DOI 10.1016/j.compeleceng.2014.05.017
   Tang JS, 2009, IEEE J-STSP, V3, P74, DOI 10.1109/JSTSP.2008.2011108
   Tsai CM, 2013, APPL MATH INFORM SCI, V7, P2019, DOI 10.12785/amis/070542
   Vadivel A, 2005, PROC SPIE, P598, DOI 10.1117/12.586823
   Vadivel A, 2016, PATTERN ANAL APPL, V19, P679, DOI 10.1007/s10044-014-0421-7
   Wang XW, 2017, SIGNAL PROCESS-IMAGE, V58, P187, DOI 10.1016/j.image.2017.07.009
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Yang XL, 2012, AASRI PROC, V3, P468, DOI 10.1016/j.aasri.2012.11.074
NR 53
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2221
EP 2241
DI 10.1007/s11042-020-09801-w
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569366600005
DA 2024-07-18
ER

PT J
AU Soualmi, A
   Alti, A
   Laouamer, L
AF Soualmi, Abdallah
   Alti, Adel
   Laouamer, Lamri
TI A novel blind watermarking approach for medical image authentication
   using MinEigen value features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical data protection; Semi-fragile watermarking; Imperceptibility;
   MinEigen values; Chaotic map; QIM; Blind watermarking
AB Developing new watermarking approaches that consider special features of medical images become increasingly necessary. This paper proposes a new watermarking approach to ensure medical images authenticity, using MinEigen value features, chaotic sequence, and Quantization Index Modulation (QIM) in the spatial domain. The idea is to choose the 3 x 3 non overlapping blocks around MinEigen values points, then embed the watermark bits in these blocks using a novel blind way based on chaotic sequence and QIM. The proposed technique is purely blind and fast in terms of execution time. Experimental results demonstrate that the proposed approach is robust against all DICOM JPEG compression attacks while keeping high imperceptibility.
C1 [Soualmi, Abdallah; Alti, Adel] Univ SETIF 1, Dept Comp Sci, LRSD Lab, Fac Sci, Setif 19000, Algeria.
   [Alti, Adel; Laouamer, Lamri] Qassim Univ, Dept Management Informat Syst & Prod Management, Coll Business & Econ, POB 6633, Buraydah 51452, Saudi Arabia.
C3 Universite Ferhat Abbas Setif; Qassim University
RP Alti, A (corresponding author), Univ SETIF 1, Dept Comp Sci, LRSD Lab, Fac Sci, Setif 19000, Algeria.; Alti, A (corresponding author), Qassim Univ, Dept Management Informat Syst & Prod Management, Coll Business & Econ, POB 6633, Buraydah 51452, Saudi Arabia.
EM sabdallah@univ-setif.dz; a.alti@qu.edu.sa; laoamr@qu.edu.sa
RI Adel, ALTI/AAW-2318-2021
OI Adel, ALTI/0000-0001-8348-1679; Soualmi, Abdallah/0000-0003-2107-8598
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Ali SA., 2017, J ENG APPL SCI, V12, P1582
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Arumugham S, 2019, ARAB J SCI ENG, V44, P9561, DOI 10.1007/s13369-019-03883-x
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Ernawan F, 2019, IEEE ACCESS, V7, P151985, DOI 10.1109/ACCESS.2019.2948086
   Farfoura ME, 2015, MULTIMED TOOLS APPL, P1
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Horng S., 2013, MULTIMED TOOLS APPL, P1
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim JH, 2018, DISPLAYS, V53, P1, DOI 10.1016/j.displa.2018.03.003
   Leng L, 2015, MULTIMED TOOLS APPL, P1
   Li JG, 2020, MOL PSYCHIATR, V25, P2630, DOI 10.1038/s41380-019-0364-x
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mainali P, 2011, IEEE T CIRC SYST VID, V21, P435, DOI 10.1109/TCSVT.2011.2125411
   Menendez-Ortiz A, 2019, IEEE ACCESS, V7, P132662, DOI 10.1109/ACCESS.2019.2940972
   Mishra A, 2018, J INF SECUR APPL, V38, P71, DOI 10.1016/j.jisa.2017.11.008
   Petitcolas F., 2012, WATERMARKING STIRMAR
   Phadikar A, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3030021
   Rosiyadi D, 2015, INT CARN CONF SECU, P304
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Singh S.K., 2019, J BUS RES, DOI [DOI 10.1016/J.JBUSRES.2019.04.040, 10.1016/j.jbusres.2019.04.040]
   Stavroulakis Peter., 2006, Chaos applications in telecommunications
NR 26
TC 12
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2279
EP 2293
DI 10.1007/s11042-020-09614-x
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569366600004
DA 2024-07-18
ER

PT J
AU Giveki, D
AF Giveki, Davar
TI Scale-space multi-view bag of words for scene categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene categorization; Bag of words; Scale-space features; Feature
   fusion; TF-IDF weighting
ID OF-VISUAL-WORDS; NEURAL-NETWORK; SPARSE REPRESENTATION; IMAGE
   CLASSIFICATION; FEATURES; MODEL; RETRIEVAL
AB As a widely-used method in the image categorization tasks, the Bag-of-Words (BoW) method still suffers from many limitations such as overlooking spatial information. In this paper, we propose four improvements to the BoW method to consider spatial and semantic information as well as information from multiple views. In particular, our contributions are: (a) encoding spatial information based on a combination of wavelet transform image scaling and a new image partitioning scheme, (b) proposing a spatial-information- and content-aware visual word dictionary generation approach, (c) developing a content-aware feature weighting approach to considers the significance of the features for different semantics, (d) proposing a novel weighting strategy to fuse color information when discriminative shape features are lacking. We call our method Scale-Space Multi-View Bag of Words (SSMV-BoW). We conducted extensive experiments to evaluate our SSMV-BoW and compare it to the state-of-the-art scene categorization methods. For our experiments, we use four publicly available and widely used scene categorization benchmark datasets. Results demonstrate that our SSMV-BoW outperforms the methods using both hand-crafted and deep learning features. In addition, ablation studies show that all four improvements contribute to the performance of our SSMV-BoW.
C1 [Giveki, Davar] Malayer Univ, Dept Comp Engn, POB 65719-95863, Malayer, Iran.
RP Giveki, D (corresponding author), Malayer Univ, Dept Comp Engn, POB 65719-95863, Malayer, Iran.
EM davood.giveki@gmail.com
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   [Anonymous], 2019, IEEE T IMAGE PROCESS
   [Anonymous], 2013, NIPS
   Arcos-García A, 2018, NEURAL NETWORKS, V99, P158, DOI 10.1016/j.neunet.2018.01.005
   Babaee M, 2014, INT WORK CONTENT MUL
   Bahmanyar R, 2015, IEEE GEOSCI REMOTE S, V12, P2046, DOI 10.1109/LGRS.2015.2444666
   Bai S, 2018, APPL SOFT COMPUT, V67, P183, DOI 10.1016/j.asoc.2018.03.007
   Bampis L, 2019, ROBOT AUTON SYST, V113, P104, DOI 10.1016/j.robot.2019.01.004
   Banerji S, 2013, LECT NOTES COMPUT SC, V8047, P490, DOI 10.1007/978-3-642-40261-6_59
   Bolovinou A, 2013, PATTERN RECOGN, V46, P1039, DOI 10.1016/j.patcog.2012.07.024
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Cakir F, 2011, COMPUT VIS IMAGE UND, V115, P1483, DOI 10.1016/j.cviu.2011.07.007
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Cheng C, 2019, ICMLC 2019: 2019 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P417, DOI 10.1145/3318299.3318322
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Lima GVL, 2019, EXPERT SYST APPL, V133, P215, DOI 10.1016/j.eswa.2019.05.021
   Dixit M, 2015, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2015.7298916
   Escalante HJ, 2015, NEURAL COMPUT APPL, P1
   Fan HQ, 2016, IMAGE VISION COMPUT, V47, P27, DOI 10.1016/j.imavis.2015.11.004
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farinella GM, 2016, COMPUT BIOL MED, V77, P23, DOI 10.1016/j.compbiomed.2016.07.006
   Fornoni M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.98
   Foumani SNM, 2019, J VIS COMMUN IMAGE R, V59, P195, DOI 10.1016/j.jvcir.2019.01.009
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Giveki D, 2020, OPTIK, V209, DOI 10.1016/j.ijleo.2020.164563
   Giveki D, 2017, INT J APPROX REASON, V91, P80, DOI 10.1016/j.ijar.2017.08.014
   Harada T, 2011, PROC CVPR IEEE, P1617, DOI 10.1109/CVPR.2011.5995691
   Hernández-García R, 2018, EXPERT SYST APPL, V92, P182, DOI 10.1016/j.eswa.2017.09.016
   Huang YZ, 2011, PROC CVPR IEEE, P1753, DOI 10.1109/CVPR.2011.5995682
   Khan FS, 2018, MACH VISION APPL, V29, P55, DOI 10.1007/s00138-017-0871-1
   Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li CY, 2013, INT J MULTIMED INF R, V2, P261, DOI 10.1007/s13735-013-0041-9
   Li JX, 2019, INFORM FUSION, V45, P215, DOI 10.1016/j.inffus.2018.02.005
   Li Y, 2018, IEEE T KNOWLEDGE DAT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60
   Montazer GA, 2017, NEURAL PROCESS LETT, V46, P681, DOI 10.1007/s11063-017-9614-6
   Montazer GA, 2015, OPTIK, V126, P1695, DOI 10.1016/j.ijleo.2015.05.002
   Montazer GA, 2015, NEUROCOMPUTING, V168, P221, DOI 10.1016/j.neucom.2015.05.104
   Montazer GA, 2015, LECT NOTES COMPUT SC, V9094, P503, DOI 10.1007/978-3-319-19258-1_41
   Nakayama H, 2010, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2010.5539921
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Penatti OAB, 2014, PATTERN RECOGN, V47, P705, DOI 10.1016/j.patcog.2013.08.012
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rantoson R, 2018, COMPUT VIS IMAGE UND, V167, P89, DOI 10.1016/j.cviu.2017.08.004
   Ravishankar S, 2015, IEEE J-STSP, V9, P637, DOI 10.1109/JSTSP.2015.2407860
   Saikia AR, 2019, TISSUE CELL, V57, P8, DOI 10.1016/j.tice.2019.02.001
   Shang RH, 2019, PATTERN RECOGN, V92, P219, DOI 10.1016/j.patcog.2019.03.026
   Silva FB, 2018, PATTERN RECOGN, V74, P266, DOI 10.1016/j.patcog.2017.09.018
   Stankovic RS, 2003, COMPUT ELECTR ENG, V29, P25, DOI 10.1016/S0045-7906(01)00011-8
   Sulam J, 2016, IEEE T SIGNAL PROCES, V64, P3180, DOI 10.1109/TSP.2016.2540599
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Sun YA, 2020, IEEE T EVOLUT COMPUT, V24, P394, DOI 10.1109/TEVC.2019.2916183
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Tirilly P, 2010, P INT C MULT INF RET, P323
   Upadhyay PK, 2019, J KING SAUD U COMP I
   van Gemert JC, 2008, LECT NOTES COMPUT SC, V5304, P696
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Wang RX, 2016, IEEE T IMAGE PROCESS, V25, P2117, DOI 10.1109/TIP.2016.2541318
   Wang S, 2012, PROCEEDINGS OF THE ASME SUMMER BIOENGINEERING CONFERENCE, PTS A AND B, P1079
   Wang Yuegang, 2007, 8th International Conference on Electronic Measurement & Instruments. ICEMI 2007, P3
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152
   Xiangsheng Huang, 2004, Proceedings. Third International Conference on Image and Graphics, P184
   Xiao Y, 2014, IEEE T IMAGE PROCESS, V23, P823, DOI 10.1109/TIP.2013.2295756
   Xie J, 2019, EXPERT SYST APPL, V126, P20, DOI 10.1016/j.eswa.2019.01.085
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang YB, 2015, PATTERN RECOGN, V48, P3067, DOI 10.1016/j.patcog.2015.03.012
   Yin WB, 2019, J VIS COMMUN IMAGE R, V60, P59, DOI 10.1016/j.jvcir.2019.01.002
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Yu WJ, 2019, PATTERN RECOGN, V91, P322, DOI 10.1016/j.patcog.2019.03.006
   Zhang SL, 2014, COMPUT VIS IMAGE UND, V118, P16, DOI 10.1016/j.cviu.2013.03.008
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
   Zhu SS, 2014, MACH VISION APPL, V25, P1561, DOI 10.1007/s00138-014-0622-5
NR 86
TC 20
Z9 20
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1223
EP 1245
DI 10.1007/s11042-020-09759-9
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871700003
DA 2024-07-18
ER

PT J
AU Goyal, K
   Singhai, J
AF Goyal, Kalpana
   Singhai, Jyoti
TI Recursive-learning-based moving object detection in video with dynamic
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Background modeling; Moving object detection;
   Segmentation; Foreground matching
AB Moving object detection is a fundamental and critical task in video surveillance systems. It is very challenging for complex scenes having slow-moving and paused objects. This paper proposes a moving object detection algorithm which combines Gaussian mixture model with foreground matching. This algorithm is able to detect slow-moving and paused objects very effectively. This algorithm uses adaptive learning rate to deal with different rates of change in background. The performance of the proposed algorithm is evaluated on the challenging videos containing strong dynamic background and slow-moving and paused objects using standard performance metrics. Experimental results show that the proposed method achieves 25%average improvement in accuracy compared over existing algorithms.
C1 [Goyal, Kalpana; Singhai, Jyoti] MANIT Bhopal, Bhopal, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Goyal, K (corresponding author), MANIT Bhopal, Bhopal, India.
EM kalpana.goyal19@gmail.com
RI Singhai, Jyoti/AAU-2844-2021
OI Singhai, Jyoti/0000-0002-7096-9269
CR [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2002, P IM VIS COMP NZ 200
   [Anonymous], 2012, P IEEE C COMP VIS PA
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T., 2010, Handbook of Pattern Recognition and Computer Vision, V4th, P181, DOI [10.1142/9789814273398_0008, DOI 10.1142/9789814273398_0008]
   Butler D, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P341
   Chen ZZ, 2014, COMPUT VIS IMAGE UND, V122, P35, DOI 10.1016/j.cviu.2014.01.004
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Ilyas A, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P454, DOI 10.1109/AVSS.2009.85
   Jiang S, 2018, IEEE T IND INFORM, V14, P3376, DOI 10.1109/TII.2017.2779814
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Li L., 2003, MULTIMEDIA 03 P 11 A, P2, DOI DOI 10.1145/957013.957017
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   Roy A., 2010, ESA, P157
   Shah M, 2014, MACH VISION APPL, V25, P1105, DOI 10.1007/s00138-013-0552-7
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Zheng Y, 2006, TRANSP RES REP, V1944, P82, DOI [10.1177/0361198106194400111, DOI 10.1177/0361198106194400111]
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 21
TC 4
Z9 4
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1375
EP 1386
DI 10.1007/s11042-020-09588-w
EA SEP 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871700009
DA 2024-07-18
ER

PT J
AU Zhou, K
   Ding, Y
   Bi, WH
AF Zhou, Kui
   Ding, Ye
   Bi, Weihong
TI High-capacity PVO-based reversible data hiding scheme using changeable
   step size
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RDH; PVO; Changeable step size; Block selection
ID IMAGE AUTHENTICATION; EXPANSION
AB Reversible data hiding (RDH) algorithm based on pixel-value-ordering (PVO) has received widespread attention because of its excellent performance. PVO algorithm divides the host image into non-overlapped equal-sized blocks, then achieves data embedding by modifying the maximum and minimum values of each block. Every pixel block can be a host of watermark data, so the smaller number of pixel blocks limit the embedding capacity (EC). In our work, a novel PVO with changeable step size (CPVO) is presented which can choose suitable step size based on the number of watermark data bits, even that allow one block to overlap other ones. Take the block size 2 x 2 as an example, we can set step size 2 x 1 or another one in CPVO. Consequently, with a block selection skill based on the noise level (NL) of a pixel block, CPVO can embed more hidden data bits into a host image. Compared to the original PVO-based schemes, experimental results show that our proposed scheme increases the EC by 2 similar to 3 times, and the marked image quality keeps much higher, even outperforms some other state-of-the-art works in some test images.
C1 [Zhou, Kui; Ding, Ye; Bi, Weihong] Zhejiang Univ, Sch Math Sci, Hangzhou 310000, Peoples R China.
C3 Zhejiang University
RP Bi, WH (corresponding author), Zhejiang Univ, Sch Math Sci, Hangzhou 310000, Peoples R China.
EM zhoukui@zju.edu.cn; 21635028@zju.edu.cn; bivh@zju.edu.cn
RI Wang, Ling/KBA-9814-2024
OI Wang, Ling/0000-0003-0272-2974
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Chang KC, 2018, MULTIMED TOOLS APPL, V77, P23579, DOI 10.1007/s11042-017-5547-3
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/104835
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P6225, DOI 10.1007/s11042-017-4533-0
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kumar R, 2020, INFORM SCIENCES, V536, P101, DOI 10.1016/j.ins.2020.05.047
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Leng L., 2013, P 6 INT C IM SIGN PR, P1694
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Pan Z., 2020, MULTIMED TOOLS APPL, P1
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, 6TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P21, DOI 10.1109/IAI.2004.1300937
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tian J., 2002, Proceedings of workshop on multimedia and security p, P19
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Yin MS, 2017, IOP C SER EARTH ENV, V69, DOI 10.1088/1755-1315/69/1/012160
NR 38
TC 9
Z9 9
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1123
EP 1141
DI 10.1007/s11042-020-09374-8
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566665500001
DA 2024-07-18
ER

PT J
AU Sharma, SS
   Chandrasekaran, V
AF Sharma, Sai Shyam
   Chandrasekaran, V
TI A robust hybrid digital watermarking technique against a powerful
   CNN-based adversarial attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Convolutional autoencoder; Copyright protection;
   Adversarial attacks; Hybrid transforms
ID IMAGE WATERMARKING; KARHUNEN-LOEVE; DCT-DWT; SCHEME; TRANSFORM;
   ALGORITHM
AB Digital watermarking techniques are valuable tools to embed digital signatures on multimedia content to establish the legal ownership and authenticity claims by the owners. Firstly this paper investigates the robustness of popular transform domain-based digital image watermarking schemes such as DCT, SVD, DWT, and their hybrid combinations against known image processing type attacks such as image blurring, compression, noise addition, rotation and cropping. Then, an enhanced hybrid scheme using DWT and SVD methods is proposed and its improved performance is demonstrated in terms of the quality of the extracted watermarks measured in terms of PSNR, SSIM and NCC values. This paper then proposes a novel adversarial attack based on a powerful Deep Convolutional Neural Network based Autoencoder(CAE) scheme. The CAE is specifically chosen to exploit its intrinsic capability to represent the image content (spatial and structural) through lower dimensional projections in the intermediate layers. The CAE is trained and tested on the entire image repository of the CIFAR10 data set. Once CAE is trained on a class of images and the parameters are frozen, it will serve as a system to produce a perceptually close image for any unseen input image belonging to the same class. The power of the proposed adversarial attack scheme is shown in terms of the quality of extracted watermarks against popular water mark embedding schemes. Finally the proposed enhanced hybrid strategy of DWT+SVD is shown to be robust against the new form of attack and outperforms all other techniques measured in terms of its high quality watermark extraction.
C1 [Sharma, Sai Shyam; Chandrasekaran, V] Sri Sathya Sai Inst Higher Learning, Anantapur, Andhra Pradesh, India.
C3 Sri Sathya Sai Institute of Higher Learning
RP Sharma, SS (corresponding author), Sri Sathya Sai Inst Higher Learning, Anantapur, Andhra Pradesh, India.
EM saishyamsharma@gmail.com; vchandrasekaran@sssihl.edu.in
OI , Sai Shyam/0000-0002-8113-7994
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2012, CHOICE WAVELET WAVEL
   Baluja S, 2020, IEEE T PATTERN ANAL, V42, P1685, DOI 10.1109/TPAMI.2019.2901877
   Barni M, 2002, J ELECTRON IMAGING, V11, P87, DOI 10.1117/1.1426383
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bhagyashri SK, 2010, INT CONF COMP SCI, P337, DOI 10.1109/ICCSIT.2010.5563757
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Böhme R, 2016, ARTECH H COMP SEC LI, P231
   Botta M, 2015, SOFT COMPUT, V19, P1905, DOI 10.1007/s00500-014-1373-y
   Brannock E, 2008, PROCEEDINGS IEEE SOUTHEASTCON 2008, VOLS 1 AND 2, P587
   Cao L., 2006, Singular value decomposition applied to digital image processing,'' Division Comput. Stud., P1
   Chandra DS, 2002, 2002 45 MIDW S CIRC, V3, P3
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dutt S, 2016, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA 2016), P61, DOI 10.1109/RADIOELEK.2016.7477392
   El Bireki MFM, 2016, INT J SECUR APPL, V10, P107, DOI 10.14257/ijsia.2016.10.5.10
   Ganic E., 2003, P IASTED INT C COMM, V85
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Hayes J., 2017, Adv. Neural Inf. Process, P1
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Jayalakshmi M, 2006, INT C PATT RECOG, P861
   Jiwu Huang, 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P239, DOI 10.1109/ISCAS.2001.922029
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Kasban H, 2017, MULTIDIM SYST SIGN P, V28, P573, DOI 10.1007/s11045-015-0361-4
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Lu C.-S., 2004, Multimedia Security: Steganography and Digital Watermarking Techniques for Protection of Intellectual Property: Steganography and Digital Watermarking Techniques for Protection of Intellectual Property
   Milano D, 2012, CISC VIS NETW IND GL
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Mukherjee S, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI'12), P573
   Najih A, 2017, J KING SAUD UNIV-COM, V29, P288, DOI 10.1016/j.jksuci.2016.02.005
   Narang M., 2013, INT J COMPUT APPL, V74, P34, DOI [10.5120/13029-0219, DOI 10.5120/13029-0219]
   Niu XM, 2000, IEEE T CONSUM ELECTR, V46, P137, DOI 10.1109/30.826391
   ORuanaidh JJK, 1996, IEE P-VIS IMAGE SIGN, V143, P250, DOI 10.1049/ip-vis:19960711
   Vo PH, 2017, 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P331, DOI 10.1109/NAFOSTED.2017.8108087
   Saxena P., 2012, 2 INT C COMP SCI INF, P28
   Saxena V., 2010, International Journal of Computer Applications, V3, P28
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Singh P. J., 2013, ISRN BIOMATER, P1
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Sverdlov ED, 2005, MOL B INT U, P1
   Tao B, 1997, INT CONF ACOUST SPEE, P2985, DOI 10.1109/ICASSP.1997.595419
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Xia XG, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P548, DOI 10.1109/ICIP.1997.647971
   Zaboli S, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P1687, DOI 10.1109/ISIE.2007.4374858
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
NR 51
TC 11
Z9 13
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32769
EP 32790
DI 10.1007/s11042-020-09555-5
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563606500001
DA 2024-07-18
ER

PT J
AU Zhang, YS
   Davison, BD
AF Zhang, Youshan
   Davison, Brian D.
TI Domain adaptation for object recognition using subspace sampling demons
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Object recognition; Subspace sampling
AB Manually labeling data for training machine learning models is time-consuming and expensive. Therefore, it is often necessary to apply models built in one domain to a new domain. However, existing approaches do not evaluate the quality of intermediate features that are learned in the process of transferring from the source domain to the target domain, which results in the potential for sub-optimal features. Also, transfer learning models in existing work do not provide optimal results for a new domain. In this paper, we first propose a fast subspace sampling demons (SSD) method to learn intermediate subspace features from two domains and then evaluate the quality of the learned features. To show the applicability of our model, we test our model using a synthetic dataset as well as several benchmark datasets. Extensive experiments demonstrate significant improvements in classification accuracy over the state of the art.
C1 [Zhang, Youshan; Davison, Brian D.] Lehigh Univ, Comp Sci & Engn, Bethlehem, PA 18015 USA.
C3 Lehigh University
RP Zhang, YS (corresponding author), Lehigh Univ, Comp Sci & Engn, Bethlehem, PA 18015 USA.
EM yoz217@lehigh.edu; bdd3@lehigh.edu
RI Davison, Brian D./I-2774-2019
OI Davison, Brian D./0000-0002-9326-3648; Zhang,
   Youshan/0000-0002-0074-0979
CR [Anonymous], 2018, P IEEE C COMP VIS PA
   Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e
   Ben-David S., 2010, INT C ART INT STAT, P129
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bergamo Alessandro, 2010, ADV NEURAL INFORM PR, V23
   Blitzer J., 2008, ADV NEURAL INFORM PR, P129, DOI DOI 10.5555/2981562.2981579
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Chen C., 2019, P AAAI
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Ghifary M, 2014, LECT NOTES ARTIF INT, V8862, P898, DOI 10.1007/978-3-319-13560-1_76
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Jiang M, 2017, IEEE T CYBERNETICS, V47, P38, DOI 10.1109/TCYB.2015.2502483
   Jolliffe I., 2011, International Encyclopedia of Statistical Science, P1094, DOI [DOI 10.1007/978-3-642-04898-2_455, 10.1007/978-3-642-04898-2_455]
   Long M., 2018, ADV NEURAL INFORM PR, P1647
   Long M., 2017, Proc Mach Learn Res, V70, P2208
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Mansour Yishay, 2009, ARXIV09023430
   Na X, 2018, J MED INTERNET RES, V20, DOI 10.2196/11655
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rahman M. M., 2020, Domain Adapt. Vis. Understand, P81, DOI DOI 10.1007/978-3-030-30671-7-6
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Szegedy C, 2017, 31 AAAI C ART INT AR
   Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Wang C, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1273
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Wang JD, 2017, IEEE DATA MINING, P1129, DOI 10.1109/ICDM.2017.150
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang SM, 2016, CHIN CONT DECIS CONF, P3443, DOI 10.1109/CCDC.2016.7531578
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400
   Zhang Y., 2019, ARXIV190402322
   Zhang Y X., 2019, P 30 BRIT MACH VIS C, P1
   Zhang Y, 2020, BACTERIAL RESISTANCE TO ANTIBIOTICS - FROM MOLECULES TO MAN, P173
NR 43
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23255
EP 23274
DI 10.1007/s11042-020-09336-0
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000563739900011
DA 2024-07-18
ER

PT J
AU Jo, J
   Koo, HI
   Soh, JW
   Cho, NI
AF Jo, Junho
   Koo, Hyung Il
   Soh, Jae Woong
   Cho, Nam Ik
TI Handwritten Text Segmentation via End-to-End Learning of Convolutional
   Neural Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten text segmentation; Text separation; Data synthesis; Class
   imbalance problem; Optical character recognition
ID LINE EXTRACTION; ALGORITHM
AB We present a method that separates handwritten and machine-printed components that are mixed and overlapped in documents. Many conventional methods addressed this problem by extracting connected components (CCs) and classifying the extracted CCs into two classes. They were based on the assumption that two types of components are not overlapping each other, while we are focusing on more challenging and realistic cases where the components are often overlapping each other. For this, we propose a new method that performs pixel-level classification with a convolutional neural network. Unlike conventional neural network methods, our method works in an end-to-end manner and does not require any preprocessing steps (e.g., foreground extraction, handcrafted feature extraction, and so on). For the training of our network, we develop a cross-entropy based loss function to alleviate theclass imbalanceproblem. Regarding the training dataset, although there are some datasets of mixed printed characters and handwritten scripts, most of them do not have overlapping cases and do not provide pixel-level annotations. Hence, we also propose a data synthesis method that generates realistic pixel-level training samples having many overlappings of printed and handwritten components. Experimental results on synthetic and real images have shown the effectiveness of the proposed method. Although the proposed network has been trained only with synthetic images, it also improves the OCR rate of real documents. Specifically, the OCR rate for machine-printed texts is increased from 0.8087 to 0.9442 by removing the overlapped handwritten scribbles by our method.
C1 [Cho, Nam Ik] Seoul Natl Univ, Dept Elect & Comp Engn, Gwanak Ro 1, Seoul 08826, South Korea.
   [Jo, Junho; Soh, Jae Woong; Cho, Nam Ik] Seoul Natl Univ, Dept Elect & Comp Engn, INMC, Seoul, South Korea.
   [Koo, Hyung Il] Ajou Univ, Dept Elect & Comp Engn, Suwon, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU); Ajou
   University
RP Cho, NI (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, Gwanak Ro 1, Seoul 08826, South Korea.; Cho, NI (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, INMC, Seoul, South Korea.
EM nicho@snu.ac.kr
RI Cho, Nam Ik/I-5029-2014
FU Institute for Information & communications Technology Planning &
   Evaluation (IITP) - Korea government(MSIT) [NI190004]; Hancom Inc.
FX This work was supported in part by Institute for Information &
   communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government(MSIT) (No.NI190004,Development of AI based Robot
   Technologies for Understanding Assembly Instruction and Automatic
   Assembly Task Planning), and in part by Hancom Inc.
CR Antonacopoulos Apostolos, 2009, ICDAR
   Bhowmik S, 2019, FRAT INTEGRITA STRUT, P419, DOI 10.3221/IGF-ESIS.48.40
   Breuel TM, 2003, P S DOC IM UND TECHN
   Chen CW, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351436
   Franke J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P581, DOI 10.1109/ICDAR.1993.395668
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kandan R, 2007, LECT NOTES COMPUT SC, V4842, P96
   Kingma D. P., 2014, arXiv
   Koo HI, 2012, IEEE T IMAGE PROCESS, V21, P1169, DOI 10.1109/TIP.2011.2166972
   Levenshtein VI., 1966, Soviet Physics Doklady, P10
   Li XH, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P145, DOI 10.1109/DAS.2018.19
   Lin YP, 2017, MULTIMED TOOLS APPL, V76, P4123, DOI 10.1007/s11042-015-2995-5
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Neelima KB, 2020, J CRIT REV, V7, P134
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng XJ, 2013, INT J DOC ANAL RECOG, V16, P1, DOI 10.1007/s10032-011-0179-z
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ryu J, 2014, IEEE SIGNAL PROC LET, V21, P1115, DOI 10.1109/LSP.2014.2325940
   Sahare P, 2019, WAVELET TRANSFORM, V36, P341, DOI DOI 10.1080/02564602.2018.1475266
   Seuret M, 2014, INT CONF FRONT HAND, P423, DOI 10.1109/ICFHR.2014.77
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17
NR 23
TC 6
Z9 6
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32137
EP 32150
DI 10.1007/s11042-020-09624-9
EA AUG 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943300001
DA 2024-07-18
ER

PT J
AU Patel, S
   Bharath, KP
   Kumar, MR
AF Patel, Sakshi
   Bharath, K. P.
   Kumar, Rajesh M.
TI Symmetric keys image encryption and decryption using 3D chaotic maps
   with DNA encoding technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Decryption; 3D chaotic maps; DNA encoding; Symmetric keys;
   Logical operations
ID GENERATOR
AB In present digital era, multimedia like images, text, documents and videos plays a vital role, therefore due to increase in usage of digital data; there comes high demand of security. Encryption is a technique used to secure and protect the images from unfair means. In cryptography, chaotic maps play an important role in forming strong and effective encryption algorithm. In this paper 3D chaotic logistic map with DNA encoding is used for confusion and diffusion of image pixels. Additionally, three symmetric keys are used to initialize 3D chaos logistic map, which makes the encryption algorithm strong. The symmetric keys used are 32 bit ASCII key, Chebyshev chaotic key and prime key. The algorithm first applies 3D non-linear logistic chaotic map with three symmetric keys in order to generate initial conditions. These conditions are then used in image row and column permutation to create randomness in pixels. The third chaotic sequence generated by 3D map is used to generate key image. Diffusion of these random pixels are done using DNA encoding; further XOR logical operation is applied between DNA encoded input image and key image. Analysis parameters like NPCR, UACI, entropy, histogram, chi-square test and correlation are calculated for proposed algorithm and also compared with different existing encryption methods.
C1 [Patel, Sakshi; Bharath, K. P.; Kumar, Rajesh M.] VIT Univ, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Kumar, MR (corresponding author), VIT Univ, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM thesakshipatel@gmail.com; bharathkp25@gmail.com; mrajeshkumar@vit.ac.in
RI M, Dr.M Ranjith Kumar/U-4667-2019; Patel, Sakshi/JBS-6792-2023
OI M, Dr.M Ranjith Kumar/0000-0001-8411-7609; Patel,
   Sakshi/0000-0002-1606-3722; M, Dr. Rajesh Kumar/0000-0003-0350-4397
CR Abdlrudha H. H., 2011, 2011 6th International Conference for Internet Technology and Secured Transactions (ICITST), P220
   Akter MT, 2018, INT J APPL MATH THEO, V4, P84
   Al-Maadeed S., 2012, J ELECT COMPUT ENG, V2012, DOI DOI 10.1155/2012/179693
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Bengtsson SEL, 2018, ROUTL STUD DEV SOC, P1, DOI 10.4324/9781315142708
   Brindha M, 2017, 2017 INT C INT SUST
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Essaid M, 2019, 2019 INT C WIR
   Faraoun K, 2010, INT ARAB J INF TECHN, V7, P231
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Hossain M. A., 2014, MAT RENEWABLE SUSTAI, V3, P1
   Huo DM, 2019, PHYS LETT A, V383, P915, DOI 10.1016/j.physleta.2018.12.011
   Khade P.N., 2012, Int. J. Comput. Sci. Issues, V9, P323
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Masmoudi A, 2010, EUR SIGNAL PR CONF, P1504
   Ratinder Kaur VK, 2012, INT C TRENDS EL EL P
   Saffari RM, 2016, 24 IR C EL ENG ICEE
   Safi HW, 2017, 2017 INTERNATIONAL CONFERENCE ON PROMISING ELECTRONIC TECHNOLOGIES (ICPET 2017), P66, DOI 10.1109/ICPET.2017.18
   Srivastava A., 2012, INT J EMERGING TECHN, V2, P163
   Tang Z., 2019, SHOCK VIB, V2019, P1
   Wang XY, 2005, CHINESE J APPL MECH, P501
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J., 2014, MATH PROBL ENG, V2014, P10, DOI DOI 10.1016/J.IJEPES.2014.09.041
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
NR 30
TC 33
Z9 33
U1 3
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31739
EP 31757
DI 10.1007/s11042-020-09551-9
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360200003
DA 2024-07-18
ER

PT J
AU Khan, M
   Jamal, SS
   Waqas, UA
AF Khan, Majid
   Jamal, Sajjad Shaukat
   Waqas, Umer Aziz
TI A novel combination of information hiding and confidentiality scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic Lorenz system; Information confidentiality; Information hiding
ID CONSTRUCTION; MAP; BOX
AB Due to exponential technological advancement, secure transmission of multimedia content is a serious challenge. These days, securing and hiding digital information most efficiently is the focus of the digital computer world. Information confidentiality and information hiding namely steganography, are the most promising techniques that can protect digital information. In this paper, a combination of encryption and steganography is used efficiently to have a double level of security to achieve confidentiality, privacy, secrecy in addition to integrity and authentication. Firstly, encryption parameters are set by using a chaotic Lorenz system (CLS), then by using CLS encryption parameter encryption is performed on the secret image. This enciphered confidential digital medium is inserted in the cover image by using the least significant bits (LSBs) steganographic scheme. Due to the double level of security, it is hard for an eavesdropper to attack the proposed scheme. All experimental and simulation results verify the efficiency of the proposed information hiding scheme.
C1 [Khan, Majid] Inst Space Technol, Cyber & Informat Secur Lab, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Jamal, Sajjad Shaukat] King Khalid Univ, Coll Sci, Dept Math, Abha, Saudi Arabia.
   [Waqas, Umer Aziz] Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
C3 King Khalid University
RP Khan, M (corresponding author), Inst Space Technol, Cyber & Informat Secur Lab, Islamabad, Pakistan.; Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019; Jamal, Sajjad/AHE-6498-2022
OI Khan, Majid/0000-0001-5454-3770; 
FU Deanship of Scientific Research at King Khalid University [R. G. P.
   1/234/41]
FX One of the author Dr. Sajjad Shaukat Jamal extends his gratitude to the
   Deanship of Scientific Research at King Khalid University for funding
   this work through research groups program under grant number R. G. P.
   1/234/41.
CR Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Alghafis A, 2020, WIREL NETW, DOI 10.1007/s11276-020-02363-7
   Alghafis A, 2020, PHYSICA A, V554, DOI 10.1016/j.physa.2019.123908
   Alghafis A, 2020, INT J THEOR PHYS, V59, P1227, DOI 10.1007/s10773-020-04402-7
   Alharan AF., 2019, INDONES J ELECT ENG, V14, P1433, DOI [10.11591/ijeecs.v14.i3.pp1433-1442, DOI 10.11591/IJEECS.V14.I3.PP1433-1442]
   Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   Arshad U, 2020, PHYSICA A, V546, DOI 10.1016/j.physa.2019.123458
   Attaullah, 2020, WIRELESS PERS COMMUN, V110, P1429, DOI 10.1007/s11277-019-06793-1
   Batool S, 2014, NEURAL COMPUT APPL, V25, P2037, DOI 10.1007/s00521-014-1691-0
   Campbell DL, 2017, CLIN INTERV AGING, V12, P2077, DOI 10.2147/CIA.S143307
   Hussain I, 2014, Z NATURFORSCH A, V69, P249, DOI 10.5560/ZNA.2014-0016
   Hussain I, 2014, OPT LASER TECHNOL, V61, P50, DOI 10.1016/j.optlastec.2014.01.018
   Jamal SS, 2019, CHINESE J PHYS, V61, P301, DOI 10.1016/j.cjph.2019.09.006
   Jamal SS, 2019, WIREL NETW, V25, P1491, DOI 10.1007/s11276-017-1606-y
   Jamal SS, 2016, WIRELESS PERS COMMUN, V90, P2033, DOI 10.1007/s11277-016-3436-0
   Jamal SS, 2013, NONLINEAR DYNAM, V73, P1469, DOI 10.1007/s11071-013-0877-9
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Khan M, 2017, MULTIMED TOOLS APPL, V76, P24027, DOI 10.1007/s11042-016-4090-y
   Khan M, 2015, NEURAL COMPUT APPL, V26, P845, DOI 10.1007/s00521-014-1747-1
   Khan M, 2014, NONLINEAR DYNAM, V76, P377, DOI 10.1007/s11071-013-1132-0
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Munir N, 2020, WIREL NETW, DOI 10.1007/s11276-020-02361-9
   Shah T, 2020, WIRELESS PERS COMMUN, V113, P1201, DOI 10.1007/s11277-020-07274-6
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Tariq S, 2020, MULTIMED TOOLS APPL, V79, P23507, DOI 10.1007/s11042-020-09134-8
   Waqas UA, 2020, MULTIMED TOOLS APPL, V79, P6891, DOI 10.1007/s11042-019-08570-5
   Waseem HM, 2020, IEEE ACCESS, V8, P71821, DOI 10.1109/ACCESS.2020.2987097
   Waseem HM, 2019, APPL PHYS B-LASERS O, V125, DOI 10.1007/s00340-019-7142-y
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Waseem HM, 2018, INT J THEOR PHYS, V57, P3584, DOI 10.1007/s10773-018-3872-6
NR 32
TC 6
Z9 6
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30983
EP 31005
DI 10.1007/s11042-020-09610-1
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560645900007
DA 2024-07-18
ER

PT J
AU Cejka, J
   Chmelík, J
   Liarokapis, F
AF Cejka, Jan
   Chmelik, Jiri
   Liarokapis, Fotis
TI Exploring tilting methods for typing under water
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater interaction; Typing; Keyboard; Tilting; User study
AB Underwater environments are still providing significant challenges for diver communication and interaction. Smartphones and tablets have the potential to provide great assistance for divers under water and even allow them to utilize augmented and mixed reality, but the housing solutions limit their capabilities. In particular, interaction with them cannot harness a touch screen medium. This paper presents a novel way of providing textual input in underwater environments. The concept is utilizing orientation sensors allowing for tilting a smartphone to input textual information. Three different titling configurations of keyboards were implemented and evaluated on land and in a swimming pool in a user study that involved 17 healthy volunteers and assessed their performance in two different conditions reflecting two typical diving poses. Results clearly demonstrate the benefit of this technique and suggest more effective configurations. A following discussion derives general recommendations for implementing similar methods that use tilting to interact with devices under water.
C1 [Cejka, Jan; Chmelik, Jiri] Masaryk Univ, Fac Informat, Brno, Czech Republic.
   [Liarokapis, Fotis] Res Ctr Interact Media Smart Syst & Emerging Tech, CY-1011 Nicosia, Cyprus.
C3 Masaryk University Brno
RP Cejka, J (corresponding author), Masaryk Univ, Fac Informat, Brno, Czech Republic.
EM xcejka2@fi.muni.cz
RI Chmelík, Jiří/P-4368-2019; Liarokapis, Fotis/AAQ-9498-2021
OI Chmelík, Jiří/0000-0002-6674-311X; Liarokapis,
   Fotis/0000-0003-3617-2261; Cejka, Jan/0000-0002-4460-4100
FU European Unions Horizon 2020 research and innovation program [727153];
   European Union's Horizon 2020 research and innovation programme [739578,
   H2020-WIDESPREAD-01-20162017-TeamingPhase2]; Government of the Republic
   of Cyprus through the Directorate General for European Programmes,
   Coordination and Development
FX This research is a part of the i-MareCulture project (Advanced VR,
   iMmersive Serious Games and Augmented REality as Tools to Raise
   Awareness and Access to European Underwater CULTURal heritagE, Digital
   Heritage) that has received funding from the European Unions Horizon
   2020 research and innovation program under Grant Agreement No. 727153.
   This research was also partially supported by the project that has
   received funding from the European Union's Horizon 2020 research and
   innovation programme under grant agreement No. 739578 (RISE Call:
   H2020-WIDESPREAD-01-20162017-TeamingPhase2) and the Government of the
   Republic of Cyprus through the Directorate General for European
   Programmes, Coordination and Development.
CR BELLARBI A, 2013, IEEE INT C NETW SENS, P00409, DOI DOI 10.1109/ICNSC.2013.6548773
   Castellucci SJ, 2019, MUM 2019: 18TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA, DOI 10.1145/3365610.3365629
   CEJKA J, 2020, PERSONAL UBIQUITOUS, DOI DOI 10.1007/S00779-019-01354-6
   CHIARELLA D, 2018, J MAR SCI ENG, V0006, DOI DOI 10.3390/JMSE6030091
   Council RST, 2019, MIN COURS CONT COMM
   DEMARCO KJ, 2014, IEEE SYS MAN CYBERN, P03738, DOI DOI 10.1109/SMC.2014.6974512
   Easydive, 2019, DIV
   FELEMBAN E, 2015, INT J DISTRIB SENS N
   Fitton D, 2013, P 27 INT BCS HUM COM
   Gong J, 2018, P 2018 CHI C HUM FAC, DOI [10.1145/3173574.3173755, DOI 10.1145/3173574.3173755]
   GUPTA A, 2019, CHI 2019 P 2019 CHI, DOI DOI 10.1145/3290605.3300244
   Hollien H, 2013, DIVER COMMUNICATION, P1
   HONG JG, 2015, CHI 2015 P 33 ANN, P01233, DOI DOI 10.1145/2702123.2702273
   JONES E, 2010, CHI2010 P 28 ANN, P02173, DOI DOI 10.1145/1753326.1753655
   Ljubic S, 2013, P 7 INT C UN ACC HUM, P651, DOI [10.1007/978-3-642-39194-1_75, DOI 10.1007/978-3-642-39194-1_75]
   MACKENZIE GC, 2002, TLS TIMES LIT S 0712, P00027, DOI DOI 10.1145/572020.572025
   MENIX M, 2014, 2014 37 INT CONV, P00976, DOI DOI 10.1109/MIPRO.2014.6859710
   MITAL MEG, 2018, 2018 2 INT C INF, P00147, DOI DOI 10.1109/ICICOS.2018.8621642
   Oney S, 2013, P SIGCHI C HUM FACT, P2799, DOI [10.1145/2470654.2481387, DOI 10.1145/2470654.2481387]
   Oppermann L, 2016, P 18 INT C HUM COMP, P330, DOI [10.1145/2935334.2935368, DOI 10.1145/2935334.2935368]
   Partridge K, 2002, P 15 ANN ACM S US IN, P201, DOI [10.1145/571985.572013, DOI 10.1145/571985.572013]
   Patron P., 2008, P 27 WORKSH UK PLANN
   RAHMAN M, 2009, CHI2009 P 27 ANN, P01943, DOI DOI 10.1145/1518701.1518997
   Rekimoto J, 1996, P 9 ANN ACM S US INT, P167, DOI [10.1145/237091.237115, DOI 10.1145/237091.237115]
   Schechner Y, 2004, P 2004 IEEE COMP SOC, DOI [10.1109/CVPR.2004.1315078, DOI 10.1109/CVPR.2004.1315078]
   Tcha-Tokey K., 2016, INT J VIRTUAL REALIT, V16, P33, DOI DOI 10.20870/IJVR.2016.16.1.2880
   Teather RJ, 2014, P GRAPH INT 2014 GI, P51
   WALMSLEY WS, 2014, ACM T COMPUT HUM INT, V0021, DOI DOI 10.1145/2542544
   Wigdor D, 2003, P 16 ANN ACM S US IN, P81, DOI [10.1145/964696.964705, DOI 10.1145/964696.964705]
   YEO HS, 2017, P 2017 ACM SIGCH C, P04194, DOI DOI 10.1145/3025453.3025520
NR 30
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31085
EP 31103
DI 10.1007/s11042-020-09305-7
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000560297300001
DA 2024-07-18
ER

PT J
AU Gnanasivam, P
   Sudhakar, MS
AF Gnanasivam, P.
   Sudhakar, M. S.
TI Extremely adaptive image retrieval scheme employing an optimized wavelet
   technique intended for characterization maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EAIR; IGO; MARS; Precision at 5; RAE; Volterra series
ID COMPRESSION; INTEGRATION; TRANSFORM
AB The demand for adaptive image retrieval is still an active research area, particularly in a dynamic environment. Erstwhile retrieval schemes ensure adaptivity by tuning the same image basis with wavelet transforms, in accordance with user's significance. To enhance adaptivity and improve the retrieval performance, an Extremely Adaptive Image Retrieval (EAIR) scheme is presented that associates each image with different wavelet basis. This objective is achieved by building Characterization maps from wavelet coefficients of images (query and target) using higher order standardized moments of the Gamma function. The resulting maps are approximated by Volterra Series and later, mathematically programmed by Integral Global Optimization (IGO) algorithm for wavelet adaptation. Finally, the best wavelet filter for each query image is fitted using the Multivariate Adaptive Regression Splines (MARS). Characterization Maps rendered by EAIR achieves 60% reduction in Relative Approximation Error (RAE) with 11% decrease in query time observed under diverse dataset. Also, relative Precision-Recall (P-R), Precision at 5 (P5) analyses reveals a significant retrieval improvement of 9.52%, 1.35%, 1.12%, 8.07% by EAIR on Caltech, Messidor, AT&T, Vistex respectively.
C1 [Gnanasivam, P.] Anna Univ, Dept ECE, Jerusalem Coll Engn, Chennai, Tamil Nadu, India.
   [Sudhakar, M. S.] VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Sudhakar, MS (corresponding author), VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM pgsivam@gmail.com; sudhakar.ms@vit.ac.in
RI P, GNANASIVAM/AAL-7037-2021
OI P, GNANASIVAM/0000-0002-4088-5902
CR Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BOYD S, 1985, IEEE T CIRCUITS SYST, V32, P1150, DOI 10.1109/TCS.1985.1085649
   Cherry JA, 1994, VOLTERRA SERIES, P16
   Claypoole RL, 1998, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.1998.681737
   Cui HQ, 2006, COMPUT MATH APPL, V52, P55, DOI 10.1016/j.camwa.2006.08.004
   Dewson T, 1997, COMPUT MATH APPL, V33, P5, DOI 10.1016/S0898-1221(97)00002-3
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Franz MO, 2006, NEURAL COMPUT, V18, P3097, DOI 10.1162/neco.2006.18.12.3097
   Friedman JH, 1990, SLAC
   GALPERIN EA, 1991, COMPUT MATH APPL, V21, P145, DOI 10.1016/0898-1221(91)90169-5
   Heijmans HJAM, 2006, INT J WAVELETS MULTI, V4, P41, DOI 10.1142/S0219691306001087
   Jekabsons G., 2011, ARESLab: Adaptive Regression Splines toolbox for Matlab/Octave
   Kundu MK, 2015, KNOWL-BASED SYST, V73, P254, DOI 10.1016/j.knosys.2014.10.009
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Muñoz J, 2004, J VEG SCI, V15, P285, DOI 10.1111/j.1654-1103.2004.tb02263.x
   Nadarajah S, 2005, J APPL STAT, V32, P685, DOI 10.1080/02664760500079464
   Natsev A, 2004, IEEE T KNOWL DATA EN, V16, P301, DOI 10.1109/TKDE.2003.1262183
   Piella G, 2006, J MATH IMAGING VIS, V25, P203, DOI 10.1007/s10851-006-6711-y
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Quellec G, 2012, IEEE T IMAGE PROCESS, V21, P1613, DOI 10.1109/TIP.2011.2180915
   Quellec G, 2010, IEEE T IMAGE PROCESS, V19, P25, DOI 10.1109/TIP.2009.2030479
   SANDBERG IW, 1992, IEEE T SIGNAL PROCES, V40, P1438, DOI 10.1109/78.139247
   Sandberg IW, 1985, DOUBLY FINITE VOLTER
   Sathiamoorthy S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-1941-y
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   TU RJ, 1993, COMPUT MATH APPL, V25, P9, DOI 10.1016/0898-1221(93)90276-2
   Usevitch BE, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.952803
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Varish N, 2017, MULTIMED TOOLS APPL, V76, P15885, DOI 10.1007/s11042-016-3882-4
   Vrankic M, 2004, P INT WORKSH SPECT M, P245
   Yang GH, 2016, MORGAN CLAYPOOL, P144
   Ye B, 2002, J OPT A-PURE APPL OP, V4, P606, DOI 10.1088/1464-4258/4/6/304
   Yerlikaya F., 2008, THESIS
   Zafar B, 2018, COMPUT SCI INF SYST, V15, P615, DOI [10.2298/CSIS180105025z, 10.2298/CSIS180105025Z]
   Zhao M, 2016, J VIS COMMUN IMAGE R, V38, P73, DOI 10.1016/j.jvcir.2016.02.016
   Zheng Q, 1999, COMPUT MATH APPL, V37, P41, DOI 10.1016/S0898-1221(99)00058-9
   ZHENG Q, 1991, COMPUT MATH APPL, V21, P17, DOI 10.1016/0898-1221(91)90157-Y
NR 40
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30419
EP 30438
DI 10.1007/s11042-020-09515-z
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900002
DA 2024-07-18
ER

PT J
AU Navin, MS
   Agilandeeswari, L
AF Navin, M. Sam
   Agilandeeswari, L.
TI Multispectral and hyperspectral images based land use / land cover
   change prediction analysis: an extensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Remote sensing; Land use; land cover change; Multispectral satellite
   data; Hyperspectral satellite data
ID ARTIFICIAL NEURAL-NETWORK; LOGISTIC-REGRESSION; MARKOV MODEL; SATELLITE
   IMAGERY; CLASSIFICATION; FOREST; LULC; DYNAMICS; PIXEL; TM
AB Research in the field of remote sensing attracts attention among researchers all over the world. From different remote sensing applications, the problem on Land Use/ Land Cover change analysis has been considered as the critical research for more than four decades. The researchers had discovered the new innovative ways of finding the solution to analyze the Land Use/ Land Cover change over a particular region. The multispectral and hyperspectral satellite images play a considerable part in analyzing environmental changes. Many algorithms developed and used by researchers for analyzing the Land Use/ Land Cover change are discussed in this paper. This review article aims to provide detailed analyses of performing Land Use/ Land Cover changes in the field of remote sensing. The main motive is to make the future researchers know about the flow of the Land Use/ Land Cover change analysis process and provide a clear presentation about every method. The results of this Land Use/ Land Cover problem mainly assist the land resource management, urban planners, and other government officials across the world in protecting the land resource and its nature for future needs.
C1 [Navin, M. Sam] Vellore Inst Technol, Sch Informat & Technol, Vellore, Tamil Nadu, India.
   [Agilandeeswari, L.] Vellore Inst Technol, Sch Informat & Technol, Dept Digital Commun, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Agilandeeswari, L (corresponding author), Vellore Inst Technol, Sch Informat & Technol, Dept Digital Commun, Vellore, Tamil Nadu, India.
EM agila.l@vit.ac.in
RI L, Agilandeeswari/P-8997-2016; Navin, Sam/AAA-6283-2019
OI L, Agilandeeswari/0000-0001-6147-9535; Navin, Sam/0000-0001-9068-1855
CR Abualigah L. M. Q., 2019, FEATURE SELECTION EN, V816
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Achmad A, 2015, APPL GEOGR, V62, P237, DOI 10.1016/j.apgeog.2015.05.001
   Adam E, 2014, INT J REMOTE SENS, V35, P693, DOI 10.1080/01431161.2013.870676
   Adhikari S, 2017, FORESTS, V8, DOI 10.3390/f8090342
   Ahmadlou M, 2015, INT ARCH PHOTOGRAMM, V41, P31, DOI 10.5194/isprsarchives-XL-1-W5-31-2015
   Alkaradaghi K., 2018, Journal of Geographic Information System, V10, P247, DOI 10.4236/jgis.2018.103013
   [Anonymous], 2014, GEOCARTO INT, DOI DOI 10.1080/10106049.2013.768300
   [Anonymous], 2013, ATMOSPHERIC TOPOGRAP
   [Anonymous], 2014, INT J DIGIT EARTH, DOI DOI 10.1080/17538947.2012.671378
   Ashaolu Eniola Damilola, 2019, Journal of Environmental Geography, V12, P41, DOI 10.2478/jengeo-2019-0005
   Baboo S.S., 2011, International Journal of Computer Applications, V14, P32, DOI DOI 10.5120/1808-2324
   Bagan H, 2018, EGYPT J REMOTE SENS, V21, P383, DOI [10.1016/j.ejrs.2017.12.003, DOI 10.1016/J.EJRS.2017.12.003]
   Balcik FB, 2016, INT ARCH PHOTOGRAMM, V42-2, P143, DOI 10.5194/isprs-archives-XLII-2-W1-143-2016
   Bernales A. M, 2016, INT ARCH PHOTOGRAMME, V41
   Birhane E, 2019, REMOTE SENS APPL, V13, P61, DOI 10.1016/j.rsase.2018.10.017
   Boitt M, 2014, J EARTH SCI CLIMATIC
   Bounouh O., 2017, 2017 INT C ADV TECHN, P1, DOI [10.1109/atsip.2017.8075511, DOI 10.1109/ATSIP.2017.8075511, 10.1109/ATSIP.2017.8075511]
   Cai GY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143120
   CAO C, 2019, SUSTAINABILITY BASEL, V0011, DOI DOI 10.3390/SU11195376
   Carranza-García M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030274
   Chang NB, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3518096
   Chen LP, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200493
   Chinsu Lin, 2015, Information Processing in Agriculture, V2, P25, DOI 10.1016/j.inpa.2015.01.003
   Choodarathnakara AL, 2012, INT J COMPUTER SCI E, V2, P11
   Christovam LE, 2019, INT ARCH PHOTOGRAMME
   Cleve C, 2008, COMPUT ENVIRON URBAN, V32, P317, DOI 10.1016/j.compenvurbsys.2007.10.001
   Cracknell, 2018, DEV REMOTE SENSING L, P8387
   Das P, 2019, J INDIAN SOC REMOTE, V47, P1443, DOI 10.1007/s12524-019-00986-8
   Das S, 2019, SPAT INF RES, V27, P439, DOI 10.1007/s41324-019-00251-7
   Dolati MK., 2016, RES J FOREST, V10, P23, DOI [10.3923/rjf.2016.23.29, DOI 10.3923/RJF.2016.23.29]
   El Jazouli A, 2019, REMOTE SENS APPL, V13, P361, DOI 10.1016/j.rsase.2018.12.004
   El-Hattab MM, 2016, EGYPT J REMOTE SENS, V19, P23, DOI 10.1016/j.ejrs.2016.02.002
   Elmore AJ, 2003, IEEE T GEOSCI REMOTE, V41, P1311, DOI 10.1109/TGRS.2003.813132
   Etemadi H, 2018, ENVIRON EARTH SCI, V77, DOI 10.1007/s12665-018-7392-8
   Fonji SF, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-61
   Gashaw T., 2017, Environ. Syst. Res, V6, P1, DOI [10.1186/s40068-017-0094-5, DOI 10.1186/S40068-017-0094-5]
   Guo Huadong., 2020, Manual of digital earth, DOI [https://doi.org/10.1007/978-981-32-9915-3, DOI 10.1007/978-981-32-9915-3]
   Halmy MWA, 2015, APPL GEOGR, V63, P101, DOI 10.1016/j.apgeog.2015.06.015
   Hamad R, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103421
   Heidarlou HB, 2019, LAND USE POLICY, V81, P76, DOI 10.1016/j.landusepol.2018.10.036
   Hemasinghe H, 2018, PROCEDIA ENGINEER, V212, P1046, DOI 10.1016/j.proeng.2018.01.135
   Hu YF, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10122053
   Iino S, 2018, INT J IMAGE DATA FUS, V9, P302, DOI 10.1080/19479832.2018.1491897
   IkIel C., 2012, The Online Journal of Science and Technology (TOJSAT), V2, P37
   Jahanifar K., 2018, Journal of Applied Sciences & Environmental Management, V22, P1269, DOI 10.4314/jasem.v22i8.20
   John J, 2019, ENVIRON MONIT ASSESS, V191, DOI 10.1007/s10661-019-7482-4
   Kabisch N, 2019, ECOL INDIC, V99, P273, DOI 10.1016/j.ecolind.2018.12.033
   Kale KV, 2017, P NATL A SCI INDIA A, V87, P541, DOI 10.1007/s40010-017-0433-y
   Kamal M, 2011, REMOTE SENS-BASEL, V3, P2222, DOI 10.3390/rs3102222
   Karimi H, 2018, ARAB J GEOSCI, V11, DOI 10.1007/s12517-018-3940-5
   Kavzoglu T, 2018, J INDIAN SOC REMOTE, V46, P1297, DOI 10.1007/s12524-018-0803-1
   Kumar KS., 2013, Int J Adv Trends Comput Sci Eng, V2, P87
   Kumar R, 2014, ECOL INDIC, V45, P444, DOI 10.1016/j.ecolind.2014.05.003
   Kumar S, 2014, GEOMAT NAT HAZ RISK, V5, P145, DOI 10.1080/19475705.2013.795502
   Kwan C, 2019, INFORMATION, V10, DOI 10.3390/info10110353
   Li M, 2014, EUR J REMOTE SENS, V47, P389, DOI 10.5721/EuJRS20144723
   Li ZL, 2018, SCI TOTAL ENVIRON, V636, P1180, DOI 10.1016/j.scitotenv.2018.04.361
   Malinverni ES, 2011, INT J GEOGR INF SCI, V25, P1025, DOI 10.1080/13658816.2011.566569
   Mallinis G, 2014, REMOTE SENS-BASEL, V6, P1684, DOI 10.3390/rs6021684
   Mallupattu PK, 2013, SCI WORLD J, DOI 10.1155/2013/268623
   Mann D, 2017, P NATL A SCI INDIA A, V87, P855, DOI 10.1007/s40010-017-0454-6
   Mhangara P, 2013, S AFR J SCI, V109, P34, DOI 10.1590/sajs.2013/1273
   Mirkatouli J., 2015, City Territ. Archit, V2, P4, DOI [10.1186/s40410-015-0023-8, DOI 10.1186/S40410-015-0023-8]
   Mishra, 2016, FORUM GEOGRAFIC, V15
   Mohajane M, 2018, ENVIRONMENTS, V5, DOI 10.3390/environments5120131
   Mohamed MM, 2018, EPIC SERIES ENG, V3, P1435, DOI [10.29007/jvz3, DOI 10.29007/JVZ3]
   Murtaza K. O., 2014, International Journal of Geomatics and Geosciences, V4, P585
   Mustafa EK, 2021, GEOJOURNAL, V86, P1089, DOI 10.1007/s10708-019-10115-0
   Nagne, 2017, 2017 11 INT C INT SY
   Navin, 2020, 2020 INT C EM TRENDS
   Navin M.Sam, 2019, INT J ENG ADV TECHNO, V9
   Nivedita Priyadarshini K, 2018, INT ARCH PHOTOGRAMM
   Nurfadila JS, 2019, IOP C SERIES EARTH E, V280
   Nurwanda A, 2016, PROCD SOC BEHV, V227, P87, DOI 10.1016/j.sbspro.2016.06.047
   Omeiza Daniel, 2019, ARXIV CS
   Omer G, 2015, IEEE J-STARS, V8, P4825, DOI 10.1109/JSTARS.2015.2461136
   Pande CB, 2018, APPL WATER SCI, V8, DOI 10.1007/s13201-018-0764-0
   Papadomanolaki Maria, 2019, IGARSS 2019 2019 IEE
   Pervez W, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.026004
   Petropoulos GP, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.096088
   Phiri D, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090967
   Qin HP, 2013, OPTIK, V124, P586, DOI 10.1016/j.ijleo.2011.12.058
   Ramzi AI, 2015, PROC SPIE, V9644, DOI 10.1117/12.2193727
   Reddy DS, 2018, MODEL EARTH SYST ENV, V4, P409, DOI 10.1007/s40808-018-0431-3
   Restrepo AMC, 2017, SCI TOTAL ENVIRON, V598, P669, DOI 10.1016/j.scitotenv.2017.04.124
   Rizeei HM, 2018, ARAB J GEOSCI, V11, DOI 10.1007/s12517-018-3397-6
   Rwanga S. S., 2017, International Journal of Geosciences, V8, P611, DOI 10.4236/ijg.2017.84033
   Saputra MH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11113024
   Sawant, 2020, J SPECT IMAG, V9
   Sawant SS, 2017, 2017 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT)
   Scheffler D, 2013, PROC SPIE, V8892, DOI 10.1117/12.2028733
   Serasinghe Pathiranage IS, 2018, CHINESE GEOGR SCI, V28, P274, DOI 10.1007/s11769-018-0946-6
   Sertel E, 2016, GEOMAT NAT HAZ RISK, V7, P1198, DOI 10.1080/19475705.2015.1050608
   Singh SK, 2015, ENVIRON PROCESS, V2, P61, DOI 10.1007/s40710-015-0062-x
   Stromann O, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010076
   Tajbakhsh A, 2020, ENVIRON MONIT ASSESS, V192, DOI 10.1007/s10661-020-08270-w
   Talukdar S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071135
   Taneja K, 2016, ATMOS POLLUT RES, V7, P585, DOI 10.1016/j.apr.2016.02.004
   Thanh P.N., 2018, SENSORS, V18, P1
   Tsai F, 2008, IEEE T GEOSCI REMOTE, V46, P4122, DOI 10.1109/TGRS.2008.2000646
   Twisa S, 2019, LAND-BASEL, V8, DOI 10.3390/land8090136
   Vaddi R, 2020, INFRARED PHYS TECHN, V107, DOI 10.1016/j.infrared.2020.103296
   Vibhute, 2016, P 2 INT C COMP COMM
   Vidal M, 2012, CHEMOMETR INTELL LAB, V117, P138, DOI 10.1016/j.chemolab.2012.05.009
   Young NE, 2017, ECOLOGY, V98, P920, DOI 10.1002/ecy.1730
NR 107
TC 38
Z9 38
U1 14
U2 162
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29751
EP 29774
DI 10.1007/s11042-020-09531-z
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300010
DA 2024-07-18
ER

PT J
AU Karmouni, H
   Yamni, M
   El ogri, O
   Daoui, A
   Sayyouri, M
   Qjidaa, H
AF Karmouni, H.
   Yamni, M.
   El ogri, O.
   Daoui, A.
   Sayyouri, M.
   Qjidaa, H.
TI Fast computation of 3D Meixner's invariant moments using 3D image cuboid
   representation for 3D image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D geometric invariant moments; 3D Meixner invariant moments; 3D image
   cuboid representation (ICR); 3D image classification
ID SCALE INVARIANTS; RECOGNITION; TRANSLATION; KRAWTCHOUK; NORMALIZATION
AB In this paper, we propose a new fast computation method of 3D discrete orthogonal invariant moments of Meixner. This proposed method is based on two fundamental notions: the first is the extraction of the invariants of the 3D Meixner moments from the invariant of 3D geometric moments. The second is the use of 3D image cuboid representation (ICR). In this representation, the invariant moments of Meixner will be extracted from the cuboids instead of the overall image which allows reducing considerably the invariant computation time of 3D Meixner moments and consequently reducing the time of 3D image classification as well. In fact, the proposed method is tested by using several well-known computer vision data sets, including the moment invariability and the 3D image classification. Hence, the results obtained show the moments' invariance extracted by the method proposed under the three different affine transformations: translation, scale and rotation of the 3D images, and clearly guarantee the efficiency of the proposed method in terms of calculation time and classification accuracy compared to existing methods.
C1 [Karmouni, H.; Yamni, M.; El ogri, O.; Qjidaa, H.] Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mahrez, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
   [Daoui, A.; Sayyouri, M.] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Syst & Applicat Lab, BP 72,My Abdallah Ave Km 5 Imouzzer Rd, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Karmouni, H (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mahrez, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
EM hicham.karmouni@usmba.ac.ma; mohamed.yamni@usmba.ac.ma;
   omar.elogri@usmba.ac.ma; achraf.daoui@usmba.ac.ma;
   mhamed.sayyouri@usmba.ac.ma; hassan.qjidaa@usmba.ac.ma
RI DAOUI, Achraf/AAE-7012-2022; Karmouni, Hicham/ACB-0232-2022; Ogri, Omar
   El/AFC-5868-2022; Sayyouri, Mhamed/AAB-5496-2020; Yamni,
   Mohamed/AAD-8740-2022
OI DAOUI, Achraf/0000-0002-2326-9550; Karmouni, Hicham/0000-0001-9225-8380;
   Ogri, Omar El/0000-0003-4807-0641; Sayyouri, Mhamed/0000-0002-1615-419X;
   Hassan, qjidaa/0000-0003-4505-5243; Yamni, Mohamed/0000-0002-9436-8361
CR ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617
   Batioua I, 2017, PATTERN RECOGN, V71, P264, DOI 10.1016/j.patcog.2017.06.013
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   Chong CW, 2003, PATTERN RECOGN, V36, P1765, DOI 10.1016/S0031-3203(02)00353-9
   Comtet, 2012, ADV COMBINATORICS AR
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   Hickman MS, 2012, J MATH IMAGING VIS, V44, P223, DOI 10.1007/s10851-011-0323-x
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   Hosny KM, 2012, DIGIT SIGNAL PROCESS, V22, P476, DOI 10.1016/j.dsp.2012.01.002
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P1305, DOI 10.1016/j.patrec.2011.03.011
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Idan ZN, 2020, IEEE ACCESS, V8, P41013, DOI 10.1109/ACCESS.2020.2977305
   Jahid T., 2018, J MATH IMAGING VIS, P1
   Karakasis EG, 2013, PATTERN RECOGN, V46, P1998, DOI 10.1016/j.patcog.2013.01.008
   Karmouni H, 2019, CIRC SYST SIGNAL PR, V38, P3715, DOI 10.1007/s00034-019-01025-0
   Liao S, 2002, INT C PATT RECOG, P485, DOI 10.1109/ICPR.2002.1047982
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   Nikiforov Arnold F, 1991, Springer Series in Computational Physics
   Papakostas GA, 2010, PATTERN RECOGN, V43, P58, DOI 10.1016/j.patcog.2009.05.008
   REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087
   REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   Sayyouri M, 2019, J REAL TIME IMAGE PR, P1
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Smieja M, 2019, KNOWL-BASED SYST, V173, P150, DOI 10.1016/j.knosys.2019.02.034
   Suk T, 2015, PATTERN RECOGN, V48, P3516, DOI 10.1016/j.patcog.2015.05.007
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Upneja R, 2015, PATTERN RECOGN, V48, P1836, DOI 10.1016/j.patcog.2014.11.012
   Wu H, 2013, MATH PROBL ENG, V2013
   Xia T, 2007, J OPT SOC AM A, V24, P50, DOI 10.1364/JOSAA.24.000050
   Yang B, 2015, PATTERN RECOGN LETT, V54, P18, DOI 10.1016/j.patrec.2014.11.014
   Yang B, 2011, SIGNAL PROCESS, V91, P2290, DOI 10.1016/j.sigpro.2011.04.012
   Zhang H, 2010, IEEE T IMAGE PROCESS, V19, P596, DOI 10.1109/TIP.2009.2036702
   Zhang L, 2007, IET INFORM SECUR, V1, P97, DOI 10.1049/iet-ifs:20060105
   Zhi RC, 2018, INFORM PROCESS LETT, V130, P30, DOI 10.1016/j.ipl.2017.09.010
   Zhou J., 2020, IEEE T SYSTEMS MAN C
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2007, PATTERN RECOGN, V40, P2530, DOI 10.1016/j.patcog.2006.12.003
   Zhu HQ, 2010, PATTERN ANAL APPL, V13, P309, DOI 10.1007/s10044-009-0159-9
NR 45
TC 14
Z9 14
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29121
EP 29144
DI 10.1007/s11042-020-09351-1
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557123500002
DA 2024-07-18
ER

PT J
AU Feng, N
   Song, ZK
   Yu, JQ
   Chen, YPP
   Zhao, YZ
   He, YF
   Guan, T
AF Feng, Na
   Song, Zikai
   Yu, Junqing
   Chen, Yi-Ping Phoebe
   Zhao, Yizhu
   He, Yunfeng
   Guan, Tao
TI SSET: a dataset for shot segmentation, event detection, player tracking
   in soccer videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soccer video dataset; Shot boundary detection; Shot classification;
   Event detection; Player tracking
ID OBJECT TRACKING
AB Soccer video analysis is the focus of sports video research as it receives widespread attention around the world. However, the lack of soccer datasets hinders the rapid development of this field. In this paper, we construct a soccer dataset named Soccer Dataset for Shot, Event, and Tracking (SSET), which can meet the research needs of shot segmentation, soccer event detection and player tracking. So far, we have collected 350 soccer videos, involving a variety of soccer games, for a total of 282 h. The dataset consists of three parts: (1) Shot, including five shot types and two shot transition types; (2) Event/Story, consisting of 11 fine-grained event and 15 coarse-grained story types where the story extends the event types with 4 extra types; (3) Bounding box of players, giving the coordinates, width and length of the bounding box. In addition, we develop an annotation tool called Sports Video Dataset Markup (SVDM) for sports video data annotation and hope that more people join our work. We conduct event detection and player tracking experiments on our dataset, and the results show that the existing works are not completely suitable for solving soccer video analysis tasks. Our dataset is available at http://media.hust.edu.cn/dataset.htm.
C1 [Feng, Na; Song, Zikai; Yu, Junqing; Zhao, Yizhu; He, Yunfeng; Guan, Tao] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Yu, Junqing] Huazhong Univ Sci & Technol, Ctr Network & Computat, Wuhan 430074, Peoples R China.
   [Chen, Yi-Ping Phoebe] La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic 3086, Australia.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology; La Trobe University
RP Yu, JQ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.; Yu, JQ (corresponding author), Huazhong Univ Sci & Technol, Ctr Network & Computat, Wuhan 430074, Peoples R China.; Chen, YPP (corresponding author), La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic 3086, Australia.
EM yjqing@hust.edu.cn; phoebe.chen@latrobe.edu.au
RI Song, Zikai/HSE-7269-2023; he, yun/JMB-6362-2023; Chen, Yi-Ping
   Phoebe/B-8844-2008
OI Chen, Yi-Ping Phoebe/0000-0002-4122-3767
CR Abu-El-Haija Sami, 2016, arXiv
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Apostolidis Evlampios, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6583, DOI 10.1109/ICASSP.2014.6854873
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bettadapura Vinay., 2016, P ACM INT C MULT, P908
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Ekin A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P173
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Giancola S, 2018, IEEE COMPUT SOC CONF, P1792, DOI 10.1109/CVPRW.2018.00223
   Gorban A., 2015, THUMOS challenge: Action recognition with a large number of classes
   Grigorios T, 2017, ELECT IMAGING COMPUT, V15-20
   Gygli M, 2018, INT WORK CONTENT MUL
   Hassanien A., 2017, Large-scale, fast and accurate shot boundary detection through spatio-temporal convolutional neural networks
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HOMAYOUNFAR N, 2017, PROC CVPR IEEE, P4012, DOI DOI 10.1109/CVPR.2017.427
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang HH, 2016, PROC INT C TOOLS ART, P490, DOI [10.1109/ICTAI.2016.0081, 10.1109/ICTAI.2016.78]
   Kapela R, 2015, COMPUT VIS SPORTS, P293
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lee K, 2015, IEEE WINT CONF APPL, P1177, DOI 10.1109/WACV.2015.161
   Li L, 2009, PROCEEDINGS OF THE F, P208
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Mohanta PP, 2012, IEEE T MULTIMEDIA, V14, P223, DOI 10.1109/TMM.2011.2170963
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Pappalardo L, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0247-7
   Pettersen S. A., 2014, P ACM MULT SYST C MI, P18, DOI [10.1145/2557642.2563677, DOI 10.1145/2557642.2563677]
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Priya GGL, 2012, PROC TECH, V1, P247, DOI 10.1016/j.protcy.2012.10.030
   Ramanathan V, 2016, PROC CVPR IEEE, P3043, DOI 10.1109/CVPR.2016.332
   Ravinder M, 2016, ADV INTELL SYST, V394, P599, DOI 10.1007/978-81-322-2656-7_55
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun B., 2017, P 2 INT C INT THINGS, P1
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang S, 2018, ARXIV180804234
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Teng Z, 2017, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2017.130
   Tiwari M., 2017, Int. J. Comput. Intell. Res, V13, P745, DOI DOI 10.1109/CIS.2009.13
   Tong W., 2015, 2015 IEEE INT S BROA, P1
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang N, 2013, P ADV NEURAL INFORM
   Wu LF, 2018, LECT NOTES COMPUT SC, V11257, P479, DOI 10.1007/978-3-030-03335-4_42
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yu JQ, 2019, LECT NOTES COMPUT SC, V11296, P377, DOI 10.1007/978-3-030-05716-9_31
   Yu JQ, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P418, DOI 10.1109/MIPR.2018.00090
   Zan L, 2015, MANAGING CULTURAL HERITAGE: AN INTERNATIONAL RESEARCH PERSPECTIVE, P1
NR 69
TC 12
Z9 15
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28971
EP 28992
DI 10.1007/s11042-020-09414-3
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557124000006
DA 2024-07-18
ER

PT J
AU Yu, HP
   He, FZ
   Pan, YT
AF Yu, Haiping
   He, Fazhi
   Pan, Yiteng
TI A survey of level set method for image segmentation with intensity
   inhomogeneity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intensity inhomogeneity; Level set method; Image segmentation; Computer
   vision
ID ACTIVE CONTOURS DRIVEN; GRADIENT DESCENT; MOTION ESTIMATION; FITTING
   ENERGY; ALGORITHM; TEXTURE; MODEL; OPTIMIZATION; SNAKES; FRAMEWORK
AB Image segmentation is a fundamental task in computer vision and image processing. Due to the presence of high noise, low resolution and intensity inhomogeneity, it is still a difficult problem in the practical applications. Level set methods have been widely used in image processing and computer vision. During the past decades, many models based on level set methods have been proposed to solve image segmentation with intensity inhomogeneity. It is necessary to conduct a comprehensive review and comparison of these models. Specifically, level set methods can be categorized into two groups, including edge-based level set methods (EBLSMs) and region-based level set methods (RBLSMs). This paper reviews some of the recent advances in EBLSMs and RBLSMs for segmenting image with intensity inhomogeneity. Their advantages and disadvantages are discussed in an objective point of view, and their performance is compared on image segmentation with intensity inhomogeneity. Finally, this paper further explores and discusses some open questions in segmenting images with intensity inhomogeneity.
C1 [Yu, Haiping; He, Fazhi; Pan, Yiteng] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Yu, Haiping] Huanggang Normal Univ, Sch Comp Sci, Huanggang, Peoples R China.
C3 Wuhan University; Huanggang Normal University
RP He, FZ (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM seaping@whu.edu.cn; fzhe@whu.edu.cn; panyiteng@whu.edu.cn
RI Pan, Yi/AAJ-2341-2021; He, Fazhi/Q-3691-2018
FU National Key R&D Program of China [2017YFB0503004]; Hubei Provincial
   Natural Science Foundation of China [2019CFB797]
FX We would like to thank all the anonymous reviewers for their valuable
   comments. This work is supported by National Key R&D Program of China
   (GrantNo. 2017YFB0503004) and Hubei Provincial Natural Science
   Foundation of China(Grant No. 2019CFB797).
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Allaire G, 2004, J COMPUT PHYS, V194, P363, DOI 10.1016/j.jcp.2003.09.032
   [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   [Anonymous], 2010, P INT C ADV NEUR INF
   [Anonymous], 2017, BRIEF BIOINFORM, DOI DOI 10.1093/bib/bbw068
   Arteaga-Salas JM, 2007, GENECHIPS BRIEF BIOI, V9, P25
   BARLES G, 1993, SIAM J CONTROL OPTIM, V31, P439, DOI 10.1137/0331021
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Brox T, 2004, LECT NOTES COMPUT SC, V3175, P415
   Brox Thomas., 2005, From Pixels to Regions: Partial Differential Equations in Image Analysis
   Cardinal MHR, 2006, IEEE T MED IMAGING, V25, P590, DOI 10.1109/TMI.2006.872142
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan T, 2005, PROC CVPR IEEE, P1164
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Chen YJ, 2009, COMPUT MED IMAG GRAP, V33, P510, DOI 10.1016/j.compmedimag.2009.04.009
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dong Y, 2016, IEEE J-STARS, V10, P1136
   Enright D, 2002, J COMPUT PHYS, V183, P83, DOI 10.1006/jcph.2002.7166
   Flaxman AD, 2005, PROCEEDINGS OF THE SIXTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P385
   Fu GF, 2018, BRIEF BIOINFORM, V19, P461, DOI 10.1093/bib/bbw111
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gomes J, 2000, J VIS COMMUN IMAGE R, V11, P209, DOI 10.1006/jvci.1999.0439
   He L, 2008, IMAGE VISION COMPUT, V26, P141, DOI 10.1016/j.imavis.2007.07.010
   Ji ZX, 2015, INFORM SCIENCES, V301, P285, DOI 10.1016/j.ins.2015.01.006
   Jiang XL, 2016, NEUROCOMPUTING, V207, P22, DOI 10.1016/j.neucom.2016.03.046
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim BC, 2015, J MECH SCI TECHNOL, V29, P5289, DOI 10.1007/s12206-015-1131-9
   Kim BC, 2014, COMPUT GRAPH-UK, V38, P97, DOI 10.1016/j.cag.2013.10.031
   KIMMEL R, 1995, IEEE T PATTERN ANAL, V17, P635, DOI 10.1109/34.387512
   Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Lee SH, 2006, IEEE T IMAGE PROCESS, V15, P2843, DOI 10.1109/TIP.2006.877308
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Liu C, 2019, J VIS COMMUN IMAGE R, V59, P89, DOI 10.1016/j.jvcir.2019.01.001
   Liu C, 2017, SIGNAL PROCESS, V130, P12, DOI 10.1016/j.sigpro.2016.06.013
   Liu H., 2006, PROC IEEE C COMPUT V, V1, P841
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Luo Z, 2007, J COMPUT PHYS, V227, P680, DOI 10.1016/j.jcp.2007.08.011
   Ma S, 2008, BRIEF BIOINFORM, V9, P392, DOI 10.1093/bib/bbn027
   Maitre E, 2009, MATH COMPUT MODEL, V49, P2161, DOI 10.1016/j.mcm.2008.07.026
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Malladi R, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P489, DOI 10.1109/ICIP.1996.559540
   Min H, 2016, NEUROCOMPUTING, V214, P910, DOI 10.1016/j.neucom.2016.07.023
   Min H, 2015, PATTERN RECOGN, V48, P1547, DOI 10.1016/j.patcog.2014.10.018
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Osher S, 2001, J COMPUT PHYS, V169, P463, DOI 10.1006/jcph.2000.6636
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Padfield D, 2009, MED IMAGE ANAL, V13, P143, DOI 10.1016/j.media.2008.06.018
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Sethian J.A., 2003, Journal of Computing and Information Technology, V11, P1
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Shen LQ, 2012, IEEE T IMAGE PROCESS, V21, P2582, DOI 10.1109/TIP.2011.2177849
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   Sussman M, 1999, SIAM J SCI COMPUT, V20, P1165, DOI 10.1137/S1064827596298245
   Tsai A, 2001, CURV EV IMPL MUMF SH
   Tseng P, 2009, MATH PROGRAM, V117, P387, DOI 10.1007/s10107-007-0170-0
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang L, 2015, NEUROIMAGE, V108, P160, DOI 10.1016/j.neuroimage.2014.12.042
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Wang MY, 2003, COMPUT METHOD APPL M, V192, P227, DOI 10.1016/S0045-7825(02)00559-5
   Wang XF, 2015, NEUROCOMPUTING, V151, P1086, DOI 10.1016/j.neucom.2014.01.079
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Weber M, 2004, LECT NOTES COMPUT SC, V3022, P391
   Wilkinson DJ, 2007, BRIEF BIOINFORM, V8, P109, DOI 10.1093/bib/bbm007
   Wu QG, 2015, NEUROCOMPUTING, V151, P1133, DOI 10.1016/j.neucom.2014.04.085
   Xing FY, 2016, IEEE T MED IMAGING, V35, P550, DOI 10.1109/TMI.2015.2481436
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Yan QA, 2016, COMPUT GRAPH FORUM, V35, P1, DOI 10.1111/cgf.12998
   Yang L, 2018, IEEE T VIS COMPUT GR, V24, P1190, DOI 10.1109/TVCG.2017.2657766
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang Y, 2008, MEDIVIS 2008: FIFTH INTERNATIONAL CONFERENCE BIOMEDICAL VISUALIZATION - INFORMATION VISUALIZATION IN MEDICAL AND BIOMEDICAL INFORMATICS, PROCEEDINGS, P71, DOI 10.1109/MediVis.2008.12
   Zhao YQ, 2014, PATTERN RECOGN, V47, P2437, DOI 10.1016/j.patcog.2014.01.006
   Zhu GP, 2007, OPT ENG, V46, DOI 10.1117/1.2740762
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
   Zhu Z, 2019, COMPUT BIOL MED, V109, P85, DOI 10.1016/j.compbiomed.2019.04.018
   Zhu Z, 2018, PROC SPIE, V10575, DOI 10.1117/12.2295470
   Zhu Z, 2018, IEEE T IMAGE PROCESS, V27, P2952, DOI 10.1109/TIP.2018.2808766
NR 96
TC 14
Z9 16
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28525
EP 28549
DI 10.1007/s11042-020-09311-9
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556182200006
DA 2024-07-18
ER

PT J
AU Malik, A
   Gupta, S
   Dhall, S
AF Malik, Anjali
   Gupta, Shailender
   Dhall, Sangeeta
TI Analysis of traditional and modern image encryption algorithms under
   realistic ambience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attacks; Brute force attacks; Chaotic; Cryptography; Key space; Noises;
   Performance metrics; Quantum-chaotic; Traditional techniques
AB Cryptography (encryption/decryption) is one of the prevailing mechanisms for protection of information (data or image) in the growing era of computerized exchange. It is the art of securing data/image by changing it into an unreadable format, called cipher text/image. Encryption mechanism is said to be efficient if it offers high security and robustness against attacks, and endow with very low correlation value between cipher and the original information. Enormous techniques and corresponding survey papers are available in literature considering only a few methods or parameters into account, but there is a stern need of investigation, which thoroughly considers vast variety of techniques and compares them in the light of numerous performance metrics under the influence of wide variety of probable threats. In view of the fact, this paper has taken account of almost all traditional, modern, chaotic, and quantum-chaotic based methods under the influence of prevalent intimidation and does a comprehensive investigation based on various performance metrics. To measure the efficacy, all the mechanisms are implemented in MATLAB-2014. Chaos and Quantum based algorithms are the superlative in comparison to others presented in literature under most of the extensive threats (attacks, noises etc.) and can resist brute force attacks due to large key space. In addition, suggestions for future scope have been given.
C1 [Malik, Anjali; Gupta, Shailender; Dhall, Sangeeta] JCBose Univ Sci & Technol, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Dhall, S (corresponding author), JCBose Univ Sci & Technol, YMCA, Faridabad, India.
EM anjalimalik0611@gmail.com; shailender81@gmail.com;
   sangeeta_dhall@yahoo.co.in
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152; Malik, Anjali/0009-0006-9598-3522
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Ahmed HAM, 2007, INZ MINER, P1
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Alloghani M, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102362
   Anderson T. W., 1958, INTRO MULTIVARIATE S, V2
   [Anonymous], 2014, P INT J INN RES ADV
   [Anonymous], RESEARCH-CHINA, DOI DOI 10.18502/JDER.4069
   [Anonymous], 2016, INT J SIG PROCESS PA
   [Anonymous], INT J ADV RES COMPUT
   Barker E, 2017, NIST Special Publication (SP) 800-67 Rev. 2 (Draft))
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   Chandra S, 2014, 2014 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATION AND COMPUTATIONAL ENGINEERING (ICECCE), P83, DOI 10.1109/ICECCE.2014.7086640
   Clement J., 2020, US DATA BREACHES EXP
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Jabade V, 2016, IMAGE, V5, P7
   John Justin M., 2012, INT J SOFT COMPUTING, V2
   Kester QA, 2013, ARXIV13077786
   Kevadia KT, 2016, LIT SURVEY IMAGE ENC, V2, P741
   Kumar M., 2020, J. Comput. Eng, V14, P31, DOI DOI 10.9790/0661-2201013137
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Li SS, 2013, MULTIMED TOOLS APPL, V66, P573, DOI 10.1007/s11042-012-1281-z
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Liu XB, 2019, IEEE ACCESS, V7, P6937, DOI 10.1109/ACCESS.2018.2889896
   Lv SX, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-017-1774-9
   Matsui M., 1994, Advances in Cryptology - CRYPTO '94. 14th Annual International Cryptology Conference. Proceedings, P1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mohammad O. F., 2017, INT J APPL ENG RES, V12, P13265
   Mousa A., 2006, Int. J. Comput. Sci. Appl., V3, P44
   Padmavathi B., 2013, INT J SCI REIJSR, V2
   Pandya A., 2018, INT RES J ENG TECHNO, V05, P2010
   Patel S., 2020, J Sci Res, V64, P291
   Rayarikar R., 2012, Int J Comput Appl, V50, P12
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   SCHNEIER B, 1994, DR DOBBS J, V19, P38
   Shujiang Xu, 2008, 2008 International Conference on Computational Intelligence and Security, P433, DOI 10.1109/CIS.2008.146
   Tanwar G, 2015, INT J ADV RES COMPUT, V5
   Wang H., 2019, IMPROVED CHESSBOARD
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
NR 42
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27941
EP 27993
DI 10.1007/s11042-020-09279-6
EA JUL 2020
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000559382300004
DA 2024-07-18
ER

PT J
AU Mallick, AK
   Mukhopadhyay, S
AF Mallick, Ajay Kumar
   Mukhopadhyay, Susanta
TI Video retrieval using salient foreground region of motion vector based
   extracted keyframes and spatial pyramid matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based video retrieval; Estimation of motion vector; Key frame
   extraction; Outlier detection; Pyramid matching; Saliency region
   detection
ID KEY FRAME EXTRACTION; KERNEL; OBJECT
AB Despite enormous research efforts devoted by the research community to effectively and precisely perform video matching and retrieval among heterogeneous videos from large-scale video repositories still remains a complex and most challenging task. In order to address this complex challenge, a content based video retrieval technique is required, which can exploit the visual content of the videos for effective retrieval from the videos repositories. In our proposed method, we introduce a computer assisted video retrieval technique which can retrieve the visually similar videos stored in the repositories. To accomplish this task, video summarization based on motion vector is employed to select keyframes based on similar segments. To estimate the video content, salient foreground extraction is executed, and matching based on the spatial pyramid is employed for matching the keyframe features of query video with videos in the repositories. The contribution of the former process has two major sections for superior saliency map generation. Firstly, it heuristically integrates the regional property, contrast, and foreground descriptors together. Secondly, it introduces a new feature vector to characterize the foreground as an object descriptor, while the latter process is the extension of orderless bag-of-features representation, which has significant performance with respect to scene categorization. The video retrieval performance is compared with standard state-of-the-art techniques using real-time datasets. Experimental and usability studies provide satisfactory results for video retrieval based on evaluation metrics such as video sampling error, fidelity, precision, and recall.
C1 [Mallick, Ajay Kumar; Mukhopadhyay, Susanta] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Mallick, AK (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
EM mallickajay6@gmail.com; msushanta2001@gmail.com
RI Mallick, Ajay Kumar/AAT-2820-2021; Mallick, Ajay Kumar/AAM-1260-2021
OI Mallick, Ajay Kumar/0000-0002-4770-9506; Mallick, Ajay
   Kumar/0000-0002-4770-9506
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Albregtsen F., 2008, STAT TEXTURE MEASURE, DOI [10.5209/ARIS.6586, DOI 10.5209/ARIS.6586]
   [Anonymous], 2017, IJCAI
   [Anonymous], 2011, Proceedings of the British Machine Vision Conference
   Aote SS, 2019, MULTIMED TOOLS APPL, V78, P14465, DOI 10.1007/s11042-018-6826-3
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Benuwa B, 2019, EXPERT SYST APPL, V119, P429, DOI 10.1016/j.eswa.2018.11.016
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Feng YA, 2019, IEEE T MULTIMEDIA, V21, P1762, DOI 10.1109/TMM.2018.2885237
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Guo YJ, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18030073
   Itti L, 1999, ADV NEUR IN, V11, P789
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Kondor Risi, 2003, ICML, P361
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Liu J., 2009, Recognizing Realistic Actions from Videos"in the Wild""
   Lyu SW, 2005, PROC CVPR IEEE, P223
   Mallick AK, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P687, DOI [10.1109/SPIN.2019.8711781, 10.1109/spin.2019.8711781]
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Mendi E, 2013, COMPUT ELECTR ENG, V39, P790, DOI 10.1016/j.compeleceng.2012.11.020
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Shashua A, 2005, ADV NEURAL INFORM PR, P1257
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Spolaôr N, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103557
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Verma SP, 2006, REV MEX CIENC GEOL, V23, P133
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Warhade KK, 2011, IETE J RES, V57, P461, DOI 10.4103/0377-2063.90172
   Wu B, 2014, MULTIMED TOOLS APPL, V73, P1053, DOI 10.1007/s11042-013-1530-9
   Xu Q, 2014, INFORM SCIENCES, V278, P736, DOI 10.1016/j.ins.2014.03.088
   Ziqian Qiang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P387, DOI 10.1007/978-3-319-48896-7_38
NR 39
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27995
EP 28022
DI 10.1007/s11042-020-09312-8
EA JUL 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000559382300005
DA 2024-07-18
ER

PT J
AU Gupta, S
   Sharma, P
   Sharma, D
   Gupta, V
   Sambyal, N
AF Gupta, Saksham
   Sharma, Paras
   Sharma, Dakshraj
   Gupta, Varun
   Sambyal, Nitigya
TI Detection and localization of potholes in thermal images using deep
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pothole detection and localization; Thermal imaging; Residual networks;
   RetinaNet; Single shot multibox detector; Convolutional neural networks;
   Deep learning
AB A pothole is a depression caused on roads due to seepage of water into soil structure or weight of continuously moving traffic. This not only damages the suspension of the vehicles but is also a prime reason for road accidents worldwide. This necessitates the need to develop an efficient automatic pothole detection system which can assist concerned authorities for timely repair and maintenance of the roads. This paper proposes a novel approach of bounding box based pothole localization from thermal images using deep neural networks. The modified ResNet34-single shot multibox detector gives an average precision of 74.53% whereas modified ResNet50-RetinaNet model provides 91.15% precision. The results obtained by the proposed modified ResNet50-RetinaNet model are the state-of-the-art results for localization of potholes using thermal images. In real-world scenarios such a system can assist relevant authorities to judge the severity of road damage and take appropriate effective measures accordingly.
C1 [Gupta, Saksham; Sharma, Paras; Sharma, Dakshraj; Gupta, Varun] Chandigarh Coll Engn & Technol, Dept Comp Sci & Engn, Degree Wing, Chandigarh, India.
   [Sambyal, Nitigya] Punjab Engn Coll Deemed Be Univ, Dept Comp Sci & Engn, Chandigarh, India.
C3 Punjab Engineering College (Deemed University)
RP Gupta, V (corresponding author), Chandigarh Coll Engn & Technol, Dept Comp Sci & Engn, Degree Wing, Chandigarh, India.
EM varungupta@ccet.ac.in
RI Gupta, Varun/AAW-9860-2020; Gupta, Varun/KFA-9728-2024
OI Gupta, Varun/0000-0002-2633-5920; Gupta, Saksham/0000-0002-1762-9185;
   sambyal, nitigya/0000-0003-2070-4462
CR [Anonymous], 2018, TIMES INDIA REPORT
   [Anonymous], 2018, 2018 IEEE INT C CONS, DOI [DOI 10.1109/ICCE.2018.8326142, 10.1109/ICCE.2018.8326142]
   [Anonymous], 2015, MATH PROBL ENG, DOI DOI 10.1155/2015/869627
   Aparna Y, 2022, J KING SAUD UNIV-COM, V34, P578, DOI 10.1016/j.jksuci.2019.02.004
   Azhar Kanza, 2016, 2016 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE), DOI 10.1109/CCECE.2016.7726722
   Bhatt U, 2017, DATA GOOD EXCH, V2017, P1
   Dhiman A, 2018, 2018 15TH INTERNATIONAL SYMPOSIUM ON PERVASIVE SYSTEMS, ALGORITHMS AND NETWORKS (I-SPAN 2018), P7, DOI 10.1109/I-SPAN.2018.00012
   Eriksson J, 2008, PLOS GENET, V4, DOI 10.1371/journal.pgen.1000010
   Fan D-P, 2020, C COMP VIS PATT REC
   Fan R, 2020, IEEE T INTELL TRANSP, V21, P4906, DOI 10.1109/TITS.2019.2947206
   Fan R, 2020, IEEE T IMAGE PROCESS, V29, P897, DOI 10.1109/TIP.2019.2933750
   Gayathri S, 2019, INT J ENG RES TECHNO, V7, P1
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hou Z., 2007, International Conference on Transportation Engineering, P376, DOI DOI 10.1061/40932(246)62
   Ivanovic B, 2019, IEEE INT CONF ROBOT, P15, DOI [10.1109/icra.2019.8794206, 10.1109/ICRA.2019.8794206]
   Jo Y, 2015, SENSORS-BASEL, V15, P29316, DOI 10.3390/s151129316
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kim T., 2014, J EMERGING TRENDS CO, V5, P603
   Koch C, 2011, ADV ENG INFORM, V25, P507, DOI 10.1016/j.aei.2011.01.002
   Kotha M., 2020, ACM INT C PROC SER, DOI [10.1145/3377283.3377286, DOI 10.1145/3377283.3377286]
   Li QG, 2010, MEAS SCI TECHNOL, V21, DOI 10.1088/0957-0233/21/1/015702
   LIN T, 2017, IEEE I CONF COMP VIS, V2017, P2999, DOI DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mednis A, 2011, 2011 INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS AND WORKSHOPS (DCOSS)
   Moazzam I, 2013, IEEE INT C INTELL TR, P1284, DOI 10.1109/ITSC.2013.6728408
   Suong LK, 2018, J UNIVERS COMPUT SCI, V24, P1244
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Turkowski K, 1990, GRAPHICS GEMS, P147, DOI DOI 10.1016/B978-0-08-050753-8.50042-5
   Wilhelm BurgerMark James Burge., 2009, Principles of Digital Image Processing
NR 29
TC 22
Z9 24
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26265
EP 26284
DI 10.1007/s11042-020-09293-8
EA JUL 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548128400003
DA 2024-07-18
ER

PT J
AU Schez-Sobrino, S
   Vallejo, D
   Glez-Morcillo, C
   Redondo, MA
   Castro-Schez, JJ
AF Schez-Sobrino, Santiago
   Vallejo, David
   Glez-Morcillo, Carlos
   Redondo, Miguel A.
   Jesus Castro-Schez, Jose
TI RoboTIC: A serious game based on augmented reality for learning
   programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Learning programming; Serious games; Visual programming; Augmented
   reality
ID EDUCATION
AB Coding skills are becoming more and more important in today's world, especially within the context of the fourth industrial revolution. They also help practice other 21 century skills such as computational thinking, problem solving and teamwork. Unfortunately, learning how to program is tough and can be also frustrating for beginner students. In this work we introduce RoboTIC, a serious game based on gamification and Augmented Reality that facilitates the learning of programming to students in lower levels of the education system by using a novel set of visual metaphors derived from a notation of roads and traffic signs. The architecture that supports RoboTIC has been designed to allow the integration of multimedia components when new programming concepts and techniques must be addressed and to add game levels that enable students to learn incrementally. Experiments have been conducted in a youth center with children who do not have coding skills at all to demonstrate the feasibility of the proposal. The results show promising conclusions in terms of children's motivation and interest in programming.
C1 [Schez-Sobrino, Santiago; Vallejo, David; Glez-Morcillo, Carlos; Redondo, Miguel A.; Jesus Castro-Schez, Jose] Univ Castilla La Mancha, Paseo Univ 4, Ciudad Real 13071, Spain.
C3 Universidad de Castilla-La Mancha
RP Schez-Sobrino, S (corresponding author), Univ Castilla La Mancha, Paseo Univ 4, Ciudad Real 13071, Spain.
EM santiago.sanchez@uclm.es; david.vallejo@uclm.es;
   carlos.gonzalez@uclm.es; miguel.redondo@uclm.es;
   josejesus.castro@uclm.es
RI Castro-Schez, Jose Jesus/AAH-7344-2021; Castro-Schez, Jose
   Jesus/E-8934-2012; Morcillo, Carlos Gonzalez/I-2361-2015; Redondo,
   Miguel A./F-7852-2015; Sánchez, Santiago/HPH-3304-2023
OI Castro-Schez, Jose Jesus/0000-0002-0201-7653; Schez-Sobrino,
   Santiago/0000-0001-6620-1719
FU Ministry of Economy, Industry and Competitiveness; European Regional
   Development Fund [TIN2015-66731-C2-2-R]
FX This work has been funded by the Ministry of Economy, Industry and
   Competitiveness, and the European Regional Development Fund through the
   project TIN2015-66731-C2-2-R. The authors would like to thank Pablo
   Gutierrez Caravantes for coordinating the experiments carried out in the
   youth center of Torralba in Calatrava (Ciudad Real, Spain) and the
   undergraduate students that participated in the project Telefonica
   Talentum for the development of the first software prototype.
CR Abelson H., 1974, Logo manual
   [Anonymous], 2007, Software Visualization: Visualizing the Structure, Behavior, and Evolution of Software
   [Anonymous], 2014, P FRONTIERS ED C, DOI [DOI 10.1109/FIE.2014.7044114, 10.1109/FIE.2014.7044114]
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Basili V. R., 1994, Encyclopedia of Software Engineering, V1, P528
   Bentrad S., 2011, ACEEE Int. J. On Information Technology, V1, P56
   Bloem J, 2014, THINGS TIGHTEN, V8, P1
   Burgess N, 2002, NEURON, V35, P625, DOI 10.1016/S0896-6273(02)00830-9
   Colombo AW, 2017, IEEE IND ELECTRON M, V11, P6, DOI 10.1109/MIE.2017.2648857
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   da Silva Esteves AM, 2019, USE AUGMENTED REALIT
   DAVIS FD, 1993, INT J MAN MACH STUD, V38, P475, DOI 10.1006/imms.1993.1022
   Dunleavy M., 2014, Augmented Reality Teaching and Learning, P735, DOI 10.1007/978-1-4614-3185-5_59
   ELIASZIW M, 1991, STAT MED, V10, P1981, DOI 10.1002/sim.4780101211
   Elshiekh R., 2017, Open Access Library Journal, V4, P1, DOI [10.4236/oalib.1103803, DOI 10.4236/OALIB.1103803]
   Figueiredo M, 2016, LECT NOTES COMPUT SC, V9739, P57, DOI 10.1007/978-3-319-40238-3_6
   Fraser N, 2015, 2015 IEEE BLOCKS AND BEYOND WORKSHOP (BLOCKS AND BEYOND), P49, DOI 10.1109/BLOCKS.2015.7369000
   Gallego-Duran FJ, 2017, INT J ENG ED
   Gouws L., 2013, P 18 ACM C INNOVATIO, P10, DOI DOI 10.1145/2462476.2466518
   Hidalgo-Céspedes J, 2016, PROC FRONT EDUC CONF
   Ibáñez MB, 2014, IEEE T LEARN TECHNOL, V7, P291, DOI 10.1109/TLT.2014.2329293
   Jee HK, 2014, MULTIMED TOOLS APPL, V68, P225, DOI 10.1007/s11042-011-0880-4
   Jimenez-Diaz G, 2012, SOFTWARE PRACT EXPER, V42, P235, DOI 10.1002/spe.1071
   Kaufmann H., 2002, ACM SIGGRAPH 2002 Conference Ab- stracts and Applications, SIGGRAPH '02, P37, DOI DOI 10.1016/S0097-8493
   Kaye LK, 2017, TRENDS COGN SCI, V21, P66, DOI 10.1016/j.tics.2016.10.007
   Kim TJ, 2018, MULTIMED TOOLS APPL, V77, P30089, DOI 10.1007/s11042-018-6181-4
   Knight C, 2000, IEEE INFOR VIS, P198, DOI 10.1109/IV.2000.859756
   Krpan D, 2018, INTED PROC, P4993
   Kumar B., 2012, International Journal of Computers and Distributed Systems, V2, P46
   Majumdar A., 2018, XRDS, V24, P12, DOI [https://doi.org/10.1145/3186711, DOI 10.1145/3186711]
   Maloney J., 2010, ACM T COMPUT EDUC, V10, P16, DOI DOI 10.1145/1868358.1868363
   Mathieson A, 2018, PRIM HEALTH CARE RES, V20, DOI 10.1017/S1463423618000488
   Milne M., 2004, Education and Information Technologies, V9, P219, DOI 10.1023/B:EAIT.0000042041.04999.17
   Myers B. A., 1990, Journal of Visual Languages and Computing, V1, P97, DOI 10.1016/S1045-926X(05)80036-9
   Paliokas I., 2011, Proceedings of the 2011 3rd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2011), P24, DOI 10.1109/VS-GAMES.2011.10
   Parmar D, 2016, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2016.7504696
   Piteira M., 2011, Workshop on Open Source and Design of Communication, P49
   ROBERTSON GG, 1993, COMMUN ACM, V36, P57, DOI 10.1145/255950.153577
   Sajaniemi Jorma., 2003, P 2003 ACM S SOFTWAR, P7, DOI DOI 10.1145/774833.774835
   Sarkar SP, 2016, INT CONF COMPUT INFO, P218, DOI 10.1109/ICCITECHN.2016.7860198
   Schez-Sobrino S, 2019, P 7 INT C TECHN EC E
   Schez-Sobrino S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041518
   Schwab K., 2017, CURRENCY
   Teng CH, 2018, J EDUC COMPUT RES, V56, P254, DOI 10.1177/0735633117706109
   Teyseyre AR, 2009, IEEE T VIS COMPUT GR, V15, P87, DOI 10.1109/TVCG.2008.86
   van Schaik P, 2018, J ED COMPUT RES
   Wald A, 1940, ANN MATH STAT, V11, P147, DOI 10.1214/aoms/1177731909
   Whittington R., 2016, The Palgrave Encyclopedia of Strategic Management, P1, DOI [10.14236/ewic/HCI2016.76, DOI 10.14236/EWIC/HCI2016.76]
   Wing JM, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1118178.1118215
   Wohlin C, 2000, EXPT PROCESS, P31
NR 50
TC 24
Z9 25
U1 4
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34079
EP 34099
DI 10.1007/s11042-020-09202-z
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000545796600003
DA 2024-07-18
ER

PT J
AU Kaljahi, MA
   Shivakumara, P
   Hakak, S
   Idris, MYI
   Anisi, MH
   Rajan, D
AF Kaljahi, Maryam Asadzadeh
   Shivakumara, Palaiahnakote
   Hakak, Saqib
   Idris, Mohd Yamani Idna
   Anisi, Mohammad Hossein
   Rajan, Deepu
TI Saliency-based bit plane detection for network applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit plane detection; Canny edge image; Saliency map; Markov chain
   process; Visual sensor network; TCP protocol
ID PATTERNS
AB Transmitting image data without losing significant information is challenging for any network application especially when large color images are transmitted through TCP communication protocol. This is due to network limitations such as buffer overflow, underflow and network traffic flow etc. This paper presents a new method for image size reduction such that the network can transmit data without much loss of information, and hence, quality. The proposed method obtains bit planes for the color input images, which results in eight binary planes. Unlike the existing bit plane based image size reduction methods, which assume that the most significant plane or some other planes contain useful information, the proposed method finds the plane that contains dominant information automatically. For each plane, the proposed method explores the saliency that finds dominant information based on Markov Chain Process and similarity estimation between neighbor pixels. To reduce computational burden, we use Canny edge maps of the saliency of the planes for feature extraction. We propose to explore ring-growing concept for the edge maps to study the spatial distribution of saliency, locally. The proposed method detects the plane based on statistics of saliency distribution. To validate the step of plane detection, we estimate transmission error caused during data transmission through TCP communication protocol for the images at sending and receiving ends. Experimental results on plane detection show that the proposed method is better than the existing methods in terms of detection rate. Our experiments on image transmission through TCP communication protocol show that the proposed method outperforms the existing methods in terms of error estimation and quality analysis. Furthermore, experiments are conducted to analyze packet loss in terms of number of duplicate acknowledgements and retransmission during packets transmission for the color, edge and plane to show that transmitting plane images improves network performance in terms of less number of duplicate acknowledgement, retransmission and time taken in seconds.
C1 [Kaljahi, Maryam Asadzadeh; Shivakumara, Palaiahnakote; Idris, Mohd Yamani Idna] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Hakak, Saqib] Univ Northern British Columbia, Fac Comp Sci, Prince George, BC, Canada.
   [Anisi, Mohammad Hossein] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
   [Rajan, Deepu] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 Universiti Malaya; University of Northern British Columbia; University
   of Essex; Nanyang Technological University
RP Shivakumara, P (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
EM asadzadeh@um.edu.my; shiva@um.edu.my; saqib.hakak@unbc.ca;
   yamani@um.edu.my; m.anisi@essex.ac.uk; asdrajan@ntu.edu.sg
RI Idris, Mohd. Yamani Idna/GPP-2401-2022; Hakak, Saqib/AAC-5134-2021;
   Palaiahnakote, Shivakumara/B-6261-2013; Palaiahnakote,
   Shivakumara/ITU-6488-2023; Idris, Mohd. Yamani Idna/B-5232-2010; Rajan,
   Deepu/A-3666-2011; Anisi, Mohammad Hossein/L-3718-2016
OI Idris, Mohd. Yamani Idna/0000-0003-4894-0838; Anisi, Mohammad
   Hossein/0000-0001-8414-2708; Palaiahnakote,
   Shivakumara/0000-0001-9026-4613; hakak, saqib/0000-0002-8718-0336
CR Abdul-Salaam G, 2017, IEEE SENS J, V17, P2289, DOI 10.1109/JSEN.2017.2665663
   Brahimi T, 2017, MULTIMED TOOLS APPL, V76, P16807, DOI 10.1007/s11042-016-4072-0
   Briscoe N, 2000, PC NETWORK ADVISOR
   Chen JZ, 2017, NEUROCOMPUTING, V251, P16, DOI 10.1016/j.neucom.2017.04.020
   Chuang A, 2019, ZOOKEYS, P1, DOI 10.3897/zookeys.874.36656
   Dutta A, 2007, P EURASIP, P261
   Ernawan F, 2018, MULTIMED TOOLS APPL, V77, P13923, DOI 10.1007/s11042-017-4999-9
   Fall Kevin R, 2011, TCP IP ILLUSTRATED, V1
   Felemban E, 2014, AD HOC NETW, V23, P65, DOI 10.1016/j.adhoc.2014.06.003
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Jesline, 2017, WIRELESS PERS COMMUN, V94, P2325, DOI 10.1007/s11277-016-3444-0
   Kalhor S, 2007, P 2 INT C SYST NETW
   Kaljahi MA, 2019, MULTIMED TOOLS APPL, V78, P5791, DOI 10.1007/s11042-018-6151-x
   Lan X, 2019, PATTERN RECOGNITION
   Lan XY, 2019, IEEE T IND ELECTRON, V66, P9887, DOI 10.1109/TIE.2019.2898618
   Lan XY, 2019, IEEE ACCESS, V7, P67761, DOI 10.1109/ACCESS.2019.2916895
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lin YF, 2019, MULTIMED TOOLS APPL, V78, P29197, DOI 10.1007/s11042-018-6687-9
   Niu PP, 2017, MULTIMED TOOLS APPL, V76, P3403, DOI 10.1007/s11042-016-3935-8
   Raghunandan KS, 2019, IEEE T CIRC SYST VID, V29, P1145, DOI 10.1109/TCSVT.2018.2817642
   Roy S, 2017, PROC INT CONF DOC, P838, DOI 10.1109/ICDAR.2017.142
   Yoo CH, 2017, J VIS COMMUN IMAGE R, V45, P11, DOI 10.1016/j.jvcir.2017.02.009
   Zhang B, 2017, P MATEC WEB C, V128, P1
NR 25
TC 3
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18495
EP 18513
DI 10.1007/s11042-020-08741-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800054
DA 2024-07-18
ER

PT J
AU Roy, S
   Biswas, M
   De, D
AF Roy, Samarjit
   Biswas, Mousumi
   De, Debashis
TI iMusic: a session-sensitive clustered classical music recommender system
   using contextual representation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classical music; Computational musicology; Deep neural network;
   Representation learning; Clustering; Hybrid collaborative filtering;
   Music recommendation; Internet of music things
ID INTERNET; ARTISTS; USERS
AB Music has emerged to be of paramount importance to humanity and is not only considered as a source of entertainment but also an agent that causes social and psychological influences. A large number of existing digital music libraries have improved awareness among people through the music recommendation approach. However, several critical technical challenges still require attention and must be well-addressed to provide a reliable recommendation to music listeners. In Indian Classical Music, Raga is composed of coalescing diverse musical note structures. The history of classical music unveils that every raga possesses some distinct sessions. With a vast collection of classical music files in online music libraries, locating and listening to classical music is no more a difficult task. However, searching and listening to the audio of one's preference may not be simple as it must instinctively satisfy the listener's preference in a precise session. In this paper, a system termed as iMusic has been proposed to classify, analyze, and recommend the session-sensitive performance of Indian classical music by analyzing the musical note structures followed by features matching. Available note-patterns in the raga performance have been illustrated using a deep neural network and a set of machine learning algorithms where raga samples have been represented as inputs in the projected network and are classified based on the performing sessions. A context-aware k-means clustering algorithm has also been illustrated, entitled as a data filtering algorithm. The proficiency of the filtering algorithm has been established in two ways. Primarily, as a data-sensitive analysis, and second as empirical studies on synthetically obtained real classical music dataset () to put on the hybrid music recommendation. In this work, a case-study of session-sensitive Indian music recommender system has been demonstrated using key-strategies viz. listener modelling, representation learning, and music profiling. Eventually, several evaluation metrics have been discussed to characterize the effectiveness of proposed representation learning-based playing session-sensitive music recommendation strategies. The proposed iMusic system renders data classification accuracy of similar to 88%. Such a framework could provide a useful basis regarding studies on hybrid music recommendation systems based on the usefulness of end-users.
C1 [Roy, Samarjit; Biswas, Mousumi; De, Debashis] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Ctr Mobile Cloud Comp, BF 142,Sect 1, Kolkata 700064, W Bengal, India.
   [De, Debashis] Univ Western Australia, Dept Phys, 35 Stirling Hwy, Crawley, WA 6009, Australia.
C3 Maulana Abul Kalam Azad University of Technology; University of Western
   Australia
RP De, D (corresponding author), Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Ctr Mobile Cloud Comp, BF 142,Sect 1, Kolkata 700064, W Bengal, India.; De, D (corresponding author), Univ Western Australia, Dept Phys, 35 Stirling Hwy, Crawley, WA 6009, Australia.
EM dr.debashis.de@gmail.com
RI Biswas, Dr. Mousumi/IUM-9021-2023; ROY, SAMARJIT/AAT-6734-2020
OI ROY, SAMARJIT/0000-0002-7874-8348; De, Debashis/0000-0002-9688-9806
FU University Grant Commission (UGC), Govt. of India
FX Authors are grateful to the University Grant Commission (UGC), Govt. of
   India, for sanctioning a research fellowship under which this
   contribution has been completed. Authors are also grateful to the
   Department of Science and Technology (DST) for sanctioning projects and
   the TEQIP-III, MAKAUT, WB.
CR Al-Qarni BH, 2019, MULTIMED TOOLS APPL, V78, P30039, DOI 10.1007/s11042-018-6883-7
   Allik A, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P167, DOI 10.1145/3184558.3186970
   Alsouda Y, 2019, INTERNATIONAL CONFERENCE ON OMNI-LAYER INTELLIGENT SYSTEMS (COINS), P62, DOI 10.1145/3312614.3312631
   Andjelkovic I, 2019, INT J HUM-COMPUT ST, V121, P142, DOI 10.1016/j.ijhcs.2018.04.004
   [Anonymous], 2017, IAES INT J ARTIF INT
   Chakrabarty S, 2017, TIME SLOT BASED INTE, P319
   Chakrabarty S., 2015, P INT SCI C ASS IND, P16
   Chang SK, 2007, IEEE T KNOWL DATA EN, V19, P1666, DOI 10.1109/TKDE.2007.190651
   Chen J., 2018, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-018-5745-7
   Fan TK, 2018, MULTIMED TOOLS APPL, V77, P10017, DOI 10.1007/s11042-017-4825-4
   Gulati S., 2016, P 17 INT SOC MUS INF, P751
   Gulati S, 2016, INT CONF ACOUST SPEE, P66, DOI 10.1109/ICASSP.2016.7471638
   Jeong J, 2017, EXPERT SYST APPL, V90, P50, DOI 10.1016/j.eswa.2017.08.014
   Kluver D, 2018, LECT NOTES COMPUT SC, V10100, P344, DOI 10.1007/978-3-319-90092-6_10
   Kodati Sarangam, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P111, DOI 10.1007/978-981-13-3600-3_11
   Kovacevic A, 2010, MULTIMED TOOLS APPL, V47, P525, DOI 10.1007/s11042-009-0336-2
   Lacey L, 2015, INTERNET THINGS COUL
   Lee K, 2019, MULTIMED TOOLS APPL, V78, P3183, DOI 10.1007/s11042-018-6084-4
   Lu CC, 2009, EXPERT SYST APPL, V36, P10035, DOI 10.1016/j.eswa.2009.01.074
   Ma X, 2018, MULTIMED TOOLS APPL, V77, P6425, DOI 10.1007/s11042-017-4550-z
   Namin SR, 2017, GETTING YA MUSIC REC
   Rao Z., 2018, J INFORM HIDING MULT, V9, P400
   Raschka S, 2020, INFORMATION, V11, DOI 10.3390/info11040193
   Reddy MS, INT J INNOVATIVE RES, V2
   Roy S, 2020, J AMB INTEL HUM COMP, V11, P151, DOI 10.1007/s12652-019-01261-x
   Roy S, 2018, J SUPERCOMPUT, V74, P6069, DOI 10.1007/s11227-018-2511-6
   Rui T, 2017, NEUROCOMPUTING, V230, P66, DOI 10.1016/j.neucom.2016.11.054
   Salas J, 2018, IEEE POTENTIALS, V37, P15, DOI 10.1109/MPOT.2016.2550015
   Sánchez-Moreno D, 2016, EXPERT SYST APPL, V66, P234, DOI 10.1016/j.eswa.2016.09.019
   Schedl M, 2018, INT J MULTIMED INF R, V7, P95, DOI 10.1007/s13735-018-0154-2
   Schedl Markus, 2018, Journal of Mobile Multimedia, V14, P95
   Selvi C, 2019, MULTIMED TOOLS APPL, V78, P14303, DOI 10.1007/s11042-018-6790-y
   Sevillano X, 2014, MULTIMED TOOLS APPL, V73, P1507, DOI 10.1007/s11042-013-1655-x
   Shakirova E, 2017, IEEE NW RUSS YOUNG, P548, DOI 10.1109/EIConRus.2017.7910613
   Stober S, 2013, MULTIMED TOOLS APPL, V65, P467, DOI 10.1007/s11042-012-1042-z
   Sunitha M, 2018, LECT NOTE DATA ENG, V3, P267, DOI 10.1007/978-981-10-4585-1_22
   Tsai CW, 2013, MULTIMED TOOLS APPL, V67, P137, DOI 10.1007/s11042-011-0957-0
   Tseng V.S., 2017, DATA SCI PATTERN REC, V1, P13
   Turchet L, 2018, IEEE ACCESS, V6, P61994, DOI 10.1109/ACCESS.2018.2872625
   Uhlich S, 2017, INT CONF ACOUST SPEE, P261, DOI 10.1109/ICASSP.2017.7952158
   Wang DJ, 2018, INFORM RETRIEVAL J, V21, P230, DOI 10.1007/s10791-017-9317-7
   Wang QQ, 2020, INT J MULTIMED INF R, V9, P3, DOI 10.1007/s13735-019-00186-7
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Zangerle E, 2021, IEEE T AFFECT COMPUT, V12, P78, DOI 10.1109/TAFFC.2018.2846596
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zheng E, 2018, EXPERT SYST APPL, V106, P244, DOI 10.1016/j.eswa.2018.04.014
   Zheng HT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040703
NR 47
TC 15
Z9 15
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24119
EP 24155
DI 10.1007/s11042-020-09126-8
EA JUN 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541201200005
DA 2024-07-18
ER

PT J
AU Lee, S
   Jang, SW
   Kim, D
   Hahn, H
   Kim, GY
AF Lee, Samuel
   Jang, Seok-Woo
   Kim, Dongho
   Hahn, Hernsoo
   Kim, Gye-Young
TI A Novel Fingerprint Recovery Scheme using Deep Neural Network-based
   Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Presentation attack; Deep learning; Fingerprint recognition;
   Recovery; Feature extraction; Vulnerability
ID OTSU METHOD; RECOGNITION; CONVOLUTION; MINUTIAE; ARCHITECTURE
AB Minutiae used in most fingerprint recognition devices is robust to presentation attack, but generates a high false match rate. Thus, it is applied along with orientation map or skeleton images. There has been plenty of research on security vulnerability of minutiae, whereas few research has been conducted on orientation map or skeleton images. This study analyzes vulnerability of presentation attack for skeleton images. For this purpose, it proposes a new algorithm of recovering fingerprints with the use of machine learning and skeleton image features of fingerprints. In the proposed method, we suggest the new machine learning Pix2Pix model to generate more natural images. The suggested model is developed in the way of adding a latent vector to the conventional image-to-image translation model Pix2Pix. In the experiment, fingerprints were recovered with the use of the proposed Pix2Pix model, and it was found that a fingerprint recognition device which recognized the recovered fingerprints had a high success rate of recognition. Therefore, it was proved that a fingerprint recognition device using skeleton images as well was vulnerable to presentation attack. It is expected that the algorithm proposed in this study will be very useful to many different application areas related to image processing, including biometrics, fingerprint recognition and recovery, and image surveillance.
C1 [Lee, Samuel; Kim, Gye-Young] Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 06978, South Korea.
   [Jang, Seok-Woo] Anyang Univ, Dept Software, 22 37 Beongil, Anyang 14028, South Korea.
   [Kim, Dongho] Soongsil Univ, Global Sch Media, 369 Sangdo Ro, Seoul 06978, South Korea.
   [Hahn, Hernsoo] Soongsil Univ, Sch Elect Engn, 369 Sangdo Ro, Seoul 06978, South Korea.
C3 Soongsil University; Anyang University; Soongsil University; Soongsil
   University
RP Kim, GY (corresponding author), Soongsil Univ, Sch Software, 369 Sangdo Ro, Seoul 06978, South Korea.
EM lsme8821@ssu.ac.kr; swjang7285@gmail.com; dkim@ssu.ac.kr;
   hahn@ssu.ac.kr; gykim11@ssu.ac.kr
FU Soongsil University; Global Infrastructure Program through the National
   Research Foundation of Korea(NRF) - Ministry of Science and ICT
   [NRF-2016K1A3A1A19945935]
FX This work was supported by the Soongsil University Research Fund of
   2017. In addition, this research was supported by Global Infrastructure
   Program through the National Research Foundation of Korea(NRF) funded by
   the Ministry of Science and ICT(NRF-2016K1A3A1A19945935).
CR Almajmaie L, 2019, COGN SYST RES, V58, P107, DOI 10.1016/j.cogsys.2019.05.004
   Bansal R., 2011, International Journal of Computer Science Issues, V8, P74
   Bontrager P., 2018, 2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems (BTAS), P1
   Cai HM, 2014, IEEE T IMAGE PROCESS, V23, P1038, DOI 10.1109/TIP.2014.2298981
   Ding SH, 2019, PATTERN RECOGN LETT, V122, P66, DOI 10.1016/j.patrec.2019.02.020
   Du C, 2019, SIGNAL PROCESS, V158, P176, DOI 10.1016/j.sigpro.2019.01.006
   Espinoza M, 2011, FORENSIC SCI INT, V204, P41, DOI 10.1016/j.forsciint.2010.05.002
   Feng JJ, 2011, IEEE T PATTERN ANAL, V33, P209, DOI 10.1109/TPAMI.2010.77
   Ge YX, 2013, J VIS COMMUN IMAGE R, V24, P627, DOI 10.1016/j.jvcir.2013.04.011
   Hamidi H, 2019, FUTURE GENER COMP SY, V91, P434, DOI 10.1016/j.future.2018.09.024
   Heusel M., 2017, Advances in Neural Information Processing Systems, P6627, DOI [DOI 10.48550/ARXIV.1706.08500, 10.48550/arXiv.1706.08500]
   Huang B, 2018, PATTERN RECOGN LETT, V111, P72, DOI 10.1016/j.patrec.2018.04.028
   Huang GQ, 2019, NEUROCOMPUTING, V332, P215, DOI 10.1016/j.neucom.2018.12.050
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jia S, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107032
   Kho JB, 2019, PATTERN RECOGN, V91, P245, DOI 10.1016/j.patcog.2019.01.039
   Kim J, 2019, ENERG BUILDINGS, V194, P328, DOI 10.1016/j.enbuild.2019.04.034
   Lee S., 2019, P WORLD C INF TECHN
   Lee W, 2017, EXPERT SYST APPL, V87, P183, DOI 10.1016/j.eswa.2017.06.019
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li J, 2018, SIGNAL PROCESS-IMAGE, V60, P52, DOI 10.1016/j.image.2017.08.010
   Liu XN, 2019, PATTERN RECOGN LETT, V117, P66, DOI 10.1016/j.patrec.2018.12.003
   Mishkin D, 2017, COMPUT VIS IMAGE UND, V161, P11, DOI 10.1016/j.cviu.2017.05.007
   Paliwal N., 2019, International Journal of Social and Humanistic Computing, V3, P191, DOI [10.1504/IJSHC.2019.101602, DOI 10.1504/IJSHC.2019.101602]
   Peralta D, 2017, INFORM SCIENCES, V408, P198, DOI 10.1016/j.ins.2017.05.001
   Riaz F, 2013, IEEE SIGNAL PROC LET, V20, P607, DOI 10.1109/LSP.2013.2259622
   Ross A, 2005, PROC SPIE, V5779, P68, DOI 10.1117/12.604477
   Sannidhan MS, 2019, PATTERN RECOGN LETT, V128, P452, DOI 10.1016/j.patrec.2019.10.010
   Sharma RP, 2019, IMAGE VISION COMPUT, V83-84, P1, DOI 10.1016/j.imavis.2019.02.006
   Sunday MA, 2019, VISION RES, V163, P14, DOI 10.1016/j.visres.2019.08.006
   Talab AMA, 2016, OPTIK, V127, P1030, DOI 10.1016/j.ijleo.2015.09.147
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Yang H.-M., 2019, INT J SOC HUMANIST C, V3, P148, DOI [10.1504/IJSHC.2019.101598, DOI 10.1504/IJSHC.2019.101598]
   Youssef R, 2016, PATTERN RECOGN, V57, P97, DOI 10.1016/j.patcog.2016.03.033
   Yu L, 2010, IMAGE VISION COMPUT, V28, P177, DOI 10.1016/j.imavis.2009.05.012
   Yuan XC, 2015, APPL SURF SCI, V349, P472, DOI 10.1016/j.apsusc.2015.05.033
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhao Y, 2018, IEEE ACCESS, V6, P60478, DOI 10.1109/ACCESS.2018.2872060
   Zuñiga AG, 2014, PATTERN RECOGN LETT, V36, P135, DOI 10.1016/j.patrec.2013.09.023
NR 43
TC 4
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34121
EP 34135
DI 10.1007/s11042-020-09157-1
EA JUN 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000540671300004
DA 2024-07-18
ER

PT J
AU Loukil, H
   Masmoudi, N
AF Loukil, Hassen
   Masmoudi, Nouri
TI A novel architecture design for VLSI implementation of integer DCT in
   HEVC standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; ICT; FPGA; VHDL; Embedded video system
AB This paper presents novel hardware of a unified architecture to compute the 4 x 4, 8 x 8, 16 x 16 and 32 x 32 efficient two dimensional (2-D) integer DCT using one block 1-D DCT for the HEVC standard with less complexity and material design. As HEVC large transforms suffer from the huge number of computations especially multiplications, this paper presents a proposition of a modified algorithm reducing the computational complexity. The goal is to ensure the maximum circuit reuse during the computation while keeping the same quality of encoded videos. The hardware architecture is described in VHDL language and synthesized on Altera FPGA. The hardware architecture throughput reaches a processing rate up to 52 million of pixels per second at 90 MHz frequency clock. An IP core is presented using the embedded video system on a programmable chip (SoPC) for implementation and validation of the proposed design. Finally, the proposed architecture has significant advantages in terms of hardware cost and improved performance compared to related work existing in the literature. This architecture can be used in ultra-high definition real-time TV coding (UHD) applications.
C1 [Loukil, Hassen] King Khalid Univ, Coll Engn, Elect Engn Dept, Abha 61413, Asir, Saudi Arabia.
   [Loukil, Hassen; Masmoudi, Nouri] Univ Sfax, Natl Sch Engn, Elect & Informat Technol Lab, Sfax 3038, Tunisia.
C3 King Khalid University; Universite de Sfax; Ecole Nationale dIngenieurs
   de Sfax (ENIS)
RP Loukil, H (corresponding author), King Khalid Univ, Coll Engn, Elect Engn Dept, Abha 61413, Asir, Saudi Arabia.; Loukil, H (corresponding author), Univ Sfax, Natl Sch Engn, Elect & Informat Technol Lab, Sfax 3038, Tunisia.
EM hloukil@kku.edu.sa
RI HASSEN, LOUKIL/HTO-1134-2023
OI HASSEN, LOUKIL/0000-0002-2028-3517
CR Ahmed A, 2011, IEEE 14 INT MULT C
   [Anonymous], 2018, SIMULATION QUICK STA
   Bhaskaranand M, 2013, IEEE INT SYM MULTIM, P163, DOI 10.1109/ISM.2013.34
   Bhaskaranand M, 2011, 2011 - MILCOM 2011 MILITARY COMMUNICATIONS CONFERENCE, P1633, DOI 10.1109/MILCOM.2011.6127543
   Bross B., 2013, High Efficiency Video Coding (HEVC) Text Specification Draft 10
   Chen M, 2017, AEU-INT J ELECTRON C, V73, P1, DOI 10.1016/j.aeue.2016.12.024
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   CONCEICAO R, 2014, J INTEGR CIRCUITS SY, V9, P25
   Fuldseth A., 2011, JCTVC G495
   JCT-VC, 2010, JCTVCA124
   Jeske R, 2012, 8 SO PROGR LOG C SPL
   Joint Collaborative Team on Video Coding (JCT-VC), 2017, HIGH EFF VID COD HEV
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Martuza M, 2012, VLSI DES, DOI 10.1155/2012/242989
   Meuel H, 2015, INT C ADV VID SIGN B, P1
   Tessier R, 2001, J VLSI SIG PROC SYST, V28, P7, DOI 10.1023/A:1008155020711
NR 16
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23977
EP 23993
DI 10.1007/s11042-020-09165-1
EA JUN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540671300005
DA 2024-07-18
ER

PT J
AU Shu, X
   Yuan, D
   Liu, Q
   Liu, JQ
AF Shu, Xiu
   Yuan, Di
   Liu, Qiao
   Liu, Jiaqi
TI Adaptive weight part-based convolutional network for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Adaptive weight; Part-based convolutional
   network
ID TRACKING; MODEL
AB While part-based methods have been shown effective in the person re-identification task, it is unreasonable for most of them to treat each part equally, due to the retrieved image may be affected by deformation, occlusion and other factors, which makes the feature information of some parts unreliable. Instead of using the same weight of each part for the final person re-ID, we consider using an adaptive weight based on the part image information for each part for precise person retrieval. Specifically, we aim at learning discriminative part-informed features and propose an adaptive weight part-based convolutional network (AWPCN) for the person re-ID task. The core component of our AWPCN framework is an adaptive weight model, in which the part-based convolutional network and the adaptive weight model are used for feature refinement and feature-pair alignment, respectively. Given an image input at first, it outputs a convolutional descriptor consisting of several part-level features by the part-based convolutional network. And then, the corresponding weights of each part are determined by the adaptive weight model. Finally, we can use the adaptive weight part-based convolutional network joint to train each part loss and simultaneous optimization of its feature representations. We evaluate the proposed AWPCN model on Market-1501, DukeMTMC-reID and CUHK03 datasets. In extensive experiments, the AWPCN model outperforms most of the state-of-the-art methods on these representative datasets which clearly demonstrates the effectiveness of our proposed method. Our code will be released at https://github.com/deasonyuan/AWPCN.
C1 [Shu, Xiu] Harbin Inst Technol, Sch Sci, Shenzhen, Peoples R China.
   [Yuan, Di; Liu, Qiao] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
   [Liu, Jiaqi] Hunan Univ, Coll Finance & Stat, Changsha, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Hunan
   University
RP Yuan, D (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
EM shuxiuhit@gmail.com; yuandi@stu.hit.edu.cn; liuqiao.hit@gmail.com;
   jiaqiliu1993@163.com
RI Shu, Xiu/HNP-8892-2023; Liu, Qiao/AAL-5654-2021; Yuan, Di/Q-6521-2019
OI Liu, Qiao/0000-0003-0885-7976; Yuan, Di/0000-0001-9403-1112
FU National Natural Science Foundation of China [61672183]; Natural Science
   Foundation of Guangdong Province [2015A030313544]; Shenzhen Research
   Council [JCYJ20170413104556946, JCYJ20170815113552036]; project "The
   Verification Platform of Multi-tier Coverage Communication Network for
   Oceans" [PCL2018KP002]; China Scholarship Council (CSC)
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61672183), by the Natural Science Foundation of
   Guangdong Province (Grant No. 2015A030313544), by the Shenzhen Research
   Council (Grant No. JCYJ20170413104556946, JCYJ20170815113552036), and by
   the project "The Verification Platform of Multi-tier Coverage
   Communication Network for Oceans (PCL2018KP002)". Di Yuan is supported
   by a scholarship from China Scholarship Council (CSC).
CR [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], ARXIV190306325
   [Anonymous], 2013, ARXIV13075748
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Geng SZ, 2019, MULTIMED TOOLS APPL, V78, P11631, DOI 10.1007/s11042-018-6654-5
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Jia JR, 2017, COMPUT VIS IMAGE UND, V160, P87, DOI 10.1016/j.cviu.2017.04.003
   Kuo CH, 2013, IEEE WORK APP COMP, P281, DOI 10.1109/WACV.2013.6475030
   Lavi Bahram., 2018, Survey on deep learning techniques for person re-identification task
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PATTERN RECOGN, V61, P327, DOI 10.1016/j.patcog.2016.08.001
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Ma F, 2019, MULTIMED TOOLS APPL, V78, P337, DOI 10.1007/s11042-018-6239-3
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Si JL, 2018, IEEE T SYST MAN CY-S, V48, P1140, DOI 10.1109/TSMC.2016.2645660
   Song L, 2012, IEEE INT SYMP INFO, P199, DOI 10.1109/ISIT.2012.6283650
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Sun ZM, 2018, INT C COMP SUPP COOP, P501, DOI 10.1109/CSCWD.2018.8465310
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   YANG Q, 2019, COMPUTER VISION PATT
   Yang Y, 2016, AAAI CONF ARTIF INTE, P3655
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105554
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105526
   Yuan D, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105697
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P27271, DOI 10.1007/s11042-019-07828-2
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P14277, DOI 10.1007/s11042-018-6800-0
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   ZHONG Z, 2017, COMPUTER VISION PATT, P384
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu FQ, 2018, MULTIMED TOOLS APPL, V77, P3049, DOI 10.1007/s11042-017-5009-y
NR 58
TC 14
Z9 14
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23617
EP 23632
DI 10.1007/s11042-020-09018-x
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539889900006
DA 2024-07-18
ER

PT J
AU Tariq, S
   Khan, M
   Alghafis, A
   Amin, M
AF Tariq, Sundas
   Khan, Majid
   Alghafis, Abdullah
   Amin, Muhammad
TI A novel hybrid encryption scheme based on chaotic Lorenz system and
   logarithmic key generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Confidentiality scheme; Lorenz chaotic system; Encryption
ID COLOR IMAGE ENCRYPTION; DNA ENCRYPTION; ALGORITHM
AB The digital information is transmitted through different communication channels with ease within no time. The sphere of digital world is evolving and become one of the key aspects of our daily lives. In this regard, confidentially to this digital information which are fundamentally transmitted over insecure line of communication is one of the mandatory concerns. This digital information is placed in different databases available online. In this article, our aim is to perform cryptanalysis of Logarithmic based image encryption scheme and investigate its potential key leakages by utilizing public key to recover its private key. Moreover, we have suggested chaos-based Logarithm scheme which is more secure. The Lorenz system is utilized in an anticipated mechanism which is sensitive to initial conditions and chaotic parameters. The proposed scheme is then authenticated by using available security performance benchmarks. To measure the security against different cryptographic attacks, we utilized the statistical analyses which are entropy and the correlation between the pixels, and the differential analyses which are number of changing pixel rate (NPCR) and the unified averaged changed intensity (UACI). In order to resist the brute force attacks, key sensitivity analyses and key space analyses is also performed. The randomness of proposed encryption scheme investigated through entropy and NIST randomness suit tests. An application on digital images is investigated. Also, we have compared our modified confidentiality scheme with existing benchmarks which suggested our encryption technique is quite reasonable for digital multimedia security.
C1 [Khan, Majid; Amin, Muhammad] Inst Space Technol, CISL, Islamabad, Pakistan.
   [Tariq, Sundas; Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Alghafis, Abdullah] King Abdulaziz City Sci & Technol, Riyadh, Saudi Arabia.
C3 King Abdulaziz City for Science & Technology
RP Alghafis, A (corresponding author), King Abdulaziz City Sci & Technol, Riyadh, Saudi Arabia.
EM alghafis@kacst.edu.sa
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Abd El-Latif AA, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123687
   Abd EL-Latif AA, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.105942
   Abdelkhalek A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-72676-2
   ABDELLATIF AA, 2020, IEEE T NETWORK SERVI
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Al-Hazaimeh OM, 2019, NEURAL COMPUT APPL, V31, P2395, DOI 10.1007/s00521-017-3195-1
   Arshad U, 2019, INT J THEOR PHYS, V58, P3565, DOI 10.1007/s10773-019-04221-5
   Batool FE, 2024, MULTIMED TOOLS APPL, V83, P14959, DOI 10.1007/s11042-020-08851-4
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Jolfaei Alireza, 2010, Journal of Theoretical and Applied Information Technology, V19, P117
   Khan M., 2019, MULTIMED TOOLS APPL, P1
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Khan M, 2015, J VIB CONTROL, V21, P3450, DOI 10.1177/1077546314523029
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Raghuvamshi A, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING EDUCATION: INNOVATIVE PRACTICES AND FUTURE TRENDS (AICERA)
   Raza H, 2020, WIRELESS PERS COMMUN, V111, P395, DOI 10.1007/s11277-019-06865-2
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Song XH, 2020, PHYSICA A, V537, DOI 10.1016/j.physa.2019.122660
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   WANG J, 2019, COLOR IMAGE ENCRYPTI
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   YANG M, 2019, COLOR IMAGE COMPRESS, V17
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 42
TC 31
Z9 31
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23507
EP 23529
DI 10.1007/s11042-020-09134-8
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539519000005
DA 2024-07-18
ER

PT J
AU Alzubaidi, L
   Fadhel, MA
   Oleiwi, SR
   Al-Shamma, O
   Zhang, JL
AF Alzubaidi, Laith
   Fadhel, Mohammed A.
   Oleiwi, Sameer R.
   Al-Shamma, Omran
   Zhang, Jinglan
TI DFU_QUTNet: diabetic foot ulcer classification using novel deep
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic foot ulcers; Convolutional neural networks; Deep learning;
   Classification; Transfer learning
ID IMAGES; INFECTION; RISK
AB Diabetic Foot Ulcer (DFU) is the main complication of Diabetes, which, if not properly treated, may lead to amputation. One of the approaches of DFU treatment depends on the attentiveness of clinicians and patients. This treatment approach has drawbacks such as the high cost of the diagnosis as well as the length of treatment. Although this approach gives powerful results, the need for a remote, cost-effective, and convenient DFU diagnosis approach is urgent. In this paper, we introduce a new dataset of 754-ft images which contain healthy skin and skin with a diabetic ulcer from different patients. A novel Deep Convolutional Neural Network, DFU_QUTNet, is also proposed for the automatic classification of normal skin (healthy skin) class versus abnormal skin (DFU) class. Stacking more layers to a traditional Convolutional Neural Network to make it very deep does not lead to better performance, instead leading to worse performance due to the gradient. Therefore, our proposed DFU_QUTNet network is designed based on the idea of increasing the width of the network while keeping the depth compared to the state-of-the-art networks. Our network has been proven to be very beneficial for gradient propagation, as the error can be back-propagated through multiple paths. It also helps to combine different levels of features at each step of the network. Features extracted by DFU_QUTNet network are used to train Support Vector Machine (SVM) and K-Nearest Neighbors (KNN) classifiers. For the sake of comparison, we have fine-tuned then re-trained and tested three pre-trained deep learning networks (GoogleNet, VGG16, and AlexNet) for the same task. The proposed DFU_QUTNet network outperformed the state-of-the-art CNN networks by achieving the F1-score of 94.5%.
C1 [Alzubaidi, Laith; Zhang, Jinglan] Queensland Univ Technol, Fac Sci & Engn, Brisbane, Qld, Australia.
   [Alzubaidi, Laith; Fadhel, Mohammed A.; Al-Shamma, Omran] Univ Informat Technol & Commun, Baghdad, Iraq.
   [Oleiwi, Sameer R.] Muthanna Univ, Muthanna, Iraq.
C3 Queensland University of Technology (QUT); University of Information
   Technology & Communication
RP Alzubaidi, L (corresponding author), Queensland Univ Technol, Fac Sci & Engn, Brisbane, Qld, Australia.; Alzubaidi, L (corresponding author), Univ Informat Technol & Commun, Baghdad, Iraq.
EM laith.alzubaidi@hdr.qut.edu.au
RI Al-Shamma, Omran/Z-3351-2019; Alzubaidi, Laith/AAC-9291-2020; Fadhel,
   Mohammed A./Q-3147-2019; Oleiwi, Sameer Razzaq/AAW-2024-2021
OI Al-Shamma, Omran/0000-0001-5930-6176; Alzubaidi,
   Laith/0000-0002-7296-5413; Fadhel, Mohammed A./0000-0001-9877-049X;
   Oleiwi, Sameer Razzaq/0000-0001-9959-3747
CR Alzubaidi L., 2020, ADV INTELLIGENT SYST, V940
   [Anonymous], 2016, THESIS
   [Anonymous], 2016, ISBN, V978, P88
   Armstrong DG, 1998, DIABETES CARE, V21, P855, DOI 10.2337/diacare.21.5.855
   Avrahami R, 2015, WOUNDS, V27, P199
   Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047
   Boulton AJM, 2005, LANCET, V366, P1719, DOI 10.1016/S0140-6736(05)67698-2
   Bowling FL, 2011, WOUND REPAIR REGEN, V19, P25, DOI 10.1111/j.1524-475X.2010.00645.x
   Cavanagh P, 2012, DIABETES-METAB RES, V28, P107, DOI 10.1002/dmrr.2245
   Cheng PM, 2017, J DIGIT IMAGING, V30, P234, DOI 10.1007/s10278-016-9929-2
   Clemensen J, 2008, INT J TELEMED APPL, V2008, DOI 10.1155/2008/132890
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   El-Gayar O, 2013, INT J MED INFORM, V82, P637, DOI 10.1016/j.ijmedinf.2013.05.006
   Foltynski P, 2011, ARTIF ORGANS, V35, P176, DOI 10.1111/j.1525-1594.2010.01046.x
   Fraiwan Luay, 2018, Open Biomed Eng J, V12, P16, DOI 10.2174/1874120701812010016
   Fraiwan L, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0408-x
   Franc S, 2011, DIABETES METAB, V37, pS71, DOI 10.1016/S1262-3636(11)70969-7
   Geng L, 2017, MATH PROBL ENG, P1, DOI DOI 10.1109/WACVW.2017.8
   Gibiansky A., 2018, CONVOLUTIONAL NEURAL
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Goyal M, 2017, IEEE SYS MAN CYBERN, P618, DOI 10.1109/SMC.2017.8122675
   Hazenberg CEVB, 2014, DIABETES TECHNOL THE, V16, P370, DOI 10.1089/dia.2013.0251
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans MH, 2010, WOUNDS, V22, P289
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang YH, 2017, ASIA-PAC NETW OPER M, P231, DOI 10.1109/APNOMS.2017.8094140
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jegede O., 2015, P INT C HLTH INF MED, P47
   Kolesnik M, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P50
   Koushik J., 2016, arXiv preprint arXiv:1605.09081, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lavery L A, 1996, J Foot Ankle Surg, V35, P528
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu C, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.2.026003
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Nair L. R., 2019, MULTIMED TOOLS APPL, P1
   Nawaz W, 2018, LECT NOTES COMPUT SC, V10882, P869, DOI 10.1007/978-3-319-93000-8_99
   Ravishankar H, 2016, LECT NOTES COMPUT SC, V10008, P188, DOI 10.1007/978-3-319-46976-8_20
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Sert M, 2019, MULTIMED TOOLS APPL, V78, P17095, DOI 10.1007/s11042-018-7067-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Veredas F, 2010, IEEE T MED IMAGING, V29, P410, DOI 10.1109/TMI.2009.2033595
   Veredas FJ, 2015, NEUROCOMPUTING, V164, P112, DOI 10.1016/j.neucom.2014.12.091
   Vesal S, 2018, LECT NOTES COMPUT SC, V10882, P812, DOI 10.1007/978-3-319-93000-8_92
   Vijayalakshmi A, 2019, MULTIMEDIA TOOLS APP, P1
   Vilcahuaman L, 2015, IFMBE PROC, V51, P228, DOI 10.1007/978-3-319-19387-8_55
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang S, 2017, IEEE T BIO-MED ENG, V64, P990, DOI [10.1109/TBME.2016.2585344, 10.1109/TBME.2016.2632522]
   Wild S, 2004, DIABETES CARE, V27, P1047, DOI 10.2337/diacare.27.5.1047
   Yu YH, 2017, INFORMATION, V8, DOI 10.3390/info8030091
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang G, 2018, MULTIMED TOOLS APPL, V77, P9849, DOI 10.1007/s11042-017-4788-5
   Zhu X, 2019, MULTIMED TOOLS APPL, V78, P7143, DOI 10.1007/s11042-018-6495-2
NR 60
TC 86
Z9 90
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15655
EP 15677
DI 10.1007/s11042-019-07820-w
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900070
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Feng, ZQ
   He, QH
   Wang, L
   Qiu, MG
AF Feng, Zhengquan
   He, Qinghua
   Wang, Li
   Qiu, Mingguo
TI RETRACTED: EEG oscillatory patterns in the different processing phase
   during motor imagery (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Motor imagery; Brain electricity; Source location analysis; Brain
   functional connectivity
ID BRAIN; DISCRIMINATION
AB Motor imagery refers to the psychological realization of movements without movement or muscle activity; it is a research hotspot in neurophysiology, neuroimaging, neurology, and psychology; and it is used as a neurological rehabilitation of brain-computer interface technology. The foundation is widely studied. The EEG signal has a millisecond time resolution, which can facilitate the acquisition of neural signal changes in the body movement process. This article has selected the finger and thumb index finger movements as the task of motion imaging. Under the guidance of image and video, the characteristics of the brain electrical shock patterns during the finger-to-finger movement, thumb and forefinger pairing and unfolding were studied. The brain electrical signals of 15 healthy subjects were collected during the experiment, and the signals were analyzed for source location and information flow network. The result of source location analysis indicated that the activation of brain regions was mainly in the contra lateral SMA region, PMC region, and M1 region. However, the subjects were right-handed, so the characteristics of contra lateral activation were not obvious in the right-handed motor imaging process. Imagine that the opposite side of the pinching process is more powerful than the imaginary finger and the activation range is wider. The results of dynamic information flow of EEG signals at different stages of motor imaging show obvious contra lateral activation characteristics. The DTF analysis of the left-hand motion imaging finger pair pinching and unfolding shows that the information flow mainly flows from the right side of the brain to the left in the imagination process, while the right-hand motion imaging process is opposite, and the information flow mainly flows from the left side of the brain to the right side. The left hand imagines that the finger-to-pinch process is simpler and the number of connections is smaller than the information flow of the imagined finger deployment process. The right hand imagines that the finger-to-kneading process looks more complex than the imagined finger-expanding process, and the number of connections is more. However, its more connections appear mainly in the occipital region of the visual stimulus, the information flow in the frontal and parietal lobes is simple, and the number of connections is reduced. This article explores the relationship among the different movement phases of hand motion imaging and the change of EEG signals. The results show that the brain oscillation modes are similar and different, and the finger deployment process is used as a follow-up of the finger-to-kneading process. The process of knowing should be relatively simple.
C1 [Feng, Zhengquan; Wang, Li; Qiu, Mingguo] Army Med Univ, Coll Biomed Engn, Dept Med Image, Chongqing 400038, Peoples R China.
   [Feng, Zhengquan; He, Qinghua] Army Med Univ, Dept 5, Affiliated Hosp 3, Chongqing 400042, Peoples R China.
   [Feng, Zhengquan; He, Qinghua] Army Med Univ, Res Inst Surg, Chongqing 400042, Peoples R China.
C3 Army Medical University; Army Medical University; Army Medical
   University
RP Qiu, MG (corresponding author), Army Med Univ, Coll Biomed Engn, Dept Med Image, Chongqing 400038, Peoples R China.
EM qiumg_2002@126.com
CR Bai XX, 2007, NEUROIMAGE, V35, P598, DOI 10.1016/j.neuroimage.2006.12.026
   Bartels A, 2004, HUM BRAIN MAPP, V21, P75, DOI 10.1002/hbm.10153
   Bassett DS, 2006, NEUROSCIENTIST, V12, P512, DOI 10.1177/1073858406293182
   Cunnington R, 1996, EXP BRAIN RES, V111, P429
   De VFF, 2007, HUM BRAIN MAPP, V28, P1334, DOI [10.1002/hbm.20353, DOI 10.1002/HBM.20353]
   do Nascimento OF, 2008, IEEE T BIO-MED ENG, V55, P2675, DOI 10.1109/TBME.2008.2001139
   Farina D, 2007, J NEUROSCI METH, V162, P357, DOI 10.1016/j.jneumeth.2007.01.011
   Gu Y, 2009, FRONT NEUROSCI-SWITZ, V3, DOI 10.3389/neuro.20.003.2009
   Gu Y, 2009, MED BIOL ENG COMPUT, V47, P1257, DOI 10.1007/s11517-009-0523-3
   Gu Y, 2009, CLIN NEUROPHYSIOL, V120, P1596, DOI 10.1016/j.clinph.2009.05.006
   Hanke M, 1996, BIT, V36, P287, DOI 10.1007/BF01731984
   Hauk O, 2004, NEUROIMAGE, V21, P1612, DOI 10.1016/j.neuroimage.2003.12.018
   JEANNEROD M, 1995, NEUROPSYCHOLOGIA, V33, P1419, DOI 10.1016/0028-3932(95)00073-C
   JEANNEROD M, 1994, BEHAV BRAIN SCI, V17, P187, DOI 10.1017/S0140525X00034026
   KAMINSKI MJ, 1991, BIOL CYBERN, V65, P203, DOI 10.1007/BF00198091
   Neuper C, 1999, J CLIN NEUROPHYSIOL, V16, P373, DOI 10.1097/00004691-199907000-00010
   Pfurtscheller G, 1997, ELECTROEN CLIN NEURO, V103, P642, DOI 10.1016/S0013-4694(97)00080-1
   Schlögl A, 2005, J NEURAL ENG, V2, pL14, DOI 10.1088/1741-2560/2/4/L02
   Yang X, 2015, BASICS NEUROINFORMAT
NR 19
TC 1
Z9 1
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17101
EP 17113
DI 10.1007/s11042-019-07763-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600072
DA 2024-07-18
ER

PT J
AU Ishtiaq, U
   Kareem, SA
   Abdullah, ERMF
   Mujtaba, G
   Jahangir, R
   Ghafoor, HY
AF Ishtiaq, Uzair
   Kareem, Sameem Abdul
   Abdullah, Erma Rahayu Mohd Faizal
   Mujtaba, Ghulam
   Jahangir, Rashid
   Ghafoor, Hafiz Yasir
TI Diabetic retinopathy detection through artificial intelligent
   techniques: a review and open issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Diabetic retinopathy; Convolutional neural network; DIARETDB1; Image
   preprocessing; Artificial neural network; Transfer learning
ID BLOOD-VESSEL SEGMENTATION; FUNDUS IMAGES; NEURAL-NETWORKS; RETINAL
   IMAGES; AUTOMATED DETECTION; EXUDATES DETECTION; BRIGHT LESIONS;
   SEVERITY LEVEL; CLASSIFIER; SYSTEM
AB Diabetic Retinopathy (DR) is the disease caused by uncontrolled diabetes that may lead to blindness among the patients. Due to the advancements in artificial intelligence, early detection of DR through an automated system is more beneficial over the manual detection. At present, there are several published studies on automated DR detection systems through machine learning or deep learning approaches. This study presents a review on DR detection techniques from five different aspects namely, datasets, image preprocessing techniques, machine learning-based approaches, deep learning-based approaches, and performance measures. Moreover, it also presents the authors' observation and significance of the review findings. Furthermore, we also discuss nine new research challenges in DR detection. After a rigorous selection process, 74 primary publications were selected from eight academic databases for this review. From the selected studies, it was observed that many public datasets are available in the field of DR detection. In image preprocessing techniques, contrast enhancement combined with green channel extraction contributed the most in classification accuracy. In features, shape-based, texture-based and statistical features were reported as the most discriminative in DR detection. The Artificial Neural Network was proven eminent classifier compared to other machine learning classifiers. In deep learning, Convolutional Neural Network outperformed compared to other deep learning networks. Finally, to measure the classification performance, accuracy, sensitivity, and specificity metrics were mostly employed. This review presents a comprehensive summary of DR detection techniques and will be proven useful for the community of scientists working in the field of automated DR detection techniques.
C1 [Ishtiaq, Uzair; Kareem, Sameem Abdul; Abdullah, Erma Rahayu Mohd Faizal; Jahangir, Rashid; Ghafoor, Hafiz Yasir] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Artificial Intelligence, Kuala Lumpur, Malaysia.
   [Ishtiaq, Uzair; Jahangir, Rashid; Ghafoor, Hafiz Yasir] COMSATS Univ Islamabad, Dept Comp Sci, Vehari Campus, Vehari, Pakistan.
   [Mujtaba, Ghulam] Sukkur IBA Univ, Dept Comp Sci, Sukkur, Pakistan.
C3 Universiti Malaya; COMSATS University Islamabad (CUI); Sukkur IBA
   University
RP Kareem, SA (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Artificial Intelligence, Kuala Lumpur, Malaysia.
EM uzair@ciitvehari.edu.pk; sameem@um.edu.my; erma@um.edu.my;
   mujtaba@iba-suk.edu.pk; rashidjahangir@ciitvehari.edu.pk;
   yasirghafoor@ciitvehari.edu.pk
RI Mujtaba, Ghulam/AAW-4254-2021; Jahangir, Rashid/AAT-6804-2021; Abdul
   Kareem, Sameem/B-2259-2009; MOHD FAIZAL ABDULLAH, ERMA
   RAHAYU/B-8456-2010
OI Abdul Kareem, Sameem/0000-0001-5177-8013; MOHD FAIZAL ABDULLAH, ERMA
   RAHAYU/0000-0002-3026-9428; Ishtiaq, Uzair/0000-0002-3006-8132;
   JAHANGIR, RASHID/0000-0003-1129-6006
CR Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Abdel-Hakim AE, 2006, P IEEE COMPUTER SOC
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Aiello LP, 1998, DIABETES CARE, V21, P143, DOI 10.2337/diacare.21.1.143
   Al-Jarrah Mohammad A., 2017, Journal of Medical Engineering & Technology, V41, P498, DOI 10.1080/03091902.2017.1358772
   Almotiri J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8020155
   Amin J, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/6838976
   [Anonymous], 1991, Ophthalmology, V98, P786
   [Anonymous], 2016, 2016 INT C COMP AN S
   [Anonymous], 2014, P 22 ACM INT C MULTI
   [Anonymous], 2017, PLOS ONE
   [Anonymous], 2017, Proceedings of the 1st International Conference on Medical and Health Informatics 2017
   Antal B, 2014, KNOWL-BASED SYST, V60, P20, DOI 10.1016/j.knosys.2013.12.023
   Arunkumar R, 2017, NEURAL COMPUT APPL, V28, P329, DOI 10.1007/s00521-015-2059-9
   Bala MP, 2014, INT J BIOMED ENG TEC, V15, P128, DOI 10.1504/IJBET.2014.062743
   Barkana BD, 2017, KNOWL-BASED SYST, V118, P165, DOI 10.1016/j.knosys.2016.11.022
   Budak U, 2017, HEALTH INF SCI SYST, V5, DOI 10.1007/s13755-017-0034-9
   Bui T, 2017, 2017 IEEE 10TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA), P203, DOI 10.1109/IWCIA.2017.8203585
   Carrera EV, 2017, AUTOMATED DETECTION
   Chen GM, 2009, BMC MED RES METHODOL, V9, DOI 10.1186/1471-2288-9-5
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Choi JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187336
   Chudzik P, 2018, COMPUT METH PROG BIO, V158, P185, DOI 10.1016/j.cmpb.2018.02.016
   Cigizoglu HK, 2006, ADV ENG SOFTW, V37, P63, DOI 10.1016/j.advengsoft.2005.05.002
   Dasgupta A, 2017, FULLY CONVOLUTIONAL
   Fong DS, 2004, DIABETES CARE, V27, P2540, DOI 10.2337/diacare.27.10.2540
   Franklin SW, 2014, BIOCYBERN BIOMED ENG, V34, P117, DOI 10.1016/j.bbe.2014.01.004
   Fraz MM, 2017, BIOMED SIGNAL PROCES, V35, P50, DOI 10.1016/j.bspc.2017.02.012
   Ganesan K, 2014, MED BIOL ENG COMPUT, V52, P663, DOI 10.1007/s11517-014-1167-5
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Gegundez-Arias ME, 2017, COMPUT BIOL MED, V88, P100, DOI 10.1016/j.compbiomed.2017.07.007
   Ghosh R, 2017, AUTOMATIC DETECTION
   Gondal WM, 2017, 2017 IEEE INT C IM P
   Guerra L, 2011, DEV NEUROBIOL, V71, P71, DOI 10.1002/dneu.20809
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hanúsková V, 2013, J ELECTR ENG-SLOVAK, V64, P311, DOI 10.2478/jee-2013-0045
   Hemanth DJ, 2016, IETE J RES, V62, P893, DOI 10.1080/03772063.2016.1221745
   IEEE, 2016, 2016 INT C SIGN INF
   Jaya T, 2015, J DIGIT IMAGING, V28, P761, DOI 10.1007/s10278-015-9793-5
   Jordan KC, 2017, EXPERT REV OPHTHALMO, V12, P207, DOI 10.1080/17469899.2017.1307105
   Joshi S, 2018, BIOMED PHARMACOTHER, V97, P1454, DOI 10.1016/j.biopha.2017.11.009
   Kavitha M, 2014, J INTELL FUZZY SYST, V27, P2511, DOI 10.3233/IFS-141224
   Kolb H., 1995, WEBVISION ORG RETINA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusakunniran W, 2018, COMPUT METH PROG BIO, V158, P173, DOI 10.1016/j.cmpb.2018.02.011
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li G, 2018, EXUDATE DETECTION IN, P193
   Li X, 2017, 2017 10 INT C IM SIG
   Mahendran G, 2015, COMPUT ELECTR ENG, V45, P312, DOI 10.1016/j.compeleceng.2015.01.013
   Mane VM, 2017, J INTELL FUZZY SYST, V32, P2837, DOI 10.3233/JIFS-169226
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41, DOI 10.1007/s13534-017-0047-y
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mo J, 2017, INT J COMPUT ASS RAD, V12, P2181, DOI 10.1007/s11548-017-1619-0
   Mumtaz R, 2018, INT J DIABETES DEV C, V38, P80, DOI 10.1007/s13410-017-0561-6
   Naqvi SAG, 2015, COMPUT BIOL MED, V64, P217, DOI 10.1016/j.compbiomed.2015.07.003
   Nijalingappa P, 2016, MACHINE LEARNING APP
   Omar M, 2016, DETECTION CLASSIFICA
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Ouyang W, 2014, ARXIV PREPRINT ARXIV
   Paing MP, 2017, DETECTION LESIONS CL
   Perdomo O, 2017, CONVOLUTIONAL NETWOR
   Ponnibala M, 2014, J BIOL SYST, V22, DOI 10.1142/S0218339014500156
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Prentai P, 2015, 2015 9 INT S IM SIGN
   Prentasic P, 2016, COMPUT METH PROG BIO, V137, P281, DOI 10.1016/j.cmpb.2016.09.018
   Prentasic P, 2014, IEEE ENG MED BIO, P138, DOI 10.1109/EMBC.2014.6943548
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Rahim SS, 2016, NEURAL COMPUT APPL, V27, P1149, DOI 10.1007/s00521-015-1929-5
   Rahimy E, 2018, CURR OPIN OPHTHALMOL, V29, P254, DOI 10.1097/ICU.0000000000000470
   Reshma Chand CP, 2015, IND J SCI TECHNOL, V8
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy P, 2017, I S BIOMED IMAGING, P1078, DOI 10.1109/ISBI.2017.7950703
   Santhi D, 2016, BIOMED ENG-BIOMED TE, V61, P443, DOI 10.1515/bmt-2015-0188
   Shan J, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P357, DOI 10.1109/CHASE.2016.12
   Shirbahadurkar SD, 2018, EARLY STAGE DETECTIO, P15
   Simó-Servat O, 2013, CURR GENOMICS, V14, P289, DOI 10.2174/13892029113149990008
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinthanayothin C, 2002, DIABETIC MED, V19, P105, DOI 10.1046/j.1464-5491.2002.00613.x
   SISODIA DS, 2017, BIOMED PHARMACOL J, V10, P615, DOI [DOI 10.13005/bpj/1148, 10.13005/bpj/1148]
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Somasundaram SK, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0853-x
   Sopharak A, 2013, MAEJO INT J SCI TECH, V7, P294
   Srivastava R, 2017, COMPUT METH PROG BIO, V138, P83, DOI 10.1016/j.cmpb.2016.10.017
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan JH, 2017, INFORM SCIENCES, V420, P66, DOI 10.1016/j.ins.2017.08.050
   Tan JH, 2017, J COMPUT SCI-NETH, V20, P70, DOI 10.1016/j.jocs.2017.02.006
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Vanithamani R, 2018, EXUDATES IN DETECTIO, P252
   Vashist Praveen, 2011, Indian J Community Med, V36, P247, DOI 10.4103/0970-0218.91324
   Vega R, 2015, COMPUT BIOL MED, V58, P20, DOI 10.1016/j.compbiomed.2014.12.016
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   Wang S, 2017, IEEE T BIO-MED ENG, V64, P990, DOI [10.1109/TBME.2016.2585344, 10.1109/TBME.2016.2632522]
   Wong TY, 2016, JAMA-J AM MED ASSOC, V316, P2366, DOI 10.1001/jama.2016.17563
   Wu JY, 2015, IEEE ENG MED BIO, P4322, DOI 10.1109/EMBC.2015.7319351
   Xiao D, 2017, RETINAL HEMORRHAGE D
   Xiao ZT, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0414-z
   Xu KL, 2017, MOLECULES, V22, DOI 10.3390/molecules22122054
   Yang Y., 2017, MEDICAL IMAGE COMPUT, P533
   YOUDEN WJ, 1950, CANCER-AM CANCER SOC, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yu S, 2017, EXUDATE DETECTION FO
   Zhou W, 2017, COMPUT MATH METHODS
   Zhou W, 2017, IEEE ACCESS, V5, P2563, DOI 10.1109/ACCESS.2017.2671918
NR 104
TC 38
Z9 40
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15209
EP 15252
DI 10.1007/s11042-018-7044-8
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900050
DA 2024-07-18
ER

PT J
AU Jha, S
   Kumar, R
   Son, L
   Chiclana, F
   Puri, V
   Priyadarshini, I
AF Jha, Sudan
   Kumar, Raghvendra
   Son, Le Hoang
   Chiclana, Francisco
   Puri, Vikram
   Priyadarshini, Ishaani
TI Neutrosophic approach for enhancing quality of signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neutrosophic sets; Signal processing; Noises and errors
ID INTUITIONISTIC FUZZY-SETS; SIMILARITY MEASURES; AGGREGATION OPERATORS;
   IMAGE SEGMENTATION; DISTANCE MEASURE; ENHANCEMENT; FRAMEWORK; NETWORK;
   OPTIMIZATION; PERFORMANCE
AB Information in a signal is often followed by undesirable disturbance which is termed as noise. Preventing noise in the signal leads to signal integrity, which also leads to better signal quality. The previous related works have the major issues while reducing noise in signals regarding assumptions, frequency and time domain, etc. This paper proposes a new Neutrosophic approach to reduce noises and errors in signal transmission. In the proposed method, confidence function is used as the truth membership function, which is associated with sampled time intervals. Then, we define a Dependency function at each time interval for the frequency of transmitted signal. Finally, a Falsehood function, which indicates the loss in information due to amplitude distortion, is defined. This function shows how much information has been lost. Our objective is to minimize the falsehood function using several neutrosophic systems. Experimental results show 1% decrease in loss compared to the original signal without PAM. It is shown the decrease of 0.1% if the frequency is shifted to a higher range.
C1 [Jha, Sudan] Kalinga Inst Ind Technol KIIT, Sch Comp Engn, Bhubaneswar, Odisha, India.
   [Kumar, Raghvendra] LNCT Coll, Dept Comp Sci & Engn, Indore, India.
   [Kumar, Raghvendra] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
   [Son, Le Hoang] Ton Duc Thang Univ, Div Data Sci, Ho Chi Minh City, Vietnam.
   [Son, Le Hoang] Ton Duc Thang Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Chiclana, Francisco] De Montfort Univ, Sch Comp Sci & Informat, Leicester LE1 9BH, Leics, England.
   [Puri, Vikram] DuyTan Univ, R&D Ctr Simulat & Virtualizat, Da Nang, Vietnam.
   [Priyadarshini, Ishaani] Univ Delaware, Newark, DE USA.
C3 Kalinga Institute of Industrial Technology (KIIT); Vietnam National
   University Hanoi; Ton Duc Thang University; Ton Duc Thang University; De
   Montfort University; Duy Tan University; University of Delaware
RP Son, L (corresponding author), Ton Duc Thang Univ, Div Data Sci, Ho Chi Minh City, Vietnam.; Son, L (corresponding author), Ton Duc Thang Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
EM jhasudan@hotmail.com; raghvendraagrawal7@gmail.com;
   lehoangson@tdtu.edu.vn; chiclana@dmu.ac.uk; purivikram@duytan.edu.vn;
   ishaanidisha@gmail.com
RI Chiclana, Francisco/B-9031-2008; Jha, Sudan/P-9823-2018; priyadarshini,
   ishaani/AAW-3437-2020
OI Chiclana, Francisco/0000-0002-3952-4210; Jha, Sudan/0000-0003-0074-2584;
   priyadarshini, ishaani/0000-0002-8826-8065; Hoang Son,
   Le/0000-0001-6356-0046
CR Abdel-Basset M, 2019, NEURAL COMPUT APPL, V31, P1595, DOI 10.1007/s00521-018-3404-6
   Abdel-Basset M, 2018, FUTURE GENER COMP SY, V89, P19, DOI 10.1016/j.future.2018.06.024
   Abdel-Basset M, 2018, FUTURE GENER COMP SY, V86, P12, DOI 10.1016/j.future.2018.03.014
   Abdel-Basset M, 2018, J INTELL FUZZY SYST, V34, P4213, DOI 10.3233/JIFS-171952
   Abdel-Basset M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10060226
   Abdel-Basset M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040106
   Abdel-Basset M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040116
   Abdel-Basset M, 2018, MEASUREMENT, V124, P47, DOI 10.1016/j.measurement.2018.04.001
   Abdel-Basset M, 2017, J INTELL FUZZY SYST, V33, P4055, DOI 10.3233/JIFS-17981
   Ali M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100510
   Ali M, 2018, APPL SOFT COMPUT, V71, P1054, DOI 10.1016/j.asoc.2017.10.012
   Ali M, 2018, INT J FUZZY SYST, V20, P986, DOI 10.1007/s40815-017-0380-4
   Ali M, 2017, J INTELL FUZZY SYST, V33, P4077, DOI 10.3233/JIFS-17999
   Ali M, 2018, EXPERT SYST APPL, V91, P434, DOI 10.1016/j.eswa.2017.09.027
   Ali M, 2017, NEURAL COMPUT APPL, V28, P1817, DOI 10.1007/s00521-015-2154-y
   Amal L, 2018, ENVIRON SCI POLLUT R, V25, P27569, DOI 10.1007/s11356-018-2826-0
   [Anonymous], 2012, EUR J SCI RES
   [Anonymous], 2016, Journal of New Theory
   Ansari AQ, 2013, APPL SOFT COMPUT, V13, P563, DOI 10.1016/j.asoc.2012.08.002
   Aravindan TE, 2018, COGN SYST RES, DOI [10.1016/j.cogsys.2018.10.027, DOI 10.1016/J.COGSYS.2018.10.027]
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Basset M, 2018, HYBRID APPROACH NEUT, P254
   Bouserhal RE, 2017, J ACOUST SOC AM, V141, P1321, DOI 10.1121/1.4976051
   Broumi Said, 2016, Applied Mechanics and Materials, V841, P184, DOI 10.4028/www.scientific.net/AMM.841.184
   Giap CN, 2018, J INTELL FUZZY SYST, V34, P2479, DOI 10.3233/JIFS-171947
   Czyzewski A, 2001, NEUROCOMPUTING, V36, P5, DOI 10.1016/S0925-2312(00)00333-7
   Hai DT, 2017, APPL SOFT COMPUT, V54, P141, DOI 10.1016/j.asoc.2017.01.021
   Deli I, 2017, INT J MACH LEARN CYB, V8, P1309, DOI 10.1007/s13042-016-0505-3
   Deli I, 2018, NEUTROSOPHIC SETS SY, V22, P131
   Deli I, 2017, J INTELL FUZZY SYST, V32, P291, DOI 10.3233/JIFS-151677
   Deli I, 2017, INT J MACH LEARN CYB, V8, P665, DOI 10.1007/s13042-015-0461-3
   Doss S, 2018, IEEE ACCESS, V6, P56954, DOI 10.1109/ACCESS.2018.2868544
   Du JY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041123
   Huyen DTT, 2017, J MED IMAG HEALTH IN, V7, P421, DOI 10.1166/jmihi.2017.2111
   Ejaz W, 2018, IEEE SYST J, V12, P1909, DOI 10.1109/JSYST.2016.2615019
   Gannot S, 2001, IEEE T SIGNAL PROCES, V49, P1614, DOI 10.1109/78.934132
   Nguyen GN, 2019, INT J MACH LEARN CYB, V10, P1, DOI 10.1007/s13042-017-0691-7
   Guo YH, 2018, MEASUREMENT, V119, P28, DOI 10.1016/j.measurement.2018.01.025
   Guo YH, 2017, NEURAL COMPUT APPL, V28, P3009, DOI 10.1007/s00521-016-2441-2
   Guo YH, 2009, NEW MATH NAT COMPUT, V5, P653, DOI 10.1142/S1793005709001490
   Hemanth DJ, 2019, IEEE ACCESS, V7, P4275, DOI 10.1109/ACCESS.2018.2885639
   Hemanth DJ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1111-6
   Hemanth DJ, 2018, J INTELL FUZZY SYST, V35, P197, DOI 10.3233/JIFS-169580
   Hemanth DJ, 2018, COMPUT ELECTR ENG, V68, P170, DOI 10.1016/j.compeleceng.2018.04.006
   Long HV, 2019, COMPUT IND ENG, V127, P687, DOI 10.1016/j.cie.2018.11.007
   Jha S, 2019, MEASUREMENT, V134, P762, DOI 10.1016/j.measurement.2018.11.006
   Jha S, 2019, EVOL SYST-GER, V10, P621, DOI 10.1007/s12530-018-9247-7
   Johnson MT, 2007, SPEECH COMMUN, V49, P123, DOI 10.1016/j.specom.2006.12.002
   Kapoor R, 2018, MEASUREMENT, V126, P134, DOI 10.1016/j.measurement.2018.05.053
   Kapoor R, 2019, WIREL NETW, V25, P4541, DOI 10.1007/s11276-018-1750-z
   Kapoor R, 2018, MEASUREMENT, V120, P52, DOI 10.1016/j.measurement.2018.02.008
   Kaur S, 2019, J INDIAN SOC REMOTE, V47, P427, DOI 10.1007/s12524-019-00946-2
   Khan M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080314
   Koundal D, 2017, IET IMAGE PROCESS, V11, P640, DOI 10.1049/iet-ipr.2017.0046
   Kulkarni SR, 2002, LECT NOTES ELE201 IN, P1
   Kumar R, 2018, SPAT INF RES, V26, P629, DOI 10.1007/s41324-018-0207-x
   Kuojun Y, 2017, EL MEAS INSTR ICEMI, P379
   Son LH, 2019, APPL INTELL, V49, P172, DOI 10.1007/s10489-018-1262-7
   Son LH, 2017, INT J FUZZY SYST, V19, P1585, DOI 10.1007/s40815-016-0260-3
   Son LH, 2017, ENG APPL ARTIF INTEL, V59, P186, DOI 10.1016/j.engappai.2017.01.003
   Son LH, 2017, APPL INTELL, V46, P1, DOI 10.1007/s10489-016-0811-1
   Son LH, 2016, INT J FUZZY SYST, V18, P894, DOI 10.1007/s40815-015-0117-1
   Son LH, 2017, J COMPUT SYST SCI, V83, P159, DOI 10.1016/j.jcss.2016.06.009
   Son LH, 2016, APPL SOFT COMPUT, V46, P284, DOI 10.1016/j.asoc.2016.05.009
   Son LH, 2016, EXPERT SYST APPL, V46, P380, DOI 10.1016/j.eswa.2015.11.001
   Son LH, 2015, INFORM SCIENCES, V317, P202, DOI 10.1016/j.ins.2015.04.050
   Son LH, 2012, EXPERT SYST APPL, V39, P9848, DOI 10.1016/j.eswa.2012.02.167
   Le T, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070250
   Liu X, 2015, METROL MEAS SYST, V22, P403, DOI 10.1515/mms-2015-0032
   Lotfollahi M, 2018, J MED ULTRASON, V45, P205, DOI 10.1007/s10396-017-0811-8
   Lu ZK, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9070121
   Maharjan R, 2016, PROCEEDINGS 2016 FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2016), P45, DOI 10.1109/ICMIP.2016.12
   Majumdar P, 2014, J INTELL FUZZY SYST, V26, P1245, DOI 10.3233/IFS-130810
   Mohan J, 2013, BIOMED SIGNAL PROCES, V8, P779, DOI 10.1016/j.bspc.2013.07.005
   Mohan J, 2013, ADV INTELL SYST, V177, P861
   Mohan J, 2013, ARCH SCI J, V66, P125
   Mohan J., 2012, INT J MULTIMEDIA APP, V4, P73, DOI DOI 10.5121/IJMA.2012.4407
   Mohan J, 2013, MEASUREMENT SCI REV, V13, P1335
   Mohapatra J, 2013, INT NANO LETT, V3, DOI 10.1186/2228-5326-3-31
   Tam NT, 2018, WIREL NETW, V24, P1477, DOI 10.1007/s11276-016-1412-y
   Tam NT, 2015, IEEE INT C NETW SENS, P327, DOI 10.1109/ICNSC.2015.7116057
   Nugroho H.A., 2017, 2017 9 INT C INF TEC
   Peng HG, 2018, NEURAL COMPUT APPL, V30, P563, DOI 10.1007/s00521-016-2702-0
   Peng JJ, 2015, INT J COMPUT INT SYS, V8, P345, DOI 10.1080/18756891.2015.1001957
   Peng JJ, 2014, APPL SOFT COMPUT, V25, P336, DOI 10.1016/j.asoc.2014.08.070
   PENG X, 2018, J INTELL FUZZY SYST, V32, P955
   Peng XD, 2020, ARTIF INTELL REV, V53, P199, DOI 10.1007/s10462-018-9652-0
   Peng XD, 2018, NEURAL COMPUT APPL, V29, P939, DOI 10.1007/s00521-016-2607-y
   Son PH, 2019, UTIL POLICY, V56, P169, DOI 10.1016/j.jup.2019.01.003
   Thong PH, 2016, ENG APPL ARTIF INTEL, V56, P121, DOI 10.1016/j.engappai.2016.08.009
   Thong PH, 2016, SOFT COMPUT, V20, P3549, DOI 10.1007/s00500-015-1712-7
   Thong PH, 2016, KNOWL-BASED SYST, V109, P48, DOI 10.1016/j.knosys.2016.06.023
   Phuong P.T.M., 2018, J COMPUT SCI CYBERN, V34, P17, DOI [10.15625/1813-9663/34/1/12725, DOI 10.15625/1813-9663/34/1/12725]
   Pramanik S., 2015, J NEW THEORY, V4, P90
   Pramanik S, 2017, NEURAL COMPUT APPL, V28, P1163, DOI 10.1007/s00521-015-2125-3
   Praveen A, 2013, ULTRASONICS, V53, P1288, DOI 10.1016/j.ultras.2013.03.013
   Rahman C, 2010, COMPLEX CASES IN PERIPHERAL VASCULAR INTERVENTIONS, P62
   Ngan RT, 2018, APPL SOFT COMPUT, V69, P393, DOI 10.1016/j.asoc.2018.04.036
   Ngan R, 2018, APPL INTELL, V48, P499, DOI 10.1007/s10489-017-0986-0
   Robinson YH, 2019, J AMB INTEL HUM COMP, V10, P4455, DOI 10.1007/s12652-018-1126-3
   Sabharwal T, 2019, ARTIF INTELL REV, V52, P1009, DOI 10.1007/s10462-018-9660-0
   Sahin R, 2017, NEURAL COMPUT APPL, V28, P1177, DOI 10.1007/s00521-015-2131-5
   Saravanan K, 2018, ENVIRON MONIT ASSESS, V190, DOI 10.1007/s10661-018-6914-x
   Saravanan K, 2019, EARTH SCI INFORM, V12, P241, DOI 10.1007/s12145-018-0371-5
   Sinderby C, 1997, ENHANCEMENT SIGNAL Q
   Singh K, 2018, COMPUT NETW, V138, P90, DOI 10.1016/j.comnet.2018.03.023
   Singh N, 2020, ENG COMPUT-GERMANY, V36, P185, DOI 10.1007/s00366-018-00696-8
   SMARANDACHE F, 2000, UNIFYING FIELD LOGIC
   Smarandache F, 2006, 2006 IEEE International Conference on Granular Computing, P38, DOI 10.1109/GRC.2006.1635754
   Son LH, 2019, TELECOMMUN SYST, V70, P617, DOI 10.1007/s11235-018-0481-x
   Son LH, 2016, INFORM SYST, V58, P87, DOI 10.1016/j.is.2014.10.001
   Son LH, 2014, EXPERT SYST APPL, V41, P6861, DOI 10.1016/j.eswa.2014.05.001
   Tian ZP, 2016, INT J SYST SCI, V47, P3598, DOI 10.1080/00207721.2015.1102359
   Tuan TM, 2016, APPL INTELL, V45, P402, DOI 10.1007/s10489-016-0763-5
   Ngan TT, 2018, ROM J INF SCI TECH, V21, P344
   Tuan TM, 2019, EVOL SYST-GER, V10, P629, DOI 10.1007/s12530-018-9251-y
   U SP, 2004, IEEE T INSTRUM MEAS, V53, P1279, DOI 10.1109/TIM.2004.830787
   Uluçay V, 2018, NEURAL COMPUT APPL, V29, P739, DOI 10.1007/s00521-016-2479-1
   Vardeman SB, 2005, IEEE T INSTRUM MEAS, V54, P409, DOI 10.1109/TIM.2004.838912
   Veras J, 2014, SPEECH QUALITY ENHAN
   Vullings R, 2011, IEEE T BIO-MED ENG, V58, P1094, DOI 10.1109/TBME.2010.2099229
   Wang H., 2010, Infinite Study
   Wang L, 2018, INT J FUZZY SYST, V20, P13, DOI 10.1007/s40815-017-0373-3
   Wen JY, 2019, IMAGING SCI J, V67, P63, DOI 10.1080/13682199.2018.1549694
   Ye J, 2014, VECTOR SIMILARITY ME
   Ye J, 2017, J EXP THEOR ARTIF IN, V29, P731, DOI [10.1080/0952813X.2016.1259263, 10.7495/j.issn.1009-3486.2017.03.001]
   Ye J, 2015, ARTIF INTELL MED, V63, P171, DOI 10.1016/j.artmed.2014.12.007
   Ye J, 2014, J INTELL FUZZY SYST, V26, P2459, DOI 10.3233/IFS-130916
   Ye J, 2014, J INTELL FUZZY SYST, V26, P165, DOI 10.3233/IFS-120724
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang HY, 2014, SCI WORLD J, DOI 10.1155/2014/645953
NR 131
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16883
EP 16914
DI 10.1007/s11042-019-7375-0
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600059
DA 2024-07-18
ER

PT J
AU Jin, X
   Wu, L
   Zhao, G
   Zhou, XH
   Zhang, XK
   Li, XD
AF Jin, Xin
   Wu, Le
   Zhao, Geng
   Zhou, Xinghui
   Zhang, Xiaokun
   Li, Xiaodong
TI IDEA: A new dataset for image aesthetic scoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aesthetic assessment; Neural network; Computer vision
AB The aesthetic quality assessment of image is a challenging work in computer vision field. The recent research work used the deep convolutional neural network to evaluate the aesthetic quality of images. However, the score of image data sets has a strongly normal distribution, which makes the training of neural network easy to be over-fitting. In addition, traditional deep learning methods usually pre-process images, which destroy the original aesthetic features of the picture, so that the network can only learn some superficial aesthetic features. This paper presents a new data set what images distributed evenly for aesthetics (IDEA). This data set has less statistical characteristics, which is helpful for the neural network to learn the deeper features. We propose a new spatial aggregation perception neural network architecture which can control channel weights automatically. Our experiments in different data sets can prove the advantages and effectiveness of our method.
C1 [Jin, Xin; Wu, Le; Zhao, Geng; Zhou, Xinghui; Zhang, Xiaokun; Li, Xiaodong] Beijing Elect Sci & Technol Inst, Beijing 100070, Peoples R China.
   [Jin, Xin] CETC Big Data Res Inst Co Ltd, Guiyang, Guizhou, Peoples R China.
C3 Beijing Electronic Science & Technology Institute
RP Li, XD (corresponding author), Beijing Elect Sci & Technol Inst, Beijing 100070, Peoples R China.
EM lxd@besti.edu.cn
RI li, xiaofeng/GXF-9442-2022; liang, liang/IAO-8518-2023; jin,
   xin/GQZ-5811-2022; li, xiao/HJP-5134-2023; li, xiao/GSN-6181-2022
CR [Anonymous], Recognizing image style
   Bianco S, 2016, LECT NOTES COMPUT SC, V10016, P117, DOI 10.1007/978-3-319-48680-2_11
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong Z, 2015, NEUROCOMPUTING, V168, P308, DOI 10.1016/j.neucom.2015.05.095
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   Hou L., 2016, ARXIV161105916
   Hu J., 2017, CoRR
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jin B, 2016, IEEE IMAGE PROC, P2291, DOI 10.1109/ICIP.2016.7532767
   Jin X, 2017, P 32 INT C AM ASS AR
   Jin Xin., 2016, 2016 8th International Conference, P1
   Kao YY, 2017, IEEE T IMAGE PROCESS, V26, P1482, DOI 10.1109/TIP.2017.2651399
   Kao YY, 2016, SIGNAL PROCESS-IMAGE, V47, P500, DOI 10.1016/j.image.2016.05.004
   Kao YY, 2015, IEEE IMAGE PROC, P1583, DOI 10.1109/ICIP.2015.7351067
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Lu H, 2018, FUTURE GENERATION CO
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Lu X, 2015, IEEE T MULTIMEDIA, V17, P2021, DOI 10.1109/TMM.2015.2477040
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Ma S, 2017, ARXIV170400248
   Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Wang ZY, 2017, IEEE IJCNN, P941, DOI 10.1109/IJCNN.2017.7965953
   Wu O, 2011, IEEE I CONF COMP VIS, P225, DOI 10.1109/ICCV.2011.6126246
   Xu TG, 2017, IEEE INT INTERC TECH
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Zhao MQ, 2016, SIGNAL PROCESS-IMAGE, V47, P511, DOI 10.1016/j.image.2016.05.009
NR 34
TC 8
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14341
EP 14355
DI 10.1007/s11042-018-6436-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900002
DA 2024-07-18
ER

PT J
AU Manogaran, G
   Baskar, S
   Shakeel, PM
   Chilamkurti, N
   Kumar, R
AF Manogaran, Gunasekaran
   Baskar, S.
   Shakeel, P. Mohamed
   Chilamkurti, Naveen
   Kumar, R.
TI Analytics in real time surveillance video using two-bit transform
   accelerative regressive frame check
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accelerative Regressive frame Check algorithm; Video datasets; Peak
   signal to noise ratio
AB Face recognition is an established area of research in computer vision and it had played a great role in developing content based personal retrieval systems from real time surveillance video feeds. Face recognition in live videos is a complex problem as facial features fall into high dimensional space and involves large search time. Though, there is an extensive improvement in computational infrastructure over the years, the need for improved search algorithms without increase in cost is a challenge. Existingmethodologies in literature fail to perform in real time scenarios as the cost of feature matching is high. Hence, this research work proposes a Two-Bit Transform AccelerativeRegressive Frame Check algorithm (2BT-ARFCA) methodology that facilitates face recognition in video at a faster rate, suitable for surveillance and authentication applications. Finally the results are experimentally validated with variousvideo datasets and the state-of-the-art techniques proves that the proposed method performs better in terms of Specificity, Sensitivity, Mean Square Error (MSE), Peak signal to noise Ratio (PSNR), The Structural Similarity Index (SSIM) and accuracy.
C1 [Manogaran, Gunasekaran] Univ Calif Davis, Davis, CA 95616 USA.
   [Baskar, S.] Karpagam Acad Higher Educ, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
   [Shakeel, P. Mohamed] Univ Teknikal Malaysia Melaka, Fac Informat & Commun Technol, Melaka, Malaysia.
   [Chilamkurti, Naveen] La Trobe Univ, Dept Comp Sci & IT, Melbourne, Vic 3086, Australia.
   [Kumar, R.] NIT Nagaland, Dept Elect & Instrumentat Engn, Dimapur 797103, Chumukedima, India.
C3 University of California System; University of California Davis;
   Karpagam Academy of Higher Education (KAHE); University Teknikal
   Malaysia Melaka; Universiti Teknologi Malaysia; La Trobe University;
   National Institute of Technology (NIT System); National Institute of
   Technology Nagaland
RP Baskar, S (corresponding author), Karpagam Acad Higher Educ, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
EM basker.s@kahedu.edu.in
RI Kumar, Rajesh/G-1408-2014; Chilamkurti, Naveen/S-9636-2019; Mohamed
   Shakeel, Pethuraj/P-4135-2019; S, Baskar/R-6346-2017
OI Kumar, Rajesh/0000-0002-6019-0702; Chilamkurti,
   Naveen/0000-0002-5396-8897; S, Baskar/0000-0003-3570-3059; Kumar,
   R./0000-0002-0462-5628
CR [Anonymous], 2019, IEEE T PATTERN ANAL
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bock RD, 2018, PROC SPIE, V10643, DOI 10.1117/12.2305455
   Chen S, 2018, STRUCTURAL HLTH MONI
   Fan C, 2018, ENERG BUILDINGS, V159, P296, DOI 10.1016/j.enbuild.2017.11.008
   Galiyawala H., 2018, ARXIV181005080
   Gao ZW, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7426915
   Gibelli D, 2017, J FORENSIC SCI, V62, P457, DOI 10.1111/1556-4029.13290
   Hemanth DJ, 2018, CIRC SYST SIGNAL PR, V37, P1609, DOI 10.1007/s00034-017-0613-7
   Huang KQ, 2017, IEEE T SYST MAN CY-S, V47, P589, DOI 10.1109/TSMC.2017.2679694
   Hussain AJ, 2018, NEUROCOMPUTING
   Kanai K, 2018, IEICE T COMMUN, VE101B, P688, DOI 10.1587/transcom.2017NRP0011
   Lin A, 2018, U.S. Patent, Patent No. [9,928,708, 9928708]
   Liu MD, 2018, LECT NOTES COMPUT SC, V11066, P48, DOI 10.1007/978-3-030-00015-8_5
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Quick D., 2018, Springer briefs on cyber security systems and networks, V1, P69, DOI [10.1007/978-981-10-7763-0_4, DOI 10.1007/978-981-10-7763-0_4]
   Solmaz B, 2018, PROC SPIE, V10802, DOI 10.1117/12.2325527
   Wang C, 2018, LECT NOTES COMPUT SC, V10705, P189, DOI 10.1007/978-3-319-73600-6_17
   Yu X, 2018, MULTIMED TOOLS APPL, V77, P4563, DOI 10.1007/s11042-017-4540-1
NR 20
TC 15
Z9 15
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16155
EP 16172
DI 10.1007/s11042-019-7526-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600020
DA 2024-07-18
ER

PT J
AU Murtaza, G
   Shuib, L
   Mujtaba, G
   Raza, G
AF Murtaza, Ghulam
   Shuib, Liyana
   Mujtaba, Ghulam
   Raza, Ghulam
TI Breast Cancer Multi-classification through Deep Neural Network and
   Hierarchical Classification Approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast Cancer; Deep Learning and Transfer Learning; Hierarchical
   Classification; Histopathology Images; Image Classification;
   Convolutional Neural Network
ID MAMMOGRAMS; DIAGNOSIS; MASSES
AB Breast cancer (BC) is the third leading cause of deaths in women globally. In general, histopathology images are recommended for early diagnosis and detailed analysis for BC. Thus, state-of-the-art classification models are required for the early prediction of BC using histopathology images. This study aims to develop an accurate and computationally feasible classification model named Biopsy Microscopic Image Cancer Network (BMIC_Net) to classify BC into eight distinct subtypes through deep learning (DL) and hierarchical classification approach. For experiments, the publicly available dataset BreakHis is used and splitted into training and testing set. Furthermore, data augmentation was performed on training set only and 4096 result-oriented features were extracted through DL. In order to improve the classification performance, feature reduction schemes were experimented to elicit the most discriminative feature subset. Finally, six machine-learning algorithms were analyzed to acquire the best results. The experimental results revealed that BMIC_Net outperformed existing baseline models by obtaining the highest accuracy of 95.48% for first-level classifier and 94.62% and 92.45% for second-level classifiers. Thus, this model can be deployed on a normal desktop machine in any healthcare center of less privileged areas in under-developing countries to serve as second opinion for breast cancer classification.
C1 [Murtaza, Ghulam; Shuib, Liyana; Mujtaba, Ghulam] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Informat Syst, Kuala Lumpur 50603, Malaysia.
   [Murtaza, Ghulam; Mujtaba, Ghulam] Sukkur IBA Univ, Dept Comp Sci, Sukkur, Pakistan.
   [Raza, Ghulam] St James Hosp, Jamess StreetUshersDublin, Dublin 8, Ireland.
C3 Universiti Malaya; Sukkur IBA University; Trinity College Dublin
RP Murtaza, G; Shuib, L (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Informat Syst, Kuala Lumpur 50603, Malaysia.; Murtaza, G (corresponding author), Sukkur IBA Univ, Dept Comp Sci, Sukkur, Pakistan.
EM gmurtaza@iba-suk.edu.pk; liyanashuib@um.edu.my; mujtaba@iba-stdc.edu.pk;
   ghulam.raza@ymail.com
RI Murtaza, Ghulam/ABD-7461-2020; Mujtaba, Ghulam/AAW-4254-2021; Shuib,
   Liyana/M-8698-2013
OI Murtaza, Ghulam/0000-0003-0318-7168; Shuib, Liyana/0000-0002-7907-0671
FU University Malaya Research Grant - Frontier Science [RG380-17AFR]
FX This research was fully funded by the University Malaya Research Grant -
   Frontier Science (Grant No: RG380-17AFR).
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   [Anonymous], AMSTER658
   [Anonymous], 2017 IEEE INT C SIGN
   [Anonymous], APPL SCI BIOM COMM T
   [Anonymous], 2016, DATA MINING PRACTICA, DOI DOI 10.1016/C2009-0-19715-5
   [Anonymous], ICML
   [Anonymous], 2018, World Cancer Report
   [Anonymous], 2006, IPCV
   [Anonymous], 1997, KDD
   [Anonymous], 2018, BIOMED RES INT
   [Anonymous], NEUR NETW 2000 IJCNN
   [Anonymous], BIOM IM NAN MACR 200
   [Anonymous], HYPERSPECTRAL IMAGE
   [Anonymous], SLR SEMICOUPLED LOCA
   [Anonymous], 2016, 2016 23 INT C PATT R
   [Anonymous], INT J RECENT TRENDS
   [Anonymous], 1995, SFITR9502010 TR SANT
   [Anonymous], 2012, MINING TEXT DATA
   Antropova N, 2017, MED PHYS, V44, P5162, DOI 10.1002/mp.12453
   Babu JS, 2013, J MED IMAG HEALTH IN, V3, P206, DOI 10.1166/jmihi.2013.1146
   Buciu I, 2011, BIOMED SIGNAL PROCES, V6, P370, DOI 10.1016/j.bspc.2010.10.003
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Cruz-Roa A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46450
   Dimitropoulos K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185110
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Han ZY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04075-z
   Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831
   Kasban H., 2015, Int. J. Inf. Sci. Intell. Syst., V4, P37
   KENT JT, 1983, BIOMETRIKA, V70, P163, DOI 10.1093/biomet/70.1.163
   Khosravi P, 2018, EBIOMEDICINE, V27, P317, DOI 10.1016/j.ebiom.2017.12.026
   Kotsiantis SB, 2007, FRONT ARTIF INTEL AP, V160, P3
   Kowal M, 2013, COMPUT BIOL MED, V43, P1563, DOI 10.1016/j.compbiomed.2013.08.003
   Kozegar E, 2013, J CANCER RES THER, V9, P592, DOI 10.4103/0973-1482.126453
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuramochi M, 2005, INT J ARTIF INTELL T, V14, P641, DOI 10.1142/S0218213005002302
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Loukas C, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/829461
   Ma Y, 2018, IEEE GEOSCI REMOTE S, V15, P587, DOI 10.1109/LGRS.2018.2800080
   Rabidas R, 2018, IEEE J BIOMED HEALTH, V22, P826, DOI 10.1109/JBHI.2017.2715021
   Rennie JD., 2003, P 20 INT C MACHINE L
   Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Spanhol FA, 2017, SYST MAN CYB SMC 201
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Wan T, 2017, NEUROCOMPUTING, V229, P34, DOI 10.1016/j.neucom.2016.05.084
   Wang P, 2016, SIGNAL PROCESS, V122, P1, DOI 10.1016/j.sigpro.2015.11.011
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Zhang Y, 2012, INT J COMPUT ASS RAD, V7, P323, DOI 10.1007/s11548-011-0628-7
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P873, DOI 10.1177/0037549716667834
NR 53
TC 34
Z9 35
U1 0
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15481
EP 15511
DI 10.1007/s11042-019-7525-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900062
DA 2024-07-18
ER

PT J
AU Shen, WZ
   Hu, HQ
   Dai, BS
   Wei, XL
   Sun, J
   Jiang, L
   Sun, YK
AF Shen, Weizheng
   Hu, Hengqi
   Dai, Baisheng
   Wei, Xiaoli
   Sun, Jian
   Jiang, Li
   Sun, Yukun
TI Individual identification of dairy cows based on convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cow identification; Precision livestock farming; Computer vision;
   Convolutional neural networks; Object detection
ID GEODESIC PROPAGATION; CATTLE
AB Individual identification of each cow is significant for precision livestock farming. In this paper, we propose a novel contactless cow identification method based on convolutional neural networks. We first collected a set of side-view images of dairy cows, then employed the YOLO model to detect the cow object in the side-view image, and finally fine-tuned a convolutional neural network model to classify each individual cow. In our experiments, a total of 105 side-view images of cows were collected, and the proposed method achieved an accuracy of 96.65% in cow identification, which outperformed existing experiments. Experimental results demonstrate the effectiveness of the proposed method for cow identification and the potential for our method to be applied to other livestock.
C1 [Shen, Weizheng; Hu, Hengqi; Dai, Baisheng; Wei, Xiaoli; Sun, Jian; Jiang, Li] Northeast Agr Univ, Sch Elect Engn & Informat, Harbin 150030, Peoples R China.
   [Dai, Baisheng] Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
   [Jiang, Li] Heilongjiang Bayi Agr Univ, Sch Elect Engn & Informat, Daqing 163319, Peoples R China.
   [Sun, Yukun] Northeast Agr Univ, Sch Anim Sci & Technol, Harbin 150030, Peoples R China.
C3 Northeast Agricultural University - China; Ministry of Agriculture &
   Rural Affairs; Heilongjiang Bayi Agricultural University; Northeast
   Agricultural University - China
RP Dai, BS (corresponding author), Northeast Agr Univ, Sch Elect Engn & Informat, Harbin 150030, Peoples R China.; Dai, BS (corresponding author), Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
EM bsdai@neau.edu.cn
RI he, he/JPL-3505-2023; zhu, yujie/KBC-4009-2024
CR Chen XW, 2012, LECT NOTES COMPUT SC, V7574, P553, DOI 10.1007/978-3-642-33712-3_40
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jin X, 2018, AAAI C ART INT AAAI
   Johnston AM, 1996, VET REC, V138, P612, DOI 10.1136/vr.138.25.612
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kühl HS, 2013, TRENDS ECOL EVOL, V28, P432, DOI 10.1016/j.tree.2013.02.013
   Kumar S, 2018, MEASUREMENT, V116, P1, DOI 10.1016/j.measurement.2017.10.064
   Kumar S, 2016, P NATL A SCI INDIA A, V86, P137, DOI 10.1007/s40010-016-0264-2
   Li Q, 2014, IEEE T IMAGE PROCESS, V23, P4812, DOI 10.1109/TIP.2014.2358193
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Voulodimos AS, 2010, COMPUT ELECTRON AGR, V70, P380, DOI 10.1016/j.compag.2009.07.009
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang Y, 2018, J NETW COMPUT APPL, V117, P10, DOI 10.1016/j.jnca.2018.05.007
   Zhao KaiXuan Zhao KaiXuan, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P181
   Zin T.T., 2018, INT MULTICONFERENCE
NR 28
TC 46
Z9 50
U1 13
U2 91
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14711
EP 14724
DI 10.1007/s11042-019-7344-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900022
DA 2024-07-18
ER

PT J
AU Wang, SH
   Chen, Y
AF Wang, Shui-Hua
   Chen, Yi
TI Fruit category classification via an eight-layer convolutional neural
   network with parametric rectified linear unit and dropout technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computer vision; Convolutional neural network; Data
   augmentation; Dropout; Fruit category classification; Parametric
   rectified linear unit
AB In this paper, we apply an improved deep convolutional neural network (CNN) in fruit category classification, which is a hotspot in computer vision field. We created an 8-layer deep convolutional neural network, and utilized parametric rectified linear unit to take the place of plain rectified linear unit, and placed dropout layer before each fully-connected layer. Data augmentation was used to help avoid overfitting. Our 8-layer deep convolutional neural network secured an overall accuracy of 95.67%. This proposed 8-layer method performs better than five state-of-the-art methods using traditional machine learning methods and one state-of-the-art CNN method.
C1 [Wang, Shui-Hua] Nanjing Univ, Med Sch, Affiliated Hosp, Dept Rheumatol & Immunol,Nanjing Drum Tower Hosp, Nanjing, Peoples R China.
   [Wang, Shui-Hua] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
   [Wang, Shui-Hua] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
   [Chen, Yi] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210008, Jiangsu, Peoples R China.
C3 Nanjing University; University of Leicester; Loughborough University;
   Nanjing Normal University
RP Wang, SH (corresponding author), Nanjing Univ, Med Sch, Affiliated Hosp, Dept Rheumatol & Immunol,Nanjing Drum Tower Hosp, Nanjing, Peoples R China.; Wang, SH (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.; Wang, SH (corresponding author), Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.; Chen, Y (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210008, Jiangsu, Peoples R China.
EM shuihuawang@ieee.org; cs_chenyi@njnu.edu.cn
RI Wang, Shuihua/G-7326-2016
OI Chen, Yi/0000-0002-8762-4523
CR Barushka A, 2016, LECT NOTES COMPUT SC, V10037, P65, DOI 10.1007/978-3-319-49130-1_6
   Benani A, 2018, M S-MED SCI, V34, P316
   Cheng CH, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1085-4
   Duggal R, 2017, IEEE INT CONF COMP V, P974, DOI 10.1109/ICCVW.2017.119
   Jia WJ, 2018, AIP CONF PROC, V1955, DOI 10.1063/1.5033677
   Jiang XH, 2018, NEUROCOMPUTING, V275, P1132, DOI 10.1016/j.neucom.2017.09.056
   Kamal-Eldin A, 2018, J FOOD MEAS CHARACT, V12, P1020, DOI 10.1007/s11694-018-9717-4
   Kheiralipour K, 2017, J FOOD PROCESS ENG, V40, DOI 10.1111/jfpe.12558
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li YA, 2017, 5 INT C IND APPL ENG, P293
   Liu FY, 2017, ADV SOC SCI EDUC HUM, V119, P1629
   Lu SY, 2018, J MED IMAG HEALTH IN, V8, P1486, DOI 10.1166/jmihi.2018.2459
   Qu YW, 2013, ADV INTEL SYS RES, V37, P62
   Qu YW, 2008, PROCEEDINGS OF THE 2008 CHINESE CONFERENCE ON PATTERN RECOGNITION (CCPR 2008), P24
   Shao XY, 2016, 2016 23RD INTERNATIONAL WORKSHOP ON ACTIVE-MATRIX FLATPANEL DISPLAYS AND DEVICES (AM-FPD), P19, DOI 10.1109/AM-FPD.2016.7543604
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22875, DOI 10.1007/s11042-018-6003-8
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22671, DOI 10.1007/s11042-017-5146-3
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
   Zhang YD, 2016, EXPERT SYST, V33, P239, DOI 10.1111/exsy.12146
   Zhang YD, 2011, LECT NOTES COMPUT SC, V6728, P514, DOI 10.1007/978-3-642-21515-5_61
   Zhang YD, 2012, SENSORS-BASEL, V12, P12489, DOI 10.3390/s120912489
   Zhang YD, 2011, ADV MATER RES-SWITZ, V186, P459, DOI 10.4028/www.scientific.net/AMR.186.459
   Zhang YD, 2010, SCI CHINA INFORM SCI, V53, P1963, DOI 10.1007/s11432-010-4075-9
   Zhang YD, 2008, SENSORS-BASEL, V8, P7518, DOI 10.3390/s8117518
   Zhang YD, 2009, SCI CHINA SER F, V52, P914, DOI 10.1007/s11432-009-0019-7
   Zhang Z, 2017, IEEE T IMAGE PROCESS, V26, P1466, DOI 10.1109/TIP.2017.2651396
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
NR 35
TC 39
Z9 41
U1 5
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15117
EP 15133
DI 10.1007/s11042-018-6661-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900045
DA 2024-07-18
ER

PT J
AU Li, WH
   Su, YT
   Zhao, ZL
   Hao, T
   Li, YY
AF Li, Wenhui
   Su, Yuting
   Zhao, Zhenlan
   Hao, Tong
   Li, Yangyang
TI Exploring contextual information for view-wised 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE View-based model retrieval; Contextual information; Similarity measure
ID OBJECT RETRIEVAL
AB Recently, with the rapid development of digital technologies and its wide application, 3D model retrieval is becoming more and more important in graphic communities. In this task, how to effectively represent the 3D model and how to robustly measure similarity between pair-wise models are two crucial problems. In previous work, most papers dedicated to researching how to effectively using the visualize features to represent 3D model and using the visual information to measure the similarity. However, visual feature can not represent 3D model well because of the model variations in poses and illumination. To address this task, we propose an novel framework, which utilizes the visual and contextual information to construct the rank graphs and fuses these two graphs to enhance the similarity measure. When fusing visual and contextual information, we define four strategies to measure the similarity among models according to the relation between the query model and the gallery models. The extensive experimental results demonstrate the superiority of our proposed method compare against the state of the arts.
C1 [Li, Wenhui; Su, Yuting; Zhao, Zhenlan] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Hao, Tong] Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
   [Li, Yangyang] CAEIT, Natl Engn Lab Publ Safety Risk Percept & Control, Beijing, Peoples R China.
C3 Tianjin University; Tianjin Normal University
RP Hao, T (corresponding author), Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
EM liwenhui@tju.edu.cn; ytsu@tju.edu.cn; zhenlantju@gmail.com;
   joyht2001@163.com; liyangyang@cetc.com.cn
RI Lu, Wang/JVO-0416-2024; Zeng, Yun/JFK-6190-2023; LI,
   Wenhui/JCD-9947-2023
FU National Natural Science Foundation of China [61772359, 61872267,
   61902277]; Tianjin New Generation Artificial Intelligence Major Program
   [19ZXZNGX00110, 18ZXZNGX00150]; Open Project Program of the State Key
   Lab of CAD & CG, Zhejiang University [A2005, A2012]
FX This work was supported in part by the National Natural Science
   Foundation of China (61772359, 61872267, 61902277), the grant of Tianjin
   New Generation Artificial Intelligence Major Program (19ZXZNGX00110,
   18ZXZNGX00150), the Open Project Program of the State Key Lab of CAD &
   CG, Zhejiang University (Grant No. A2005, A2012).
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Giorgi D, 2010, P ACM WORKSH 3D OBJ, P9
   Guo HY, 2016, IEEE T IMAGE PROCESS, V25, P5526, DOI 10.1109/TIP.2016.2609814
   He XW, 2018, PROC CVPR IEEE, P1945, DOI 10.1109/CVPR.2018.00208
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hong CQ, 2015, INFORM SCIENCES, V320, P395, DOI 10.1016/j.ins.2015.03.032
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leibe B, 2003, PROC CVPR IEEE, P409
   Liu A, 2017, EEE T CYBERN, P1
   Liu A. A., 2017, IEEE T CYBERNETICS
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu Y, 2010, INT J COMPUT VISION, V89, P408, DOI 10.1007/s11263-009-0298-x
   Lu K, 2014, INFORM SCIENCES, V281, P703, DOI 10.1016/j.ins.2014.03.079
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2018, MULTIMED TOOLS APPL, V77, P22953, DOI 10.1007/s11042-018-5641-1
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Wang XY, 2015, NEUROCOMPUTING, V151, P620, DOI 10.1016/j.neucom.2014.03.091
   Yang LR, 1996, PATTERN RECOGN, V29, P1061, DOI 10.1016/0031-3203(95)00147-6
   Zhang DH, 2002, P SOC PHOTO-OPT INS, V4918, P425, DOI 10.1117/12.483108
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhu ZT, 2016, NEUROCOMPUTING, V204, P41, DOI 10.1016/j.neucom.2015.08.127
NR 37
TC 1
Z9 1
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16397
EP 16412
DI 10.1007/s11042-020-08967-7
EA MAY 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000559592800001
DA 2024-07-18
ER

PT J
AU Xing, BX
   Zhang, X
   Zhang, KJ
   Wu, XD
   Zhang, H
   Zheng, J
   Zhang, LK
   Sun, SQ
AF Xing, Baixi
   Zhang, Xiang
   Zhang, Kejun
   Wu, Xinda
   Zhang, Hui
   Zheng, Jun
   Zhang, Lekai
   Sun, Shouqian
TI PopMash: an automatic musical-mashup system using computation of musical
   and lyrical agreement for transitions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music; Sound and music computing; Musical-mashup; Signal processing
AB Musical-mashup is a popular form of music re-creation, aiming at combining multiple pieces of music to create new music artworks. Presently, it is also a challenge in the field of music information study. In this work, an effective framework for harmonious musical-mashup generation is provided. In the experiment, lyrics, melody, and rhythm of music were synthetically analyzed. The "harmony" of mashup transition was evaluated in view of the similarity scores of rhythm, melody and lyrics rhyme. "Mashupable" song segments were selected based on the transition harmony evaluation. Then, the musical-mashup output was carried out by adjusting the rhythm, tone and loudness of each segment. Finally, we created PopMash based on the proposed method, an automatic musical-mashup system that can make smooth and harmony transitions from multiple perspectives, which can efficiently reduce the manual work of music recreation.
C1 [Xing, Baixi; Zhang, Kejun; Wu, Xinda; Zhang, Hui; Zheng, Jun; Zhang, Lekai; Sun, Shouqian] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Xing, Baixi] Zhejiang Univ Technol, Inst Ind Design, Hangzhou, Peoples R China.
   [Zhang, Xiang] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Zhang, Kejun] Alibaba Zhejiang Univ Joint Res Inst Frontier Tec, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University of Technology; Hong Kong
   Polytechnic University
RP Zhang, KJ (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.; Zhang, KJ (corresponding author), Alibaba Zhejiang Univ Joint Res Inst Frontier Tec, Hangzhou, Peoples R China.
EM zhangkejun@zju.edu.cn
RI zhang, hui/GXH-6098-2022
OI Zhang, Xiang/0000-0002-8667-2443
FU Natural Science Foundation of Zhejiang Province of China [LY19F020047,
   LZ19F020002]; National Natural Science Foundation of China [61402141]
FX This study is partly supported by the Natural Science Foundation of
   Zhejiang Province of China (LY19F020047, LZ19F020002) and National
   Natural Science Foundation of China (61402141). And the authors would
   like to thank the Key Laboratory of Design Intelligence and Digital
   Creativity of Zhejiang Province, Alibaba-Zhejiang University Joint
   Institute of Frontier Technologies.
CR [Anonymous], 2009, LEVENSHTEIN DISTANCE
   Basu S, 2004, P ICMC MIAM US
   Brown S, 1975, DIRECTORY TUNES MUSI
   Catarina M, 2018, INT C INF VIS IEEE C
   Chang S, 2017, IEEE ACCESS, V5, P16635, DOI 10.1109/ACCESS.2017.2738558
   Davies MEP, 2014, IEEE-ACM T AUDIO SPE, V22, P1726, DOI 10.1109/TASLP.2014.2347135
   Diehl N., 1991, Signal Processing: Image Communication, V3, P23, DOI 10.1016/0923-5965(91)90028-Z
   DOWNIE S, 2000, P 23 ANN INT ACM SIG, P73
   Francu C, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P889, DOI 10.1109/ICME.2000.871502
   Fu R, 2005, INT ENERGY J, V6
   Gebhardt RB, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050123
   Goto M, 1988, INT C AC SPEECH SIGN
   Goto M, 2012, GRAND CHALLENGES MUS, P217
   Griffin G, 2010, IEEE INT C SPEECH SI
   Hofmann-Engl L, 2002, P 7 INT C MUS PERC C, P564
   HOFMANNENGL L, 2002, P 2 INT C UND CREAT
   Ishizaki H., 2009, P INT SOC MUS INF RE, P135
   Jehan Tristan, 2005, PhD dissertation
   Jennings HD, 2004, PHYSICA A, V336, P585, DOI 10.1016/j.physa.2003.12.049
   Kim YE, 2001, P INT
   Langford S., 2011, The remix manual
   Lerdahl F, 1983, GENERATIVE GOING TON
   Levy M, IEEE T AUDIO RES LAN, V16, P318
   Li Yang, 2003, COMPUTER RES DEV, V40, P1554
   Lin HY, 2009, P ISMIR KOB JAP
   Lin YT, 2015, IEEE INT S MULT IEEE
   Liu IT, 2013, P ISMIR CUR PR BRAZ
   Maddage NC, 2004, ACM INT C MULT
   Maidn D.O., 1998, COMPUTING MUSICOLOGY, P65
   McKinney M., 2004, Proceedings of the 5th International Conference on Music Information Retrieval, P146
   Miller SM, 2002, COMPUT MUSIC J, V26, P98, DOI [10.1162/comj.2002.26.2.98, DOI 10.1162/COMJ.2002.26.2.98]
   MOULINES E, 1995, SPEECH COMMUN, V16, P175, DOI 10.1016/0167-6393(94)00054-E
   Nguyen DTD, 2013, P 21 ACM INT C MULT
   Ohya H, 2013, P INT C CULT COMP IE
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Phaye SSR, 2018, IEEE INTERNATIONAL S
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Rand W, 2001, J INDIANA U
   ROSS MJ, 1974, IEEE T ACOUST SPEECH, VAS22, P353, DOI 10.1109/TASSP.1974.1162598
   Saini MK, 2012, P 20 ACM INT C MULT
   Shrestha P, 2010, P 18 INT C MULT FIR
   Tokui N, 2008, P 3 INT C DIG INT ME, P10
   Turchet L, 2018, IEEE ACCESS, V6, P61994, DOI 10.1109/ACCESS.2018.2872625
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 46
TC 3
Z9 4
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21841
EP 21871
DI 10.1007/s11042-020-08934-2
EA MAY 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000532672800001
DA 2024-07-18
ER

PT J
AU Pawlowski, P
   Dabrowski, A
   Balcerek, J
   Konieczka, A
   Piniarski, K
AF Pawlowski, Pawel
   Dabrowski, Adam
   Balcerek, Julian
   Konieczka, Adam
   Piniarski, Karol
TI Visualization techniques to support CCTV operators of smart city
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vision monitoring; Panoramas; Stereovision; Thermo-vision; High dynamic
   range (HDR); Threat recognition
ID PEDESTRIAN DETECTION; CLASSIFICATION; OPTIMIZATION; TRACKING;
   ALGORITHMS; RESOLUTION
AB In this paper visualization techniques for modern closed circuit television (CCTV) smart city services are discussed with application to prevention of threats. Unconventional approaches to the intelligent visual data processing are proposed in order to support video surveillance operators, thus to make their work less exhaustive and more effective. Although registration of a huge amount of video data requires development of intelligent and automatic signal processing information extraction techniques, improvement of visualization methods for operators is also a very important task, because of the crucial role the human factor plays and should always play in the decision making, e.g. in the operator reactions to various crisis situations, which can never be fully eliminated by artificial intelligence. Four software based mechanisms connected with a standard or with a slightly extended hardware are proposed as options for the CCTV operators. They utilize rather known ideas but are implemented with new extensions to original algorithms, as well as with additional, innovative modifications and solutions (not presented in the literature). With them they become reliable and efficient tools for the CCTV systems. First, generation of cylindrical panoramas is suggested in order to make long-time video content analysis of a defined area easier and faster. Using panoramas it is possible to reduce the time that is required to watch the video by a factor of hundreds or even thousands and perform an efficient compression of the video stream for the long-time storage. Second, the controlled stereovision option is discussed for quicker and more precise extraction of relevant information from the observed scene. Third, the thermo-vision is analyzed for faultless detection of pedestrians at night. Finally, a novel high dynamic range (HDR) technique is proposed, dedicated to the CCTV systems, in contrast to other typical entertainment oriented HDR approaches, for clear visualization of important and meaningful image details, otherwise invisible. We validated usefulness of the proposed techniques with many experiments presented in this paper.
C1 [Pawlowski, Pawel; Dabrowski, Adam; Balcerek, Julian; Konieczka, Adam; Piniarski, Karol] Poznan Univ Tech, Fac Control Robot & Elect Engn, Inst Automat & Robot, Div Signal Proc & Elect Syst, 3A Piotrowo St, PL-60965 Poznan, Poland.
C3 Poznan University of Technology
RP Pawlowski, P (corresponding author), Poznan Univ Tech, Fac Control Robot & Elect Engn, Inst Automat & Robot, Div Signal Proc & Elect Syst, 3A Piotrowo St, PL-60965 Poznan, Poland.
EM pawel.pawlowski@put.poznan.pl; adam.dabmwski@put.poznan.pl;
   julian.balcerek@put.poznan.pl; adam.konieczka@put.poznan.pl;
   karol.piniarski@put.poznan.pl
RI Piniarski, Karol/AAY-1568-2021; Pawłowski, Paweł/L-4951-2014; Piniarski,
   Karol/O-8357-2015; Balcerek, Julian/K-8777-2014; Konieczka,
   Adam/J-8389-2014
OI Piniarski, Karol/0000-0001-9329-720X; Pawłowski,
   Paweł/0000-0001-5373-5148; Balcerek, Julian/0000-0003-1317-9866;
   Konieczka, Adam/0000-0002-0362-3006
CR [Anonymous], 2011, CIT TOM CHALL VIS WA
   [Anonymous], 2019, MONITORING SYSTEM CI
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Balcerek Julian, 2017, Elektronika, V58, P31, DOI 10.15199/13.2017.10.8
   Balcerek J., 2014, Elektronika, V55, P9
   Balcerek J, 2008, P NEW TRENDS AUD VID, P219
   Balcerek J, 2013, SIG P ALGO ARCH ARR, P226
   Balcerek J, 2011, SPA 2011: SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS CONFERENCE PROCEEDINGS, P138
   Balcerek J, 2012, PRZ ELEKTROTECHNICZN, V88, P17
   Banitalebi-Dehkordi A, 2017, MULTIMED TOOLS APPL, V76, P23859, DOI 10.1007/s11042-016-4155-y
   Bao SYZ, 2010, PROC CVPR IEEE, P65, DOI 10.1109/CVPR.2010.5540229
   Benhimane S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P943
   Bertozzi M, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P24
   Bertozzi M, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P231, DOI 10.1109/IVS.2006.1689633
   Bertozzi M., 2007, 2007 IEEE Intelligent Transportation Systems Conference, P143, DOI 10.1109/ITSC.2007.4357692
   Bota S, 2009, INT C INTELL COMP CO, P153, DOI 10.1109/ICCP.2009.5284771
   Bouzidi I, 2018, MULTIMED TOOLS APPL, V77, P5215, DOI 10.1007/s11042-017-4425-3
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Calagari K, 2018, IEEE T MULTIMEDIA, V20, P605, DOI 10.1109/TMM.2017.2748458
   Cetnarowicz D, 2012, FP7218086 INDECT CON
   Chang YL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1958
   Chen ZZ, 2012, IEEE INT C INTELL TR, P951, DOI 10.1109/ITSC.2012.6338852
   Choi K, 2015, SENSORS-BASEL, V15, P23341, DOI 10.3390/s150923341
   Dabrowski A, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P329, DOI 10.1109/PCS.2012.6213359
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dbrowski A, 2010, FP7218086
   Dbrowski A, 2011, 20 EUR C CIRC THEOR, P878
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Eilertsen G, 2017, COMPUT GRAPH FORUM, V36, P565, DOI 10.1111/cgf.13148
   Elzein H, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P500, DOI 10.1109/IVS.2003.1212962
   Eur. Commission, CRIM CRIM JUST STAT
   European Commission, 2019, EUR ROAD SAF POL FRA
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Ge JF, 2009, IEEE T INTELL TRANSP, V10, P283, DOI 10.1109/TITS.2009.2018961
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Guo YH, 2018, MULTIMED TOOLS APPL, V77, P22299, DOI 10.1007/s11042-018-5948-y
   Herald Globe Int. News & Information Service, 2014, HERALD GLOBE INT NEW
   Huang F., 2008, PANORAMIC IMAGING SE
   Huynh-Thu Q, 2011, IEEE T BROADCAST, V57, P421, DOI 10.1109/TBC.2011.2128250
   Ideses Ianir, 2007, 3DTV Conference, 2007, P1
   Ideses I, 2007, J REAL-TIME IMAGE PR, V2, P3, DOI 10.1007/s11554-007-0038-9
   Irani M, 1999, DIRECT METHODS, P267
   Jiang YJ, 2019, MULTIMED TOOLS APPL, V78, P3781, DOI 10.1007/s11042-018-6057-7
   Jumisko-Pyykkö S, 2011, MULTIMED TOOLS APPL, V55, P185, DOI 10.1007/s11042-010-0573-4
   Kaljahi MA, 2019, MULTIMED TOOLS APPL, V78, P5791, DOI 10.1007/s11042-018-6151-x
   Kanmani M, 2017, MULTIMED TOOLS APPL, V76, P20989, DOI 10.1007/s11042-016-4030-x
   Karol Piniarski, 2015, CMST, V21, P141
   Kim D., 2007, 3DTV C, P1
   Koch A, 2015, MULTIMED TOOLS APPL, V74, P8703, DOI 10.1007/s11042-014-2354-y
   Kuang JT, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1265957.1265958
   Kun-Ming Yang, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P477, DOI 10.1109/CISP.2010.5647065
   Lin WS, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS, P410
   Liu Q, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P391, DOI 10.1109/ICACI.2012.6463193
   Liu Q, 2013, INFRARED PHYS TECHN, V60, P288, DOI 10.1016/j.infrared.2013.06.003
   Lopez-Fuentes L, 2018, MULTIMED TOOLS APPL, V77, P17069, DOI 10.1007/s11042-017-5276-7
   Marciniak T, 2015, MULTIMED TOOLS APPL, V74, P4329, DOI 10.1007/s11042-013-1568-8
   Marciniak T, 2012, COMM COM INF SC, V287, P220
   Mishra S, 2007, ECON BULL, V3
   Myszkowski K., 2008, HIGH DYNAMIC RANGE V
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   Pawlowski P, 2015, SPA 2015 SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS, P185, DOI 10.1109/SPA.2015.7365157
   Piniarski K, 2014, SIG P ALGO ARCH ARR, P104
   Rankin S, 2012, INT CARN CONF SECU, P325, DOI 10.1109/CCST.2012.6393580
   Redert A, 2006, VISUALIZATION TRANSM, V2006, P429
   Reinhard E, 2006, SIGGRAPH 2006
   Ribeiro FML, 2018, IEEE T MULTIMEDIA, V20, P1, DOI 10.1109/TMM.2017.2714425
   Shashua A, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P1
   Shimizu H, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P596
   Stepanov D, 2016, 18 C OP INN ASS SEM, DOI [10.1109/FRUCT-ISPIT.2016.7561546, DOI 10.1109/FRUCT-ISPIT.2016.7561546]
   Torfs M, 2016, FLANDERS NEWS
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   Valizadeh S, 2018, MULTIMED TOOLS APPL, V77, P22985, DOI 10.1007/s11042-017-5486-z
   Velten J, 2012, FP7218086 INDECT
   Wagner I, 2018, STAT BUSINESS DATA P
   Wan YL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P945, DOI 10.1109/ICME.2008.4607592
   Wang BH, 2013, IEEE INT VEH SYM, P1209, DOI 10.1109/IVS.2013.6629631
   Wang M, 2018, IEEE T MULTIMEDIA, V20, P620, DOI 10.1109/TMM.2017.2748459
   Zhang P., 2019, BUSINESS INSIDER
   Zou Xiao-chun, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P641, DOI 10.1109/ICCET.2010.5485664
NR 82
TC 5
Z9 5
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21095
EP 21127
DI 10.1007/s11042-020-08895-6
EA MAY 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529768400003
OA hybrid
DA 2024-07-18
ER

PT J
AU Talal, TM
   Attiya, G
   Metwalli, MR
   Abd El-Samie, FE
   Dessouky, MI
AF Talal, Tamer M.
   Attiya, Gamal
   Metwalli, Mohamed R.
   Abd El-Samie, Fathi E.
   Dessouky, Moawad, I
TI Satellite image fusion based on modified central force optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; DWT; HPF; IHS; Landsat; MCFO; PAN-sharpening; Quickbird;
   Spot
ID FACE
AB Nowadays, optimization has become a brand methodology for different applications. One of the most promising fields for application of optimization is the image processing field, especially image fusion. A new effective deterministic optimization technique is the modified central force optimization (MCFO) that overcomes the low convergence rate drawback of the central force optimization (CFO). In this paper, the MCFO is applied with standard image fusion methods as a novel brand to improve the fusion efficiency either qualitatively or quantitatively. Intensity-hue-saturation (IHS), high-pass filtering (HPF), and discrete wavelet transform (DWT) are powerful standard techniques for satellite image fusion that are implemented with MCFO optimization in this paper. They are performed on satellite panchromatic (PAN) and multispectral (MS) images. The target of using the MCFO is to reduce some spectral and spatial distortions that may occur without optimization. Different qualitative indices have been used to validate the proposed approach comprising optimization for satellite image fusion.
C1 [Talal, Tamer M.; Metwalli, Mohamed R.] Natl Author Remote Sensing & Space Sci NARSS, Cairo, Egypt.
   [Attiya, Gamal] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.; Dessouky, Moawad, I] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Infoimat Sci, Dept Infomat Technol, Riyadh, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); National Authority for Remote Sensing &
   Space Sciences (NARSS); Egyptian Knowledge Bank (EKB); Menofia
   University; Egyptian Knowledge Bank (EKB); Menofia University; Princess
   Nourah bint Abdulrahman University
RP Talal, TM (corresponding author), Natl Author Remote Sensing & Space Sci NARSS, Cairo, Egypt.
EM tamer.talal@narss.sci.eg; gamal_mahrouce@yahoo.com;
   moh_roshdym@yahoo.com; fathi_sayed@yahoo.com; dr_moawad@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; Attiya, Gamal/AAE-8414-2021
OI Sayed, Fathi/0000-0001-8749-9518; ATTIYA, Gamal/0000-0002-4771-9165
FU NARSS organization
FX The authors thank the NARSS organization as it supported and provided
   them with different SPOT-4 and Landsat-8 satellite images in addition to
   the theoretical background.
CR Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Amarsaikhan D, 2011, IMAGE FUSION ITS APP, P127
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2014, INNOVATIVE COMPUTATI
   Bick M, 2015, THESIS
   El-Hoseny HM, 2018, INFRARED PHYS TECHN, V94, P223, DOI 10.1016/j.infrared.2018.09.003
   Formato RA, 2007, PROG ELECTROMAGN RES, V77, P425, DOI 10.2528/PIER07082403
   Formato RA, 2010, PARAMETER FREE DETER, P309
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   Han S. S., 2008, Int. Arch. Photogramm., Remote Sens. Spatial Inf. Sci., V7, P1159
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Ji Q, 2016, INT C COMM EL SYST I, P1
   Jin NB, 2007, IEEE T ANTENN PROPAG, V55, P556, DOI 10.1109/TAP.2007.891552
   Lan XY, 2018, AAAI CONF ARTIF INTE, P7008
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   LEE DTL, 1994, HEWLETT-PACKARD J, V45, P44
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liu H, 2009, URBAN REMOTE SENSING
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mahdinejad N, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2659652
   Mahmoud KR, 2016, IET MICROW ANTENNA P, V10, P1011, DOI 10.1049/iet-map.2015.0801
   Metwalli MR, 2012, THESIS
   Mitchell HB, 2010, IMAGE FUSION: THEORIES, TECHNIQUES AND APPLICATIONS, P1, DOI 10.1007/978-3-642-11216-4
   Murino V, 1996, IEEE T SIGNAL PROCES, V44, P119, DOI 10.1109/78.482017
   Naidu V PS., 2012, Journal of Communication, Navigation and Signal Processing, V1, P35
   Pandit R., 2015, IJCA, V120, P22, DOI DOI 10.5120/21263-3846
   Rajo-Iglesias E, 2007, IEEE ANTENN PROPAG M, V49, P70, DOI 10.1109/MAP.2007.376644
   Raut G.N., 2013, IJITEE, V2
   Rojas R., 1996, NEURAL NETWORKS SPRI, P429
   Siddiqui Y, 2003, P ASPRS ANN C
   Wald L, 1999, IEEE T GEOSCI REMOTE, V37, P1190, DOI 10.1109/36.763269
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Zejing Guang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1916, DOI 10.1109/CISP.2011.6100599
NR 38
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21129
EP 21154
DI 10.1007/s11042-019-08471-7
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529768400002
DA 2024-07-18
ER

PT J
AU Xing, ZK
   Jia, HM
AF Xing, Zhikai
   Jia, Heming
TI An improved thermal exchange optimization based GLCM for multi-level
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image segmentation; GLCM; Thermal exchange optimization; Levy
   flight; Opposition-based learning
ID LEVY FLIGHT; DIFFERENTIAL EVOLUTION; HEURISTIC OPTIMIZATION; TEXTURE
   ANALYSIS; CROSS-ENTROPY; ALGORITHM; SEARCH
AB The gray-level co-occurrence matrix (GLCM) can obtain the pixel matrix of the image, and selecting multiple thresholds for the matrix can obtain better segmentation results. However, as the number of threshold increases, the computational complexity of the algorithm will also increase. In order to solve this problem, this paper proposes a multi-threshold image segmentation method based on thermal exchange optimization (TEO) algorithm, and take a novel diagonal class entropy (DCE) as the fitness function. We improve TEO algorithm by using two strategic methods of Levy flight (LF) and opposition-based learning (OBL). In order to verify the segmentation ability of the proposed algorithm, color natural images, satellite images and Berkeley images are taken as experimental objects to analyze the segmentation result graph and image segmentation quality evaluation indexes. Experimental results show that the GLCM-ITEO algorithm has good segmentation capability, less CPU time.
C1 [Xing, Zhikai; Jia, Heming] Northeast Forestry Univ, Coll Mech & Elect Engn, Harbin 150040, Peoples R China.
C3 Northeast Forestry University - China
RP Jia, HM (corresponding author), Northeast Forestry Univ, Coll Mech & Elect Engn, Harbin 150040, Peoples R China.
EM jiaheming@nefu.edu.cn
CR Akram F, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174813
   [Anonymous], 2005, P INT C COMPUTATIONA
   [Anonymous], 2016, AS C COMP VIS ACCV
   [Anonymous], J IND ENG INT
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Becker AS, 2017, NMR BIOMED, V30, DOI 10.1002/nbm.3669
   Biyanto TR, 2017, PROCEDIA COMPUT SCI, V124, P151, DOI 10.1016/j.procs.2017.12.141
   Bouchekara HREH, 2016, APPL SOFT COMPUT, V42, P119, DOI 10.1016/j.asoc.2016.01.041
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Cheng X, 2018, J CLEAN PROD, V176, P535, DOI 10.1016/j.jclepro.2017.12.068
   Dong SY, 2017, NANO RES, V10, P4448, DOI 10.1007/s12274-017-1753-6
   Dong WY, 2017, SOFT COMPUT, V21, P5081, DOI 10.1007/s00500-016-2102-5
   Ewees AA, 2018, EXPERT SYST APPL, V112, P156, DOI 10.1016/j.eswa.2018.06.023
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Farag TH, 2017, ARAB J SCI ENG, V42, P3573, DOI 10.1007/s13369-017-2577-0
   Fister I, 2014, SCI WORLD J, DOI 10.1155/2014/709738
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   He Y, 2017, COMPUTER VISION PATT
   Heidari AA, 2017, APPL SOFT COMPUT, V60, P115, DOI 10.1016/j.asoc.2017.06.044
   Hong KS, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00035
   Jiang YZ, 2016, INFORM SCIENCES, V369, P171, DOI 10.1016/j.ins.2016.06.020
   Kang Y, 2017, KOREAN J RADIOL, V18, P691, DOI 10.3348/kjr.2017.18.4.691
   Kaveh A, 2017, ADV ENG SOFTW, V110, P69, DOI 10.1016/j.advengsoft.2017.03.014
   Kennedy J, 2002, ICNN95 INT C NEUR NE
   Kwong S.T.W., 2018, IEEE T IND INF, V99, P1
   Leszczynski B, 2016, J NONDESTRUCT EVAL, V35, DOI 10.1007/s10921-016-0352-x
   Li F, 2018, IEEE T GEOSCI REMOTE, V56, P3, DOI 10.1109/TGRS.2017.2713123
   Li HP, 2017, INT J REMOTE SENS, V38, P6970, DOI 10.1080/01431161.2017.1368102
   Li YY, 2017, APPL SOFT COMPUT, V56, P345, DOI 10.1016/j.asoc.2017.03.018
   Lv TL, 2019, MULTIMED TOOLS APPL, V78, P17051, DOI 10.1007/s11042-018-7087-x
   Mala C, 2016, SOFT COMPUT, V20, P1793, DOI 10.1007/s00500-015-1677-6
   Malegori C, 2016, J FOOD ENG, V185, P48, DOI 10.1016/j.jfoodeng.2016.04.001
   Marinaki M, 2016, EXPERT SYST APPL, V46, P145, DOI 10.1016/j.eswa.2015.10.012
   Min L, 2012, APPL MECH MATER, V220-223, P1398, DOI 10.4028/www.scientific.net/AMM.220-223.1398
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mousavirad SJ, 2017, APPL INTELL, V47, P850, DOI 10.1007/s10489-017-0903-6
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Oghaz MM, 2017, NEURAL COMPUT APPL, V6, P1
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Qayyum R, 2016, INT C AUT COMP
   Raj S, 2018, INT T ELECTR ENERGY, V28, DOI 10.1002/etep.2551
   Rosner B, 2003, BIOMETRICS, V59, P1089, DOI 10.1111/j.0006-341X.2003.00125.x
   Sarkar S, 2015, PATTERN RECOGN LETT, V54, P27, DOI 10.1016/j.patrec.2014.11.009
   Sarkar S, 2013, IEEE T IMAGE PROCESS, V22, P4788, DOI 10.1109/TIP.2013.2277832
   Singh VP, 2016, INT J ARTIF INTELL T, V25, DOI 10.1142/S0218213016500305
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Pham TX, 2018, APPL SOFT COMPUT, V65, P230, DOI 10.1016/j.asoc.2018.01.003
   Vallaeys V, 2017, J R SOC INTERFACE, V14, DOI 10.1098/rsif.2016.0889
   Xue J, 2017, INT C BIOINSP COMP T, P39
   Xutang Z, 2016, MATH PROBL ENG, V2016, P1
   Yan B, 2017, COMPUT PHYS COMMUN, V219, pS001046551730139X
   Ye ZW, 2015, APPL SOFT COMPUT, V31, P381, DOI 10.1016/j.asoc.2015.02.012
   Zhang HW, 2018, APPL SOFT COMPUT, V71, P242, DOI 10.1016/j.asoc.2018.06.028
   Zhao MH, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2815608
   Zheng YJ, 2015, COMPUT OPER RES, V55, P1, DOI 10.1016/j.cor.2014.10.008
   Zhou JJ, 2017, APPL INTELL, V47, P721, DOI 10.1007/s10489-017-0927-y
NR 57
TC 10
Z9 10
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12007
EP 12040
DI 10.1007/s11042-019-08566-1
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400034
DA 2024-07-18
ER

PT J
AU Elashry, IF
   El-Shafai, W
   Hasan, ES
   El-Rabaie, S
   Abbas, AM
   Abd El-Samie, FE
   El-sayed, HS
   Faragallah, OS
AF Elashry, Ibrahim F.
   El-Shafai, Walid
   Hasan, Emad S.
   El-Rabaie, S.
   Abbas, Alaa M.
   Abd El-Samie, Fathi E.
   El-sayed, Hala S.
   Faragallah, Osama S.
TI Efficient chaotic-based image cryptosystem with different modes of
   operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Chaotic map; RC6; Security analysis; Noise immunity; Modes
   of operation
ID ALGORITHM; CRYPTANALYSIS; PERMUTATION; DIFFUSION; SYSTEM
AB This paper proposes a design of 2-D chaotic Baker map for image encryption which utilizes three modes of operations: 1) the cipher block chaining (CBC) mode, 2) the cipher feedback (CFB) mode, and 3) the output feedback (OFB) mode. The proposed image cryptosystem is characterized by a short encryption time of scalevariant images and a high level of confusion and diffusion due to its shuffling and substitution processes. This is useful in applications such as online streaming of paid videos, in which both the speed of encryption\decryption and a good encryption quality is required. A comparison between the proposed image cryptosystem, the traditional 2-D chaotic Baker map permutation cryptosystem, and the RC6 substitution cryptosystem is presented in the paper. A comparison is held with relevant techniques and the results reveal that the proposed image cryptosystem achieves a high degree of security. It is also more immune to noise than the RC6 cryptosystem and takes less processing time for images with large dimensions than both the chaotic cryptosystem and the RC6 cryptosystem. The superiority of the proposed cryptosystem has been proved for image encryption against the recent techniques from the cryptographic viewpoint.
C1 [Elashry, Ibrahim F.] Kafrelsheikh Univ, Fac Engn, Dept Elect Commun, Kafrelsheikh, Egypt.
   [El-Shafai, Walid; Hasan, Emad S.; El-Rabaie, S.; Abbas, Alaa M.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
   [El-sayed, Hala S.] Menoufia Univ, Fac Engn, Dept Elect Engn, Shibin Al Kawm 32511, Egypt.
   [Faragallah, Osama S.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Al Hawiya 21974, Saudi Arabia.
   [Abbas, Alaa M.] Taif Univ, Coll Engn, Elect Engn Dept, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; Egyptian
   Knowledge Bank (EKB); Menofia University; Egyptian Knowledge Bank (EKB);
   Menofia University; Egyptian Knowledge Bank (EKB); Menofia University;
   Taif University; Taif University
RP El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
EM ibrahim_elashry@eng.kfs.edu.eg; eng.waled.elshafai@gmail.com;
   eng_emadash@yahoo.com; srabiel@yahoo.com; m2alaa@hotmail.com;
   fathi_sayed@yahoo.com; hall_hhh@yahoo.com; osam_sal@yahoo.com
RI El-Sayed, Hala S./GXG-7641-2022; Abbas, Alaa M./GXN-0651-2022; Sayed,
   Fathi/HRA-4752-2023; Faragallah, Osama S./AHB-8031-2022; Elashry,
   Ibrahim/Y-4816-2019; El-Shafai, Walid/AAG-4796-2021
OI El-Sayed, Hala S./0000-0002-2776-783X; Abbas, Alaa
   M./0000-0003-0929-161X; Sayed, Fathi/0000-0001-8749-9518; Faragallah,
   Osama S./0000-0003-1982-335X; Elashry, Ibrahim/0000-0001-8947-2239;
   El-Shafai, Walid/0000-0001-7509-2120; EL-Rabaie,
   El-Sayed/0000-0001-6854-5881
CR Al-Ghamdi M, 2018, MULTIMED TOOLS APPL, V78, P1
   Al-Juaid N.A., 2018, J INF SECUR CYBERCRI, DOI [10.26735/16587790.2018.006, DOI 10.26735/16587790.2018.006]
   Alanizy N., 2018, J RES ENG APPL SCI, V3
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Almazrooie M, 2018, J KING SAUD UNI COMP
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Amin M, 2010, COMMUN NONLINEAR SCI, V15, P3484, DOI 10.1016/j.cnsns.2009.12.025
   Anand MV, 2016, LECT NOTES COMPUT SC, V9606, P44, DOI 10.1007/978-3-319-29360-8_4
   [Anonymous], 2016, CIRCUITS SYSTEMS
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2015, OPT COMMUN, V341, P263, DOI 10.1016/j.optcom.2014.12.045
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Elhosany HM, 2012, RAD SCI C NRSC 2012, P223
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Kadir R., 2010, PROC INT C COMPUT CO, P1
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Özkaynak F, 2016, OPTIK, V127, P5190, DOI 10.1016/j.ijleo.2016.03.018
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 38
TC 41
Z9 42
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20665
EP 20687
DI 10.1007/s11042-019-08322-5
EA APR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528160800001
DA 2024-07-18
ER

PT J
AU Zhou, YF
   Li, J
   Du, B
   Chang, J
   Xiao, YF
AF Zhou, Yifei
   Li, Jing
   Du, Bo
   Chang, Jun
   Xiao, Yafu
TI A target response adaptive correlation filter tracker with spatial
   attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target tracking; Boundary effect; Spatial attention; Self-adaption
   response
ID OBJECT TRACKING
AB In recent years, many efficient and accurate algorithms have been proposed in the field of target tracking. The existing correlation filter(CF) based tracking expands the sample through cyclic shift and uses the position of the maximum response map as the most likely position of the target. Since the cyclic shift sample is not the real sample, the target response may also occur in the non-target region, which not only causes the boundary effect problem but also results in the positioning error. To train the filter with the wrong position will lead to the tracking drift. This paper proposes a target response adaptive correlation filter tracker with spatial attention to solve the above problems. Firstly, more useful feature information can be learned by making full use of the context information of the target area, and spatial attention mechanisms can be introduced to suppress the background information and reduce the unnecessary boundary effect. Secondly, the dynamic change of the target response is captured, and the most reliable response map is selected when the interference response map appears, to reduce the probability of dispositioning and train the more recognizable filter. Extensive experimental results on popular benchmarks(OTB2013 OTB100 and VOT2016) demonstrate that the proposed tracker performs favorably against other state-of-the-art tracking methods, with real-time performance.
C1 [Zhou, Yifei; Li, Jing; Du, Bo; Chang, Jun; Xiao, Yafu] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Li, J (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
EM yifeizhou@whu.edu.cn; leejingcn@whu.edu.cn; remoteking@whu.edu.cn;
   chang.jun@whu.edu.cn; xiaoyafu@whu.edu.cn
CR [Anonymous], 2016, TARGET RESPONSE ADAP
   [Anonymous], 2001, P 2000 C ADV NEUR IN
   Vo BN, 2019, IEEE T SIGNAL PROCES, V67, P5952, DOI 10.1109/TSP.2019.2946023
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Behrad A, 2003, IEICE T INF SYST, VE86D, P2764
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cannons K, 2008, 200807 CSE YORK U
   Choi J., 2017, P IEEE C COMP VIS PA, V2, P7
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2015, LEARNING SPATIALLY R
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Gao L, 2016, COLLABORATIVE SOCIAL
   Gao L, 2017, 31 C ART INT AAAI 17
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jamasbi B, 2007, 2007 IEEE WORKSH MOT, P22
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kiani Galoogahi H, 2015, CORRELATION FILTERS
   Krishna MV, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON POWER ELECTRONICS, DRIVES AND ENERGY SYSTEMS (PEDES)
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li DCF, 2019, IEEE INT CONF ROBOT, P3976, DOI [10.1109/icra.2019.8793571, 10.1109/ICRA.2019.8793571]
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2014, SCALE ADAPTIVE KERNE, P466
   Liu WX, 2019, IEEE T IMAGE PROCESS, V28, P3766, DOI 10.1109/TIP.2019.2902784
   Liu YX, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P398, DOI 10.1109/ICInfA.2017.8078941
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mueller Matthias, 2017, CONTEXT AWARE CORREL
   Possegger H, 2015, DEFENSE COLOR BASED
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Ullah M, 2019, ELECT IMAGING, V466-1
   Ullah M, 2018, IEEE IMAGE PROC, P3738, DOI 10.1109/ICIP.2018.8451472
   Ullah M, 2017, IEEE IMAGE PROC, P2612, DOI 10.1109/ICIP.2017.8296755
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang T, 2019, DEEP LEARNING LIGHT
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wu JH, 2018, COMPLEXITY, DOI 10.1155/2018/4824350
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang B, 2016, TSMC
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
NR 53
TC 3
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20521
EP 20543
DI 10.1007/s11042-020-08839-0
EA APR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000527911700003
DA 2024-07-18
ER

PT J
AU Liu, Y
   Kim, J
AF Liu, Ying
   Kim, Joohee
TI Variable block-size compressed sensing for depth map coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Depth map; Quad-tree decomposition; Rate-distortion
   optimization; Three-dimensional video; Total-variation
ID SIGNAL RECOVERY
AB Compressed sensing (CS) is the theory and practice of sub-Nyquist sampling of sparse signals of interest. Perfect reconstruction is possible with much fewer than the Nyquist required number of data samples. In this work, we consider a variable block-size CS architecture for fast compression of depth maps for three-dimensional video (3DV) applications. While existing CS-based depth map coding methods encode depth maps with equal block size, the proposed algorithm partitions a depth map into smooth and edge blocks of variable sizes via rate-distortion optimized quad-tree decomposition. CS is then performed on edge blocks, and eight-bit encoding is performed on smooth blocks. At the decoder, high quality depth map reconstruction is achieved by minimizing the spatial total-variation. Experimental results show that at a small extra expense of encoder complexity, the proposed variable block-size compressed sensing has enhanced significantly the rate-distortion performance over existing low-complexity CS-based depth map coding algorithms.
C1 [Liu, Ying] Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
   [Kim, Joohee] IIT, Multimedia Commun Lab, Chicago, IL 60616 USA.
C3 Santa Clara University; Illinois Institute of Technology
RP Liu, Y (corresponding author), Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
EM yliu15@scu.edu; joohee@ece.iit.edu
CR [Anonymous], 2010, VIEW SYNTH REF SOFTW
   Candes E.J., 2005, l1-MAGIC: Recovery of sparse signals via convex programming
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duan J., 2011, IEEE INT C MULT TECH, P3401
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Gao K, 2011, IEEE T SIGNAL PROCES, V59, P4759, DOI 10.1109/TSP.2011.2160860
   Jiang H, 2012, BELL LABS TECH J, V16, P149, DOI 10.1002/bltj.20539
   Lee S, 2012, IEEE IMAGE PROC, P929, DOI 10.1109/ICIP.2012.6467013
   Li C., 2009, EFFICIENT ALGORITHM
   Li CB, 2011, 2011 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P2077, DOI 10.1109/WCNC.2011.5779474
   Liu Y, 2013, SPIE J ELECT IMAGING, V22
   Liu Y, 2013, P SPIE, V8717
   Maitre M, 2010, J VIS COMMUN IMAGE R, V21, P513, DOI 10.1016/j.jvcir.2010.03.005
   Meng FZ, 2014, PROCEEDINGS OF 2014 IEEE WORKSHOP ON ADVANCED RESEARCH AND TECHNOLOGY IN INDUSTRY APPLICATIONS (WARTIA), P870, DOI 10.1109/WARTIA.2014.6976411
   Morvan Y, 2006, PROC SPIE, V6055, DOI 10.1117/12.642666
   Sarkis M, 2009, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2009.5414286
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Sun QY, 2010, INT CONF COMP SCI, P566, DOI 10.1109/ICCSIT.2010.5563616
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
NR 23
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8825
EP 8839
DI 10.1007/s11042-019-7545-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600024
DA 2024-07-18
ER

PT J
AU Xu, CE
   Cui, Y
   Zhang, YH
   Gao, P
   Xu, JY
AF Xu, Caie
   Cui, Yang
   Zhang, Yunhui
   Gao, Peng
   Xu, Jiayi
TI Image enhancement algorithm based on generative adversarial network in
   combination of improved game adversarial loss mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SR reconstruction; Adversarial network; Deep learning; Game adversarial;
   Loss function; Identity mapping
ID SUPERRESOLUTION RECONSTRUCTION
AB The feed-forward architectures of recently proposed generative adversarial network can learn the non-linear mapping from low-resolution output to high-resolution output. However, this approach does not fully address the mutual dependencies of different resolution images. By analyzing the zero-sum game, the paper proposes an image enhancement algorithm by using conditional generative adversarial networks based on improved non-saturating game. Firstly, the enhancement image obtained by the GAN model is adopted as a condition against the network object image, making the original image learning the network structure of the object image with dim-small. Our proposed generative adversarial networks can obtain a clearer image through improved non-saturating game, and it can still get a large gradient and sufficient learning, which makes up for the deficiencies in the mini-maximum game. In addition, the loss function of the network adds the loss of discriminator to guide discriminator to generate high quality images. We compared the proposed method (SRG) with other methods including SC, SRCNN, VESPCN and ESPCN, and the proposed method resulted in obvious improvements in the peak signal-to-noise ratio (PSNR) by 2.348 dB and in structural similarity index measurement (SSIM) by 1.89% to enhance the visual effects of nature images.
C1 [Xu, Caie] Univ Yamanashi, Fac Engn, Kofu, Yamanashi 4000016, Japan.
   [Cui, Yang; Zhang, Yunhui; Gao, Peng; Xu, Jiayi] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310000, Zhejiang, Peoples R China.
C3 University of Yamanashi; Hangzhou Dianzi University
RP Xu, CE (corresponding author), Univ Yamanashi, Fac Engn, Kofu, Yamanashi 4000016, Japan.; Xu, JY (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310000, Zhejiang, Peoples R China.
EM G17DHL01@yamanashi.ac.jp; xujiayi@hdu.edu.cn
CR [Anonymous], 2016, REAL TIME SINGLE IMA, V12, P722
   [Anonymous], 2018, IEEE GEOSCI REMOTE S
   Caballero J, 2017, 2017 IEEE C COMP VIS, P172
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Culley S, 2018, NAT METHODS, V15, P263, DOI [10.1038/NMETH.4605, 10.1038/nmeth.4605]
   Darren P, 2018, REMOTE SENS, V10, P394, DOI [10.3390/rs10030394, DOI 10.3390/RS10030394]
   Elad M, 2009, COMPUT J, V52, P15, DOI 10.1093/comjnl/bxm008
   Fan C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030623
   Fan C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020362
   Graf BL, 2017, FOOD CHEM, V131, P387
   Huang B, 2018, PATTERN RECOGN LETT, V111, P72, DOI 10.1016/j.patrec.2018.04.028
   Huang DT, 2017, INFRARED PHYS TECHN, V83, P103, DOI 10.1016/j.infrared.2017.04.006
   Jinsheng X, 2017, ACTA OPT SINICA, V32, P872
   Ledig C., 2017, P IEEE C COMP VIS PA, P4681
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lei JJ, 2017, IEEE T IMAGE PROCESS, V26, P1732, DOI 10.1109/TIP.2017.2656463
   Li D, 2017, CCF CHIN C COMP VIS
   Lucas A, 2018, IEEE IMAGE PROC, P51, DOI 10.1109/ICIP.2018.8451714
   Mahapatra D., 2017, RETINAL VASCULATURE
   Mahapatra D, 2017, INT C MED IM COMP CO
   Okanovic M, 2018, MAGN RESON MED, V80, P1812, DOI 10.1002/mrm.27167
   Sanchez I., 2018, Med Imaging Deep Learn
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Ying CS, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013026
   Yisheng L, 2018, IEEE INTEL TRANSP SY, P1
   Yuan Y, 2018, COMPUTER VISION PATT, P701
   Zhang D, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023008
   [张东晓 Zhang Dongxiao], 2014, [自动化学报, Acta Automatica Sinica], V40, P2851
   Zhang DY, 2017, LECT NOTES COMPUT SC, V10636, P217, DOI 10.1007/978-3-319-70090-8_23
   Zhang M, 2017, J APPL REMOTE SENS, P11
   Zhao L, 2017, PATTERN RECOGN, P356
NR 31
TC 6
Z9 6
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9435
EP 9450
DI 10.1007/s11042-019-07776-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600061
DA 2024-07-18
ER

PT J
AU Xiang, SC
   Fu, YZ
   Xie, MY
   Yu, ZF
   Liu, T
AF Xiang, Suncheng
   Fu, Yuzhuo
   Xie, Mingye
   Yu, Zefang
   Liu, Ting
TI Unsupervised person re-identification by hierarchical cluster and domain
   transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE re-ID; Unsupervised domain; Hierarchical clustering; TriHard loss
AB Person re-identification (re-ID) has recently been tremendously boosted due to the advancement of deep convolutional neural networks. Unfortunately, the majority of deep re-ID methods focus on supervised, single-domain re-ID task, while less attention is paid on unsupervised domain adaptation. Therefore, these methods always fail to generalize well to real-world scenarios, which have attracted much attention from academia. To address this challenge, we propose a joint unsupervised domain adaptive re-ID method, named HCTL, which is aided by Hierarchical Clustering and Transfer Learning. Specifically, our method performs camera invariance learning using iStarGAN by transferring style of reliable images, which is mined by hierarchical clustering, to the style of other cameras in target domain. During training stage, HCTL integrates TriHard loss on top of ResNet-50 to reduce intra-class variance among dataset and enforce connectedness simultaneously between source domain and target domain. Comprehensive experiments based on Market-1501, DukeMTMC-reID and CUHK03 are conducted, results indicate that our method robustly achieves state-of-the-art performances with only a few reliable samples in target domain and outperform any existing approaches by a large margin.
C1 [Xiang, Suncheng; Fu, Yuzhuo; Xie, Mingye; Yu, Zefang; Liu, Ting] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Xiang, SC (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM xiangsuncheng17@sjtu.edu.cn
RI Liu, Ting/AAZ-7386-2021
OI Liu, Ting/0000-0003-3489-4578; Xie, Mingye/0000-0001-9826-9806; Xiang,
   Suncheng/0000-0002-9141-6460
FU National Natural Science Foundation of China [61472244]; National
   Defense Pre-Research Foundation of China [513110501]
FX This work was supported by the National Natural Science Foundation of
   China under Project(Grant No.61472244), the National Defense
   Pre-Research Foundation of China(Grant No.513110501) The authors would
   like to thank the anonymous reviewers for their valuable suggestions and
   constructive criticism.
CR Chang XB, 2019, AAAI CONF ARTIF INTE, P3288
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li D, 2017, INT SYM COMPUT INTEL, P338, DOI 10.1109/ISCID.2017.51
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Shan, 2018, 2018 IEEE 36 VLSI TE
   Liu X, 2012, PATTERN RECOGN, V45, P4204, DOI 10.1016/j.patcog.2012.05.019
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang Q, 2020, IEEE T PATTERN ANAL, V42, P46, DOI 10.1109/TPAMI.2018.2875002
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Yuan Y, 2018, IEEE ACCESS, V6, P56059, DOI 10.1109/ACCESS.2018.2872804
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 34
TC 8
Z9 8
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19769
EP 19786
DI 10.1007/s11042-020-08723-x
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000522592200002
DA 2024-07-18
ER

PT J
AU Lin, JR
   Xiao, LY
   Wu, T
   Bian, WJ
AF Lin, Jirui
   Xiao, Laiyuan
   Wu, Tao
   Bian, Wenjiao
TI Image set-based face recognition using pose estimation with facial
   landmarks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Face image sets; Pose estimation; Nonlinear least
   squares; Facial landmarks
ID ENSEMBLES
AB Face recognition (FR) based on image set is an important topic in computer vision. There are numerous approaches that apply pose estimation method for single image face recognition, but few embed pose estimation method into image set-based face recognition. The conventional pose estimation method PnP used for single image needs to be modified to be fit for set-based recognition task. This study presents a method to estimate the poses of image set by applying nonlinear least squares to facial landmarks. Moreover, the distances between every single image in the query set and the ones with similar corresponding poses in the gallery sets are compared. We improve the conventional PnP method by identifying a frontal image of each image set instead of using a fixed 3-D model. Our method is evaluated on the benchmark Honda/UCSD database and YouTube Celebrities database. Experimental results show that our method leads the performance in FR based on image sets compared with other published methods.
C1 [Lin, Jirui; Xiao, Laiyuan; Wu, Tao; Bian, Wenjiao] Huazhong Univ Sci & Technol, Sch Software, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Xiao, LY (corresponding author), Huazhong Univ Sci & Technol, Sch Software, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
EM xiao.l.y@hust.edu.cn
OI Wu, Tao/0000-0002-2519-7407
FU National Natural Science Foundation of China [51575204]; Independent
   Innovation Research Foundation of Huazhong University of Science and
   Technology [2017KFYXJJ224]
FX This study was supported by the National Natural Science Foundation of
   China (51575204) and Independent Innovation Research Foundation of
   Huazhong University of Science and Technology (2017KFYXJJ224).
CR [Anonymous], 2011, PROC CVPR IEEE
   [Anonymous], 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539965
   [Anonymous], NEUROCOMPUTING
   Cootes TF., 2000, An Introduction to Active Shape Models
   De-la-Torre M, 2015, PATTERN RECOGN, V48, P3385, DOI 10.1016/j.patcog.2015.05.008
   De-la-Torre M, 2015, INFORM FUSION, V24, P31, DOI 10.1016/j.inffus.2014.05.006
   Dewan MAA, 2016, PATTERN RECOGN, V49, P129, DOI 10.1016/j.patcog.2015.08.002
   Dorao CA, 2006, COMPUT CHEM ENG, V30, P535, DOI 10.1016/j.compchemeng.2005.10.012
   EDWARDS GJ, 1999, IMPROVING IDENTIFICA, V1, P1486
   Hayat M, 2014, PROC CVPR IEEE, P1915, DOI 10.1109/CVPR.2014.246
   Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283
   Huang LK, 2014, J VIS COMMUN IMAGE R, V25, P1774, DOI 10.1016/j.jvcir.2014.08.006
   Kim M, 2008, PROC CVPR IEEE, P1787
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Klove T, 2011, DESIGN CODE CRYPTOGR, V59, P183, DOI 10.1007/s10623-010-9454-0
   Lee KC, 2003, PROC CVPR IEEE, P313
   Li B, 2008, PATTERN RECOGN, V41, P3813, DOI 10.1016/j.patcog.2008.05.027
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Pagano C, 2014, INFORM SCIENCES, V286, P75, DOI 10.1016/j.ins.2014.07.005
   PAL SK, 1980, ELECTRON LETT, V16, P376, DOI 10.1049/el:19800267
   SHAH SAA, 2016, ITERATIVE DEEP LEARN
   Shah SAA, 2016, NEUROCOMPUTING, V174, P866, DOI 10.1016/j.neucom.2015.10.004
   Shakeri S, 2017, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2017/10/014
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   TAO D, 2017, IEEE T IMAGE PROCESS, V99, P1, DOI DOI 10.1177/1094342017737147
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P1397, DOI 10.1109/TCSVT.2008.2002825
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang RP, 2008, PROC CVPR IEEE, P2940
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Yang D, 2013, IEEE INT WORKSH COMP, P13, DOI 10.1109/CAMAD.2013.6708080
   Yang MH, 2015, APPL ENERG, V149, P1, DOI 10.1016/j.apenergy.2015.03.083
   ZENG QS, 2014, MULTILOCAL MODEL IMA
   ZHANG J, 2014, INT C ART INT SOFTW, P2014
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou SH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P221, DOI 10.1109/AFGR.2002.1004158
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277
NR 41
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19493
EP 19507
DI 10.1007/s11042-019-08408-0
EA MAR 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521701200001
DA 2024-07-18
ER

PT J
AU Lee, SW
   Jiang, GB
   Kong, HY
   Liu, C
AF Lee, Sung-Won
   Jiang, Guangbo
   Kong, Hai-Yan
   Liu, Chang
TI A difference of multimedia consumer's rating and review through
   sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Sentimental analysis; Online review; Sentiment analysis; Text mining;
   Lexicon method; Multimedia
AB With the increase in communication using online and mobile channels, consumers, in purchasing products or services, use online user reviews as an important decision-making tool providing information about other consumers' experiences. Companies also objectively analyze consumer opinions about their products and services to derive business insights. However, the rating, a quantitative information that serves as the basis for the evaluation and recommendation system of reviews, has the limitation that it does not reflect actual consumers' opinions or is inappropriate for use in recommendation systems. Sentiment analysis, which identifies the emotions and feelings contained in the online text generated by users, has been proposed as a way to deal with and solve such problems related to existing ratings. The present study aimed to investigate, using the lexicon-based approaches for review sentiment analysis, to whether the rating systems reflect genuine experience, satisfaction, and thoughts of customers. The results of this study demonstrate that reviews do not accurately represent the positive or negative aspects of the reviewed products and services, suggesting the need for future modifications in terms of system and consumer analysis. This study also suggests directions of future system and consumer research.
C1 [Lee, Sung-Won] Univ Seoul, Business Adm, 163 Seoulsiripdaero, Seoul 02504, South Korea.
   [Jiang, Guangbo; Kong, Hai-Yan] Chungbuk Natl Univ, Dept MIS, Chungdae Ro 1, Chungbuk 28644, South Korea.
   [Liu, Chang] Taishan Univ, Sch Econ & Management, 525 Dongyue St, Tai An 271000, Shandong, Peoples R China.
C3 University of Seoul; Chungbuk National University; Taishan University
RP Liu, C (corresponding author), Taishan Univ, Sch Econ & Management, 525 Dongyue St, Tai An 271000, Shandong, Peoples R China.
EM lsw1600@gmail.com; widejiang@outlook.com; haiyankong@naver.com;
   lc97123@tsu.edu.cn
RI Kong, Haiyan/L-1191-2013; Freienberg, Selina/AAV-8829-2021
OI LIU, CHANG/0000-0001-6524-8099
CR [Anonymous], 1991, West. J. Speech Commun, DOI DOI 10.1080/10570319109374395
   Banerjee S, 2017, DECIS SUPPORT SYST, V96, P17, DOI 10.1016/j.dss.2017.01.006
   Bickart B, 2002, ADV CONSUM RES, V29, P428
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Brister J.M., 1991, Advances in Consumer Research, V18, P155
   Devine I., 2001, Corporate Reputation Review, V4, P42
   Dhande L., 2014, INT J EMERG TRENDS T, V3, P313
   Duan WJ, 2008, DECIS SUPPORT SYST, V45, P1007, DOI 10.1016/j.dss.2008.04.001
   Fang X, 2015, Journal of Big Data, V2, P5, DOI 10.1186/s40537-015-0015-2
   Ficamos P, 2017, INT CONF BIG DATA, P336, DOI 10.1109/BIGCOMP.2017.7881689
   Gamon M, 2005, LECT NOTES COMPUT SC, V3646, P121
   Godes D, 2009, MARKET SCI, V28, P721, DOI 10.1287/mksc.1080.0444
   Han HY, 2018, MULTIMED TOOLS APPL, V77, P21265, DOI 10.1007/s11042-017-5529-5
   Harrison-Walker L.J., 2001, J SERV MARK, V15, P397, DOI DOI 10.1108/EUM0000000005657
   Hu N., 2009, 7 ACM C EL COMM, P324
   Kamel M, 2019, MULTIMED TOOLS APPL, V78, P21917, DOI 10.1007/s11042-019-7505-8
   류신, 2015, [Journal of Tourism and Leisure Research, 관광레저연구], V27, P187
   Litvin SW, 2008, TOURISM MANAGE, V29, P458, DOI 10.1016/j.tourman.2007.05.011
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   Ma X, 2018, MULTIMED TOOLS APPL, V77, P6425, DOI 10.1007/s11042-017-4550-z
   Mauri AG, 2013, INT J HOSP MANAG, V34, P99, DOI 10.1016/j.ijhm.2013.02.012
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mudambi SM, 2010, MIS QUART, V34, P185
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   SCAFFIDI C, 2007, P 8 ACM C EL COMM EC
   Scharl A, 2008, J INF TECHNOL POLITI, V5, P121, DOI 10.1080/19331680802149582
   Cantallops AS, 2014, INT J HOSP MANAG, V36, P41, DOI 10.1016/j.ijhm.2013.08.007
   VAIDYA MP, 2015, INT J RES, V2, P427
NR 29
TC 12
Z9 13
U1 9
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34625
EP 34642
DI 10.1007/s11042-020-08820-x
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000521701400003
DA 2024-07-18
ER

PT J
AU Lee, D
   Park, N
AF Lee, Donghyeok
   Park, Namje
TI Blockchain based privacy preserving multimedia intelligent video
   surveillance using secure Merkle tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Blockchain; Privacy; CCTV; Intelligent video surveillance;
   Merkle tree
ID IMPLEMENTATION
AB The recent intelligent surveillance systems provide various services that have not existed before, such as proactive predictive surveillance, through the AI-based video analysis technology. However, there are common security and privacy challenges caused by malicious attacker and untrusted 3rd party in the CCTV cloud system. To solve this problem, we exploit the blockchain technology to insure integrity and security of cloud-based intelligent surveillance system. In this paper, we propose a new method for cloud-based CCTV blockchain system. Our contribution is to propose a new Merkle-Tree method for the efficient transmission of video data. The suggested method in this paper is efficient because it reduces the bandwidth required for transmission. It also has the advantage of enabling deduplication to reduce storage costs. Also, the proposed method can synchronize CCTV video data safely without exposing the privacy of the object in the course of synchronization.
C1 [Lee, Donghyeok; Park, Namje] Jeju Natl Univ, Grad Sch, Dept Convergence Informat Secur, Jeju City, South Korea.
   [Park, Namje] Jeju Natl Univ, Teachers Coll, Dept Comp Educ, Jeju City, South Korea.
C3 Jeju National University; Jeju National University
RP Park, N (corresponding author), Jeju Natl Univ, Grad Sch, Dept Convergence Informat Secur, Jeju City, South Korea.; Park, N (corresponding author), Jeju Natl Univ, Teachers Coll, Dept Comp Educ, Jeju City, South Korea.
EM bonfard@jejunu.ac.kr; namjepark@jejunu.ac.kr
FU Institute for Information & communications Technology Promotion(IITP) -
   Korea government(MSIT) [2019-0-00203]; Basic Science Research Program
   through the National Research Foundation of Korea(NRF) - Ministry of
   Education [NRF-2019R1I1A3A01062789]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIT)
   [2019-0-00203, The Development of Predictive Visual Security Technology
   for Preemptive Threat Response]. And, This research was supported by
   Basic Science Research Program through the National Research Foundation
   of Korea(NRF) funded by the Ministry of
   Education(NRF-2019R1I1A3A01062789).
CR Agrawal R., 2004, P SIGMOID 04, P563
   Baier SL, 2018, HANDBOOK OF INTERNATIONAL TRADE AND TRANSPORTATION, P15
   Gallo P., 2018, 2018 IEEE INT C ENV, P1
   Huang BT, 2017, MULTIMED TOOLS APPL, V76, P20099, DOI 10.1007/s11042-017-4396-4
   Jeong Y, 2019, 2019 INT C INF NETW
   Kang JA, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/395752
   Lee D, 2017, J SUPERCOMPUT, V73, P1103, DOI 10.1007/s11227-016-1841-5
   Mendki P, 2019, 2019 INTERNATIONAL CONFERENCE ON BLOCKCHAIN TECHNOLOGY (ICBCT 2019), P66, DOI 10.1145/3320154.3320166
   Merkle RC, 1979, SECURITY AUTHENTICAT
   Park Hyun-A, 2012, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V22, P621
   Park Namje, 2014, Journal of KIISE: Computing Practices and Letters, V20, P430
   Park N, 2018, PERS UBIQUIT COMPUT, V22, P3, DOI 10.1007/s00779-017-1017-1
   Park Namje, 2013, [The Journal of Korean Institute of Communications and Information Sciences C, 한국통신학회논문지C], V38, P841
   Park N, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010020
   Park N, 2014, CLUSTER COMPUT, V17, P653, DOI 10.1007/s10586-014-0367-y
   Park N, 2011, INT J AD HOC UBIQ CO, V8, P205, DOI 10.1504/IJAHUC.2011.043583
   Rodriguez-Silva DA, 2012, IEEE 5 INT C CLOUD C, V2012
   Rusitschka S, 2010, SMART GRID COMM SMAR
   Xu QQ, 2018, MULTIMED TOOLS APPL, V77, P18223, DOI 10.1007/s11042-017-5224-6
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   박남제, 2010, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V8, P189
NR 21
TC 47
Z9 48
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34517
EP 34534
DI 10.1007/s11042-020-08776-y
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000563170500001
DA 2024-07-18
ER

PT J
AU Pasupa, K
   Tungjitnob, S
   Vatathanavaro, S
AF Pasupa, Kitsuchart
   Tungjitnob, Suchat
   Vatathanavaro, Supawit
TI Semi-supervised learning with deep convolutional generative adversarial
   networks for canine red blood cells morphology classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Red blood cell; Semi-supervised learning; Generative adversarial
   networks
AB Information of Red Blood Cell (RBC) morphology, obtained by analysing RBC images, is regularly requested by veterinarians to diagnose anaemic dogs. Machine learning techniques have been exploited to speed up the image classification. Recently, many researchers used deep learning techniques for classification; however, a large quantity of labelled data is necessary to extract performance with them. A lack of annotated data, due to time and costs for pathologist and their limited numbers, has become a difficulty. This limits the amount of annotated data and leads to a large number of unannotated data, preventing traditional deep learning algorithms from being effective. We show that a semi-supervised learning method, using the Generative Adversarial Networks (GANs) for canine RBC morphology classification, can solve the lack of labelled data, when we want to train a deep learning classifier. Our semi-supervised GAN can use both labelled and unlabelled data and showed that they can achieve the same level of performance as a traditional convolutional neural network, with a smaller number of labelled images. Furthermore, we showed that augmenting the limited numbers of a labelled images enhanced the overall performance. A key benefit of our method is reduced pathologist cost and time to annotate cell images for developing a deep learning classifier.
C1 [Pasupa, Kitsuchart; Tungjitnob, Suchat; Vatathanavaro, Supawit] King Mongkuts Inst Technol Ladkrabang, Fac Informat Technol, Bangkok 10520, Thailand.
C3 King Mongkuts Institute of Technology Ladkrabang
RP Pasupa, K (corresponding author), King Mongkuts Inst Technol Ladkrabang, Fac Informat Technol, Bangkok 10520, Thailand.
EM kitsuchart@it.kmitl.ac.th; 62606062@kmitl.ac.th; 62606061@kmitl.ac.th
RI Pasupa, Kitsuchart/A-8902-2010; Pasupa, Kitsuchart/ABB-2573-2020
OI Pasupa, Kitsuchart/0000-0001-8359-9888; Pasupa,
   Kitsuchart/0000-0001-8359-9888
FU Faculty of Information Technology, King Mongkut's Institute of
   Technology Ladkrabang
FX We thank the Veterinary Teaching Hospital, Kasetsart University, Hua
   Hin, Thailand, for providing stained glass slides of peripheral blood
   smears and labelling the dataset. This research was supported by the
   Faculty of Information Technology, King Mongkut's Institute of
   Technology Ladkrabang.
CR [Anonymous], 2019, P CVPR WORKSH LONG B
   [Anonymous], 2015, arXiv Learning
   Bikhet SF, 2000, INT CONF ACOUST SPEE, P2259, DOI 10.1109/ICASSP.2000.859289
   Bin Jin, 2017, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2017.185
   Brock Andrew, 2018, ARXIV180911096
   Chapelle O., 2006, SEMISUPERVISED LEARN
   CSEKE I, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P530, DOI 10.1109/ICPR.1992.202041
   Dai Z. H., 2017, NIPS
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Dorini LB, 2007, SIBGRAPI, P294, DOI 10.1109/SIBGRAPI.2007.33
   Ford J, 2013, INT J LAB HEMATOL, V35, P351, DOI 10.1111/ijlh.12082
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gregory TR, 2000, GENOME, V43, P895, DOI 10.1139/gen-43-5-895
   Habibzadeh M, 2018, PROC SPIE, V10696, DOI 10.1117/12.2311282
   Hiremath P.S., 2010, International Journal of Computer Applications, Special Issue on RTIPPR, V2, P59
   Hou Q, 2018, ARXIV180309859
   Jambhekar N.D., 2011, Science Research Reporter, P151
   Macawile MJ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CONTROL AND ROBOTICS ENGINEERING (ICCRE), P259, DOI 10.1109/ICCRE.2018.8376476
   Kim K. S., 2000, Proceedings ACM Multimedia 2000, P395, DOI 10.1145/354384.354543
   King DB, 2015, ACS SYM SER, V1214, P1
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CX, 2017, ADV NEUR IN, V30
   LI W, 2019, ARXIV191008540
   MaalOe L, 2016, ARXIV 160205473
   Madani A, 2018, I S BIOMED IMAGING, P1038, DOI 10.1109/ISBI.2018.8363749
   Malihi L, 2013, IRAN CONF MACH, P360, DOI 10.1109/IranianMVIP.2013.6780011
   Markiewicz T, 2005, IEEE IJCNN, P2496
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   O'Mahony Niall, 2020, Advances in Computer Vision. Proceedings of the 2019 Computer Vision Conference (CVC). Advances in Intelligent Systems and Computing (AISC 943), P128, DOI 10.1007/978-3-030-17795-9_10
   Odena Augustus., 2016, Semi-supervised learning with generative adversarial networks
   Olmschenk G, 2019, COMPUT VIS IMAGE UND, V186, P1, DOI 10.1016/j.cviu.2019.06.004
   Osowski S, 2009, IEEE T INSTRUM MEAS, V58, P2159, DOI 10.1109/TIM.2008.2006726
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Pasupa K, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01773-x
   Radford A., 2015, ARXIV
   Rasmus A., 2015, ADV NEURAL INFORM PR, DOI DOI 10.1186/1477-5956-9-S1-S5
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Razzak MI, 2017, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2017.111
   Salimans T, 2016, ADV NEUR IN, V29
   Shafique S, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533033818802789
   Shahin AI, 2019, COMPUT METH PROG BIO, V168, P69, DOI 10.1016/j.cmpb.2017.11.015
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Sricharan K., 2017, ARXIV170805789
   Sunhem W, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P390, DOI 10.1109/ICACI.2016.7449857
   Taherisadr M, 2013, SHIRAZ E MED J, V14, P44
   TAI WL, 2011, IEEE INT S, V7, P129
   Tiwari P, 2018, COGN SYST RES, V52, P1036, DOI 10.1016/j.cogsys.2018.08.022
   Tomari R, 2014, PROCEDIA COMPUT SCI, V42, P206, DOI 10.1016/j.procs.2014.11.053
   Tu Y, 2018, CMC-COMPUT MATER CON, V55, P243, DOI 10.3970/cmc.2018.01755
   USHIZIMA DM, 2005, P INT C HYDR INT SYS, P1
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Weiss D.J., 2011, Schalm's veterinary hematology
   Weston Jason, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P639, DOI 10.1007/978-3-642-35289-8_34
   Xu MJ, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005746
   Yang Z., 2016, ARXIV160308861
   Zhang H., 2018, ARXIV180508318
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 59
TC 17
Z9 17
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34209
EP 34226
DI 10.1007/s11042-020-08767-z
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000518068900001
DA 2024-07-18
ER

PT J
AU Anjum, A
   Islam, S
AF Anjum, Areesha
   Islam, Saiful
TI Recapture detection technique based on edge-types by analysing
   high-frequency components in digital images acquired through LCD screens
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Recapture detection; Blurriness; Aliasing;
   Edge-profile
AB Digital images are part of our lives but with the advancement of technology, the authenticity of images is in doubt. Image editing tools are used to tamper images and high-quality cameras are used to recapture tampered images to evade tamper detection. In general, tampering introduces artifacts in images and these artifacts are camouflaged by the re-acquisition process. The re-acquisition process makes forged image more like original which is hard to detect visually and statistically. Thus, existing forensic tools and techniques fail to detect tampering in reacquired or recaptured images. This paper proposes a novel technique to detect recaptured images by exploiting the high-level details present in images and based on that edge profile is obtained. Further, edges are classified into different groups. It has been observed that the number of edge pixels in these edge groups is different for original and recaptured images. Based on the number of pixels in edges, a feature vector is built and a system is trained using SVM classifier. The proposed method tested on two databases. The experimental results demonstrated that proposed method is better than existing techniques for recapture detection.
C1 [Anjum, Areesha; Islam, Saiful] Aligarh Muslim Univ, Zakir Husain Coll Engn & Technol, Dept Comp Engn, Aligarh, Uttar Pradesh, India.
C3 Aligarh Muslim University; Zakir Husain College Of Engineering &
   Technology
RP Anjum, A (corresponding author), Aligarh Muslim Univ, Zakir Husain Coll Engn & Technol, Dept Comp Engn, Aligarh, Uttar Pradesh, India.
EM areesha.anjum@zhcet.ac.in; saifulislam@zhcet.ac.in
RI Islam, Saiful/HLW-5299-2023
OI Anjum, Areesha/0000-0003-2987-8258
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2003, 2003 C COMPUTER VISI, DOI [DOI 10.1109/CVPRW.2003.10093, DOI 10.1109/CVPRW.2003.10093.27.T.-T]
   [Anonymous], 2015, ARXIV150900552
   [Anonymous], 2015, J INF HIDING MULTIME
   [Anonymous], 2017, ELECT IMAGING
   [Anonymous], 2016, Digital Forensics and Watermarking, DOI DOI 10.1007/978-3-319-53465-7-9
   Bai JM, 2010, IEEE INT SYMP CIRC S, P3425, DOI 10.1109/ISCAS.2010.5537866
   Cao H., 2010, THESIS NANYANG TU
   Cao H, 2010, ROSE RECAPTURED IMAG
   Cao H, 2010, INT CONF ACOUST SPEE, P1790, DOI 10.1109/ICASSP.2010.5495419
   Choi HY, 2017, LECT NOTES ELECTR EN, V424, P339, DOI 10.1007/978-981-10-4154-9_40
   Choudhury T., 1999, P INT C AUD AND VID, P176
   Gambhir D, 2017, STUD COMPUT INTELL, V672, P115, DOI 10.1007/978-3-319-46245-5_8
   Gao XT, 2011, LECT NOTES COMPUT SC, V6526, P90, DOI 10.1007/978-3-642-18405-5_8
   Gao XT, 2010, IEEE INT CON MULTI, P1469, DOI 10.1109/ICME.2010.5583280
   Guo KZ, 2015, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND ENGINEERING MANAGEMENT 2014, P103, DOI 10.2991/978-94-6239-102-4_22
   Haron N, 2010, INNOVATIONS IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P477, DOI 10.1007/978-90-481-9112-3_81
   Ke Y., 2013, INT J MULTIMEDIA UBI, V8, P71, DOI DOI 10.14257/IJMUE.2013.8.5.08
   Kose N, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P1027, DOI 10.1109/ICIEV.2012.6317336
   Luo Weiqi, 2007, Frontiers of Computer Science in China, V1, P166, DOI 10.1007/s11704-007-0017-0
   Mahdian B., 2015, J FORENSIC RES, V6, DOI 10.4172/21577145.1000294
   Muammar H, 2013, INT CONF ACOUST SPEE, P2242, DOI 10.1109/ICASSP.2013.6638053
   Mushtaq S., 2014, International Journal of Advanced Science and Technology, V73, P15, DOI DOI 10.14257/IJAST.2014.73.02
   Piva A., 2013, ISRN SIGNAL PROCESS, V2013, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Tang YY, 2000, IEEE T SYST MAN CY B, V30, P93, DOI 10.1109/3477.826950
   Thongkamwitoon T, 2014, RECAPTURE IMAGE DATA
   Thongkamwitoon T, 2015, IEEE T INF FOREN SEC, V10, P953, DOI 10.1109/TIFS.2015.2392566
   Tong HH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P17, DOI 10.1109/ICME.2004.1394114
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Wang K, 2017, DIGIT INVEST, V23, P75, DOI 10.1016/j.diin.2017.10.001
   Yin J., 2012, P 20 ACM INT C MULT, P1113
   Yu H, 2008, IEEE IMAGE PROC, P3140, DOI 10.1109/ICIP.2008.4712461
   Zhai XB, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P234, DOI 10.1109/IIH-MSP.2013.67
NR 34
TC 11
Z9 14
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 6965
EP 6985
DI 10.1007/s11042-019-08418-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100003
DA 2024-07-18
ER

PT J
AU Bhattacharya, A
   Palit, S
AF Bhattacharya, Ankan
   Palit, Sarbani
TI Measurement of image degradation: a no-reference approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Noise; Blurring; No-reference approach; Identification;
   Quantification
ID REFERENCE QUALITY ASSESSMENT; NATURAL SCENE STATISTICS; DISTORTED
   IMAGES; BLUR
AB In modern communication systems, transmission of data, particularly that of images is very important. Unfortunately, the process is prone to different kinds of degradations. For instance, the large traffic on the network makes the reduction of data volume and storage imperative. This is achieved through compression techniques such as JPEG and JPEG2000, at the expense of image quality, unfortunately. Image quality also deteriorates on account of the state of the transmission channel and the amount of losses occurring. Another common type of image degradation is blurring. At the receiving end, identifying the degradation is an important requirement for applications like blind image denoising so that appropriate techniques for removal may be adopted. Since the undegraded original image is usually not available, no-reference methods are not only attractive but also essential. This article proposes a novel no-reference method which can clearly distinguish between noise, compression and blurring. This is achieved in two stages - the first distinguishes between noise and compression/blurring while the second distinguishes between compression and blurring. Finally, a quantification of the degradation suffered is also carried out, which forms another important contribution of the approach. The primary tool employed is the Discrete Wavelet Transform (DWT) and the differential behaviour of the image DWT coefficients to noise, compression and blurring, at various levels of resolution. The use of the properties of the inter-level coefficients make this approach unique in nature. These properties have been explored and analyzed in detail. A large number of simulations using images from popular databases, establish the usefulness of the approach.
C1 [Bhattacharya, Ankan] Aliah Univ, Kolkata, India.
   [Palit, Sarbani] Indian Stat Inst, Kolkata, India.
C3 Aliah University; Indian Statistical Institute; Indian Statistical
   Institute Kolkata
RP Palit, S (corresponding author), Indian Stat Inst, Kolkata, India.
EM ankan.bhattacharya@gmail.com; sarbanip@isical.ac.in
CR [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], KODIM DATABASE
   [Anonymous], P IVCNZ2013 27 29 NO
   [Anonymous], P IVCNZ2012 DUN NZ
   [Anonymous], P ISPA2011 4 6 SEPT
   Babu RV, 2007, SIGNAL PROCESS, V87, P1493, DOI 10.1016/j.sigpro.2006.12.014
   Bhattacharya A, 2018, MULTIDIM SYST SIGN P, V29, P1679, DOI 10.1007/s11045-017-0518-4
   Brandao T, 2008, SIGNAL PROCESS, V88, P822, DOI 10.1016/j.sigpro.2007.09.017
   Campisi P, 2003, IEEE T SIGNAL PROCES, V51, P996, DOI 10.1109/TSP.2003.809381
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Freitas PG, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Jiao SH, 2013, ELECTRON LETT, V49, P1137, DOI 10.1049/el.2013.1837
   Kundur D, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P409, DOI 10.1109/ICIP.1998.723403
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Lu W, 2010, NEUROCOMPUTING, V73, P784, DOI 10.1016/j.neucom.2009.10.012
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sazzad ZMP, 2008, SIGNAL PROCESS-IMAGE, V23, P257, DOI 10.1016/j.image.2008.03.005
   Serir A, 2013, J VIS COMMUN IMAGE R, V24, P911, DOI 10.1016/j.jvcir.2013.06.002
   Sheikh H. R., 2003, Live image quality assessment database
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Suthaharan S, 2009, SIGNAL PROCESS, V89, P1647, DOI 10.1016/j.sigpro.2009.02.007
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wu SQ, 2009, J VIS COMMUN IMAGE R, V20, P231, DOI 10.1016/j.jvcir.2009.03.002
   Zhai GT, 2008, SIGNAL PROCESS-IMAGE, V23, P417, DOI 10.1016/j.image.2008.04.007
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
NR 38
TC 1
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5545
EP 5572
DI 10.1007/s11042-019-08444-w
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900006
DA 2024-07-18
ER

PT J
AU Madasu, A
   Elango, S
AF Madasu, Avinash
   Elango, Sivasankar
TI Efficient feature selection techniques for sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Ensemble techniques; Sentiment analysis; Machine
   learning
ID CLASSIFICATION
AB Sentiment analysis is a domain of study that focuses on identifying and classifying the ideas expressed in the form of text into positive, negative and neutral polarities. Feature selection is a crucial process in machine learning. In this paper, we aim to study the performance of different feature selection techniques for sentiment analysis. Term Frequency Inverse Document Frequency (TF-IDF) is used as the feature extraction technique for creating feature vocabulary. Various Feature Selection (FS) techniques are experimented to select the best set of features from feature vocabulary. The selected features are trained using different machine learning classifiers Logistic Regression (LR), Support Vector Machines (SVM), Decision Tree (DT) and Naive Bayes (NB). Ensemble techniques Bagging and Random Subspace are applied on classifiers to enhance the performance on sentiment analysis. We show that, when the best FS techniques are trained using ensemble methods achieve remarkable results on sentiment analysis. We also compare the performance of FS methods trained using Bagging, Random Subspace with varied neural network architectures. We show that FS techniques trained using ensemble classifiers outperform neural networks requiring significantly less training time and parameters thereby eliminating the need for extensive hyper-parameter tuning.
C1 [Madasu, Avinash] Samsung R&D Inst India, Bagmane Constellat Business Pk,Outer Ring Rd, Bengaluru 560037, Karnataka, India.
   [Elango, Sivasankar] Natl Inst Technol, Dept Comp Sci, Tanjore Main Rd,Natl Highway 67,Near BHEL Trichy, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Madasu, A (corresponding author), Samsung R&D Inst India, Bagmane Constellat Business Pk,Outer Ring Rd, Bengaluru 560037, Karnataka, India.
EM avinash.sai001@gmail.com; sivasankar@nitt.edu
RI Elango, Sivasankar/AAY-5197-2021; Madasu, Avinash/HGU-0417-2022
CR Abdi A, 2019, INFORM PROCESS MANAG, V56, P1245, DOI 10.1016/j.ipm.2019.02.018
   Agarwal R, 2012, PROCEEDINGS OF THE FIRST WORKSHOP ON INFORMATION AND KNOWLEDGE MANAGEMENT FOR DEVELOPING REGION, P1
   [Anonymous], 2015, GROUP INDIVIDUAL LAB
   [Anonymous], 2008, ACM Transactions on Information Systems (TOIS)
   [Anonymous], 2009, P 14 AUSTRALASIAN DO
   Bahassine S, 2018, J KING SAUD U COMPUT
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cai J, 2008, LECT NOTES COMPUTER, V4993
   Chi X, 2017, IEEE SYS MAN CYBERN, P1238, DOI 10.1109/SMC.2017.8122782
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Das S., 2001, P 18 INT C MACHINE L, P74, DOI DOI 10.5555/645530.658297
   Galavotti L, 2000, LECT NOTES COMPUTER, V1923
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jones K. S., 2004, J DOCUMENTATION
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kolen JF, 2009, A Field Guide to Dynamical Recurrent Networks, DOI [DOI 10.1109/9780470544037.CH14, 10.1109/9780470544037]
   Labani M, 2018, ENG APPL ARTIF INTEL, V70, P25, DOI 10.1016/j.engappai.2017.12.014
   Lee J, 2019, INFORM SCIENCES, V485, P263, DOI 10.1016/j.ins.2019.02.021
   Liu P, 2016, ARXIV160505101
   López M, 2019, INFORM SCIENCES, V480, P273, DOI 10.1016/j.ins.2018.12.038
   Metsis Vangelis, 2006, CEAS, V17, P28, DOI 10.1.1.61.5542
   Morinaga S., 2002, P 8 ACM SIGKDD INT C, P341, DOI [DOI 10.1145/775047.775098, 10.1145/775047.775098]
   Oussous A., 2019, Proceedings of the 2nd International Conference on Networking, Information Systems Security, P65
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Pascanu R., 2013, INT C MACH LEARN, P1310
   PLACKETT RL, 1983, INT STAT REV, V51, P59, DOI 10.2307/1402731
   Pong-Inwong C, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1222, DOI 10.1109/CompComm.2016.7924899
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rehman A, 2015, EXPERT SYST APPL, V42, P3670, DOI 10.1016/j.eswa.2014.12.013
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Tan SB, 2008, EXPERT SYST APPL, V34, P2622, DOI 10.1016/j.eswa.2007.05.028
   Tang J, 2014, TRANSL VIS SCI TECHN, V3, DOI 10.1167/tvst.3.6.1
   vander Maaten L., 2009, J MACH LEARN RES, V10, P13, DOI [10.1080/13506280444000102, DOI 10.1080/13506280444000102]
   Wang S., 2012, Baselines and bigrams: Simple, good sentiment and topic classification, P90
   Wang S, 2009, LECT NOTES COMPUTER, V5854
   Xiao LQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4496
   Yadav AK, 2013, INT CONF RECENT, P13, DOI 10.1109/ICRTIT.2013.6844173
NR 44
TC 29
Z9 29
U1 5
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6313
EP 6335
DI 10.1007/s11042-019-08409-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900039
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Prabha, K
   Sam, IS
AF Prabha, K.
   Sam, I. Shatheesh
TI A novel blind color image watermarking based on Walsh Hadamard Transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Walsh Hadamard Transform; Blind watermarking; Color image watermarking;
   non-overlapping blocks; 2D-Logistic Sine Coupling Map Encryption
ID ROBUST WATERMARKING; ALGORITHM; DCT
AB A new blind color image watermarking based on Walsh Hadamard Transform (WHT) is proposed in this paper which uses Triangular Vertex Transform (TVT) along with WHT. This method introduces a Triangular Vertex Transform (TVT) and Inverse Triangular Vertex Transform (ITVT) as well as applies this transform for image watermarking. Initially, convert the R, G, B color image to TVT coefficients U, V and W using the proposed TVT transform. Then the W coefficient is subdivided into 4 x 4 non-overlapping blocks, which are then transformed using WHT. The watermark is encrypted with the key K using the 2D-Logistic Sine Coupling Map encryption to obtain the encrypted watermarked image. The bits of the encrypted image is embedded in the first row WHT coefficients since the embedding of watermark bit on the first row provides high robustness to attacks. After embedding the data, the inverse WHT and inverse TVT are applied to obtain the watermarked image. The extraction process is similar to that of the embedding process where TVT is applied on the Watermarked image to construct W ' coefficient. Subdivide the attained W ' coefficient into 4 x 4 sub-block and then the WHT is applied to the 4 x 4 sub-block for extracting the data from the first row of WHT coefficients. The performance of the proposed watermarking algorithm outperforms in terms of Peak Signal to Noise Ratio (PSNR), Structural Similarity Index (SSIM) and Normalized cross-correlation (NC). Experimental results reveal that the proposed watermarking method is highly resistant to different types of attacks.
C1 [Prabha, K.] Manonmaniam Sundaranar Univ, Dept Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
   [Sam, I. Shatheesh] Manonmaniam Sundaranar Univ, Dept PG Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Prabha, K (corresponding author), Manonmaniam Sundaranar Univ, Dept Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
EM k.prabhajaya@gmail.com; shatheeshsam@yahoo.com
RI K, Dr Prabha/GMX-2333-2022
OI , Dr. K. Prabha/0000-0001-6382-8233
CR Araghi T.K., 2016, Int. J. Adv. Image Process. Tech, V3, P6
   Bhatnagar G, 2012, IET IMAGE PROCESS, V6, P386, DOI 10.1049/iet-ipr.2010.0400
   Bhatnagar G, 2012, COMPUT ELECTR ENG, V38, P1164, DOI 10.1016/j.compeleceng.2012.02.002
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Ganic Emir., 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Han SC, 2018, OPTOELECTRON LETT, V14, P61, DOI 10.1007/s11801-018-7212-0
   Horng G, 2014, J INFORM HIDING MULT, V5, P152
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Jane O, 2014, TURK J ELECTR ENG CO, V22, P1354, DOI 10.3906/elk-1212-75
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liu NS, 2015, NONLINEAR DYNAM, V80, P1329, DOI 10.1007/s11071-015-1946-z
   Meenakshi K, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT), P167, DOI 10.1109/ICIT.2014.53
   Mehto A, 2016, PROCEDIA COMPUT SCI, V78, P88, DOI 10.1016/j.procs.2016.02.015
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Parashar P., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P111, DOI DOI 10.14257/IJSIP.2014.7.6.10
   Pullayikodi SK, 2017, J IMAGING, V3, DOI 10.3390/jimaging3040046
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Shih FY, 2018, MULTIMED TOOLS APPL, V77, P1623, DOI 10.1007/s11042-017-4367-9
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Yen CT, 2016, MULTIMED TOOLS APPL, V75, P9745, DOI 10.1007/s11042-015-2718-y
   Zhu HG, 2019, IEEE ACCESS, V7, P14081, DOI 10.1109/ACCESS.2019.2893538
NR 33
TC 17
Z9 17
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6845
EP 6869
DI 10.1007/s11042-019-08212-w
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900063
DA 2024-07-18
ER

PT J
AU Kastner, MA
   Ide, I
   Nack, F
   Kawanishi, Y
   Hirayama, T
   Deguchi, D
   Murase, H
AF Kastner, Marc A.
   Ide, Ichiro
   Nack, Frank
   Kawanishi, Yasutomo
   Hirayama, Takatsugu
   Deguchi, Daisuke
   Murase, Hiroshi
TI Estimating the imageability of words by mining visual characteristics
   from crawled image data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Deep transfer network; Heterogeneous-domain
   knowledge propagation; Cross-domain label transfer
AB Natural Language Processing and multi-modal analyses are key elements in many applications. However, the semantic gap is an everlasting problem, leading to unnatural results disconnected from the user's perception. To understand semantics in multimedia applications, human perception needs to be taken into consideration. Imageability is an approach originating from Pyscholinguistics to quantize the human perception of words. Research shows a relationship between language usage and the imageability of words, making it useful for multimodal applications. However, the creation of imageability datasets is often manual and labor-intensive. In this paper, we propose a method using image data mining of a variety of visual features to estimate the imageability of words. The main assumption is a relationship between the imageability of concepts, human perception, and the contents of Web-crawled images. Using a set of low- and high-level visual features from Web-crawled images, a model is trained to predict imageability. The evaluations show that the imageability can be predicted with both a sufficiently low error, and a high correlation to the ground-truth annotations. The proposed method can be used to increase the corpus of imageability dictionaries.
C1 [Kastner, Marc A.; Ide, Ichiro; Kawanishi, Yasutomo; Murase, Hiroshi] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Nack, Frank] Univ Amsterdam, Informat Inst, NL-1098 XH Amsterdam, Netherlands.
   [Hirayama, Takatsugu] Nagoya Univ, Inst Innovat Future Soc, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Deguchi, Daisuke] Nagoya Univ, Informat Strategy Off, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
C3 Nagoya University; University of Amsterdam; Nagoya University; Nagoya
   University
RP Kastner, MA (corresponding author), Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM kastnerm@murase.is.i.nagoya-u.ac.jp; ide@i.nagoya-u.ac.jp; nack@uva.nl;
   kawanishi@i.nagoya-u.ac.jp; takatsugu.hirayama@nagoya-u.jp;
   ddeguchi@nagoya-u.jp; murase@i.nagoya-u.ac.jp
RI Kawanishi, Yasutomo/AAF-9529-2019; Ide, Ichiro/M-4863-2014
OI Kawanishi, Yasutomo/0000-0002-3799-4550; Ide,
   Ichiro/0000-0003-3942-9296; Kastner, Marc/0000-0002-9193-5973; Deguchi,
   Daisuke/0000-0003-0603-8790
FU JSPS KAKENHI [16H02846]; NII, Japan; Grants-in-Aid for Scientific
   Research [16H02846] Funding Source: KAKEN
FX Parts of this research were supported by JSPS KAKENHI 16H02846, and a
   joint research project with NII, Japan.
CR [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2015, Open Source Computer Vision Library
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   BALAHUR A, 2018, P 9 WORKSH COMP APPR
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bird S., 2006, P COLING ACL INT PRE, P69, DOI DOI 10.3115/1118108.1118117
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Charbonnier Jean, 2019, P 13 INT C COMPUTATI, P176, DOI [10.18653/v1/W19-0415, DOI 10.18653/V1/W19-0415]
   Chollet F, 2015, KERAS
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   COLTHEART V, 1988, BRIT J PSYCHOL, V79, P1, DOI 10.1111/j.2044-8295.1988.tb02270.x
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cortese MJ, 2004, BEHAV RES METH INS C, V36, P384, DOI 10.3758/BF03195585
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Douze M, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646421
   Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4647, DOI 10.1145/2858036.2858535
   Giesbrecht B, 2004, CEREB CORTEX, V14, P521, DOI 10.1093/cercor/bhh014
   Hessel J., 2018, N AM ASS COMPUTATION
   Hewitt J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2566
   Holzinger A., 2017, ARXIV171209923
   Inoue Nakamasa., 2016, ACM on Multimedia Conference, P277
   JONES GV, 1985, BRAIN LANG, V24, P1, DOI 10.1016/0093-934X(85)90094-X
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kastner MA, 2019, MULTIMED TOOLS APPL, V78, P9463, DOI 10.1007/s11042-018-6528-x
   Kawakubo H., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P330, DOI 10.1109/ISM.2010.57
   Li JJ, 2015, AAAI CONF ARTIF INTE, P2281
   Ljubesic N, 2018, REPRESENTATION LEARNING FOR NLP, P217
   Ma WY, 2009, J CHILD LANG, V36, P405, DOI 10.1017/S0305000908009008
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   PAIVIO A, 1968, J EXP PSYCHOL, V76, P1, DOI 10.1037/h0025327
   Pattichis Constantinos S., 2017, ARXIV PREPRINT ARXIV
   PAULA JS, 2013, PSYCHOL WORD MEANING
   Pedregosa F, 2011, LEARN RES, V12
   Pennebaker J.W., 2001, Linguistic inquiry and word count: LIWC 2001, V71, P1
   Reilly J, 2007, COGNITIVE SCI, V31, P157, DOI 10.1080/03640210709336988
   Ringeval F, 2018, PROCEEDINGS OF THE 2018 AUDIO/VISUAL EMOTION CHALLENGE AND WORKSHOP (AVEC'18), P3, DOI 10.1145/3266302.3266316
   Samek W., 2017, ARXIV PREPRINT ARXIV
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Sianipar A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01907
   Smolík F, 2015, FIRST LANG, V35, P446, DOI 10.1177/0142723715609228
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   TANAKA S, 2013, P 6 ACM INT C WEB SE, P475
   Tang JH, 2019, IEEE T PATTERN ANAL, V41, P2027, DOI 10.1109/TPAMI.2019.2906603
   Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882
   Tang JH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2998574
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   VIDANAPATHIRANA M, 2018, YOLO3 4 PY
   Yanai K., 2005, 13th Annual ACM International Conference on Multimedia, P419, DOI 10.1145/1101149.1101241
   Yee LTS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174569
   ZHANG M, 2018, P BRIT MACH VIS C 20
NR 52
TC 6
Z9 6
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18167
EP 18199
DI 10.1007/s11042-019-08571-4
EA FEB 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000517055900002
DA 2024-07-18
ER

PT J
AU Linhares, CDG
   Ponciano, JR
   Pereira, FSF
   Rocha, LEC
   Paiva, JGS
   Travenolo, BAN
AF Linhares, Claudio D. G.
   Ponciano, Jean R.
   Pereira, Fabiola S. F.
   Rocha, Luis E. C.
   Paiva, Jose Gustavo S.
   Travencolo, Bruno A. N.
TI Visual analysis for evaluation of community detection algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex networks; Network community detection; Information visualization
ID COMPLEX NETWORKS
AB Networks are often used to model the structure of interactions between parts of a system. One important characteristic of a network is the so-called network community structures that are groups of nodes more connected between themselves than with nodes from other groups. Such community structure is fundamental to better understand the organization of networks. Although there are several community detection algorithms in the literature, choosing the most appropriate for a specific task is not always trivial. This paper introduces a methodology to analyze the performance of community detection algorithms using network visualization. We assess the methodology using two widely adopted community detection algorithms: Infomap and Louvain. We apply both algorithms to four real-world networks with a variety of characteristics to demonstrate the usefulness and generality of the methodology. We discuss the performance of these algorithms and show how the user may use statistical and visual analytics to identify the most appropriate network community detection algorithm for a certain network analysis task.
C1 [Linhares, Claudio D. G.; Ponciano, Jean R.; Pereira, Fabiola S. F.; Paiva, Jose Gustavo S.; Travencolo, Bruno A. N.] Univ Fed Uberlandia, Uberlandia, MG, Brazil.
   [Rocha, Luis E. C.] Univ Ghent, Ghent, Belgium.
C3 Universidade Federal de Uberlandia; Ghent University
RP Linhares, CDG (corresponding author), Univ Fed Uberlandia, Uberlandia, MG, Brazil.
EM claudiodgl@gmail.com; jeanrobertop@gmail.com; fabiola.pereira@ufu.br;
   luis.rocha@ugent.be; gustavo@ufu.br; travencolo@gmail.com
RI Rocha, Luis/AAB-4049-2019; Linhares, Claudio/AAJ-8869-2021; Travençolo,
   Bruno/F-6752-2010
OI Rocha, Luis/0000-0001-9046-8739; Linhares, Claudio/0000-0001-7012-4461;
   Travençolo, Bruno/0000-0001-7690-301X; Ponciano, Jean
   Roberto/0000-0003-4629-3542
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico - CNPq
   [456855/2014-9]; Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior (CAPES PrInt) [88881.311513/2018-01]
FX This research was supported by Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico -CNPq [grant number 456855/2014-9] and
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES PrInt
   -Grant number 88881.311513/2018-01). The authors also thank
   SocioPatterns (www.sociopatterns.org) for making available the network
   data sets used in this paper.
CR Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47
   [Anonymous], INT J COMPUT SCI ENG
   [Anonymous], Physical Review E, DOI DOI 10.1103/PHYSREVE.80.056117
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Burch M, 2017, INFORM VISUAL, V16, P167, DOI 10.1177/1473871616661194
   Cattuto C, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011596
   Costa LD, 2011, ADV PHYS, V60, P329, DOI 10.1080/00018732.2011.572452
   Crampes M, 2014, ADV COMPLEX SYST, V17, DOI 10.1142/S0219525914500015
   DIBATTISTA G, 1994, COMP GEOM-THEOR APPL, V4, P235, DOI 10.1016/0925-7721(94)00014-X
   Dunne C., 2013, P SIGCHI C HUM FACT, P3247
   Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104
   Fortunato S, 2016, PHYS REP, V659, P1, DOI 10.1016/j.physrep.2016.09.002
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gemmetto V, 2014, BMC INFECT DIS, V14, DOI 10.1186/s12879-014-0695-9
   Génois M, 2015, NETW SCI, V3, P326, DOI 10.1017/nws.2015.10
   Gialampoukidis I, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P1, DOI 10.1109/SMAP.2016.7753375
   JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640
   Kriegel H.-P., 1996, KNOWLEDGE DISCOVERY, P226, DOI DOI 10.5555/3001460
   Labatut V., 2011, Journal of Convergence Information Technology, DOI 10.4156/jcit.vol6.issue11.32
   Linhares C. D. G., 2017, P S APPL COMP SAC 17, P187, DOI [DOI 10.1145/3019612.3019686, 10.1145/3019612.3019686]
   Linhares CDG, 2019, COMPUT GRAPH-UK, V84, P185, DOI 10.1016/j.cag.2019.08.006
   Mastrandrea R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136497
   Mothe J, 2017, 2017 ELEVENTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGIES (CSIT), P125, DOI 10.1109/CSITechnol.2017.8312155
   Newman MEJ, 2016, PHYS REV E, V94, DOI 10.1103/PhysRevE.94.052315
   Orman GK, 2012, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2012/08/P08001
   Perer A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P265
   Rajpoot K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134944
   Rocha LEC, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1001109
   Rosvall M., 2019, Advances in Network Clustering and Blockmodeling, P105, DOI [DOI 10.1002/9781119483298.CH4, 10.1002/9781119483298.ch4]
   Rosvall M, 2008, P NATL ACAD SCI USA, V105, P1118, DOI 10.1073/pnas.0706851105
   Rosvall M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008694
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stehlé J, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023176
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Traud AL, 2009, CHAOS, V19, DOI 10.1063/1.3194108
   Vanhems P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073970
   Vehlow C, 2015, COMPUT GRAPH FORUM, V34, P277, DOI 10.1111/cgf.12512
   Wang W., 2006, P SIGCHI C HUM FACT, DOI 10.1371/journal.pcbi.1004226
   Wang WJ, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P555, DOI 10.1109/ASONAM.2014.6921641
   Ware C., 2012, MORGAN KAUFMANN SERI, V3rd
   Yang Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30750
   YIN C, 2015, IJDSN 2015
   Zhang QG, 2005, LECT NOTES COMPUT SC, V3612, P28
NR 43
TC 15
Z9 16
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17645
EP 17667
DI 10.1007/s11042-020-08700-4
EA FEB 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516363300008
DA 2024-07-18
ER

PT J
AU Santos-Torres, A
   Zarraonandia, T
   Díaz, P
   Onorati, T
   Aedo, I
AF Santos-Torres, Andres
   Zarraonandia, Telmo
   Diaz, Paloma
   Onorati, Teresa
   Aedo, Ignacio
TI An empirical comparison of interaction styles for map interfaces in
   immersive virtual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Map interfaces; Interaction; Immersive virtual reality
ID REALITY VISUALIZATION
AB Geographical Information Systems (GIS) can be visualized using immersive technologies like Virtual Reality (VR). Before using this kind of technologies it is required to explore which interactions are affordable, efficient and satisfactory from the users' point of view. The purpose of this work is to provide insight on how to design efficient and natural interaction on GIS VR interfaces. This study presents a within-subjects comparative study that assesses the usability and performance of two popular interaction strategies: body-based interaction and device based interaction. In body-based interaction, participants use their hands and head orientation to control the VR map. In the second case, users interact with the Oculus Touch controller. Thirty two users participated in an experiment whose results suggest that interacting with the controller improves performance of the selection task, in terms of time spent and error rate. Also, the results show a preference of users for the controller in terms of perceived usability.
C1 [Santos-Torres, Andres; Zarraonandia, Telmo; Diaz, Paloma; Onorati, Teresa; Aedo, Ignacio] Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
C3 Universidad Carlos III de Madrid
RP Santos-Torres, A (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
EM andsanto@inf.uc3m.es; tzarraon@inf.uc3m.es; pdp@inf.uc3m.es;
   tonorati@inf.uc3m.es; aedo@ia.uc3m.es
RI ONORATI, TERESA/AAO-2691-2020; Torres, Andres Javier
   Santos/AAX-6674-2021; ., TERESA ONORATI/AAA-7118-2019; Santos-Torres,
   Andrés/HCH-4065-2022; Zarraonandia, Telmo/K-7177-2012; Aedo,
   Ignacio/F-3222-2014
OI Torres, Andres Javier Santos/0000-0003-2679-2440; ., TERESA
   ONORATI/0000-0002-3154-249X; Santos-Torres, Andrés/0000-0003-2679-2440;
   Zarraonandia, Telmo/0000-0003-3574-0984; DIAZ PEREZ, MARIA
   PALOMA/0000-0002-9493-7739; Aedo, Ignacio/0000-0001-5819-0511
FU project PACE - Spanish Ministry of Economy, Industry and Competitiveness
   [TIN2016-77690-R]
FX This work is supported by the project PACE funded by the Spanish
   Ministry of Economy, Industry and Competitiveness (TIN2016-77690-R).
CR Adhinarayanan Vignesh, 2014, 2014 International Conference on Reconfigurable Computing and FPGAs (ReConFig14), P1, DOI 10.1109/ReConFig.2014.7032542
   Anderson A, 1999, J MOL GRAPH MODEL, V17, P180, DOI 10.1016/S1093-3263(99)00029-7
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Beheshti E., 2012, Proceedings of the 2012 ACM international conference on Interactive tabletops and surfaces, ITS '12, P205, DOI DOI 10.1145/2396636.2396669
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   BOWMAN DA, 1997, METHODOLOGY, V98, P37
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Büschel W, 2018, LECT NOTES COMPUT SC, V11190, P95, DOI 10.1007/978-3-030-01388-2_4
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/ICSENS.2015.7370446, 10.1109/GLOCOM.2015.7417476]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Donalek C, 2014, IEEE INT CONF BIG DA, P609, DOI 10.1109/BigData.2014.7004282
   FERRER G, 2016, AUTON ROBOT, P1
   GIANNOPOULOS I, 2017, P 21 PANH C INF PART
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Kageyama A, 2000, PROG THEOR PHYS SUPP, P665, DOI 10.1143/PTPS.138.665
   Kim D, 2017, LECT NOTES COMPUT SC, V10273, P208, DOI 10.1007/978-3-319-58521-5_16
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Lazar J., 2010, Research Methods in Human-Computer Interaction
   LV Z, 2017, NEUROCOMPUTING, V254, P1339, DOI DOI 10.1016/J.NEUC0M.2016.07.078
   MARRIOTT K, 2018, CHAP IMMERSIVE ANAL, P25
   Mendes D, 2019, COMPUT GRAPH FORUM, V38, P21, DOI 10.1111/cgf.13390
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Muhanna MA, 2015, J KING SAUD UNIV-COM, V27, P344, DOI 10.1016/j.jksuci.2014.03.023
   PAHUD M, 2013, P 15 INT C HUM COMP, P113, DOI DOI 10.1145/2493190.2493210
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Qian Y, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P91, DOI 10.1145/3131277.3132182
   Radle R, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4127, DOI 10.1145/2556288.2557071
   RAUSCHERT I, 2002, DESIGNING HUMAN CTR, P2
   SANTOSTORRES A, 2018, P 19 INT C HUM COMP
   SLATER M, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P125
   Souza Danilo, 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P215, DOI 10.1007/978-3-319-07458-0_21
   Usher W, 2018, IEEE T VIS COMPUT GR, V24, P994, DOI 10.1109/TVCG.2017.2744079
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
   Zarraonandia T, 2016, LECT NOTES COMPUT SC, V10069, P450, DOI 10.1007/978-3-319-48746-5_46
   Zhang S, 2001, IEEE VISUAL, P437, DOI 10.1109/VISUAL.2001.964545
NR 37
TC 6
Z9 6
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35717
EP 35738
DI 10.1007/s11042-020-08709-9
EA FEB 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000516363300005
OA Green Published
DA 2024-07-18
ER

PT J
AU Elkabbany, GF
   Moussa, MM
AF Elkabbany, Ghada F.
   Moussa, Mona M.
TI Accelerating video encoding using cluster computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cluster computing; Parallel computing; Video encoding; Video on demand
AB The great advance and variety of multimedia applications such as video streaming, TV broadcasting, and video conferencing stimulated research to enhance video encoding, where a video is reduced in size and possibly transformed to numerous formats for portability. This paper is concerned with solving the problem of the huge processing time taken by the serial video encoding approaches by proposing a hybrid-parallel video encoding technique to speed up the process. In this work, the Joint Scalable Video Model (JSVM 9.19.14) is chosen as the basic serial video encoding algorithm for building different parallel video encoding architectures. The proposed technique exploits the triple-step nature of JSVM and intelligently determines the best task organization to achieve speedup and increase the efficiency on a cluster computing platform. Moreover, a dynamic load sharing scheme is proposed to redistribute load among different machines for additional parallelism. The remarkable feature of our approach is that, both the granularity of load partitioning among the cluster machines and all the associated overheads are considered. The experimental results are applied on a compact library of 160 mp4 encoded videos and two other bench mark datasets. The results proves a significant improvement in performance in comparison to the sequential version; which ranges from 64.2% to 95.3%, for a cluster with a number of machines ranging from 2 to 20 respectively.
C1 [Elkabbany, Ghada F.] Elect Res Inst, Informat Res Dept, Cairo, Egypt.
   [Moussa, Mona M.] Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI);
   Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI)
RP Moussa, MM (corresponding author), Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
EM mona.moussa@gmail.com
OI moussa, mona/0000-0002-3647-1993
CR ABOALMAALY M, 2013, INT J ADVANCEMENTS C, V5
   Ahmad I, 2002, PARALLEL COMPUT, V28, P1039, DOI 10.1016/S0167-8191(02)00100-X
   BARNEY B, PARALLEL COMPUTING T
   Bodasingi N, 2017, J ENG-JOE, P1
   Cui YS, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141855011X
   CZECH ZJ, 2017, INTRO PARALLEL COMPU
   DAYANAND M, 2014, INT J ADV RES, V4, P659
   Dhakal S, 2007, IEEE T PARALL DISTR, V18, P485, DOI 10.1109/TPDS.2007.1007
   EKABBANY G, 2007, THESIS
   El-Rewini H., 2005, ADV COMPUTER ARCHITE, V42
   ERIC A, 2017, CHAPMAN HALL COMPUTA
   FAROUK H, 2018, 15269 STDF
   Foster I, 1995, DESIGNING BUILDING P
   Franche J-F, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P3034, DOI 10.1109/CECNet.2012.6202018
   GERBER R, 2009, OPTIMIZING VIDEO ENC
   Hennessy John L, 2011, Computer Architecture: A Quantitative Approach
   HSU TH, 2015, 4 INT C INF APPL ICI, P89
   KAUR K, 2014, INT J ADV RES COMPUT, V3, P5730
   Khaldi Dounia, 2013, Languages and Compilers for Parallel Computing. 25th International Workshop (LCPC 2012). Revised Selected Papers, P174, DOI 10.1007/978-3-642-37658-0_12
   KIM BG, 2011, INT J SOFT COMPUT, V6, P102
   Konstantopoulos C, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1038-z
   Kumar R., 2015, International Journal of Modern Computer Science and Applications, V3, P42
   LAN Z, 2002, SCI PROGRAMMING-NETH, V10, P319
   Li P, 2005, IEEE T CIRC SYST VID, V15, P1098, DOI 10.1109/TCSVT.2005.852627
   Lin XH, 2015, IEEE I C EMBED SOFTW, P871, DOI 10.1109/HPCC-CSS-ICESS.2015.33
   Liu WY, 2018, INT C PAR DISTRIB SY, P307, DOI [10.1109/PADSW.2018.8644865, 10.1109/ICPADS.2018.00049]
   Oh SM, 2011, PROC CVPR IEEE
   Qian DX, 2017, CHIN CONTR CONF, P9900, DOI 10.23919/ChiCC.2017.8028936
   Sit HY, 2004, I-SPAN 2004: 7TH INTERNATIONAL SYMPOSIUM ON PARALLEL ARCHITECTURES, ALGORITHMS AND NETWORKS, PROCEEDINGS, P415
   Sivasubramaniam A, 1999, IEEE T PARALL DISTR, V10, P193, DOI 10.1109/71.755819
   Su HY, 2014, SCI WORLD J, DOI 10.1155/2014/716020
   Trobec R., 2018, INTRO PARALLEL COMPU, DOI DOI 10.1007/978-3-319-98833-7.594,596
   Usman M, 2017, INT J EDUC RES INNOV, P1
   Wilkinson B, 1999, PARALLEL PROGRAMMING
   Xu C., 1997, Load Balancing in Parallel Computers: Theory and Practice
   Zhao Z., 2010, THESIS
   Zomaya AY, 2001, IEEE T PARALL DISTR, V12, P899, DOI 10.1109/71.954620
   2018, JSVM REFERENCE SOFTW
NR 38
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17427
EP 17444
DI 10.1007/s11042-020-08717-9
EA FEB 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516251700003
DA 2024-07-18
ER

PT J
AU Gutub, A
   AlKhodaidi, T
AF Gutub, Adnan
   AlKhodaidi, Taghreed
TI Smart expansion of target key for more handlers to access multimedia
   counting-based secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Counting-based secret sharing; Information security; Key management;
   Shares generation; Secret reconstruction; Target key expansion
ID SCHEMES
AB The secret sharing scheme is a data security tool to provide safe reliability and robustness for multi-user authentication systems. This work focus on expanding counting-based secret sharing technique to generate more shares for more handlers' services considering security as well as simple and fast computation. The research considers resolving some originally published imperfections in the share's generation phase proposing new smart expansion models validated to be optimized practical and efficient. We proposed seven possible models to expand the number of participants for applicable share's keys generated from the target key. The smart security randomness of the shares and target keys adjusted were all analyzed to select the best choice based on consistency randomness test. The study further used standard simulations applied on two different applicable multimedia target keys sizes of 16-bits and 64-bits showing attractive remarks pointing for further research improvements to continue. The improved smart system has been analyzed according to distortion security and capacity parameters showing attractive contributions.
C1 [Gutub, Adnan] Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
   [AlKhodaidi, Taghreed] Umm Al Qura Univ, Comp Sci Dept Al Qunfudhah, Mecca, Saudi Arabia.
C3 Umm Al Qura University; Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
EM aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016; Alkhodaidi, Taghreed/AAH-2964-2020
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X; Alkhodaidi,
   Taghreed/0000-0001-5366-3295
CR Al Mahmoud Q, 2013, IET INFORM SECUR, V7, P312, DOI 10.1049/iet-ifs.2012.0366
   Al-Juaid N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0875-8
   Al-Qurashi A, 2018, RELIABLE SECRET KEY, V8
   Alaseri K., 2018, IJRDO J COMPUTER SCI, V4, P1
   [Anonymous], 2010, NIST SPECIAL PUBLICA
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Beimel Amos, 2011, Coding and Cryptology. Proceedings of the Third International Workshop, IWCC 2011, P11, DOI 10.1007/978-3-642-20901-7_2
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Blundo C, 1996, THEOR COMPUT SCI, V165, P407, DOI 10.1016/0304-3975(96)00003-5
   Blundo C., 1993, STACS 93. 10th Annual Symposium on Theoretical Aspects of Computer Science, P692
   Desmedt Y., 1995, ADV CRYPTOLOGY ASIAC, P19
   Di Crescenzo G, 2003, THEOR COMPUT SCI, V295, P123, DOI 10.1016/S0304-3975(02)00399-7
   Dosanjh K, 2006, ARTHURIANA, V16, P63, DOI 10.1353/art.2006.0085
   Gutub A, J ENG RES JER
   Gutub A, MERGING GF P ELLIPTI, P1
   Gutub A.A.-A., 2006, International Arab Journal of Information Technology (IAJIT), V3, P342
   Gutub A, 2020, ARAB J SCI ENG, V45, P2433, DOI 10.1007/s13369-019-04010-6
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P7951, DOI 10.1007/s11042-019-08427-x
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2021, J KING SAUD UNIV-COM, V33, P1108, DOI 10.1016/j.jksuci.2019.06.014
   Herzberg A, 1995, LECT NOTES COMPUT SC, V963, P339
   Ito M., 1989, Electronics and Communications in Japan, Part 3 (Fundamental Electronic Science), V72, P56, DOI 10.1002/ecjc.4430720906
   Kaya KG, 2009, THESIS
   Li Bai, 2009, International Journal of Security and Networks, V4, P201, DOI 10.1504/IJSN.2009.028667
   Masucci B, 2006, DESIGN CODE CRYPTOGR, V39, P89, DOI 10.1007/s10623-005-2761-1
   MCELIECE RJ, 1981, COMMUN ACM, V24, P583, DOI 10.1145/358746.358762
   Nojoumian Mehrdad, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P269, DOI 10.1109/PST.2016.7906973
   Ogata W, 1996, LECT NOTES COMPUT SC, V1070, P200
   Ostrovsky R., 1991, Proceedings of the Tenth Annual ACM Symposium on Principles of Distributed Computing, P51, DOI 10.1145/112600.112605
   Pang LJ, 2005, APPL MATH COMPUT, V167, P840, DOI 10.1016/j.amc.2004.06.120
   Raja Koti B, 2016, SECRET IMAGE SHARING, V6, P138
   Sarrna K.S., 2013, Research Journal of Information Technology, V5, P67
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Tompa M., 1988, Journal of Cryptology, V1, P133
   Van Son R, 2011, MEASURE PASSWORD STR
   Wan S, 2017, INT J DIGIT CRIME
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang K, 2009, P INT COMP SOFTW APP, P400, DOI 10.1109/COMPSAC.2009.60
   Wang M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL ASIA CONFERENCE ON INDUSTRIAL ENGINEERING AND MANAGEMENT INNOVATION: CORE THEORY AND APPLICATIONS OF INDUSTRIAL ENGINEERING, VOL 1, P261, DOI 10.2991/978-94-6239-148-2_26
   Xu J, 2017, 2017 INTERNATIONAL CONFERENCE ON GREEN INFORMATICS (ICGI), P34, DOI 10.1109/ICGI.2017.28
   Yan XH, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY, IEEE 3RD INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING, (HPSC) AND 2ND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P86, DOI 10.1109/BigDataSecurity.2017.19
NR 42
TC 19
Z9 19
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17373
EP 17401
DI 10.1007/s11042-020-08695-y
EA FEB 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000520065200002
DA 2024-07-18
ER

PT J
AU Lee, SH
   Jang, WD
   Kim, CS
AF Lee, Se-Ho
   Jang, Won-Dong
   Kim, Chang-Su
TI Superpixels for image and video processing based on proximity-weighted
   patch matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixel; Temporal superpixel; Image segmentation; Saliency detection;
   Image processing; Video processing
ID SALIENCY DETECTION
AB In this paper, a temporal superpixel algorithm using proximity-weighted patch matching (PPM) is proposed to yield temporally consistent superpixels for image and video processing. PPM estimates the motion vector of a superpixel robustly, by considering the patch matching distances of neighboring superpixels as well as the superpixel itself. In each frame, we initialize superpixels by transferring the superpixel labels of the previous frame using PPM motion vectors. Then, we update the superpixel labels of boundary pixels by minimizing a cost function, which is composed of feature distance, compactness, contour, and temporal consistency terms. Finally, we carry out superpixel splitting, merging, and relabeling to regularize superpixel sizes and correct inaccurate labels. Extensive experimental results confirm that the proposed algorithm outperforms the state-of-the-art conventional algorithms significantly. Also, it is demonstrated that the proposed algorithm can be applied to video object segmentation and video saliency detection tasks.
C1 [Lee, Se-Ho; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
   [Jang, Won-Dong] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
C3 Korea University; Harvard University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
EM seholee@mcl.korea.ac.kr; wdjang@seas.harvard.edu; changsukim@korea.ac.kr
OI Kim, Chang-Su/0000-0002-4276-1831
FU Signal Intelligence Research Center; National Research Foundation of
   Korea (NRF) - Korea government (MSIP) [NRF-2018R1A2B3003896]
FX This work was supported by the research fund of Signal Intelligence
   Research Center supervised by Defense Acquisition Program Administration
   and Agency for Defense Development of Korea, and by the National
   Research Foundation of Korea (NRF) grant funded by the Korea government
   (MSIP) (No. NRF-2018R1A2B3003896).
CR Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akamine K, 2012, COMPUT J, V55, P3, DOI 10.1093/comjnl/bxq075
   [Anonymous], 2017, 2017 IEEE C COMP VIS
   [Anonymous], 2008, 2008 IEEE C COMP VIS
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], BMVC
   Ban ZH, 2018, IEEE T IMAGE PROCESS, V27, P4105, DOI 10.1109/TIP.2018.2836306
   Bao LC, 2014, PROC CVPR IEEE, P3534, DOI 10.1109/CVPR.2014.452
   BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P1003, DOI 10.1016/0167-8655(94)90032-9
   Chang J, 2013, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2013.267
   Chen CLZ, 2018, IEEE T MULTIMEDIA, V20, P3324, DOI 10.1109/TMM.2018.2839523
   Chen CLZ, 2018, IEEE SIGNAL PROC LET, V25, P154, DOI 10.1109/LSP.2017.2775212
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen XP, 2010, ICIM 2010: PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON INDUSTRIAL MANAGEMENT, P14
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808
   Fu HZ, 2014, IEEE T MULTIMEDIA, V16, P1165, DOI 10.1109/TMM.2014.2305571
   Hu YL, 2018, IMAGE VISION COMPUT, V70, P1, DOI 10.1016/j.imavis.2017.12.001
   Hu YL, 2016, PROC CVPR IEEE, P5704, DOI 10.1109/CVPR.2016.615
   Jampani V., 2018, ECCV
   Jang W.-D., 2016, BMVC
   Jang WD, 2016, PROC CVPR IEEE, P696, DOI 10.1109/CVPR.2016.82
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Koh Y. J., 2018, ECCV
   Lee S.-H., 2017, CVPR
   Lee SH, 2018, IEEE ACCESS, V6, P54982, DOI 10.1109/ACCESS.2018.2872735
   Lee SH, 2017, PROC CVPR IEEE, P5863, DOI 10.1109/CVPR.2017.621
   Lee SH, 2017, ICCV, P2947
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2016, LECT NOTES COMPUT SC, V9905, P144, DOI 10.1007/978-3-319-46448-0_9
   Liu YJ, 2018, IEEE T PATTERN ANAL, V40, P653, DOI 10.1109/TPAMI.2017.2686857
   Liu YJ, 2016, PROC CVPR IEEE, P651, DOI 10.1109/CVPR.2016.77
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Reso M, 2019, IEEE T PATTERN ANAL, V41, P1441, DOI 10.1109/TPAMI.2018.2832628
   Reso M, 2013, IEEE I CONF COMP VIS, P385, DOI 10.1109/ICCV.2013.55
   Schick A, 2012, INT C PATT RECOG, P930
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Tang YB, 2016, LECT NOTES COMPUT SC, V9912, P809, DOI 10.1007/978-3-319-46484-8_49
   Van den Bergh M, 2013, IEEE I CONF COMP VIS, P377, DOI 10.1109/ICCV.2013.54
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Vargas-Muñoz JE, 2019, IEEE T IMAGE PROCESS, V28, P3477, DOI 10.1109/TIP.2019.2897941
   Wang H., 2019, IEEE T CIRCUITS SYST
   Wei X, 2018, IEEE T IMAGE PROCESS, V27, P4838, DOI 10.1109/TIP.2018.2836300
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Xiao XL, 2018, IEEE T IMAGE PROCESS, V27, P2883, DOI 10.1109/TIP.2018.2810541
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45
   Xu CL, 2012, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2012.6247802
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yao J, 2015, PROC CVPR IEEE, P2947, DOI 10.1109/CVPR.2015.7298913
   Yeo D., 2017, PROC IEEE C COMPUT V, P1812
   Zeng G, 2011, IEEE I CONF COMP VIS, P447, DOI 10.1109/ICCV.2011.6126274
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 59
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13811
EP 13839
DI 10.1007/s11042-019-08438-8
EA FEB 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515805300004
DA 2024-07-18
ER

PT J
AU Alavesa, P
   Pakanen, M
   Ojala, T
   Pouke, M
   Kukka, H
   Samodelkin, A
   Voroshilov, A
   Abdellatif, M
AF Alavesa, Paula
   Pakanen, Minna
   Ojala, Timo
   Pouke, Math
   Kukka, Hannu
   Samodelkin, Alexander
   Voroshilov, Alexander
   Abdellatif, Mohamed
TI Embedding virtual environments into the physical world: memorability and
   co-presence in the context of pervasive location-based games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location based mobile games; Pervasive games; Co-presence; Memorability;
   Player experience
ID HYBRID REALITY; NAVIGATION; MEMORY
AB Realistic 3D virtual environments, such as existing city models, have the potential to be used in pervasive games as a passageway between physical and virtual. Smooth attention displacement and transitions between these two realities are largely unexplored in the context of pervasive gameplay. We conducted two field trials using a pervasive live action role playing game to study the effect moving between the virtual and the physical has on co-presence and memorability. Although differences in co-presence during gameplay were small, they highlight the subtleties in the social structuring of pervasive gameplay. Spatial similarity between the physical and virtual environments made the 3D virtual environments more memorable. We identify two important issues to consider in embedding virtual environments into pervasive games: structuring of social interactions and the spatial realism of the VEs.
C1 [Alavesa, Paula; Pakanen, Minna; Ojala, Timo; Pouke, Math; Abdellatif, Mohamed] Univ Oulu, Ctr Ubiquitous Comp, POB 4500, FI-90014 Oulu, Finland.
   [Pakanen, Minna] Dept Engn, Sociotech Design, Inge Lehmann Gade 10, DK-8000 Aarhus C, Denmark.
   [Kukka, Hannu] Boogie Software Ltd, Kasarmintie 15, Oulu 90130, Finland.
   [Samodelkin, Alexander] Adminotech Ltd, Hallituskatu 13, Oulu 90100, Finland.
   [Voroshilov, Alexander] Elektrobit Automot Finland Ltd, Elelctroniikkatie 13, Oulu 90590, Finland.
C3 University of Oulu
RP Alavesa, P (corresponding author), Univ Oulu, Ctr Ubiquitous Comp, POB 4500, FI-90014 Oulu, Finland.
EM paula.alavesa@oulu.fi; Denmarkmpakanen@eng.au.dk
OI Alavesa, Paula/0000-0003-3546-5150; Pakanen, Minna/0000-0002-0933-9479
CR Alatalo T., 2016, P 21 INT C WEB3D TEC, P95, DOI [DOI 10.1145/2945292.2945305, 10.1145/2945292.2945305]
   Alatalo T, 2017, WEB3D 2017, DOI 10.1145/3055624.3075950
   Alavesa P, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P64, DOI 10.1145/2836041.2836047
   Alavesa P, 2017, INT CONF GAMES VIRTU, P71, DOI 10.1109/VS-GAMES.2017.8055813
   [Anonymous], 2012, Proceedings of the Designing Interactive Systems Conference. DIS'12, DOI [DOI 10.1145/2317956.2318078, 10.1145/2317956.2318078]
   Bakeman R., 2011, SEQUENTIAL ANAL OBSE, DOI DOI 10.1017/CBO9781139017343
   Beaulieu A, 2010, SOC STUD SCI, V40, P453, DOI 10.1177/0306312709359219
   Benford S., 2006, ACM Transactions on Computer-Human Interaction, V13, P100, DOI 10.1145/1143518.1143522
   Biljecki F, 2014, COMPUT ENVIRON URBAN, V48, P1, DOI 10.1016/j.compenvurbsys.2014.05.004
   Brade J, 2017, INT J HUM-COMPUT ST, V101, P76, DOI 10.1016/j.ijhcs.2017.01.004
   BREWER WF, 1981, COGNITIVE PSYCHOL, V13, P207, DOI 10.1016/0010-0285(81)90008-6
   Callon Michel., 2003, TECHNOL SOC, V25, P193, DOI [DOI 10.1016/S0160-791X, DOI 10.1016/S0160-791X(03)00021-6]
   Casanueva J, 2000, SPRING COMP SCI, P85
   Crabtree A., 2004, P SIGCHI C HUMAN FAC, P391, DOI DOI 10.1145/985692.985742
   Csikszentmihalyi M., 1997, Finding flow: the psychology of engagement with everyday life
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Silva ADE, 2008, CRIT STUD MEDIA COMM, V25, P447, DOI 10.1080/15295030802468081
   Silva ADE, 2009, SIMULAT GAMING, V40, P404, DOI 10.1177/1046878108314643
   Fallout 4, 2015, FALL 4
   Farman J., 2013, Mobile interface theory: Embodied space and locative media
   Feiner S., 1993, Sixth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P145, DOI 10.1145/168642.168657
   Fleiss J.L., 2004, Statistical Methods for Rates and Proportions, VThird, P1, DOI [10.1002/0471445428, DOI 10.1002/0471445428]
   Gajadhar BJ, 2008, LECT NOTES COMPUT SC, V5294, P106, DOI 10.1007/978-3-540-88322-7_11
   Geiger Philip, 2014, 10th International Conference on Web Information Systems and Technologies (WEBIST 2014). Proceedings, P383
   Gelernter D.H., 1993, MIRROR WORLDS DAY SO
   Goerger S, 1998, P 16 APPL BEH SCI S
   Goffman Erving, 1963, BEHAV PUBLIC PLACES
   Grand Theft Auto V, 2013, GRAND THEFT AUT V
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hektner J. M., 2007, EXPERIENCE SAMPLING
   Isola Phillip, 2011, Advances in Neural Information Processing Systems (NIPS), V24, P2429, DOI DOI 10.1167/12.9.1082
   Kasapakis V, 2015, J NETW COMPUT APPL, V55, P213, DOI 10.1016/j.jnca.2015.05.009
   Li Z, 2018, 2018 CHI C HUM FACT, pVS12
   Ling N, 2016, MULTIMED TOOLS APPL, V75, P14015, DOI 10.1007/s11042-016-3826-z
   Mania K, 2005, PRESENCE-TELEOP VIRT, V14, P606, DOI 10.1162/105474605774918769
   Montola Marcus., 2009, Pervasive Games: Theory and Design
   Nakamura J., 2009, Handbook of Positive Psychology, V2nd, P194, DOI [DOI 10.1093/OXFORDHB/9780195187243.013.0018, 10.1093/oxfordhb/9780195187243.013.0018]
   Neustaedter C, 2013, PERS UBIQUIT COMPUT, V17, P335, DOI 10.1007/s00779-011-0497-7
   Niantic, 2016, Pokemon go
   Nickerson RC, 2008, INT J MOB COMMUN, V6, P541, DOI 10.1504/IJMC.2008.019321
   Nitsche Micheal., 2008, Video Game Space: Image, Play, and Structure in 3D Game Worlds
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   O'Hara K, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1177
   Paavilainen J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2493, DOI 10.1145/3025453.3025871
   Richardson AE, 1999, MEM COGNITION, V27, P741, DOI 10.3758/BF03211566
   Richardson Ingrid., 2011, CONVERGENCE-US, V17, P419, DOI [DOI 10.1177/1354856511414797, 10.1177/1354856511414797]
   Sakamoto M, 2016, MULTIMED TOOLS APPL, V75, P8289, DOI 10.1007/s11042-015-2751-x
   Samodelkin A, 2016, 15TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2016), P335, DOI 10.1145/3012709.3016066
   Skopik A, 2003, C GRAPH INT GI 03 HA, P67
   Slater M, 2002, PRESENCE-TELEOP VIRT, V11, P435, DOI 10.1162/105474602760204327
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Uden M., 2012, PROGR NEW TRENDS 3D, V1st, P299
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vella K, 2019, GAMES CULT, V14, P583, DOI 10.1177/1555412017719973
   Vinson N.G., 1999, CHI 99, P278, DOI DOI 10.1145/302979.303062
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 57
TC 3
Z9 3
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3285
EP 3309
DI 10.1007/s11042-018-7077-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700012
OA hybrid
DA 2024-07-18
ER

PT J
AU Brindha, D
   Nagarajan, N
AF Brindha, D.
   Nagarajan, N.
TI An efficient automatic segmentation of spinal cord in MRI images using
   interactive random walker (RW) with artificial bee colony (ABC)
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Central nervous system (CNS); Spinal cord segmentation; Magnetic
   resonance images (MRI); Random-walk solvers (RW); Artificial bee Colony
   (ABC); Probabilistic boosting tree (PBT); Support vector machine (SVM)
ID CT
AB Spinal cord Magnetic Resonance Images (MRI) have a remarkable role to play in the learning of neurological diseases such as Multiple Sclerosis (MS) affecting the Central Nervous System (CNS), in which spinal cord atrophy can help in the measurement of disease advancement and the changes in shape. Spinal cord segmentation plays a significant part in analyzing the neurological disease. In this paper here, an approach on the basis of the automatic spinal cord segmentation is proposed. This automatic technique presented performs the segmentation of the spinal cord with the help of MRI datasets. This new segmentation follows the interactive Random-Walk solvers (RW) along with Artificial Bee Colony (ABC) optimization algorithm in order to be an entirely automatic flow pipeline. The initialization of the automatic segmentation pipeline is then done with a reliable voxel-wise classification employing features similar to Haar and supervised machine learning technique i.e. Probabilistic Boosting Tree (PBT) along with Support Vector Machine (SVM) so named as PBTSVM. Thereafter, the extraction of the refinement topology of the spinal cord is then done from the temporary segmentation and it is fine-tuned for the further next random-walk solver with ABC. The refined topology results in the spinal cord's boundary conditions from the MRI that permits the following random-walk solver with ABC for improving the segmentation result. The experimental outcomes of the novel segmentation approach depending on the MRI images indicate that the system proposed PBT-SVM algorithm provides better accuracy when compared to the other existing Active Contour Model, Multi-Resolution Propagation algorithms. Experimentation results of the proposed PBT-SVM algorithm produces higher accuracy results of 93% which is 2.5 and 3.233% higher when compared to Active Contour Model and Multi-Resolution Propagation methods respectively.
C1 [Brindha, D.; Nagarajan, N.] Coimbatore Inst Engn & Technol, ECE Dept, Coimbatore, Tamil Nadu, India.
RP Brindha, D (corresponding author), Coimbatore Inst Engn & Technol, ECE Dept, Coimbatore, Tamil Nadu, India.
EM brindhadciet@gmail.com
RI D, BRINDHA/GRY-0424-2022
OI D, BRINDHA/0000-0003-3127-0196
CR Alizadeh Mahdi, 2015, 2015 41st Annual Northeast Biomedical Engineering Conference (NEBEC). Proceedings, P1, DOI 10.1109/NEBEC.2015.7117146
   [Anonymous], 2003, P ADV NEUR INF PROC
   [Anonymous], 2012, MICCAI GRAND CHALLEN
   [Anonymous], 2014, OPEN J COMMUN SOFTWA, DOI DOI 10.15764/CS.2014.01001
   Archip N, 2002, IEEE T MED IMAGING, V21, P1504, DOI 10.1109/TMI.2002.806578
   Burnett SSC, 2004, MED PHYS, V31, P251, DOI 10.1118/1.1634483
   Cadotte A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139323
   Chen M, 2013, NEUROIMAGE, V83, P1051, DOI 10.1016/j.neuroimage.2013.07.060
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   De Leener B, 2015, IEEE T MED IMAGING, V34, P1705, DOI 10.1109/TMI.2015.2437192
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Egger J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031064
   Feder M, 1995, PROCEEDINGS 1995 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, P233, DOI 10.1109/ISIT.1995.535748
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Kalkers NF, 2002, MULT SCLER, V8, P532, DOI 10.1191/1352458502ms849xx
   Karangelis Grigorios., 2002, BILDVERARBEITUNG FR, P370, DOI DOI 10.1007/978-3-642-55983-9_87
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kawahara JG, 2013, THESIS
   Kelm BM, 2013, MED IMAGE ANAL, V17, P1283, DOI 10.1016/j.media.2012.09.007
   Koh J, 2011, I S BIOMED IMAGING, P1467, DOI 10.1109/ISBI.2011.5872677
   Lao ZQ, 2006, I S BIOMED IMAGING, P307
   Lin X, 2004, J NEUROIMAGING, V14, p20S, DOI 10.1111/j.1552-6569.2004.tb00275.x
   McIntosh C, 2006, LECT NOTES COMPUT SC, V4190, P808
   Militzer A, 2009, SPIE MED IMAGING, P725946
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Real P, 2013, J MATH IMAGING VIS, V47, P1, DOI 10.1007/s10851-013-0451-6
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Tu ZW, 2005, IEEE I CONF COMP VIS, P1589
   Tu ZW, 2006, LECT NOTES COMPUT SC, V3953, P436
   van Opbroek AG., 2013, Automated brain-tissue segmentation by multi-feature SVM classification
   Yao JH, 2006, I S BIOMED IMAGING, P390
NR 32
TC 4
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3623
EP 3644
DI 10.1007/s11042-018-6331-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700028
DA 2024-07-18
ER

PT J
AU Jiang, LF
   Ji, JS
   Zhong, WL
   Zhang, T
   Xiong, HL
AF Jiang, Linfeng
   Ji, Jinsheng
   Zhong, Weilin
   Zhang, Tao
   Xiong, Huilin
TI Exploiting context based on CNN and coding representations for
   pedestrian co-detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Conditional random field; Context modeling; Object
   co-detection; Pedestrian detection
ID CONVOLUTIONAL NETWORKS; OBJECT DETECTION; RANDOM-FIELDS; SEGMENTATION;
   HISTOGRAMS
AB The exploitation of contextual information among multiple images has been proven significant to improve detection performance by object co-detection methods. In this paper, we propose a pedestrian co-detection method that combines the strengths of convolutional neural networks (CNNs) and locality-constrained linear coding (LLC) in a unified conditional random field (CRF) model. First, we obtain object candidates by using a region proposal network (RPN) in Faster R-CNN. Second, we build a fully connected CRF that consists of unary potentials on individual object candidates and two types of pairwise potentials on pairs of object candidates. The unary potential is computed independently for each object candidate by using the baseline method. The pairwise potentials consist of multiscale CNN and LLC representation-based potentials, which contribute to the capturing of relationships among object candidates in all the test images. Finally, we jointly predict the category labels of all the object candidates through the mean field inference in the CRF. We evaluated the proposed method on the ETH, Caltech, and INRIA Pedestrian datasets. The experimental results demonstrate the effectiveness of the proposed method as compared to the baseline method.
C1 [Jiang, Linfeng; Ji, Jinsheng; Zhong, Weilin; Zhang, Tao; Xiong, Huilin] Shanghai Jiao Tong Univ, Dept Automat, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Jiang, LF; Xiong, HL (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM fine0228@sjtu.edu.cn; jinshengji@sjtu.edu.cn; zhongweilin@sjtu.edu.cn;
   sjtu-zt@sjtu.edu.cn; hlxiong@sjtu.edu.cn
RI huang, libo/JMB-4345-2023; JI, JINSHENG/KHW-3948-2024
OI JI, JINSHENG/0000-0002-5360-919X
CR Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2018, ADV CIVIL ENG
   [Anonymous], 2013, PMLR
   Arnab A, 2018, IEEE SIGNAL PROC MAG, V35, P37, DOI 10.1109/MSP.2017.2762355
   Arnab A, 2016, LECT NOTES COMPUT SC, V9906, P524, DOI 10.1007/978-3-319-46475-6_33
   Bao SY, 2012, LECT NOTES COMPUT SC, V7572, P86, DOI 10.1007/978-3-642-33718-5_7
   Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Benenson R, 2013, PROC CVPR IEEE, P3666, DOI 10.1109/CVPR.2013.470
   Brazil G, 2017, IEEE I CONF COMP VIS, P4960, DOI 10.1109/ICCV.2017.530
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Q, 2015, IEEE T PATTERN ANAL, V37, P13, DOI 10.1109/TPAMI.2014.2343217
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Fu KR, 2017, IEEE T MULTIMEDIA, V19, P1531, DOI 10.1109/TMM.2017.2679898
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Guo X, 2013, PROC CVPR IEEE, P3206, DOI 10.1109/CVPR.2013.412
   Hayder Z, 2015, IEEE I CONF COMP VIS, P2632, DOI 10.1109/ICCV.2015.302
   Hayder Z, 2014, LECT NOTES COMPUT SC, V8691, P330, DOI 10.1007/978-3-319-10578-9_22
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoffman J., 2014, NIPS (News Physiol. Sci.), P3536
   Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Marín J, 2013, IEEE I CONF COMP VIS, P2592, DOI 10.1109/ICCV.2013.322
   Nam W., 2014, P 27 INT C NEURAL IN, V27
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Rui T, 2017, MULTIMED TOOLS APPL, V76, P25079, DOI 10.1007/s11042-017-4837-0
   Shen CH, 2013, INT J COMPUT VISION, V103, P326, DOI 10.1007/s11263-013-0608-1
   Shi JP, 2013, IEEE I CONF COMP VIS, P2096, DOI 10.1109/ICCV.2013.262
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Toca C., 2015, BMVC
   Toyoda T, 2008, IEEE T PATTERN ANAL, V30, P1483, DOI 10.1109/TPAMI.2008.105
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vineet V, 2014, INT J COMPUT VISION, V110, P290, DOI 10.1007/s11263-014-0708-6
   Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang Shanshan., 2015, CVPR, V1, P4
NR 54
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4277
EP 4296
DI 10.1007/s11042-018-6806-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500003
DA 2024-07-18
ER

PT J
AU Liu, YL
   Zhang, HJ
AF Liu, Yali
   Zhang, Huijie
TI Three-dimensional campus 360-degree video encoding VR technology based
   on OpenGL
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Virtual campus; Roam system; Scene design; X3D
ID APOPTOSIS
AB Virtual campus is the concrete application of virtual reality technology in digital campus. Virtual campus can reproduce the real campus scene, which can make the people who have no chance to visit the site have the immersive experience. It can also build a 3D virtual university on this basis and then provide corresponding online education, with high application value. In this paper, the virtual reality technology and X3D technology are fully introduced, and the technical problems involved in virtual campus' roaming system are studied in details. It takes a domestic university as object, and mainly uses X3D technology with various techniques to design the multiple scenes in the campus, build the three-dimensional model of office building, library, science and technology building, and so on; then after the overall integration, it finally realizes a virtual campus roaming system.
C1 [Liu, Yali] Inner Mongolia Elect Informat Vocat Tech Coll, Dept Digital Media Arts, Hohhot 010070, Inner Mongolia, Peoples R China.
   [Zhang, Huijie] Tianjin Acad Tradit Chinese Med Affiliated Hosp, Dept Pharm, Tianjin 300120, Peoples R China.
RP Liu, YL (corresponding author), Inner Mongolia Elect Informat Vocat Tech Coll, Dept Digital Media Arts, Hohhot 010070, Inner Mongolia, Peoples R China.
EM taoshenrou@163.com
RI ZHANG, hui jie/HTN-1690-2023; Zhang, Hw/HPD-4999-2023; Zhang,
   Hui/HHN-8494-2022; zhang, hui/GXH-6098-2022
CR Abdelhamid DS, 2015, BIOMATERIALS, V53, P32, DOI 10.1016/j.biomaterials.2015.02.038
   Arunkumar N, 2016, J MED IMAG HEALTH IN, V6, P724, DOI 10.1166/jmihi.2016.1736
   Arunkumar N, 2011, P 3 INT C TRENDZ INF, P133
   Chen YZ, 2016, OPT LETT, V41, P2306, DOI 10.1364/OL.41.002306
   Du XL, 2017, CELL PHYSIOL BIOCHEM, V43, P568, DOI 10.1159/000480529
   Du XL, 2017, J CELL PHYSIOL, V232, P3296, DOI 10.1002/jcp.25773
   Hamza R, 2018, IEEE ACCESS, V6, P60160, DOI 10.1109/ACCESS.2017.2762405
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Pan WS, 2013, APPL MATH INFORM SCI, V7, P675, DOI 10.12785/amis/070235
   Song YX, 2016, J DAIRY SCI, V99, P9184, DOI 10.3168/jds.2016-11219
   Stephygraph LR, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P596, DOI 10.1109/ICSTM.2015.7225484
   Zhang YY, 2016, J COLLOID INTERF SCI, V482, P19, DOI 10.1016/j.jcis.2016.07.013
   Zhang YY, 2016, BIOMATERIALS, V84, P230, DOI 10.1016/j.biomaterials.2015.12.028
   Zhao YJ, 2017, IEEE T INSTRUM MEAS, V66, P1789, DOI 10.1109/TIM.2017.2665983
NR 14
TC 4
Z9 4
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5099
EP 5107
DI 10.1007/s11042-018-6306-9
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500049
DA 2024-07-18
ER

PT J
AU Shao, HR
   Li, J
   Wan, WB
   Zhang, HX
   Sun, JD
AF Shao, Huiru
   Li, Jing
   Wan, Wenbo
   Zhang, Huaxiang
   Sun, Jiande
TI Saccadic trajectory-based identity authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saccadic trajectory; Identity authentication; Wavelet packet transform;
   Features selection
ID EYE-MOVEMENTS
AB The saccadic trajectory is generated by extra-ocular muscles in the eyes, which is a complex mechanism related to brain-driven neural signal. The saccadic trajectory has the characteristics of non-reproducibility and non-contact. In this paper, we propose a saccadic trajectory-based identity authentication method considering that saccadic trajectory can be used as a behavior-based biometric. In this method, we adopt Velocity-Threshold (I-VT) algorithm to extract saccadic trajectories from the whole eye movement data, extract features via wavelet packet transform and authenticate the identity via classifying these features by SVM. In this paper, we verify the proposed method on EMDBv1.0 dataset for horizontal eye movements. We select one subject to be the host and randomly choose another 50 subjects from the remaining 58 subjects as the attackers. We achieve the best performance via optimizing feature selection and the parameter of SVM. The experiment results show that the average accuracy for accepting the host can reach 98.09%, and the average accuracy for rejecting the attackers can reach 99.55%. It demonstrates that the saccadic trajectory-based identity authentication is promising in information security.
C1 [Shao, Huiru; Wan, Wenbo; Zhang, Huaxiang; Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Li, Jing] Shandong Management Univ, Sch Mech & Elect Engn, Jinan, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Management University
RP Wan, WB; Sun, JD (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM wanwenbo@sdnu.edu.cn; jiandesun@hotmail.com
RI Zhang, Yuchen/GYI-8858-2022
CR Bednarik R, 2005, LECT NOTES COMPUT SC, V3540, P780
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Coifman RR, 1992, ENTROPY BASED ALGORI
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Du J, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/4685187
   Kasprowski P, 2004, LECT NOTES COMPUT SC, V3087, P248
   Kinnunen T, 2010, P S EYE TRACK RES AP, P187
   Komogortsev O. V., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P413, DOI 10.1109/ICB.2012.6199786
   Komogortsev Oleg, 2010, P 2010 S EYE TRACK R, P57, DOI [DOI 10.1145/1743666.1743679, 10.1145/1743666.1743679]
   Komogortsev OV, 2010, IEEE T BIO-MED ENG, V57, P2635, DOI 10.1109/TBME.2010.2057429
   Leigh R. John, 2015, NEUROLOGY EYE MOVEME, P1
   Li C, 2015, IRIS RECOGNITION BAS
   Liang Y, 2012, INT CONF FRONT HAND, P728, DOI 10.1109/ICFHR.2012.220
   Luo MN, 2018, IEEE T NEUR NET LEAR, V29, P944, DOI 10.1109/TNNLS.2017.2650978
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Mukhopadhyay S, 2018, MACH LEARN, V107, P313, DOI 10.1007/s10994-017-5649-1
   Roy KC, 2008, WORLD SCI STUD INT E, V5, P1
   Silver D.L., 2006, P IC, P344
   Wang YB, 2009, J TIANJIN U SCI TECH
   Wang Zhan-shan, 2018, Huanjing Kexue, V39, P1, DOI 10.13227/j.hjkx.201705276
   Zhang Y, 2012, BIOMETRIC VERIFICATI, P85
NR 21
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4891
EP 4905
DI 10.1007/s11042-018-6816-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500036
DA 2024-07-18
ER

PT J
AU Vadivu, PB
   Sundararajan, J
AF Vadivu, P. Balashanmuga
   Sundararajan, J.
TI RETRACTED: EEG signal based brain activity monitoring using adaptive
   wavelet transform and activity learning neural vector (ALNV)
   classification technique (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Electroencephalogram (EEG); Wavelet transform filtering; Activity
   learning neural vector; Matlab
ID DESIGN; SYSTEM
AB The brain produces weak electrical signals that can be measured from the skull. There are different kind of techniques are accessible for brain monitoring system they are near-infrared spectroscopy, Functional MRI, Positron emission tomography, Magnetic resonance imaging, and Electroencephalography (EEG). The additional benefits of low system cost, efficient operation with low noninvasiveness the Electroenphalography (EEG) is mostly used in brain activity based signal recognition system. The EEG signal is also helps to evaluate the accurate signal from the organ. The proposed aims to recognize the brain activity from electroencephalography (EEG) signal using Adaptive Wavelet Transform and Activity Learning Neural Vector (ALNV) Classification techniques. The recognize the brain activity condition of the subjects under test with it feature are extracted using adaptive wavelet transform and its classified using ANLV classification technique. The performance of the proposed techniques were evaluated using simulated EEG signal under variation of different parameters such as the number of nominated regions, the signal to noise ratio, and the number of electrodes using MATLAB simulink environment. Under the test of different brain activity EEG signals in Matlab simulation are proposed adaptive wavelet transform and Activity Learning Neural Vector (ALNV) classification proves that the accuracy of those techniques is more than 95%.
C1 [Vadivu, P. Balashanmuga] Mahendra Engn Coll, Dept Elect & Commun Engn, Namakkal, India.
   [Sundararajan, J.] Pavai Coll Technol, Namakkal, India.
C3 Mahendra Engineering College, Namakkal
RP Vadivu, PB (corresponding author), Mahendra Engn Coll, Dept Elect & Commun Engn, Namakkal, India.
EM balasathishsalem@gmail.com
RI Jayapal, Sundararajan/IVV-5173-2023
OI Jayapal, Sundararajan/0009-0009-4375-8843; , Dr.BALASHANMUGA VADIVU
   P/0000-0002-7128-0383
CR Aydin A, 2017, 2017 MED TECHN NAT C, P1
   Azar AT, 2014, CLASSIFICATION EEG B, DOI [10.1007/978-3-319-00467-9_9, DOI 10.1007/978-3-319-00467-9_9]
   Fu YF, 2017, IEEE T NEUR SYS REH, V25, P1641, DOI 10.1109/TNSRE.2016.2627809
   Hosen B, 2017, IEEE T PLASMA SCI, V45, P3316, DOI 10.1109/TPS.2017.2766167
   Huang S, 2018, IEEE T BIO-MED ENG, V65, P1272, DOI 10.1109/TBME.2017.2713647
   Hutka S, 2016, J COGNITIVE NEUROSCI, V28, P2044, DOI 10.1162/jocn_a_01021
   Jayaprakasam S, 2017, IEEE T ANTENN PROPAG, V65, P2348, DOI 10.1109/TAP.2017.2684187
   Jiang YZ, 2017, IEEE T NEUR SYS REH, V25, P2270, DOI 10.1109/TNSRE.2017.2748388
   Karimi-Bidhendi A, 2017, IEEE T BIOMED CIRC S, V11, P1111, DOI 10.1109/TBCAS.2017.2723607
   Ketenci S., 2017, 2017 MEDICAL TECHNOL, P1
   Kopel R, 2017, IEEE T BIO-MED ENG, V64, P1228, DOI 10.1109/TBME.2016.2598818
   Lee CWL, 2015, IEEE T MICROW THEORY, V63, P2060, DOI 10.1109/TMTT.2015.2421491
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Lim GH, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), P336, DOI 10.1109/MFI.2017.8170451
   Lin CT, 2017, IEEE SYST MAN CYBERN, V3, P16, DOI 10.1109/MSMC.2017.2702378
   Liu XL, 2017, IEEE T BIOMED CIRC S, V11, P729, DOI 10.1109/TBCAS.2016.2622738
   Maddirala AK, 2018, IEEE T INSTRUM MEAS, V67, P382, DOI 10.1109/TIM.2017.2775358
   Manolova A, 2016, IEEE INT BLACK SEA C
   Nayak DR, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0867-4
   Rajeswari J., 2017, Informatics in Medicine Unlocked, V8, P13, DOI 10.1016/j.imu.2017.04.002
   Suk HI, 2013, IEEE T PATTERN ANAL, V35, P286, DOI 10.1109/TPAMI.2012.69
   Veeramuthu A., 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P1545, DOI 10.1109/ICCSP.2014.6950108
   Wang HY, 2016, J COGNITIVE NEUROSCI, V28, P971, DOI 10.1162/jocn_a_00947
   Wong SY, 2015, IEEE T NEUR NET LEAR, V26, P1417, DOI 10.1109/TNNLS.2014.2341655
   Zanini P, 2018, IEEE T BIO-MED ENG, V65, P1107, DOI 10.1109/TBME.2017.2742541
NR 25
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4199
EP 4215
DI 10.1007/s11042-019-7718-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700062
DA 2024-07-18
ER

PT J
AU Visu, P
   Sivakumar, N
   Kumaresan, P
   Babu, SY
   Ramesh, PS
AF Visu, P.
   Sivakumar, Nagarajan
   Kumaresan, P.
   Babu, Sundaresan Yokesh
   Ramesh, P. S.
TI Removing leaf petioles and auto locating apex-base points using straight
   line interpolation and bisection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apex point; Base point; Petiole; Straight line interpolation; Bisection;
   Pattern recognition; Plant recognition system
AB Plants are one of the long lasting species on Earth and are used for various purposes such as medicine, food and organics. Apex point and base point, coined here, are very important points of leaf facilitating extraction of various leaf shape based features. The main challenge in automatic plant recognition system is automatically identifying apex-base points and removing petiole of the leaf. Here, we propose a novel methodology, using straight line interpolation and bisection, for automatically identifying leaf apex point and base point. The coordinates of apex point and base point are successfully retrieved and the methodology is rotation and scale invariant. Finally, a logistic regression is used for classification. The proposed methodology is tested in several datasets like Leaflia, flavia and the results are satisfactory.
C1 [Visu, P.] Anna Univ, Dept IT, Velammal Engn Coll, Chennai, Tamil Nadu, India.
   [Sivakumar, Nagarajan; Kumaresan, P.] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Babu, Sundaresan Yokesh] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Ramesh, P. S.] Vellore Inst Technol, CIIS, Vellore, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Velammal Engineering College;
   Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore; Vellore Institute of Technology (VIT);
   VIT Vellore
RP Visu, P (corresponding author), Anna Univ, Dept IT, Velammal Engn Coll, Chennai, Tamil Nadu, India.
EM pandu.visu@gmail.com; knsksiva@gmail.com; pkumaresan@vit.ac.in;
   yokeshbabu.s@vit.ac.in; ramesh.ps@vit.ac.in
RI P, Kumaresan/O-1053-2018; S, RAMESH P/AAA-6297-2019; P,
   Visu/EVU-7748-2022
OI P, Kumaresan/0000-0001-5563-8325; S, RAMESH P/0000-0001-5190-768X; P,
   Visu/0000-0001-8020-1678
CR [Anonymous], 2011, HYBRID IMAGE SEGMENT, DOI [DOI 10.1109/PACC2011.5978883, DOI 10.1109/PACC.2011.5978883]
   Bi W, 2016, INT C INTEL HUM MACH, P525, DOI 10.1109/IHMSC.2016.37
   Chaki J, 2016, INT C MICR, P1
   Hati S., 2013, International Journal of Computer Applications, V62, P15, DOI [DOI 10.5120/10172-4897, 10.5120/10172-4897]
   Jiazhi Pan, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P906, DOI 10.1109/CSSE.2008.918
   Karpathy A., Cs231n: Convolutional Neural Networks for Visual Recognition
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lakshmi JK, 2009, ICDIP 2009: INTERNATIONAL CONFERENCE ON DIGITAL IMAGE PROCESSING, PROCEEDINGS, P260, DOI 10.1109/ICDIP.2009.21
   Langner J, 2001, LEAVES RECOGNITION V
   Mishra P. K., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P68
   Nandyal S.S., 2013, Int. J. Comput. Vis. Robot., V3, P197, DOI DOI 10.1504/IJCVR.2013.056040
   Prasad S., 2011, 2011 2nd International Conference on Computer and Communication Technology, P646, DOI 10.1109/ICCCT.2011.6075212
   Price CA, 2011, PLANT PHYSIOL, V155, P236, DOI 10.1104/pp.110.162834
   Sibi Chakaravarthy S, 2016, ADV SIGNAL PROCESSIN, P581
   Suta L., 2012, 2012 IEEE International Conference on Intelligent Computer Communication and Processing (ICCP 2012). Proceedings, P181, DOI 10.1109/ICCP.2012.6356183
   Wang XF, 2007, APPL MATH COMPUT
   Wilf P, 1998, MANUAL LEAF ARCHITEC, P65
   Winberg S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1000, DOI 10.1109/ICIT.2013.6505808
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Zulkifli Z., 2011, Proceedings of the 2011 11th International Conference on Hybrid Intelligent Systems (HIS 2011), P430, DOI 10.1109/HIS.2011.6122144
NR 20
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5355
EP 5369
DI 10.1007/s11042-018-6579-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500064
DA 2024-07-18
ER

PT J
AU Yuan, L
   Hu, YS
   Li, D
   Tan, QW
   Xu, PZ
AF Yuan, Ling
   Hu, Yingsong
   Li, Dan
   Tan, Qiwei
   Xu, Pengzhan
TI Illumination consistency based on single low dynamic range images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range image; Illumination consistency; Inverse tone
   mapping; Low dynamic range image; Relighting
ID COLOR CONSTANCY ALGORITHMS; SCENES
AB In this paper, a light consistency solution for generating high dynamic range (HDR) images based on a single low dynamic range image(LDR) is proposed, and the virtual object is rendered by illumination. The solution can reduce the time of image acquisition and processing, and solve the problems caused by the limitations of image acquisition equipment. The solution is divided into three stages: image preprocessing, high dynamic range image generation and virtual object relighting. Firstly, in the stage of image pretreatment, the wavelet noise reduction method based on a Gaussian mixture model is used to remove image noise and avoid image detail distortion. The inverse camera response function is utilized to linearize the image, the pixel brightness range is expanded based on the inverse tone mapping function, and the threshold segmentation method is combined with flooding Gaussian smoothing to calculate the highlight spread diagram to compensate for scene highlights lost during camera shooting. Then, the extended dynamic range image is interpolated linearly by using the specular expansion image to get the high dynamic range image. Based on the analysis and experimental simulation, compared with other methods, it is found that using a single low-dynamic-range image can greatly reduce the time of image acquisition and processing and reduce the limitations of image acquisition equipment, while maintaining good light fusion. Based on the simulation results, the efficiency of light consistency processing is improved.
C1 [Yuan, Ling; Hu, Yingsong; Li, Dan; Tan, Qiwei; Xu, Pengzhan] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Li, D (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM lidanhust@hust.edu.cn
CR Agrafiotis P, 2015, INT C COMPUT VISION, P2756
   [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 2008, SIGGRAPH 2008 Classes
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529
   Barrueco J., 2018, IEEE T BROADCAST, P1
   Boivin S, 2001, COMP GRAPH, P107, DOI 10.1145/383259.383270
   Chantler M, 2005, INT J COMPUT VISION, V62, P83, DOI 10.1007/s11263-005-4636-3
   Cho SY, 2001, IEEE T NEURAL NETWOR, V12, P1204, DOI 10.1109/72.950148
   Chow CK, 2010, PATTERN RECOGN, V43, P1700, DOI 10.1016/j.patcog.2009.10.008
   Debevec P, 2002, IEEE COMPUT GRAPH, V22, P26, DOI 10.1109/38.988744
   Debevec P.E., 2008, P 24 ANN C COM GRAPH, P1
   Imai Y, 2011, INT C COMPUT COLOR I, P85
   Jacobs K, 2008, IEEE COMPUT GRAPH, V28, P84, DOI 10.1109/MCG.2008.23
   Kán P, 2015, LECT NOTES COMPUT SC, V9474, P574, DOI 10.1007/978-3-319-27857-5_52
   Kanbara M, 2004, INT C PATT RECOG, P911, DOI 10.1109/ICPR.2004.1334407
   Karungaru S, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P1085
   Karungaru S, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P881
   Kontogianni G, 2015, ISPRS INT ARCH PHOTO
   Kontogianni G, 2014, INT C CULT HER EUROM
   Liu YL, 2009, VISUAL COMPUT, V25, P637, DOI 10.1007/s00371-009-0342-4
   [马晋涛 MA Jintao], 2008, [中国图象图形学报, Journal of Image and Graphics], V13, P780
   Madsen CB, 2011, GRAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P129
   Panagopoulos A, 2011, PROC CVPR IEEE, P673, DOI 10.1109/CVPR.2011.5995585
   Panagopoulos A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130334
   Rohmer K, 2017, IEEE T VIS COMPUT GR, P1
   Sato I, 1999, IEEE T VIS COMPUT GR, V5, P1, DOI 10.1109/2945.764865
   Sato I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P875, DOI 10.1109/ICCV.1999.790314
   Sun N, 2010, IEEE IMAGE PROC, P2973, DOI 10.1109/ICIP.2010.5653371
   Yu YZ, 1999, COMP GRAPH, P215
   Zhang F, 2017, IEEE INT C IM SIGN P, P358
   Zhou W, 2008, IMAGE VISION COMPUT, V26, P415, DOI 10.1016/j.imavis.2006.12.003
NR 32
TC 1
Z9 1
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3189
EP 3215
DI 10.1007/s11042-018-6799-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700008
DA 2024-07-18
ER

PT J
AU Baek, JW
   Chung, KY
AF Baek, Ji-Won
   Chung, Kyung-Yong
TI Multimedia recommendation using Word2Vec-based social relationship
   mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Recommendation; Word2vec; Social relationship mining
ID ROC; SELECTION; FEATURES; AREA
AB This study proposes the multimedia recommendation method using Word2Vec-based social relationship mining. This is to analyze users with a similar tendency on the basis of the keywords related to multimedia content and sentiment words of comments, to build a trust relationship, and to recommend multimedia. In order to solve the problem of data sparsity, metadata of multimedia content are collected and then are clustered by genre. User's evaluate a preference for multimedia content. With the use of evaluation data, the attributes preferred by users are predicted. In terms of propensities, the sentiment words in users comments are classified by SVM on the basis of sentiment dictionary. The classified sentiment words are presented in vector with the use of Word2Vec. In terms of the vector of sentiment words, the dynamic relationship between users of words in the same preference by the similarity using the distance scale. It helps to build a trust relationship between users with preferences that can change with a lapse of time. Accordingly, multimedia content are recommended to users with a similar tendency. In terms of performance evaluation, F-measure is compared with the uses of precision and recall for a recommendation. As the result of evaluation, the social relationship mining method is evaluated to be better than explicit and implicit recommendation methods. With the proposed method, it is possible to search with metadata of content and make a intelligent recommendation explicitly and implicitly according to user's tendency.
C1 [Baek, Ji-Won] Kyonggi Univ, Dept Comp Sci, Data Min Lab, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
   [Chung, Kyung-Yong] Kyonggi Univ, Div Comp Sci & Engn, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
C3 Kyonggi University; Kyonggi University
RP Chung, KY (corresponding author), Kyonggi Univ, Div Comp Sci & Engn, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
EM hy1233hh@naver.com; dragonhci@gmail.com
RI Chung, Kyungyong/JAC-2276-2023
OI Chung, Kyungyong/0000-0002-6439-9992
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2019R1F1A1058651]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2019R1F1A1058651).
CR Ali-Eldin AMT, 2018, AIN SHAMS ENG J, V9, P3103, DOI 10.1016/j.asej.2018.03.005
   Aslan S, 2018, FUTURE GENER COMP SY, V89, P249, DOI 10.1016/j.future.2018.06.050
   Back JW, 2019, TECHNOL HEALTH CARE, V27, P459, DOI 10.3233/THC-191730
   Bag S, 2019, INFORM SCIENCES, V483, P53, DOI 10.1016/j.ins.2019.01.023
   Barbancho AM, 2015, KNOWL-BASED SYST, V89, P218, DOI 10.1016/j.knosys.2015.07.005
   Boutaba R, 2014, CLUSTER COMPUT, V17, P723, DOI 10.1007/s10586-014-0349-0
   Cerisara C, 2018, COMPUT SPEECH LANG, V47, P175, DOI 10.1016/j.csl.2017.07.009
   Cheng F, 2019, KNOWL-BASED SYST, V170, P61, DOI 10.1016/j.knosys.2019.01.029
   Chung KY, 2014, MULTIMED TOOLS APPL, V71, P889, DOI 10.1007/s11042-011-0885-z
   Fadaei A, 2019, EXPERT SYST APPL, V132, P126, DOI 10.1016/j.eswa.2019.04.061
   George KK, 2018, PATTERN RECOGN LETT, V112, P285, DOI 10.1016/j.patrec.2018.08.019
   Gigliarano C, 2014, COMPUT STAT DATA AN, V77, P300, DOI 10.1016/j.csda.2014.03.008
   Gómez M, 2019, COMPUT HUM BEHAV, V96, P196, DOI 10.1016/j.chb.2019.01.026
   Guo L, 2019, PHYSICA A, V523, P301, DOI 10.1016/j.physa.2019.02.005
   Hao PY, 2020, FUZZY SET SYST, V387, P1, DOI 10.1016/j.fss.2019.03.012
   Helal NA, 2016, INTERNATIONAL CONFERENCE ON INFORMATICS AND SYSTEMS (INFOS 2016), P180, DOI 10.1145/2908446.2908474
   Jung KY, 2004, IEICE T INF SYST, VE87D, P2781
   Khanmohammadi S, 2017, EXPERT SYST APPL, V67, P12, DOI 10.1016/j.eswa.2016.09.025
   King VL, 2014, J SUBST ABUSE TREAT, V46, P36, DOI 10.1016/j.jsat.2013.08.009
   Laref R, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113716
   Lazarevic-McManus N, 2008, COMPUT VIS IMAGE UND, V111, P74, DOI 10.1016/j.cviu.2007.07.007
   Liu MS, 2017, KNOWL-BASED SYST, V119, P178, DOI 10.1016/j.knosys.2016.12.010
   Iribarren JL, 2011, SOC NETWORKS, V33, P134, DOI 10.1016/j.socnet.2010.11.003
   Mamitsuka H, 2006, PATTERN RECOGN, V39, P2393, DOI 10.1016/j.patcog.2006.07.010
   Mesquita DPP, 2017, NEUROCOMPUTING, V248, P11, DOI 10.1016/j.neucom.2016.12.081
   Pang SN, 2011, INFORM SCIENCES, V181, P2071, DOI 10.1016/j.ins.2011.01.008
   Sanghani G, 2019, EXPERT SYST APPL, V115, P287, DOI 10.1016/j.eswa.2018.07.049
   Seo YD, 2017, EXPERT SYST APPL, V69, P135, DOI 10.1016/j.eswa.2016.10.024
   Song CW, 2019, CLUSTER COMPUT, V22, P1949, DOI 10.1007/s10586-017-0942-0
   Song GY, 2014, PERS UBIQUIT COMPUT, V18, P1387, DOI 10.1007/s00779-013-0740-5
   Wang B, 2019, STAT PROBABIL LETT, V151, P67, DOI 10.1016/j.spl.2019.03.015
   Yoo H, 2018, PEER PEER NETW APPL, V11, P1309, DOI 10.1007/s12083-017-0620-2
   Yu W, 2014, J KOREAN STAT SOC, V43, P161, DOI 10.1016/j.jkss.2013.05.003
   Yuan WW, 2019, INFORM FUSION, V46, P1, DOI 10.1016/j.inffus.2018.04.004
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
   Zhou HM, 2016, NEUROCOMPUTING, V216, P208, DOI 10.1016/j.neucom.2016.07.036
NR 36
TC 21
Z9 23
U1 6
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34499
EP 34515
DI 10.1007/s11042-019-08607-9
EA JAN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000515728500003
DA 2024-07-18
ER

PT J
AU He, XS
   He, F
AF He, Xuansen
   He, Fan
TI Underdetermined mixing matrix estimation based on artificial bee colony
   optimization and single-source-point detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underdetermined blind source separation (UBSS); Mixing matrix
   estimation; Artificial bee colony (ABC) algorithm; Search strategy; Levy
   flight
ID BLIND SOURCE SEPARATION; SPARSE REPRESENTATION; ALGORITHM; FACTORIZATION
AB It is difficult to solve the problem of underdetermined blind source separation (UBSS) since the mixing system is not invertible. Therefore, estimating the underdetermined mixing matrix becomes the most crucial step in the well-known "two-step approach". To improve the estimation performance, this paper proposes a novel clustering analysis method combining artificial bee colony (ABC) optimization with single-source-point (SSP) detection. The observed signals in the time domain are first transformed into sparse signals in the time-frequency domain by a short time Fourier transform (STFT). And the SSP detection is performed to enhance the sparsity of the signals, and the linear clustering of sparse signal is also converted into compact clustering by mirroring mapping in order to find the corresponding clustering centers in the dense data piles. The clustering centers correspond to the column vectors of the mixing matrix, so the mixing matrix can be estimated by cluster analysis. In the estimation process, the global search capability of the ABC algorithm is fully utilized. Based on the linear clustering characteristics of sparse signals, a new search strategy combining deterministic search with stochastic search is used for bee colony to alleviate the contradiction between the population diversity and the convergence speed of the algorithm. Considering the fact that the ABC algorithm has poor local exploitation capacity, a local search strategy based on Levy flight is also used to further search the neighborhood of the current optimal solution, which can significantly improve the local exploitation performance of the algorithm. The simulation results show that the proposed method can not only estimate the underdetermined mixing matrix (and the source signals) more accurately, but also provide a more robust estimator.
C1 [He, Xuansen] Guangzhou Coll Commerce, Sch Informat Technol & Engn, Guangzhou 511363, Peoples R China.
   [He, Xuansen] Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Peoples R China.
   [He, Fan] Beijing Inst Technol, Sch Management & Econ, Beijing 100081, Peoples R China.
C3 Guangzhou College of Commerce; Hunan University; Beijing Institute of
   Technology
RP He, XS (corresponding author), Guangzhou Coll Commerce, Sch Informat Technol & Engn, Guangzhou 511363, Peoples R China.; He, XS (corresponding author), Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Peoples R China.
EM xshe2010@163.com
RI He, Xuan-sen/AAP-6658-2021
FU National Natural Science Foundation of China [60572183]
FX Funding for this work was supported by the National Natural Science
   Foundation of China [No. 60572183].
CR Ambroise C, 2019, ALGORITHM MOL BIOL, V14, DOI 10.1186/s13015-019-0157-4
   Arberet S, 2010, IEEE T SIGNAL PROCES, V58, P121, DOI 10.1109/TSP.2009.2030854
   Banharnsakun A, 2011, APPL SOFT COMPUT, V11, P2888, DOI 10.1016/j.asoc.2010.11.025
   Bofill P, 2001, SIGNAL PROCESS, V81, P2353, DOI 10.1016/S0165-1684(01)00120-7
   Bouchard F, 2018, IEEE T SIGNAL PROCES, V66, P2041, DOI 10.1109/TSP.2018.2795539
   Carabias-Orti JJ, 2018, IEEE-ACM T AUDIO SPE, V26, P1512, DOI 10.1109/TASLP.2018.2830105
   Chakraborty R, 2019, MULTIMED TOOLS APPL, V78, P34027, DOI 10.1007/s11042-019-08114-x
   Chen YQ, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P1077, DOI 10.1109/ICCT.2018.8600136
   Chen YQ, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P1063, DOI 10.1109/ICCT.2018.8599968
   Comon P, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, pXXI, DOI 10.1016/B978-0-12-374726-6.00003-5
   Domanov I, 2016, IEEE J-STSP, V10, P701, DOI 10.1109/JSTSP.2016.2526971
   Hakli H, 2014, APPL SOFT COMPUT, V23, P333, DOI 10.1016/j.asoc.2014.06.034
   Han HG, 2019, IEEE T CYBERNETICS, V49, P69, DOI 10.1109/TCYB.2017.2764744
   He XS, 2016, CIRC SYST SIGNAL PR, V35, P2881, DOI 10.1007/s00034-015-0173-7
   He XS, 2013, CHINESE J ELECTRON, V22, P319
   Jun H, 2018, IEEE ACCESS, V6, P658, DOI 10.1109/ACCESS.2017.2773665
   Kameoka H, 2018, IEEE-ACM T AUDIO SPE, V26, P1025, DOI 10.1109/TASLP.2018.2795746
   Karaboga D, 2011, APPL SOFT COMPUT, V11, P652, DOI 10.1016/j.asoc.2009.12.025
   Karaboga D, 2009, APPL MATH COMPUT, V214, P108, DOI 10.1016/j.amc.2009.03.090
   Karfoul A, 2010, IEEE T SIGNAL PROCES, V58, P638, DOI 10.1109/TSP.2009.2031731
   Li YQ, 2014, IEEE SIGNAL PROC MAG, V31, P96, DOI 10.1109/MSP.2013.2296790
   Ozerov A, 2010, IEEE T AUDIO SPEECH, V18, P550, DOI 10.1109/TASL.2009.2031510
   Qin ZJ, 2018, IEEE SIGNAL PROC MAG, V35, P40, DOI 10.1109/MSP.2018.2789521
   Reju VG, 2009, SIGNAL PROCESS, V89, P1762, DOI 10.1016/j.sigpro.2009.03.017
   Reju VG, 2010, IEEE T AUDIO SPEECH, V18, P101, DOI 10.1109/TASL.2009.2024380
   Slowik A, 2018, IEEE T IND INFORM, V14, P1004, DOI 10.1109/TII.2017.2786782
   Tengtrairat N, 2016, IEEE T SIGNAL PROCES, V64, P1881, DOI 10.1109/TSP.2015.2477059
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Zayyani H, 2009, IEEE T SIGNAL PROCES, V57, P4378, DOI 10.1109/TSP.2009.2025154
   Zhang CS, 2010, EXPERT SYST APPL, V37, P4761, DOI 10.1016/j.eswa.2009.11.003
NR 30
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13061
EP 13087
DI 10.1007/s11042-020-08635-w
EA JAN 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509165900002
DA 2024-07-18
ER

PT J
AU Cui, YH
   Pan, TH
   Chen, S
   Zou, XB
AF Cui, Yanhai
   Pan, Tianhong
   Chen, Shan
   Zou, Xiaobo
TI A gender classification method for Chinese mitten crab using deep
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network; Chinese mitten crab;
   Gender; Classification
AB Chinese mitten crab is a very popular food in China. Due to different nutrients between the male crab and the female crab, it is necessary to distinguish crab's gender before selling in the market. Current computer vision methods need complex image preprocessing and cannot distinguish crab's gender through the crab shell. In this paper, a new classification approach for crab's gender using the deep convolutional neural network (CNN) was proposed. Firstly, four different types of data augmentation methods were used to enrich the data set. Then, a batch normalization technique was taken to solve the problem of the gradient disappearance and shorten the training time. In order to suppress over-fitting phenomenon, a dropout technique was also taken into consideration. Experimental results demonstrated the effectiveness of the proposed crab's gender classification method. The proposed method achieved 98.90% classified accuracy which is 3 percentage points higher than two state-of-the-art methods.
C1 [Cui, Yanhai; Pan, Tianhong; Chen, Shan] Anhui Univ, Sch Elect Engn & Automat, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei 230601, Anhui, Peoples R China.
   [Cui, Yanhai; Pan, Tianhong] Jiangsu Univ, Sch Elect & Informat Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Zou, Xiaobo] Jiangsu Univ, Sch Food & Biol Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Anhui University; Jiangsu University; Jiangsu University
RP Pan, TH (corresponding author), Anhui Univ, Sch Elect Engn & Automat, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei 230601, Anhui, Peoples R China.; Pan, TH (corresponding author), Jiangsu Univ, Sch Elect & Informat Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM thpan@ahu.edu.cn
RI Pan, Tianhong/AAD-9843-2020; Pan, Tianhong/J-8591-2012
OI Pan, Tianhong/0000-0002-0993-3937; Pan, Tianhong/0000-0002-0993-3937
FU National Natural Science Foundation of China [61873113]; Key R&D Program
   of Jiangsu Province, China [BE2018370]
FX This study was supported by the National Natural Science Foundation of
   China under Grant 61873113 & the Key R&D Program of Jiangsu Province,
   China (Grant number BE2018370).
CR Biswas N, 2018, PATTERN RECOGN LETT, V101, P80, DOI 10.1016/j.patrec.2017.11.003
   Costa C, 2011, FOOD BIOPROCESS TECH, V4, P673, DOI 10.1007/s11947-011-0556-0
   Faris H, 2018, NEURAL COMPUT APPL, V30, P2355, DOI 10.1007/s00521-016-2818-2
   Florensa Carlos., 2017, P 2017 IEEE 24 INT C, P1, DOI DOI 10.1109/INTERCON.2017.8079727
   Gao LG, 2016, IEEE ELECTR DEVICE L, V37, P870, DOI 10.1109/LED.2016.2573140
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo WL, 2019, IEEE T CYBERNETICS, V49, P3088, DOI 10.1109/TCYB.2018.2838680
   He XY, 2018, NEUROCOMPUTING, V291, P187, DOI 10.1016/j.neucom.2018.02.073
   HIROSE Y, 1991, NEURAL NETWORKS, V4, P61, DOI 10.1016/0893-6080(91)90032-Z
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jian GZ, 2018, INT COMP S, P150
   Jiang XH, 2018, NEUROCOMPUTING, V275, P1132, DOI 10.1016/j.neucom.2017.09.056
   Ke HJ, 2018, IEEE ACCESS, V6, P14722, DOI 10.1109/ACCESS.2018.2810882
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P601097
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Liu Y, 2017, MULTIMED TOOLS APPL, V76, P11065, DOI 10.1007/s11042-016-3540-x
   Lu SY, 2018, J MED IMAG HEALTH IN, V8, P1486, DOI 10.1166/jmihi.2018.2459
   Miki Y, 2017, COMPUT BIOL MED, V80, P24, DOI 10.1016/j.compbiomed.2016.11.003
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Petersen P, 2018, NEURAL NETWORKS, V108, P296, DOI 10.1016/j.neunet.2018.08.019
   Qian RQ, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P578, DOI 10.1109/FSKD.2016.7603237
   Rajkomar A, 2017, J DIGIT IMAGING, V30, P95, DOI 10.1007/s10278-016-9914-9
   Sahiner B, 1996, IEEE T MED IMAGING, V15, P598, DOI 10.1109/42.538937
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Wang P, 2016, NEUROCOMPUTING, V174, P806, DOI 10.1016/j.neucom.2015.09.096
   Xiaobo Z, 2018, Patent No. [CN108287010, 108287010]
   Xuan Q, 2018, IEEE T IND ELECTRON, V65, P6538, DOI 10.1109/TIE.2017.2784394
   Xue DX, 2016, J MED BIOL ENG, V36, P755, DOI 10.1007/s40846-016-0182-4
   Yoo H.-J., 2015, IEIE Transactions on Smart Processing and Computing, V4, P35, DOI DOI 10.5573/IEIESPC.2015.4.1.035
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22875, DOI 10.1007/s11042-018-6003-8
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   [周飞燕 Zhou Feiyan], 2017, [计算机学报, Chinese Journal of Computers], V40, P1229
NR 36
TC 11
Z9 12
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7669
EP 7684
DI 10.1007/s11042-019-08355-w
EA JAN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600006
DA 2024-07-18
ER

PT J
AU Barni, M
   Nowroozi, E
   Tondi, B
AF Barni, Mauro
   Nowroozi, Ehsan
   Tondi, Benedetta
TI Improving the security of image manipulation detection through
   one-and-a-half-class multiple classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial multimedia forensics; Forensics and counter-forensics;
   Manipulation detection; Secure classification; Security of machine
   learning classifiers
ID SUPPORT; IDENTIFICATION
AB Protecting image manipulation detectors against perfect knowledge attacks requires the adoption of detector architectures which are intrinsically difficult to attack. In this paper, we do so, by exploiting a recently proposed multiple-classifier architecture combining the improved security of 1-Class (1C) classification and the good performance ensured by conventional 2-Class (2C) classification in the absence of attacks. The architecture, also known as 1.5-Class (1.5C) classifier, consists of one 2C classifier and two 1C classifiers run in parallel followed by a final 1C classifier. In our system, the first three classifiers are implemented by means of Support Vector Machines (SVM) fed with SPAM features. The outputs of such classifiers are then processed by a final 1C SVM in charge of making the final decision. Particular care is taken to design a proper strategy to train the SVMs the 1.5C classifier relies on. This is a crucial task, due to the difficulty of training the two 1C classifiers at the front end of the system. We assessed the performance of the proposed solution with regard to three manipulation detection tasks, namely image resizing, median filtering and contrast enhancement. As a result the security improvement allowed by the 1.5C architecture with respect to a conventional 2C solution is confirmed, with a performance loss in the absence of attacks that remains at a negligible level.
C1 [Barni, Mauro; Nowroozi, Ehsan; Tondi, Benedetta] Univ Siena, Dept Informat Engn & Math Sci, Siena, Italy.
C3 University of Siena
RP Nowroozi, E (corresponding author), Univ Siena, Dept Informat Engn & Math Sci, Siena, Italy.
EM barni@diism.unisi.it; ehsan.nowroozi@diism.unisi.it;
   benedettatondi@gmail.com
RI Nowroozi, Ehsan/ABD-3903-2020
OI Nowroozi, Ehsan/0000-0002-5714-8378
CR [Anonymous], 2013, INTRIGUING PROPERTIE
   Barnett Michael, 2016, Paternalism beyond Borders, P1
   Barni M, 2018, IEEE IMAGE PROC, P3803, DOI 10.1109/ICIP.2018.8451698
   Barni M, 2018, EUR SIGNAL PR CONF, P962, DOI 10.23919/EUSIPCO.2018.8553305
   Barni M, 2017, EUR SIGNAL PR CONF, P281, DOI 10.23919/EUSIPCO.2017.8081213
   Bayar B, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2007, DOI 10.1109/ICASSP.2018.8462383
   BIGGIO B, 2013, EVASION ATTACKS MACH
   Biggio B, 2015, LECT NOTES COMPUT SC, V9132, P168, DOI 10.1007/978-3-319-20248-8_15
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen ZB, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/7538190
   Costa Filipe de O., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P71, DOI 10.1109/SIBGRAPI.2012.19
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   DAvino D., 2017, Media Watermarking, Security, and Forensics 2017, Burlingame, CA, USA, 29 January 2017-2 February 2017, V29, P92
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Huang L., 2011, P 4 ACM WORKSH SEC A, P43
   Khan SS, 2010, LECT NOTES ARTIF INT, V6206, P188
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Marchi E, 2015, INT CONF ACOUST SPEE, P1996, DOI 10.1109/ICASSP.2015.7178320
   Marra F, 2015, PROC SPIE, V9409, DOI 10.1117/12.2182173
   Montgomery D. C., 2020, DESIGN ANAL EXPT
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Perdisci R, 2006, IEEE DATA MINING, P488
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Rattani A, 2015, IEEE T INF FOREN SEC, V10, P2447, DOI 10.1109/TIFS.2015.2464772
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583
   Tondi B, 2018, ELECTRON LETT, V54, P1220, DOI 10.1049/el.2018.6469
   Verdoliva L, 2014, IEEE INT WORKS INFOR, P149, DOI 10.1109/WIFS.2014.7084319
   Wang B, 2009, IFIP ADV INF COMM TE, V306, P107
   Yarlagadda Sri Kalyan, 2018, P ELECT IMAGING EI, DOI DOI 10.2352/ISSN.2470-1173.2018.07.MWSF-214
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zheng P., 2018, ARXIV180301798
   Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 41
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2383
EP 2408
DI 10.1007/s11042-019-08425-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000029
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, HT
   Li, GA
AF Wu, Haotian
   Li, Guangan
TI RETRACTED: Innovation and improvement of visual communication design of
   mobile app based on social network interaction interface design
   (Retracted article. See vol. 81, pg. 39825, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Social network; Smartphone; Interaction; User interface design; Visual
   design
ID USER-INTERFACE; SMARTPHONE; USABILITY; QUALITY
AB In order to achieve information visualization, realize good interaction between users and information, and meet the needs of users, this study first studied the interaction behavior of the user when using the smartphone was studied, and analyzed the visual factors of the smartphone interface were analyzed from the user sensory interaction level, and the user operation mode level, from the expression of visual form to the commonly used interface mode and User Interface (UI) component space. On this basis, the situational visual expression of the scene in different interaction scenarios was analyzed. Secondly, the basic theory of visual design of smartphone application interface was explained from the perspectives of aesthetics, semiotics and Gestalt psychology, In other words, the visual design of the application interface should be metaphorical, highlighting the key points in the overall visual style, and conforming to the user's psychological model. At the same time, in order to meet the user's personalized needs for control, it must add customized options. Finally, the model of the interface visual design method of the interdisciplinary "Shared Communication" system for the interface design of the mobile APP was constructed, and the case of Didi Chuxing was analyzed, which preliminarily confirmed the feasibility of the construction of the interface visual design method model of the "Shared Communication" system.
C1 [Wu, Haotian] Shanghai Univ Engn Sci, Shanghai, Peoples R China.
   [Li, Guangan] Shanghai Univ Engn Sci, Sch Art & Design, Shanghai, Peoples R China.
   [Wu, Haotian] Edinburgh Napier Univ, Edinburgh, Midlothian, Scotland.
   [Li, Guangan] Tongji Univ, Shanghai Int Inst Design & Innovat, Shanghai, Peoples R China.
C3 Shanghai University of Engineering Science; Shanghai University of
   Engineering Science; Edinburgh Napier University; Tongji University
RP Wu, HT (corresponding author), Shanghai Univ Engn Sci, Shanghai, Peoples R China.; Wu, HT (corresponding author), Edinburgh Napier Univ, Edinburgh, Midlothian, Scotland.
EM wuhaotian784@gmail.com; Hnasmy@126.com
RI Wu, Hao-Tian/S-5360-2019
OI Wu, Hao-Tian/0000-0001-6462-7193
CR Anagnostopoulos T, 2016, PERVASIVE MOB COMPUT, V31, P22, DOI 10.1016/j.pmcj.2016.01.012
   Aounallah MA, 2017, APPL BIOCHEM BIOTECH, V181, P1
   Awwad AM, 2016, MOB INF SYST, V16, P1
   Breil C, 2016, MOLECULES, V21, DOI 10.3390/molecules21020196
   Cheng Karen, 2017, Information Design Journal, V23, P80, DOI 10.1075/idj.23.1.09che
   Droste AM, 2017, J ATMOS OCEAN TECH, V34, P1853, DOI 10.1175/JTECH-D-16-0150.1
   He X, 2017, CLIN EXP OPHTHALMOL, V46, P281
   Hesse G, 2018, HNO, V66, P350, DOI 10.1007/s00106-018-0474-9
   Jung W, 2017, PROCEDIA COMPUT SCI, V121, P166, DOI 10.1016/j.procs.2017.11.023
   Lee H, 2016, IEICE T INF SYST, VE99D, P1852, DOI 10.1587/transinf.2016EDP7047
   Lee LSA, 2018, ADV SCI LETT, V24, P1012, DOI 10.1166/asl.2018.10677
   Lee MJ., 2016, WIRELESS PERS COMMUN, V93, P1
   Lee U, 2017, PROCEEDINGS OF THE A, V1, P63
   Loohuis AMM, 2018, NEUROUROL URODYNAM, P22
   Maloshonok N, 2016, COMPUT HUM BEHAV, V62, P506, DOI 10.1016/j.chb.2016.04.025
   Miraz MH, 2016, UNIVERSAL ACCESS INF, V15, P431, DOI 10.1007/s10209-014-0397-5
   Moon SM, 2016, CLUSTER COMPUT, V19, P949, DOI 10.1007/s10586-016-0548-y
   Nunes F, 2016, UNIVERSAL ACCESS INF, V15, P659, DOI 10.1007/s10209-015-0440-1
   Petis SM, 2016, CAN J SURG, V59, P48, DOI 10.1503/cjs.010715
   Poan ED, 2016, CLIM DYNAM, V47, P3113, DOI 10.1007/s00382-016-3016-8
   Rahmat H, 2018, ADV SCI LETT, V24, P1633, DOI 10.1166/asl.2018.11125
   Salman HM, 2018, IEEE ACCESS, V4, P1
   Simpson N, 1999, INTERACT COMPUT, V11, P323, DOI 10.1016/S0953-5438(98)00069-1
   Singh S, 2017, PROCEDIA MANUF, V10, P1020, DOI 10.1016/j.promfg.2017.07.093
   Tomita K, 2017, TECHTRENDS, V61, P313, DOI 10.1007/s11528-017-0197-x
   Weersink A, 2017, CANADIAN JOURNAL OF, V66, P1
   Xiang L, 2018, IEEE TRANSACTIONS ON, V99, P1
   Zhang MWB, 2017, TECHNOL HEALTH CARE, V25, P373, DOI 10.3233/THC-161287
NR 28
TC 20
Z9 20
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1
EP 16
DI 10.1007/s11042-019-7523-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600001
DA 2024-07-18
ER

PT J
AU Guo, ZP
   Li, J
   Wu, ZK
   Huang, C
   Gao, HW
AF Guo, Zhipeng
   Li, Juan
   Wu, Ziku
   Huang, Chao
   Gao, Hongwei
TI A new image transmission compression approach based on Beidou navigation
   satellite system on the Open Sea
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variable sequence progressive compression approach (VSPC); Beidou
   navigation satellite system (BDS); Open sea; Mariculture; Data
   transmission; Image processing
ID ALGORITHM; BDS
AB In order to solve the problem that a great amount of image information need to be transmitted on the mariculture of open sea and Beidou Navigation Satellite System (BDS) has the limited transmitting capability, this paper proposes a new compression approach to transmit image using BDS, i.e., the variable sequence progressive compression approach (VSPC). Firstly, by performing matrix operation and difference component extraction on the binary stream data, the data quantity is reduced. Then, the data quantity is further reduced by using the iterative compression approach. The simulation results show that the proposed approach can effectively reduce the amount of transmitted data, reduce the compression ratio and improve the data transmission efficiency under the premise of ensuring the same image quality by comparing with the traditional Huffman and DCT (Discrete Cosine Transform) algorithms.
C1 [Guo, Zhipeng; Li, Juan; Huang, Chao; Gao, Hongwei] Qingdao Agr Univ, Coll Mech & Elect Engn, Qingdao, Shandong, Peoples R China.
   [Wu, Ziku] Qingdao Agr Univ, Coll Sci & Informat, Qingdao, Shandong, Peoples R China.
C3 Qingdao Agricultural University; Qingdao Agricultural University
RP Li, J (corresponding author), Qingdao Agr Univ, Coll Mech & Elect Engn, Qingdao, Shandong, Peoples R China.
EM 18363973948@163.com; lijuan291@sina.com
RI Huang, Chao/JJD-0553-2023; Huang, Chao/L-1445-2019
OI Huang, Chao/0000-0001-8775-3192; Li, Juan/0000-0001-8900-3897
FU National Natural Science Foundation of China [41674037, 61374126];
   National Natural Science Foundation of China
FX The research work is financially supported by the National Natural
   Science Foundation of China (41674037; 61374126). The authors would like
   to acknowledge the support provided by the National Natural Science
   Foundation of China and the reviewers for their constructive suggestions
   to improve the quality of this paper.
CR Abdallah A., 2014, THESIS
   Al-Zaidi R, 2017, 2 INT C FOG MOB EDG
   Antony A, 2017, MULTIMED TOOLS APPL, V76, P1639, DOI 10.1007/s11042-015-3138-8
   [边少锋 Bian Shaofeng], 2017, [中国科学. 信息科学, Scientia Sinica Informationis], V47, P275
   CARDULLO MW, 1968, J SPACECRAFT ROCKETS, V5, P1479, DOI 10.2514/3.29508
   Fu WJ, 2018, ADV SPACE RES, V62, P477, DOI 10.1016/j.asr.2018.04.025
   Han ZZ, 2019, COMPUTER VISION BASE
   Hu QS, 2018, MEAS CONTROL TECHNOL, V37, P59
   Imani M, 2018, I SYMPOS LOW POWER E, P67, DOI 10.1145/3218603.3218621
   Khan A, 2017, MULTIMED TOOLS APPL, V76, P12391, DOI 10.1007/s11042-016-3629-2
   Kouwen A, 2018, DIGIT INVEST, V26, pS77, DOI 10.1016/j.diin.2018.04.007
   Li Hang, 2016, Telecommunication Engineering, V56, P618, DOI 10.3969/j.issn.1001-893x.2016.06.004
   Liu Houpu, 2011, Geomatics and Information Science of Wuhan University, V36, P843
   Odolinski R, 2015, GPS SOLUT, V19, P151, DOI 10.1007/s10291-014-0376-6
   Richard S, 2017, INT S ANT TECHN APPL
   Shi C, 2016, J GEODESY, V90, P161, DOI 10.1007/s00190-015-0863-8
   Sun L, 2016, SHIP ELECT ENG, V36, P76
   Tang QH, 2016, SHIP ELECT ENG, V36, P96
   White S, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4467
   Xie J, 2013, CHINA SATELLITE NAVIGATION CONFERENCE (CSNC) 2013 PROCEEDINGS: BEIDOU/GNSS NAVIGATION APPLICATIONS, TEST & ASSESSMENT TECHNOLOGY, USER TERMINAL TECHNOLOGY, P197, DOI 10.1007/978-3-642-37398-5_19
   Zheng HY, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1954-8
   [周万振 Zhou Wanzhen], 2017, [导航定位学报, Journal of Navigation and Positioning], V5, P79
NR 22
TC 3
Z9 4
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14919
EP 14931
DI 10.1007/s11042-019-08357-8
EA DEC 2019
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000504164600003
DA 2024-07-18
ER

PT J
AU Verma, V
   Muttoo, SK
   Singh, VB
AF Verma, Vinita
   Muttoo, Sunil K.
   Singh, V. B.
TI Enhanced payload and trade-off for image steganography via a novel pixel
   digits alteration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; LSB substitution; PVD; Steganalysis
AB Many high capacity image steganography algorithms have been proposed but at the cost of lower imperceptibility. To fill the gap, this paper proposes a novel RGB image steganography technique that not only enhances the hiding capacity but also largely improves the trade-off between capacity and imperceptibility on maximum embedding rate. The technique encrypts the secret data (text, grayscale or a color image) into a sequence of two-digit decimal values. A digit in the sequence is hidden in a cover pixel by altering the pixel's digits to the nearest pixel value possible. Most common spatial hiding techniques are the Least Significant Bit (LSB) substitution and Pixel Value Differencing (PVD) which hide data in the form of bits. The proposed linear time digit based hiding technique outperforms LSB substitution, PVD or their variants in terms of both capacity and imperceptibility. It also outperforms the existing digit hiding methods in color images. Moreover, the method is secure against the two detection schemes of Weighted Stego-Image steganalysis.
C1 [Verma, Vinita; Muttoo, Sunil K.] Univ Delhi, Dept Comp Sci, Delhi, India.
   [Singh, V. B.] Univ Delhi, Dept Comp Sci, Delhi Coll Arts & Commerce, Delhi, India.
C3 University of Delhi; University of Delhi
RP Verma, V (corresponding author), Univ Delhi, Dept Comp Sci, Delhi, India.
EM vinitaducs@gmail.com; drskmuttoo@gmail.com; vbsinghdcacdu@gmail.com
RI SINGH, V.B./GNW-3297-2022
OI SINGH, V B/0000-0001-6678-4977; Verma, Vinita/0000-0003-1318-8041
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   Anjum A, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P636
   Balamurugan CR, 2013, INT CONF COMPUT POW, P1, DOI 10.1109/ICCPEIC.2013.6778495
   Böhme R, 2010, ADVANCED STATISTICAL STEGANALYSIS, P1
   FRIDRICH J, 2004, P SPIE, V5306
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Hussain M, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8060041
   Jung KH, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P355, DOI 10.1109/ICHIT.2008.279
   KER AD, 2008, P SPIE, V6819
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Laffont A, 2017, INT CONF INFORM COMM, P61, DOI 10.1109/ICTS.2017.8265647
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P1482, DOI 10.1109/TIP.2018.2878290
   Nagaraj V, 2013, IERI PROC, V4, P17, DOI 10.1016/j.ieri.2013.11.004
   Pradhan A., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2016/v9i37/88557, DOI 10.17485/ijst/2016/v9i37/88557]
   Prasad S, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.161066
   Schöttle P, 2012, IEEE INT WORKS INFOR, P193, DOI 10.1109/WIFS.2012.6412648
   Shen SY, 2015, MULTIMED TOOLS APPL, V74, P707, DOI 10.1007/s11042-014-2016-0
   SUDEEP PV, 2009, 10 NAT C TECHN TREND
   SWAIN G, 2014, INDIAN J SCI TECHNOL, V7, P1444
   Swain G, 2019, OPTIK, V180, P807, DOI 10.1016/j.ijleo.2018.11.015
   Swain G, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/4847098
   Swain G, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1505896
   Swain G, 2019, ARAB J SCI ENG, V44, P2995, DOI 10.1007/s13369-018-3372-2
   Swain G, 2018, ARAB J SCI ENG, V43, P7549, DOI 10.1007/s13369-018-3163-9
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Thanikaiselvan V., 2014, Journal of Artificial Intelligence, V7, P54
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
NR 28
TC 11
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7471
EP 7490
DI 10.1007/s11042-019-08283-9
EA DEC 2019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164600010
DA 2024-07-18
ER

PT J
AU Al-Obaydy, WNI
   Suandi, SA
AF Al-Obaydy, Wasseem N. Ibrahem
   Suandi, Shahrel Azmin
TI Automatic pose normalization for open-set single-sample face recognition
   in video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Open-Set single-sample face recognition; Pose normalization; Video
   surveillance
ID ROBUST
AB Face images acquired by video surveillance cameras usually involve large pose variations which significantly degrade the performance of face recognition systems. Existing techniques address the pose variation problem by normalizing the arbitrary poses to the desired pose prior to recognition. However, these methods may require 2D or 3D model fitting and manual facial landmarks annotation. In this work, we present an automatic pose normalization technique that is free from model fitting and manual intervention. Our method utilizes an automatic facial landmark detection algorithm and thin-plate splines warping method to normalize pose-varied face images to a canonical frontal pose. Detecting facial landmarks automatically in face images provides 2D surface points that are used by thin-plate splines warping to geometrically transform face images to the desired pose. Experimental results carried out on the FERET database have shown that the proposed method achieved a comparable or higher performance compared to the state-of-the-art pose normalization approaches under constrained conditions. Moreover, extended experiments on the ChokePoint database have shown that our method substantially improved the performance of our open-set single-sample face recognition approach in the surveillance environment.
C1 [Al-Obaydy, Wasseem N. Ibrahem; Suandi, Shahrel Azmin] Univ Sains Malaysia, Sch Elect & Elect Engn, Intelligent Biometr Grp, Engn Campus, Nibong Tebal 14300, Pulau Pinang, Malaysia.
   [Al-Obaydy, Wasseem N. Ibrahem] Univ Technol Baghdad, Comp Engn Dept, Baghdad, Iraq.
C3 Universiti Sains Malaysia; University of Technology- Iraq
RP Suandi, SA (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Intelligent Biometr Grp, Engn Campus, Nibong Tebal 14300, Pulau Pinang, Malaysia.
EM wasseem.alobaydy@student.usm.my; shahrel@usm.my
RI Al-Obaydy, Wasseem N. Ibrahem/Q-3159-2016; Suandi, Shahrel
   Azmin/D-1776-2009
OI Al-Obaydy, Wasseem N. Ibrahem/0000-0003-4251-5240; Suandi, Shahrel
   Azmin/0000-0001-9980-7426
FU Malaysia Ministry of Higher Education (MOHE) Fundamental Research Grant
   Scheme (FRGS) [203/PELECT/6071294]
FX This work is fully supported by the Malaysia Ministry of Higher
   Education (MOHE) Fundamental Research Grant Scheme (FRGS) no.
   203/PELECT/6071294.
CR Al-Obaydy WNI, 2020, NEURAL COMPUT APPL, V32, P1405, DOI 10.1007/s00521-018-3649-0
   [Anonymous], INT C EL ENG INF COM
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299058
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Brown D, 2017, COMM COM INF SC, V716, P415, DOI 10.1007/978-3-319-58274-0_33
   Deng WH, 2017, PATTERN RECOGN, V68, P260, DOI 10.1016/j.patcog.2017.03.024
   Ding CX, 2017, PATTERN RECOGN, V66, P144, DOI 10.1016/j.patcog.2016.11.024
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   dos Santos CE, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P188, DOI 10.1109/SIBGRAPI.2014.23
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferrari C, 2016, INT C PATT RECOG, P1047, DOI 10.1109/ICPR.2016.7899774
   Gao H, 2015, INT CONF BIOMETR, P487, DOI 10.1109/ICB.2015.7139114
   Haghighat M, 2016, EXPERT SYST APPL, V47, P23, DOI 10.1016/j.eswa.2015.10.047
   Hu LQ, 2017, IEEE INT CONF AUTOMA, P9, DOI 10.1109/FG.2017.12
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Jo J, 2015, PATTERN RECOGN, V48, P73, DOI 10.1016/j.patcog.2014.07.013
   Kakadiaris IA, 2017, COMPUT VIS IMAGE UND, V154, P137, DOI 10.1016/j.cviu.2016.04.012
   Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Mendez N, 2017, IB C PATT REC, P391
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Sagonas C, 2017, INT J COMPUT VISION, V122, P270, DOI 10.1007/s11263-016-0920-7
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Wu Z, 2016, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-40991-7
   Wu ZJ, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P116, DOI 10.1109/ACPR.2015.7486477
   Yang GW, 2016, Adv Inform Managemen, P1674, DOI 10.1109/IMCEC.2016.7867502
   Yin X, 2017, IEEE I CONF COMP VIS, P4010, DOI 10.1109/ICCV.2017.430
   Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881
   Zhang BL, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P633, DOI 10.1109/CISP.2014.7003856
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang YH, 2016, COMM COM INF SC, V662, P225, DOI 10.1007/978-981-10-3002-4_19
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 34
TC 11
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2897
EP 2915
DI 10.1007/s11042-019-08414-2
EA DEC 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500178100001
DA 2024-07-18
ER

PT J
AU Cao, DY
   Zhu, MG
   Gao, L
AF Cao, Danyang
   Zhu, Menggui
   Gao, Lei
TI An image caption method based on object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image caption; Attention mechanism; Object detection; Deep learning
ID NETWORK
AB How to represent image information more effectively is the key to the task of image caption. In the existing research, a large number of image caption methods are proposed. Most of them use the global information of the image, and the information in the image that is not related to the caption generation also participates in the calculation, caused a certain amount of waste of resources. In order to solve this problem, a method of generating image caption based on object detection is proposed in this paper. Firstly, the object detection algorithm is used to extract image feature, only the features of meaningful regions in the image are used, and then image caption is generated by combining the spatial attention mechanism with the caption generation network. Experiments show that the image feature of the object region and the salient region are sufficient to represent the information of the entire image in the image caption task. For better convergence of the model, this paper also uses a new strategy for model training. The experimental results show that the proposed model in this paper work well on the test dataset of image caption, and it has created a precedent for new technology to a large extent.
C1 [Cao, Danyang; Zhu, Menggui; Gao, Lei] North China Univ Technol, Sch Informat Sci & Technol, 5 Jin Yuan Zhuang Rd, Beijing 100144, Peoples R China.
   [Cao, Danyang] Beijing Key Lab Integrat & Anal Large Scale Strea, Beijing 100144, Peoples R China.
C3 North China University of Technology
RP Cao, DY (corresponding author), North China Univ Technol, Sch Informat Sci & Technol, 5 Jin Yuan Zhuang Rd, Beijing 100144, Peoples R China.; Cao, DY (corresponding author), Beijing Key Lab Integrat & Anal Large Scale Strea, Beijing 100144, Peoples R China.
EM ufocdy@163.com
FU Yuyou Talent Support Plan of North China University of Technology
   [107051360019XN132/017]; Fundamental Research Funds for Beijing
   Universities [110052971803/037]; Special Research Foundation of North
   China University of Technology [PXM2017_014212_000014]
FX The work was supported by Yuyou Talent Support Plan of North China
   University of Technology (107051360019XN132/017), the Fundamental
   Research Funds for Beijing Universities (110052971803/037), Special
   Research Foundation of North China University of Technology
   (PXM2017_014212_000014).
CR [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], PROC CVPR IEEE
   [Anonymous], ARXIV
   [Anonymous], 2016, KNOWING LOOK ADAPTIV
   [Anonymous], 2012, P INTERSPEECH 2012 P
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2018, HINDAWI MOBILE INF S, DOI DOI 10.1155/2018/4070283
   [Anonymous], 2013, P 51 ANN M ASS COMP
   [Anonymous], 2014, COMPUTER SCI
   [Anonymous], 2015, Guiding Long-Short Term Memory for Image Caption Generation
   Bahdanau D., 2015, P INT C LEARN REPR
   Bin JC, 2019, MULTIMED TOOLS APPL, V78, P31163, DOI 10.1007/s11042-019-07895-5
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Fang F, 2018, ASIA COMMUN PHOTON
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Ge HW, 2019, MULTIMED TOOLS APPL, V78, P20533, DOI 10.1007/s11042-019-7404-z
   Guo YJ, 2018, IEEE GEOSCI REMOTE S, V15, P1016, DOI 10.1109/LGRS.2018.2822266
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuznetsova Polina, 2012, Association for Computational Linguistics
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Ren S, 2015, NIPS, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Sak H, 2014, INTERSPEECH, P338
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   Yang Z., 2016, ENCODE REV DECODE RE
   Yao T, 2016, BUCKLING AND ULTIMATE STRENGTH OF SHIP AND SHIP-LIKE FLOATING STRUCTURES, P495
   Ye SM, 2018, IEEE T IMAGE PROCESS, V27, P5514, DOI 10.1109/TIP.2018.2855406
   Zhu ZH, 2018, IEEE IMAGE PROC, P2615, DOI 10.1109/ICIP.2018.8451083
NR 34
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35329
EP 35350
DI 10.1007/s11042-019-08116-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800049
DA 2024-07-18
ER

PT J
AU Liu, JY
   Qiao, R
   Li, YY
   Li, S
AF Liu, Jianyi
   Qiao, Rui
   Li, Yueying
   Li, Sheng
TI Witness detection in multi-instance regression and its application for
   age estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; Web images; Multiple instance regression; Positive
   instance detection; Supervised citer kNN
AB The huge data resource on the Web provides us with an emerging chance to solve the lack of training sample problem that lasting for years in facial age estimation. We show that the web images assisted age estimation can be modeled into a Multiple Instance Regression (MIR) problem. Different from the traditional Multiple Instance Learning (MIL) problem that deals with the bag-level classification task, we model the age estimation problem as an instance-level task. To this end, it is essential to reveal the latent instance labels from all bags. In this paper, we propose a novel algorithm named Witness Detecting Multi-instance Regression (WDMR) that can find all possible positive instances from training bags and use them to train an instance-level regressor. Considering the connection between neighbor relationship and inter-/intra- class differences among instances, we develop a Supervised Citer k-Nearest Neighbor (SC-kNN) graph and a sparse voting strategy to address these problems within a joint learning framework. Experimental results on synthetic and real-world datasets have verified the advantages of our method compared with other state-of-the-art MIL approaches.
C1 [Liu, Jianyi; Qiao, Rui; Li, Yueying] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
   [Li, Sheng] Univ Georgia, Dept Comp Sci, Athens, GA 30602 USA.
C3 Xi'an Jiaotong University; University System of Georgia; University of
   Georgia
RP Liu, JY (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
EM jyliu@xjtu.edu.cn; 18709210718@163.com; liyueying94@163.com;
   sheng.li@uga.edu
OI Li, Sheng/0000-0003-1205-8632
FU China Scholarship Council (CSC) [201706285003]; Provincial Key
   Laboratory Program of Shaanxi [2013SZS12-K01]; National Natural
   Scientific Foundation of China [61379104]
FX This work is supported by the funding of China Scholarship Council (CSC)
   (No.201706285003), the Provincial Key Laboratory Program of Shaanxi (No.
   2013SZS12-K01), and the National Natural Scientific Foundation of China
   (No.61379104).
CR Andrews S., 2003, Advances in Neural Information Processing Systems 15(NIPS*2002), P1
   [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], P ICCV
   [Anonymous], 2019, IEEE T IND ELECT
   Astorino A., 2019, IEEE T NEUR NET LEAR, P1
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   He ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3846, DOI 10.1109/TIP.2017.2655445
   Jia M, 2017, PATTERN RECOGNITION
   Kraus OZ, 2016, BIOINFORMATICS, V32, P52, DOI 10.1093/bioinformatics/btw252
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Li K, 2018, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2018.00049
   Li YF, 2009, LECT NOTES ARTIF INT, V5782, P15
   Liao HB, 2019, MULTIMED TOOLS APPL, V78, P2181, DOI 10.1007/s11042-018-6342-5
   Liu Guangliang., 2012, Advances in Environmental Chemistry and Toxicology of Mercury, P1
   Ma Y, 2015, NEUROCOMPUTING, V147, P380, DOI 10.1016/j.neucom.2014.06.047
   Mathias M., 2014, EUR C COMP VIS
   Ni BB, 2011, IEEE T MULTIMEDIA, V13, P1217, DOI 10.1109/TMM.2011.2167317
   Wang D, 2006, LECT NOTES COMPUT SC, V4212, P473
   Wang H., 2000, ADV IND CON, P1
   Yang X., 2014, International Conference on Electrical Machines, P1
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhong P, 2019, IEEE T NEUR NET LEAR, P1
NR 26
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33703
EP 33722
DI 10.1007/s11042-019-08203-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600052
DA 2024-07-18
ER

PT J
AU Tong, T
   Zhu, XF
   Du, TT
AF Tong, Tao
   Zhu, Xiaofeng
   Du, Tingting
TI Connected graph decomposition for spectral clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local PCA; Spectral clustering; Connected graph decomposition
ID FEATURE-SELECTION; SPARSE; CLASSIFICATION; REGRESSION; REDUCTION;
   ALGORITHM; IMAGE
AB This paper proposes a new spectral clustering method based on local Principal Component Analysis (PCA) and connected graph decomposition. Specifically, our method randomly select centroids of the data set to take global structure of data points into consideration, and then uses local PCA to preserve the local structure of data points for constructing the similarity matrix. Furthermore, our method employs the connected graph decomposition to partition the resulting similarity matrix to group data points into clusters. Experimental analysis on 12 UCI data sets showed that our proposed method outperformed the state-of-the-art clustering methods in terms of clustering performance.
C1 [Tong, Tao; Zhu, Xiaofeng; Du, Tingting] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Zhu, Xiaofeng] Massey Univ, Inst Nat & Math Sci, Auckland 0745, New Zealand.
C3 Guangxi Normal University; Massey University
RP Zhu, XF (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Zhu, XF (corresponding author), Massey Univ, Inst Nat & Math Sci, Auckland 0745, New Zealand.
EM seanzhuxf@gmail.com
RI Zhu, Xiaofeng/HII-5291-2022
OI Zhu, Xiaofeng/0000-0001-6840-0578
FU China Key Research Program [2016YFB1000905]; Natural Science Foundation
   of China [61876046, 61573270, 61672177]; Project of Guangxi Science and
   Technology [GuiKeAD17195062]; Guangxi Natural Science Foundation
   [2015GXNSFCB139011]; Guangxi Collaborative Innovation Center of
   Multi-Source Information Integration and Intelligent Processing; Guangxi
   High Institutions Program of Introducing 100 High-Level Overseas
   Talents; Guangxi Key Lab of Multisource Information Mining Security
   [18-A-01-01]
FX This work is partially supported by the China Key Research Program
   (Grant No: 2016YFB1000905); the Natural Science Foundation of China
   (Grants No: 61876046, 61573270 and 61672177); the Project of Guangxi
   Science and Technology (GuiKeAD17195062); the Guangxi Natural Science
   Foundation (Grant No: 2015GXNSFCB139011); the Guangxi Collaborative
   Innovation Center of Multi-Source Information Integration and
   Intelligent Processing; the Guangxi High Institutions Program of
   Introducing 100 High-Level Overseas Talents; and the Research Fund of
   Guangxi Key Lab of Multisource Information Mining & Security
   (18-A-01-01).
CR Arias-Castro E, 2017, J MACH LEARN RES, V18, P1
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fei W, 2015, SURVEY ON DISTANCE M
   Fodor I. K, 2002, SURVEY DIMENSION RED
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Geach JE, 2012, MON NOT R ASTRON SOC, V419, P2633, DOI 10.1111/j.1365-2966.2011.19913.x
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Jolliffe I.T., 1986, PRINCIPAL COMPONENT, P129, DOI 10.1007/978-1-4757-1904-8_8
   Kaufman L., 1987, Statistical Data Analysis Based on the L1-Norm and Related Methods. First International Conference, P405
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Li Y, 2016, MULTIMED TOOLS APPL, V76, P1, DOI DOI 10.1007/S11042-016-4118-3
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   MacQueen J, 1965, P 5 BER S MATH STAT, P281
   Pang YW, 2005, LECT NOTES COMPUT SC, V3644, P117
   Riffenburgh RH, 1960, ENCY SYSTEMBIOL, V3, P27, DOI DOI 10.1007/978-1-4419-9863-7_395
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scholkopf B., 2003, ADV KERNEL METHODS S, V27, P555
   Shashanka M., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P499, DOI 10.1109/ICDMW.2010.109
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song JK, 2016, IEEE T MULTIMEDIA, V18, P484, DOI 10.1109/TMM.2016.2515990
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tran TN, 2013, CHEMOMETR INTELL LAB, V120, P92, DOI 10.1016/j.chemolab.2012.11.006
   Wang S., 2011, AAAI, V1, P519
   Yang MH, 2003, LECT NOTES COMPUT SC, V2626, P470
   Yang Y, 2019, IEEE T KNOWL DATA EN, V31, P757, DOI 10.1109/TKDE.2018.2842190
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang Y, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026018
   Zhang Y, 2012, BIOMED SIGNAL PROCES, V7, P104, DOI 10.1016/j.bspc.2011.02.002
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhu X, 2018, LOCAL GLOBAL STRUCTU, P517
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2017, IEEE T BIG DATA, V3, P405, DOI 10.1109/TBDATA.2017.2735991
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zhu Yingying, 2017, Med Image Comput Comput Assist Interv, V10435, P205, DOI 10.1007/978-3-319-66179-7_24
   Zhu YY, 2017, LECT NOTES COMPUT SC, V10265, P158, DOI 10.1007/978-3-319-59050-9_13
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 48
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33247
EP 33259
DI 10.1007/s11042-018-6643-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600030
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Li, XF
   Duan, HR
   Zhang, XL
   Wang, HC
AF Wang, Zeyu
   Li, Xiongfei
   Duan, Haoran
   Zhang, Xiaoli
   Wang, Hancheng
TI Multifocus image fusion using convolutional neural networks in the
   discrete wavelet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multifocus image fusion; Convolutional neural network; Discrete wavelet
   transform
ID SEGMENTATION; LAPLACIAN
AB In this paper, a novel multifocus image fusion algorithm based on the convolutional neural network (CNN) in the discrete wavelet transform (DWT) domain is proposed. The algorithm combines the advantages of spatial domain- and transform domain-based methods. The CNN is used to amplify features and generate different decision maps for different frequency subbands instead of image blocks or source images. In addition, the CNN, which can be seen as an adaptive fusion rule, replaces the traditional fusion rules. The proposed algorithm includes the following steps: first, we decompose each source image into one low frequency subband and several high frequency subbands using the DWT; second, these frequency subbands are used as input to the CNN to generate weight maps. To obtain a more accurate decision map, it is refined by a series of postprocessing operations, including the sum-modified-Laplacian (SML) and guided filter (GF). According to their decision maps, the frequency subbands are fused; finally, the fused image can be obtained using the inverse DWT. The experimental results show that our algorithm is superior to other algorithms.
C1 [Wang, Zeyu; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Wang, Zeyu; Wang, Hancheng] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
   [Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Duan, Haoran] Newcastle Univ, Sch Comp, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England.
C3 Jilin University; Jilin University; Jilin University; Newcastle
   University - UK
RP Zhang, XL (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.; Zhang, XL (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM zhangxiaoli@jlu.edu.cn
RI Duan, Haoran/HLG-5730-2023; Wang, Zeyu/AFI-7323-2022; Wang,
   Zeyu/AAF-3906-2022; Wang, Ling/AGR-4917-2022; Zhang,
   Xiaoli/ABC-2210-2021
OI Duan, Haoran/0000-0001-9956-7020; Wang, Ling/0000-0003-0272-2974; Wang,
   Zeyu/0000-0002-1223-1661
FU National Science AMP; Technology Pillar Program of China [2012BAH48F02];
   National Natural Science Foundation of China [61801190]; Nature Science
   Foundation of Jilin Province [20180101055JC]; Outstanding Young Talent
   Foundation of Jilin Province [20180520029JH]; China Postdoctoral Science
   Foundation [2017M611323]; Industrial Technology Research and Development
   Funds of Jilin province [2019C054-3]; Fundamental Research Funds for the
   Central Universities, JLU
FX The work was supported by National Science & Technology Pillar Program
   of China (Grant NO.2012BAH48F02), National Natural Science Foundation of
   China (Grant No.61801190), Nature Science Foundation of Jilin Province
   (Grant No.20180101055JC), Outstanding Young Talent Foundation of Jilin
   Province (Grant No.20180520029JH), China Postdoctoral Science Foundation
   (Grant No.2017M611323), Industrial Technology Research and Development
   Funds of Jilin province (2019C054-3), and the Fundamental Research Funds
   for the Central Universities, JLU.
CR Acerbi-Junior FW, 2006, INT J APPL EARTH OBS, V8, P278, DOI 10.1016/j.jag.2006.01.001
   Amin-Naji M., 2018, J AI DATA MINING, V6, P233, DOI DOI 10.22044/JADM.2017.5169.1624
   Anderson CH, 1988, FILTER SUBTRACT DECI
   [Anonymous], CVPR
   [Anonymous], 2015, P IEEE C COMP VIS PA
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Burt PJ, 1987, The Laplacian Pyramid as a Compact Image Code
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Fan D-P, ARXIV180510421
   Fan D-P, 2018, ARXIV180402975
   Fan D-P, 2019, PROC CVPR IEEE, P8554, DOI DOI 10.1109/CVPR.2019.00875
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Gao Z, 2019, IEEE INTERNET THINGS
   Guo XP, 2018, NEURAL COMPUT, V30, P1775, DOI 10.1162/neco_a_01098
   Gutman I, 2006, LINEAR ALGEBRA APPL, V414, P29, DOI 10.1016/j.laa.2005.09.008
   Hareeta M, 2016, COMM COM INF SC, V628, P111, DOI 10.1007/978-981-10-3433-6_14
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Holzinger A, 2018 WORLD S DIG INT, P55
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hou Q, 2018, ARXIV180309859
   Hu Yuan-Ting, 2018, ECCV, P786
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Jia Y, P 22 ACM INT C MULT
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P23501, DOI 10.1007/s11042-018-5659-4
   Kong J, 2008, INT J COMPUT SCI NET, V8, P220
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee K, 2015, TENCON IEEE REGION
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li ZH, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1050
   Liu Y., 2018, ARXIV180402864
   Liu Y, 2019, DNA DEEPLY SUPERVISE
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Lv X, 2019, FUTURE GENER COMP SY, V100, P473, DOI 10.1016/j.future.2019.05.021
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Norouzi M, 2018, ADV NEURAL INF PROCE, V2, P1061
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Pan Y, FRONTIERS COMPUTER S
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Piella G., 2008, ASTRON NACHR, V173, P267
   Qu Xiao-bo, 2009, Optics and Precision Engineering, V17, P1203
   Sermanet Pierre, OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks arXiv
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Wu Z, 2018, J INDIAN SOC REMOTE, V3, P1
   Xiao-bo Q., 2009, OPT PRECIS ENG, V17, P1203
   Xu KP, 2018, KSII T INTERNET INF, V12, P2253, DOI 10.3837/tiis.2018.05.019
   Yin M, 2017, NEUROCOMPUTING, V226, P182, DOI 10.1016/j.neucom.2016.11.051
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhang Q, 2011, PATTERN RECOGN LETT, V32, P1544, DOI 10.1016/j.patrec.2011.06.002
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao H, 2008, IMAGE VISION COMPUT, V26, P1285, DOI 10.1016/j.imavis.2008.03.007
   Zhao J-X, 2019, P IEEE C COMP VIS PA
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 68
TC 29
Z9 32
U1 2
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34483
EP 34512
DI 10.1007/s11042-019-08070-6
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800012
DA 2024-07-18
ER

PT J
AU Gopalakrishnan, C
   Iyapparaja, M
AF Gopalakrishnan, C.
   Iyapparaja, M.
TI Active contour with modified Otsu method for automatic detection of
   polycystic ovary syndrome from ultrasound image of ovary
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Follicle; PCOS; Ultrasound image active contour; Modified Otsu
ID MATURE CYSTIC TERATOMA; MALIGNANT-TRANSFORMATION; NOISE
AB Polycystic ovary syndrome (PCOS) disorder is identified by the presence of a number of follicles present in the ovary of female reproductive system. Ultrasound imaging of the ovary contains essential information about the size, number of follicles and its position. In real time, the detection of PCOS is a difficult task for radiologists due to the various sizes of follicles and is highly connected with blood vessels and tissues. This often results in error diagnosis. For preprocessing various standard filtering techniques are applied on ovary image. Based on the performance, appropriate filter is chosen to remove the noise from the image. This paper presents an effectual active contour with modified Otsu threshold value to automated discovery of follicles from the ultrasound images. The performances of the proposed method illustrate the betterments of the proposed approach over other techniques.
C1 [Gopalakrishnan, C.; Iyapparaja, M.] VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Gopalakrishnan, C (corresponding author), VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM arungopalit@gmail.com; Iyapparaja@vit.ac.in
RI chandrasekaran, Gopalakrishnan/ABG-4452-2020
OI Chandran, Gopalakrishnan/0000-0002-3178-6443
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P5419, DOI [10.1007/s11042-018-6266-0, 10.1007/s11042-018-5840-9]
   [Anonymous], 2018, CLUSTER COMPUTING
   Bal Amanjit, 2007, Archives of Gynecology and Obstetrics, V275, P179, DOI 10.1007/s00404-006-0244-x
   Balen AH, 2003, HUM REPROD UPDATE, V9, P505, DOI 10.1093/humupd/dmg044
   Battaglia C, 1997, GYNECOL ENDOCRINOL, V11, P105, DOI 10.3109/09513599709152520
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Courant R, 1928, MATH ANN, V100, P32, DOI 10.1007/BF01448839
   Deng YH, 2011, ARTIF INTELL MED, V51, P199, DOI 10.1016/j.artmed.2010.10.002
   Finn S, 2011, IEEE T ULTRASON FERR, V58, P82, DOI 10.1109/TUFFC.2011.1776
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gharbia R, 2018, FUTURE GENER COMP SY, V88, P501, DOI 10.1016/j.future.2018.06.022
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   HANNA MD, 1994, ULTRASOUND OBST GYN, V4, P488, DOI 10.1046/j.1469-0705.1994.04060488.x
   HIREMATH PS, 2011, INT J SERV COMPUT CO, V1, P26
   HIREMATH PS, 2010, INT J COMPUTER APPL, P15
   Iyapparaja M., 2017, IOP Conference Series: Materials Science and Engineering, V263, DOI 10.1088/1757-899X/263/4/042018
   IYAPPARAJA M, 2017, RES J PHARM TECHNOLO, V10, P2487
   Jeyalakshmi TR, 2010, International Journal of Computer and Electrical Engineering, V2, P54, DOI [DOI 10.7763/IJCEE.2010.V2.112, 10.7763/IJCEE.2010.V2.112]
   Kelsey TW, 2012, OBSTET GYNECOL INT, V2012, DOI 10.1155/2012/305025
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   *MED INC, 2007, MED GUID POL OV SYND
   Mehrotra R, 2011, 2011 8TH IEEE INTERNATIONAL CONFERENCE AND WORKSHOPS ON ENGINEERING OF AUTONOMIC AND AUTONOMOUS SYSTEMS (EASE), P1, DOI 10.1109/EASe.2011.17
   Michailovich OV, 2006, IEEE T ULTRASON FERR, V53, P64, DOI 10.1109/TUFFC.2006.1588392
   Murugan NS, 2018, WIRELESS PERS COMMUN, V103, P1353, DOI 10.1007/s11277-018-5513-z
   Nicolae L.M. M. C., 2010, Romanian Journal of Biophysics, V20, P13
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PACHE TD, 1992, RADIOLOGY, V183, P421, DOI 10.1148/radiology.183.2.1561343
   Pellicer A, 1998, J REPROD IMMUNOL, V39, P29, DOI 10.1016/S0165-0378(98)00012-6
   PHILLIPS C, 1999, MIT UNDERGRADUATE J
   Sudha S., 2009, International journal of computer theory and engineering, V1, P7, DOI 10.7763/IJCTE.2009.V1.2
   Yamanaka Y, 2005, EUR J GYNAECOL ONCOL, V26, P391
   Yinhui D, 2008, P 30 ANN INT C IEEE, P20
NR 35
TC 12
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17169
EP 17192
DI 10.1007/s11042-019-07762-3
EA NOV 2019
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000495055900001
DA 2024-07-18
ER

PT J
AU Chen, YF
   Wang, LW
   Li, CK
   Hou, YH
   Li, WQ
AF Chen, Yanfang
   Wang, Liwei
   Li, Chuankun
   Hou, Yonghong
   Li, Wanqing
TI ConvNets-based action recognition from skeleton motion maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Action recognition; Convolutional neural networks;
   Skeleton motion maps
ID FACE
AB With the advance of deep learning, deep learning based action recognition is an important research topic in computer vision. The skeleton sequence is often encoded into an image to better use Convolutional Neural Networks (ConvNets) such as Joint Trajectory Maps (JTM). However, this encoding method cannot effectively capture long temporal information. In order to solve this problem, This paper presents an effective method to encode spatial-temporal information into color texture images from skeleton sequences, referred to as Temporal Pyramid Skeleton Motion Maps (TPSMMs), and Convolutional Neural Networks (ConvNets) are applied to capture the discriminative features from TPSMMs for human action recognition. The TPSMMs not only capture short temporal information, but also embed the long dynamic information over the period of an action. The proposed method has been verified and achieved the state-of-the-art results on the widely used UTD-MHAD, MSRC-12 Kinect Gesture and SYSU-3D datasets.
C1 [Chen, Yanfang; Wang, Liwei; Li, Chuankun; Hou, Yonghong] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Li, Wanqing] Univ Wollongong, Adv Multimedia Res Lab, Wollongong, NSW, Australia.
C3 Tianjin University; University of Wollongong
RP Li, CK (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM cyftju@163.com; suoaiw700a@tju.edu.cn; cl564@uowmail.edu.au;
   houroy@tju.edu.cn; wanqing@uow.edu.au
RI Li, Wanqing/ABG-2620-2020
OI Li, Chuankun/0000-0001-9427-8780; Li, Wanqing/0000-0002-4427-2687
FU National Natural Science Foundation of China [61571325]; Key Projects in
   the Tianjin Science and Technology Pillar Program [16ZXHLGX00190]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No.61571325 and in part by the Key
   Projects in the Tianjin Science and Technology Pillar Program under
   Grant No.16ZXHLGX00190.
CR [Anonymous], DICTA
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, 2012 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2012.6239231
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chollet F, 2015, KERAS
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Gowayyed M.A., 2013, Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, P1351
   Hu JF, 2016, LECT NOTES COMPUT SC, V9905, P280, DOI 10.1007/978-3-319-46448-0_17
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hussein, 2013, INT JOINT C ART INT
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu J., 2017, P CVPR WORKSH LONG B
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu Juncheng., 2017, P IEEE C COMPUTER VI, P792, DOI DOI 10.1109/CVPR.2017.391
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Peng Wang, 2014, Database and Expert Systems Applications 25th International Conference (DEXA 2014). Proceedings: LNCS 8645, P1, DOI 10.1007/978-3-319-10085-2_1
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xie CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1639
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, NEUROCOMPUTING, V74, P3946, DOI 10.1016/j.neucom.2011.08.011
   Yang S, 2014, INT C PATT RECOG, P2613, DOI 10.1109/ICPR.2014.451
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yonghong Hou, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 46
TC 19
Z9 19
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1707
EP 1725
DI 10.1007/s11042-019-08261-1
EA NOV 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495055800002
DA 2024-07-18
ER

PT J
AU Attaullah
   Javeed, A
   Shah, T
AF Attaullah
   Javeed, Adnan
   Shah, Tariq
TI Cryptosystem techniques based on the improved Chebyshev map: an
   application in image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Substitution box (S-box); Encryption; Substitution
ID S-BOXES; SUBSTITUTION BOX; CHAOTIC MAP; ALGORITHM; CONSTRUCTION;
   CRYPTOGRAPHY
AB The use of nonlinear (chaotic) transformations in cryptography to create confusion during encryption process has become a common practice. In this paper, a pair of proficient cryptosystem techniques are proposed in the form of substitution and permutation constructed on the one-dimensional chaotic map (Improved Chebyshev map). Initially, an efficient and simple method for the construction of S-box using one-dimensional chaotic system is presented. The main advantage of the suggested scheme is to generate strong S-boxes depending upon keys used by chaotic map. Then, an efficient encryption scheme based on substitution box and the chaotic map (substitution and permutation system) is presented. Experimental consequences validate the efficiency of anticipated algorithms. A great potential and higher performance for noticeable dominance regarding cryptographic applications can be seen for the presented cryptosystems in comparison with the algorithms already developed in literature.
C1 [Attaullah; Javeed, Adnan; Shah, Tariq] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Javeed, A (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM ajaveed@math.qau.edu.pk
RI ullah, Atta/IAM-4174-2023
OI ullah, Atta/0000-0003-2640-2377
CR Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   El-Latif A. A. A., 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P369, DOI 10.1109/IIHMSP.2011.67
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hao BL, 1993, Starting with parabolas-an introduction to chaotic dynamics
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Hussain I, 2013, NONLINEAR DYNAM, V71, P133, DOI 10.1007/s11071-012-0646-1
   Hussain I, 2012, NONLINEAR DYNAM, V70, P1791, DOI 10.1007/s11071-012-0573-1
   Hussain I, 2012, COMPUT MATH APPL, V64, P2450, DOI 10.1016/j.camwa.2012.05.017
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu YS, 2016, NONLINEAR DYNAM, V84, P2241, DOI 10.1007/s11071-016-2642-3
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P1311, DOI 10.1007/s11071-014-1517-8
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   PARKER AT, 2001, IEEE T CIRCUITS-I, V48, P104
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Stoyanov B, 2015, ENTROPY-SWITZ, V17, P2117, DOI 10.3390/e17042117
   Stoyanov B, 2014, SCI WORLD J, DOI 10.1155/2014/283639
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yi X, 2002, INT C INF NETW APPL, V2, P14
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhou CS, 1999, PHYS REV E, V60, P320, DOI 10.1103/PhysRevE.60.320
NR 40
TC 16
Z9 16
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31467
EP 31484
DI 10.1007/s11042-019-07981-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000022
DA 2024-07-18
ER

PT J
AU Din, IU
   Asmat, H
   Guizani, M
AF Din, Ikram Ud
   Asmat, Hamid
   Guizani, Mohsen
TI A review of information centric network-based internet of things:
   communication architectures, design issues, and research opportunities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE ICN; IoT design issues; SDN; Fog; Cloud; Edge; 5G
ID CHALLENGES; FUTURE; STRATEGY; IOT; ICN; 5G
AB In the perspective of Internet advancements for the future Internet, Information Centric Network (ICN) offers a communication model, which is different from the current IP-based paradigm. ICN is a name based communication architecture, where the retrieval of content is done using names rather than their locations. Besides, ICN provides other features such as caching, mobility, scalability, and robustness. Future Internet will have Internet of Things (IoT) devices that will provide very strict requirements. The integration of ICN with IoT opens a new set of design issues and opportunities for researchers. This paper sheds light on the ICN-based IoT design issues and explains some of the research opportunities in which ICN accommodates other Internet technologies, for example, Cloud, Software Defined Network (SDN), Edge, Fog, and 5G. Besides the IoT-ICN integration, IoT also requires suitable wireless communication standards. This paper also provides a description of several wireless communication standards and elaborates their main features. IoT designers will benefit from the provided description to make a decision for the selection of an appropriate standard.
C1 [Din, Ikram Ud; Asmat, Hamid] Univ Haripur, Dept Informat Technol, Haripur, Pakistan.
   [Guizani, Mohsen] Qatar Univ, Comp Sci & Engn Dept, Coll Engn, Doha, Qatar.
C3 Qatar University
RP Din, IU (corresponding author), Univ Haripur, Dept Informat Technol, Haripur, Pakistan.
EM ikramuddin205@yahoo.com; hamid@uoh.edu.pk; mguizani@ieee.org
RI Ud Din, Ikram/AAK-4524-2020; Guizani, Mohsen/AAX-4534-2021
OI Ud Din, Ikram/0000-0001-8896-547X; Guizani, Mohsen/0000-0002-8972-8094
CR Adhatarao Sripriya, 2018, 2018 10th International Conference on Communication Systems & Networks (COMSNETS), P251, DOI 10.1109/COMSNETS.2018.8328205
   Amadeo C., 2014, NETWORKS COMMUNICATI, P1
   Amadeo M., 2018, European Wireless 2018; 24th European Wireless Conference, P1
   Amadeo M, 2019, INTERNET THINGS-TECH, P75, DOI 10.1007/978-3-319-96550-5_4
   Amadeo M, 2016, IEEE NETWORK, V30, P92, DOI 10.1109/MNET.2016.7437030
   Andrews JG, 2014, IEEE J SEL AREA COMM, V32, P1065, DOI 10.1109/JSAC.2014.2328098
   [Anonymous], TECH REP
   [Anonymous], 2012, International Journal of Future Computer and Communication
   [Anonymous], TECH REP
   [Anonymous], ZIGBEE WIRELESS NETW
   [Anonymous], 2017 20 INT S WIR PE
   [Anonymous], TECH REP
   [Anonymous], J COMMUNITY INFORM
   [Anonymous], 2017, 2017 IEEE 85 VEH TEC
   [Anonymous], IEEE INT C SMART EN
   [Anonymous], 2018, IEEE ACCESS
   [Anonymous], 11 INT C SENS TECHN
   [Anonymous], COMPUTER J
   [Anonymous], 17 AS PAC C COMM
   [Anonymous], CORR
   [Anonymous], TECH REP
   [Anonymous], TECH REP
   [Anonymous], IEEE 11 INT C WIR MO
   [Anonymous], 2001, BLUETOOTH 1 1 CONNEC
   [Anonymous], INT J SCI ENG RES
   [Anonymous], IEEE T CLOUD COMPUTI
   [Anonymous], P AFIPS 70 FALL P FA, DOI [10.1145/1478462.1478502, DOI 10.1145/1478462.1478502]
   [Anonymous], TECH REP
   [Anonymous], TECH REP
   [Anonymous], 2007, IECON 2007 33 ANN C
   [Anonymous], TECH REP
   [Anonymous], INT J DISTRIB SENS N
   [Anonymous], IEEE INT C SYST MAN
   [Anonymous], 2017, NVIDIA Tesla V100 GPU architecture
   [Anonymous], 2013, IEEE INT C COMP COMM
   [Anonymous], 2010, Tech.rep
   [Anonymous], 2017 INT C COMP NETW
   [Anonymous], IEEE 14 INT C NETW S
   [Anonymous], 2012, J ADV INTERNET THING, DOI DOI 10.4236/AIT.2012.22003
   Atzori L, 2017, AD HOC NETW, V56, P122, DOI 10.1016/j.adhoc.2016.12.004
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Borgia E, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P422, DOI 10.1109/ISCC.2016.7543776
   Borgia E, 2014, COMPUT COMMUN, V54, P1, DOI 10.1016/j.comcom.2014.09.008
   Din IU, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113957
   Din IU, 2018, IEEE COMMUN SURV TUT, V20, P1443, DOI 10.1109/COMST.2017.2787609
   Evans-Pughe C, 2003, IEE REVIEW, V49, P28, DOI 10.1049/ir:20030303
   Ferro E, 2005, IEEE WIREL COMMUN, V12, P12, DOI 10.1109/MWC.2005.1404569
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hahm O, 2016, IEEE GLOBE WORK
   Hail MA, 2015, 2015 INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN INTERNET OF THINGS (RIOT)
   Hannan A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082431
   Hassan SM, 2016, IEEE IMTC P, P648
   Jammal M, 2014, COMPUT NETW, V72, P74, DOI 10.1016/j.comnet.2014.07.004
   Kamerman A, 1997, BELL LABS TECH J, V2, P118, DOI 10.1002/bltj.2069
   Katsaros KV, 2015, 2015 IFIP NETWORKING CONFERENCE (IFIP NETWORKING)
   Lee JS, 2006, IEEE T CONSUM ELECTR, V52, P742
   Li J, 2013, IEEE COMMUN LETT, V17, P797, DOI 10.1109/LCOMM.2013.022213.122741
   Li R, 2017, IEEE INTERNET THINGS, V4, P791, DOI 10.1109/JIOT.2017.2666799
   Madakam Somayya., 2015, Journal of Computer and Communications, V3, P164
   Meddeb M, 2017, PROCEDIA COMPUT SCI, V109, P1067, DOI 10.1016/j.procs.2017.05.385
   Naeem MA, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10072576
   Nunes BAA, 2014, IEEE COMMUN SURV TUT, V16, P1617, DOI 10.1109/SURV.2014.012214.00180
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Qin YR, 2016, J NETW COMPUT APPL, V64, P137, DOI 10.1016/j.jnca.2015.12.016
   Quevedo J, 2014, IEEE GLOB COMM CONF, P2770, DOI 10.1109/GLOCOM.2014.7037227
   Quevedo J, 2014, IEEE CONF COMPUT, P482, DOI 10.1109/INFCOMW.2014.6849279
   Ravindran R., 2013, IEEE 2 INT C CLOUD N
   Ravindran R, 2017, IEEE COMMUN MAG, V55, P101, DOI 10.1109/MCOM.2017.1600938
   Ravindran R, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1102
   Ren Z, 2013, 2013 IEEE EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING, P123, DOI 10.1109/ISSNIP.2013.6529776
   Satyanarayanan M, 2017, COMPUTER, V50, P30, DOI 10.1109/MC.2017.9
   Shang WT, 2014, IEEE NETWORK, V28, P50, DOI 10.1109/MNET.2014.6843232
   Sheng ZG, 2013, IEEE WIREL COMMUN, V20, P91, DOI 10.1109/MWC.2013.6704479
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Shrimali R., 2017, Advances in internet of Things, Vol, V7, P11, DOI DOI 10.4236/AIT.2017.72002
   Suarez J, 2016, J NETW COMPUT APPL, V63, P190, DOI 10.1016/j.jnca.2016.01.016
   Sun CL, 2012, AASRI PROC, V1, P106, DOI 10.1016/j.aasri.2012.06.019
   Vural S, 2017, IEEE ACM T NETWORK, V25, P1048, DOI 10.1109/TNET.2016.2616359
   Weis S.A., 2007, System, V2, P1
   Xylomenos G, 2014, IEEE COMMUN SURV TUT, V16, P1024, DOI 10.1109/SURV.2013.070813.00063
   Yi S., 2015, P 2015 WORKSH MOB BI, P37
   Yu XP, 2011, MOL CELL PROTEOMICS, V10, DOI 10.1074/mcp.M111.012500
   Zhang DZ, 2017, J ADV TRANSPORT, DOI 10.1155/2017/6350562
   Zhang Z, 2018, COMPUT COMMUN, V118, P81, DOI 10.1016/j.comcom.2017.10.002
   Zhao WC, 2017, IEEE ACCESS, V5, P12657, DOI 10.1109/ACCESS.2017.2714191
NR 86
TC 33
Z9 35
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30241
EP 30256
DI 10.1007/s11042-018-6943-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200034
DA 2024-07-18
ER

PT J
AU Dong, XM
   Ai, LF
   Jiang, R
AF Dong, Xiaoming
   Ai, Liefu
   Jiang, Rong
TI Motion estimation of indoor robot based on image sequences and improved
   particle filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Visual odometry; Indoor robot; Localization; Motion
   estimation
ID RECURSIVE ESTIMATION
AB Robot motion estimation is fundamental in most robot applications such as robot navigation, which is an indispensable part of future internet of things. Indoor robot motion estimation is difficult to be resolved because GPS (Global Positioning System) is unavailable. Vision sensors can provide larger amount of image sequences information compared with other traditional sensors, but it is subject to the changes of light. In order to improve the robustness of indoor robot motion estimation, an enhanced particle filter framework is constructed: firstly, motion estimation was implemented based on the distinguished indoor feature points; secondly, particle filter method was utilized and the least square curve fitting was inserted into the particle resampling process to solve the problem of particle depletion. The various experiments based on real robots show that the proposed method can reduce the estimation errors greatly and provide an effective resolution for the indoor robot localization and motion estimation.
C1 [Dong, Xiaoming; Ai, Liefu] Anqing Normal Univ, Univ Key Lab Intelligent Percept & Comp Anhui Pro, Anqing 246133, Anhui, Peoples R China.
   [Jiang, Rong] Yunnan Univ Finance & Econ, Sch Informat, Kunming 650221, Yunnan, Peoples R China.
C3 Anqing Normal University; Yunnan University of Finance & Economics
RP Jiang, R (corresponding author), Yunnan Univ Finance & Econ, Sch Informat, Kunming 650221, Yunnan, Peoples R China.
EM jiang_rong@aliyun.com
FU National Natural Science Foundation of China [61763048, 61263022,
   61303234]; National Social Science Foundation of China [12XTQ012];
   Science and Technology Foundation of Yunnan Province [2017FB095,
   201801PF00021]; 18th Yunnan Young and Middle-aged Academic and Technical
   Leaders Reserve Personnel Training Program [2015HB038]; Foundation of
   University Research and Innovation Platform Team for Intelligent
   Perception and Computing of Anhui Province; key research project of
   natural science of Anhui Provincial Education Department [KJ2017A354];
   Anhui Provincial Natural Science Foundation of China [1608085MF144]
FX The paper was supported by National Natural Science Foundation of China
   (Nos. 61763048,61263022, 61303234), National Social Science Foundation
   of China (No. 12XTQ012), Science and Technology Foundation of Yunnan
   Province (Nos. 2017FB095, 201801PF00021), the 18th Yunnan Young and
   Middle-aged Academic and Technical Leaders Reserve Personnel Training
   Program (No.2015HB038). It is also supported by the Foundation of
   University Research and Innovation Platform Team for Intelligent
   Perception and Computing of Anhui Province, key research project of
   natural science of Anhui Provincial Education Department (KJ2017A354).
   Anhui Provincial Natural Science Foundation of China (1608085MF144). The
   authors would like to thank the anonymous reviewers and the editors for
   their suggestions.
CR Alon J, 2000, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2000.854911
   [Anonymous], 2002, 18 NATL C ARTIFICIAL, DOI DOI 10.1007/S00244-005-7058-X
   Ascani A, 2008, IROS
   AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503
   BORTZ JE, 1971, IEEE T AERO ELEC SYS, VAES7, P61, DOI 10.1109/TAES.1971.310252
   Bronzwaer SLAM, 2002, EMERG INFECT DIS, V8, P278, DOI 10.3201/eid0803.010192
   Campbell J, 2004, P IROS
   Carlevaris-Bianco N, 2014, IEEE T ROBOT, V30, P1371, DOI 10.1109/TRO.2014.2347571
   Chaolei Wang, 2012, 2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA 2012). Proceedings, P1694, DOI 10.1109/ICIEA.2012.6360998
   Cumani A, 2009, MATH COMPUT SCI ENG, P126
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Eckenhoff K, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P3275, DOI 10.1109/IROS.2016.7759505
   Helmick DM, 2004, P 2004 IEEE AER C BI
   Indelman V, 2016, IEEE ROBOT AUTOM LET, V1, P407, DOI 10.1109/LRA.2016.2518224
   Kandepu R, 2008, J PROCESS CONTR, V18, P753, DOI 10.1016/j.jprocont.2007.11.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Magnabosco M, 2013, ROBOT AUTON SYST, V61, P195, DOI 10.1016/j.robot.2012.09.023
   Ning MF, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030854
   Olson CF, 2003, ROBOT AUTON SYST, V43, P215, DOI 10.1016/S0921-8890(03)00004-6
   Potkonjak M, 2006, IEEE FOCOM, V26, P43
   Sajeeb R, 2009, IJEUU, V1, P1
   Sirtkaya S, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P219
   Ssu KF, 2005, IEEE T VEH TECHNOL, V54, P1187, DOI 10.1109/TVT.2005.844642
   Torr PHS, 1999, INT J COMPUT VISION, V32, P27, DOI 10.1023/A:1008140928553
   Wang H, 2005, IEEE INT C INF ACQ I
   Wu J, 2019, IEEE T SYST MAN CY-S, V49, P638, DOI 10.1109/TSMC.2018.2800783
   Wu J, 2017, INFORM SCIENCES, V420, P517, DOI 10.1016/j.ins.2017.08.085
   Xu D, 2009, IEEE T IND ELECTRON, V56, P1617, DOI 10.1109/TIE.2009.2012457
NR 28
TC 3
Z9 3
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29747
EP 29763
DI 10.1007/s11042-018-6383-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200007
DA 2024-07-18
ER

PT J
AU Sadeghi, H
   Raie, AA
AF Sadeghi, Hamid
   Raie, Abolghasem-A.
TI Human vision inspired feature extraction for facial expression
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Complex cell; Human vision system; Gabor
   filter; Image texture description
ID EMOTION RECOGNITION; FACE; PATTERNS; SYSTEM
AB Facial expression is a powerful way for human emotional communications. According to various applications, automatic facial expression recognition becomes an interesting problem for researchers in different areas. An automatic facial expression recognition system recognizes the expressed emotion in input facial image using several processing stages. Feature extraction is a vital step in facial expression recognition. One of the most widely used techniques for feature extraction in machine vision is utilizing Gabor filter which is sensitive to lines at various orientations. The disadvantage of Gabor filters is their computational cost and large feature vector length. Inspiring the human vision system and stimulations of complex cells, in this paper, firstly, facial image is convolved with Gabor filters. Then, the achieved convolution matrices are properly coded based on the maximum and minimum responses. Finally, the feature vector is obtained by calculating the histogram of these codes. The length of achieved histogram for 16 and 8 Gabor filters are 240 and 56, respectively, which is considerably less than keeping all Gabor responses. The proposed method is (person-independently) evaluated on four facial expression recognition datasets including CK+, SFEW, MMI, and RAF-DB. The experimental results show that the proposed method outperforms existing image texture descriptors in facial expression recognition in both controlled and uncontrolled images.
C1 [Sadeghi, Hamid; Raie, Abolghasem-A.] Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
C3 Amirkabir University of Technology
RP Raie, AA (corresponding author), Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
EM hamid.sadeghi@aut.ac.ir; raie@aut.ac.ir
CR Acevedo D, 2017, IEEE INT CONF AUTOMA, P802, DOI 10.1109/FG.2017.101
   [Anonymous], 2005, ICME
   [Anonymous], 1997, The psychology of facial expression
   [Anonymous], FACIAL EXPRESSION AN
   [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], 2010, P 3 INT WORKSH EM SA
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], 2018, MULTIMED TOOLS APPL
   [Anonymous], CVPR WORKSH
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Ben XY, 2018, PATTERN RECOGN LETT, V107, P50, DOI 10.1016/j.patrec.2017.07.010
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Gabbiani Fabrizio, 2017, Mathematics for neuroscientists
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7921, DOI 10.1007/s11042-016-3428-9
   Girard JM, 2014, IMAGE VISION COMPUT, V32, P641, DOI 10.1016/j.imavis.2013.12.007
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Highfield R., 2009, NEW SCI
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Hsu FS, 2014, MULTIMED TOOLS APPL, V73, P309, DOI 10.1007/s11042-013-1616-4
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jia XT, 2018, J COMPUT SCI-NETH, V25, P289, DOI 10.1016/j.jocs.2017.03.016
   Joshi J, 2012, INT C PATT RECOG, P2634
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Kandel E., 2013, PRINCIPLES NEURAL SC
   KOBAYASHI H, 1992, IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION : PROCEEDINGS, P387, DOI 10.1109/ROMAN.1992.253856
   KOBAYASHI H, 1992, IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION : PROCEEDINGS, P381
   Lei YM, 2017, BIOMED SIGNAL PROCES, V38, P281, DOI 10.1016/j.bspc.2017.06.014
   LEVENSON RW, 1990, PSYCHOPHYSIOLOGY, V27, P363, DOI 10.1111/j.1469-8986.1990.tb02330.x
   [李瑞 Li Rui], 2018, [现代制造工程, Modern Manufacturing Engineering], P1
   Li ST, 2017, IEEE IND ELEC, P2852
   Linton Oliver., 2017, Probability, statistics and econometrics
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu ZW, 2017, IEEE INT CONF AUTOMA, P967, DOI 10.1109/FG.2017.120
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525
   Majumder A, 2014, PATTERN RECOGN, V47, P1282, DOI 10.1016/j.patcog.2013.10.010
   Min Guo, 2017, Multimedia Tools and Applications, V76, P2995, DOI 10.1007/s11042-016-3282-9
   Moreno P, 2005, LECT NOTES COMPUT SC, V3522, P11
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Niedenthal PM, 2007, SCIENCE, V316, P1002, DOI 10.1126/science.1136930
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pai NS, 2011, COMPUT MATH APPL, V61, P2101, DOI 10.1016/j.camwa.2010.08.082
   Palestra G, 2015, LECT NOTES COMPUT SC, V9280, P518, DOI 10.1007/978-3-319-23234-8_48
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Sadeghi H, 2014, COMM COM INF SC, V427, P100, DOI 10.1007/978-3-319-10849-0_11
   Scherer S., 2013, AUTOMATIC FACE GESTU, P1
   Shams L, 2002, VISION RES, V42, P2547, DOI 10.1016/S0042-6989(02)00202-X
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shu Chang, 2011, Tsinghua Science and Technology, V16, P216, DOI 10.1016/S1007-0214(11)70032-3
   Xiao R, 2011, PATTERN RECOGN, V44, P107, DOI 10.1016/j.patcog.2010.07.017
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
   Zong Y, 2016, J MULTIMODAL USER IN, V10, P163, DOI 10.1007/s12193-015-0210-7
NR 64
TC 24
Z9 25
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30335
EP 30353
DI 10.1007/s11042-019-07863-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200040
DA 2024-07-18
ER

PT J
AU Xu, HJ
   Huang, CQ
   Huang, XD
   Huang, MX
AF Xu, Haijiao
   Huang, Changqin
   Huang, Xiaodi
   Huang, Muxiong
TI Multi-modal multi-concept-based deep neural network for automatic image
   annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Deep neural network; Multi-concept
   semantics; Machine learning
AB Automatic Image Annotation (AIA) remains as a challenge in computer vision with real-world applications, due to the semantic gap between high-level semantic concepts and low-level visual appearances. Contextual tags attached to visual images and context semantics among semantic concepts can provide further semantic information to bridge this gap. In order to effectively capture these semantic correlations, we present a novel approach called Multi-modal Multi-concept-based Deep Neural Network (M2-DNN) in this study, which models the correlations of visual images, contextual tags, and multi-concept semantics. Unlike traditional AIA methods, our M2-DNN approach takes into account not only single-concept context semantics, but also multi-concept context semantics with abstract scenes. In our model, a multi-concept such as {"plane","buildings"} is viewed as one holistic scene concept for concept learning. Specifically, we first construct a multi-modal Deep Neural Network (DNN) as a concept classifier for visual images and contextual tags, and then employ it to annotate unlabeled images. Second, real-world databases commonly include many difficult concepts that are hard to be recognized, such as concepts with similar appearances, concepts with abstract scenes, and rare concepts. To effectively recognize them, we utilize multi-concept semantics inference and multi-modal correlation learning to refine semantic annotations. Finally, we estimate the most relevant labels for each of unlabeled images through a new strategy of label decision. The results of our comprehensive experiments on two publicly available datasets have shown that our method performs favourably compared with several other state-of-the-art methods.
C1 [Xu, Haijiao; Huang, Changqin; Huang, Muxiong] South China Normal Univ, Sch Informat Technol Educ, Guangzhou, Guangdong, Peoples R China.
   [Huang, Changqin] South China Normal Univ, Guangdong Engn Res Ctr Smart Learning, Guangzhou, Guangdong, Peoples R China.
   [Huang, Xiaodi] Charles Sturt Univ, Sch Comp & Math, Albury, NSW, Australia.
C3 South China Normal University; South China Normal University; Charles
   Sturt University
RP Huang, CQ (corresponding author), South China Normal Univ, Sch Informat Technol Educ, Guangzhou, Guangdong, Peoples R China.; Huang, CQ (corresponding author), South China Normal Univ, Guangdong Engn Res Ctr Smart Learning, Guangzhou, Guangdong, Peoples R China.
EM guesskkk@hust.edu.cn; cqhuang@scnu.edu.cn; xhuang@csu.edu.au;
   hmx1103@163.com
RI Huang, Changqin/AAD-4590-2020; XU, HaiJiao/A-3222-2015; Huang,
   Xiaodi/E-9204-2012; Huang, Xiaodi/ABE-6432-2020
OI Huang, Changqin/0000-0003-1371-2608; XU, HaiJiao/0000-0002-3093-7246;
   Huang, Xiaodi/0000-0002-6084-1851; 
FU National Natural Science Foundation of China [61877020]; GDUPS (2015);
   CSC [201706755023]; China Postdoctoral Science Foundation [2016M600657,
   2017T100637]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61877020), the GDUPS (2015), the CSC (No. 201706755023) and
   the China Postdoctoral Science Foundation (No. 2016M600657 and
   2017T100637).
CR [Anonymous], 2014, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2018, NEUROCOMPUTING, DOI DOI 10.1016/j.neucom.2017.09.048
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bai Y, 2014, PROC INT CONF RECON
   Chen A., 2013, ICML, P1274
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hayward CJ, 2011, SALMON LICE: AN INTEGRATED APPROACH TO UNDERSTANDING PARASITE ABUNDANCE AND DISTRIBUTION, P1
   Izadinia H, 2015, MMCOMMONS'15: PROCEEDINGS OF THE 2015 WORKSHOP ON COMMUNITY-ORGANIZED MULTIMODAL MINING: OPPORTUNITIES FOR NOVEL SOLUTIONS, P13, DOI 10.1145/2814815.2814821
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Lai HJ, 2016, IEEE T IMAGE PROCESS, V25, P2469, DOI 10.1109/TIP.2016.2545300
   Li YF, 2017, AER ADV ENG RES, V126, P426
   Lin GF, 2017, PATTERN RECOGN, V68, P14, DOI 10.1016/j.patcog.2017.03.014
   Liu WW, 2015, AAAI CONF ARTIF INTE, P2800
   Liu Z, 2018, EXPERT SYST APPL, V104, P168, DOI 10.1016/j.eswa.2018.03.014
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Nogueira K, 2016, MULTIMED TOOLS APPL, V75, P4083, DOI 10.1007/s11042-015-3087-2
   Shu X, 2015, NEUROCOMPUTING, V168, P356, DOI 10.1016/j.neucom.2015.05.090
   Song Y., 2016, 2016 IEEE INT C VEHI, P1, DOI DOI 10.1109/ICVES.2016.7548171
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wu BY, 2018, INT J COMPUT VISION, V126, P875, DOI 10.1007/s11263-018-1085-3
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Xiang Y, 2010, PROC CVPR IEEE, P3368, DOI 10.1109/CVPR.2010.5540015
   Xie L, 2015, MULTIMED TOOLS APPL, V74, P613, DOI 10.1007/s11042-014-2018-y
   Xu CY, 2016, IEEE T CIRC SYST VID, V26, P2273, DOI 10.1109/TCSVT.2015.2477937
   Xu HL, 2015, SCI CHINA PHYS MECH, V58, DOI 10.1007/s11433-015-5720-5
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
   Zhang W., 2016, P INT JOINT C ART IN, P2153
NR 42
TC 6
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30651
EP 30675
DI 10.1007/s11042-018-6555-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200057
DA 2024-07-18
ER

PT J
AU Yolcu, G
   Oztel, I
   Kazan, S
   Oz, C
   Palaniappan, K
   Lever, TE
   Bunyak, F
AF Yolcu, Gozde
   Oztel, Ismail
   Kazan, Serap
   Oz, Cemil
   Palaniappan, Kannappan
   Lever, Teresa E.
   Bunyak, Filiz
TI Facial expression recognition for monitoring neurological disorders
   based on convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial component segmentation; Facial expression recognition;
   Convolutional neural network; Deep learning
ID FACE
AB Facial expressions are a significant part of non-verbal communication. Recognizing facial expressions of people with neurological disorders is essential because these people may have lost a significant amount of their verbal communication ability. Such an assessment requires time consuming examination involving medical personnel, which can be quite challenging and expensive. Automated facial expression recognition systems that are low-cost and non-invasive can help experts detect neurological disorders. In this study, an automated facial expression recognition system is developed using a novel deep learning approach. The architecture consists of four-stage networks. The first, second and third networks segment the facial components which are essential for facial expression recognition. Owing to the three networks, an iconize facial image is obtained. The fourth network classifies facial expressions using raw facial images and iconize facial images. This four-stage method combines holistic facial information with local part-based features to achieve more robust facial expression recognition. Preliminary experimental results achieved 94.44% accuracy for facial expression recognition on RaFD database. The proposed system produced 5% improvement than the facial expression recognition system by using raw images. This study presents a quantitative, objective and non-invasive facial expression recognition system to help in the monitoring and diagnosis of neurological disorders influencing facial expressions.
C1 [Yolcu, Gozde; Oztel, Ismail; Kazan, Serap; Oz, Cemil] Sakarya Univ, Dept Comp Engn, TR-54050 Serdivan, Sakarya, Turkey.
   [Yolcu, Gozde; Oztel, Ismail; Palaniappan, Kannappan; Bunyak, Filiz] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
   [Lever, Teresa E.] Univ Missouri, Dept Otolaryngol, Columbia, MO 65211 USA.
C3 Sakarya University; University of Missouri System; University of
   Missouri Columbia; University of Missouri System; University of Missouri
   Columbia
RP Bunyak, F (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
EM bunyak@missouri.edu
RI Oztel, Ismail/ABI-4346-2020; Öz, Cemil/HTM-5477-2023; Bunyak,
   Filiz/AFR-4120-2022; Çakar, Serap/HTL-9593-2023; Yolcu Öztel,
   Gözde/HSH-8239-2023
OI Oztel, Ismail/0000-0001-5157-7035; Öz, Cemil/0000-0001-9742-6021; Çakar,
   Serap/0000-0002-3682-0831; Bunyak Ersoy, Filiz/0000-0002-0421-6920
FU Scientific and Technological Research Council of Turkey [TUBITAK-BIDEB
   2214/A]; Sakarya University Scientific Research Projects Unit
   [2015-50-02-039]
FX Gozde Yolcu and Ismail Oztel have worked in this research while at
   University of Missouri-Columbia as visiting scholars and this study was
   supported by The Scientific and Technological Research Council of Turkey
   (TUBITAK-BIDEB 2214/A) and The Sakarya University Scientific Research
   Projects Unit (Project number: 2015-50-02-039).
CR Adams D, 2015, J AUTISM DEV DISORD, V45, P2624, DOI 10.1007/s10803-015-2404-y
   Agarwal S, 2018, VISUAL COMPUT, V34, P177, DOI 10.1007/s00371-016-1323-z
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Aifanti N, 2014, SIGNAL PROCESS-IMAGE, V29, P177, DOI 10.1016/j.image.2013.10.004
   Aina S, 2014, EUR SIGNAL PR CONF, P2505
   Ali G, 2016, PATTERN RECOGN, V55, P14, DOI 10.1016/j.patcog.2016.01.032
   Alphonse AS, 2018, MULTIMED TOOLS APPL, V77, P9455, DOI 10.1007/s11042-017-5141-8
   [Anonymous], COGNIT EMOT
   Aydogdu MF, 2017, IEEE INT C SEMANT CO, P372, DOI 10.1109/ICSC.2017.61
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baugh RF, 2013, OTOLARYNG HEAD NECK, V149, P656, DOI 10.1177/0194599813506835
   Ben Abdallah T, 2018, MULTIMED TOOLS APPL, V77, P19455, DOI 10.1007/s11042-017-5354-x
   Bevilacqua V., 2011, P IEEE INT S MEDICAL, P544, DOI 10.1109/MeMeA.2011.5966766
   Bijlstra G., 2011, FaceReader 4 Emotion Classification Performance On Images from the Radboud Faces Database
   Brewer R, 2016, AUTISM RES, V9, P262, DOI 10.1002/aur.1508
   Cha KH, 2016, MED PHYS, V43, P1882, DOI 10.1118/1.4944498
   Chang J, 2018, MULTIMED TOOLS APPL, V77, P5059, DOI 10.1007/s11042-017-5241-5
   Chen J., 2018, Multimedia Tools and Applications, P1
   Cheng HC, 2017, IEEE IMAGE PROC, P1377, DOI 10.1109/ICIP.2017.8296507
   Dantcheva A, 2017, EUR SIGNAL PR CONF, P783, DOI 10.23919/EUSIPCO.2017.8081314
   Dapogny A, 2018, IEEE INT CONF AUTOMA, P723, DOI 10.1109/FG.2018.00114
   Dornaika F, 2013, ENG APPL ARTIF INTEL, V26, P467, DOI 10.1016/j.engappai.2012.09.002
   Edvinsson SE, 2016, DEV MED CHILD NEUROL, V58, P385, DOI 10.1111/dmcn.12867
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P., 2002, Investigator's guide: Facial action coding system
   Fathallah A, 2017, I C COMP SYST APPLIC, P745, DOI 10.1109/AICCSA.2017.124
   Fernandez-Duque D, 2005, NEUROPSYCHOLOGIA, V43, P1673, DOI 10.1016/j.neuropsychologia.2005.01.005
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Ghimire D, 2015, BIODIVERSITAT UND NATURAUSSTATTUNG IM HIMALAYA V, P143
   Gola KA, 2017, NEUROIMAGE-CLIN, V14, P672, DOI 10.1016/j.nicl.2017.01.016
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guha T, 2015, INT CONF ACOUST SPEE, P803, DOI 10.1109/ICASSP.2015.7178080
   Hinton G. E., 2012, 12070580 ARXIV
   Hosseini S, 2018, PROC INT WORKSH ADV
   Ilbeygi M, 2012, ENG APPL ARTIF INTEL, V25, P130, DOI 10.1016/j.engappai.2011.07.004
   Jia S, 2016, INT CONF DAT MIN WOR, P462, DOI [10.1109/ICDMW.2016.0072, 10.1109/ICDMW.2016.45]
   Khan SA, 2018, MULTIMED TOOLS APPL, V77, P1133, DOI 10.1007/s11042-016-4324-z
   Kohler CG, 2005, AM J GERIAT PSYCHIAT, V13, P926, DOI 10.1176/appi.ajgp.13.11.926
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   LECUN Y, 1989, CONNECTIONISM IN PERSPECTIVE, P143
   Li ZD, 2018, MULTIMED TOOLS APPL, V77, P11775, DOI 10.1007/s11042-017-4818-3
   Lin JW, 2017, J STROKE CEREBROVASC, V26, P834, DOI 10.1016/j.jstrokecerebrovasdis.2016.10.029
   Liu SQ, 2014, I S BIOMED IMAGING, P1015, DOI 10.1109/ISBI.2014.6868045
   Livingstone SR, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00780
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lou YX, 2017, IEEE GLOB CONF SIG, P1280, DOI 10.1109/GlobalSIP.2017.8309167
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Mandache D, 2018, I S BIOMED IMAGING, P784, DOI 10.1109/ISBI.2018.8363689
   Matsugu M, 2003, NEURAL NETWORKS, V16, P555, DOI 10.1016/S0893-6080(03)00115-1
   da Silva FAM, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023015
   MEHRABIA.A, 1969, BEHAV RES METH INSTR, V1, P203
   Min Guo, 2017, Multimedia Tools and Applications, V76, P2995, DOI 10.1007/s11042-016-3282-9
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nigam S, 2018, MULTIMED TOOLS APPL
   Oztel I, 2018, INT J DATA MIN BIOIN, V21, P91, DOI 10.1504/IJDMB.2018.096398
   Oztel I, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023003
   Oztel I, 2017, IEEE INT C BIOINFORM, P1195, DOI 10.1109/BIBM.2017.8217827
   Pitaloka DA, 2017, PROCEDIA COMPUT SCI, V116, P523, DOI 10.1016/j.procs.2017.10.038
   Pons G, 2017, IEEE T AFFECT COMPUT, P1
   Qin XR, 2017, PROC INT CONF DOC, P1074, DOI 10.1109/ICDAR.2017.178
   Rao QY, 2015, INT CONF AFFECT, P630, DOI 10.1109/ACII.2015.7344635
   Ricciardi L, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169110
   S. C. Face++, 2017, FAC COGN SERV
   Saha P, 2018, MULTIMED TOOLS APPL, V77, P20177, DOI 10.1007/s11042-017-5436-9
   Shpilman A, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1, DOI 10.1109/ICMLA.2017.0-186
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2017, 13 INT C MED INF PRO, P84
   Socher R., 2012, NIPS, V3, P8
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Thevenot J, 2018, IEEE J BIOMED HEALTH, V22, P1497, DOI 10.1109/JBHI.2017.2754861
   Uddin MZ, 2017, IEEE ACCESS, V5, P26146, DOI 10.1109/ACCESS.2017.2777003
   Venturelli Marco, 2018, Understanding Human Activities Through 3D Sensors. Second International Workshop, UHA3DS 2016 Held in Conjunction with the 23rd International Conference on Pattern Recognition, ICPR 2016. Revised Selected Papers: LNCS 10188, P74, DOI 10.1007/978-3-319-91863-1_6
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wei B, 2017, COMPUTING RES REPOSI
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Wu CJ, 2018, MULTIMED TOOLS APPL, V77, P11575, DOI 10.1007/s11042-017-5158-z
   Xie WC, 2018, MULTIMED TOOLS APPL, V77, P7565, DOI 10.1007/s11042-017-4661-6
   Xie XD, 2009, PATTERN RECOGN, V42, P1003, DOI 10.1016/j.patcog.2008.08.034
   Yolcu G, 2017, IEEE INT C BIOINFORM, P1652, DOI 10.1109/BIBM.2017.8217907
   Yuvaraj R., 2012, 2012 IEEE Symposium on Industrial Electronics and Applications (ISIEA 2012), P287, DOI 10.1109/ISIEA.2012.6496645
   Zhang H, 2018, IEEE T VEH TECHNOL, P1
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
   Zia MS, 2018, MULTIMED TOOLS APPL, V77, P25537, DOI 10.1007/s11042-018-5806-y
NR 84
TC 39
Z9 42
U1 14
U2 93
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31581
EP 31603
DI 10.1007/s11042-019-07959-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000027
PM 35693322
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Lin, YW
   Zhu, L
   Zhang, ZP
   Tang, Y
   Huang, F
AF Zhang, Chengyuan
   Lin, Yunwu
   Zhu, Lei
   Zhang, Zuping
   Tang, Yan
   Huang, Fang
TI Efficient region of visual interests search for geo-multimedia data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Region of visual interests; Geo-image; Geographical similarity; Visual
   similarity
ID SIFT; RETRIEVAL; NETWORKS; BAG
AB With the proliferation of online social networking services and mobile smart devices equipped with mobile communications module and position sensor module, massive amount of multimedia data has been collected, stored and shared. This trend has put forward higher request on massive multimedia data retrieval. In this paper, we investigate a novel spatial query named region of visual interests query (RoVIQ), which aims to search users containing geographical information and visual words. Three baseline methods are presented to introduce how to exploit existing techniques to address this problem. Then we propose the definition of this query and related notions at the first time. To improve the performance of query, we propose a novel spatial indexing structure called quadtree based inverted visual index which is a combination of quadtree, inverted index and visual words. Based on it, we design a efficient search algorithm named region of visual interests search to support RoVIQ. Experimental evaluations on real geo-image datasets demonstrate that our solution outperforms state-of-the-art method.
C1 [Zhang, Chengyuan; Lin, Yunwu; Zhu, Lei; Zhang, Zuping; Tang, Yan; Huang, Fang] Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
C3 Central South University
RP Zhu, L (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
EM cyzhang@csu.edu.cn; lywcsu@csu.edu.cn; leizhu@csu.edu.cn;
   zpzhang@csu.edu.cn; tangyan@csu.edu.cn; hfang@csu.edu.cn
RI HUANG, FANG/JBS-3517-2023; Zhu, Lei/GQQ-1130-2022
OI Zhu, Lei/0000-0002-5348-7532
FU National Natural Science Foundation of China [61702560]; project of and
   Technology Plan of Hunan Province [2018JJ3691, 2016JC2011]; Research and
   Innovation Project of Central South University Graduate Students
   [2018zzts177, 2018zzts588]
FX This work was supported in part by the National Natural Science
   Foundation of China (61702560), project (2018JJ3691, 2016JC2011) of
   Science and Technology Plan of Hunan Province, and the Research and
   Innovation Project of Central South University Graduate
   Students(2018zzts177,2018zzts588).
CR [Anonymous], PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.45
   [Anonymous], ARXIV180801911
   [Anonymous], 1990, SIGMOD, DOI DOI 10.1145/93597.98741
   [Anonymous], 2013, P 16 INT C EXT DAT T
   Cao S, 2012, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2012/03/016
   Cao XL, 2011, IEEE INT CONF TRUST, P373, DOI 10.1109/TrustCom.2011.48
   Charfi N, 2017, MULTIMED TOOLS APPL, V76, P20457, DOI 10.1007/s11042-016-3987-9
   Cong G., 2009, PROC VLDB ENDOW, V2, P337, DOI DOI 10.14778/1687627.1687666
   De Felipe I, 2008, PROC INT CONF DATA, P656, DOI 10.1109/ICDE.2008.4497474
   Deng K, 2015, IEEE T KNOWL DATA EN, V27, P61, DOI 10.1109/TKDE.2014.2324897
   dos Santos JM, 2017, MULTIMED TOOLS APPL, V76, P16855, DOI 10.1007/s11042-016-3955-4
   Faloutsos C., 1986, SIGMOD Record, V15, P227, DOI 10.1145/16856.16877
   Fan J, 2012, PROC VLDB ENDOW, V5, P824, DOI 10.14778/2311906.2311910
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Guo L, 2015, GEOINFORMATICA, V19, P29, DOI 10.1007/s10707-014-0204-8
   Guo T, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P405, DOI 10.1145/2723372.2723723
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Hariharan Ramaswamy, 2007, 2007 International Conference on Scientific and Statistical Database Management, DOI 10.1109/SSDBM.2007.22
   HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Karakasis EG, 2015, PATTERN RECOGN LETT, V55, P22, DOI 10.1016/j.patrec.2015.01.005
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lee KCK, 2012, IEEE T KNOWL DATA EN, V24, P547, DOI 10.1109/TKDE.2010.243
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li ZS, 2011, IEEE T KNOWL DATA EN, V23, P585, DOI 10.1109/TKDE.2010.149
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Morton G M, 2015, PHYS PLASMAS, V24, P159
   Nam SH, 2018, MULTIMED TOOLS APPL, V77, P7811, DOI 10.1007/s11042-017-4678-x
   Rocha-Junior Joao B., 2011, Advances in Spatial and Temporal Databases. Proceedings 12th International Symposium (SSTD 2011), P205, DOI 10.1007/978-3-642-22922-0_13
   Rocha-Junior J.B., 2012, EDBT, P168
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Su MZ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178090
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang F., 2013, ADV MULTIMEDIA MODEL, P513
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P981, DOI 10.1145/2647868.2654999
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang Y, 2013, IEEE IMAGE PROC, P805, DOI 10.1109/ICIP.2013.6738166
   Wang Yuan-sheng, 2014, COMPUTER MODELLING N, V16, P13
   Wu L, 2018, ARXIV180411013
   Wu L, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (9TH), VOL II, P598
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Zhang C., 2014, 17 INT C EXTENDING D, P367
   Zhang CY, 2016, IEEE T KNOWL DATA EN, V28, P1706, DOI 10.1109/TKDE.2016.2530060
   Zhang FG, 2015, 2015 IEEE International Conference on Applied Superconductivity and Electromagnetic Devices (ASEMD), P110, DOI 10.1109/ASEMD.2015.7453490
   Zheng K, 2015, PROC INT CONF DATA, P423, DOI 10.1109/ICDE.2015.7113303
   Zhu GQ, 2016, ONCOTARGETS THER, V9, P2153, DOI 10.2147/OTT.S97864
NR 58
TC 4
Z9 4
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30839
EP 30863
DI 10.1007/s11042-018-6750-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200065
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Balaguer, P
   Teixidó, I
   Vilaplana, J
   Mateo, J
   Rius, J
   Solsona, F
AF Balaguer, Pau
   Teixido, Ivan
   Vilaplana, Jordi
   Mateo, Jordi
   Rius, Josep
   Solsona, Francesc
TI CatSent: a Catalan sentiment analysis website
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Natural language processing; Emojis; Catalan;
   Twitter
ID CLASSIFICATION
AB In this paper we investigate, analyze and compare sentimental analysis methodologies in Catalan tweets. The main goal is to develop a high-performance Catalan classifier. There are three main steps: Catalan language preprocessing tool, classification model and corpus training. The preprocessing tool is used for cleaning and extracting features from a document (or tweet). This is a key step due to the great morphological complexity of the Catalan language. The tool will remove empty words from the text and find the roots of other words. The classification algorithm will divide the tweet into "positive" and "negative" classes. To choose the best algorithm, five models are compared: Naive Bayes, Maximum Entropy, Support Vector Machine, Decision Tree and Neural Networks. Finally, the corpus will be used for training and testing these methods. There is no known public corpus in Catalan, so we created one using a lexicon-based approach. This work aims to enable the tools to carry out sentiment analysis studies in the Catalan language. The last step is to develop a public web service with the best classification model achieved where users will be able to check its effectiveness.
C1 [Balaguer, Pau] Parc Cient & Tecnol Lleida, Bldg H3,Ground Floor, Lleida 25003, Spain.
   [Teixido, Ivan; Vilaplana, Jordi; Mateo, Jordi; Solsona, Francesc] Univ Lleida, Dept Comp Sci, Jaume II 69, Lleida 25001, Spain.
   [Rius, Josep] Univ Lleida, Dept AEGERN, Jaume II 73, Lleida 25001, Spain.
C3 Universitat de Lleida; Universitat de Lleida
RP Solsona, F (corresponding author), Univ Lleida, Dept Comp Sci, Jaume II 69, Lleida 25001, Spain.
EM phalaguer19@gmail.com; iteixido@diei.udl.eat; jordi@diei.udl.eat;
   jmateo@diei.udl.cat; josepmaria.rius@aegem.udl.eat;
   fiancesc@diei.udl.cat
RI Mateo-Fornés, Jordi/AAH-4183-2020; Torrento, Josep Rius/U-3691-2019;
   Mateo, Jordi/HZI-0461-2023; Rius Torrento, Josep/HHR-9527-2022; Solsona,
   Francesc/AAR-4195-2020; Mayoral, Jordi Vilaplana/G-6766-2012; Teixidó,
   Ivan/L-3365-2017; Mateo-Fornes, Jordi/A-2237-2015; Solsona,
   Francesc/D-6226-2014
OI Torrento, Josep Rius/0000-0003-2783-6230; Rius Torrento,
   Josep/0000-0003-2783-6230; Mateo-Fornes, Jordi/0000-0002-1660-0380;
   Solsona, Francesc/0000-0002-4830-9184
FU Ministerio de Economia y Competitividad [TIN2017-84553-C2-2-R];
   Generalitat de Catalunya [2017-SGR363]; European Union FEDER (CAPAP-H6
   network) [TIN2016-81840-REDT]; RecerCaixa
FX This work was supported by the Ministerio de Economia y Competitividad
   under contract TIN2017-84553-C2-2-R. IT, JV, JM, JR and FS are members
   of the research group 2017-SGR363, funded by the Generalitat de
   Catalunya. Besides, this research is partly supported by the European
   Union FEDER (CAPAP-H6 network TIN2016-81840-REDT). The research leading
   to these results has received funding from RecerCaixa.
CR Abdulla NA, 2013, 2013 IEEE JORDAN CONFERENCE ON APPLIED ELECTRICAL ENGINEERING AND COMPUTING TECHNOLOGIES (AEECT)
   [Anonymous], 2014, INT C COMP LING
   [Anonymous], 2011, PROCESAMIENTO LENGUA
   Aparicio J, 2008, P 13 EURALEX INT C
   Barnes J, 2018, ABS180308614 CORR
   Buitinck L, 2013, ECML PKDD WORKSH LAN, P108, DOI DOI 10.48550/ARXIV.1309.0238
   Calzolari N., 2016, P 10 INT C LANG RES
   Chen CC, 2011, DECIS SUPPORT SYST, V50, P755, DOI 10.1016/j.dss.2010.08.023
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Cruz FL, 2014, PROCES LENG NAT, P113
   Dubiau L., 2013, 14 ARG S ART INT ASA
   Duric A, 2012, EXPERT SYST APPL, V39, P9166, DOI [10.1016/j.eswa.2012.02.057, DOI 10.1016/J.ESWA.2012.02.057]
   Feixa C, 2015, COLLECCIO ESTUDIS, V35
   Goeldi A., 2011, US Patent, Patent No. [7,974,983, 7974983]
   Huh JH, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040093
   Hurtado L. F., 2015, P TASS 2015 WORKSH S, P75
   Kang H, 2012, EXPERT SYST APPL, V39, P6000, DOI 10.1016/j.eswa.2011.11.107
   Kim Y., 2014, P 2014 C EMPIRICAL M
   Kularathne SD, 2017, IJAEMS, V3
   Lane PCR, 2012, DECIS SUPPORT SYST, V53, P712, DOI 10.1016/j.dss.2012.05.028
   Loper E., 2002, ASS COMPUTATIONAL LI
   Mart n MT, 2013, EXPERT SYST APPL
   Medhat W, 2014, AIN SHAMS ENG J, P2090
   Mehra N., 2002, SENTIMENT IDENTIFICA
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Moreo A, 2012, DECIS SUPPORT SYST, V53, P704, DOI [10.1016/j.dss.2012.05.023, DOI 10.1016/J.DSS.2012.05.023]
   Novak PK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144296
   Padro L., 2011, LINGUAMATICA
   Patel D, 2016, INT J INNOVATIVE RES
   Petz Gerald, 2013, Human-Computer Interaction and Knowledge Discovery in Complex, Unstructured, Big Data. Third International Workshop, HCI-KDD 2013. Held at SouthCHI 2013. Proceedings: LNCS 7947, P35, DOI 10.1007/978-3-642-39146-0_4
   Petz Gerald, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P618, DOI 10.1007/978-3-642-35236-2_62
   Petz G, 2015, INF PROCESS MANAG, V51
   Qu Y., 2004, AAAI Spring Symposium
   Ramirez M, 2015, RES COMPUTING SCI, P193
   Rehling JA, 2013, U. S. Patent, Patent No. [8,463,595, 8463595]
   Rill S, 2014, KNOWL-BASED SYST, V69, P24, DOI 10.1016/j.knosys.2014.05.008
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Stojanovski D, 2015, TWITTER SENTIMENT AN
   Suresh A., 2016, International Journal of Control Theory and Applications, V9, P419
   van de Camp M, 2012, DECIS SUPPORT SYST, V53, P761, DOI 10.1016/j.dss.2012.05.031
   Walker MA, 2012, DECIS SUPPORT SYST, V53, P719, DOI 10.1016/j.dss.2012.05.032
NR 41
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28137
EP 28155
DI 10.1007/s11042-019-07877-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000060
DA 2024-07-18
ER

PT J
AU Bier, A
   Sroczynski, Z
AF Bier, Agnieszka
   Sroczynski, Zdzislaw
TI Rule based intelligent system verbalizing mathematical notation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-to-speech interface; Verbalizing mathematical notation; Adaptive
   interface; Visually impaired learning assistance
ID STUDENTS; BLIND
AB An adaptive and adaptable multi-purpose math-to-speech translation system is proposed in the paper. Along with the detailed presentation and design approach for the core math-to-speech translation system, exemplary output and tests are discussed. A scripting extension, providing flexibility of the system and enabling the user to adjust the output translations to his/hers preferences is incorporated into the presented solution. Some unit-tests and adaptable versions of translation rule sets are elaborated and evaluated by means of standard measures of machine translation quality. Designed as a flexible self contained solution, the presented system may be applied for various purposes such as e-learning audio presentation systems, educational tools for non-native speakers or visually impaired people, and may be easily adjusted to different national languages.
C1 [Bier, Agnieszka; Sroczynski, Zdzislaw] Inst Math, Fac Appl Math, PL-44100 Gliwice, Poland.
RP Bier, A (corresponding author), Inst Math, Fac Appl Math, PL-44100 Gliwice, Poland.
EM agnieszka.bier@polsl.pl; zdzislaw.sroczynski@polsl.pl
RI Bier, Agnieszka/AAE-1826-2019; Sroczynski, Zdzislaw/B-8258-2019; Bier,
   Agnieszka/B-3051-2013
OI Sroczynski, Zdzislaw/0000-0002-5802-4449; Bier,
   Agnieszka/0000-0003-1743-7447
CR Ahmetovic D, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P352, DOI 10.1145/3234695.3241029
   [Anonymous], 2017, INT C MAN MACHINE IN
   [Anonymous], THEOR APPL INF
   [Anonymous], ETS RES REPORT SERIE
   [Anonymous], INTELLIGENT ENV
   [Anonymous], ELEARN CTR RES PAPER
   [Anonymous], NTCIR
   [Anonymous], P I ACOUSTICS
   [Anonymous], INT J COMPUT SCI ENG
   [Anonymous], INT C MATH ED ICME
   [Anonymous], INTED2009 P
   [Anonymous], 2014, P 16 INT C MULTIMODA
   [Anonymous], TECH REP
   [Anonymous], P 2014 HCI INT CRET
   [Anonymous], ACAD TXB
   [Anonymous], P VLSI COMP PER COMP
   [Anonymous], INT C MAN MACH INT
   [Anonymous], P 6 INT C ELEARNING
   [Anonymous], ICTER
   [Anonymous], VISUALLY IMPAIRED AS
   [Anonymous], CHI EA 15
   [Anonymous], INT WORKSH SPEECH LA
   [Anonymous], EFFECTIVE E LEARNING
   [Anonymous], MATH FORMULAS TEXT S
   [Anonymous], ARXIV170602400
   Attanayake D, 2015, IMA INT C BARR EN LE
   Bateman A, 2018, INT J HUM-COMPUT ST, V109, P102, DOI 10.1016/j.ijhcs.2017.09.004
   Bier A, 2015, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MULTIMEDIA, INTERACTION, DESIGN AND INNOVATION, DOI 10.1145/2814464.2814471
   Bocconi S, 2007, UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: APPLICATIONS AND SERVICES, PT 3, PROCEEDINGS, P491
   Chang L.A., 1983, HDB SPOKEN MATH LARR
   Corn AL, 2002, J VISUAL IMPAIR BLIN, V96, P197, DOI 10.1177/0145482X0209600402
   Ferreira H., 2005, HUMAN COMPUTER INTER
   Isaac M, 2016, AMB INTELL SMART ENV, V21, P217, DOI 10.3233/978-1-61499-690-3-217
   Lewis C., 2005, ACM SIGACCESS Accessibility and Computing, P12, DOI [10.1145/1102187.1102190., DOI 10.1145/1102187.1102190]
   Líska M, 2014, LECT NOTES ARTIF INT, V8543, P444, DOI 10.1007/978-3-319-08434-3_36
   Makowski M, 2017, MULTIMEDIA TOOLS APP, P1
   Nazemi A, 2012, C HUM SYST INTERACT, P48, DOI 10.1109/HSI.2012.17
   Neto R, 2014, PROC TECH, V16, P1200, DOI 10.1016/j.protcy.2014.10.135
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Polap D, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122803
   Polap D, 2016, COMM COM INF SC, V639, P392, DOI 10.1007/978-3-319-46254-7_31
   Riga P, 2016, LECT NOTES COMPUT SC, V9758, P27, DOI 10.1007/978-3-319-41264-1_4
   Salamonczyk A, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON CYBERNETICS (CYBCONF), P240, DOI 10.1109/CYBConf.2015.7175939
   Sheikh W, 2018, INT J LEARN TECHNOL, V13, P3, DOI 10.1504/IJLT.2018.091609
   Spinczyk D, 2019, COMPUT BIOL MED, V104, P1, DOI 10.1016/j.compbiomed.2018.10.025
   Sroczynski Z, 2017, ADV INTELL SYST, V575, P339, DOI 10.1007/978-3-319-57141-6_37
   Sroczynski Z, 2014, INTERNET IN THE INFORMATION SOCIETY: INSIGHTS ON THE INFORMATION SYSTEMS, STRUCTURES AND APPLICATIONS, P93
   Su W, 2018, LECT NOTES ARTIF INT, V11110, P237, DOI 10.1007/978-3-319-99957-9_18
   Wolk K, 2014, ADV INTELL SYST, V275, P107, DOI 10.1007/978-3-319-05951-8_11
   Wongkia W, 2012, COMPUT MATH APPL, V64, P2128, DOI 10.1016/j.camwa.2012.04.009
NR 50
TC 8
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28089
EP 28110
DI 10.1007/s11042-019-07889-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000058
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, YX
   Tao, G
   Xie, QQ
   Song, ML
AF Chen, Yanxiang
   Tao, Gang
   Xie, Qiangqiang
   Song, Minglong
TI Video attention prediction using gaze saliency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze saliency; Facial landmark detection; Gaze estimation
ID VISUAL-ATTENTION; FACE ALIGNMENT; LEVEL; IMAGES
AB In recent years, the significant progress has been achieved in the field of visual saliency modeling. Our research key is in video saliency, which differs substantially from image saliency and could be better detected by adding the gaze information from the movement of eyes while people are looking at the video. In this paper we purposed a novel gaze saliency method to predict video attention, which is inspired by the widespread usage of mobile smart devices with camera. It is a non-contacted method to predict visual attention, and it does not bring the burden on the hardware. Our method first extracts the bottom-up saliency maps from the video frames, and then constructs the mapping from eye images obtained by the camera in synchronization with the video frames to the screen region. Finally the combination between top-down gaze information and bottom-up saliency maps is conducted by point-wise multiplication to predict the video attention. Furthermore, the proposed approach is validated on the two datasets: one is the public dataset MIT, the other is the dataset we collected, versus other four usual methods, and the experiment results show that our method achieves the state-of-the-art.
C1 [Chen, Yanxiang; Xie, Qiangqiang; Song, Minglong] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
   [Tao, Gang] Anhui Keli Informat Ind Co Ltd, Hefei 230088, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Chen, YX (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM chenyx@hfut.edu.cn
FU National Natural Science Foundation of China [61672201]; Anhui Province
   Nature Science Foundation of China [1408085MKL76]; Anhui Province
   Science and Technology Major Project of China [15czz02074]
FX This work is partially supported by National Natural Science Foundation
   of China (61672201), Anhui Province Nature Science Foundation of China
   (1408085MKL76), Anhui Province Science and Technology Major Project of
   China (15czz02074).
CR [Anonymous], ADV INF SCI SERV SCI
   [Anonymous], P 2016 ACM MULT C
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 2013, IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI DOI 10.1109/TPAMI.2012.89
   [Anonymous], ACM T INFORM SYSTEMS
   [Anonymous], 2008, NIPS
   [Anonymous], CONTRIBUTION COLOR I
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Chen YX, 2015, INFORM SCIENCES, V320, P361, DOI 10.1016/j.ins.2015.03.023
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Fang YM, 2015, INFORM SCIENCES, V309, P1, DOI 10.1016/j.ins.2015.03.004
   Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641
   Han JW, 2014, INFORM SCIENCES, V281, P781, DOI 10.1016/j.ins.2013.12.039
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6
   Mital PK, 2011, COGN COMPUT, V3, P5, DOI 10.1007/s12559-010-9074-z
   Ni BB, 2014, IEEE T MULTIMEDIA, V16, P1779, DOI 10.1109/TMM.2014.2329275
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peters JF, 2012, INFORM SCIENCES, V195, P211, DOI 10.1016/j.ins.2012.01.023
   Rekik W, 2015, INFORM SCIENCES, V306, P132, DOI 10.1016/j.ins.2015.01.039
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Saragih J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2881, DOI 10.1109/CVPR.2011.5995618
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Stirk JA, 2007, J VISION, V7, DOI 10.1167/7.10.3
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Wu B, 2014, MULTIMED TOOLS APPL, V73, P1053, DOI 10.1007/s11042-013-1530-9
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang Y, 2014, INFORM SCIENCES, V281, P601, DOI 10.1016/j.ins.2014.03.016
   Zhang H, 2015, APPL NMR SPECTROSC, V1, P3
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang YD, 2014, INFORM SCIENCES, V281, P586, DOI 10.1016/j.ins.2013.12.043
NR 45
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 26867
EP 26884
DI 10.1007/s11042-016-4294-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000003
DA 2024-07-18
ER

PT J
AU Choo, BJ
   Joo, HJ
   Kim, BS
   Cha, SH
   Myung, DH
AF Choo, Bong-Jo
   Joo, Hae-Jong
   Kim, Bong-Soo
   Cha, Si-hwan
   Myung, Do-Hyun
TI RETRACTED: Using multimedia based big data for child abuse prevention
   system (Based on the establishment of e-child welfare support system)
   (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Big data; Child abuse; Detection system; E-child welfare support system;
   Hadoop ecosystem
AB With the case of a child's death by child abuse in 2013, public attention has grown on child abuse cases and a variety of policies to protect child abuse were in operation with the enactment of the Special Act on Punishment of Child Abuse Crimes. However, the crime of child abuse is still concealed at home due to lack of parental understanding due to the precise concept of abuse and home discipline. Since children are physically and mentally incompetent, awareness and support for victims of child abuse should be preceded by appropriate care and attention. Prevention of child abuse should be pursued with constant interest. As the age of Big Data is introduced, the value of big data is increasing day by day by using crime prevention using large-scale data in particular. Especially, valuable data shared by public organizations are showing the effects in preventing crime, disease and disaster. Many public data are open to the public and crime prevention using Big Data has proved effective so far. Therefore, in this paper, we propose a guideline for the establishment of a child abuse prevention system using Big Data based on the promotion of child abuse eradication system using public data and big data in order to build a system to prevent child abuse.
C1 [Choo, Bong-Jo; Kim, Bong-Soo; Cha, Si-hwan; Myung, Do-Hyun] Gimcheon Univ, Dept Police Adm, Gimcheon, South Korea.
   [Joo, Hae-Jong] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Dongguk University
RP Kim, BS (corresponding author), Gimcheon Univ, Dept Police Adm, Gimcheon, South Korea.
EM bjchoo@gimcheon.ac.kr; hjjoo@dongguk.edu; sbong78@gimcheon.ac.kr;
   shihoan@gimcheon.ac.kr; myungdohyun@gimcheon.ac.kr
RI Kim, Bong-Soo/L-4779-2013
OI Kim, Bong-Soo/0000-0003-1243-8280
CR Busan, 2013, STUD EST BUS CRIM PR, P3
   Lee D-H, 2005, ASYSTEMATIC PLAN COL, P23
   Lee H-J, 2012, KOREA COMMUNICATIONS, V29, P47
   Ministry of Health and Welfare, 2015, CHIN MIN RES, P54
   박소현, 2013, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V23, P803, DOI 10.13089/JKIISC.2013.23.5.803
NR 5
TC 3
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28805
EP 28814
DI 10.1007/s11042-018-6630-0
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700025
DA 2024-07-18
ER

PT J
AU He, XY
   Zhang, W
   Zhang, HF
   Ma, L
   Li, YB
AF He, Xuanyu
   Zhang, Wei
   Zhang, Haifeng
   Ma, Lin
   Li, Yibin
TI Reversible data hiding for high dynamic range images using edge
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; High dynamic range image; Edge detection;
   Prediction error
ID EXPANSION; ALGORITHM
AB In this work, a reversible data hiding (RDH) algorithm is proposed for high dynamic range (HDR) images containing an additional luminance channel. Since prediction accuracy is the key of RDH, we propose to embed data into HDR images by exploiting the edge information among the luminance channel and color channels to achieve accurate prediction and high embedding capacity. Besides, a new edge-directed order is presented to reduce the visual loss of the stego image. Various experimental results demonstrate that the proposed algorithm can hide more data into HDR images with less distortion than directly applying traditional RDH methods designed for low dynamic range (LDR) images. Compared to the current HDR hiding algorithms, the proposed method is not only reversible, but also achieves a tradeoff between embedding capacity and distortion.
C1 [He, Xuanyu; Zhang, Wei; Zhang, Haifeng; Li, Yibin] Shandong Univ, Sch Control Sci & Engn, Jinan, Shandong, Peoples R China.
   [He, Xuanyu; Zhang, Wei] Shandong Univ, Shenzhen Res Inst, Shenzhen, Peoples R China.
   [Ma, Lin] Tencent Inc, AI Lab, Shenzhen, Peoples R China.
C3 Shandong University; Shandong University; Tencent
RP Zhang, W (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan, Shandong, Peoples R China.; Zhang, W (corresponding author), Shandong Univ, Shenzhen Res Inst, Shenzhen, Peoples R China.
EM davidzhang@sdu.edu.cn
FU National Key Research and Development Plan of China [2017YFB1300205];
   NSFC [61573222]; Shenzhen Future Industry Special Fund
   [JCYJ20160331174228600]; Major Research Program of Shandong Province
   [2015ZDXX0801A02]; Fundamental Research Funds of Shandong University
   [2018CXGC1503]
FX This work was supported by National Key Research and Development Plan of
   China under Grant 2017YFB1300205, the NSFC Grant no. 61573222, Shenzhen
   Future Industry Special Fund JCYJ20160331174228600, Major Research
   Program of Shandong Province 2015ZDXX0801A02 and Fundamental Research
   Funds of Shandong University 2018CXGC1503.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Chang CC, 2016, MULTIMED TOOLS APPL, V75, P145, DOI 10.1007/s11042-014-2279-5
   Cheng YM, 2009, IEEE MULTIMEDIA, V16, P70, DOI 10.1109/MMUL.2009.43
   Fridrich J, 1900, EURASIP J ADV SIG PR, V2002, P185
   Fujiyoshi M, 2017, LECT NOTES COMPUT SC, V10431, P347, DOI 10.1007/978-3-319-64185-0_26
   Heidrich Wolfgang, ERIK REINHARD
   Hu MQ, 2017, IEEE T IMAGE PROCESS, V26, P4871, DOI 10.1109/TIP.2017.2717185
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Kalker T, 2003, PROC SPIE, V5020, P604, DOI 10.1117/12.473164
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Larson GregW., 1992, GRAPHICS GEMS 2, P80, DOI [10.1016/B978-0-08-050754-5.50025-6, DOI 10.1016/B978-0-08-050754-5.50025-6]
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nikolaidis A, 2016, MULTIMED TOOLS APPL, V75, P1869, DOI 10.1007/s11042-014-2377-4
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Pan Qu J., 2016, J. Inf. Hiding Multim. Signal Process., V7, P1194
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tuncer T, 2016, DISPLAYS, V41, P1, DOI 10.1016/j.displa.2015.10.005
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Yang Y, 2019, IEEE T KNOWL DATA EN, V31, P757, DOI 10.1109/TKDE.2018.2842190
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yu CM, 2011, DISPLAYS, V32, P225, DOI 10.1016/j.displa.2011.02.004
   Zhang MX, 2019, IEEE T IMAGE PROCESS, V28, P32, DOI 10.1109/TIP.2018.2855415
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhang W, 2017, INFORM SCIENCES, V415, P19, DOI 10.1016/j.ins.2017.05.019
   Zhang W, 2017, IEEE T IMAGE PROCESS, V26, P2042, DOI 10.1109/TIP.2017.2672440
   Zhang W, 2017, INFORM SCIENCES, V376, P190, DOI 10.1016/j.ins.2016.10.020
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
   Zhi-Hui Wang, 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P33, DOI 10.1109/ICDH.2012.49
NR 41
TC 13
Z9 13
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29137
EP 29160
DI 10.1007/s11042-018-6589-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700041
DA 2024-07-18
ER

PT J
AU Ou, XY
   Ma, QZ
   Wang, YJ
AF Ou, Xinyu
   Ma, Qianzhi
   Wang, Yijin
TI Improving person re-identification by multi-task learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Multi-Task learning; Identity; Attribute;
   Identification; Verification
AB We propose a novel Multi-Task Learning Network (MTNET) with four different subtasks for person re-identification mission. At the same time, the attribute recognition mission can be implemented by the same network. We achieve multi-mission by integrating four subtasks, such as identity identification, identity verification, attribute identification, attribute verification. Identity loss and attribute loss can provide complementary information on a different perspective by integrating multi-context information. Identity focuses on the overall contour and appearance, while attribute focuses on local aspects and dresses of one person. Identification loss and verification loss are used to optimize the distance of samples. Identification loss used to construct a robust category space, while verification loss used to optimize the space by minimizing the distance between similar images, and maximizing the distance between dissimilar images. Moreover, an effective verification loss named constraint contrast verification (CCV) is proposed to restrict the distance between feature pair to a foreseeable range that ensures the network has better convergence. The MTNet is an end-to-end deep learning framework, all the parameters and losses can be jointly optimized. We evaluate our approach with the state-of-the-art methods on two famous dataset Market1501 and DukeMTMC-reID. Experiments demonstrate that our MTNet achieves the very competitive results.
C1 [Ou, Xinyu; Ma, Qianzhi] Yunnan Open Univ, Sch Commun, Informat Engn, Yunnan Tech Coll Ind, Kunming, Yunnan, Peoples R China.
   [Ou, Xinyu] Yunnan Univ, Natl Pilot Sch Software, Kunming, Yunnan, Peoples R China.
   [Wang, Yijin] Yunnan Open Univ, Dept Human Resources, Yunnan Tech Coll Ind, Kunming, Yunnan, Peoples R China.
C3 Yunnan University
RP Ou, XY (corresponding author), Yunnan Open Univ, Sch Commun, Informat Engn, Yunnan Tech Coll Ind, Kunming, Yunnan, Peoples R China.; Ou, XY (corresponding author), Yunnan Univ, Natl Pilot Sch Software, Kunming, Yunnan, Peoples R China.
EM ouxinyu@alumni.hust.edu.cn; 289125594@qq.com; 3419276@qq.com
RI wang, yijin/GRS-5538-2022
OI ou, xinyu/0000-0002-2905-426X
FU National Natural Science Foundation of China [61572493]; Scientific
   Research Project of Yunnan Education Department [2018JS373, 2018JS374];
   research projects of educational science of Yunnan higher education
   society [2018YGZ72]; excellent young teachers program of open university
   of China
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61572493, the Scientific Research Project of
   Yunnan Education Department under Grant Nos. 2018JS373, 2018JS374, the
   research projects of educational science of Yunnan higher education
   society under Grant No. 2018YGZ72, the excellent young teachers program
   of open university of China.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2014, BRIT MACH VIS C BMVC
   [Anonymous], ARXIVABS170307220 CO
   [Anonymous], ARXIVABS161105244 CO
   [Anonymous], ARXIVABS161105666 CO
   [Anonymous], ARXIVABS151205300 CO
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], ARXIVABS170307737 CO
   [Anonymous], ARXIVABS160107255 CO
   [Anonymous], ARXIVABS161002984 CO
   [Anonymous], ARXIVABS170107732 CO
   Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jose C, 2016, LECT NOTES COMPUT SC, V9909, P875, DOI 10.1007/978-3-319-46454-1_53
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Sudowe P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P329, DOI 10.1109/ICCVW.2015.51
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Ustinova E, 2016, ADV NEUR IN, V29
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhu FQ, 2017, IEEE T IMAGE PROCESS, V26, P4806, DOI 10.1109/TIP.2017.2695101
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
NR 41
TC 5
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28257
EP 28283
DI 10.1007/s11042-019-07921-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000066
DA 2024-07-18
ER

PT J
AU Zhao, F
   Si, WJ
   Dou, Z
AF Zhao, Feng
   Si, Weijian
   Dou, Zheng
TI Image super-resolution via two stage coupled dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image superresolution; Dictionary learning; Sparse representation; Low
   pass filter
ID RESOLUTION
AB Example-based image super-resolution aims to establish a learning model for generating the high resolution image from the coupled training pairs, which is an active study area of mobile media in the recent modern communication. In this paper, we proposed a novel example-based method to address the single image super-resolution problem, where the training pairs are selected from a large amount of natural images. The main idea of our method is to reconstruct the high resolution by a two stage-based scheme. In the first stage, one dictionary is learned to represent the coarse high resolution image from its low version, and the other is trained within the same coding as the coarse image to recover texture details. And then, to further enhance the fine edges in image, a similar dictionary learning scenario are done about the synthesis high resolution image and its fine structure in residual component. Extensive experimental results on some benchmark test images show the advantage of our method compare with other excellent ones.
C1 [Zhao, Feng; Si, Weijian; Dou, Zheng] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Dou, Z (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM douzheng@hrbeu.edu.cn
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], APPL MATH COMPUT
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2014, MATH PROBL ENG, DOI DOI 10.1155/2014/586014
   Babacan SD, 2008, IEEE IMAGE PROC, P641, DOI 10.1109/ICIP.2008.4711836
   Ding GR, 2016, IEEE J SEL AREA COMM, V34, P107, DOI 10.1109/JSAC.2015.2452532
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jiji CV, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/73767
   Li A, 2016, OPT REV, V23, P776, DOI 10.1007/s10043-016-0267-x
   Li A, 2016, J SENSORS, V2016, DOI 10.1155/2016/6586032
   Lin Y, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101675
   Lin Y, 2016, J SUPERCOMPUT, V72, P2874, DOI 10.1007/s11227-016-1681-3
   Liu S, 2017, J NONLINEAR SCI APPL, V10, P1148, DOI 10.22436/jnsa.010.03.24
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang GD, 2017, IEEE NETWORK, V31, P21, DOI 10.1109/MNET.2017.1600182
   Wu QD, 2017, MULTIMED TOOLS APPL, V76, P17179, DOI 10.1007/s11042-016-3760-0
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang HC, 2012, IEEE T IMAGE PROCESS, V21, P4054, DOI 10.1109/TIP.2012.2199330
NR 24
TC 6
Z9 6
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28453
EP 28460
DI 10.1007/s11042-017-5493-0
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700007
DA 2024-07-18
ER

PT J
AU AlZu'bi, S
   Jararweh, Y
   Al-Zoubi, H
   Elbes, M
   Kanan, T
   Gupta, B
AF AlZu'bi, Shadi
   Jararweh, Yaser
   Al-Zoubi, Hassan
   Elbes, Mohammed
   Kanan, Tarek
   Gupta, Brij
TI Multi-orientation geometric medical volumes segmentation using 3D
   multiresolution analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Geometric 3D image processing; Multiresolution
   analysis; Volume reconstruction; Segmentation
ID COMPUTER-AIDED DIAGNOSIS; IMAGE; ALGORITHMS; OBJECT; SYSTEM; MRI; GPU
AB Medical images have a very significant impact in the diagnosing and treating process of patient ailments and radiology applications. For many reasons, processing medical images can greatly improve the quality of radiologists' job. While 2D models have been in use for medical applications for decades, wide-spread utilization of 3D models appeared only in recent years. The proposed work in this paper aims to segment medical volumes under various conditions and in different axel representations. In this paper, we propose an algorithm for segmenting Medical Volumes based on Multiresolution Analysis. Different 3D volume reconstructed versions have been considered to come up with a robust and accurate segmentation results. The proposed algorithm is validated using real medical and Phantom Data. Processing time, segmentation accuracy of predefined data sets and radiologist's opinions were the key factors for methods validations.
C1 [AlZu'bi, Shadi; Elbes, Mohammed; Kanan, Tarek] Al Zaytoonah Univ Jordan, Fac Sci & IT, Dept Comp Sci, Amman, Jordan.
   [Jararweh, Yaser] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid, Jordan.
   [Al-Zoubi, Hassan] Al Zaytoonah Univ Jordan, Fac Sci & IT, Dept Math, Amman, Jordan.
   [Gupta, Brij] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 Al-Zaytoonah University of Jordan; Jordan University of Science &
   Technology; Al-Zaytoonah University of Jordan; National Institute of
   Technology (NIT System); National Institute of Technology Kurukshetra
RP AlZu'bi, S (corresponding author), Al Zaytoonah Univ Jordan, Fac Sci & IT, Dept Comp Sci, Amman, Jordan.
EM smalzubi@zuj.edu.jo; yijararweh@just.edu.jo; dr.hassanz@zuj.edu.jo;
   M.Elbes@zuj.edu.jo; tarek.kanan@zuj.edu.jo; bbgupta@nitkkr.ac.in
RI Jararweh, Yaser/ABE-6543-2021; Jararweh, Yaser/JCO-2836-2023; AlZu'bi,
   Shadi/W-4507-2018; Gupta, Brij B/E-9813-2011
OI AlZu'bi, Shadi/0000-0003-4173-2323; Gupta, Brij B/0000-0003-4929-4698
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Al-Ayyoub Mahmoud, 2013, WSEAS Transactions on Information Science and Applications, V10, P261
   Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   Al-Ayyoub M, 2015, J SUPERCOMPUT, V71, P3149, DOI 10.1007/s11227-015-1431-y
   Al-Zu'bi S, 2017, PROCEDIA COMPUT SCI, V113, P531, DOI 10.1016/j.procs.2017.08.318
   AlZu'bi S, 2010, ADV ARTIFICIAL INTEL, V2010
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   AlZubi S., 2011, THESIS
   AlZubi S., 2011, IEEE INT S MEDICAL M, P619, DOI [DOI 10.1109/MEMEA.2011.5966667, 10.1109/MeMeA.2011.5966667]
   AlZubi S., 2012, 2012 INT C INN INF T, P156
   [Anonymous], 2006, THESIS
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], [No title captured]
   [Anonymous], 2012, APPL GPU COMPUTING S
   [Anonymous], 2018, IEEE Transactions on Cybernetics
   [Anonymous], 1999, THESIS
   [Anonymous], 2009, Image processing and mathematical morphology fundamentals and applications
   Badura P, 2018, COMPUT MED IMAG GRAP, V65, P152, DOI 10.1016/j.compmedimag.2017.04.004
   Badura P, 2011, ECTA 2011/FCTA 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION THEORY AND APPLICATIONS AND INTERNATIONAL CONFERENCE ON FUZZY COMPUTATION THEORY AND APPLICATIONS, P486, DOI 10.5220/0003670904860492
   Bezdek James C., 1981, PATTERN RECOGN
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Eklund A, 2013, MED IMAGE ANAL, V17, P1073, DOI 10.1016/j.media.2013.05.008
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Engel Klaus, 2001, P ACM SIGGRAPH EUROG, P9, DOI [DOI 10.1145/383507.383515, 10.1145/383507.383515]
   Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902
   Fishman EK, 2006, RADIOGRAPHICS, V26, P905, DOI 10.1148/rg.263055186
   Fulkerson B., 2012, Trends and Topics in Computer Vision, Lecture Notes in Computer Science, V6554, P350
   García-Vázquez V, 2017, Z MED PHYS, V27, P218, DOI 10.1016/j.zemedi.2016.07.002
   Gletsos M, 2003, IEEE T INF TECHNOL B, V7, P153, DOI 10.1109/TITB.2003.813793
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Hwang C, 2007, IEEE T FUZZY SYST, V15, P107, DOI 10.1109/TFUZZ.2006.889763
   (IEC) IEC (NEMA) NEMA, 2001, NEMA STAND PUBL, Vnu2
   Kostrzewa M, 2015, EUR J RADIOL, V84, P1970, DOI 10.1016/j.ejrad.2015.06.028
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   Lee RK, 2000, GRAPH MODELS, V62, P263, DOI 10.1006/gmod.2000.0524
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li JJ, 2016, NEUROCOMPUTING, V173, P501, DOI 10.1016/j.neucom.2015.06.041
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lum EB, 2004, VISSYM 04
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Max N., 1990, Computer Graphics, V24, P27, DOI 10.1145/99308.99315
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   Nikolaidis D, 2001, THESIS
   Osher Stanley, 2002, LEVEL SET METHODS DY
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Pietka E, 2010, EXPERT SYST, V27, P17, DOI 10.1111/j.1468-0394.2009.00524.x
   Silverstein JC, 2008, J BIOMED INFORM, V41, P927, DOI 10.1016/j.jbi.2008.02.008
   STYTZ MR, 1991, COMPUT SURV, V23, P421, DOI 10.1145/125137.125155
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   von Berg J, 2004, INT CONGR SER, V1268, P492, DOI 10.1016/j.ics.2004.03.171
   Wieclawek W, 2015, COMPUT MED IMAG GRAP, V43, P122, DOI 10.1016/j.compmedimag.2015.01.003
   Wieclawek W, 2008, ADV INTEL SOFT COMPU, V47, P93
   Wieclawek W, 2007, P ANN INT IEEE EMBS, P5645, DOI 10.1109/IEMBS.2007.4353627
   Won HJ, 2017, DIAGN INTERV RADIOL, V23, P233, DOI 10.5152/dir.2017.16422
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Zarychta P, 2012, LECT N BIOINFORMAT, V7339, P93
   Zhang Y, 2008, MEDIVIS 2008: FIFTH INTERNATIONAL CONFERENCE BIOMEDICAL VISUALIZATION - INFORMATION VISUALIZATION IN MEDICAL AND BIOMEDICAL INFORMATICS, PROCEEDINGS, P71, DOI 10.1109/MediVis.2008.12
   Zhao B, 2015, DATA LUNG PHANTOM CA, DOI [10.7937/K9/TCIA.2015.08A1IXOO, DOI 10.7937/K9/TCIA.2015.08A1IX00]
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
NR 71
TC 19
Z9 19
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24223
EP 24248
DI 10.1007/s11042-018-7003-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900024
DA 2024-07-18
ER

PT J
AU Choi, JY
AF Choi, Jae Young
TI Weighted fusion joint bayesian metric with patch-based facial
   region-specific features for face identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Patch-based local texture; Facial region-specific features; Face
   identification; Joint bayesian; Weighted fusion; Metric learning; Sparse
   representation
ID SPARSE REPRESENTATION; RECOGNITION; PATTERNS; HISTOGRAM; MODEL; POSE
AB This paper presents a new automated face identification method. The novelty of our method consists of two parts: (1) facial region-specific sparse feature learning and (2) Weighted Fusion Joint Bayesian (WFJB) metric learning for classification. In the former part, a face is partitioned into a number of local regions and a set of small image patches is then extracted from each of the local regions. Subsequently, local texture descriptors extracted from patch images are applied to dictionary learning for creating sparse representations of individual local regions. The low-dimensional features of sparse representations from all the local regions are then pooled to generate our proposed Patch-based Local Spare Feature (PLSF) set, which is discriminant and complementary for face identification. In our WFJB model, the similarity between gallery (pre-enrolled) and probe (test) faces is measured using a weighted sum of probabilistic similarity scores, each computed for a particular feature element within a PLSF set. The weights are determined in an automatic and adaptive way via class-wise discriminant analysis on PLSF sets. Extensive and comparative experiments have been conducted on five public face databases. Results show that combination of our proposed PLSF set and WFJB metric is a feasible solution for improving face identification on challenging face images with severe variation in illumination, viewpoint, and expression. In addition, our method achieves better or comparable state-of-the-art results on the standard LFW identification protocols.
C1 [Choi, Jae Young] Hankuk Univ Foreign Studies, Div Comp & Elect Syst Engn, Pattern Recognit & Machine Intelligence Lab, 81 Oedae Ro, Yongin 17305, Gyeonggi Do, South Korea.
C3 Hankuk University Foreign Studies
RP Choi, JY (corresponding author), Hankuk Univ Foreign Studies, Div Comp & Elect Syst Engn, Pattern Recognit & Machine Intelligence Lab, 81 Oedae Ro, Yongin 17305, Gyeonggi Do, South Korea.
EM jychoi@hufs.ac.kr
FU Hankuk University of Foreign Studies Research Fund; National Research
   Foundation of Korea (NRF) - Ministry of Education [2018R1D1A1A09082615]
FX This research was supported by Hankuk University of Foreign Studies
   Research Fund. This research was supported by Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Education (No. 2018R1D1A1A09082615).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Best-Rowden L, 2014, IEEE T INF FOREN SEC, V9, P2144, DOI 10.1109/TIFS.2014.2359577
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54
   Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398
   Chai ZH, 2014, IEEE T INF FOREN SEC, V9, P14, DOI 10.1109/TIFS.2013.2290064
   Chan CH, 2010, IEEE IMAGE PROC, P2441, DOI 10.1109/ICIP.2010.5651933
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Choi JY, 2012, IEEE T SYST MAN CY B, V42, P1270, DOI 10.1109/TSMCB.2012.2185693
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Davis J. V., 2007, ICML, P209
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Fukunaga K., 1992, INTRO STAT PATTERN R, V2nd
   Geng C, 2009, IEEE IMAGE PROC, P3313, DOI 10.1109/ICIP.2009.5413956
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   HUANG GB, 2012, PROC CVPR IEEE, P2518, DOI DOI 10.1109/CVPR.2012.6247968
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708
   Lei Z, 2007, LECT NOTES COMPUT SC, V4642, P49
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lu JW, 2010, PROC CVPR IEEE, P2661, DOI 10.1109/CVPR.2010.5539983
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Maturana D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P470, DOI 10.1109/FG.2011.5771444
   Maturana Daniel., 2010, Asian Conference on Computer Vision, P618
   Meng X, 2006, INT C PATT RECOG, P536
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Nguyen Hieu V., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P709, DOI 10.1007/978-3-642-19309-5_55
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ramirez I., 2010, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2010.5539964, 10.1109/CVPR.2010.5539964]
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2015, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2015.7298891
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016
   Yang AY, 2010, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP.2010.5651522
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yin L, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417415
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383
NR 53
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24883
EP 24902
DI 10.1007/s11042-018-6950-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900055
DA 2024-07-18
ER

PT J
AU Feng, XK
   Cui, JT
   Li, H
   Liu, YF
AF Feng Xiaokang
   Cui Jiangtao
   Li Hui
   Liu Yingfan
TI An efficient LSH indexing on discriminative short codes for
   high-dimensional nearest neighbors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Approximate nearest neighbor; Hashing; Locality-sensitive hashing;
   Discriminative short codes; Linear order
ID QUANTIZATION
AB In massive multimedia era, the dimension curse and the I/O performance bottleneck have become two major challenges for disk-based Approximate Nearest Neighbor (ANN) search. Hashing is a popular solution to overcome the dimension curse, one promising hashing technique is Locality Sensitive Hashing (LSH). However, most existing LSH indexings incur significant I/O cost during the search due to their low NN candidate hits in each I/O access. We recommend a novel method SC-LSH (SortingCodes-LSH) which combines LSH with another hashing technique (i.e., the discriminative short codes) to lift the hit of NN candidates so as to further boost the ANN search performance. Firstly, we intensify an LSH index and sort all the compound hashing keys according to a linear order to make similar NN candidates distributed locally. Then we generate product quantization (PQ) codes to use them as candidates instead of the original data points. These space-efficient short codes can enable us acquire significantly candidates via much less I/O operations. Moreover, based on theoretical and empirical studies among series of space-filling curves, we finally choose the Gray curve as the linear order to produce better local distribution of candidate data. All these above significantly increase the NN hits during each I/O, which greatly reduce the amount of necessary I/O access. Meanwhile, with the good similarity preserving ability, PQ codes are precise enough to discriminate NNs and thus guarantee the accuracy. Empirical study demonstrates that, comparing with four state-of-the-arts, SC-LSH achieves the best accuracy with significantly smaller I/O cost and space consumption. In fact, depending on the datasets, the I/O cost (resp., space consumption) of our scheme is only 5%-20% (resp., 1%-20%) of the other methods.
C1 [Feng Xiaokang; Cui Jiangtao] Xidian Univ, Sch Comp Sci & Technol, Xian, Shaanxi, Peoples R China.
   [Li Hui] Xidian Univ, Sch Cyber Engn, Xian, Shaanxi, Peoples R China.
   [Liu Yingfan] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Peoples R China.
C3 Xidian University; Xidian University; Chinese University of Hong Kong
RP Cui, JT (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian, Shaanxi, Peoples R China.
EM research@xkfeng.com; cuijt@xidian.edu.cn; hli@xidian.edu.cn;
   liuyf@se.cuhk.edu.hk
RI æŽ, è¾‰/AAF-5399-2020
FU National Natural Science Foundation of China [61472298, 61672408,
   61702403, U1135002]; China 111 Project [B16037]; China Postdoctoral
   Science Foundation [2018M633473]; Natural Science Basic Research Plan in
   Shaanxi Province of China [2015JQ6227]; SRF for ROCS, SEM; Fundamental
   Research Funds for the Central Universities [JB170308]; Innovation Fund
   of Xidian University
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61472298, 61672408, 61702403, U1135002), China 111 Project
   (No. B16037), China Postdoctoral Science Foundation (No. 2018M633473),
   Natural Science Basic Research Plan in Shaanxi Province of China
   (Program No. 2015JQ6227), SRF for ROCS, SEM, the Fundamental Research
   Funds for the Central Universities (No. JB170308, etc.) and the
   Innovation Fund of Xidian University.
CR [Anonymous], 2014, Hashing for similarity search: A survey
   [Anonymous], 2012, P 2012 ACM SIGMOD IN
   Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038
   Böhm C, 2000, ACM T DATABASE SYST, V25, P129, DOI 10.1145/357775.357776
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Faloutsos C., 1989, Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, P247, DOI 10.1145/73721.73746
   Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   He SY, 2018, NEUROCOMPUTING, V282, P32, DOI 10.1016/j.neucom.2017.12.005
   Huang Q, 2015, PROC VLDB ENDOW, V9, P1
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Joly Alexis., 2008, PROCEEDING 16 ACM IN, P209
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu YF, 2014, PROC VLDB ENDOW, V7, P745, DOI 10.14778/2732939.2732947
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Luo X, 2018, ACM/SIGIR PROCEEDINGS 2018, P735, DOI 10.1145/3209978.3210035
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Panigrahy R, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1186, DOI 10.1145/1109557.1109688
   Park Y, 2015, PROC VLDB ENDOW, V9, P144
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Sun YF, 2014, PROC VLDB ENDOW, V8, P1
   Tao YF, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P563
   Vitter JS, 2006, FOUND TRENDS THEOR C, V2, P305, DOI 10.1561/0400000014
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Zhang PF, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1762, DOI 10.1145/3123266.3123320
NR 37
TC 1
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24407
EP 24429
DI 10.1007/s11042-018-6987-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900033
DA 2024-07-18
ER

PT J
AU Guo, J
   Nie, XS
   Jian, MW
   Yin, YL
AF Guo, Jie
   Nie, Xiushan
   Jian, Muwei
   Yin, Yilong
TI Binary feature representation learning for scene retrieval in
   micro-video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene retrieval; Micro-video; Multi-layer neural network; Supervised
   hash learning
AB Micro-video is popular as new social media, and scene retrieval is a useful application in micro-video. At present, few researches focus on scene retrieval in micro-video, and there is a big gap between scene feature and semantics. In order to extract better semantical feature, we propose a combinational fusion method which combines multi-layer neural network and supervised hash learning method. As nonlinear projection, multi-layer neural network fuses multiple modalities by nonlinear transformation, and supervised hash learning method transforms fusion feature by linear projection to binary code for semantics and similarity preservation. We evaluate the proposed method on an actual micro-video dataset crawled from Vine. The experimental results show its superior performance than single multi-modal fusion methods and single hash learning methods.
C1 [Guo, Jie] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
   [Nie, Xiushan; Jian, Muwei] Shandong Univ Finance & Econ, Jinan 250014, Shandong, Peoples R China.
   [Yin, Yilong] Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
C3 Shandong University; Shandong University of Finance & Economics;
   Shandong University
RP Yin, YL (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
EM guojiesdu@163.com; niexsh@sdufe.edu.cn; jianmuweihk@163.com;
   ylyin@sdu.edu.cn
RI Nie, Xiushan/AAZ-6410-2020; Jian, Muwei/Q-8319-2018
OI Jian, Muwei/0000-0002-4249-2264
FU National Natural Science Foundation of China [61671274, 61573219,
   61876098]; China Postdoctoral Science Foundation [2016M592190]; Shandong
   Provincial Key Research and Development Plan [2017CXGC1504]; Shandong
   Provincial High College Science and Technology Plan [J17KB161];
   Fostering Project of Dominant Discipline and Talent Team of Shandong
   Province Higher Education Institutions
FX This work is supported by the National Natural Science Foundation of
   China (61671274, 61573219, 61876098), China Postdoctoral Science
   Foundation (2016M592190), Shandong Provincial Key Research and
   Development Plan (2017CXGC1504), Shandong Provincial High College
   Science and Technology Plan (J17KB161) and the Fostering Project of
   Dominant Discipline and Talent Team of Shandong Province Higher
   Education Institutions.
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], P INT C MACH LEARN
   [Anonymous], P INT C MACH LEARN
   [Anonymous], 2016, ARXIV160309439
   [Anonymous], 2016, P 24 ACM INT C MULT
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Cui H, 2020, PATTERN RECOGN LETT, V130, P174, DOI 10.1016/j.patrec.2018.08.033
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Liu M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P970, DOI 10.1145/3123266.3123341
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XB, 2019, IEEE T CIRC SYST VID, V29, P2431, DOI 10.1109/TCSVT.2018.2862891
   Liu XB, 2018, IEEE T CIRC SYST VID, V28, P2884, DOI 10.1109/TCSVT.2017.2781738
   Lu X, 2019, SIGNAL PROCESS, V154, P217, DOI 10.1016/j.sigpro.2018.09.007
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie XS, 2017, IEEE T MULTIMEDIA, V19, P785, DOI 10.1109/TMM.2016.2629758
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Redi M, 2014, PROC CVPR IEEE, P4272, DOI 10.1109/CVPR.2014.544
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang L, 2018, IEEE ACCESS, V6, P27091, DOI 10.1109/ACCESS.2018.2831675
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang P, 2014, PROCEDIA ENGINEER, V83, P37, DOI 10.1016/j.proeng.2014.09.010
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2017, IEEE PHOT SPEC CONF, P721, DOI 10.1109/PVSC.2017.8366628
NR 35
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24539
EP 24552
DI 10.1007/s11042-018-6999-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900039
DA 2024-07-18
ER

PT J
AU Peng, P
   Gu, XL
   Zhu, SG
   Shou, LD
   Chen, G
AF Peng, Pai
   Gu, Xiaoling
   Zhu, Suguo
   Shou, Lidan
   Chen, Gang
TI One net to rule them all: efficient recognition and retrieval of POI
   from geo-tagged photos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Places-of-interest; Image recognition; Image retrieval; Deep hashing
ID IMAGE RETRIEVAL
AB In this work, we present DeepCamera, a novel framework that combines visual recognition and spatial recognition for identifying places-of-interest (POIs) from smartphone photos. Both deep visual features and geographic features of images are explored in our framework. For visual recognition, we first design the HashNet model extended from an ordinary convolutional neural network (ConvNet) by adding a "hash layer" following the last fully connected layer. Furthermore, we compress multiple pre-trained deep HashNets into one single shallow and hash network namely "SHNet" that outputs semantic labels and compact hash codes simultaneously. As a result, it significantly reduces the time and memory consumption during POI recognition. For spatial recognition, a new layer called Spatial Layer is appended to a ConvNet to capture spatial information. Finally, both visual and spatial knowledge contribute to generating a hybrid probability distribution over all possible POI candidates by plugging the spatial layer into SHNet. Notably, the proposed SHNet model can be used for general visual recognition and retrieval. The experiments conducted on real-world datasets and classic datasets (MNIST and CIFAR-10) demonstrate the competitive accuracy and run-time performance of our proposed framework.
C1 [Peng, Pai] YoutuLab Tencent Technol Shanghai Co, Shanghai 200233, Peoples R China.
   [Gu, Xiaoling; Zhu, Suguo] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Shou, Lidan; Chen, Gang] Zhejiang Univ, Coll Comp Sci & Technol, Database Lab, Hangzhou 310007, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University
RP Gu, XL (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Zhejiang, Peoples R China.
EM popeyepeng@tencent.com; guxl@hdu.edu.cn; zsg2016@hdu.edu.cn;
   should@zju.edu.cn; cg@zju.edu.cn
FU National Basic Research Program (973 Program) [2015CB352400]; National
   Science Foundation of China [61802100, 61672455, 61528207, 61472348];
   Natural Science Foundation of Zhejiang Province of China [LY18F020005]
FX The project was supported by the National Basic Research Program (973
   Program, GrantNo. 2015CB352400), and the National Science Foundation of
   China (GrantNo. 61802100, 61672455, 61528207 and 61472348). The project
   was also supported by the Natural Science Foundation of Zhejiang
   Province of China (GrantNo. LY18F020005).
CR [Anonymous], ARXIV150700101
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], UNDERSTANDING FASHIO
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Ba LJ, 2014, ADV NEUR IN, V27
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cheng ZY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3654
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   Gao F, 2018, PATTERN RECOGN, V81, P432, DOI 10.1016/j.patcog.2018.04.016
   Gao F, 2017, NEUROCOMPUTING, V257, P104, DOI 10.1016/j.neucom.2017.01.054
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gu XL, 2017, INFORM SCIENCES, V417, P310, DOI 10.1016/j.ins.2017.07.027
   Gu XL, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P463, DOI 10.1145/2671188.2749298
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li R., 2016, Advances in Neural Information Processing Systems, V29, P4655
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Luo X, 2018, ACM/SIGIR PROCEEDINGS 2018, P735, DOI 10.1145/3209978.3210035
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Peng P, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P707, DOI 10.1145/2600428.2609557
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Sermanet P., 2 INT C LEARN REPR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2018, IEEE T INF FOREN SEC, V13, P1317, DOI 10.1109/TIFS.2017.2787986
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 44
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24347
EP 24371
DI 10.1007/s11042-018-6847-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900030
DA 2024-07-18
ER

PT J
AU Ren, Y
   Liu, F
   Yan, W
   Wang, W
AF Ren, Y.
   Liu, F.
   Yan, W.
   Wang, W.
TI A new visual evaluation criterion of visual cryptography scheme for
   character secret image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography scheme; Visual secret sharing; Contrast; Recognition
   rate; Overall pixel expansion
ID SHARING SCHEMES; PIXEL EXPANSION; SIZE; CONTRAST; QUALITY
AB Since visual cryptography scheme (VCS) was introduced by Naor and Shamir, contrast has been always regarded as an evaluation standard of visual quality of the revealed secret image. However, its original definition only reflects the relative difference between white area and black area of the revealed secret image so that it is incapable to access actual visual quality. Although other definitions of contrast were also proposed, researchers have not reached consensus on the definition of contrast until now. In this paper, a novel method is proposed to obtain recognition result of the revealed character secret image through simulating the recognition procedure of our human eyes. Recognition rate is adopted to evaluate the clearness of the revealed secret image. Experimental results and comparisons demonstrate that recognition rate can be regarded as a new visual evaluation criterion of VCS for character secret image. Finally, a construction of VCS with optimized overall pixel expansion is provided, in which the pixel expansion is thoroughly determined by recognition rate, rather than contrast.
C1 [Ren, Y.] Beijing Informat Sci Technol Univ, Sch Informat Management, Beijing, Peoples R China.
   [Liu, F.; Wang, W.] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Liu, F.; Wang, W.] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Yan, W.] Auckland Univ Technol, Dept Comp Sci, Auckland, New Zealand.
C3 Beijing Information Science & Technology University; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS; Auckland
   University of Technology
RP Ren, Y (corresponding author), Beijing Informat Sci Technol Univ, Sch Informat Management, Beijing, Peoples R China.
EM ryweier@sina.com
RI liu, feng/B-3050-2019
FU National Natural Science Foundation of China [61671448]; Scientific
   Research Project of Beijing Municipal Educational Committee
   [KM201611232016]
FX The authors thank the anonymous reviewers for their valuable comments.
   This work was supported by the National Natural Science Foundation of
   China grant No. 61671448 and the Scientific Research Project of Beijing
   Municipal Educational Committee grant No.KM201611232016.
CR Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Blundo C, 1998, COMPUT GRAPH, V22, P449, DOI 10.1016/S0097-8493(98)00034-X
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, DESIGN CODE CRYPTOGR, V35, P311, DOI 10.1007/s10623-003-6741-z
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   Eisen PA, 2002, DESIGN CODE CRYPTOGR, V25, P15, DOI 10.1023/A:1012504516447
   Fu ZX, 2014, MULTIMED TOOLS APPL, V73, P1177, DOI 10.1007/s11042-013-1625-3
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Hou YC, 2005, J RES PRACT INF TECH, V37, P179
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Koga H, 2002, LECT NOTES COMPUT SC, V2501, P328
   Liu F., 2014, VISUAL CRYPTOGRAPHY
   Liu F, 2014, FLEXIBLE VISUAL CRYP, VIX, P110
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P331, DOI 10.1016/j.jvcir.2011.11.003
   Liu F, 2010, INFORM PROCESS LETT, V110, P241, DOI 10.1016/j.ipl.2010.01.003
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Peng Li, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P219, DOI 10.1109/IIH-MSP.2012.59
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Shyu SJ, 2015, THEOR COMPUT SCI, V565, P30, DOI 10.1016/j.tcs.2014.10.048
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Tzeng WG, 2002, DESIGN CODE CRYPTOGR, V27, P207, DOI 10.1023/A:1019939020426
   Verheul E. R., 1997, Designs, Codes and Cryptography, V11, P179, DOI 10.1023/A:1008280705142
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Yang CN, 2015, INFORM SCIENCES, V312, P131, DOI 10.1016/j.ins.2015.03.024
   Yang CN, 2013, PERS UBIQUIT COMPUT, V17, P843, DOI 10.1007/s00779-012-0535-0
   Yang CN, 2006, PATTERN RECOGN, V39, P1300, DOI 10.1016/j.patcog.2006.01.013
   Yang CN, 2005, PATTERN RECOGN LETT, V26, P193, DOI 10.1016/j.patrec.2004.08.025
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang CN, 2011, VISUAL CRYPTOGRAPHY
NR 35
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25299
EP 25319
DI 10.1007/s11042-019-7698-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700005
DA 2024-07-18
ER

PT J
AU Hung, KW
   Wang, K
   Jiang, JM
AF Hung, Kwok-Wai
   Wang, Kun
   Jiang, Jianmin
TI Image interpolation using convolutional neural networks with deep
   recursive residual learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image interpolation; Recursive residual learning; Convolutional neural
   network; Up-sampling
AB Recent developments of image super-resolution often utilize the deep convolutional neural network (CNN) and residual learning to relate the observed low-resolution pixels and unknown high-resolution pixels. However, image interpolation assumes that the observed image was directly down-sampled without low-pass filtering, such that the aliased down-sampled low-resolution image exhibits jags and chaos that cannot be easily modeled by conventional residual learning in super-resolution. In this paper, we propose a new framework to exploit the residual dense network using hierarchical levels of recursive residual learning and densely connected convolutional layers for image interpolation. The proposed deep recursive network iteratively reconstructs hierarchical levels of image details for aliased and discontinuous residual of interpolated pixels. Experimental results on popular Set16, Set18, and Urban12 image datasets show that the proposed method outperforms state-of-the-art image interpolation methods using local and nonlocal autoregressive models, random forests and deep CNN, in terms of PSNR (0.27-1.57 dB gain), SSIM and subjective evaluations. More importantly, model parameters of the proposed method are significantly less than that of existing deep CNN for image interpolation.
C1 [Hung, Kwok-Wai; Wang, Kun; Jiang, Jianmin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
C3 Shenzhen University
RP Hung, KW (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM kwhung@szu.edu.cn; jianmin.jiang@szu.edu.cn
OI Hung, Kwok Wai/0000-0002-1665-3669
FU Natural Science Foundation China (NSFC) [61602312, 61620106008];
   Shenzhen Commission for Scientific Research Innovations
   [JCYJ20160226191842793]
FX The authors wish to acknowledge the financial support from: (i) Natural
   Science Foundation China (NSFC) under the Grant No. 61602312,
   61620106008; and (ii) Shenzhen Commission for Scientific Research &
   Innovations under the Grant No. JCYJ20160226191842793.
CR [Anonymous], 2014, ACM INT C MULTIMEDIA
   [Anonymous], 2016, CVPR
   Bai XF, 2013, IEICE T INF SYST, VE96D, P387, DOI 10.1587/transinf.E96.D.387
   Colonnese S, 2013, SIGNAL PROCESS-IMAGE, V28, P967, DOI 10.1016/j.image.2012.07.001
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Dong-Hun Chae, 2016, 2016 Conference on Precision Electromagnetic Measurements (CPEM), P1, DOI 10.1109/CPEM.2016.7540495
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Huang JJ, 2015, IEEE T IMAGE PROCESS, V24, P3232, DOI 10.1109/TIP.2015.2440751
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakshman H, 2015, SIGNAL PROCESS-IMAGE, V36, P83, DOI 10.1016/j.image.2015.06.004
   Li MD, 2015, IEEE T CIRC SYST VID, V25, P200, DOI 10.1109/TCSVT.2014.2347531
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643
   Liu XM, 2011, IEEE T IMAGE PROCESS, V20, P3455, DOI 10.1109/TIP.2011.2150234
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Nemirovsky S, 2009, SIGNAL PROCESS-IMAGE, V24, P139, DOI 10.1016/j.image.2008.11.001
   Romano Y, 2014, IEEE T IMAGE PROCESS, V23, P3085, DOI 10.1109/TIP.2014.2325774
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   YAN XX, 2013, J INF HIDING MULTIME, V4
   Yang W, IEEE T CIRCUIT SYST
   Yang WH, 2017, IEEE IMAGE PROC, P1652, DOI 10.1109/ICIP.2017.8296562
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhu S, IEEE SIGNAL PROCESS
NR 33
TC 9
Z9 9
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22813
EP 22831
DI 10.1007/s11042-019-7633-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400029
DA 2024-07-18
ER

PT J
AU Regouid, M
   Touahria, M
   Benouis, M
   Costen, N
AF Regouid, Meryem
   Touahria, Mohamed
   Benouis, Mohamed
   Costen, Nicholas
TI Multimodal biometric system for ECG, ear and iris recognition based on
   local descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; EAR; IRIS; 1D-LBP; Shifted-1D-LBP; 1D-MR-LBP; CRR; EER
ID LEVEL FUSION; EXTRACTION; SIGNAL
AB Combination of multiple information extracted from different biometric modalities in multimodal biometric recognition system aims to solve the different drawbacks encountered in a unimodal biometric system. Fusion of many biometrics has proposed such as face, fingerprint, iris horizontal ellipsis etc. Recently, electrocardiograms (ECG) have been used as a new biometric technology in unimodal and multimodal biometric recognition system. ECG provides inherent the characteristic of liveness of a person, making it hard to spoof compared to other biometric techniques. Ear biometrics present a rich and stable source of information over an acceptable period of human life. Iris biometrics have been embedded with different biometric modalities such as fingerprint, face and palm print, because of their higher accuracy and reliability. In this paper, a new multimodal biometric system based ECG-ear-iris biometrics at feature level is proposed. Preprocessing techniques including normalization and segmentation are applied to ECG, ear and iris biometrics. Then, Local texture descriptors, namely 1D-LBP (One D-Local Binary Patterns), Shifted-1D-LBP and 1D-MR-LBP (Multi-Resolution) are used to extract the important features from the ECG signal and convert the ear and iris images to a 1D signals. KNN and RBF are used for matching to classify an unknown user into the genuine or impostor. The developed system is validated using the benchmark ID-ECG and USTB1, USTB2 and AMI ear and CASIA v1 iris databases. The experimental results demonstrate that the proposed approach outperforms unimodal biometric system. A Correct Recognition Rate (CRR) of 100% is achieved with an Equal Error Rate (EER) of 0.5%.
C1 [Regouid, Meryem; Touahria, Mohamed] Univ Ferhat Abbas Setif 1, Comp Sci Dept, Pole 2 El Bez, Setif 19000, Algeria.
   [Benouis, Mohamed] Univ MsilaBP, Comp Sci Dept, Msila 28000, Algeria.
   [Costen, Nicholas] Manchester Metropolitan Univ, Cognit Comp Vis, Face Recognit & Human Mot Anal, Manchester, Lancs, England.
C3 Universite Ferhat Abbas Setif; Manchester Metropolitan University
RP Regouid, M (corresponding author), Univ Ferhat Abbas Setif 1, Comp Sci Dept, Pole 2 El Bez, Setif 19000, Algeria.
EM meryem.regouid@univ-setif.dz; mohamed.touahria@univ-setif.dz;
   mohamed.benouis@univ.msila.dz; n.costen@mmu.ac.uk
RI Benouis, Mohamed/AAJ-2731-2021
OI Benouis, Mohamed/0000-0002-9107-9329; Costen,
   Nicholas/0000-0001-9454-8840
CR Al-Hamdani O, 2013, MULTIMODAL BIOMETRIC, V04
   Annapurani K, 2015, EXPERT SYST APPL, V42, P649, DOI 10.1016/j.eswa.2014.08.009
   [Anonymous], AMI Ear Database
   [Anonymous], 2003, Recognition of Human Iris Patterns for Biometric Identification
   [Anonymous], P MULT US AUTH WORKS
   [Anonymous], IAPR WORKSH MULT PAT
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   [Anonymous], NEURAL NETWORKS LEAR
   [Anonymous], 2018, MACH VIS APPL
   Anwar AS, 2015, PROCEDIA COMPUT SCI, V65, P529, DOI 10.1016/j.procs.2015.09.126
   Barpanda SS, 2018, MULTIMED TOOLS APPL, V77, P7637, DOI 10.1007/s11042-017-4668-z
   Barra S, 2017, MULTIMED TOOLS APPL, V76, P4835, DOI 10.1007/s11042-016-3796-1
   Bassiouni M, 2018, SIGNAL IMAGE VIDEO P, V12, P941, DOI 10.1007/s11760-018-1237-5
   Belgacem N., 2013, INT C E TECHN BUS WE
   Benaliouche H, 2014, SCI WORLD J, DOI 10.1155/2014/829369
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Boumbarov O, 2011, INTECH
   Chakraborty S, 2017, IET SCI MEAS TECHNOL, V11, P226, DOI 10.1049/iet-smt.2015.0308
   Chatlani N, 2010, EUR SIGNAL PR CONF, P95
   CHUN SY, 2016, BIOM ICB 2016 INT C
   Czajka A, 2017, IEEE T INF FOREN SEC, V12, P2184, DOI 10.1109/TIFS.2017.2701332
   DAR MN, 2015, IT CONV SEC ICITCS 2, P5
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Ertugrul ÖF, 2016, EXPERT SYST APPL, V56, P156, DOI 10.1016/j.eswa.2016.03.018
   FITZSIMMONS JR, 2005, COMP VIS PATT REC WO, P121
   Ghoualmi L, 2016, EXPERT SYST APPL, V57, P49, DOI 10.1016/j.eswa.2016.03.004
   Ghoualmi L, 2015, ADV INTELL SYST, V370, P37, DOI 10.1007/978-3-319-21206-7_4
   Gürkan H, 2013, IEEE ENG MED BIO, P4259, DOI 10.1109/EMBC.2013.6610486
   He S, 2009, IEEE T BIO-MED ENG, V56, P1864, DOI 10.1109/TBME.2009.2017508
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295, DOI 10.1109/34.735803
   Iannerelli, 1989, FORENSIC IDENTIFICAT
   Islam MS, 2017, MULTIMED TOOLS APPL, V76, P12709, DOI 10.1007/s11042-016-3694-6
   Israel SA, 2004, 32ND APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P226
   Louis W, 2014, INT CONF DIGIT SIG, P601, DOI 10.1109/ICDSP.2014.6900735
   LUMINI A., 2007, International Journal of Network Security, V4, P27
   Marciniak T, 2014, MULTIMED TOOLS APPL, V68, P193, DOI 10.1007/s11042-012-1035-y
   Monwar MM, 2013, SIGNAL IMAGE VIDEO P, V7, P137, DOI 10.1007/s11760-011-0226-8
   Nemirko A., 2005, Proceedings of the XIIIth Russian Conference on Mathematical Methods of Pattern Recognition, P20
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Raol J.R., 2015, Data Fusion Mathematics: Theory and Practice
   Ritter N., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P740, DOI 10.1109/ICIAP.1999.797683
   Ross A, 2005, PROC SPIE, V5779, P196, DOI 10.1117/12.606093
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Shin D, 2017, MULTIMED TOOLS APPL, V76, P11449, DOI 10.1007/s11042-016-4203-7
   Tahmasebi A, 2017, IJST-T ELECTR ENG, V41, P51, DOI 10.1007/s40998-017-0017-5
   Vezzetti E, 2012, ROBOT AUTON SYST, V60, P928, DOI 10.1016/j.robot.2012.01.003
   Wildes R. P., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P121, DOI 10.1109/ACV.1994.341298
   Wübbeler G, 2007, PATTERN RECOGN LETT, V28, P1172, DOI 10.1016/j.patrec.2007.01.014
NR 52
TC 30
Z9 30
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22509
EP 22535
DI 10.1007/s11042-019-7467-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400015
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sarkar, A
   Singh, BK
AF Sarkar, Arpita
   Singh, Binod Kumar
TI A cancelable fingerprint biometric based session key establishment
   protocol
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Cryptography; Session key; NIST; Symmetric key
   cryptography; Key management; Key distribution
ID SCHEME
AB Symmetric key cryptography needs the communicating parties to share a secret key. It is desired that a different shared key is established for each communication session. A trusted third party distributes these shared keys through a communication link between communicating parties. As the key is transferred through an insecure communication link attacker can guess the key easily. So maintenance and distribution of keys is a problem. Efficient and reliable techniques are needed that allow two or more remote parties to set up a shared secret key in a dynamic on-demand manner. As a probable solution to this problem, generation of the cryptographic key using the biometric traits of both communicating parties during the transmission session can be done. Thus avoiding key storing and key sharing in session key establishment protocols. However, this biometric based cryptographic key generation has some difficulties of maintaining the privacy of user's biometric data, exchanging of biometric data and revocable key generation from irrevocable biometric. This present methodology addresses the mentioned concern and proposes a session key establishment protocol where communicating parties first transform their biometric template in cancelable one to preserve the privacy of biometric template and exchange transformed template with each other. After that generate a 128- bit session key in their end with the help of their combined cancelable fingerprint templates and a random shuffle key provided to them by a trusted authentication server. Authentication server works as a trusted third party and is located in between the communicating parties. As both parties generates the same session key in their end there is no need to share secret key through insecure channel. This generated biometric based session keys can be used in the session key establishment protocol for better security of data transmission.
C1 [Sarkar, Arpita; Singh, Binod Kumar] NIT Jamshedpur, Dept CSE, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Sarkar, A (corresponding author), NIT Jamshedpur, Dept CSE, Jharkhand, India.
EM asarkar.cse@nitjsr.ac.in; bksingh.cse@nitjsr.ac.in
RI Singh, Binod/AAB-8663-2019; Sarkar, Arpita/JFL-1710-2023
OI Singh, Binod/0000-0002-2697-8918; 
CR Abid M, 2009, J INF ASSUR SECUR, V4, P338
   [Anonymous], 2013, NAT C CHALL RES TECH
   [Anonymous], 2007, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2007.383110
   [Anonymous], 2008, The transport layer security (TLS) protocol version 1.2
   Barman S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1629, DOI 10.1109/ICACCI.2014.6968299
   Barni Mauro., 2010, MM SEC 2010 2010 ACM, P231
   Bassham III LE, 2010, Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications, DOI DOI 10.6028/NIST.SP.800-22R1A
   Boyen X., 2004, Proceedings of the 11th ACM Conference on Computer and Communications Security, P82, DOI DOI 10.1145/1030083.1030096
   Boyen X., 2005, LNCS, V3494, P147, DOI [10.1007/114266399, DOI 10.1007/114266399]
   Bringer J, 2007, 12 AUSTR C INF SEC P, DOI 10. 1007/978-3-540-73458-1
   Buhan I, 2007, TECHNICAL REPORT, DOI [10. 1504/IJSN. 2009. 023424, DOI 10.1504/IJSN.2009.023424]
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Fan CI, 2009, IEEE T INF FOREN SEC, V4, P933, DOI 10.1109/TIFS.2009.2031942
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Juels A, 2002, ISIT: 2002 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P408, DOI 10.1109/ISIT.2002.1023680
   Kanade S, BTAS 2010, P1
   Kanade S., 2009, P WORLD ACAD SCI ENG
   Liu Y, P 24 INT C ART INT I, P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nandakumar K., 2008, IEEE 2 INT C BIOM TH
   Nandakumar K, 2007, FINGERPRINT BASED FU, V2
   Sakurai YU, 2006, SECURITY MANAGEMENT
   Sarkar A., 2018, 2018 4 INT C REC ADV, P1
   Scheirer W.J., 2008, 2008 BIOMETRICS S BS, P9, DOI [10. 1109/BSYM. 2008. 4655516, DOI 10.1109/BSYM.2008.4655516]
   Scheirer WJ, 2009, INT C BIOM ICB, DOI [10.1007/978-3-642-01793-379, DOI 10.1007/978-3-642-01793-379]
   Stallings W., 2010, CRYPTOGRAPHY NETWORK, V5e
   Tang Q, 2008, INF SEC PRACT EXP C, DOI [10.1007/978-3-540-79104-15, DOI 10.1007/978-3-540-79104-15]
   Upmanyu M, 2009, INT C BIOM ICB, DOI [10.1007/978-3-642-01793-3-91, DOI 10.1007/978-3-642-01793-3-91]
   Upmanyu M, 2010, IEEE T INF FOREN SEC, V5, P255, DOI 10.1109/TIFS.2010.2043188
NR 29
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21645
EP 21671
DI 10.1007/s11042-019-7426-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400050
DA 2024-07-18
ER

PT J
AU Abdulla, AA
   Sellahewa, H
   Jassim, SA
AF Abdulla, Alan A.
   Sellahewa, Harin
   Jassim, Sabah A.
TI Improving embedding efficiency for digital steganography by exploiting
   similarities between secret and cover images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Security; Embedding efficiency; Least
   significant bit (LSB)
AB Digital steganography is becoming a common tool for protecting sensitive communications in various applications such as crime/terrorism prevention whereby law enforcing personals need to remotely compare facial images captured at the scene of crime with faces databases of known criminals/suspects; exchanging military maps or surveillance video in hostile environment/situations; privacy preserving in the healthcare systems when storing or exchanging patient's medical images/records; and prevent bank customers' accounts/records from being accessed illegally by unauthorized users. Existing digital steganography schemes for embedding secret images in cover image files tend not to exploit various redundancies in the secret image bit-stream to deal with the various conflicting requirements on embedding capacity, stego-image quality, and undetectibility. This paper is concerned with the development of innovative image procedures and data hiding schemes that exploit, as well as increase, similarities between secret image bit-stream and the cover image LSB plane. This will be achieved in two novel steps involving manipulating both the secret and the cover images, prior to embedding, to achieve higher 0:1 ratio in both the secret image bit-stream and the cover image LSB plane. The above two steps strategy has been exploited to use a bit-plane(s) mapping technique, instead of bit-plane(s) replacement to make each cover pixel usable for secret embedding. This paper will demonstrate that this strategy produces stego-images that have minimal distortion, high embedding efficiency, reasonably good stego-image quality and robustness against 3 well-known targeted steganalysis tools.
C1 [Abdulla, Alan A.] Univ Sulaimani, Coll Commerce, Dept Informat Technol, Sulaimani, Krg, Iraq.
   [Sellahewa, Harin; Jassim, Sabah A.] Univ Buckingham, Appl Comp Dept, Buckingham MK18 1EG, England.
C3 University of Sulimanyah; University of Buckingham
RP Abdulla, AA (corresponding author), Univ Sulaimani, Coll Commerce, Dept Informat Technol, Sulaimani, Krg, Iraq.
EM alananwer@yahoo.com; harin.sellahewa@buckingham.ac.uk;
   sabah.jassim@buckingham.ac.uk
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, P SPIE ELECT IMAGING
   Abdulla AA, 2013, P SPIE ELECT IMAGING
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Alharbi F, 2013, INT J ADV COMPUT SC, V4, P52
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2011, P 13 INF HID C PRAG
   Aroukatos N., 2012, Proceedings of the 2012 Ninth International Conference on Information Technology: New Generations (ITNG), P392, DOI 10.1109/ITNG.2012.96
   Astola, 2006, 14 EUR SIGN PROC C E, P1
   Bhattacharyya D, 2009, PROCEEDINGS OF THE 8TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P196, DOI 10.1109/COGINF.2009.5250756
   Calderbank AR, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P596, DOI 10.1109/ICIP.1997.647983
   Chan CS, 2009, FUND INFORM, V96, P49, DOI 10.3233/FI-2009-166
   Chen P.Y., 2006, INT J APPL SCI ENG, V4, P275, DOI DOI 10.6703/IJASE/2006.4(3).275
   Cox IJ, 2005, LECT NOTES COMPUT SC, V3710, P15
   Cox IJ., 2007, DIGITAL WATERMARKING
   Crandall R., 1998, SOME NOTES STEGANOGR
   Dey Sandipan, 2007, 2007 3rd International Symposium on Information Assurance and Security, P101
   Dey S, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P473
   Fridrich J, 2004, PROC SPIE, V5306, P23, DOI 10.1117/12.521350
   Fridrich J, 2007, LECT NOTES COMPUT SC, V4437, P282
   Iranpour M, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON HIGH CAPACITY OPTICAL NETWORKS AND ENABLING TECHNOLOGIES (HONET-CNS), P21, DOI 10.1109/HONET.2013.6729751
   Ker A, 2005, INFORM HIDING, V3200, P97
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Ker A. D., 2008, P SPIE ELECT IMAGING, V6819
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Lin GS, 2010, IEEE T MULTIMEDIA, V12, P345, DOI 10.1109/TMM.2010.2051243
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Viterbi U, 1981, USC SIPI IM DAT
   Zhang T, 2003, AIEEE INT C AC SPEEC, V1, P54
NR 32
TC 55
Z9 57
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17799
EP 17823
DI 10.1007/s11042-019-7166-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Coelho, H
   Melo, M
   Martins, J
   Bessa, M
AF Coelho, Hugo
   Melo, Miguel
   Martins, Jose
   Bessa, Maximino
TI Collaborative immersive authoring tool for real-time creation of
   multisensory VR experiences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative; Multisensory; Virtual reality; Real-time; Authoring tool
ID VIRTUAL-REALITY; METAANALYSIS; DESIGN
AB With the appearance of innovative virtual reality (VR) technologies, the need to create immersive content arose. Although there are already some non-immersive solutions to address immersive audio-visual content, there are no solutions that allow the creation of immersive multisensory content. This work proposes a novel architecture for a collaborative immersive tool that allows the creation of multisensory VR experiences in real-time, thus promoting the expeditious development, adoption, and use of immersive systems and enabling the building of custom-solutions that can be used in an intuitive manner to support organizations' business initiatives. To validate the presented proposal, two approaches for the authoring tools (Desktop interface and Immersive interface) were subjected to a set of tests and evaluations consisting of a usability study that demonstrated not only the participants' acceptance of the authoring tool but also the importance of using immersive interfaces for the creation of such VR experiences.
C1 [Coelho, Hugo; Martins, Jose] Univ Tras Os Montes & Alto Douro, Vila Real, Portugal.
   [Bessa, Maximino] Univ Tras Os Montes & Alto Douro, Habilitat, Dept Engn, Vila Real, Portugal.
   [Melo, Miguel; Martins, Jose; Bessa, Maximino] INESC TEC, Porto, Portugal.
   [Martins, Jose] Polytech Inst Bragranca EsACT, Mirandela, Portugal.
C3 University of Tras-os-Montes & Alto Douro; University of Tras-os-Montes
   & Alto Douro; INESC TEC
RP Coelho, H (corresponding author), Univ Tras Os Montes & Alto Douro, Vila Real, Portugal.
EM hcoelho@utad.pt
RI Melo, Miguel/AAN-1855-2020; Bessa, Maximino/B-4729-2012; Martins,
   José/N-7005-2018; Martins, José/ABB-5272-2020
OI Melo, Miguel/0000-0003-4050-3473; Bessa, Maximino/0000-0002-3002-704X;
   Martins, José/0000-0002-7787-6305; Coelho, Hugo/0000-0003-4227-6198
CR Adobe, 2017, AD CREAT CLOUD
   Ahlberg G, 2002, SURG ENDOSC, V16, P126, DOI 10.1007/s00464-001-9025-6
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   [Anonymous], 2017, CryEngine
   Arnold Peter, 2017, P 2017 CHI C EXTENDE, P206
   BlueLabel Labs, 2017, ID APPST
   Bouvier P., 2008, Presence 2008: Proceedings of the 11th International Workshop, P246
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Burdea G. C., 2003, Virtual reality technology
   Coelho H, 2018, P 6 WORLD C INF SYST, P309
   De Barros P.G., 2013, Proceedings of the 1st symposium on Spatial user interaction, P41, DOI DOI 10.1145/2491367.2491371
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Engström E, 2011, INFORM SOFTWARE TECH, V53, P2, DOI 10.1016/j.infsof.2010.05.011
   Epic Games, 2017, UNR ENG 4
   Feng M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P95, DOI 10.1109/3DUI.2016.7460037
   Freitas J., 2015, Em 2015 10th Iberian Conference on Information Systems and Technologies (CISTI), P1, DOI DOI 10.1109/CISTI.2015.7170495
   Frohlich Julia, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P159, DOI 10.1007/978-3-642-39405-8_19
   Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529
   Heilig M, 1962, Patent No. [3,050,870, 3050870]
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Huang YS, 2014, IEEE T INTELL TRANSP, V15, P530, DOI 10.1109/TITS.2013.2283034
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Iwata N, 2011, SURG ENDOSC, V25, P423, DOI 10.1007/s00464-010-1184-x
   Jones S, 2018, PROGR IS, P183, DOI 10.1007/978-3-319-64027-3_13
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Luigi M, 2015, ENRGY PROCED, V78, P471, DOI 10.1016/j.egypro.2015.11.703
   Manghisi Vito M, 2017, IEEE Comput Graph Appl, V37, P19, DOI 10.1109/MCG.2017.4031064
   Marchand A, 2013, J INTERACT MARK, V27, P141, DOI 10.1016/j.intmar.2013.05.001
   Maroco J., 2014, ANALISE ESTATISTICA
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   McGregor C., 2017, IEEE INT CONF SERIOU, P1
   Mortara M, 2014, J CULT HERIT, V15, P318, DOI 10.1016/j.culher.2013.04.004
   Mujber TS, 2004, J MATER PROCESS TECH, V155, P1834, DOI 10.1016/j.jmatprotec.2004.04.401
   Newbutt N., 2017, Recent advances in technologies for inclusive well-being: From worn to off-body sensing, virtual worlds, and games for serious applications, P221, DOI 10.1007/978-3-319-49879-9_11
   Pan MKXJ, 2017, P IEEE VIRT REAL ANN, P269, DOI 10.1109/VR.2017.7892280
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Passig D, 2016, COMPUT EDUC, V95, P296, DOI 10.1016/j.compedu.2016.01.009
   Portman ME, 2015, COMPUT ENVIRON URBAN, V54, P376, DOI 10.1016/j.compenvurbsys.2015.05.001
   Qu T, 2016, INT J ADV MANUF TECH, V84, P147, DOI 10.1007/s00170-015-7220-1
   Sacau A, 2008, COMPUT HUM BEHAV, V24, P2255, DOI 10.1016/j.chb.2007.11.001
   Schneider O, 2017, INT J HUM-COMPUT ST, V107, P5, DOI 10.1016/j.ijhcs.2017.04.004
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Unity Technologies, 2017, UN VERS 2017 3 0 COM
   Wang J, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P195
   Wang RH, 2017, IEEE SYMP 3D USER, P215, DOI 10.1109/3DUI.2017.7893348
NR 48
TC 17
Z9 19
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19473
EP 19493
DI 10.1007/s11042-019-7309-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800025
DA 2024-07-18
ER

PT J
AU de Amorim, MN
   Saleme, EB
   Neto, FRD
   Santos, CAS
   Ghinea, G
AF de Amorim, Marcello Novaes
   Saleme, Estevao Bissoli
   de Assis Neto, Fabio Ribeiro
   Santos, Celso A. S.
   Ghinea, Gheorghita
TI Crowdsourcing authoring of sensory effects on videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mulsemedia content; Sensory effects; MPEG-V metadata; Crowdsourcing;
   Multimedia authoring; Multimedia annotation
ID EXPERIENCE; QUALITY
AB Human perception is inherently multi-sensorial involving five traditional senses: sight, hearing, touch, taste, and smell. In contrast to traditional multimedia, based on audio and visual stimuli, mulsemedia seek to stimulate all the human senses. One way to produce multi-sensorial content is authoring videos with sensory effects. These effects are represented as metadata attached to the video content, which are processed and rendered through physical devices into the user's environment. However, creating sensory effects metadata is not a trivial activity because authors have to identify carefully different details in a scene such as the exact point where each effect starts, finishes, and also its presentation features such as intensity, direction, etc. It is a subjective task that requires accurate human perception and time. In this article, we aim at finding out whether a crowdsourcing approach is suitable for authoring coherent sensory effects associated with video content. Our belief is that the combination of a collective common sense to indicate time intervals of sensory effects with an expert fine-tuning is a viable way to generate sensory effects from the point of view of users. To carry out the experiment, we selected three videos from a public mulsemedia dataset, sent them to the crowd through a cascading microtask approach. The results showed that the crowd can indicate intervals in which users agree that there should be insertions of sensory effects, revealing a way of sharing authoring between the author and the crowd.
C1 [de Amorim, Marcello Novaes; Saleme, Estevao Bissoli; de Assis Neto, Fabio Ribeiro; Santos, Celso A. S.] Univ Fed Espirito Santo, Av Fernando Ferrari 514, BR-29075910 Vitoria, ES, Brazil.
   [Ghinea, Gheorghita] Brunel Univ London, Wilfred Brown Bldg 215,Kingston Lane, Uxbridge UB8 3PH, Middx, England.
C3 Universidade Federal do Espirito Santo; Brunel University
RP de Amorim, MN (corresponding author), Univ Fed Espirito Santo, Av Fernando Ferrari 514, BR-29075910 Vitoria, ES, Brazil.
EM cellonovaes@gmail.com; estevaobissoli@gmail.com;
   fabio.ribeiro.neto@gmail.com; saibel@inf.ufes.br;
   george.ghinea@brunel.ac.uk
RI Saleme, Estêvão Bissoli/U-4446-2019; Ghinea, Gheorghita/AAG-6770-2020;
   SANTOS, CELSO Alberto Saibel/M-9733-2014; Saleme, Estevao
   B./AAZ-7161-2020
OI Saleme, Estêvão Bissoli/0000-0003-1856-3824; Ghinea,
   Gheorghita/0000-0003-2578-5580; SANTOS, CELSO Alberto
   Saibel/0000-0002-3287-5843; Saleme, Estevao B./0000-0003-1856-3824;
   Novaes de Amorim, Marcello/0000-0002-9422-8756
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior -Brasil
   (CAPES); Brazilian National Council for Scientific and Technological
   Development (CNPq); Fundacao de Amparo a Pesquisa e Inovacao do Espirito
   Santo (FAPES); Federal Institute of Espirito Santo; European Union's
   Horizon 2020 Research and Innovation programme [688503]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior -Brasil (CAPES), the Brazilian National
   Council for Scientific and Technological Development (CNPq), and the
   Fundacao de Amparo a Pesquisa e Inovacao do Espirito Santo (FAPES).
   Estevao Bissoli Saleme thankfully acknowledges support from the Federal
   Institute of Espirito Santo. Prof. Gheorghita Ghinea gratefully
   acknowledges funding from the European Union's Horizon 2020 Research and
   Innovation programme under Grant Agreement no. 688503 for the NEWTON
   project (http://www.newtonproject.eu).
CR Amorim MN, 2018, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2018.8439402
   [Anonymous], 2016, ACM T MULTIM COMPUT, DOI DOI 10.1145/2957753
   [Anonymous], ACM T MULTIM COMPU S
   [Anonymous], P 5 WORKSH AUT KNOWL
   [Anonymous], 2010, THESIS
   [Anonymous], INFLUENCE HUMAN FACT
   [Anonymous], DR DETECTIVE COMBINI
   [Anonymous], P ACM MULT WORKSH CR
   [Anonymous], 2016, IEEE, DOI DOI 10.1109/QOMEX.2016.7498964
   Neto FRA, 2018, INFORM PROCESS MANAG, V54, P490, DOI 10.1016/j.ipm.2018.03.006
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Bartocci S, 2015, 2015 AEIT INTERNATIONAL ANNUAL CONFERENCE (AEIT)
   Chen JW, 2019, MULTIMED TOOLS APPL, V78, P2689, DOI 10.1007/s11042-018-5746-6
   Choi Bumsuk, 2011, 2011 INT C INFORM SC, DOI [10.1109/icisa.2011.5772390, DOI 10.1109/ICISA.2011.5772390]
   Covaci A, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3233774
   Cross Andrew., 2014, Proceedings_of_the_17th_ACM_conference_on_Computer_supported_cooperative_work__social computing, P1167, DOI DOI 10.1145/2531602.2531670
   Di Salvo Roberto., 2016, Applications of Computer Vision (WACV), 2016 IEEE Winter Conference on, P1
   Foncubierta-Rodriguez A., 2012, P ACM MULT 2012 WORK, DOI [DOI 10.1145/2390803.2390808, 10.1145/2390803.2390808]
   Galton F, 1907, NATURE, V75, P450, DOI 10.1038/075450a0
   Hardman L, 2008, MULTIMEDIA SYST, V14, P327, DOI 10.1007/s00530-008-0134-0
   Hyun-Woo Oh, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P160, DOI 10.1109/ICCE.2017.7889269
   Kim SK, 2014, ETRI J, V36, P224, DOI 10.4218/etrij.14.2113.0065
   Kim SK, 2013, SIGNAL PROCESS-IMAGE, V28, P162, DOI 10.1016/j.image.2012.10.011
   Kim SI, 2014, ADV MATER INTERFACES, V1, DOI 10.1002/admi.201300029
   Lasecki WS, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P23
   Masiar A, 2015, 10TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION SMAP 2015, P61
   McNaney R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4464, DOI 10.1145/2858036.2858321
   Rainer B, 2012, INT WORK QUAL MULTIM, P278, DOI 10.1109/QoMEX.2012.6263842
   Sadallah M, 2014, MULTIMED TOOLS APPL, V70, P869, DOI 10.1007/s11042-012-1177-y
   Saleme EB, 2019, IEEE MULTIMEDIA, V26, P66, DOI 10.1109/MMUL.2018.2873565
   Saleme EB, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P308, DOI 10.1145/3083187.3084013
   Shin SH, 2016, INT CONF UBIQ FUTUR, P730, DOI 10.1109/ICUFN.2016.7537133
   Taborsky E, 2015, INT CONF BIOMETR, P264, DOI 10.1109/ICB.2015.7139094
   Teki S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153916
   Timmerer C, 2012, SIGNAL PROCESS-IMAGE, V27, P909, DOI 10.1016/j.image.2012.01.016
   van Holthoon F., 1987, COMMON SENSE FDN SOC
   Waltl Markus, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P124, DOI 10.1109/QOMEX.2010.5517704
   Waltl M, 2013, SIGNAL PROCESS-IMAGE, V28, P136, DOI 10.1016/j.image.2012.10.009
   Waltl M, 2012, INT WORK QUAL MULTIM, P115, DOI 10.1109/QoMEX.2012.6263841
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P957, DOI 10.1109/TMM.2015.2431915
   Yue T, 2018, MULTIMED TOOLS APPL, V77, P27269, DOI 10.1007/s11042-018-5918-4
   Zhai HJ, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2426
NR 42
TC 10
Z9 10
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19201
EP 19227
DI 10.1007/s11042-019-7312-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU El-Bakary, EM
   El-Shafai, W
   El-Rabaie, S
   Zahran, O
   El-Halawany, M
   Abd El-Samie, FE
AF El-Bakary, E. M.
   El-Shafai, W.
   El-Rabaie, S.
   Zahran, O.
   El-Halawany, M.
   Abd El-Samie, F. E.
TI Proposed enhanced hybrid framework for efficient 3D-MVC and 3D-HEVC
   wireless communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D MVC; Convolution codes; Linear equalization; Chaotic interleaving;
   HEVC; OFDM
ID MULTIVIEW VIDEO; OFDM
AB The streaming of Three-Dimensional Video (3DV) over erroneous wireless channels causes Macro-Blocks (MBs) corruptions. Thus, the efficient performance of 3DV communication techniques over wireless channels has become an interesting research topic because of the restricted resources and the existence of severe communication losses. The 3DV consists of various video sequences captured via multiple cameras surrounding an object, and working simultaneously. Therefore, there is a need to achieve high encoding efficiency. Unfortunately, the highly-compressed 3DV content is subject to communication channel corruptions. Thus, in this research, we suggest the utilization of a chaotic randomization technique based on Baker map with convolution coding and equalization for high-quality 3D Multi-view Video Coding (MVC) and High Efficiency Video Coding (HEVC) transmission over an Orthogonal Frequency Division Multiplexing (OFDM) wireless system. Rayleigh fading and Additive White Gaussian Noise (AWGN) are considered in this paper in a real scenario of 3DV transmission. Firstly, the 3DV volume is compressed making use of the intra- and inter-prediction correlations between frames. Then, the compressed 3D-MVC and 3D-HEVC frames are converted into binary data format. After that, the chaotic randomization technique is employed before the modulation stage. It is utilized to minimize the channel corruptions on the streamed encoded 3DV data, and it as well introduces a degree of encryption to the transmitted 3DV frames. To evaluate the efficiency of the suggested hybrid framework; different simulations on several 3D-MVC and 3D-HEVC frames have been executed. The results prove that the delivered 3DV frames with the suggested framework have high Peak Signal-to-Noise Ratios (PSNRs).
C1 [El-Bakary, E. M.; El-Shafai, W.; El-Rabaie, S.; Zahran, O.; El-Halawany, M.; Abd El-Samie, F. E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP El-Bakary, EM (corresponding author), Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
EM eman_elbakary449@yahoo.com; eng.waled.elshafai@gmail.com;
   srabie1@yahoo.com; osama_zahran@el-eng.menofia.edu.eg;
   mmohamedelhalawany@gmail.com; fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; El-Shafai, Walid/AAG-4796-2021
OI Sayed, Fathi/0000-0001-8749-9518; El-Shafai, Walid/0000-0001-7509-2120;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881; Zahran,
   Osama/0000-0001-5334-5908
CR Alfa A. S., 2014, WIR TEL S APR 2014 9, P1
   Andrews J., 2007, FUNDAMENTALS WIMAX, Vfirst
   [Anonymous], 2014, JOINT COLL TEAM 3D V
   Chakareski J, 2013, IEEE COMMUN MAG, V51, P94, DOI 10.1109/MCOM.2013.6515052
   Cho S, 2002, IEEE T CIRC SYST VID, V12, P157
   Conti A, 2003, IEEE J SEL AREA COMM, V21, P259, DOI 10.1109/JSAC.2002.807345
   El-Bakary EM, 2013, WIRELESS PERS COMMUN, V69, P979, DOI 10.1007/s11277-012-0622-6
   El-Shafai W, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0131-1
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0042-y
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0064-5
   Fraunhofer Heinrich Hertz Institute, 2015, HIGH EFF VID COD HEV
   Harada H, 2002, ART H UNI PER COMMUN, P1
   Huang F, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1340, DOI 10.1109/IIH-MSP.2008.227
   Huo YK, 2013, IEEE T CIRC SYST VID, V23, P1622, DOI 10.1109/TCSVT.2013.2254911
   Kuo C, 2012, APPL MATH INFORM SCI, V5, p16S
   Lei SW, 2002, IEEE T VEH TECHNOL, V51, P435, DOI 10.1109/TVT.2002.1002494
   Liu YW, 2017, J VIS COMMUN IMAGE R, V46, P208, DOI 10.1016/j.jvcir.2017.04.005
   Ozcinar C, 2016, MULTIMED TOOLS APPL, V75, P12431, DOI 10.1007/s11042-016-3475-2
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Qinchun Qian, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.597
   Ramzan N, 2013, IEEE IMAGE PROC, P1885, DOI 10.1109/ICIP.2013.6738388
   Salim OH, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P4077
   Sung CK, 2007, IEEE T COMMUN, V55, P1649, DOI 10.1109/TCOMM.2007.904361
   Webb W., 2007, WIRELESS COMMUNICATI
   Xiang T, 2014, APPL SOFT COMPUT, V21, P159, DOI 10.1016/j.asoc.2014.03.009
   Zhang QY, 2016, HORTIC RES-ENGLAND, V3, DOI 10.1038/hortres.2016.7
   Zhang QW, 2016, MULTIDIM SYST SIGN P, V27, P743, DOI 10.1007/s11045-014-0303-6
   Zhang QW, 2015, DIGIT SIGNAL PROCESS, V44, P37, DOI 10.1016/j.dsp.2015.06.005
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
NR 29
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14173
EP 14193
DI 10.1007/s11042-018-6765-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700004
DA 2024-07-18
ER

PT J
AU Lv, CL
   Wu, ZK
   Wang, XC
   Zhou, MQ
AF Lv, Chenlei
   Wu, Zhongke
   Wang, Xingce
   Zhou, Mingquan
TI Constructing 3D facial hierarchical structure based on surface
   measurements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D facial hierarchical structures; Conformal parametrization; Facial
   data organization
ID CLASSIFICATION; RETRIEVAL
AB In this paper, we propose a novel framework for 3D facial similarity measures and facial data organization. The 3D facial similarity measures of our method are based on iso-geodesic stripes and conformal parameterization. Using the conformal parameterization, the 3D facial surface can be mapped into a 2D domain and the iso-geodesic stripes of the face can be measured. The measure results can be regarded as the similarity of faces, which is robust to head poses and facial expressions. Based on the measure result, a hierarchical structure of faces can be constructed, which is used to organize different faces. The structure can be utilized to accelerate the face searching speed in a large database. In experiment, we construct the hierarchical structures from two public facial databases: Gavab and Texas3D. The searching speed based on the structure can be increased by 4-6 times without accuracy loss of recognition.
C1 [Lv, Chenlei; Wu, Zhongke; Wang, Xingce; Zhou, Mingquan] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
   [Lv, Chenlei; Wu, Zhongke; Wang, Xingce; Zhou, Mingquan] Beijing Normal Univ, Engn Res Ctr Virtual Real & Applicat, Minist Educ, Beijing Key Lab Digital Preservat & Virtual Real, Beijing 100875, Peoples R China.
C3 Beijing Normal University; Beijing Normal University
RP Wang, XC (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.; Wang, XC (corresponding author), Beijing Normal Univ, Engn Res Ctr Virtual Real & Applicat, Minist Educ, Beijing Key Lab Digital Preservat & Virtual Real, Beijing 100875, Peoples R China.
EM wangxingce@bnu.edu.cn
OI Chenlei, Lv/0000-0002-8203-3118
FU National Key Cooperation between the BRICS Program of China
   [2017YE0100500]; National Key R&D Program of China [2017YFB1002600,
   2017YFB1402105]; Beijing Natural Science Foundation of China [4172033]
FX This research was partially supported by the National Key Cooperation
   between the BRICS Program of China (No. 2017YE0100500), National Key R&D
   Program of China (No. 2017YFB1002600, No. 2017YFB1402105) and Beijing
   Natural Science Foundation of China (No. 4172033). We thank the face
   database (Gavab and Texas3D) and method's code provider in github. We
   also thank the provider of geodesic path tools (GeodesicLib;
   http://www.cs.technion.ac.il/vitus/papers/GeodesicLib.zip).
CR Ahdid R., 2015, J COMPUT SCI APPL, V3, P67
   Ahdid R, 2015, J ELECTRON COMMER OR, V13, P15, DOI [10.4018/jeco.2015070102, 10.4018/JECO.2015070102]
   [Anonymous], IEEE 2 INT C BIOM TH, DOI DOI 10.1109/BTAS.2008.4699378
   [Anonymous], 2001, J Appl Sci Eng, DOI DOI 10.6180/JASE.2001.4.3.05
   Antipov G, 2016, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2016.105
   Ballihi L, 2012, INT S COMM CONTR SIG, P1, DOI DOI 10.1109/ISCCSP.2012.6217828
   Berretti S, 2003, IEEE T MULTIMEDIA, V5, P52, DOI 10.1109/TMM.2002.802833
   Berretti S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168759
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Bronstein AM, 2007, IEEE T IMAGE PROCESS, V16, P188, DOI 10.1109/TIP.2006.884940
   Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Coates Adam, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P561, DOI 10.1007/978-3-642-35289-8_30
   Desbrun M, 2002, COMPUT GRAPH FORUM, V21, P209, DOI 10.1111/1467-8659.00580
   Drira H, 2010, IEEE INT C COMP VIS, V30, P2050
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Ghahari A., 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1314, DOI 10.1109/IIH-MSP.2009.38
   Gilani SZ, 2015, PROC CVPR IEEE, P4639, DOI 10.1109/CVPR.2015.7299095
   Jahanbin S, 2013, INT J COMPUT VISION, V105, P87, DOI 10.1007/s11263-013-0631-2
   Jermyn IH, 2012, LECT NOTES COMPUT SC, V7576, P804, DOI 10.1007/978-3-642-33715-4_58
   Kurtek S, 2015, COMPREHENSIVE STAT F, V51
   Li ZF, 2004, PROC CVPR IEEE, P374
   Liew SS, 2016, TURK J ELECTR ENG CO, V24, P1248, DOI 10.3906/elk-1311-58
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Luciano P, 2017, CELL DISCOV, V3, DOI 10.1038/celldisc.2017.40
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Masoumi M, 2017, J VIS COMMUN IMAGE R, V43, P198, DOI 10.1016/j.jvcir.2017.01.001
   Mühling M, 2017, MULTIMED TOOLS APPL, V76, P22169, DOI 10.1007/s11042-017-4962-9
   Otto C, 2016, IEEE T PATTERN ANAL, V40, P1
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pickup D, 2016, INT J COMPUT VISION, V120, P169, DOI 10.1007/s11263-016-0903-8
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Surazhsky V, 2005, ACM T GRAPHIC, V24, P553, DOI 10.1145/1073204.1073228
   Wu J, 2007, P BRIT MACH VIS C, DOI 10.5244/C.21.50
   Xia J., 2010, P 18 ACM INT C MULTI, P591, DOI DOI 10.1145/1873951.1874010
   Xia JZ, 2012, IEEE T CIRC SYST VID, V22, P77, DOI 10.1109/TCSVT.2011.2158337
   Yu D., 2017, MULTIMED TOOLS APPL, P1
   Zeng W., 2009, INT J CAD CAM, V9, P103
   Zeng W, 2011, IEEE CEWIT C CEWIT 1
   Zeng W, 2010, IEEE T PATTERN ANAL, V32, P662, DOI 10.1109/TPAMI.2009.201
NR 44
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14753
EP 14776
DI 10.1007/s11042-018-6839-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700028
DA 2024-07-18
ER

PT J
AU Le, N
   Odobez, JM
AF Nam Le
   Odobez, Jean-Marc
TI Improving speech embedding using crossmodal transfer learning with
   audio-visual data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker diariazation; Multimodal identification; Metric learning;
   Transfer learning; Deep learning
ID SPEAKER; FACE
AB Learning a discriminative voice embedding allows speaker turns to be compared directly and efficiently, which is crucial for tasks such as diarization and verification. This paper investigates several transfer learning approaches to improve a voice embedding using knowledge transferred from a face representation. The main idea of our crossmodal approaches is to constrain the target voice embedding space to share latent attributes with the source face embedding space. The shared latent attributes can be formalized as geometric properties or distribution characterics between these embedding spaces. We propose four transfer learning approaches belonging to two categories: the first category relies on the structure of the source face embedding space to regularize at different granularities the speaker turn embedding space. The second category -a domain adaptation approach- improves the embedding space of speaker turns by applying a maximum mean discrepancy loss to minimize the disparity between the distributions of the embedded features. Experiments are conducted on TV news datasets, REPERE and ETAPE, to demonstrate our methods. Quantitative results in verification and clustering tasks show promising improvement, especially in cases where speaker turns are short or the training data size is limited. The analysis also gives insights the embedding spaces and shows their potential applications.
C1 [Nam Le; Odobez, Jean-Marc] Idiap Res Inst, Martigny, Switzerland.
   [Nam Le] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
   [Odobez, Jean-Marc] Ecole Polytech Fed Lausanne, MER, Percept & Activ Understanding Grp, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Swiss Federal Institutes of Technology Domain;
   Ecole Polytechnique Federale de Lausanne
RP Le, N (corresponding author), Idiap Res Inst, Martigny, Switzerland.; Le, N (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
EM nle@idiap.ch; odobez@idiap.ch
RI Le, Nam/S-5950-2019; Odobez, Jean-Marc/B-1426-2010; ARSLAN,
   Okan/AAA-3232-2020
OI Le, Nam/0000-0002-6862-9257; Odobez, Jean-Marc/0000-0002-9537-9898
FU EU [FP7-611057, H2020-688147]
FX This work was supported by the EU projects EUMSSI - Event Understanding
   through Multimodal Social Stream Interpretation (FP7-611057) and MuMMER
   - MultiModal Mall Entertainment Robot (H2020-688147).
CR [Anonymous], 2012, P INT
   [Anonymous], LREC
   [Anonymous], 2016, ARXIV160306432
   [Anonymous], CVPR
   [Anonymous], 2016, ARXIV160200955
   [Anonymous], 2016, CVPR
   Baktashmotlagh M, 2016, J MACH LEARN RES, V17
   Barras C, 2006, IEEE T AUDIO SPEECH, V14, P1505, DOI 10.1109/TASL.2006.878261
   Bendris Meriem, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P494, DOI 10.1109/ICASSP.2014.6853645
   Bost X, 2014, 2014 IEEE SPOK LANG
   Bredin H, 2017, ICASSP
   Bredin Herve, 2016, ACM MULTIMEDIA, P157
   Chen S., 1998, P DARPA BROADC NEWS
   Clement P, 2011, ICASSP
   Dean J., 2015, NIPS DEEP LEARNING R
   Dey S, 2018, INTERSPEECH, P3598, DOI 10.21437/Interspeech.2018-2300
   Dubout C., 2013, BMVC
   Ganin Y., 2015, ICML
   Gay P., 2014, ICASSP
   Gravier G., 2012, LREC
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   He K, 2016, CVPR IEEE
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu D, 2016, ACM MULTIMEDIA
   Hu YT, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1107, DOI 10.1145/2733373.2806293
   Jousse V., 2009, ICASSP
   Le N, 2017, P 19 ACM INT C MULT, P411
   Le N, 2016, ICPR
   Le N, 2018, INTERSPEECH, P2257, DOI 10.21437/Interspeech.2018-1685
   Le N, 2017, IEEE INT CONF COMP V, P428, DOI 10.1109/ICCVW.2017.58
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li AN, 2011, PATTERN RECOGN LETT, V32, P1948, DOI 10.1016/j.patrec.2011.07.020
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1234, DOI 10.1109/TMM.2016.2646180
   Long M, 2010, ICDM
   Ma C., 2007, ICASSP
   Nagrani A, 2018, PROC CVPR IEEE, P8427, DOI 10.1109/CVPR.2018.00879
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Poignant J, 2015, IEEE-ACM T AUDIO SPE, V23, P57, DOI 10.1109/TASLP.2014.2367822
   Ren J, 2016, AAAI CONF ARTIF INTE, P3581
   Roy A, 2010, BTAS
   Sargent G, 2016, MED WORKSH
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Snyder D, 2017, INTERSPEECH, P999, DOI 10.21437/Interspeech.2017-620
   Steinwart Ingo, 2001, JMLR
   Tapaswi Makarand, 2014, ICVGIP
   Tieleman T., 2012, Technical report, V4, P26
   Yi Dong, 2014, ARXIV14117923
   Zheng YT, 2018, PROC CVPR IEEE, P5089, DOI 10.1109/CVPR.2018.00534
   Zhuang F., 2011, STAT ANAL DATA MIN, V4, P100, DOI DOI 10.1002/SAM.10099
NR 52
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15681
EP 15704
DI 10.1007/s11042-018-6992-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700068
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Dixit, R
   Naskar, R
AF Dixit, Rahul
   Naskar, Ruchira
TI Region duplication detection in digital images based on Centroid Linkage
   Clustering of key-points and graph similarity matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Centroid Linkage Clustering; Digital image forensics;
   Graph similarity matching; Maximally stable extremal region; Region
   duplication
ID COPY-MOVE FORGERY
AB Region duplication or copy-move forgery is an attack in which a region of an image is copied and pasted onto another location of the same image. In the recent state-of-the-art, a number of key-point based methods have been proposed for copy-move forgery detection in digital images. Though the problems of re-scaling and rotation in region duplication, have been sufficiently investigated using key-point based methods, post-processing based attacks such as flip, blur, brightness and noise, remain an open challenge in this field. In this paper, we address the problem of copy-move forgery detection in images, plus aim to identify copied regions, having undergone different geometric (such as rotation, re-scale), and post-processing attacks (such as Gaussian noise, blurring and brightness adjustment). In the proposed algorithm we introduce a region based key-point selection concept, which is considerably more discriminative than single SIFT key-point extraction. In this work, we apply Centroid Linkage Clustering, to identify duplicated regions in an image, from matched key-points. Also, we introduce a Graph Similarity Matching algorithm, to optimize false matches. Our experimental results demonstrate the efficiency of the proposed method in terms of forgery detection and localization efficiency, for a wide range of geometric and post-processing based attacks in region duplication.
C1 [Dixit, Rahul] Manipal Univ Jaipur, Dept Comp Commun & Engn, Jaipur, Rajasthan, India.
   [Naskar, Ruchira] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, India.
C3 Manipal University Jaipur; National Institute of Technology (NIT
   System); National Institute of Technology Rourkela
RP Dixit, R (corresponding author), Manipal Univ Jaipur, Dept Comp Commun & Engn, Jaipur, Rajasthan, India.
EM rahul2012ism@gmail.com; naskarr@nitrkl.ac.in
RI Dixit, Rahul/A-2826-2019
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2015, J INFORM HIDING MULT
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Baraldi A, 1996, IEEE T GEOSCI REMOTE, V34, P137, DOI 10.1109/36.481899
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   BLASHFIELD RK, 1976, PSYCHOL BULL, V83, P377, DOI 10.1037/0033-2909.83.3.377
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Caldelli R., 2012, 2012 5th International Symposium on Communications Control and Signal Processing, P1
   Coeurjolly D, 2004, IEEE T PATTERN ANAL, V26, P252, DOI 10.1109/TPAMI.2004.1262194
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Dimitriadou E, 2004, ARTIF INTELL MED, V31, P57, DOI 10.1016/j.artmed.2004.01.010
   Ding C, 2003, IEEE INT C DAT MIN I, P139
   Farid A. P., 2004, TECHNICAL REPORT
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Lakemond R, 2012, J MATH IMAGING VIS, V44, P150, DOI 10.1007/s10851-011-0317-8
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li JW, 2017, MULTIMED TOOLS APPL, V76, P20483, DOI 10.1007/s11042-016-3967-0
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Li Z., 2012, P AAAI C ART INT, P1026
   Li ZC, 2018, IEEE T NEUR NET LEAR, V29, P1947, DOI 10.1109/TNNLS.2017.2691725
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Manu VT, 2016, ADV INTELL SYST COMP, V425, P645, DOI 10.1007/978-3-319-28658-7_55
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Moravec Hans P., 1977, P INT JOINT C ART IN, P584
   Muhammad G., 2012, DIGITAL INVESTIGATIO
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   PUNJ G, 1983, J MARKETING RES, V20, P134, DOI 10.2307/3151680
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Ryu SJ, 2010, INT WORKSH INF HID, V6, P351
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Wu QM, 2011, IEEE SIGNAL PROC LET, V18, P559, DOI 10.1109/LSP.2011.2163507
   WU Z, 2009, PROC CVPR IEEE, V22, P25
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Yang J., 2013, J COMPUT INF SYST, V9, P6399
   Zhang J, 2008, 2008 11TH IEEE SINGAPORE INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS (ICCS), VOLS 1-3, P362, DOI 10.1109/ICCS.2008.4737205
   ZHENG J, 2014, J COMPUT INF SYST, V10, P1481, DOI DOI 10.12733/JCIS9302
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 49
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13819
EP 13840
DI 10.1007/s11042-018-6666-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900055
DA 2024-07-18
ER

PT J
AU Fang, LJ
   Zhao, X
   Zhang, SQ
AF Fang, Liangji
   Zhao, Xu
   Zhang, Shiquan
TI Small-objectness sensitive detection based on shifted single shot
   detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Shifted SSD; Smooth NMS; IoU prediction
AB We present a small object sensitive method for object detection. Our method is built based on SSD (Single Shot MultiBox Detector (Liu et al. 2016)), a simple but effective deep neural network for image object detection. The discrete nature of anchor mechanism used in SSD, however, may cause misdetection for the small objects located at gaps between the anchor boxes. SSD performs better for small object detection after circular shifts of the input image. Therefore, auxiliary feature maps are generated by conducting circular shifts over lower extra feature maps in SSD for small-object detection, which is equivalent to shifting the objects in order to fit the locations of anchor boxes. We call our proposed system Shifted SSD. Moreover, pinpoint accuracy of localization is of vital importance to small objects detection. Hence, two novel methods called Smooth NMS and IoU-Prediction module are proposed to obtain more precise locations. Then for video sequences, we generate trajectory hypothesis to obtain predicted locations in a new frame for further improved performance. Experiments conducted on PASCAL VOC 2007, along with MS COCO, KITTI and our small object video datasets, validate that both mAP and recall are improved with different degrees and the speed is almost the same as SSD.
C1 [Fang, Liangji; Zhao, Xu; Zhang, Shiquan] Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Zhao, X (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
EM fangliangji@sjtu.edu.cn; zhaoxu@sjtu.edu.cn; 15221529981@163.com
FU NSFC [61673269, 61273285]
FX This research is supported by NSFC funding (61673269, 61273285).
CR [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   [Anonymous], 2017, ARXIV170310295
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Everingham Mark, 2007, TECH REP
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Geiger A., 2012, CVPR
   Gidaris S, 2016, PROC CVPR IEEE, P789, DOI 10.1109/CVPR.2016.92
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W., 2015, ARXIV150604579
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Milan A., 2015, JOINT TRACKING SEGME
   Park S, ANAL DROPOUT EFFECT
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Xiang YJ, 2015, IEEE INT ULTRA SYM, DOI 10.1109/ULTSYM.2015.0258
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Yu F., 2015, ARXIV
   Yu J, 2017, IEEE T IND ELECT
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhou HJ, 2017, IEEE INT CONF COMP V, P760, DOI 10.1109/ICCVW.2017.95
NR 46
TC 9
Z9 12
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13227
EP 13245
DI 10.1007/s11042-018-6227-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900027
DA 2024-07-18
ER

PT J
AU Pandey, A
   Saini, BS
   Singh, B
   Sood, N
AF Pandey, Anukul
   Saini, Barjinder Singh
   Singh, Butta
   Sood, Neetu
TI Complexity sorting and coupled chaotic map based on 2D ECG data
   compression-then-encryption and its OFDM transmission with impair sample
   correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; ECG compression; ECG encryption; ECG transmission; Chaotic map;
   OFDM
ID IMAGE ENCRYPTION; WIRELESS ECG; ALGORITHM; SIGNALS; DECOMPOSITION;
   EQUALIZATION; SYSTEM
AB The present paper proposes a complexity sorting and coupled chaotic map mutation mechanism for compression-then-encryption of the Electrocardiogram (ECG) signals. The compressed-then-encrypted ECG is wirelessly transmitted using orthogonal frequency division multiplexing scheme modified to perform impair sample correction. The compression based on complexity sorting involves following steps: Beat Detection, 2D ECG array formation, Period Normalization, Dc Equalization, Complexity Sorting, Codec Quantization and JPEG2000 codec. The 2D compression results in reduced memory requirements for the clinical data storage. The coupled chaotic based on mutation mechanism for ECG encryption randomizes the ECG array to prevent the attackers from deducing the confidential information from it. The compressed-then-encrypted ECG bitstream is transmitted through the Rayleigh fading wireless channel. At the receiver end, the erroneous sample is corrected by moving median filtering (MMF) mechanism to reduce Percentage Root mean square Difference (PRD). The 2D compressed and the encrypted ECG remains diagnosable after reconstruction. The average compressor metrics Compression Ratio (CR), PRD, and Quality Score (QS) were 72.81 +/- 15.90, 2.57 +/- 1.68%, and 44.36 +/- 29.92 respectively on MIT-BIH Arrhythmia database. Furthermore, 2D compressed ECG is effectually encrypted as validated by the histogram analysis, Information Entropy(En), Entropy Score (ES), and the correlation coefficient analysis. The En, ES, and the correlation values were equal to 7.996, 0.999, and 0.0042 respectively for an 8-bit quantization resolution. Moreover, due to MMF approach at the particular Channel Signal to Noise Ratio (SNRc=15dB) & BER=10(-2), the PRD reduces from 45% (without erroneous sample correction) to 2.2% (with erroneous ECG sample correction).
C1 [Pandey, Anukul; Saini, Barjinder Singh; Sood, Neetu] Dr BR Ambedkar Natl Inst Technol, Dept Elect & Commun Engn, Jalandhar 144011, Punjab, India.
   [Pandey, Anukul] Dumka Engn Coll, Dept Elect & Commun Engn, Dumka 814101, India.
   [Singh, Butta] Guru Nanak Dev Univ, Dept Elect & Commun Engn, Reg Campus, Jalandhar 144007, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Guru Nanak Dev University
RP Pandey, A (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Elect & Commun Engn, Jalandhar 144011, Punjab, India.; Pandey, A (corresponding author), Dumka Engn Coll, Dept Elect & Commun Engn, Dumka 814101, India.
EM anukul66@gmail.com; sainibss@gmail.com; bsl.khanna@gmail.com;
   soodn@nitj.ac.in
RI Saini, Barjinder Singh/Y-2321-2019; Pandey, Anukul/AAB-2712-2021;
   Pandey, Anukul/Q-9577-2016; Sood, Neetu/X-8624-2019
OI Saini, Barjinder Singh/0000-0003-0932-6851; Pandey,
   Anukul/0000-0003-2737-112X; Sood, Neetu/0000-0001-7475-8672; Singh,
   Butta/0000-0002-0170-6270
CR Abo-Zahhad M, 2014, SIGNAL IMAGE VIDEO P, V8, P739, DOI 10.1007/s11760-013-0593-4
   Adamo A, 2015, BIOMED SIGNAL PROCES, V15, P11, DOI 10.1016/j.bspc.2014.09.002
   Al-Fahoum AS, 2006, IEEE T INF TECHNOL B, V10, P182, DOI 10.1109/TITB.2005.855554
   Alesanco A, 2010, IEEE T INF TECHNOL B, V14, P1144, DOI 10.1109/TITB.2010.2047650
   [Anonymous], 2014, Digital Communications
   Bai T, 2019, FUTURE GENER COMP SY, V92, P800, DOI 10.1016/j.future.2018.01.031
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Chen CK, 2012, INFORM SCIENCES, V193, P125, DOI 10.1016/j.ins.2012.01.016
   Chou HH, 2006, IEEE T BIO-MED ENG, V53, P1198, DOI 10.1109/TBME.2005.863961
   Dhar S, 2018, MEASUREMENT, V116, P533, DOI 10.1016/j.measurement.2017.11.006
   Eng M, 2013, ROBUST ECG BASED PER
   Engin M, 2005, MEASUREMENT, V37, P167, DOI 10.1016/j.measurement.2004.11.001
   Filho EBL, 2008, IEEE T BIO-MED ENG, V55, P1923, DOI 10.1109/TBME.2008.919880
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Guler Nihal Fatma, 2006, J Med Syst, V30, P231, DOI 10.1007/s10916-005-7980-5
   Gupta R, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0090-5
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Hejazi M, 2016, DIGIT SIGNAL PROCESS, V52, P72, DOI 10.1016/j.dsp.2016.02.008
   Hernández AI, 2001, IEEE T INF TECHNOL B, V5, P253, DOI 10.1109/4233.945297
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang BQ, 2013, BIOMED SIGNAL PROCES, V8, P59, DOI 10.1016/j.bspc.2012.04.003
   Ibaida A, 2014, FUTURE GENER COMP SY, V35, P91, DOI 10.1016/j.future.2013.12.025
   Istepanian RSH, 2000, IEEE T INF TECHNOL B, V4, P200, DOI 10.1109/4233.870030
   Khalaj A., 2009, 2009 Canadian Conference on Electrical and Computer Engineering (CCECE 2009), P983, DOI 10.1109/CCECE.2009.5090276
   Kim BS, 2006, IEEE T INF TECHNOL B, V10, P77, DOI 10.1109/TITB.2005.856854
   Kocarev L, 2001, PHYS LETT A, V289, P199, DOI 10.1016/S0375-9601(01)00609-0
   Kumar R, 2016, COMPUT METH PROG BIO, V129, P135, DOI 10.1016/j.cmpb.2016.01.006
   Kumar V, 2006, INT J SYST SCI, V37, P45, DOI 10.1080/00319100500412337
   Kumbasar V, 2012, DIGIT SIGNAL PROCESS, V22, P841, DOI 10.1016/j.dsp.2012.02.004
   Lee S, 2011, IEEE T BIO-MED ENG, V58, P2448, DOI 10.1109/TBME.2011.2156794
   Lin CT, 2010, IEEE T INF TECHNOL B, V14, P726, DOI 10.1109/TITB.2010.2047401
   Liu TY, 2018, IEEE J BIOMED HEALTH, V22, P707, DOI 10.1109/JBHI.2017.2698498
   Ma JL, 2015, IEEE J BIOMED HEALTH, V19, P986, DOI 10.1109/JBHI.2014.2357841
   Mahmoud SS, 2012, DIGIT SIGNAL PROCESS, V22, P114, DOI 10.1016/j.dsp.2011.09.007
   Manikandan AS, 2007, BIOMED SIGNAL PROCES, V2, P80, DOI 10.1016/j.bspc.2007.05.001
   Michel-Macarty JA, 2018, COMPUT METH PROG BIO, V162, P165, DOI 10.1016/j.cmpb.2018.05.021
   Mukhopadhyay SK, 2013, BIOMED SIGNAL PROCES, V8, P354, DOI 10.1016/j.bspc.2013.02.007
   Murillo-Escobar MA, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0698-3
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   PANDEY A, 2016, COMPUT TOOLS TECH BI, V2, P1
   Pandey A, 2016, AUSTRALAS PHYS ENG S, V39, P833, DOI 10.1007/s13246-016-0476-4
   Pandey A, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0830-4
   Pandey A, 2016, COMPUT ELECTR ENG, V56, P30, DOI 10.1016/j.compeleceng.2016.10.012
   Pandya UT, 2012, IEEE T BIO-MED ENG, V59, P3148, DOI 10.1109/TBME.2012.2217494
   Pavlopoulos S, 1998, IEEE Trans Inf Technol Biomed, V2, P261, DOI 10.1109/4233.737581
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Prasad R, 2000, OFDM WIRELESS COMMUN
   Raeiatibanadkooki M, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0433-5
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Sharma LN, 2012, IEEE T INF TECHNOL B, V16, P730, DOI 10.1109/TITB.2012.2195322
   Sidek KA, 2014, J NETW COMPUT APPL, V44, P83, DOI 10.1016/j.jnca.2014.04.008
   Singh B, 2012, INT J SYST SCI, V43, P884, DOI 10.1080/00207721.2010.543478
   Sufi F, 2011, SECUR COMMUN NETW, V4, P515, DOI 10.1002/sec.226
   Sufi F, 2008, SECUR COMMUN NETW, V1, P389, DOI 10.1002/sec.44
   Venkatesan C, 2018, MULTIMED TOOLS APPL, V77, P10365, DOI 10.1007/s11042-018-5762-6
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 59
TC 7
Z9 8
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11223
EP 11261
DI 10.1007/s11042-018-6681-2
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900007
DA 2024-07-18
ER

PT J
AU Sasikaladevi, N
   Geetha, K
   Sriharshini, K
   Aruna, MD
AF Sasikaladevi, N.
   Geetha, K.
   Sriharshini, K.
   Aruna, M. Durga
TI RADIANT - hybrid multilayered chaotic image encryption system for color
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic curve cryptography; DNA encoding; Encryption; Decryption;
   Logistic map
ID FRACTIONAL FOURIER-TRANSFORM; ELLIPTIC CURVE; DNA; SCHEME; PERMUTATION;
   SECURE; WAVELET; MAP
AB Rapid growth in the use of digitized images in commercial, business, government and medical use has led to the need for protecting the images against eavesdroppers and securely transmit them in the network. Images pertained to finance, medical and crime investigation fields are expected to be confidential because of its sensitivity. As reported in the literature most of encryption algorithms developed for gray images is only applied for color images. An exclusive system to exploit color spaces has been proposed that functions in a multilayered model. It is named as HybRid multilAyereD chaotic ImAge eNcrypTion (RADIANT) system to process sensitive color images especially applicable for medical and forensic domains. In the first layer, logistic mapping is done to perform chaotic masking, followed by DNA encoding in the second layer. This layer objective is to increase confusion diffusion level by substitution permutation. In the third layer, ECC over GF(p) that focus on spatial domain is adopted for encryption as it has been identified as a prominent encryption technique being popular for its mathematical strength. The proposed RADIANT system is hybrid in nature as it operates on both symmetric and asymmetric cryptosystem combination. Experimental results obtained by testing with bench mark images ascertain an ideal measure for MSE, PSNR that makes it more suitable for signal processing activities involving sensitive color images.
C1 [Sasikaladevi, N.; Geetha, K.; Sriharshini, K.; Aruna, M. Durga] SASTRA Univ, Dept CSE SoC, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sasikaladevi, N (corresponding author), SASTRA Univ, Dept CSE SoC, Thanjavur, India.
EM sasikalade@gmail.com
RI , Sasikaladevi/AAF-7847-2019; KRISHNAN, GEETHA/IUO-9520-2023
OI KRISHNAN, GEETHA/0000-0002-8546-2719; , Sasikaladevi
   N/0000-0002-0841-502X
FU Department of Science and Technology (DST), Science and Engineering
   Board (SERB), Government of India under the ECR grant
   [ECR/2017/000679/ES]
FX The part of this research work is supported by Department of Science and
   Technology (DST), Science and Engineering Board (SERB), Government of
   India under the ECR grant (ECR/2017/000679/ES)
CR Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   Abdul-Aziz Gutub Adnan, 2013, IADIS INT C APPL COM
   Al-Otaibi Nouf A., 2014, P 2014 INT C ADV ENG
   Alassaf N., 2003, ARABIA
   [Anonymous], [No title captured]
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Gehani A, 2004, LECT NOTES COMPUT SC, V2950, P167
   Gutub AA-A., 2010, INT J SECUR, V4, P46
   Gutub AAA, 2007, KUWAIT J SCI ENG, V34, P165
   Gutub AAA, 2011, KUWAIT J SCI ENG, V38, P125
   Halvorsen K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044212
   Head T, 2000, BIOSYSTEMS, V57, P87, DOI 10.1016/S0303-2647(00)00091-5
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Lang J, 2015, OPT COMMUN, V338, P181, DOI 10.1016/j.optcom.2014.10.049
   Lang J, 2012, OPT EXPRESS, V20, P2386, DOI 10.1364/OE.20.002386
   Li L, 2012, SIGNAL PROCESS, V92, P1069, DOI 10.1016/j.sigpro.2011.10.020
   Lima JB, 2014, SIGNAL PROCESS, V94, P521, DOI 10.1016/j.sigpro.2013.07.020
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu S, 2013, OPT COMMUN, V287, P73, DOI 10.1016/j.optcom.2012.09.033
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Mishra DC, 2014, FRACTALS, V22, DOI 10.1142/S0218348X1450011X
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Ning K., 2009, COMPUTING RES REPOSI, DOI DOI 10.1016/J.COMPELECENG.2012.02.007
   Niu YJ, 2011, COMMUN NONLINEAR SCI, V16, P1986, DOI 10.1016/j.cnsns.2010.08.015
   Pan SM, 2017, MULTIMED TOOLS APPL, V76, P2933, DOI 10.1007/s11042-015-3209-x
   Radhika KR, 2017, REC ADV EL COMM TECH
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P472, DOI 10.1016/j.procs.2015.06.054
   Sui LS, 2014, OPT LASER ENG, V62, P139, DOI 10.1016/j.optlaseng.2014.06.003
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Xia T, 2017, APPL COMPUTING INFOR
   Zhang Q, 2013, IETE TECH REV, V30, P404, DOI 10.4103/0256-4602.123123
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zheng XD, 2009, APPL MATH COMPUT, V212, P177, DOI 10.1016/j.amc.2009.02.011
NR 47
TC 9
Z9 9
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11675
EP 11700
DI 10.1007/s11042-018-6711-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900026
DA 2024-07-18
ER

PT J
AU Wang, YT
   Huang, L
   Ren, TW
   Zhong, SH
   Gu, H
   Liu, Y
AF Wang, Yuantian
   Huang, Lei
   Ren, Tongwei
   Zhong, Sheng-Hua
   Gu, Han
   Liu, Yan
TI Insights of object proposal evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object proposal evaluation; Objectness measurement ability; Hit
   probability of random sampling
ID IMAGE; RECOGNITION; MODEL
AB Object proposal aims to locate category-independent objects in a given image with a limited number of object candidates indicated by bounding boxes, which can be served as a fundamental of various multimedia applications. Current evaluation criteria based on recall cannot reveal the real abilities of different object proposal methods in objectness measurement. In this paper, we propose a novel object proposal evaluation criterion instead of recall, named objectness measurement ability (OMA). We first analyze the probability to hit an object by non-repetitive random sampling (HPRS), and provide an algorithm for calculating HPRS efficiently. Based on HPRS, we define OMA and extend three commonly used object proposal evaluation criteria by replacing recall with OMA. We evaluated six typical object proposal methods using recall based criteria and OMA based criteria on the test data of PASCAL VOC 2007 and PASCAL VOC 2012. The experimental results show that OMA based criteria can provide more stable evaluation results than recall based ones in revealing objectness measurement ability.
C1 [Wang, Yuantian; Huang, Lei; Ren, Tongwei; Gu, Han] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
   [Zhong, Sheng-Hua] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Liu, Yan] Hong Kong Polytech Univ, Comp Dept, Hong Kong, Peoples R China.
C3 Nanjing University; Shenzhen University; Hong Kong Polytechnic
   University
RP Ren, TW (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM wangyt@smail.nju.edu.cn; leihuang@nju.edu.cn; rentw@nju.edu.cn;
   csshzhong@szu.edu.cn; 141250039@smail.nju.edu.cn;
   csyliu@comp.polyu.edu.hk
RI liu, yan/HGV-1365-2022; HUANG, LING/HTR-1819-2023; huang,
   lei/GQP-8739-2022
FU National Science Foundation of China [61321491, 61202320]; Undergraduate
   Innovation Project of Nanjing University [X201610284039]; Collaborative
   Innovation Center of Novel Software Technology and Industrialization
FX This work is supported by National Science Foundation of China
   (61321491, 61202320), Undergraduate Innovation Project of Nanjing
   University (X201610284039), and Collaborative Innovation Center of Novel
   Software Technology and Industrialization.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2010, P 18 ACM INT C MULT
   [Anonymous], ACM MULTIMEDIA
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Bai JF, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853823
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chavali N, 2015, COMP SCI
   Chen XZ, 2015, PROC CVPR IEEE, P2587, DOI 10.1109/CVPR.2015.7298874
   Chen XP, 2009, 2009 IEEE 8TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P529, DOI 10.1109/ASICON.2009.5351635
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao Z, 2016, NEUROCOMPUTING, V215, P138, DOI 10.1016/j.neucom.2016.01.113
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Guo JF, 2019, MULTIMEDIA SYST, V25, P35, DOI 10.1007/s00530-017-0546-9
   Hosang J., 2015, IEEE T PATTERN ANAL, V6, P6644
   Jiang F, 2016, NEUROCOMPUTING, V175, P146, DOI 10.1016/j.neucom.2015.10.044
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu J, 2017, NEUROCOMPUTING, V236, P134, DOI 10.1016/j.neucom.2016.09.111
   Liu J, 2014, IEEE T MULTIMEDIA, V16, P588, DOI 10.1109/TMM.2014.2302732
   Liu J, 2016, IEEE INT CONF COMM, P98, DOI 10.1109/ICCW.2016.7503771
   Liu Y, 2013, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR.2013.270
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Rahman ASMM, 2011, ICIMCS, P103
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Ren TW, 2015, MULTIMEDIA SYST, V21, P189, DOI 10.1007/s00530-014-0384-y
   Sang JT, 2013, IEEE T MULTIMEDIA, V15, P1665, DOI 10.1109/TMM.2013.2268052
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P963, DOI 10.1109/TMM.2011.2181344
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P586, DOI 10.1109/TMM.2012.2188784
   Song XN, 2016, MULTIMEDIA SYST, V22, P41, DOI 10.1007/s00530-014-0390-0
   Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang P, 2016, MMM
   Zhang KH, 2015, IEEE T CYBERNETICS, V45, P1426, DOI 10.1109/TCYB.2014.2352343
   Zhu SB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION PROBLEM-SOLVING (ICCP), P1, DOI [10.1109/PVSC.2015.7355773, 10.1109/ICCPS.2015.7454074]
   Zhu YY, 2016, NEUROCOMPUTING, V187, P83, DOI 10.1016/j.neucom.2015.09.114
   Zitnick C.L., 2014, Edge boxes: Locating object proposals from edges
NR 40
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13111
EP 13130
DI 10.1007/s11042-017-5471-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900021
DA 2024-07-18
ER

PT J
AU Xie, XL
   Xie, G
   Xu, XY
   Cui, L
AF Xie, Xinlin
   Xie, Gang
   Xu, Xinying
   Cui, Lei
TI Adaptive high-precision superpixel segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixel; Image segmentation; Adaptivity; Isolated pixels;
   Under-segmentation
AB Superpixel as a fundamental processing unit can significantly reduce the computational complexity of subsequent computer vision tasks. In this paper, an Adaptive High-Precision (AHP) superpixel segmentation algorithm is proposed. Three major schemes are proposed in this algorithm. First, a scheme of generating the initial number of superpixels adaptively is proposed by calculating the histogram peak value of L-component corresponding to the smallest salient region. In addition, we show that the isolated pixels are not only existent but also abundant. Instead of using distance-measurement of color and position space, we reclassify each isolated pixel just relying on the LAB color space. Furthermore, the detection and re-segmentation scheme of the under-segmentation superpixels is adopted according to the standard deviation and mean value of the L-component, which can re-segment each under-segmentation superpixel directly without measuring the distance between each under-segmentation pixel and new centroid. The proposed algorithm has linear computational complexity and the merits of adaptivity and high precision. Experiments on the Berkeley segmentation dataset demonstrate the effectiveness and feasibility of the proposed schemes, and they also prove AHP can achieve high-precision superpixel segmentation results in comparison with the state-of-the-art algorithms on standard metrics.
C1 [Xie, Xinlin; Xie, Gang; Xu, Xinying; Cui, Lei] Taiyuan Univ Technol, Coll Informat Engn, Taiyuan, Shanxi, Peoples R China.
   [Xie, Gang] Taiyuan Univ Sci & Technol, Coll Elect Informat Engn, Taiyuan, Shanxi, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University of Science &
   Technology
RP Xie, G (corresponding author), Taiyuan Univ Technol, Coll Informat Engn, Taiyuan, Shanxi, Peoples R China.; Xie, G (corresponding author), Taiyuan Univ Sci & Technol, Coll Elect Informat Engn, Taiyuan, Shanxi, Peoples R China.
EM xiexinlin.tyut@qq.com; xiegang@tyut.edu.cn; xuxinying@tyut.edu.cn;
   alencui@outlook.com
RI Li, Zexi/KFA-6939-2024
OI Xie, Gang/0000-0001-5769-0565
FU National Natural Science Foundation of China [61503271]; Shanxi
   Scholarship Council of China [2016-044]
FX This work was supported by the National Natural Science Foundation of
   China (61503271) and the Shanxi Scholarship Council of China (2016-044).
CR Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2009, IEEE I CONF COMP VIS, DOI 10.1109/ICCV.2009.5459175
   [Anonymous], 2008, 2008 IEEE C COMP VIS
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Ban ZH, 2018, IEEE T IMAGE PROCESS, V27, P4105, DOI 10.1109/TIP.2018.2836306
   Cheng J, 2013, IEEE T MED IMAGING, V32, P1019, DOI 10.1109/TMI.2013.2247770
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li L, 2013, PROC CVPR IEEE, P3174, DOI 10.1109/CVPR.2013.408
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Liu B, 2013, IEEE T GEOSCI REMOTE, V51, P907, DOI 10.1109/TGRS.2012.2203358
   Liu FY, 2015, PATTERN RECOGN, V48, P2983, DOI 10.1016/j.patcog.2015.04.019
   Liu Y, 2013, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR.2013.270
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Papon J, 2013, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2013.264
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   VANDENB M, 2012, LECT NOTES COMPUT SC, P13
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P1241, DOI 10.1109/TPAMI.2012.47
   Wang MR, 2017, SIGNAL PROCESS-IMAGE, V56, P28, DOI 10.1016/j.image.2017.04.007
   Wang P, 2013, INT J COMPUT VISION, V103, P1, DOI 10.1007/s11263-012-0588-6
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Zhang YH, 2011, IEEE I CONF COMP VIS, P1387, DOI 10.1109/ICCV.2011.6126393
NR 31
TC 5
Z9 5
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12353
EP 12371
DI 10.1007/s11042-018-6774-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900057
DA 2024-07-18
ER

PT J
AU Vilas, AF
   Redondo, RPD
   Crockett, K
   Owda, M
   Evans, L
AF Fernandez Vilas, Ana
   Diaz Redondo, Rebeca P.
   Crockett, Keeley
   Owda, Majdi
   Evans, Lewis
TI Twitter permeability to financial events: an experiment towards a model
   for sensing irregularities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter data analysis; Stock market; Irregularity behaviour; London
   stock exchange
ID STOCK-MARKET; MICROBLOGGING DATA; INFORMATION; PREDICTION; NEWS
AB There is a general consensus of the good sensing and novelty characteristics of Twitter as an information media for the complex financial market. This paper investigates the permeability of Twittersphere, the total universe of Twitter users and their habits, towards relevant events in the financial market. Analysis shows that a general purpose social media is permeable to financial-specific events and establishes Twitter as a relevant feeder for taking decisions regarding the financial market and event fraudulent activities in that market. However, the provenance of contributions, their different levels of credibility and quality and even the purpose or intention behind them should to be considered and carefully contemplated if Twitter is used as a single source for decision taking. With the overall aim of this research, to deploy an architecture for real-time monitoring of irregularities in the financial market, this paper conducts a series of experiments on the level of permeability and the permeable features of Twitter in the event of one of these irregularities. To be precise, Twitter data is collected concerning an event comprising of a specific financial action on the 27th January 2017: the announcement about the merge of two companies Tesco PLC and Booker Group PLC, listed in the main market of the London Stock Exchange (LSE), to create the UK's Leading Food Business. The experiment attempts to answer two research questions which aim to characterize the features of Twitter permeability to the financial market. The experimental results confirm that a far-impacting financial event, such as the merger considered, caused apparent disturbances in all the features considered, that is, information volume, content and sentiment as well as geographical provenance. Analysis shows that although Twitter is not a specific financial forum, it is permeable to financial events. Therefore it should be considered within the architecture for real-time monitoring of irregularities in the financial market.
C1 [Fernandez Vilas, Ana; Diaz Redondo, Rebeca P.] Univ Vigo, I&C Lab, AtlantTIC Res Ctr, Vigo 36310, Spain.
   [Crockett, Keeley; Owda, Majdi; Evans, Lewis] Manchester Metropolitan Univ, Sch Comp Math & Digital Technol, Manchester M1 5GD, Lancs, England.
C3 Universidade de Vigo; atlanTTic; Manchester Metropolitan University
RP Vilas, AF (corresponding author), Univ Vigo, I&C Lab, AtlantTIC Res Ctr, Vigo 36310, Spain.
EM avilas@det.uvigo.es; rebeca@det.uvigo.es; k.crockett@mmu.ac.uk;
   m.owda@mmu.ac.uk; L.Evans@mmu.ac.uk
RI Vilas, Ana Fernández/L-2055-2014; Díaz Redondo, Rebeca P./L-3108-2014;
   Owda, Majdi/ADV-6815-2022
OI Vilas, Ana Fernández/0000-0003-1047-2143; Díaz Redondo, Rebeca
   P./0000-0002-2367-2219; Owda, Majdi/0000-0002-7393-2381
FU Spanish Ministry of Education Culture and Sports, National Plan for
   Scientific and Technical Research and Innovation (Sub-Programme for
   Mobility) [PRIX16/00368]; Manchester Metropolitan University (School of
   Computing Mathematics and Digital Technology); Spanish Ministry of
   Economy and Competitiveness under the National Science Program
   [TEC2014-54335-C4-3-R, TEC2017-84197-C4-2-R]
FX This work was funded by Spanish Ministry of Education Culture and
   Sports, National Plan for Scientific and Technical Research and
   Innovation (Sub-Programme for Mobility) under the research stay grant
   PRIX16/00368. We thank the Manchester Metropolitan University (School of
   Computing Mathematics and Digital Technology) for its support during the
   research stay. This work is also partially funded by the Spanish
   Ministry of Economy and Competitiveness under the National Science
   Program (TEC2014-54335-C4-3-R, TEC2017-84197-C4-2-R).
CR Adnan M, 2014, GEO-SPAT INF SCI, V17, P145, DOI 10.1080/10095020.2014.941316
   Agarwal S, 2017, ANNU REV FINANC ECON, V9, P127, DOI 10.1146/annurev-financial-110716-032417
   Al Nasseri A, 2014, LECT NOTES ARTIF INT, V8777, P13, DOI 10.1007/978-3-319-11812-3_2
   Alonso O., 2014, First Monday, V19
   [Anonymous], 2014, SECONDARY TEXTBLOB S
   [Anonymous], 2018, P SAI INT SYST C
   [Anonymous], 2011, J COMPUT SCI-NETH, DOI DOI 10.1016/j.jocs.2010.12.007
   Antweiler W, 2004, J FINANC, V59, P1259, DOI 10.1111/j.1540-6261.2004.00662.x
   Azar P, 2016, WISDOM TWITTER CROWD, DOI [10.2139/ssrn.2756815, DOI 10.2139/SSRN.2756815]
   Billett MT, 2016, J FINANC QUANT ANAL, V51, P1165, DOI 10.1017/S0022109016000612
   Bordino I, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040014
   Bormetti G, 2015, QUANT FINANC, V15, P1137, DOI 10.1080/14697688.2014.996586
   Campbell J, 2011, INFORM MANAGE-AMSTER, V48, P37, DOI 10.1016/j.im.2010.12.003
   Cavalcante RC, 2016, EXPERT SYST APPL, V55, P194, DOI 10.1016/j.eswa.2016.02.006
   Cazzoli L, 2016, 2016 THIRD EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2016), P98, DOI [10.1109/ENIC.2016.21, 10.1109/ENIC.2016.022]
   Ceccarelli D, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P527, DOI 10.1145/2911451.2926727
   Cortez P., 2016, WIMS 16 P 6 INT C WE
   De Choudhury M, 2011, 2011 IEEE 3 INT C IE
   Delort JY, 2012, INT J BANKING FINAN, V8, P19
   Dickinson B., 2015, Social Networking, V4, P62
   Ding Xiao., 2015, Deep learning for event-driven stock prediction
   Dredze M, 2016, P 2 INT WORKSH DAT S
   Elliott W.B., 2017, Investor Reaction To $ Firm Or # CEO Use Of Social Media For Negative Disclosures
   Feng X., 2015, Journal Of Developing Areas, V49, P421
   Fernandez-Vilas A, 2017, EXPT ANAL IMPACT FIN, P407
   Gunduz H, 2015, EXPERT SYST APPL, V42, P9001, DOI 10.1016/j.eswa.2015.07.058
   Hobijn B, 2001, AM ECON REV, V91, P1203, DOI 10.1257/aer.91.5.1203
   Hu T, 2016, IMPACT SOCIAL MEDIA, DOI [10.2139/ssrn.2964054, DOI 10.2139/SSRN.2964054]
   Karppi T, 2016, THEOR CULT SOC, V33, P73, DOI 10.1177/0263276415583139
   LI Q, 2012, MULTIMED TOOLS APPL, V345, P10, DOI DOI 10.1007/S11042-016-3643-4
   Liew J.K.S, 2016, DO TWEET SENTIMENTS
   Liu H., 2016, INT J DATA SCI ANAL, V1, P137, DOI [10.1007/s41060-016-0023-0, DOI 10.1007/S41060-016-0023-0]
   Liu L, 2015, EXPERT SYST APPL, V42, P3893, DOI 10.1016/j.eswa.2014.12.049
   Miller GS, 2015, J ACCOUNT RES, V53, P221, DOI 10.1111/1475-679X.12075
   Morstatter F., 2013, P 7 INT AAAI C WEBL
   Nassirtoussi AK, 2015, EXPERT SYST APPL, V42, P306, DOI 10.1016/j.eswa.2014.08.004
   Oliveira N, 2017, EXPERT SYST APPL, V73, P125, DOI 10.1016/j.eswa.2016.12.036
   Oliveira N, 2016, DECIS SUPPORT SYST, V85, P62, DOI 10.1016/j.dss.2016.02.013
   Owda M, 2017, INT SYST C 2017
   Ozyer T., 2014, State of the art applications of social network analysis, P227
   Pagolu Venkata Sasank, 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P1345, DOI 10.1109/SCOPES.2016.7955659
   Rajesh N, 2016, INT CONF INTELL SYS
   Ranco G, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146576
   Ranco G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138441
   Domínguez DR, 2017, EXPERT SYST APPL, V78, P319, DOI 10.1016/j.eswa.2017.02.018
   Ruiz E.J., 2012, P 5 ACM INT C WEB SE, P513, DOI DOI 10.1145/2124295.2124358
   Sabherwal S, 2011, J BUS FINAN ACCOUNT, V38, P1209, DOI 10.1111/j.1468-5957.2011.02258.x
   Servia-Rodriguez S, 2015, INT C SOC COMP BEH C
   Shutes K, 2016, EC BUS REV, V2, P57
   Sprenger TO, 2014, EUR FINANC MANAG, V20, P926, DOI 10.1111/j.1468-036X.2013.12007.x
   Tafti A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159226
   Nguyen TH, 2015, EXPERT SYST APPL, V42, P9603, DOI 10.1016/j.eswa.2015.07.052
   Välja M, 2016, PORTL INT CONF MANAG, P14
   Vosoughi S., 2015, Automatic Detection and Verification of Rumors on Twitter
   Wang BH, 2012, NEUROCOMPUTING, V83, P136, DOI 10.1016/j.neucom.2011.12.013
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Xiong F., 2016, C FIN MARKS CORP GOV
   Zhang L, 2013, THESIS U TEXAS
   Zheludev I, 2014, SCI REP-UK, V4, DOI 10.1038/srep04213
NR 59
TC 11
Z9 11
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9217
EP 9245
DI 10.1007/s11042-018-6388-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800071
OA hybrid
DA 2024-07-18
ER

PT J
AU Idris, WMRW
   Rafi, A
   Bidin, A
   Jamal, AA
   Fadzli, SA
AF Idris, Wan Mohd Rizhan Wan
   Rafi, Ahmad
   Bidin, Azman
   Jamal, Azrul Amri
   Fadzli, Syed Abdullah
TI A systematic survey of martial art using motion capture technologies:
   the importance of extrinsic feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion capture; Martial arts; System development; Extrinsic feedback
ID TAI-CHI; RETRIEVAL; GAIT
AB The number of research papers on Motion Capture technologies published in conferences and journals has been rapidly increasing due to the emerging of new technologies, software and hardware which create new challenges and opportunities for Martial Arts research. Current trend of the Martial Arts using Motion Capture technologies (MAMoCap) researches consists of phases of MoCap-Processing and Post-MoCap-Processing; contexts of algorithms, performance and system development; and feedbacks of intrinsic and extrinsic. The purpose of this paper is to study and explore the potential future trend of research and publications pertaining to MAMoCap researches. A systematic survey of research publications was conducted through the topic of Martial Art (MA) and Motion Capture (MoCap) in order to retrieve the scientific articles published in FOUR (4) established publishers including SPRINGERLINK, SCIENCEDIRECT, IEEE and ACM. Search refinements were done by the inclusions criteria of document types of academic journals and conference proceedings; and by the exceptions criteria of letters, editorials and book reviews. The findings show that only 27% of the publications have been selected while other 73% have been classified as irrelevant contents due to none significance and relevance to the MAMoCap researches. Analysis on the research phases, contexts and feedbacks has been conducted and discussed in detailed for pertaining knowledge gaps and future research agenda. Based on the preliminary study, a framework of EFs-Based Automated Evaluation System for the martial arts should be proposed.
C1 [Idris, Wan Mohd Rizhan Wan; Rafi, Ahmad; Bidin, Azman] Multimedia Univ, Fac Creat Multimedia, Cyberjaya Campus, Cyberjaya 63000, Selangor, Malaysia.
   [Idris, Wan Mohd Rizhan Wan; Jamal, Azrul Amri; Fadzli, Syed Abdullah] Univ Sultan Zainal Abidin, Fac Informat & Comp, Besut Campus, Besut 22200, Terengganu, Malaysia.
C3 Multimedia University; Universiti Sultan Zainal Abidin
RP Idris, WMRW (corresponding author), Multimedia Univ, Fac Creat Multimedia, Cyberjaya Campus, Cyberjaya 63000, Selangor, Malaysia.; Idris, WMRW (corresponding author), Univ Sultan Zainal Abidin, Fac Informat & Comp, Besut Campus, Besut 22200, Terengganu, Malaysia.
EM wmrizhan@unisza.edu.my
RI Bidin, Azman/AAF-5196-2019; WAN IDRIS, WAN MOHD RIZHAN/IUM-9372-2023;
   Jamal, Azrul Amri/JAD-1193-2023
OI WAN IDRIS, WAN MOHD RIZHAN/0000-0002-1098-4416; Jamal, Azrul
   Amri/0000-0002-9969-3120; Bidin, Azman/0000-0002-6913-2090
FU Ministry of Higher Education (MoHE); Universiti Sultan Zainal Abidin
   (UniSZA) through RAGS [RAGS/1/2015/ICT04/UNISZA/03/1]
FX The authors gratefully acknowledge the Ministry of Higher Education
   (MoHE) and Universiti Sultan Zainal Abidin (UniSZA) for the financial
   support through RAGS Project No. RAGS/1/2015/ICT04/UNISZA/03/1. Thanks
   to Multimedia University (MMU) for providing facilities and technical
   assistance for this research.
CR Abualkibash M, 2009, 2 INT C COMP SCI ITS, P1
   Baker JF, 2010, KNEE SURG SPORT TR A, V18, P115, DOI 10.1007/s00167-009-0877-y
   Bandouch J, 2012, INT J COMPUT VISION, V99, P166, DOI 10.1007/s11263-012-0522-y
   Benitezsantiago AS, 2011, THESIS
   Bing Sun, 2012, Proceedings of the 2012 International Symposium on Information Technology in Medicine and Education (ITME 2012), P26, DOI 10.1109/ITiME.2012.6291239
   Chao SP, 2004, 24TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P254
   Chen J, 2013, TRIALS, V14, DOI 10.1186/1745-6215-14-361
   Chen XL, 2010, LECT NOTES COMPUT SC, V6459, P422
   Chiu C-Y, 2003, INT C MULT EXP ICME
   Chiu CY, 2006, J VIS COMMUN IMAGE R, V17, P892, DOI 10.1016/j.jvcir.2005.01.002
   Chiu CY, 2004, J VIS COMMUN IMAGE R, V15, P446, DOI 10.1016/j.jvcir.2004.04.004
   Choi C-H, 2015, MULTIMED TOOLS APPL, P1
   Choi W, 2008, 2008 19 INT C PATT R
   Chye C, 2014, APPL SERVICES
   Cynarski WJ, 2014, IDO MOV CULT, V14, P39, DOI 10.14589/ido.14.1.4
   Draxler T, 2011, J PUBLIC HEALTH-HEID, V19, P57, DOI 10.1007/s10389-010-0343-9
   Endres D, 2016, BAYESIAN APPROACHES
   Endres D, 2011, LECT NOTES ARTIF INT, V7006, P75, DOI 10.1007/978-3-642-24455-1_7
   Endres D, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010326
   Fernandes F.M., 2011, J MORPHOL SCI, V28, P141
   Flagg Matthew, 2009, P 2009 S INTERACTIVE, P199
   Hachaj T, 2013, COMPUTER KARATE TRAI
   Hai Yu, 2013, Journal of Theoretical and Applied Information Technology, V48, P1458
   Hass CJ, 2004, ARCH PHYS MED REHAB, V85, P1593, DOI 10.1016/j.apmr.2004.01.020
   Hegarini E, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTING (ICIC), P389, DOI 10.1109/IAC.2016.7905750
   Ilg W, 2003, PATTERN RECOGNITION
   Ilg W, 2002, BIOL MOTIVATED COMPU
   Ismail AM, 2002, PENERAPAN JATI DIRI
   Iwaanaguchi T, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P365, DOI 10.1109/CW.2015.13
   Kolykhalova K, 2015, PROCEEDINGS OF THE 2015 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES FOR INTERACTIVE ENTERTAINMENT, P74, DOI 10.4108/icst.intetain.2015.260039
   Komura T, 2006, LECT NOTES COMPUTER, V4181
   Kovavisaruch L., 2011, 2011 Proceedings of PICMET '11: Technology Management in the Energy Smart World (PICMET), P1
   Lee W, 2010, INT J CONTROL AUTOM, V8, P1072, DOI 10.1007/s12555-010-0516-x
   Li Y, 2012, P INT C INF ENG APPL
   Liang XB, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 1, PROCEEDINGS, P247, DOI 10.1109/IITA.2009.72
   Liu Y, 2014, COMPUTER VISION MACH
   Majoe D., 2009, SIGMAP 2009 P INT C, P13
   Mariconda M, 2014, KNEE SURG SPORT TR A, V22, P874, DOI 10.1007/s00167-014-2850-7
   McPherson M, 2010, BMC PUBLIC HEALTH, V10, DOI 10.1186/1471-2458-10-795
   Menache A, 2011, UNDERSTANDING MOTION CAPTURE FOR COMPUTER ANIMATION, 2ND EDITION, P1
   Mezger J., 2005, P 2 S APPL PERCEPTIO, V95, P25, DOI DOI 10.1145/1080402.1080406
   Morel M, 2017, IMAGE VISION COMPUT, V64, P67, DOI 10.1016/j.imavis.2017.05.008
   Mustapha G, 2014, P INT C SPORTS EX EN, P3
   Mustapha G, 2015, ARCH BUDO, V11
   Petri K, 2017, P 11 INT S COMP SCI, P124
   Ramachandran AK, 2007, GAIT POSTURE, V26, P248, DOI 10.1016/j.gaitpost.2006.09.005
   Saponara S, 2017, IEEE T INSTRUM MEAS, V66, P2545, DOI 10.1109/TIM.2017.2677679
   Tanaka Y, 2014, IEEE INT C INT ROBOT, P2187, DOI 10.1109/IROS.2014.6942857
   Torres EB, 2011, EXP BRAIN RES, V215
   Ruiz AT, 2014, IFMBE PROC, V49, P285, DOI 10.1007/978-3-319-13117-7_74
   Wan BJ, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2067-y
   Wenbai Chen, 2011, Proceedings of the 2011 International Conference on Computer Science and Network Technology (ICCSNT), P1128, DOI 10.1109/ICCSNT.2011.6182159
   Wu MY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P315, DOI 10.1109/ICME.2004.1394189
   Ye GZ, 2012, LECT NOTES COMPUT SC, V7573, P828, DOI 10.1007/978-3-642-33709-3_59
   Zago M, 2015, J ELECTROMYOGR KINES, V25, P894, DOI 10.1016/j.jelekin.2015.10.002
   Zhang S, 2006, INTERACT TECHNOL SOC
   Zhang WC, 2017, IMAGE VISION COMPUT, V61, P22, DOI 10.1016/j.imavis.2017.02.002
NR 57
TC 11
Z9 11
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10113
EP 10140
DI 10.1007/s11042-018-6624-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400029
OA Bronze
DA 2024-07-18
ER

PT J
AU Kastner, MA
   Ide, I
   Kawanishi, Y
   Hirayama, T
   Deguchi, D
   Murase, H
AF Kastner, Marc A.
   Ide, Ichiro
   Kawanishi, Yasutomo
   Hirayama, Takatsugu
   Deguchi, Daisuke
   Murase, Hiroshi
TI Estimating the visual variety of concepts by referring to Web popularity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual variety; Language and vision; Concept semantics; Semantic gap
AB Increasingly sophisticated methods for data processing demand knowledge on the semantic relationship between language and vision. New fields of research like Explainable AI demand to step away from black-boxed approaches and understanding how the underlying semantics of data sets and AI models work. Advancements in Psycholinguistics suggest, that there is a relationship from language perception to how language production and sentence creation work. In this paper, a method to measure the visual variety of concepts is proposed to quantify the semantic gap between vision and language. For this, an image corpus is recomposed using ImageNet and Web data. Web-based metrics for measuring the popularity of sub-concepts are used as a weighting to ensure that the image composition in a dataset is as natural as possible. Using clustering methods, a score describing the visual variety of each concept is determined. A crowd-sourced survey is conducted to create ground-truth values applicable for this research. The evaluations show that the recomposed image corpus largely improves the measured variety compared to previous datasets. The results are promising and give additional knowledge about the relationship of language and vision.
C1 [Kastner, Marc A.; Ide, Ichiro; Kawanishi, Yasutomo; Murase, Hiroshi] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Hirayama, Takatsugu] Nagoya Univ, Inst Innovat Future Soc, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Deguchi, Daisuke] Nagoya Univ, Informat Strategy Off, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
C3 Nagoya University; Nagoya University; Nagoya University
RP Kastner, MA (corresponding author), Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM kastnerm@murase.is.i.nagoya-u.ac.jp; ide@i.nagoya-u.ac.jp;
   kawanishi@i.nagoya-u.ac.jp; takatsugu.hirayama@nagoya-u.jp;
   ddeguchi@nagoya-u.jp; murase@i.nagoya-u.ac.jp
RI Ide, Ichiro/M-4863-2014; Kawanishi, Yasutomo/AAF-9529-2019
OI Ide, Ichiro/0000-0003-3942-9296; Kawanishi,
   Yasutomo/0000-0002-3799-4550; Deguchi, Daisuke/0000-0003-0603-8790;
   Kastner, Marc/0000-0002-9193-5973
FU Ministry of Education, Culture, Sports, Science and Technology; NII,
   Japan
FX Parts of this research were supported by the Ministry of Education,
   Culture, Sports, Science and Technology, Grant-in-Aid for Scientific
   Research, and a joint research project with NII, Japan.
CR [Anonymous], 2017, Merriam-Webster online dictionary
   [Anonymous], MULTIMEDIA MODELING
   [Anonymous], FLICKR
   [Anonymous], ARXIV171206657 COMP
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], ARXIV170808296 COMP
   [Anonymous], ARXIV171209923 COMP
   [Anonymous], GOOGL CUST SEARCH AP
   [Anonymous], MICR AZ BING SEARCH
   [Anonymous], 2015, Open Source Computer Vision Library
   [Anonymous], CHOIX INFERENCE ALGO
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Davis Mark, 2008, The Corpus of Contemporary American English (COCA)
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Hentschel Christian, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P95, DOI 10.1007/978-3-319-14445-0_9
   Inoue Nakamasa., 2016, ACM on Multimedia Conference, P277
   Kawakubo H., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P330, DOI 10.1109/ISM.2010.57
   Kennedy L.S., 2006, Proc. ACM Multimedia Information Retrieval, P249, DOI DOI 10.1145/1178677.1178712
   Kilgarriff A., 2014, LEXICOGRAPHY, V1, P7, DOI [10.1007/s40607-014-0009-9, DOI 10.1007/S40607-014-0009-9]
   Li JJ, 2015, AAAI CONF ARTIF INTE, P2281
   Loper E, 2002, ETMTNLP 02 P ACL 02, P63, DOI [10.3115/1225403.1225421, DOI 10.3115/1225403.1225421, DOI 10.3115/1118108.1118117]
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nakamura K, 2015, LECT NOTES COMPUT SC, V9010, P56, DOI 10.1007/978-3-319-16634-6_5
   PAIVIO A, 1968, J EXP PSYCHOL, V76, P1, DOI 10.1037/h0025327
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Smolík F, 2015, FIRST LANG, V35, P446, DOI 10.1177/0142723715609228
   Spearman C., 2008, Spearman Rank Correlation Coefficient, P502, DOI [DOI 10.1007/978-0-387-32833-1_379, 10.1007/978-0-387-32833-1_379]
   Thurstone LL, 1926, J ABNORM SOC PSYCH, V21, P384
   Van Leuken Reinier H, 2009, P 18 INT C WORLD WID, P341, DOI 10.1145/1526709.1526756
   Yanai K., 2005, 13th Annual ACM International Conference on Multimedia, P419, DOI 10.1145/1101149.1101241
NR 35
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9463
EP 9488
DI 10.1007/s11042-018-6528-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800081
DA 2024-07-18
ER

PT J
AU Li, L
   Zhang, WM
   Chen, KJ
   Zha, HY
   Yu, NH
AF Li, Li
   Zhang, Weiming
   Chen, Kejiang
   Zha, Hongyue
   Yu, Nenghai
TI Side Channel Steganalysis: When Behavior is Considered in Steganographer
   Detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganographer Detection; Side Channel; Behavior; Steganalysis; Social
   Network
AB This paper intents to solve the challenging problem of steganographer detection in the real world from a new perspective: side channel attack. We propose utilizing the behavior of actors in the social network to identify the steganographer. While there are many behavior information may expose the steganographer, we just consider the correlation between images sequence as an example in this paper. Base on the assumption that the steganographer choosing images for communication randomly, we design the feature of subtractive images adjacent model (SIAM) to represent the correlations between images sequence of each actor. And then a binary classifier is used to identify the steganographer. To simulate the real world, the images in the experiment are all crawled from twitter. The experimental result shows good performance of our method.
C1 [Li, Li; Zhang, Weiming; Chen, Kejiang; Zha, Hongyue; Yu, Nenghai] Univ Sci & Technol China, Key Lab Electromagnet Space Informat, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Key Lab Electromagnet Space Informat, Hefei 230026, Anhui, Peoples R China.
EM zhangwm@ustc.edu.cn
RI Chen, Kejiang/ABD-7057-2020
OI Zhang, Weiming/0000-0001-5576-6108; Chen, Kejiang/0000-0002-9868-3414
FU Natural Science Foundation of China [U1636201, 6157245]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1636201, 6157245.
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2007, P 9 WORKSH MULT SEC
   Chen M, 2017, JPEG PHASE AWARE CON
   Cogranne R, 2017, AC SPEECH SIGN PROC
   Denemark T, 2014, INF FOR SEC WIFS 201
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Ker AD, 2011, MED FOR SEC
   Ker AD, 2012, P MULT SEC
   Ker AD, 2006, INF HID
   Ker AD, 2014, IEEE T INF FOREN SEC, V9, P1424, DOI 10.1109/TIFS.2014.2336380
   Li F, 2017, ADV MATER SCI ENG, V2017, DOI 10.1155/2017/4502904
   Li FY, 2016, IEEE T INF FOREN SEC, V11, P344, DOI 10.1109/TIFS.2015.2496910
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Russell, 2013, MINING SOCIAL WEB DA
   Tan S, 2014, AS PAC SIGN INF PROC
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Zhao Z, 2016, INT WORKSH DIG WAT
   Zheng M., 2017, MULT EXP ICME 2017 I
NR 18
TC 3
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8041
EP 8055
DI 10.1007/s11042-018-6582-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800009
DA 2024-07-18
ER

PT J
AU Liu, H
   Guo, Q
   Wang, GL
   Gupta, BB
   Zhang, CM
AF Liu, Hui
   Guo, Qiang
   Wang, Guangli
   Gupta, B. B.
   Zhang, Caiming
TI Medical image resolution enhancement for healthcare using nonlocal
   self-similarity and low-rank prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resolution enhancement; Low rank approximation; Minimum variance
   estimation; Nonlocal self-similarity; Healthcare
ID INTERPOLATION; SUPERRESOLUTION; ALGORITHM
AB Medical images have high information redundancy, which can be used to improve image analysis and visualization for purpose of healthcare. In order to recover a high-resolution (HR) image from its low-resolution (LR) counterpart, this paper proposes a resolution enhancement method by using the nonlocal self-similar redundancy and the low-rank prior. The proposed method consists of three main steps. First, an initial HR image is generated by nonlocal interpolation, which is based on the self-similarity of medical images. Next, the low-rank minimum variance estimator is exploited to reconstruct the HR image. At last, we iteratively apply the subsampling consistency constraint and perform the low-rank reconstruction to refine the reconstructed HR result. Experimental results conducted on MR and CT images demonstrate that the proposed method outperforms conventional interpolation methods and is competitive with the current stat-of-the-art methods in terms of both quantitative metrics and visual quality.
C1 [Liu, Hui; Guo, Qiang] Shandong Univ Finance & Econ, Dept Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Liu, Hui; Guo, Qiang; Zhang, Caiming] Shandong Prov Key Lab Digital Media Technol, Jinan, Shandong, Peoples R China.
   [Wang, Guangli] Shandong Prov Qianfoshan Hosp, Dept Radiol, Jinan, Shandong, Peoples R China.
   [Gupta, B. B.] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
   [Zhang, Caiming] Shandong Univ, Dept Comp Sci & Technol, Jinan, Shandong, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong First Medical
   University & Shandong Academy of Medical Sciences; National Institute of
   Technology (NIT System); National Institute of Technology Kurukshetra;
   Shandong University
RP Liu, H (corresponding author), Shandong Univ Finance & Econ, Dept Comp Sci & Technol, Jinan, Shandong, Peoples R China.; Liu, H (corresponding author), Shandong Prov Key Lab Digital Media Technol, Jinan, Shandong, Peoples R China.
EM liuh_lh@126.com
RI Wang, Guang/JFS-8374-2023; Cheng, Lin/KFQ-3111-2024; Guo,
   Qiang/I-2949-2019; Gupta, Brij B/E-9813-2011
OI Guo, Qiang/0000-0003-4219-3528; Gupta, Brij B/0000-0003-4929-4698
FU National Natural Science Foundation [61572286, 61332015, 61472220];
   Shandong Provincial Key Research and Development Plan [2017CXGC1504];
   Natural Science Foundation of Shandong Province [2016ZRB01143];
   Fostering Project of Dominant Discipline an Talent Team of Shandong
   Province Higher Education
FX This work is partially supported by National Natural Science Foundation
   (61572286, 61332015, and 61472220), Shandong Provincial Key Research and
   Development Plan (2017CXGC1504), Natural Science Foundation of Shandong
   Province (2016ZRB01143), and Fostering Project of Dominant Discipline an
   Talent Team of Shandong Province Higher Education. The authors also
   gratefully acknowledge the helpful comments and suggestions of the
   anonymous reviewers, which have improved the presentation significantly.
CR Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Baudes A., 2005, MULTISCALE MODEL SIM, V4, P490, DOI DOI 10.1137/040616024
   Cai JF, 2013, METHODS APPL ANAL, V20, P335, DOI 10.4310/MAA.2013.v20.n4.a2
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Cao FL, 2015, IEEE T CIRC SYST VID, V25, P1261, DOI 10.1109/TCSVT.2014.2372351
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   DONG W, 1994, TIP, V22, P1382, DOI DOI 10.1109/TIP.2012.2231086
   Dong WS, 2009, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2009.5414423
   Guo Q, 2017, IEEE T VISUALIZATION
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   Guo Qiang, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P2237
   Guo Q, 2014, SCIENCEASIA, V40, P168, DOI 10.2306/scienceasia1513-1874.2014.40.168
   Hardie R, 2007, IEEE T IMAGE PROCESS, V16, P2953, DOI 10.1109/TIP.2007.909416
   He KM, 2012, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.2012.6247665
   Hossain MS, 2016, IEEE ACCESS, V4, P7806, DOI 10.1109/ACCESS.2016.2626316
   Hossain MS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0627-x
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Hung KW, 2012, INT CONF ACOUST SPEE, P1269, DOI 10.1109/ICASSP.2012.6288120
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   Jafari-Khouzani K, 2014, IEEE T MED IMAGING, V33, P1969, DOI 10.1109/TMI.2014.2329271
   Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421
   Kwan RKS, 1999, IEEE T MED IMAGING, V18, P1085, DOI 10.1109/42.816072
   Larsen RM, 1998, DAIMI REP, V27, DOI [10.7146/dpb.v27i537.7070, DOI 10.7146/DPB.V27I537.7070]
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Li P, 2018, CLUSTER COMPUT, V21, P277, DOI 10.1007/s10586-017-0849-9
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu H, 2017, SOFT COMPUTER
   Manjón JV, 2010, INT J BIOMED IMAGING, V2010, DOI 10.1155/2010/425891
   Manjón JV, 2010, MED IMAGE ANAL, V14, P784, DOI 10.1016/j.media.2010.05.010
   Ning Q, 2013, IEEE SIGNAL PROC LET, V20, P399, DOI 10.1109/LSP.2013.2242198
   Olshansky SJ, 2016, COMPUTER, V49, P14, DOI 10.1109/MC.2016.336
   Pan ZX, 2013, IEEE T GEOSCI REMOTE, V51, P4864, DOI 10.1109/TGRS.2012.2230270
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   REN C, 2016, TIP, V25, P2168, DOI DOI 10.1109/TIP.2016.2542442
   Schaeffer H, 2013, SIAM J IMAGING SCI, V6, P226, DOI 10.1137/110854989
   Shi F, 2015, IEEE T MED IMAGING, V34, P2459, DOI 10.1109/TMI.2015.2437894
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   TRINH DH, 1995, TIP, V23, P1882, DOI DOI 10.1109/TIP.2014.2308422
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MC, 2013, IEEE T MULTIMEDIA, V15, P498, DOI 10.1109/TMM.2012.2232646
   Yap PT, 2014, NEUROIMAGE, V84, P939, DOI 10.1016/j.neuroimage.2013.09.016
   ZHANG K, 1956, TIP, V21, P4544, DOI DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang Y., 2013, MED PHYS, V40, P4, DOI DOI 10.1118/1.4825097
   Zhang Y, 2012, IEEE T MED IMAGING, V31, P1993, DOI 10.1109/TMI.2012.2202245
NR 51
TC 25
Z9 25
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9033
EP 9050
DI 10.1007/s11042-017-5277-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800063
DA 2024-07-18
ER

PT J
AU Rajagopalan, S
   Sharma, S
   Arumugham, S
   Upadhyay, HN
   Rayappan, JBB
   Amirtharajan, R
AF Rajagopalan, Sundararaman
   Sharma, Shriramana
   Arumugham, Sridevi
   Upadhyay, Har Narayan
   Rayappan, John Bosco Balaguru
   Amirtharajan, Rengarajan
TI YRBS coding with logistic map - a novel Sanskrit aphorism and chaos for
   image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; YRBS coding; Logistic map
ID DNA; ALGORITHM; CRYPTANALYSIS; OPERATION; SYSTEM
AB The role of image encryption in secure communication of confidential images is quite significant and novel schemes to encrypt images always have a demand in the scientific research community. DNA coding has found a noteworthy position in various earlier proposed image encryption schemes because of its simple but effective diffusion capabilities. Similar to the DNA coding, novel coding technique based on an aphorism present in the Sanskrit literature has been utilized in this image encryption work. The utility of Sanskrit s<umacron>tra yamtrjabhnasalagam (YRBS)' for performing scrambling, substitution and cyclic bit shifting promises the usage of this scheme as a part of various image encryption solutions. In this approach, YRBS coding has been employed along with simple one dimensional logistic map for encrypting 256x256 grayscale test images. The suggested scheme possesses a keyspace of 4.3769x10(46) and average correlation figures of -0.00021, -0.00021, -0.00015 in horizontal, vertical and diagonal directions respectively when applied on ten test images. The encrypted pixels passed the NIST Test suite and this approach also offers a good resistance to chosen cipher text attack which was a challenge in DNA coding.
C1 [Rajagopalan, Sundararaman; Arumugham, Sridevi; Upadhyay, Har Narayan; Rayappan, John Bosco Balaguru; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
   [Sharma, Shriramana] Shri Kanchi Shankara Mutt, Nerur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Rajagopalan, S (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM raman@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011; Rayappan, John Bosco
   Balaguru/K-6842-2013
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Sundararaman,
   Rajagopalan/0000-0003-3505-3260; Upadhyay, Har
   Narayan/0000-0002-1219-9649; Rayappan, John Bosco
   Balaguru/0000-0003-4641-9870
FU SASTRA University [R&M / 0026 / SEEE - 010 / 2012 - 13]
FX The authors wish to thank SASTRA University for providing infrastructure
   through the Research & Modernization Fund (Ref.No: R&M / 0026 / SEEE -
   010 / 2012 - 13) to carry out the research work.
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   [Anonymous], 1966, KEDARAS VRTTARATNAKA
   [Anonymous], 2008, ASTADHYAYISUTRAPATHA
   Barry RandallK., 1997, ALA LC ROMANIZATION
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Bhandarkar RG, 1883, 1 BOOK SANSKRIT
   Bodha Shruta, 1906, SHRUTA BODHA
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   Dou YQ, 2017, OPTIK, V145, P456, DOI 10.1016/j.ijleo.2017.08.050
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   JANSEN CJA, 1991, IEEE T INFORM THEORY, V37, P1475, DOI 10.1109/18.133272
   Kak S., 2000, INDIAN J HIST SCI, V35, P123
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Rajagopalan S, 2018, MICROPROCESS MICROSY, V61, P257, DOI 10.1016/j.micpro.2018.06.011
   Rajagopalan S, 2018, MULTIMED TOOLS APPL, V77, P23449, DOI 10.1007/s11042-017-5566-0
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Sharma D, 1972, TRANSLITERATION ROMA
   Stein S, 1969, MATH MAN MADE UNIVER, P144
   Stein S, 1961, SCI AM           MAY, P149
   Volos CK, 2013, SIGNAL PROCESS, V93, P1328, DOI 10.1016/j.sigpro.2012.11.008
   Wang L., 1986, IEEE International Conference on Computer-Aided Design: ICCAD-86. A Conference for the EE CAD Professional. Digest of Technical Papers (Cat. No.86CH2353-1), P56
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Weber A, 1973, UEBER METRIK INDER F
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Xu M, 2018, OPTIK, V171, P891, DOI 10.1016/j.ijleo.2018.06.112
   Xu M, 2017, OPTIK, V134, P45, DOI 10.1016/j.ijleo.2017.01.029
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YS, 2014, INFORM SCIENCES, V289, P254, DOI 10.1016/j.ins.2014.08.005
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 41
TC 15
Z9 15
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10513
EP 10541
DI 10.1007/s11042-018-6574-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400044
DA 2024-07-18
ER

PT J
AU Zhao, YH
   Zheng, N
   Qiao, T
   Xu, M
AF Zhao, Yihua
   Zheng, Ning
   Qiao, Tong
   Xu, Ming
TI Source camera identification via low dimensional PRNU features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image origin identification; Sensor pattern noise; Photo-response
   non-uniformity (PRNU); Weight function
ID MODEL
AB Identifying the source of digital images is the key task in the community of image forensics. Sensor pattern noise dominantly serves as an intrinsic fingerprint or feature for dealing with the problem of source camera identification. However, how to decrease the dimensionality of the pattern noise while guaranteeing the detection power remains a hot topic. The goal of this paper is to investigate the problem of source camera identification for natural images in JPEG format. By considering the image texture, we propose to design a new classifier with adopting a weight function, leading to the remarkable reduction of the feature dimensionality. In the extensive experiments, it is verified that our proposed algorithm performs comparably with the prior art. Besides, the robustness of the proposed classifier is also evaluated when the query images are attacked by post-processing techniques such as JPEG compression, noise adding, noise removing and image cropping.
C1 [Zhao, Yihua; Zheng, Ning] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Zheng, Ning; Qiao, Tong; Xu, Ming] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Zhejiang, Peoples R China.
   [Qiao, Tong] Zhengzhou Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University; PLA Information
   Engineering University
RP Qiao, T (corresponding author), Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Zhejiang, Peoples R China.; Qiao, T (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM tong.qiao@hdu.edu.cn
FU Cyberspace Security Major Program in National Key Research and
   Development Plan of China [2016YFB0800201]; Natural Science Foundation
   of China [61702150, 61572165]; State Key Program of Zhejiang Province
   Natural Science Foundation of China [LZ15F020003]; Key Research and
   Development Plan Project of Zhejiang Province [2017C01062, 2017C01065]
FX This work is funded by the Cyberspace Security Major Program in National
   Key Research and Development Plan of China under grant No.
   2016YFB0800201, the Natural Science Foundation of China under grant No.
   61702150 and No. 61572165, the State Key Program of Zhejiang Province
   Natural Science Foundation of China under grant No. LZ15F020003, the Key
   Research and Development Plan Project of Zhejiang Province under grant
   No. 2017C01062 and No.2017C01065.
CR [Anonymous], 2010, J DIGITAL FORENSIC P
   [Anonymous], 2009, MEDIA FORENSICS SECU
   [Anonymous], 2018, IEEE T CIRCUITS SYST
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Costa FD, 2014, PATTERN RECOGN LETT, V39, P92, DOI 10.1016/j.patrec.2013.09.006
   Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399
   Goljan M, 2013, PROC SPIE, V8665, DOI 10.1117/12.2003234
   Goljan M, 2010, PROC SPIE, V7541, DOI 10.1117/12.838378
   Goljan M, 2009, LECT NOTES COMPUT SC, V5450, P454, DOI 10.1007/978-3-642-04438-0_38
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Holst G.C., 1998, CCD ARRAYS CAMERAS D
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Hu YJ, 2015, MULTIMED TOOLS APPL, V74, P7405, DOI 10.1007/s11042-014-1985-3
   Janesick J. R., 2001, SCI CHARGE COUPLED D, V83
   Kay S. M., 1998, SIGNAL PROCESSING
   Li RZ, 2018, PATTERN RECOGN, V74, P556, DOI 10.1016/j.patcog.2017.09.027
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Nakamura J., 2017, Image Sensors and Signal Processing for Digital Still Cameras
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   QIAO T, 2013, 2013 PROCEEDINGS OF, V21, P1
   Qiao T, 2018, MULTIMED TOOLS APPL, V77, P1501, DOI 10.1007/s11042-016-4314-1
   Qiao T, 2017, SIGNAL PROCESS-IMAGE, V52, P74, DOI 10.1016/j.image.2016.12.011
   Qiao T, 2015, IEEE IMAGE PROC, P3812, DOI 10.1109/ICIP.2015.7351518
   Qiao T, 2015, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0019-7
   Ramanath R, 2005, IEEE SIGNAL PROC MAG, V22, P34, DOI 10.1109/MSP.2005.1407713
   Thai TH, 2016, DIGIT SIGNAL PROCESS, V48, P285, DOI 10.1016/j.dsp.2015.10.002
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P250, DOI 10.1109/TIP.2013.2290596
   Xu BC, 2016, NEUROCOMPUTING, V207, P131, DOI 10.1016/j.neucom.2016.05.012
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 31
TC 15
Z9 16
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8247
EP 8269
DI 10.1007/s11042-018-6809-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800021
DA 2024-07-18
ER

PT J
AU Zhong, SP
   Jia, CM
   Chen, KZ
   Dai, P
AF Zhong, Shangping
   Jia, Cunmin
   Chen, Kaizhi
   Dai, Peng
TI A novel steganalysis method with deep learning for different texture
   complexity images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Deep learning; Texture complexity; Ensemble learning
ID STEGANOGRAPHY; PERFORMANCE
AB Most steganalysis methods based on deep learning don't distinguish the image texture complexity, but rather to mix all images for training. As a result, the differences of image content between images with different texture complexities are larger than the differences caused by steganographic signal, which is unfavourable for extracting the effective stegananalysis features. In order to reduce the influence of image content difference on steganalysis performance, this paper propose a steganalyais framework adopting the method of training model separately on dividing data sets. Firstly, according to the image texture feature, some correlated statistical features of gray level co-occurrence matrix are used as a measure index of texture complexity, and the data set is divided into several subsets of different complexity according to the index. Secondly, for images with different texture complexities, the corresponding steganalysis models are constructed and trained by using Most Effective Region (MER) and Inception ideas, respectively. For an image to be detected, its texture complexity is calculated first and the corresponding model is used for detection. Finally, an ensemble learning method is used to further improve the framework precision. The experimental results show that our proposed steganalysis method outperforms the handcrafted-features-based steganalysis methods and several CNN-based methods in detection accuracy.
C1 [Zhong, Shangping; Jia, Cunmin; Chen, Kaizhi; Dai, Peng] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
   [Zhong, Shangping; Jia, Cunmin; Chen, Kaizhi; Dai, Peng] Fuzhou Univ, Univ Key Lab Informat Secur Network Syst, Fuzhou 350116, Fujian, Peoples R China.
C3 Fuzhou University; Fuzhou University
RP Zhong, SP (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.; Zhong, SP (corresponding author), Fuzhou Univ, Univ Key Lab Informat Secur Network Syst, Fuzhou 350116, Fujian, Peoples R China.
EM spzhong@fzu.edu.cn; N160320072@fzu.edu.cn; ckz@fzu.edu.cn;
   fz_daipeng@163.com
CR Amirkhani H, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3554413
   [Anonymous], 2017, P 3 INT C CLOUD COMP
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], INFORM SEC COMMUN PR
   [Anonymous], SPIE MED WATERMARK S
   [Anonymous], INT J ADV TRENDS COM
   [Anonymous], 2016, ELECT IMAGING
   [Anonymous], ACTA AUTOMAT SIN
   Cho SG, 2013, J VIS COMMUN IMAGE R, V24, P846, DOI 10.1016/j.jvcir.2013.05.007
   Deng Guo, 2012, Computer Engineering, V38, P116, DOI 10.3969/j.issn.1000-3428.2012.14.034
   Dixit Anuja, 2017, International Journal of Image, Graphics and Signal Processing, V9, P56, DOI 10.5815/ijigsp.2017.04.07
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2007, PROC SPIE, V6505, DOI 10.1117/12.697471
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu DH, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/2314860
   Juarez-Sandoval O, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P478, DOI 10.1109/TSP.2016.7760925
   Liu QZ, 2008, PATTERN RECOGN, V41, P56, DOI 10.1016/j.patcog.2007.06.005
   Liu XY, 2019, IEEE T CYBERNETICS, V49, P2398, DOI 10.1109/TCYB.2018.2821119
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma Y, 2019, IEEE T CONTR SYST T, V27, P1788, DOI 10.1109/TCST.2018.2819965
   Mao Jia-Fa, 2010, Chinese Journal of Computers, V33, P569, DOI 10.3724/SP.J.1016.2010.00569
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Wang Lina, 2017, Journal of Wuhan University (Natural Science Edition), V63, P421, DOI 10.14188/j.1671-8836.2017.05.006
   Wang R, 2015, MULTIMED TOOLS APPL, V74, P5725, DOI 10.1007/s11042-014-1880-y
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Wu ST, 2017, IEEE INT CON MULTI, P241, DOI 10.1109/ICME.2017.8019304
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 35
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8017
EP 8039
DI 10.1007/s11042-018-6573-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800008
DA 2024-07-18
ER

PT J
AU Ding, XL
   Li, Y
   Xia, M
   He, J
   Yang, GB
AF Ding, Xiangling
   Li, Yue
   Xia, Ming
   He, Jiale
   Yang, Gaobo
TI Detection of motion compensated frame interpolation via motion-aligned
   temporal difference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Motion compensated frame interpolation; Motion-aligned;
   One-class SVM
ID RATE UP-CONVERSION; SEARCH ALGORITHM
AB Motion compensated frame interpolation (MCFI) is a special frame based video manipulation, which increases the temporal continuity of low frame rate videos by synthesizing new frames between successive frames. MCFI might also be used to counterfeit high frame-rate videos, which mislead users' attraction and waste storage spaces in video-sharing websites. Existing MCFI detectors are designed to judge the absence or presence of MCFI forgery in a controllable environment of known MCFI techniques. Practical detector should consider the possibility of unknown MCFI techniques. We are motivated to propose a robust MCFI detector for more practical scenarios. Considering the effects of non-motion regions in candidate frame, the statistical moments are firstly extracted from motion-aligned frame differences (MAFD). Then, the one-class support vector machine (SVM), following a training stage capturing the properties of original frames, is exploited to judge whether the candidate frame is interpolated by MCFI or not. Finally, a special interpolated frame detection (SIFD) is designed to pick out interpolated frames, which are synthesized from two consecutive reference frames with no motion vectors (MVs) or less MVs. A series of experiments evaluated on four representative MCFI techniques have shown promising results.
C1 [Ding, Xiangling; Li, Yue; Xia, Ming; He, Jiale; Yang, Gaobo] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Ding, Xiangling] Jishou Univ, Sch Informat Sci & Engn, Jishou 416000, Hunan, Peoples R China.
C3 Hunan University; Jishou University
RP Yang, GB (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM yanggaobo@hnu.edu.cn
RI xiangling, Ding/T-7175-2019
OI Yang, Gaobo/0000-0003-2734-659X; ding, xiangling/0000-0002-6581-4633
FU National Natural Science Foundation of China [61572183, 61379143]
FX The authors appreciate Dr. Ran Li in Xinyang Normal University, China
   for permission to use their codes in theirs experiments. They appreciate
   Dr. Won Hee Lee in Korea Advanced Institute of Science and Technology,
   Korea for providing up-converted videos in the experiments. They also
   appreciate Dr Ningbo Zhu in Hunan University, China for providing
   technical editing of the revised manuscript. This work is supported in
   part by the National Natural Science Foundation of China (61572183,
   61379143).
CR Bestagini P, 2013, INT CONF ACOUST SPEE, P3033, DOI 10.1109/ICASSP.2013.6638215
   Bian S, 2014, MULTIMED TOOLS APPL, V72, P437, DOI 10.1007/s11042-013-1364-5
   Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chen RC, 2014, FORENSIC SCI INT, V236, P164, DOI 10.1016/j.forsciint.2013.12.022
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Conotter V, 2012, IEEE T INF FOREN SEC, V7, P283, DOI 10.1109/TIFS.2011.2165843
   Dar Yehuda, 2015, IEEE Trans Image Process, V24, P2051, DOI 10.1109/TIP.2015.2412378
   Ding X, 2018, IEEE T CIRC SYST VID, V28, P1497, DOI 10.1109/TCSVT.2017.2676162
   Kang SJ, 2012, J DISP TECHNOL, V8, P121, DOI 10.1109/JDT.2011.2167740
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Lee WH, 2014, IEEE T IMAGE PROCESS, V23, P399, DOI 10.1109/TIP.2013.2288139
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li R, 2018, MULTIMED TOOLS APPL, V77, P663, DOI 10.1007/s11042-016-4268-3
   Li R, 2014, J DISP TECHNOL, V10, P1010, DOI 10.1109/JDT.2014.2334598
   LI Z, 2017, TKDE, V29, P2100, DOI DOI 10.1109/TKDE.2017.2728531
   Liu HB, 2012, IEEE T CIRC SYST VID, V22, P1188, DOI 10.1109/TCSVT.2012.2197081
   Liu YQ, 2017, MULTIMEDIA SYST, V23, P223, DOI [10.1007/s00530-015-0478-1, 10.1007/s00530-015-0461-x]
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Rijsbergen C. J. V., 1979, Information Retrieval
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Vapnik V., 1963, AUTOMAT REM CONTR, V24, P774, DOI DOI 10.12691/JGG-2-3-9
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Xia M., 2016, MULTIMED TOOLS APPL, V72, P1
   YAO Y, 2016, JOURNAL OF INFORMATI, V26, P39, DOI DOI 10.1016/j.jisa.2015.12.001
   Yoo DG, 2013, J DISP TECHNOL, V9, P840, DOI 10.1109/JDT.2013.2263374
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zhang J., 2009, INT J GRAPHICS VISIO, V9, P1
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 39
TC 5
Z9 6
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7453
EP 7477
DI 10.1007/s11042-018-6504-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700046
DA 2024-07-18
ER

PT J
AU Ozcinar, C
   Ekmekcioglu, E
   Anbarjafari, G
   Kondoz, A
AF Ozcinar, Cagri
   Ekmekcioglu, Erhan
   Anbarjafari, Gholamreza
   Kondoz, Ahmet
TI Adaptive multi-view video streaming using side information over
   peer-to-peer networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view plus-depth-map (MVD); Peer-to-peer (P2P); Compression;
   Adaptation; Streaming
ID FRAMEWORK; SYSTEM
AB Multi-view plus-depth-map (MVD) video streaming with autostereoscopic displays provides multi-user immersive media experiences. In this context, delivery of MVD representation to multiple clients remains a challenging problem because of the high-volume of data involved and the inherent limitations imposed by the delivery networks. To this end, this paper investigates the side information (SI) assisted adaptation algorithm using peer-to-peer (P2P) systems. P2P delivery systems for MVD video can maximize link utilization, preventing the transport of multiple video copies of the same packet for many users. However, the quality of experience (QoE) can be significantly degraded by dynamic variations caused by network congestions. To this end, our solution comprises the extraction of low-overhead metadata at the encoding server that is distributed through the P2P network as SI and used by P2P clients performing network adaptation. In the proposed adaptation strategy, pre-selected views are discarded at times of network congestion and reconstructed with an optimal reconstruction performance using the delivered SI and the delivered neighboring camera views. The experimental results show that the robustness of P2P multi-view streaming using the proposed adaptation scheme is significantly increased in the P2P network.
C1 [Ozcinar, Cagri] TCD, V SENSE Project, Dublin 2, Ireland.
   [Ekmekcioglu, Erhan; Kondoz, Ahmet] Loughborough Univ London, Inst Digital Technol, London, England.
   [Anbarjafari, Gholamreza] Univ Tartu, iCV Res Grp, EE-50411 Tartu, Estonia.
   [Anbarjafari, Gholamreza] Hasan Kalyoncu Univ, Dept Elect & Elect Engn, Gaziantep, Turkey.
C3 Trinity College Dublin; Loughborough University; University of Tartu;
   Hasan Kalyoncu University
RP Ozcinar, C (corresponding author), TCD, V SENSE Project, Dublin 2, Ireland.
EM ozcinarc@scss.tcd.ie
CR [Anonymous], P 2013 ACM INT WORKS
   [Anonymous], 1988, ACM SIGCOMM COMP COM
   [Anonymous], 2004, DEPTH IMAGE BASED RE
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Castellanos WE, 2017, MULTIMED TOOLS APPL, V76, P437, DOI 10.1007/s11042-015-3046-y
   Chen Q., 2010, CONSUM COMM NETWORK, P1
   De Abreu A, 2015, IEEE J-STSP, V9, P487, DOI 10.1109/JSTSP.2015.2407320
   Ekmekcioglu E, 2017, IEEE T CIRC SYST VID, V27, P1313, DOI 10.1109/TCSVT.2016.2527318
   Gürler CG, 2013, IEEE COMMUN MAG, V51, P108, DOI 10.1109/MCOM.2013.6515054
   Gurler CG, 2012, IEEE IMAGE PROC, P2289, DOI 10.1109/ICIP.2012.6467353
   Gürler CG, 2011, P IEEE, V99, P694, DOI 10.1109/JPROC.2010.2100010
   Habib A, 2006, IEEE T MULTIMEDIA, V8, P610, DOI 10.1109/TMM.2006.870724
   Hu SY, 2008, IEEE INFOCOM SER, P2047
   Karakaya M, 2009, IEEE INTERNET COMPUT, V13, P92, DOI 10.1109/MIC.2009.33
   Kim WS, 2009, IEEE IMAGE PROC, P721, DOI 10.1109/ICIP.2009.5414304
   Kurutepe Engin, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P157, DOI 10.1109/3DTV.2008.4547832
   Liu ZY, 2009, IEEE T MULTIMEDIA, V11, P1340, DOI 10.1109/TMM.2009.2030656
   Maugey T, 2013, IEEE T MULTIMEDIA, V15, P1070, DOI 10.1109/TMM.2013.2246147
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Merkle P, 2010, IEEE T CONSUM ELECTR, V56, P946, DOI 10.1109/TCE.2010.5506024
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Morvan Y., 2007, P IEEE INT C IM PROC, V5, pV
   Müller K, 2009, IEEE IMAGE PROC, P741, DOI 10.1109/ICIP.2009.5414287
   Ozcinar C, 2017, SIGNAL IMAGE VIDEO P, V11, P1279, DOI 10.1007/s11760-017-1085-8
   Ozcinar C, 2016, MULTIMED TOOLS APPL, V75, P12431, DOI 10.1007/s11042-016-3475-2
   Ozcinar C, 2014, IEEE IMAGE PROC, P2462, DOI 10.1109/ICIP.2014.7025498
   Safaaldin S, 2017, MULTIMED TOOLS APPL, V76, P1775, DOI 10.1007/s11042-015-3131-2
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   SUGIYAMA Y, 1986, IEEE T INFORM THEORY, V32, P394, DOI 10.1109/TIT.1986.1057178
   Tanimoto Masayuki, 2013, 105 M MPEG
   Yun D., 2017, IEEE T CIRCUITS SYST, P1
   Zhang XH, 2018, FITOTERAPIA, V124, P1, DOI 10.1016/j.fitote.2017.09.019
   Zhou Y, 2009, 2009 INTERNATIONAL CONFERENCE ON E-BUSINESS AND INFORMATION SYSTEM SECURITY, VOLS 1 AND 2, P1001
NR 35
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7225
EP 7242
DI 10.1007/s11042-018-6492-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700037
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sun, R
   Wang, X
   Yan, XX
AF Sun, Rui
   Wang, Xu
   Yan, Xiaoxing
TI Robust visual tracking based on convolutional neural network with
   extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Extreme learning machine; Visual tracking;
   Deep learning
ID OBJECT TRACKING; RECOGNITION; APPEARANCE; REGRESSION
AB Recently, deep learning has attracted substantial attention as a promising solution to many problems in computer vision. Among various deep learning architectures, convolutional neural network (CNN) has demonstrated superior performance as a feature learning method. In this paper, we present a novel hybrid model of CNN and extreme learning machine (ELM) for object tracking. Training a conventional CNN requires a substantial amount of computation and a large dataset. ELM randomly generates the parameters of hidden layers and calculates network weights between output and hidden layers via the regularized least-square method, thereby dramatically reducing the learning time while producing accurate results with minimal training data. Therefore, we integrate the ELM auto-encoder architecture into the CNN model. In addition, an effective updating scheme is designed for the model training to overcome the tracking drift problem. The joint CNN-ELM tracker is robust to object variations such as illumination, occlusion, and rotation in a video sequence. Numerous experiments on various challenging videos demonstrate that the proposed tracker performs favourably compared to several state-of-the-art methods.
C1 [Sun, Rui; Wang, Xu; Yan, Xiaoxing] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
   [Sun, Rui; Wang, Xu; Yan, Xiaoxing] Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Sun, R (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.; Sun, R (corresponding author), Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Anhui, Peoples R China.
EM sunrui@hfut.edu.cn
FU National Natural Science Foundation of China [61471154]; Anhui Province
   science and technology project [1704d0802181]
FX This work was supported by the National Natural Science Foundation of
   China (61471154) and Anhui Province science and technology project
   (1704d0802181).
CR [Anonymous], TMM
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Black M. J., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P329, DOI 10.1007/BFb0015548
   Cheng WC, 2012, IEEE INFOCOM SER, P864, DOI 10.1109/INFCOM.2012.6195835
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Duan MX, 2018, IEEE T INF FOREN SEC, V13, P758, DOI 10.1109/TIFS.2017.2766583
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kim J, 2017, NEURAL NETWORKS, V87, P109, DOI 10.1016/j.neunet.2016.12.002
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leichter I, 2012, IEEE T PATTERN ANAL, V34, P695, DOI 10.1109/TPAMI.2011.167
   Li HX, 2015, LECT NOTES COMPUT SC, V9007, P194, DOI 10.1007/978-3-319-16814-2_13
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Martinel Niki, 2015, IEEE Systems, Man, and Cybernetics Magazine, V1, P17, DOI 10.1109/MSMC.2015.2461151
   MEI X, 2011, TPAMI, V33, P2259, DOI DOI 10.1109/TPAMI.2011.66
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Shen CH, 2007, IEEE T IMAGE PROCESS, V16, P1457, DOI 10.1109/TIP.2007.894233
   Shi YR, 2013, ASIA PACIF MICROWAVE, P809, DOI 10.1109/APMC.2013.6694940
   Song HH, 2014, ELECTRON LETT, V50, P1931, DOI 10.1049/el.2014.1911
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Wang BX, 2015, SENSORS-BASEL, V15, P26877, DOI 10.3390/s151026877
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wang XH, 2018, NEUROCOMPUTING, V275, P438, DOI 10.1016/j.neucom.2017.08.063
   Wen LY, 2014, IEEE T IMAGE PROCESS, V23, P785, DOI 10.1109/TIP.2013.2293430
   Weng Q, 2017, IEEE GEOSCI REMOTE S, V14, P704, DOI 10.1109/LGRS.2017.2672643
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Yang YM, 2012, IEEE T NEUR NET LEAR, V23, P1498, DOI 10.1109/TNNLS.2012.2202289
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yoo YW, 2016, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2016.7727403
   Zhang D, 2017, ARXIV170108936V2
   Zhang SP, 2017, IEEE T CIRC SYST VID, V27, P421, DOI 10.1109/TCSVT.2016.2539860
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhang X, 2015, IEEE I C EMBED SOFTW, P848, DOI 10.1109/HPCC-CSS-ICESS.2015.309
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
   Zhou TF, 2017, IEEE T CIRC SYST VID, V27, P313, DOI 10.1109/TCSVT.2015.2493498
NR 55
TC 7
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7543
EP 7562
DI 10.1007/s11042-018-6491-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700050
DA 2024-07-18
ER

PT J
AU Vyas, R
   Kanumuri, T
   Sheoran, G
AF Vyas, Ritesh
   Kanumuri, Tirupathiraju
   Sheoran, Gyanendra
TI Cross spectral iris recognition for surveillance based applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Difference of Variance (DoV); Template partitioning;
   Surveillance; Cross-spectral matching
ID REPRESENTATION; VIDEO
AB Human iris has been explored as one of the most promising biometric traits since last many years. This paper presents a new ingenious feature extraction approach which is based on the texture variations of the iris template. A 2D Gabor filter bank is first employed to reveal the iris texture at different scales and orientations. Each filtered iris template is then partitioned into smaller sub-blocks. Contemplating the iris texture variations at micro-levels, two-level template partitioning is employed here. Difference of Variance (DoV) of corresponding first and second level sub-blocks, from each filtered image, then forms the feature set of the iris. Performance of the proposed iris recognition scheme is first tested with the benchmark IITD iris database to find the optimal window size of the filter bank. Thereafter, to prove the efficacy of the proposed approach in surveillance based applications, cross-spectral iris matching experiments (i.e. visible wavelength (VW) to near infrared (NIR) matching) are performed using PolyU cross-spectral database. Experiments show that the proposed approach achieves outperforming results for both IITD and PolyU databases.
C1 [Vyas, Ritesh] Natl Inst Technol Delhi, Delhi 110040, India.
   [Kanumuri, Tirupathiraju] Natl Inst Technol Delhi, Dept Elect & Elect Engn, Delhi 110040, India.
   [Sheoran, Gyanendra] Natl Inst Technol Delhi, Dept Appl Sci, Delhi 110040, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi; National Institute of Technology (NIT System);
   National Institute of Technology Delhi; National Institute of Technology
   (NIT System); National Institute of Technology Delhi
RP Kanumuri, T (corresponding author), Natl Inst Technol Delhi, Dept Elect & Elect Engn, Delhi 110040, India.
EM ritesh.vyas@nitdelhi.ac.in; ktraju@nitdelhi.ac.in;
   gsheoran@nitdelhi.ac.in
RI sheoran, gyanendra/AAD-3973-2022; Sheoran, Gyanendra/ADH-1043-2022;
   Kanumuri, Tirupathiraju/V-5584-2019; Vyas, Ritesh/AAF-9410-2020
OI Sheoran, Gyanendra/0000-0002-9631-9707; Kanumuri,
   Tirupathiraju/0000-0002-0441-7642; Vyas, Ritesh/0000-0002-9739-2551
CR [Anonymous], IEEE IND INT C INF P
   [Anonymous], TIP
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], IAPR 2 INT C COMP VI
   [Anonymous], IEEE 4 INT C BIOM TH
   [Anonymous], ALGORITHMS TECHNOLOG
   [Anonymous], 2016, IPSJ T COMPUTER VISI
   [Anonymous], STAT
   Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1976, DOI 10.1016/j.patrec.2006.05.008
   Bansal M, 2016, OPTIK, V127, P4808, DOI 10.1016/j.ijleo.2016.01.160
   Barpanda SS, 2018, MULTIMED TOOLS APPL, V77, P7637, DOI 10.1007/s11042-017-4668-z
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Farouk RM, 2011, COMPUT VIS IMAGE UND, V115, P1239, DOI 10.1016/j.cviu.2011.04.002
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   Llano EG, 2018, PATTERN RECOGN LETT, V101, P44, DOI 10.1016/j.patrec.2017.11.012
   Huo G, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013033
   Kang BJ, 2010, OPT ENG, V49, DOI 10.1117/1.3447924
   Karn P, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.063002
   Khalighi S, 2015, J SIGNAL PROCESS SYS, V81, P111, DOI 10.1007/s11265-014-0911-2
   Kulkarni SB, 2014, INT J IMAGE GRAPH, V14, DOI 10.1142/S0219467814500107
   Liu NAF, 2016, PATTERN RECOGN LETT, V82, P154, DOI 10.1016/j.patrec.2015.09.016
   Luz E, 2018, PATTERN RECOGN LETT, V114, P2, DOI 10.1016/j.patrec.2017.12.009
   Miyazawa K, 2008, IEEE T PATTERN ANAL, V30, P1741, DOI 10.1109/TPAMI.2007.70833
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Nguyen K, 2017, PATTERN RECOGN, V72, P123, DOI 10.1016/j.patcog.2017.05.021
   Nigam Aditya, 2015, Computational Forensics. 5th International Workshop, IWCF 2012 and 6th International Workshop, IWCF 2014. Revised Selected Papers: LNCS 8915, P55, DOI 10.1007/978-3-319-20125-2_6
   Qi MB, 2019, MULTIMED TOOLS APPL, V78, P27029, DOI 10.1007/s11042-017-4649-2
   Rai H, 2014, EXPERT SYST APPL, V41, P588, DOI 10.1016/j.eswa.2013.07.083
   Shin KY, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.4.047201
   Pham TTT, 2017, IMAGE VISION COMPUT, V59, P44, DOI 10.1016/j.imavis.2016.10.010
   Umer S, 2016, PATTERN ANAL APPL, V19, P283, DOI 10.1007/s10044-015-0482-2
   Umer S, 2015, PATTERN RECOGN LETT, V65, P67, DOI 10.1016/j.patrec.2015.07.008
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
   Zhao ZJ, 2015, IEEE I CONF COMP VIS, P3828, DOI 10.1109/ICCV.2015.436
NR 39
TC 11
Z9 13
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5681
EP 5699
DI 10.1007/s11042-018-5689-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100033
DA 2024-07-18
ER

PT J
AU Chen, L
   Wang, SK
   Lam, KM
   Zhou, HY
   Jian, MW
   Dong, JY
AF Chen, Long
   Wang, Shengke
   Lam, Kin-Man
   Zhou, Huiyu
   Jian, Muwei
   Dong, Junyu
TI Cascaded one-vs-rest detection network for fine-grained recognition
   without part annotations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained Recognition; Detection; One-vs-rest; Without part
   annotations
ID ENCRYPTION; SECURE
AB Fine-grained recognition is a challenging task due to small intra-category variances. Most of the top-performing fine-grained recognition methods leverage parts of objects for better performance. Therefore, part annotations which are extremely computationally expensive are required. In this paper, we propose a novel cascaded deep CNN detection framework for fine-grained recognition which is trained to detect a whole object without considering parts. Nevertheless, most of the current top-performing detection networks use N+1 class (N object categories plus background) softmax loss. The background category with much more training samples dominates the feature learning progress where the features are not suitable for object categorisation with fewer samples. To address this issue, we here introduce two strategies: 1) We leverage a cascaded structure to eliminate the background. 2) We introduce a novel one-vs-rest loss function to capture more minute variances from different subordinate categories. Experiments show that our proposed recognition framework achieves comparable performance against the state-of-the-art, part-free, fine-grained recognition methods on the CUB-200-2011 Bird dataset. Meanwhile, our method outperforms most of the existing part annotation based methods and does not need part annotations at the training stage whilst being free from any annotations at the test stage.
C1 [Chen, Long; Wang, Shengke; Jian, Muwei; Dong, Junyu] Ocean Univ China, Qingdao, Shandong, Peoples R China.
   [Lam, Kin-Man] Hong Kong Polytech Univ, Hung Hom, Hong Kong, Peoples R China.
   [Zhou, Huiyu] Univ Leicester, Univ Rd, Leicester LE1 7RH, Leics, England.
C3 Ocean University of China; Hong Kong Polytechnic University; University
   of Leicester
RP Wang, SK (corresponding author), Ocean Univ China, Qingdao, Shandong, Peoples R China.
EM neverme@ouc.edu.cn
RI Zhou, Huiyu/O-2692-2014; Jian, Muwei/Q-8319-2018
OI Zhou, Huiyu/0000-0003-1634-9840; Jian, Muwei/0000-0002-4249-2264
FU UK EPSRC [EP/N011074/1]; Royal Society-Newton Advanced Fellowship
   [NA160342];  [2014DFA10410]; EPSRC [EP/N011074/1] Funding Source: UKRI
FX 2014DFA10410. H. Zhou is supported by UK EPSRC under Grant EP/N011074/1
   and Royal Society-Newton Advanced Fellowship under Grant NA160342.
CR Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   [Anonymous], 2016, ARXIV160403239
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Berg T, 2014, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2014.259
   Branson S., 2014, BIRD SPECIES CATEGOR, V1, P7
   Branson S, 2014, INT J COMPUT VISION, V108, P3, DOI 10.1007/s11263-014-0698-4
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jouini M, 2016, INT J CLOUD APPL COM, V6, P32, DOI 10.4018/IJCAC.2016070103
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   LI Z, 2017, TKDE, V29, P2100, DOI DOI 10.1109/TKDE.2017.2728531
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Maji S, 2012, LECT NOTES COMPUT SC, V7585, P21, DOI 10.1007/978-3-642-33885-4_3
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sfar AR, 2013, PROC CVPR IEEE, P835, DOI 10.1109/CVPR.2013.113
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang XP, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P287, DOI 10.1145/2647868.2654937
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
NR 34
TC 2
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4381
EP 4395
DI 10.1007/s11042-018-5875-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200025
DA 2024-07-18
ER

PT J
AU Deng, XL
   Li, YQ
   Weng, J
   Zhang, JL
AF Deng, Xuelian
   Li, Yuqing
   Weng, Jian
   Zhang, Jilian
TI Feature selection for text classification: A review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Feature Selection; Text classification; Text classifiers; Multimedia
ID HYBRID FEATURE-SELECTION; GENETIC ALGORITHM; SIMILARITY MEASURE; NAIVE
   BAYES; IMAGE; CATEGORIZATION; DISTANCE; REGRESSION
AB Big multimedia data is heterogeneous in essence, that is, the data may be a mixture of video, audio, text, and images. This is due to the prevalence of novel applications in recent years, such as social media, video sharing, and location based services (LBS), etc. In many multimedia applications, for example, video/image tagging and multimedia recommendation, text classification techniques have been used extensively to facilitate multimedia data processing. In this paper, we give a comprehensive review on feature selection techniques for text classification. We begin by introducing some popular representation schemes for documents, and similarity measures used in text classification. Then, we review the most popular text classifiers, including Nearest Neighbor (NN) method, Naive Bayes (NB), Support Vector Machine (SVM), Decision Tree (DT), and Neural Networks. Next, we survey four feature selection models, namely the filter, wrapper, embedded and hybrid, discussing pros and cons of the state-of-the-art feature selection approaches. Finally, we conclude the paper and give a brief introduction to some interesting feature selection work that does not belong to the four models.
C1 [Deng, Xuelian; Li, Yuqing] Guangxi Univ Chinese Med, Coll Publ Hlth & Management, Guangxi, Peoples R China.
   [Weng, Jian] Jinan Univ, Coll Informat Sci & Technol, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Jilian] Jinan Univ, Coll Cyber Secur, Guangzhou, Guangdong, Peoples R China.
C3 Guangxi University of Chinese Medicine; Jinan University; Jinan
   University
RP Zhang, JL (corresponding author), Jinan Univ, Coll Cyber Secur, Guangzhou, Guangdong, Peoples R China.
EM 173213455@qq.com; 28272306@qq.com; cryptjweng@gmail.com;
   jilian.z.2007@smu.edu.sg
OI Weng, Jian/0000-0003-4067-8230
FU National Key RD Plan of China [2017YFB0802203, 2018YFB100013]; National
   Natural Science Foundation of China [U1736203, 61732021, 61472165,
   61373158, 61363009]; Guangdong Provincial Engineering Technology
   Research Center on Network Security Detection and Defense
   [2014B090904067]; Guangdong Provincial Special Funds for Applied
   Technology Research and Development and Transformation of Important
   Scientific and Technological Achieve [2016B010124009]; Zhuhai Top
   Discipline-Information Security; Guangzhou Key Laboratory of Data
   Security and Privacy Preserving; Guangdong Key Laboratory of Data
   Security and Privacy Preserving; National Joint Engineering Research
   Center of Network Security Detection and Protection Technology
FX This work was supported by National Key R&D Plan of China (Grant No.
   2017YFB0802203 and 2018YFB100013), National Natural Science Foundation
   of China (Grant Number U1736203, 61732021, 61472165, 61373158, and
   61363009), Guangdong Provincial Engineering Technology Research Center
   on Network Security Detection and Defense (Grant No. 2014B090904067),
   Guangdong Provincial Special Funds for Applied Technology Research and
   Development and Transformation of Important Scientific and Technological
   Achieve (Grant No. 2016B010124009), the Zhuhai Top
   Discipline-Information Security, Guangzhou Key Laboratory of Data
   Security and Privacy Preserving, Guangdong Key Laboratory of Data
   Security and Privacy Preserving, National Joint Engineering Research
   Center of Network Security Detection and Protection Technology.
CR Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420
   [Anonymous], [No title captured]
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 1993, MORGAN KAUFMANN SERI
   [Anonymous], 2009, P 12 INT C ART INT S
   [Anonymous], 2000, WORKSH ART INT WEB S
   [Anonymous], 1997, ICML
   [Anonymous], 2007, MULTIPLE CLASSIFIER
   [Anonymous], 1998, LEARNING TEXT CATEGO
   [Anonymous], 2014, Effective Use of Word Order for Text Categorization with Convolutional Neural Networks
   APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423
   Aslam JavedA., 2003, P 26 ANN INT ACM SIG, P449
   Baccianella S, 2014, NEURAL COMPUT, V26, P557, DOI 10.1162/NECO_a_00558
   Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Ballan L, 2015, MULTIMED TOOLS APPL, V74, P1443, DOI 10.1007/s11042-014-1976-4
   Basu T, 2016, INT J MACH LEARN CYB, V7, P877, DOI 10.1007/s13042-015-0421-y
   Bermejo P, 2012, KNOWL-BASED SYST, V25, P35, DOI 10.1016/j.knosys.2011.01.015
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054
   Choi S.-S., 2010, Systemics, Cybernetics and Informatic, V8, P43
   Chou CH, 2010, J ASSOC INF SYST, V11, P491
   Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P115
   Combarro EF, 2005, IEEE T KNOWL DATA EN, V17, P1223, DOI 10.1109/TKDE.2005.149
   Das S., 2001, P 18 INT C MACHINE L, P74, DOI DOI 10.5555/645530.658297
   Dasgupta A, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P230
   Dash M., 1997, Intelligent Data Analysis, V1
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P148, DOI 10.1145/288627.288651
   Dy JG, 2004, J MACH LEARN RES, V5, P845
   Eyheramendy S., 2005, P WORKSH FEAT SEL DA, P1
   Fang Y, 2017, LECT NOTES ARTIF INT, V10604, P273, DOI 10.1007/978-3-319-69179-4_19
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Forman G., 2004, P 21 INT C MACH LEAR, P38, DOI DOI 10.1145/1015330.1015356
   Fragoudis D, 2005, KNOWL INF SYST, V8, P16, DOI 10.1007/s10115-004-0177-2
   Galavotti L, 2000, LECT NOTES COMPUT SC, V1923, P59
   Gao B, 2005, IEEE T KNOWL DATA EN, V17, P1263, DOI 10.1109/TKDE.2005.147
   Ghareb AS, 2016, EXPERT SYST APPL, V49, P31, DOI 10.1016/j.eswa.2015.12.004
   Gütlein M, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P332, DOI 10.1109/CIDM.2009.4938668
   Günal S, 2012, TURK J ELECTR ENG CO, V20, P1296, DOI 10.3906/elk-1101-1064
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   He X., 2005, P ADV NEURAL INFORM, V18, P507
   Hinneburg A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506
   Hu RY, 2017, MULTIMED TOOLS APPL, V76, P17479, DOI 10.1007/s11042-016-4119-2
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Huang A., 2008, NZCSRSC 2008
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jian L., 2016, P 25 INT JOINT C ART, P1627
   Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P137, DOI 10.1007/BFb0026683
   John G.H., 1994, P 11 INT C MACH LEAR, P121
   Jun Yan, 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P122, DOI 10.1145/1076034.1076058
   Kalousis A, 2007, KNOWL INF SYST, V12, P95, DOI 10.1007/s10115-006-0040-8
   Kim SB, 2006, IEEE T KNOWL DATA EN, V18, P1457, DOI 10.1109/TKDE.2006.180
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Koller D., 1996, TECH REP
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lam SLY, 1999, 6TH INTERNATIONAL CONFERENCE ON DATABASE SYSTEMS FOR ADVANCED APPLICATIONS, PROCEEDINGS, P195, DOI 10.1109/DASFAA.1999.765752
   Largeron C., 2011, P 2011 ACM S APPL CO, P924
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   LEVANDOWSKY M, 1971, NATURE, V234, P34, DOI 10.1038/234034a0
   Lewis D.D., 1994, Third Annual Symposium on Document Analysis and Information Retrieval, P81
   Lin D, 1998, P INT C MACH LEARN, V98, P29
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Lin YS, 2014, IEEE T KNOWL DATA EN, V26, P1575, DOI 10.1109/TKDE.2013.19
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Liu H., 1997, P 9 INT C IND ENG AP, P419
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Manku GS, 2007, P 16 INT C WORLD WID, P141, DOI DOI 10.1145/1242572.1242592
   McCallum A., 1998, Proceedings of ICML-98, 15th International Conference on Machine Learning, P350
   Mladenic D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P95, DOI 10.1007/BFb0026677
   Molina LC, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P306, DOI 10.1109/ICDM.2002.1183917
   Ng HT, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P67, DOI 10.1145/258525.258537
   Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105
   Pappas N, 2015, MULTIMED TOOLS APPL, V74, P1175, DOI 10.1007/s11042-013-1840-y
   Pietramala A, 2008, LECT NOTES ARTIF INT, V5212, P188, DOI 10.1007/978-3-540-87481-2_13
   Pouget V., 2017, IEEE T NEUR NET LEAR, V64, P13, DOI DOI 10.1109/TNNLS.2016.2521602
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   Rocchio J., 1971, SMART RETRIEVAL SYST, P313
   Rogati M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P659, DOI 10.1145/584792.584911
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Schutze H., 1995, SIGIR Forum, P229
   Scott S, 1999, MACHINE LEARNING, PROCEEDINGS, P379
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Song QB, 2013, IEEE T KNOWL DATA EN, V25, P1, DOI 10.1109/TKDE.2011.181
   Strehl A, 2000, PROC SPIE, V4057, P33, DOI 10.1117/12.381756
   Taira H, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P480
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P2508, DOI 10.1109/TKDE.2016.2563436
   Tang J., 2014, DATA CLASSIFICATION, P37, DOI DOI 10.1201/B17320
   Uguz H, 2011, KNOWL-BASED SYST, V24, P1024, DOI 10.1016/j.knosys.2011.04.014
   Uysal AK, 2016, EXPERT SYST APPL, V43, P82, DOI 10.1016/j.eswa.2015.08.050
   Uysal AK, 2014, EXPERT SYST APPL, V41, P5938, DOI 10.1016/j.eswa.2014.03.041
   Uysal AK, 2012, KNOWL-BASED SYST, V36, P226, DOI 10.1016/j.knosys.2012.06.005
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Wan X, 2005, P 14 ACM INT C INF K, P301
   Wan XJ, 2007, INFORM SCIENCES, V177, P3718, DOI 10.1016/j.ins.2007.02.045
   Wang DQ, 2014, PATTERN RECOGN LETT, V45, P1, DOI 10.1016/j.patrec.2014.02.013
   Wang JL, 2014, IEEE T KNOWL DATA EN, V26, P698, DOI 10.1109/TKDE.2013.32
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Weston J, 2001, ADV NEUR IN, V13, P668
   WIENER E, 1995, P 4 ANN S DOC AN INF
   Wu XD, 2013, IEEE T PATTERN ANAL, V35, P1178, DOI 10.1109/TPAMI.2012.197
   Xing E.P., 2001, P 18 INT C MACH LEAR, V1, P601, DOI DOI 10.3233/IDA-1997-1302
   Yang JM, 2012, INFORM PROCESS MANAG, V48, P741, DOI 10.1016/j.ipm.2011.12.005
   YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424
   Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42, DOI 10.1145/312624.312647
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhao SC, 2016, MULTIMED TOOLS APPL, V75, P8921, DOI 10.1007/s11042-014-2342-2
   Zhao Z, 2013, IEEE T KNOWL DATA EN, V25, P619, DOI 10.1109/TKDE.2011.222
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zheng Z., 2004, ACM Sigkdd Explorations Newsletter, V6, P80, DOI DOI 10.1145/1007730.1007741
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
   Zhu XF, 2017, IEEE T BIG DATA, V3, P405, DOI 10.1109/TBDATA.2017.2735991
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   杨云峰, 1999, [西安公路交通大学学报, Journal of Xian Highway University], P67
NR 123
TC 174
Z9 179
U1 20
U2 207
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3797
EP 3816
DI 10.1007/s11042-018-6083-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600062
DA 2024-07-18
ER

PT J
AU Kim, H
   Park, J
   Kim, H
   Hwang, E
   Rho, S
AF Kim, Hyungjoon
   Park, Jisoo
   Kim, HyeonWoo
   Hwang, Eenjun
   Rho, Seungmin
TI Robust facial landmark extraction scheme using multiple convolutional
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Facial landmark; Semantic segmentation;
   Object detection; Faster R-CNN
AB Facial landmarks are a set of features that can be distinguished on the human face with the naked eye. Typical facial landmarks include eyes, eyebrows, nose, and mouth. Landmarks play an important role in human-related image analysis. For example, they can be used to determine whether there is a human being in the image, identify who the person is, or recognize the orientation of a face when taking a photograph. General techniques for detecting facial landmarks can be classified into two groups: One is based on traditional image processing techniques, such as Haar cascade classifiers and edge detection. The other is based on machine learning techniques in which landmarks can be detected by training neural network using facial features. However, such techniques have shown low accuracy, especially in some special conditions such as low luminance and overlapped faces. To overcome these problems, we proposed in our previous work a facial landmark extraction scheme using deep learning and semantic segmentation, and demonstrated that with even a small dataset, our scheme could achieve reasonable facial landmark extraction performance under such conditions. Nevertheless, for more extensive dataset, we found several exceptional cases where the scheme could not detect face landmarks precisely. Hence, in this paper, we revise our facial landmark extraction scheme using a deep learning model called Faster R-CNN and show how our scheme can improve the overall performance by handling such exceptional cases appropriately. Also, we show how to expand the training dataset by using image filters and image operations such as rotation for more robust landmark detection.
C1 [Kim, Hyungjoon; Park, Jisoo; Kim, HyeonWoo; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
C3 Korea University; Sungkyul University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM hyungjun89@korea.ac.kr; jisoo_park@korea.ac.kr; guihon12@korea.ac.kr;
   ehwang04@korea.ac.kr; smrho@sungkyul.edu
RI Rho, Seungmin/HTP-6683-2023
OI Kim, Hyungjoon/0000-0003-4580-489X
FU Korea Environment Industry & Technology Institute (KEITI) through Public
   Technology Program based on Environmental Policy - Korea Ministry of
   Environment (MOE) [2017000210001]
FX This work was supported by Korea Environment Industry & Technology
   Institute (KEITI) through Public Technology Program based on
   Environmental Policy, funded by Korea Ministry of Environment
   (MOE)(2017000210001).
CR [Anonymous], 2015, ARXIV151100561
   [Anonymous], 2015, ARXIV, DOI DOI 10.48550/ARXIV.1504.08083
   [Anonymous], 2018 INT C PLATF TEC
   [Anonymous], COMP VIS WORKSH ICCV
   [Anonymous], INT C UB INF MAN COM
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], ADV NEURAL INF PROCE
   Badrinarayanan V., 2015, SEGNET DEEP CONVOLUT
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guclu U., 2017, ARXIV170303305
   Kasinski A, 2010, PATTERN ANAL APPL, V13, P197, DOI 10.1007/s10044-009-0150-5
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Redmon J., 2016, 2016 IEEE Conf. Comp. Vis. Patt. Recog. (CVPR), P779
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O., 2015, Int. J. Comput. Vis. (IJCV)
   Simonyan K., 2014, 14091556 ARXIV
NR 21
TC 12
Z9 12
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3221
EP 3238
DI 10.1007/s11042-018-6482-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600030
DA 2024-07-18
ER

PT J
AU Kim, M
   Sung, NJ
   Kim, SJ
   Choi, YJ
   Hong, M
AF Kim, Minsang
   Sung, Nak-Jun
   Kim, Sang-Joon
   Choi, Yoo-Joo
   Hong, Min
TI Parallel cloth simulation with effective collision detection for
   interactive AR application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloth simulation; GPU-based parallel processing; Mass-spring system;
   Physically-based simulation; Augmented reality
AB In this paper, we present a parallel cloth simulation with an efficient collision detection algorithm for interactive AR applications. In the first step of the proposed method, a set of sphere colliders is automatically defined for the 3D moving object colliding with a cloth model for the effective collision detection even on low-end devices. In the second step, the collision detection and handling between a set of sphere colliders and a cloth model are performed in parallel. We propose an efficient collision handling method based on a sphere to prevent the penetration of cloth into the object which can be happened due to the low mesh resolution of the cloth model. The proposed method was implemented as a plugin for Unity which is widely used for the real-time game development. Comparative experimental tests with the cloth object basically provided by Unity was performed in order to analyze the performance of the proposed method. As a result, we confirmed that the proposed method can reduce the cumbersome work to manually build colliders on a 3D model, and can effectively express more accurate and plausible behavior of the cloth that collides with the object.
C1 [Kim, Minsang] Soonchunhyang Univ, Dept Comp Sci, Asan, South Korea.
   [Sung, Nak-Jun; Kim, Sang-Joon; Choi, Yoo-Joo] Seoul Media Inst Technol, Dept Newmedia, Seoul, South Korea.
   [Hong, Min] Soonchunhyang Univ, Dept Comp Software Engn, Asan, South Korea.
C3 Soonchunhyang University; Soonchunhyang University
RP Hong, M (corresponding author), Soonchunhyang Univ, Dept Comp Software Engn, Asan, South Korea.
EM ben399399@gmail.com; njsung1217@gmail.com; gogo5911@naver.com;
   yjchoi@smit.ac.kr; mhong@sch.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (Ministry
   of Science, ICT & Future Planning) [2017R1A2B1005207]; Soonchunhyang
   University Research Fund
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (Ministry of Science, ICT &
   Future Planning) (No. 2017R1A2B1005207) and was supported by the
   Soonchunhyang University Research Fund.
CR [Anonymous], OPENGL 4 SHADING LAN
   [Anonymous], P COMP GRAPH INT CGI
   Chen J, 2017, VISUAL COMPUT, V33, P801, DOI 10.1007/s00371-017-1389-2
   Cirio G, 2017, IEEE T VIS COMPUT GR, V23, P1152, DOI 10.1109/TVCG.2016.2592908
   de Aguiar E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778843
   Kaldor JM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778842
   Liu L, 2014, MULTIMED TOOLS APPL, V71, P411, DOI 10.1007/s11042-013-1437-5
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Pei SW, 2016, KSII T INTERNET INF, V10, P3231, DOI 10.3837/tiis.2016.07.020
   Rodriguez-Navarro J., 2006, VRIPHYS, P1
   Schuettel P., 2017, The concise Fintech compendium
   Sung NJ, 2017, KSII T INTERNET INF, V11, P4120, DOI 10.3837/tiis.2017.08.021
   Tang M, 2013, COMPUT GRAPH FORUM, V32, P21, DOI 10.1111/cgf.12208
   Wu K, 2019, IEEE T VIS COMPUT GR, V25, P1297, DOI 10.1109/TVCG.2017.2731949
NR 14
TC 6
Z9 8
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4851
EP 4868
DI 10.1007/s11042-018-6063-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200048
DA 2024-07-18
ER

PT J
AU Liao, MZ
   Chen, J
AF Liao, Mingzhi
   Chen, Jie
TI RETRACTED: Intelligent business and marketing model under full platform
   multimedia soft computing framework (Retracted article. See vol. 82, pg.
   3179, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Full platform multimedia; Soft computing algorithm; Framework;
   Intelligent business; Marketing model
ID CLASSIFICATION; FEATURES
AB Data warehouse technology-oriented financial information system solutions the system design and traditional management information system design should use engineering design ideas as a guide. This trend inspires us to consider modern soft computing techniques into business. Therefore, this paper proposes the novel intelligent business and marketing model under full platform multimedia soft computing framework. Our model is implemented based on three major pipelines. (1) In order to ensure that the empirical research conclusion persuasive, usually need to choose authority site for data collection, authorities such as the national decision-making and the information department. (2) Financial empirical research generally does not need pictures, video and other multimedia data and its extensive use of the text and numerical data. (3) Financial empirical research need the amount of data is often a lot (such as often need to the whole market transaction data for many years, even the high frequency data), and the data distribution channels are often involved in different institutions. Therefore the regression model is considered. The numerical simulations have proved the effectiveness of the proposed method.
C1 [Liao, Mingzhi] Sichuan Normal Univ, Sch Business, Chengdu, Sichuan, Peoples R China.
   [Chen, Jie] Sichuan Acad Social Sci, Dept Finance & Int Econ, Chengdu, Sichuan, Peoples R China.
C3 Sichuan Normal University
RP Liao, MZ (corresponding author), Sichuan Normal Univ, Sch Business, Chengdu, Sichuan, Peoples R China.
EM liaomingming@yahoo.com
CR Alanazi A, 2016, MOB SEC SERV MOBISEC, P1
   Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212
   Chen H, 2017, J MED IMAG HEALTH IN, V7, P875, DOI 10.1166/jmihi.2017.2097
   Chergui M., 2014, NEXT GEN NETW SERV N, P1
   Choi K, 2015, MULTIMED TOOLS APPL, V74, P1537, DOI 10.1007/s11042-015-2486-8
   Espinoza A, 2013, IEEE T IND INFORM, V9, P1384, DOI 10.1109/TII.2013.2256792
   Ghofrani M, 2016, APPL SOFT COMPUT, V48, P207, DOI 10.1016/j.asoc.2016.07.022
   Hosseinpour S, 2017, INT J HYDROGEN ENERG, V42, P8518, DOI 10.1016/j.ijhydene.2016.11.090
   Jaffar MA, 2017, J EXP THEOR ARTIF IN, V29, P149, DOI 10.1080/0952813X.2015.1132263
   Kim SK, 2015, MULTIMED TOOLS APPL, V74, P3273, DOI 10.1007/s11042-015-2459-y
   Kovachev D, 2014, MULTIMED TOOLS APPL, V70, P977, DOI 10.1007/s11042-012-1100-6
   Kubanek M, 2016, INT MULT ADV COMP SY, P266
   Kumar N, 2015, CLUSTER COMPUT, V18, P1263, DOI 10.1007/s10586-015-0463-7
   Liu L, 2016, INTERNATIONAL CONFERENCE ON ADVANCED MANUFACTURE TECHNOLOGY AND INDUSTRIAL APPLICATION, AMTIA 2016, P247
   Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48
   Lugmayr A, 2013, MULTIMED TOOLS APPL, V66, P33, DOI 10.1007/s11042-012-1143-8
   Calvo-Rolle JL, 2017, ADV COMPU INTELL ROB, P469, DOI 10.4018/978-1-5225-2128-0.ch016
   Lv SG, 2015, INFORM SCIENCES, V294, P255, DOI 10.1016/j.ins.2014.09.011
   Ma L, 2017, J MED IMAG HEALTH IN, V7, P833, DOI 10.1166/jmihi.2017.2081
   MARINELLI L, 2015, INT CONF MARK BUS DE, V1, P393
   Murray N, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2816454
   Pal SK, 2017, STUD COMPUT INTELL, V712, P195, DOI 10.1007/978-3-319-57115-7_7
   Parker MC, 2016, 2016 EUROPEAN CONFERENCE ON NETWORKS AND COMMUNICATIONS (EUCNC), P240, DOI 10.1109/EuCNC.2016.7561040
   Premnath KN, 2017, ARTIF INTELL, P2279
   Sahu Anoop Kumar, 2015, International Journal of Business Excellence, V8, P675
   Sayed K, 2017, J MED IMAG HEALTH IN, V7, P771, DOI 10.1166/jmihi.2017.2078771
   Shamsuzzoha AHM, 2013, INTELLIGENT NONHIERA, P349
   Sunitha R, 2016, P INT C SOFT COMP SY, P365
   Trad A, 2015, PROCEDIA COMPUT SCI, V64, P214, DOI 10.1016/j.procs.2015.08.483
   Vadali S, 2017, ADV INTELL SYST, V546, P52, DOI 10.1007/978-981-10-3322-3_6
   Wang C, 2016, APPL SOFT COMPUT, V38, P1099, DOI 10.1016/j.asoc.2015.06.006
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang JB, 2015, IEEE SYS MAN CYBERN, P1870, DOI 10.1109/SMC.2015.327
   Wei Li, 2015, 2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). Proceedings, P216, DOI 10.1109/IHMSC.2015.200
   Yu YT, 2015, IEEE T COMPUT AID D, V34, P460, DOI 10.1109/TCAD.2014.2387858
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhou QY, 2016, CLUSTER COMPUT, V19, P1275, DOI 10.1007/s10586-016-0580-y
NR 37
TC 2
Z9 2
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4155
EP 4177
DI 10.1007/s11042-017-5384-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200015
DA 2024-07-18
ER

PT J
AU Kanakkath, P
   Madathil, S
   Krishnan, R
AF Kanakkath, Praveen
   Madathil, Sethumadhavan
   Krishnan, Ramakrishnan
TI Deterministic extended visual cryptographic schemes for general access
   structures with OR-AND and XOR-AND operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Extended visual cryptography; OR-AND
   reconstruction; XOR-AND reconstruction; General access structure
ID SECRET SHARING SCHEMES; RANDOM GRIDS; AUTHENTICATION; PROTECTION;
   BIOMETRICS
AB In Visual Cryptographic Scheme (VCS) shares of the secret image look like random, whereas in Extended Visual Cryptographic Scheme (EVCS) the shares look like meaningful images. In the case of ideal contrast deterministic constructions for VCS, depending upon the access structure, each participant needs to hold one/multiple image shares with same size of the binary secret image and the secret image will be reconstructed without any change in resolution. In this paper, two deterministic constructions for EVCS with a relative contrast of 0.333 are proposed by utilizing the ideal contrast deterministic constructions for VCS as a building block. The proposed schemes are applicable to share secret binary images only. Theoretical analysis and comparison with other related works are given in this paper.
C1 [Kanakkath, Praveen; Madathil, Sethumadhavan; Krishnan, Ramakrishnan] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, TIFAC CORE Cyber Secur, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Kanakkath, P (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn, TIFAC CORE Cyber Secur, Coimbatore, Tamil Nadu, India.
EM k_praveen@cb.amrita.edu; m_sethu@cb.amrita.edu; drrkdrrk@gmail.com
CR ABADI M, 1993, SCI COMPUT PROGRAM, V21, P93, DOI 10.1016/0167-6423(93)90002-7
   Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   Abdullah MAM, 2016, IEEE ACCESS, V4, P10180, DOI 10.1109/ACCESS.2016.2623905
   Adhikari A, 2014, DESIGN CODE CRYPTOGR, V73, P865, DOI 10.1007/s10623-013-9832-5
   Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Chiu PL, 2015, SIGNAL PROCESS, V108, P476, DOI 10.1016/j.sigpro.2014.09.032
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   Cimato S., 2014, T DATA HIDING MULTIM, VIX, P91, DOI DOI 10.1007/978-3-642-55046-1_6
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Dang W, 2015, INT J COMPUT COMMUN, V4
   De Bonis A, 2004, THEOR COMPUT SCI, V314, P351, DOI 10.1016/j.tcs.2003.12.018
   Dutta Sunil., 2015, Dynamic Effects of Information Disclosure on Investment Efficiency, P1
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Guo T, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P391, DOI 10.1109/IIH-MSP.2013.104
   Guo T, 2014, LECT NOTES COMPUT SC, V8317, P56, DOI 10.1007/978-3-319-04268-8_4
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Lee KH, 2012, IEEE T INF FOREN SEC, V7, P219, DOI 10.1109/TIFS.2011.2167611
   Li X, 2013, MATH COMPUT MODEL, V58, P85, DOI 10.1016/j.mcm.2012.06.033
   Liao X, 2017, MULTIMED TOOL APPL
   Liao X, 2017, COMPUT ELECT ENG
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu F, 2014, FLEXIBLE VISUAL CRYP, VIX, P110
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P331, DOI 10.1016/j.jvcir.2011.11.003
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Lu JF, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/4356038
   Lu S, 2011, J COMB OPTIM, V21, P47, DOI 10.1007/s10878-009-9241-x
   Nakajima M, 2002, P WSGC, P2002
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ou DH, 2016, MULTIMED TOOLS APPL, V75, P3517, DOI 10.1007/s11042-015-2462-3
   Praveen K, 2015, P 3 ICACNI, V2015, P309
   Ross A, 2011, IEEE T INF FOREN SEC, V6, P70, DOI 10.1109/TIFS.2010.2097252
   Shivani S, 2017, MULTIMED TOOLS APPL, P1
   Shivani S, 2017, MULTIMED TOOLS APPL, V76, P8711, DOI 10.1007/s11042-016-3484-1
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Shyu SJ, 2014, IEEE SIGNAL PROC LET, V21, P1521, DOI 10.1109/LSP.2014.2344093
   Tai GC, 2004, PAC RIM C MULT
   Tzung-Her Chen, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P353, DOI 10.1109/IIH-MSP.2009.135
   Ulutas M, 2010, MATH PROBL ENG, V2010, DOI 10.1155/2010/593236
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wang S, 2016, MULTIMED TOOLS APPL, V75, P3353, DOI 10.1007/s11042-014-2438-8
   Wang ZM, 2006, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2006.312384
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Wang ZM, 2006, P EUSIPCO, P2006
   Xiong L, 2015, CRYPTANALYSIS DYNAMI, V28, P374
   Yamaguchi Y, 2014, P T DAT HID MULT SEC, VIX, P25, DOI [10.1007/978-3-642-55046-1_2, DOI 10.1007/978-3-642-55046-1_2]
   Yan B, 2016, MULTIMED TOOLS APPL, V75, P11157, DOI 10.1007/s11042-015-2838-4
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yan XH, 2015, SIGNAL PROCESS, V109, P317, DOI 10.1016/j.sigpro.2014.12.002
   Yang CN, 2007, INT J PATTERN RECOGN, V21, P879, DOI 10.1142/S0218001407005740
   Yang CN, 2016, J REAL-TIME IMAGE PR, V12, P483, DOI 10.1007/s11554-015-0511-9
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
   Yang CN, 2005, LECT NOTES COMPUT SC, V3656, P1184, DOI 10.1007/11559573_143
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang CN, 2016, INT C IND IOT TECHN
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 63
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1315
EP 1344
DI 10.1007/s11042-018-6158-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700005
DA 2024-07-18
ER

PT J
AU Shao, X
   Cheng, ZY
   Kankanhalli, MS
AF Shao, Xi
   Cheng, Zhiyong
   Kankanhalli, Mohan S.
TI Music auto-tagging based on the unified latent semantic modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music tag; Latent semantic analysis; Music recommendation
ID LEAST-SQUARES
AB We proposed a music auto-tagging approach based on the latent space modeling both for music context and content. First, we introduce the latent semantic analysis for music tags with Sparse Nonnegative Matrix Factorization. Then the music contents semantics will be learnt by decomposing the music content into a pre-trained dictionary and an adaptive dictionary learning algorithm is proposed. Finally, the two latent spaces will be associated with a certain subspace mapping algorithm. The experimental results show that our proposed approach outperforms the state-of-the-art auto-tagging systems when applied to the CAL500 dataset in the 5-fold cross-validation experiments.
C1 [Shao, Xi] Nanjing Univ Posts & Telecommun, Coll Commun & Informat Engn, 172,66 Xinmofan Rd, Nanjing 210003, Jiangsu, Peoples R China.
   [Shao, Xi; Cheng, Zhiyong; Kankanhalli, Mohan S.] Natl Univ Singapore, Sch Comp, Singapore 119613, Singapore.
C3 Nanjing University of Posts & Telecommunications; National University of
   Singapore
RP Shao, X (corresponding author), Nanjing Univ Posts & Telecommun, Coll Commun & Informat Engn, 172,66 Xinmofan Rd, Nanjing 210003, Jiangsu, Peoples R China.; Shao, X (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 119613, Singapore.
EM shaoxi@njupt.edu.cn; zhiyong.cheng@nus.edu.sg; mohan@comp.nus.edu.sg
RI shao, xi/ABE-3263-2021; Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
FU National Nature Science Foundation of China [60902065, 61401227];
   Beijing Natural Science Foundation [4152053]
FX This work is supported by the National Nature Science Foundation of
   China under Grant No. 60902065, No. 61401227, and by Beijing Natural
   Science Foundation (No.4152053).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2012, P 13 INT SOC MUS INF
   Bertin-Mahieux T, 2008, J NEW MUSIC RES, V37, P115, DOI 10.1080/09298210802479250
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Coviello E., 2012, In Advances in Neural Information Processing Systems, P404
   Coviello E, 2011, IEEE T AUDIO SPEECH, V19, P1343, DOI 10.1109/TASL.2010.2090148
   Domingues MA, 2013, INT J MULTIMED INF R, V2, P3, DOI 10.1007/s13735-012-0025-1
   Ellis K, 2013, IEEE T AUDIO SPEECH, V21, P2554, DOI 10.1109/TASL.2013.2279318
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   He XF, 2004, ADV NEUR IN, V16, P153
   Hoffman MatthewD., 2009, Proceedings of the 10th International Symposium on Music Information Retrieval, P369
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134
   Knees P, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542206
   Lamere P, 2008, J NEW MUSIC RES, V37, P101, DOI 10.1080/09298210802479284
   Levy M, 2008, J NEW MUSIC RES, V37, P137, DOI 10.1080/09298210802479292
   Li T, 2003, 2003 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS PROCEEDINGS, P143
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mandel M.I., 2008, P INT SOC MUSIC INFO, P577
   Min W, 2017, IEEE T MULTIMED, P1
   Min WQ, 2014, IEEE MULTIMEDIA, V21, P20, DOI 10.1109/MMUL.2014.1
   Miotto R, 2012, IEEE T AUDIO SPEECH, V20, P1096, DOI 10.1109/TASL.2011.2172423
   Panagakis Y, 2012, INT CONF ACOUST SPEE, P497, DOI 10.1109/ICASSP.2012.6287925
   Schedl M, 2013, P 21 ACM INT C MULT, P1117
   Schedl M, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P793
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Xie Bo., 2011, ISMIR, P711
NR 28
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 161
EP 176
DI 10.1007/s11042-018-5632-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500009
DA 2024-07-18
ER

PT J
AU Wu, JH
   Huang, F
   Hu, WJ
   He, W
   Tu, B
   Guo, LY
   Ou, XF
   Zhang, GY
AF Wu, Jianhui
   Huang, Feng
   Hu, Wenjing
   He, Wei
   Tu, Bing
   Guo, Longyuan
   Ou, Xianfeng
   Zhang, Guoyun
TI Study of multiple moving targets' detection in fisheye video based on
   the moving blob model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple moving targets; fisheye system; moving blob model; algorithm
   design
ID CAMERA; TRACKING; LENS
AB This paper discussed some improved algorithms for multiple moving targets detection and tracking in fisheye video sequences which based on the moving blob model. The view field of fisheye lens achieved 183 degree which used in our system, so it has more effective in the no blind surveillance system. However, the fisheye image has a big distortion that makes it difficult to achieve an intelligent function. In this paper we try to establish a moving blob model to detect and track multiple moving targets in the fisheye video sequences, in order to achieve the automation and intelligent ability for no blind surveillance system. It is divided into three steps. Firstly, the distortion model of fisheye lens was established, we are discussing the character of the imaging principle of fisheye lens, and calculate the distortion coefficient which can be used in the moving blob model. Secondly, the principle of the moving blob model was analyzed in detail which based on the fisheye distortion model. It was included four main algorithms, which the first is the traditional algorithm of background extraction; and the background updating algorithm; the algorithm of the fisheye video sequence with the background subtracted in order to get the moving blobs; the algorithm of removing the shadow of blobs in RGB space. Thirdly, we determined that every extracted blob is a real moving target by calculating the pixels with a threshold, which can discard the faulty moving targets. Lastly, we designed the algorithm for tracking the moving targets based on the moving blobs selected through calculating the geometry center. The experiment indicated that every algorithm has a better processing efficiency of multiple moving targets in fisheye video sequences. Compared the traditional algorithm, the improved algorithm can be detected the moving target in a circular fisheye image effectively and stably.
C1 [Wu, Jianhui; Huang, Feng; Hu, Wenjing; He, Wei; Tu, Bing; Guo, Longyuan; Ou, Xianfeng; Zhang, Guoyun] Coll Informat & Commun Engn, Key Lab Optimizat & Control Complex Syst, Shanghai, Peoples R China.
   [Wu, Jianhui; Huang, Feng; Hu, Wenjing; He, Wei; Tu, Bing; Guo, Longyuan; Ou, Xianfeng; Zhang, Guoyun] Hunan Inst Sci & Technol, Res Ctr Heterogeneous Comp & Its Applicat, Yueyang 414006, Hunan, Peoples R China.
C3 Hunan Institute of Science & Technology
RP Ou, XF; Zhang, GY (corresponding author), Coll Informat & Commun Engn, Key Lab Optimizat & Control Complex Syst, Shanghai, Peoples R China.; Ou, XF; Zhang, GY (corresponding author), Hunan Inst Sci & Technol, Res Ctr Heterogeneous Comp & Its Applicat, Yueyang 414006, Hunan, Peoples R China.
EM ouxf@hnist.edu.cn; gyzhang@hnist.edu.cn
FU Hunan Provincial Natural Science Foundation [2016JJ2064, 2017JJ3099];
   Open Fund of Education Department of Hunan Province [15K051]; Research
   Fund of Science and Technology Program of Hunan Province [2016TP1021];
   Fund of Education Department of Hunan Province [16C0723]
FX We should like to acknowledge that this work was supported in part by
   the Hunan Provincial Natural Science Foundation (2016JJ2064,
   2017JJ3099), and the Open Fund of Education Department of Hunan
   Province(15K051). The experiment of this work also was supported in part
   by the Research Fund of Science and Technology Program of Hunan Province
   (2016TP1021) and Fund of Education Department of Hunan
   Province(16C0723). Its contents are solely the responsibility of the
   authors and do not necessarily represent the official views. At the same
   time, we are thanks to provide lots of experimental support by the
   Research Center for Heterogeneous Computing and Applications, Hunan
   Institute of Science and Technology.
CR Bellas N, 2009, ANN IEEE SYM FIELD P, P149, DOI 10.1109/FCCM.2009.16
   Chahooki M, 2016, COMPUT SYST SCI ENG, V31
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Ding Y, 2017, MULTIMED TOOLS APPL, V76, P22979, DOI 10.1007/s11042-016-4184-6
   Du H, 2016, IEEE ACCESS, V4, P8987, DOI 10.1109/ACCESS.2016.2632724
   Gennery DB, 2006, INT J COMPUT VISION, V68, P239, DOI 10.1007/s11263-006-5168-1
   Hughes C, 2010, IEEE T PATTERN ANAL, V32, P2289, DOI 10.1109/TPAMI.2010.159
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Kweon GI, 2008, J OPT SOC KOREA, V12, P79, DOI 10.3807/JOSK.2008.12.2.079
   Li J, 2010, J SYST ENG ELECTRON, V21, P740, DOI 10.3969/j.issn.1004-4132.2010.05.004
   Lin CC, 2012, SENSORS-BASEL, V12, P4431, DOI 10.3390/s120404431
   [Liu Bo 刘勃], 2004, [中国科学技术大学学报, Journal of University of Science and Technology of China], V34, P599
   Mitiche A, 2004, IEEE T IMAGE PROCESS, V13, P848, DOI 10.1109/TIP.2004.827235
   Nielsen F, 2005, VISUAL COMPUT, V21, P92, DOI 10.1007/s00371-004-0273-z
   [钱永青 Qian Yongqing], 2010, [计算机工程与科学, Computer Engineering and Science], V32, P81
   Song HZ, 2013, SCI CHINA INFORM SCI, V5, P115
   Tu LF, 2014, J CENT SOUTH UNIV, V21, P2306, DOI 10.1007/s11771-014-2182-2
   Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2
   Wei J, 2012, IEEE T VIS COMPUT GR, V18, P1771, DOI 10.1109/TVCG.2011.130
   Wu JH, 2014, COMM COM INF SC, V484, P255
   Yin HP, 2011, J SYST ENG ELECTRON, V22, P587, DOI 10.3969/j.issn.1004-4132.2011.04.006
   Ying Xiang-Hua, 2003, Chinese Journal of Computers, V26, P1702
   Yuan X, 2011, CHIN OPT LETT, V2, P37
   Zhang BY, 2014, IEEE COMPUT SOC CONF, P676, DOI 10.1109/CVPRW.2014.103
   Zhang ZK, 2011, J SYST ENG ELECTRON, V22, P760, DOI 10.3969/j.issn.1004-4132.2011.05.006
NR 25
TC 5
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 877
EP 896
DI 10.1007/s11042-018-5763-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500050
DA 2024-07-18
ER

PT J
AU Ho, N
   Wong, PM
   Chua, M
   Chui, CK
AF Ho, Nicholas
   Wong, Pooi-Mun
   Chua, Matthew
   Chui, Chee-Kong
TI Virtual reality training for assembly of hybrid medical devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive training environment; Virtual reality; Virtual assembly
   workcell; Hybrid medical device; Assembly training
ID TRACHEAL PROSTHESIS; SYSTEM; REHABILITATION; SIMULATION; TECHNOLOGIES;
   OPERATIONS; SURGERY; SAFETY; SKILLS; MODEL
AB Skill training in the medical device manufacturing industry is essential to optimize and expedite the efficiency level of new workers. This process, however, gives rise to many underlying issues such as contamination and safety risks, long training period, high skill and experience requirements of operators, and greater training costs. In this paper, we proposed and evaluated a novel virtual reality (VR) training system for the assembly of hybrid medical devices. The proposed system, which is an integration of Artificial Intelligence (AI), VR and gaming concepts, is self-adaptive and autonomous. This enables the training to take place in a virtual workcell environment without the supervision of a physical trainer. In this system, a sequential framework is proposed and utilized to enhance the training through its various game levels of familiarity-building processes. A type of hybrid medical device: carbon nanotubes-polydimethylsiloxane (CNT-PDMS) based artificial trachea prosthesis is used as a case study in this paper to demonstrate the effectiveness of the proposed system. Evaluation results with quantitative and qualitative comparisons demonstrated that our proposed training method has significant advantages over common VR training and conventional training methods. The proposed system has addressed the underlying training issues for hybrid medical device assembly by providing trainees with effective, efficient, risk-free and low cost training.
C1 [Ho, Nicholas; Wong, Pooi-Mun; Chui, Chee-Kong] Natl Univ Singapore, Dept Mech Engn, 9 Engn Dr 1, Singapore 117576, Singapore.
   [Chua, Matthew] Natl Univ Singapore, Inst Syst Sci, 25 Heng Mui Keng Terrace, Singapore 119615, Singapore.
C3 National University of Singapore; National University of Singapore
RP Ho, N (corresponding author), Natl Univ Singapore, Dept Mech Engn, 9 Engn Dr 1, Singapore 117576, Singapore.
EM e0013180@u.nus.edu
RI Chua, Matthew/P-6434-2014
OI Matthew, Chua/0000-0002-5200-5079; Ho, Nicholas/0000-0001-7522-2984
FU MOE FRC Tier 1 Grant from National University of Singapore [WBS:
   R-265-000-614-114]
FX We wish to acknowledge the contributions from Mr. Rahul Singh Chauhan,
   Mr. Jayendra Laxman Zambre and Mr. Ritesh Kumar Agrahari for their
   assistance in the development of the VR systems. This project is
   supported in parts by a MOE FRC Tier 1 Grant from National University of
   Singapore (WBS: R-265-000-614-114).
CR Alamri A, 2008, IEEE T INSTRUM MEAS, V57, P1876, DOI 10.1109/TIM.2008.919878
   Albert DE, 2015, DEV SURFACE CONTAMIN, P109
   Boian R, 2002, STUD HEALTH TECHNOL, V85, P64
   Borst CW, 2006, PRESENCE-VIRTUAL AUG, V15, P47, DOI 10.1162/pres.2006.15.1.47
   Brough John E., 2007, Virtual Reality, V11, P189, DOI 10.1007/s10055-007-0076-4
   Chua M, 2013, 7 IEEE INT C NAN MED
   Chua M, 2015, INT J ARTIF ORGANS, V38, P31, DOI 10.5301/ijao.5000374
   Chua M, 2013, IEEE NANOTECHNOL MAG, V7, P27, DOI 10.1109/MNANO.2013.2289691
   Ciurana J, 2014, INT J COMPUT INTEG M, V27, P901, DOI 10.1080/0951192X.2014.934292
   Ciuti G, 2015, SENSORS-BASEL, V15, P6441, DOI 10.3390/s150306441
   Connolly J, 2018, IEEE SENS J, V18, P1273, DOI 10.1109/JSEN.2017.2776262
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Gallagher AG, 2002, SURG ENDOSC, V16, P1746, DOI 10.1007/s00464-001-8215-6
   Gislen L, 2016, THESIS
   Grantcharov TP, 2004, BRIT J SURG, V91, P146, DOI 10.1002/bjs.4407
   He YF, 2017, MULTIMED TOOLS APPL, V76, P1479, DOI 10.1007/s11042-015-3121-4
   Ho N, 2017, 3 CIRP C BIOM CHIC
   Hoedt S, 2016, IFAC PAPERSONLINE, V49, P261, DOI 10.1016/j.ifacol.2016.07.614
   Hoeji P, 2015, 25 DAAAM INT S INT M
   Hyppola J, 2014, 4 GLOB C EXP LEARN V
   Jayaram Sankar, 2007, Virtual Reality, V11, P217, DOI 10.1007/s10055-007-0070-x
   Kiliboz NÇ, 2015, J VIS COMMUN IMAGE R, V28, P97, DOI 10.1016/j.jvcir.2015.01.015
   Kizony R, 2005, J REHABIL RES DEV, V42, P595, DOI 10.1682/JRRD.2005.01.0023
   König J, 2013, LABOUR-ENGL, V27, P351, DOI 10.1111/labr.12018
   Kusuda Y, 2010, ASSEMBLY AUTOM, V30, P306, DOI 10.1108/01445151011075753
   Langley A, 2016, HUM FACTOR ERGON MAN, V26, P667, DOI 10.1002/hfm.20406
   Lawson Mark V, 2003, Finite Automata
   Liu Y, 2016, P 24 INT JOINT C ART
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lucke L., 2009, Journal of Medical Devices, V3, DOI 10.1115/1.3147388
   Manjiyani Z.A. A., 2014, INT J SCI RES PUBLIC, V4, P1
   Muller BC, 2016, 13 GLOB C SUST MAN D
   Nee A.Y., 2013, IFAC P VOLUMES, V46, P15, DOI [10.3182/20130619-3-RU-3018.00637, DOI 10.3182/20130619-3-RU-3018.00637]
   Nerem R. M., 2007, TISSUE ENG, V1, P3, DOI DOI 10.1089/ten.1995.1.3
   Neto P, 2013, IECON 2013
   Pilia A, 2015, FUSION ENG DES, V98-99, P1589, DOI 10.1016/j.fusengdes.2015.06.168
   Premkumar T, 2012, PROG POLYM SCI, V37, P515, DOI 10.1016/j.progpolymsci.2011.08.003
   Rahni A. A. A., 2007, P AS PAC C APPL EL D, P1
   Rodriguez L, 2015, PROCEDIA COMPUT SCI, V75, P327, DOI 10.1016/j.procs.2015.12.254
   Rose P., 2014, WHITEPAPER CONTAMINA
   Sahithi K, 2010, INT J BIOL MACROMOL, V46, P281, DOI 10.1016/j.ijbiomac.2010.01.006
   Saposnik G, 2011, STROKE, V42, P1380, DOI 10.1161/STROKEAHA.110.605451
   Schwaitzberg SD, 2016, SURG ENDOSC, V30, P190, DOI 10.1007/s00464-015-4182-1
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Shirke S., 2013, INT J ENG RES TECHNO, V2, P3124
   Stancin S, 2011, SENSORS-BASEL, V11, P8536, DOI 10.3390/s110908536
   Stratos A, 2016, 49 CIRP C MANUFACTUR
   STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916
   Suzuki Naoki, 2012, Augmented Environments for Computer-Assisted Interventions. 6th International Workshop, AE-CAI 2011. Held in Conjunction with MICCAI 2011. Revised Selected Papers, P117, DOI 10.1007/978-3-642-32630-1_12
   Tang ZY, 2015, ADV BIOMED ENG, V4, P135, DOI 10.14326/abe.4.135
   Vaughan N, 2016, COMPUT SCI REV, V22, P65, DOI 10.1016/j.cosrev.2016.09.001
   Wang Y, 2018, MED BIOL ENG COMPUT, V56, P25, DOI 10.1007/s11517-017-1666-2
   Wasfy A, 2004, ADV ENG SOFTW, V35, P337, DOI 10.1016/j.advengsoft.2004.04.005
   Xia PJ, 2012, INT J ADV MANUF TECH, V58, P379, DOI 10.1007/s00170-011-3381-8
   Yang Q, 2013, COMPUT IND, V64, P869, DOI 10.1016/j.compind.2013.06.001
   Yu Y, 2017, SHIPS OFFSHORE STRUC, V12, P873, DOI 10.1080/17445302.2017.1293762
   Yuviler-Gavish N, 2013, ERGON DES, V21, P12, DOI 10.1177/1064804612463214
   Zhou JL, 2010, IEEE T INSTRUM MEAS, V59, P2496, DOI 10.1109/TIM.2010.2057712
NR 59
TC 29
Z9 31
U1 1
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30651
EP 30682
DI 10.1007/s11042-018-6216-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600024
DA 2024-07-18
ER

PT J
AU Taheri, AM
   Mahdavi-Nasab, H
AF Taheri, Amir Masoud
   Mahdavi-Nasab, Homayoun
TI Sparse representation based facial image compression via multiple
   dictionaries and separated ROI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Image compression; Dictionary learning; RLS-DLA;
   JPEG2000; ROI
ID LINEAR INVERSE PROBLEMS; ACTIVE CONTOURS; K-SVD; ALGORITHM;
   SUPERRESOLUTION; SYSTEMS
AB Constant increasing of visual information necessitates most efficient image compression schemes for saving storage space or reducing required transmission bandwidth. In compressing a class of images, such as a fingerprint database, facial images of an organization or MR images of a hospital, overall information redundancy is increased and compression becomes more significant. In this paper, image signal sparse representation and RLS-DLA dictionary design are utilized for compressing whole or part of a facial image database by exploiting the structural similarity of the class members. In the proposed algorithm, images are compressed by multiple overcomplete learned dictionaries which are designed to provide least required bit-rates for different target qualities. To fortify the process, more interested head and shoulders regions of the images are extracted to provide dictionary training sets. A combined edge detection and active contour segmentation method is used for a robust ROI extraction. Simulation results show superior performance of about 0.3 to 1.5 dB quality enhancement in terms of PSNR, for similar compression ratios compared to JPEG2000 standard for the complete image, and a near loss-less compression for restoring the ROI.
C1 [Taheri, Amir Masoud; Mahdavi-Nasab, Homayoun] Islamic Azad Univ, Najafabad Branch, Dept Elect Engn, Najafabad, Iran.
   [Mahdavi-Nasab, Homayoun] Islamic Azad Univ, Najafabad Branch, Digital Proc & Machine Vis Res Ctr, Najafabad, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Mahdavi-Nasab, H (corresponding author), Islamic Azad Univ, Najafabad Branch, Dept Elect Engn, Najafabad, Iran.; Mahdavi-Nasab, H (corresponding author), Islamic Azad Univ, Najafabad Branch, Digital Proc & Machine Vis Res Ctr, Najafabad, Iran.
EM a.m.taheri1984@gmail.com; mahdavinasab@iaun.ac.ir
RI Mahdavi-Nasab, Homayoun/AAN-3772-2021
OI Mahdavi-Nasab, Homayoun/0000-0003-2992-8657
CR Agarwal A., 2014, COLT, P123
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1
   [Anonymous], 1998 P 1998 IEEE INT
   Blake A.Isard., 2012, Active Contours: The Application of Techniques from Graphics, Vision, Control Theory and Statistics to Visual Tracking of Shapes in Motion
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Bryt Ori, 2008, 2008 IEEE 25th Convention of Electrical and Electronics Engineers in Israel (IEEEI), P533, DOI 10.1109/EEEI.2008.4736586
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Elad M, 2012, IEEE SIGNAL PROC LET, V19, P922, DOI 10.1109/LSP.2012.2224655
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Engan K., 1999, P IEEE INT C AC SPEE, V5
   He N, 2016, MULTIMED TOOLS APPL, V75, P2579, DOI 10.1007/s11042-015-2471-2
   Horev I., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P592
   Jiang JJ, 2014, J SIGNAL PROCESS SYS, V75, P245, DOI 10.1007/s11265-013-0804-9
   Liu ET, 2012, IEEE T INFORM THEORY, V58, P2040, DOI 10.1109/TIT.2011.2177632
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nejati M, 2016, IEEE T IMAGE PROCESS, V25, P4900, DOI 10.1109/TIP.2016.2598483
   Ram I, 2014, IEEE SIGNAL PROC LET, V21, P1270, DOI 10.1109/LSP.2014.2332276
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Shao GQ, 2014, IEEE T IMAGE PROCESS, V23, P489, DOI 10.1109/TIP.2013.2287996
   Shi YQ, 2008, IMAGE PROCESS SER, P3
   Skretting K, 2011, INT CONF ACOUST SPEE, P1517
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Sun JW, 2015, PR MACH LEARN RES, V37, P757
   Taheri AM, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P92, DOI 10.1109/IranianMVIP.2015.7397512
   Taubman David., 2012, JPEG2000 Image Compression Fundamentals, Standards and Practice
   Tosic I, 2011, IEEE SIGNAL PROC MAG, V28, P27, DOI 10.1109/MSP.2010.939537
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xing XF, 2017, MULTIMED TOOLS APPL, V76, P2039, DOI 10.1007/s11042-015-3164-6
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao PL, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P788, DOI 10.1109/FSKD.2014.6980937
   Zheng HX, 2015, J SIGNAL PROCESS SYS, V81, P99, DOI 10.1007/s11265-014-0907-y
   Zhou LY, 2014, VISUAL COMPUT, V30, P845, DOI 10.1007/s00371-014-0957-y
   Zhu JY, 2015, J VIS COMMUN IMAGE R, V31, P225, DOI 10.1016/j.jvcir.2015.07.002
NR 45
TC 6
Z9 6
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31095
EP 31114
DI 10.1007/s11042-018-6197-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600042
DA 2024-07-18
ER

PT J
AU Yang, CC
   Zhang, MF
   Zhang, ZJ
   Wei, LF
   Chen, RQ
   Zhou, HB
AF Yang, Changcai
   Zhang, Meifang
   Zhang, Zejun
   Wei, Lifang
   Chen, Riqing
   Zhou, Huabing
TI Non-rigid point set registration via global and local constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point set registration; Coherent spatial mapping; Local geometrical
   constraint
ID IMAGE REGISTRATION; PARALLEL FRAMEWORK; ROBUST; TRANSFORMATION;
   ALGORITHM; EM
AB Non-rigid point set registration is often encountered in meical image processing, pattern recognition, and computer vision. This paper presents a new method for non-rigid point set registration that can be used to recover the underlying coherent spatial mapping (CSM). Firstly, putative correspondences between two point sets are established by using feature descriptors. Secondly, each point is expressed as a weighted sum of several nearest neighbors and the same relation holds after the transformation. Then, this local geometrical constraint is combined with the global model, and the transformation problem is solved by minimizing an error function. These two steps of recovering point correspondences and transformation are performed iteratively to obtained a promising result. Extensive experiments on various synthetic and real data demonstrate that the proposed approach is robust and outperforms the state-of-the-art methods.
C1 [Yang, Changcai] Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Digital Fujian Res Inst Big Data Agr & Forestry, Fuzhou 350002, Fujian, Peoples R China.
   [Zhang, Meifang] Fujian Hlth Coll, Fuzhou 350101, Fujian, Peoples R China.
   [Zhang, Zejun; Wei, Lifang; Chen, Riqing] Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Fujian, Peoples R China.
   [Zhou, Huabing] Wuhan Inst Technol, Wuhan 430073, Hubei, Peoples R China.
C3 Fujian Agriculture & Forestry University; Fujian Agriculture & Forestry
   University; Wuhan Institute of Technology
RP Chen, RQ (corresponding author), Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Fujian, Peoples R China.
EM changcaiyang@gmail.com; zjzhang_fafu@163.com; mfzhang85@163.com;
   weilifang0028@fafu.edu.cn; riqing.chen@fafu.edu.cn;
   zhouhuabing@gmail.com
RI Zhang, Zejun/IRZ-3618-2023; Wei, Lifang/HGV-2770-2022; Yang,
   Changcai/AAI-4951-2020
OI Wei, Lifang/0000-0001-6358-0274; 
FU National Natural Science Foundation of China [61501120, 41501505]; 2016
   Outstanding Youth Research Talent Cultivation Program in Colleges and
   Universities in Fujian Province
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant 61501120 and 41501505 and in part by
   2016 Outstanding Youth Research Talent Cultivation Program in Colleges
   and Universities in Fujian Province.
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bishop C, 2006, PATTERN RCOGNITION M
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   CARPANETO G, 1980, ACM T MATH SOFTWARE, V6, P104, DOI 10.1145/355873.355883
   Chen J, 2015, SIGNAL PROCESS, V106, P62, DOI 10.1016/j.sigpro.2014.07.004
   Chen L, 2015, BIOMED SIGNAL PROCES, V16, P22, DOI 10.1016/j.bspc.2014.10.009
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Du SY, 2017, MULTIMED TOOLS APPL, V76, P12065, DOI 10.1007/s11042-016-4018-6
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Grace, 1990, SPLINE MODELS OBSERV
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lian W., 2012, P EUR C COMP VIS
   Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058
   Ma JY, 2018, IEEE T GEOSCI REMOTE, V56, P4435, DOI 10.1109/TGRS.2018.2820040
   Ma JY, 2017, AAAI CONF ARTIF INTE, P4218
   Ma JY, 2017, INFORM SCIENCES, V417, P128, DOI 10.1016/j.ins.2017.07.010
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Ma JY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092282
   Ma JY, 2013, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2013.279
   Ma JY, 2013, PATTERN RECOGN, V46, P3519, DOI 10.1016/j.patcog.2013.05.017
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81
NR 34
TC 12
Z9 12
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31607
EP 31625
DI 10.1007/s11042-018-6206-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000004
DA 2024-07-18
ER

PT J
AU Liu, JJ
   Liu, WQ
   Ma, SW
   Lu, C
   Xiu, XC
   Pathirage, N
   Li, L
   Chen, GH
   Zeng, WM
AF Liu, Jingjing
   Liu, Wanquan
   Ma, Shiwei
   Lu, Chong
   Xiu, Xianchao
   Pathirage, Nadith
   Li, Ling
   Chen, Guanghua
   Zeng, Weimin
TI Face recognition based on manifold constrained joint sparse sensing with
   K-SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Manifold constraints; K-SVD dictionary learning;
   Joint sparse representation
ID APPROXIMATED NEAREST POINTS; SINGLE-SAMPLE; IMAGE; REPRESENTATION;
   CLASSIFICATION
AB Face recognition based on Sparse representation idea has recently become an important research topic in computer vision community. However, the dictionary learning process in most of the existing approaches suffers from the perturbations brought by the variations of the input samples, since the consistence of the learned dictionaries from similar input samples based on K-SVD are not well addressed in the existing literature. In this paper, we will propose a novel technique for dictionary learning based on K-SVD to address the consistence issue. In particular, the proposed method embeds the manifold constraints into a standard dictionary learning framework based on k-SVD and force the optimization process to satisfy the structure preservation requirement. Therefore, this new approach can consistently integrate the manifold constraints during the optimization process, and it can contribute a better solution which is robust to the variance of the input samples. Extensive experiments on several popular face databases show a consistent performance improvement in comparison to some related state-of-the-art algorithms.
C1 [Liu, Jingjing; Ma, Shiwei; Chen, Guanghua; Zeng, Weimin] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
   [Liu, Wanquan; Pathirage, Nadith; Li, Ling] Curtin Univ, Dept Comp, Perth, WA, Australia.
   [Lu, Chong] Xinjiang Vocat & Tech Coll Commun, Urumqi 831401, Peoples R China.
   [Xiu, Xianchao] Beijing Jiaotong Univ, Dept Appl Math, Beijing, Peoples R China.
C3 Shanghai University; Curtin University; Beijing Jiaotong University
RP Liu, WQ (corresponding author), Curtin Univ, Dept Comp, Perth, WA, Australia.
EM Liu.jingjing@shu.edu.cn; W.Liu@curtin.edu.au; masw@shu.edu.cn;
   18699928908@163.com
RI Huang, Liping/KIB-4430-2024; zhu, yujie/KBC-4009-2024; Zhao,
   YuHan/KIE-0813-2024
OI Li, Ling/0000-0001-9722-9503; liu, wanquan/0000-0003-4910-353X
FU National Natural Science Foundation of China [61671285, 61363066,
   11671029, 61603211]
FX This work was partially supported by the National Natural Science
   Foundation of China with Grant Nos. 61671285, 61363066, 11671029 and
   61603211.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], [No title captured]
   [Anonymous], IEEE J SELECTED TOPI
   [Anonymous], IEEE J SEL TOPICS SI
   [Anonymous], FAST SOLUTION NORM M
   [Anonymous], 1999, GEORGIA TECH FACE DA
   [Anonymous], 2018, IEEE Photonics J
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Chen YC, 2012, LECT NOTES COMPUT SC, V7577, P766, DOI 10.1007/978-3-642-33783-3_55
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Ding RX, 2015, J VIS COMMUN IMAGE R, V30, P35, DOI 10.1016/j.jvcir.2015.03.001
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Gao SH, 2015, INT J COMPUT VISION, V111, P365, DOI 10.1007/s11263-014-0750-4
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Hadid A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P813, DOI 10.1109/AFGR.2004.1301634
   Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   Huang LK, 2014, IEEE SIGNAL PROC LET, V21, P875, DOI 10.1109/LSP.2014.2319817
   Huang SM, 2013, IEEE SIGNAL PROC LET, V20, P91, DOI 10.1109/LSP.2012.2230257
   Kan MN, 2013, PATTERN RECOGN, V46, P2497, DOI 10.1016/j.patcog.2013.01.037
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Li XX, 2014, COMPUT STAT DATA AN, V79, P203, DOI 10.1016/j.csda.2014.05.017
   Li ZM, 2016, IEEE T INF FOREN SEC, V11, P2203, DOI 10.1109/TIFS.2016.2567318
   Liu JJ, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P426, DOI 10.1109/FSKD.2016.7603211
   Long MS, 2013, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.2013.59
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Luo XY, 2016, IEEE SW SYMP IMAG, P133, DOI 10.1109/SSIAI.2016.7459193
   Meina Kan, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P193, DOI 10.1109/FG.2011.5771397
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Rakotomamonjy A, 2011, SIGNAL PROCESS, V91, P1505, DOI 10.1016/j.sigpro.2011.01.012
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang R, 2008, CVPR 2008 IEEE C COM, P1
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wang ZW, 2013, IEEE I CONF COMP VIS, P1217, DOI 10.1109/ICCV.2013.154
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zhang BC, 2015, PROC CVPR IEEE, P4557, DOI 10.1109/CVPR.2015.7299086
   Zhang HC, 2012, PATTERN RECOGN, V45, P1290, DOI 10.1016/j.patcog.2011.09.009
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang X, 2015, PATTERN RECOGN, V48, P2935, DOI 10.1016/j.patcog.2015.02.022
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhuang LS, 2015, INT J COMPUT VISION, V114, P272, DOI 10.1007/s11263-014-0749-x
NR 58
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28863
EP 28883
DI 10.1007/s11042-018-6071-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500045
DA 2024-07-18
ER

PT J
AU Petscharnig, S
   Schöffmann, K
AF Petscharnig, Stefan
   Schoeffmann, Klaus
TI Binary convolutional neural network features off-the-shelf for image to
   video linking in endoscopic multimedia databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video retrieval; Endoscopic multimedia; CNNs
ID COLOR
AB With a rigorous long-term archival of endoscopic surgeries, vast amounts of video and image data accumulate. Surgeons are not able to spend their valuable time to manually search within endoscopic multimedia databases (EMDBs) or manually maintain links to interesting sections in order to quickly retrieve relevant surgery sections. Enabling the surgeons to quickly access the relevant surgery scenes, we utilize the fact that surgeons record external images additionally to the surgery video and aim to link them to the appropriate video sequence in the EMDB using a query-by-example approach. We propose binary Convolutional Neural Network (CNN) features off-the-shelf and compare them to several baselines: pixel-based comparison (PSNR), image structure comparison (SSIM), hand-crafted global features (CEDD and feature signatures), as well as CNN baselines Histograms of Class Confidences (HoCC) and Neural Codes (NC). For evaluation, we use 5.5 h of endoscopic video material and 69 query images selected by medical experts and compare the performance of the aforementioned image mathing methods in terms of video hit rate and distance to the true playback time stamp (PTS) for correct video predictions. Our evaluation shows that binary CNN features are compact, yet powerful image descriptors for retrieval in the endoscopic imaging domain. They are able to maintain state-of-the-art performance, while providing the benefit of low storage space requirements and hence provide the best compromise.
C1 [Petscharnig, Stefan; Schoeffmann, Klaus] Alpen Adria Univ Klagenfurt, Univ Str 65-67, A-9020 Klagenfurt Am Worthersee, Austria.
RP Petscharnig, S (corresponding author), Alpen Adria Univ Klagenfurt, Univ Str 65-67, A-9020 Klagenfurt Am Worthersee, Austria.
EM stefan.petscharnig@itec.aau.at; ks@itec.aau.at
OI Petscharnig, Stefan/0000-0003-2791-7110
FU University of Klagenfurt
FX Open access funding provided by University of Klagenfurt.
CR [Anonymous], 2008, P 16 INT C MULTIMEDI, DOI [DOI 10.1145/1459359.1459577, 10.1145/1459359.1459577]
   [Anonymous], 2014, CONT BAS MULT IND CB, DOI DOI 10.1109/CBMI.2014.6849821
   Awad G., 2016, Proceedings of TRECVID, V2016
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Beecks C, 2015, IEEE P INT S MULT MI, P1
   Bois R, 2017, EXPLOITING MULTIMODA, P185
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   BVLC, 2016, CAFF MOD ZOO
   Carlos JR, 2015, 2015 13 INT WORKSH C, P1
   Chandrasekhar V, 2016, SIGNAL PROCESS, V128, P426, DOI 10.1016/j.sigpro.2016.05.021
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Cheng Z, 2015, CMU SMU TRECVID 2015
   Ercoli S, 2017, IEEE T MULTIMEDIA, V19, P2521, DOI 10.1109/TMM.2017.2697824
   Eskevich M, 2014, SEARCH HYPERLINKING
   Galuscáková P, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P299, DOI 10.1145/3078971.3079026
   Guo J, 2015, ARXIV150901354
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lokoc J., 2011, Proceedings of the Fourth International Conference on SImilarity Search and Applications, SISAP'11, P9, DOI DOI 10.1145/1995412.1995417
   Münzer B, 2013, IEEE INT SYM MULTIM, P84, DOI 10.1109/ISM.2013.22
   OpenCV, 2015, Open source computer vision library
   Petscharnig S, 2018, MULTIMED TOOLS APPL, V77, P8061, DOI 10.1007/s11042-017-4699-5
   Petscharnig S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095737
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Schoeffmann K, 2016, CONTENT BASED RETRIE
   Schoeffmann K, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1957, DOI 10.1145/3123266.3130142
   Simon AR, 2015, TRECVID 2015 WORKSH
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Vukotic V., 2016, P 2016 ACM WORKSH VI, P37
   Vukotic V, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P421, DOI 10.1145/3078971.3079038
   Vukotic V, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P343, DOI 10.1145/2911996.2912064
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 35
TC 7
Z9 7
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28817
EP 28842
DI 10.1007/s11042-018-6016-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500043
OA hybrid
DA 2024-07-18
ER

PT J
AU Vo, PH
   Nguyen, TS
   Huynh, VT
   Do, TN
AF Vo, Phuoc-Hung
   Nguyen, Thai-Son
   Huynh, Van-Thanh
   Do, Thanh-Nghi
TI A novel reversible data hiding scheme with two-dimensional histogram
   shifting mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible; Data hiding; DCT; 2D histogram shifting; Stereo image; 3D
   image
ID WATERMARKING TECHNIQUE; JPEG IMAGES; DOMAIN
AB In this paper, we propose a novel reversible data hiding technique based on two-dimensional histogram shifting for quantized discrete cosine transformation coefficients (QDCT). In the proposed scheme, a two-dimensional histogram is constructed by QDCT coefficients blocks with the size of 8 x 8 of the left image and the right image. Once most of the QDCT coefficients are located at the top-right corner of the two-dimensional histogram, the QDCT coefficients are selected for embedding data to achieve high embedding capacity. In the embedding procedure, the three main steps, i.e., expanding, shifting, and embedding, are only used for QDCT coefficients in this corner not only to gain embedding capacity, but also to maintain good visual quality of stego images. The experimental results demonstrated that the proposed scheme is superior to the previous schemes in terms of embedding capacity and image quality.
C1 [Vo, Phuoc-Hung; Nguyen, Thai-Son; Huynh, Van-Thanh] Tra Vinh Univ, Sch Engn & Technol, Tra Vinh City, Tra Vinh Provin, Vietnam.
   [Vo, Phuoc-Hung; Do, Thanh-Nghi] Can Tho Univ, Coll Informat Technol, Can Tho 92100, Vietnam.
C3 Tra Vinh University; Can Tho University
RP Nguyen, TS (corresponding author), Tra Vinh Univ, Sch Engn & Technol, Tra Vinh City, Tra Vinh Provin, Vietnam.
EM hungvo@tvu.edu.vn; thaison@tvu.edu.vn; hvlhanh@tvu.edu.vn;
   dhighi@cit.ctu.edu.vn
RI Vo, Phuoc-Hung/AAY-2916-2021; Nguyen, Thai-Son/AGD-3594-2022; Huynh,
   Van/GSM-7997-2022; Vo, Phuoc-Hung/JAC-9657-2023
OI Nguyen, Thai-Son/0000-0001-7008-0462; Huynh,
   Van-Thanh/0000-0003-3831-4323; Vo, Phuoc-Hung/0000-0002-7653-9200
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2016.06]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2016.06
CR [Anonymous], 2015 ANN IEEE IND C
   Campisi P, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3009554
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   DES, 1999, DAT ENCR STAND
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Kumar R, 2016, MULTIMED TOOLS APPL, V75, P241, DOI 10.1007/s11042-014-2289-3
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Luo T, 2014, MULTIMED TOOLS APPL, V73, P1077, DOI 10.1007/s11042-013-1435-7
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nikolaidis A, 2015, IET IMAGE PROCESS, V9, P560, DOI 10.1049/iet-ipr.2014.0689
   Parah SA, 2018, MULTIMED TOOLS APPL, V77, P185, DOI 10.1007/s11042-016-4253-x
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, INT J ELECTRON, V104, P659, DOI 10.1080/00207217.2016.1242162
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   PUB F., 2011, ADV ENCRYPTION STAND
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Yang WC, 2015, MULTIMED TOOLS APPL, V74, P7181, DOI 10.1007/s11042-014-1958-6
NR 24
TC 8
Z9 10
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28777
EP 28797
DI 10.1007/s11042-018-5991-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500041
DA 2024-07-18
ER

PT J
AU Chen, YC
   Lee, JS
   Su, HC
AF Chen, Ying-Chin
   Lee, Jung-San
   Su, Hong-Chi
TI Selective scalable secret image sharing with adaptive pixel-embedding
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Selective; Scalable; Secret sharing; Adaptive pixel-embedding
ID SALIENT OBJECT DETECTION; STEGANOGRAPHY; SCHEME
AB Different from secret image sharing technique, the secret of a scalable secret image sharing is displayed in the way that it could be progressively recovered by a set of shares. In other word, incomplete gathering of shadows cannot be used to reconstruct the whole image S immediately. To improve the security of SSIS, Lee and Chen have designed a selective scalable secret image sharing mechanism (SSSIS) to reduce the awareness of malicious attackers. Nevertheless, the quality of Lee and Chen's scheme is not good due to the image distortion and storage overhead of static embedding. Thus, we introduce the concept of adaptive pixel-embedding into SSSIS, in which the embedded bits could be uniformly distributed in the stego image. Aside from the human vision perception, experimental results have demonstrated the superiority of new method over related works in terms of two objective indexes, including peak signal to noise ratio (PSNR) and structural similarity (SSIM).
C1 [Chen, Ying-Chin; Lee, Jung-San; Su, Hong-Chi] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Feng Chia University
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM leejs@fcu.edu.tw
OI Lee, Jung-San/0000-0001-7030-2985
CR Chang CC, 2006, PATTERN RECOGN, V39, P1155, DOI 10.1016/j.patcog.2005.12.011
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Lee JS, 2017, MULTIMED TOOLS APPL, V76, P1, DOI 10.1007/s11042-015-3011-9
   Lee JS, 2016, MULTIMED TOOLS APPL, V75, P2233, DOI 10.1007/s11042-014-2403-6
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Rao TRN, 2006, CIRC SYST SIGNAL PR, V25, P1, DOI 10.1007/s00034-005-1123-6
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
NR 17
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27107
EP 27121
DI 10.1007/s11042-018-5908-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500040
DA 2024-07-18
ER

PT J
AU Liu, YJ
   Chang, CC
AF Liu, Yanjun
   Chang, Chin-Chen
TI A turtle shell-based visual secret sharing scheme with reversibility and
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing (VSS); Turtle shell (TS) reference matrix; Visual
   quality; Reversibility; Authentication
ID CRYPTOGRAPHY
AB Visual secret sharing (VSS), also called visual cryptography, allows a secret image to be divided into several shares and the secret image can only be recovered through the collaboration of the shares. Due to high security and low computational complexity, VSS has been widely used in secure communications. In this paper, we propose the first turtle shell (TS)-based VSS scheme that shares the secret information into two meaningful shares. Firstly, a TS reference matrix is established. Then, secret information is hidden in a cover image to construct two meaningful shares with the help of TS reference matrix. The hidden secret information can be extracted without distortion if both shares are gathered and the cover image can be correctly restored by solving the location conflict problem. Moreover, an invalid share can easily be detected by the proposed scheme. Experimental results indicate that the proposed scheme provides excellent visual quality and is superior to state-of-the-art VSS schemes.
C1 [Liu, Yanjun; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
C3 Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
EM yjliu104@gmail.com; alan3c@gmail.com
RI liu, yan/HGV-1365-2022; 刘, 严君/GZL-5764-2022; Chang,
   Ching-Chun/JAN-6210-2023; liu, yan/HCI-5542-2022
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   [Anonymous], 2015, 12 LEARN TECHN C WEA
   [Anonymous], 2007, 4 IEEE GCC C EXH GUL
   [Anonymous], 1995, LECT NOTES COMPUTER
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 2008, 5 IEEE INT WORKSH SI
   [Anonymous], 2013, P 3 INT C INFORM COM
   Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang CC, 2016, IET IMAGE PROCESS, V10, P590, DOI 10.1049/iet-ipr.2015.0568
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P7865, DOI 10.1007/s11042-017-4680-3
   Chin-Chen Chang, 2010, Journal of Communications, V5, P5, DOI 10.4304/jcm.5.1.5-12
   Chin-Chen Chang, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.149
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Huynh NT, 2015, J VIS COMMUN IMAGE R, V28, P105, DOI 10.1016/j.jvcir.2015.01.011
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Yang CN, 2017, J VIS COMMUN IMAGE R, V48, P182, DOI 10.1016/j.jvcir.2017.06.012
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhi-Hui Wang, 2013, Journal of Electronic Science and Technology, V11, P44, DOI 10.3969/j.issn.1674-862X.2013.01.009
NR 29
TC 43
Z9 43
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25295
EP 25310
DI 10.1007/s11042-018-5785-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400031
DA 2024-07-18
ER

PT J
AU Samee, R
   Riaz, MM
   Ghafoor, A
AF Samee, Rida
   Riaz, M. Mohsin
   Ghafoor, Abdul
TI Adaptive interpolation and segmentation based reversible image
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive image interpolation; Prediction error expansion; Simple linear
   iterative clustering
ID MULTIPLE WATERMARKING; ROBUST
AB Reversible image watermarking schemes are used to protect ownership and copyrights of digital images. This paper proposes a novel reversible image watermarking scheme based on adaptive image interpolation, segmentation and additive prediction error expansion (PEE). Proposed interpolation comprises of weighted average of neighboring pixels by allocating higher and lower weights to less and more distant neighboring pixel values respectively. The proposed adaptive image interpolation focuses on detection of edges thus minimizing artifacts imposed by interpolation. The idea of embedding varying amount of watermark bits in different image segments has been explored. Simple linear iterative clustering (SLIC) based image segmentation is performed to separate very sharp, sharp, smooth and very smooth regions in image. Higher number of watermark bits are embedded in sharp regions by using additive prediction error expansion embedding technique. Simulations of proposed and existing techniques were performed on different images and compared using embedding capacity (EC), peak signal to noise ratio (PSNR), computational efficiency, image quality, mean square error (MSE), normalized cross correlation (NCC) and structural similarity index (SSIM). The experimental results show that proposed scheme achieves better results in terms of EC, PSNR, computational efficiency, image quality, MSE, NCC and SSIM as compared to existing techniques.
C1 [Samee, Rida; Ghafoor, Abdul] NUST, Islamabad, Pakistan.
   [Riaz, M. Mohsin] COMSATS Islamabad, CAST, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Ghafoor, A (corresponding author), NUST, Islamabad, Pakistan.
EM rida.msis12@students.mcs.edu.pk; mohsin.riaz@comsats.edu.pk;
   abdulghafoor-mcs@nust.edu.pk
RI Imran, Muhammad/AAS-9984-2021
OI Imran, Muhammad/0000-0002-7122-8454; Ghafoor, Abdul/0000-0002-6117-3656
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alavianmehr MA, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P976, DOI 10.1109/ISTEL.2012.6483128
   [Anonymous], URBAN WATER QUALITY
   [Anonymous], ANN M ASS COMP LING
   [Anonymous], J INTELLIGENT SYSTEM
   [Anonymous], 2016, CIRCUITS SYSTEMS
   [Anonymous], 2016, FUTURE GENERATION CO
   Chauhan DS, 2017, MULTIMED TOOLS APPL, P1
   Chen T, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P872, DOI 10.1109/ICACI.2012.6463294
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   El Kerek B, 2013, 2013 FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, MODELLING AND SIMULATION (AIMS 2013), P267, DOI 10.1109/AIMS.2013.49
   Jaiswal S.P., 2014, PROC INT WORKSHOP DI, P276
   Jaiswal SP, 2013, IEEE IMAGE PROC, P4540, DOI 10.1109/ICIP.2013.6738935
   Kumar M, 2016, SECUR COMMUN NETW, V9, P3703, DOI 10.1002/sec.1575
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Nagarju P, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P62, DOI 10.1109/ISSP.2013.6526875
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Solachidis V, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1023, DOI 10.1109/ICIP.2001.958300
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Zear Aditi, 2017, International Journal of Information and Computer Security, V9, P20
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 36
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26821
EP 26843
DI 10.1007/s11042-018-5890-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500027
DA 2024-07-18
ER

PT J
AU Sheela, SJ
   Suresh, KV
   Tandur, D
AF Sheela, S. J.
   Suresh, K. V.
   Tandur, Deepaknath
TI Image encryption based on modified Henon map using hybrid chaotic shift
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Confusion; Diffusion; 2D-modified Henon map; Hybrid chaotic shift
   transform
ID LOGISTIC MAP; ALGORITHM; SCHEME; CRYPTOSYSTEM; SYSTEM
AB In this paper, a new two dimensional modified Henon map (2D-MHM) which is derived from Henon map is proposed. Its chaotic performance is analyzed through bifurcation diagram, Lyapunov exponent spectrum and Lyapunov dimension. The map has broad chaotic regime over an extensive range of system parameters, maximum Lyapunov exponent and better chaotic performance when compared to existing chaotic maps. Further, a novel image cryptosystem is proposed based on 2D-MHM and sine map. The algorithm employs confusion and diffusion operations in consecutive manner which is different from traditional chaos based cryptosystems. Hybrid chaotic shift transform (HCST) is introduced to perform confusion operation which is controlled by 2D-MHM. The principle of diffusion is achieved by using chaotic matrix generated from sine map and exclusive or (XOR) operation. Extensive simulation results and performance analysis demonstrate that the proposed image cryptosystem is able to resist various cryptanalytic attacks. Furthermore, the comparison results reveal that the algorithm outperforms traditional and existing encryption schemes. The proposed algorithm is also applicable for speech signals and data encryption of other multimedia.
C1 [Sheela, S. J.] Siddaganga Inst Technol, Cryptog, Tumakuru 572103, Karnataka, India.
   [Suresh, K. V.] Siddaganga Inst Technol, Dept Elect & Commun Engn, Tumakuru 572103, Karnataka, India.
   [Tandur, Deepaknath] ABB, Corp Res India, Bengaluru 560048, Karnataka, India.
C3 Siddaganga Institute of Technology; Siddaganga Institute of Technology
RP Sheela, SJ (corresponding author), Siddaganga Inst Technol, Cryptog, Tumakuru 572103, Karnataka, India.
EM sheeladinu@sit.ac.in; sureshkvsit@sit.ac.in;
   deepaknath.tandur@in.abb.com
RI Sheela, S. J/GNH-2430-2022; K V, Dr Suresh/AAE-4867-2022
OI Sheela, S. J./0000-0001-6793-1182; K V, Suresh/0000-0001-8822-8672
CR Alligood K.T, 1997, Textbooks in Mathematical Sciences
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2012, INT J NETW
   Bakhache B, 2014, IEEE SYST J, V8, P1021, DOI 10.1109/JSYST.2013.2246011
   Boriga R, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/409586
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   El-Latif AAA, 2012, SENS IMAGING, V13, P67, DOI 10.1007/s11220-012-0071-z
   Elkamchouchi HM, 2005, 2005 NAT C IEEE RAD, P277
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Faragallah OS, 2011, SENS IMAGING, V12, P73, DOI 10.1007/s11220-011-0062-5
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Galizzi GE, 2015, OPT COMMUN, V353, P76, DOI 10.1016/j.optcom.2015.05.011
   GALLAS JAC, 1993, PHYS REV LETT, V70, P2714, DOI 10.1103/PhysRevLett.70.2714
   HABUTSU T, 1991, LECT NOTES COMPUT SC, V547, P127
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Henon M., 1976, THEORY CHAOTIC ATTRA, P94
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua Z, 2013, 2013 IEEE DIG SIGN P, P118
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Kanafchian M, 2017, INT J E-NAVIG MARIT, V6, P53, DOI 10.1016/j.enavi.2017.05.007
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Li CQ, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413500752
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Machkour M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0068-1
   Mandal MK, 2012, IETE TECH REV, V29, P395, DOI 10.4103/0256-4602.103173
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mehra I, 2015, OPT COMMUN, V354, P344, DOI 10.1016/j.optcom.2015.06.015
   Memos V. A, 2017, FUTURE GENER COMPUT
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sheela SJ, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/2721910
   Sheela SJ, 2016, LECT NOTES COMPUT SC, V10063, P225, DOI 10.1007/978-3-319-49806-5_12
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Tong XJ, 2015, OPTIK, V126, P2445, DOI 10.1016/j.ijleo.2015.06.018
   Wang XY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/3/030503
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xie JQ, 2009, NSWCTC 2009: INTERNATIONAL CONFERENCE ON NETWORKS SECURITY, WIRELESS COMMUNICATIONS AND TRUSTED COMPUTING, VOL 2, PROCEEDINGS, P111, DOI 10.1109/NSWCTC.2009.201
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Xue XL, 2010, NEURAL NETW WORLD, V20, P285
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76, P8087, DOI 10.1007/s11042-016-3454-7
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang XP, 2014, NONLINEAR DYNAM, V78, P359, DOI 10.1007/s11071-014-1445-7
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Ziedan IE, 2003, 2003 NAT C IEEE RAD, P16
NR 52
TC 81
Z9 82
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25223
EP 25251
DI 10.1007/s11042-018-5782-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400028
DA 2024-07-18
ER

PT J
AU Zhu, CB
   Li, G
AF Zhu, Chunbiao
   Li, Ge
TI A multilayer backpropagation saliency detection algorithm and its
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Multilayer; Backpropagation; Depth mining; Image
   montage; Small target detection
ID REMOVAL
AB Saliency detection is an active topic in the multimedia field. Most previous works on saliency detection focus on 2D images. However, these methods are not robust against complex scenes which contain multiple objects or complex backgrounds. Recently, depth information supplies a powerful cue for saliency detection. In this paper, we propose a multilayer backpropagation saliency detection algorithm based on depth mining by which we exploit depth cue from three different layers of images. The proposed algorithm shows a good performance and maintains the robustness in complex situations. Experiments' results show that the proposed framework is superior to other existing saliency approaches. Besides, we give two innovative applications by this algorithm, such as scene reconstruction from multiple images and small target object detection in video.
C1 [Zhu, Chunbiao; Li, Ge] Peking Univ, Sch Elect & Comp Engn, Grad Sch, Shenzhen 518055, Peoples R China.
C3 Peking University
RP Li, G (corresponding author), Peking Univ, Sch Elect & Comp Engn, Grad Sch, Shenzhen 518055, Peoples R China.
EM zhuchunbiao@pku.edu.cn; geli@ece.pku.edu.cn
RI Zhu, Chunbiao/AAK-6667-2020
FU National Natural Science Foundation of China [U1611461]; grant of
   Science and Technology Planning Project of Guangdong Province, China
   [2014B090910001]; grant of Shenzhen Peacock Plan [20130408-183003656]
FX The first author (Zhu, Chunbiao) thanks his family for their kindness,
   understanding, encouragement, and support. This work was supported by
   the grant of National Natural Science Foundation of China(No.U1611461),
   the grant of Science and Technology Planning Project of Guangdong
   Province, China(No.2014B090910001) and the grant of Shenzhen Peacock
   Plan(No.20130408-183003656).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Chang CH, 2011, IEEE T MULTIMEDIA, V13, P589, DOI 10.1109/TMM.2011.2116775
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng Y, 2014, IEEE INT CON MULTI
   Chunbiao Z, 2017, 3 PATHWAY PSYCHOBIOL
   Chunbiao Z, 2017, INNOVATIVE SALIENT O
   Criminisi A., 2003, PROC CVPR IEEE, V2, pII, DOI DOI 10.1109/CVPR.2003.1211538
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 2004, AUTOMATIC FOVEATION
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li J, 2013, IEEE SIGNAL PROC LET, V20, P845, DOI 10.1109/LSP.2013.2268868
   Li X, 2013, CONTEXTUAL HYPERGRAP
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821
   Liu HJ, 2017, IEEE INT CON MULTI, P319, DOI 10.1109/ICME.2017.8019375
   Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lou J, 2016, MULTIMED TOOLS APPL, V76, P1
   Lu Y, 2011, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2011.6126247
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Mehrani P, 2010, SALIENCY SEGMENTATIO
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng H., 2014, RGBD SALIENT OBJECT
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409
   Sun X, 2017, INTEGRATED MODEL EFF
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhu CB, 2017, LECT NOTES COMPUT SC, V10425, P14, DOI 10.1007/978-3-319-64698-5_2
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 52
TC 17
Z9 18
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25181
EP 25197
DI 10.1007/s11042-018-5780-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400026
DA 2024-07-18
ER

PT J
AU Kanmani, M
   Narsimhan, V
AF Kanmani, Madheswari
   Narsimhan, Venkateswaran
TI An image contrast enhancement algorithm for grayscale images using
   particle swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Entropy; Edge content; Particle swarm
   optimization; Grayscale image
ID ADAPTIVE GAMMA CORRECTION; HISTOGRAM EQUALIZATION; BRIGHTNESS
AB This paper addresses a contrast enhancement technique that combines classical contrast enhancement with an evolutionary approach. The central goal of this work is to increase the information content and enhance the details of an image using an adaptive gamma correction technique aided by particle swarm optimization. Gamma correction is a well established technique that preserves the mean brightness of an image that produces natural looking images by the choice of an optimal gamma value. Here, Swarm intelligence based particle swarm optimization is employed to estimate an optimal gamma value. In the proposed method, the edge and information content (entropy) are the parameters used to formulate the fitness function. The proposed method is compared with state-of-the-art of techniques in terms of Weighted Average Peak Signal to Noise Ratio (WPSNR), Contrast, Homogeneity, Contrast Noise Ratio (CNR), and Measure of Enhancement (EME). Simulation results demonstrate that the proposed particle swarm optimization based contrast enhancement method improves the overall image contrast and enriches the information present in the image. In comparison to other contrast enhancement techniques, the proposed method brings out the hidden details of an image and is more suitable for applications in satellite imaging and night vision.
C1 [Kanmani, Madheswari] SSN Coll Engn, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
   [Narsimhan, Venkateswaran] SSN Coll Engn, Dept Elect & Commun Engn, Madras, Tamil Nadu, India.
C3 SSN College of Engineering; SSN College of Engineering
RP Kanmani, M (corresponding author), SSN Coll Engn, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
EM madheswarik@ssn.edu.in
CR Agaian S.S., 2000, IASTED INT C SIGNAL, P19
   AGHAGOLZADEH S, 1992, OPT ENG, V31, P614, DOI 10.1117/12.56095
   Al-Ameen Z, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0214-1
   Amiri SA., 2012, International Journal of Computer Applications, V12, P38
   [Anonymous], 2014, INT J COMPUT APPL, DOI [DOI 10.5120/17735-8849, 10.5120/17735-8849]
   [Anonymous], ENG OPTIMIZATION THE
   [Anonymous], 2013, Int. J. Comput. Appl, DOI DOI 10.5120/13766-1620
   [Anonymous], 2011, INT J ENG-IRAN, DOI DOI 10.5829/IDOSI.IJE.2011.24.04B.01
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Bechara B, 2012, J ORAL SCI, V54, P227, DOI 10.2334/josnusd.54.227
   Caselles V, 1999, IEEE T IMAGE PROCESS, V8, P220, DOI 10.1109/83.743856
   Chen SD, 2004, DIGIT SIGNAL PROCESS, V14, P413, DOI 10.1016/j.dsp.2004.04.001
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Cheng HD, 2003, PATTERN RECOGN, V36, P2687, DOI 10.1016/S0031-3203(03)00054-2
   Chiu YS, 2011, IEEE SYS MAN CYBERN, P2946, DOI 10.1109/ICSMC.2011.6084119
   Coello CAC, 2004, IEEE T EVOLUT COMPUT, V8, P256, DOI 10.1109/tevc.2004.826067
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Gao QQ, 2011, C IND ELECT APPL, P234, DOI 10.1109/ICIEA.2011.5975586
   Gorai A., 2009, Nature Biologically Inspired Computing, P72, DOI DOI 10.1109/NABIC.2009.5393603
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jana A, 2015, ADV HUM-COMPUT INTER, V2015, DOI 10.1155/2015/373419
   Kanmani M, 2016, QUANTITATIVE INFRARE, V14, P24
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Navas K. A., 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P627, DOI 10.1109/RAICS.2011.6069386
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2552, DOI 10.1109/TCE.2010.5681140
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Shanmugavadivu P, 2014, COMPUT ELECTR ENG, V40, P757, DOI 10.1016/j.compeleceng.2013.06.013
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yong Hu, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P277, DOI 10.1109/PACIIA.2008.279
   Zuiderveld K., 1994, CONTRAST LTD ADAPTIV, P474
NR 36
TC 30
Z9 31
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23371
EP 23387
DI 10.1007/s11042-018-5650-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900014
DA 2024-07-18
ER

PT J
AU Liu, H
   Wu, WS
   Wang, XD
   Qian, YL
AF Liu, Hong
   Wu, Wenshan
   Wang, Xiangdong
   Qian, Yueliang
TI RGB-D joint modelling with scene geometric information for indoor
   semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D; Gravity direction; Semantic segmentation; CRF
ID FEATURES
AB This paper focuses on the problem of RGB-D semantic segmentation for indoor scenes. We introduce a novel gravity direction detection method based on vertical lines fitting combined 2D vision information and 3D geometric information to improve the original HHA depth encoding. Then to fuse two-stream networks of deep convolutional networks from RGB and depth encoding, we propose a joint modelling method by learning a weighted summing layer to fuse the prediction results. Finally, to refine the pixel-wise score maps, we adopt fully-connected CRF as a post-processing and propose a pairwise potential function combined normal kernel to explore geometric information. Experimental results show our proposed approach achieves state-of-the-art performance of RGB-D semantic segmentation on public dataset.
C1 [Liu, Hong; Wu, Wenshan; Wang, Xiangdong; Qian, Yueliang] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Liu, H (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100190, Peoples R China.
EM hliu@ict.ac.cn; wuwenshan@ict.ac.cn; xdwang@ict.ac.cn; ylqian@ict.ac.cn
RI wang, xiao/HZI-9156-2023; wang, xiao/HGB-7081-2022
OI wang, xiao/0000-0002-4088-3341
FU Beijing Natural Science Foundation [4142051]
FX This work is supported in part by Beijing Natural Science Foundation:
   4142051.
CR Anand A, 2013, INT J ROBOT RES, V32, P19, DOI 10.1177/0278364912461538
   [Anonymous], ICCV
   [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2015, ARXIV150504366
   [Anonymous], 2014, ECCV
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2013, INT C LEARN REPR
   [Anonymous], ARXIV160107649
   [Anonymous], EUR C COMP VISION
   [Anonymous], NIPS 2015
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], 2011, P ADV NEURAL INFORM
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Filliat D., 2012, 2012 IEEE Conference on Technologies for Practical Robot Applications (TePRA), P127, DOI 10.1109/TePRA.2012.6215666
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   He Y, 2017, PROC CVPR IEEE, P7158, DOI 10.1109/CVPR.2017.757
   Khan SH, 2014, LECT NOTES COMPUT SC, V8689, P679, DOI 10.1007/978-3-319-10590-1_44
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Shuai B, 2016, PROC CVPR IEEE, P3620, DOI 10.1109/CVPR.2016.394
   Shuai B, 2016, IEEE T IMAGE PROCESS, V25, P2379, DOI 10.1109/TIP.2016.2533862
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   [王炳杰 Wang Bingjie], 2014, [北京航空航天大学学报, Journal of Beijing University of Aeronautics and Astronautics], V40, P1477
NR 28
TC 25
Z9 26
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22475
EP 22488
DI 10.1007/s11042-018-6056-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500039
DA 2024-07-18
ER

PT J
AU Liu, SH
   Rho, S
   Wang, RJ
   Jiang, F
AF Liu, Shaohui
   Rho, Seungmin
   Wang, Renjie
   Jiang, Feng
TI Feature-preserving mesh denoising based on guided normal filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mesh denoising; Feature face; Joint bilateral filtering;
   Feature-preserving; Partial neighbor
AB In order to robustly perform tasks based on 3D data model, we propose a feature-preserving mesh denoising algorithm based on the face classification. In the proposed algorithm, the sharp features which play a key role in 3D models are kept unchanged while denoising. The multiscale tensor voting is used to classify the faces into two classes where one is called as feature faces and another as non-feature faces. Feature faces is usually distributed in the neighbourhood of shape edges. Thus these feature faces are key faces in perceptual quality. For processing the faces more efficiently, we propose a search algorithm to find those faces which are close to the feature face and are of similar geometrical properties and then use them to guide the filtering process. The remaining faces are processed by an iteratively joint bilateral filtering. Finally, vertex position is updated according to the filtered face normals. the effectiveness of proposed approach is validated through extensive experiments. Experimental results show the performance is better than the existing methods.
C1 [Liu, Shaohui; Wang, Renjie; Jiang, Feng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Sungkyul, South Korea.
C3 Harbin Institute of Technology; Sungkyul University
RP Liu, SH (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
EM shliu@hit.edu.cn; smrho@sungkyul.edu; 837825229@qq.com;
   fjiang@hit.edu.cn
RI Rho, Seungmin/HTP-6683-2023; JIANG, Feng/HTP-2862-2023; Liu,
   Shaohui/AAC-3092-2019; Liu, shaohui/HKE-1383-2023
OI Liu, Shaohui/0000-0002-1810-5412; 
FU Major State Basic Research Development Program of China (973 Program)
   [2015CB351804]; Science and Technology Commission of China
   [17-H863-03-ZT-003-010-01]; Natural Science Foundation of China
   [61572155, 61672188]
FX This work is partially funded by the Major State Basic Research
   Development Program of China (973 Program 2015CB351804), the Science and
   Technology Commission of China No. 17-H863-03-ZT-003-010-01 and the
   Natural Science Foundation of China under Grant No. 61572155 and
   61672188.
CR Bian Z, 2011, COMPUT AIDED GEOM D, V28, P50, DOI 10.1016/j.cagd.2010.10.001
   Fan HQ, 2010, IEEE T VIS COMPUT GR, V16, P312, DOI 10.1109/TVCG.2009.70
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Gao Y, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2967502
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Kim HS, 2009, COMPUT AIDED DESIGN, V41, P47, DOI 10.1016/j.cad.2008.12.003
   Lee KW, 2006, INT C COMPUT AIDED D, V1, P275
   loannidou A, 2017, J ACM COMPUT SURV, V50, P1
   Peratham W, 2016, ACM COMPUT SURV, V49, P1
   Su LF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2779
   Sun XF, 2008, COMPUT AIDED GEOM D, V25, P437, DOI 10.1016/j.cagd.2007.12.008
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wang J, 2012, COMPUT AIDED DESIGN, V44, P597, DOI 10.1016/j.cad.2012.03.001
   Wang R, 2017, PAC RIM C MULT PCM 2
   Wei MQ, 2017, IEEE T AUTOM SCI ENG, V14, P931, DOI 10.1109/TASE.2016.2553449
   Wei MQ, 2015, IEEE T VIS COMPUT GR, V21, P43, DOI 10.1109/TVCG.2014.2326872
   Zhang WY, 2015, COMPUT GRAPH FORUM, V34, P23, DOI 10.1111/cgf.12742
   Zhao SC, 2015, P ACM MM AUSTR
   Zhao SC, 2016, P ACM MM NETH
   Zhao SC, 2015, PREDICTING DISCRETE
   Zhao SC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P369, DOI 10.1145/3123266.3130858
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
   Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zheng YY, 2011, IEEE T VIS COMPUT GR, V17, P1521, DOI 10.1109/TVCG.2010.264
NR 31
TC 7
Z9 9
U1 6
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 23009
EP 23021
DI 10.1007/s11042-018-5735-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500066
DA 2024-07-18
ER

PT J
AU Liu, YB
   Liu, KH
   Zhang, CQ
   Wang, X
   Wang, SN
   Xiao, ZT
AF Liu, Yanbei
   Liu, Kaihua
   Zhang, Changqing
   Wang, Xiao
   Wang, Shaona
   Xiao, Zhitao
TI Entropy-based active sparse subspace clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active learning; Sparse subspace clustering; Constrained clustering;
   Entropy-based query strategy
ID ALGORITHM; MODELS
AB Sparse Subspace Clustering (SSC) is widely used in data mining and machine learning. Some studies have been developed to add pairwise constraints as side information to improve the clustering results. However, most of these algorithms are "passive" in the sense that the side information is provided beforehand. In this paper, we propose a novel extension for SSC with active learning framework, in which we aim to select the most informative pairwise constraints to guide the SSC for accurate clustering results. Specifically, in the first step, an entropy-based query strategy is proposed to select the most uncertain pairwise constraints. Next, constrained sparse subspace clustering algorithms are followed to integrate the selected pairwise constraints and obtain the final clustering results. Two steps are effectively performed in an iterative manner until satisfactory results are achieved. Experimental results on two face datasets clustering well demonstrate the effectiveness of the proposed method.
C1 [Liu, Yanbei; Wang, Shaona; Xiao, Zhitao] Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.
   [Liu, Yanbei; Wang, Shaona; Xiao, Zhitao] Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Liu, Kaihua] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Zhang, Changqing] Tianjin Univ, Sch Comp & Sci Technol, Tianjin, Peoples R China.
   [Wang, Xiao] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Tiangong University; Tianjin University; Tianjin University; Tsinghua
   University
RP Xiao, ZT (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.; Xiao, ZT (corresponding author), Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM liuyanbei@tjpu.edu.cn; liukaihua@tju.edu.cn; zhangchangqing@tju.edu.cn;
   wangxiao_cv@163.com; shaonaw@163.com; xiaozhitao@tjpu.edu.cn
RI Zhang, Chang/HTO-2939-2023; Liu, Yanbei/IQR-5059-2023
FU National Natural Science Foundation of China [13ZD162, 61601325];
   Applied Basic Research Programs of China National Textile and Apparel
   Council [J201509]; Plan Program of Tianjin Educational Science and
   Research [2017KJ087]
FX This work was supported in part by Major Program of National Natural
   Science Foundation of China (Grant no. 13&ZD162), Applied Basic Research
   Programs of China National Textile and Apparel Council (Grant no.
   J201509), National Natural Science Foundation of China(Grant no.
   61601325), and Plan Program of Tianjin Educational Science and Research
   (Grant no. 2017KJ087).
CR [Anonymous], P 19 INT C PATT REC
   [Anonymous], 2014, Multimedia and Expo (ICME), 2014 IEEE International Conference on
   Basu S, 2004, SIAM PROC S, P333
   Biswas A, 2011, INT C MACH LEARN WOR
   Biswas A, 2012, PROC CVPR IEEE, P2152, DOI 10.1109/CVPR.2012.6247922
   Cai D., 2007, PROC IEEE 11 INT C C
   Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Elhamifar E, 2009, PROC CVPR IEEE, P2782
   Eriksson B., 2011, ARXIV11023887
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Greene D, 2007, CONSTRAINT SELECTION, P140
   Grira N, 2008, PATTERN RECOGN, V41, P1834, DOI 10.1016/j.patcog.2007.10.004
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Hoi S.C. H., 2008, Proc. of Int. Conference on Machine Learning, P400
   Hu QH, 2012, IEEE T KNOWL DATA EN, V24, P2052, DOI 10.1109/TKDE.2011.149
   Huang RZ, 2007, IEEE DATA MINING, P517, DOI 10.1109/ICDM.2007.79
   Kenley E. C., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P1116, DOI 10.1109/ICDM.2011.64
   Kim Taewan, 2017, ARXIV170903202
   Kim Taewan, 2017, ARXIV171107433
   Klein D., 2002, Tech. rep., P307
   Koh KM, 2007, J MACH LEARN RES, V8, P1519
   Krishnamurthy A., 2012, ARXIV12064672
   Kulis B, 2009, MACH LEARN, V74, P1, DOI 10.1007/s10994-008-5084-4
   Li T., 2004, P 21 INT C MACH LEAR, P68, DOI DOI 10.1145/1015330.1015404
   Li T, 2007, IEEE DATA MINING, P577, DOI 10.1109/ICDM.2007.98
   Nogueira B.M., 2012, Proceedings of the 27th Annual ACM Symposium on Applied Computing, P216
   Vu VV, 2012, PATTERN RECOGN, V45, P1749, DOI 10.1016/j.patcog.2011.10.016
   Wang F, 2009, IEEE DATA MINING, P562, DOI 10.1109/ICDM.2009.66
   Wauthier Fabian L, 2012, P 18 ACM SIGKDD INT, P1339
   Xiong C, 2012, EUR C DAT MIN, P1
   Xiong CM, 2017, IEEE T PATTERN ANAL, V39, P5, DOI 10.1109/TPAMI.2016.2539965
   Xu QJ, 2005, LECT NOTES COMPUT SC, V3735, P294
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, PROC CVPR IEEE, P2809, DOI 10.1109/CVPR.2016.307
NR 40
TC 5
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22281
EP 22297
DI 10.1007/s11042-018-5945-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500030
DA 2024-07-18
ER

PT J
AU Saha, P
   Bhattacharjee, D
   De, BK
   Nasipuri, M
AF Saha, Priya
   Bhattacharjee, Debotosh
   De, Barin Kumar
   Nasipuri, Mita
TI Facial component-based blended facial expressions generation from static
   neutral face images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blended facial expressions; Knowledge-based system; Normalized facial
   feature parameter; Symbolic formulation of expressions; Expressive face
   image generator
AB Facial expression synthesis is getting a wide-spread attention since past several years due to its multimedia applications. In most of the earlier research works, example images of target expressions are required to produce synthesized facial expressions. The paper aims to generate six basic and twelve blended facial expressions from a static and RGB neutral face image without any exemplar of expressive face images. The proposed automatic expression generation system consists of several sub-systems, namely, a knowledge-based system, a module for symbolic formulations of basic and blended facial expressions, an expressive facial components generator and an expressive face generator. The knowledge-based system stores the normalized facial feature parameter values. Symbolic formulations of facial expressions are used to reconstruct facial expressions from a static neutral face image using the parameters stored in the knowledge base. Expressive facial components generator performs automatic expressive facial feature generation as well as automatic facial feature extraction and landmark annotation. Finally, expressive facial components are combined to produce an expressive face in expressive face generator. The system generated expressive face images are validated in four different ways: inter-rater reliability measure, similarity measurement in the frequency domain, similarity measurement using SSIM, FSIM, HOG features and accuracy measurement using both appearance-based and geometry-based feature extraction methods. The geometry based feature extraction method generates 90% recognition accuracy for system generated face images.
C1 [Saha, Priya] Tripura Univ, Dept Comp Sci & Engn, Suryamaninagar 799022, Tripura, India.
   [Bhattacharjee, Debotosh; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, W Bengal, India.
   [De, Barin Kumar] Tripura Univ, Dept Phys, Suryamaninagar 799022, Tripura, India.
C3 Tripura University; Jadavpur University; Tripura University
RP Saha, P (corresponding author), Tripura Univ, Dept Comp Sci & Engn, Suryamaninagar 799022, Tripura, India.
EM priyasaha.cse@gmail.com
RI Bhattacharjee, Debotosh/L-8521-2015; Bhattacharjee,
   Debotosh/Q-4065-2019; Saha, Priya/AAA-7464-2019; De, Barin
   Kumar/GRS-7957-2022
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; 
FU DeitY, MCIT, Government of India [12(2)/2011-ESD]; Department of Science
   and Technology (DST), Government of India under DST-INSPIRE fellowship
   program [IF131067]
FX The work presented here is being conducted under the research project
   supported by the Grant No. 12(2)/2011-ESD, dated 29/03/2011, from DeitY,
   MCIT, Government of India. The first author is grateful to Department of
   Science and Technology (DST), Government of India for providing her
   Junior Research Fellowship-Professional (JRF-Professional) under
   DST-INSPIRE fellowship program (No. IF131067).
CR Abboud B, 2005, IEE P-VIS IMAGE SIGN, V152, P327, DOI 10.1049/ip-vis:20045060
   ADAMS R, 1993, CVGIP-GRAPH MODEL IM, V55, P325, DOI 10.1006/cgip.1993.1024
   Agarwal S, 2012, P 8 IND C COMP VIS G, V12, P1, DOI 10.1145/2425333.2425361
   Agarwala A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239545, 10.1145/1276377.1276495]
   [Anonymous], 2010, ACM SIGGRAPH 2010 Papers. SIGGRAPH'10, DOI [DOI 10.1145/1833349.1778769, DOI 10.1145/1778765.1778769]
   [Anonymous], 2009, TECHNICAL REPORT
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 2007, MATH DISCRETE FOURIE
   [Anonymous], 1997, ALGORITHMS IMAGE PRO
   [Anonymous], COMPUTER ROBOT VISIO
   [Anonymous], 1995, CONTINUOUS UNIVARIAT
   Bhattacharjee D, 2011, SOFT COMPUT, V15, P429, DOI 10.1007/s00500-009-0524-z
   Bhowmik MK, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.10.102106
   Chen YZ, 2013, IEEE T CIRC SYST VID, V23, P74, DOI 10.1109/TCSVT.2012.2203198
   Contreras V, 2005, ARTNATOMY ARMATOMIA
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Huang D, 2010, LECT NOTES COMPUTER, DOI [10.1007/978-3-642-15552-927, DOI 10.1007/978-3-642-15552-927]
   Hunan P., 1978, FACIAL ACTION CODING
   Juebo Wu, 2011, Journal of Multimedia, V6, P217, DOI 10.4304/jmm.6.2.217-224
   King I, 1996, P INT C NEUR INF PRO
   Kouzani AZ, 2001, 7 AUSTR NZ INT INF S, P18, DOI [10.1109/ANZITS.2001.974072, DOI 10.1109/ANZITS.2001.974072]
   Lei Xiong, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P1582, DOI 10.1109/ICIEA.2009.5138461
   Li K, 2014, IEEE T MULTIMEDIA, V16, P299, DOI 10.1109/TMM.2013.2293064
   Liu ZC, 2001, COMP GRAPH, P271
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Saha P, 2016, PROCEDIA COMPUT SCI, V84, P94, DOI 10.1016/j.procs.2016.04.071
   Sheu JS, 2014, J APPL RES TECHNOL, V12, P1115, DOI 10.1016/S1665-6423(14)71671-2
   Song ML, 2007, IEEE T MULTIMEDIA, V9, P1384, DOI 10.1109/TMM.2007.906591
   Susskind Joshua M., 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition, P421
   Tang XO, 2000, COMPUT VIS IMAGE UND, V79, P25, DOI 10.1006/cviu.2000.0843
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tsai YJ, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/51906
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wan XM, 2012, MULTIMED TOOLS APPL, V58, P109, DOI 10.1007/s11042-010-0688-7
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xavier I, 2015, 2015 SIXTH INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P80, DOI 10.1109/EST.2015.17
   Xie WC, 2018, MULTIMED TOOLS APPL, V77, P7565, DOI 10.1007/s11042-017-4661-6
   Yang CK, 2008, MULTIMED TOOLS APPL, V40, P41, DOI 10.1007/s11042-007-0184-x
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
   Zhang YH, 2012, IEEE INT SYMP CIRC S, P2685, DOI 10.1109/ISCAS.2012.6271860
   Zhang Y, 2014, ANAL BIOCHEM, V462, P13, DOI 10.1016/j.ab.2014.06.008
   Zhe X, 2004, PROC, P367, DOI [10.1007/978-1-4471-3754-2, DOI 10.1007/978-1-4471-3754-2]
   Zhu X, 2013, P 2 INT C INN COMP C, P78, DOI [10.1145/2556871.2556889, DOI 10.1145/2556871.2556889]
NR 51
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20177
EP 20206
DI 10.1007/s11042-017-5436-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500057
DA 2024-07-18
ER

PT J
AU Vard, A
AF Vard, Alireza
TI A new combination active contour model for segmenting texture image with
   low contrast and high illumination variations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture image segmentation; Active contour model; Monogenic signal;
   Local cumulative distribution function
ID SCALABLE FITTING ENERGY; SEGMENTATION; REGION; DRIVEN
AB This paper presents a novel combined energy functional based on edge and region information for active contour model, which can be applied to segment textured images containing low contrast and high illumination variations. In the proposed method, the edge features are calculated based on the phase-based approaches derived from the monogenic signal, which are robust to illumination variations in the image. These feature values are used in an edge energy functional to assist the active contour evolving towards the true object boundaries. To extract the region features, at first, we compute the normalized accumulated short-term autocorrelation (NASTA) values for the image, which suppress background clutter and enhance dissimilarities between objects and background. Next, a local cumulative distribution function (LCDF) of NASTA is calculated for every pixel in a local window around it and is used as a region feature for that pixel. Then, the obtained features are employed to define a new localized region-based energy functional that can correctly segment regions with same intensity mean and variance. The proposed edge and region energy terms are integrated and a regularization term is added to them to form our combined active contour. Experimental results indicate remarkable advantages of proposed method comparing to existing combination models.
C1 [Vard, Alireza] Isfahan Univ Med Sci, Dept Biomed Engn, Sch Adv Technol Med, Esfahan 81746, Iran.
   [Vard, Alireza] Isfahan Univ Med Sci, Med Image & Signal Proc Res Ctr, Esfahan 81746, Iran.
C3 Isfahan University Medical Science; Isfahan University Medical Science
RP Vard, A (corresponding author), Isfahan Univ Med Sci, Dept Biomed Engn, Sch Adv Technol Med, Esfahan 81746, Iran.; Vard, A (corresponding author), Isfahan Univ Med Sci, Med Image & Signal Proc Res Ctr, Esfahan 81746, Iran.
EM vard@amt.mui.ac.ir
RI Vard, Alireza/N-4708-2019; Vard, Alireza/U-7284-2017
OI Vard, Alireza/0000-0003-1768-910X; Vard, Alireza/0000-0003-1768-910X
CR [Anonymous], 2002, LOW LEVEL IMAGE PROC
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Boyle, 2014, CENGAGE LEARNING
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Felsberg M, 2003, LECT NOTES COMPUT SC, V2695, P209
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   Felsberg Michael., 2000, DAGM-Symposium, P195
   Gao SB, 2014, MULTIMED TOOLS APPL, V72, P2321, DOI 10.1007/s11042-013-1553-2
   He CJ, 2012, SIGNAL PROCESS, V92, P587, DOI 10.1016/j.sigpro.2011.09.004
   Houhou N, 2009, NUMER MATH-THEORY ME, V2, P445, DOI 10.4208/nmtma.2009.m9007s
   IVINS J, 1995, IMAGE VISION COMPUT, V13, P431, DOI 10.1016/0262-8856(95)99730-O
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Kovesi Peter., 1997, Tenth Australian Joint Converence on Artificial Intelligence, P2
   Li C, 2007, PROC IEEE COMPUT SOC, P1
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P10149, DOI 10.1007/s11042-016-3603-z
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu JG, 2017, MULTIMED TOOLS APPL, V76, P10991, DOI 10.1007/s11042-016-3462-7
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Marouf A, 2017, MULTIMED TOOLS APPL, V76, P12583, DOI 10.1007/s11042-016-3648-z
   Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073
   Mirmehdi Majid., 2008, Handbook of Texture Analysis
   Nixon Mark S, 2012, FEATURE EXTRACTION I, DOI DOI 10.1016/B978-0-12-396549-3.00007-0
   Norouzi A, 2014, IETE TECH REV, V31, P199, DOI 10.1080/02564602.2014.906861
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   Rabiner Lawrence, 2010, Digital Processing of Speech Signals
   Sagiv C, 2006, IEEE T IMAGE PROCESS, V15, P1633, DOI 10.1109/TIP.2006.871133
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shan H, 2010, PATTERN RECOGN LETT, V31, P355, DOI 10.1016/j.patrec.2009.10.018
   Tian Y, 2013, MACH VISION APPL, V24, P47, DOI 10.1007/s00138-011-0363-7
   Vard AR, 2008, J CHIN INST ENG, V31, P649, DOI 10.1080/02533839.2008.9671418
   Vard A, 2012, AUSTRALAS PHYS ENG S, V35, P135, DOI 10.1007/s13246-012-0131-7
   Vard A, 2012, PATTERN RECOGN LETT, V33, P543, DOI 10.1016/j.patrec.2011.11.012
   Vard A, 2011, EXPERT SYST APPL, V38, P11722, DOI 10.1016/j.eswa.2011.03.058
   Wang GG, 2018, MEMET COMPUT, V10, P151, DOI 10.1007/s12293-016-0212-3
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang Y.J., 2006, Advances in image and video segmentation
   Zhu GP, 2010, PATTERN RECOGN LETT, V31, P845, DOI 10.1016/j.patrec.2010.01.011
NR 47
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20021
EP 20042
DI 10.1007/s11042-017-5427-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500050
DA 2024-07-18
ER

PT J
AU Zhang, C
   Yao, R
   Cai, JP
AF Zhang, Chi
   Yao, Rui
   Cai, Jinpeng
TI Efficient eye typing with 9-direction gaze estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze estimation; Eye tracking; Convolutional neural network;
   Human-computer interaction
AB Vision based text entry systems aim to help disabled people achieve text communication using eye movement. Most previous methods have employed an existing eye tracker to predict gaze direction and designed an input method based upon that. However, these methods can result in eye tracking quality becoming easily affected by various factors and lengthy amounts of time for calibration. Our paper presents a novel efficient gaze based text input method, which has the advantage of low cost and robustness. Users can type in words by looking at an on-screen keyboard and blinking. Rather than estimate gaze angles directly to track eyes, we introduce a method that divides the human gaze into nine directions. This method can effectively improve the accuracy of making a selection by gaze and blinks. We built a Convolutional Neural Network (CNN) model for 9-direction gaze estimation. On the basis of the 9-direction gaze, we used a nine-key T9 input method which is widely used in candy bar phones. Bar phones were very popular in the world decades ago and have cultivated strong user habits and language models. To train a robust gaze estimator, we created a large-scale dataset with images of eyes sourced from 25 people. According to the results from our experiments, our CNN model is able to accurately estimate different people's gaze under various lighting conditions. In considering disable people's needs, we removed the complex calibration process. The input methods can run in screen mode and portable off-screen mode. Moreover, The datasets used in our experiments are made available to the community to allow further research.
C1 [Zhang, Chi; Yao, Rui] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Cai, Jinpeng] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT 2601, Australia.
C3 China University of Mining & Technology; Australian National University
RP Yao, R (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM 08133396@cumt.edu.cn; ruiyao@cumt.edu.cn; u5715685@anu.edu.au
OI Yao, Rui/0000-0003-2734-915X; Zhang, Chi/0000-0001-6344-2824
FU Fundamental Research Funds for the Central Universities [2017XKQY075]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (No. 2017XKQY075).
CR [Anonymous], REHABILITATION
   [Anonymous], P 1 EUR C DIS VIRT R
   [Anonymous], M ASS COMP LING
   [Anonymous], 2001, PROC IEEE COMPUT SOC
   Chen Jixu, 2008, 2008 19 INT C PATT R, P1
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dohse K.C. Kurt Chris, 2007
   Fejtová M, 2004, LECT NOTES COMPUT SC, V3118, P770
   Gips James., 1996, 11 INT C TECHNOLOGY, P1
   Grauman Kristen, 2003, Universal Access in the Information Society, V2, P359, DOI [10.1007/s10209-003-0062-x, DOI 10.1007/s10209-003-0062-x]
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hansen DW, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P132, DOI 10.1109/ACV.2002.1182170
   HUTCHINSON TE, 1989, IEEE T SYST MAN CYB, V19, P1527, DOI 10.1109/21.44068
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Królak A, 2012, UNIVERSAL ACCESS INF, V11, P409, DOI 10.1007/s10209-011-0256-6
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Majaranta P., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P15, DOI 10.1145/507072.507076
   Majaranta P., 2014, ADV PHYSL COMPUTING, P39, DOI DOI 10.1007/978-1-4471-6392-3_3
   Majaranta P, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P357
   Morimoto CH, 2002, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2002.1047459
   Silfverberg M., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P9, DOI 10.1145/332040.332044
   Tuisku O, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P19, DOI 10.1145/1344471.1344476
   Wobbrock J.O., 2007, P 3 C COMMUNICATION, P61
   Yang S., 2007, Text Entry Systems: Mobility, Accessibility, Universality, P175
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
NR 32
TC 28
Z9 28
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19679
EP 19696
DI 10.1007/s11042-017-5426-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500036
DA 2024-07-18
ER

PT J
AU Lam, MC
   Arshad, H
   Prabuwono, AS
   Tan, SY
   Kahaki, SMM
AF Lam, Meng Chun
   Arshad, Haslina
   Prabuwono, Anton Satria
   Tan, Siok Yee
   Kahaki, S. M. M.
TI Interaction techniques in desktop virtual environment: the study of
   visual feedback and precise manipulation method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interaction technique; Hand gesture; Virtual training system; Virtual
   grasping
AB Gesture-based systems allow users to interact with a virtual reality application in a natural way. Visual feedback for the gesture-based interaction technique has an impact on the performance and the hand instability making the manipulation of the object less precise. This paper investigated two new interaction techniques in a virtual environment. It describes the influence of natural and non-natural virtual feedback in the selection process using the GITDVR-G interaction technique, which consists of a grasping visual feedback. The GITDVR-G was evaluated in a virtual knee surgery training system. The results showed that it was effective in terms of the task completion time, and that the participants preferred the natural grasping visual feedback. Besides that, the precise manipulation in a newly-designed interaction technique (Precise GITDVR-G) was evaluated. The Precise GITDVR-G includes a normal manipulation mode and a precise manipulation mode that can be triggered by hand gestures. During the precise manipulation mode, an inset view will appear and move with the selected object to provide a better view to users, while the movements of the virtual hand are scaled down to improve the precision. Four different configurations of the precise manipulation technique were evaluated, and the results showed that the unimanual control method with an inset view performed better in terms of the task performance time and the subjective feedback. The finding suggested that the realistic virtual grasping visual feedback can be applied in a virtual hand interaction technique, and that the inset view feature is helpful in the precise manipulation.
C1 [Lam, Meng Chun; Arshad, Haslina; Tan, Siok Yee] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Bangi 43600, Selangor, Malaysia.
   [Prabuwono, Anton Satria] Rabigh King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Technol, Rabigh 21911, Saudi Arabia.
   [Kahaki, S. M. M.] Northeastern Univ, Dana Res Ctr, Boston, MA 02115 USA.
C3 Universiti Kebangsaan Malaysia; King Abdulaziz University; Northeastern
   University
RP Lam, MC (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence Technol, Bangi 43600, Selangor, Malaysia.
EM lammc@ukm.edu.my
RI arshad, haslina/AAF-8737-2019; Tan, Siok Yee/V-5845-2018; Chun, Lam
   Meng/H-4105-2019; Kahaki, Seyed Mostafa Mousavi/H-3906-2015; Prabuwono,
   Anton Satria/K-7555-2014
OI Tan, Siok Yee/0000-0003-3566-9938; Chun, Lam Meng/0000-0002-9435-9473;
   Kahaki, Seyed Mostafa Mousavi/0000-0002-0249-3238; Prabuwono, Anton
   Satria/0000-0003-3337-6605; tan, siok yee/0000-0003-0772-440X
FU Universiti Kebangsaan Malaysia (UKM) Grant Scheme [AP-2013-011,
   GGPM-2015-023]
FX This research work was supported by the AP-2013-011 and the
   GGPM-2015-023 from Universiti Kebangsaan Malaysia (UKM) Grant Scheme.
   Other than that, the authors would like to thank the members of MyXLab,
   the Faculty of Information Science & Technology, Universiti Kebangsaan
   Malaysia for their support in this research.
CR Argelaguet F., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P163
   Ascension Technology Corporation, 2002, FLOCK BIRDS INST OP
   Bowman D., 1996, DESIGNING DIGITAL SP, P225
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Brooks F. P.  Jr., 1990, Computer Graphics, V24, P177, DOI 10.1145/97880.97899
   Burdea G., 1994, VIRTUAL REALITY TECH
   Duval Thierry, 2014, ICAT EGVE 2014, P8
   Fabiani L, 1996, P IEEE VIRT REAL ANN, P54, DOI 10.1109/VRAIS.1996.490510
   Faieza AAP, 2008, JURNAL TEKNOLOGI, V49, P157
   Feiner A.O.S., 2003, P UIST, V3, P81
   Fifth Dimension Technologies, 2004, 5DT DAT GLOB ULTR US
   Forsberg A., 1996, P 9 ANN ACM S USER I, P95, DOI 10.1145/237091.237105
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Grossman T., 2006, P UIST 2006, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Grossman Tovi., 2005, CHI 05, P281, DOI DOI 10.1145/1054972.1055012
   Hilliges O, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P139
   Hou Wenjun, 2008, Advances in Human Computer Interaction, P543
   JACOBY R, 1994, P SOC PHOTO-OPT INS, V2177, P355, DOI 10.1117/12.173892
   Jauregui D. A. G., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P69, DOI 10.1109/3DUI.2012.6184186
   JIANG H, 2002, P ACM VRST 2002 C HO
   Kadri A., 2007, P 3DUI 2007 S 3D USE, DOI [10.1109/3DUI.2007.340767, DOI 10.1109/3DUI.2007.340767]
   Kavakli M, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P613
   Köpsel A, 2016, BEHAV INFORM TECHNOL, V35, P1044, DOI 10.1080/0144929X.2016.1194477
   Kosch T, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P53, DOI 10.1145/2982142.2982157
   Lam MC, 2011, INT REV COMPUTERS SO, V6, P1044
   LIANG JD, 1994, COMPUT GRAPH, V18, P499, DOI 10.1016/0097-8493(94)90062-0
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Ortega M., 2013, P SIGCHI C HUM FACT, P193
   Osawa N., 2006, Proceedings of the 2006 ACM International Conference on Virtual Reality Continuum and Its Applications, P121
   Osawa N., 2010, P 9 ACM SIGGRAPH C V, P131
   Petzold B, 2004, PRESENCE-TELEOP VIRT, V13, P16, DOI 10.1162/105474604774048207
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Poupyrev I., 1998, P ACM CHI, V98
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Prachyabrued M., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P39, DOI 10.1109/3DUI.2012.6184182
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Prachyabrued M, 2012, INT J HUM-COMPUT ST, V70, P828, DOI 10.1016/j.ijhcs.2012.06.002
   Ramli IS, 2010, BUSINESS TRANSFORMATION THROUGH INNOVATION AND KNOWLEDGE MANAGEMENT: AN ACADEMIC PERSPECTIVE, VOLS 1-2, P882
   Smith G., 2001, P GRAPH INT C OTT ON, P135
   Stuerzlinger W, 2011, VIRTUAL REALITIES: DAGSTUHL SEMINAR 2008, P203, DOI 10.1007/978-3-211-99178-7_11
   Teather R.J., 2014, Proceedings of the 2nd ACM Symposium on Spatial User Interaction, P127
   Vanacken L, 2009, INT J HUM-COMPUT ST, V67, P237, DOI 10.1016/j.ijhcs.2008.09.001
   Viciana-Abad R, 2014, MULTIMED TOOLS APPL, V68, P623, DOI 10.1007/s11042-012-1070-8
   Wan HG, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P185, DOI 10.1109/VECIMS.2009.5068890
   Wilkes C., 2008, Proceedings of the 2008 ACM Symposium on Virtual Reality Software and Technology, P23, DOI DOI 10.1145/1450579.1450585
   Wu CH, 2016, MULTIMED TOOLS APPL, V75, P7065, DOI 10.1007/s11042-015-2632-3
   Wyss HP, 2006, IEEE Symposium on 3D User Interfaces 2006, Proceedings, P59, DOI 10.1109/TRIDUI.2006.1618271
NR 49
TC 7
Z9 7
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16367
EP 16398
DI 10.1007/s11042-017-5205-9
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300017
DA 2024-07-18
ER

PT J
AU Ramos, J
   Nedjah, N
   Mourelle, LD
   Gupta, BB
AF Ramos, Joelmir
   Nedjah, Nadia
   Mourelle, Luiza de Macedo
   Gupta, Brij B.
TI Visual data mining for crowd anomaly detection using artificial bacteria
   colony
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd anomaly detection; Optical flow; Artificial bacteria colony;
   Kohonen's neural network
AB This paper presents a novel method for global anomaly detection in crowded scenes. The optical flow of frames is used to extract the foreground of areas with people motions in the crowd in the form of layers. The optical flow between two frames generates one layer. The proposed method applies the metaheuristic of artificial bacteria colony as a robust algorithm to optimize the extracted layers. Artificial bacteria cover all regions of interest that have high movement between frames. The artificial bacteria colony adapts quickly to the most varied scenarios. Moreover, the algorithm has low sensibility to noise and to sudden changes in video lighting as captured by optical flow. The bacteria population of the colonies, its food storage and the colony's centroid position regarding each optical flow layer, are used as input to train a Kohonen's neural network. Once trained the network is able to detect specific events based on behavior patterns similarity, as produced by the bacteria colony during such events. Experiments are conducted on available public dataset. The achieved results show that the proposed method captures the dynamics of the crowd behavior successfully, revealing that the proposed scheme outperforms the available state-of-the-art algorithms for global anomaly detection.
C1 [Ramos, Joelmir; Nedjah, Nadia] Univ Estado Rio De Janeiro, Fac Engn, Dept Elect Engn & Telecommun, Rio De Janeiro, Brazil.
   [Mourelle, Luiza de Macedo] Univ Estado Rio De Janeiro, Fac Engn, Dept Syst Engn & Computat, Rio De Janeiro, Brazil.
   [Gupta, Brij B.] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 Universidade do Estado do Rio de Janeiro; Universidade Federal de Juiz
   de Fora; Universidade Federal de Juiz de Fora; Universidade do Estado do
   Rio de Janeiro; National Institute of Technology (NIT System); National
   Institute of Technology Kurukshetra
RP Ramos, J (corresponding author), Univ Estado Rio De Janeiro, Fac Engn, Dept Elect Engn & Telecommun, Rio De Janeiro, Brazil.
EM joelmiramos@gmail.com; nadia@eng.uerj.br; ldmm@eng.uerj.br;
   bbgupta.nitkkr@gmail.com
RI Gupta, Brij B/E-9813-2011; Nedjah, Nadia/AAE-7320-2019; de Macedo
   Mourelle, Luiza/GVS-4735-2022; de Macedo Mourelle, Luiza/AAG-8935-2019
OI Gupta, Brij B/0000-0003-4929-4698; de Macedo Mourelle,
   Luiza/0000-0002-4680-2047; de Macedo Mourelle,
   Luiza/0000-0002-4680-2047; Nedjah, Nadia/0000-0002-1656-6397
CR Andrade EL, 2006, INT C PATT RECOG, P175
   Chaaraoui AA, 2012, EXPERT SYST APPL, V39, P10873, DOI 10.1016/j.eswa.2012.03.005
   [Anonymous], 2015, 2015 9 INT C SIGNAL, DOI DOI 10.1109/ICSPCS.2015.7391778
   [Anonymous], 2002, MATH BIOL
   [Anonymous], 2006, UNUSUAL CROWD ACTIVI
   [Anonymous], CVPR
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Garate Carolina., 2009, Performance Evaluation of Tracking and Surveillance (PETS- Winter), 2009 Twelfth IEEE International Workshop on, P1
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jie Feng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3599, DOI 10.1109/ICPR.2010.878
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Kaltsa V, 2014, IEEE IMAGE PROC, P2353, DOI 10.1109/ICIP.2014.7025477
   Lui YM, 2012, IEEE T CIRC SYST VID, V22, P930, DOI 10.1109/TCSVT.2011.2181452
   Mahadevan V., 2010, CVPR, V249, P250
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Passino KM, 2002, IEEE CONTR SYST MAG, V22, P52, DOI 10.1109/MCS.2002.1004010
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Raghavendra R., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P136, DOI 10.1109/ICCVW.2011.6130235
   Rao AS, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P14, DOI 10.1109/ICACCI.2013.6637139
   Shandong W, 2010, 2010 IEEE C COMP VIS, P2010
   Thida M, 2013, IEEE T CYBERNETICS, V43, P2147, DOI 10.1109/TCYB.2013.2242059
   Wu XX, 2013, IEEE T CIRC SYST VID, V23, P1422, DOI 10.1109/TCSVT.2013.2244794
NR 22
TC 13
Z9 13
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17755
EP 17777
DI 10.1007/s11042-017-5382-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900011
DA 2024-07-18
ER

PT J
AU Srivastava, R
   Kumar, B
   Singh, AK
   Mohan, A
AF Srivastava, Rohini
   Kumar, Basant
   Singh, Amit Kumar
   Mohan, Anand
TI Computationally efficient joint imperceptible image watermarking and
   JPEG compression: a green computing approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Compression; Jpeg; DCT; Quantization; Checkmark attacks
AB This paper presents a computationally efficient joint imperceptible image watermarking and joint photographic experts group (JPEG) compression scheme. In recent times, the transmission and storage of digital documents/information over the unsecured channel are enormous concerns and nearly all of the digital documents are compressed before they are stored or transmitted to save the bandwidth requirements. There are many similar computational operations performed during watermarking and compression which lead to computational redundancy and time delay. This demands development of joint watermarking and compression scheme for various multimedia contents. In this paper, we propose a technique for image watermarking during JPEG compression to address the optimal trade-off between major performance parameters including embedding and compression rates, robustness and embedding alterations against different known signal processing attacks. The performance of the proposed technique is extensively evaluated in the form of peak signal to noise ratio (PSNR), correlation, compression ratio and execution time for different discrete cosine transform (DCT) blocks and watermark sizes. Embedding is done on DCT coefficients using additive watermarking.
C1 [Srivastava, Rohini; Kumar, Basant] Motilal Nehru Natl Inst Technol, Dept Elect & Comm Engn, Allahabad, Uttar Pradesh, India.
   [Singh, Amit Kumar] Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
   [Mohan, Anand] Indian Inst Technol BHU, Dept Elect Engn, Varanasi, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; Jaypee University of Information Technology;
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM srivastava.rohini14@gmail.com; singhbasant@yahoo.com;
   amit_245singh@yahoo.com; profanandmohan@gmail.com
RI ; Singh, Amit Kumar/D-1300-2015
OI Srivastava, Rohini/0000-0002-3712-6534; Singh, Amit
   Kumar/0000-0001-7359-2068
CR [Anonymous], 2016, CIRCUITS SYSTEMS
   [Anonymous], 2017, BOOK SERIES MULTIMED
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Guo JM, 2010, IEEE T IMAGE PROCESS, V19, P2056, DOI 10.1109/TIP.2010.2045709
   Lin NH, 2004, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P66
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Maheshwari JP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1059, DOI 10.1109/ICCSP.2015.7322663
   Pereira S., 2001, INFORM HIDING, P340, DOI [10.1007/3-540-45496-925, DOI 10.1007/3-540-45496-925]
   SINGH AK, 2016, HDB RES MODERN CRYPT, P246, DOI DOI 10.4018/978-1-5225-0105-3.CH011
   Tian J, 2002, P SOC PHOTO-OPT INS, V4675, P679, DOI 10.1117/12.465329
   Zargar AJ, 2016, INT J ELECTRON SECUR, V8, P53, DOI 10.1504/IJESDF.2016.073734
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhou Y., 2009, P 11 CAN WORKSH INF
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 18
TC 13
Z9 14
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16447
EP 16459
DI 10.1007/s11042-017-5214-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300021
DA 2024-07-18
ER

PT J
AU Ganapathi, S
   Varadharajan, V
AF Ganapathi, Sivakumar
   Varadharajan, Venkatachalam
TI Popularity based hierarchical prefetching technique for P2P
   video-on-demand
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoD; P2P network; Communication; Prefetching technique
AB In Peer-to-Peer Video on Demand System like Video Cassette Recording (VCR) various operations (i.e. forward, backward, resume) are found to be used very frequently. The uncertainty of frequent VCR operations makes it difficult to provide services to play as download and also the workload on VoD server is very high because of it handles the overall network. So it may sometimes hinder the network performance. To overcome these issues we propose to develop popularity based hierarchical prefetching technique in this paper. In this technique, the network is considered in a hierarchical topology and then the popularity level of each video is estimated by the proxy and based on it, the popular video is cached in the proxy and streamed to the required peer nodes in the network. Simulation results of our work show that our proposed prefetching technique outperforms the delay of the previous technique.
C1 [Ganapathi, Sivakumar; Varadharajan, Venkatachalam] Erode Sengunthar Engn Coll, Dept Comp Sci & Engn, Erode, Tamil Nadu, India.
C3 Erode Sengunthar Engineering College
RP Ganapathi, S (corresponding author), Erode Sengunthar Engn Coll, Dept Comp Sci & Engn, Erode, Tamil Nadu, India.
EM sivakumarg0574@gmail.com
RI G, Sivakumar/AAC-7651-2022
OI , Sivakumar G/0000-0002-0455-775X
CR Abbasi U, 2010, INT J COMPUT NETW CO, V2
   Arulkumar CV, 2012, INT J COMPUT APPL, V44
   Chen Y- W, 2011, INT C SOFTW COMP APP
   ChengW Tan Z, 2012, P 2012 2 INT C COMP
   Graffi Kalman, 2008, LOAD BALANCING MULTI
   Hefeeda M., 2008, IEEE/ACM Transactions on Networking, V16
   Kao HH, 2016, J NETW COMPUT APPL, V60, P180, DOI 10.1016/j.jnca.2015.09.010
   Kim E, 2017, J NETW COMPUT APPL, V88, P112, DOI 10.1016/j.jnca.2017.02.012
   Liu P, 2013, COMP SCI NETW TECHN
   Mushtaq M, 2007, LECT NOTES COMPUT SC, V4787, P1
   Nikolaos E, 2008, L CAN LOCALITY AWARE
   Takeda A., 2008, 12 WSEAS INT C COMPU
   Tian Y, 2010, FRONT COMPUT SCI CHI, V4, P500, DOI 10.1007/s11704-010-0347-1
   Wang Q, 2008, POPULARITY AWARE PRE
   Xu C, 2009, IEEE T BROADCAST, V55
   Xu T, 2009, 15 INT C PAR DISTR S
   Yuji Y, 2013, INT C PAR DISTR PROC
NR 17
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15913
EP 15928
DI 10.1007/s11042-017-5167-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200063
DA 2024-07-18
ER

PT J
AU Goklani, HS
   Shravya, S
   Sarvaiya, JN
AF Goklani, Hemant S.
   Shravya, S.
   Sarvaiya, Jignesh N.
TI Single image super-resolution using coupled dictionary learning and
   cross domain mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Clustering; Standard deviation; Sparse
   coding; Coupled dictionary learning
ID K-SVD; INTERPOLATION
AB In this paper, a new algorithm for single image super resolution using coupled wavelet and spatial domain dictionary pairs is proposed. The standard deviation parameter, which is approximately scale invariant for low and high resolution patch pairs is employed for clustering. A pair of online coupled dictionaries is learned for each cluster using a low resolution image. The standard deviation measure of a low resolution patch is used to select the appropriate cluster dictionary pair for reconstructing the high resolution counterpart. Experimental results show that the performance of the proposed algorithm is superior to the existing methods in terms of objective and subjective quality measures. The objective image quality is measured in terms of PSNR and SSIM. This paper also proposed an extended algorithm, based on selective sparse representation over a set of coupled dictionary pair. The extended algorithm applies the coupled dictionary based sparse framework for patches having high standard deviation. Whereas, low complexity patch collaging method is used to super resolve low standard deviation valued patches. It is found empirically that a large percentage of patches have low standard deviation values. Moreover, the selective approach significantly reduces the computational complexity without losing the overall reconstruction quality.
C1 [Goklani, Hemant S.; Shravya, S.; Sarvaiya, Jignesh N.] SVNIT, Dept Elect Engn, Surat 395007, India.
C3 National Institute of Technology (NIT System); Sardar Vallabhbhai
   National Institute of Technology
RP Goklani, HS (corresponding author), SVNIT, Dept Elect Engn, Surat 395007, India.
EM hsgoklani@gmail.com; shravya2490@gmail.com; jns@eced.svnit.ac.in
RI Goklani, Hemantkumar/Y-2190-2019
OI Goklani, Hemantkumar/0000-0002-9478-9334
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], 2001, Int J Comput Vis
   Dai D, 2015, COMPUT GRAPH FORUM, V34, P95, DOI 10.1111/cgf.12544
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Leung BO, 2011, APPL SPECTROSC, V65, P967, DOI 10.1366/11-06398
   Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Li Y, 2016, APPL OPTICS, V55, P1814, DOI 10.1364/AO.55.001814
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Liang RZ, 2016, PROC INT C TOOLS ART, P299, DOI [10.1109/ICTAI.2016.50, 10.1109/ICTAI.2016.0053]
   Mahmoud Nazzal, 2013, IEEE SIGN PROC COMM
   Mairal J, 2009, P 26 ANN INT C MACH, V689-696
   Mallat S., 1999, WAVELET TOUR SIGNAL, DOI [10.1016/B978-012466606-1/50004-0, DOI 10.1016/B978-012466606-1/50004-0]
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Nazzal M, 2015, SIGNAL IMAGE VIDEO P, V9, P1491, DOI 10.1007/s11760-013-0602-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   SOMAN KP, 2006, INSIGHT WAVELETS THE
   Sun D, 2016, DIGIT SIGNAL PROCESS, V49, P33, DOI 10.1016/j.dsp.2015.11.003
   Sun J, 2003, IEEE P COMP SOC C CO, V2
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Suryanarayana G, 2016, AEU INT J ELECT COMM
   Tao DP, 2017, IEEE T CIRC SYST VID, V27, P62, DOI 10.1109/TCSVT.2016.2539778
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Taubman DS, 2001, JPEG 2000 IMAGE COMP, V2000
   Timofte R., 2015, ARXIV151102228
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Walha R, 2013, PROC INT CONF DOC, P484, DOI 10.1109/ICDAR.2013.103
   Wang FF, 2015, OPT EXPRESS, V23, P16803, DOI 10.1364/OE.23.016803
   Wang S., 2012, INT C COMP VIS PATT
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber A., 1997, The usc-sipi image database
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang SY, 2012, IEEE T IMAGE PROCESS, V21, P4016, DOI 10.1109/TIP.2012.2201491
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
NR 46
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14979
EP 15002
DI 10.1007/s11042-017-5084-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200024
DA 2024-07-18
ER

PT J
AU Huang, LH
   Li, W
   Chen, C
   Zhang, F
   Lang, HT
AF Huang, Longhui
   Li, Wei
   Chen, Chen
   Zhang, Fan
   Lang, Haitao
TI Multiple features learning for ship classification in optical imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ship classification; Multiple features learning; Optical imagery;
   Feature-level fusion; Decision-level fusion
ID FACE RECOGNITION; DECISION FUSION; REPRESENTATION; SCALE
AB The sea surface vessel/ship classification is a challenging problem with enormous implications to the world's global supply chain and militaries. The problem is similar to other well-studied problems in object recognition such as face recognition. However, it is more complex since ships' appearance is easily affected by external factors such as lighting or weather conditions, viewing geometry and sea state. The large within-class variations in some vessels also make ship classification more complicated and challenging. In this paper, we propose an effective multiple features learning (MFL) framework for ship classification, which contains three types of features: Gabor-based multi-scale completed local binary patterns (MS-CLBP), patch-based MS-CLBP and Fisher vector, and combination of Bag of visual words (BOVW) and spatial pyramid matching (SPM). After multiple feature learning, feature-level fusion and decision-level fusion are both investigated for final classification. In the proposed framework, typical support vector machine (SVM) classifier is employed to provide posterior-probability estimation. Experimental results on remote sensing ship image datasets demonstrate that the proposed approach shows a consistent improvement on performance when compared to some state-of-the-art methods.
C1 [Huang, Longhui; Li, Wei; Zhang, Fan] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
   [Chen, Chen] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA.
   [Lang, Haitao] Beijing Univ Chem Technol, Fac Sci, Beijing 100029, Peoples R China.
C3 Beijing University of Chemical Technology; State University System of
   Florida; University of Central Florida; Beijing University of Chemical
   Technology
RP Li, W (corresponding author), Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
EM liwei089@ieee.org; chenchen@crcv.ucf.edu; zhangf@mail.buct.edu.cn;
   langht@mail.buct.edu.cn
RI Lang, Haitao/ABA-8911-2020; LI, WEI/ABD-5001-2021; ,
   Chen_Chen/A-8825-2015
OI , Chen_Chen/0000-0003-3957-7061
FU National Key Research and Development Program of China [2016YFB0501501];
   Higher Education and High-Quality and World-Class Universities
   [PY201619]
FX This work was supported by the National Key Research and Development
   Program of China under Grant 2016YFB0501501, and partly by the Higher
   Education and High-Quality and World-Class Universities under Grant
   PY201619.
CR [Anonymous], 2011, APPL IM PATT REC WOR
   [Anonymous], REMOTE SENS
   [Anonymous], 2012, P SPIE INT SOC OPTIC
   [Anonymous], 2007, MIR
   [Anonymous], IEEE J OCEAN ENG
   [Anonymous], P SPIE INT SOC OPT E
   [Anonymous], 2007 IEEE 11 INT C C
   [Anonymous], 2015 IEEE WINT C APP
   [Anonymous], 2015, SIGNAL IMAGE VIDEO P, DOI DOI 10.1371/J0URNAL.P0NE.0139565
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], FEATURE LEARNING HYP
   Arguedas VF, 2015, IEEE IMAGE PROC, P3866, DOI 10.1109/ICIP.2015.7351529
   BARNUM JR, 1986, IEEE J OCEANIC ENG, V11, P196, DOI 10.1109/JOE.1986.1145176
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Guo WY, 2015, OPTIK, V126, P4004, DOI 10.1016/j.ijleo.2015.07.178
   Guo WY, 2015, OPTIK, V126, P2300, DOI 10.1016/j.ijleo.2015.05.132
   Guo WY, 2014, EXPERT SYST APPL, V41, P6446, DOI 10.1016/j.eswa.2014.03.033
   Guo ZH, 2010, IEEE IMAGE PROC, P4521, DOI 10.1109/ICIP.2010.5653119
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Huang SZ, 2016, OPTIK, V127, P11688, DOI 10.1016/j.ijleo.2016.09.089
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li W, 2014, IEEE T GEOSCI REMOTE, V52, P3399, DOI 10.1109/TGRS.2013.2272760
   Liu C., 2003, Advanced Medical Statistics, P1051, DOI DOI 10.1142/9789812388759_0028
   Liu W, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121009
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Margarit G, 2009, REMOTE SENS-BASEL, V1, P375, DOI 10.3390/rs1030375
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Parameswaran S, 2015, PROC SPIE, V9476, DOI 10.1117/12.2177779
   Perronnin Florent, 2007, 2007 IEEE C COMPUTER, P1
   Prasad S, 2008, IEEE T GEOSCI REMOTE, V46, P1448, DOI 10.1109/TGRS.2008.916207
   Prasad S, 2012, IEEE T GEOSCI REMOTE, V50, P3474, DOI 10.1109/TGRS.2012.2185053
   Rainey K., 2011, PROC IEEE APPL IMAG, P1
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Teng F, 2015, SIGNAL PROCESS-IMAGE, V31, P76, DOI 10.1016/j.image.2014.12.006
   Toh KA, 2008, PATTERN RECOGN, V41, P1066, DOI 10.1016/j.patcog.2007.07.020
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Yang GP, 2007, INT C WAVEL ANAL PAT, P1139
   Zhang Mabel M., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P10, DOI 10.1109/CVPRW.2015.7301291
NR 48
TC 25
Z9 28
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13363
EP 13389
DI 10.1007/s11042-017-4952-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900014
DA 2024-07-18
ER

PT J
AU Li, CL
   Bao, ZM
   Wang, X
   Tang, J
AF Li, Chenglong
   Bao, Zhimin
   Wang, Xiao
   Tang, Jin
TI Moving object detection via robust background modeling with recurring
   patterns voting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; Background modeling; Recurring patterns;
   Gaussian mixture model; Graph-based manifold ranking
ID TRACKING
AB This paper proposes a simple yet effective background modeling method based on recurring patterns voting for moving object detection under challenging scenes. Our method performs the following two steps. First, we employ Gaussian Mixture Model (GMM) to generate the initial background probability map for each frame, in which the value of each pixel represents its probability belonging to the background. Second, we perform recurring patterns voting by employing the graph-based manifold ranking algorithm on the spatially constrained graph to refine the probability map. This prior bases on the observation that the same patterns tend to recur frequently in same semantic regions (background or foreground). We verify it in our problem by calculating the background-background, foreground-foreground and background-foreground densities on some video sequences with ground truths. Experimental results on public video sequences suggest that the proposed method significantly outperforms other moving object detection methods.
C1 [Li, Chenglong; Bao, Zhimin; Wang, Xiao; Tang, Jin] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.
C3 Anhui University
RP Li, CL (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.
EM lcl1314@foxmail.com; baozhimin43@foxmail.com; wangxiaocvpr@foxmail.com;
   tj@ahu.edu.cn
RI Li, Chenglong/AAH-4234-2019; Wang, Xiao/CAG-7835-2022
OI Wang, Xiao/0000-0001-6117-6745
FU National Natural Science Foundation of China [61472002]; Natural Science
   Foundation of Anhui Higher Education Institution of China [KJ2017A017];
   Co-Innovation Center for Information Supply & Assurance Technology of
   Anhui University [Y01002449]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61472002, in part by the Natural Science
   Foundation of Anhui Higher Education Institution of China under Grant
   KJ2017A017 and in part by the Co-Innovation Center for Information
   Supply & Assurance Technology of Anhui University under Grant Y01002449.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2012, HDB SOFT COMPUT VIDE
   [Anonymous], 2015, BMVC
   [Anonymous], 2012, P IEEE C COMP VIS PA
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bouttefroy PLM, 2010, INT CONF ACOUST SPEE, P4042, DOI 10.1109/ICASSP.2010.5495760
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chan AB, 2011, MACH VISION APPL, V22, P751, DOI 10.1007/s00138-010-0262-3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Derpanis KG, 2012, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2012.6247815
   Faktor Alon, 2014, BMVC
   Guo CS, 2014, MULTIMED TOOLS APPL, V72, P2633, DOI 10.1007/s11042-013-1566-x
   Hammersley M., 2013, MULTIMED TOOLS APPL, P1
   Jalal AS, 2014, MULTIMED TOOLS APPL, V73, P779, DOI 10.1007/s11042-012-1326-3
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kulchandani JS, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Li CL, 2017, IEEE T CIRC SYST VID, V27, P725, DOI 10.1109/TCSVT.2016.2556586
   Li CL, 2016, IEEE T IMAGE PROCESS, V25, P1947, DOI 10.1109/TIP.2016.2537211
   Li CL, 2015, PROC CVPR IEEE, P5519, DOI 10.1109/CVPR.2015.7299191
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Liu XB, 2014, IEEE T IMAGE PROCESS, V23, P2159, DOI 10.1109/TIP.2013.2297027
   Pilet J, 2008, LECT NOTES COMPUT SC, V5305, P567, DOI 10.1007/978-3-540-88693-8_42
   Shakeri M, 2016, COMPUT VIS IMAGE UND, V146, P27, DOI 10.1016/j.cviu.2016.02.009
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tong YB, 2011, COGN COMPUT, V3, P241, DOI 10.1007/s12559-010-9094-8
   Tu ZZ, 2016, COGN COMPUT, V8, P629, DOI 10.1007/s12559-016-9387-7
   Walha A, 2015, MULTIMED TOOLS APPL, V74, P6745, DOI 10.1007/s11042-014-1928-z
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zheng AH, 2017, MULTIMED TOOLS APPL, V76, P11003, DOI 10.1007/s11042-016-3565-1
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 35
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13557
EP 13570
DI 10.1007/s11042-017-4975-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900022
DA 2024-07-18
ER

PT J
AU Liu, XM
   Zhai, LL
   Zhu, T
   Liu, J
   Zhang, K
   Hu, W
AF Liu, Xiaoming
   Zhai, Leilei
   Zhu, Ting
   Liu, Jun
   Zhang, Kai
   Hu, Wei
TI Multiple TBSVM-RFE for the detection of architectural distortion in
   mammographic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE architecture distortion; MTBSVM-RFE; TBSVM; breast cancer; computer
   aided detection
ID COMPUTER-AIDED DETECTION; BREAST-CANCER; MASS CLASSIFICATION; TEXTURE
   FEATURES; GENE SELECTION; MAMMARY-GLAND; PATTERNS
AB Breast cancer is a leading health threaten for women in the world. Among the several abnormalities observable on mammograms, architecture distortion is one of the most difficult to detect due to its subtlety. Computer-Aided Diagnosis (CAD) technology has been widely used for the detection and diagnosis of breast cancer. In this paper, a new automatic architectural distortion detection method for breast cancer in mammographic images is proposed. Firstly, Gabor filters and phase portrait analysis are used to locate the suspicious regions based on the image characteristic of architectural distortion. Twin bounded Support Vector Machine (TBSVM) is employed to reduce the large amounts of false positives. TBSVM is a kind of binary classifier, which has advantages in both computation efficiency and generalization when dealing with binary classification. For each suspicious region, several features are extracted. However, not every extracted feature contributes to the classification accuracy. We proposed a novel feature selection method for TBSVM and utilized it for the architectural distortion detection in mammograms, named Multiple Twin Bound Support Vector Machines Recursive Feature Elimination (MTBSVM-RFE). The results showed that our proposed method detect the region of architecture distortion with high accuracy.
C1 [Liu, Xiaoming; Zhai, Leilei; Zhu, Ting; Liu, Jun; Zhang, Kai; Hu, Wei] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Liu, Xiaoming; Zhai, Leilei; Zhu, Ting; Liu, Jun; Zhang, Kai; Hu, Wei] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Hubei, Peoples R China.
C3 Wuhan University of Science & Technology
RP Liu, XM (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan, Hubei, Peoples R China.; Liu, XM (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Hubei, Peoples R China.
EM liuxiaoming@wust.edu.cn
RI Liu, Xiaoming/AFF-8698-2022
OI Liu, Xiaoming/0000-0003-3467-5607
FU National Natural Science Foundation of China [61403287, 61472293,
   31201121, 61572381, 61273303]; China Postdoctoral Science Foundation
   [2014 M552039]; Natural Science Foundation of Hubei Province
   [2014CFB288]
FX This work is partially supported by the National Natural Science
   Foundation of China (No. 61403287, No. 61472293, No. 31201121, No.
   61572381, No. 61273303), China Postdoctoral Science Foundation (No. 2014
   M552039) and the Natural Science Foundation of Hubei Province (No.
   2014CFB288).
CR Anand S., 2013, INT J COMPUTER APPL, V74, P12, DOI DOI 10.5120/12880-9752
   [Anonymous], 2011, INT J COMPUT SCI ENG
   Ayres F. J., 2010, SYNTHESIS LECT BIOME, V5, P1, DOI DOI 10.2200/S00301ED1V01Y201010BME038
   Ayres FJ, 2004, PROC SPIE, V5370, P587, DOI 10.1117/12.530966
   Banik S, 2012, MACHINE LEARNING IN COMPUTER-AIDED DIAGNOSIS: MEDICAL IMAGING INTELLIGENCE AND ANALYSIS, P23, DOI 10.4018/978-1-4666-0059-1.ch002
   Banik S, 2013, INT J COMPUT ASS RAD, V8, P121, DOI 10.1007/s11548-012-0681-x
   Ben-Ari R, 2017, I S BIOMED IMAGING, P552, DOI 10.1109/ISBI.2017.7950581
   Bowyer K, 1996, INT CONGR SER, V1119, P431
   Cevikalp H, 2017, IEEE T PATTERN ANAL, V39, P1076, DOI 10.1109/TPAMI.2016.2587647
   Chandy DA, 2014, MULTIMED TOOLS APPL, V72, P2011, DOI 10.1007/s11042-013-1511-z
   DeSantis CE, 2016, CA-CANCER J CLIN, V66, P31, DOI 10.3322/caac.21320
   Duan KB, 2005, IEEE T NANOBIOSCI, V4, P228, DOI 10.1109/TNB.2005.853657
   Duda R., 1973, Pattern Classification and Scene Analysis
   Ferrari RJ, 2004, IEEE T MED IMAGING, V23, P232, DOI 10.1109/TMI.2003.823062
   Ganesan Karthikeyan, 2013, IEEE Rev Biomed Eng, V6, P77, DOI 10.1109/RBME.2012.2232289
   Gershenfeld N.A., 1999, The Nature of Mathematical Modeling
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Guo Q, 2009, INT J COMPUT ASS RAD, V4, P11, DOI 10.1007/s11548-008-0276-8
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hara T, 2006, LECT NOTES COMPUT SC, V4046, P370
   Hofvind S, 2014, RADIOLOGY, V272, P52, DOI 10.1148/radiol.14131502
   Ichikawa T, 2004, PROC SPIE, V5370, P920, DOI 10.1117/12.535116
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Kamra A, 2016, J DIGIT IMAGING, V29, P104, DOI 10.1007/s10278-015-9807-3
   Khan S, 2017, MULTIMED TOOLS APPL, V76, P33, DOI 10.1007/s11042-015-3017-3
   KNUTZEN AM, 1993, MAYO CLIN PROC, V68, P454, DOI 10.1016/S0025-6196(12)60194-3
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Lakshmanan R, 2017, INTELL AUTOM SOFT CO, V23, P183, DOI 10.1080/10798587.2017.1257544
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li H, 2004, MED PHYS, V31, P549, DOI 10.1118/1.1644514
   Liu X, 2016, 8 INT C DIG IM PROC
   Liu XM, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P494, DOI 10.1109/CISP-BMEI.2016.7852761
   Liu XM, 2015, EURASIP J ADV SIG PR, P1, DOI 10.1186/s13634-015-0249-3
   Liu XM, 2015, NEUROCOMPUTING, V152, P388, DOI 10.1016/j.neucom.2014.10.040
   Liu XM, 2014, IEEE SYST J, V8, P910, DOI 10.1109/JSYST.2013.2286539
   Liu Xuebo, 2017, Journal of Chinese Institute of Food Science and Technology, V17, P1, DOI 10.16429/j.1009-7848.2017.10.001
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Matsubara T, 2005, INT CONGR SER, V1281, P1036, DOI 10.1016/j.ics.2005.03.324
   Matsubara T, 2003, INT CONGR SER, V1256, P950, DOI 10.1016/S0531-5131(03)00496-5
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Narváez F, 2017, J MED SYST, V41, DOI 10.1007/s10916-016-0672-5
   Nemoto M, 2009, INT J COMPUT ASS RAD, V4, P27, DOI 10.1007/s11548-008-0267-9
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Prajna S, 2008, MED IMAGING
   Rangayyan RM, 2006, MED BIOL ENG COMPUT, V44, P883, DOI 10.1007/s11517-006-0088-3
   Rangayyan RM, 2013, INT J COMPUT ASS RAD, V8, P527, DOI 10.1007/s11548-012-0793-3
   Rangayyan RM, 2010, J DIGIT IMAGING, V23, P611, DOI 10.1007/s10278-009-9257-x
   Rangayyan RM, 2012, MED MEAS APPL P MEME, P1
   Rangayyan RM, 2011, MED MEAS APPL P MEME, P609
   Rao A.R., 2012, TAXONOMY TEXTURE DES
   RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Reston, 1998, ILLUSTRATED BREAST I
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Sampat MP, 2005, P SOC PHOTO-OPT INS, V5747, P27
   Shao YH, 2011, IEEE T NEURAL NETWOR, V22, P962, DOI 10.1109/TNN.2011.2130540
   Singh B, 2015, COMPUTER, V1, P29952
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Tang JS, 2009, IEEE T INF TECHNOL B, V13, P236, DOI 10.1109/TITB.2008.2009441
   Tourassi GD, 2006, PHYS MED BIOL, V51, P1299, DOI 10.1088/0031-9155/51/5/018
   Yamazaki M, 2016, LECT NOTES COMPUT SC, V9699, P174, DOI 10.1007/978-3-319-41546-8_23
NR 63
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15773
EP 15802
DI 10.1007/s11042-017-5150-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200058
DA 2024-07-18
ER

PT J
AU Vo, Q
   Lee, G
   Kim, S
   Yang, H
AF Vo, QuangNhat
   Lee, GueeSang
   Kim, SooHyung
   Yang, HyungJeong
TI Recognition of Music Scores with Non-Linear Distortions in Mobile
   Devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music score recognition; Optical music recognition; Staff line removal;
   Staff line detection
AB Optical music recognition (OMR), when the input music score is captured by a handheld or a mobile phone camera, suffers from severe degradation in the image quality and distortions caused by non-planar document curvature and perspective projection. Hence the binarization of the input often fails to preserve the details of the original music score, leading to a poor performance in recognition of music symbols. This paper addresses the issue of staff line detection, which is the most important step in OMR, in the presence of nonlinear distortions and describes how to cope with severe degradations in recognition of music symbols. First, a RANSAC-based detection of curved staff lines is presented and staves are segmented into sub-areas for the rectification with bi-quadratic transformation. Then, run length coding is used to recognize music symbols such as stem, note head, flag, and beam. The proposed system is implemented on smart phones, and it shows promising results with music score images captured in the mobile environment.
C1 [Vo, QuangNhat; Lee, GueeSang; Kim, SooHyung; Yang, HyungJeong] Chonnam Natl Univ, Sch Elect & Comp Engn, Gwangju 500757, South Korea.
C3 Chonnam National University
RP Lee, G (corresponding author), Chonnam Natl Univ, Sch Elect & Comp Engn, Gwangju 500757, South Korea.
EM vqnhat@gmail.com; gslee@jnu.ac.kr; shkim@jnu.ac.kr; hjyang@jnu.ac.kr
RI Yang, Hyung-Jeong/GXV-4819-2022
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - MEST [NRF-2015R1D1A1A01060172, NRF-2017R1A4A1015559]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by MEST
   (NRF-2015R1D1A1A01060172 and NRF-2017R1A4A1015559).
CR [Anonymous], SMARTSCORE X PRO REV
   [Anonymous], STRUCTURED DOCUMENT
   [Anonymous], MAKEMUSIC RELEASES F
   [Anonymous], IAPR C MACH VIS APPL
   [Anonymous], MUSIC NOTATION PREPA
   [Anonymous], P INT C DOC AN REC
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], FINALE 2008 POWER
   Bellini P, 2001, FIRST INTERNATIONAL CONFERENCE ON WEB DELIVERING OF MUSIC, PROCEEDINGS, P183, DOI 10.1109/WDM.2001.990175
   Blostein D., 1992, STRUCTURED DOCUMENT, P405
   Bolan Su, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P160, DOI 10.1109/DAS.2012.16
   Bolles R.C., 1981, IJCAI, P637
   Cardoso JD, 2009, IEEE T PATTERN ANAL, V31, P1134, DOI 10.1109/TPAMI.2009.34
   CORMACK AM, 1963, J APPL PHYS, V34, P2722, DOI 10.1063/1.1729798
   Fujinaga I., 2004, Visual Perception of Music Notation: On-Line and Off Line Recognition, P1, DOI DOI 10.4018/978-1-59140-298-5.CH001
   HSU YN, 1982, APPL OPTICS, V21, P4012, DOI 10.1364/AO.21.004012
   KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901
   Kato H, 1992, STRUCTURED DOCUMENT, P435
   Randriamahefa R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P898, DOI 10.1109/ICDAR.1993.395592
   Rebelo A, 2012, INT J MULTIMED INF R, V1, P173, DOI 10.1007/s13735-012-0004-6
   Sayood K., 2002, Lossless Compression Handbook. Communications
   Soille P., 2004, MORPHOLOGICAL IMAGE, DOI [10.1007/978-3-662-05088-0, DOI 10.1007/978-3-662-05088-0]
   Tang Y. Y., 1988, 1988 International Conference on Computer Processing of Chinese and Oriental Languages. Proceedings, P293
   TANG YY, 1993, IEEE T SYST MAN CYB, V23, P155, DOI 10.1109/21.214774
   Tardón LJ, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/843401
   Todd Reed K., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P803, DOI 10.1109/ICPR.1996.547279
   Vo QN, 2014, INT C PATT RECOG, P2956, DOI 10.1109/ICPR.2014.510
NR 27
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15951
EP 15969
DI 10.1007/s11042-017-5169-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200065
DA 2024-07-18
ER

PT J
AU Chen, TH
   Chang, TC
AF Chen, Tzung-Her
   Chang, Tzu-Ching
TI On the security of a BTC-based-compression image authentication scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Block truncation coding; Tampered detection; False
   alarm
ID DIGITAL WATERMARKING METHOD; TAMPER DETECTION
AB With image integrity in mind, the sensitivity-of-tamper property of a new image authentication scheme is always one of main concerns. However, to claim integrity guarantee of image authentication techniques is meaningful only when the false negative probability is taken into consideration. In this paper, the security of an image authentication scheme based on Block-Truncation-Coding (BTC) compression proposed by Li et al. is analyzed. The false alarm of their scheme is shown unneglectable in this paper. Precisely, it is potentially problematic since their scheme only protects the quantization values of BTC codes, but ignores the bitmap part. The main weak design will be shown by means of conducting some counter experiments. Thanks to Li et al.'s well design to protect the two values of quantization levels of the compressed image, the improvement to remove the potential security concern is simple. The experimental results and the further analysis demonstrate that the simple and secure improvement does work.
C1 [Chen, Tzung-Her; Chang, Tzu-Ching] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, 300 Univ Rd, Chiayi 60004, Taiwan.
C3 National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, 300 Univ Rd, Chiayi 60004, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
FU Ministry of Science and Technology, Taiwan, R.O.C. [MOST
   105-2221-E-415-012-]
FX The authors would like to thank the anonymous referees for their
   valuable discussions and comments. This work was partially supported by
   Ministry of Science and Technology, Taiwan, R.O.C., under contract by
   MOST 105-2221-E-415-012-.
CR Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Chan CS, 2007, PATTERN RECOGN, V40, P681, DOI 10.1016/j.patcog.2006.05.018
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Guo JM, 2016, J VIS COMMUN IMAGE R, V35, P193, DOI 10.1016/j.jvcir.2015.12.016
   Hu YC, 2016, MULTIMED TOOLS APPL, P1
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Hui YC, 2013, INT J SECUR APPL, V7, P11
   Kim S, 2016, IEEE T CONSUM ELECTR, V62, P412, DOI 10.1109/TCE.2016.7838094
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li W, 2016, MULTIMED TOOLS APPL, V75, P4771, DOI 10.1007/s11042-015-2502-z
   Liang RZ, 2016, P 2016 23 INT C PATT
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Lin CH, 2013, DISPLAYS, V34, P59, DOI 10.1016/j.displa.2012.11.004
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lin RD, 2009, INT J INNOV COMPUT I, V5, P2603
   Qu DH, 2015, J VIS COMMUN IMAGE R, V29, P46, DOI 10.1016/j.jvcir.2015.01.017
NR 16
TC 15
Z9 15
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12979
EP 12989
DI 10.1007/s11042-017-4927-z
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100059
DA 2024-07-18
ER

PT J
AU Fan, YW
   Zhou, Q
   Yue, WJ
   Zhu, WP
AF Fan, Yawen
   Zhou, Quan
   Yue, Wenjing
   Zhu, Weiping
TI A dynamic causal topic model for mining activities from complex videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic models; Video surveillance; Activity analysis
ID REGRESSION
AB In this paper, a novel probabilistic topic model is proposed for mining activities from complex video surveillance scenes. In order to handle the temporal nature of the video data, we devise a dynamical causal topic model (DCTM) that can detect the latent topics and causal interactions between them. The model is based on the assumption that all temporal relationships between latent topics at neighboring time steps follow a noisy-OR distribution. And the parameter of the noisy-OR distribution is estimated by a data driven approach based on the idea of nonparametric Granger causality statistic. Furthermore, for convergence analysis during model learning process, the Kullback-Leibler between the prior and the posterior distributions is calculated. At last, using the causality matrix learned by DCTM, the total causal influence of each topic is measured. We evaluate the proposed model through experimentations on several challenging datasets and demonstrate that our model can identify the high influence activity in crowded scenes.
C1 [Fan, Yawen; Zhou, Quan; Yue, Wenjing; Zhu, Weiping] Nanjing Univ Posts & Telecommun, Key Lab, Minist Educ Broad Band Wireless Commun & Sensor N, Nanjing, Jiangsu, Peoples R China.
   [Zhou, Quan] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Zhu, Weiping] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Information Science & Technology; Concordia University - Canada
RP Fan, YW (corresponding author), Nanjing Univ Posts & Telecommun, Key Lab, Minist Educ Broad Band Wireless Commun & Sensor N, Nanjing, Jiangsu, Peoples R China.
EM ywfan@njupt.edu.cn; quan.zhou@njupt.edu.cn; yuewj@njupt.edu.cn;
   zwp@njupt.edu.cn
OI Zhu, Wei-Ping/0000-0001-7955-7044
FU Natural Science Foundation of Jiangsu Province [BK20160908]; Key Lab of
   Broadband Wireless Communication and Sensor Network Technology
   [NYKL2015012]; National Natural Science Foundation of China [61401228,
   61501253]; Basic Research Program of Jiangsu Province(Natural Science
   Foundation) [BK20151506]; China Postdoctoral Science Foundation
   [2015M581841]; Postdoctoral Science Foundation of Jiangsu Province
   [1501019A]; Priority Academic Program Development of Jiangsu Higer
   Education Institutions(PAPD); Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology(CICAEET); Nanjing
   University of Information Science and Technology Research Foundation for
   Talented Scholars [2015r014]
FX The authors would like to thank the associated editor and all the
   anonymous reviewers for their valuable comments and suggestions. This
   work was partly supported by Natural Science Foundation of Jiangsu
   Province(Grant No. BK20160908), and the Key Lab of Broadband Wireless
   Communication and Sensor Network Technology(Grant No. NYKL2015012), and
   the National Natural Science Foundation of China (Grant No. 61401228,
   61501253) and the Basic Research Program of Jiangsu Province(Natural
   Science Foundation)(Grant No. BK20151506), and the China Postdoctoral
   Science Foundation(Grant No. 2015M581841), and the Postdoctoral Science
   Foundation of Jiangsu Province (Grant No. 1501019A), and the Priority
   Academic Program Development of Jiangsu Higer Education
   Institutions(PAPD), and the Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology(CICAEET), and the
   Nanjing University of Information Science and Technology Research
   Foundation for Talented Scholars (Grant No. 2015r014).
CR [Anonymous], J AM STAT ASS
   [Anonymous], J AM STAT ASS
   [Anonymous], IEEE T NEURAL NETW L, DOI [10.1109/TNNLS.2016.2527796, DOI 10.1109/TNNLS.2016.2527796]
   Blei D.M., 2006, INT C MACHINE LEARNI, DOI [DOI 10.1145/1143844.1143859, 10.1145/1143844.1143859]
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chua FCT, 2015, COMPUTER SCI
   Emonet Remi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3233, DOI 10.1109/CVPR.2011.5995572
   Fan YW, 2013, SENSORS-BASEL, V13, P13685, DOI 10.3390/s131013685
   Faruquie T.A., 2009, BMVC, P1
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342
   Kinoshita A, 2015, INFORM SYST, V54, P169, DOI 10.1016/j.is.2015.07.002
   Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869
   Kular D, 2015, LECT NOTES COMPUT SC, V9474, P647, DOI 10.1007/978-3-319-27857-5_58
   Li J., 2008, BMVC, V3231, P3232
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   McCaffery J.P., 2013, Neural Networks (IJCNN), The 2013 International Joint Conference on, P1
   Nedungadi AG, 2009, J COMPUT NEUROSCI, V27, P55, DOI 10.1007/s10827-008-0126-2
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Song LB, 2011, MOBILE OPPORTUNISTIC NETWORKS: ARCHITECTURES, PROTOCOLS AND APPLICATIONS, P1, DOI 10.1145/1287791.1287799
   Varadarajan J, 2013, INT J COMPUT VISION, V103, P100, DOI 10.1007/s11263-012-0596-6
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Xue JF, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P229, DOI 10.1145/2911996.2912041
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhou L, 2013, IEEE J SEL AREA COMM, V31, P981, DOI 10.1109/JSAC.2013.130516
NR 29
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10669
EP 10684
DI 10.1007/s11042-017-4760-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900017
DA 2024-07-18
ER

PT J
AU Wang, JL
AF Wang, Jiale
TI Application of improved Quasi-Newton method to the massive image
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Quasi-Newton method; CB filter; BB filter; Big data
ID FILTER
AB Nowadays, sensors have generated more and more images than before, and parallel processing capacity shows great importance in massive image denoising tasks. Those images are always various in quality and hard to recognize by human or computer. In consequence, massive image denoising are essential. In this paper, two kinds of filter based on Quasi-Newton method called CB and BB filter are proposed, which takes the Newton iteration algorithm as the mathematical basis. Both two filters were achieved with MATLAB to produce the n product n matrix filter. The difference is that the CB filter process the pixels from the image center to the edge, while the BB filter process the pixels from the upper left of the image to the lower right boundary. To illustrate the effectiveness of CB and BB filter, we analyze key indicators after the massive image denoising with massive remote sensing image and high resolution image. We also compared the two filters with the traditional FastICA algorithm. The results indicate that the CB and BB filter have their own advantages in different type of image. The two filters both can effectively improve the massive image quality and enhance the visual effect.
C1 [Wang, Jiale] Taizhou Vocat & Tech Coll, Telecommun Inst, Comp Engn Dept, Taizhou, Zhejiang, Peoples R China.
RP Wang, JL (corresponding author), Taizhou Vocat & Tech Coll, Telecommun Inst, Comp Engn Dept, Taizhou, Zhejiang, Peoples R China.
EM wangjiale_wjl@126.com
RI wang, jiale/GPX-1361-2022
OI wang, jiale/0000-0001-6530-7060
CR Ai DN, 2015, OPTIK, V126, P3844, DOI 10.1016/j.ijleo.2015.07.155
   ALZAROK H, 2016, AUT COMP ICAC 2016 2, P278
   [Anonymous], 2015, P IEEE C COMP VIS PA
   Aum J, 2015, APPL OPTICS, V54, pD43, DOI 10.1364/AO.54.000D43
   Goyal Garima, 2016, GLOBAL J COMPUTER SC, V16
   Jin J, 2016, INT J RADIAT ONCOL, V95, P1058, DOI 10.1016/j.ijrobp.2016.02.006
   Khmag A, 2015, J MED IMAG HEALTH IN, V5, P1261, DOI 10.1166/jmihi.2015.1523
   Kim M, 2015, IEEE T CONSUM ELECTR, V61, P72, DOI 10.1109/TCE.2015.7064113
   Kour S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P17, DOI 10.1109/CGVIS.2015.7449884
   Kumudham R, 2016, INT CONF COMPUT POW, P288, DOI 10.1109/ICCPEIC.2016.7557212
   Lin S., 2016, NEUROCOMPUTING
   Miura Yasuyuki, 2016, 2016 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P1, DOI 10.1109/ICCE-TW.2016.7521025
   Miura Y, 2015, IEEE ICCE, P35, DOI 10.1109/ICCE-TW.2015.7216937
   Pawar A, 2015, ANNU IEEE IND CONF
   Stehly L, 2015, GEOPHYS J INT, V201, P1939, DOI 10.1093/gji/ggv110
   Uddin N, 2015, INT CONF INF COMMUN
   Weijie Zhou, 2016, 2016 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P1, DOI 10.1109/ICCE-TW.2016.7521023
   Wong TS, 2016, IEEE IMAGE PROC, P988, DOI 10.1109/ICIP.2016.7532505
   Yang Zhi, 2015, U.S. Patent, Patent No. [8,938,105, 8938105]
NR 19
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12157
EP 12170
DI 10.1007/s11042-017-4863-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100025
DA 2024-07-18
ER

PT J
AU Zhou, Q
   Zhang, C
   Yu, WB
   Fan, YW
   Zhu, H
   Xu, XF
   Ou, WH
   Zhu, WP
   Latecki, LJ
AF Zhou, Quan
   Zhang, Cheng
   Yu, Wenbin
   Fan, Yawen
   Zhu, Hu
   Xu, Xiaofu
   Ou, Weihua
   Zhu, Weiping
   Latecki, Longin Jan
TI Face recognition via fast dense correspondence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image matching; Face alignment; Face recognition; Deformable spatial
   pyramid graph; Dense correspondence
ID SPARSE REPRESENTATION
AB Face recognition plays a significant role in computer vision. It is well know that facial images are complex stimuli signals that suffer from non-rigid deformations, including misalignment, orientation, pose changes, and variations of facial expression, etc. In order to address these variations, this paper introduces an improved sparse-representation based face recognition method, which constructs dense pixel correspondences between training and testing facial samples. Specifically, we first construct a deformable spatial pyramid graph model that simultaneously regularizes matching consistency at multiple spatial extents ranging from an entire image, though coarse grid cells, to every single pixel. Secondly, a matching energy function is designed to perform face alignment based on dense pixel correspondence, which is very effective to address the issue of non-rigid deformations. Finally, a novel coarse-to-fine matching scheme is designed so that we are able to speed up the optimization of the matching energy function. After the training samples are aligned with respect to testing samples, an improved sparse representation model is employed to perform face recognition. The experimental results demonstrate the superiority of the proposed method over other methods on ORL, AR, and LFWCrop datasets. Especially, the proposed approach improves nearly 4.4 % in terms of recognition accuracy and runs nearly 10 times faster than previous sparse approximation methods.
C1 [Zhou, Quan; Fan, Yawen; Zhu, Hu; Xu, Xiaofu; Zhu, Weiping] Nanjing Univ Posts & Telecommun, Key Lab, Minist Educ Broad Band Commun & Sensor Network Te, Nanjing, Jiangsu, Peoples R China.
   [Zhou, Quan; Yu, Wenbin] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Zhang, Cheng] State Grid HuBei Informat & Telecommun Co, Wuhan, Hubei, Peoples R China.
   [Yu, Wenbin] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Jiangsu, Peoples R China.
   [Ou, Weihua] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Guizhou, Peoples R China.
   [Zhu, Weiping] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
   [Latecki, Longin Jan] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Information Science & Technology; Nanjing University of Information
   Science & Technology; Guizhou Normal University; Concordia University -
   Canada; Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Temple University
RP Zhou, Q (corresponding author), Nanjing Univ Posts & Telecommun, Key Lab, Minist Educ Broad Band Commun & Sensor Network Te, Nanjing, Jiangsu, Peoples R China.; Zhou, Q (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
EM quan.zhou@njupt.edu.cn; 37500419@qq.com; ywb1518@126.com;
   ywfan@njupt.edu.cn; zhuhu@njupt.edu.cn; xfuwu@njupt.edu.cn;
   ouweihuahust@gmail.com; weiping@ece.concordia.ca; latecki@temple.edu
RI zhu, hu/GQQ-8365-2022; Ou, Weihua/T-9156-2019; Ou, Weihua/AAD-9887-2020
OI Ou, Weihua/0000-0001-5241-7703; Latecki, Longin Jan/0000-0002-5102-8244
FU National Science Foundation [IIS-1302164]; National Natural Science
   Foundation of China [61401228, 61402122, 61571240, 61501247, 61501259,
   61671253]; China Postdoctoral Science Foundation [2015M581841]; Natural
   Science Foundation of Jiangsu Province [BK20160908]; Postdoctoral
   Science Foundation of Jiangsu Province [1501019A]; Priority Academic
   Program Development of Jiangsu Higer Education Institutions(PAPD);
   Jiangsu Collaborative Innovation Center on Atmospheric Environment and
   Equipment Technology(CICAEET); Nanjing University of Information Science
   and Technology Research Foundation for Talented Scholars [2015r014]
FX The authors would like to thank the associated editor and all the
   anonymous reviewers for their valuable comments and suggestions. This
   work was partly supported by the National Science Foundation (Grant No.
   IIS-1302164), and the National Natural Science Foundation of China
   (Grant No. 61401228, 61402122, 61571240, 61501247, 61501259, 61671253),
   and China Postdoctoral Science Foundation (Grant No. 2015M581841), and
   Natural Science Foundation of Jiangsu Province (Grant No. BK20160908),
   and Postdoctoral Science Foundation of Jiangsu Province (Grant No.
   1501019A), and the Priority Academic Program Development of Jiangsu
   Higer Education Institutions(PAPD), and Jiangsu Collaborative Innovation
   Center on Atmospheric Environment and Equipment Technology(CICAEET), and
   Nanjing University of Information Science and Technology Research
   Foundation for Talented Scholars (Grant No. 2015r014).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P IEEE WORKSH APPL C
   [Anonymous], CONCURRENCY COMPUTAT
   Assaleh K, 2014, LECT NOTES COMPUT SC, V8835, P503, DOI 10.1007/978-3-319-12640-1_61
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boyd S., 2004, CONVEX OPTIMIZATION
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Chen YD, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-0957-4
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Fukui K, 2005, SPRINGER TRAC ADV RO, V15, P192
   Gu B., 2016, IEEE Transactions on Neural Networks and Learning Systems, DOI DOI 10.1109/TNNLS.2016.2527796
   Gu B, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3532
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Jain A. K., 2011, HDB FACE RECOGNITION
   Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708
   Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez A. M., 1998, THE AR FACE DATABASE
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Shao CB, 2017, MULTIMED TOOLS APPL, V76, P6641, DOI 10.1007/s11042-016-3349-7
   Shen FM, 2016, MULTIMED TOOLS APPL, V75, P12535, DOI 10.1007/s11042-014-2340-4
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang WH, 2015, LECT NOTES COMPUT SC, V8944, P812, DOI 10.1007/978-3-319-15554-8_73
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Zhang L, 2015, MULTIMED TOOLS APPL, V74, P123, DOI 10.1007/s11042-013-1457-1
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zhang YD, 2016, J ALZHEIMERS DIS, V50, P1163, DOI 10.3233/JAD-150988
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 42
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10501
EP 10519
DI 10.1007/s11042-017-4569-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900008
DA 2024-07-18
ER

PT J
AU Bouzidi, I
   Zaid, AO
   Larabi, MC
AF Bouzidi, I.
   Zaid, A. Ouled
   Larabi, M. C.
TI Revertible tone mapping of high dynamic range imagery: Integration to
   JPEG 2000
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range; Tone-mapping; Companding; Subband decomposition;
   Gain map; JPEG 2000 compression
ID QUALITY ASSESSMENT; COMPRESSION; DISPLAY
AB This paper presents a revertible tone mapping approach based on subband architecture where the dynamic range of the HDR (High Dynamic Range) image is decreased to LDR (Low Dynamic Range) to fit several types of applications. The LDR image can be later expanded to get back the original HDR content. One important benefit of the proposed approach is its backward compatibility with low dynamic (LDR) image applications since no extra information is needed to perform a very efficient HDR reconstruction. In order to improve the efficiency of our TM (Tone Mapping), we couple it with an optimisation procedure to minimize the reconstruction error. Subjective and objective comparisons with state-of-the-art methods have shown superior quality results of both tone mapped and reconstructed images. As a potential application, the integration of the proposed tone mapping to JPEG 2000 encoder achieved competitive performance compared to reference HDR image encoders.
C1 [Bouzidi, I.; Zaid, A. Ouled] Univ Tunis El Manar, Natl Engn Sch Tunis, SysCom Lab, BP 37, Tunis 1002, Tunisia.
   [Larabi, M. C.] Univ Poitiers, UMR CNRS 6172, XLIM SIC Lab, SP2MI 2 Bd Marie & Pierre Curie,POB 30179, F-86962 Futuroscope, France.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Poitiers
RP Zaid, AO (corresponding author), Univ Tunis El Manar, Natl Engn Sch Tunis, SysCom Lab, BP 37, Tunis 1002, Tunisia.
EM azza.ouledzaid@isi.rnu.tn
OI Ouled Zaid, Azza/0000-0002-3264-5933
CR Akyüz AG, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276425
   [Anonymous], ACM SIGGRAPH 2006 CO
   [Anonymous], 1994, Graph. Gems, DOI DOI 10.1016/B978-0-12-336156-1.50054-9
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   Banterle F., 2006, P 4 INT C COMP GRAPH, P349
   Banterle F., 2012, ACM S APPL PERC 2012, P39
   Bruce NDB, 2014, COMPUT GRAPH-UK, V39, P12, DOI 10.1016/j.cag.2013.10.001
   Cohen J, 2001, SPRING EUROGRAP, P313
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Jianping Z, 2005, WAVELET APPLICATIONS, pXI
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Landis H., 2002, SIGGRAPH COURSE NOTE, V16
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Ma KD, 2015, IEEE T IMAGE PROCESS, V24, P3086, DOI [10.1109/TIP.2015.2436340, 10.1109/TIP.2015.2456638]
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Meylan L, 2006, I SID 14 COL IM C
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Munkberg J, 2006, ACM T GRAPHIC, V25, P698, DOI 10.1145/1141911.1141944
   Pattanaik S. N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P287, DOI 10.1145/280814.280922
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   Pece F., 2010, Proceedings 2010 Conference on Visual Media Production (CVMP 2010). 7th European Conference on Visual Media Production, P1, DOI 10.1109/CVMP.2010.8
   Reinhard E, 2005, IEEE T VIS COMPUT GR, V11, P13, DOI 10.1109/TVCG.2005.9
   Richter PST, 2015, P SPIE APPL DIGITAL, VXXXVIII, P9599
   Scheel A, 2000, COMPUT GRAPH FORUM, V19, pC301, DOI 10.1111/1467-8659.00422
   SMITH MJT, 1990, IEEE T ACOUST SPEECH, V38, P1446, DOI 10.1109/29.57579
   Taubman D, 2000, JPEG 2000 IMAGE COMP, P2001
   Tumblin J, 1999, COMP GRAPH, P83, DOI 10.1145/311535.311544
   Tumblin J, 1999, ACM T GRAPHIC, V18, P56, DOI 10.1145/300776.300783
   Vetterli Martin, 1995, Wavelets and Subband Coding
   Xu RF, 2005, IEEE COMPUT GRAPH, V25, P57, DOI 10.1109/MCG.2005.133
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Zhang Y, 2016, IEEE T CIRC SYST VID, V26, P950, DOI 10.1109/TCSVT.2015.2426552
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
NR 36
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5215
EP 5239
DI 10.1007/s11042-017-4425-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800006
DA 2024-07-18
ER

PT J
AU Ganesan, VSK
   Vasuki, S
AF Ganesan, Veera Senthil Kumar
   Vasuki, S.
TI Maximin distance based band selection for endmember extraction in
   hyperspectral images using simplex growing algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual dimensionality; Band selection; Maximin distance algorithm;
   Simplex growing algorithm; Spectral angle distance; Spectral similarity
   value
ID COMPONENT ANALYSIS; N-FINDR; SIMILARITY; CLASSIFICATION; DESIGN
AB With the fast growing technologies in the field of remote sensing, hyperspectral image analysis has made a great breakthrough. It provides accurate and detailed information of objects in the image when compared to any other remotely sensed data. It is possible because of its high redundancy in nature. But this redundancy in hyperspectral images leads to high computational complexity in their analysis. Hence Dimensionality Reduction (DR) is a significant task in all hyperspectral image processing. DR can be achieved either by feature extraction or feature selection. Feature selection or Band selection is adopted in this paper because of no compromise in original data. Despite many algorithms that exist for band selection, this paper proposes a new concept of Maximin distance algorithm using Spectral Angle Distance (SAD) as distance measure for band selection. Virtual Dimensionality (VD) is used to provide the number of bands to be selected because it has been proved to be reliable estimate. Simplex Growing Algorithm (SGA) is deployed for endmember extraction in the experiment work. In order to evaluate the performance of the proposed band selection algorithm, the Spectral Angle Distance (SAD) and Spectral Similarity Value (SSV) are used as measures. The efficacy of our proposed algorithm has been proved from experimental results in comparison with Constrained Band Selection (CBS), Similarity Based Band Selection (SBBS), Clustering Based Band Selection (CBBS), Uniform Band Selection (UBS), Minimum Variance Principal Component Analysis (MVPCA) and Exemplar Component Analysis (ECA) and Firefly Algorithm Based Band Selection (FABBS).
C1 [Ganesan, Veera Senthil Kumar; Vasuki, S.] Velammal Coll Engn & Technol, Elect & Commun Engn Dept, Madurai, Tamil Nadu, India.
RP Ganesan, VSK (corresponding author), Velammal Coll Engn & Technol, Elect & Commun Engn Dept, Madurai, Tamil Nadu, India.
EM gvs@vcet.ac.in
RI ECE0909, Dr. Vasuki.S/ABG-3155-2021
OI ECE0909, Dr. Vasuki.S/0000-0003-0815-6424
CR [Anonymous], 1993, P 9 THEM C GEOL REM
   Asl MG, 2014, IEEE T GEOSCI REMOTE, V52, P3774, DOI 10.1109/TGRS.2013.2275831
   Boardman J. W., 1993, SUMM 4 ANN JPL AIRB, V1, P11
   Chang C. I., 2003, HYPERSPECTRAL IMAGIN
   Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P2804, DOI 10.1109/TGRS.2006.881803
   Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389
   Chang CI, 2013, IEEE T GEOSCI REMOTE, V51, P1693, DOI 10.1109/TGRS.2012.2207389
   Chang CI, 2011, IEEE T IMAGE PROCESS, V20, P641, DOI 10.1109/TIP.2010.2071310
   Chang CI, 2010, IEEE T GEOSCI REMOTE, V48, P1834, DOI 10.1109/TGRS.2009.2034979
   Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631, DOI 10.1109/36.803411
   Chang CI, 2004, IEEE T GEOSCI REMOTE, V42, P608, DOI 10.1109/TGRS.2003.819189
   CONESE C, 1993, ISPRS J PHOTOGRAMM, V48, P2, DOI 10.1016/0924-2716(93)90059-V
   Du Q, 2008, IEEE GEOSCI REMOTE S, V5, P564, DOI 10.1109/LGRS.2008.2000619
   Envi-Tutorials, 2013, OV HYP REM SENS
   Geng XR, 2014, IEEE T GEOSCI REMOTE, V52, P7111, DOI 10.1109/TGRS.2014.2307880
   Granahan JC, 2001, INT GEOSCI REMOTE SE, P2022, DOI 10.1109/IGARSS.2001.977890
   HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007
   Keshava N, 2004, IEEE T GEOSCI REMOTE, V42, P1552, DOI 10.1109/TGRS.2004.830549
   Kumar GVS, 2017, MULTIMED TOOLS APPL, V76, P8355, DOI 10.1007/s11042-016-3420-4
   Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293
   Plaza A, 2006, IEEE T GEOSCI REMOTE, V44, P3397, DOI 10.1109/TGRS.2006.879538
   Qian Y, 2009, IET COMPUT VIS, V3, P213, DOI 10.1049/iet-cvi.2009.0034
   Shen SS, 2002, PROC SPIE, V4725, P18, DOI 10.1117/12.478755
   Sohaib Muhammad, 2013, International Journal of Computer and Communication Engineering, V2, P101
   Song A, 2015, SENSORS-BASEL, V15, P2593, DOI 10.3390/s150202593
   Su HJ, 2017, IEEE J-STARS, V10, P309, DOI 10.1109/JSTARS.2016.2591004
   Su HJ, 2014, IEEE J-STARS, V7, P2659, DOI 10.1109/JSTARS.2014.2312539
   Sun K, 2015, IEEE GEOSCI REMOTE S, V12, P998, DOI 10.1109/LGRS.2014.2372071
   Sun K, 2014, IEEE J-STARS, V7, P2697, DOI 10.1109/JSTARS.2014.2320299
   TOU JT, 1974, PATTERN RECOGN, P92
   Winter ME, 1999, PROC SPIE, V3753, P266, DOI 10.1117/12.366289
   Zhu FY, 2014, IEEE T IMAGE PROCESS, V23, P5412, DOI 10.1109/TIP.2014.2363423
   Zhu FY, 2014, ISPRS J PHOTOGRAMM, V88, P101, DOI 10.1016/j.isprsjprs.2013.11.014
NR 35
TC 11
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7221
EP 7237
DI 10.1007/s11042-017-4630-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700037
DA 2024-07-18
ER

PT J
AU Guo, Z
   Zhang, YD
   Fan, YY
   Hu, SQ
   Liu, S
   Wang, Y
AF Guo, Zhe
   Zhang, Yandian
   Fan, Yangyu
   Hu, Siqiang
   Liu, Shu
   Wang, Yi
TI Multi-thread block terrain dynamic scheduling based on three-dimensional
   array and Sudoku
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic scheduling; Block terrain; Terrain preprocessing; Sudoku
ID VISUALIZATION
AB With the increasing of the scale and resolution of terrains, graphic processing hardware meet the new challenges during the terrain rendering. To solve this problem, a dynamic scheduling algorithm based on the three-dimensional array and Sudoku is proposed in this paper. Mesh optimization and texture format conversion mode is utilized to reduce the terrain data size without quality reduction. Stratified block terrains can be then built corresponding to the three-dimensional array. Finally, these block terrains are loaded and unloaded dynamically based on Sudoku strategy according to the viewpoint position. Experimental results show that the efficiency of the proposed algorithm is significantly higher than six state-of-the-art algorithms. Consequently, our algorithm has the ability to load a great amount of terrain data with high performance in frame frequency, which achieves more fluid visual experience.
C1 [Guo, Zhe; Zhang, Yandian; Fan, Yangyu; Hu, Siqiang; Liu, Shu; Wang, Yi] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Guo, Z (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
EM guozhe@nwpu.edu.cn; zhangyandian@126.com; fan_yangyu@nwpu.edu.cn;
   jenyse@126.com; liushu0922@mail.nwpu.edu.cn; wangyi79@nwpu.edu.cn
RI WU, SHAN/KGM-5484-2024; wang, yi/KBB-3614-2024
OI Wang, Yi/0000-0002-7743-1779
FU Natural Science Basic Research Plan in Shaanxi Province of China
   [2015JM6317]; National Natural Science Foundation of China [61461025,
   61402371]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61402371 and 61461025, Natural Science
   Basic Research Plan in Shaanxi Province of China under Grant 2015JM6317.
CR Digne J, 2014, J MATH IMAGING VIS, V48, P369, DOI 10.1007/s10851-013-0414-y
   Felgenhauer B., 2006, Mathematical Spectrum, V39, P15
   Judnich J, 2011, P ACM C SIGGRAPH AS, V29
   Kwon K, 2013, COMPUT BIOL MED, V43, P1382, DOI 10.1016/j.compbiomed.2013.07.014
   Liang ZX, 2014, 2014 IEEE 17th International Conference on Computational Science and Engineering (CSE), P1827, DOI 10.1109/CSE.2014.335
   Porwal S, 2013, DEFENCE SCI J, V63, P89, DOI 10.14429/dsj.63.3768
   Que X, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0027-2
   Sanada Y, 2013, J SIGNAL PROCESS, V17, P111, DOI DOI 10.2299/jsp.17.111
   Shen M, 2003, INFORM TECHNOL, V6, P176
   Ulrich T, 2002, P C SIGGRAPH
   Wang H, 2015, GEOINFORMATICS RESOU, P225, DOI [10.1007/s00371-014-0941-6, DOI 10.1007/S00371-014-0941-6]
   Wate P, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P154, DOI 10.1109/ICIIP.2013.6707573
   [吴金连 Wu Jinlian], 2015, [生物学杂志, Journal of Biology], V32, P1
   Yang Y, 2014, OPEN AUTOM CONTROL S, V6, P1378
   Yi J, 2015, INT CONF MEAS, P901, DOI 10.1109/ICMTMA.2015.222
   Zhai R, 2016, NEUROCOMPUTING, V171, P1, DOI 10.1016/j.neucom.2014.08.108
   [张兵强 Zhang Bingqiang], 2013, [计算机工程与应用, Computer Engineering and Application], V49, P213
NR 17
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5819
EP 5835
DI 10.1007/s11042-017-4496-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800031
DA 2024-07-18
ER

PT J
AU Xiao, QK
   Song, R
AF Xiao, Qinkun
   Song, Ren
TI Action recognition based on hierarchical dynamic Bayesian network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; HDBN; Deep neural networks; HASD; Graph model
AB In this paper, a novel action recognition method is proposed based on hierarchical dynamic Bayesian network (HDBN). The algorithm is divided into system learning stage and action recognition stage. In the stage of system learning, the video features are extracted using deep neural networks firstly, and using hierarchical clustering and assisting manually, a hierarchical action semantic dictionary (HASD) is built. The next, we construct the HDBN graph model to present video sequence. In the stage of recognition, we first get the representative frames of unknown video using deep neural networks. The features are inputted into the HDBN, and the HDBN inference is used to get recognition results. The testing results show the proposed method is promising.
C1 [Xiao, Qinkun; Song, Ren] Xian Technol Univ, Dept Elect Informat Engn, Xian 710032, Shaanxi, Peoples R China.
C3 Xi'an Technological University
RP Xiao, QK (corresponding author), Xian Technol Univ, Dept Elect Informat Engn, Xian 710032, Shaanxi, Peoples R China.
EM xiaoqinkun10000@163.com
FU National Natural Science Foundation of China [61271362, 61671362]
FX This research is supported by the project (61271362, 61671362) of the
   National Natural Science Foundation of China.
CR Chaaraoui AA, 2013, PATTERN RECOGN LETT, V34, P1799, DOI 10.1016/j.patrec.2013.01.021
   [Anonymous], 2013, AUT FAC GEST REC FG
   [Anonymous], INT J ADV COMPUTING
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2009, CVPR
   [Anonymous], ARXIV150500295
   [Anonymous], KEY FRAME SELECTION
   Artieres T., 2010, P 13 INT C ARTIFICIA, P177
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen HZ, 2016, PATTERN RECOGN, V55, P148, DOI 10.1016/j.patcog.2016.01.020
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding WW, 2016, SIGNAL PROCESS-IMAGE, V42, P109, DOI 10.1016/j.image.2016.01.010
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Gross Jonathan L., 2011, Graph theory and its applications, V2nd
   Haykin S. S., 2009, NEURAL NETWORKS LEAR
   Husain F, 2016, IEEE ROBOT AUTOM LET, V1, P984, DOI 10.1109/LRA.2016.2529686
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   JhuangH, 2007, ICCV, P1
   Ji XF, 2016, MULTIMED TOOLS APPL, V75, P11847, DOI 10.1007/s11042-015-2661-y
   Kong Y, 2016, COMPUT VIS IMAGE UND, V144, P14, DOI 10.1016/j.cviu.2015.10.001
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Lafferty JohnD., 2004, ICML
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295
   Liu CH, 2016, PATTERN RECOGN, V59, P213, DOI 10.1016/j.patcog.2016.03.019
   Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845
   Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470
   Shen HQ, 2015, MULTIMED TOOLS APPL, V74, P523, DOI 10.1007/s11042-014-1936-z
   Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yi Y, 2016, PATTERN RECOGN, V53, P148, DOI 10.1016/j.patcog.2015.11.022
   Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 35
TC 26
Z9 28
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6955
EP 6968
DI 10.1007/s11042-017-4614-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700024
DA 2024-07-18
ER

PT J
AU Hu, Y
   Hu, XY
   Li, PL
   Ding, Y
AF Hu, Yan
   Hu, Xiangyun
   Li, Penglong
   Ding, Yi
TI Building detection from orthophotos using binary feature classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Building detection; Machine learning; Local feature; Descriptor;
   Classifier
ID SCALE
AB Building detection in orthophotos is crucial for various applications, such as urban planning and real-estate management. In order to realize accurate and fast building detection, a non-interactive approach based on binary feature classification is brought forward in this paper. The proposed approach includes two major stages, i.e., building area detection and building contours extraction. In the first stage, a sequence of intersections is obtained by superpixel segmentation in the subsampled orthophoto, and then building area is reserved roughly according to the classification of intersections. In the second stage, the sequence of intersections is updated by superpixel segmentation in the building area from original orthophoto, and then building contours is extracted in accordance with the classification of intersections likewise. The local feature of the intersections is descripted employing our extremely compact binary descriptor, and is classified using binary bag-of-features. Experiments show that benefiting from binary description and making full use of texture details and color channels, the proposed descriptor is not only computationally frugal, but also accurate. Experiments are also conducted on orthophotos with different roof colors, textures, shapes, sizes and orientations, and demonstrate that the proposed approach are capable of achieving desirable results.
C1 [Hu, Yan; Hu, Xiangyun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
   [Hu, Yan; Li, Penglong; Ding, Yi] Chongqing Geomat Ctr, Chongqing 401121, Peoples R China.
C3 Wuhan University
RP Hu, Y (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.; Hu, Y (corresponding author), Chongqing Geomat Ctr, Chongqing 401121, Peoples R China.
EM huyan_dl023@cqu.edu.cn
RI Chen, Xiaojia/JYV-2395-2024
OI Hu, Xiang-Yun/0000-0003-3623-8304
FU Key Laboratory for Earth Observation, National Administration of
   Surveying, Mapping and Geoinformation of China [K2015009]
FX This research was supported by the Key Laboratory for Earth Observation,
   National Administration of Surveying, Mapping and Geoinformation of
   China (K2015009).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bruzzone L, 2014, REMOTE SENS DIGIT IM, V18, P127, DOI 10.1007/978-94-007-7969-3_9
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Dornaika F, 2016, EXPERT SYST APPL, V58, P130, DOI 10.1016/j.eswa.2016.03.024
   Ghamisi P, 2015, IEEE T GEOSCI REMOTE, V53, P2335, DOI 10.1109/TGRS.2014.2358934
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Khurana M, 2015, INT J ADV RES COMPUT, V4, P158
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li ZH, 2009, OPT EXPRESS, V17, P22096, DOI 10.1364/OE.17.022096
   Li ZH, 2009, OPT EXPRESS, V17, P7407, DOI 10.1364/OE.17.007407
   Liu LC, 2016, INT C PATT RECOG, P1713, DOI 10.1109/ICPR.2016.7899883
   Liu LC, 2017, PATTERN RECOGN, V64, P314, DOI 10.1016/j.patcog.2016.10.034
   Liu LC, 2014, INT C PATT RECOG, P2619, DOI 10.1109/ICPR.2014.452
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Passino KM, 2002, IEEE CONTR SYST MAG, V22, P52, DOI 10.1109/MCS.2002.1004010
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, P1873, DOI 10.1109/IGARSS.2015.7326158
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Yang F, 2012, IET IMAGE PROCESS, V6, P115, DOI 10.1049/iet-ipr.2010.0127
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
NR 33
TC 1
Z9 2
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3339
EP 3351
DI 10.1007/s11042-017-5093-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600024
DA 2024-07-18
ER

PT J
AU Kim, H
   Cho, T
   Ahn, GJ
   Yi, JH
AF Kim, Hyunki
   Cho, Taejoo
   Ahn, Gail-Joon
   Yi, Jeong Hyun
TI Risk assessment of mobile applications based on machine learned malware
   dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile security; Malware analysis; Machine learning
AB With the expected development of the Internet of Things, in which all devices will be connected, mobile devices will play a greater role in providing personalized services and will store larger amounts of personal information. However, the number of malicious applications is also increasing, with the aim being to steal user personal information. Furthermore, given the open-market policies of Android and the distribution structure of the Google Play store, any application developer can readily distribute such applications. On the other hand, end users cannot easily determine whether an application is malicious or not. Therefore, we propose an Android application package (APK) Vulnerability Identification System (AVIS) that can identify malicious applications in advance using the Na < ve Bayes classification scheme. To achieve this goal, AVIS builds a dataset by downloading sample applications and extracting their framework methods. To verify the accuracy of AVIS, we analyze sample applications. The APK vulnerability score determined by AVIS is expected to be used as a core metric for quantitatively evaluating the vulnerability of mobile applications.
C1 [Kim, Hyunki] Soongsil Univ, Dept Software Convergence, Seoul 06978, South Korea.
   [Cho, Taejoo] Soongsil Univ, Dept Comp Sci & Engn, Seoul 06978, South Korea.
   [Ahn, Gail-Joon] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, 699 S Mill Ave,Suite 469, Tempe, AZ 85281 USA.
   [Yi, Jeong Hyun] Soongsil Univ, Sch Software, Seoul 06978, South Korea.
C3 Soongsil University; Soongsil University; Arizona State University;
   Arizona State University-Tempe; Soongsil University
RP Yi, JH (corresponding author), Soongsil Univ, Sch Software, Seoul 06978, South Korea.
EM hitechnet92@gmail.com; taejoo90@gmail.com; gahn@asu.edu; jhyi@ssu.ac.kr
OI Ahn, Gail-Joon/0000-0002-4271-1666
FU Global Research Laboratory (GRL) program through the National Research
   Foundation of Korea (NRF) - Ministry of Science, ICT, and Future
   Planning [NRF-2014K1A1A2043029]; Next-Generation Information Computing
   Development Program through the National Research Foundation of
   Korea(NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2014M3C4A7030649]
FX This research was supported in part by the Global Research Laboratory
   (GRL) program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Science, ICT, and Future Planning
   (NRF-2014K1A1A2043029), and in part by Next-Generation Information
   Computing Development Program through the National Research Foundation
   of Korea(NRF) funded by the Ministry of Science, ICT & Future Planning
   (NRF-2014M3C4A7030649).
CR [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], IJCAI 2001 WORKSHOP
   [Anonymous], 2014, 7 EUR WORKSH SYST SE
   [Anonymous], 1998, LEARNING TEXT CATEGO
   Bailey M, 2007, LECT NOTES COMPUT SC, V4637, P178
   CHO T, 2015, ADV SCI LETT, V21, P381, DOI DOI 10.1166/asl.2015.5804
   Felt A. P., 2011, P 1 ACM WORKSH SEC P, P3, DOI DOI 10.1145/2046614.2046618
   Han J, 2012, MOR KAUF D, P1
   Jung JH, 2013, WIRELESS PERS COMMUN, V73, P1421, DOI 10.1007/s11277-013-1258-x
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
NR 10
TC 17
Z9 18
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 5027
EP 5042
DI 10.1007/s11042-017-4756-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500052
DA 2024-07-18
ER

PT J
AU Ko, HG
   Ko, IY
   Lee, D
AF Ko, Han-Gyu
   Ko, In-Young
   Lee, Dongman
TI Multi-criteria matrix localization and integration for personalized
   collaborative filtering in IoT environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Collaborative filtering; Multi-criteria
   recommendation; Multi-criteria matrix localization and integration
ID RECOMMENDATION ALGORITHMS; INTERNET; THINGS
AB Collaborative filtering (CF)-based recommender systems can be used to deal with the complexity problem of users when they want to identify possible tasks on the fly and perform desired tasks by using various smart objects in Internet of Things (IoT) environments. However, in order to use CF-based recommender systems, users need to provide their feedbacks and there are usually more than one criterion considered when users choose an item. Although there have been studies of multi-criteria recommendations, existing approaches require multi-criteria ratings that are explicitly given by users. It is usually a burden for a user to provide more than one instance of feedback on an item; therefore, user feedback datasets are usually sparse when users are asked to provide multi-criteria ratings. Due to the sparsity of multi-criteria rating data, the similarity measurements used by the existing approaches may produce biased results, possibly leading to degradation of the recommendation accuracy. This problem becomes worse as the sparsity of a dataset increases. To alleviate the effects of the data-sparsity problem, and to take advantage of using multi-criteria ratings, we proposed a multi-criteria matrix localization and integration (MCMLI) approach for collaborative filtering in this paper. The main goal of MCMLI is to find cohesive user-item subgroups (CUISs) for each criterion from sparse data, and to predict users' interests for each criterion in a more precise manner. The proposed approach is composed of three phases. At the first phase, a given user-item matrix is divided into a set of CUIS matrices, each of which is organized with correlated users and items for each criterion. MCMLI repeats this CUIS generation process until the generated subgroups cover all elements of the given user-item matrix. To generate prediction results for each criterion, MCMLI then predicts user ratings on new items for each CUIS and aggregates the prediction results to make recommendations to users. To enable personalized recommendations, during the aggregation process, each user's preferences on multiple criteria are weighted differently according to the number of CUISs to which the user belongs. We demonstrate the effectiveness of our approach by conducting an experiment with real-world datasets from TripAdvisor and Yahoo! Movies. The experimental results show that MCMLI outperforms existing multi-criteria collaborative-filtering-based recommendation methods in terms of the recommendation accuracy. In addition, unlike the existing multi-criteria recommendation approaches, even when the sparsity level of a dataset increases, the recommendation accuracy of MCMLI does not decrease significantly.
C1 [Ko, Han-Gyu; Ko, In-Young; Lee, Dongman] Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Ko, HG (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
EM kohangyu@kaist.ac.kr; iko@kaist.ac.kr; dlee@kaist.ac.kr
RI Lee, Dongman/C-1728-2011; Ko, In-Young/C-1777-2011
FU Institute for Information & communications Technology Promotion (IITP)
   grant - Korea government (MSIP) [2017-0-00537]
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIP)
   (No. 2017-0-00537, Development of Autonomous IoT Collaboration Framework
   for Space Intelligence).
CR Adoinavicius G, 2007, IEEE INTELL SYST, V22, P48, DOI 10.1109/MIS.2007.58
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P769, DOI 10.1007/978-0-387-85820-3_24
   Albani A, 2009, 4 INT WORKSH VAL MOD
   [Anonymous], INT C MACH LEARN ICM
   [Anonymous], 2009, Proceedings of the Third ACM Conference on Recommender Systems, DOI DOI 10.1145/1639714.1639731
   [Anonymous], SECURE INTEGRATION I
   [Anonymous], 2012, Proceedings of the 13th ACM Conference on Electronic Commerce, EC'12, DOI [DOI 10.1145/2229012.2229065, 10.1145/2229012.2229065]
   Banerjee A., 2004, KDD, P509, DOI DOI 10.1145/1014052.1014111
   David H. A., 1988, The Method of Paired Comparisons
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Hsu H., 2005, Wiley Encyclopedia of Clinical Trials, P1, DOI [10.1002/9780471462422.eoct969, DOI 10.1002/9780471462422.EOCT969]
   Jamali M., 2013, P 22 INT C WORLD WID, P643
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Kim B, 2014, PERS UBIQUIT COMPUT, V18, P413, DOI 10.1007/s00779-013-0659-x
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Larose DT., 2005, Introduction to Data-mining
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee J, 2012, J MACH LEARN RES, V13, P2699
   Lee Joonseok, 2013, ICML, P82
   Liu L., 2011, 5 ACM C RECOMMENDER, P77, DOI DOI 10.1145/2043932.2043950
   Ma H., 2008, P 17 ACM C INF KNOWL, P931, DOI [DOI 10.1145/1458082.1458205, 10.1145/1458082.1458205]
   Manouselis N, 2007, INT J PATTERN RECOGN, V21, P311, DOI 10.1142/S021800140700548X
   Mashal I, 2016, PHYSICA A, V451, P646, DOI 10.1016/j.physa.2016.01.051
   Nilashi M, 2015, INFORM SCIENCES, V293, P235, DOI 10.1016/j.ins.2014.09.012
   Nilashi M, 2014, KNOWL-BASED SYST, V60, P82, DOI 10.1016/j.knosys.2014.01.006
   Onuma K, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P657
   Paterek A., 2007, P KDD CUP WORKSH, V2007, P5, DOI [DOI 10.1145/1557019.1557072, 10.1145/1557019.1557072]
   Plageras A, 2016, 42 ANN C IEEE IND EL
   Saaty T.L., 1999, Decision-Making for Leaders: The Analytic Hierarchy Process for Decisions in a Complex World
   SAHOO N, 2006, P 16 WORKSH INF TECH
   Salakhutdinov Ruslan, 2008, P INT C MACH LEARN, P880, DOI [10.1145/1390156.1390267, DOI 10.1145/1390156.1390267]
   Shambour Q, 2012, DECIS SUPPORT SYST, V54, P768, DOI 10.1016/j.dss.2012.09.005
   Vo CC, 2012, MOBILE UBIQUITOUS SY, P332
   Vo CC, 2011, P 9 INT C ADV MOB CO, P223
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Xu B., 2012, P 21 INT C WORLD WID, P21
   Zhang Xi., 2013, WWW, P1501
NR 38
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4697
EP 4730
DI 10.1007/s11042-017-4849-9
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500036
DA 2024-07-18
ER

PT J
AU Liu, YT
   Li, HJ
   Chen, T
   Huang, YQ
   Zhang, L
   Zhang, HX
   Huang, ZC
   Liu, B
   Yang, M
AF Liu, Yu-Ting
   Li, Hui-Jun
   Chen, Ting
   Huang, Ya-Qing
   Zhang, Lian
   Zhang, Hui-Xin
   Huang, Zhi-chun
   Liu, Bin
   Yang, Ming
TI Aberrant functional connectivity in patients with obstructive sleep
   apnea-hypopnea syndrome: a resting-state functional MRI study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Default mode network; Magnetic resonance imaging; Obstructive sleep
   apnea-hypopnea syndrome; Functional connectivity
ID DEFAULT-MODE NETWORK; FASTIGIAL NUCLEUS; WORKING-MEMORY; BRAIN ACTIVITY;
   DAYTIME SLEEPINESS; CORTEX; FLUCTUATIONS; STIMULATION; ACTIVATION;
   SEVERITY
AB The objective of this study was to investigate the change in the default mode network (DMN) in subjects with obstructive sleep apnea-hypopnea syndrome (OSAHS) using resting-state functional connectivity (rsFC). Functional magnetic resonance imaging (rs-fMRI) data were collected from twenty-nine subjects with OSAHS and twenty-six normal controls. The data were analyzed with the rsFC method and were compared between OSAHS subjects and controls. The Z-values of abnormal rsFC in different brain regions were correlated with clinical variables, including the apnea-hypopnea index (AHI), oxygen desaturation index (ODI), Epworth sleepiness scale (ESS), Rey-osterrieth complex figure test (CFT-immediately), CFT-delay, Logical memory test-immediately (LMT-immediately), LMT-delay and Minimum mental state examination (MMSE). The rsFC showed significant increases in the left temporal cortex, right midfrontal cortex, and left precuneus cortex as well as decreases in the bilateral inferior parietal lobule (IPL), left medial prefrontal cortex (MPFC), left superior frontal cortex and right cerebellum in patients with OSAHS. The FC strength in the left precuneus showed a remarkable positive correlation with ODI(p = .032, r = .399)and CFT-delay scores (p = .043, r = .378). We found that the FC strength in the right cerebellum was positively correlated with the CFT-delay scores (p = .017, r = .441). FC strength in the right cerebellum and left IPL demonstrated a remarkable positive correlation with LMT-delay scores (p = .037,r = .389;p = .043 and r = .379, respectively). However, there was a strong negative correlation between the left MPFC region and ESS scores (p = .032, r = -.398). The abnormal rsFC in subjects with OSAHS indicated the compensatory change of brain function, which possibly provides an innovative approach and perspective on understanding the neural mechanism alteration of OSAHS-related cognition.
C1 [Chen, Ting; Huang, Ya-Qing; Zhang, Hui-Xin; Liu, Bin] SEU Southeast Univ, Zhongda Hosp, Dept Radiol, Nanjing 210009, Jiangsu, Peoples R China.
   [Liu, Yu-Ting] SEU, Sch Med, Nanjing 210009, Jiangsu, Peoples R China.
   [Li, Hui-Jun; Yang, Ming] Nanjing Med Univ, Childrens Hosp, Dept Radiol, Nanjing 210008, Jiangsu, Peoples R China.
   [Zhang, Lian; Huang, Zhi-chun] SEU, Dept Otolaryngol Head & Neck Surg, Zhongda Hosp, Nanjing 210009, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China; Nanjing
   Medical University; Southeast University - China
RP Liu, B (corresponding author), SEU Southeast Univ, Zhongda Hosp, Dept Radiol, Nanjing 210009, Jiangsu, Peoples R China.; Yang, M (corresponding author), Nanjing Med Univ, Childrens Hosp, Dept Radiol, Nanjing 210008, Jiangsu, Peoples R China.
EM liubin1220@126.com; yangming19710217@163.com
RI Zhang, Hui/HHN-8494-2022; Li, Ly/JCD-4746-2023; Yuan, Ye/KBC-9835-2024;
   Zhang, Huiming/HZH-4348-2023; Zhang, Cheng/JAD-2236-2023; Yun,
   Wang/KHM-3009-2024
OI Yuan, Ye/0009-0008-1640-7047; 
FU Clinical Medical Science and Technology Special Project of Jiangsu,
   China [BL2013029]; Maternity and Child Care Project, Jiangsu Province,
   China [F201554]; Science and Technology Development Project, Nanjing,
   China [2015sc511023]; Six Talent Peaks Project in Jiangsu Province,
   China [WSN-192]
FX This paper was supported by the Clinical Medical Science and Technology
   Special Project of Jiangsu, China(NO. BL2013029) and was partly
   supported by the Maternity and Child Care Project, Jiangsu Province,
   China(F201554), Science and Technology Development Project, Nanjing,
   China (2015sc511023) and Six Talent Peaks Project in Jiangsu Province
   (WSN-192), China.
CR Akkoyunlu ME, 2013, RESPIRATION, V86, P414, DOI 10.1159/000350461
   Archbold KH, 2009, J CLIN SLEEP MED, V5, P21
   Ayalon L, 2009, J SLEEP RES, V18, P204, DOI 10.1111/j.1365-2869.2008.00707.x
   Bagai K, 2010, NEUROLOGIST, V16, P329, DOI 10.1097/NRL.0b013e3181f097cb
   BONNET MH, 1992, SLEEP, V15, P526
   Buckner RL, 2008, ANN NY ACAD SCI, V1124, P1, DOI 10.1196/annals.1440.011
   Cavanna AE, 2006, BRAIN, V129, P564, DOI 10.1093/brain/awl004
   Chen T, 2016, CNS NEUROL DISORD DR
   Cross RL, 2008, SLEEP, V31, P1103
   Ferini-Strambi L, 2003, BRAIN RES BULL, V61, P87, DOI 10.1016/S0361-9230(03)00068-6
   Fletcher PC, 1996, NEUROIMAGE, V3, P209, DOI 10.1006/nimg.1996.0023
   Fox MD, 2005, P NATL ACAD SCI USA, V102, P9673, DOI 10.1073/pnas.0504136102
   Fox MD, 2007, NAT REV NEUROSCI, V8, P700, DOI 10.1038/nrn2201
   Fox MD, 2009, J NEUROPHYSIOL, V101, P3270, DOI 10.1152/jn.90777.2008
   Fransson P, 2005, HUM BRAIN MAPP, V26, P15, DOI 10.1002/hbm.20113
   Galea M, 2005, AUST J PHYSIOTHER, V51, P198, DOI 10.1016/S0004-9514(05)70034-9
   Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101
   Gusnard DA, 2001, NAT REV NEUROSCI, V2, P685, DOI 10.1038/35094500
   Ip MSM, 2002, AM J RESP CRIT CARE, V165, P670, DOI 10.1164/ajrccm.165.5.2103001
   JOHNS MW, 1991, SLEEP, V14, P540, DOI 10.1093/sleep/14.6.540
   Joo EY, 2013, SLEEP, V36, P1153, DOI 10.5665/sleep.2876
   Joo EY, 2010, SLEEP, V33, P235, DOI 10.1093/sleep/33.2.235
   Kim HC, 1997, AM J RESP CRIT CARE, V156, P1813, DOI 10.1164/ajrccm.156.6.9610026
   Kumar R, 2012, J NEUROSCI RES, V90, P2043, DOI 10.1002/jnr.23083
   Li HJ, 2016, NEUROPSYCH DIS TREAT, V12, P203, DOI 10.2147/NDT.S97449
   LUTHERER LO, 1986, AM J PHYSIOL, V250, pR418, DOI 10.1152/ajpregu.1986.250.3.R418
   LUTHERER LO, 1983, BRAIN RES, V269, P251, DOI 10.1016/0006-8993(83)90134-8
   Macey PM, 2002, AM J RESP CRIT CARE, V166, P1382, DOI 10.1164/rccm.200201-050OC
   Maddock RF, 2001, NEUROSCIENCE, V104, P667, DOI 10.1016/S0306-4522(01)00108-7
   Naghavi HR, 2005, CONSCIOUS COGN, V14, P390, DOI 10.1016/j.concog.2004.10.003
   Park JG, 2011, MAYO CLIN PROC, V86, P549, DOI 10.4065/mcp.2010.0810
   Peng DC, 2014, NEUROPSYCH DIS TREAT, V10, P1819, DOI 10.2147/NDT.S67805
   Prilipko O, 2011, SLEEP, V34, P293, DOI 10.1093/sleep/34.3.293
   Punjabi Naresh M, 2008, Proc Am Thorac Soc, V5, P136, DOI 10.1513/pats.200709-155MG
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Redline S, 2007, J CLIN SLEEP MED, V3, P169
   Reichle ME, 2010, TRENDS COGN SCI, V14, P180, DOI 10.1016/j.tics.2010.01.008
   Sarchielli P, 2008, EUR J NEUROL, V15, P1058, DOI 10.1111/j.1468-1331.2008.02244.x
   Saunamäki T, 2007, ACTA NEUROL SCAND, V115, P1, DOI 10.1111/j.1600-0404.2006.00744.x
   Seneviratne U, 2004, SLEEP MED, V5, P339, DOI 10.1016/j.sleep.2004.01.021
   Shen Y, 2016, BIOL PSYCHIAT, V80, pE13, DOI 10.1016/j.biopsych.2016.02.006
   Shin MS, 2006, NAT PROTOC, V1, P892, DOI 10.1038/nprot.2006.115
   Song XW, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025031
   Squire LR, 2004, ANNU REV NEUROSCI, V27, P279, DOI 10.1146/annurev.neuro.27.070203.144130
   Supekar K, 2010, NEUROIMAGE, V52, P290, DOI 10.1016/j.neuroimage.2010.04.009
   Thomas RJ, 2005, J APPL PHYSIOL, V98, P2226, DOI 10.1152/japplphysiol.01225.2004
   Tregear S, 2009, J CLIN SLEEP MED, V5, P573
   Uddin LQ, 2009, HUM BRAIN MAPP, V30, P625, DOI 10.1002/hbm.20531
   Wang SH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060169
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Wang YJ, 2016, J PSYCHIATR RES, V79, P1, DOI 10.1016/j.jpsychires.2016.04.001
   Wilson CRE, 2010, TRENDS NEUROSCI, V33, P533, DOI 10.1016/j.tins.2010.08.001
   Xu FD, 1997, J APPL PHYSIOL, V82, P1177, DOI 10.1152/jappl.1997.82.4.1177
   Yan CG, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00013
   Zang YF, 2004, NEUROIMAGE, V22, P394, DOI 10.1016/j.neuroimage.2003.12.030
   Zhang Q, 2013, SLEEP, V36, P651, DOI 10.5665/sleep.2620
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2016, TECHNOL HEALTH CARE, V24, pS641, DOI 10.3233/THC-161191
   Zhang YD, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0525-2
   Zhang YD, 2016, SCI REP-UK, V6, DOI 10.1038/srep21816
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhao XH, 2007, EUR J RADIOL, V63, P373, DOI 10.1016/j.ejrad.2007.02.006
NR 63
TC 2
Z9 3
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 4065
EP 4079
DI 10.1007/s11042-017-4670-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600063
DA 2024-07-18
ER

PT J
AU Lu, SY
   Lu, ZH
   Yang, JF
   Yang, M
   Wang, SH
AF Lu, Siyuan
   Lu, Zhihai
   Yang, Jianfei
   Yang, Ming
   Wang, Shuihua
TI A pathological brain detection system based on kernel based ELM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet entropy; K-ELM; Classification; Pattern recognition
ID EXTREME LEARNING-MACHINE; WAVELET TRANSFORM; IMAGES; CLASSIFICATION;
   ENTROPY; MRI; HYBRIDIZATION; OPTIMIZATION; DISEASE
AB Magnetic resonance (MR) imaging is widely used in daily medical treatment. It could help in pre-surgical, diagnosis, prognosis, and postsurgical processes. It could be beneficial for diagnosis to classify MR images of brain into healthy or abnormal automatically and accurately, since the information set MRIs generate is too large to interpret with manual methods. We propose a new approach with wavelet-entropy as the features and the kernel based extreme learning machine (K-ELM) to be the classifier. Our method employs 2D-discreet wavelet transform (DWT), and calculates the entropy as features. Then, a K-ELM is trained to classify images as pathological or healthy. A 10 x 10-fold cross validation is conducted to prevent overfitting. The method achieves the sensitivity as 97.48 %, the specificity as 94.44 %, and the overall accuracy as 97.04 % based on 125 MR images. The performance suggests the classifier is robust and effective by comparison with the recently published approaches.
C1 [Lu, Siyuan; Lu, Zhihai; Wang, Shuihua] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Lu, Siyuan; Lu, Zhihai] Nanjing Normal Univ, Sch Educ Sci, Nanjing 210023, Jiangsu, Peoples R China.
   [Yang, Jianfei] Jiangsu Key Lab 3D Printing Equipment & Mfg, Nanjing 210042, Jiangsu, Peoples R China.
   [Yang, Ming] Nanjing Med Univ, Nanjing Childrens Hosp, Dept Radiol, Nanjing 210008, Jiangsu, Peoples R China.
   [Wang, Shuihua] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
   [Wang, Shuihua] CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
C3 Nanjing Normal University; Nanjing Normal University; Nanjing Medical
   University; Zhejiang University; City University of New York (CUNY)
   System; City College of New York (CUNY)
RP Wang, SH (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Wang, SH (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.; Wang, SH (corresponding author), CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
EM wangshuihua@njnu.edu.cn
RI Lu, Siyuan/ABE-7949-2020; Wang, shuihua/G-7326-2016
OI Lu, Siyuan/0000-0001-6720-1323; Wang, shuihua/0000-0003-4713-2791
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Natural Science Foundation of Jiangsu Province
   [BK20150983]; Open Project Program of the State Key Lab of CADAMP;CG,
   Zhejiang University [A1616]; Fundamental Research Funds for the Central
   Universities [LGYB201604]
FX This study is financially supported by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), Natural
   Science Foundation of Jiangsu Province (BK20150983), Open Project
   Program of the State Key Lab of CAD&CG, Zhejiang University (A1616), the
   Fundamental Research Funds for the Central Universities (LGYB201604)
CR Aguiar V, 2015, PHYSICA A, V423, P72, DOI 10.1016/j.physa.2014.12.031
   Bamford C, 2016, INT PSYCHOGERIATR, V28, P123, DOI 10.1017/S1041610215001039
   Cao WB, 2016, OPTIK, V127, P558, DOI 10.1016/j.ijleo.2015.10.115
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Chen Y, 2013, PHYS MED BIOL, V58, P5803, DOI 10.1088/0031-9155/58/16/5803
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Ertugrul ÖF, 2016, INT J ELEC POWER, V78, P429, DOI 10.1016/j.ijepes.2015.12.006
   Fallah M, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616500195
   Harikumar R, 2015, INT J IMAG SYST TECH, V25, P33, DOI 10.1002/ima.22118
   He YL, 2016, CHEMOMETR INTELL LAB, V151, P78, DOI 10.1016/j.chemolab.2015.12.010
   Hu CH, 2016, NEUROIMAGE, V125, P587, DOI 10.1016/j.neuroimage.2015.10.026
   Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Hwang M, 2016, PLOS ONE, V11, P15
   Kumar A, 2015, J MED IMAG HEALTH IN, V5, P138, DOI 10.1166/jmihi.2015.1369
   Kushnirsky M, 2016, J NEUROSURG, V124, P489, DOI 10.3171/2015.2.JNS141993
   Li B, 2014, SCI WORLD J, V7
   Ma C, 2014, 2014 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P299
   Maitra M, 2006, BIOMED SIGNAL PROCES, V1, P299, DOI 10.1016/j.bspc.2006.12.001
   Mondal U, 2016, T I MEAS CONTROL, V38, P14, DOI 10.1177/0142331214562657
   Mulia IE, 2016, COAST ENG, V109, P1, DOI 10.1016/j.coastaleng.2015.11.010
   Saber A, 2016, IEEJ T ELECTR ELECTR, V11, P43, DOI 10.1002/tee.22187
   Shamshirband S, 2016, CLIM DYNAM, V46, P1893, DOI 10.1007/s00382-015-2682-2
   Tang J, 2015, IEEE T NEURAL NETW L
   Wang BT, 2015, NEUROCOMPUTING, V149, P224, DOI 10.1016/j.neucom.2014.03.076
   Wang SY, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/3159805
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   West RJH, 2015, SCI REP, V5, P13
   Wong PK, 2015, RENEW ENERG, V74, P640, DOI 10.1016/j.renene.2014.08.075
   Yamashita Y, 2016, PATTERN RECOGN, V52, P459, DOI 10.1016/j.patcog.2015.10.002
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Yaroshenko TY, 2015, COMMUN NONLINEAR SCI, V26, P265, DOI 10.1016/j.cnsns.2015.02.013
   Yuvaraj R, 2016, BEHAV BRAIN RES, V298, P248, DOI 10.1016/j.bbr.2015.10.036
   Zhang Y, 2012, P INT C PIPELINES TR, V2012, P269
   Zhang YC, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ORANGE TECHNOLOGIES (ICOT), P3
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/130134
   Zhang YD, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18030077
   Zhang YD, 2016, J ALZHEIMERS DIS, V50, P1163, DOI 10.3233/JAD-150988
   Zhang YD, 2015, PROG ELECTROMAGN RES, V152, P41, DOI 10.2528/PIER15040602
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhang YD, 2015, PATTERN RECOGN LETT, V62, P14, DOI 10.1016/j.patrec.2015.04.016
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2010, J BIOL SYST, V18, P115, DOI 10.1142/S0218339010003652
   Zhou XX, 2015, LECT N BIOINFORMAT, V9043, P201, DOI 10.1007/978-3-319-16483-0_20
NR 48
TC 51
Z9 52
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3715
EP 3728
DI 10.1007/s11042-016-3559-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600045
DA 2024-07-18
ER

PT J
AU Yu, X
   Zhang, CY
   Xue, Y
   Zhu, HF
   Li, YZ
   Tan, YA
AF Yu Xiao
   Zhang Changyou
   Xue Yuan
   Zhu Hongfei
   Li Yuanzhang
   Tan Yu-An
TI An extra-parity energy saving data layout for video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Storage system; Disk array; RS code; S-RAID; Energy efficiency
ID EFFICIENT; ALGORITHM
AB The advent of big data age has brought about a growing performance and scale of the storage system, as well as huge energy consumption. Based on the sequential data storage featured workload as video surveillance, etc., we proposed EPS-RAID, that is to add a solid state disk(SSD) and a parity disk on S-RAID, and to optimize the random reads and writes in storage system by means of random write logs and Reed-Solomon(RS) code. Preserving the grouping strategy and the local parallel strategy of S-RAID, EPS-RAID has achieved good effect for random reads and writes on standby grouping, especially for the repeated reads and writes on the same logical address. The experiments show that, in the 3 file systems of EXT4, NTFS, NILFS, the energy consumption of EPS-RAID which consists of 2 disks of each grouping has effectively improved under the premise of ensuring performance and reliability.
C1 [Yu Xiao; Xue Yuan; Zhu Hongfei; Li Yuanzhang; Tan Yu-An] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Yu Xiao] Shandong Univ Technol, Dept Comp Sci & Technol, Zibo 255022, Shandong, Peoples R China.
   [Zhang Changyou] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
   [Tan Yu-An] Res Ctr Mass Language Informat Proc & Cloud Comp, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology; Shandong University of Technology;
   Chinese Academy of Sciences; Institute of Software, CAS
RP Tan, YA (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.; Tan, YA (corresponding author), Res Ctr Mass Language Informat Proc & Cloud Comp, Beijing 100081, Peoples R China.
EM tan2008@bit.edu.cn
FU National Natural Science Foundation of China [61370063, 61379048,
   U1636213]
FX This research was supported by the National Natural Science Foundation
   of China (No. 61370063, 61379048, No. U1636213).
CR Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   [Anonymous], 1988, A case for redundant arrays of inexpensive disks RAID, DOI DOI 10.1145/50202.50214
   Bagheri S, 2016, COMPUT VIS IMAGE UND, V144, P237, DOI 10.1016/j.cviu.2015.11.014
   Chen P, 1997, ACM COMPUT SURV, V26, P145
   FENG D., 2008, P 16 ANN M IEEE INT, P113
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Li J, 2015, BOUND VALUE PROBL, DOI 10.1186/s13661-014-0269-1
   Li XiaoShun Li XiaoShun, 2011, Transactions of the Chinese Society of Agricultural Engineering, V27, P1
   Li Y, 2014, CHINESE J COMPUT, V36, P1290
   [刘靖宇 Liu Jingyu], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P37
   Lu Y, 2013, J COMPUTER RES DEV, V01, P49
   Ma A, 2015, ACM T STORAGE, V11, DOI 10.1145/2820615
   Mu Y, 2007, CHINESE J ELECTRON, V35, P90
   Narayanan D, 2008, PROCEEDINGS OF THE 6TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '08), P253
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Pinheiro E., 2006, Performance Evaluation Review, V34, P15, DOI 10.1145/1140103.1140281
   Plank J, 2010, SOFTWARE PRACT EXPER, V27, P995
   Plank JS, 2005, SOFTWARE PRACT EXPER, V35, P189, DOI 10.1002/spe.631
   Psannis K, 2008, IEICE T COMMUN, VE91B, P2692, DOI 10.1093/ietcom/e91-b.8.2692
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Psannis KE, 2009, TELECOMMUN SYST, V41, P65, DOI 10.1007/s11235-009-9151-3
   Storer MW, 2008, PROCEEDINGS OF THE 6TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '08), P1, DOI 10.1145/1456469.1456471
   Sun ZZ, 2018, IEEE T CIRC SYST VID, V28, P193, DOI 10.1109/TCSVT.2016.2605045
   Sun ZZ, 2014, MULTIMED TOOLS APPL, V73, P151, DOI 10.1007/s11042-012-1262-2
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang J, 2008, IEEE T COMPUT, V57, P359, DOI 10.1109/TC.2007.70821
   Weddle C., 2007, ACM T STORAGE, V3
   Wu S., 2009, USENIX C FILE STORAG, V9, P239
   Yan F, 2016, CHINESE J ELECTRON, V25, P832, DOI 10.1049/cje.2016.06.021
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zhang XZ, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P2016, DOI 10.1109/ICIT.2016.7475077
   Zhu HF, 2017, FUTURE GENER COMP SY, V73, P106, DOI 10.1016/j.future.2017.01.031
   Zhu RJ, 2017, INT J CRIT INFR PROT, V16, P26, DOI 10.1016/j.ijcip.2016.12.002
   Zhu RJ, 2016, IEICE T INF SYST, VE99D, P351, DOI 10.1587/transinf.2015EDP7217
   Zhu RJ, 2016, DIGIT INVEST, V16, P19, DOI 10.1016/j.diin.2016.01.002
NR 37
TC 19
Z9 20
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4563
EP 4583
DI 10.1007/s11042-017-4540-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500030
DA 2024-07-18
ER

PT J
AU Andries, B
   Lemeire, J
   Munteanu, A
AF Andries, Bob
   Lemeire, Jan
   Munteanu, Adrian
TI Optimized wavelet-based texture representation and streaming for GPU
   texture mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture mapping; Texture streaming; Wavelet transform; Texture
   compression
ID COMPRESSION; DECOMPOSITION
AB Because of the ever increasing resolution of consumer displays, high quality real-time 3D rendering applications require large amounts of 2D texture data, which in turn require large amounts of storage, memory and bandwidth. One of the major advantages of using compressed texture data is the significant decrease in bandwidth requirements, decreasing texture loading times. Additionally, instead of preloading all the potentially required information, texture data can be streamed progressively at run-time, which is a very common scenario in web-based applications, games and large virtual environments. This paper proposes a new texture streaming system, utilizing both pre-computed and run-time scene analysis, camera prediction and wavelet-based texture compression to provide maximal visual quality within bandwidth and real-time constraints. Texture decoding is done on the GPU, saving both on streaming bandwidth and GPU memory. The pre-computed scene analysis system can perform the run-time analysis at virtually no performance cost in multi-threaded systems. The proposed solution can easily be plugged into existing classical texture mapping solutions, as it features drop-in replacement shaders and re-uses existing render facilities. The wavelet-based streaming system results in PSNR improvements of up to 2 dB when compared to a DXT1-based streaming system.
C1 [Andries, Bob; Lemeire, Jan; Munteanu, Adrian] Vrije Univ Brussel, Dept Elect & Informat, Pl Laan 2, B-1050 Brussels, Belgium.
   [Lemeire, Jan] Vrije Univ Brussel, Dept Ind Sci, Pl Laan 2, B-1050 Brussels, Belgium.
C3 Vrije Universiteit Brussel; Vrije Universiteit Brussel
RP Andries, B (corresponding author), Vrije Univ Brussel, Dept Elect & Informat, Pl Laan 2, B-1050 Brussels, Belgium.
EM bob.andries@etro.vub.ac.be; jan.lemeire@etro.vub.ac.be;
   adrian.munteanu@etro.vub.ac.be
RI Lemeire, Jan/AAJ-6474-2020; Munteanu, Adrian/HKO-9955-2023
OI Lemeire, Jan/0000-0002-2106-448X; Munteanu, Adrian/0000-0001-7290-0428
CR Andries B., 2016, VISUAL COMPUT, V32, P1
   Andries B, 2014, IEEE INT C IM PROC 2
   [Anonymous], 2003, LEVEL DETAIL 3D GRAP
   [Anonymous], 2003, HWWS'03: Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware
   Barrett S, 2008, GAM DEV C SAN FRANC
   Bjontegaard G, 2001, VCEGM33ITUTQ616
   Cline D, 1998, VISUALIZATION '98, PROCEEDINGS, P343, DOI 10.1109/VISUAL.1998.745322
   CohenOr D, 1996, IEEE T VIS COMPUT GR, V2, P255, DOI 10.1109/2945.537308
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dick C, 2009, P EUROGRAPHICS CIT, V50
   Dumont R, 2003, ACM T GRAPHIC, V22, P152, DOI 10.1145/636886.636888
   Durand F, 2000, COMP GRAPH, P239, DOI 10.1145/344779.344891
   Hollemeersch CF, 2012, VISUAL COMPUT, V28, P371, DOI 10.1007/s00371-011-0621-8
   Hosseini M., 2012, Proceedings of the 3rd Multimedia Systems Conference, P143
   Iourcha KI, 2003, US Patent, Patent No. [6,658,146, 6658146]
   Kilgard MJ, 2009, LATC OPENGL EXTENSIO
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mavridis P, 2012, COMPUT GRAPH FORUM, V31, P2107, DOI 10.1111/j.1467-8659.2012.03203.x
   Mittring Martin., 2008, ACM SIGGRAPH Games, P23
   Ngoc NP, 2002, QOS FRAMEWORK INTERA
   Nystad A., 2012, Proceedings of the Fourth ACM SIGGRAPH/Eurographics Conference on High-Performance Graphics, P105, DOI 10.2312/EGGH/HPG12/105-114
   Park J, 2016, MULTIMED TOOLS APPL, V75, P1983, DOI 10.1007/s11042-014-2383-6
   Sellers G, 2013, SPARSE TEXTURE OPENG
   Sun YK, 2015, MULTIMED TOOLS APPL, V74, P5449, DOI 10.1007/s11042-014-1863-z
   Treib M, 2012, COMPUT GRAPH FORUM, V31, P383, DOI 10.1111/j.1467-8659.2012.03017.x
   Williams L., 1983, Computer Graphics, V17, P1, DOI 10.1145/964967.801126
   Yu YZ, 1999, COMPUT GRAPH-UK, V23, P245, DOI 10.1016/S0097-8493(99)00034-5
   Zorrilla M, 2014, MULTIMED TOOLS APPL, V71, P533, DOI 10.1007/s11042-013-1516-7
NR 28
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2873
EP 2899
DI 10.1007/s11042-017-4433-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400059
DA 2024-07-18
ER

PT J
AU Ghufran, RS
   Leu, JS
   Prakosa, SW
AF Ghufran, Reza Syahroel
   Leu, Jenq-Shiou
   Prakosa, Setya Widyawan
TI Improving the age estimation accuracy by a hybrid optimization scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; Principle component analysis; Linear discriminant
   analysis; Support vector machines; Genetic algorithm; Particle swarm
   optimization
AB Age estimation from digital contents is an interesting topic. Face image reading for age estimation is an intuitive way after classifying face images into several predefined age groups. Age estimation can be regarded as a multiclass problem due to the variation of given individuals determined by genes and several external factors. There are various applications from age estimation, such as forensic and image detection. To approximate and detect the age of each person, the implementation of age estimation algorithm is essential. Many proposed algorithms contain several methods to build the whole mechanism. However, the implementation of SVM combined with optimization is not explored yet. Using an optimization algorithm supposedly can improve accuracy of age estimation algorithm. Based on that fact, we apply GA and PSO for this goal due to their simplicity and powerful ability. GA and PSO are used for this study to make the comparison between both optimizations. This work derives the results for both with optimization and without optimization to prove whether the approach has been successfully realized or not. In the proposed scheme, we conducted age range estimation with five predefined classes and combined several techniques of extracting estimation information from image data, such as Local Gabor Binary Patterns (LGBP) for filtering, Principle Component Analysis (PCA), Linear Discriminant Analysis (LDA) for feature extraction, Support Vector Machines (SVM) for classification, as well as Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) for optimization. Genetic Algorithm and Particle Swarm Optimization were used to find the most suitable parameters to carry out the SVM method. Experimental results show that our proposed hybrid method can raise the estimation accuracy compared to other schemes. The outcome of fold 3 is enhanced up to 14% for both GA and PSO, and the scheme with GA has diminished processing time up to 26 s while it with PSO can reduce up to 25 s.
C1 [Ghufran, Reza Syahroel; Leu, Jenq-Shiou; Prakosa, Setya Widyawan] Natl Taiwan Univ Sci & Technol, Elect & Comp Engn Dept, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Leu, JS (corresponding author), Natl Taiwan Univ Sci & Technol, Elect & Comp Engn Dept, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM jsleu@mail.ntust.edu.tw
OI Leu, Jenq-Shiou/0000-0001-7197-9912; Prakosa, Setya
   Widyawan/0000-0002-7601-6039
CR [Anonymous], 2010, J EMERGING TRENDS CO
   Chen WN, 2013, IEEE T EVOLUT COMPUT, V17, P241, DOI 10.1109/TEVC.2011.2173577
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Cote M, 2015, IEEE SIGNAL PROC LET, V22, P2102, DOI 10.1109/LSP.2015.2461026
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fukai H., 2011, APPARENT AGE ESTIMAT
   Geng X., 2006, P 14 ACM INT C MULT
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Li J, 2009, 1 INT C INF SCI ENG
   Luu K, 2009, BIOM THEOR APPL SYST
   Rodríguez MA, 2005, IEEE T EVOLUT COMPUT, V9, P252, DOI 10.1109/TEVC.2005.844157
   Sai PK, 2015, NEUROCOMPUTING, V149, P364, DOI 10.1016/j.neucom.2014.03.074
   Sun X, 2008, CYB INT SYST 2008 I
   Takimoto H, 2007, SICE 2007 ANN C IEEE
   Wang X-M, 2009, IM SIGN PROC 2009 CI
   Xie S, 2008, PATT REC 2008 ICPR 2
   Xuefeng C, 2014, INT CONTR AUT WCICA
   Ye F, 2009, UB VIRT REAL 2009 IS
   Zhang WC, 2007, IEEE SIGNAL PROC LET, V14, P875, DOI 10.1109/LSP.2007.903260
   Zhihua X, 2014, CONTR C CCC 2014 33
NR 22
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2543
EP 2559
DI 10.1007/s11042-017-4397-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400045
DA 2024-07-18
ER

PT J
AU Li, R
   Liu, ZH
   Zhang, Y
   Li, YL
   Fu, ZJ
AF Li, Ran
   Liu, Zhenghui
   Zhang, Yu
   Li, Yanling
   Fu, Zhangjie
TI Noise-level estimation based detection of motion-compensated frame
   interpolation in video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Motion-compensated frame interpolation; Noise-level
   estimation; Spectral analysis
ID RATE UP-CONVERSION
AB Motion-Compensated Frame Interpolation (MCFI) is commonly used to produce the fake high-frame-rate videos, and it can be regarded as a video forgery operation from a broad sense. In this paper, we use the noise-level estimation to expose MCFI operator, and exploit the periodicity of noise-level varying to propose an effective automatic detection method. To guarantee the high detection accuracy, the high-pass filtering and the spike enhancement are both employed to extract the peak outliers in the Fourier domain. Depending on these outliers, we design the criterion of credibility value to make a final decision. The extensive experiments evaluated on hundreds of video sequences with different spatial resolutions and two parameter configurations of H.264/AVC have shown that the validity of the proposed method, which has the better detection accuracy for the MCFI method and the frame repetition.
C1 [Li, Ran; Liu, Zhenghui; Zhang, Yu; Li, Yanling] Xinyang Normal Univ, Sch Comp & Informat Technol, Nanhu Rd 237, Xinyang 464000, Peoples R China.
   [Li, Ran; Fu, Zhangjie] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210003, Jiangsu, Peoples R China.
   [Liu, Zhenghui] Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.
   [Liu, Zhenghui] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
C3 Xinyang Normal University; Nanjing University of Information Science &
   Technology; Shenzhen University; Shenzhen University
RP Li, R (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Nanhu Rd 237, Xinyang 464000, Peoples R China.; Li, R (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210003, Jiangsu, Peoples R China.
EM liran358@163.com
RI li, yan/GTI-4638-2022; Li, Ran/N-3389-2013; li, chunyuan/IQW-1618-2023
OI Li, Ran/0000-0001-7475-759X; 
FU National Natural Science Foundation of China [61501393, 61572417,
   61502409, 61471162]
FX This work was supported in part by the National Natural Science
   Foundation of China, under Grants nos. 61501393, 61572417, 61502409 and
   61471162.
CR Alsmirat M. A., 2016, MULTIMED TOOLS APPL, P1
   Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   [Anonymous], 2016, IEEE TIFS, DOI [10.1109/TIFS.2016.2596138, DOI 10.1109/TIFS.2016.2596138]
   Bestagini P, 2013, INT CONF ACOUST SPEE, P3033, DOI 10.1109/ICASSP.2013.6638215
   Bian S, 2014, IEEE T CIRC SYST VID, V24, P2144, DOI 10.1109/TCSVT.2014.2334031
   Bian S, 2014, MULTIMED TOOLS APPL, V72, P437, DOI 10.1007/s11042-013-1364-5
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Dikbas S, 2013, IEEE T IMAGE PROCESS, V22, P2931, DOI 10.1109/TIP.2012.2222893
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   HAAN GD, 1993, IEEE T CIRCUITS SYST, V3, P368
   Jeong SG, 2013, IEEE T IMAGE PROCESS, V22, P4497, DOI 10.1109/TIP.2013.2274731
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liu HB, 2012, IEEE T CIRC SYST VID, V22, P1188, DOI 10.1109/TCSVT.2012.2197081
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mehmood I, 2016, NEUROCOMPUTING, V174, P393, DOI 10.1016/j.neucom.2015.05.126
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Yao YX, 2016, J INF SECUR APPL, V26, P39, DOI 10.1016/j.jisa.2015.12.001
   Yoo DG, 2013, J DISP TECHNOL, V9, P840, DOI 10.1109/JDT.2013.2263374
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 22
TC 11
Z9 13
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 663
EP 688
DI 10.1007/s11042-016-4268-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400028
DA 2024-07-18
ER

PT J
AU Padilla-Zea, N
   Medina, NM
   Vela, FLG
   Paderewski, P
   Collazos, CA
AF Padilla-Zea, Natalia
   Medina Medina, Nuria
   Gutierrez Vela, Francisco L.
   Paderewski, Patricia
   Collazos, Cesar A.
TI PLAGER-VG: platform for managing educational multiplayer video games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design of educational video games; Architecture PLAGER-VG; Collaborative
   learning; Learning process personalization
ID ARCHITECTURE; EXPERIENCES; MODEL
AB Information and communication technologies, in general, and multimedia systems, in particular, are currently incorporated into the learning processes with certain normality. Furthermore, the scientific community agrees that video games, as a specific expression of these technologies, present additional benefits that improve many student skills. In an educational context which uses video games as learning tools, the need for a well-defined framework to develop effective educational games seems evident. However, most educational games are not supported by specific architectures; perhaps because the existing ones do not include fundamental aspects such as collaboration, adaptation or gameplay, or its conceptual language is hardly understandable to the educational team. With the aim of fill this gap, we here describe the architecture PLAGER-VG to design, execute, monitor and adapt collaborative learning processes supported by video games, focusing the paper in the design and personalization aspects. PLAGER-VG is a modular platform composed of five sub-systems which allows incrementally designing video games and using them, as well as integrating a video game with other related to it. In particular, we propose the Design Sub-system for managing the educational game design process and the Personalization Sub-system for adapting the gameplay, and therefore the educational process, to the needs of students. The architecture has been considered during the development of several video games and a set of thirty teachers have expressed their acceptance regarding the main elements of PLAGER-VG.
C1 [Padilla-Zea, Natalia] Univ Int la Rioja UNIR, Avda Paz 137, Logrono 26002, La Rioja, Spain.
   [Medina Medina, Nuria; Gutierrez Vela, Francisco L.; Paderewski, Patricia] Univ Granada, Video Games & E Learning Res Lab, GEDES Res Grp, CITIC UGR, C Periodista Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.
   [Collazos, Cesar A.] Univ Cauca, IDIS Res Grp, Sect Tulcan, Popayan, Colombia.
C3 Universidad Internacional de La Rioja (UNIR); University of Granada;
   Universidad del Cauca
RP Medina, NM (corresponding author), Univ Granada, Video Games & E Learning Res Lab, GEDES Res Grp, CITIC UGR, C Periodista Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.
EM natalia.padilla@unir.net; nmedina@ugr.es; fgutierr@ugr.es;
   patricia@ugr.es; ccollazo@unicauca.edu.co
RI Paderewski Rodriguez, Patricia/E-1009-2012; Padilla Zea,
   Natalia/AAD-7366-2022; Hidayat, Ima Kusumawati/ABF-6870-2021; Medina,
   Nuria Medina/B-1743-2012; Gutierrez Vela, Francisco Luis/C-2433-2012
OI Paderewski Rodriguez, Patricia/0000-0001-6626-9633; Padilla Zea,
   Natalia/0000-0001-6677-0372; Hidayat, Ima
   Kusumawati/0000-0002-3387-9213; Medina, Nuria
   Medina/0000-0002-6013-732X; Collazos, Cesar/0000-0002-7099-8131;
   Gutierrez Vela, Francisco Luis/0000-0001-6629-7597
FU Spanish Ministry of Science and Innovation, as part of the DISPERSA
   [TIN2015-67149-C3-3-R]; Andalusia Research Program [P11-TIC-7486]; FEDER
   (European Regional Development Fund - ERDF)
FX This study and work is financed by the Spanish Ministry of Science and
   Innovation, as part of the DISPERSA Project (TIN2015-67149-C3-3-R), and
   by the Andalusia Research Program under the project P11-TIC-7486
   co-financed by FEDER (European Regional Development Fund - ERDF.
CR Alshammari SH, 2015, RES J APPL SCI, V10, P311, DOI DOI 10.3923/RJASCI.2015.311.316
   [Anonymous], 2007, Journal of Applied Educational Technology
   Aouadi N, 2015, PROC EUR CONF GAME, P15
   Balakrishnan B, 2015, COMPUT APPL ENG EDUC, V23, P352, DOI 10.1002/cae.21605
   Brown DJ, 2011, COMPUT EDUC, V56, P11, DOI 10.1016/j.compedu.2010.04.014
   Carvalho MB, 2015, IEEE INT CONF ADV LE, P147, DOI 10.1109/ICALT.2015.145
   Carvalho MB, 2015, COMPUT EDUC, V87, P166, DOI 10.1016/j.compedu.2015.03.023
   Carvalho MB, 2015, ENTERTAIN COMPUT, V6, P1, DOI 10.1016/j.entcom.2014.11.001
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   del Blanco A, 2010, INT J DIST EDUC, V8, P1, DOI 10.4018/jdet.2010070101
   del Blanco A, 2009, ICALT: 2009 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, P53, DOI 10.1109/ICALT.2009.151
   Egenfeldt-Nielsen S., 2011, Beyond edutainment: Exploring the educational potential of computer games
   Ellis C. A., 1991, Communications of the ACM, V34, P39, DOI 10.1145/99977.99987
   Gifford BR, 1991, LEARNING SOC SERIOUS, V7
   Sánchez JLG, 2012, BEHAV INFORM TECHNOL, V31, P1033, DOI 10.1080/0144929X.2012.710648
   Griffiths M., 2002, Education and Health, V20, P47
   HANNEMAN R. A., 2005, Introduction to social network methods
   Hernandez M, 2016, 4 INT C SOFTW ENG RE
   Hodhod R, 2011, LECT NOTES COMPUT SC, V6530, P1, DOI 10.1007/978-3-642-18452-9_1
   Hu WF, 2010, LECT NOTES COMPUT SC, V6249, P405
   Jarvin L, 2015, NEW DIR CHILD ADOLES, V147, P33, DOI 10.1002/cad.20082
   Jong BS, 2006, LECT NOTES COMPUT SC, V3942, P39, DOI 10.1007/11736639_8
   Kafai YB, 2015, EDUC PSYCHOL-US, V50, P313, DOI 10.1080/00461520.2015.1124022
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   MacDonald J, 2014, INTEGRATING GAMES LE, P273
   McFarlane A, 2002, REPORT ED USE GAMES
   McGloin R, 2016, COMPUT HUM BEHAV, V59, P173, DOI 10.1016/j.chb.2016.02.022
   Moreno-Ger P, 2007, J INTERACT MEDIA EDU
   Nemec J., 2007, EVOLUTION CHILDREN P, P55
   Zea NP, 2009, CSEDU 2009: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION, VOL II, P329
   Padilla-Zea N, 2013, LNCS, V7997, P1
   Padilla-Zea Natalia, 2015, Dyna rev.fac.nac.minas, V82, P223
   Parnandi A, 2015, J MULTIMODAL USER IN, V9, P31, DOI 10.1007/s12193-014-0159-y
   Prensky M., 2001, HORIZON, V9, P1, DOI [10.1108/10748120110424816, DOI 10.1108/10748120110424816, 10.1108/10748120110424843]
   Sancho P., 2011, 2011 IEEE Global Engineering Education Conference (EDUCON), P1177, DOI 10.1109/EDUCON.2011.5773296
   Sancho P, 2009, INT J ENG EDUC, V25, P665
   Sawyer B., 2008, The second European conference on games-based learning, P16
   Sullivan Gail M, 2013, J Grad Med Educ, V5, P541, DOI 10.4300/JGME-5-4-18
   Sun HC, 2016, J SPORT HEALTH SCI, V5, P239, DOI 10.1016/j.jshs.2014.12.004
   Tennyson R, 2011, TECHNOLOGY ENHANCED, P1
   Tsai TH, 2012, J SYST SOFTWARE, V85, P1363, DOI 10.1016/j.jss.2012.01.023
   Wehbe-Alamah H., 2015, Online Journal of Cultural Competence in Nursing and Healthcare, V5, P64, DOI DOI 10.9730/OJCCNH.ORG/V5N1A5
   Weinreich R, 2012, J SYST SOFTWARE, V85, P546, DOI 10.1016/j.jss.2011.05.036
   Zea NP, 2011, STUD COMPUT INTELL, V350, P167
   Zea NPPadilla, 2011, THESIS
NR 45
TC 8
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2115
EP 2152
DI 10.1007/s11042-017-4376-8
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400029
DA 2024-07-18
ER

PT J
AU Wang, QZ
   Wei, MY
   Chen, XM
   Miao, Z
AF Wang, Qingzhu
   Wei, Mengying
   Chen, Xiaoming
   Miao, Zhuang
TI Joint encryption and compression of 3D images based on tensor
   compressive sensing with non-autonomous 3D chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D chaotic cipher; Tensor compressed sensing; Tensor decomposition; 3D
   images
ID PARALLEL FRAMEWORK; HEVC
AB Existing techniques for the simultaneous encryption and compression of three-dimensional (3D) image sequences (e.g., video sequences, medical image sequences) may come with sufficient decryption accuracy or compression ratio, but do not inherently have both; the relationship between them is generally ignored because the images of a sequence are handled individually. To address this problem, we designed Tensor Compressive Sensing (TCS) to simultaneously encrypt and compress a 3D sequence as a tensor rather than several 2D images. To further enhance security, a non-autonomous Lorenz system is constructed to control the three measurement matrices of TCS. The proposed method preserves the intrinsic structure of tensor-based 3D image sequences and achieves a favorable balance of compression ratio, decryption accuracy, and security. Numerical simulation results verify the validity and the reliability of the TCS scheme.
C1 [Wang, Qingzhu; Wei, Mengying; Chen, Xiaoming] Northeast Dianli Univ, Sch Informat Engn, Jilin 132012, Jilin, Peoples R China.
   [Miao, Zhuang] Jilin Univ, China Japan Union Hosp, Dept Neurosurg, Changchun, Jilin, Peoples R China.
C3 Northeast Electric Power University; Jilin University
RP Wang, QZ (corresponding author), Northeast Dianli Univ, Sch Informat Engn, Jilin 132012, Jilin, Peoples R China.
EM 150681573@qq.com
FU National Natural Science Foundation of China [61301257]
FX This work was supported by National Natural Science Foundation of China
   (61301257).
CR Abuturab MR, 2014, OPT LASER ENG, V57, P13, DOI 10.1016/j.optlaseng.2014.01.006
   Alfalou A, 2015, OPT COMMUN, V338, P371, DOI 10.1016/j.optcom.2014.10.020
   Ballester-Ripoll R, 2015, COMPUT GRAPH-UK, V47, P34, DOI 10.1016/j.cag.2014.10.002
   Caiafa CF, 2015, IEEE T SIGNAL PROCES, V63, P780, DOI 10.1109/TSP.2014.2385040
   Cambareri V, 2015, IEEE T INF FOREN SEC, V10, P2182, DOI 10.1109/TIFS.2015.2450676
   Cambareri V, 2015, IEEE T SIGNAL PROCES, V63, P2183, DOI 10.1109/TSP.2015.2407315
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Friedland S, 2014, IEEE T IMAGE PROCESS, V23, P4438, DOI 10.1109/TIP.2014.2348796
   Ji XY, 2017, MULTIMED TOOLS APPL, V76, P12965, DOI 10.1007/s11042-016-3684-8
   Lang J, 2015, OPT COMMUN, V338, P45, DOI 10.1016/j.optcom.2014.10.018
   Li-bo Zhang, 2015, Mathematical Problems in Engineering, V2015, DOI 10.1155/2015/940638
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu H, 2015, OPTIK, V126, P2663, DOI 10.1016/j.ijleo.2015.06.079
   Liu XB, 2016, OPT COMMUN, V366, P22, DOI 10.1016/j.optcom.2015.12.024
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Mishra B, 2016, SIAM J OPTIMIZ, V26, P635, DOI 10.1137/140970860
   Mohamed FH, 2015, NONLINEAR DYNAM, V81, P1053
   Nirmala S, 2015, J OPT, V17, P1
   Qin Y, 2016, OPT LASER ENG, V77, P191, DOI 10.1016/j.optlaseng.2015.09.002
   Ran QW, 2015, OPT COMMUN, V348, P43, DOI 10.1016/j.optcom.2015.03.016
   Rawat N, 2015, J OPT, V17, P1
   Rawat N, 2016, OPTIK, V127, P2282, DOI 10.1016/j.ijleo.2015.11.064
   Sandeep R, 2016, MULTIMED TOOLS APPL, V75, P7779, DOI 10.1007/s11042-015-2695-1
   Sheehan BN, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P355
   Sidiropoulos ND, 2012, IEEE SIGNAL PROC LET, V19, P757, DOI 10.1109/LSP.2012.2210872
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Tong XJ, 2013, NONLINEAR DYNAM, V72, P229, DOI 10.1007/s11071-012-0707-5
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang HQ, 2012, ACTA PHYS SIN-CH ED, V61, DOI 10.7498/aps.61.040505
   Zeng WL, 2016, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3753-z, DOI 10.1007/S11042-016-3753-Z]
   Zhao SM, 2015, OPT COMMUN, V353, P90, DOI 10.1016/j.optcom.2015.04.063
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
NR 38
TC 23
Z9 23
U1 0
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1715
EP 1734
DI 10.1007/s11042-017-4349-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400011
DA 2024-07-18
ER

PT J
AU Zhang, C
   Liu, JC
   Chen, F
   Cui, Y
   Ngai, ECH
   Hu, YM
AF Zhang, Cong
   Liu, Jiangchuan
   Chen, Fei
   Cui, Yong
   Ngai, Edith C. -H.
   Hu, Yuemin
TI Dependency- and similarity-aware caching for HTTP adaptive streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Caching strategy; Segment dependency; Request similarity; Dynamic
   adaptive streaming over HTTP
ID MULTIMEDIA; MODEL
AB There has been significant interest in the use of HTTP adaptive streaming for live or on-demand video over the Internet in recent years. To mitigate the streaming transmission delay and reduce the networking overhead, an effective and critical approach is to utilize cache services between the origin servers and the heterogeneous clients. As the underlying protocol for web transactions, HTTP has great potentials to explore the resources within state-of-the-art CDNs for caching; yet distinct challenges arise in the HTTP adaptive streaming context. After examining a long-term and large-scale adaptive streaming dataset as well as statistical analysis, we demonstrate that the switching requests among the different qualities frequently emerge and constitute a significant portion in a per-day view. Consequently, they have substantially affected the performance of cache servers and Quality-of-Experience (QoE) of viewers. In this paper, we propose a novel cache model that captures the dependency among the segments in the cache server for adaptive HTTP streaming. Our work does not assume any specific selection algorithm on the client's side and hence can be easily incorporated into existing streaming cache systems. Its centralized nature is also well accommodated by the latest DASH specification. Moreover, we extend our work to the multi-server caching context and present a similarity-aware allocation mechanism to enhance the caching efficiency. The performance evaluation shows our dependency- and similarity-aware strategy can significantly improve the cache hit-ratio and QoE of HTTP streaming as compared to previous approaches.
C1 [Zhang, Cong; Liu, Jiangchuan] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC, Canada.
   [Chen, Fei] Jiangnan Univ, Sch Digital Media, Wuxi, Peoples R China.
   [Cui, Yong] Tsinghua Univ, Dept Comp Sci, Beijing, Peoples R China.
   [Ngai, Edith C. -H.] Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
   [Liu, Jiangchuan; Hu, Yuemin] South China Agr Univ, Coll Nat Resources & Environm, Guangzhou, Guangdong, Peoples R China.
C3 Simon Fraser University; Jiangnan University; Tsinghua University;
   Uppsala University; South China Agricultural University
RP Liu, JC (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC, Canada.; Liu, JC (corresponding author), South China Agr Univ, Coll Nat Resources & Environm, Guangzhou, Guangdong, Peoples R China.
EM congz@cs.sfu.ca; csljc@ieee.org; chenf@jiangnan.edu.cn;
   cuiyong@tsinghua.edu.cn; edith.ngai@it.uu.se; ymhu@scau.edu.cn
CR Adhikari V. K., 2012, P IEEE INFOCOM 12 OR
   [Anonymous], P IEEE INFOCOM 14 TO
   Basso S, 2014, P ACM MMSYS 14 NEW Y
   CBC Sports, 2014, CBC FIFAWORLD CUP WA
   Cheng X, 2011, P ACM NOSSDAV 11 NEW
   Cheuk WK, 2007, MULTIMED TOOLS APPL, V35, P311, DOI 10.1007/s11042-007-0134-7
   Dreier T, 2016, RIO 2016 ONLINE OLYM
   Erman J., 2011, P 2011 ACM SIGCOMM C, P127
   Gouta A, 2013, P IEEE MASCOTS 13 SA
   Han J, 2012, MOR KAUF D, P1
   Hao J, 2014, P ACM MMSYS 14 NEW Y
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   Kim HJ, 2014, MULTIMED TOOLS APPL, V72, P2163, DOI 10.1007/s11042-013-1507-8
   Lee DH, 2014, P ACM NOSSDAV 14 NEW
   Li BC, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2505805
   Liu C, 2012, P ACM MMSYS 12 NEW Y
   Liu JC, 2004, IEEE COMMUN MAG, V42, P88, DOI 10.1109/MCOM.2004.1321397
   Liu PC, 2012, MULTIMED TOOLS APPL, V60, P47, DOI 10.1007/s11042-011-0793-2
   Lu Y, 2004, IEEE T PARALL DISTR, V15, P440, DOI 10.1109/TPDS.2004.1278101
   Malamos AG, 2002, MULTIMED TOOLS APPL, V16, P207, DOI 10.1023/A:1013956019587
   MALAMOS AG, 1999, P IMACS IEEE CSCC 99
   Mok RKP, 2012, P ACM MMSYS 12 NEW Y
   Mueller C, 2012, P IEEE VCIP 12 SAN D
   Nafaa A, 2012, MULTIMED TOOLS APPL, V59, P169, DOI 10.1007/s11042-011-0755-8
   Rejaie R, 2000, P IEEE INFOCOM 10 TE
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Timmerer C., 2013, DYNAMIC ADAPTIVE STR
   Wang G, 2010, P IEEE INFOCOM 10 SA
   Yu F, 2003, IEEE T CIRC SYST VID, V13, P257, DOI 10.1109/TCSVT.2003.809829
   Zhou C, 2012, P IEEE VCIP 12 SAN D
NR 30
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1453
EP 1474
DI 10.1007/s11042-016-4308-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400060
DA 2024-07-18
ER

PT J
AU Chen, HC
   Wong, CC
   Feng, HM
AF Chen, Hua-Ching
   Wong, Ching-Chang
   Feng, Hsuan-Ming
TI Wireless image fuzzy recognition system for human activity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human Activity; Fuzzy image model; Wireless Network; Image Recognition
ID VIDEO; NETWORKS; SERVICE; EVENTS
AB This study developed a fuzzy image model system for transmitting data over a wireless network channel to efficiently realize human activity in virtual images presentation. Because of the excellent mobile characteristics of wireless sensing networks, small devices are very desirable for local-area deployment. Complex model identification problems, such as acquiring and handling wireless image patterns, require analyzing a large amount of data, which occupies a long time at an acceptable transmission quality. In the proposed system, a cross-layer access method is employed to improve the visual clarity. Image packets are assigned to tune the category queue priority, with the probability allocated through a Markov chain model. This is a favorable approach to balancing the wireless image transmission traffic load. The similarity mixing algorithm, which is based on the maximal similarity and minimal disparity concepts, is used to aggregate the primary image features. The collected image patterns with converted coding vectors are efficiently trained through a human feature recognition procedure to generate a human model. A human action is received in real time from wireless sensing networks, and the image feature is retrieved by approximating a higher compatibility in practice simulations. The fuzzy image model uses the simple region-based evaluation and flexible extraction concepts to describe appropriate image partitions. This technology provides the highest possibility of human feature maps to identify the current action and offers a simple method for detecting human activity in indoor environments. Several human sensing and feature mapping experiments were conducted to verify the feasibility of applying the image recognition technology in nonlinear, time variant, and uncertain human activity problems. This study integrates numerous advantages from the mobility of wireless sensing; the proposed system efficiently controls congested image packages and easily confirms their related human activity. Experimental results verify that 60 testing frames approach about 96.6% accuracy within 3 s. These evaluations illustrate that it is applicable usage in some indoor environments.
C1 [Chen, Hua-Ching; Feng, Hsuan-Ming] Natl Quemoy Univ, Dept Comp Sci & Informat Engn, 1 Univ Rd, Kin Ning Vallage Kinmen 892, Taiwan.
   [Wong, Ching-Chang] Tamkang Univ, Dept Elect Engn, New Taipei, Taiwan.
C3 Tamkang University
RP Feng, HM (corresponding author), Natl Quemoy Univ, Dept Comp Sci & Informat Engn, 1 Univ Rd, Kin Ning Vallage Kinmen 892, Taiwan.
EM hmfeng@nqu.edu.tw
RI 陳, 華慶/JYQ-3317-2024
OI 陳, 華慶/0009-0007-0930-1431; Feng, Hsuan-Ming/0000-0002-6498-7006
FU National Science Council of the Republic of China [NSC
   102-2221-E-507-002]
FX This research was partly supported by the National Science Council of
   the Republic of China under contract NSC 102-2221-E-507-002.
CR Alvarez-Alvarez A, 2013, INFORM SCIENCES, V233, P162, DOI 10.1016/j.ins.2013.01.029
   Amer A, 2005, REAL-TIME IMAGING, V11, P244, DOI 10.1016/j.rti.2004.12.001
   [Anonymous], 2005, 80211E IEEE
   Azhari S. V., 2016, IEEE 2016 MED AD HOC, P1
   Chen CW, 2013, CHINA COMMUN, V10, P1, DOI 10.1109/CC.2013.6520934
   Chen HC, 2016, MULTIMED TOOLS APPL, V75, P15327, DOI 10.1007/s11042-015-2518-4
   Chen HC, 2014, INT J INNOV COMPUT I, V10, P133
   Chen HC, 2013, INT J COMPUT SCI ENG, V8, P171
   Chen YP, 2008, APPL MATH COMPUT, V205, P849, DOI 10.1016/j.amc.2008.05.099
   D'Urso P, 2013, FUZZY SET SYST, V215, P29, DOI 10.1016/j.fss.2012.05.009
   Fernández C, 2011, EXPERT SYST APPL, V38, P4068, DOI 10.1016/j.eswa.2010.09.070
   Gómez-Romero J, 2011, EXPERT SYST APPL, V38, P7494, DOI 10.1016/j.eswa.2010.12.118
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Ignatov AD, 2016, MULTIMED TOOLS APPL, V75, P7257, DOI 10.1007/s11042-015-2643-0
   Kim JO, 2005, GLOB TELECOMM CONF, P3341
   Majkowski J, 2006, 64 VEH TECHN C VTC 2, P1
   Rahman SA, 2013, J VIS COMMUN IMAGE R, V24, P217, DOI 10.1016/j.jvcir.2012.12.001
   Ramos N, 2007, WIREL NETW, V13, P511, DOI 10.1007/s11276-006-9203-5
   Shiang-Min Jou, 2013, ICIC Express Letters, V7, P971
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Xiaofeng Li, 2010, 2010 International Conference on Computational Problem-Solving (ICCP 2010), P306
NR 21
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25231
EP 25251
DI 10.1007/s11042-016-4302-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300038
DA 2024-07-18
ER

PT J
AU Forestiero, A
AF Forestiero, Agostino
TI Bio-inspired algorithm for outliers detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outliers detection; Data streams; Bio-inspired algorithm; Multi-agent
   systems
AB An essential activity to obtain valuable information to identify, for example, intrusions, faults, system failures, etc, is outliers detection. This paper proposes a bio-inspired algorithm able to detect anomaly data in distributed systems. Each data object is associated with a mobile agent that follows the well-known bio-inspired algorithm of flocking. The agents are randomly disseminated onto a virtual space where they move autonomously in order to form one or more flocks. Through a tailored similarity function, the agents associated with similar objects join in the same flock, whereas, the agents associated with dissimilar objects do not join in any flock. The objects associated with isolated agents or associated with agents grouped into flock with a number of entities lower than a given threshold, represent the outliers. Experimental results on synthetic and real data sets confirm the validity of the approach.
C1 [Forestiero, Agostino] Natl Res Council Italy, Inst High Performance Comp & Networking, CNR ICAR, Via Pietro Bucci 7-11 C, I-87036 Arcavacata Di Rende, CS, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad
   Alte Prestazioni (ICAR-CNR)
RP Forestiero, A (corresponding author), Natl Res Council Italy, Inst High Performance Comp & Networking, CNR ICAR, Via Pietro Bucci 7-11 C, I-87036 Arcavacata Di Rende, CS, Italy.
EM agostino.forestiero@icar.cnr.it
RI Forestiero, Agostino/AAW-9191-2020
OI FORESTIERO, AGOSTINO/0000-0002-3025-7689
CR Acuna E.C.A. Rodriguez., 2004, META ANAL STUDY OUTL
   Aggarwal C.C., 2007, ADV DATABASE SYSTEMS, P9, DOI DOI 10.1007/978-0-387-47534-9_
   Aggarwal CC, 2001, SIGMOD RECORD, V30, P37
   [Anonymous], 2012, OUTLIER ANAL
   [Anonymous], P IEEE SWARM INT S S
   [Anonymous], 2003, KDD 03, DOI [10.1145/956750.956758, DOI 10.1145/956750.956758]
   [Anonymous], 2002, ADV INF SECUR
   [Anonymous], 2010, P IEE C EV COMP IEEE, DOI DOI 10.1109/CEC.2010.5586152
   [Anonymous], 1997, Proceedings of the 20th national information systems security conference
   [Anonymous], 2011, INT J COMPUTER SCI E
   Arning A., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P164
   Asuncion A., 2007, Uci machine learning repository
   Babcock B., 2002, P 21 ACM SIGMOD SIGA, P1, DOI [DOI 10.1145/543613.543615, 10.1145/543613]
   Bonabeau E., 1999, SWARM INTELLIGENCE N, V4
   Cao F, 2006, SIAM PROC S, P328, DOI 10.1137/1.9781611972764.29
   Cui XH, 2006, LECT NOTES COMPUT SC, V4149, P124
   EBERHART R., 2001, Swarm Intelligence
   Elahi M, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 5, PROCEEDINGS, P298, DOI 10.1109/FSKD.2008.374
   Ellabib I, 2007, INFORM SCIENCES, V177, P1248, DOI 10.1016/j.ins.2006.09.016
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Folino G, 2009, INFORM SCIENCES, V179, P3059, DOI 10.1016/j.ins.2009.05.017
   Forestiero A, ICTAI
   Gupta M, 2014, IEEE T KNOWL DATA EN, V26, P2250, DOI 10.1109/TKDE.2013.184
   Huang L., 2007, NIPS, P617
   Jindal R., 2013, INT J INNOV TECHNOL, V3, P128
   Khalilian M, 2010, ABS10065261 CORR
   Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P392
   Liu B., 2015, INFORMATICA, V39
   Locasto MichaelE., 2004, Collaborative distributed intrusion detection
   Mohemmed A., 2010, P 12 ANN C GEN EV CO, P83, DOI [10.1145/1830483.1830498, DOI 10.1145/1830483.1830498]
   Monmarché N, 1999, LECT NOTES ARTIF INT, V1674, P626
   Otey ME, 2006, DATA MIN KNOWL DISC, V12, P203, DOI 10.1007/s10618-005-0014-6
   Palpanas T, 2003, SIGMOD REC, V32, P77, DOI 10.1145/959060.959074
   Pokrajac D, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, VOLS 1 AND 2, P504, DOI 10.1109/CIDM.2007.368917
   Ramaswamy S, 2000, SIGMOD REC, V29, P427, DOI 10.1145/335191.335437
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Su L, 2007, LECT NOTES COMPUT SC, V4782, P74
   Tang J, 2007, KNOWL INF SYST, V11, P45, DOI 10.1007/s10115-005-0233-6
   Zimek Arthur, 2012, Statistical Analysis and Data Mining, V5, P363, DOI 10.1002/sam.11161
NR 39
TC 21
Z9 21
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25659
EP 25677
DI 10.1007/s11042-017-4443-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500008
DA 2024-07-18
ER

PT J
AU Fouad, MM
   Dansereau, RM
AF Fouad, Mohamed M.
   Dansereau, Richard M.
TI An optimized parallel order scheme of the deblocking filtering process
   for enhancing the performance of the HEVC standard using GPUs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; Deblocking filtering; Parallel processing; HEVC; GPU
ID ARCHITECTURE; H.264/AVC; EFFICIENCY; COMPLEXITY
AB In HEVC, deblocking filtering (DF) is responsible for about 20% of the time consumed to perform video compression. In a typical parallel DF scheme, a set of horizontal and vertical edges are processed using deblocking filters. In conventional parallel DF schemes, deblocking filters could be applied to the same edges more than once. Moreover, some edges are assigned to cores to be filtered even though those edges are not designated to be filtered. Accordingly, the used parallel hardware architecture requires more on-chip memory modules. Those challenges negatively affect HEVC performance resulting in an increase in computational complexity. In this paper, an optimized parallel DF scheme is proposed for HEVC using graphical processing units (GPUs). The proposed scheme outperforms competing ones in terms of reducing the decoding time of all frames of video sequences by average speed-up factors of 2.83 and 2.45 using the all-intra and low-delay video coding configuration modes, respectively. The proposal does not change the rate-distortion between the decoded video sequences and their original sequences.
C1 [Fouad, Mohamed M.] Mil Tech Coll, Dept Comp Engn, Cairo, Egypt.
   [Dansereau, Richard M.] Carleton Univ, Dept Syst & Comp Engn, Ottawa, ON K1S 5B6, Canada.
C3 Military Technical College; Carleton University
RP Fouad, MM (corresponding author), Mil Tech Coll, Dept Comp Engn, Cairo, Egypt.
EM mmafoad@mtc.edu.eg; rdanse@sce.carleton.ca
RI Fouad, Mohamed Mahmoud Aly/C-7372-2014
OI Fouad, Mohamed Mahmoud Aly/0000-0001-6382-9199
CR Bossen F, 2011, JCTVC11100
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chao YC, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1260
   Chi CC, 2012, IEEE T CIRC SYST VID, V22, P1827, DOI 10.1109/TCSVT.2012.2223056
   de Souza Diego F., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4993, DOI 10.1109/ICASSP.2014.6854552
   Eldeken Alaa F., 2015, International Journal of Image, Graphics and Signal Processing, V7, P9, DOI 10.5815/ijigsp.2015.03.02
   Eldeken AF, 2015, IEEE IMAGE PROC, P1538, DOI 10.1109/ICIP.2015.7351058
   Hsia SC, 2012, SIGNAL PROCESS-IMAGE, V27, P749, DOI 10.1016/j.image.2012.04.004
   Huang YW, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P693
   Kim IK, 2013, JCTVC11002
   Kotra AM, 2013, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.2013.6638151
   Kthiri M, 2010, 2010 9TH INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND TELECOMMUNICATIONS (ISETC), P341, DOI 10.1109/ISETC.2010.5679363
   Le HHN, 2014, J INF SCI ENG, V30, P281
   Li Y, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P26, DOI 10.1109/MUE.2009.97
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Lou J, 2009, IEEE T CIRC SYST VID, V19, P1178, DOI 10.1109/TCSVT.2009.2020262
   Monteiro E., 2011, 2011 Proceedings of 23rd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD 2011), P128, DOI 10.1109/SBAC-PAD.2011.19
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Shen WW, 2013, IEEE INT SYMP CIRC S, P673, DOI 10.1109/ISCAS.2013.6571936
   Sheng B, 2004, IEEE IMAGE PROC, P665
   Su HY, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P280, DOI 10.1109/PACRIM.2011.6032906
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tahir SM, 2013, 2013 IEEE CONFERENCE ON SYSTEMS, PROCESS & CONTROL (ICSPC), P97, DOI 10.1109/SPC.2013.6735111
   Vijay S., 2010, Proceedings of the 2010 IEEE Workshop on Signal Processing Systems (SiPS 2010), P116, DOI 10.1109/SIPS.2010.5624773
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
NR 26
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24609
EP 24634
DI 10.1007/s11042-017-4876-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300003
DA 2024-07-18
ER

PT J
AU Hussain, R
   Gao, H
   Shaikh, RA
AF Hussain, Rafaqat
   Gao, Hui
   Shaikh, Riaz Ahmed
TI Segmentation of connected characters in text-based CAPTCHAs for
   intelligent character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAPTCHAs; Artificial Intelligence; Machine learning; Image processing;
   Crowding characters together; Intelligent character recognition
ID BREAKING
AB Over last few years, CAPTCHAs are ubiquitously found on internet as a security mechanism to distinguish between humans and spams. The text-based CAPTCHAs offer users to recognize the distorted text from the challenged images. Having based on hard AI problem, they have emerged as a hot research topic in computer vision and machine learning. The contemporary text-based CAPTCHAs are based on the segmentation problem that involves their decomposition into sub-images of individual characters. This is a challenging task for current OCR programs which is not yet solved to a great extent. In this paper, we present a novel segmentation and recognition method which uses simple image processing techniques including thresholding, thinning and pixel count methods along with an artificial neural network for text-based CAPTCHAs. We attack the popular CCT (Crowded Characters Together) based CAPTCHAs and compare our results with other schemes. As overall, our system achieves an overall precision of 51.3, 27.1 and 53.2% for Taobao, MSN and eBay datasets with 1000,500 and 1000 CAPTCHAs respectively. The benefits of this research are twofold: by recognizing text-based CAPTCHAs, we not only explore the weaknesses in the current design but also find a way to segment and recognize the connected characters from images. The proposed algorithm can be used in digitization of ancient books, handwriting recognition and other similar tasks.
C1 [Hussain, Rafaqat; Gao, Hui] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.
   [Shaikh, Riaz Ahmed] Shah Abdul Latif Univ, Dept Comp Sci, Khairpur 66020, Pakistan.
C3 University of Electronic Science & Technology of China; Shah Abdul Latif
   University
RP Hussain, R (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.
EM rafaqat.arain@salu.edu.pk
CR [Anonymous], INT C SEC COMP NETW
   [Anonymous], AUTOMATICA
   [Anonymous], 2004, ADV NEURAL INF PROCE
   Blumenstein M, 2003, PROC INT CONF DOC, P137
   Bursztein E, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P125
   Chellapilla K, 2005, BUILDING SEGMENTATIO, P1
   El Ahmad Ahmad S., 2011, Computing Science
   Gao HC, 2016, IET INFORM SECUR, V10, P45, DOI 10.1049/iet-ifs.2014.0381
   Gao HC, 2014, J INF SCI ENG, V30, P347
   Gaurav D. D., 2012, ARXIV12023884
   Huang SY, 2010, MULTIMED TOOLS APPL, V48, P267, DOI 10.1007/s11042-009-0341-5
   Kun Fang, 2012, Artificial Intelligence and Computational Intelligence. Proceedings of the 4th International Conference, AICI 2012, P735, DOI 10.1007/978-3-642-33478-8_91
   Mori G, 2003, PROC CVPR IEEE, P134
   Starostenko O, 2015, PATTERN RECOGN, V48, P1101, DOI 10.1016/j.patcog.2014.09.006
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   Yan J, 2008, CCS'08: PROCEEDINGS OF THE 15TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P543
   Zhang HY, 2014, ADV INTELL SYST, V277, P759, DOI 10.1007/978-3-642-54924-3_71
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 18
TC 14
Z9 14
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25547
EP 25561
DI 10.1007/s11042-016-4151-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500002
DA 2024-07-18
ER

PT J
AU Li, YJ
   Li, YS
AF Li, Yongjun
   Li, Yunsong
TI A fast and efficient saliency detection model in video compressed-domain
   for human fixations prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed domain; Human fixations detection; Visual saliency
ID BOTTOM-UP; VISUAL-ATTENTION; TOP-DOWN; VISION; SEARCH
AB Research and application of human fixations detection in video compressed-domain have gained an increasing attention in the latest years. However, both prediction accuracy and computational complexity still remain a challenge. This paper addresses the problem of compressed-domain video human fixations prediction based on saliency detection, and presents a fast and efficient algorithm based on Residual DCT Coefficients Norm (RDCN feature) and Operational Block Description Length (OBDL feature). These two features are directly extracted from the compressed bit-stream with partial decoding, and are normalized. After spatial and temporal filtering, the normalized salient maps are fused by the dynamic fusion coefficients with variation of quantization parameters. Then the fused salient map is worked by Gaussian model whose center is determined by the feature values. The proposed saliency detection model for human fixations prediction combines the accuracy of the pixel-domain saliency detections with the computational efficiency of their compressed-domain counterparts. The validation and comparison are made by several accuracy metrics on two ground truth datasets. Experimental results show that the proposed saliency detection model for human fixations prediction obtains superior performances over several state-of-the-art compressed-domain and pixel-domain algorithms on evaluation metrics. Computationally, our algorithm achieves a speed-up of over 10 times as compared to similar algorithms, which illustrates it appropriate for in-camera saliency estimation.
C1 [Li, Yongjun; Li, Yunsong] Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, 2 South Taibai St, Xian 710071, Peoples R China.
   [Li, Yongjun; Li, Yunsong] Xidian Univ, Sch Telecommun Engn, Joint Lab High Speed Multisource Image Coding & P, 2 South Taibai St, Xian 710071, Peoples R China.
   [Li, Yongjun] Henan Univ, Sch Phys & Elect, 1 Jinming St, Kaifeng 475004, Henan, Peoples R China.
C3 Xidian University; Xidian University; Henan University
RP Li, YS (corresponding author), Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, 2 South Taibai St, Xian 710071, Peoples R China.; Li, YS (corresponding author), Xidian Univ, Sch Telecommun Engn, Joint Lab High Speed Multisource Image Coding & P, 2 South Taibai St, Xian 710071, Peoples R China.
EM lyjustc@163.com; ysli@mail.xidian.edu.cn
FU National Nature Science Foundation of China [61222101, 61301287,
   61301291, 61502367]
FX This work was partially supported by the National Nature Science
   Foundation of China (Grant Nos. 61222101, 61301287, 61301291, 61502367)
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   Agarwal G, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P133
   Aminlou A, 2016, IEEE T CIRC SYST VID, V26, P696, DOI 10.1109/TCSVT.2015.2412811
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   BRAUN J, 1990, PERCEPT PSYCHOPHYS, V48, P45, DOI 10.3758/BF03205010
   Cao J, 2014, JAMA-J AM MED ASSOC, V312, P543, DOI 10.1001/jama.2014.9440
   Chamaret C, 2010, IEEE IMAGE PROC, P1077, DOI 10.1109/ICIP.2010.5651381
   Davis JW, 2007, INT J COMPUT VISION, V71, P161, DOI [10.1007/s11263-006-4121-7, 10.1007/sl1263-006-4121-7]
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hadizadeh H, 2012, IEEE T IMAGE PROCESS, V21, P898, DOI 10.1109/TIP.2011.2165292
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2014, I-PERCEPTION, V5, P415
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Khatoonabadi SH, 2015, MULTIMED TOOLS APPL, V74, P10057, DOI 10.1007/s11042-015-2802-3
   Khatoonabadi SH, 2015, PROC CVPR IEEE, P5501, DOI 10.1109/CVPR.2015.7299189
   Khatoonabadi SH, 2014, IEEE IMAGE PROC, P1081, DOI 10.1109/ICIP.2014.7025215
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kreyszig Erwin., 1970, INTRO MATH STAT PRIN
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lin XY, 2012, IEEE T CONSUM ELECTR, V58, P505, DOI 10.1109/TCE.2012.6227454
   Liu Z, 2009, PROCEEDINGS OF THE 8TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, P568, DOI 10.1109/ICIS.2009.165
   Ma YF, 2002, IEEE IMAGE PROC, P129
   Ma YF, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P426, DOI 10.1109/ICIP.2001.958142
   Markus MT, 1998, PSYCHOMETRIKA, V63, P97
   MOULDEN B, 1984, PERCEPTION, V13, P387, DOI 10.1068/p130387
   Muthuswamy K, 2013, IEEE SIGNAL PROC LET, V20, P996, DOI 10.1109/LSP.2013.2277884
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Reinagel P, 1999, NETWORK-COMP NEURAL, V10, P341, DOI 10.1088/0954-898X/10/4/304
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Swets J, 1996, LAWRENCE ERLBAUM ASS, V43, P840
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   TREISMAN A, 1988, PSYCHOL REV, V95, P15, DOI 10.1037/0033-295X.95.1.15
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wolfe JM, 2003, J EXP PSYCHOL HUMAN, V29, P483, DOI 10.1037/0096-1523.29.2.483
   Xie R, 2008, OPT ENG, V47, DOI 10.1117/1.2976797
NR 46
TC 10
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26273
EP 26295
DI 10.1007/s11042-016-4118-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500035
DA 2024-07-18
ER

PT J
AU Wang, CC
AF Wang, Chuen-Ching
TI Fair billing method for VOD systems based on video quality monitoring
   using watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video on demand; IPTV; Digital watermarking; Video quality monitoring;
   H.264
AB The received quality of the video contents streamed over Video on Demand (VOD) networks is easily degraded by interference and other external factors during the encoding and transmission stages. However, the service provider generally bills the subscriber in accordance with the original fee, irrespective of the actual video quality received. Consequently, the subscribers' rights are infringed and their dissatisfactions increased. To address this problem, the present study outlines a VOD billing method in which the video quality at the receiver end is evaluated using a watermarking scheme, and the fee charged by the service provider is then adjusted accordingly. The basic feasibility of the proposed approach is demonstrated by means of simulations using standard test video sequences. The results show that the watermarking scheme provides an effective means of evaluating the video quality at the receiver end, and thus provides a reliable basis for quality-dependent subscriber billing in VOD systems. Moreover, the watermarking scheme also reduces the size of the watermarked file. As a result, both the storage space requirement at the video server and the server network bandwidth requirement are reduced. Consequently, the proposed system provides a win-win solution for the subscribers and service providers in VOD systems.
C1 [Wang, Chuen-Ching] Kao Yuan Univ, Dept Informat Technol, Kaohsiung, Taiwan.
RP Wang, CC (corresponding author), Kao Yuan Univ, Dept Informat Technol, Kaohsiung, Taiwan.
EM t90261@cc.kyu.edu.tw
FU Ministry of Science Technology of Taiwan [MOST104-2221-E-244-018]
FX The author gratefully acknowledge the financial support provided to this
   study by the Ministry of Science Technology of Taiwan under Grant No.
   MOST104-2221-E-244-018.
CR 4G Americas, 2014, CISC VIS NETW IND GL
   [Anonymous], 2008, TRIPLE PLAY BUILDING
   Campisi P, 2003, IEEE T SIGNAL PROCES, V51, P996, DOI 10.1109/TSP.2003.809381
   Chan HT, 2015, J DISP TECHNOL, V11, P193, DOI 10.1109/JDT.2014.2367528
   Declerq D, 2014, CHANNEL CODING: THEORY, ALGORITHMS, AND APPLICATIONS, P1
   Dovrolis C, 1999, IEEE NETWORK, V13, P26, DOI 10.1109/65.793688
   Fu F, 2007, IEEE J SEL TOP QUANT, V1
   Glavieux A, 2013, CHANNEL CODING COMMU
   Guy C., 2014, ICWMC C 22 26 JUN, P90
   Iftikhar M., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P109, DOI 10.1109/JCSSE.2012.6261935
   Mehdi F, 2014, IEEE T INSTRUMENT ME, V63
   Mehmood N, 2012, PROCEEDINGS OF THE 37TH ANNUAL IEEE CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN 2012), P1014, DOI 10.1109/LCNW.2012.6424038
   Roberts JW, 1998, IEICE T COMMUN, VE81B, P824
   Wang CC, 2010, OPT ENG, V49, DOI 10.1117/1.3309472
   Wang Q, 2008, I C WIREL COMM NETW, P1101
   Wang X, 2000, IEEE J SEL AREA COMM, V18, P2514, DOI 10.1109/49.898734
   Xu K., 2014, Internet Resource Pricing Models
NR 17
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25215
EP 25229
DI 10.1007/s11042-016-4286-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300037
DA 2024-07-18
ER

PT J
AU Wang, LF
   Pan, ZB
   Zhu, RX
AF Wang, Lingfei
   Pan, Zhibin
   Zhu, Ruoxin
TI A novel reversible data hiding scheme by introducing current state
   codebook and prediction strategy for joint neighboring coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Side-match vector quantization (SMVQ);
   Joint neighboring coding (JNC); State codebook (SC); Median edge
   detector (MED) prediction
ID WATERMARKING ALGORITHM; VECTOR QUANTIZATION; COMPRESSION SCHEME;
   EFFICIENT; INDEXES; IMAGES; SMVQ; ERRORS
AB Reversible data hiding (RDH) in compression domain is an important research issue in the security of digital multimedia. Obtaining a high embedding rate and a low compression rate are the main goals of compression domain RDH. This paper proposes a novel RDH scheme to improve joint neighboring coding (JNC) scheme. In embedding process, the first index SC (1st) in current state codebook (SC) and median edge detector (MED) prediction P (med) are exploited. These two parameters are employed to replace the right-up and left-up neighboring SMVQ indices, which have lower correlation with the current index. As a result, a more concentrated distribution of difference "d" is obtained. Difference "d" is computed by the difference between the current SMVQ index and its left, upper neighboring indices, P (med) and SC (1st) after embedding secret bits. The experimental results show that our work achieves the average compression rate of 0.45/0.51/0.57 bpp and the average embedding efficiency of 0.28/0.36/0.43 after embedding 2/3/4 bits secret data into each SMVQ index. As demonstrated in the comparative results, it can be observed that the proposed scheme outperforms the other previous works.
C1 [Wang, Lingfei; Pan, Zhibin; Zhu, Ruoxin] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM Wang.lingfei@stu.xjtu.edu.cn; zbpan@mail.xjtu.edu.cn;
   Zhuruoxin1992@stu.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Key Laboratory of Spectral Imaging Technology,
   Chinese Academy of Sciences [LSIT201606D]; Key Science and Technology
   Program of Shaanxi Province [2016GY-097]; Industrial Program of Zhejiang
   Province [2016C31G4180003]
FX This work is supported in part by the Project Funded by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD), the Open Research Fund of Key Laboratory of Spectral Imaging
   Technology, Chinese Academy of Sciences (Grant No. LSIT201606D), the Key
   Science and Technology Program of Shaanxi Province (Grant No.
   2016GY-097) and the Industrial Program of Zhejiang Province (Grant No.
   2016C31G4180003).
CR BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang CC, 2014, J VIS COMMUN IMAGE R, V25, P1704, DOI 10.1016/j.jvcir.2014.06.003
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Huang HC, 2002, IEICE T FUND ELECTR, VE85A, P1719
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Kieu TD, 2015, EXPERT SYST APPL, V42, P713, DOI 10.1016/j.eswa.2014.09.001
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2015, SECUR COMMUN NETW, V8, P899, DOI 10.1002/sec.1046
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang LF, 2014, J VIS COMMUN IMAGE R, V25, P454, DOI 10.1016/j.jvcir.2013.12.004
   Wang SY, 2013, IET IMAGE PROCESS, V7, P805, DOI 10.1049/iet-ipr.2012.0521
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wright M. A., 2001, Network Security, P11, DOI 10.1016/S1353-4858(01)01018-2
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xin Z, 2007, OPT LASER TECHNOL, V39, P1360, DOI 10.1016/j.optlastec.2006.11.002
   Yang B, 2005, Proceedings of the Fifth IASTED International Conference on Visualization, Imaging, and Image Processing, P298
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 29
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26153
EP 26176
DI 10.1007/s11042-016-4000-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500030
DA 2024-07-18
ER

PT J
AU Aljawarneh, S
   Yassein, MB
   Talafha, WA
AF Aljawarneh, Shadi
   Yassein, Muneer Bani
   Talafha, We'am Adel
TI A resource-efficient encryption algorithm for multimedia big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Multimedia big data; Encryption; AES; GPU
ID INTERNET
AB Nowadays, multimedia is considered to be the biggest big data as it dominates the traffic in the Internet and mobile phones. Currently symmetric encryption algorithms are used in IoT but when considering multimedia big data in IoT, symmetric encryption algorithms incur more computational cost. In this paper, we have designed and developed a resource-efficient encryption system for encrypting multimedia big data in IoT. The proposed system takes the advantages of the Feistel Encryption Scheme, an Advanced Encryption Standard (AES), and genetic algorithms. To satisfy high throughput, the GPU has also been used in the proposed system. This system is evaluated on real IoT medical multimedia data to benchmark the encryption algorithms such as MARS, RC6, 3-DES, DES, and Blowfish in terms of computational running time and throughput for both encryption and decryption processes as well as the avalanche effect. The results show that the proposed system has the lowest running time and highest throughput for both encryption and decryption processes and highest avalanche effect with compared to the existing encryption algorithms. To satisfy the security objective, the developed algorithm has better Avalanche Effect with compared to any of the other existing algorithms and hence can be incorporated in the process of encryption/decryption of any plain multimedia big data. Also, it has shown that the classical and modern ciphers have very less Avalanche Effect and hence cannot be used for encryption of confidential multimedia messages or confidential big data. The developed encryption algorithm has higher Avalanche Effect and for instance, AES in the proposed system has an Avalanche Effect of %52.50. Therefore, such system is able to secure the multimedia big data against real-time attacks.
C1 [Aljawarneh, Shadi; Yassein, Muneer Bani; Talafha, We'am Adel] Jordan Univ Sci & Technol, Fac Comp & Informat Technol, Irbid, Jordan.
C3 Jordan University of Science & Technology
RP Aljawarneh, S (corresponding author), Jordan Univ Sci & Technol, Fac Comp & Informat Technol, Irbid, Jordan.
EM saaljawarneh@just.edu.jo; masadeh@just.edu.jo;
   Watalafha13@cit.just.edu.jo
RI Aljawarneh, Shadi/ABD-6329-2021
OI Aljawarneh, Shadi/0000-0001-5748-4921; Bani Yassein,
   Muneer/0000-0001-5030-6196
CR Abd Elminaam DiaaSalama., 2010, IJ NETWORK SECURITY, V10, P216
   Aljawarneh S, 2011, INT J CLOUD APPL COM, V1, P64, DOI 10.4018/ijcac.2011040105
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bandyopadhyay D, 2011, WIRELESS PERS COMMUN, V58, P49, DOI 10.1007/s11277-011-0288-5
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Dave E., 2016, INTERNET THINGS NEXT
   Evans D., 2011, CISCO
   Hart JK, 2015, EARTH SPACE SCI, V2, P194, DOI 10.1002/2014EA000044
   HEYS HM, 1995, IEEE T COMPUT, V44, P1131, DOI 10.1109/12.464391
   Kalyani V., 2015, J MANAG ENG INF TECH, V2, P2394
   Kuehner H, 2016, P 4 ACM INT WORKSH S
   Kumar A, 2005, NEW SIGNAL SECURITY
   Lee JY, 2014, P INT S NEXT GEN EL
   Li SC, 2015, INFORM SYST FRONT, V17, P243, DOI 10.1007/s10796-014-9492-7
   Madakam Somayya, 2015, International Journal of Future Computer and Communication, V4, P250, DOI 10.7763/IJFCC.2015.V4.395
   Mahalle P.N., 2013, J. Cyber Secur. Mobil., V1, P309, DOI DOI 10.13052/JCSM2245-1439.142
   Prasetyo KN, 2014, INT C INF COMM TECHN
   Santucci G., 2009, P INT C FUT TRENDS I
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Schweitzer Dino, 2009, J COMPUT SCI COLL, V25, P39
   Smith J, 2013, P INT ACM SIGIR C RE
   Stallings W., 1999, CRYPTOGRAPHY NETWORK, Vsecond
   Sundaram BV, 2015, P INT C SIGN PROC CO
   Wang W, 2012, P IEEE C HIGH PERF E
   Xin Mingyuan, 2015, INT C CYB EN DISTR C
   Yao XX, 2015, FUTURE GENER COMP SY, V49, P104, DOI 10.1016/j.future.2014.10.010
   Zhao Y, 2013, P INT C MECH CONTR E
NR 28
TC 124
Z9 128
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22703
EP 22724
DI 10.1007/s11042-016-4333-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200041
DA 2024-07-18
ER

PT J
AU de Boer, M
   Pingen, G
   Knook, D
   Schutte, K
   Kraaij, W
AF de Boer, Maaike
   Pingen, Geert
   Knook, Douwe
   Schutte, Klamer
   Kraaij, Wessel
TI Improving video event retrieval by user feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video event retrieval; Relevance feedback; Information retrieval;
   Semantic space; Rocchio
ID RELEVANCE FEEDBACK; IMAGE RETRIEVAL; CLASSIFICATION; DESCRIPTORS;
   RECOGNITION; SCALE
AB In content based video retrieval videos are often indexed with semantic labels (concepts) using pre-trained classifiers. These pre-trained classifiers (concept detectors), are not perfect, and thus the labels are noisy. Additionally, the amount of pre-trained classifiers is limited. Often automatic methods cannot represent the query adequately in terms of the concepts available. This problem is also apparent in the retrieval of events, such as bike trick or birthday party. Our solution is to obtain user feedback. This user feedback can be provided on two levels: concept level and video level. We introduce the method Adaptive Relevance Feedback (ARF) on video level feedback. ARF is based on the classical Rocchio relevance feedback method from Information Retrieval. Furthermore, we explore methods on concept level feedback, such as the re-weighting and Query Point Modification (QPM) methods as well as a method that changes the semantic space the concepts are represented in. Methods on both concept level and video level are evaluated on the international benchmark TRECVID Multimedia Event Detection (MED) and compared to state of the art methods. Results show that relevance feedback on both concept and video level improves performance compared to using no relevance feedback; relevance feedback on video level obtains higher performance compared to relevance feedback on concept level; our proposed ARF method on video level outperforms a state of the art k-NN method, all methods on concept level and even manually selected concepts.
C1 [de Boer, Maaike; Pingen, Geert; Knook, Douwe; Schutte, Klamer] TNO, Oude Waalsdorperweg 63, NL-2597 AK The Hague, Netherlands.
   [de Boer, Maaike] Radboud Univ Nijmegen, Toernooiveld 200, NL-6525 EC Nijmegen, Netherlands.
   [Pingen, Geert] Univ Twente, Drienerlolaan 5, NL-7522 NB Enschede, Netherlands.
   [Knook, Douwe] Univ Amsterdam, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
   [Kraaij, Wessel] TNO, Anna van Buerenpl 1, NL-2595 DA The Hague, Netherlands.
   [Kraaij, Wessel] Leiden Univ, Niels Bohrweg 1, NL-2333 Leiden, Netherlands.
C3 Netherlands Organization Applied Science Research; Radboud University
   Nijmegen; University of Twente; University of Amsterdam; Netherlands
   Organization Applied Science Research; Leiden University; Leiden
   University - Excl LUMC
RP de Boer, M (corresponding author), TNO, Oude Waalsdorperweg 63, NL-2597 AK The Hague, Netherlands.; de Boer, M (corresponding author), Radboud Univ Nijmegen, Toernooiveld 200, NL-6525 EC Nijmegen, Netherlands.
EM maaike.deboer@tno.nl; geert.pingen@tno.nl; douwe.knook@gmail.com;
   klamer.schutte@tno.nl; w.kraaij@liacs.leidenuniv.nl
RI Kraaij, Wessel/S-2071-2016
OI Kraaij, Wessel/0000-0001-7797-619X
FU ERP Making Sense of Big Data (MSoBD)
FX We would like to thank the VIREO team from the City University of Hong
   Kong for the application of their concept detectors on the TRECVID MED
   2014 data sets and the ERP Making Sense of Big Data (MSoBD) for their
   financial support. Furthermore, we could like to thank Thomas Mensink
   and Robin Aly for their feedback on the work of Douwe and Geert that
   initiated this journal paper.
CR [Anonymous], 1977, BIOMETRICS
   [Anonymous], P TRECVID 2015 NIST
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, P ALLDATA
   [Anonymous], 2012, International Journal of Engineering Research and Technology
   [Anonymous], 2009, MOSIFT RECOGNIZING H
   [Anonymous], P TRECVID 2015
   [Anonymous], J APPL COMPUTER SCI
   [Anonymous], 2010, P ACM INT C MULT
   [Anonymous], 2013, NeurIPS
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2014, P NIPS
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Burgess JeanJoshua Green., 2013, YOUTUBE ONLINE VIDEO
   Cochran W.G. G.M. Cox., 1957, Experimental Design
   Crucianu M, 2004, RELEVANCE FEEDBACK I
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dalton J, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1857, DOI 10.1145/2505515.2507880
   de Boer M, 2016, MULTIMED TOOLS APPL, V75, P9025, DOI 10.1007/s11042-015-2757-4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Elhoseiny M, 2015, ARXIV151200818
   Goldberg Y., 2014, ARXIV
   Habibian A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P17, DOI 10.1145/2647868.2654913
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918
   Jiang L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P27, DOI 10.1145/2671188.2749399
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Kaliciak Leszek, 2013, ADV MULTIMEDIA MODEL, P445
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A, 2008, SPATIOTEMPORAL DESCR, P275
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lev G, 2015, LECT NOTES COMPUT SC, V9103, P35, DOI 10.1007/978-3-319-19581-0_3
   Liu J, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P297, DOI 10.1109/ROBIO.2014.7090346
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv YH, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P579
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mironica I, 2016, COMPUT VIS IMAGE UND, V143, P38, DOI 10.1016/j.cviu.2015.10.005
   Natarajan P., 2011, NIST TRECVID WORKSH
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rocha R, 2015, LECT NOTES COMPUT SC, V9423, P281, DOI 10.1007/978-3-319-25751-8_34
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Ruthven I, 2003, KNOWL ENG REV, V18, P95, DOI 10.1017/S0269888903000638
   SAKAI T., 2005, ACM TRANS ASIAN LANG, V4, P111, DOI DOI 10.1145/1105696.1105699
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Snoek CG, 2015, QUALCOMM RES U AMSTE
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P3, DOI 10.1109/TCSVT.2007.906936
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Tsai CF, 2015, J ASSOC INF SCI TECH, V66, P40, DOI 10.1002/asi.23154
   Tzelepis Christos, 2016, Image and Vision Computing, V53, P3, DOI 10.1016/j.imavis.2016.05.005
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P256, DOI 10.1016/j.jvcir.2016.03.008
   Wu YM, 2004, MULTIMEDIA SYST, V10, P41, DOI 10.1007/s00530-004-0136-5
   Xu SC, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P675, DOI 10.1145/2671188.2749413
   Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221
   Yu J, 2007, INT CONF ACOUST SPEE, P965
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 65
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22361
EP 22381
DI 10.1007/s11042-017-4798-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200026
DA 2024-07-18
ER

PT J
AU Hladek, D
   Stas, J
   Ondas, S
   Juhar, J
   Kovacs, L
AF Hladek, Daniel
   Stas, Jan
   Ondas, Stanislav
   Juhar, Jozef
   Kovacs, Laszlo
TI Learning string distance with smoothing for OCR spelling correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OCR; Spelling correction; Learning string distance; Hidden Markov model
AB Large databases of scanned documents (medical records, legal texts, historical documents) require natural language processing for retrieval and structured information extraction. Errors caused by the optical character recognition (OCR) system increase ambiguity of recognized text and decrease performance of natural language processing. The paper proposes OCR post correction system with parametrized string distance metric. The correction system learns specific error patterns from incorrect words and common sequences of correct words. A smoothing technique is proposed to assign non-zero probability to edit operations not present in the training corpus. Spelling correction accuracy is measured on database of OCR legal documents in English language. Language model and learning string metric with smoothing improves Viterbi-based search for the best sequence of corrections and increases performance of the spelling correction system.
C1 [Hladek, Daniel; Stas, Jan; Ondas, Stanislav; Juhar, Jozef] Tech Univ Kosice, Dept Elect & Multimedia Commun, Letna 9, Kosice 04200, Slovakia.
   [Kovacs, Laszlo] Univ Miskolc, Inst Informat Technol, H-3515 Miskolc, Hungary.
C3 Technical University Kosice; University of Miskolc
RP Hladek, D (corresponding author), Tech Univ Kosice, Dept Elect & Multimedia Commun, Letna 9, Kosice 04200, Slovakia.
EM daniel.hladek@tuke.sk; jan.stas@tuke.sk; stanislav.ondas@tuke.sk;
   jozef.juhar@tuke.sk; kovacs@iit.uni-miskolc.hu
RI Ondáš, Stanislav/AAA-2381-2020; Juhár, Jozef/B-2803-2014; Staš,
   Ján/B-6716-2017; Hladek, Daniel/B-7893-2017
OI Ondáš, Stanislav/0000-0002-0075-3788; Juhár, Jozef/0000-0002-1596-9258;
   Hladek, Daniel/0000-0003-1148-3194
FU Ministry of Education, Science, Research and Sport of the Slovak
   Republic [VEGA 1/0075/15]; Slovak Research and Development Agency
   [APVV-15-0517]; Technical University of Kosice under research project
   DIALab
FX The work presented in this paper was supported by the Ministry of
   Education, Science, Research and Sport of the Slovak Republic under
   research project VEGA 1/0075/15 and by the Slovak Research and
   Development Agency under research project APVV-15-0517 and by the
   Technical University of Kosice under research project DIALab.
CR [Anonymous], PERFORMANCE COMPARIS
   [Anonymous], 2005, Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT '05
   [Anonymous], COMBING CROWDSOURCIN
   [Anonymous], USING FIELD INTERDEP
   [Anonymous], 2015, INT J ELECT COMPUT E, DOI DOI 10.11591/IJECE.V5I6.PP1458-1467
   [Anonymous], 2014, P 1 INT C DIGITAL AC, DOI DOI 10.1145/2595188.2595191
   [Anonymous], SCRIPT INDEPENDENT T
   [Anonymous], BAYESIAN SIMILARITY
   Bellet A, 2012, MACH LEARN, V89, P5, DOI 10.1007/s10994-012-5293-8
   Bilenko M., 2003, P 9 ACM SIGKDD INT C, P39, DOI DOI 10.1145/956750.956759
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Evershed J., 2014, P 1 INT C DIG ACC TE, P45, DOI [DOI 10.1145/2595188.2595200, 10.1145/2595188.2595200]
   Gao PC, 2015, MULTIMED TOOLS APPL, V74, P7221, DOI 10.1007/s11042-014-1969-3
   Gerdjikov S, 2013, PROC INT CONF DOC, P324, DOI 10.1109/ICDAR.2013.72
   Ghosh K, 2016, INFORM PROCESS MANAG, V52, P873, DOI 10.1016/j.ipm.2016.03.006
   Hladek D, 2013, ADV ELECTR ELECTRON, V11, P392, DOI 10.15598/aeee.v11i5.898
   Kantor P. B., 2000, Information Retrieval, V2, P165, DOI 10.1023/A:1009902609570
   KUKICH K, 1992, COMPUT SURV, V24, P377
   Lin YP, 2017, MULTIMED TOOLS APPL, V76, P4123, DOI 10.1007/s11042-015-2995-5
   Lv YY, 2016, FRONT ARTIF INTEL AP, V281, P32, DOI 10.3233/978-1-61499-619-4-32
   Mohri M, 2004, STUD FUZZ SOFT COMP, V148, P551
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Oard DW, 2010, ARTIF INTELL LAW, V18, P347, DOI 10.1007/s10506-010-9093-9
   Park JH, 2015, MULTIMED TOOLS APPL, V74, P2359, DOI 10.1007/s11042-014-1971-9
   Reffle U, 2013, PATTERN RECOGN, V46, P1346, DOI 10.1016/j.patcog.2012.10.002
   Ristad ES, 1998, IEEE T PATTERN ANAL, V20, P522, DOI 10.1109/34.682181
   Sariev A, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P31, DOI 10.1109/DAS.2014.12
   Schulz K. U., 2002, International Journal on Document Analysis and Recognition, V5, P67, DOI 10.1007/s10032-002-0082-8
   Springmann U., 2014, P 1 INT C DIG ACC TE, P71, DOI 10.1145/2595188
   Stas J, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2014-14
   Taghva K, 2014, PROC SPIE, V9021, DOI 10.1117/12.2042403
   Taghva K, 2013, PROC SPIE, V8658, DOI 10.1117/12.2006500
   Tange O., 2011, GNU Parallel: The Command-Line Power Tool, V36, P42, DOI DOI 10.5281/ZEN0D0.16303
   Vobl T., 2014, Proceedings of the First International Conference on Digital Access to Textual Cultural Heritage, P57, DOI DOI 10.1145/2595188.2595197
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   Yang HJ, 2014, MULTIMED TOOLS APPL, V69, P217, DOI 10.1007/s11042-012-1250-6
NR 36
TC 8
Z9 8
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24549
EP 24567
DI 10.1007/s11042-016-4185-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700064
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, J
   Lan, XG
   Wang, J
   Yang, M
   Zheng, NN
AF Li, Jin
   Lan, Xuguang
   Wang, Jiang
   Yang, Meng
   Zheng, Nanning
TI Fast additive quantization for vector compression in nearest neighbor
   search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Additive quantization; Beam search; Vector compression; Nearest neighbor
   search
AB Vector quantization has been widely employed in nearest neighbor search because it can approximate the Euclidean distance of two vectors with the table look-up way that can be precomputed. Additive quantization (AQ) algorithm validated that low approximation error can be achieved by representing each input vector with a sum of dependent codewords, each of which is from its own codebook. However, the AQ algorithm relies on computational expensive beam search algorithm to encode each vector, which is prohibitive for the efficiency of the approximate nearest neighbor search. In this paper, we propose a fast AQ algorithm that significantly accelerates the encoding phase. We formulate the beam search algorithm as an optimization of codebook selection orders. According to the optimal order, we learn the codebooks with hierarchical construction, in which the search width can be set very small. Specifically, the codewords are firstly exchanged into proper codebooks by the indexed frequency in each step. Then the codebooks are updated successively to adapt the quantization residual of previous quantization level. In coding phase, the vectors are compressed with learned codebooks via the best order, where the search range is considerably reduced. The proposed method achieves almost the same performance as AQ, while the speed for the vector encoding phase can be accelerated dozens of times. The experiments are implemented on two benchmark datasets and the results verify our conclusion.
C1 [Li, Jin; Lan, Xuguang; Yang, Meng; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Shaanxi, Peoples R China.
   [Wang, Jiang] Inst Deep Learning, Sunnyvale, CA USA.
C3 Xi'an Jiaotong University
RP Lan, XG (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Shaanxi, Peoples R China.
EM xglan@mail.xjtu.edu.cn
RI Lan, Xuguang/N-8814-2019
OI Lan, Xuguang/0000-0002-3422-944X; Jin, Li/0000-0002-0260-3169
FU National Key Research and Development Program of China [2016YFB1000903];
   NSFC [61573268]
FX This work was supported in part by the National Key Research and
   Development Program of China under grant No. 2016YFB1000903, and NSFC
   No. 61573268.
CR [Anonymous], 2010, EUR C COMP VIS ECCV
   [Anonymous], 2009, P ACM INT C IMAGE VI
   Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124
   Barnes CF, 1996, IEEE T IMAGE PROCESS, V5, P226, DOI 10.1109/83.480761
   Boiman O, 2008, 2008 IE C COMP VIS P
   Brandt J, 2010, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2010.5539852
   Chen YJ, 2010, SENSORS-BASEL, V10, P11259, DOI 10.3390/s101211259
   Ge T, 2013, 2013 IE C COMP VIS P
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541
   Guo QZ, 2016, NEUROCOMPUTING, V171, P866, DOI 10.1016/j.neucom.2015.07.062
   He K., SOURCE CODE OPTIMIZA
   Jegou H, 2011, PATTERN ANAL MACHINE, V33
   Jegou H, SOURCE CODE PRODUCT
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Martinez J., 2014, ARXIV14112173
   Obdrzalek S, 2005, 2005 BRIT MACH VIS C
   Oliva A, 2001, INT J COMPUT VIS, V42
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Pearl J, 1988, PROBABILISTIC REASON, V3
   Shapiro S.C., 1987, Encyclopedia of artificial intelligence
   Strecha C, 2010, PATTERN ANAL MACHINE, V34
   Torralba A, 2008, 2008 IE C COMP VIS P
   Wang J, 2010, 2010 IE C COMP VIS P
   Yu G, 2014, IEEE INT CON MULTI
   Zhang T, 2014, INT C MACH LEARN ICM
NR 30
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23273
EP 23289
DI 10.1007/s11042-016-4023-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700007
DA 2024-07-18
ER

PT J
AU Zheng, Y
   Yao, HX
   Sun, XS
   Jiang, XS
   Porikli, F
AF Zheng, Ying
   Yao, Hongxun
   Sun, Xiaoshuai
   Jiang, Xuesong
   Porikli, Fatih
TI Breaking video into pieces for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Video partition; Video representation; Decision
   value matrix
AB We present a simple yet effective approach for human action recognition. Most of the existing solutions based on multi-class action classification aim to assign a class label for the input video. However, the variety and complexity of real-life videos make it very challenging to achieve high classification accuracy. To address this problem, we propose to partition the input video into small clips and formulate action recognition as a joint decision-making task. First, we partition all videos into two equal segments that are processed in the same manner. We repeat this procedure to obtain three layers of video subsegments, which are then organized in a binary tree structure. We train separate classifiers for each layer. By applying the corresponding classifiers to video subsegments, we obtain a decision value matrix (DVM). Then, we construct an aggregated representation for the original full-length video by integrating the elements of the DVM. Finally, we train a new action recognition classifier based on the DVM representation. Our extensive experimental evaluations demonstrate that the proposed method achieves significant performance improvement against several compared methods on two benchmark datasets.
C1 [Zheng, Ying; Yao, Hongxun; Sun, Xiaoshuai; Jiang, Xuesong] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
   [Zheng, Ying; Jiang, Xuesong; Porikli, Fatih] Australian Natl Univ, Res Sch Engn, Canberra, ACT, Australia.
C3 Harbin Institute of Technology; Australian National University
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM zhengying@hit.edu.cn; h.yao@hit.edu.cn; xiaoshuaisun@hit.edu.cn;
   xsjiang@hit.edu.cn; fatih.porikli@anu.edu.au
FU National Science Foundation of China [61472103]; Australian Research
   Council (ARC) grant [DP150104645]; China Scholarship Council (CSC)
FX The work was supported in part by the National Science Foundation of
   China (No. 61472103) and Australian Research Council (ARC) grant
   (DP150104645). We especially would like to thank the China Scholarship
   Council (CSC) for funding the first author to conduct the partially of
   this project at Australian National University.
CR Abu-El-Haija Sami, 2016, arXiv
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kong Y., 2014, European conference on computer vision, P596
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lan T, 2015, IEEE I CONF COMP VIS, P4552, DOI 10.1109/ICCV.2015.517
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Ryoo M, 2010, UT INTERACTION DATAS
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shen HQ, 2015, MULTIMED TOOLS APPL, V74, P523, DOI 10.1007/s11042-014-1936-z
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LM, 2013, IEEE I CONF COMP VIS, P2680, DOI 10.1109/ICCV.2013.333
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Xu HY, 2016, MULTIMED TOOLS APPL, V75, P5701, DOI 10.1007/s11042-015-2536-2
   Xu Z, 2015, IEEE I CONF COMP VIS, P3191, DOI 10.1109/ICCV.2015.365
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Zhang SP, 2017, IEEE T NEUR NET LEAR, V28, P2357, DOI 10.1109/TNNLS.2016.2586194
   Zhang SP, 2015, SIGNAL PROCESS, V110, P132, DOI 10.1016/j.sigpro.2014.08.027
   Zhang SP, 2014, INFORM SCIENCES, V281, P635, DOI 10.1016/j.ins.2013.12.052
   Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280
   Zhou Y, 2015, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR.2015.7298953
   Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442
NR 58
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22195
EP 22212
DI 10.1007/s11042-017-5038-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200017
DA 2024-07-18
ER

PT J
AU Boomilingam, T
   Subramaniam, M
AF Boomilingam, Thenkalvi
   Subramaniam, Murugavalli
TI An efficient retrieval using edge GLCM and association rule mining
   guided IPSO based artificial neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local Gabor XOR Pattern (LGXP); Edge Grey Level Co-Occurrence Matrix
   (EGLCM); Association Rule Mining (ARM); Improved Particle Swarm
   Optimization (IPSO); Artificial Neural Network (ANN); Optimized
   retrieval
ID MEDICAL IMAGE RETRIEVAL; RELEVANCE FEEDBACK; SYSTEM; SVM; TEXTURE;
   SCHEME; CBIR
AB Content Based Image Retrieval (CBIR) is a challenging research area due to increase in multimedia database and other image libraries day by day. With an intent to provide an efficient search and retrieval, we propose an enhanced Content Based Medical Image Retrieval (CBMIR) system to support the medical practitioners in their diagnosis task. For which, we introduce boosted feature extraction and retrieval phase for medical images using Edge GLCM (EGLCM) and Association Rule Mining (ARM) integrated with Artificial Neural Network (ANN). Improved Particle Swarm Optimization (IPSO) is deployed to optimize the weights of ANN. The system is put forth with four important phases; 1. Pre-Processing, 2. Feature Extraction using Edge Histogram Descriptor (EHD), Local Gabor XOR Pattern (LGXP) and EGLCM, 3. Association Rule Mining using Apriori and 4. Optimized Retrieval using IPSO based ANN and Euclidean distance. In ANN, 7,000 images are trained and 1,100 images are tested. On Comparison with the existing systems, our method has shown best results with improved accuracy of 95 % in addition to reduced computational complexity by pre-processing and dimensionality reduction through minimal feature vector.
C1 [Boomilingam, Thenkalvi] Anna Univ, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Subramaniam, Murugavalli] Anna Univ, Dept Comp Sci & Engn, Panimalar Engn Coll, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Anna University; Anna
   University Chennai
RP Boomilingam, T (corresponding author), Anna Univ, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM thenkalviboomilingam@gmail.com
RI S, Murugavalli/GRX-6642-2022; S, murugavalli/AAC-9610-2019; Muthusamy,
   Subramaniam/HIR-4836-2022
OI S, Murugavalli/0000-0003-3827-8596; S, murugavalli/0000-0003-3827-8596;
   Muthusamy, Subramaniam/0000-0003-4486-2115
CR AlGarni G, 2008, FORENSIC SCI INT, V181, P10, DOI 10.1016/j.forsciint.2008.07.004
   Avni U, 2011, IEEE T MED IMAGING, V30, P733, DOI 10.1109/TMI.2010.2095026
   Balan JAAR, 2014, TECHNOL HEALTH CARE, V22, P13, DOI 10.3233/THC-130767
   Bhagat A, 2014, ADV INTELL SYST, V248, P109, DOI 10.1007/978-3-319-03107-1_13
   Bugatti PH, 2014, COMPUT BIOL MED, V45, P8, DOI 10.1016/j.compbiomed.2013.11.015
   Chinnasamy S, 2014, IET IMAGE PROCESS, V8, P319, DOI 10.1049/iet-ipr.2012.0510
   Dass MV, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), VOL 1, P215, DOI 10.1109/CSCI.2014.44
   Fan X., 2014, P 30 ANN C UNC ART I
   Fan XN, 2014, AAAI CONF ARTIF INTE, P2439
   Fan XN, 2015, AAAI CONF ARTIF INTE, P3526
   Hafiane A, 2006, PATTERN RECOGN LETT, V27, P259, DOI 10.1016/j.patrec.2005.08.007
   Khan YD, 2014, NEURAL COMPUT APPL, V24, P1735, DOI 10.1007/s00521-013-1410-2
   Kumar A, 2014, MED IMAGE ANAL, V18, P330, DOI 10.1016/j.media.2013.11.003
   Kumari RSS, 2014, AUST J BASIC APPL SC, V8, P165
   Kurhe AB, 2011, GLOBAL J COMP SCI TE, V11, P86
   Kurtz C, 2014, MED IMAGE ANAL, V18, P1082, DOI 10.1016/j.media.2014.06.009
   Lai CH, 2013, IMAGING SCI J, V61, P320, DOI 10.1179/1743131X11Y.0000000061
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Mathew SP, 2014, ACTA POLYTECH HUNG, V11, P25
   Medjeded M, 2014, J MED IMAG HEALTH IN, V4, P43, DOI 10.1166/jmihi.2014.1223
   Medina JM, 2012, IEEE T FUZZY SYST, V20, P786, DOI 10.1109/TFUZZ.2012.2201726
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2014, SIGNAL PROCESS-IMAGE, V29, P400, DOI 10.1016/j.image.2013.12.002
   Nandagopalan S, 2012, IMAGING SCI J, V60, P256, DOI 10.1179/1743131X11Y.0000000048
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   Sadek S., 2009, INT J VIDEO MAGE PRO, V9, P17
   Schnorrenberg F, 2000, Technol Health Care, V8, P291
   Selvi SMalar., 2014, International Journal of Engineering Sciences and Emerging Technologies, V6, P410
   Sriramakrishnan C., 2012, Journal of Computer Science, V8, P1809, DOI 10.3844/jcssp.2012.1809.1813
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P3, DOI 10.1109/TCSVT.2007.906936
   Tsai HH, 2014, APPL SOFT COMPUT, V17, P127, DOI 10.1016/j.asoc.2013.12.003
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Wang XY, 2014, NEUROCOMPUTING, V127, P214, DOI 10.1016/j.neucom.2013.08.007
   Yang HY, 2014, J VIS COMMUN IMAGE R, V25, P1308, DOI 10.1016/j.jvcir.2014.05.003
   Yang L, 2010, IEEE T PATTERN ANAL, V32, P30, DOI 10.1109/TPAMI.2008.273
   Yin PY, 2006, J VIS COMMUN IMAGE R, V17, P1108, DOI 10.1016/j.jvcir.2006.04.004
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
   Zheng L, 2003, IEEE T INF TECHNOL B, V7, P249, DOI 10.1109/TITB.2003.822952
NR 38
TC 4
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21729
EP 21747
DI 10.1007/s11042-016-3969-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400063
DA 2024-07-18
ER

PT J
AU Jana, B
   Giri, D
   Mondal, SK
AF Jana, Biswapati
   Giri, Debasis
   Mondal, Shyamal Kumar
TI Partial reversible data hiding scheme using (7,4) hamming code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Hamming error correcting code; Least significant bit;
   Partial reversible data hiding; RS analysis; Steganographic attack
ID EMBEDDING EFFICIENCY; IMAGES
AB In this paper, we propose a partial reversible data hiding scheme using (7,4) Hamming code (PRDHHC) with secret position (kappa). In this scheme, we partition the original cover image into (7 x 7) pixel block and adjust redundant LSB bits of each row using odd parity. Then we calculate secret position kappa = (delta mod 7) + 1, where delta is a shared secret key. The bit at position kappa and a suitable location for hidden message bit is modified through error creation caused by tamper in each row of the selected block. For the next row, the kappa is updated by the data embedding position (omega) of the previous row. We repeat this process to embed secret message bits within the selected block. For each new block, the kappa is updated by kappa (i+1) = (kappa (i) x delta x omega) mod 7 + 1, where i = 0, 1, 2, 3, ..., number of blocks. At the receiver end, we complement the bit at position kappa then retrieve the secret message bit by applying Hamming error correcting code. The extraction process will be stopped when we find continuous no error within stego image. The propose PRDHHC scheme extract the hidden message successfully and recover hamming adjusted cover image by complement bits at both the kappa and omega positions but can not recover original cover image, that is to say, our scheme is partial reversible. Finally, we compared our scheme with other state-of-the-art methods and obtained reasonably better performance in terms of visual quality (measured by PSNR). Also we analyze our generated stego image using some steganalysis techniques which give promising results.
C1 [Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
   [Giri, Debasis] Haldia Inst Technol, Dept Comp Sci & Engn, Haldia 721657, W Bengal, India.
   [Mondal, Shyamal Kumar] Vidyasagar Univ, Dept Appl Math Oceanol & Comp Programming, Midnapore 721102, India.
C3 Vidyasagar University; Haldia Institute of Technology; Vidyasagar
   University
RP Jana, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM biswapatijana@gmail.com; debasis_giri@hotmail.com;
   shyamal_260180@yahoo.com
RI Giri, Debasis/W-7417-2019; Jana, Prof. Biswapati/AAA-2154-2019
OI Giri, Debasis/0000-0003-3033-3036; Jana, Prof.
   Biswapati/0000-0003-4476-3459
CR [Anonymous], P 2 INT C UB INF MAN
   [Anonymous], 2001, F5 STEGANOGRAPHIC AL
   Cao Z., 2016, SPRINGERPLUS, V5, P1
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2006, PATTERN RECOGN, V39, P1155, DOI 10.1016/j.patcog.2005.12.011
   Chang CC, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P16, DOI 10.1109/ISECS.2008.222
   Fan L, 2013, COMPUT ELECTR ENG, V39, P873, DOI 10.1016/j.compeleceng.2012.06.014
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Guo JM, 2008, SIGNAL PROCESS, V88, P1496, DOI 10.1016/j.sigpro.2007.12.015
   Kim C., 2011, DATA HIDING HALFTONE, P372
   Kim C., 2014, IMPROVING DATA HIDIN, P697
   Lien B. K., 2015, DISPERSED DATA HIDIN, P179
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   MA ZP, 2013, J SHANGHAI U NAT SCI, V2
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
NR 19
TC 24
Z9 24
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21691
EP 21706
DI 10.1007/s11042-016-3990-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400061
DA 2024-07-18
ER

PT J
AU Liu, G
   Wang, F
   Liu, ZH
AF Liu Gang
   Wang Fei
   Liu Zhonghua
TI Infrared aerial small target detection based on digital image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared image; Small target; Background suppression; Contourlet
   transform; Directional energies; BP neural network
ID CONTOURLET TRANSFORM
AB Aiming for the problem detection of infrared imaging aerial small target under complex background, an intelligent algorithm is presented based on digital image processing which mainly makes use of the theory of contourlet transform and BP(Back propagation) neural network. Firstly, this method transforms the infrared image from space domain to contourlet domain. Then, in order to suppress most complex background, this algorithm sets lowpass coefficients to zero because it includes most gentle background information of the infrared image. Furtherly, this method constructs a novel threshold formula for bandpass coefficients which is based on the classic formula and takes the directional energies into account for restraining the remained background edges and noises. Subsequently, the reverse transform is carried out and the preprocessing result is obtained. Secondly, taking pixel's grayscale, horizontal gradient, vertical gradient, diagonal gradient, neighborhood mean and neighborhood variance as input feature vector, a BP neural network which has three layers is constructed and trained so that the non-linear relationship between the features and the target or background's pixel. In the end, infrared small target is detected by this BP network which has finished the procedure of training. The experimental results show that the method given by this paper can not only realize the suppression for the infrared complex background effectively, but also detect the small target whose SNR(Signal Noise Ratio) value is above 2 steadily.
C1 [Liu Gang; Wang Fei; Liu Zhonghua] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang, Henan, Peoples R China.
C3 Henan University of Science & Technology
RP Liu, G (corresponding author), Henan Univ Sci & Technol, Informat Engn Coll, Luoyang, Henan, Peoples R China.
EM lg19741011@163.com
FU Henan University of Science and Technology; aviation science fund
   [20130142004]
FX This paper's work is jointly supported by the doctor research fund of
   Henan University of Science and Technology and aviation science fund
   (#20130142004).
CR Bai XZ, 2013, OPTIK, V124, P6163, DOI 10.1016/j.ijleo.2013.04.098
   Bai XZ, 2012, INFRARED PHYS TECHN, V55, P177, DOI 10.1016/j.infrared.2011.12.002
   [陈炳文 Chen Bingwen], 2012, [中国图象图形学报, Journal of Image and Graphics], V17, P1252
   Chen H, 2015, INT J SMART SENS INT, V8, P497, DOI 10.21307/ijssis-2017-769
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   [焦建彬 Jiao Jianbin], 2010, [控制工程, Control Engineering of China], V17, P611
   Lu L, 2013, SENS TRANSDUCERS, V156, P116
   Lu Y, 2007, SYST ENG ELECT, V29, P1270
   Luo X, 2011, INFRARED LASERS ENG, V40, P1819
   Mo J., 2011, CHIN J STEREOLOGY IM, V16, P223
   Peng Jia-Xiong, 1999, Acta Electronica Sinica, V27, P47
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Tom VT, 2003, P SOC PHOTO-OPT INS, V1954, P2
   Wei Y, 2003, ISPA 2003: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, PTS 1 AND 2, P23
   [杨杰 YANG Jie], 2007, [红外与激光工程, Infrared and Laser engineering], V36, P382
   Zhang Yan, 2004, Systems Engineering and Electronics, V26, P1901
NR 17
TC 7
Z9 7
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19809
EP 19823
DI 10.1007/s11042-016-3568-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500029
DA 2024-07-18
ER

PT J
AU Lu, QM
   Wang, YL
AF Lu, Qingmei
   Wang, Yulin
TI Detection technology of malicious code based on semantic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic; Malicious code; Detection; Characteristic extraction
AB This paper puts forward one kind of behavioral characteristic extraction and detection method of malicious code based on semantic; it extracts the key behavior and dependence relations among behaviors by combining with stain spread analysis in command layer and semantic analysis in behavior layer. And then it uses anti-confusion engine identification semantic irrelevance and semantic equivalence behavior to obtain malicious code behavior characteristic with certain capacity of resisting disturbance, as well as realize characteristic extraction and detection on prototype system. It completes experimental demonstration on this system through analysis and detection on plenty of malicious code samples. The test result indicates that extraction characteristic based on the above methods has characteristic such as stronger capacity of resisting disturbance etc., detection based on this characteristic has better identification ability for malicious code.
C1 [Lu, Qingmei; Wang, Yulin] Wuhan Univ, Int Sch Software, Wuhan 430072, Hubei, Peoples R China.
   [Lu, Qingmei] North Univ China, Sch Sci & Control Engn, Taiyuan 030051, Shanxi, Peoples R China.
   [Lu, Qingmei] Univ Louisville, Dept Bioengn, Louisville, KY 40292 USA.
C3 Wuhan University; North University of China; University of Louisville
RP Lu, QM (corresponding author), Wuhan Univ, Int Sch Software, Wuhan 430072, Hubei, Peoples R China.; Lu, QM (corresponding author), North Univ China, Sch Sci & Control Engn, Taiyuan 030051, Shanxi, Peoples R China.; Lu, QM (corresponding author), Univ Louisville, Dept Bioengn, Louisville, KY 40292 USA.
EM luqingmei113@163.com
RI Yulin, Wang/AAL-3345-2021
OI Yulin, Wang/0000-0002-9899-7712
FU Science and Technology Program of Wuhan City [2014060101010029]
FX This work is sponsored by Science and Technology Program of Wuhan City
   under Grant No. 2014060101010029.
CR [Anonymous], J BIOMEDICINE BIOTEC
   [Anonymous], 2005, Chiba, Japan, Proceedings for the 14th International World Wide Web Conference, DOI DOI 10.1145/1060745.1060766
   [Anonymous], J CONVERGENCE
   Anyanwu K., 2003, Proceedings of the Twelfth International Conference on World Wide Web, May 2003, P690
   Diao M, 2011, LARGE SCALE SEMANTIC, P384
   Dong X., 2010, 19 INT WORLD WID WEB
   El-Semary AM, 2010, J INF PROCESS SYST, V6, P481, DOI 10.3745/JIPS.2010.6.4.481
   Ha HY, 2014, 2014 IEEE 15TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P765, DOI 10.1109/IRI.2014.7051966
   Jiang X, 2009, INFORM SCIENCES, V179, P2794, DOI 10.1016/j.ins.2009.04.005
   Kolter JZ, 2004, P 10 ACM SIGKDD INT
   Kumar KPK, 2014, HCIS, P4
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu TT, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-4
   Martens G, 2011, J INF PROCESS SYST, V7, P199, DOI 10.3745/JIPS.2011.7.1.199
   Min HS, 2012, IEEE T CIRC SYST VID, V22, P1174, DOI 10.1109/TCSVT.2012.2197080
   Minsu KO, 2013, JOS, V2, P23
   Mozgovoy M, 2013, HCIS, V8, P3
   Nguyen NP, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P213
   Ning G, 2011, COMPUT APPL, V31, P1006
   Patil PB, 2013, J INF PROCESS SYST, V9, P349, DOI 10.3745/JIPS.2013.9.3.349
   Qazvinian V., 2011, RUMOR HAS IT IDENTIF
   Viswanathan V, 2012, HCIS, V3, P2
   Viswanathan V, 2012, HCIS, P3
   Weon I-Y, 2013, JIPS, P5
NR 25
TC 3
Z9 3
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19543
EP 19555
DI 10.1007/s11042-015-3228-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500013
DA 2024-07-18
ER

PT J
AU Yang, Z
   Yang, F
   Xiong, HL
AF Yang, Zhen
   Yang, Fan
   Xiong, Huilin
TI Combining background information and a top-down model for computing
   salient objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background information; Locality-constrained linear codes; CRFs; Salient
   object
ID ATTENTION; SCENES
AB Predicting the salient object region in real scenes has progressed significantly in recent years. In this work, we propose a novel method for computing salient object regions by combining background information and a top-down visual saliency model, which is well-suited for locating category-specific salient objects in cluttered real scenes. First, we used a robust background measure to acquire clean saliency maps by optimizing background information. Second, we learned a top-down saliency object model by combining a class-specific codebook and conditional random fields (CRFs) during the training phase. Furthermore, our model used the locality-constrained linear codes as latent CRF variables. Finally, we computed salient object regions by combining the robust background measure and top-down model. Experimental results on the Graz-02 and PASCAL VOC2007 datasets show that our method creates much better saliency maps than current state-of-the-art methods.
C1 [Yang, Zhen; Xiong, Huilin] Shanghai Jiao Tong Univ, Dept Automat, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Yang, Fan] Jiangxi Sci & Technol Normal Univ, Sch Commun & Elect, 605 Fenglin Rd, Nanchang, Jiangxi, Peoples R China.
C3 Shanghai Jiao Tong University; Jiangxi Science & Technology Normal
   University
RP Yang, Z (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM yangzhen5771@sjtu.edu.cn; kooyang@aliyun.com; hlxiong@sjtu.edu.cn
FU National Natural Foundation of China [61375008]
FX This work was supported by the National Natural Foundation of China
   under grant no. 61375008. We thank LetPub (www.letpub.com) for its
   linguistic assistance during the preparation of this manuscript.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2009, P ADV NEUR INF PROC
   Aytekin C, 2017, MULTIMED TOOLS APPL, V76, P10443, DOI 10.1007/s11042-016-3431-1
   Bodesheim Paul, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P450, DOI 10.1007/978-3-642-23123-0_47
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Ding YY, 2011, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2011.5995445
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Ehinger KA, 2009, VIS COGN, V17, P945, DOI 10.1080/13506280902834720
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Khan N, 2013, IEEE IMAGE PROC, P166, DOI 10.1109/ICIP.2013.6738035
   Kocak A, 2014, P BRIT MACH VIS C BM
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Liang Z, 2012, MULTIMED TOOLS APPL, V68, P517
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Moosmann F, 2007, Adv Neural Inf Process Syst, P985
   Nguyen Thang-An., 2016, MANIPULATION AUTOMAT, P1
   Opelt A, 2006, IEEE T PATTERN ANAL, V28, P416, DOI 10.1109/TPAMI.2006.54
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sun J, 2013, INT J COMPUT VISION, V104, P135, DOI 10.1007/s11263-013-0618-z
   Tang C, 2016, MULTIMED TOOLS APPL, V75, P6963, DOI 10.1007/s11042-015-2622-5
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wu B, 2014, MULTIMED TOOLS APPL, V73, P1053, DOI 10.1007/s11042-013-1530-9
   Xu X, 2016, MULTIMED TOOLS APPL, V75, P2667, DOI 10.1007/s11042-015-2570-0
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Yang Z, 2016, VISUAL COMPUT, P1
   Yang Z, 2016, NEUROCOMPUTING, V184, P188, DOI 10.1016/j.neucom.2015.07.124
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 45
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20815
EP 20832
DI 10.1007/s11042-016-4005-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400020
DA 2024-07-18
ER

PT J
AU Fu, CX
   Zhang, PL
   Jiang, J
   Yang, KW
   Lv, ZH
AF Fu, Chunxiao
   Zhang, Pengle
   Jiang, Jiang
   Yang, Kewei
   Lv, Zhihan
TI A Bayesian approach for sleep and wake classification based on dynamic
   time warping method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Sleep and wake classification; Dynamic time warping;
   Bayesian classification; Wearable devices; Internet of things
AB Sleep plays a significant role in human' smental and physical health. Recently, the associations between lack of sleep and weight gain, development of cancer and many other health problems have been recognized. Then monitoring the sleep and wake state all night is becoming a hotspot issue. Traditionally it classified by a PSG recording which is very costly and uncomfortable. Nowadays, with the advance of internet of things, many convenient wearable devices are being used for medical use, like measuring the heart rate (HR), blood pressure and other signals. With the sleep quality monitor problem, the key question is how to discriminate the sleep and weak stage from these signals. This paper proposed a Bayesian approach based on dynamic time warping (DTW) method for sleep and wake classification. It used HR and surplus pulse O2 (SPO2) signals to analyze the sleep states and the occurrence of some sleep-related problems. DTW is an algorithm that searches an optimal alignment between time series with scaling and shifting and Bayesian methods have been successfully used for object classification in many study. In this paper, a three-step process is used for sleep and wake classification. In the first step, the DTW is used to extract features of the original HR and SPO2 signals. Then a probabilistic model is introduced for using the Bayesian classification for uncertain data. And in the classification step, the DTW features are used as the training dataset in the Bayesian approach for sleep and wake classification. Finally, a case study form a real-word applications, collected from the website of the Sleep Heart Health Study, is presented to shown the feasibility and advantages of the DTW-based Bayesian approach.
C1 [Fu, Chunxiao; Zhang, Pengle; Jiang, Jiang; Yang, Kewei] Natl Univ Def Technol, Coll Informat Syst & Management, Changsha, Hunan, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 National University of Defense Technology - China; Chinese Academy of
   Sciences; Shenzhen Institute of Advanced Technology, CAS
RP Fu, CX (corresponding author), Natl Univ Def Technol, Coll Informat Syst & Management, Changsha, Hunan, Peoples R China.; Lv, ZH (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM chunxiaosky@hotmail.com; paulplayergg@gmail.com; jiangjiangnudt@163.com;
   kayyang27@nudt.edu.cn; lvzhihan@gmail.com
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022; jiang,
   jun/GWC-9329-2022; jiang, jiang/GRX-1861-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074; 
FU National Natural Science Foundation of China [71201168]
FX This work was supported (in part) by the National Natural Science
   Foundation of China under Grant Nos. 71201168.
CR [Anonymous], 2014, SLEEP HEART HLTH STU
   [Anonymous], 2005, PRACTICE PARAMETERS, V28, P21
   [Anonymous], 2002, ADV PTRN RECOGNIT
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Bishop CM, 2004, COMP SYST SCI, P190
   Bishop CM, 1997, MICROSOFT RES
   Devot S, 2010, 32 ANN INT C IEEE EM
   Dingde J, 2015, J SYST STWARE
   Dingde J, 2015, WIRELESS PERSONAL CO
   Dongfang Z, 2014, 2014 I E INT C IEEE
   Hedner J, 2004, SLEEP, V27, P10
   Jiachen Y, 2015, SENSORS
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Jiang DD, 2009, IEEE COMMUN LETT, V13, P52, DOI 10.1109/LCOMM.2008.081271
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Long X, 2014, IEEE J BIOMED HEALTH, P18
   Long X, 2012, P 2012 I E 12 INT C
   Long X, 2012, P IEEE EMBS INT C BI
   Lv Z, 2015, PERSONAL UBIQUITOUS
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   MacKay DJC, 1992, NEURAL COMPUT, V4, P16
   Marcos JV, 2010, PHYSIOL MEAS, V31, P375, DOI 10.1088/0967-3334/31/3/007
   Neal RM, 1996, BAYESAIN LEARNING NE
   Rechtschaffen E. A., 1968, MANUAL STANDARDIZED
   Skolidis G, 2011, IEEE T NEURAL NETWOR, V22, P2011, DOI 10.1109/TNN.2011.2168568
   Su Tianyun, 2016, COMP GRAPHICS
   Wang Ke, 2014, P 23 INT S HIGH PERF
   Wang Y, 2011, IEEE T CONTR SYST T, V19, P9
   Yang JC, 2015, IEEE SENS J, V15, P4508, DOI 10.1109/JSEN.2015.2421518
   Yang JC, 2014, J CLIN MONIT COMPUT, V28, P363, DOI 10.1007/s10877-013-9541-7
   Yang JC, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.3.033001
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
   Yi Wang, 2015, P 27 INT C SCI STAT
   Zhang S, 2014, IEEE IMAGE PROC, P2724, DOI 10.1109/ICIP.2014.7025551
NR 38
TC 15
Z9 17
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17765
EP 17784
DI 10.1007/s11042-015-3053-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800010
DA 2024-07-18
ER

PT J
AU Gupta, H
   Singh, S
   Sinha, P
AF Gupta, Harshita
   Singh, Saumya
   Sinha, Priyanka
TI Multimedia tool as a predictor for social media advertising- a YouTube
   way
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YouTube; Multimedia; Advertising; Content analysis; Social media; AIDA
   model
ID SENSATION VALUE; APPEALS
AB Multimedia has embraced the marketing industry with its innovative tools. Advertising as a part of marketing is not an exception. Social media is one of its tools which is growing with an accelerating speed and facilitating meaningful participation. YouTube is the second largest search engine after Google and is considered to leverage its features to provide nothing but the best to its users. Marketers of beauty products have also realized its potential and are using YouTube as a powerful marketing tool. The paper attempts to evaluate importance of YouTube as a multimedia tool. Content analysis of hundred YouTube advertisements of the beauty segment has been done to identify their critical success factors like Audio content (sound saturation, background music, loud and fast music, sound effects), Visual Category (No. of cuts, visual effects, intense imagery, slow motion, bold/ unusual colours), Content category (acted out, unexpected format, surprise ending), Message Appeals (Rational, Fear, Social, Youth, Statistics, Bandwagon and Celebrity Appeal) and viewers' response through the number of views and likes. Accordingly, a framework has been proposed that may be useful for the managers who develop promotional strategies for the organizations. AIDA model has been used to validate the framework.
C1 [Gupta, Harshita; Singh, Saumya; Sinha, Priyanka] IIT ISM, Dept Management Studies, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Gupta, H (corresponding author), IIT ISM, Dept Management Studies, Dhanbad 826004, Jharkhand, India.
EM harshitagpt12@gmail.com; saumya.ism@gmail.com;
   sinha.priyanka09@gmail.com
RI Singh, Saumya/AAD-9056-2020
OI Singh, Saumya/0000-0001-7726-6104; Gupta, Harshita/0000-0001-7653-9692
CR Albers-Miller ND, 1999, J CONSUM MARK, V16, P42, DOI 10.1108/07363769910250769
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   An D., 2003, CONTENT ANAL ADVERTI, V06, P1
   Barry T.E., 1990, INT J ADVERT, V9, P121, DOI [DOI 10.1080/02650487.1990.11107138, 10.1080/02650487.1990.11107138]
   Barry T. F., 1990, BRIT J MARKETING STU, V9, P121
   Chua TS, 2016, SIGNAL PROCESS, V124, P1, DOI 10.1016/j.sigpro.2015.12.004
   Dehghani M, 2016, COMPUT HUM BEHAV, V59, P165, DOI 10.1016/j.chb.2016.01.037
   HYMAN MR, 1990, J BUS ETHICS, V9, P105, DOI 10.1007/BF00382660
   Jeon W., 1999, ASIA PAC J MANAG, V16, P249, DOI [DOI 10.1023/A:1015491009717, 10.1023/A:1015491009717]
   Klepek M., 2007, GUERRILLA MARKETING, P79
   Know Your Audience, 2016, CODING CONTENT ANAL
   Liebrecht C., 2016, ONE CODER RELIABILIT, P1
   Loosemore M, 2010, INT J MANAG PROJ BUS, V3, P307, DOI 10.1108/17538371011036608
   Macnamara J., 2006, Asia Pacific Public Relations Journal, V6, P1, DOI [10.4249/scholarpedia.3712, DOI 10.4249/SCHOLARPEDIA.3712]
   Morgan SE, 2003, J COMMUN, V53, P512, DOI 10.1111/j.1460-2466.2003.tb02605.x
   Paek HJ, 2010, HEALTH EDUC RES, V25, P1085, DOI 10.1093/her/cyq063
   Palmgreen P.M., 1991, Health Communication, V3, P217, DOI 10.1207/s15327027hc0304_4
   Prasad B. D., 2008, CONTENT ANAL
   Riffe D, 1997, JOURNALISM MASS COMM, V74, P873, DOI 10.1177/107769909707400414
   Stephenson MT, 2003, HUM COMMUN RES, V29, P343, DOI 10.1111/j.1468-2958.2003.tb00843.x
   YALE L, 1988, J ADVERTISING, V17, P12, DOI 10.1080/00913367.1988.10673099
NR 21
TC 27
Z9 33
U1 6
U2 130
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18557
EP 18568
DI 10.1007/s11042-016-4249-6
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800019
DA 2024-07-18
ER

PT J
AU Jaswal, G
   Nigam, A
   Nath, R
AF Jaswal, Gaurav
   Nigam, Aditya
   Nath, Ravinder
TI DeepKnuckle: revealing the human identity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Finger knuckle print; Bubble ordinal pattern; Star ordinal
   pattern; Image ray transform; DeepMatching
ID KNUCKLE; IDENTIFICATION; ORIENTATION; PATTERNS; TEXTURE
AB Identification and authentication are ubiquitous questions which pan across various systems. In certain domains, they are of paramount importance. Like, security forces deploy various human identifications systems to discern potential wrongdoers. They constitute a vital part of various government social welfare schemes. The efficacy of the schemes is greatly impacted by them. Being pervasive and eminent, they demand more dedicated and focused research. Now-a-days, most of the systems incorporate a biometric system to address identification and authentication. The biometric system employs disparate traits like face, signature, iris, fingerprint, palmprint, speech, etc. for identification and authentication. A biometric trait must possess the following fundamental aspects; It should be able to identify an individual uniquely. For an individual, it should be consistent. To acquire it should be easy, cost-effective, time-efficient and automated. On such account, fingerprint trait is of outstanding merit. It has been widely studied and is an integral part of the many present biometric systems. However, fingerprints are subject to occupational hazard. The fingerprint is of abysmal quality for hand labourer, blacksmith, etc. due to the nature of their work. If a fingerprint based biometric system has a large number of such users then its precision is greatly affected. In such scenario, an alternate is to use finger-knuckle-print which possess almost comparable feature as fingerprint while being unaffected by such occupational hazards. In this paper, we propose a novel finger-knuckle-print based biometric system which could be deployed where a large number of user base is rural. Initially, ROI of finger knuckle image has been extracted, enhanced and transformed using the proposed Bubble ordinal pattern (BOP), STAR ordinal pattern (SOP), and Image ray transform (IRT) based locally adapted procedures. A novel DeepMatching technique has been used to perform non-rigid distortion free matching between multiple features of two Finger Knuckle Images (FKI). Finally, the performance of proposed system has been evaluated using score level fusion rule, revealing improvement in the results.
C1 [Jaswal, Gaurav; Nath, Ravinder] Natl Inst Technol, Hamirpur 177005, India.
   [Nigam, Aditya] Indian Inst Technol, Mandi 175005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Mandi
RP Jaswal, G (corresponding author), Natl Inst Technol, Hamirpur 177005, India.
EM gauravjaswal@nith.ac.in; aditya@iitmandi.ac.in; nath@nith.ac.in
RI Jaswal, Gaurav/AAE-4016-2021; Nath, Ravinder/ABE-7725-2021
OI Jaswal, Gaurav/0000-0002-3971-0160; Nath, Ravinder/0000-0003-4366-8185
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2005, IEEE INT C IMAGE PRO
   [Anonymous], 2010, EURASIP J ADV SIG PR, DOI DOI 10.1109/EC0C.2010.5622099
   [Anonymous], 2009, FINGER KNUCKLE PRINT
   [Anonymous], 2010, BIOMETRIC FINGERPRIN
   Bera A, 2014, HAND BIOMETRICS DIGI
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Cheng K., 2012, Proceedings of the International Conference of the Biometrics Special Interest Group (BIOSIG), P1
   Colbert C, 1997, US Patent, Patent No. [5,94,806, 594806]
   Cummings AH, 2011, PATTERN RECOGN LETT, V32, P2053, DOI 10.1016/j.patrec.2011.08.020
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Ferrer MA, 2006, IEEE AERO EL SYS MAG, V21, P23, DOI 10.1109/MAES.2006.1662005
   Gao GW, 2014, NEUROCOMPUTING, V135, P180, DOI 10.1016/j.neucom.2013.12.036
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Jain A. K., 2010, Second Gener Biom, V12, P2
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jaswal G, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P214, DOI 10.1109/ICIIP.2015.7414768
   Joshi DG, 1998, PATTERN RECOGN, V31, P15, DOI 10.1016/S0031-3203(97)00034-4
   Kong T, 2014, INT J MACH LEARN CYB, V5, P569, DOI 10.1007/s13042-013-0208-y
   Kumar A, 2009, HUMAN IDENTIFICATION
   Kumar A, 2015, PATTERN RECOGN LETT, V68, P361, DOI 10.1016/j.patrec.2015.08.013
   Kumar A, 2014, IEEE T INF FOREN SEC, V9, P1288, DOI 10.1109/TIFS.2014.2328869
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Kumar A, 2009, IEEE T IMAGE PROCESS, V18, P2127, DOI 10.1109/TIP.2009.2023153
   Kumar A, 2009, IEEE T INF FOREN SEC, V4, P98, DOI 10.1109/TIFS.2008.2011089
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Morales A, 2011, ELECTRON LETT, V47, P380, DOI 10.1049/el.2011.0156
   Morales A, 2007, P 1 SPAN WORKSH BIOM
   Nigam A, 2016, NEUROCOMPUTING, V188, P190, DOI 10.1016/j.neucom.2015.04.126
   Nigam A, 2013, IEEE IMAGE PROC, P4205, DOI 10.1109/ICIP.2013.6738866
   Ravikanth C., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Revaud J., 2015, INT J COMPUT VISION, V120, P1
   Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796
   Woodard DL, 2005, PROC CVPR IEEE, P1030
   Yu H., 2015, INT J SIGNAL PROCESS, V8, P185
   Yu PF, 2014, APPL MECH MATER, V441, P703, DOI 10.4028/www.scientific.net/AMM.441.703
   Zaw Kyi Pyar, 2014, INT J SCI ENG TECHNO, V3, P1599
   Zhang L, 2011, PATTERN RECOGN, V44, P1990, DOI 10.1016/j.patcog.2010.06.007
   Zhang L, 2009, IEEE IMAGE PROC, P1981, DOI 10.1109/ICIP.2009.5413734
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
NR 41
TC 22
Z9 22
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18955
EP 18984
DI 10.1007/s11042-017-4475-6
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800038
DA 2024-07-18
ER

PT J
AU Zeng, QM
   Zhu, TL
   Zhuang, XY
   Zheng, MX
   Guo, YB
AF Zeng, Qingmao
   Zhu, Tonglin
   Zhuang, Xueying
   Zheng, Mingxuan
   Guo, Yubin
TI Using the periodic wavelet descriptor of plant leaf to identify plant
   species
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periodic wavelet descriptor (PWD); Plant leaf; Identification of plant
   species; Neural network
ID CLASSIFICATION; IDENTIFICATION; DESIGN
AB Plant species identification is one of the most important research branches of botanical science. In this paper, a novel shape descriptor, namely Periodic Wavelet Descriptor (PWD) of plant leaf, is firstly presented. Then based on the PWDs of the leaves of different plant species, we constructed a database of PWDs. At last, a Back Propagation Neural Network (BPNN) is trained to fulfill the experiment of plant species identification. The experimental results show that the proposed algorithm combined the PWD of plant leaf with BPNN is effective with a correct identification rate about 90 %.
C1 [Zeng, Qingmao; Zhu, Tonglin; Guo, Yubin] South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Guangdong, Peoples R China.
   [Zeng, Qingmao; Zhu, Tonglin] South China Agr Univ, Inst Agr Multimedia Technol, Guangzhou 510642, Guangdong, Peoples R China.
   [Guo, Yubin] Minist Land & Resources Construct Land Transforma, Key Lab, Guangzhou 510642, Guandong, Peoples R China.
   [Guo, Yubin] Guangdong Prov Key Lab Land Use & Consolidat, Guangzhou 510642, Guandong, Peoples R China.
   [Zhuang, Xueying; Zheng, Mingxuan] South China Agr Univ, Coll Forestry & Landscape Architecture, Guangzhou 510642, Guandong, Peoples R China.
C3 South China Agricultural University; South China Agricultural
   University; South China Agricultural University
RP Guo, YB (corresponding author), South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Guangdong, Peoples R China.; Guo, YB (corresponding author), Minist Land & Resources Construct Land Transforma, Key Lab, Guangzhou 510642, Guandong, Peoples R China.; Guo, YB (corresponding author), Guangdong Prov Key Lab Land Use & Consolidat, Guangzhou 510642, Guandong, Peoples R China.
EM 1276686239@qq.com
FU National Science and Technology Ministry in the 12th Five-Year Plan of
   China: Research on digital supervision technology for rural construction
   land reuse business [2013BAJ13B05]
FX Foundation item: The work is supported by National Science and
   Technology Ministry in the 12th Five-Year Plan of China: Research on
   digital supervision technology for rural construction land reuse
   business (ID: 2013BAJ13B05).
CR [Anonymous], 2015, PLOSE ONE
   [Anonymous], 1992, CBMSNSF REGIONAL C S
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Bhardwaj A, 2013, LECT NOTES COMPUT SC, V7995, P86, DOI 10.1007/978-3-642-39479-9_11
   Cerutti G, 2014, PATTERN RECOGN LETT, V49, P177, DOI 10.1016/j.patrec.2014.07.016
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073
   de Carvalho MR, 2007, EVOL BIOL, V34, P140, DOI 10.1007/s11692-007-9011-6
   Demuth H., 2009, NEURAL NETWORK TOOLB
   Gonzalez R E Woods R.C., 2004, DIGITAL IMAGE PROCES
   Gonzalez RE Woods R.C., 2007, DIGITAL IMAGE PROCES, V3rd
   Haykin S. S., 2009, NEURAL NETWORKS LEAR
   Jadid MN, 1996, ENG APPL ARTIF INTEL, V9, P309, DOI 10.1016/0952-1976(96)00021-8
   Kith K, 2008, INT J WAVELETS MULTI, V6, P25, DOI 10.1142/S0219691308002197
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012
   Narcowich FJ, 2009, 1 COURSE WAVELETS FO
   Satti V., 2013, INT J ENG SCI TECHNO, V4, P874
   Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108
   Ye P, 2011, CLASSIFICATION RECOG, P38
   Zeng Qingmao, 2011, Journal of Computer Aided Design & Computer Graphics, V23, P2046
   Zhang SW, 2013, PATTERN RECOGN, V46, P1891, DOI 10.1016/j.patcog.2013.01.015
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004
   Zhao ZQ, 2015, NEUROCOMPUTING, V151, P1112, DOI 10.1016/j.neucom.2014.02.077
   Zhu TL, 1998, APPL MATH COMPUT, V96, P127, DOI 10.1016/S0096-3003(97)10111-4
NR 23
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17873
EP 17890
DI 10.1007/s11042-015-3178-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800016
DA 2024-07-18
ER

PT J
AU Liu, LF
   Miao, SX
AF Liu, Lingfeng
   Miao, Suoxia
TI An image encryption algorithm based on Baker map with varying parameter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Baker map with varying parameter; Non-stationary;
   Chaotic matrix
ID CHAOTIC MAP; IMPROVEMENT; SYSTEM
AB Because of the excellent properties, such as unpredictability, randomness, aperiodicity, sensitive dependence on initial conditions and parameters, chaotic systems become popular in security applications. However, for a fixed chaotic system, with the development of chaos theory, the chaotic orbits may be estimated and their parameters or initial values may be predicted. In this paper, we introduce a parameter-varying Baker map (PVBM), whose output signal is non-stationary. The varying parameters disrupt the phase space of the system, which can resist the phase space reconstruction attacks and chaotic signal estimation technologies effectively. To investigate its applications, we propose a new image encryption algorithm, which is combined with chaotic shuffling and chaotic substitution. Simulation results demonstrate the proposed algorithm have high security as well as to resist various attacks.
C1 [Liu, Lingfeng] Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
   [Miao, Suoxia] Nanchang Inst Technol, Fac Sci, Nanchang 330029, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang Institute Technology
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018
FU National Natural Science Foundation of China (NSFC) [61601215]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under grants no. 61601215.
CR Alireza J., 2011, COMPUT INF SCI, V4, P172
   APPEL U, 1983, INFORM SCIENCES, V29, P27, DOI 10.1016/0020-0255(83)90008-7
   Chatzis SP, 2012, PATTERN RECOGN, V45, P3985, DOI 10.1016/j.patcog.2012.04.018
   Chen CS, 2013, J SYST SOFTWARE, V86, P100, DOI 10.1016/j.jss.2012.07.020
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Hermassi H, 2012, J SYST SOFTWARE, V85, P2133, DOI 10.1016/j.jss.2012.04.031
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Liu L.M., 2010, J SHENYANG NORM U NA, V28, P357
   Liu LF, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1959-1
   Pincus S, 1997, P NATL ACAD SCI USA, V94, P3513, DOI 10.1073/pnas.94.8.3513
   PINCUS SM, 1991, P NATL ACAD SCI USA, V88, P2297, DOI 10.1073/pnas.88.6.2297
   Rukhin A, 2001, 80022 DEP COMM NAT I
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Z, 2012, CHINESE PHYS B, V21, DOI 10.1088/1674-1056/21/5/050506
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Ye GD, 2013, NONLINEAR DYNAM, V71, P259, DOI 10.1007/s11071-012-0658-x
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yoon Ji Won, 2010, COMMUNICATIONS NONLI, V15, P3998
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhou Q, 2012, J SYST SOFTWARE, V85, P400, DOI 10.1016/j.jss.2011.08.032
NR 31
TC 45
Z9 46
U1 0
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16511
EP 16527
DI 10.1007/s11042-016-3925-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100020
DA 2024-07-18
ER

PT J
AU Park, SW
   Cho, CH
   Choi, SB
AF Park, Sun-Woo
   Cho, Chul-Ho
   Choi, Suk Bong
TI Social multimedia network service quality, user satisfaction, and
   prosumer activity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social multimedia network service; Prosumer activity; User satisfaction;
   Sports game and event
ID TRUST; MODEL
AB This study addresses the effects of social multimedia network service quality on user satisfaction and prosumer activity by analyzing data from 400 Korean sports game and event enthusiasts who are social networking service (SNS) users. We also examine the mediating role of value in the relationship between SNS information service quality and prosumer activity. The findings show that trust, interactivity, and search convenience, which are sub-constructs of SNS information service quality, positively influence value and that trust and accuracy are positively associated with user satisfaction. Further, while value has a positive effect on user satisfaction and prosumer activity, user satisfaction has a positive effect on prosumer activity. We also find that value has a partial mediating role in the relationship between SNS information service quality and prosumer activity. In our conclusion, the implications of our findings for future research and practice are discussed.
C1 [Park, Sun-Woo] Sookmyung Womens Univ, Dept Dance, Seoul, South Korea.
   [Cho, Chul-Ho] Daegu Haany Univ, Dept Hosp Management, Gyeongsangbuk Do, South Korea.
   [Choi, Suk Bong] Korea Univ, Coll Business & Econ, 2511 Sejong Ro, Sejong 30019, South Korea.
C3 Sookmyung Women's University; Daegu Haany University; Korea University
RP Choi, SB (corresponding author), Korea Univ, Coll Business & Econ, 2511 Sejong Ro, Sejong 30019, South Korea.
EM sukchoi@korea.ac.kr
CR ACHROL RS, 1991, J MARKETING, V55, P77, DOI 10.2307/1251958
   Agarwal R, 2002, INFORM SYST RES, V13, P168, DOI 10.1287/isre.13.2.168.84
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   Bolton RN, 1999, J MARKETING RES, V36, P171, DOI 10.2307/3152091
   Choi Jae H., 2013, J. theor. appl. electron. commer. res., V8, P69, DOI 10.4067/S0718-18762013000100006
   Cronin J., 1997, JOURNAI SERVICING MA, V11, P375, DOI [https://doi.org/10.1108/08876049710187482, DOI 10.1108/08876049710187482]
   CRONIN JJ, 1992, J MARKETING, V56, P55, DOI 10.2307/1252296
   De Wulf K, 2006, INFORM MANAGE-AMSTER, V43, P434, DOI 10.1016/j.im.2005.10.005
   DeLone WH, 2003, J MANAGE INFORM SYST, V19, P9, DOI 10.1080/07421222.2003.11045748
   Dong TP, 2014, COMPUT HUM BEHAV, V30, P708, DOI 10.1016/j.chb.2013.07.037
   Drew JH, 1987, ADD VALUE YOUR SERVI
   Ettinger WH, 1998, J AM GERIATR SOC, V46, P111, DOI 10.1111/j.1532-5415.1998.tb01024.x
   Gooding SK, 1995, J RETAILING, V70, P163
   Hakserver C, 2000, SERVICE MANAGEMENT O
   Heinonen Kristina, 2009, International Journal of Electronic Business, V7, P190, DOI 10.1504/IJEB.2009.024627
   Hennig-Thurau T, 2004, J INTERACT MARK, V18, P38, DOI 10.1002/dir.10073
   Houston StephenD., 2004, 1 WRITING SCRIPT INV, P3
   Hsiao KL, 2011, ONLINE INFORM REV, V35, P770, DOI 10.1108/14684521111176499
   Jang YT, 2015, MULTIMED TOOLS APPL, V74, P159, DOI 10.1007/s11042-013-1430-z
   Jreskog KG, 1993, LISREL 8 USERS REFER
   Kim K, 2000, ICIS P BRISB
   Kim Tae-Kyung, 2015, [Journal of Korean Society for Quality Management, 품질경영학회지], V43, P185, DOI 10.7469/JKSQM.2015.43.2.185
   Kotler P., 2010, Prosumer Revisited, P51
   Lee M., 1997, J SERV MARK, V11, P39
   LEWIS JD, 1985, SOC FORCES, V63, P967, DOI 10.2307/2578601
   Liljander V., 1994, International Journal of Service Industry Management, v, V4, n, P6
   Liu C, 2000, INFORM MANAGE, V38, P23, DOI 10.1016/S0378-7206(00)00049-5
   Madu C. N, 2002, INT J QUAL RELIAB MA, V19, P246, DOI [10.1108/02656710210415668, DOI 10.1108/02656710210415668]
   McKinney V, 2002, INFORM SYST RES, V13, P296, DOI 10.1287/isre.13.3.296.76
   Mcknight DH, 1998, ACAD MANAGE REV, V23, P473, DOI 10.5465/AMR.1998.926622
   Misic MM, 1999, INTERNET RES, V9, P383, DOI 10.1108/10662249910297787
   MOORMAN C, 1993, J MARKETING, V57, P81, DOI 10.2307/1252059
   MOSS P, 1986, HLTH VISIT, V0059
   Naumann Earl., 1994, Creating Customer Value: The Path to Sustainable Competitive Advantage
   OLIVER RL, 1980, J MARKETING RES, V17, P460, DOI 10.2307/3150499
   PARASURAMAN A, 1988, J RETAILING, V64, P12
   Prahalad CK, 2000, HARVARD BUS REV, V78, P79
   Raymond L, 1999, MIS Q, V9, P37
   RAYPORT JF, 1994, HARVARD BUS REV, V72, P141
   Song K, 2013, MULTIMED TOOLS APPL, V64, P455, DOI 10.1007/s11042-012-1068-2
   Suki NM, 2012, J INF TECHNOL RES, V5, P1, DOI 10.4018/jitr.2012040101
   Sweeney JC, 1999, J RETAILING, V75, P77, DOI 10.1016/S0022-4359(99)80005-0
   Toffler A., 1980, 3 WAVE
   Verhoef PC, 2002, J ACAD MARKET SCI, V30, P202, DOI 10.1177/00970302030003002
NR 44
TC 8
Z9 9
U1 3
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17213
EP 17229
DI 10.1007/s11042-016-3983-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500019
DA 2024-07-18
ER

PT J
AU Zhang, J
   Liang, JM
   Hu, HH
AF Zhang, Jun
   Liang, Jimin
   Hu, Haihong
TI Multi-view texture classification using hierarchical synthetic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture classification; Multi-view points; Affine transform; Random
   forests; Dictionary learning
ID ROTATION; SCALE; DESCRIPTORS; PATTERN
AB Multi-view texture classification is a very challenging task since the view-point variation often leads to the inconsistent local texton patterns. Existing studies focus on the extraction of scale, rotation or affine invariant representations by some specially designed invariant measurements or local descriptors. Differently, in this paper, we propose another framework for multi-view texture classification. A number of synthetic images are hierarchically created to enlarge the training dataset to cover the possible variations of different view-points. Then, a classifier based on random forests is trained based on these synthetic images. In the classification stage, we also create synthetic images for each testing image, and the synthetic images are classified with the pre-trained classifier. The final decision for this testing image is made by the majority voting of the classification results of all these synthetic images. The classification performance is evaluated on the UIUC texture dataset. Our method achieves the classification rate of 99.21%, which is higher than most of the state-of-the-arts.
C1 [Zhang, Jun; Liang, Jimin; Hu, Haihong] Xidian Univ, Sch Life Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Liang, JM (corresponding author), Xidian Univ, Sch Life Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM jiminliang@gmail.com
RI Zhang, Jun/L-3826-2017; Liang, Jimin/B-5394-2014
OI Liang, Jimin/0000-0003-1428-5804
FU National Natural Science Foundation of China [61571353]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2015JZ019]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61571353 and the Natural Science Basic Research
   Plan in Shaanxi Province of China under Grant No. 2015JZ019.
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], MULTIMEDIA TOOLS APP
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Breiman L., 2001, Mach. Learn., V45, P5
   Caputo B, 2005, IEEE I CONF COMP VIS, P1597, DOI 10.1109/iccv.2005.54
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen XY, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/414250
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Criminisi A., 2013, DECISION FORESTCOM, DOI DOI 10.1007/978-1-4471-4929-3
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55
   Dash JK, 2016, MULTIMED TOOLS APPL, P1
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P649
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li ST, 2003, PATTERN RECOGN, V36, P2883, DOI 10.1016/S0031-3203(03)00219-X
   Liu MX, 2016, IEEE T CYBERNETICS, V46, P298, DOI 10.1109/TCYB.2015.2401733
   Liu MX, 2016, IEEE T PATTERN ANAL, V38, P2335, DOI 10.1109/TPAMI.2015.2430325
   Mellor M, 2008, IEEE T PATTERN ANAL, V30, P52, DOI 10.1109/TPAMI.2007.1161
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Zhang J, 2015, PATTERN RECOGN LETT, V51, P57, DOI 10.1016/j.patrec.2014.08.002
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhang J, 2013, COMPUT VIS IMAGE UND, V117, P56, DOI 10.1016/j.cviu.2012.10.004
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
NR 35
TC 1
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17511
EP 17523
DI 10.1007/s11042-016-4231-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500035
DA 2024-07-18
ER

PT J
AU Zhu, N
   Deng, C
   Gao, XB
AF Zhu, Nan
   Deng, Cheng
   Gao, Xinbo
TI Image sharpening detection based on multiresolution overshoot artifact
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Image sharpening detection; Nonsubsampled contourlet
   transform; Overshoot artifacts
ID FORENSICS
AB With the wide use of sophisticated photo editing tools, digital image manipulation becomes very convenient, which makes the detection of image tampering significant. Image sharpening, which aims to enhance the contrast of edges in an image, is a ubiquitous image tampering operation. The detection of image sharpening can serve as a reliable clue for image forgery. In this paper, we propose a novel image sharpening detection method based on multiresolution overshoot artifact analysis (MOAA). By building the relationship between the overshoot artifact strength and the slope of a sharpened edge, we find that although undergoing the same sharpening operation, the edge with large slope will present a stronger overshoot artifact than the one with small slope. Based on this finding, we use the nonsubsampled contourlet transform (NSCT) to classify the image edge points into three categories, i.e., weak, middle and strong edge points and measure the overshoot artifact of each category respectively. A cascaded decision strategy is adopted to decide an image is sharpened or not. Experimental results on digital images with various sharpening operators demonstrate the superiority of our proposed method when compared with state-of-the-art approaches.
C1 [Zhu, Nan; Deng, Cheng; Gao, Xinbo] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Deng, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM nanzhu@stu.xidian.edu.cn; chdeng@mail.xidian.edu.cn;
   xbgao@mail.xidian.edu.cn
RI Zhu, Nan/L-8741-2019; Gao, Xinbo/Q-8622-2016
OI Zhu, Nan/0000-0002-8073-149X; Gao, Xinbo/0000-0003-1443-0776; Deng,
   Cheng/0000-0003-2620-3247
FU National High Technology Research and Development Program of China
   [2013AA01A602]; National Natural Science Foundation of China [61432014,
   61572388]; Program for Changjiang Scholars and Innovative Research Team
   in University [IRT13088]
FX The authors would like to thank the Editor-in-Chief, the handling
   associate editor and all anonymous reviewers for their considerations
   and suggestions. This work was supported by the National High Technology
   Research and Development Program of China (2013AA01A602), the National
   Natural Science Foundation of China (Grant Nos. 61432014 and 61572388)
   and Program for Changjiang Scholars and Innovative Research Team in
   University (No. IRT13088).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bas P., 2007, Break our Watermarking System, V2nd
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2011, IEEE SIGNAL PROC LET, V18, P603, DOI 10.1109/LSP.2011.2164791
   Cao G, 2009, IEEE INT CON MULTI, P1026, DOI 10.1109/ICME.2009.5202672
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Choi CH, 2013, FORENSIC SCI INT, V226, P94, DOI 10.1016/j.forsciint.2012.12.014
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Deng C, 2010, SIGNAL PROCESS, V90, P3256, DOI 10.1016/j.sigpro.2010.05.032
   Ding Feng., 2013, INT WORKSH DIG WAT, P180
   Fan S, 2012, INT J COMPUT INF SCI, V9, P2877
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Gao LL, 2016, AAAI CONF ARTIF INTE, P1188
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Gloe T, 2010, P SPIE C MED FOR SEC
   Hou XD, 2014, MULTIMED TOOLS APPL, V72, P1681, DOI 10.1007/s11042-013-1466-0
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Liu GJ, 2013, MATH COMPUT MODEL, V57, P2647, DOI 10.1016/j.mcm.2011.06.026
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Lu LJ, 2013, INT J DIGIT CRIME FO, V5, P53, DOI 10.4018/jdcf.2013070104
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Muammar H, 2013, INT CONF ACOUST SPEE, P2242, DOI 10.1109/ICASSP.2013.6638053
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shen ZY, 2016, MULTIMED TOOLS APPL, V75, P2327, DOI 10.1007/s11042-014-2407-2
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Thongkamwitoon T, 2015, IEEE T INF FOREN SEC, V10, P953, DOI 10.1109/TIFS.2015.2392566
   Wang XF, 2014, COMPUT VIS IMAGE UND, V128, P84, DOI 10.1016/j.cviu.2014.07.007
   Zhang R, 2015, MULTIMED TOOLS APPL, V74, P5557, DOI 10.1007/s11042-014-1868-7
NR 35
TC 10
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16563
EP 16580
DI 10.1007/s11042-016-3938-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100022
DA 2024-07-18
ER

PT J
AU Azmi, AN
   Nasien, D
   Omar, FS
AF Azmi, Aini Najwa
   Nasien, Dewi
   Omar, Fakhrul Syakirin
TI Biometric signature verification system based on freeman chain code and
   k-nearest neighbor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Offline signature verification system; Preprocessing; Feature
   extraction; Freeman chain code; Euclidean distance
AB Signature is one of human biometrics that may change due to some factors, for example age, mood and environment, which means two signatures from a person cannot perfectly matching each other. A Signature Verification System (SVS) is a solution for such situation. The system can be decomposed into three stages: data acquisition and preprocessing, feature extraction and verification. This paper presents techniques for SVS that uses Freeman chain code (FCC) as data representation. Before extracting the features, the raw images will undergo preprocessing stage; binarization, noise removal, cropping and thinning. In the first part of feature extraction stage, the FCC was extracted by using boundary-based style on the largest contiguous part of the signature images. The extracted FCC was divided into four, eight or sixteen equal parts. In the second part of feature extraction, six global features were calculated against split image to test the feature efficiency. Finally, verification utilized Euclidean distance to measured and matched in k-Nearest Neighbors. MCYT bimodal database was used in every stage in the system. Based on the experimental results, the lowest error rate for FRR and FAR were 6.67 % and 12.44 % with AER 9.85 % which is better in term of performance compared to other works using that same database.
C1 [Azmi, Aini Najwa; Nasien, Dewi; Omar, Fakhrul Syakirin] Univ Teknol Malaysia, Fac Comp, Dept Comp Sci, Johor Baharu 81310, Johor, Malaysia.
C3 Universiti Teknologi Malaysia
RP Azmi, AN; Nasien, D; Omar, FS (corresponding author), Univ Teknol Malaysia, Fac Comp, Dept Comp Sci, Johor Baharu 81310, Johor, Malaysia.
EM aininajwa.azmi@gmail.com; dewinasien@utm.my; fsyakirin2@live.utm.my
RI nasien, dewi/AAC-8722-2021
OI nasien, dewi/0000-0001-7932-0573
FU Research Management Centre of Universiti Teknologi Malaysia (UTM),
   Ministry of Higher Education Malaysia [4F264]; Research University Grant
   (RUG) [10 J73]; The World Academy of Sciences-Committee on Scientific
   and Technological (TWAS-COMSTECH) [4B197]
FX The authors are grateful to the Research Management Centre of Universiti
   Teknologi Malaysia (UTM), Ministry of Higher Education Malaysia for the
   Fundamental Research Grant Scheme (FRGS) vote number 4F264, Research
   University Grant (RUG) vote number 10 J73 and The World Academy of
   Sciences-Committee on Scientific and Technological (TWAS-COMSTECH) vote
   number 4B197, which have facilitated the success of this project.
CR Akram M, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P925, DOI 10.1109/ICIEV.2012.6317435
   Al-Mayyan W, 2011, DIGIT SIGNAL PROCESS, V21, P477, DOI 10.1016/j.dsp.2011.01.007
   Alonso- Fernandez F., 2007, P 2007 15 INT C IMAG, P1
   [Anonymous], TECHNOLOGICAL CHANGE
   [Anonymous], 1989, QUALITY ENG PRODUCTI
   [Anonymous], INT J EMERGING TECHN
   [Anonymous], P INT WORKSH FRONT H
   [Anonymous], INT J COMPUTER APPL
   [Anonymous], P C COMPUTERS CITY
   [Anonymous], 2010, INT J COMPUT APPL, DOI DOI 10.5120/383-573
   [Anonymous], 1993, P 3 INT WORKSH FRONT
   [Anonymous], THESIS
   Baltzakis H, 2001, ENG APPL ARTIF INTEL, V14, P95, DOI 10.1016/S0952-1976(00)00064-6
   BARON R, 1989, IEEE T INSTRUM MEAS, V38, P1132, DOI 10.1109/19.46414
   Cheriet M, 2007, CHARACTER RECOGNITION SYSTEMS: A GUIDE FOR STUDENTS AND PRACTIONERS, P1, DOI 10.1002/9780470176535
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Leclerc F., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P643, DOI 10.1142/S0218001494000346
   LEE S, 1992, IEEE T SYST MAN CYB, V22, P755, DOI 10.1109/21.156588
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Ozgunduz Emre, 2005, 2005 13th European Signal Processing Conference, P1
   Pal S., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P672, DOI 10.1109/DICTA.2011.119
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Prakash HN, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P201, DOI 10.1109/ICAPR.2009.28
   Samuel Daramola, 2010, INT J ENG SCI TECHNO, VED-2, P3137
   Song Y, 2007, LECT NOTES ARTIF INT, V4702, P248
   Zhan EQ, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT UBIQUITOUS COMPUTING AND EDUCATION, P202, DOI 10.1109/IUCE.2009.142
   Zhang ZX, 2011, LECT NOTES COMPUT SC, V7098, P141, DOI 10.1007/978-3-642-25449-9_18
NR 27
TC 20
Z9 21
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15341
EP 15355
DI 10.1007/s11042-016-3831-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900007
OA hybrid
DA 2024-07-18
ER

PT J
AU Chai, XL
   Gan, ZH
   Zhang, MH
AF Chai, Xiuli
   Gan, Zhihua
   Zhang, Miaohui
TI A fast chaos-based image encryption scheme with a novel plain
   image-related swapping block permutation and block diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diffusion method within the block image (DMWBI); Diffusion method
   between two block images (DMBTBI); Image encryption; Block permutation;
   Block diffusion; Chaos
ID ALGORITHM; EFFICIENT; CRYPTANALYSIS; IMPROVEMENT; CONFUSION; SYSTEM; MAP
AB In the paper, a fast image encryption scheme with block permutation and block diffusion is introduced. Considering the increasing size of the image, encryption process is manipulated by block, and the encryption of every block image consists of block permutation and block diffusion. A novel plain image-related swapping block permutation strategy is presented, the swapping operation of the block image is controlled by the random chaotic sequences, and the initial value and parameter of the chaotic system are produced by SHA 256 hash value of the plain image, thus our algorithm is highly sensitive to changes of the plain image. Diffusion method within the block image (DMWBI) and diffusion method between two block images (DMBTBI) are presented to effectively eliminate the correlation of adjacent pixels in the plain image. The correlated chaos is employed to enhance the relationship of chaos, and take fully use of chaotic maps. One-dimensional Logistic-Sine System (LSS) is used to generate pseudo-random sequences during the whole encryption process. Experiment results and security analysis have proved the proposed image encryption algorithm is secure and effective.
C1 [Chai, Xiuli; Zhang, Miaohui] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Chai, Xiuli] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15261 USA.
   [Gan, Zhihua] Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
C3 Henan University; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); University of Pittsburgh; Henan University
RP Chai, XL (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.; Chai, XL (corresponding author), Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15261 USA.
EM chaixiuli@henu.edu.cn
FU National Natural Science Foundation of China [61203094, 61305042];
   Science and Technology Foundation of Henan Province of China
   [152102210048]; Foundation and Frontier Project of Henan Province of
   China [162300410196]; Natural Science Foundation of Educational
   Committee of Henan Province of China [14A413015]; Research Foundation of
   Henan University [xxjc20140006]
FX All the authors are deeply grateful to the editors for careful and fast
   handling of the manuscript. The authors would also like to thank the
   anonymous referees for their valuable suggestions to improve the quality
   of this paper. This work is supported by the National Natural Science
   Foundation of China (Grant No. 61203094 and 61305042), Science and
   Technology Foundation of Henan Province of China (Grant No.
   152102210048), Foundation and Frontier Project of Henan Province of
   China (Grant No. 162300410196), Natural Science Foundation of
   Educational Committee of Henan Province of China (Grant No. 14A413015),
   the Research Foundation of Henan University (Grant No. xxjc20140006).
CR Abdo AA, 2013, COMMUN NONLINEAR SCI, V18, P136, DOI 10.1016/j.cnsns.2012.05.023
   Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Chen JX, 2015, OPT LASER ENG, V66, P1, DOI 10.1016/j.optlaseng.2014.08.010
   Chen JX, 2014, NONLINEAR DYNAM, V77, P1191, DOI 10.1007/s11071-014-1370-9
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Galizzi GE, 2015, OPT COMMUN, V353, P76, DOI 10.1016/j.optcom.2015.05.011
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li HJ, 2013, OPT LASER ENG, V51, P1327, DOI 10.1016/j.optlaseng.2013.05.011
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu YS, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415501886
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Mao Y, 2014, WORLD SCI J BIFURCAT, V14, P3613
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mehra I, 2015, OPT COMMUN, V354, P344, DOI 10.1016/j.optcom.2015.06.015
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Özkaynak F, 2013, COMPUT PHYS COMMUN, V184, P2178, DOI 10.1016/j.cpc.2013.04.014
   Ping P, 2014, SIGNAL PROCESS, V105, P419, DOI 10.1016/j.sigpro.2014.06.020
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/3/030503
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang XY, 2012, OPT COMMUN, V285, P562, DOI 10.1016/j.optcom.2011.10.098
   Wang XY, 2011, OPT COMMUN, V284, P5804, DOI 10.1016/j.optcom.2011.08.053
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wong KW, 2009, CHAOS SOLITON FRACT, V41, P2652, DOI 10.1016/j.chaos.2008.09.047
   Wu Y, 2014, SIGNAL PROCESS, V102, P122, DOI 10.1016/j.sigpro.2014.03.015
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Yen JC, 2000, IEE P-VIS IMAGE SIGN, V147, P167, DOI 10.1049/ip-vis:20000208
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 59
TC 78
Z9 81
U1 2
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15561
EP 15585
DI 10.1007/s11042-016-3858-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900016
DA 2024-07-18
ER

PT J
AU Parsa, SS
   Sourizaei, M
   Dehshibi, MM
   Shateri, RE
   Parsaei, MR
AF Parsa, Seyyedeh-Sahar
   Sourizaei, Mohamad
   Dehshibi, Mohammad Mahdi
   Shateri, Reza Esmaeilzadeh
   Parsaei, Mohammad Reza
TI Coarse-grained correspondence-based ancient Sasanian coin classification
   by fusion of local features and sparse representation-based classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ancient coin classification; Cultural heritage; Feature fusion; Feature
   selection; Kernelized sparse representation-based classification
ID RECOGNITION
AB Numismatics sorts out historical aspects of money. Identification and classification of coins, as a part of their duties, need years of experience. This research aims at using the knowledge of numismatics for developing an image-based classification of ancient Sassanian dynasty coins. A straightforward method is to take coins observe and reverse-side motifs into account, just like numismatics does. To this aim, three feature descriptors, Cosine transform, Wavelet transform and Bi-Directional Principal Component Analysis, are separately applied to the extracted motifs' areas to form the feature space. To cope with the 'curse of dimensionality' and increase the 'discrimination power', feature space is enriched with spatial information achieved by applying a feature selection method. Indeed, the best feature subset, which maximizes the mutual information between the joint distribution of the selected features and the classification variable, is selected using the minimum Redundancy Maximum Relevance (mRMR) method to a trade-off between thousands of features and a few hundreds of samples. One fold of our contribution dedicates to decrease the over-fitting probability of the learning model by making the Sparse Representation-based Classifier kernelized. We evaluate our method on a dataset of 573 coin images. The experimental results show that our proposed image representation is more discriminative than the competitive ones in which the system achieves a mean classification rate of 96.51 %.
C1 [Parsa, Seyyedeh-Sahar; Dehshibi, Mohammad Mahdi] Islamic Azad Univ, Sci & Res Branch, Fac Engn, Dept Comp Engn, Tehran, Iran.
   [Sourizaei, Mohamad] Islamic Azad Univ, Zahedan Branch, Young Researchers & Elite Club, Zahedan, Iran.
   [Shateri, Reza Esmaeilzadeh] Islamic Azad Univ, Ahar Branch, Dept Mechatron, Ahar, Iran.
   [Parsaei, Mohammad Reza] Shiraz Univ Technol, Dept Comp Engn & Informat Technol, Shiraz, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University; Shiraz University of Technology
RP Parsa, SS (corresponding author), Islamic Azad Univ, Sci & Res Branch, Fac Engn, Dept Comp Engn, Tehran, Iran.
EM parsa@iranprc.org; sourizaei.m@gmail.com
RI Sourizaei, Mohammad/AAO-4014-2021; Dehshibi, Mohammad Mahdi/S-9946-2017
OI Dehshibi, Mohammad Mahdi/0000-0001-8112-5419; Parsaei, Mohammad
   Reza/0000-0002-1026-5489
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Allahverdi R., 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P278, DOI 10.1109/AISP.2012.6313758
   Allahverdi R., 2012, WCIT-2011, V1, P1151
   [Anonymous], 2003, P INT C DIG IM COMP
   [Anonymous], P MUSCL CIS COIN COM
   Anwar Hafeez, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P17, DOI 10.1007/978-3-642-40246-3_3
   Arandjelovic O, 2010, PROC CVPR IEEE, P1728, DOI 10.1109/CVPR.2010.5539841
   Bremananth R, 2005, INDICON 2005 Proceedings, P366
   Charvillat V, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/163064
   Davidsson P, 1997, 9 INT C IND ENG APPL, P403
   FUKUMI M, 1992, IEEE T NEURAL NETWOR, V3, P272, DOI 10.1109/72.125868
   Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635
   Huber R, 2005, PATTERN RECOGN LETT, V26, P61, DOI 10.1016/j.patrec.2004.09.006
   Huber-Mörk R, 2011, MACH VISION APPL, V22, P983, DOI 10.1007/s00138-010-0283-y
   Kampel M, 2008, LECT NOTES COMPUT SC, V5358, P11, DOI 10.1007/978-3-540-89639-5_2
   Khashman A, 2007, ADV SOFT COMP, V41, P290, DOI 10.1007/978-3-540-72432-2_29
   Kim J, 2014, INT C PATT RECOG, P321, DOI 10.1109/ICPR.2014.64
   Liu H, 2008, CH CRC DATA MIN KNOW, P3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mitsukura Y, 2000, IEEE IJCNN, P178, DOI 10.1109/IJCNN.2000.861454
   Moreno JM, 1997, LECT NOTES COMPUT SC, V1240, P922, DOI 10.1007/BFb0032552
   Oppenheim A. V., 1989, Discrete -Time Signal Processing
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   Parsa S.-S., 2015, Recent Advances in Information and Communication Technology, Advances in Intelligent Systems and Computing, V265, P75
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Reisert M., 2006, P MUSCL CIS COIN COM, P19
   VANDERMAATEN LJ, 2006, P MUSCL CIS COIN COM, P7
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   YEGNANARAYANA B, 1984, IEEE T ACOUST SPEECH, V32, P610, DOI 10.1109/TASSP.1984.1164365
   Zaharieva M, 2007, LECT NOTES COMPUT SC, V4673, P547
   Zambanini Sebastian, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P25, DOI 10.1007/978-3-642-37484-5_3
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
NR 34
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15535
EP 15560
DI 10.1007/s11042-016-3856-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900015
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Chu, TG
AF Zhang, Qi
   Chu, Tianguang
TI Learning in multimodal and mixmodal data: locality preserving
   discriminant analysis with kernel and sparse representation techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal and mixmodal data; Feature extraction; Kernel theory; Sparse
   representation
ID FACE RECOGNITION; PROJECTIONS
AB We consider the problem of feature extraction for "multimodal" and "mixmodal" data. A new supervised learning method called locality preserving discriminant analysis (LPDA) is presented, which aims to maximize the weighted between-class distances and minimize the locality-preserved within-class distances. By introducing a specific affinity matrix for each class, LPDA can better preserve the local geometric structure of the samples within it, and thus efficiently derive nonlinear characters of the data structure. Meanwhile, by using the defined between-class weight matrix, LPDA also preserves the interrelation information of data from different classes. This facilitates the separation of between-class data. We further extend LPDA to kernel-LPDA and sparse-LPDA by taking advantage of theories of kernel technique and sparse representation. Experiments for data classification, handwriting and face recognition are carried out to verify the feasibility and effectiveness of the proposed approaches.
C1 [Zhang, Qi; Chu, Tianguang] Peking Univ, Coll Engn, State Key Lab Turbulence & Complex Syst, Beijing 100871, Peoples R China.
C3 Peking University
RP Chu, TG (corresponding author), Peking Univ, Coll Engn, State Key Lab Turbulence & Complex Syst, Beijing 100871, Peoples R China.
EM zhang_qi@pku.edu.cn; chutg@pku.edu.cn
FU NSFC [61273111]; National Basic Research Program of China (973 Program)
   [2012CB821200]
FX This work was supported by NSFC (No. 61273111) and National Basic
   Research Program of China (973 Program, No. 2012CB821200).
CR [Anonymous], 2010, P 13 INT C ART INT S
   [Anonymous], ABSTR APPL AN
   [Anonymous], UNSUPERVISED PROCESS
   ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Chen Z., 2017, Multimedia Tools and Applications, V76, P17669, DOI [DOI 10.1155/2015/749748, DOI 10.1186/S12929-015-0197-0, DOI 10.1007/S11042-015-2882-0]
   Chung F. R. K., 1997, AM MATH SOC, V92, DOI DOI 10.1090/CBMS/092
   Cui JR, 2015, NEUROCOMPUTING, V149, P1451, DOI 10.1016/j.neucom.2014.08.047
   d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506
   Ding CT, 2015, PATTERN RECOGN, V48, P1734, DOI 10.1016/j.patcog.2014.08.025
   Franc V., 2004, Statistical Pattern Recognition Toolbox for Matlab
   Fu Y., 2005, LOCALLY LINEAR EMBED
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Golub G. H., 1965, SIAM J. Numer. Anal., V2, P205
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Lai Z, 2012, IET COMPUT VIS, V6, P551, DOI 10.1049/iet-cvi.2011.0196
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li Z, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0554-z
   [刘明 Liu Ming], 2015, [现代制造工程, Modern Manufacturing Engineering], P1
   Müller MK, 2013, NEURAL NETWORKS, V41, P137, DOI 10.1016/j.neunet.2012.07.006
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Raducanu B, 2014, PATTERN RECOGN, V47, P480, DOI 10.1016/j.patcog.2013.06.021
   SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467
   Scholkopf B., 2002, Encyclopedia of Biostatistics
   Shi CJA, 2015, IEEE T MULTIMEDIA, V17, P16, DOI 10.1109/TMM.2014.2375792
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Tseng P, 2009, MATH PROGRAM, V117, P387, DOI 10.1007/s10107-007-0170-0
   Wang Y, 2010, PATTERN RECOGN, V43, P1008, DOI 10.1016/j.patcog.2009.08.009
   Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wong WK, 2012, PATTERN RECOGN, V45, P186, DOI 10.1016/j.patcog.2011.05.014
   Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769
   Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412
   Yu J, 2016, MULTIMED TOOLS APPL, P1
   Zhang LM, 2010, PATTERN RECOGN, V43, P1993, DOI 10.1016/j.patcog.2009.12.022
   Zhang Tong, 2008, Proc. Adv. Neural Inf. Process. Syst, P1929
   Zheng WM, 2005, NEUROCOMPUTING, V67, P357, DOI 10.1016/j.neucom.2004.12.008
NR 46
TC 7
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15465
EP 15489
DI 10.1007/s11042-016-3848-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900012
DA 2024-07-18
ER

PT J
AU Cao, WQ
   Guan, QX
   Zhao, XF
   Wang, KR
   Han, JS
AF Cao, Weiquan
   Guan, Qingxiao
   Zhao, Xianfeng
   Wang, Keren
   Han, Jiesi
TI Constructing local information feature for spatial image steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial image steganalysis; Local feature; Image steganography; Spatial
   rich model
AB Feature is a key part for steganalysis. In this paper we propose a spatial feature set for image steganalysis, named Local Information Feature (LIF), to increase the diversity of spatial steganalysis feature and improve its performance. It also provide a heuristic framework for designing steganalysis feature through 3 steps. It first collects local information from its local region consisting of adjacent pixels. Then according to certain rules, it maps each pixel to its corresponding local type by its local information. Finally, the feature set is formed by adaptive weighted statistical histograms of local types. We design two schemes for LIF, each of which can generate different feature sets using different methods of local information computing. Experimental results show that our feature is effective for detecting stego images embedded by adaptive steganography. We also discussed some possible method to extent the feature designing based on LIF.
C1 [Cao, Weiquan; Wang, Keren; Han, Jiesi] Natl Key Lab Sci & Technol Blind Signal Proc, Chengdu 610041, Peoples R China.
   [Cao, Weiquan; Guan, Qingxiao; Zhao, Xianfeng] Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing 100093, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS
RP Guan, QX (corresponding author), Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing 100093, Peoples R China.
EM caoweiquan322@126.com; guanqingxiao@iie.ac.cn; zhaoxianfeng@iie.ac.cn;
   cfan662003@163.com; jacksonhanrabbit@163.com
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399
FU NSFC [U1536105, 61303259]; Strategic Priority Research Program of
   Chinese Academy of Sciences (CAS) [XDA06030600]; Key Project of
   Institute of Information Engineering, CAS [Y5Z0131201]
FX This work was supported by the NSFC under U1536105 and 61303259, the
   Strategic Priority Research Program of Chinese Academy of Sciences (CAS)
   under XDA06030600, and the Key Project of Institute of Information
   Engineering, CAS, under Y5Z0131201.
CR Filler T, 2011, P SOC PHOTO-OPT INS, V7880
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hulob V, 2014, 2014 IEEE INT WORKSH
   Ker AD, 2008, P SOC PHOTO-OPT INS, V6819, P681
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Shi Yun Q., 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P63, DOI 10.1007/978-3-642-36373-3_5
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Zou D, 2010, 2006 IEEE INT C MULT, P1365
NR 14
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13221
EP 13237
DI 10.1007/s11042-016-3751-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900013
DA 2024-07-18
ER

PT J
AU Kong, TL
   Isa, NAM
AF Kong, Teck Long
   Isa, Nor Ashidi Mat
TI Enhancer-based contrast enhancement technique for non-uniform
   illumination and low-contrast images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-uniform illumination; Image enhancement; Contrast; Histogram;
   Entropy
ID BI-HISTOGRAM EQUALIZATION; MULTISCALE RETINEX; FUZZY-LOGIC; ALGORITHM
AB Digital imaging is widely applied in medical, surveillance, machine vision, and other fields. Occasionally, limited light sources during image acquisition process cause non-uniform illumination and low contrast images. Non-uniform illumination and low-contrast image are challenges faced by researchers during the image processing stage. In this paper, a new algorithm called Enhancer-based Contrast Enhancement (EBCE) is proposed to enhance non-uniform illumination and low-contrast image to produce uniform illumination and improve the contrast of images. The proposed method initially derives two enhancers, namely, bright enhancer and dark enhancer from a blurred input image. The bright and dark enhancers respectively enhance the bright and dark regions of the given input image. To enhance the contrast of the image, limited histogram equalization is applied to both regions. Finally, an enhancement ratio is proposed to control the enhancement level of the images. Compared with state-of-the-art methods, the proposed EBCE method successfully produces better images. Visually, the EBCE method produces the best images with more uniform illumination and better contrast. The method produces the best EME, entropy, and NIQE values when applied to 450 test images.
C1 [Kong, Teck Long; Isa, Nor Ashidi Mat] Univ Sains Malaysia, Sch Elect & Elect Engn, Imaging & Intelligent Syst Res Team ISRT, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
C3 Universiti Sains Malaysia
RP Isa, NAM (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Imaging & Intelligent Syst Res Team ISRT, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM konglyng@gmail.com; ashidi@usm.my
RI Mat Isa, Nor Ashidi/I-7826-2017
OI Mat Isa, Nor Ashidi/0000-0002-2675-4914
FU Ministry of Higher Education (MOHE), Malaysia
FX This project is supported by the Fundamental Research Grant Scheme
   (FRGS), of the Ministry of Higher Education (MOHE), Malaysia under the
   theme "Formulation of a robust framework of image enhancement for
   non-uniform illumination and low-contrast images."
CR Agaian S.S., 2000, IASTED INT C SIGNAL, P19
   Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   [Anonymous], COMPUT J
   [Anonymous], TECHN INN C 2009 ITI
   [Anonymous], OASCE INT C COMP CIV
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Chang YC, 2010, IEEE T CONSUM ELECTR, V56, P737, DOI 10.1109/TCE.2010.5505995
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Cheng HD, 2000, PATTERN RECOGN, V33, P809, DOI 10.1016/S0031-3203(99)00096-5
   Hasikin K, 2014, SIGNAL IMAGE VIDEO P, V8, P1591, DOI 10.1007/s11760-012-0398-x
   Jadiya S, 2013, 2013 4TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT), P54, DOI 10.1109/ICCCT.2013.6749603
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kim T, 2008, IEEE T CONSUM ELECTR, V54, P1803, DOI 10.1109/TCE.2008.4711238
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee H, 2009, OPT EXPRESS, V17, P23880, DOI 10.1364/OE.17.023880
   Leung CC, 2005, PATTERN RECOGN LETT, V26, P769, DOI 10.1016/j.patrec.2004.09.032
   Liang K, 2012, INFRARED PHYS TECHN, V55, P309, DOI 10.1016/j.infrared.2012.03.004
   Lin HN, 2014, OPTIK, V125, P7143, DOI 10.1016/j.ijleo.2014.07.118
   Magudeeswaran V, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/891864
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nafornita C, 2014, 2014 11TH INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND TELECOMMUNICATIONS (ISETC), DOI 10.1109/ISETC.2014.7010797
   Pratt W., 2007, DIGITAL IMAGE PROCES, V4th
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Raju G, 2014, AEU-INT J ELECTRON C, V68, P237, DOI 10.1016/j.aeue.2013.08.015
   Rubin SH, 2006, IRI 2006: PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P602
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Tang JR, 2014, COMPUT ELECTR ENG, V40, P86, DOI 10.1016/j.compeleceng.2014.05.017
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Weber M., 1999, COMPUTATIONAL VISION
   Wharton E, 2007, INT CONF ACOUST SPEE, P729
NR 34
TC 11
Z9 14
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14305
EP 14326
DI 10.1007/s11042-016-3787-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800028
DA 2024-07-18
ER

PT J
AU Krulis, M
   Osipyan, H
   Marchand-Maillet, S
AF Krulis, Martin
   Osipyan, Hasmik
   Marchand-Maillet, Stephane
TI Employing GPU architectures for permutation-based indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GPU; Parallel; Permutation-based indexing; Approximate similarity
   search; Bitonic sorting
AB Permutation-based indexing is one of the most popular techniques for the approximate nearest-neighbor search problem in high-dimensional spaces. Due to the exponential increase of multimedia data, the time required to index this data has become a serious constraint. One of the possible steps towards faster index construction is utilization of massively parallel platforms such as the GPGPU architectures. In this paper, we have analyzed the computational costs of individual steps of the permutation-based index construction in a high-dimensional feature space and summarized our hybrid CPU-GPU solution. Our experience gained from this research may be utilized in other individual problems that require computing L (p) distances in high-dimensional spaces, parallel top-k selection, or partial sorting of multiple smaller sets. We also provide guidelines how to balance workload in hybrid CPU-GPU systems.
C1 [Krulis, Martin] Charles Univ Prague, Prague, Czech Republic.
   [Osipyan, Hasmik] Natl Polytech Univ Armenia, Yerevan, Armenia.
   [Marchand-Maillet, Stephane] Univ Geneva, Dept Comp Sci, Geneva, Switzerland.
C3 Charles University Prague; National Polytechnic University of Armenia;
   University of Geneva
RP Krulis, M (corresponding author), Charles Univ Prague, Prague, Czech Republic.
EM krulis@ksi.mff.cuni.cz; hasmik.osipyan.external@worldline.com;
   stephane.marchand-maillet@unige.ch
RI Krulis, Martin/D-6454-2017
OI Krulis, Martin/0000-0002-0985-8949
FU Czech Science Foundation (GACR) project [P103-1414292P]; Swiss National
   Foundation (SNF) under interdisciplinary project MAAYA [144238]
FX This paper was supported by Czech Science Foundation (GACR) project no.
   P103-1414292P and partly by the Swiss National Foundation (SNF) under
   interdisciplinary project MAAYA (grant number 144238).
CR Alabi T., 2012, J EXPT ALGORITHMICS, V17, P4
   Amato G, 2012, MI FILE USING INVERT
   [Anonymous], 2008, 3 INT ICST C SCAL IN
   [Anonymous], 2008, P IASTED INT S COMPU
   [Anonymous], 2005, The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling
   Batcher K. E., 1968, P AFIPS SPRING JOINT, P307, DOI [DOI 10.1145/1468075.1468121, 10.1145/1468075. 1468121]
   Chavez E, 2008, IEEE T PATTERN ANAL, V30, P1647, DOI 10.1109/TPAMI.2007.70815
   Ciaccia P., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P244, DOI 10.1109/ICDE.2000.839417
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Esuli A, 2009, P LSDS IR
   Esuli A, 2009, SISAP 2009: 2009 SECOND INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P146, DOI 10.1109/SISAP.2009.14
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jagadish H. V., 1995, Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1995, P36, DOI 10.1145/212433.212444
   Jan B, 2012, FAST PARALLEL SORTIN, V3
   Knuth DE, 2003, SORTING SEARCHING
   Krulis M, 2015, OPT SORT TOP K SEL S, P305
   Krulis M, 2012, ITAT, P17
   Krulis M, 2015, PERM BAS IND HIGH DI, P1
   Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P614, DOI 10.1145/276698.276877
   Lopresti M, 2013, COMPUT SIST, V17, P341
   Mohamed Hisham, 2012, Similarity Search and Applications. Proceedings of the 5th International Conference, SISAP 2012, P148, DOI 10.1007/978-3-642-32153-5_11
   Mohamed H, 2013, LECT NOTES COMPUT SC, V8199, P103, DOI 10.1007/978-3-642-41062-8_11
   Mohammed H, 2014, MULT CPU GPU PERM BA, P277
   Monroe Laura., 2011, Proceedings of the ACM SIGGRAPH Symposium on High Performance Graphics, P89, DOI DOI 10.1145/2018323.2018338
   Novak David., 2010, Proceedings of the Third International Conference on SImilarity Search and APplications, SISAP'10, P59
   Patella M, 2009, J DISCRET ALGORITHMS, V7, P36, DOI 10.1016/j.jda.2008.09.014
   Peters H, 2010, LECT NOTES COMPUT SC, V6067, P403
   Pheatt Chuck, 2008, Journal of Computing Sciences in Colleges, V23, P298
   Qi Li, 2010, 2010 Ninth International Conference on Machine Learning and Applications (ICMLA 2010), P208, DOI 10.1109/ICMLA.2010.38
   Sanders J, 2010, CUDA EXAMPLE INTRO G
   Satish N, 2009, INT PARALL DISTRIB P, P257
   Téllez ES, 2009, LECT NOTES COMPUT SC, V5856, P529, DOI 10.1007/978-3-642-10268-4_62
   Ye Xiaochun., 2010, P IEEE INT PARALLEL, P1, DOI DOI 10.1145/1872007.1872037
NR 33
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11859
EP 11887
DI 10.1007/s11042-016-3677-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000040
DA 2024-07-18
ER

PT J
AU Zhai, YJ
   Wang, D
   Zhang, ML
   Wang, JR
   Guo, F
AF Zhai, Yongjie
   Wang, Di
   Zhang, Muliu
   Wang, Jiarong
   Guo, Feng
TI Fault detection of insulator based on saliency and adaptive morphology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glass insulator; Fault detection; Saliency; Adaptive morphological
ID INSPECTION; IMAGE
AB We study the problem of glass insulator fault detection from image in this work. It is a challenging task as no reliable electromagnetism cues are available. Since the characteristics of insulator fault are not clear and the positions of the insulator fault are uncertain. Previous efforts have been focusing on insulator classification and the insulator location. Recently, there is mounting evidence that saliency detection are setting new records for various vision applications. On the other hand, considering the particularly structure of insulator, fault detection can be naturally enhanced by morphology problem. Therefore, we in this paper present a saliency and adaptive morphological based insulator fault detection algorithm, aiming to jointly explore the capacity of saliency and morphology. Specifically, we propose an adaptive learning scheme which learns the saliency and morphology in a unified adaptive framework. According to the experiment, we can process most of the circumstances with 92 % accuracy in 0.5 second on average, which suits the Unmanned Aerial Vehicle (UAV) patrol device well.
C1 [Zhai, Yongjie; Wang, Di; Zhang, Muliu; Wang, Jiarong] North China Elect Power Univ, Automat Dept, Baoding 071003, Peoples R China.
   [Guo, Feng] Xiamen Univ, Sch Informat Sci & Engn, Dept Cognit Sci, Xiamen 361005, Peoples R China.
C3 North China Electric Power University; Xiamen University
RP Guo, F (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Dept Cognit Sci, Xiamen 361005, Peoples R China.
EM betop@xmu.edu.cn
RI GUO, FENG/JRX-3555-2023
FU Fundamental Research Funds of China for the Central Universities
   [2014MS140]; Natural Science Foundation of Fujian Province of China
   [2014J01249]; Xiamen City Science and Technology Project [3502Z20153003]
FX This work was supported in part by the Fundamental Research Funds of
   China for the Central Universities under Grant(No. 2014MS140), the
   Natural Science Foundation of Fujian Province of China(No. 2014J01249),
   the Xiamen City Science and Technology Project(No. 3502Z20153003).
CR [Anonymous], 2010 2 INT C MECH EL
   [Anonymous], 2010 2 WRI GLOB C IN
   Chuang D., 2014, J COMMUN, V9, P687, DOI [DOI 10.12720/JCM.9.9.687-692, 10.12720/jcm.9.9.687-6, 10.12720/jcm.9.9.687-692]
   Fang Ting, 2013, Journal of Shanghai Jiaotong University, V47, P1818
   Fletcher SDA, 2011, IET ELECTR SYST TRAN, V1, P137, DOI 10.1049/iet-est.2010.0070
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Han S, 2009, IEEE T POWER DELIVER, V24, P2319, DOI 10.1109/TPWRD.2009.2028534
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   He SY, 2015, IEEE ANN INT CONF CY, P431, DOI 10.1109/CYBER.2015.7287976
   Hyunho L., 2013, 44 INT S ROB SEOUL, P1, DOI DOI 10.1109/ISR.2013.6695677
   Liao SL, 2015, IEEE GEOSCI REMOTE S, V12, P963, DOI 10.1109/LGRS.2014.2369525
   Lin Jucai, 2011, Power System Technology, V35, P127
   Lin Y, 2016, NEUROCOMPUTING
   Luque-Vega LF, 2014, IEEE MEDITERR ELECT, P393, DOI 10.1109/MELCON.2014.6820566
   Oberweger M., 2014, Comput. Vis. Winter Work
   Pagnano A, 2013, PROC CIRP, V12, P234, DOI 10.1016/j.procir.2013.09.041
   Reddy MJB, 2011, IEEE T DIELECT EL IN, V18, P588, DOI 10.1109/TDEI.2011.5739465
   Sun Fengjie, 2014, Proceedings of the CSEE, V34, P206
   Tong Weiguo, 2010, Power System Technology, V34, P204
   Wang Yin-li, 2014, Computer Engineering and Design, V35, P583
   Wolfe Jeremy M, 2010, Curr Biol, V20, pR346, DOI 10.1016/j.cub.2010.02.016
   Wu QG, 2012, IEEE J-STARS, V5, P1509, DOI 10.1109/JSTARS.2012.2197672
   Yao Chun-yu, 2012, Journal of System Simulation, V24, P1818
   [张晶晶 Zhang Jingjing], 2014, [中国图象图形学报, Journal of Image and Graphics], V19, P1194
   Zhao ZB, 2016, RECENT ADV ELECTR EL, V9, P53, DOI 10.2174/2352096508666150826202726
NR 25
TC 66
Z9 73
U1 8
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12051
EP 12064
DI 10.1007/s11042-016-3981-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000050
DA 2024-07-18
ER

PT J
AU Deng, J
   Zhao, S
   Wang, Y
   Wang, L
   Wang, H
   Sha, H
AF Deng, Juan
   Zhao, Shu
   Wang, Yan
   Wang, Lei
   Wang, Hong
   Sha, Hong
TI Image compression-encryption scheme combining 2D compressive sensing
   with discrete fractional random transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Discrete fractional random transform; Logistic
   chaos map; NSL0 algorithm; Image encryption
ID PLAINTEXT ATTACK; MELLIN TRANSFORM; ALGORITHM; INTERFERENCE; CHAOS;
   OPERATION; DOMAIN
AB Most of the existing image encryption algorithms based on compressive sensing are too complex to operate. An image compression-encryption scheme with simple operation is presented based on 2D compressive sensing and discrete fractional random transform (DFrRT). To accomplish compression and encryption simultaneously, the original image is expressed in a 2D discrete cosine domain and measured by the measurement matrices in two orthogonal directions during the encryption process, where the matrices are constructed with Logistic chaos map to control the row vectors of Hadamard matrix. Then the intermediate resulting image is re-encrypted by taking discrete fractional random transform. Decryption process includes the inverse operation of the DFrRT and the reconstruction process with the Newton Smoothed l (0) Norm (NSL0) algorithm in sequence. Simulation results verify the security and the effectiveness of this scheme by taking advantages of both compressive sensing and DFrRT.
C1 [Deng, Juan; Zhao, Shu; Wang, Yan; Wang, Lei; Wang, Hong; Sha, Hong] Chinese Acad Med Sci, Inst Biomed Engn, Tianjin 300192, Peoples R China.
   [Deng, Juan; Zhao, Shu; Wang, Yan; Wang, Lei; Wang, Hong; Sha, Hong] Peking Union Med Coll, Tianjin 300192, Peoples R China.
C3 Chinese Academy of Medical Sciences - Peking Union Medical College;
   Institute of BioMedical Engineering - CAMS; Chinese Academy of Medical
   Sciences - Peking Union Medical College; Peking Union Medical College
RP Deng, J; Sha, H (corresponding author), Chinese Acad Med Sci, Inst Biomed Engn, Tianjin 300192, Peoples R China.; Deng, J; Sha, H (corresponding author), Peking Union Med Coll, Tianjin 300192, Peoples R China.
EM camsdeng@163.com; hong_sha@yeah.com
RI Wang, Peiyun/JVE-1196-2024; zhou, bolin/KHX-0072-2024; Wang,
   Hong/HIK-3347-2022
OI Wang, Hong/0000-0002-1300-9595
FU National Natural Science Foundation of China [81301200, 81301288];
   Fundamental Research Funds for the Central Universities and the PUMC
   Youth Fund [3332016102]; Natural Science Foundation of Jiangxi Province
   [20142BAB207004]; Youth Fund of Peking Union Medical College
   [3332014052]
FX This work was supported by the National Natural Science Foundation of
   China (81301200), the Fundamental Research Funds for the Central
   Universities and the PUMC Youth Fund (3332016102) and the Natural
   Science Foundation of Jiangxi Province (20142BAB207004). This work was
   supported by the National Natural Science Foundation of China
   (81301288), the Youth Fund of Peking Union Medical College (3332014052)
   and the Natural Science Foundation of Jiangxi Province (20142BAB207004).
CR [Anonymous], NEW IND
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Chen LF, 2015, OPT LASER TECHNOL, V69, P80, DOI 10.1016/j.optlastec.2014.12.007
   Chen W, 2012, APPL OPTICS, V51, P6076, DOI 10.1364/AO.51.006076
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Endra, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS (CYBERNETICSCOM), P122, DOI 10.1109/CyberneticsCom.2013.6865794
   Gong LH, 2013, J MOD OPTIC, V60, P1074, DOI 10.1080/09500340.2013.831139
   He WQ, 2012, OPT LASER TECHNOL, V44, P1203, DOI 10.1016/j.optlastec.2012.01.021
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Lang J, 2015, OPTIK, V126, P3644, DOI 10.1016/j.ijleo.2015.08.262
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li J, 2015, OPT COMMUN, V344, P166, DOI 10.1016/j.optcom.2015.01.048
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Liu XB, 2014, J MOD OPTIC, V61, P1570, DOI 10.1080/09500340.2014.946565
   Liu YF, 2015, J NANOMATER, V2015, DOI 10.1155/2015/792095
   Liu YJ, 2015, J CHEM-NY, V2015, DOI 10.1155/2015/580950
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   Liu ZJ, 2005, OPT COMMUN, V255, P357, DOI 10.1016/j.optcom.2005.06.031
   Lu DJ, 2015, OPT COMMUN, V336, P77, DOI 10.1016/j.optcom.2014.09.057
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Pan XM, 2015, APPL OPTICS, V54, P8485, DOI 10.1364/AO.54.008485
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Peng X, 2006, OPT LETT, V31, P3261, DOI 10.1364/OL.31.003261
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Rong Huang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P105, DOI 10.1109/IIHMSP.2011.53
   Sreedhanya AV, 2012, 2012 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC), P207, DOI 10.1109/ICACC.2012.48
   Stern A, 2013, SPIE OPT ENG APPL IN
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Sun JC, 2013, PROC SPIE, V9046, DOI 10.1117/12.2037012
   Wang XG, 2012, OPT EXPRESS, V20, P11994, DOI 10.1364/OE.20.011994
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Yong-Liang XA, 2010, OPT COMMUN, V283, P2789, DOI 10.1016/j.optcom.2010.03.003
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 40
TC 44
Z9 45
U1 2
U2 92
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10097
EP 10117
DI 10.1007/s11042-016-3600-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300045
DA 2024-07-18
ER

PT J
AU Liu, L
   Cheng, DS
   Tian, F
   Shi, DM
   Wu, R
AF Liu, Lin
   Cheng, Dansong
   Tian, Feng
   Shi, Daming
   Wu, Rui
TI Active contour driven by multi-scale local binary fitting and
   Kullback-Leibler divergence for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active contour model; Energy function; Image segmentation;
   Kullback-Leibler divergence; Multi-scale local binary fitting
ID LEVEL SET EVOLUTION; MUMFORD
AB Image segmentation is an important processing in many applications such as image retrieval and computer vision. One of the most successful models for image segmentation is the level set methods which are based on local context. The methods, though comparatively effective in segmenting images with inhomogeneous intensity, are considerably computation-intensive and at the risk of falling into local minima in the convergence of the active contour energy function. To address the issues, we propose a region-based level set method, called KL-MLBF, which is based on the multi-scale local binary fitting (MLBF) and the Kullback-Leibler (KL) divergence. We first apply the multi-scale theory to the local binary fitting model to build MLBF. Then the energy term measured by KL divergence between regions to be segmented is incorporated into the energy function of MLBF. KL-MLBF utilizes the between-cluster distance and the adaptive kernel function selection strategy to formulate the energy function. Being more robust to the initial location of the contour than the classical segmentation models, KL-MLBF can deal with blurry boundaries and noise problems. The results of experiments on synthetic and real images have shown that KL-MLBF can improve the effectiveness of segmentation while ensuring the accuracy by accelerating the minimization of the energy function.
C1 [Liu, Lin; Cheng, Dansong; Shi, Daming; Wu, Rui] Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Peoples R China.
   [Liu, Lin] Harbin Univ, Sch Engn, Harbin, Peoples R China.
   [Tian, Feng] Bournemouth Univ, Fac Sci & Technol, Bournemouth, Dorset, England.
C3 Harbin Institute of Technology; Harbin University; Bournemouth
   University
RP Cheng, DS (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Peoples R China.
EM cdsinhit@hit.edu.cn
RI Cheng, Dan/ITT-7298-2023
OI Rui, Wu/0000-0003-0941-2688
FU National Natural Science Foundation of China [61440025, 61402133];
   National Postdoctoral Science Foundation [20100480998]
FX This research was supported by the National Natural Science Foundation
   of China (Grant No. 61440025, 61402133) and the National Postdoctoral
   Science Foundation(Grant No. 20100480998)
CR Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Cheng D, 2007, CHINESE HIGH TECHNOL, V12, P24
   Cheng Dan-song, 2007, Journal of the Harbin Institute of Technology, V39, P435
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Islam M.J., 2011, IEEE International Conference on Electro/Information Technology (EIT), P1
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Leung T., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P544, DOI 10.1007/BFb0055689
   Li CH, 2007, BMC EVOL BIOL, V7, DOI 10.1186/1471-2148-7-44
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2005, PROC CVPR IEEE, P430
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mansouri AR, 2003, IEEE T IMAGE PROCESS, V12, P201, DOI 10.1109/TIP.2002.807582
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Monteiro FC, 2008, INT C PATT RECOG, P1586
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Musarrat Y., 2013, WORLD APPL SCI J, V22, P85
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   REDDI SS, 1984, IEEE T SYST MAN CYB, V14, P661, DOI 10.1109/TSMC.1984.6313341
   Sofou A, 2008, IEEE T IMAGE PROCESS, V17, P364, DOI 10.1109/TIP.2007.916156
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Varshney S.S., 2009, International Conference on Methods and Models in Computer Science, P1
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang LF, 2014, PATTERN RECOGN, V47, P1917, DOI 10.1016/j.patcog.2013.11.014
   Wang LF, 2011, LECT NOTES COMPUT SC, V6493, P148
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
NR 37
TC 16
Z9 16
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10149
EP 10168
DI 10.1007/s11042-016-3603-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300048
DA 2024-07-18
ER

PT J
AU Hamdi, M
   Rhouma, R
   Belghith, S
AF Hamdi, Mimoun
   Rhouma, Rhouma
   Belghith, Safya
TI An appropriate system for securing real-time voice communication based
   on ADPCM coding and chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Audio and speech signals; Encryption scheme; Statistical
   tests
ID CRYPTOGRAPHY; ALGORITHM
AB This paper presents a very simple and efficient encryption scheme based on controlled chaotic maps and ADPCM (Adaptive Differential Pulse Code Modulation) coding, in order to secure the real-time voice communication for operating at 16, 24, 32 or 40 kbps. This encryption algorithm adopts three main operations one to generate chaotic values using two chaotic logistic maps starting from independent initial conditions, the second to transform them into binary words using random encoding tables and the third to execute some basic operations and substitutions. It has important properties of randomness that can pass NIST batteries of tests. The evaluation and simulation analysis indicate that our proposal possesses an excellent statistical and cryptographic properties; it provides low correlation between adjacent samples in encryption speech, extremely sensitive encryption keys and has a large key space which is sufficient to protect against brute-force attack. As an illustrative example, an application on a commonly-encoder type used in communications, standard ITU-T G. 726, is presented.
C1 [Hamdi, Mimoun; Rhouma, Rhouma; Belghith, Safya] Ecole Natl Ingn Tunis, BP 37, Belvedere 1002, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Hamdi, M (corresponding author), Ecole Natl Ingn Tunis, BP 37, Belvedere 1002, Tunisia.
EM my.hamdi@gmail.com
RI Hamdi, Mimoun/AAV-4747-2021; Rhouma, Rhouma/B-8018-2010
OI Hamdi, Mimoun/0000-0003-2390-0151; Rhouma, Rhouma/0000-0002-5715-4110;
   Belghith, Safya/0000-0001-7408-7848
CR Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Alanazi H., 2010, J COMPUTING, V2, P152
   Alligood K. A., 1996, Chaos: An Introduction to Dynamical Systems
   Anees A, 2014, COMMUN NONLINEAR SCI, V19, P3106, DOI 10.1016/j.cnsns.2014.02.011
   [Anonymous], 1990, AD DIFF PULS COD MOD
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Barenghi A, 2013, J SYST SOFTWARE, V86, P1864, DOI 10.1016/j.jss.2013.02.021
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Boriga R, 2014, ADV MULTIMEDIA, V2014, P15
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cheng CJ, 2013, COMMUN NONLINEAR SCI, V18, P2825, DOI 10.1016/j.cnsns.2013.02.011
   Francois M, 2013, INFORMATICA-LITHUAN, V24, P181
   Hamdi M., 2015, Int J Comput Electr Autom Control Inf Eng, V9, P481
   Hamdi M, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P7, DOI 10.1109/ATSIP.2014.6834580
   Hermassi H, 2015, MULTIMED TOOLS APPL, V74, P1
   Huang D, 2000, IEEE INT C MULT EXP, V3, P1775
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Ji XY, 2015, COMMUN NONLINEAR SCI, V22, P321, DOI 10.1016/j.cnsns.2014.09.011
   Jolfaei A., 2011, COMPUT INFORM SCI, V4, P172
   Kazmi S, 2013, MULTIMED TOOLS APPL, V66, P267, DOI 10.1007/s11042-011-0767-4
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Lasota A., 1994, Chaos, Fractals, and Noise; Stochastic Aspects of Dynamics
   Ling C, 2008, CIRC SYST SIGNAL PR, V27, P883, DOI 10.1007/s00034-008-9065-4
   Mao Y, 2014, WORLD SCI J BIFURCAT, V14, P3613
   Masmoudi A., 2010, J SOFTWARE ENG APPL, V3, P1141, DOI 10.4236/jsea.2010.312133
   Özkaynak F, 2013, COMPUT PHYS COMMUN, V184, P2178, DOI 10.1016/j.cpc.2013.04.014
   Piret G, 2003, LECT NOTES COMPUT SC, V2779, P77, DOI 10.1007/978-3-540-45238-6_7
   Purwar RK, 2013, INT J LATEST TRENDS, V2
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shlomo Y, 2003, METRON INT J STAT, VLXI, P285
   Wang XY, 2012, NONLINEAR DYNAM, V70, P1589, DOI 10.1007/s11071-012-0558-0
NR 31
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7105
EP 7128
DI 10.1007/s11042-016-3377-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400044
DA 2024-07-18
ER

PT J
AU Kumar, S
   Sharma, RK
AF Kumar, Sachin
   Sharma, Rajendra K.
TI Securing color images using Two-square cipher associated with Arnold map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Image decryption; Arnold map; Two-square cipher
ID GYRATOR TRANSFORM; ENCRYPTION SCHEME
AB This paper presents an image encryption scheme using modified Two-square cipher associated with Arnold map. The traditional Two-square cipher is modified to make it more secure and applicable on the image data. A new block-based scheme is considered for Arnold map to handle the images of any size. The proposed scheme is structured into a substitution-permutation framework such that it has an excessively huge key space, and the correct decoding is highly sensitive to the correct keys with their correct order. The experimental results are given to validate the feasibility and robustness of the proposed scheme. Further, the superiority of the proposed scheme is analyzed by comparing with the related work.
C1 [Kumar, Sachin; Sharma, Rajendra K.] Indian Inst Technol Delhi, Dept Math, Hauz Khas, New Delhi 110016, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Kumar, S (corresponding author), Indian Inst Technol Delhi, Dept Math, Hauz Khas, New Delhi 110016, India.
EM skiitd09@gmail.com; rksharma@maths.iitd.ac.in
RI Sharma, Rajendra/C-1234-2018
OI Sharma, Rajendra/0000-0001-5666-4103
CR [Anonymous], 2009, HINDAWI PUBL CORP MA
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Guo Q, 2010, OPT LASER ENG, V48, P1174, DOI 10.1016/j.optlaseng.2010.07.005
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li HJ, 2009, OPT LASER ENG, V47, P45, DOI 10.1016/j.optlaseng.2008.08.001
   Li L, 2012, SIGNAL PROCESS, V92, P1069, DOI 10.1016/j.sigpro.2011.10.020
   Li M, 2013, ADV INTEL SYS RES, V84, P1309
   Liu Z, 2010, J OPT, V12
   Liu Z, 2011, J ELECTRON IMAGING, V20
   Liu ZJ, 2012, OPT LASER ENG, V50, P248, DOI 10.1016/j.optlaseng.2011.08.006
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Pandurangan HT, 2014, INT J WAVELETS MULTI, V12
   Scharinger J, 1998, J ELECTRON IMAGING, V7, P318, DOI 10.1117/1.482647
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Taneja N, 2012, MULTIMED TOOLS APPL, V61, P281, DOI 10.1007/s11042-011-0837-7
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Zhang Y, 2002, OPT COMMUN, V202, P277, DOI 10.1016/S0030-4018(02)01113-6
   Zheng YF, 2015, MULTIMED TOOLS APPL, V74, P7803, DOI 10.1007/s11042-014-2024-0
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
NR 26
TC 10
Z9 10
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8757
EP 8779
DI 10.1007/s11042-016-3504-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800050
DA 2024-07-18
ER

PT J
AU Li, XN
   Chen, MS
   Qu, ZW
   Xiao, JM
   Gabbouj, M
AF Li, Xiaoni
   Chen, Mianshu
   Qu, Zhaowei
   Xiao, Jimin
   Gabbouj, Moncef
TI An effective CU size decision method for quality scalability in SHVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SHVC; CU depth level; Inter layer correlation; Spatio-temporal
   correlation; CU size decision
ID PARALLEL FRAMEWORK; MOTION ESTIMATION; MODE DECISION; HEVC; EFFICIENCY;
   SELECTION
AB The Scalable extension of the High Efficiency Video Coding (known as SHVC) combines the high compression efficiency with the possibility of encoding different resolutions of the same encoded video in a single bitstream. However, this is accompanied with a high computational complexity. In this paper, we propose an effective coding unit (CU) size decision method by restricting the CU depth range to reduce the encoding time for quality scalability in SHVC. Since the optimal depth level in the enhancement layer (EL) is highly correlated to that in the base layer (BL), we can determine the CU depth range in the EL according to the depth of the co-located CU in the BL. Based on the high correlation between the current CU and its spatio-temporal neighboring CUs, the proposed method skips some specific depth levels which are rarely used in the previous frame and neighboring CUs to further reduce the computational complexity. Experimental results demonstrate that the proposed method can efficiently reduce computational complexity while maintaining similar rate distortion (RD) performance as the original SHVC encoder.
C1 [Li, Xiaoni; Chen, Mianshu] Jilin Univ, Coll Commun Engn, Changchun, Peoples R China.
   [Qu, Zhaowei] Jilin Univ, Coll Traff, Changchun, Peoples R China.
   [Xiao, Jimin] Xian Jiaotong Liverpool Univ, Dept Elect & Elect Engn, Suzhou, Peoples R China.
   [Gabbouj, Moncef] Tampere Univ Technol, Dept Signal Proc, Tampere, Finland.
C3 Jilin University; Jilin University; Xi'an Jiaotong-Liverpool University;
   Tampere University
RP Li, XN (corresponding author), Jilin Univ, Coll Commun Engn, Changchun, Peoples R China.
EM lxn@jlu.edu.cn
RI Gabbouj, Moncef/G-4293-2014
OI Gabbouj, Moncef/0000-0002-9788-2323
FU Project of International Cooperation and Exchange Foundation of Jilin
   Province, China [20140414013GH, 20130413053GH]; Project of Youth Science
   Foundation of Jilin Province [20130522164JH]; Jilin Key Science and
   Technology Project [20130206093SF]; National Natural Science Foundation
   of China [61501379, 61210006]; Jiangsu Science and Technology Programme
   [BK20150375]
FX This work is supported by Project of International Cooperation and
   Exchange Foundation of Jilin Province, China (Grant No.20140414013GH,
   20130413053GH), Project of Youth Science Foundation of Jilin Province
   (Grant No. 20130522164JH), Jilin Key Science and Technology Project (No.
   20130206093SF), National Natural Science Foundation of China (No.
   61501379, No. 61210006), Jiangsu Science and Technology Programme
   (BK20150375).
CR [Anonymous], 2001, ITU T VCEG M
   [Anonymous], 2013, JTC1SC29WG11 ISOIEC
   [Anonymous], 2013, 16WP3 ITUT SG
   Bailleul R, 2014, I SYMP CONSUM ELECTR, P195
   Boyce J, 2014, JCTVCS1008 ITUTISOIE
   Choi K, 2011, JCTVCF092 ITUTISOIEC
   Ge QY, 2014, PROCEEDINGS OF 2014 IEEE WORKSHOP ON ADVANCED RESEARCH AND TECHNOLOGY IN INDUSTRY APPLICATIONS (WARTIA), P1366, DOI 10.1109/WARTIA.2014.6976537
   Gweon RH, 2011, JCTVCF045 ITUTISOIEC
   Hannuksela MM, 2013, JCTVCL045052 ITUTISO
   Joint Collaborative Team on Video Coding (JCT-VC), 2011, SG16WP3 ITUT
   Kim J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P449, DOI 10.1109/PCS.2012.6213251
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tohidypour H, 2013, 12 JCT VC M GEN SWIT
   Tohidypour HR, 2016, IEEE T MULTIMEDIA, V18, P182, DOI 10.1109/TMM.2015.2510332
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang J., 2011, JCTVCG543 ITUTISOIEC
   Zhao TS, 2013, IEEE J-STSP, V7, P1135, DOI 10.1109/JSTSP.2013.2271421
NR 26
TC 17
Z9 17
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8011
EP 8030
DI 10.1007/s11042-016-3460-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800019
DA 2024-07-18
ER

PT J
AU Xu, JL
   Hao, Y
   Song, HW
AF Xu, Jianlou
   Hao, Yan
   Song, Hongwei
TI A modified LOT model for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Total variation; Staircase effect; Primal-dual method
AB In image processing, it is often desirable to remove the noise and preserve image features. Due to the strong edge preserving ability, the total variation (TV) based regularization has been widely studied. However, it produces undesirable staircase effect. To alleviate the staircase effect, the LOT model proposed by Lysaker et al. (IEEE Trans Image Process 13(10): 1345-1357, 2004) has been studied, which is called the two-step method. After that, this method has started to appear as one of the more effective methods for image denoising, which includes two energy functions: one is about the normal field, the other is about the reconstruction image using the normal field obtained in the first step. However, the smoothed normal field is only related to the original noisy image in the first step, which is not enough. In this paper, we proposed a modified LOT model for image denoising, which lets the reconstruction vector field be related to the restored image. In addition, to compute the new model, we design a relaxed alternative direction method. The numerical experiments show that the new model can obtain the better results compared with some state-of-the art methods.
C1 [Xu, Jianlou; Hao, Yan; Song, Hongwei] Henan Univ Sci & Technol, Sch Math & Stat, 263 Kai Yuan Rd, Luoyang 471023, Henan, Peoples R China.
C3 Henan University of Science & Technology
RP Xu, JL (corresponding author), Henan Univ Sci & Technol, Sch Math & Stat, 263 Kai Yuan Rd, Luoyang 471023, Henan, Peoples R China.
EM xujianlou@126.com; haoyan_@126.com; songhwei2006@126.com
FU National Science Foundation of China [61301229, U1504603]; key
   scientific research project of Colleges and Universities in Henan
   province [15A110020]; soft science research project of Henan province
   [142400411404]; doctoral research fund of Henan University of Science
   and Technology [09001708, 09001751]
FX This work is supported by the National Science Foundation of China (Nos.
   61301229, U1504603), the key scientific research project of Colleges and
   Universities in Henan province (No. 15A110020), the soft science
   research project of Henan province (No. 142400411404) and the doctoral
   research fund of Henan University of Science and Technology (No.
   09001708, 09001751).
CR Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chen DQ, 2012, J SCI COMPUT, V51, P505, DOI 10.1007/s10915-011-9519-x
   Dong FF, 2009, J MATH IMAGING VIS, V34, P89, DOI 10.1007/s10851-008-0132-z
   Hahn J, 2012, J SCI COMPUT, V50, P235, DOI 10.1007/s10915-011-9482-6
   Hahn J, 2011, INT J COMPUT VISION, V92, P308, DOI 10.1007/s11263-010-0371-5
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Hao Y, 2014, COMPUT ELECTR ENG, V40, P808, DOI 10.1016/j.compeleceng.2013.08.010
   Litvinov WG, 2011, SIAM J SCI COMPUT, V33, P1574, DOI 10.1137/080727506
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Rahman T, 2007, LECT NOTES COMPUT SC, V4485, P473
   Rajwade A, 2013, IEEE T PATTERN ANAL, V35, P849, DOI 10.1109/TPAMI.2012.140
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu TT, 2014, NUMER ALGEBR CONTROL, V4, P209, DOI 10.3934/naco.2014.4.209
   XU J, 2014, SCI CHINA INFORM SCI, V57, P1
   Xu JL, 2014, J SYST ENG ELECTRON, V25, P168, DOI 10.1109/JSEE.2014.00020
   Xu JL, 2014, MULTIDIM SYST SIGN P, V25, P83, DOI 10.1007/s11045-012-0190-7
   Yan RM, 2013, IEEE T IMAGE PROCESS, V22, P4689, DOI 10.1109/TIP.2013.2277813
   Yang YF, 2011, APPL MATH COMPUT, V217, P5392, DOI 10.1016/j.amc.2010.12.009
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhang XB, 2015, MULTIMED TOOLS APPL, V74, P10495, DOI 10.1007/s11042-014-2182-0
NR 24
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8131
EP 8144
DI 10.1007/s11042-016-3451-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800024
DA 2024-07-18
ER

PT J
AU Bested, M
   Weisberg, AH
   Durao, FA
AF Bested, Morten
   Weisberg, Andreas Harby
   Durao, Frederico Araujo
TI A social interactive whiteboard system using finger-tracking for mobile
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finger-tracking; Whiteboard; Detection; Mobile-based; Drawing tool
AB Mobile devices have become a commodity in nowadays allowing people to get connected and perform several tasks for work. The usefulness of mobile is mobility leading people to solve their problems remotely, facilitating an everyday life. Based on these premises we propose a social interactive whiteboard system using finger-tracking for mobile devices. The application is a drawing tool, allowing users to create a virtual whiteboard and draw different kinds of lines, erase lines, zoom etc. from mobile devices that are featured with built-in projectors. Beyond the end-user application, this study investigates the problematic of tracking a finger using the build-in camera and how images are properly projected as a whiteboard from a mobile device. We present a thorough analysis of the various techniques that can be used to track a finger and depict our proposal to build the mobile-based interactive whiteboard application. The experimental evaluation analysed the performance, reliability and usability of the application taking into account valuable feedback for endusers.
C1 [Durao, Frederico Araujo] Univ Fed Bahia, Dept Comp Sci, Av Adhemar de Barro, Salvador, BA, Brazil.
   [Bested, Morten; Weisberg, Andreas Harby] Aalborg Univ, Dept Comp Sci & Engn, Selma Lagerlofs Vej 300, DK-9220 Aalborg, Denmark.
C3 Universidade Federal da Bahia; Aalborg University
RP Durao, FA (corresponding author), Univ Fed Bahia, Dept Comp Sci, Av Adhemar de Barro, Salvador, BA, Brazil.
EM mortenbested@gmail.com; andreas.weisberg@gmail.com;
   freddurao@dcc.ufba.br
RI Durao, Frederico/O-4898-2015
CR Alvarado Christine, 2007, ACM SIGGRAPH 2007 CO
   [Anonymous], 1994, INT C AUT FAC GEST R
   [Anonymous], 2003, PROC GRAPHICON
   Apple, 2010, ZOOM IN OUR OUT
   Arrington M, 2010, GOOGLE NEXUS ONE TEC
   Beardsley P, 2005, IEEE COMPUT GRAPH, V25, P39, DOI 10.1109/MCG.2005.12
   Beavis G, 2013, SAMSUNG SNEAKS OUT I
   Blasko G., 2005, Proceedings. Ninth IEEE International Symposium on Wearable Computers, P2, DOI 10.1109/ISWC.2005.21
   Boring S., 2007, ACM MOBILITY 07, P24, DOI DOI 10.1145/1378063.1378068
   Boring S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2287
   Cao X, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P43
   Crowley JL, 1995, FINGER TRACKING INPU
   Dao VN, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P43
   Digitimes, 2014, FOXL DEV MICR HANDS
   Ghuneim AG, 2016, CONTOUR TRACING
   Hosoi K, 2007, COGAME MANIPULATION
   Jones M., 1999, COMPUTER VISION PATT, V1, P280
   Keaton T, 2002, SIXTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P75, DOI 10.1109/ISWC.2002.1167221
   Kjeldskov J, 2004, NORDICHI 04, P233
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Launius R., 2005, Arkham Horror
   Malik S., 2003, Real-time Hand tracking and Finger Tracking for Interaction
   Oka K, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P429, DOI 10.1109/AFGR.2002.1004191
   Raskar R, 2003, ACM T GRAPHIC, V22, P809, DOI 10.1145/882262.882349
   Sato Y., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P462, DOI 10.1109/AFGR.2000.840675
   Schoning J., 2009, CHI '09 Extended Abstracts on Human Factors in Computing Systems, P3841, DOI DOI 10.1145/1520340.1520581
   Song HY, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2451
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Wu A., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P536, DOI 10.1109/AFGR.2000.840686
   Wu Y, 2000, MICROSOFT RES
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yang DD, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P4991
NR 33
TC 3
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5367
EP 5397
DI 10.1007/s11042-016-3922-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500031
DA 2024-07-18
ER

PT J
AU Hong, W
   Chen, TS
   Yin, ZX
   Luo, B
   Ma, YB
AF Hong, Wien
   Chen, Tung Shou
   Yin, Zhaoxia
   Luo, Bin
   Ma, Yuanbo
TI Data hiding in AMBTC images using quantization level modification and
   perturbation technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block truncation coding; Data hiding; Threshold mechanism
ID MEDICAL IMAGES; WATERMARKING; ROBUST; STEGANOGRAPHY; SEGMENTATION
AB A novel data hiding method for Absolute Moment Block Truncation Coding (AMBTC) compressed image based on quantization level modification is proposed. Blocks of AMBTC-compressed image are classified into two categories, namely smooth and complex, according to a predefined threshold. For smooth blocks, the bitmap is replaced by secret data for data embedment. Meanwhile, the corresponding quantization levels are modified to achieve a minimum distortion. If a larger payload is required, the modified quantization levels can be further perturbed for carrying two additional bits. If the blocks are complex, one data bit can be embedded with no distortion by swapping the values of the two quantization levels together with bitmap flipping. In addition, a suppress threshold mechanism is used to prevent from the application of the perturbation technique at low payload to maintain the image quality. The proposed method minimizes the distortion of each stego block while ensuring high payload, thus the embedding efficiency can be enhanced. Experimental results demonstrate the improvement of the proposed method compared with other related state-of-art works.
C1 [Hong, Wien] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Chen, Tung Shou] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Yin, Zhaoxia; Luo, Bin] Anhui Univ, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei, Peoples R China.
   [Hong, Wien; Ma, Yuanbo] Sun Yat Sen Univ, Nanfang Coll, Dept Elect Commun & Software Engn, Guangzhou, Guangdong, Peoples R China.
C3 Nanjing University of Information Science & Technology; National
   Taichung University of Science & Technology; Anhui University; Sun Yat
   Sen University; Nanfang College, Guangzhou
RP Hong, W (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.; Hong, W (corresponding author), Sun Yat Sen Univ, Nanfang Coll, Dept Elect Commun & Software Engn, Guangzhou, Guangdong, Peoples R China.
EM wienhong@gmail.com
RI Yin, Zhaoxia/HRD-7425-2023; lu, bin/HPE-4790-2023; LUO, BIN/Y-1233-2018
OI Yin, Zhaoxia/0000-0003-0387-4806; LUO, BIN/0000-0001-5948-5055
CR [Anonymous], 2015, MULTIDIMENS SYST SIG, DOI DOI 10.1007/S11045-015-0358-Z
   [Anonymous], 2014, AM J ENG TECHNOL RES
   [Anonymous], INT J INNOV COMPUT I
   Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Junlan Bai, 2016, International Journal of Network Security, V18, P1122
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parah SA, 2015, INT J ELECTRON, V102, P1253, DOI 10.1080/00207217.2014.954635
   Parah SA, 2015, MULTIMED TOOLS APPL, P1
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Qian ZX, 2014, J SYST SOFTWARE, V91, P100, DOI 10.1016/j.jss.2013.12.043
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xie SD, 2014, WIRELESS PERS COMMUN, V78, P231, DOI 10.1007/s11277-014-1748-5
   Zargar AJ, 2016, INT J ELECTRON SECUR, V8, P53, DOI 10.1504/IJESDF.2016.073734
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
NR 39
TC 16
Z9 16
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3761
EP 3782
DI 10.1007/s11042-016-3977-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200029
DA 2024-07-18
ER

PT J
AU Ripamonti, LA
   Mannalà, M
   Gadia, D
   Maggiorini, D
AF Ripamonti, Laura Anna
   Mannala, Mattia
   Gadia, Davide
   Maggiorini, Dario
TI Procedural content generation for platformers: designing and testing FUN
   PLEdGE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User experience design; Video games design; Procedural content
   generation; User interfaces; Artificial intelligence for games
ID GAME
AB Video games are a peculiar medium, standing at the crossing point between art and software application, and characterized by an active involvement of its audience. The complexity of the product generates a huge challenge for the companies that develop video games. In the development process, level designers play a crucial role: they are in charge of declining the theoretical framework developed by the game designer into game levels, which contain the actual gameplay scenarios. Hence, the final goal of any level designer is to valorize the game design by creating enjoyable gaming experiences while, at the same time, respecting several constraints. To lighten the burden on level designers, several semi-automated approaches to level generation have appeared in time, but the majority of these tools suffer from several drawbacks. In the present work, we tackle the issue of designing, prototyping and testing FUN PLEdGE, a general-purpose automated levels generator and editor for platform video games. Its main goal is to shrink development time while producing - unassisted - levels that are both playable and fun. Moreover, our tool provides the maximum freedom to the level designer, by avoiding to impose unnecessary constraints on the structure of the levels and by guaranteeing the possibility to modify and personalize by hand the generated levels. During this process, the generator assists the designer by suggesting corrections functional to the quality of the player experience. To prove the effectiveness of our prototypal application we have also developed and tested with players a platform game. In the same vein, we asked to a group of game developers to test FUN PLEdGE.
C1 [Ripamonti, Laura Anna; Mannala, Mattia; Gadia, Davide; Maggiorini, Dario] Univ Milan, Dept Comp Sci, Via Comelico 39, I-20135 Milan, Italy.
C3 University of Milan
RP Ripamonti, LA (corresponding author), Univ Milan, Dept Comp Sci, Via Comelico 39, I-20135 Milan, Italy.
EM ripamonti@di.unimi.it
RI Gadia, Davide/P-6309-2016; Ripamonti, Laura Anna/GQH-8599-2022
OI Gadia, Davide/0000-0003-4491-9150; Maggiorini, Dario/0000-0002-7460-2966
CR Andrade G, 2005, IAT 05
   Andrade G, 2005, AAMAS 05
   [Anonymous], P IEEE S COMP INT GA
   [Anonymous], 2004, Theory of Fun for Game Design
   [Anonymous], 2015, ART GAME DESIGN BOOK
   Bartle R., 2003, Designing Virtual Worlds
   Bates B., 2004, GAME DESIGN, V2nd
   Bleszinski C., 2000, ART SCI LEVEL DESIGN
   Chen GN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360702
   Compton K, 2006, P AIIDE 2006 MAR DEL
   Csikszentmihalyi M., 2008, FLOW PSYCHOL OPTIMAL
   Dormans J, 2011, P PCGAMES 2011 JUN 2
   Ebert D.S., 2003, TEXTURING MODELING, V3rd
   ECMA International, 2012, ECMA335
   Farnell A, 2010, DESIGNING SOUND, P1
   Fisher J, 2014, MAKE INSANE PROCEDUR
   Fullerton T, 2014, GAME DESIGN WORKSHOP, DOI DOI 10.1201/B16671
   Hastings E, 2009, P ART INT INT DIG EN
   Hastings EJ, 2009, IEEE T COMP INTEL AI, V1, P245, DOI 10.1109/TCIAIG.2009.2038365
   Hudlicka E, 2008, GAMEON NA 08
   Hunicke R, 2004, P 2004 AAAI WORKSH C
   Hunicke Robin, 2005, P ACE 2005, P429, DOI DOI 10.1145/1178477.1178573
   Iyer V, 1997, P 23 INT COMP MUS C
   Kremers R., 2009, Level Design: Concept, Theory, and Practice
   Lee S, 2006, LECT NOTES ARTIF INT, V4099, P955
   Maggiorini D, 2012, P ICCCN 2012
   Maggiorini D, 2012, P IEEE C COMP INT GA
   Maggiorini D, 2015, P CHITALY 2015 11 BI
   Mark B, 2015, P FDN DIG GAM FDG
   Marks J, 2007, P AIIDE
   Mcentee Chris., 2012, Rational Design: The Core of Rayman Origins
   Missura O, 2009, LECT NOTES ARTIF INT, V5808, P197, DOI 10.1007/978-3-642-04747-3_17
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Persson M, 2011, TERRAIN GENERATION 1
   Prusinkiewicz P., 2004, The Algorithmic Beauty of Plants
   Schwarz M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766956
   Shaker N, 2010, P AIIDE 2010 6 AAAI
   Smith G, 2010, P 2010 WORKSH PROC C
   Smith G, 2012, P FDN DIG GAM FDG 12
   Smith G, 2009, P 2009 INT C FDN DIG
   Smith G, 2010, P PCGAMES 2011 JUN 2
   Smith G, 2011, IEEE T COMP INTEL AI, V3, P201, DOI 10.1109/TCIAIG.2011.2159716
   Smith G, 2011, IEEE T COMP INTEL AI, V3, P1, DOI 10.1109/TCIAIG.2010.2095855
   Spronck P, 2006, MACH LEARN, V63, P217, DOI 10.1007/s10994-006-6205-6
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   TATHAM Mark., 2005, Developments in Speech Synthesis
   Thorn Alan., 2010, GAME ENGINE DESIGN I
   Togelius J, 2008, P CIG 08 IEEE S COMP
   Togelius J, 2007, P IEEE S COMP INT GA
   Togelius J, 2011, P PCGAMES 2011 JUN 2
   Toy Michael., 1980, ROGUE
   Yannakakis GN, 2009, IEEE T COMP INTEL AI, V1, P121, DOI 10.1109/TCIAIG.2009.2024533
NR 54
TC 10
Z9 10
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5001
EP 5050
DI 10.1007/s11042-016-3636-3
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500016
DA 2024-07-18
ER

PT J
AU Sajjad, M
   Muhammad, K
   Baik, SW
   Rho, S
   Jan, Z
   Yeo, SS
   Mehmood, I
AF Sajjad, Muhammad
   Muhammad, Khan
   Baik, Sung Wook
   Rho, Seungmin
   Jan, Zahoor
   Yeo, Sang-Soo
   Mehmood, Irfan
TI Mobile-cloud assisted framework for selective encryption of medical
   images with steganography for resource-constrained devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image processing; Image steganography; Visual saliency models;
   Selective image encryption; Mobile-cloud computing; Information
   security; Resource-constrained devices
ID ALGORITHM
AB In this paper, the problem of outsourcing the selective encryption of a medical image to cloud by resource-constrained devices such as smart phone is addressed, without revealing the cover image to cloud using steganography. In the proposed framework, the region of interest of the medical image is first detected using a visual saliency model. The detected important data is then embedded in a host image, producing a stego image which is outsourced to cloud for encryption. The cloud which has powerful resources, encrypts the image and sent back the encrypted marked image to the client. The client can then extract the selectively encrypted region of interest and can combine it with the region of non-interest to form a selectively encrypted image, which can be sent to medical specialists and healthcare centers. Experimental results and analysis validate the effectiveness of the proposed framework in terms of security, image quality, and computational complexity and verify its applicability in remote patient monitoring centers.
C1 [Sajjad, Muhammad; Jan, Zahoor] Islamia Coll Peshawar, Digital Image Proc Lab, Dept Comp Sci, Peshawar, Pakistan.
   [Muhammad, Khan; Baik, Sung Wook] Sejong Univ, Intelligent Media Lab, Dept Digital Contents, Coll Elect & Informat Engn, Seoul, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
   [Yeo, Sang-Soo] Mokwon Univ, Div Convergence Comp & Media, Daejeon, South Korea.
   [Mehmood, Irfan] Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 University of Peshawar; Sejong University; Sungkyul University; Mokwon
   University; Sejong University
RP Mehmood, I (corresponding author), Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM irfan@sejong.ac.kr
RI Yeo, Sang-Soo/D-3216-2016; Sajjad, Muhammad/L-5269-2016; Khan,
   Muhammad/IXN-8470-2023; Baik, Sung Wook/AAR-8236-2020; Muhammad,
   Khan/L-9059-2016; Sajjad, Muhammad/GZL-4962-2022; Rho,
   Seungmin/HTP-6683-2023; Yeo, Sang-Soo/AAD-6176-2020; Ahmad,
   Habib/L-9669-2016
OI Yeo, Sang-Soo/0000-0002-0224-0150; Sajjad, Muhammad/0000-0001-5646-0338;
   Muhammad, Khan/0000-0003-4055-7412; Sajjad,
   Muhammad/0000-0003-0006-1156; Muhammad, Khan/0000-0002-5302-1150;
   Mehmood, Irfan/0000-0001-7864-957X; Baik, Sung Wook/0000-0002-6678-7788
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [2013R1A1A2061978]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education (2013R1A1A2061978).
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], J MED SYST
   [Anonymous], DIAGNOSTIC THERAPEUT
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], WOSPA 2008 5 IEEE IN
   [Anonymous], 2015, ARXIV151108865
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 12 LEARN TECHN C
   [Anonymous], LECT NOTES INFORM TH
   [Anonymous], 4 IEEE GCC C EXH
   Ao BK, 2015, CHINA COMMUN, V12, P1, DOI 10.1109/CC.2015.7114054
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Ejaz N, 2013, MICROSC RES TECHNIQ, V76, P559, DOI 10.1002/jemt.22205
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gupta BB, 2009, INF SECUR J, V18, P224, DOI 10.1080/19393550903317070
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hussain M, 2015, IEEE ICCE, P21, DOI 10.1109/ICCE-TW.2015.7216859
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   Lin CY, 2008, IEICE T INF SYST, VE91D, P836, DOI 10.1093/ietisy/e91-d.3.836
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Lv ZH, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0475-8
   Mehmood I, 2015, INFORM FUSION, V24, P16, DOI 10.1016/j.inffus.2014.07.002
   Mehmood I, 2014, SENSORS-BASEL, V14, P17112, DOI 10.3390/s140917112
   Muhammad Khan, 2016, 2016 International Conference on Platform Technology and Service (PlatCon). Proceedings, P1, DOI 10.1109/PlatCon.2016.7456799
   Muhammad Khan, 2015, NED University Journal of Research, V12, P81
   Muhammad K, MULTIMED TOOLS APPL, P1
   MUHAMMAD K, 2014, MIDDLE-EAST J SCI RE, V22, P647, DOI DOI 10.5829/idosi.mejsr.2014.22.05.21946
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad Khan, 2015, [The Journal of Korean Institute of Next Generation Computing, 한국차세대컴퓨팅학회 논문지], V11, P87
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Mustafa RJ., 2014, SYST APPL TECHN C LI, V2014, P2014, DOI [10.1109/LISAT.2014.6845191, DOI 10.1109/LISAT.2014.6845191]
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Parvez MT, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1322, DOI 10.1109/APSCC.2008.105
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Salvatore M, 2014, RADIOLOGY, V270, P67, DOI 10.1148/radiol.13130733
   Singh A., 2016, Microscale Technologies for Cell Engineering, DOI [10.1007/978-3-319-20726-1, DOI 10.1007/978-3-319-20726-1, DOI 10.1007/S11042015-27547]
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Tewari A., 2016, J INFORM PRIVACY SEC, V12, P3, DOI DOI 10.1080/15536548.2016.1139423
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wu HZ, 2015, MULTIMED TOOLS APPL, V74, P8171, DOI 10.1007/s11042-014-2050-y
   Wu HZ, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P224, DOI 10.1109/ISBAST.2013.39
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Xiang T, 2015, DIGIT SIGNAL PROCESS, V43, P28, DOI 10.1016/j.dsp.2015.05.006
   Yang JJ, 2015, COMPUT IND, V69, P3, DOI 10.1016/j.compind.2015.01.012
   Yang JC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145800
NR 52
TC 54
Z9 56
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3519
EP 3536
DI 10.1007/s11042-016-3811-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200018
DA 2024-07-18
ER

PT J
AU Yan, SY
   Zhu, XD
   Liu, GQ
   Wu, JX
AF Yan, Shengye
   Zhu, Xiaodong
   Liu, Guoqing
   Wu, Jianxin
TI Sparse multiple instance learning as document classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse multiple instance learning; Low witness rate; Structural
   representation; Document classification
AB This work focuses on multiple instance learning (MIL) with sparse positive bags (which we name as sparse MIL). A structural representation is presented to encode both instances and bags. This representation leads to a non-i.i.d. MIL algorithm, miStruct, which uses a structural similarity to compare bags. Furthermore, MIL with this representation is shown to be equivalent to a document classification problem. Document classification also suffers from the fact that only few paragraphs/words are useful in revealing the category of a document. By using the TF-IDF representation which has excellent empirical performance in document classification, the miDoc method is proposed. The proposed methods achieve significantly higher accuracies and AUC (area under the ROC curve) than the state-of-the-art in a large number of sparse MIL problems, and the document classification analogy explains their efficacy in sparse MIL problems.
C1 [Yan, Shengye; Zhu, Xiaodong] NUIST, CICAEET, Sch Informat & Control, B DAT, Niuliu Rd, Nanjing 210044, Peoples R China.
   [Liu, Guoqing] Youjia Innovat LLC, Minieye, Shenzhen, Peoples R China.
   [Wu, Jianxin] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University
RP Yan, SY (corresponding author), NUIST, CICAEET, Sch Informat & Control, B DAT, Niuliu Rd, Nanjing 210044, Peoples R China.
EM shengye.yan@gmail.com
RI Wu, Jianxin/A-3700-2011
FU National Natural Science Foundation of China [61300163, 61422203]
FX This research was supported by the National Natural Science Foundation
   of China under Grant Nos of 61300163 and 61422203.
CR Andrews S, 2003, 15 ADV NEURAL INFORM
   [Anonymous], IEEE C COMP VIS PATT
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bunescu RC, 2007, 24 INT C MACH LEARN
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Cheung P-M, 2006, 23 INT C MACH LEARN
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Fung G, 2007, 19 ADV NEURAL INFORM
   Gartner T, 2002, 19 INT C MACH LEARN
   Gehler PV, 2007, 11 INT C ART INT STA
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Li F, 2010, 24 ADV NEURAL INFORM
   Li WJ, 2010, IEEE T KNOWL DATA EN, V22, P76, DOI 10.1109/TKDE.2009.58
   Rastegari M, 2015, DISCRIMINATIVE CONSI
   Ray S, 2005, 22 INT C MACH LEARN
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Settles B, 2008, 20 ADV NEURAL INFORM
   Viola P, 2006, 18 ADV INFORM PROCES
   Viola P, 2007, MULTIPLE INSTANCE BO
   Winn J., 2005, 10 IEEE INT C COMP V
   Wu J, 2011, 15 PAC AS C KNOWL DI
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Zhang B-C, 2016, BOUNDING MULTIPLE GA
   Zhang BC, 2015, IEEE WINT CONF APPL, P25, DOI 10.1109/WACV.2015.11
   Zhang BC, 2015, NEUROCOMPUTING, V170, P221, DOI 10.1016/j.neucom.2014.08.102
   Zhang ML, 2009, APPL INTELL, V31, P47, DOI 10.1007/s10489-007-0111-x
   Zhang Q, 2002, 14 ADV NEURAL INFORM
   Zhou Z-H, 2009, 26 INT C MACH LEARN
   Zhou Z-H, 2007, 24 INT C MACH LEARN
NR 31
TC 5
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4553
EP 4570
DI 10.1007/s11042-016-3567-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200066
DA 2024-07-18
ER

PT J
AU Dumic, E
   Grgic, S
   Sakic, K
   Rocha, PMR
   Cruz, LAD
AF Dumic, Emil
   Grgic, Sonja
   Sakic, Kresimir
   Regalo Rocha, Pedro Miguel
   da Silva Cruz, Luis A.
TI 3D video subjective quality: a new database and grade comparison study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video quality; Subjective assessment; Objective quality measures;
   3DVCL@FER video database
ID STEREOSCOPIC VIDEO
AB This paper presents a research study on the subjective assessment of 3D video quality using a newly constructed 3D video database (3DVCL@FER). This database consists of 8 original 3D video sequences, each degraded with 22 different degradation types, including degradations specific to stereoscopic systems. The subjective assessment was done with the support of a purpose-built easily customizable grade collection platform and conducted in two research laboratories, in Croatia and Portugal. Subjective scores for quality, depth and comfort were collected and DMOS (Difference Mean Opinion Score) values were calculated. Different objective measures (for image, 3D image, 2D video and 3D video) were separately compared with DMOS values for quality, depth and comfort. The 3D video grade-annotated database described is publicly accessible and can be used in research-related activities like assessment of existing objective measures, using the entire database or parts of it, and construction of new objective measures specific to 3D video degradations. The system presented can also be used to collect and compare subjective quality grades originating from different sites to study the effect of different observation conditions and observer/graders populations on the DMOS quality values for 3D video depth and comfort.
C1 [Dumic, Emil] Univ North, Dept Elect Engn, 104 Brigade 3, Varazhdin 42000, Croatia.
   [Grgic, Sonja] Univ Zagreb, Dept Wireless Commun, Fac Elect Engn & Comp, Unska 3-12, HR-10000 Zagreb, Croatia.
   [Sakic, Kresimir] Croatian Regulatory Author Network Ind HAKOM, Radio Commun Dept, Zagreb 10000, Croatia.
   [Regalo Rocha, Pedro Miguel; da Silva Cruz, Luis A.] Univ Coimbra, Dept Elect & Comp Engn, Inst Telecomunicacoes, Rua Silvio Lima,Polo 2, P-3030290 Coimbra, Portugal.
C3 University North - Croatia; University of Zagreb; Universidade de
   Coimbra; Institute of Telecommunications - Coimbra
RP Dumic, E (corresponding author), Univ North, Dept Elect Engn, 104 Brigade 3, Varazhdin 42000, Croatia.
EM emil.dumic@gmail.com
RI da Silva Cruz, Luis A/A-9125-2011; Dumic, Emil/U-9142-2019
OI da Silva Cruz, Luis A/0000-0003-1141-4404; Dumic,
   Emil/0000-0002-0262-5595; Grgic, Sonja/0000-0002-0802-3288
CR [Anonymous], 2012, Recommendation BT.500-13
   [Anonymous], 3DTV C TRUE VIS CAPT
   [Anonymous], SPIE P
   [Anonymous], TEST PLAN E IN PRESS
   [Anonymous], MAGAZIN COMPUTER TEC
   [Anonymous], QUAL MULTIM EXP
   [Anonymous], THESIS
   [Anonymous], BT2021 ITUR
   Banitalebi-Dehkordi A, 2015, 3D RES, V6, DOI 10.1007/s13319-014-0034-3
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Cheng E, 2012, INT WORK QUAL MULTIM, P212, DOI 10.1109/QoMEX.2012.6263873
   De Silva V, 2013, IEEE T IMAGE PROCESS, V22, P3392, DOI 10.1109/TIP.2013.2268422
   Dumic E, 2014, SIGNAL IMAGE VIDEO P, V8, P1159, DOI 10.1007/s11760-014-0654-3
   Dumic E, 2014, ELMAR PROC, P119, DOI 10.1109/ELMAR.2014.6923330
   Dumic E, 2010, MULTIMED TOOLS APPL, V49, P409, DOI 10.1007/s11042-009-0441-2
   ITU, 2008, Rec. ITU-T P.910
   Joveluro P, 2010, 3DTV CONF
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Ma R, 2013, IEEE IMAGE PROC, P1714, DOI 10.1109/ICIP.2013.6738353
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   López JP, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-62
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Urvoy M, 2012, INT WORK QUAL MULTIM, P109, DOI 10.1109/QoMEX.2012.6263847
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xing LY, 2013, INT WORK QUAL MULTIM, P136, DOI 10.1109/QoMEX.2013.6603226
NR 28
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2087
EP 2109
DI 10.1007/s11042-015-3172-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000023
DA 2024-07-18
ER

PT J
AU Gharavian, D
   Bejani, M
   Sheikhan, M
AF Gharavian, Davood
   Bejani, Mehdi
   Sheikhan, Mansour
TI Audio-visual emotion recognition using FCBF feature selection method and
   particle swarm optimization for fuzzy ARTMAP neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio-visual emotion recognition; Particle swarm optimization; Fuzzy
   ARTMAP neural network
ID AUTOMATIC-ANALYSIS; BEHAVIOR
AB Humans use many modalities such as face, speech and body gesture to express their feeling. So, to make emotional computers and make the human-computer interaction (HCI) more naturally and friendly, computers should be able to understand human feelings using speech and visual information. In this paper, we recognize the emotions from audio and visual information using fuzzy ARTMAP neural network (FAMNN). Audio and visual systems fuse at decision and feature levels. Finally, the particle swarm optimization (PSO) is employed to determine the optimum values of the choice parameter (alpha), the vigilance parameters (rho), and the learning rate (beta) of the FAMNN. Experimental results showed that the feature-level and decision-level fusions improve the outcome of unimodal systems. Also PSO improved the recognition rate. By using the PSO-optimized FAMNN at feature level fusion, the recognition rate was improved by about 57 % with respect to the audio system and by about 4.5 % with respect to the visual system. The final emotion recognition rate on the SAVEE database was reached to 98.25 % using audio and visual features by using optimized FAMNN.
C1 [Gharavian, Davood; Sheikhan, Mansour] Islamic Azad Univ, South Tehran Branch, Dept Elect Engn, Tehran, Iran.
   [Gharavian, Davood] Shahid Beheshti Univ, Dept Elect Engn, Tehran, Iran.
   [Bejani, Mehdi] Islamic Azad Univ, South Tehran Branch, Tehran, Iran.
C3 Islamic Azad University; Shahid Beheshti University; Islamic Azad
   University
RP Gharavian, D (corresponding author), Islamic Azad Univ, South Tehran Branch, Dept Elect Engn, Tehran, Iran.; Gharavian, D (corresponding author), Shahid Beheshti Univ, Dept Elect Engn, Tehran, Iran.
EM dgharavian@gmail.com; St_m_bejani@azad.ac.ir; msheikhn@azad.ac.ir
RI Bejani, Mehdi/GRS-4904-2022
OI Bejani, Mehdi/0000-0002-7668-3413; Sheikhan, Mansour/0000-0002-4733-6113
FU Islamic Azad University-South Tehran Branch
FX This work was supported by Islamic Azad University-South Tehran Branch
   under a research project entitled "Audio-Visual Emotion Modeling to
   Improve human-computer interaction".
CR AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   [Anonymous], CBMI
   [Anonymous], 2006, P 22 INT C DAT ENG W
   Atashpaz-Gargari E, 2007, IEEE C EVOL COMPUTAT, P4661, DOI 10.1109/CEC.2007.4425083
   Banda N., 2011, INT C MULT INT AL SP
   Bejani M, 2014, NEURAL COMPUT APPL, V24, P399, DOI 10.1007/s00521-012-1228-3
   Boersma P., 2007, PRAAT: doing phonetics by computer
   Bulut M., 2004, P 6 INT C MULT INT, P205
   Carpenter GA, 2003, IEEE IJCNN, P1396
   CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059
   Chen CY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1469
   Cheng-Yao C, 2005, VISUAL ACOUSTIC EMOT, P1468
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dai WH, 2015, INFORM MANAGE-AMSTER, V52, P777, DOI 10.1016/j.im.2015.02.003
   De Silva L. C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P332, DOI 10.1109/AFGR.2000.840655
   Devillers L, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P801
   Ekman P., 2005, WHAT FACE REVEALS BA
   Ekman P., 1971, Nebraska symposium on motivation, V19, P207
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Gharavian D, 2012, NEURAL COMPUT APPL, V21, P2115, DOI 10.1007/s00521-011-0643-1
   Haq S., 2015, Sindh University Research Journal -Science Series, V47, P67
   Haq S., 2009, INT C AUDITORY VISUA, P53
   Harley JM, 2015, COMPUT HUM BEHAV, V48, P615, DOI 10.1016/j.chb.2015.02.013
   Hassan A, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2354
   Hoch S, 2005, INT CONF ACOUST SPEE, P1085
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Klein J, 2002, INTERACT COMPUT, V14, P119, DOI 10.1016/S0953-5438(01)00053-4
   Lee CC, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P328
   López-de-Ipiña K, 2015, NEUROCOMPUTING, V150, P392, DOI 10.1016/j.neucom.2014.05.083
   Mansoorizadeh M, 2009, MULTIMED TOOLS APPL
   Mansoorizadeh M, 2009, P 14 INT CSI COMP C
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Paleari M., 2008, 15th International Multimedia Modeling Conference on Advances in Multimedia Modeling, P435
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Polzehl T, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P340
   Rajabioun R, 2011, APPL SOFT COMPUT, V11, P5508, DOI 10.1016/j.asoc.2011.05.008
   Schuller B, 2007, INT CONF ACOUST SPEE, P733
   Sheikhan M, 2013, NEURAL COMPUT APPL, V23, P215, DOI 10.1007/s00521-012-0814-8
   Shlens J., 2005, ARXIV
   Song M, 2008, NEUROCOMPUTING
   Weisgerber A, 2015, PSYCHIAT RES, V229, P188, DOI 10.1016/j.psychres.2015.07.042
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zeng ZH, 2007, LECT NOTES COMPUT SC, V4451, P72
NR 47
TC 31
Z9 34
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2331
EP 2352
DI 10.1007/s11042-015-3180-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000033
DA 2024-07-18
ER

PT J
AU Meng, FR
   Tang, ZY
   Wang, ZX
AF Meng, Fanrong
   Tang, Zhenyu
   Wang, Zhixiao
TI An improved redundant dictionary based on sparse representation for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Face recognition; Redundant dictionary; Feature
   fusion; LDA (linear discriminate analysis)
AB In recent years sparse representation has been widely used for face recognition and achieved good results. Most sparse representation methods need a redundant dictionary to solve sparse coefficients. And the number of atoms must be much larger than the dimension of atoms in the dictionary. So the design of redundant dictionary is very important for improving the performance of sparse representation methods. By experiments we find that feature fusion (LBP, Gabor, Hog, and raw pixels) after PCA can remain a high recognition rate, which means the feature fusion can represent faces well with a low dimension. So we can use the dictionary based on feature fusion to solve small sample size problem in LDA without losing useful information. And LDA can increase between-class scatter and decrease within-class scatter while reducing the dimensionality, which can build a better structure for redundant dictionary. Based on above we propose a linear discriminative redundant dictionary based on feature fusion to improve the performance of face sparse representation methods, namely, LDRD. Firstly, extract and concatenate a standard set of features (LBP, Gabor, Hog, and raw pixels) to form a feature vector as the atoms, then introduce LDA to rebuild the dictionary of atoms, to reduce dimensionality and enhance the discriminative ability of the dictionary. We compare LDRD with the dictionary based on downsampling and feature fusion for SRC, CRC_RLS and LASRC. The extensive experiments demonstrate that the proposed dictionary has better recognition rate and operating efficiency, while it can easily reject distractor faces.
C1 [Meng, Fanrong; Tang, Zhenyu; Wang, Zhixiao] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Meng, FR (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
EM tzyhpcom@163.com
FU National High Technology Research and Development Program of China
   [2012AA0622022, 2012AA011004]; Doctoral Fund of Ministry of Education of
   China [20100095110003, 20110095110010]; Fundamental Research Funds for
   the Central Universities [2013XK10]; National Natural Science Fund
   [61402482]; key project of coal union fund under the National Natural
   Science Fund [U1261201]
FX The authors would like to thank Dr. Zhizhen Liang for helpful and
   informative discussion on face recognition and the design of
   experiments. This work was supported by the National High Technology
   Research and Development Program of China (Grant No. 2012AA0622022 and
   Grant No. 2012AA011004), the Doctoral Fund of Ministry of Education of
   China (Grant No. 20100095110003 and Grant No. 20110095110010), the
   Fundamental Research Funds for the Central Universities under Grant
   (Grant No. 2013XK10), the National Natural Science Fund (Grant No.
   61402482) and the key project of coal union fund under the National
   Natural Science Fund (Grant No. U1261201).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2007, 0749 U MASS
   Becker BC, 2013, IEEE COMPUT SOC CONF, P904, DOI 10.1109/CVPRW.2013.133
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Buhmann J., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P155, DOI 10.1109/IJCNN.1989.118574
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Georghiades A. S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P277, DOI 10.1109/AFGR.2000.840647
   Howland P, 2006, PATTERN RECOGN, V39, P277, DOI 10.1016/j.patcog.2005.06.013
   Martinez A. M., 1998, THE AR FACE DATABASE
   Ortiz EG, 2014, COMPUT VIS IMAGE UND, V118, P153, DOI 10.1016/j.cviu.2013.09.004
   Pinto Z., 2011, CVPR 2011 WORKSH, P35, DOI DOI 10.1109/CVPRW.2011.5981788
   Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
NR 17
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 895
EP 912
DI 10.1007/s11042-015-3083-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000038
DA 2024-07-18
ER

PT J
AU Roh, MC
   Kang, D
   Huh, S
   Lee, SW
AF Roh, Myung-Cheol
   Kang, Dongoh
   Huh, Sungju
   Lee, Seong-Whan
TI A virtual mouse interface with a two-layered Bayesian network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-layer Bayesian network; Hand gesture recognition; Virtual mouse
   interface
ID GESTURE RECOGNITION; HAND TRACKING
AB During the last decade, many natural interaction methods between human and computer have been introduced. They were developed for substitutions of keyboard and mouse devices so that they provide convenient interfaces. Recently, many studies on vision based gestural control methods for Human-Computer Interaction (HCI) have been attracted attention because of their convenience and simpleness. Two of the key issues in these kinds of interfaces are robustness and real-time processing. This paper presents a hand gesture based virtual mouse interface and Two-layer Bayesian Network (TBN) for robust hand gesture recognition in real-time. The TBN provides an efficient framework to infer hand postures and gestures not only from information at the current time frame, but also from the preceding and following information, so that it compensates for erroneous postures and its locations under cluttered background environment. Experiments demonstrated that the proposed model recognized hand gestures with a recognition rate of 93.76 % and 85.15 % on simple and cluttered background video data, respectively, and outperformed previous methods: Hidden Markov Model (HMM), Finite State Machine (FSM).
C1 [Roh, Myung-Cheol] S-1,S-1 Bldg,25,Sejong Daero 7 Gil, Seoul 100733, South Korea.
   [Kang, Dongoh; Huh, Sungju; Lee, Seong-Whan] Korea Univ, Dept Brain & Cognit Engn, Seoul 136713, South Korea.
C3 Korea University
RP Lee, SW (corresponding author), Korea Univ, Dept Brain & Cognit Engn, Seoul 136713, South Korea.
EM myung.roh@gmail.com; dokang@image.korea.ac.kr; sjheo@image.korea.ac.kr;
   sw.lee@korea.ac.kr
FU ICT R&D program of MSIP/IITP [B0101-15-0552]; Implementation of
   Technologies for Identification, Behavior, and Location of Human based
   on Sensor Network Fusion Program through Ministry of Trade, Industry and
   Energy [10041629]
FX This work was partly supported by the ICT R&D program of MSIP/IITP
   [B0101-15-0552, Development of Predictive Visual Intelligence
   Technology] and also supported by the Implementation of Technologies for
   Identification, Behavior, and Location of Human based on Sensor Network
   Fusion Program through the Ministry of Trade, Industry and Energy (Grant
   No. 10041629).
CR Argyros AA, 2006, LECT NOTES COMPUT SC, V3979, P40
   Brand J, 2000, INT C PATT RECOG, P1056, DOI 10.1109/ICPR.2000.905653
   Bretzner L, 2001, CVAP251 KTH DEP NUM
   Caschera MC, 2013, IEEE T SYST MAN CY-S, V43, P911, DOI 10.1109/TSMCA.2012.2210407
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DORNER B, 1994, ARTIF INTELL REV, V8, P235, DOI 10.1007/BF00849076
   Fu Y., 2007, 2007 IEEE WORKSH APP, P30
   Hu K, 2015, P 11 IEEE INT C AUT
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Krejov P, 2015, P 11 IEEE INT C AUT
   Laptev I, 2001, TRACKING MULTI STATE, P63
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Murphy KevinP., 1994, DYNAMIC BAYESIAN NET
   Nguyen V-T, 2015, P 11 IEEE INT C AUT
   Raheja Jagdish Lal, 2010, Proceedings of the 2nd International Conference on Machine Learning and Computing (ICMLC 2010), P12, DOI 10.1109/ICMLC.2010.12
   Ramamoorthy A, 2003, PATTERN RECOGN, V36, P2069, DOI 10.1016/S0031-3203(03)00042-6
   Robertson P, 2004, VIRTUAL MOUSE VISION, P177
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   Vafadar M, 2008, LECT NOTES COMPUT SC, V5099, P378, DOI 10.1007/978-3-540-69905-7_43
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yeasin M, 2000, PATTERN RECOGN, V33, P1805, DOI 10.1016/S0031-3203(99)00175-2
NR 24
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1615
EP 1638
DI 10.1007/s11042-015-3144-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000001
DA 2024-07-18
ER

PT J
AU Su, QT
   Wang, G
   Zhang, XF
   Lv, GH
   Chen, BJ
AF Su, Qingtang
   Wang, Gang
   Zhang, Xiaofeng
   Lv, Gaohuan
   Chen, Beijing
TI An improved color image watermarking algorithm based on QR decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color watermark image; Matrix decomposition; Orthogonal matrix;
   Robustness
ID TRANSFORM
AB Most of the existing color image watermarking schemes use binary or grayscale image as watermark, and many of them belong to non-blind watermarking methods. In this paper, an improved color image watermarking algorithm based on QR decomposition is proposed to embed color watermark image into color host image. For embedding watermark, the 24-bits color host image is divided into non-overlapping 3 x 3 pixel blocks and each pixel block is decomposed by QR decomposition, and the 24-bits color watermark image is embedded into the color host image by modifying the relation between the second row first column coefficient and the third row first column coefficient of the orthogonal matrix Q. For extracting watermark, only the watermarked image is needed. Experimental results show that the proposed color image scheme not only has better watermark performance such as invisibility, robustness, security, capacity, and computation complexity, but also overcomes the false-positive detection problem.
C1 [Su, Qingtang; Wang, Gang; Zhang, Xiaofeng; Lv, Gaohuan] Ludong Univ, Sch Informat Sci & Engn, Yantai 264025, Shandong, Peoples R China.
   [Chen, Beijing] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Ludong University; Nanjing University of Information Science &
   Technology
RP Su, QT (corresponding author), Ludong Univ, Sch Informat Sci & Engn, Yantai 264025, Shandong, Peoples R China.
EM sdytsqt@163.com
RI Su, Qingtang/P-4285-2017
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology (CICAEET); Natural
   Science Foundation of Shandong Province [ZR2014FM005, ZR2013FL008];
   Shandong Province Higher Educational Science and Technology Program
   [J14N20]; Doctoral Foundation of Ludong University [LY2014034]; Shandong
   Province Science and Technology Plan Projects [2014GGB01944]; Shandong
   Province Important Research Plan Projects [2015GSF116001]
FX The research was partially supported by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET), Natural Science Foundation of Shandong Province
   (ZR2014FM005, ZR2013FL008), Shandong Province Higher Educational Science
   and Technology Program (J14N20), Doctoral Foundation of Ludong
   University (LY2014034), Shandong Province Science and Technology Plan
   Projects (2014GGB01944) and Shandong Province Important Research Plan
   Projects (2015GSF116001). The authors would like to thank anonymous
   referees for their valuable comments and suggestions which lead to
   substantial improvements of this paper.
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   Chou CH, 2003, EURASIP J APPL SIG P, V2003, P32, DOI 10.1155/S1110865703211227
   DEMOOR B, 1992, SIAM J MATRIX ANAL A, V13, P993, DOI 10.1137/0613060
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Kuribayashi M, 2014, IEEE T INF FOREN SEC, V9, P610, DOI 10.1109/TIFS.2014.2305799
   Li XW, 2014, OPT COMMUN, V319, P45, DOI 10.1016/j.optcom.2013.12.089
   Mao L, 2011, MULTIMED TOOLS APPL, V52, P201, DOI 10.1007/s11042-010-0467-5
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Rawat S, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P206, DOI 10.1109/IADCC.2010.5423010
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   University of Granada. Computer Vision Group, 2012, CVG UGR IM DAT
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yin CQ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2607, DOI 10.1109/ICAL.2007.4339020
NR 20
TC 25
Z9 25
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 707
EP 729
DI 10.1007/s11042-015-3071-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000031
DA 2024-07-18
ER

PT J
AU Tazeem, H
   Farid, MS
   Mahmood, A
AF Tazeem, Hadia
   Farid, Muhammad Shahid
   Mahmood, Arif
TI Improving security surveillance by hidden cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security surveillance; Mosaicing; Scene stitching; Global flow;
   Illumination compensation
ID IMAGE; ALGORITHMS; OBJECT
AB Increasing solicitudes about security demand better, robust and effective solutions. Security cameras are playing a vital role in this regard and the surveillance technology is improving rapidly. However, these cameras are usually installed at obvious and visible locations which are often exploitable by the criminals either by hiding themselves from the camera, choosing an alternative path or deceiving the camera. This situation can be overcome to a large extent if the cameras are installed at hidden places looking through narrow regions, e.g. camera fixed inside the building and looking through the window curtain slits. However, this solution poses new challenges in terms of capturing the video through slits and accumulating the information to a meaningful view. In this paper we propose an effective and robust solution to this problem that automatically extracts the slit regions and merges them over a large number of frames to construct a panoramic view. Moreover, such a security surveillance system will be subjected to the sudden illumination variations. We effectively handle such variations by incorporating robustness in the proposed framework. A large number of experiments are performed on various indoor and outdoor real video sequences. The results demonstrate the effectiveness of the proposed framework. Experiments are also performed to objectively assess the perceptual quality of the resulting panoramic images. Our results are even better than the existing commercial software.
C1 [Tazeem, Hadia; Farid, Muhammad Shahid] Punjab Univ, Coll Informat Technol, University, Punjab, Pakistan.
   [Farid, Muhammad Shahid] Univ Turin, Dipartimento Informat, Corso Svizzera 185, I-10149 Turin, Italy.
   [Mahmood, Arif] Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, Australia.
C3 University of Punjab; University of Turin; University of Western
   Australia
RP Farid, MS (corresponding author), Punjab Univ, Coll Informat Technol, University, Punjab, Pakistan.; Farid, MS (corresponding author), Univ Turin, Dipartimento Informat, Corso Svizzera 185, I-10149 Turin, Italy.
EM hadia.tazeem@pucit.edu.pk; farid@di.unito.it; arif.mahmood@uwa.edu.au
RI Mahmood, Arif/R-7949-2019; Farid, Muhammad Shahid/AAF-1825-2019
OI Mahmood, Arif/0000-0001-5986-9876; Farid, Muhammad
   Shahid/0000-0002-8384-2830
CR Aach T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P640, DOI 10.1109/ICIP.2001.958200
   Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   CHANG CH, 2014, PROC CVPR IEEE, P3254, DOI DOI 10.1109/CVPR.2014.422
   Cristofaro A, 2014, IEEE DECIS CONTR P, P2191, DOI 10.1109/CDC.2014.7039723
   Dornaika F, 2012, J OPT SOC AM A, V29, P928, DOI 10.1364/JOSAA.29.000928
   Elibol A, 2014, J OPT SOC AM A, V31, P773, DOI 10.1364/JOSAA.31.000773
   Farid MS, 2014, MULTIMED TOOLS APPL, V71, P1699, DOI 10.1007/s11042-012-1303-x
   Farid MS, 2012, J MATH IMAGING VIS, V42, P50, DOI 10.1007/s10851-011-0273-3
   Fu ZX, 2014, MULTIMED TOOLS APPL, V72, P503, DOI 10.1007/s11042-013-1387-y
   Guizar-Sicairos M, 2008, OPT LETT, V33, P156, DOI 10.1364/OL.33.000156
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hou J, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION WORKSHOP: IITA 2008 WORKSHOPS, PROCEEDINGS, P554, DOI 10.1109/IITA.Workshops.2008.223
   Kosmopoulos DI, 2012, COMPUT VIS IMAGE UND, V116, P422, DOI 10.1016/j.cviu.2011.09.006
   Li B, 2013, OPT EXPRESS, V21, P9824, DOI 10.1364/OE.21.009824
   Li X, 2015, IEEE-ASME T MECH, V20, P1624, DOI 10.1109/TMECH.2014.2364620
   Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314
   Litvinov A, 2005, J OPT SOC AM A, V22, P839, DOI 10.1364/JOSAA.22.000839
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu T, 2014, SENS IMAGING, V15, DOI 10.1007/s11220-014-0101-0
   Monroe D, 2003, US Patent, Patent No. [6,545,601, 6545601]
   Mubasher MM, 2012, 2012 15TH INTERNATIONAL MULTITOPIC CONFERENCE (INMIC), P201, DOI 10.1109/INMIC.2012.6511449
   Ng MK, 2013, SIAM J IMAGING SCI, V6, P1345, DOI 10.1137/120872140
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Prados R, 2014, SPRINGERBRIEF COMPUT, P35, DOI 10.1007/978-3-319-05558-9_3
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Shah M, 2007, IEEE MULTIMEDIA, V14, P30, DOI 10.1109/MMUL.2007.3
   Silva F. A., 2014, Pattern Recognition and Image Analysis, V24, P41, DOI 10.1134/S1054661814010167
   Srikantha A, 2012, SIGNAL PROCESS-IMAGE, V27, P650, DOI 10.1016/j.image.2012.02.001
   Suen STY, 2007, OPT EXPRESS, V15, P7689, DOI 10.1364/OE.15.007689
   Szwed P, 2016, MULTIMED TOOLS APPL, V75, P10667, DOI 10.1007/s11042-014-2047-6
   Uyttendaele M, 2001, PROC CVPR IEEE, P509
   Wang W, 2012, IEEE T IMAGE PROCESS, V21, P1809, DOI 10.1109/TIP.2011.2176952
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu G., 2003, P ACM INT C MULTIMED, P528
   Xu ZZ, 2013, SIGNAL IMAGE VIDEO P, V7, P129, DOI 10.1007/s11760-011-0212-1
   Zagrouba E, 2009, MACH VISION APPL, V20, P139, DOI 10.1007/s00138-007-0114-y
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zeng L, 2014, SIGNAL IMAGE VIDEO P, V8, P1007, DOI 10.1007/s11760-012-0413-2
   Zeng L, 2014, MACH VISION APPL, V25, P1271, DOI 10.1007/s00138-013-0551-8
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 43
TC 3
Z9 4
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2713
EP 2732
DI 10.1007/s11042-016-3260-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000049
DA 2024-07-18
ER

PT J
AU Benini, S
   Svanera, M
   Adami, N
   Leonardi, R
   Kovács, AB
AF Benini, Sergio
   Svanera, Michele
   Adami, Nicola
   Leonardi, Riccardo
   Kovacs, Andras Balint
TI Shot scale distribution in art films
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot scale distribution; Antonioni; Feature extraction; Cognitive
   pattern; Authorship
ID CLASSIFICATION; SHAPE; VIDEO
AB The scale of shot, i.e. the apparent distance of the camera from the main subject of a scene, is one of the main stylistic and narrative functions of audiovisual products, conveying meaning and inducing the viewer's emotional state. The statistical distribution of different shot scales in a film may be an important identifier of an individual film, an individual author, and of various narrative and affective functions of a film. In order to understand at which level shot scale distribution (SSD) of a movie might become its fingerprint, it is necessary to produce automatic recognition of shot scale on a large movie corpus. In our work we propose an automatic framework for estimating the SSD of a movie by using inherent characteristics of shots containing information about camera distance, without the need to recover the 3D structure of the scene. In the experimental investigation, the comparison of obtained results with manual SSD annotations proves the validity of the framework. Experiments conducted on movies by Michelangelo Antonioni taken from different stylistic periods (1950-57, 1960-64, 1966-75, 1980-82) show a strong similarity in shot scale distributions within each period, thus opening interesting research lines regarding the possible aesthetic and cognitive sources of such a regularity.
C1 [Benini, Sergio; Svanera, Michele; Adami, Nicola; Leonardi, Riccardo] Univ Brescia, Dept Informat Engn, Via Branze 38, I-25123 Brescia, Italy.
   [Kovacs, Andras Balint] ELTE Univ, Film Dept, Muzeum Korut 6-8-1088, H-1088 Budapest, Hungary.
C3 University of Brescia; Eotvos Lorand University
RP Svanera, M (corresponding author), Univ Brescia, Dept Informat Engn, Via Branze 38, I-25123 Brescia, Italy.
EM m.svanera005@unibs.it; sergio.benini@unibs.it; nicola.adami@unibs.it;
   riccardo.leonardi@unibs.it; kovacs.andras.balint@btk.elte.hu
RI Svanera, Michele/AAN-7736-2020; Leonardi, Riccardo/F-5666-2010; Kovacs,
   Andras Balint/I-8027-2018
OI Svanera, Michele/0000-0002-7828-9209; Leonardi,
   Riccardo/0000-0003-0755-1924; Kovacs, Andras Balint/0000-0003-3004-2669;
   Adami, Nicola/0000-0002-8879-9456
CR [Anonymous], 1991, Grammar of the film language
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7
   Benini S, 2010, IEEE INT CON MULTI, P855, DOI 10.1109/ICME.2010.5582611
   Bhattacharya S, 2014, IEEE T MULTIMEDIA, V16, P686, DOI 10.1109/TMM.2014.2300833
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brooks M.J., 1989, Shape from Shading, P53
   Canini L, 2013, MULTIMED TOOLS APPL, V62, P51, DOI 10.1007/s11042-011-0916-9
   Cantoni V., 2001, Visual Form 2001. 4th International Workshop on Visual Form IWVF4. Proceedings (Lecture Notes in Computer Science Vol.2059), P135
   Caruana R, 2006, P 23 INT C MACH LEAR, V148, P161, DOI DOI 10.1145/1143844.1143865
   Chatman S, 2008, M ANTONIONI TUTTI FI
   Chen F, 2011, IEEE T MULTIMEDIA, V13, P1381, DOI 10.1109/TMM.2011.2166379
   Cherif I., 2007, 2007 9 INT S SIGN PR, P1
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Criminisi A., 2011, Microsoft Research Cambridge, Tech. Rep. MSRTR-2011-114, V5, P12
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Ekin A, 2003, IEEE IMAGE PROC, P21
   Fan JP, 2004, IEEE T MULTIMEDIA, V6, P70, DOI 10.1109/TMM.2003.819583
   Hoiem D., 2007, SEEING WORLD IMAGE S
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   KELLER JM, 1987, IEEE T PATTERN ANAL, V9, P621, DOI 10.1109/TPAMI.1987.4767956
   Kovács AB, 2014, PROJECTIONS, V8, P50, DOI 10.3167/proj.2014.080204
   KURITA T, 1992, PATTERN RECOGN, V25, P1231, DOI 10.1016/0031-3203(92)90024-D
   Matessi A, 1999, LECT NOTES COMPUT SC, V1685, P987
   McIvor AlanM., 2000, Proc. of Image and Vision Computing, V1, P155
   Nagai T, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P561
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Palmer S.E., 1999, VISION SCI PHOTONS P, V1
   Shimshoni I, 2000, INT J COMPUT VISION, V39, P97, DOI 10.1023/A:1008118909580
   SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983
   Svanera M., 2015, 2015 13th International Workshop on Content-Based Multimedia Indexing (CBMI), P1, DOI DOI 10.1109/CBMI.2015.7153627
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Tsingalis I., 2012, IEEE MED EL C, P104
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang HL, 2009, IEEE T CIRC SYST VID, V19, P1529, DOI 10.1109/TCSVT.2009.2022705
   Xie LX, 2002, INT CONF ACOUST SPEE, P4096
   Xu M, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6116510
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 39
TC 17
Z9 18
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16499
EP 16527
DI 10.1007/s11042-016-3339-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700072
DA 2024-07-18
ER

PT J
AU Chae, SH
   Moon, HM
   Chung, Y
   Shin, J
   Pan, S
AF Chae, Seung-Hoon
   Moon, Hae-Min
   Chung, Yongwha
   Shin, JuHyun
   Pan, Sung Bum
TI Automatic lung segmentation for large-scale medical image management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Large-scale data management; RoI coding; Image
   segmentation; Level-set; Chest CT image; Initial contour
ID SHAPE MODELS; REGION
AB Digital medical images assist specialists in improving their diagnostic efficiency and in treating diseases. For example, the chest Computed Tomography (CT) images help in diagnosing the lung disease. The chest CT scan generates multiple images of a patient's lung. The size of the medical imaging data has increased with the usage of medical images. In a picture archiving and communication system, large-scale medical images must be transmitted to specialists through either wired or wireless communications and retained in the archive. Hence, medical images have to be compressed, and there should be no damage to the Region of Interest (RoI) during compression. In order to protect the RoI, image segmentation is needed to detect RoI in medical images. Among the various image segmentation methods available, the method using Level-set is robust to irregular noises. However, the problems faced in using this method include manual input of the initial contour and slow performance speed. Inputting an initial contour to the Level-set that correctly fits the object's form helps in reducing the number of repetitions. This in turn helps in improving the segmentation performance speed. However, it is difficult for a user to input an appropriate initial contour. Therefore, this paper aims at providing a method to auto-configure the initial contour in the Level-set method. Multi-resolution analysis helps in reducing the pace of the auto-configuration process of the initial contour. In addition, the volume data of a CT image is used to prevent data loss that occurs during the MRA transformation process. Studies have confirmed that the proposed method facilitates drastic improve.
C1 [Chae, Seung-Hoon] Chosun Univ, Res Inst IT, 309 Pilmun Daero, Gwangju 501759, South Korea.
   [Moon, Hae-Min] Chosun Univ, Dept Informat & Commun Engn, 309 Pilmun Daero, Gwangju 501759, South Korea.
   [Chung, Yongwha] Korea Univ, Dept Comp & Informat Sci, Jochiwon Eup, Chungnam 339700, South Korea.
   [Shin, JuHyun] Chosun Univ, Dept Control Instrumentat & Robot Engn, 309 Pilmun Daero, Gwangju 501759, South Korea.
   [Pan, Sung Bum] Chosun Univ, Dept Elect Engn, 309 Pilmun Daero, Gwangju 501759, South Korea.
C3 Chosun University; Chosun University; Korea University; Chosun
   University; Chosun University
RP Pan, S (corresponding author), Chosun Univ, Dept Elect Engn, 309 Pilmun Daero, Gwangju 501759, South Korea.
EM ssuguly@gmail.com; bombilove@gmail.com; ychungy@korea.ac.kr;
   jhshinkr@chosun.ac.kr; sbpan@chosun.ac.kr
RI Shin, Juhyun/ITW-2431-2023
OI Shin, Juhyun/0000-0003-0568-9743; Chae, Seung-Hoon/0000-0002-4115-1345
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2011-0023147]
FX This paper is extended and improved from accepted paper of
   KCIC-2013/FCC-2014 conferences. This research was supported by Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education, Science and Technology
   (2011-0023147).
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Algur SP, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-20
   Annex G., 2011, DICOM STANDARD 5, P101
   Bach PB, 2012, JAMA-J AM MED ASSOC, V307, P2418, DOI 10.1001/jama.2012.5521
   Chen S, 2011, P SPIE 2011, V7964
   Chorianopoulos K, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-10
   Chung Y., 2013, J CONVERG, V4, P23
   Cooper D, 2007, CALCIFIED TISSUE INT, V80, P211, DOI 10.1007/s00223-005-0274-6
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Costaridou L., 2005, MED IMAGE ANAL METHO
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Frangi AF, 2002, IEEE T MED IMAGING, V21, P1151, DOI 10.1109/TMI.2002.804426
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Manh HT, 2013, J INF PROCESS SYST, V9, P592, DOI 10.3745/JIPS.2013.9.4.592
   Kim H.-I., 2013, J. Converg, V4, P23
   Kim SG, 2013, J INF PROCESS SYST, V9, P103
   Lee HR, 2013, J INF PROCESS SYST, V9, P237, DOI 10.3745/JIPS.2013.9.2.237
   Lee M, 2012, COMPUT BIOL MED, V42, P523, DOI 10.1016/j.compbiomed.2012.01.005
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Oosterwijk H, 2004, PACS FUNDAMENTALS
   Rettmann ME, 2008, P SPIE 2008, V6916
   Sethian J., 1999, LEVEL SET METHODS FA
   Tolias YA, 1998, IEEE T SYST MAN CY A, V28, P359, DOI 10.1109/3468.668967
   Verma P, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-21
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wei Q, 2009, IEEE T BIO-MED ENG, V56, P1383, DOI 10.1109/TBME.2009.2014074
   Xu CY, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P104, DOI 10.1109/VLSM.2001.938888
   Yoon M., 2013, J CONVERGENCE, V4, P15
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 31
TC 13
Z9 15
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15347
EP 15363
DI 10.1007/s11042-014-2201-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700015
DA 2024-07-18
ER

PT J
AU Lee, WP
   Tseng, GY
AF Lee, Wei-Po
   Tseng, Guan-Yu
TI Incorporating contextual information and collaborative filtering methods
   for multimedia recommendation in a mobile environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context awareness; Collaborative filtering; Information fusion; Mobile
   multimedia; Recommendation
ID SYSTEMS
AB Recommender systems have been developed in different application services. In addition to using recommendation techniques, it is helpful to employ contextual information in determining the relevance of an item to a users's needs. To enhance recommendation performance, we present in this study two approaches that, in a direct way, integrate different types of contextual information and user ratings in computational methods. To verify the proposed approaches in making collaborative recommendations, we conduct a series of experiments to evaluate performance. The results show that the proposed context-aware methods outperform other conventional approaches. Moreover, we implement a mobile multimedia recommendation system on a cloud platform to demonstrate how our approaches can be used to develop a real-world application.
C1 [Lee, Wei-Po; Tseng, Guan-Yu] Natl Sun Yat Sen Univ, Dept Informat Management, Kaohsiung, Taiwan.
C3 National Sun Yat Sen University
RP Lee, WP (corresponding author), Natl Sun Yat Sen Univ, Dept Informat Management, Kaohsiung, Taiwan.
EM wplee@mail.nsysu.edu.tw
CR Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Agarwal Deepak, 2011, P 17 ACM SIGKDD INT, P609
   [Anonymous], 2014, IEEE T KNOWL DATA EN
   Baltrunas L., 2009, Proceedings of the Third ACM Conference on Recommender Systems, RecSys'09, P245, DOI [DOI 10.1145/1639714.1639759, 10.1145/1639714.1639759]
   Baltrunas L, 2012, PERS UBIQUIT COMPUT, V16, P507, DOI 10.1007/s00779-011-0417-x
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Campos PG, 2014, USER MODEL USER-ADAP, V24, P67, DOI 10.1007/s11257-012-9136-x
   Chen KL, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P661, DOI 10.1145/2348283.2348372
   Cheng ZY, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1267, DOI 10.1145/2600428.2611187
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2925, DOI 10.1007/s11042-013-1582-x
   He Q., 2010, P 19 INT C WORLD WID, P421, DOI [DOI 10.1145/1772690.1772734, 10.1145/1772690.1772734]
   Hong JY, 2009, EXPERT SYST APPL, V36, P8509, DOI 10.1016/j.eswa.2008.10.071
   Karatzoglou Alexandros, 2010, Multiverse recommendation: N-dimensional tensor factorization for context-aware collaborative filtering, P79, DOI DOI 10.1145/1864708.1864727
   Khan WZ, 2013, IEEE COMMUN SURV TUT, V15, P402, DOI 10.1109/SURV.2012.031412.00077
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   Lee WP, 2014, INFORM SCIENCES, V277, P21, DOI 10.1016/j.ins.2014.04.033
   Lee WP, 2014, KNOWL-BASED SYST, V56, P167, DOI 10.1016/j.knosys.2013.11.007
   Leon B, 2008, ADV NEURAL INFORM PR, P161, DOI DOI 10.7751/mitpress/8996.003.0015
   Li B., 2009, P 26 ANN INT C MACH, P617, DOI DOI 10.1145/1553374.1553454
   Liu LW, 2010, IEEE INT C SEMANT CO, P277, DOI 10.1109/ICSC.2010.39
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Nguyen TV, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P63, DOI 10.1145/2600428.2609623
   Pan Weike, 2011, P 22 INT JOINT C ART, P2318
   Panniello U., 2009, Proceedings of the Third ACM Conference on Recommender Systems, RecSys'09, P265, DOI DOI 10.1145/1639714.1639764
   Panniello U, 2014, USER MODEL USER-ADAP, V24, P35, DOI 10.1007/s11257-012-9135-y
   Panniello U, 2012, ELECTRON COMMER RES, V12, P1, DOI 10.1007/s10660-012-9087-7
   Porteous I, 2010, AAAI CONF ARTIF INTE, P563
   Quercia Daniele, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P971, DOI 10.1109/ICDM.2010.152
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Sánchez-Pi N, 2012, KNOWL-BASED SYST, V27, P1, DOI 10.1016/j.knosys.2011.08.017
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Soares M, 2015, MULTIMED TOOLS APPL, V74, P7015, DOI 10.1007/s11042-014-1950-1
   Strobbe M, 2012, IEEE PERVAS COMPUT, V11, P64, DOI 10.1109/MPRV.2011.60
   Su JH, 2010, IEEE INTELL SYST, V25, P16, DOI 10.1109/MIS.2010.23
   Xiong L, 2010, P SIAM INT C DAT MIN, P211, DOI DOI 10.1137/1.9781611972801.19
   Zhong E., 2012, SDM'12, P744
NR 43
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16719
EP 16739
DI 10.1007/s11042-015-2915-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600001
DA 2024-07-18
ER

PT J
AU Liu, SW
   Hu, JL
AF Liu, Shangwang
   Hu, Jianlan
TI Visual saliency based on frequency domain analysis and spatial
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Frequency domain analysis; HFT; Spatial information;
   Contrast function
AB Saliency detection plays an important role in computer vision field. In this paper, a saliency detection model for images is proposed based on frequency domain analysis and spatial information. Saliency is detected in the proposed model via the following main steps: coefficients of the input hyper complex image are designed in Hyper Complex Fourier Transform (HFT); then, during the analysis of the spectrum scale space in frequency domain, a series of saliency maps at different scales are obtained; finally, considering spatial relationship, the spatial contrast function is taken for selecting the optimal saliency map. Experimental results show that the proposed model can achieve high performance in terms of the average AUC and F-measure evaluation metrics and outperform state-of-the-art baselines.
C1 [Liu, Shangwang; Hu, Jianlan] Henan Normal Univ, Coll Comp & Informat Engn, 46 East Jianshe Rd, Xinxiang 453007, Henan Province, Peoples R China.
   [Liu, Shangwang; Hu, Jianlan] Engn Lab Intelligence Business & Internet Things, Xinxiang, Henan Province, Peoples R China.
C3 Henan Normal University
RP Liu, SW (corresponding author), Henan Normal Univ, Coll Comp & Informat Engn, 46 East Jianshe Rd, Xinxiang 453007, Henan Province, Peoples R China.; Liu, SW (corresponding author), Engn Lab Intelligence Business & Internet Things, Xinxiang, Henan Province, Peoples R China.
EM shwl2012@hotmail.com
FU National Natural Science Foundation of China [U1304607, U1404603]; Key
   Scientific Research Project of Higher School of Henan Province
   [15A520080]; Dr. Startup Project of Henan Normal University [qd12138]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. U1304607 and U1404603, the Key Scientific Research
   Project of Higher School of Henan Province under Grant No. 15A520080 and
   the Dr. Startup Project of Henan Normal University under Grant No.
   qd12138.
CR Achanta R., 2008, INT C COMP VIS SYST
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Arya R, 2016, MULTIMED TOOLS APPL, V75, P8267, DOI 10.1007/s11042-015-2750-y
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Jin ZL, 2015, ELECTRON LETT, V51, P628, DOI 10.1049/el.2014.4316
   Kong XW, 2014, MECH MACH THEORY, V74, P188, DOI 10.1016/j.mechmachtheory.2013.12.010
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liang ZJ, 2014, MULTIMED TOOLS APPL, V68, P517, DOI 10.1007/s11042-012-1040-1
   López-Rubio E, 2015, INFORM SCIENCES, V298, P136, DOI 10.1016/j.ins.2014.12.014
   Omari M, 2015, MULTIMED TOOLS APPL, V74, P8685, DOI 10.1007/s11042-014-2353-z
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Thangaraju J, 2015, INT J APPL ENG RES, V10, P17325
   Wu B, 2014, MULTIMED TOOLS APPL, V73, P1053, DOI 10.1007/s11042-013-1530-9
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yao ZT, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ARTIFICIAL INTELLIGENCE (CAAI 2015), P1, DOI 10.1109/PESGM.2015.7285696
   Zhang Y, 2016, FUTUR GENER COMPUT S
NR 20
TC 4
Z9 4
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16699
EP 16711
DI 10.1007/s11042-016-3903-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700081
DA 2024-07-18
ER

PT J
AU Chen, YH
   Huang, HC
   Lin, CC
AF Chen, Yueh-Hong
   Huang, Hsiang-Cheh
   Lin, Chuan-Chang
TI Block-based reversible data hiding with multi-round estimation and
   difference alteration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Difference histogram; Prediction; Image quality;
   Capacity
ID HISTOGRAM-MODIFICATION; WATERMARKING; EXPANSION; PREDICTION
AB In this paper, we propose a new algorithm in reversible data hiding, with the characteristics of ease of implementation, based on the alteration of difference values relating to original image. Three major categories can make reversible data hiding possible, one is to modify the histogram of original images, the second is to alter the difference between neighboring pixels, and the third is to apply prediction method to modify the difference between original and predicted pixels. By integrating the advantages from the these categories, and by extending the flexibility to acquire the difference values for data hiding, we employ the block-based, multi-round prediction to look for enhanced performances. Simulations with conventional and medical images have presented the superiority with our algorithm over existing ones in literature. With our algorithm, enhanced amount of capacity, in addition to the better image quality, and most important of all, the reversibility of algorithm, can be reached. It is also famous for its ease of implementation for medical applications in hospitals.
C1 [Chen, Yueh-Hong] Far East Univ, 49 Zhonghua Rd, Tainan 74448, Taiwan.
   [Huang, Hsiang-Cheh; Lin, Chuan-Chang] Natl Univ Kaohsiung, 700 Univ Rd, Kaohsiung 81148, Taiwan.
C3 National University Kaohsiung
RP Huang, HC (corresponding author), Natl Univ Kaohsiung, 700 Univ Rd, Kaohsiung 81148, Taiwan.
EM yuehhong@gmail.com; huang.hc@gmail.com
FU Ministry of Science and Technology of Taiwan, R.O.C.
   [NSC102-2220-E-390-002, MOST103-2221-E-390-018, MOST104-2221-E-390-012]
FX This work is supported in part by Ministry of Science and Technology
   (formerly National Science Council) of Taiwan, R.O.C., under grants
   NSC102-2220-E-390-002, MOST103-2221-E-390-018, and
   MOST104-2221-E-390-012.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chen CC, 2011, J SYST SOFTWARE, V84, P428, DOI 10.1016/j.jss.2010.11.891
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P513, DOI 10.1007/s11042-010-0486-2
   Hsu FH, 2013, MULTIMED TOOLS APPL, V67, P571, DOI 10.1007/s11042-012-1047-7
   Huang HC, 2013, INFORMATION, V16, P6069
   Huang HC, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P13, DOI 10.1109/IIH-MSP.2013.12
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Huang HC, 2010, TELECOMMUN SYST, V44, P241, DOI 10.1007/s11235-009-9262-x
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lee CP, 2015, J TISSUE ENG, V6, DOI 10.1177/2041731415586318
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Luo H, 2014, SIGNAL IMAGE VIDEO P, V8, P813, DOI 10.1007/s11760-012-0306-4
   Marin J., 2014, J INFORM HIDING MULT, V5, P451
   Mihara T, 2014, J INF HIDING MULTIME, V5, P117
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Qin C, 2012, FUND INFORM, V120, P59, DOI 10.3233/FI-2012-749
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
NR 28
TC 17
Z9 18
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13679
EP 13704
DI 10.1007/s11042-015-2825-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800036
DA 2024-07-18
ER

PT J
AU Jiang, DD
   Shi, L
   Zhang, P
   Ge, XZ
AF Jiang, Dingde
   Shi, Lei
   Zhang, Peng
   Ge, Xiongzi
TI QoS constraints-based energy-efficient model in cloud computing networks
   for multimedia clinical issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy efficiency; Cloud computing; Modeling; Constraint optimization;
   Multimedia medical devices
ID ROUTING ALGORITHM; POWER; SYSTEMS
AB For many applications of multimedia medical devices in clinical and medical issues, cloud computing becomes a very useful way. However, high energy consumption of cloud computing networks for these applications brings forth a large challenge. This paper studies the energy-efficient problem with QoS constraints in large-scale cloud computing networks. We use the sleeping and rate scaling mechanism to propose a link energy consumption model to characterize the network energy consumption. If there is no traffic on a link, we will let it be sleeping. Otherwise, it is activated and we divide its energy consumption into base energy consumption and traffic energy consumption. The former describes the constant energy consumption that exists when the link runs, while the later, which is a quadratic function with respect to the traffic, indicates the relations between link energy consumption and the traffic on the link. Then considering the relation among network energy consumption, number of active links, and QoS constraints, we build the multi-constrained energy efficient model to overcome the high energy consumption in large-scale cloud computing networks. Finally, we exploit the NSF and GEANT network topology to validate our model. Simulation results show that our approach can significantly improve energy efficiency of cloud computing networks.
C1 [Jiang, Dingde; Zhang, Peng] Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110016, Peoples R China.
   [Shi, Lei] Waterford Inst Technol, TSSG, Waterford X91P20H, Ireland.
   [Ge, Xiongzi] Univ Minnesota, Dept Comp Sci & Engn, St Paul, MN 55455 USA.
C3 Northeastern University - China; South East Technological University
   (SETU); University of Minnesota System; University of Minnesota Twin
   Cities
RP Jiang, DD (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110016, Peoples R China.
EM jiangdingde@ise.neu.edu.cn
RI Shi, Lei/T-7301-2019
OI Shi, Lei/0000-0001-7119-3207
FU National Natural Science Foundation of China [61571104, 61071124];
   General Project of Scientific Research of the Education Department of
   Liaoning Province [L20150174]; Program for New Century Excellent Talents
   in University [NCET-11-0075]; Fundamental Research Funds for the Central
   Universities [N120804004, N130504003]; State Scholarship Fund
   [201208210013]
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos. 61571104, 61071124), the General Project of
   Scientific Research of the Education Department of Liaoning Province
   (No. L20150174), the Program for New Century Excellent Talents in
   University (No. NCET-11-0075), the Fundamental Research Funds for the
   Central Universities (Nos. N120804004, N130504003), and the State
   Scholarship Fund (201208210013). The authors wish to thank the reviewers
   for their helpful comments.
CR Andrews M., 2010, INFOCOM IEEE C COMPU, P1
   [Anonymous], P CCGC 12
   [Anonymous], P ECDC 14
   [Anonymous], P ICC 12
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], CHAOS SOLITONS FRACT
   [Anonymous], TELECOMMUNICATION SY
   [Anonymous], IEEE NETWOR IN PRESS
   Antonakopoulos S, 2010, IEEE GLOBE WORK, P1428, DOI 10.1109/GLOCOMW.2010.5700173
   Beloglazov A, 2015, CONCURR COMP-PRACT E, V27, P1310, DOI 10.1002/cpe.3314
   Bolla R, 2009, 2ND ACM SIGCOMM WORKSHOP ON PROGRAMMABLE ROUTERS FOR EXTENSIBLE SERVICES OF TOMORROW - PRESTO 09, P49
   Chiaraviglio L, 2009, PROC ICC 2009, P1
   Chiaraviglio L, 2012, IEEE ACM T NETWORK, V20, P463, DOI 10.1109/TNET.2011.2161487
   Cianfrani A, 2010, INFOCOM IEEE C COM C, P1
   Dabbagh M, 2015, IEEE NETWORK, V29, P56, DOI 10.1109/MNET.2015.7064904
   Dinh HT, 2013, WIREL COMMUN MOB COM, V13, P1587, DOI 10.1002/wcm.1203
   Gattulli M, 2014, IEEE J SEL AREA COMM, V32, P28, DOI 10.1109/JSAC.2014.140104
   Ge XH, 2014, IEEE T VEH TECHNOL, V63, P2127, DOI 10.1109/TVT.2014.2310773
   Guo CX, 2015, DISCRETE CONT DYN-S, V8, P1139, DOI 10.3934/dcdss.2015.8.1139
   Han Qi, 2012, 2012 Second International Conference on Digital Information and Communication Technology and it's Applications (DICTAP), P195, DOI 10.1109/DICTAP.2012.6215350
   Jiang DD, 2015, J NETW COMPUT APPL, V57, P182, DOI 10.1016/j.jnca.2015.06.010
   Jiang DD, 2015, COMPUT NETW, V84, P1, DOI 10.1016/j.comnet.2015.04.003
   Jiang DD, 2015, J SYST SOFTWARE, V104, P152, DOI 10.1016/j.jss.2015.03.006
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Kim Y, 2012, J LIGHTWAVE TECHNOL, V30, P2088, DOI 10.1109/JLT.2012.2192098
   Lange C, 2014, 2014 INTERNATIONAL CONFERENCE ON OPTICAL NETWORK DESIGN AND MODELING, P96
   Lian SG, 2015, TELECOMMUN SYST, V59, P289, DOI 10.1007/s11235-014-9935-y
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Marnerides AK, 2013, IEEE GLOBE WORK, P482, DOI 10.1109/GLOCOMW.2013.6825034
   Mastelic T, 2015, IEEE CLOUD COMPUT, V2, P40, DOI 10.1109/MCC.2015.15
   Moreno-Vozmediano R, 2013, IEEE INTERNET COMPUT, V17, P18, DOI 10.1109/MIC.2012.69
   Pickavet M, 2008, INT SYMP ADV NETW, P1
   Sanaei Z, 2014, IEEE COMMUN SURV TUT, V16, P369, DOI 10.1109/SURV.2013.050113.00090
   Sheng G, 2015, COMM COM INF SC, V557, P280, DOI 10.1007/978-3-662-48683-2_25
   Shu WN, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-64
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Wang C, 2012, IEEE T SERV COMPUT, V5, P220, DOI 10.1109/TSC.2011.24
   Wang K, 2015, IEEE INT C CL COMP, P236, DOI 10.1109/CLUSTER.2015.42
   Wang Y, 2015, PROC 27 INT C SCI ST, P1
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang JC, 2015, SENSORS-BASEL, V15, P29535, DOI 10.3390/s151129535
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Zhang XL, 2015, LECT NOTES COMPUT SC, V9492, P647, DOI 10.1007/978-3-319-26561-2_76
   Zhou HB, 2014, IEEE T INTELL TRANSP, V15, P2644, DOI 10.1109/TITS.2014.2321293
NR 48
TC 15
Z9 15
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14307
EP 14328
DI 10.1007/s11042-015-3239-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500018
DA 2024-07-18
ER

PT J
AU Ma, YJ
   Zhang, Y
   Sheng, ZG
   Ruan, H
   Wang, JF
   Sun, YM
AF Ma, Yujun
   Zhang, Yin
   Sheng, Zhengguo
   Ruan, Hang
   Wang, Junfeng
   Sun, Yanming
TI CGMP: cloud-assisted green multimedia processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile cloud computing; Multimedia processing; Principal component
   analysis; Nearest neighbor classifier
ID BIG DATA; MOBILE; SYSTEMS
AB With continued advancements of mobile computing and communications, emerging novel multimedia services and applications have attracted lots of attention and been developed for mobile users, such as mobile social network, mobile cloud medical treatment, mobile cloud game. However, because of limited resources on mobile terminals, it is of great challenge to improve the energy efficiency of multimedia services. In this paper, we propose a cloud-assisted green multimedia processing architecture (CGMP) based on mobile cloud computing. Specifically, the tasks of multimedia processing with energy-extensive consumption can be offloaded to the cloud, and the face recognition algorithm with improved principal component analysis and nearest neighbor classifier is realized on CGMP based cloud platform. Experimental results show that the proposed scheme can effectively save the energy consumption of the equipment.
C1 [Ma, Yujun; Ruan, Hang; Wang, Junfeng; Sun, Yanming] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Ma, Yujun] Nanyang Inst Technol, Comp Network Ctr, Nanyang, Peoples R China.
   [Zhang, Yin] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan, Peoples R China.
   [Sheng, Zhengguo] Univ Sussex, Sch Engn & Informat, Brighton, E Sussex, England.
C3 Huazhong University of Science & Technology; Nanyang Institute of
   Technology; Zhongnan University of Economics & Law; University of Sussex
RP Sun, YM (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM yujun.hust@gmail.com; yin.zhang.cn@ieee.org; z.sheng@sussex.ac.uk;
   hangruan.hust@gmail.com; junfengwang.cs@gmail.com;
   yanming.epic@gmail.com
RI Zhang, Yin/O-2149-2015; Ma, Yujun/G-8818-2016; Zhang, Yin/K-2414-2019
OI Zhang, Yin/0000-0002-1772-0763; Ma, Yujun/0000-0003-2733-8813; Zhang,
   Yin/0000-0002-8103-8937
FU national nature science foundation of China [2011CB302505, 61103234];
   Guangdong Foundation [201001D0104726115]; Henan province science and
   technology research projects [142102210602]
FX This work was supported by the national nature science foundation of
   China under grant No. 2011CB302505 and 61103234, Guangdong Foundation
   Team Grant No. 201001D0104726115, and Henan province science and
   technology research projects No. 142102210602.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Abolfazli S, 2014, IEEE COMMUN SURV TUT, V16, P337, DOI 10.1109/SURV.2013.070813.00285
   Bo Dong, 2010, 2010 IEEE 7th International Conference on Services Computing (SCC 2010), P65, DOI 10.1109/SCC.2010.72
   Borthakur D., 2008, HADOOP APACHE PROJECT
   Chen M, 2015, ACM MOBIHOC
   Chen M, 2015, MOBILE NETW APPL, V20, P704, DOI 10.1007/s11036-015-0590-7
   Chen M, 2015, IEEE COMMUN MAG, V53, P18, DOI 10.1109/MCOM.2015.7120041
   Chen M, 2015, IEEE NETWORK, V29, P32, DOI 10.1109/MNET.2015.7064900
   Chen M, 2015, IEEE WIREL COMMUN, V22, P20, DOI 10.1109/MWC.2015.7054715
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Chen M, 2013, COMPUT J, V56, P923, DOI 10.1093/comjnl/bxt051
   Chen M, 2012, INT J AD HOC UBIQ CO, V9, P95, DOI 10.1504/IJAHUC.2012.045551
   Chen Min, 2014, Big Data: Related Technologies, Challenges and Future Prospects
   Chen MJ, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-3
   Garage Willow, 2011, OPENCV OPEN SOURCE C
   Ge XH, 2014, IEEE NETWORK, V28, P6, DOI 10.1109/MNET.2014.6963798
   Ge XH, 2014, IEEE T VEH TECHNOL, V63, P2127, DOI 10.1109/TVT.2014.2310773
   Hu H., 2014, MULTISCREEN SOCIAL T, P1
   Hu H, 2014, IEEE ACCESS, V2, P652, DOI 10.1109/ACCESS.2014.2332453
   Hu SM, 2013, VISUAL COMPUT, V29, P393, DOI 10.1007/s00371-013-0792-6
   Jifang Pei, 2013, 2013 10th International Conference on Communications, Circuits and Systems (ICCCAS), P267, DOI 10.1109/ICCCAS.2013.6765230
   Jing Zhang, 2010, Proceedings 2010 5th International Conference on Pervasive Computing and Applications (ICPCA 2010), P93, DOI 10.1109/ICPCA.2010.5704081
   Kumar K, 2010, COMPUTER, V43, P51, DOI 10.1109/MC.2010.98
   Lei L, 2013, IEEE WIREL COMMUN, V20, P34, DOI 10.1109/MWC.2013.6549281
   Shah JH, 2013, INT ARAB J INF TECHN, V10, P536
   Sonka M, 2008, TECH REP
   University C, 2002, ORL DAT FAC
   Wen YG, 2014, IEEE T MULTIMEDIA, V16, P885, DOI 10.1109/TMM.2014.2315596
   White T., 2012, HADOOP DEFINITIVE GU
   Wiley K, 2011, PUBL ASTRON SOC PAC, V123, P366, DOI 10.1086/658877
   Wu D, 2013, EEE COMSOC MMTC E, V8, P19
   Wu D, 2014, IEEE T CIRC SYST VID, V24, P1405, DOI 10.1109/TCSVT.2014.2302543
   Zhang WW, 2013, IEEE T WIREL COMMUN, V12, P4569, DOI 10.1109/TWC.2013.072513.121842
   Zheng K, 2015, IEEE WIREL COMMUN, V22, P70, DOI 10.1109/MWC.2015.7054721
NR 34
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13317
EP 13332
DI 10.1007/s11042-015-2783-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800019
DA 2024-07-18
ER

PT J
AU Niitsuma, Y
   Torii, S
   Yaguchi, Y
   Oka, R
AF Niitsuma, Yuki
   Torii, Syunpei
   Yaguchi, Yuichi
   Oka, Ryuichi
TI Time-segmentation and position-free recognition of air-drawn gestures
   and characters in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Segmentation-free recognition; Position-free
   recognition; Moving camera; Dynamic programming
AB We report the recognition in video streams of isolated alphabetic characters and connected cursive textual characters, such as alphabetic, hiragana and kanji characters, that are drawn in the air. This topic involves a number of difficult problems in computer vision, such as the segmentation and recognition of complex motion on videos. We use an algorithm called time-space continuous dynamic programming (TSCDP), which can realize both time- and location-free (spotting) recognition. Spotting means that the prior segmentation of input video is not required. Each reference (model) character is represented by a single stroke that is composed of pixels. We conducted two experiments involving the recognition of 26 isolated alphabetic characters and 23 Japanese hiragana and kanji air-drawn characters. We also conducted gesture recognition experiments based on TSCDP, which showed that TSCDP was free from many of the restrictions imposed by conventional methods.
C1 [Niitsuma, Yuki; Torii, Syunpei; Yaguchi, Yuichi; Oka, Ryuichi] Turuga Ikkichimachi, Aizu Wakamatsu, Fukushima, Japan.
   [Yaguchi, Yuichi] Univ Aizu, Aizu Wakamatsu, Fukushima, Japan.
   [Oka, Ryuichi] Minist & Ind & Trade, Electrotech Lab, Aizu Wakamatsu, Fukushima, Japan.
C3 University of Aizu
RP Oka, R (corresponding author), Turuga Ikkichimachi, Aizu Wakamatsu, Fukushima, Japan.
EM wega315@gmail.com; peso0217@gmail.com; yaguchi@u-aizu.ac.jp;
   oka@u-aizu.ac.jp
OI Yaguchi, Yuichi/0000-0003-4929-4364
CR Alon J., 2006, THESIS
   Baumann F., 2014, 3 INT C PATT REC APP
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Ezaki N, 2010, CHARACTER RECOGNITIO, P1094
   Gao W, 2000, INT J PATTERN RECOGN, V14, P587, DOI 10.1142/S0218001400000386
   Horo T, 2006, WORKSH INT SYST SOFT
   Kölsch M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P614, DOI 10.1109/AFGR.2004.1301601
   Laptev I., 2004, Local Spatio-Temporal Image Features for Motion Interpretation
   Nakai M., 2009, AERIAL HANDWRITTEN C, P133
   Oka R, 1998, COMPUT J, V41, P559, DOI 10.1093/comjnl/41.8.559
   Oka R, 2012, JOINT TECHNICAL M IN, V27, P873
   Okada T, 2003, INFORM COMMUNICATION, V7, P1015
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Sato A, 2010, SIGN LANGUAGE RECOGN, pIS3
   Sclaro S, 2005, ICDAR INT C DOC AN R
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
NR 16
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11615
EP 11639
DI 10.1007/s11042-015-2669-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200003
DA 2024-07-18
ER

PT J
AU Wang, SK
   Chen, L
   Zhou, ZX
   Sun, X
   Dong, JY
AF Wang, Shengke
   Chen, Long
   Zhou, Zixi
   Sun, Xin
   Dong, Junyu
TI Human fall detection in surveillance video based on PCANet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall detection; PCA Net; Behavior analysis; Patient monitoring; Visual
   surveillance
ID ALGORITHM
AB Fall incidents have been reported as the second most common cause of death, especially for elderly people. Human fall detection is necessary in smart home healthcare systems. Recently various fall detection approaches have been proposed., among which computer vision based approaches offer a promising and effective way. In this paper, we proposed a new framework for fall detection based on automatic feature learning methods. First, the extracted frames, including human from video sequences of different views, form the training set. Then, a PCANet model is trained by using all samples to predict the label of every frame. Because a fall behavior is contained in many continuous frames, the reliable fall detection should not only analyze one frame but also a video sequence. Based on the prediction result of the trained PCANet model for each frame, an action model is further obtained by SVM with the predicted labels of frames in video sequences. Experiments show that the proposed method achieved reliable results compared with other commonly used methods based on the multiple cameras fall dataset, and a better result is further achieved in our dataset which contains more training samples.
C1 [Wang, Shengke] Ocean Univ China, Comp Sci & Technol Dept, Qingdao, Peoples R China.
   [Chen, Long] Ocean Univ China, Vis Lab, Comp Architecture, Qingdao, Peoples R China.
   [Zhou, Zixi] Ocean Univ China, Vis Lab, Software Engn, Qingdao, Peoples R China.
   [Sun, Xin] Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
   [Dong, Junyu] Ocean Univ China, Qingdao, Peoples R China.
C3 Ocean University of China; Ocean University of China; Ocean University
   of China; Ocean University of China; Ocean University of China
RP Dong, JY (corresponding author), Ocean Univ China, Qingdao, Peoples R China.
EM dongjunyu@ouc.edu.cn
RI Sun, Xin/ADH-1623-2022
OI Sun, Xin/0000-0003-1870-9037; Dong, Junyu/0000-0001-7012-2087
FU National Natural Science Foundation of China (NSFC) [61301241, 61401413,
   61403353, 61271405]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) Grants 61301241, 61401413, 61403353 and 61271405.
CR Alwan M., 2006, Information and Communication Technologies
   [Anonymous], 2014, ARXIV14043606
   [Anonymous], SIGNAL IMAGE VIDEO P
   Auvinet E., 2010, Multiple cameras fall dataset
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bourke AK, 2008, MED ENG PHYS, V30, P84, DOI 10.1016/j.medengphy.2006.12.001
   Cetin A, 2013, SIGN PROC COMM APPL
   Chen Y-T, 2010, IM PROC ICIP 2010 17
   Hausdorff JM, 2001, ARCH PHYS MED REHAB, V82, P1050, DOI 10.1053/apmr.2001.24893
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kangas M, 2008, GAIT POSTURE, V28, P285, DOI 10.1016/j.gaitpost.2008.01.003
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Nguyen T-T, 2009, ENG MED BIOL SOC 200
   Rougier C, 2007, ADV INF NETW APPL WO
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   TAO J, 2005, INF COMM SIGN PROC 2
   Vishwakarma V, 2007, LECT NOTES COMPUT SC, V4815, P616
   WILD D, 1981, BMJ-BRIT MED J, V282, P266, DOI 10.1136/bmj.282.6260.266
   Williams A., 2007, P 15 INT C MULT
   Yazar A, 2013, PATTERN RECOGN LETT, V34, P1945, DOI 10.1016/j.patrec.2012.12.010
   Yu X, 2008, E HLTH NETW APPL SER
   Zambanini S, 2010, INF TECHN APPL BIOM
NR 23
TC 81
Z9 87
U1 1
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11603
EP 11613
DI 10.1007/s11042-015-2698-y
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200002
DA 2024-07-18
ER

PT J
AU Zhai, B
   Zheng, J
   Li, B
AF Zhai, Bo
   Zheng, Jin
   Li, Bo
TI Digital image stabilization based on adaptive motion filtering with
   feedback correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online digital image stabilization; Motion filtering; Kalman filter;
   Feedback correction; Objective evaluation
ID STRUCTURAL DESCRIPTION TECHNOLOGY; CONTENT-PRESERVING WARPS; 3D VIDEO
   STABILIZATION; KALMAN FILTER; CAMERA MOTION; BIG DATA
AB For online digital image stabilization system, the camera usually moves with diverse and variable modes, which make the motion filtering process difficult to reserve the intentional fluctuations and remove unwanted jitters simultaneously. This paper presents an adaptive motion filtering algorithm with feedback correction. Firstly, based on the low frequency character of intentional motion in adjacent frames, the intentional velocity is regarded as the control variable, thus the modified one dimension Kalman filtering algorithm is proved to converge to a balance state of consistency and stabilization. Secondly, according to the mutual restraint of consistency and stabilization, this paper proposes two corresponding online feedback factors to reflect the immediate filtering performances. Hence, a motion filtering algorithm with improved Kalman filtering and parameter self-adjustment is realized, which can describe the real camera motion flexibly, as well as adapt to its changes. At last, an objective evaluation method for motion filtering is presented from the aspects of integral consistency, integral stabilization and integral robustness. Compared with other classical motion filtering algorithms, experimental results indicate that the proposed algorithm is more fast-computing and adaptive for different moving modes of the camera, which can reserve the intentional motions and remove the jitters steadily.
C1 [Zhai, Bo; Zheng, Jin; Li, Bo] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zheng, Jin; Li, Bo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zheng, J (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.; Zheng, J (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM bozhai@buaa.edu.cn; JinZheng@buaa.edu.cn; boli@buaa.edu.cn
RI Li, Bo/AAA-8968-2020; Li, bo/IWL-9318-2023
OI Li, Bo/0000-0002-7294-6888; 
FU National Science Foundation of China [61370124]; National Science
   Foundation of China for Distinguished Young Scholars [61125206]; China
   863 Program [2014AA015104]; China Scholarship Foundation [201303070205]
FX The authors would like to thank all the anonymous reviewers for their
   helpful comments and suggestions. This work is supported by the National
   Science Foundation of China (No. 61370124), the National Science
   Foundation of China for Distinguished Young Scholars (No. 61125206), the
   China 863 Program (Project No. 2014AA015104) and China Scholarship
   Foundation (No. 201303070205).
CR Aguilar WG, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-46
   Ahlem W, 2014, SPRINGER MULTIMED TO, V74, P6745
   Amanatiadis A., 2007, IEEE INT WORKSH IM S, P1
   Dong J, 2014, SPIE J ELECT IMAGING, V23
   Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Kim SW, 2014, COMPUT VIS IMAGE UND, V118, P71, DOI 10.1016/j.cviu.2013.09.005
   Kumar S, 2011, IEEE T IMAGE PROCESS, V20, P3406, DOI 10.1109/TIP.2011.2156420
   Kwon O, 2005, LECT NOTES COMPUT SC, V3656, P141, DOI 10.1007/11559573_18
   Lamza A, 2012, COMM COM INF SC, V287, P180
   Lee TH, 2014, J VIS COMMUN IMAGE R, V25, P943, DOI 10.1016/j.jvcir.2014.02.011
   Litvin A, 2003, PROC SPIE, V5022, P663, DOI 10.1117/12.476436
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Monteiro E., 2011, 2011 Proceedings of 23rd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD 2011), P128, DOI 10.1109/SBAC-PAD.2011.19
   Okade M, 2014, MULTIMED TOOLS APPL, V68, P947, DOI 10.1007/s11042-012-1095-z
   Or EM, 2007, IEEE T CONSUM ELECTR, V53, P1508, DOI 10.1109/TCE.2007.4429245
   Qu H, 2013, IEEE IMAGE PROC, P29, DOI 10.1109/ICIP.2013.6738007
   Ryu YG, 2012, IEEE SIGNAL PROC LET, V19, P223, DOI 10.1109/LSP.2012.2188286
   Saini M, 2014, MULTIMED TOOLS APPL, V68, P135, DOI 10.1007/s11042-012-1207-9
   Schwertfeger S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P61, DOI 10.1109/SSRR.2011.6106770
   Song CH, 2012, IEEE T CONSUM ELECTR, V58, P570, DOI 10.1109/TCE.2012.6227462
   Tanakian MJ, 2011, 2011 1ST INTERNATIONAL ECONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P126, DOI 10.1109/ICCKE.2011.6413338
   Tsai TH, 2012, IEEE T CIRC SYST VID, V22, P817, DOI 10.1109/TCSVT.2011.2177179
   VASILEIOS M, 2013, SPRINGER MULTIMED TO, V70, P1
   Wang CT, 2009, IEEE T CONSUM ELECTR, V55, P6, DOI 10.1109/TCE.2009.4814407
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Yang JL, 2009, IEEE T CIRC SYST VID, V19, P945, DOI 10.1109/TCSVT.2009.2020252
   Zhou ZH, 2013, PROC CVPR IEEE, P2299, DOI 10.1109/CVPR.2013.298
NR 30
TC 7
Z9 7
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12173
EP 12200
DI 10.1007/s11042-015-3183-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200033
DA 2024-07-18
ER

PT J
AU Correia, JMC
   Gomes, AJP
AF Correia, Joao M. C.
   Gomes, Abel J. P.
TI Balloon extraction from complex comic books using edge detection and
   histogram scoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sobel operator; Enhanced region fill; Histogram; Comic book; Balloon
   extraction; Text extraction
AB Extracting balloons has been a challenge in digital comics, in particular for complex comic books. In fact, current algorithms are seemingly adequate for simple comics, but not for complex ones. This paper proposes an algorithm based on the Sobel operator plus a modified flood fill operator to identify and extract balloons in comic book pages. Unlike other approaches, our algorithm applies to any sort of comics, no matter they are simple or complex comics, without making any assumptions regarding the line continuity of the image, color depth of the image, orientation of the text, and language. Experimental results show that our algorithm significantly improves the rate of correctly detected balloons, and simultaneously decreases the number of false positives, when compared to other algorithms.
C1 [Correia, Joao M. C.; Gomes, Abel J. P.] Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
C3 Universidade da Beira Interior
RP Gomes, AJP (corresponding author), Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
EM joaomiguelcorreia@gmail.com; agomes@di.ubi.pt
RI Gomes, Abel/H-9602-2014
OI Gomes, Abel/0000-0002-5804-5717
FU FCT project [UID/EEA/50008/2013]
FX The authors are very grateful to reviewers for their valuable questions
   and suggestions that contributed to significantly improve the paper.
   This work was supported by FCT project UID/EEA/50008/2013.
CR Anh Khoi Ngo Ho, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P424, DOI 10.1109/DAS.2012.66
   Arai K., 2011, INT J IMAGE PROCESSI, V4, P669
   Brahma S, 2006, TEXT EXTRACTION USIN
   Byrne J, 1984, ALPHA FLIGHT MARVEL, V1
   Cao RN, 2001, PROC INT CONF DOC, P44, DOI 10.1109/ICDAR.2001.953752
   Eisner Will, 1985, Comics and Sequential Art: Principles and Practices from the Legendary Cartoonist
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   Grover S, 2009, IND C INDICON, P1
   Guo Q, 2006, ACM SIGGRAPH RES SIG
   Hoashi Keiichiro, 2011, P 19 ACM INT C MULT, P1489
   Hunt R., 1987, REPROD COLOUR PHOTOG
   ITU-R, 2011, REC IT R BT 601 7
   McCloud S., 1994, Understanding Comics: The Invisible Art
   Praneesh M, 2012, INT J COMPUT APPL IP, V1, P16
   Rigaud C, 2012, EXTRACTION ROBUSTE C
   Slott D, 2011, MARVEL COMICS, V1
   Sushma J, 2009, P INT C INT AG MULT, P1
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yuan Q, 2001, PROC INT CONF DOC, P302, DOI 10.1109/ICDAR.2001.953803
NR 19
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11367
EP 11390
DI 10.1007/s11042-015-2858-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900025
DA 2024-07-18
ER

PT J
AU Geng, P
   Huang, M
   Liu, SQ
   Feng, J
   Bao, PN
AF Geng, Peng
   Huang, Min
   Liu, Shuaiqi
   Feng, Jun
   Bao, Peina
TI Multifocus image fusion method of Ripplet transform based on cycle
   spinning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ripplet transform; Cycle spinning; Image fusion
ID CONTOURLET TRANSFORM; PERFORMANCE
AB The curvelet transform can represent images at both different scales and different directions. Ripplet transform, as a higher dimensional generalization of the curvelet transform, provides a new tight frame with sparse representation for images with discontinuities along C-2 curves. However, the ripplet transform is lack of translation invariance, which causes the pseudo-Gibbs phenomenon on the edges of image. In this paper, the cycle spinning method is adopted to suppress the pseudo-Gibbs phenomena in the multifocus image fusion. On the other hand, a modified sum-modified-laplacian rule based on the threshold is proposed to make the decision map to select the ripplet coefficient. Several experiments are executed to compare the presented approach with other methods based on the curvelet, sharp frequency localized contourlet transform and shearlet transform. The experiments demonstrate that the presented fusion algorithm outperforms these image fusion works.
C1 [Geng, Peng; Feng, Jun; Bao, Peina] Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang 050043, Peoples R China.
   [Huang, Min] South Cent Univ Nationalities, Coll Biomed Engn, Wuhan 430000, Peoples R China.
   [Liu, Shuaiqi] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Liu, Shuaiqi] Tianjin Normal Univ, Coll Elect & Commun Engn, Tianjin 300387, Peoples R China.
C3 Shijiazhuang Tiedao University; South Central Minzu University; Beijing
   Jiaotong University; Tianjin Normal University
RP Geng, P (corresponding author), Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang 050043, Peoples R China.
EM gengpeng@stdu.edu.cn
RI Peng, Geng/HKF-8217-2023
OI Geng, Peng/0000-0003-0234-9380; Liu, Shuaiqi/0000-0001-7520-8226
FU Natural Science Foundation of China [30970782]; Natural Science
   Foundation of Hebei Province [2013210094, F2013210109]; Science and
   Technology Research and Development of Hebei Province [10213516D];
   University Science Research Project of Hebei Education Department
   [201142]
FX Some of the images used in this paper are available at
   http://www.imagefusion.org. This work was supported in part by Natural
   Science Foundation of China under grant 30970782, Natural Science
   Foundation of Hebei Province under grant 2013210094 and F2013210109,
   Science and Technology Research and Development of Hebei Province under
   grant 10213516D, the University Science Research Project of Hebei
   Education Department under grant 201142. The authors also thank the
   editors and anonymous reviewers for their valuable suggestions.
CR Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chai Y, 2010, OPT COMMUN, V283, P3591, DOI 10.1016/j.optcom.2010.04.100
   Das S., 2011, Progress In Electromagnetics Research B, V30, P355
   Eslami R, 2003, CONF REC ASILOMAR C, P1982
   Geng P, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.6.067005
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Kamilov U, 2012, IEEE SIGNAL PROC LET, V19, P187, DOI 10.1109/LSP.2012.2185929
   Liang Dong, 2007, Acta Electronica Sinica, V35, P320
   Liu K, 2011, J SYST ENG ELECTRON, V22, P353, DOI 10.3969/j.issn.1004-4132.2011.02.025
   [马东辉 Ma Donghui], 2011, [红外与激光工程, Infrared and Laser Engineering], V40, P1168
   Miao QG, 2006, INT C COMMUN CIRCUIT, P548
   Miao QG, 2011, CHIN OPT LETT, V9, DOI 10.3788/COL201109.041001
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Qu Xiao-bo, 2009, Optics and Precision Engineering, V17, P1203
   Xu J, 2008, RIPPLET TRANSFORM FE, V6970
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhao H, 2008, IMAGE VISION COMPUT, V26, P1285, DOI 10.1016/j.imavis.2008.03.007
NR 18
TC 17
Z9 18
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10583
EP 10593
DI 10.1007/s11042-014-1942-1
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800023
DA 2024-07-18
ER

PT J
AU Karamiani, A
   Farajzadeh, N
AF Karamiani, Aziz
   Farajzadeh, Nacer
TI Optimal feature points for tracking multiple moving objects in active
   camera model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tracking; Camera motion estimation; Good features to track; KLT; Active
   camera
ID SURVEILLANCE; PEOPLE
AB Object tracking is an important task in computer vision that is essential for higher level vision applications such as surveillance systems, human-computer interaction, industrial control, smart compression of video, and robotics. Tracking, however, cannot be easily accomplished due to challenges such as real-time processing, occlusions, changes in intensity, abrupt motions, variety of objects, and mobile platforms. In this paper, we propose a new method to estimate and eliminate the camera motion in mobile platforms, and accordingly, we propose a set of optimal feature points for accurate tracking. Experimental results on different videos show that the proposed method estimates camera motion very well and eliminate its effect on tracking moving objects. And the use of optimal feature points results in a promising tracking. The proposed method in terms of accuracy and processing time has desirable results compared to the state-of-the-art methods.
C1 [Karamiani, Aziz; Farajzadeh, Nacer] Azarbaijan Shahid Madani Univ, Dept IT & Comp Engn, Tabriz, Iran.
C3 Azarbaijan Shahid Madani University
RP Farajzadeh, N (corresponding author), Azarbaijan Shahid Madani Univ, Dept IT & Comp Engn, Tabriz, Iran.
EM a.karamiani@azaruniv.edu; n.farajzadeh@azaruniv.edu
RI Farajzadeh, Nacer/ACM-0675-2022
OI Farajzadeh, Nacer/0000-0001-7590-0503
CR Aggarwal JK, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P90, DOI 10.1109/NAMW.1997.609859
   [Anonymous], P SPIE
   [Anonymous], INT J ADV SCI TECHNO
   [Anonymous], ELECT LETT COMPUTER
   [Anonymous], INT MULTICONF ENG CO
   [Anonymous], AIRBORNE INTELLIGENC
   [Anonymous], MULTITARGET TRACKING
   [Anonymous], P INT C IM SIGN PROC
   Argyros AA, 2004, LECT NOTES COMPUT SC, V3023, P368
   Beyan C, 2012, IET COMPUT VIS, V6, P1, DOI 10.1049/iet-cvi.2011.0054
   Chen CH, 2006, INT C PATT RECOG, P1091
   Chen Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109809
   Choi W, 2010, LECT NOTES COMPUT SC, V6314, P553, DOI 10.1007/978-3-642-15561-1_40
   Collins R., 2005, PROC IEEE INT WORKSH, V2, P35
   Doyle DD, 2014, MEASUREMENT, V48, P195, DOI 10.1016/j.measurement.2013.10.025
   Giesbrecht J, 2010, CAN CON EL COMP EN
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hashemzadeh M, 2014, MULTIMED TOOLS APPL, V72, P453, DOI 10.1007/s11042-013-1367-2
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Hsieh YS, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P696, DOI 10.1109/ICCE.2012.6162066
   Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58
   Jung B., 2004, International Conference on Intelligent Autonomous Systems, P980
   Jung YK, 2002, LECT NOTES COMPUT SC, V2532, P1137
   Kim IS, 2010, INT J CONTROL AUTOM, V8, P926, DOI 10.1007/s12555-010-0501-4
   Kundu A., 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1635, DOI 10.1109/ROBIO.2010.5723575
   Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384
   Lee KW, 1998, ELECTRON LETT, V34, P256, DOI 10.1049/el:19980176
   Lefèvre S, 2004, LECT NOTES COMPUT SC, V3212, P606
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Lim JS, 2005, LECT NOTES COMPUT SC, V3804, P527
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Manigandan M., 2010, 2010 International Conference on Emerging Trends in Robotics and Communication Technologies (INTERACT 2010), P20, DOI 10.1109/INTERACT.2010.5706172
   Micheloni C, 2005, IEEE IMAGE PROC, P3681
   MURRAY D, 1994, IEEE T PATTERN ANAL, V16, P449, DOI 10.1109/34.291452
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Rosenberg Y, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P238, DOI 10.1109/ACV.1998.732887
   Selsis M., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P96, DOI 10.1109/IVS.1995.528264
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Siam M., 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2399, DOI 10.1109/ROBIO.2012.6491329
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stolkin R., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P192, DOI 10.1109/MFI.2012.6343021
   Talukder A, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1308
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiang GS, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P1162
   Yao F., 2008, International Conference on Pattern Recognition, P1
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yoon Y, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS AND AMBIENT INTELLIGENCE (URAL), P191, DOI 10.1109/URAI.2012.6462968
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zaki M, 2009, SIGNAL IMAGE VIDEO P, V3, P145, DOI 10.1007/s11760-008-0066-3
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang RL, 2012, PROCEDIA ENGINEER, V29, P1351, DOI 10.1016/j.proeng.2012.01.139
   Zhao T, 2004, PROC CVPR IEEE, P406
NR 57
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 10999
EP 11017
DI 10.1007/s11042-015-2823-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900009
DA 2024-07-18
ER

PT J
AU Moghadas, M
   Afshari, H
   Hashemi, MR
AF Moghadas, Maryam
   Afshari, Hossein
   Hashemi, Mahmoud Reza
TI Joint application-architeture design space exploration of multimedia
   applications on many-core platforms an experimental analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design space exploration; Energy; Execution time; Memory; Video coding;
   Many-core platform
ID VIDEO; HEVC
AB The design space of mapping multimedia applications on an architectural platform is complex and many parameters are needed to be considered in order to find the optimum mapping. Conventionally, architectural parameters are varied to find different design points and the application side parameters are considered fixed and unchanged, while multimedia applications are equipped with several configurations to control the complexity and quality of the output. In this paper, we experimentally investigate joint application-architecture design space exploration of multimedia applications on many-core platforms. The joint exploration is conducted on two state of the art video coding standards and STHorm many-core platform as the underlying architecture. In the first case study, MPEG4-SP decoder is mapped on STHorm with varying buffer size and variable number of Processing Elements (PEs). In the second case study, HEVC (High Efficiency Video Coding) decoder with variable Quantization Parameter (QP) is mapped on STHorm with variable PE number. The application is characterized with representative parameters on the basis of high level dataflow representation of the application. It is demonstrated that joint exploration of these parameters outperforms that of their separate exploration in terms of well-established combinatory metrics such as space-time product and energy-time product metrics while achieving performance constraints.
C1 [Moghadas, Maryam; Hashemi, Mahmoud Reza] Univ Tehran, Sch Elect & Comp Engn, Coll Engn, Multimedia Proc Lab, Tehran, Iran.
   [Afshari, Hossein] EPFL Univ, EPFL Alumni, Lausanne, Switzerland.
C3 University of Tehran
RP Moghadas, M (corresponding author), Univ Tehran, Sch Elect & Comp Engn, Coll Engn, Multimedia Proc Lab, Tehran, Iran.
EM mmoghadas@ut.ac.ir; hossein.afshari@a3.epfl.ch; rhashemi@ut.ac.ir
RI Hashemi, Mahmoud Reza/H-2172-2011
OI Hashemi, Mahmoud Reza/0000-0002-3518-9195
CR Azizi O, 2010, DES AUT TEST EUROPE, P250
   Benini L, 2010, ARTIST DESIGN SUMMER
   Benini L, 2012, DES AUT TEST EUROPE, P983
   Bombieri N, 2010, ACM T EMBED COMPUT S, V9, DOI 10.1145/1721695.1721703
   Brunet SC, 2013, IEEE INT SYMP CIRC S, P1384, DOI 10.1109/ISCAS.2013.6572113
   Cho S, 2010, IEEE T PARALL DISTR, V21, P342, DOI 10.1109/TPDS.2009.41
   Helmstetter C, 2012, 19 OP INT WORKSH SYN
   Hübert H, 2009, IEEE T CIRC SYST VID, V19, P1680, DOI 10.1109/TCSVT.2009.2031522
   Le Beux S, 2009, PROCEEDINGS OF THE 2009 NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, P474, DOI 10.1109/AHS.2009.35
   Lee GG, 2009, IEEE T CIRC SYST VID, V19, P1576, DOI 10.1109/TCSVT.2009.2031376
   Lee GG, 2007, IEEE T MULTIMEDIA, V9, P455, DOI 10.1109/TMM.2006.889355
   Mattavelli M, 2010, IEEE SIGNAL PROC MAG, V27, P159, DOI 10.1109/MSP.2010.936032
   Nicol DM, 1996, IEEE T COMPUT, V45, P730, DOI 10.1109/12.506428
   Roquier G, 2012, CAN J ELECT COMPUT E, V2012, P1
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Viitanen M., 2013, 2012 IE INT S CIRC S, P20
NR 17
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11291
EP 11310
DI 10.1007/s11042-015-2854-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900021
DA 2024-07-18
ER

PT J
AU Chen, CY
   Feng, HM
   Chen, HC
   Jou, SM
AF Chen, Ching-Yi
   Feng, Hsuan-Ming
   Chen, Hua-Ching
   Jou, Shiang-Min
TI Dynamic image segmentation algorithm in 3D descriptions of remote
   sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic image segmentation algorithm; 3D image describer; Remote sensing
   image
ID SPATIAL INFORMATION; MULTIRESOLUTION; FUSION
AB The dynamic image segmentation algorithm with multiple stepwise evaluation machines was applied to resultant the new boundary from image contents. The concept of data fusion is also discussed in this research for making the good decision of image behavior by a 3D image describer. It achieves the high-understanding objects by merging some non-distinct image domains from the training patterns. Image describer contains expert knowledge to extract appropriate behaviors of the identified image patterns through the efficient dynamic image segmentation algorithm. The novel dynamic image segmentation algorithm is directly applied to explore recognitions of remote sensing images, where it can quickly choice the proper partition number of interesting image patterns area and determine their associated central positions. Due to the specific image intensity appropriately represent in the form of 3D description, an approximation object was dynamically generated with the image partition phase and merging stage to find appropriate 3D image describer. This 3D image describer explicitly presents its feature in diverse maps. Finally, the classification problems of three remote sensing images in computer simulations compared with both k-means and Fuzzy c-means (FCMs) methods. The measurement of misclassification error (ME) is selected to present the great results in various remote sensing images segmentation by the designed algorithm.
C1 [Chen, Ching-Yi] Ming Chuan Univ, Dept Informat & Telecommun Engn, Taoyuan, Taiwan.
   [Feng, Hsuan-Ming; Chen, Hua-Ching] Natl Quemoy Univ, Dept Comp Sci & Informat Engn, Kinmen 892, Taiwan.
   [Jou, Shiang-Min] Xiamen Univ, Dept Elect Engn, 422 Siming South Rd, Xiamen 361005, Peoples R China.
C3 Ming Chuan University; Xiamen University
RP Feng, HM (corresponding author), Natl Quemoy Univ, Dept Comp Sci & Informat Engn, Kinmen 892, Taiwan.
EM hmfeng@nqu.edu.tw
RI 陳, 華慶/JYQ-3317-2024
OI 陳, 華慶/0009-0007-0930-1431; Feng, Hsuan-Ming/0000-0002-6498-7006
FU National Science Council of the Republic of China [100-2221-E-507-002]
FX This work is partly supported by National Science Council of the
   Republic of China under Contract 100-2221-E-507-002.
CR Ashraf S, 2012, APPL GEOGR, V32, P619, DOI 10.1016/j.apgeog.2011.07.010
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Bezdek James C., 1981, PATTERN RECOGN
   Burnett C, 2003, ECOL MODEL, V168, P233, DOI 10.1016/S0304-3800(03)00139-X
   Chatzis SP, 2008, IEEE T FUZZY SYST, V16, P1351, DOI 10.1109/TFUZZ.2008.2005008
   Chen C., 1994, PUBLIC ROADS, V57, P8
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Feng HM, 2014, J MAR SCI TECH-TAIW, V22, P430, DOI 10.6119/JMST-013-0521-2
   Feng HM, 2014, INFORM SCIENCES, V270, P204, DOI 10.1016/j.ins.2014.02.098
   Gao X, 2007, INT J FUZZY SYST, V9, P188
   Kim M, 2011, PHOTOGRAMM ENG REM S, V77, P51, DOI 10.14358/PERS.77.1.51
   Liu HQ, 2012, APPL SOFT COMPUT, V12, P3636, DOI 10.1016/j.asoc.2012.05.026
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P2815, DOI 10.1109/TGRS.2012.2213825
   Melendez-Pastor I, 2010, APPL GEOGR, V30, P254, DOI 10.1016/j.apgeog.2009.05.006
   Neubert M., 2008, OBJECT BASED IMAGE A, P769, DOI [DOI 10.1007/978-3-540-77058-9_42, 10.1007/9783-54077058-942, DOI 10.1007/9783-54077058-942]
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Smith GM, 2010, PHOTOGRAMM ENG REM S, V76, P163, DOI 10.14358/PERS.76.2.163
   Swathi N, 2012, INT J SCI TECHNOL RE, V1, P143
   Tansey K, 2009, APPL GEOGR, V29, P145, DOI 10.1016/j.apgeog.2008.08.004
   Tao WB, 2008, IEEE T SYST MAN CY A, V38, P1181, DOI 10.1109/TSMCA.2008.2001068
   Tong HJ, 2012, PHOTOGRAMM ENG REM S, V78, P1029, DOI 10.14358/PERS.78.10.1029
   Wang LF, 2014, PATTERN RECOGN, V47, P1917, DOI 10.1016/j.patcog.2013.11.014
   Yang BY, 2012, GISCI REMOTE SENS, V49, P687, DOI 10.2747/1548-1603.49.5.687
   Yao H, 2013, MATH COMPUT MODEL, V58, P784, DOI 10.1016/j.mcm.2012.12.025
   Yuan Y, 2015, SIGNAL PROCESS, V112, P27, DOI 10.1016/j.sigpro.2014.06.018
   Zhao F, 2013, NEUROCOMPUTING, V106, P115, DOI 10.1016/j.neucom.2012.10.022
NR 26
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9723
EP 9743
DI 10.1007/s11042-015-2795-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500013
DA 2024-07-18
ER

PT J
AU Lin, GS
   Ji, XW
AF Lin, Guo-Shiang
   Ji, Xian-Wei
TI Video quality enhancement based on visual attention model and
   multi-level exposure correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention model; Exposure correction; Image fusion
AB Due to unfavorable environmental conditions such as lack of lighting, poor visual quality in images and videos may make intelligent image/video systems unstable. This means that visual quality enhancement plays an important role in image/video processing, computer vision, and pattern recognition. In this paper, we propose a video quality enhancement scheme based on visual attention model and multi-level exposure correction. To this end, the proposed scheme is composed of four parts: pre-processing, visual attention model generation, multi-level exposure correction, and temporal filtering. To extract more visual cues for visual attention model generation, a pre-processing is used to modify each frame. After preprocessing, facial and non-facial cues are measured to generate visual attention maps of each frame. On the basis of visual attention maps, a multi-level exposure correction algorithm is utilized to adjust the exposure level of each frame and then create several intermediate results. After fusing intermediate results, a synthesized image with good visual quality can be obtained. To avoid flicker effect, a temporal filter is exploited to make the variance of the exposure level small in the temporal domain. To evaluate the performance of the proposed scheme, some images/videos captured by mobile phones and digital cameras are tested. The experimental results show that the proposed scheme can effectively deal with the images/videos with low and high exposure levels. The results also demonstrate that the proposed scheme outperforms some existing methods in terms of visual quality.
C1 [Lin, Guo-Shiang; Ji, Xian-Wei] Dayeh Univ, Dept Comp Sci & Informat Engn, 168 Univ Rd, Dacun 51591, Changhua, Taiwan.
C3 Da Yeh University
RP Lin, GS (corresponding author), Dayeh Univ, Dept Comp Sci & Informat Engn, 168 Univ Rd, Dacun 51591, Changhua, Taiwan.
EM khlin@mail.dyu.edu.tw; xianedwin@gmail.com
FU Ministry of Science and Technology, Taiwan [MOST 103-2221-E-212-004-MY2]
FX This research was supported by the Ministry of Science and Technology,
   Taiwan, under the grant of MOST 103-2221-E-212-004-MY2.
CR Aditi M, 2005, COMPUT VISION PATTER, P377, DOI [10.1145/1140491.1140506, DOI 10.1145/1140491.1140506]
   [Anonymous], 2006, Digital Video Image Quality and Perceptual Coding
   BHUKHANWALA SA, 1994, IEEE T CONSUM ELECTR, V40, P1, DOI 10.1109/30.273657
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chi MC, 2008, SIGNAL PROCESS-IMAGE, V23, P127, DOI 10.1016/j.image.2007.12.001
   Chi MC, 2009, IEEE T CIRC SYST VID, V19, P1025, DOI 10.1109/TCSVT.2009.2022822
   Dorai C, 2002, MEDIA COMPUTING COMP, DOI [10.1109/93.959093, DOI 10.1109/93.959093]
   Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398
   Hsu CT, 2009, IEEE T BROADCAST, V55, P767, DOI 10.1109/TBC.2009.2032802
   Huang DY, 2014, J INF HIDING MULTIME, V5, P310
   Huang shih-Chia, 2013, IEEE T IMAGE PROCESS, V22
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang XS, 2013, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.2013.6738114
   Knutsson H., 1989, Proceedings of 6th Scandinavian Conference on Image Analysis, P244
   Krishna Kishore P, 2012, INT J EMERG TECHNOL, V2, P2250
   Lin GS, 2011, AS PAC SIGN INF PROC, DOI [10.1109/ICMLC.2008.4620379, DOI 10.1109/ICMLC.2008.4620379]
   Lin GS, 2014, IEEE T BROADCAST, V60, P452, DOI 10.1109/TBC.2014.2330391
   Lin GS, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-237
   Messina G, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P549
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Qian Zhao, 2011, Journal of Software, V6, P814, DOI 10.4304/jsw.6.5.814-818
   Shi CZ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P701
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu JL, 2013, ADV INTELL SYST, V181, P1
   Xiao L, 2010, INT C MECH AUT CONTR, P1569, DOI [10.1109/MACE.2010.5535992, DOI 10.1109/MACE.2010.5535992]
   Yang K-C, 2006, P IEEE INT S MULT, P525, DOI [10.1109/ISM.2006.86, DOI 10.1109/ISM.2006.86]
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P496, DOI 10.1109/TCSVT.2005.844458
   Yeh CH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P429, DOI 10.1109/IIH-MSP.2008.13
   Yeh CH, 2014, INFORM SCIENCES, V269, P106, DOI 10.1016/j.ins.2013.08.014
   Zettl H, 1990, MOTION APPL MEDIA AE
   Zhai Y., 2006, ACM Multimedia, P815824
NR 31
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9903
EP 9925
DI 10.1007/s11042-015-2777-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500022
DA 2024-07-18
ER

PT J
AU Sheu, JS
   Shou, HN
   Lin, WJ
AF Sheu, Jia-Shing
   Shou, Ho-Nien
   Lin, Wei-Jun
TI Realization of an Ethernet-based synchronous audio playback system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IEEE 1588; Precision time protocol; Zero configuration networking; User
   datagram protocol control
ID NETWORKING
AB A Dante network card and development template developed by Audinate were used as a platform for realizing an Ethernet synchronous audio playback system. A personal computer (PC) was connected to each Dante device through a switch hub and Ethernet cable PC to transmit sound before TAS3204EVM was applied in digital signal processing and EQ adjustment for application in a live music concert. The expensive wire and cable currently used in live music concerts can be replaced with an Ethernet cable, substantially reducing costs. To ensure that the Dante devices deliver sound simultaneously, an artificial delay was introduced to enable devices closer to the sound source to delay the playback time while devices farther from the sound source play back sound with the other devices. This study examined how the IEEE 1588 Precision Time Protocol can be used for clock correction to synchronize the sound of all devices. Zero Configuration Networking (ZCN) was used to enable the devices to obtain an Internet Protocol address, and the Multicast Domain Name System was employed to obtain the device names, thus ensuring that User Datagram Protocol control instructions can be correctly delivered to control interdevice channel connections.
C1 [Sheu, Jia-Shing; Lin, Wei-Jun] Natl Taipei Univ Educ, Dept Comp Sci, Taipei 10671, Taiwan.
   [Shou, Ho-Nien] Air Force Inst Technol, Dept Aviat & Commun Elect, Kaohsiung 820, Taiwan.
C3 National Taipei University of Education
RP Sheu, JS (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei 10671, Taiwan.
EM jiashing@tea.ntue.edu.tw; honien.shou@gmail.com; yageun2001@yahoo.com.tw
OI Sheu, Jia-Shing/0000-0002-9498-3110
CR [Anonymous], STEINB AUD STREAM IN
   [Anonymous], 15882008 IEEE
   [Anonymous], 1991, MULT PROGR INT DAT S
   [Anonymous], 2007, MULT CHANN AUD DAT W
   [Anonymous], 2006, COBRANET PROGR REF V
   [Anonymous], 15882002 IEEE
   Bouillot N, 2009, AUDIO ENG SOC, V4, P729
   Cheshire S, 2008, 5227 RFC NETW WORK G
   Cheshire S., 2013, 6762 IETF RFC
   Cheshire S, 2005, 3927 RFC NETW WORK G
   Cheshire S., 2013, 6763 IETF RFC
   DROMS R, 1997, 2131 RFC NETW WORK G
   Fleischman E, 1998, 2361 RFC NETW WORK G
   Fu Y., 2010, 2010 INT C E PRODUCT, P1, DOI [10.1109/ICEEE.2010.5661006, DOI 10.1109/ICEEE.2010.5661006]
   Gross K, 2006, J AUDIO ENG SOC, V54, P62
   Gross K, 2000, P AES 15 UK C MOV AU
   Guttman E, 2001, IEEE INTERNET COMPUT, V5, P81, DOI 10.1109/4236.935181
   Hill S, 1942, J I ELECT ENG LOND, V89, P124
   Richard SW, 1996, TCP IP ILLUSTRATED, VI
   Roberts D., 1995, DEV INTERNET WINSOCK
   TANENBAUM AS, 1996, COMPUTER NETWORKING
   Wang L, 2010, SCI TECHNOL CONSULT, V2, P240
   Weibel H, 2004, 2004 INT C PREC CLOC, P24
   Xu A., 2000, REAL TIME STREAMING
   Yu F, 2006, 2006 IET INT C WIR M, P1
   Zhao Jian, 2008, Audio Engineering, V32, P72
NR 26
TC 5
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9797
EP 9818
DI 10.1007/s11042-015-2983-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500017
DA 2024-07-18
ER

PT J
AU Singh, AK
   Dave, M
   Mohan, A
AF Singh, Amit Kumar
   Dave, Mayank
   Mohan, Anand
TI Hybrid technique for robust and imperceptible multiple watermarking
   using medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermark; Text watermark; Steganography; DWT; DCT; SVD;
   Encryption; Checkmark
ID DCT
AB This paper presents a secure multiple watermarking method based on discrete wavelet transform (DWT), discrete cosine transforms (DCT) and singular value decomposition (SVD). For identity authentication purpose, the proposed method uses medical image as the image watermark, and the personal and medical record of the patient as the text watermark. In the embedding process, the cover medical image is decomposed up to second level of DWT coefficients. Low frequency band (LL) of the host medical image is transformed by DCT and SVD. The watermark medical image is also transformed by DCT and SVD. The singular value of watermark image is embedded in the singular value of the host image. Furthermore, the text watermark is embedding at the second level of the high frequency band (HH) of the host image. In order to enhance the security of the text watermark, encryption is applied to the ASCII representation of the text watermark before embedding. Results are obtained by varying the gain factor, size of the text watermark, and medical image modalities. Experimental results are provided to illustrate that the proposed method is able to withstand a variety of signal processing attacks such as JPEG, Gaussian, Salt-and-Pepper, Histogram equalization etc. The performance of the proposed technique is also evaluated by using the benchmark software Checkmark and the technique is found to be robust against the Checkmark attacks such as Collage, Trimmed Mean, Hard and Soft Thresholding, Wavelet Compression, Mid Point, Projective, and Wrap etc.
C1 [Singh, Amit Kumar] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
   [Dave, Mayank] Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
   [Mohan, Anand] BHU, Indian Inst Technol, Dept Elect Engn, Varanasi, Uttar Pradesh, India.
C3 Jaypee University of Information Technology; National Institute of
   Technology (NIT System); National Institute of Technology Kurukshetra;
   Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM amit_245singh@yahoo.com; mdave67@gmail.com; profanandmohan@gmail.com
RI Dave, Mayank/F-5617-2011; Singh, Amit Kumar/D-1300-2015
OI Dave, Mayank/0000-0003-4748-0753; Singh, Amit Kumar/0000-0001-7359-2068
CR [Anonymous], INT J COMPUT APPL
   [Anonymous], EUROPEAN J SCI RES
   [Anonymous], INT J COMPUT SCI MOB
   [Anonymous], 2012, AM J BIOMEDICAL ENG, DOI DOI 10.5923/J.AJBE.20120202.06
   [Anonymous], ADV ELECT ELECT ENG
   [Anonymous], 2013, IOSR J COMPUTER ENG
   [Anonymous], INT C SCI EL TECHN I
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], DIGITAL IMAGE WATERM
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Golshan F, 2013, IMAGING SCI J, V61, P35, DOI 10.1179/1743131X11Y.0000000049
   Harish N., 2013, INT J ADV ELECT ELEC, V2, P137
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P2469, DOI 10.1007/s11042-013-1561-2
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Kannammal A., 2012, EUR J SCI RES, V70, P46
   Khan Mohammad Ibrahim, 2013, INT J COMPUTER SCI I, V10, P223
   Kumar B., 2011, WORLD ACAD SCI ENG T, V5, P62
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Memon NA, 2008, INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE, P106, DOI 10.1109/INMIC.2008.4777717
   Mostafa Salwa A K, 2010, Open Biomed Eng J, V4, P93, DOI 10.2174/1874120701004010093
   Navas KA, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P271, DOI 10.1109/COMSWA.2008.4554423
   Navas K. A., 2007, 2007 IEEE International Conference on Electro/Information Technology, P697
   Navas K.A., 2007, 4 INT C SCI EL TECHN, P1
   Nisha S.K., 2013, International Journal of Advanced Research in Computer Science and Software Engineering, V3, P636
   Rosiyadi D., 2012, Int J Comput Theory and Eng (IJCTE), V4, P329
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Singh A, 2012, INT J COMPUT APPL, V48, P9
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Soliman MM., 2012, Int J Smart Home, V6, P37
   Wang B, 2009, IEEE INT C NETW INFR, P6
   Zaz Y, 2010, INT C MOD INF COMM S
   Zhang L, 2010, TELECOMMUN SYST, V44, P205, DOI 10.1007/s11235-009-9260-z
   [No title captured]
NR 39
TC 112
Z9 114
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8381
EP 8401
DI 10.1007/s11042-015-2754-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300011
DA 2024-07-18
ER

PT J
AU Zhu, SP
   Zhao, DY
   Li, LY
AF Zhu, Shiping
   Zhao, Dongyu
   Li, Liyun
TI Adaptive fast intra prediction for high efficiency video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Fast intra prediction; Structural similarity; Content adaptive
ID HEVC
AB In this paper, a fast intra prediction algorithm for High Efficiency Video Coding (HEVC) is proposed by adopting the mode correlation between adjacent coding units. The proposed approach is realized by two pieces. Firstly, the prediction mode and partition structure for the current coding unit will inherit its optimal prediction coding unit directly if the Structural Similarity (SSIM) between the adjacent coding units satisfies the threshold condition. Secondly, unless the first case occurs, a two-step rough mode decision with adaptive threshold method including Sum of Absolute Difference (SAD) and Sum of Absolute Hadamard Transformed Difference (SATD) criterions is used to accelerate intra mode decision process based on HEVC test Model (HM) encoder. Besides, the most probable mode (MPM) which refers to the optimal prediction mode of the coded left and upper Prediction Units (PUs) surrounding the current PU is also considered. Experimental results show that the proposed algorithm can save 30.18 % encoding time on average with negligible loss of coding efficiency compared with HM10.0. The complexity and the bitrate are reduced by 11.45 and 0.46 % respectively compared with coding tree pruning method.
C1 [Zhu, Shiping; Zhao, Dongyu; Li, Liyun] Beihang Univ, Dept Measurement Control & Informat Technol, Sch Instrumentat Sci & Optoelect Engn, Beijing 100191, Peoples R China.
   [Zhao, Dongyu] CSR Qingdao Sifang Locomot & Rolling Stock Co Ltd, 88 Jinhong East Rd, Qingdao 266111, Shandong, Peoples R China.
   [Li, Liyun] Lenovo Beijing Co Ltd, 6 Shangdi West Rd, Beijing 100085, Peoples R China.
C3 Beihang University; Legend Holdings; Lenovo
RP Zhu, SP (corresponding author), Beihang Univ, Dept Measurement Control & Informat Technol, Sch Instrumentat Sci & Optoelect Engn, Beijing 100191, Peoples R China.
EM spzhu@163.com
RI Zhu, Shiping/C-3754-2012
FU National Natural Science Foundation of China (NSFC) [61375025, 61075011,
   60675018]; Scientific Research Foundation for the Returned Overseas
   Chinese Scholars from the State Education Ministry of China
FX This research is funded by the National Natural Science Foundation of
   China (NSFC) under grants No. 61375025, No. 61075011, and No. 60675018,
   also the Scientific Research Foundation for the Returned Overseas
   Chinese Scholars from the State Education Ministry of China. We express
   our appreciations to the reviewers for their through review and very
   helpful comments, which help improving this paper.
CR Bossen F, 2011, JCTVCF900 ITUT SG16
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Choi K, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.3.030502
   Iwata K, 2012, IEEE IMAGE PROC, P2933, DOI 10.1109/ICIP.2012.6467514
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Piao Y, 2010, JCTVCC207 ITUT SG16
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Viitanen M, 2012, IEEE INT SYMP CIRC S, P882, DOI 10.1109/ISCAS.2012.6272182
   Wallendael G.V., 2011, P IEEE INT C MULT EX, P1
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yu Y, 2010, JCTVCC259 ITUT SG16
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
NR 16
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7559
EP 7573
DI 10.1007/s11042-015-2677-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600005
DA 2024-07-18
ER

PT J
AU Choi, KC
   Pun, CM
AF Choi, Ka-Cheng
   Pun, Chi-Man
TI Robust lossless digital watermarking using integer transform with Bit
   plane manipulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossless data hiding; Generalized integer transform; Robust reversible
   watermarking; Threshold; Bit plane
ID FRAGILE; SCHEME
AB In this paper, a robust lossless digital watermarking scheme based on a generalized integer transform in spatial domain is proposed. In the proposed method, data bits are hidden into the cover media by a reversible generalized integer transform with bit plane manipulation. With the reversible transform, data can be hidden in the cover media, and the stego media can be restored to its original form after extraction of the hidden data. In embedding procedure, adaptive bit plane manipulation is applied to increase robustness of the algorithm while keeps good visual quality. To further increase the robustness of the algorithm, we repeatedly embed watermark bits and use majority voting to decode the hidden information in extraction procedure. Furthermore, a threshold is introduced in the algorithm, which helps in choosing regions that would result lower variance for embedding, as regions with lower variance is more robust against JPEG compression. The proposed scheme is quite different from the existing robust lossless data hiding algorithms which are histogram-based. The performance of the proposed scheme is evaluated and compared with state-of-the-arts techniques respect to robustness, data payload capacity and peak signal-to-noise ratio (PSNR). In the experiments, the proposed method can embed more than 10000 bits into 512 by 512 grayscale and medical images, and has around 30 dB in PSNR. In case of small watermark with 100 bits, marked images can have PSNR above 60 dB and with 0.1 bpp in JPEG robustness in the best cases. Conclusively, the robustness of the proposed method is quite good, and the results of hiding capacity and imperceptibility are also satisfactory.
C1 [Choi, Ka-Cheng; Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo
RI Pun, Chi Man/GRJ-3703-2022
OI Pun, Chi-Man/0000-0003-1788-3746; Choi, Ka-Cheng/0000-0002-1742-3224
FU Research Committee of the University of Macau [MYRG2015-00012-FST,
   MYRG2015-00013-FST]; Science and Technology Development Fund of Macau
   SAR [008/2013/A1, 093-2014-A2]
FX This research was supported in part by Research Committee of the
   University of Macau (MYRG2015-00012-FST, MYRG2015-00013-FST) and the
   Science and Technology Development Fund of Macau SAR (008/2013/A1,
   093-2014-A2).
CR ALAVIANMEHR MA, 2012, TEL IST 2012 6 INT S, P976
   ALI MA, 2012, COMP CONV TECHN ICCC, P631
   [Anonymous], JIH MSP
   Caronni G., 1995, VERL LICHE ITSYSTEME, P251
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   De Vleeschouwer C, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P345, DOI 10.1109/MMSP.2001.962758
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P404, DOI 10.1109/ICIP.1998.723401
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Lee CP, 2015, J TISSUE ENG, V6, DOI 10.1177/2041731415586318
   Lingling An, 2010, 2010 International Conference on High Performance Computing & Simulation (HPCS 2010), P512, DOI 10.1109/HPCS.2010.5547084
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Naskar R, 2013, IET IMAGE PROCESS, V7, P99, DOI 10.1049/iet-ipr.2012.0232
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Nishimura A., 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P318, DOI 10.1109/IIHMSP.2011.76
   Rui D, 2002, IM PROC 2002 P 2002, V2, pII
   Shi YQ, 2004, CIRC SYST 2004 ISCAS, V2
   Tashk A, 2012, INT ISC CONF INFO SE, P60, DOI 10.1109/ISCISC.2012.6408192
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   van der Veen M., 2003, HIGH CAPACITY REVERS, P1
   Walia E, 2013, IET COMPUT VIS, V7, P9, DOI 10.1049/iet-cvi.2012.0109
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Zou DK, 2006, IEEE T CIRC SYST VID, V16, P1294, DOI 10.1109/TCSVT.2006.881857
NR 28
TC 6
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6621
EP 6645
DI 10.1007/s11042-015-2596-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700028
DA 2024-07-18
ER

PT J
AU Niitsuma, M
   Schomaker, L
   van Oosten, JP
   Tomita, Y
   Bell, D
AF Niitsuma, Masahiro
   Schomaker, Lambert
   van Oosten, Jean-Paul
   Tomita, Yo
   Bell, David
TI Musicologist-driven writer identification in early music manuscripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Writer identification; Domain driven data mining;
   Optical music recognition
ID STAFF REMOVAL
AB Recent renewed interest in computational writer identification has resulted in an increased number of publications. In relation to historical musicology its application has so far been limited. One of the obstacles seems to be that the clarity of the images from the scans available for computational analysis is often not sufficient. In this paper, the use of the Hinge feature is proposed to avoid segmentation and staff-line removal for effective feature extraction from low quality scans. The use of an auto encoder in Hinge feature space is suggested as an alternative to staff-line removal by image processing, and their performance is compared. The result of the experiment shows an accuracy of 87 % for the dataset containing 84 writers' samples, and superiority of our segmentation and staff-line removal free approach. Practical analysis on Bach's autograph manuscript of the Well-Tempered Clavier II (Additional MS. 35021 in the British Library, London) is also presented and the extensive applicability of our approach is demonstrated.
C1 [Tomita, Yo] Queens Univ Belfast, Sch Creat Arts, Belfast, Antrim, North Ireland.
   [Schomaker, Lambert; van Oosten, Jean-Paul] Univ Groningen, Dept Artificial Intelligence, Groningen, Netherlands.
   [Bell, David] Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast, Antrim, North Ireland.
   [Niitsuma, Masahiro] Ritsumeikan Univ, Coll Informat Sci & Engn, Dept Media Technol, Shiga, Japan.
C3 Queens University Belfast; University of Groningen; Queens University
   Belfast; Ritsumeikan University
RP Niitsuma, M (corresponding author), Ritsumeikan Univ, Coll Informat Sci & Engn, Dept Media Technol, Shiga, Japan.
EM mniitsuma@media.ritsumei.ac.jp; l.schomaker@ai.rug.nl
RI Schomaker, Lambert/A-9489-2008; Schomaker, Lambert/GYU-5840-2022
OI Schomaker, Lambert/0000-0003-2351-930X; 
CR [Anonymous], AUTOMATICA
   Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009
   DADELSEN GV, 1958, TUBINGER BACH STUDIE, V4
   Dalitz C, 2008, IEEE T PATTERN ANAL, V30, P753, DOI [10.1109/TPAMI.2007.70749, 10.1109/TPAM1.2007.70749]
   Fornés A, 2011, PROC INT CONF DOC, P1511, DOI 10.1109/ICDAR.2011.300
   Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131
   Franklin DO, 1989, BACH STUDIES, P240
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   JARVIS Martin, 2007, THESIS
   Kirchhoff Gottfried., 1957, BJ, V44, P5
   Kobayashi Y, 2007, KOPISTEN JS BACHS KA
   Maarse F, 1987, THESIS
   MAARSE F, 1988, HUMAN COMPUTER INTER, P353
   Niitsuma M, 2011, P 12 INT C MUS INF R, P417
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Schomaker L, 2004, AUTOMATIC WRITER IDE
   Schomaker L, 2007, PROC INT CONF DOC, P1268
NR 17
TC 0
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6463
EP 6479
DI 10.1007/s11042-015-2583-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700020
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, BQ
   Zhang, T
   Gu, CC
   Wu, KJ
   Guan, XP
AF Yang, Bao-Qing
   Zhang, Tao
   Gu, Chao-Chen
   Wu, Kai-Jie
   Guan, Xin-Ping
TI A novel face recognition method based on IWLD and IWBC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Improved Weber local descriptors; Improved Weber
   binary coding; Contour information; Block-based Fishers linear
   discriminant
ID FEATURE-EXTRACTION; PATTERNS; CLASSIFICATION; REPRESENTATION; FRAMEWORK;
   HISTOGRAM; SCALE; MODEL
AB This paper presents a face recognition method using improved Weber local descriptor (IWLD) and improved Weber binary coding method. Compared to the existing Weber local descriptor, the proposed IWLD represent local patterns more effectively and accurately by introducing novel Weber magnitude and orientation components. In order to extract more discriminative and robust feature for face recognition, the IWBC is proposed to encode the cues embedded in IWLD. Moreover, to reduce the dimension of feature extracted by IWBC and enhance its discriminative ability, the block-based Fishers linear discriminant (BFLD) is employed to learn a projection matrix from the training set. Experimental results on three (AR, FERET and PolyU-NIR) challenging databases demonstrate the effectiveness and robustness of our proposed method.
C1 [Yang, Bao-Qing; Zhang, Tao; Gu, Chao-Chen; Wu, Kai-Jie; Guan, Xin-Ping] Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
   [Yang, Bao-Qing; Zhang, Tao; Gu, Chao-Chen; Wu, Kai-Jie; Guan, Xin-Ping] Minist Educ China, Key Lab Syst Controal & Informat Proc, 800 Dongchuan Rd, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Gu, CC (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.; Gu, CC (corresponding author), Minist Educ China, Key Lab Syst Controal & Informat Proc, 800 Dongchuan Rd, Shanghai, Peoples R China.
EM jacygu@sjtu.edu.cn
OI w, yufan/0000-0003-2609-4706
FU National Instrument Development Special Program of China
   [2013YQ03065101, 2013YQ03065105]; Ministry of Science and Technology of
   China [2010CB731803]; National Natural Science Foundation of China
   [61221003, 61290322, 61174127, 61273181, 60934003, U1405251]; Program of
   New Century Talents in University of China [NCET-13-0358]; Science and
   Technology Commission of Shanghai Municipal, China [13QA1401900];
   Postdoctoral Science Foundation of China [2014M551406]
FX This work was supported by National Instrument Development Special
   Program of China under the grants 2013YQ03065101, 2013YQ03065105,
   Ministry of Science and Technology of China under National Basic
   Research Project under the grants 2010CB731803, and by National Natural
   Science Foundation of China under the grants 61221003, 61290322,
   61174127, 61273181, 60934003, 61290322 and U1405251, the Program of New
   Century Talents in University of China under the grant NCET-13-0358, the
   Science and Technology Commission of Shanghai Municipal, China under the
   grant 13QA1401900, Postdoctoral Science Foundation of China under the
   grants 2014M551406.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Li ST, 2013, NEUROCOMPUTING, V122, P272, DOI 10.1016/j.neucom.2013.05.038
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Martinez A., 1998, AR FACE DATABASE
   Meng Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2680, DOI 10.1109/ICPR.2010.657
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Qian JJ, 2013, IEEE T IMAGE PROCESS, V22, P3591, DOI 10.1109/TIP.2013.2264676
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P235
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang BA, 2012, IEEE IMAGE PROC, P1441, DOI 10.1109/ICIP.2012.6467141
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang WC, 2009, PATTERN ANAL APPL, V12, P301, DOI 10.1007/s10044-008-0123-0
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
NR 43
TC 14
Z9 15
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6979
EP 7002
DI 10.1007/s11042-015-2623-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400015
DA 2024-07-18
ER

PT J
AU Wu, H
   Miao, ZJ
   Wang, Y
   Chen, JY
AF Wu, Hao
   Miao, Zhenjiang
   Wang, Yi
   Chen, Jingyue
TI Recognition improvement through optimized spatial support methodology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WLS operator; Multi-scale decompositions; Multi-layer smoothing; Spatial
   support; Edge-preserving; Image segmentation; Image recognition
ID IMAGE; SEGMENTATION
AB Spatial support is an effective method of improving object recognition that is widely used in the field of computer vision. Compared to various other spatial support methods, such as sliding windows, spatial support based on image segmentation is a classic technique with high-quality segmentation that can positively contribute to image recognition. However, over-segmentation and under-segmentation often occur in the segmentation process. It is difficult for object classifiers to recognize objects in low-quality, segmented images, thus low-quality segmentation will reduce recognition accuracy. In order to resolve this drawback, watershed segmentation, multi-scale decompositions based on WLS (Weighted-Least Squares) filters and multi-layer smoothing, have been used to process the images. This methodology was utilized to maintain the sharp regions' boundaries, while smoothing regions which could contribute to accurately segmenting the images. After obtaining high-quality segmentation, the images could then be utilized in image recognition. The superiority of this paper's methodology compared to that of previous methods has been demonstrated herein. Experiments using a large database have demonstrated that this methodology is capable of improving image recognition through optimizing segmentation results.
C1 [Wu, Hao; Miao, Zhenjiang; Chen, Jingyue] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Wang, Yi] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Beijing Jiaotong University; Carnegie Mellon University
RP Wu, H (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM 10112056@bjtu.edu.cn; zjm@bjtu.edu.cn; ywangcmu@gmail.com;
   jychen@bjtu.edu.cn
FU NSFC [61273274, 61370127]; 973 Program [2011CB302203]; National Key
   Technology R&D Program of China [2012BAH01F03, NSFB4123104, FRFCU
   2014JBZ004, Z131110001913143]; Tsinghua-Tencent Joint Lab for IIT
FX This work is supported by the NSFC 61273274, 61370127, 973 Program
   2011CB302203, National Key Technology R&D Program of China 2012BAH01F03,
   NSFB4123104, FRFCU 2014JBZ004, Z131110001913143 and Tsinghua-Tencent
   Joint Lab for IIT.
CR [Anonymous], DOC AN REC ICDAR 201
   [Anonymous], COMP VIS 2005 ICCV 2
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS 1998 6 INT
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP PATT REC CVPR 2
   [Anonymous], P 21 ACM INT C INF K
   [Anonymous], ACM T GRAPHICS TOG
   [Anonymous], 2008, PASCAL 2008 RESULTS
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], 2011, IMAGE CLASSIFICATION
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS 2001 ICCV 2
   [Anonymous], COMP VIS 2009 IE 12
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS 2009 IE 12
   [Anonymous], COMP VIS 2009 IE 12
   [Anonymous], COMP VIS PATT REC 20
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Beucher S., 1979, P INT WORKSH IM PROC
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chung F. R. K., 1997, Spectral graph theory
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Frucci M, 2006, INT J PATTERN RECOGN, V20, P15, DOI 10.1142/S0218001406004533
   Frucci M, 2008, STUD COMPUT INTELL, V73, P319
   LAGENDIJK RL, 1988, IEEE T ACOUST SPEECH, V36, P1874, DOI 10.1109/29.9032
   Levner I, 2007, IEEE T IMAGE PROCESS, V16, P1437, DOI 10.1109/TIP.2007.894239
   Lobo JM, 2008, GLOBAL ECOL BIOGEOGR, V17, P145, DOI 10.1111/j.1466-8238.2007.00358.x
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Malisiewicz T., 2007, Improving spatial support for objects via multiple segmentations
   Maulik U, 2009, IEEE T INF TECHNOL B, V13, P166, DOI 10.1109/TITB.2008.2007301
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sethian J., 1999, LEVEL SET METHODS FA
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Soille P, 2009, PATTERN RECOGN LETT, V30, P456, DOI 10.1016/j.patrec.2008.10.015
   Tomasi C., 1998, P ICCV
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu H., 2014, VISUAL COMPUT, P1
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
NR 51
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5603
EP 5618
DI 10.1007/s11042-015-2527-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600012
DA 2024-07-18
ER

PT J
AU Chang, CC
   Lu, TC
   Homg, G
   Huang, YH
AF Chang, Chin-Chen
   Lu, Tzu-Chuen
   Homg, Gwoboa
   Huang, Ying-Hsuan
TI Very efficient variable-length codes for the lossless compression of VQ
   indices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector quantization; Principal component analysis; Huffman code;
   Compression efficiency
ID ALGORITHM
AB In this paper, we propose a novel compression method that can efficiently compress a vector quantization (VQ) index table. Before compressing the VQ index table, the method sorts all of the codewords in the VQ codebook by principal component analysis (PCA), assuring that each codeword has extreme similarity to its adjacent codewords. Afterwards, in the VQ index table, the difference between the current compressed VQ index and one of its adjacent VQ indices is calculated as the compression code, and the indicators generated by the Huffman code method are used to identify the encoding length of each difference. In other words, each VQ index is replaced by one indicator and the difference, which are variable-length codes. The experimental results showed that the compression efficiency of the proposed method is superior to that of the other lossless data compression methods.
C1 [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Lu, Tzu-Chuen] Chaoyang Univ Technol, Dept Informat Management, Taichung 41349, Taiwan.
   [Homg, Gwoboa; Huang, Ying-Hsuan] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 40227, Taiwan.
C3 Feng Chia University; Chaoyang University of Technology; National Chung
   Hsing University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com; tclu@cyut.edu.tw; gbhomg@cs.nchu.edu.tw;
   phd9807@cs.nchu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Chang CC, 1997, J VIS COMMUN IMAGE R, V8, P27, DOI 10.1006/jvci.1997.0327
   Cheng B, 2013, IEEE T AUDIO SPEECH, V21, P1676, DOI 10.1109/TASL.2013.2260156
   Ghido F, 2013, IEEE T AUDIO SPEECH, V21, P12, DOI 10.1109/TASL.2012.2211014
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Kekre HB, 2009, P INT C ADV COMP COM, P317
   Kuo HC, 2012, IEEE T MULTIMEDIA, V14, P500, DOI 10.1109/TMM.2012.2191945
   Qin C, 2015, SECUR COMMUN NETW, V8, P899, DOI 10.1002/sec.1046
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Nguyen VA, 2013, IEEE T CIRC SYST VID, V23, P189, DOI 10.1109/TCSVT.2012.2203212
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
NR 14
TC 3
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3537
EP 3552
DI 10.1007/s11042-015-2463-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600029
DA 2024-07-18
ER

PT J
AU Ding, XH
   Chen, LQ
   Zheng, XH
   Huang, Y
   Zeng, DL
AF Ding, Xinghao
   Chen, Liqin
   Zheng, Xianhui
   Huang, Yue
   Zeng, Delu
TI Single image rain and snow removal via guided L0 smoothing filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image rain and snow removal; Guided filter; L0 gradient
   minimization; Guided L0 smoothing filter
ID STREAKS REMOVAL; SPARSE
AB Since no temporal information can be exploited, rain and snow removal from single image is a challenging problem. In this paper, an improved rain and snow removal method from single image is proposed by designing a guided L0 smoothing filter. The designed filter is inspired by the previous L0 gradient minimization. Then a coarse rain-free or snow-free image can be obtained with the proposed filter, and the final refined result is recovered by a further minimization operation depending on the observed image. Experimental results show that the proposed algorithm generates better or comparable outputs than the state-of-the-art algorithms in rain and snow removal task for single image.
C1 [Ding, Xinghao; Chen, Liqin; Zheng, Xianhui; Huang, Yue; Zeng, Delu] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Peoples R China.
C3 Xiamen University
RP Zeng, DL (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Peoples R China.
EM dltsang@xmu.edu.cn
FU National Natural Science Foundation of China [30900328, 61172179,
   61103121, 81301278]; Natural Science Foundation of Fujian Province of
   China [2012J05160]; National Key Technology RD Program [2012BAI07B06];
   Fundamental Research Funds for the Central Universities [2011121051,
   2013121023]; Research Fund for the Doctoral Program of Higher Education
   [20120121120043]
FX The project is supported by the National Natural Science Foundation of
   China (No. 30900328, 61172179, 61103121, 81301278), the Natural Science
   Foundation of Fujian Province of China (No. 2012J05160), The National
   Key Technology R&D Program (2012BAI07B06), the Fundamental Research
   Funds for the Central Universities (No. 2011121051, 2013121023), the
   Research Fund for the Doctoral Program of Higher Education under Grant
   20120121120043.
CR Barnum P, 2007, P 1 INT WORKSH PHOT
   Barnum PC, 2010, INT J COMPUT VISION, V86, P256, DOI 10.1007/s11263-008-0200-2
   Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Chen DY, 2014, IEEE T CIRC SYST VID, V24, P1430, DOI 10.1109/TCSVT.2014.2308627
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Xianhui Zheng, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P258, DOI 10.1007/978-3-642-42051-1_33
   Xu J., 2012, CANADIAN CTR SCI ED, V5, P49, DOI DOI 10.5539/CIS.V5N3P49
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572
NR 17
TC 65
Z9 68
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2697
EP 2712
DI 10.1007/s11042-015-2657-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000019
DA 2024-07-18
ER

PT J
AU Li, QY
   Tian, M
   Liu, J
   Sun, JR
AF Li, Qingyong
   Tian, Mei
   Liu, Jun
   Sun, Jinrui
TI An implicit relevance feedback method for CBIR with real-time eye
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Implict relevance feedback; Eye tracking; Content based image retrieval;
   Query expansion; Bag of visual words
ID IMAGE RETRIEVAL
AB Relevance feedback is an efficient approach to improve the performance of content-based image retrieval systems, and implicit relevance feedback approaches, which gather users' feedback by biometric devices (e.g. eye tracker), have extensively investigated in recent years. This paper proposes a novel image retrieval system with implicit relevance feedback, named eye tracking based relevance feedback system (ETRFs). ETRFs is composed of three main modules: image retrieval subsystem based on bag-of-word architecture; user relevance assessment that implicitly acquires relevant images with the help of a modern eye tracker; and relevance feedback module that applies a weighted query expansion method to fuse users' relevance feedback. ETRFs is implemented online and real-time, which makes it remarkably distinguish from other offline systems. Ten subjects participate our experiments on the dataset of Oxford buildings and UKBench. The experimental results demonstrate that ETRFs achieves notable improvement for image retrieval performance.
C1 [Li, Qingyong; Tian, Mei; Liu, Jun; Sun, Jinrui] Beijing Jiaotong Univ, Beijing Key Lab Transportat Data Anal & Min, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Li, QY (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Transportat Data Anal & Min, Beijing, Peoples R China.
EM liqy@bjtu.edu.cn; mtian@bjtu.edu.cn; 12125123@bjtu.edu.cn;
   12120448@bjtu.edu.cn
RI Li, Qingyong/P-5250-2015; Li, Qingyong/GPK-0945-2022
OI Li, Qingyong/0000-0002-3860-4809
FU National Nature Science Foundation of China [61105119]; Fundamental
   Research Funds for the Central Universities [2014JBZ003]; Beijing
   Natural Science Foundation [4142043]; Beijing Higher Education Young
   Elite Teacher Project
FX This work is supported by National Nature Science Foundation of China
   (61105119), Fundamental Research Funds for the Central Universities
   (2014JBZ003), Beijing Natural Science Foundation (No. 4142043), Beijing
   Higher Education Young Elite Teacher Project.
CR [Anonymous], 2009, ICMI MLMI
   [Anonymous], 2010, P 2010 S EYE TRACKIN
   [Anonymous], 2010, P 2010 S EYE TRACK R
   [Anonymous], 2009, P 17 ACM INT C MULT, DOI DOI 10.1145/1631272.1631463
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Arapakis I., 2008, Proceedings of the 31st International ACM SIGIR Conference on Research and Development in Information Retrieval, P395, DOI DOI 10.1145/1390334.1390403
   Arapakis I., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P461, DOI DOI 10.1145/1631272.1631336
   Arapakis I, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P371
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Buscher Georg., 2008, Proceedings of SIGIR '08, P387, DOI DOI 10.1145/1390334.1390401
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Cole MJ, 2013, INFORM PROCESS MANAG, V49, P1075, DOI 10.1016/j.ipm.2012.08.004
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Faro Alberto., 2010, Proceedings of the Symposium on Eye-Tracking Research Appli- cations (ETRA), P73, DOI [10.1145/1743666.1743684, DOI 10.1145/1743666.1743684]
   Granka L. A., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P478, DOI 10.1145/1008992.1009079
   Hajimirza SN, 2012, IEEE T MULTIMEDIA, V14, P805, DOI 10.1109/TMM.2012.2186792
   Hardoon David R., 2007, J MACHINE LEARNING R, V2, P179
   Hughes A, 2003, LECT NOTES COMPUT SC, V2728, P271
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713
   Kelly D., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P377, DOI 10.1145/1008992.1009057
   Kelly D., 2003, SIGIR Forum, V37, P18, DOI 10.1145/959258.959260
   Kowler E, 2011, VISION RES, V51, P1457, DOI 10.1016/j.visres.2010.12.014
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moshfeghi Y, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P133
   Nister David, 2006, CVPR
   Oyekoya K, 2004, BT TECHNOL J, V22, P161, DOI 10.1023/B:BTTJ.0000047130.98920.2b
   Oyekoya O, 2004, INT C PATT RECOG, P945, DOI 10.1109/ICPR.2004.1333929
   Pantic M, 2009, IEEE SIGNAL PROC MAG, V26, P173, DOI 10.1109/MSP.2009.934186
   Papadopoulos GT, 2014, IEEE T MULTIMEDIA, V16, P440, DOI 10.1109/TMM.2013.2291535
   Puolamaki K., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P146, DOI 10.1145/1076034.1076062
   Qian M, 2009, IEEE T BIO-MED ENG, V56, P1929, DOI 10.1109/TBME.2009.2016670
   RAYNER K, 1978, PSYCHOL BULL, V85, P618, DOI 10.1037/0033-2909.85.3.618
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Shenoy P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P845
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Vrochidis S., 2011, P 1 ACM INT C MLT RE, V43
   Zhai S, 2003, COMMUN ACM, V46, P34, DOI 10.1145/636772.636795
   Zhang Y, 2010, PROCEEDINGS OF CHINA-CANADA WORKSHOP ON FINANCIAL ENGINEERING AND ENTERPRISE RISK MANAGEMENT 2010, P37, DOI 10.1145/1743666.1743674
   Zhang YD, 2014, IEEE T IMAGE PROCESS, V23, P4448, DOI 10.1109/TIP.2014.2346991
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 46
TC 4
Z9 5
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2595
EP 2611
DI 10.1007/s11042-015-2873-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000012
DA 2024-07-18
ER

PT J
AU Wen, WY
AF Wen, Wenying
TI Security analysis of a color image encryption scheme based on skew tent
   map and hyper chaotic system of 6th-order CNN against chosen-plaintext
   attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Cryptanalysis; Chosen-plaintext attack
ID ONLY MULTIMEDIA CIPHERS; QUANTITATIVE CRYPTANALYSIS; PERMUTATION;
   FOURIER
AB Recently, a color image encryption scheme based on skew tent map and hyper chaotic system of 6th-order CNN was proposed. It consists of two phases including one-time confusion and many times diffusion, which are controlled by skew tent map and hyper chaotic system of 6th-order CNN, respectively. It was claimed that the scheme can resist common attacks. However, this scheme is found to be insecure against chosen-plaintext attack. In this paper, we analyze the security weakness of the scheme. Although many keys were utilized, they keep fixed so that the corresponding chaotic keystreams are also consistent when encrypting different color images. All the keystreams used for each encryption can be wholly revealed through the derivation. In spite of many times of iterations in the diffusion phase, cryptanalytic results show that it is the same as only once. Experiment also verifies the proposed assertion.
C1 [Wen, Wenying] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330013, Peoples R China.
C3 Jiangxi University of Finance & Economics
RP Wen, WY (corresponding author), Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330013, Peoples R China.
EM wenyingfe@gmail.com
FU National Natural Science Foundation of China [61462032, 61461021];
   Natural Science Foundation of Jiangxi Province [20142BAB217012]
FX This work was supported by the National Natural Science Foundation of
   China (Grant nos. 61462032 and 61461021), the Natural Science Foundation
   of Jiangxi Province (Grant no. 20142BAB217012).
CR Benrhouma O, 2015, MULTIMED TOOLS APPL, V74, P3617, DOI 10.1007/s11042-013-1790-4
   Chen JX, 2015, COMMUN NONLINEAR SCI, V23, P294, DOI 10.1016/j.cnsns.2014.11.021
   Chen JX, 2014, J OPTICS-UK, V16, DOI 10.1088/2040-8978/16/12/125403
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Liu H, 2014, OPT LASER TECHNOL, V56, P313, DOI 10.1016/j.optlastec.2013.09.012
   Liu H, 2014, OPT LASER TECHNOL, V56, P15, DOI 10.1016/j.optlastec.2013.07.009
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Wen WY, 2015, OPT COMMUN, V341, P131, DOI 10.1016/j.optcom.2014.12.026
   You SP, 2013, OPTIK, V124, P4197, DOI 10.1016/j.ijleo.2012.12.064
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang LY, 2012, J SYST SOFTWARE, V85, P2077, DOI 10.1016/j.jss.2012.04.002
   Zhang YS, 2014, MULTIMED TOOLS APPL, V73, P1885, DOI 10.1007/s11042-013-1684-5
   Zhang YS, 2014, INFORM SCIENCES, V289, P254, DOI 10.1016/j.ins.2014.08.005
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhang YS, 2013, OPT LETT, V38, P4506, DOI 10.1364/OL.38.004506
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhang YS, 2013, OPT LASER TECHNOL, V54, P1, DOI 10.1016/j.optlastec.2013.04.029
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zheng YF, 2015, MULTIMED TOOLS APPL, V74, P7803, DOI 10.1007/s11042-014-2024-0
NR 29
TC 19
Z9 19
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3553
EP 3560
DI 10.1007/s11042-015-2464-1
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600030
DA 2024-07-18
ER

PT J
AU Beyragh, AA
   Rahbar, AG
AF Beyragh, Ali Athari
   Rahbar, Akbar Ghaffarpour
TI A novel idea on supporting mobile IPTV services over mixed DVB-H and 3G
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DVB-H; 3G; Mobile IPTV; Vertical handover
ID TV SERVICES
AB Mobile IPTV is one of the IPTV branches applied to small and handheld devices such as mobile phones, where users can access shared videos on IPTV servers by their mobile devices everywhere. Because of the availability of small-size mobile phones, mobile IPTV is going to be turned into a main part of hobbies and information gathering. This paper presents a novel concept for mixing 3G and DVB-H network to develop mobile IPTV. In this paper, we propose a framework to combine DVB-H and 3G cells in order to extend coverage area of mobile IPTV and increase penetration of mobile IPTV. By combining these two technologies, users leaving a 3G area and entering a DVB-H area (or vice versa) can continue watching their videos by vertical handover between 3G and DVB-H networks. Switching a video stream between DVB-H and 3G networks to reduce the usage fee and extend the coverage area is the main idea of this paper. In fact, this paper introduces a cheap and suitable solution for extending Mobile IPTV with available facilities in underdeveloped countries. Our performance evaluation shows the effectiveness of the proposed combination on improving the quality of service for mobile IPTV users.
C1 [Beyragh, Ali Athari] Payame Noor Univ, IT Dept, Tehran, Iran.
   [Rahbar, Akbar Ghaffarpour] Sahand Univ Technol, Comp Networks Res Lab, Tabriz, Iran.
C3 Payame Noor University; Sahand University of Technology
RP Rahbar, AG (corresponding author), Sahand Univ Technol, Comp Networks Res Lab, Tabriz, Iran.
EM ali.athari@gmail.com; akbar_rahbar92@yahoo.com
RI athari, ali/AFM-0143-2022
OI Ghaffarpour Rahbar, Akbar/0000-0002-0902-379X; Athari Beyragh,
   Ali/0000-0003-1148-3389
FU Research Institute for ICT, Iran; Payame noor university, Iran
FX This research is financially supported by Research Institute for ICT,
   Iran and Payame noor university, Iran.
CR Bikfalvi A, 2011, COMPUT NETW, V55, P1310, DOI 10.1016/j.comnet.2010.12.020
   Djama I, 2007, IEEE T BROADCAST, V53, P382, DOI 10.1109/TBC.2006.889111
   Gómez-Barquero D, 2007, IEEE NETWORK, V21, P34, DOI 10.1109/MNET.2007.334310
   Hartung F, 2007, IEEE T BROADCAST, V53, P188, DOI 10.1109/TBC.2007.891711
   Huijiong Wang, 2009, Journal of Technology Management in China, V4, P4, DOI 10.1108/17468770910942816
   Huttl O, 2011, 21 INT C RAD BRNO CZ
   Ibanez JA, 2008, ERICSSON REV, V85, P38
   Kim EH, 2006, INT WORKSH BROADB CO
   Kondrad L, 2008, P 7 INT C MOB UB MUL, P181
   Leroux P, 2011, J NETW COMPUT APPL, V34, P1474, DOI 10.1016/j.jnca.2010.10.004
   Márquez-Barja J, 2011, COMPUT COMMUN, V34, P985, DOI 10.1016/j.comcom.2010.11.010
   Mikoczy E, 2011, INT C NEXT GEN MOB A
   Miloucheva I, 2007, J COMMUN, V2, P46
   Minoli D., 2008, IP Multicast with Applications to IPTV and Mobile DVB-H
   Navarro E. S., 2009, INT J FUTURE GENERAT, V1, P51
   Negru D, 2006, COMPUT COMMUN, V29, P741, DOI 10.1016/j.comcom.2005.07.017
   Park S, 2009, IEEE INTERNET COMPUT, V13, P23, DOI 10.1109/MIC.2009.65
   Penttinen J.T.J., 2009, DVB H HDB FUNCTIONIN
   Tamea G, 2009, 2009 6TH INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATION SYSTEMS (ISWCS 2009), P418, DOI 10.1109/ISWCS.2009.5285298
   Vulic N, 2011, COMPUT NETW, V55, P1533, DOI 10.1016/j.comnet.2010.12.028
   Zekri M, 2012, COMPUT COMMUN, V35, P2055, DOI 10.1016/j.comcom.2012.07.011
NR 21
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2091
EP 2110
DI 10.1007/s11042-014-2396-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000017
DA 2024-07-18
ER

PT J
AU Cai, ZB
   Gu, ZH
   Yu, ZL
   Liu, H
   Zhang, K
AF Cai, Zebin
   Gu, Zhenghui
   Yu, Zhu Liang
   Liu, Hao
   Zhang, Ke
TI A real-time visual object tracking system based on Kalman filter and
   MB-LBP feature matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Feature matching; Kalman filter; Multi-scale block
   local binary patterns
ID ONLINE; CLASSIFICATION; MODELS; SCALE
AB Visual tracking has very important applications in practice. Many proposed visual trackers are not suitable for real-time applications because of their huge computational loads or sensitivities against changing environments such as illumination variation. In this paper, we propose a new tracker which uses modified Multi-scale Block Local Binary Patterns (MB-LBP) like feature to characterize the tracked object. Such feature has low computational load and robustness against illumination variation. An updated appearance model is build based on the modified MB-LBP feature. The model is updated in every frame by replacing the appearance model with the features extracted from the most current detected image patch of target. Moreover, we use the predicted information about the target to constructed a smaller searching area for target in new frame. It greatly reduces computational load for target searching. Numerical experiments show that the drift effect of tracker is greatly avoided and the tracker has very effective and robust performance on various test videos.
C1 [Cai, Zebin; Gu, Zhenghui; Yu, Zhu Liang] S China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Liu, Hao] Beijing Transportat Informat Ctr, Beijing, Peoples R China.
   [Zhang, Ke] Beijing Transportat Operat Coordinat Ctr, Beijing, Peoples R China.
C3 South China University of Technology
RP Gu, ZH (corresponding author), S China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
EM zhgu@scut.edu.cn
FU National Natural Science Foundation of China [61105121, 61175114];
   Natural Science Foundation of Guangdong [S2012020010945]; High Level
   Talent Project of Guangdong Province [2013KJCX0009]; China Postdoctoral
   Science Foundation [2014M560060]
FX The authors would like to thank the associate editor and the anonymous
   reviewers for their valuable comments and suggestions to improve the
   quality of the paper. This work was supported in part by the National
   Natural Science Foundation of China under grants 61105121 and 61175114,
   the Natural Science Foundation of Guangdong under grants S2012020010945,
   the High Level Talent Project of Guangdong Province 2013KJCX0009, China
   Postdoctoral Science Foundation 2014M560060.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2011, Kalman filtering: theory and practice using MATLAB
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Balan A.O., 2006, COMPUTER VISION PATT, V1, P758
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Welch G., 1995, INTRO KALMAN FILTER
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zeisl B, 2010, PROC CVPR IEEE, P1879, DOI 10.1109/CVPR.2010.5539860
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
NR 38
TC 23
Z9 23
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2393
EP 2409
DI 10.1007/s11042-014-2411-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000030
DA 2024-07-18
ER

PT J
AU Chowdhury, M
   Kundu, MK
AF Chowdhury, Manish
   Kundu, Malay Kumar
TI Comparative assessment of efficiency for content based image retrieval
   systems using different wavelet features and pre-classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Fuzzy C-means clustering algorithm;
   Multi-resolution analysis; Multi-scale geometric analysis;
   Classification
ID CONTOURLET TRANSFORM; FEATURE-SELECTION; CURVELET; COLOR;
   REPRESENTATION; ANNOTATION; SHAPE
AB Recently, Content Based Image Retrieval (CBIR) has emerged as an active research area having applications in various fields. There exist several states-of-the art CBIR systems that uses both spatial and transform features as input. However, as hardly any details study reported so far on the effectiveness of different transform domain features in CBIR paradigm. This motivates the current article where we have presented extensive comparative assessment of five different transform domain features considering various filter combinations. Three different feature representation schemes and three different classifiers have been used for this purpose. Extensive experiments on four widely used benchmark image databases (Oliva, Caltech101, Caltech256 and MIRFlickr25000) were conducted to determine the best combination of transform, filters, feature representation and classifier. Furthermore, we have also attempted to discover the optimal features from the best combinations using maximal information compression index (MICI). Both qualitative and quantitative evaluations show that the combination of Least Square Support Vector Machine (LSSVM) as a classifier and the statistical parametric framework based reduced feature representation in Non-Subsampled Contourlet Transform (NSCT) with "pyrexc" and "sinc" filters gives the best retrieval performances.
C1 [Chowdhury, Manish; Kundu, Malay Kumar] Indian Stat Inst, Machine Intelligence Unit, Kolkata 108, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Chowdhury, M (corresponding author), Indian Stat Inst, Machine Intelligence Unit, 203 BT Rd, Kolkata 108, India.
EM st.manishc@gmail.com; malay@isical.ac.in
OI Chowdhury, Manish/0000-0002-7767-3399
FU Machine Intelligence Unit, Indian Statistical Institute, Kolkata; Indian
   National Academy of Engineering (INAE)
FX The authors would like to thank all the anonymous reviewers and the
   associate editor for their valuable comments. The work is mainly funded
   by Machine Intelligence Unit, Indian Statistical Institute, Kolkata-108
   (Internal Academic Project) for providing facilities to carry out this
   work. Malay K. Kundu acknowledges the Indian National Academy of
   Engineering (INAE) for their support through INAE Distinguished
   Professor fellowship.
CR Acharyya M, 2001, SIGNAL PROCESS, V81, P1337, DOI 10.1016/S0165-1684(00)00278-4
   [Anonymous], P UNIS REP
   [Anonymous], EURASIP J APPL SIGNA
   [Anonymous], ELECT LETT COMPUT VI
   [Anonymous], 2007, UCBCSD041366 CALTECH
   [Anonymous], ORG VISION ESSAYS GE
   [Anonymous], WAVELET TOUR SIGNAL
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P INT C MULT MOD KLA
   [Anonymous], J COMPUT ROBOT
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], MED PHYS
   [Anonymous], THESIS
   [Anonymous], APPL MATH SCI
   [Anonymous], J INF DATA MANAG
   [Anonymous], P 18 ACM INT C MULT
   [Anonymous], P INT C MULT INF RET
   [Anonymous], INT J MACH LEARN CYB
   [Anonymous], NETWORKS NEURAL RIVE
   Hernández-Gracidas CA, 2013, MULTIMED TOOLS APPL, V62, P479, DOI 10.1007/s11042-011-0911-1
   Ashley J., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P24, DOI 10.1117/12.205303
   Atnafu S, 2002, J UNIVERS COMPUT SCI, V8, P613
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   Banerjee M, 2009, FUZZY SET SYST, V160, P3323, DOI 10.1016/j.fss.2009.02.024
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beecks C, 2014, MULTIMED TOOLS APPL, V71, P349, DOI 10.1007/s11042-012-1334-3
   Beecks Christian., 2011, Proceedings of the 5th Interna- tional Workshop on Ranking in Databases (DBRank), P31
   Betker AL, 2003, P ANN INT IEEE EMBS, V25, P2714, DOI 10.1109/IEMBS.2003.1280477
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Breiman L., 2001, Mach. Learn., V45, P5
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chang SF, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P443
   Ciocca G, 2011, INFORM SCIENCES, V181, P4943, DOI 10.1016/j.ins.2011.06.025
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   El Sayad I, 2012, MULTIMED TOOLS APPL, V60, P455, DOI 10.1007/s11042-010-0596-x
   Eltoukhy MM, 2010, COMPUT BIOL MED, V40, P384, DOI 10.1016/j.compbiomed.2010.02.002
   Fleites FC, 2012, INT J SEMANT COMPUT, V6, P155, DOI 10.1142/S1793351X12400065
   GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1
   Gong YH, 1996, MULTIMED TOOLS APPL, V2, P133, DOI 10.1007/BF00672252
   Grgic M., 2001, Journal of Electrical Engineering, V52, P117
   Mai HT, 2014, MULTIMED TOOLS APPL, V72, P331, DOI 10.1007/s11042-013-1360-9
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jiang W, 2006, IEEE T IMAGE PROCESS, V15, P702, DOI 10.1109/TIP.2005.863105
   Kankanhalli MS, 1999, PATTERN RECOGN LETT, V20, P109, DOI 10.1016/S0167-8655(98)00100-7
   KELLMAN PJ, 1991, COGNITIVE PSYCHOL, V23, P141, DOI 10.1016/0010-0285(91)90009-D
   Ko BC, 2012, J DIGIT IMAGING, V25, P454, DOI 10.1007/s10278-011-9443-5
   Kobayashi T, 2008, LECT NOTES COMPUT SC, V4985, P598
   Kosch H., 2010, JDIM, V8, P54
   Kovács L, 2009, LECT NOTES COMPUT SC, V5807, P265
   Larnard M, 2007, P ANN INT IEEE EMBS, P4532
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li HJ, 2013, MULTIMEDIA SYST, V19, P37, DOI 10.1007/s00530-012-0265-1
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Maji S., 2008, P COMPUTER VISION PA, P1
   Marques O, 2002, MULTIMED TOOLS APPL, V17, P21, DOI 10.1023/A:1014679605305
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Müller H, 2011, BIOL MED PHYS BIOMED, P471, DOI 10.1007/978-3-642-15816-2_19
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ou P., 2009, MODERN APPL SCI, V3, P28, DOI [10.5539/mas.v3n12p28, DOI 10.5539/MAS.V3N12P28]
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   Quellec G, 2012, IEEE T IMAGE PROCESS, V21, P1613, DOI 10.1109/TIP.2011.2180915
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rubner Y., 2001, Perceptual metrics for image database navigation
   Sandhaus P, 2011, MULTIMED TOOLS APPL, V51, P5, DOI 10.1007/s11042-010-0673-1
   Shahabi C, 2007, MULTIMED TOOLS APPL, V32, P29, DOI 10.1007/s11042-006-0070-y
   Shan H, 2009, J APPL GEOPHYS, V69, P103, DOI 10.1016/j.jappgeo.2009.08.002
   Shirdhonkar S, 2008, P COMPUTER VISION PA, P1
   Sumana I. J., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P290, DOI 10.1109/ICME.2012.90
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tang FH, 2009, INFORM SYST FRONT, V11, P381, DOI 10.1007/s10796-009-9151-6
   Tao Y, 2000, J VISUAL LANG COMPUT, V11, P323, DOI 10.1006/jvlc.2000.0160
   Tzikas D, 2010, LECT NOTES COMPUT SC, V6352, P87, DOI 10.1007/978-3-642-15819-3_12
   Vetterli Martin, 1995, Wavelets and Subband Coding
   Vollmer D. Todd, 2010, 2010 3rd International Symposium on Resilient Control Systems (ISRCS 2010), P31, DOI 10.1109/ISRCS.2010.5603475
   Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Wei Xiong, 2005, 13th Annual ACM International Conference on Multimedia, P1023, DOI 10.1145/1101149.1101359
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Yan R, 2011, IEEE MULTIMEDIA, V18, P11, DOI 10.1109/MMUL.2011.11
   Yap KH, 2010, J SIGNAL PROCESS SYS, V59, P163, DOI 10.1007/s11265-008-0288-1
   Zhang JL, 2011, OPT APPL, V41, P183
NR 89
TC 11
Z9 11
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11595
EP 11630
DI 10.1007/s11042-014-2252-3
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600028
DA 2024-07-18
ER

PT J
AU Dantcheva, A
   Dugelay, JL
AF Dantcheva, Antitza
   Dugelay, Jean-Luc
TI Assessment of female facial beauty based on anthropometric,
   non-permanent and acquisition characteristics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial beauty; Facial aesthetics; Facial symmetry; Female aesthetics;
   Female beauty; Beauty prediction; Beauty estimation; Beauty assessment;
   Plastic surgery; Aging beauty
ID IMAGE QUALITY ASSESSMENT; ATTRACTIVE FACES; SHAPE
AB In this work we study the interrelation between, on the one hand, subjective perception of female facial aesthetics, and on the other hand, selected objective parameters that include facial features, photo-quality, as well as non-permanent facial characteristics. This study seeks to provide insight on the role of this specific set of features in affecting the way humans perceive facial images. The approach is novel in that it jointly considers both previous results on photo quality and beauty assessment, as well as non-permanent facial characteristics and expressions. Based on 37 such objective parameters, we construct a metric that aims to quantify modifiable parameters for aesthetics enhancement, as well as tunes systems that would seek to predict the way humans perceive facial aesthetics. The proposed metric is evaluated on a face dataset, that includes images with variations in illumination, image quality, as well as age, ethnicity and expression. We show that our approach outperforms two state of the art beauty estimation metrics. In addition we apply the designed metric in three interesting datasets, where we assess beauty in images of females before and after plastic surgery, of females across time, as well as of females famous for their beauty. We conclude by giving insight towards beauty prediction.
C1 [Dantcheva, Antitza] INRIA, Sophia Antipolis, France.
   [Dugelay, Jean-Luc] EURECOM, Paris, France.
C3 Inria; IMT - Institut Mines-Telecom; EURECOM
RP Dantcheva, A (corresponding author), INRIA, Sophia Antipolis, France.
EM antitza.dantcheva@inria.fr; jean-luc.dugelay@eurecom.fr
RI DUGELAY, Jean-Luc/ABE-7096-2021
OI DUGELAY, jean-luc/0000-0003-3151-4330
CR Aarabi P, 2001, P IEEE SMC
   ALLEY TR, 1991, PSYCHOL SCI, V2, P123, DOI 10.1111/j.1467-9280.1991.tb00113.x
   [Anonymous], 1976, PHOTOGRAPHIC COMPOSI
   [Anonymous], 2010, 2010 4 IEEE INT C BI
   [Anonymous], 2010, P ECCV
   [Anonymous], 2011, P 2011 IEEE INT C MU
   [Anonymous], 2014, UNIVERSAL CONCEPTS B, V4
   [Anonymous], AUTOMATIC PREDICTION
   [Anonymous], 2013, DATING RATING WEBPAG
   Bhattacharya S, 2010, P ACM MM
   Bottino A, 2010, LECT NOTES COMPUT SC, V6111
   Braun C., 2001, Beautycheck Ursachen und Folgen von Attraktivitaet
   Buggio L, 2012, GYNECOL ENDOCRINOL, V28, P753, DOI 10.3109/09513590.2012.662545
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang F, 2009, NEURAL COMPUT, V21, P890, DOI 10.1162/neco.2008.07-07-566
   Chen C, 2014, VISAPP 14
   Chen CJ, 2013, INT CONF BIOMETR
   Chen FM, 2010, LECT NOTES COMPUT SC, V6165, P21, DOI 10.1007/978-3-642-13923-9_3
   Cheng B., 2010, P ACM MM
   Chiang WC, 2014, PATTERN RECOGN, V47, P1249, DOI 10.1016/j.patcog.2013.09.007
   Dantcheva Antitza, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P309, DOI 10.1109/AVSS.2011.6027342
   Dantcheva A., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P511, DOI 10.1109/MMSP.2010.5662074
   Dantcheva A, 2011, P INT C COMP VIS WOR
   Dantcheva A, 2012, IEEE INT C BIOM THEO
   Davis BC, 2008, P IEEE ICIP
   Ding L., 2008, P CVPR, P1
   Doczi Gyorgy., 2005, POWER LIMITS PROPORT
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   Fink B, 2006, EVOL HUM BEHAV, V27, P433, DOI 10.1016/j.evolhumbehav.2006.08.007
   Fisher Maryanne L, 2006, J Cosmet Dermatol, V5, P190, DOI 10.1111/j.1473-2165.2006.00249.x
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Gray D, 2010, P ECCV
   Gunes H, 2004, P SMC
   Gunes H., 2011, P JOINT ACM WORKSH H, P19
   Guo J-M, 2011, IEEE SIGNAL PROCESSI
   Irem Turkmen H, 2007, P EUSIPCO
   Ji HI, 2004, PERCEPTION, V33
   Kagian A, 2006, P NIPS, P674
   Kagian A, 2008, VISION RES, V48, P235, DOI 10.1016/j.visres.2007.11.007
   Kendall M.G., 1973, The Advanced Theory of Statistics: Inference and Relationship, V2
   LANGLOIS JH, 1990, PSYCHOL SCI, V1, P115, DOI 10.1111/j.1467-9280.1990.tb00079.x
   Laurentini A, 2014, COMPUTER VISION IMAG
   Lee L, 2008, PSYCHOL SCI, V19, P669, DOI 10.1111/j.1467-9280.2008.02141.x
   Mao H, 2009, P IEEE SMC
   McKeen S, 2006, EDMONTON J
   Mizumoto Y, 2009, AM J ORTHOD DENTOFAC, V136, P168, DOI 10.1016/j.ajodo.2007.07.029
   Moorthy A., 2009, BIQI software release
   Moorthy A. K., 2009, IEEE Signal Process. Lett, V17, P7
   O'Toole AJ, 1999, IMAGE VISION COMPUT, V18, P9, DOI 10.1016/S0262-8856(99)00012-8
   Obrador P, 2010, IEEE IMAGE PROC, P3185, DOI 10.1109/ICIP.2010.5654231
   Parris C, 1999, TECHNICAL REPORT
   Penton-Voak IS, 1999, CURR PSYCHOL, V18, P104
   PERRETT DI, 1994, NATURE, V368, P239, DOI 10.1038/368239a0
   Said CP, 2011, PSYCHOL SCI, V22, P1183, DOI 10.1177/0956797611419169
   Savakis AE, 2000, P SOC PHOTO-OPT INS, V3959, P111, DOI 10.1117/12.387147
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083
   Sutic D, 2010, P MIPRO
   Vapnik Vladimir, 2006, INFORM SCI STAT
   Wang J, 2014, HUMAN CTR SOCIAL MED, P133
   Wang Y., 2013, Proceedings of the 21st ACM international conference on Multimedia, P369
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WANG Z, 2002, P IEEE ICIP
   Whitehill J, 2008, P IEEE FRG
   Wu B, 2004, P ICPR
   Zhang D, 2011, PATTERN RECOGN, V44, P940, DOI 10.1016/j.patcog.2010.10.013
NR 67
TC 12
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11331
EP 11355
DI 10.1007/s11042-014-2234-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600017
DA 2024-07-18
ER

PT J
AU Khoenkaw, P
   Piamsa-nga, P
AF Khoenkaw, Paween
   Piamsa-nga, Punpiti
TI Automatic pan-and-scan algorithm for heterogeneous displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video cropping; Image cropping; Importance estimation; Pan-and-scan;
   Mobile device; Cinematic; Video aspect ratio adaption; Video analysis
ID ATTENTION
AB This paper presents a fully automatic algorithm for selecting the most appropriate areas of every video frame to show on heterogeneous display devices. The algorithm is used to analyze cinematic features in video and identify important parts of each frame. The proposed method is a client-server model. An importance map of video is created on the server and transmitted along with the video stream. The client uses this map to determine the cropping area of video frames to fit its display screen. An experimental comparison involving users' satisfaction of 160 participants who compared the results of our algorithm with others, such as letterbox, and commercially cropped editions of well-known motion pictures was performed. The results show that the audience preferred the video processed by our algorithm as the algorithm requires little additional preprocessing and little extra information embedded in the video stream. The results suggest that this algorithm could improve the video viewing experience for mobile users.
C1 [Khoenkaw, Paween; Piamsa-nga, Punpiti] Kasetsart Univ, Dept Comp Engn, Fac Engn, Bangkok 10900, Thailand.
C3 Kasetsart University
RP Piamsa-nga, P (corresponding author), Kasetsart Univ, Dept Comp Engn, Fac Engn, 50 Ngam Wong Wan Rd, Bangkok 10900, Thailand.
EM g4885027@ku.ac.th; pp@ku.ac.th
RI Piamsa-nga, Punpiti/D-4846-2012
OI Khoenkaw, Paween/0000-0002-4687-2256; Piamsa-nga,
   Punpiti/0000-0001-9730-3005
FU Kasetsart University Research and Development Institute
FX The authors would like to thank the reviewers for their comments that
   help us improve the manuscript. We also would like to thank Dr. James E.
   Brucker and Dr. Bussba Tonthong for assistances on proofreading. This
   research is partially supported by research grant from Kasetsart
   University Research and Development Institute.
CR Abrams J.J., 2009, STAR TREK
   [Anonymous], 2012, PALM TREO PROT SPEC
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], 2012, NOK N80 TECHN SPEC
   [Anonymous], 1984, Indiana Jones and the Temple of Doom
   [Anonymous], 1994, SMPTE SPECIFICATIONS
   [Anonymous], 2003, SMPTE METHOD DETEMIN
   [Anonymous], 1991, Film directing shot by shot: visualizing from concept to screen
   [Anonymous], 2006, P 14 ACM INT C MULT
   Apple.com, 2012, IPH 3GS TECHN SPEC
   Baina J., 1995, Fifth International Conference on Image Processing and its Applications (Conf. Publ. No.410), P232, DOI 10.1049/cp:19950655
   Bay M, 2009, TRANFORMERS REVENGE
   Becker Harold., 1998, MERCURY RISING
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   Blackberry.com, 2012, BLACKB BOLD 9900 TEC
   Byers Z, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2636
   Chen DY, 2011, J VIS COMMUN IMAGE R, V22, P226, DOI 10.1016/j.jvcir.2010.12.003
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Cheng WH, 2007, IEEE T CIRC SYST VID, V17, P43, DOI 10.1109/TCSVT.2006.885717
   Chin CH, 2003, EL PACKAG TECH CONF, P777
   Chung Nam Cho, 1999, 1999 Digest of Technical Papers. International Conference on Consumer Electronics (Cat. No.99CH36277), P92, DOI 10.1109/ICCE.1999.785182
   Dalton C. J., 1996, International Broadcasting Convention (Conf. Publ.No.428), P366, DOI 10.1049/cp:19960835
   Evans-Pughe C, 2005, IEE REVIEW, V51, P44
   Fan Xin., 2003, P ACM MULTIMEDIA, P247
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Grinias I, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P679, DOI 10.1109/ICDSP.2002.1028182
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He J, 2003, IEEE T CONSUM ELECTR, V49, P257, DOI 10.1109/TCE.2003.1209511
   Holzinger A, 2005, COMMUN ACM, V48, P71, DOI 10.1145/1039539.1039541
   Jordan N., 2006, INT C DIG TEL, P55
   Kim JK, 2005, IEEE ICCE, P67
   KOPF S, 2006, P 14 ACM INT C MULT, P957
   Kopf S, 2011, MULTIMED TOOLS APPL, V51, P819, DOI 10.1007/s11042-010-0717-6
   Lee MS, 2007, IEEE COMMUN MAG, V45, P61, DOI 10.1109/MCOM.2007.284539
   Li-Wei He, 1996, Computer Graphics Proceedings. SIGGRAPH '96, P217
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Manchel F., 1990, FILM STUDY ANAL BIBL
   Mann Michael., 1986, MANHUNTER
   Nam HM, 2010, IEEE T CONSUM ELECTR, V56, P182, DOI 10.1109/TCE.2010.5439143
   Park CH, 2000, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - 2000 DIGEST OF TECHNICAL PAPERS, P250, DOI 10.1109/ICCE.2000.854611
   Piamsa-nga P, 2004, IEEE IMAGE PROC, P365
   Prince Stephen, 2004, MOVIES MEANING INTRO
   Sang Ku K, 1998, DIGEST TECHNICAL PAP, P430
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Shen C, 2006, INT EL DEVICES MEET, P69
   Spielberg Steven., 1981, Raiders of the Lost Ark
   Spielberg Steven., 1989, INDIANA JONES LAST C
   SUBBARAO M, 1993, OPT ENG, V32, P2824, DOI 10.1117/12.147706
   Suh B., 2003, AUTOMATIC THUMBNAIL
   Tae-Kyu K, 2006, P IEEE INT C AC SPEE, V3, P3
   Union IT, 2012, REC ITU R BT 500 13
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1711
   Wheeler LJ, 1969, PRINCIPLES CINEMATOG
   Wright S., 2006, DIGITAL COMPOSITING
   Xue Yin-zhu, 2011, Journal of Shanghai University, V15, P331, DOI 10.1007/s11741-011-0746-2
   Yan JZ, 2013, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2013.130
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yang SH, 2005, IEEE ASIAN SOLID STA, P101, DOI 10.1109/ASSCC.2005.251817
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang MJ, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P438
   [No title captured]
NR 65
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11837
EP 11865
DI 10.1007/s11042-014-2308-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600039
DA 2024-07-18
ER

PT J
AU Lokoc, J
AF Lokoc, Jakub
TI Approximating adaptive distance measures using scalable feature
   signatures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity search; Approximate search; Content-based retrieval; Adaptive
   distance measures; Scalable descriptor; Agglomerative hierarchical
   clustering
ID EARTH MOVERS DISTANCE
AB The feature signatures in connection with the adaptive distance measures have become a respected similarity model for effective multimedia retrieval. However, the efficiency of the model is still a challenging task because the adaptive distance measures have at least quadratic time complexity according to the number of tuples in feature signatures. In order to reduce the number of tuples in feature signatures, we introduce the scalable feature signatures, a new formal framework enabling definition of new methods based on agglomerative hierarchical clustering. We show the framework can be used to express nontrivial feature signature reduction techniques including also popular agglomerative hierarchical clustering techniques. We experimentally demonstrate our new feature signature reduction techniques can be used to implement order of magnitude faster yet effective filter distances approximating the original adaptive distance measures. We also show the filter distances using our new feature signature reduction techniques can compete or even outperform the filter distances based on the related feature signature reduction techniques.
C1 [Lokoc, Jakub] Charles Univ Prague, Fac Math & Phys, Dept Software Engn, SIRET Res Grp, Prague, Czech Republic.
C3 Charles University Prague
RP Lokoc, J (corresponding author), Charles Univ Prague, Fac Math & Phys, Dept Software Engn, SIRET Res Grp, Prague, Czech Republic.
EM lokoc@ksi.mff.cuni.cz
RI Lokoc, Jakub/P-1216-2017
OI Lokoc, Jakub/0000-0002-3558-4144
FU Czech Science Foundation [GACR P202/12/P297]
FX This research has been supported by Czech Science Foundation project
   GACR P202/12/P297. I would also like to thank prof. Mathias Lux for his
   help with experiments regarding LIRE framework and provided detailed
   descriptions of utilized LIRE feature histograms and distance measures.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], MMM
   [Anonymous], 2013, P 3 ACM C INT C MULT
   Assent I, 2008, PROC INT CONF DATA, P307, DOI 10.1109/ICDE.2008.4497439
   Beecks C, 2011, LECT NOTES COMPUT SC, V6523, P381
   Beecks C, 2010, I C DATA ENGIN WORKS, P10, DOI 10.1109/ICDEW.2010.5452772
   Beecks Christian., 2010, ACM International Conference on Image and Video Retrieval, P438, DOI [10.1145/1816041.1816105, DOI 10.1145/1816041.1816105]
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Budikova P, 2011, LECT NOTES COMPUT SC, V6966, P130, DOI 10.1007/978-3-642-24469-8_15
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chatzichristofis S., 2009, Proc. ofthe 6th IASTED International Conference, V134643, page, P064
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Davidson I, 2009, DATA MIN KNOWL DISC, V18, P257, DOI 10.1007/s10618-008-0103-4
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Do T. T. T., 2010, Proceedings of 2010 21st IEEE International Symposium on Rapid System Prototyping (RSP), DOI 10.1109/RSP.2010.5656347
   Everitt B. S., 2011, CLUSTER ANAL, V5, P71
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   GORDON AD, 1987, J ROY STAT SOC A STA, V150, P119, DOI 10.2307/2981629
   Hetland ML, 2013, INFORM SYST, V38, P989, DOI 10.1016/j.is.2012.05.011
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   LANCE GN, 1967, COMPUT J, V9, P373, DOI 10.1093/comjnl/9.4.373
   Lokoc Jakub, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8326, P415, DOI 10.1007/978-3-319-04117-9_49
   Lokoc Jakub, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P86, DOI 10.1007/978-3-319-04114-8_8
   Lokoc Jakub, 2012, Similarity Search and Applications. Proceedings of the 5th International Conference, SISAP 2012, P177, DOI 10.1007/978-3-642-32153-5_13
   Lux M., 2013, P 21 ACM INT C MULT, P843
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   *MPEG 7, 2002, 1593832002 MPEG7 ISO
   Park BG, 2006, LECT NOTES COMPUT SC, V4179, P990
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Rubner Y., 2001, Perceptual metrics for image database navigation
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Skopal T, 2012, IEEE T KNOWL DATA EN, V24, P868, DOI 10.1109/TKDE.2011.19
   Wagstaff K., 2000, AAAI/IAAI, V1097, P577
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Zhao HF, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P195, DOI 10.1109/WKDD.2010.123
NR 41
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11569
EP 11594
DI 10.1007/s11042-014-2251-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600027
DA 2024-07-18
ER

PT J
AU Sakamoto, M
   Nakajima, T
   Alexandrova, T
AF Sakamoto, Mizuki
   Nakajima, Tatsuo
   Alexandrova, Todorka
TI Enhancing values through virtuality for intelligent artifacts that
   influence human attitude and behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Persuasion; Intelligent artifacts; Values; Virtuality; Fictionality;
   Ideological messages; Transmedia storytelling; Internet of things;
   Gamification
ID MODEL
AB Embodied interaction technologies allow us to enhance physical artifacts surrounding us by adding an information layer to the artifacts. The information layer that we call virtual forms presents dynamically generated visual information representing virtual objects and creatures that influence human attitude and behavior. The focus of our research is to develop intelligent artifacts enhanced with virtual forms that influence human attitude and behavior. To suggest some ways to develop such artifacts that harmoniously integrate virtual forms into them, based on our experience with three case studies presented in the paper, we propose a value-based analysis framework, which allows us to discuss and consider some good-design implications for the design of the enhanced intelligent artifacts. We also present design implications to apply the value-based analysis framework to analyze and enhance one of intelligent artifact. Finally, our experience suggests that incorporating fictionality is a promising direction for the designing of intelligent artifacts with ideological messages intended to influence people's attitude and behavior.
C1 [Sakamoto, Mizuki; Nakajima, Tatsuo; Alexandrova, Todorka] Waseda Univ, Dept Comp Sci & Engn, Shinjuku Ku, Tokyo 1698555, Japan.
C3 Waseda University
RP Nakajima, T (corresponding author), Waseda Univ, Dept Comp Sci & Engn, Shinjuku Ku, 3-4-1 Okubo, Tokyo 1698555, Japan.
EM tatsuo@dcl.cs.waseda.ac.jp
OI Alexandrova, Todorka/0000-0001-5765-8581
FU Grants-in-Aid for Scientific Research [14J07106] Funding Source: KAKEN
CR [Anonymous], P 25 INT C DAT EXP S
   [Anonymous], 1998, MEDIA EQUATION MEDIA
   [Anonymous], 2009, PERVASIVE GAMES THEO
   [Anonymous], 2005, The semantic turn: A new foundation for design
   [Anonymous], 2013, P INT C MOB UB MULT
   [Anonymous], 2009, THESIS
   [Anonymous], 2010, Experience-Centered Design: Designers, Users, and Communities in Dialogue
   Ardenne P., 2009, AC DC CONT ART CONT
   Arrasvuori J., 2011, P DES PLEAS PROD INT
   Baudrillard Jean., 1981, Simulacra and Simulation
   Beyer Hugh., 1999, CONTEXTUAL DESIGN
   Bogost I., 2010, Newsgames: Journalism at play
   Boztepe S, 2007, INT J DES, V1, P55
   Cagan C., 2002, Creating breakthrough products: Innovation from product planning to program approval
   Cockton G., 2006, P 4 NORDIC C HUMAN C, P165
   Consolvo S., 2006, P INT C HUM FACT COM
   Deterding S., 2011, P AC MINDTR C
   Dewey John., 1987, Art as Experience
   Djajadiningrat Tom, 2002, P 4 C DES INT SYST P, P285, DOI 10.1145/
   Dunne Anthony, 2013, SPECULATIVE EVERYTHI, DOI DOI 10.1093/JDH/EPV001
   Dunne L., 2010, FASHION PRACT, V2, P41, DOI DOI 10.2752/175693810X12640026716393
   Ehn P., 2017, PDC 17 PART DES C, P41
   Fogg B.J., 2003, PERSUASIVE TECHNOLOG, DOI [DOI 10.1145/764008.763957, 10.1016/B978-1-55860-643-2.X5000-8, DOI 10.1016/B978-1-55860-643-2.X5000-8]
   Fredrikson B, 2009, POSITIVITY TOP NOTCH
   Friedman B, 2006, ADV MANAG INFORM SYS, V5, P348
   Fuad-Luka A., 2009, DESIGN ACTIVISM BEAU
   Fujinami K, 2005, LECT NOTES COMPUT SC, V3823, P335
   Fujinami K., 2005, LNCS, P137
   Fulton SJ, 2005, THOUGHTLESS ACTS
   Goffman E., 1974, Frame Analysis: An Essay on the Organization of Experience
   Hakknas L., 2001, J PERSONAL UBIQUITOU, V5
   Hara K, 2011, JAPANESE DESIGN AEST
   Hassenzahl M., 2006, USER EXPERIENCE RES, P91
   Hekler EB., 2013, P CHI 2013
   Huizinga Johan., 2000, Homo Ludens: A Study of the Play-Element in Culture, DOI [10.1177/0907568202009004005, DOI 10.1177/0907568202009004005]
   IDEO, 2003, IDEO Method Cards: 51 Ways to Inspire Design
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Iwata T, 2011, IEEE INT CONF EMBED, P105, DOI 10.1109/RTCSA.2011.43
   Jordan P.W., 2002, Designing pleasurable products: An introduction to the new human factors
   Jull J., 2005, Half-Real: Video Games between Real Rules and Fictional Worlds
   Kahneman D., 2012, Pensar rapido, pensar despacio
   Kawsar F, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P282, DOI 10.1145/1409635.1409673
   Kawsar Fahim., 2005, sOc-EUSAI '05, P141, DOI DOI 10.1145/1107548.1107587
   Kim WC, 2005, CALIF MANAGE REV, V47, P105, DOI 10.2307/41166308
   Lehdonvirta V., 2011, Knowledge Map of the Virtual Economy
   Lehdonvirta V., 2009, PUBLICATIONS TURKU S, V11, P2009
   Lehdonvirta V, 2009, ELECTRON COMMER RES, V9, P97, DOI 10.1007/s10660-009-9028-2
   Lockton D, 2010, APPL ERGON, V41, P382, DOI 10.1016/j.apergo.2009.09.001
   Marzano S., 2003, The new everyday view on ambient intelligence
   Maslow A.H., 1970, MOTIVATION PERSONALI
   Mattila A.S., 2000, J SERV RES-US, V3, P35, DOI DOI 10.1177/109467050031003
   McGonical Jane., 2011, REALITY IS BROKEN WH
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Nakajima T, 2013, PERS UBIQUIT COMPUT, V17, P107, DOI 10.1007/s00779-011-0469-y
   Peterssen M.G., 2004, Proceedings of the 5th Conference on Design Interactive Systems: Processes, Practices, Methods and Techniques DSI '04, P269, DOI [DOI 10.1145/1013115.1013153, 10.1145/1013115.1013153.]
   Pine B.Joseph., 2011, The Experience Economy
   Prochaska JO, 1997, AM J HEALTH PROMOT, V12, P38, DOI 10.4278/0890-1171-12.1.38
   Ritterfeld U., 2009, Serious Games: Mechanisms and Effects, DOI [DOI 10.4324/9780203891650, 10.4324/9780203891650]
   RUPPEL M, 2012, THESIS
   Ruth M., 2007, PRODUCT EXPERIENCE H
   Sakamoto M., 2014, P 6 INT C SOC COMP S
   Sakamoto M., 2014, P 2 INT C DISTR AMB
   Sakamoto M, 2014, P INT C INT POL POL
   Sakamoto M., 2013, P 6 INT C ADV COMP H
   Sakamoto M., 2014, 6 INT C CROSS CULT D
   Sakamoto M., 2014, INT J SMART HOME, V8
   Sakamoto Mizuki, 2014, INT J HYBRID INFORM, V7
   Schwartz Barry., 2005, The Paradox of Choice: Why More Is Less
   Schwarz N, 2006, SOCIAL PSYCHOL HDB B
   Sengers P., 2006, Designing Interactive Systems. DIS2006, P99
   Sunstein C., 2009, NUDGE IMPROVING DECI
   Szulborski D., 2005, THIS IS NOT GAME GUI
   Todd PM, 2007, EUR J OPER RES, V177, P1317, DOI 10.1016/j.ejor.2005.04.005
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
   Zuckerman O., 2014, PERSONAL UBIQUITOUS, V18
NR 75
TC 24
Z9 24
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11537
EP 11568
DI 10.1007/s11042-014-2250-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600026
DA 2024-07-18
ER

PT J
AU Song, XF
   Liu, FL
   Luo, XY
   Lu, JC
   Zhang, Y
AF Song, Xiaofeng
   Liu, Fenlin
   Luo, Xiangyang
   Lu, Jicang
   Zhang, Yi
TI Steganalysis of perturbed quantization steganography based on the
   enhanced histogram features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE perturbed quantization steganography; steganalysis; histogram feature;
   detection accuracy
ID IMAGE STEGANALYSIS
AB In this paper, the enhanced histogram features are proposed for detecting perturbed quantization (PQ) steganography applied to double-compression JPEG image. Firstly, the principle of PQ steganography is analyzed and the special positions for feature extraction are determined. Secondly, the changes of the global, local and dual histogram features are analyzed for PQ embedding, and then these histogram features are extracted from the DCT coefficients at the special positions. Thirdly, to improve the effectiveness and diversity of steganalysis feature, the three kinds of histogram features are also extracted from DCT coefficients difference. Lastly, all the histogram features are calibrated and combined as the enhanced histogram features, and the ensemble classifier is employed to obtain detection results. The experimental results show the proposed feature can improve the detection accuracy for PQ and PQt; for PQe, it can obtain approximate detection accuracy with Cartesian-calibrated JPEG rich model (CC-JRM), but the feature dimensionality is far below CC-JRM.
C1 [Song, Xiaofeng; Liu, Fenlin; Luo, Xiangyang; Lu, Jicang; Zhang, Yi] Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
   [Song, Xiaofeng; Liu, Fenlin; Luo, Xiangyang; Lu, Jicang; Zhang, Yi] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Luo, XY (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
EM xiaofengsong@sina.com; liufenlin@sina.vip.com; xiangyangluo@126.com;
   lujicang@sina.com; zhangyi@163.com
RI Liu, Yi/HTN-4916-2023
FU National Natural Science Foundation of China [61379151, 61274189,
   61302159]; Excellent Youth Foundation of Henan Province of China
   [144100510001]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61379151, 61274189, and 61302159), and the Excellent Youth
   Foundation of Henan Province of China (No. 144100510001).
CR [Anonymous], P 13 ACM MULT SEC WO
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Avcibas I, 2005, EURASIP J APPL SIG P, V2005, P2749, DOI 10.1155/ASP.2005.2749
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Fridrich J, 2005, MULTIMEDIA SYST, V11, P98, DOI 10.1007/s00530-005-0194-3
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J., 2004, MMSEC 04, P4
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Gül G, 2007, IEEE SIGNAL PROC LET, V14, P205, DOI 10.1109/LSP.2006.884010
   Kharrazi M, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2400672
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Pevny T, 2007, P ELECT IMAGING SECU, P1
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sallee P, 2005, INT J IMAGE GRAPH, V5, P167, DOI 10.1142/S0219467805001719
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
NR 23
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11045
EP 11071
DI 10.1007/s11042-014-2217-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600005
DA 2024-07-18
ER

PT J
AU Wang, FN
   Sahli, H
   Gao, JB
   Jiang, DM
   Verhelst, W
AF Wang, Fengna
   Sahli, Hichem
   Gao, Junbin
   Jiang, Dongmei
   Verhelst, Werner
TI Relevance units machine based dimensional and continuous speech emotion
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Relevance units machine; Continuous speech emotion regression;
   Dimensional emotion modeling
ID RECOGNITION
AB Emotion plays a significant role in human-computer interaction. The continuing improvements in speech technology have led to many new and fascinating applications in human-computer interaction, context aware computing and computer mediated communication. Such applications require reliable online recognition of the user's affect. However most emotion recognition systems are based on speech via an isolated short sentence or word. We present a framework for online emotion recognition from speech. On the front-end, a voice activity detection algorithm is used to segment the input speech, and features are estimated to model long-term properties. Then, dimensional and continuous emotion recognition is performed via a Relevance Units Machine (RUM). The advantages of the proposed system are: (i) its computational efficiency in run-time (regression outputs can be produced continuously in pseudo real-time), (ii) RUM offers superior sparsity to the well-known Support Vector Regression (SVR) and Relevance Vector Machine for regression (RVR), and (iii) RUM's predictive performance is comparable to SVR and RVR.
C1 [Wang, Fengna; Sahli, Hichem; Verhelst, Werner] Univ Brussel, Dept Elect & Informat ETRO, VUB NPU Joint AVSP Lab, B-1050 Brussels, Belgium.
   [Sahli, Hichem] Interuniv Microelect Ctr IMEC, Leuven, Belgium.
   [Gao, Junbin] Charles Sturt Univ, Sch Comp & Math, Bathurst, NSW 2795, Australia.
   [Jiang, Dongmei] Northwestern Polytech Univ, Sch Comp Sci, VUB NPU Joint AVSP Lab, Xian 710072, Peoples R China.
   [Verhelst, Werner] iMinds, Gaston Crommenlaan 8, B-9050 Ghent, Belgium.
C3 IMEC; Charles Sturt University; Northwestern Polytechnical University;
   IMEC
RP Wang, FN (corresponding author), Univ Brussel, Dept Elect & Informat ETRO, VUB NPU Joint AVSP Lab, Pleinlaan 2, B-1050 Brussels, Belgium.
EM fwang@etro.vub.ac.be; hsahli@vub.ac.be; jbgao@csu.edu.au;
   jiangdm@nwpu.edu.cn; wverhelst@etro.vub.ac.be
RI Gao, Junbin/C-6566-2008; Gao, Junbin/A-1766-2009
OI Sahli, Hichem/0000-0002-1774-2970; Gao, Junbin/0000-0001-9803-0256
FU CSC-VUB [[2009]3012]; EU FP7 project ALIZ-E [248116]
FX The research reported in this paper has been supported in part by the
   CSC-VUB scholarship grant [2009]3012, and the EU FP7 project ALIZ-E
   grant 248116.
CR Baron-Cohen S., 2003, Mind Reading: The interactive guide to emotion
   Bishop C. M., 2006, PATTERN RECOGN
   Borod J., 2000, The Neuropsychology of Emotion (Affective Science)
   Bouman C.A., 1997, CLUSTER UNSUPERVISED
   Busso C, 2009, IEEE T AUDIO SPEECH, V17, P582, DOI 10.1109/TASL.2008.2009578
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Cowie R., 2000, PROC ISCA WORKSHOP S, P19
   Dekens T, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2660
   Eyben F, 2010, J MULTIMODAL USER IN, V3, P7, DOI 10.1007/s12193-009-0032-6
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   FORGACS P, 1971, THORAX, V26, P288, DOI 10.1136/thx.26.3.288
   Gao JB, 2009, LECT NOTES ARTIF INT, V5476, P612
   Grimm M, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P381
   Grimm M., 2007, Robust speech recognition and understanding, P281, DOI DOI 10.5772/4755
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Gunes Hatice, 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition, P185
   HUTTAR GL, 1968, J SPEECH HEAR RES, V11, P481, DOI 10.1044/jshr.1103.481
   Kehrein R, 2002, P SPEECH PROS
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lefter I, 2010, COMPSYSTECH ACM INT, P287
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Nicolaou MA, 2012, IMAGE VISION COMPUT, V30, P186, DOI 10.1016/j.imavis.2011.12.005
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Rong J, 2009, INFORM PROCESS MANAG, V45, P315, DOI 10.1016/j.ipm.2008.09.003
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K.R., 1977, Motivation and Emotion, V1, P331, DOI DOI 10.1007/BF00992539
   Scherer K. R., 2001, Appraisal processes in emotion: Theory, methods, research, P92
   Schuller B, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P449
   Schuller B, 2011, LECT NOTES COMPUT SC, V6975, P415, DOI 10.1007/978-3-642-24571-8_53
   Shami M, 2007, SPEECH COMMUN, V49, P201, DOI 10.1016/j.specom.2007.01.006
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Vogt T, 2008, LECT NOTES ARTIF INT, V5078, P188, DOI 10.1007/978-3-540-69369-7_21
   Whissell C. M., 1989, The Measurement of Emotions, P113, DOI 10.1016/B978-0-12-558704-4.50011-6
   Wöllmer M, 2010, IEEE J-STSP, V4, P867, DOI 10.1109/JSTSP.2010.2057200
   WOLLMER M, 2008, 9 ANN C INT SPEECH C, P597
   Wu DR, 2010, IEEE INT CON MULTI, P737, DOI 10.1109/ICME.2010.5583101
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 41
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 9983
EP 10000
DI 10.1007/s11042-014-2319-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400009
DA 2024-07-18
ER

PT J
AU Wu, ZY
   Ning, YS
   Zang, X
   Jia, J
   Meng, FB
   Meng, HL
   Cai, LH
AF Wu, Zhiyong
   Ning, Yishuang
   Zang, Xiao
   Jia, Jia
   Meng, Fanbo
   Meng, Helen
   Cai, Lianhong
TI Generating emphatic speech with hidden Markov model for expressive
   speech synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emphasis; Emphatic speech synthesis; Hidden Markov model (HMM); Decision
   tree clustering; Parameter compensation
ID FOCUS
AB Emphasis plays an important role in expressive speech synthesis in highlighting the focus of an utterance to draw the attention of the listener. As there are only a few emphasized words in a sentence, the problem of the data limitation is one of the most important problems for emphatic speech synthesis. In this paper, we analyze contrastive (neutral versus emphatic) speech recordings considering kinds of contexts, i.e. the relative locations between the syllables and the emphasized words. Based on the analysis, we propose a hidden Markov model (HMM) based method for emphatic speech synthesis with limited amount of data. In this method, decision trees (DTs) are constructed with non-emphasis-related questions using both neutral and emphasis corpora. The data in each leaf node of the DTs are classified into 6 emphasis categories according to the emphasis-related questions. The data in the same emphasis category are grouped into one sub-node and are used to train one HMM. As there might be no data of some specific emphasis categories in the leaf nodes of the DTs, a method based on cost calculation is proposed to select a suitable HMM in the same leaf node for predicting parameters. Further a compensation model is proposed to adjust the predicted parameters. We conduct a series of experiments to evaluate the performances of the approach. Experiments indicate that the proposed emphatic speech synthesis models improve the emphasis quality of synthesized speech while keeping a high degree of the naturalness.
C1 [Wu, Zhiyong; Ning, Yishuang; Zang, Xiao; Jia, Jia; Meng, Fanbo; Meng, Helen; Cai, Lianhong] Tsinghua Univ, Grad Sch Shenzhen, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Shenzhen 518055, Peoples R China.
   [Wu, Zhiyong; Ning, Yishuang; Zang, Xiao; Jia, Jia; Meng, Fanbo; Meng, Helen; Cai, Lianhong] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen Key Lab Informat Sci & Technol, Shenzhen 518055, Peoples R China.
   [Wu, Zhiyong; Meng, Helen] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
   [Wu, Zhiyong; Ning, Yishuang; Zang, Xiao; Jia, Jia; Meng, Fanbo; Cai, Lianhong] Tsinghua Univ, TNList, Beijing 100084, Peoples R China.
   [Wu, Zhiyong; Ning, Yishuang; Zang, Xiao; Jia, Jia; Meng, Fanbo; Cai, Lianhong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School;
   Tsinghua Shenzhen International Graduate School; Tsinghua University;
   Chinese University of Hong Kong; Tsinghua University; Tsinghua
   University
RP Zang, X (corresponding author), Tsinghua Univ, Grad Sch Shenzhen, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Shenzhen 518055, Peoples R China.
EM zywu@se.cuhk.edu.hk; ningys13@mails.tsinghua.edu.cn; zangxiaocs@163.com;
   jjia@tsinghua.edu.cn; skywing32@gmail.com; hmmeng@se.cuhk.edu.hk;
   clh-dcs@tsinghua.edu.cn
RI Meng, Helen M/F-6043-2011; jia, jia/JKJ-5720-2023
OI Meng, Helen M/0000-0002-4427-3532; 
FU National Basic Research Program of China [2012CB316401, 2013CB329304];
   Hong Kong SAR Government's Research Grants Council [N-CUHK414/09];
   National Natural Science Foundation of China [61375027, 61370023,
   60805008]; National Social Science Foundation (Major Project) [13ZD189];
   Guangdong Provincial Science and Technology Program [2012A011100008]
FX This work is supported by the National Basic Research Program of China
   (2012CB316401 and 2013CB329304). This work is also partially supported
   by the Hong Kong SAR Government's Research Grants Council
   (N-CUHK414/09), the National Natural Science Foundation of China
   (61375027, 61370023 and 60805008), the National Social Science
   Foundation (Major Project) (13&ZD189), and Guangdong Provincial Science
   and Technology Program (2012A011100008). The authors would like to thank
   the students of the research group of Human Computer Speech Interaction
   in Tsinghua University, the Graduate School at Shenzhen of Tsinghua
   University and the Chinese University of Hong Kong, for their
   cooperation with the dataset setup and experiments.
CR Cai LH, 2003, FDN APPL MODERN SPEE
   Kominek J., 2003, CMULTI03177
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010
   Li AJ, 1994, DURATION CHARATERIST
   Maeno Y., 2011, P INTERSPEECH, P1849
   Meng FB, 2014, MULTIMED TOOLS APPL, V73, P463, DOI 10.1007/s11042-013-1601-y
   Meng H., 2011, P AS PAC SIGN INF PR
   Meng H., 2007, P IEEE WORKSH AUT SP
   Morizane K, 2009, INT CONF SPEECH DATA, P76, DOI 10.1109/ICSDA.2009.5278371
   Raux A, 2003, P IEEE WORKSH AUT SP
   Shinoda K., 2000, Journal of the Acoustical Society of Japan (E), V21, P79, DOI 10.1250/ast.21.79
   Wu ZY, 2009, IEEE T AUDIO SPEECH, V17, P1567, DOI 10.1109/TASL.2009.2023161
   Xu J, 2009, THESIS TSINGHUA U
   Xu Y, 2005, J PHONETICS, V33, P159, DOI 10.1016/j.wocn.2004.11.001
   Xydas G, 2006, SPEECH COMMUN, V48, P1057, DOI 10.1016/j.specom.2006.02.002
   Yu K, 2010, INT CONF ACOUST SPEE, P4238, DOI 10.1109/ICASSP.2010.5495690
   [朱维彬 ZHU Weibin], 2007, [中文信息学报, Journal of Chinese Information Processing], V21, P122
NR 17
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 9909
EP 9925
DI 10.1007/s11042-014-2164-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400005
DA 2024-07-18
ER

PT J
AU Zhang, G
   Yuan, ZJ
   Liu, YH
   Ma, L
   Zheng, NN
AF Zhang, Geng
   Yuan, Zejian
   Liu, Yuehu
   Ma, Liang
   Zheng, Nanning
TI Video object segmentation by integrating trajectories from points and
   regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video object segmentation; Point tajectory; Region trajectory;
   Complementary property; High-order model
ID IMAGE; COLOR
AB We describe a novel video object segmentation system based on a conditional random field model with high-order term which is capable of capturing longer-range spatial and temporal grouping information. Our system is able to segment different moving objects effectively from complex background due to integrating the complementary properties of trajectories from points and regions. Although point and region trajectories have already been used in video object segmentation, their complementary properties have not been well investigated. In this paper, we propose an ingenious scheme to transfer the labels of sparse point trajectories to region trajectories. Especially, for region trajectories with few texture, this scheme can automatically predict their label probabilities by using a Gaussian mixture model of appearance and motion given the labels of point trajectories. Meanwhile, we design a reliability measurement for region trajectories based on shape consistency, which helps us to design robust high-order potentials for spatially overlapping region trajectories. Our region trajectories are extracted from hierarchical image over-segmentation, and hence they can capture meaningful regions over time. Additionally, our approach is a streaming process, in which object labels are propagated over a video. We validate the effectiveness of our approach on public challenging datasets, and show that our approach outperforms other competing methods.
C1 [Zhang, Geng; Yuan, Zejian; Liu, Yuehu; Ma, Liang; Zheng, Nanning] Inst Artificial Intelligence & Robot, Xian, Shaanxi, Peoples R China.
RP Zhang, G (corresponding author), Inst Artificial Intelligence & Robot, 28 West Xianning Rd, Xian, Shaanxi, Peoples R China.
EM zhangtetsu@gmail.com
FU National Basic Research Program of China [2012CB316402]; National
   Natural Science Foundation of China [91120006, 61273252]
FX This work was supported in part by the National Basic Research Program
   of China under Grant No. 2012CB316402 and the National Natural Science
   Foundation of China under Grant No. 91120006 and No. 61273252.
CR [Anonymous], 2007, P IEEE C COMP VIS PA
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Budvytis I., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2257, DOI 10.1109/CVPR.2011.5995600
   Cheriyadat AM, 2009, IEEE I CONF COMP VIS, P865, DOI 10.1109/ICCV.2009.5459311
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Dimitriou N, 2013, IMAGE VISION COMPUT, V31, P593, DOI 10.1016/j.imavis.2013.06.005
   Esche M, 2012, IEEE T CIRC SYST VID, V22, P659, DOI 10.1109/TCSVT.2011.2177142
   Fathi A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.78
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185
   Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883
   Galasso F., 2013, LNCS, V7724, P760
   Galasso F, 2011, IEEE I CONF COMP VIS, P1738, DOI 10.1109/ICCV.2011.6126438
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Huttenlocher D. P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P93, DOI 10.1109/ICCV.1993.378231
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   Nagaraja NS, 2012, SPRINGER LNCS
   Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728
   Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418
   Panagiotakis C, 2011, IEEE T IMAGE PROCESS, V20, P2276, DOI 10.1109/TIP.2011.2114893
   Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6
   Sheikh Y, 2009, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2009.5459334
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32
   Sundberg P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2233, DOI 10.1109/CVPR.2011.5995364
   Vazquez-Reina A, 2010, LECT NOTES COMPUT SC, V6315, P268, DOI 10.1007/978-3-642-15555-0_20
   Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45
   Xu CL, 2012, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2012.6247802
   Zhang G, 2012, INT C PATT RECOG, P2598
NR 40
TC 5
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9665
EP 9696
DI 10.1007/s11042-014-2145-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200028
DA 2024-07-18
ER

PT J
AU Huang, XM
   Chiou, Y
AF Huang, Xin-Mao
   Chiou, Yi
TI Using homography relationship for auto-calibration in mobile
   smart-project device system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile device; Dynamic projection; Camera-projector; Homography
   relationship; Auto-calibration
AB As technology advances, mobile devices have become indispensable 3C products. Smart phones and tablet computers have become the favorite products of technology, and they are commonly seen everywhere. In addition to making phone calls and sending messages, people also use smart phones and tablet computers to browse the Internet, listen to music, take videos and pictures, and play games, all of which have become an integral part of people's lives. In addition, according to a market survey, the most expected function of future smart phones by consumers is the projection. However, the projection will accelerate the battery power consumption. In this paper, we conducted an auto-calibration based on homography relationship in mobile smart-project device system to take advantage of the capability of the projector to project an image onto any opaque and unflat plane, thus breaking through the restricted display interfaces of mobile devices. Moreover, we also proposed the method that named FDPA (standing for Fast Detecting Projection Area) to reduce the battery power consumption via decreasing the calculation cost of the auto-calibration. The experimental results show that FDPA is able to improve the dynamic projection performance and to reduce battery power consumption in the mobile smart-projector device system. This was expected to help further develop an interactive projection system between mobile devices, adding diversity to mobile device applications and development.
C1 [Huang, Xin-Mao; Chiou, Yi] Aletheia Univ, Dept Comp Sci & Informat Engn, New Taipei City 25103, Taiwan.
C3 Aletheia University
RP Huang, XM (corresponding author), Aletheia Univ, Dept Comp Sci & Informat Engn, New Taipei City 25103, Taiwan.
EM xmhuang@au.edu.tw; fm990052@au.edu.tw
CR Baxes G. A., 1994, Digital Image Processing-Principles and Applications
   Bimber O, 2005, COMPUTER, V38, P48, DOI 10.1109/MC.2005.17
   Fiala M., 2005 IEEE CVPR WORKS, P113, DOI DOI 10.1109/CVPR.2005.416
   Fujii K, 2005, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.2005.41
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Griminisi A, 2011, ACCURATE VISUAL METR
   HUANG CH, 2001, P C COMP VIS GRAPH I, P113
   Lee WY, 2010, J INF SCI ENG, V26, P1637
   Li BX, 2004, IEEE IMAGE PROC, P2829
   Majumder A, 2004, IEEE T VIS COMPUT GR, V10, P177, DOI 10.1109/TVCG.2004.1260769
   Okatani T, 2005, IEEE T PATTERN ANAL, V27, P1845, DOI 10.1109/TPAMI.2005.235
   Okatani T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P774
   Sukthankar R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P247, DOI 10.1109/ICCV.2001.937525
   Tardif JP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P217, DOI 10.1109/im.2003.1240253
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
NR 15
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8293
EP 8311
DI 10.1007/s11042-013-1783-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600004
DA 2024-07-18
ER

PT J
AU Ribón, JCR
   Villalba, LJG
   Moro, TPD
   Kim, TH
AF Rodriguez Ribon, Julio Cesar
   Garcia Villalba, Luis Javier
   de Miguel Moro, Tomas Pedro
   Kim, Tai-hoon
TI Solving technological isolation to build virtual learning communities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-learning; Grid; Learning communities; Learning resources
AB Educational institutions may form virtual learning communities by cooperating with others to develop online academic activities. In the cloud, communities make up a grid of expertise, which is built with the learning resources that each organization shares with other pairs. Currently little is known about the problems that prevent the formation of the grid of Expertise in Virtual Learning Communities. Such techniques are not being implemented optimally and efficiently. In this paper we present a description of these problems. This work is important for community members (directors, teachers, researchers and practitioners) because it offers a conceptual framework that helps understand these scenarios and can provide useful design requirements when generating learning services for the community. We also propose an experience implemented at the University of Cartagena (Colombia) in which virtual learning communities have been integrated obtaining an alternative solution to the current problems. We believe that the result of this experience could solve the technological isolation to build communities efficiently and optimally.
C1 [Rodriguez Ribon, Julio Cesar] Univ Cartagena, Fac Ingn, Programa Ingn Sistemas, Cartagena De Indias, Colombia.
   [Garcia Villalba, Luis Javier] Univ Complutense Madrid, Grp Anal Seguridad & Sistemas, Dept Ingn Software & Inteligencia Artificial, Fac Informat, E-28040 Madrid, Spain.
   [de Miguel Moro, Tomas Pedro] Univ Politecn Madrid, Dept Ingn Sistemas Telemat DIT, Escuela Tecn Super Ingn Telecomunicac, E-28040 Madrid, Spain.
   [Kim, Tai-hoon] Sungshin Womens Univ, Dept Convergence Secur, Seoul 136742, South Korea.
C3 Universidad de Cartagena; Complutense University of Madrid; Universidad
   Politecnica de Madrid; Sungshin Women's University
RP Villalba, LJG (corresponding author), Univ Complutense Madrid, Grp Anal Seguridad & Sistemas, Dept Ingn Software & Inteligencia Artificial, Fac Informat, Despacho 431, E-28040 Madrid, Spain.
EM jrodriguezr@unicartagena.edu.co; javiergv@fdi.ucm.es;
   tmiguel@dit.upm.es; taihoonn@daum.net
RI Garcia Villalba, Luis Javier/N-4631-2014
OI Garcia Villalba, Luis Javier/0000-0001-7573-6272
FU Agencia Espanola de Cooperacion Internacional para el Desarrollo (AECID,
   Spain) through Accion Integrada MAEC-AECID MEDITERRANEO [A1/037528/11];
   Security Engineering Research Center - Ministry of Knowledge Economy
   (MKE, Korea)
FX This work was supported by the Agencia Espanola de Cooperacion
   Internacional para el Desarrollo (AECID, Spain) through Accion Integrada
   MAEC-AECID MEDITERRANEO A1/037528/11. This work was also supported by
   the Security Engineering Research Center, granted by the Ministry of
   Knowledge Economy (MKE, Korea).
CR Akram A, 2006, P 4 INT WORKSH MIDDL, V194, DOI [10.1145/1186675.1186697, DOI 10.1145/1186675.1186697]
   [Anonymous], SCORM SHAR CONT OBJ
   Calegari D, 2005, J COMPUT SCI TECHNOL, V5, P167
   Ferretti S., 2008, P 2008 INT CROSS DIS, V317, P116
   Grainne C, 2010, COMP ED LEARN DIG WO, V54, P679
   Hunter MG, 2009, 42 HAW INT C SYST SC, p[1, 5], DOI [10.1109/HICSS.2009.418, DOI 10.1109/HICSS.2009.418]
   IEEE Learning Technology Standards Committee-LTSC, 2005, 14841212002 IEEE
   IEEE LTSC, 2002, P14841D9 IEEE LTSC
   Iriberri A, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459356
   Isla Montes JL, 2007, IEEE LATIN AM T, V5, P204, DOI [10.1109/TLA.2007.4378507, DOI 10.1109/TLA.2007.4378507]
   Kim KR, 2013, MULTIMED TOOLS APPL, V64, P423, DOI 10.1007/s11042-012-1014-3
   Liaw SS, 2008, COMPUT EDUC, V50, P950, DOI 10.1016/j.compedu.2006.09.007
   Miroslav M, 2011, MULTIMED TOOLS APPL, DOI [10.1007/s11042-011-0964-1, DOI 10.1007/S11042-011-0964-1]
   *OMG, 2007, UN MOD LANG
   Ribon RJ, 2009, P 2009 EUR C TEL INF
   Rodriguez JC, 2011, CCIS, V263, P295
   Weller M, 2007, COMPUT EDUC, V49, P148, DOI 10.1016/j.compedu.2005.04.015
NR 17
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8521
EP 8539
DI 10.1007/s11042-013-1542-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600018
DA 2024-07-18
ER

PT J
AU Cruz-Ramos, C
   Nakano-Miyatake, M
   Perez-Meana, H
   Reyes-Reyes, R
   Rosales-Roldan, L
AF Cruz-Ramos, Clara
   Nakano-Miyatake, Mariko
   Perez-Meana, Hector
   Reyes-Reyes, Rogelio
   Rosales-Roldan, Luis
TI Face region authentication and recovery system based on SPIHT and
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Tamper detection; Self-recovery; Watermarking; SPIHT;
   QIM
ID SEMI-FRAGILE WATERMARKING; IMAGE TAMPER DETECTION; HALF-TONING TECHNIQUE
AB The face regions of digital pictures are some of the principal target of tampering to generate a potential scandal, causing social and economic damages to involved persons. In this paper, we propose a face region authentication and recovery system, in which the face regions are automatically protected at the moment when the picture is taken by a digital camera. When the original face of the picture is replaced by another face by malicious person, the system can detect the tampered face and recover the original one. The proposed system consists of two stages: the face region protection stage and the face region tamper detection and recovery stage. In both stages, the face detection module based on the Viola-Jones algorithm, face region encoding/decoding modules based on the Set Partitioning in Hierarchical Trees (SPIHT) algorithm and watermarking module based on Quantization Index Modulation (QIM) are used. These three algorithms, Viola-Jones detector, SPIHT and QIM, are determined as most adequate algorithms for proposed system after several evaluations. The experimental results show a high quality of the watermarked as well as the recovered images, obtaining average Peak Signals to Noise Ratios (PSNR) of more than 40 and 38 dB, respectively.
C1 [Cruz-Ramos, Clara; Nakano-Miyatake, Mariko; Perez-Meana, Hector; Reyes-Reyes, Rogelio; Rosales-Roldan, Luis] Inst Politecn Nacl, Mech Elect Engn Sch, Mexico City, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Nakano-Miyatake, M (corresponding author), Inst Politecn Nacl, Mech Elect Engn Sch, Av Santa Ana 1000,Col San Francisco Culhuacan, Mexico City, DF, Mexico.
EM mnakano@ipn.mx
RI Cruz-Ramos, Clara/AAN-2761-2020; Rosales-Roldan, Luis/S-3248-2019;
   Perez-Meana, Hector/N-1624-2019; Reyes-Reyes, Rogelio/AAC-7553-2019;
   Nakano, Mariko/N-4075-2019; Nakano, Mariko/O-2954-2017
OI Cruz-Ramos, Clara/0000-0001-6050-5885; Rosales-Roldan,
   Luis/0000-0002-0908-3944; Perez-Meana, Hector/0000-0002-7786-2050;
   Reyes-Reyes, Rogelio/0000-0001-5506-6611; Nakano,
   Mariko/0000-0003-1346-7825
FU National Council of Science and Technology of Mexico (CONACyT); IPN
FX Authors thank the National Council of Science and Technology of Mexico
   (CONACyT) and IPN for financial support to carry out this work.
CR [Anonymous], 2010, Fddb: A benchmark for face detection in unconstrained settings
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Cruz C, 2010, REV FAC ING-UNIV ANT, P160
   Hartung F, 2000, IEEE COMMUN MAG, V38, P78, DOI 10.1109/35.883493
   Kanamori T, 2007, NEW GENERAT COMPUT, V25, P117, DOI 10.1007/s00354-006-0006-0
   Kaur R, 2010, P ISCET, V101, P137
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lenarczyk P, 2013, TELECOMMUN SYST, V54, P287, DOI 10.1007/s11235-013-9734-x
   Lian SG, 2012, TELECOMMUN SYST, V49, P187, DOI 10.1007/s11235-010-9367-2
   Lin SFD, 2011, INT J INNOV COMPUT I, V7, P6875
   Luo H, 2008, CIRC SYST SIGNAL PR, V27, P155, DOI 10.1007/s00034-008-9024-0
   Mingju Chen, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P621, DOI 10.1109/ICSPS.2010.5555738
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sang J, 2013, OPTIK, V124, P6512, DOI 10.1016/j.ijleo.2013.05.046
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang JW, 2015, MULTIMEDIA SYST, V21, P345, DOI 10.1007/s00530-013-0338-9
   Yang HF, 2015, MULTIMED TOOLS APPL, V74, P1725, DOI 10.1007/s11042-013-1714-3
   Zhang Cha., 2010, BOOSTING BASED FACE
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 23
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7685
EP 7709
DI 10.1007/s11042-014-2006-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200013
DA 2024-07-18
ER

PT J
AU Kim, CG
   Kim, KJ
   Lee, J
AF Kim, Cheong Ghil
   Kim, Kuinam J.
   Lee, JungHoon
TI NAND flash memory system based on the Harvard buffer architecture for
   multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flash memory; XIP (execute in place); Buffer system; Harvard vs von
   neumann architecture; Multimedia applications
AB The main purpose of this research is to design a new memory architecture for NAND flash memory to provide XIP (execute in place) for code execution as well as overcome the biggest bottleneck for data execution. NOR flash for multimedia application is particularly well suited for code storage and execute-in-place (XIP) applications, which requires high-speed random access. While NAND flash provides high density and low cost data storage, it is not applicable to XIP applications due to the page access and long access latency. To overcome these limitations, NAND flash can be exploited as code memory for XIP by using SDRAM/SRAM buffer. In order to design the code memory, we proposed a NAND flash with a dual instruction buffer. Furthermore, another enhancement was proposed for the overall system performance by applying a data buffer system to the existing NAND flash memory to reduce the number of write and erase operations; otherwise which could be the biggest bottleneck in a flash memory system. In conclusion, the proposed NAND flash buffer system based on Harvard architecture is operated as main memory as well as the lowest storage device for mobile multimedia system. According to our simulation results, write and erase operations are approximately 60 % and 68 % less than other unified buffer systems, respectively, with two times more space. In addition, the average memory access time is improved by approximately 75 % compared with other unified buffer systems.
C1 [Kim, Cheong Ghil] Namseoul Univ, Dept Comp Sci, Cheonan, Chungnam, South Korea.
   [Kim, Kuinam J.] Kyonggi Univ, Dept Convergence Secur, Suwon 443760, Gyeonggi Do, South Korea.
   [Lee, JungHoon] GyeongSang Natl Univ, Control & Instrument Engn, ERI, Jinju 660701, Gyeongnam, South Korea.
C3 Namseoul University; Kyonggi University; Gyeongsang National University
RP Lee, J (corresponding author), GyeongSang Natl Univ, Control & Instrument Engn, ERI, 501 Jinju Daero, Jinju 660701, Gyeongnam, South Korea.
EM cgkim@nsu.ac.kr; harap123@hanmail.net; leejh@gsnu.ac.kr
FU Namseoul University
FX Funding for this paper was provided by Namseoul University.
CR BOSUNG JUNG, 2009, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V14, P41
   Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739
   Hennessy J.L., 2006, Computer Architecture: A Quantitative Approach'', V4th
   Huang W., 2008, P MULT UB ENG, P543
   Hyun S, 2008, INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCES AND ITS APPLICATIONS, PROCEEDINGS, P157, DOI 10.1109/ICCSA.2008.69
   Igor S, 2011, FLASH MEMORIES
   Jo H, 2006, IEEE T CONSUM ELECTR, V52, P485, DOI 10.1109/TCE.2006.1649669
   Joo Y., 2006, CODES+ISSS '06: Internatinal Conference on Hardware/Software Codesign and System Synthesis, P229
   Lee JH, 2005, J SYST ARCHITECT, V51, P111, DOI 10.1016/j.sysarc.2004.10.002
   Park C, 2003, CODES(PLUS)ISSS 2003: FIRST IEEE/ACM/IFIP INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN & SYSTEM SYNTHESIS, P138, DOI 10.1109/CODESS.2003.1275273
   Park JW, 2011, MICROPROCESS MICROSY, V35, P48, DOI 10.1016/j.micpro.2010.08.001
   Poovey JA, 2009, IEEE MICRO, V29, P18, DOI 10.1109/MM.2009.74
   Przybylski S., 1990, Proceedings. The 17th Annual International Symposium on Computer Architecture (Cat. No.90CH2887-8), P160, DOI 10.1109/ISCA.1990.134521
   Samsung Elec, 2010, NAND FLASH MEM SMART
   Sanchez FJ, 1997, 1997 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, PROCEEDINGS, P261, DOI 10.1109/PACT.1997.644022
   Santarini M., 2005, NAND VERSUS NOR
   SimpleScalar LLC, SIMPLESCALAR 3 0
NR 17
TC 2
Z9 2
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6287
EP 6302
DI 10.1007/s11042-014-2122-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700011
DA 2024-07-18
ER

PT J
AU Baran, R
   Glowacz, A
   Matiolanski, A
AF Baran, Remigiusz
   Glowacz, Andrzej
   Matiolanski, Andrzej
TI The efficient real- and non-real-time make and model recognition of cars
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Make and model recognition of cars; SURF; SIFT; SVM; Content
   descriptors; Classification accuracy
ID ALGORITHM; CLASSIFIER
AB Make and Model recognition of cars (MMR) has become an important element of automatic vision based systems. Nowadays, MMR utility is commonly added to traffic monitoring (e.g. Licence Plate Recognition) or law enforcement surveillance systems. Facing the growing significance of Make and Model Recognition of cars we have designed and implemented two different MMR approaches. According to their disparate assumption data of these implementations one is obligated to estimate different car models in milliseconds (with a bit less emphasis placed on its accuracy) while the other is aimed first of all to reach higher classification accuracy. Both the implemented MMR approaches, called Real-Time and Visual Content Classification, respectively, are described in this paper in detail and with reference to other MMR methods presented in the literature. Analyses of their performance with respect to classification accuracy and, in case of the Real-Time approach, to its response time are also presented, discussed and finally concluded.
C1 [Baran, Remigiusz] Kielce Univ Technol, Fac Elect Engn Automat & Comp Sci, PL-25314 Kielce, Poland.
   [Glowacz, Andrzej; Matiolanski, Andrzej] AGH Univ Sci & Technol, Dept Telecommun, PL-30059 Krakow, Poland.
C3 Kielce University of Technology; AGH University of Krakow
RP Baran, R (corresponding author), Kielce Univ Technol, Fac Elect Engn Automat & Comp Sci, Al 1000 Lecia PP 7, PL-25314 Kielce, Poland.
EM r.baran@tu.kielce.pl; aglowacz@agh.edu.pl; matiolanski@kt.agh.edu.pl
RI Matiolanski, Andrzej/B-9649-2015; Baran, Remigiusz/E-5457-2014
OI Baran, Remigiusz/0000-0002-3643-5642
FU European Union from the European regional Development Fund, as a part of
   the Innovative Economy Operational Programme INSIGMA
   [POIG.01.01.02-00-062/09]; EU Operational Programme Innovative Economy
   [POIG.02.02.00-26-023/09-00]; EU Operational Programme Development of
   Eastern Poland [POPW.01.03.00-26-016/09-00]
FX The work was co-financed by the European Union from the European
   regional Development Fund, as a part of the Innovative Economy
   Operational Programme INSIGMA no. POIG.01.01.02-00-062/09.; The
   numerical experiments reported in this paper have been performed using
   computational equipment purchased in the framework of the EU Operational
   Programme Innovative Economy (POIG.02.02.00-26-023/09-00) and the EU
   Operational Programme Development of Eastern Poland
   (POPW.01.03.00-26-016/09-00).
CR Ahmad N, 2012, MULTIMED TOOLS APPL, V57, P423, DOI 10.1007/s11042-011-0739-8
   Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   [Anonymous], 2005, THESIS U CALIFORNIA
   [Anonymous], P SPIE INT C REAL TI
   [Anonymous], 2002, COMPUTATIONAL INTELL
   [Anonymous], 2000, Em: Proceedings of the 2000 ACM workshops on Multimedia, DOI DOI 10.1145/357744.357758
   [Anonymous], 2004, BMVC
   [Anonymous], 2005, P IRISH C ARTIFICIAL
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Anthony D, 2005, MORAL LOCAL STRUCTUR
   Baran Remigiusz, 2010, Pomiary Automatyka Kontrola, V56, P1409
   Bauer J., 2007, IFAC Proceedings Volumes, V40, P143
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bernardo J.M., 1994, Bayesian Theory
   Butzke M, 2008, HIFEN, V32, P293
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Clady X, 2008, LECT NOTES ARTIF INT, V5064, P228, DOI 10.1007/978-3-540-69939-2_22
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalka P, 2010, LECT NOTES ARTIF INT, V6086, P70, DOI 10.1007/978-3-642-13529-3_9
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Gasca M, 2000, J COMPUT APPL MATH, V122, P23, DOI 10.1016/S0377-0427(00)00353-8
   Glowacz A, 2012, COMM COM INF SC, V287, P118
   Gorzalczany MB, 2012, LECT NOTES COMPUT SC, V7269, P222, DOI 10.1007/978-3-642-29353-5_26
   Gorzalczany MB, 2010, LECT NOTES ARTIF INT, V6113, P88, DOI 10.1007/978-3-642-13208-7_12
   Gorzalczany MB, 1999, INFORM SCIENCES, V120, P69, DOI 10.1016/S0020-0255(99)00069-9
   Gu HZ, 2013, MULTIMED TOOLS APPL, V65, P387, DOI 10.1007/s11042-012-0996-1
   Gunn S.., 1998, Technical Report, V14, P5
   GUPTA MM, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, P1271, DOI 10.1109/FUZZY.1992.258594
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang H, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P298, DOI 10.1109/ITSC.2008.4732559
   Iqbal U., 2010, International Journal of Navigation and Observation, V2010, P1
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Janowski L, 2014, MULTIMED TOOLS APPL, V68, P23, DOI 10.1007/s11042-012-1199-5
   Kazemi FM, 2007, INT J COMPUT SCI NET, V7, P130
   Kazemi FM, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P516
   Lee HJ, 2006, LECT NOTES COMPUT SC, V3973, P66
   Leszczuk M, 2011, COMM COM INF SC, V149, P10
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Matiolanski A, 2011, COMM COM INF SC, V149, P158
   Mclachlan GJ., 2005, DISCRIMINANT ANAL ST
   Negri P, 2006, INT C PATT RECOG, P574
   Pearce G., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P373, DOI 10.1109/AVSS.2011.6027353
   Psyllos A., 2008, P C APPL ADV TECH TR, V5, P4229
   Rahati S, 2008, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P894, DOI 10.1109/ITNG.2008.136
   Ukasha A, 2009, P INT C VIS IM IM PR, P213
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Witten I. H., 2005, DATA MINING PRACTICA
   Zafar I, 2007, PROCEEDINGS OF THE SEVENTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P271
   Zafar I, 2009, P SPIE IS T ELECT IM, V7251
NR 57
TC 40
Z9 42
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4269
EP 4288
DI 10.1007/s11042-013-1545-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600006
OA hybrid
DA 2024-07-18
ER

PT J
AU Dias, R
   Fonseca, MJ
   Silva, N
   Cardoso, T
AF Dias, Ricardo
   Fonseca, Manuel J.
   Silva, Nelson
   Cardoso, Tiago
TI EnContRA: a generic multimedia information retrieval meta-framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Architectural meta-framework; Multimedia information retrieval; Query
   processing
AB Over the last years, multimedia collections have largely increased as new items are produced every day, such as pictures, audio/music or video. In Multimedia Information Retrieval, this exponential growth leads content-based approaches to gain advantage over other solutions, not only because they take advantage of the intrinsic information contained in the objects, but also because they automatically process and extract it, reducing the burden taken by developers. Several domain specific frameworks have been developed to efficiently retrieve multimedia items empowering the creation of new content-based applications. However, these frameworks are attached to a specific media type, are too complex to be used in a fast prototyping environment, and are not very flexible nor extensible. To solve these issues, we developed EnContRA, an architectural meta-framework that provides generic building blocks for creating domain specific frameworks. Our meta-framework aims at being ready to be used for fast prototyping, with support for rich and multimodal queries, allowing validation of new descriptors, indexing structures or searching algorithms, while creating domain specific frameworks. In this paper we present the meta-framework architecture and describe in detail its modules and features. To validate the meta-framework, we created an image retrieval framework and a demo application that combines image descriptors with textual information, showing how the hierarchical design of EnContRA could be applied to a searching system and to empower the creation of queries.
C1 [Dias, Ricardo; Fonseca, Manuel J.] INESC ID IST ULisboa, Dept Informat Syst & Comp Sci, Lisbon, Portugal.
   [Silva, Nelson; Cardoso, Tiago] InEvo R&D Lda, Lisbon, Portugal.
C3 INESC-ID
RP Dias, R (corresponding author), INESC ID IST ULisboa, Dept Informat Syst & Comp Sci, Lisbon, Portugal.
EM ricardo.dias@ist.utl.pt; mjf@inesc-id.pt; nelson.silva@inevo.pt;
   tiago.cardoso@inevo.pt
RI Fonseca, Manuel J./D-5120-2011
OI Fonseca, Manuel J./0000-0002-3559-828X; Silva,
   Nelson/0009-0001-7428-454X
FU FCT -Fundacao para a Ciencia e a Tecnologia [PEst-OE/EEI/LA0021/2013];
   ADI through the ColaDI project; ADI through the Crush project
   [PTDC/EIA-EIA/108077/2008]; FCT [SFRH/BD/70939/2010]; Fundação para a
   Ciência e a Tecnologia [SFRH/BD/70939/2010] Funding Source: FCT
FX This work was supported by national funds through FCT -Fundacao para a
   Ciencia e a Tecnologia, under project PEst-OE/EEI/LA0021/2013, by ADI
   through the ColaDI project and through the Crush project,
   PTDC/EIA-EIA/108077/2008. Ricardo Dias was supported by FCT, grant
   reference SFRH/BD/70939/2010.
CR Amato G, 2005, LECT NOTES COMPUT SC, V3652, P69, DOI 10.1007/11551362_7
   Amato G., 2013, DIGITAL LIB ARCH, P163
   [Anonymous], 2008, P 16 INT C MULTIMEDI, DOI [DOI 10.1145/1459359.1459577, 10.1145/1459359.1459577]
   [Anonymous], 2009, MM 09 P 2009 ACM MUL, DOI DOI 10.1145/1631272.1631456
   [Anonymous], 2010, SISAP
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Batko M, 2007, DELOS07
   COMER D, 1979, COMPUT SURV, V11, P121, DOI 10.1145/356770.356776
   Fonseca MJ, 2003, DASFAA
   Huang T.S., 1996, P 33 ANN CLIN LIB AP
   Kiranyaz S, 2006, IEE P-VIS IMAGE SIGN, V153, P285, DOI 10.1049/ip-vis:20050063
   Mcennis D, 2005, INT C MUS INF RETR
   Mcennis Daniel., 2006, P 7 INT C MUSIC INFO, P385
   Novak D, 2009, SISAP 2009: 2009 SECOND INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P65, DOI 10.1109/SISAP.2009.26
   Novak D, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P841
   Tzanetakis George., 2000, ORGAN SOUND, V4, P2000
   Wimmers E. L., 1999, Proceedings Fourth IFCIS International Conference on Cooperative Information Systems. CoopIS 99 (Cat. No.PR00384), P267, DOI 10.1109/COOPIS.1999.792176
NR 18
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3691
EP 3713
DI 10.1007/s11042-013-1794-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800005
DA 2024-07-18
ER

PT J
AU Fan, WT
   Bouguila, N
AF Fan, Wentao
   Bouguila, Nizar
TI Face detection and facial expression recognition using simultaneous
   clustering and feature selection via an expectation propagation
   statistical learning framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generalized Dirichlet mixture; Dirichlet process; Expectation
   propagation; Feature selection; Face detection; Facial expression
   recognition
ID LOCAL BINARY PATTERNS; KERNEL PCA; MIXTURE; MODELS; CLASSIFICATION;
   EIGENFACES
AB In this paper, we focus on developing a novel framework which can be effectively used for both face detection (i.e. discriminate faces from non-face patterns) and facial expression recognition. The proposed statistical framework is based on a Dirichlet process mixture of generalized Dirichlet (GD) distributions used to model local binary pattern (LBP) features. Our method is built on nonparametric Bayesian analysis where the determination of the number of clusters is sidestepped by assuming an infinite number of mixture components. An unsupervised feature selection scheme is also integrated with the proposed nonparametric framework to improve modeling performance and generalization capabilities. By learning the proposed model using an expectation propagation (EP) inference approach, all the involved model parameters and feature saliencies can be evaluated simultaneously in a single optimization framework. Furthermore, the proposed framework is extended by adopting a localized feature selection scheme which has shown, according to our results, superior performance, to determine the most important facial features, as compared to the global one. The effectiveness and utility of the proposed method is illustrated through extensive empirical results using both synthetic data and two challenging applications involving face detection, and facial expression recognition.
C1 [Fan, Wentao] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
   [Bouguila, Nizar] Concordia Univ, CIISE, Montreal, PQ, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Bouguila, N (corresponding author), Concordia Univ, CIISE, Montreal, PQ, Canada.
EM wenta_fa@encs.concordia.ca; nizar.bouguila@concordia.ca
RI Bouguila, Nizar/AGN-5929-2022; Bouguila, Nizar/AAJ-2518-2020; Fan,
   Wentao/AAO-9378-2020; Fan, Wentao/JUU-7543-2023
OI Fan, Wentao/0000-0001-6694-7289; Fan, Wentao/0000-0001-6694-7289
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 2011, P 28 INT C MACH LEAR
   [Anonymous], 2012, P JMLR WORKSHOP C P
   [Anonymous], 2002, Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence. UAI'02
   [Anonymous], 1983, RECNT ADV STAT
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berrani SA, 2008, MULTIMED TOOLS APPL, V38, P271, DOI 10.1007/s11042-007-0176-x
   BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915
   Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104
   Bouguila N, 2007, IEEE T PATTERN ANAL, V29, P1716, DOI [10.1109/TPAMI.2007.1095, 10.1109/TPAMl.2007.1095]
   Bouguila N, 2006, IEEE T IMAGE PROCESS, V15, P2657, DOI 10.1109/TIP.2006.877379
   Bouguila N, 2012, KNOWL INF SYST, V33, P351, DOI 10.1007/s10115-011-0467-4
   Boutemedjet S, 2009, IEEE T PATTERN ANAL, V31, P1429, DOI 10.1109/TPAMI.2008.155
   Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9
   Chang S, 2005, PROC CVPR IEEE, P1043
   Cheng F, 2010, IEEE T NEURAL NETWOR, V21, P1685, DOI 10.1109/TNN.2010.2064176
   Constantinopoulos C, 2006, IEEE T PATTERN ANAL, V28, P1013, DOI 10.1109/TPAMI.2006.111
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Fan WT, 2012, LECT NOTES COMPUT SC, V7665, P25, DOI 10.1007/978-3-642-34487-9_4
   Fan WT, 2014, MULTIMED TOOLS APPL, V70, P1685, DOI 10.1007/s11042-012-1191-0
   Fan WT, 2013, IEEE T KNOWL DATA EN, V25, P1670, DOI 10.1109/TKDE.2012.101
   Fan WT, 2012, COMM COM INF SC, V287, P95
   Fan WT, 2012, IEEE T NEUR NET LEAR, V23, P762, DOI 10.1109/TNNLS.2012.2190298
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Hwang WS, 2000, IEEE T PATTERN ANAL, V22, P1277, DOI 10.1109/34.888712
   Jun B, 2011, PATTERN RECOGN LETT, V32, P329, DOI 10.1016/j.patrec.2010.09.011
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   KORWAR RM, 1973, ANN PROBAB, V1, P705, DOI 10.1214/aop/1176996898
   Kotsia I, 2009, IEEE T NEURAL NETWOR, V20, P14, DOI 10.1109/TNN.2008.2004376
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71
   Li YH, 2009, IEEE T PATTERN ANAL, V31, P953, DOI 10.1109/TPAMI.2008.261
   Liao S, 2006, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2006.312418
   Lin WY, 2014, MULTIMED TOOLS APPL, V68, P877, DOI 10.1007/s11042-012-1092-2
   Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Ma ZY, 2010, INT CONF ACOUST SPEE, P2082, DOI 10.1109/ICASSP.2010.5495085
   Maybeck Peter S., 1982, Stochastic models, estimation, and control
   Minka T., 2001, P 17 C UNC ART INT, P362
   Nefian A. V., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P133, DOI 10.1109/ICME.2002.1035530
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   SETHURAMAN J, 1994, STAT SINICA, V4, P639
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Tefas A, 2001, IEEE T PATTERN ANAL, V23, P735, DOI 10.1109/34.935847
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wentao Fan, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P1032, DOI 10.1109/ICDM.2011.152
   Xie XD, 2006, IEEE T IMAGE PROCESS, V15, P2481, DOI 10.1109/TIP.2006.877435
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 64
TC 9
Z9 9
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4303
EP 4327
DI 10.1007/s11042-013-1548-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600008
DA 2024-07-18
ER

PT J
AU Li, QJ
AF Li, Qiujie
TI A computer vision attack on the ARTiFACIAL CAPTCHA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAPTCHA; ARTiFACIAL; Attack; Computer vision
AB Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA) is a reverse Turing test that is used to differentiate bots from humans. Text CAPTCHAs have been widely used in commercial applications, but most of the text CAPTCHAs have been successfully attacked. An alternative is to develop image CAPTCHAs to replace text CAPTCHAs. ARTiFACIAL (Automated Reverse Turing test using FACIAL features) Rui and Liu (2003) is an image CAPTCHA system based on detecting human face and facial features and claimed to be attack-resistant and user-friendly. This paper proposes a compute vision attack on ARTiFACIAL. By carefully analyzing the limitations of face and facial feature detectors that ARTiFACIAL exploits, tailor-made attacking algorithm is designed instead of using general face and facial feature detectors directly. When tested with the 800 ARTiFACIAL challenges, the overall success rate of the attacking algorithm is 18.0 %, which is significantly higher than the estimate of 0.0006 % given in Rui and Liu (2003) for computer vision attacks. It takes an average time 1.47s for a PC with 3.2GHz Intel P4 and 2GB memory to pass an ARTiFACIAL test, compared with 14s for a human subject given in Rui and Liu (2003). From the successful attack, useful lessons for guiding the design of image CAPTCHAs are derived to advance the current understanding of the design of image CAPTCHAs and lead to more secure design.
C1 Nanjing Forestry Univ, Coll Mech & Elect Engn, Nanjing 210037, Jiangsu, Peoples R China.
C3 Nanjing Forestry University
RP Li, QJ (corresponding author), Nanjing Forestry Univ, Coll Mech & Elect Engn, Nanjing 210037, Jiangsu, Peoples R China.
EM liqiujie_1@163.com
RI Li, Qiujie/HDM-6016-2022
OI Li, Qiujie/0000-0002-4529-3594
CR Ahn LV, 2005, THESIS CARNEGIE MELL
   [Anonymous], 2007, CVPR
   [Anonymous], 2005, P SIGCHI C HUM FACT
   [Anonymous], UCBCSD041333 EECS DE
   [Anonymous], 1999, MACH LEARN
   [Anonymous], 2006, 2D CAPTCHAS 3D MODEL, DOI [10.1109/second.2006.1629343, DOI 10.1109/SECOND.2006.1629343]
   Azad Silky., 2013, Global Journal of Computer Science and Technology, V13, P15
   Chellapilla K., 2004, proc. 17th International Conference on Neural Information Processing Systems, Vancouver, BC, Canada, P265
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Datta R., 2005, 13th Annual ACM International Conference on Multimedia, P331, DOI 10.1145/1101149.1101218
   DSouza D., 2012, IEEE INT C ELECTRO I, P1, DOI DOI 10.1109/EIT.2012.6220734
   El Ahmad A.S., 2010, P 3 EUR WORKSH SYST, P36, DOI DOI 10.1145/1752046.1752052
   Elson J, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P366
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531339
   Golle P, 2008, CCS'08: PROCEEDINGS OF THE 15TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P535
   Gossweiler R., 2009, P 18 INT C WORLD WID, P841, DOI DOI 10.1145/1526709.1526822
   Hu YX, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P843
   Huang SY, 2010, MULTIMED TOOLS APPL, V48, P267, DOI 10.1007/s11042-009-0341-5
   Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6
   Mori G, 2003, PROC CVPR IEEE, P134
   Moy G, 2004, PROC CVPR IEEE, P23
   Roshanbin N, 2013, J WEB ENG, V12, P1
   Rui Y., 2003, P 11 ACM INT C MULT, P295, DOI DOI 10.1145/957013.957075
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   Xiao R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P709
   Yan J, 2008, P 4 S USABLE PRIVACY, P44, DOI 10.1145/1408664.1408671
   Yan J, 2007, TWENTY-THIRD ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, PROCEEDINGS, P279, DOI 10.1109/ACSAC.2007.47
   Yan J, 2008, CCS'08: PROCEEDINGS OF THE 15TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P543
   Yan SC, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P51
   Zhang C., 2010, A survey of recent advances in face detection
   Zhu B, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P187, DOI 10.1145/1866307.1866329
NR 35
TC 9
Z9 9
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4583
EP 4597
DI 10.1007/s11042-013-1823-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400006
DA 2024-07-18
ER

PT J
AU Sandonis, V
   Soto, I
   Calderon, M
   Fernandez, I
   Vidal, I
AF Sandonis, Victor
   Soto, Ignacio
   Calderon, Maria
   Fernandez, Ismael
   Vidal, Ivan
TI CATMISS: context-aware transparent mobility for IMS services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context-awareness; Transparent mobility; IMS; SIP
AB The IP Multimedia Subsystem (IMS) is considered as the common platform for providing a unified session control on top of various access network technologies for multimedia applications. At the same time, we are witnessing how wireless technologies become an integral part of our daily life, due to an increasing number of mobile multi-interface devices and the proliferation of wireless access networks. In this context the availability of transparent mobility management mechanisms is a key element to enhance user's quality of experience. On the other hand, context-awareness is a vital ingredient to allow mobile devices to make appropriate and timely mobility decisions. The benefits of using diverse context information (e.g., about the user, the service and the network) to manage mobility are twofold. First, the richer information is available, the more likely an intelligent decision can be taken. Second, it allows the network to assist the terminal to take mobility decisions, even up to the point of automatically initiating a mobility procedure if according to the context and user preferences this improves the user's quality of experience. In this paper we propose CATMISS, a solution to support context-aware mobility in IMS services. The solution is based on SIP signalling and makes mobility transparent for communication peers of mobile terminals. Two types of mobility are supported: a terminal changing of access network and a multimedia session being transferred from one terminal to another. The paper also describes the implementation of the solution and its deployment in an experimental platform. Experiments in this platform, with IPTV and videoconference services, are used to validate the proposal.
C1 [Sandonis, Victor; Soto, Ignacio; Calderon, Maria; Fernandez, Ismael; Vidal, Ivan] Univ Carlos III Madrid, Dept Ingn Telemat, Madrid 28911, Spain.
C3 Universidad Carlos III de Madrid
RP Soto, I (corresponding author), Univ Carlos III Madrid, Dept Ingn Telemat, Avda Univ 30, Madrid 28911, Spain.
EM vsandoni@it.uc3m.es; isoto@it.uc3m.es; maria@it.uc3m.es;
   ismafc06@gmail.com; ividal@it.uc3m.es
RI Soto, Ignacio/E-9850-2016; Soto, Ignacio/HNR-3681-2023; Calderon,
   Maria/D-2177-2014
OI Soto, Ignacio/0000-0002-7421-3733; Calderon, Maria/0000-0002-5441-3367;
   Vidal, Ivan/0000-0001-7381-971X
FU Spanish Government through project I-MOVING [TEC2010-18907]; Spanish
   Government through the UP-TO-US Celtic project [CP07-015]
FX The work described in this paper has received funding from the Spanish
   Government through project I-MOVING (TEC2010-18907) and through the
   UP-TO-US Celtic project (CP07-015).
CR 3GPP, 2012, 24302 3GPP TS
   3GPP, 2011, 23237 3GPP TS
   3GPP, 2012, 23060 3GPP TS
   3GPP, 2012, 23402 3GPP TS
   3GPP, 2013, 24229 3GPP TS
   Achour A, 2012, IEEE COMMUN MAG, V50, P109, DOI 10.1109/MCOM.2012.6231286
   [Anonymous], 2013, 23228 3GPP TS
   [Anonymous], 2002, 3261 RFC INT ENG TAS
   Arnaud J, 2012, 2012 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS (ISCC), P43, DOI 10.1109/ISCC.2012.6249266
   Chiba Tsunehiko, 2008, 2008 International Wireless Communications and Mobile Computing Conference Conference, P68, DOI 10.1109/IWCMC.2008.13
   Choong KN, 2007, BT TECHNOL J, V25, P219, DOI 10.1007/s10550-007-0047-z
   Doolin Kevin, 2008, P 2008 AMB SYS WORKS
   Hasswa A., 2011, 2011 IEEE Symposium on Computers and Communications (ISCC 2011), P85, DOI 10.1109/ISCC.2011.5984032
   Jeon HK, 2008, IEEE INT SYMP CIRC S, P157, DOI 10.1109/ISCAS.2008.4541378
   Johnson D.B., 2011, Mobility Support in IPv6
   Lister D, 2000, IEE CONF PUBL, P218, DOI 10.1049/cp:20000046
   Mahy R, 2004, 3891 RFC INT ENG TAS
   Nguyen Huu Thanh, 2008, Second International Conference on Communications and Electronics, P162, DOI 10.1109/CCE.2008.4578951
   Perkins C. E., 2010, 5944 RFC INT ENG TAS
   Renier T, 2007, IEEE VEH TECHNOL MAG, V2, P20, DOI 10.1109/MVT.2007.898098
   Rosenberg J, 2009, 5627 RFC INT ENG TAS
   Sandonis V, 2012, UP TO US WORKSH EURO, P271
   Shacham R, 2009, 5631 RFC INT ENG TAS
   Song SB, 2010, LECT NOTES COMPUT SC, V6157, P75, DOI 10.1007/978-3-642-13789-1_8
   Soto I., 2010, The Internet Protocol Journal, V13, P2
   Sparks R, 2003, 3515 RFC INT ENG TAS
   Vidal I, 2013, IEEE COMMUN MAG, V51, P97, DOI 10.1109/MCOM.2013.6553684
   Vidal I, 2011, COMPUT NETW, V55, P1474, DOI 10.1016/j.comnet.2011.01.011
   Vidal I, 2010, COMPUT COMMUN, V33, P1736, DOI 10.1016/j.comcom.2010.05.001
   Wilson PR, 2009, ULTR TEL WORKSH 2009, P1
NR 30
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4789
EP 4816
DI 10.1007/s11042-013-1839-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400016
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kim, J
   Kim, Y
   Chang, H
AF Kim, Jeongyeon
   Kim, Yanghoon
   Chang, Hangbae
TI A study on performance evaluation of intelligent collaboration system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent collaboration system; Value network; Empirical analysis;
   Delivery management; Inventory management; Logistic management
ID SME
AB According as competition environment of businesses is generally expanded to that of corporate networks from a simple corporate linkage structure throughout the industries, coexistence between businesses and exterior stakeholders becomes more important than ever. This study conducted quantitative performance analysis for big/small medium businesses (mother company, cooperating companies) which carried out collaboration for procurement and production in the form of a virtual company for production of final products through electronic information sharing. The analysis result found that small and medium-sized cooperating companies had more benefit than mother company and there was more benefit in delivery management than logistics management in comparison. Along the way, it was found that cooperating companies could achieve significant performance through collaboration system only when their business dependence on mother company should be more than critical point.
C1 [Kim, Jeongyeon; Chang, Hangbae] Sangmyung Univ, Dept Business Adm, Seoul, South Korea.
   [Kim, Yanghoon] Sangmyung Univ, Inst Comp Software & Media Technol, Seoul, South Korea.
C3 Sangmyung University; Sangmyung University
RP Chang, H (corresponding author), Sangmyung Univ, Dept Business Adm, Seoul, South Korea.
EM hbchang@smu.ac.kr
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) [NIPA-2013-H0301-13-5004]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2013-H0301-13-5004) supervised by the NIPA
   (National IT Industry Promotion Agency).
CR Anthony T., 2000, Achieving Supply Chain Excellence Through Technology, V2, P41
   Banker RG, 2000, ACC REV, V79, P1, DOI DOI 10.2308/ACCR.2004.79.1.1
   Beylier C, 2009, J ENG DESIGN, V20, P523, DOI 10.1080/09544820801898482
   Das TK., 2003, Scandinavian journal of management, V19, P279, DOI DOI 10.1016/S0956-5221(03)00003-4
   de Jong JPJ, 2010, RES POLICY, V39, P47, DOI 10.1016/j.respol.2009.10.003
   Ginige A., 2012, INFORM SYSTEMS CROSS, P181, DOI DOI 10.1007/978-3-7908-2789-7_
   IVES B, 1984, MANAGE SCI, V30, P586, DOI 10.1287/mnsc.30.5.586
   Robey D, 2008, J ASSOC INF SYST, V9, P497
   Sawers JL, 2008, TECHNOVATION, V28, P171, DOI 10.1016/j.technovation.2007.09.002
   Zhang MJ, 2005, J ENG TECHNOL MANAGE, V22, P163, DOI 10.1016/j.jengtecman.2005.06.003
NR 10
TC 2
Z9 2
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3305
EP 3316
DI 10.1007/s11042-013-1834-9
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000004
DA 2024-07-18
ER

PT J
AU Mao, Q
   Chang, CC
   Harn, L
   Chang, SC
AF Mao, Qian
   Chang, Chin-Chen
   Harn, Lein
   Chang, Shih-Chang
TI An image-based key agreement protocol using the morphing technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Key agreement; Image morphing; De-morphing
AB Most traditional key agreement protocols are based on data exchange. In this paper, a novel key agreement protocol based on image exchange is proposed. In this protocol, the communication entities who want to establish a session key are pre-assigned a secret image by the registration center (RC) initially. In real-time communication, using this image as the source image, along with another image of her/his choosing as the target image, the entity creates a morphed image and transmits it to the other communication entity. At the receiver side, the entity de-morphs the received image using the same source image and recovers the target image. However, the recovered image is not completely the same as the original image because some pixels have been lost during the morphing process. Therefore, the relationship between the original image and the morphed image needs to be analyzed and the lost pixels are located accurately. By removing the lost pixels from the self-generated original image and the recovered image of the other entity, both communication entities can obtain the same information that can be used as the secret session key. This approach using the exchanged morphed image for establishing secret session key can conceal the purpose of the key distribution and therefore enhances its security. In addition, the exchange of the image between two entities provides intuitive information for communication entities.
C1 [Mao, Qian] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Mao, Qian; Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Harn, Lein] Univ Missouri, Dept Comp Sci Elect Engn, Kansas City, MO 64110 USA.
   [Chang, Shih-Chang] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 University of Shanghai for Science & Technology; Asia University Taiwan;
   Feng Chia University; University of Missouri System; University of
   Missouri Kansas City; National Chung Cheng University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM maoqiansh@gmail.com; alan3c@gmail.com; harnl@umkc.edu;
   chang.coby@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
CR Ali A, 2013, MULTIMED TOOLS APPL, V66, P201, DOI 10.1007/s11042-011-0791-4
   [Anonymous], IACR CRYPTOLOGY EPRI
   Areeyapinan J., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P283, DOI 10.1109/JCSSE.2012.6261966
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Biham E, 2004, LECT NOTES COMPUT SC, V3152, P290
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Harn L, 2010, IEEE T COMPUT, V59, P842, DOI 10.1109/TC.2010.40
   Jarecki S, 2011, IEEE T PARALL DISTR, V22, P879, DOI 10.1109/TPDS.2010.128
   Joux A, 2004, J CRYPTOL, V17, P263, DOI 10.1007/s00145-004-0312-y
   Lai LF, 2012, IEEE T INF FOREN SEC, V7, P480, DOI 10.1109/TIFS.2011.2180527
   Law L, 2003, DESIGN CODE CRYPTOGR, V28, P119, DOI 10.1023/A:1022595222606
   Mao Q, 2013, IETE TECH REV, V30, P336, DOI 10.4103/0256-4602.116723
   McCullagh N, 2005, LECT NOTES COMPUT SC, V3376, P262
   Nakamura H, 2008, 2008 22ND INTERNATIONAL WORKSHOPS ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOLS 1-3, P1585, DOI 10.1109/WAINA.2008.163
   Qiangfu Zhao, 2011, Proceedings of the 2011 3rd International Conference on Awareness Science and Technology (iCAST), P117, DOI 10.1109/ICAwST.2011.6163124
   Renna F, 2013, IEEE T COMMUN, V61, P620, DOI 10.1109/TCOMM.2012.102512.120084
   Salimi S, 2011, IEEE T INF FOREN SEC, V6, P775, DOI 10.1109/TIFS.2011.2158310
   Shamir A., 1985, Advances in Cryptology, V84 4, P47, DOI 10.1007/3-540-39568-7_5
   Wang SB, 2009, INFORM SCIENCES, V179, P307, DOI 10.1016/j.ins.2008.09.020
   Wolberg G., 1989, Visual Computer, V5, P95, DOI 10.1007/BF01901485
   Zhang YY, 2013, MULTIMED TOOLS APPL, V67, P97, DOI 10.1007/s11042-012-1054-8
   Zhao QF, 2012, IEEE SYS MAN CYBERN, P364, DOI 10.1109/ICSMC.2012.6377728
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
   Zhu L, 2007, IEEE T IMAGE PROCESS, V16, P1481, DOI 10.1109/TIP.2007.896637
NR 26
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3207
EP 3229
DI 10.1007/s11042-013-1780-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800018
DA 2024-07-18
ER

PT J
AU Kwon, JH
   Kim, EJ
AF Kwon, Jung-Hyok
   Kim, Eui-Jik
TI Adaptive multi-channel allocation for vehicular infrastructure mesh
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrastructure communications; Multi-channel MAC; Vehicular network;
   Wireless mesh network
ID WIRELESS SENSOR NETWORKS; MAC
AB This paper focuses on a wireless solution for vehicular infrastructure systems. In order to achieve both low cost and high efficiency, infrastructures can be connected to each other in vehicular networks by a wireless link similar to a mesh router in wireless mesh networks (WMNs). However, the existing WMN solutions cannot appropriately support various vehicular applications that require high rate and low latency communications. Therefore, in this paper, we present the design and performance evaluation of an adaptive multi-channel allocation for vehicular infrastructure mesh systems (abbreviated AMCA). In order to meet both high rate and low latency communications, AMCA is designed to provide optimal channel assignment duration for each flow to efficiently utilize multiple non-overlapping channels. The performance evaluation of AMCA is conducted by the QualNet 5.0 simulator under various network scenarios to consider diverse network conditions. Simulation results show that AMCA can achieve higher network throughput and lower average packet delay than other well known wireless solutions.
C1 [Kwon, Jung-Hyok] LIG Nex1 Co Ltd, Software R&D Lab, Songnam 463400, Gyeonggi Do, South Korea.
   [Kim, Eui-Jik] Hallym Univ, Dept Ubiquitous Comp, Chuncheon Si 200702, Gangwon Do, South Korea.
C3 LIG Nex1 Co., Ltd.; Hallym University
RP Kim, EJ (corresponding author), Hallym Univ, Dept Ubiquitous Comp, 39 Hallymdaehak Gil, Chuncheon Si 200702, Gangwon Do, South Korea.
EM ejkim32@hallym.ac.kr
FU Hallym University Research Fund [HRF-201309-002]
FX This research was supported by Hallym University Research Fund, 2013
   (HRF-201309-002).
CR Akyildiz IF, 2005, COMPUT NETW, V47, P445, DOI 10.1016/j.comnet.2004.12.001
   [Anonymous], 2016, IEEE Standard 802.11-2020
   [Anonymous], P IEEE VEH TECHN C S
   [Anonymous], 2012 IEEE 75 VEH TEC
   Bianchi G, 2000, IEEE J SEL AREA COMM, V18, P535, DOI 10.1109/49.840210
   Bruno R, 2005, IEEE COMMUN MAG, V43, P123, DOI 10.1109/MCOM.2005.1404606
   Dar K, 2010, IEEE COMMUN MAG, V48, P156, DOI 10.1109/MCOM.2010.5458377
   Delhoum M. E. A., 2012, COMMUN COMPUT INF SC, V293, P459, DOI [10.1007/978-3-642- 30507-8_39, DOI 10.1007/978-3-642-30507-8_]
   Ergen M, 2005, MOBILE NETW APPL, V10, P705, DOI 10.1007/s11036-005-3364-9
   Ezell S., 2010, Intelligent Transportation Systems
   Hamza-Lup GL, 2008, IEEE T INTELL TRANSP, V9, P615, DOI 10.1109/TITS.2008.2006738
   Kim EJ, 2012, IET COMMUN, V6, P2120, DOI 10.1049/iet-com.2011.0700
   Kim EJ, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/50911
   Kim EJ, 2012, IEICE T INF SYST, VE95D, P188, DOI 10.1587/transinf.E95.D.188
   Kim EJ, 2011, IEICE T COMMUN, VE94B, P2461, DOI 10.1587/transcom.E94.B.2461
   Kim EJ, 2011, SENSORS-BASEL, V11, P6629, DOI 10.3390/s110706629
   Nieminen J, 2011, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2011-108
   Rawat DB, 2011, IEEE T PARALL DISTR, V22, P1528, DOI 10.1109/TPDS.2011.41
   So J., 2004, MOBIHOC 04, P222
   Task Group P, 2009, 80211P IEEE TASK GRO
   Uzcátegui RA, 2009, IEEE COMMUN MAG, V47, P126, DOI 10.1109/MCOM.2009.4939288
   Ye F, 2010, EURASIP J WIREL COMM, DOI 10.1155/2010/930414
   Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001
NR 23
TC 11
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1593
EP 1609
DI 10.1007/s11042-013-1752-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900005
DA 2024-07-18
ER

PT J
AU Chen, Y
   Aygün, RS
AF Chen, Yi
   Ayguen, Ramazan S.
TI SpriteCam: virtual camera control using sprite
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual camera control; Sprite generation; Video editing
ID GLOBAL MOTION ESTIMATION; EFFICIENT; SYSTEM; ROBUST
AB Editing or browsing video based on spatial content without distortion or cropping has been challenging because of providing unavailable information (view) in a single frame. Virtual camera control enables the user to view the video from her perspective by using camera functions such as pan, tilt, and zoom on a recorded video. In this paper, we propose our SpriteCam system that provides virtual camera controls by first generating the background sprite or mosaic of the video. We provide the theoretical framework and then explain how pan, tilt, and zoom operations are applied using the sprite. SpriteCam allows centralizing objects, aspect ratio conversion, and fixing the camera view without distortion or information loss for videos which sprite can be generated.
C1 [Chen, Yi; Ayguen, Ramazan S.] Univ Alabama, Dept Comp Sci, Huntsville, AL 35899 USA.
C3 University of Alabama System; University of Alabama Huntsville
RP Aygün, RS (corresponding author), Univ Alabama, Dept Comp Sci, Huntsville, AL 35899 USA.
EM yichen@cs.uah.edu; raygun@cs.uah.edu
RI Chen, Yi/G-6720-2013; Aygun, Ramazan/HTQ-3507-2023
OI Aygun, Ramazan/0000-0001-7244-7475
FU National Science Foundation [0812307]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [0812307] Funding
   Source: National Science Foundation
FX This material is based upon work supported by the National Science
   Foundation under Grant No. 0812307.
CR [Anonymous], P PACK VID 2007
   Avidan S., 2007, ACM SIGGRAPH 2007 PA, P10, DOI [10.1145/1275808.1276390, DOI 10.1145/1275808.1276390]
   Aygün RS, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA537
   Aygun RS, 2004, 2004 IE INT C MULT E
   Barhoumi W, 2011, MULTIMEDIA TOOLS APP
   Chen Y, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2168996.2169002
   Cheung HK, 2007, IET IMAGE PROCESS, V1, P13, DOI 10.1049/iet-ipr:20050212
   Deng ZL, 2008, MUE: 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P114, DOI 10.1109/WE.2008.112
   Deshpande AA, 2009, PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, P231, DOI 10.1109/DEXA.2009.77
   Dufaux F, 2000, IEEE T IMAGE PROCESS, V9, P497, DOI 10.1109/83.826785
   Glantz A, 2010, MULTIMED TOOLS APPL, V49, P483, DOI 10.1007/s11042-010-0469-3
   Guo YD, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 4, PROCEEDINGS, P92, DOI 10.1109/CISP.2008.714
   GUO YD, 2007, LNCS
   HSIA SC, 1994, IEEE T CONSUM ELECTR, V40, P216, DOI 10.1109/30.320798
   Kunter M, 2007, PROC SPIE, V6508, DOI 10.1117/12.704145
   Lee MC, 1997, IEEE T CIRC SYST VID, V7, P130, DOI 10.1109/76.554424
   Lu Y, 2003, IEEE T CIRC SYST VID, V13, P394, DOI 10.1109/TCSVT.2003.811607
   Lu Y, 2001, P 2 IEEE PAC RIM C M
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P9
   Smolic A, 1999, IEEE T CIRC SYST VID, V9, P1227, DOI 10.1109/76.809158
   SMOLIC A, 2000, P ICIP2000 IEEE INT
   Wilson A., 2000, Proceedings ACM Multimedia 2000, P75, DOI 10.1145/354384.354431
   Xinding Sun, 2005, IEEE Transactions on Multimedia, V7, P981, DOI 10.1109/TMM.2005.854388
NR 23
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 1067
EP 1089
DI 10.1007/s11042-013-1711-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400019
DA 2024-07-18
ER

PT J
AU Cheng, J
   Li, P
   Rui, T
   Lu, HQ
AF Cheng, Jian
   Li, Peng
   Rui, Ting
   Lu, Hanqing
TI Learning latent semantic model with visual consistency for image
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PLSA; Latent semantic model; Image clustering
AB Latent semantic models (e.g. PLSA and LDA) have been successfully used in document analysis. In recent years, many of the latent semantic models have also been proved to be promising for visual content analysis tasks, such as image clustering and classification. The topics and words which are two of the key components in latent semantic models have explicit semantic meaning in document analysis. However, these topics and words are difficult to be described or represented in visual content analysis tasks, which usually leads to failure in practice. In this paper, we consider simultaneously the topic consistency and word consistency in semantic space to adapt the traditional PLSA model to the visual content analysis tasks. In our model, the a"" (1)-graph is constructed to model the local neighborhood structure of images in feature space and the word co-occurrence is computed to capture the local word consistency. Then, the local information is incorporated into the model for topic discovering. Finally, the generalized EM algorithm is used to estimate the parameters. Extensive experiments on publicly available databases demonstrate the effectiveness of our approach.
C1 [Cheng, Jian; Li, Peng; Lu, Hanqing] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   [Rui, Ting] PLA Univ Sci & Technol, Nanjing 210007, Jiangsu, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Army
   Engineering University of PLA
RP Cheng, J (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM jcheng@nlpr.ia.ac.cn; pli@nlpr.ia.ac.cn; luhq@nlpr.ia.ac.cn
RI , chengjian/KGL-5551-2024
OI , chengjian/0000-0003-1289-2758
FU 973 Program [2010CB327905]; National Natural Science Foundation of China
   [61332016, 61202325]
FX This work was supported in part by 973 Program (Grant No. 2010CB327905),
   National Natural Science Foundation of China (Grant No. 61332016,
   61202325).
CR [Anonymous], 2004, P 12 ANN ACM INT C M, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   [Anonymous], 2009, P 26 ANN INT C MACH, DOI DOI 10.1145/1553374.1553388
   [Anonymous], 2008, Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM '08
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Gallagher AC, 2011, PROC CVPR IEEE
   He X., 2003, P NIPS
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li F., 2004, P IEEE C COMP VIS PA, P178
   Li P, 2012, P ACCV, P648
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   NEAL R, 1998, LEARN GRAPH MODELS
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tenenbaum JB, 1998, ADV NEUR IN, V10, P682
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
NR 27
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1341
EP 1356
DI 10.1007/s11042-014-1916-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300010
DA 2024-07-18
ER

PT J
AU Hou, HM
   Xu, XS
   Wang, G
   Wang, XL
AF Hou, Hong-Mei
   Xu, Xin-Shun
   Wang, Gang
   Wang, Xiao-Lin
TI Joint-Rerank: a novel method for image search reranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Joint-Rerank; Multimodal fusion; Image search; Random walk; Graph model
AB Image search reranking which aims to improve the text-based image search results with the help of other cues has grown into a hot research topic. Most existing reranking methods only focus on image visual cues. However, the visual cues cannot always guarantee to provide enough information for the reranking process. Although, some approaches try to fuse multiple image cues for reranking, they do not or weakly exploit the relationships among multiple image cues. In this paper,we present a novel image reranking framework-Joint-Rerank which considers multiple modalities of images (or multiple cues) jointly as interdependent attributes of an image entity. Joint-Rerank models the images as a multigraph where each image is a node with multimodal attributes (textual and visual cues) and the parallel edges between nodes measure both image intra-modal and inter-modal similarities. Besides, each node has a "self-consistency" that measures how much the multiple modalities of an image may be consistent. To solve the reranking problem, we first degenerate the multigraph into a new complete graph, and then employ a random walk on the degenerated graph to propagate the relevance scores of each node. Finally, the relevance scores of multiple modalities are fused to rank the images. Moreover, in Joint-Rerank, "cross-modal" walk is possible, i.e., a surfer can jump from one image to another following both intra-modal and inter-modal links. In this framework, we propose two methods: Sym-Joint-Rerank and Asym-Joint-Rerank which use different approaches to measure the inter-modal similarities between two nodes. Experimental results on a large web queries dataset which contains 353 image search queries show that both of them are superior or highly competitive to several state-of-the-art reranking algorithms.
C1 [Hou, Hong-Mei; Xu, Xin-Shun; Wang, Gang; Wang, Xiao-Lin] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Peoples R China.
C3 Shandong University
RP Xu, XS (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Peoples R China.
EM hongmeisd@gmail.com; xuxinshun@sdu.edu.cn; wanggang.sdu@gmail.com;
   wangxiaolin@sdu.edu.cn
FU National Natural Science Foundation of China [61173068]; Program for New
   Century Excellent Talents in University; DNSLAB, China Internet Network
   Information Center [K201206007]
FX We would like to thank the reviewers for carefully reading our
   manuscript and giving detailed comments and suggestions that have been
   helpful to improve the manuscript. This research is partially supported
   by National Natural Science Foundation of China (61173068), Program for
   New Century Excellent Talents in University and DNSLAB, China Internet
   Network Information Center (K201206007).
CR [Anonymous], P ACM MULT
   [Anonymous], 2010, P ACM INT C MULT
   [Anonymous], 2010, P ACM INT C IMAGE VI
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Baluja S, 2008, WORLD WID WEB C, P895
   Berg TamaraL., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.57
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cao Z., 2007, P 24 INT C MACHINE L, P129, DOI DOI 10.1145/1273496.1273513
   Cui J., 2008, MM 08, P729
   Deng HB, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P239
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242
   Gang Wang., 2008, Computer Vision and Pattern Recognition, IEEE Computer Society Conference on, P1
   Houle ME, 2010, LECT NOTES COMPUT SC, V6187, P482, DOI 10.1007/978-3-642-13818-8_34
   Hsu W. H., 2006, MULTIMEDIA '06, P35
   Hsu WinstonH., 2007, ACM MM
   Iyengar G., 2005, 13th Annual ACM International Conference on Multimedia, P21, DOI 10.1145/1101149.1101154
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kennedy L. S., 2005, 13th Annual ACM International Conference on Multimedia, P882, DOI 10.1145/1101149.1101339
   Krapac J, 2010, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR.2010.5540092
   LAM MS, 1991, SIGPLAN NOTICES, V26, P63, DOI 10.1145/106973.106981
   Li LJ, 2010, INT J COMPUT VISION, V88, P147, DOI 10.1007/s11263-009-0265-6
   Lin WH, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P242
   Liu Jingjing., 2007, MULTIMEDIA 07, P208
   Liu Y., 2008, P ACM INT WORKSH MUL, P253
   Liu Y, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P297, DOI 10.1109/ICME.2008.4607430
   Lu JY, 2012, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2012.6248033
   Ma H, 2010, IEEE T MULTIMEDIA, V12, P462, DOI 10.1109/TMM.2010.2051360
   Mei T., 2007, TREC VID RETR EV ONL
   Natsev Apostol., 2007, MULTIMEDIA 07, P991
   Qi GJ, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404883
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Robertson S., 2000, TREC9, P25
   Schroff F, 2007, IEEE I CONF COMP VIS, P2120
   Tian X., 2008, ACM INT C MULTIMEDIA, P131, DOI DOI 10.1145/1459359.1459378.ISBN
   Tian XM, 2010, LECT NOTES COMPUT SC, V5916, P163, DOI 10.1007/978-3-642-11301-7_19
   Tian XM, 2010, IEEE T IMAGE PROCESS, V19, P805, DOI 10.1109/TIP.2009.2035866
   Wang G, 2012, P ACM INT C MULT RET
   Wang M., 2009, Tech. Rep. MSR-TR-2009-30
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Yan R, 2003, LECT NOTES COMPUT SC, V2728, P238
   Yang LJ, 2012, IEEE T MULTIMEDIA, V14, P871, DOI 10.1109/TMM.2012.2187778
   Zhang L, 2011, PATTERN RECOGN, V44, P1811, DOI 10.1016/j.patcog.2011.01.016
NR 44
TC 3
Z9 4
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1423
EP 1442
DI 10.1007/s11042-014-1962-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300014
DA 2024-07-18
ER

PT J
AU Pappas, N
   Popescu-Belis, A
AF Pappas, Nikolaos
   Popescu-Belis, Andrei
TI Combining content with user preferences for non-fiction multimedia
   recommendation: a study on TED lectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based multimedia indexing; Recommender systems; Multimedia
   recommendation; TED lectures
AB This paper introduces a new dataset and compares several methods for the recommendation of non-fiction audio visual material, namely lectures from the TED website. The TED dataset contains 1,149 talks and 69,023 profiles of users, who have made more than 100,000 ratings and 200,000 comments. The corresponding metadata, which we make available, can be used for training and testing generic or personalized recommender systems. We define content-based, collaborative, and combined recommendation methods for TED lectures and use cross-validation to select the best parameters of keyword-based (TFIDF) and semantic vector space-based methods (LSI, LDA, RP, and ESA). We compare these methods on a personalized recommendation task in two settings, a cold-start and a non-cold-start one. In the cold-start setting, semantic vector spaces perform better than keywords. In the non-cold-start setting, where collaborative information can be exploited, content-based methods are outperformed by collaborative filtering ones, but the proposed combined method shows acceptable performances, and can be used in both settings. For the generic recommendation task, LSI and RP again outperform TF-IDF.
C1 [Pappas, Nikolaos] Idiap Res Inst, CH-1920 Martigny, Switzerland.
   [Pappas, Nikolaos] Ecole Polytech Fed Lausanne, CH-1920 Martigny, Switzerland.
   [Popescu-Belis, Andrei] Idiap Res Inst, CH-1920 Martigny, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Pappas, N (corresponding author), Idiap Res Inst, Rue Marconi 19, CH-1920 Martigny, Switzerland.
EM nikolaos.pappas@idiap.ch; andrei.popescu-belis@idiap.ch
RI ; Popescu-Belis, Andrei/P-2246-2017
OI Pappas, Nikolaos/0000-0002-2004-8111; Popescu-Belis,
   Andrei/0000-0003-4934-2071
FU European Union [287872]
FX We are grateful for the support received for this work from the European
   Union through the inEvent project FP7-ICT n. 287872 (see
   http://www.inevent-project.eu).
CR Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Anderson C., 2006, LONG TAIL WHY FUTURE
   [Anonymous], 2006, P ACMSIGKDD INT C KN
   [Anonymous], 2006, THESIS STOCKHOLM U S
   [Anonymous], 2007, P 6 ACM INT C IM VID
   [Anonymous], 2010, P ACM INT C INFORM K
   [Anonymous], 2009, HDB RES DIGITAL LIB
   Antulov-Fantulin N, 2011, P ECML PKDD 2011 DIS
   Arapakis I., 2009, P ACM INT C IM VID R, P29, DOI [10.1145/1646396.1646433, DOI 10.1145/1646396.1646433]
   Arapakis I, 2009, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2009.5202773
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cremonesi P, 2010, P 4 ACM C REC SYST B
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V46, P331, DOI 10.1007/s11042-009-0387-4
   Degemmis M, 2007, USER MODEL USER-ADAP, V17, P217, DOI 10.1007/s11257-006-9023-4
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Di Massa R, 2010, P 3 INT WORKSH AUT I, P33, DOI [10.1145/1877850.1877861, DOI 10.1145/1877850.1877861]
   Federico M, 2012, P INT WORKSH SPOK LA
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1606
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hofmann T, 1999, P 22 ANN INT ACM SIG, V99, P50
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Johansson P, 2003, P 1 NORD S MULT COMM, P53
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Lees-Miller J, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P337, DOI 10.1109/ICMLA.2008.121
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   Magnini B, 2001, LECT NOTES ARTIF INT, V2109, P74
   Mahmood T, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P73
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P83, DOI 10.1109/MMUL.2002.1022862
   Mei T, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1961209.1961213
   Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773
   Pan R, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P667
   Pan R, 2008, IEEE DATA MINING, P502, DOI 10.1109/ICDM.2008.16
   Papagelis M, 2005, ENG APPL ARTIF INTEL, P152
   Pappas N, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P773
   Pappas N, 2013, INT WORK CONTENT MUL, P47, DOI 10.1109/CBMI.2013.6576551
   Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847
   Rendle S., 2009, P 25 C UNCERTAINTY A, P452
   Sahlgren M, 2005, P 7 INT C TERM KNOWL, V5
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Semeraro G., 2009, Proc. Int. ACM Conf. Recommender Systems (RecSys), P301
   Semeraro G, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2856
   Shani G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P257, DOI 10.1007/978-0-387-85820-3_8
   Shi Y., 2012, P 6 ACM C RECOMMENDE, P139, DOI [10.1145/2365952.2365981, DOI 10.1145/2365952.2365981]
   Shin H, 2009, IEEE T CONSUM ELECTR, V55, P1417, DOI 10.1109/TCE.2009.5278008
   Sindhwani V, 2009, P 3 ACM C REC SYST R
   Smirnov AV, 2008, ARXIV08042354 CORR
   Tsinaraki C, 2006, P 12 INT C MULT MOD, P8
   Xia Ning, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P497, DOI 10.1109/ICDM.2011.134
NR 49
TC 10
Z9 13
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1175
EP 1197
DI 10.1007/s11042-013-1840-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Doan, TN
   Do, TN
   Poulet, F
AF Thanh-Nghi Doan
   Thanh-Nghi Do
   Poulet, Francois
TI Large scale classifiers for visual classification tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Large scale visual classification; Support vector machines; Incremental
   learning method; Balanced bagging; High performance computing
ID IMAGE CLASSIFICATION; SVM
AB ImageNet dataset with more than 14 million images and 21,000 classes makes the problem of visual classification more difficult to deal with. One of the most difficult tasks is to train a fast and accurate visual classifier on several multi-core computers with limited individual memory resource. In this paper we address this challenge by extending both state-of-the-art large scale linear classifier (LIBLINEAR-CDBLOCK) and non-linear classifier (Power Mean SVM) for large scale visual classification tasks in these following ways: (1) an incremental learning method for Power Mean SVM, (2) a balanced bagging algorithm for training binary classifiers. Our approach has been evaluated on the 100 largest classes of ImageNet and ILSVRC 2010. The evaluation shows that our approach can save up to 82.01 % memory usage and the learning process is much faster than the original implementation and LIBLINEAR SVM.
C1 [Thanh-Nghi Doan] An Giang Univ, An Giang, Vietnam.
   [Thanh-Nghi Do] Inst Telecom, Telecom Bretagne UMR CNRS Lab STICC 6285, Brest, France.
   [Thanh-Nghi Do] Can Tho Univ, Can Tho, Vietnam.
   [Poulet, Francois] Univ Rennes 1, IRISA, F-35042 Rennes, France.
C3 Vietnam National University Hochiminh City; IMT - Institut
   Mines-Telecom; IMT Atlantique; Can Tho University; Universite de Rennes
RP Doan, TN (corresponding author), An Giang Univ, An Giang, Vietnam.
EM dtnghi@agu.edu.vn; dtnghi@cit.ctu.edu.vn; francois.poulet@irisa.fr
OI Doan, Thanh-Nghi/0000-0002-9957-0948
FU Region Bretagne (France); VIED (Vietnam International Education
   Development)
FX This work was funded by Region Bretagne (France) and VIED (Vietnam
   International Education Development).
CR [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], MPI: A Message Passing Interface Standard
   [Anonymous], 2008, P 14 ACM SIGKDD INT
   Berg A., 2010, Large scale visual recognition challenge
   Chawla NV, 2003, LECT NOTES ARTIF INT, V2838, P107, DOI 10.1007/978-3-540-39804-2_12
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6
   Doan TN, 2013, 9 INT C DAT MIN LAS, P197
   Doan TN, 2013, IEEE INT JOINT C NEU, P2976
   Duda R., 1973, Pattern Classification and Scene Analysis
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fergus Rob, 2009, Advances in Neural Information Processing Systems, P522
   Griffin G., 2007, CALTECH 256 OBJECT C
   Griffin G, 2008, PROC CVPR IEEE, P533
   Guermeur Y., 2007, SVM MULTICLASSES THE
   Hsieh C.-J., 2008, P 25 INT C MACH LEAR, P408, DOI [DOI 10.1145/1390156.1390208, 10.1145/1390156.1390208]
   Japkowicz N., 2000, Learning from Imbalanced Data Sets. Papers from the AAAI Workshop (Technical Report WS-00-05), P10
   Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI [10.1145/1150402.1150429, DOI 10.1145/1150402.1150429]
   Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lenca P, 2008, LECT NOTES ARTIF INT, V5012, P634, DOI 10.1007/978-3-540-68125-0_59
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Lin CJ, 2008, J MACH LEARN RES, V9, P627
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maji S, 2008, PROC CVPR IEEE, P2245
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   OpenMP Architecture Review Board, 2008, OpenMP Application Program Interface
   Perronnin F, 2012, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2012.6248090
   Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914
   Pham NK, 2008, INT C DAT MIN, P117
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Ricamato MT, 2008, INT C PATT RECOG, P3523
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Do TN, 2008, LECT NOTES ARTIF INT, V5139, P147
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Visa S., 2005, P 16 MIDW ART INT CO, P67
   Wang CH, 2009, INT CONF ACOUST SPEE, P3709, DOI 10.1109/ICASSP.2009.4960432
   Weiss GM, 2003, J ARTIF INTELL RES, V19, P315, DOI 10.1613/jair.1199
   Weston J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P219
   Wu JX, 2012, PROC CVPR IEEE, P2344, DOI 10.1109/CVPR.2012.6247946
   Wu JX, 2011, J MACH LEARN RES, V12, P3097
   Wu JX, 2010, LECT NOTES COMPUT SC, V6312, P552
   Yibin Li, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1957, DOI 10.1109/ICAL.2009.5262626
   Yu HF, 2012, ACM T KNOWL DISCOV D, V5, DOI 10.1145/2086737.2086743
   Yuan GX, 2012, P IEEE, V100, P2584, DOI 10.1109/JPROC.2012.2188013
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 56
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1199
EP 1224
DI 10.1007/s11042-014-2049-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300004
DA 2024-07-18
ER

PT J
AU Wang, WD
   Nie, T
   Tu, ZP
   Chen, XH
   Wang, YH
AF Wang, Weidong
   Nie, Tao
   Tu, Zhipao
   Chen, Xiaohong
   Wang, Yuehai
TI A threshold-adaptive film mode detection method in video de-interlacing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Film mode detection; De-interlacing; Pull-down pattern;
   Threshold-adaptive
AB With the popularization of the network video, format conversion and de-interlacing are more required in video displaying and transmission. Field merge is perfect to de-interlace the film mode video sequence in which repeated fields or even/odd fields from the same film frame are contained. In this paper, inter-field difference is compared with a threshold, and repetition pattern of the result is utilized to determine the film mode. The threshold is set variable by tracking the local minimum difference of previous and subsequent fields. Film modes with repeated fields are identified using frame difference pattern. The 2-2 film mode is decided if forward and backward field differences jaggedly swing in opposite direction. Other film modes with fields from the same film frame are recognized by the combination of frame difference and forward field difference patterns. In this way, correct field merge is guaranteed after knowing which adjacent fields are decomposed from the same film frame. Experimental results show that various film modes in television systems, animations, camcorders and particularly interlaced network video can be correctly recognized by proposed method.
C1 [Wang, Weidong; Nie, Tao; Tu, Zhipao; Chen, Xiaohong; Wang, Yuehai] Zhejiang Univ, Dept Informat Sci & Elect Engn, Zhejiang Prov Key Lab Informat Network Technol, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, WD (corresponding author), Zhejiang Univ, Dept Informat Sci & Elect Engn, Zhejiang Prov Key Lab Informat Network Technol, Hangzhou 310027, Zhejiang, Peoples R China.
EM wdwang@zju.edu.cn
RI Wang, Yuehai/E-6989-2016
CR [Anonymous], 2012, INT J MATH TEACHING, DOI DOI 10.1109/ICSICT.2012.6466730
   Brox P, 2007, IEEE T CONSUM ELECTR, V53, P1647, DOI 10.1109/TCE.2007.4429265
   Christopher TJ, 1996, United States Patent Office US, Patent No. 5563651
   Communications Specialties Inc, 2009, HDTV STAND PRACT DIG
   Han SH, 2005, IEEE INT C IM PROC, V2, DOI [10.1109/ICIP.2005.1530240, DOI 10.1109/ICIP.2005.1530240]
   IDT, 2012, FILM CAD VID FILM DE
   Jia YW, 2010, United States Patent Office, Patent No. [US 7705913B2, 7705913]
   Jia YW, 2007, United States Patent Office, Patent No. [US 2007/0104273A1, 20070104273]
   Ku CC, 2004, IEEE T CONSUM ELECTR, V50, P1190, DOI 10.1109/TCE.2004.1362518
   Lin SF, 2003, IEEE T CONSUM ELECTR, V49, P1256, DOI 10.1109/TCE.2003.1261227
   ozer N, 2010, European Patent Office, Patent No. [EP 2265010A2, 2265010]
   Schutten RJ, 1998, IEEE T CONSUM ELECTR, V44, P930, DOI 10.1109/30.713216
   SWAN P, 2000, Patent No. 6055018
   Xu D, 1994, World Intellectual Property Organization, Patent No. [WO94/30006, 9430006]
   Yang S, 2004, IEEE T CIRC SYST VID, V14, P1138, DOI 10.1109/TCSVT.2004.833163
   Yuan Y., 2012, IEEE T POWER ELECTR, P1, DOI DOI 10.1109/BMSB.2012.6264277
NR 16
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1361
EP 1389
DI 10.1007/s11042-013-1623-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200013
DA 2024-07-18
ER

PT J
AU Hossain, MS
AF Hossain, M. Shamim
TI QoS-aware service composition for distributed video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Service composition; Distributed video surveillance; QoS; Transcoding
   service; Ant-based algorithm
ID IMPLEMENTATION; DESIGN; ANTNET
AB Quality of Service (QoS) is essential for the ubiquitous access of media services in real-time distributed video surveillance applications. To have ubiquitous access of desired media with emergency officials' handheld devices, appropriate media transcoding services are required. Currently, it is challenging to select and compose these services for each of the devices to satisfy the desired QoS demand. To compose these media services so that video stream is available for target pervasive and smart devices, a composition algorithm is required. Thus, this paper presents a QoS-aware service composition algorithm to select the best composition for the target ubiquitous client so that it can optimally provide QoS to heterogeneous users. We have implemented a video surveillance prototype to demonstrate the performance of the proposed QoS-aware composition algorithm. Results from this prototype reveal that the approach is suitable for real-time video surveillance.
C1 King Saud Univ, CCIS, Riyadh, Saudi Arabia.
C3 King Saud University
RP Hossain, MS (corresponding author), King Saud Univ, CCIS, Riyadh, Saudi Arabia.
EM mshossain@ksu.edu.sa
RI Hossain, M. Shamim/K-1362-2014; Guizani, Mohsen/AAX-4534-2021
OI Hossain, M. Shamim/0000-0001-5906-9422; Guizani,
   Mohsen/0000-0002-8972-8094
FU Research Center of College of Computer and Information Sciences (CCIS),
   King Saud University
FX This work was supported by the Research Center of College of Computer
   and Information Sciences (CCIS), King Saud University. The authors are
   grateful for this support.
CR Ahmad I., 2010, 2010 IEEE WIR COMM N, P1
   [Anonymous], 1998, An Architecture for Differentiated Services, RFC 2475 Informational
   Barake B, 2010, P IEEE ISSPA 2010 10
   Bela G, 2010, STUD U BABES BOLYAI, VLV, P35
   Calvert KL, 1997, IEEE COMMUN MAG, V35, P160, DOI 10.1109/35.587723
   Chen CW, 2009, IEEE T CIRC SYST VID, V19, P1, DOI 10.1109/TCSVT.2009.2012413
   Chen HX, 2009, 2009 INTERNATIONAL CONFERENCE ON SCALABLE COMPUTING AND COMMUNICATIONS & EIGHTH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING, P435, DOI 10.1109/EmbeddedCom-ScalCom.2009.84
   Chunmiao Yuan, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P334, DOI 10.1109/ICINIS.2009.92
   Di Caro G, 1998, J ARTIF INTELL RES, V9, P317, DOI 10.1613/jair.530
   Di Caro G, 2006, ECRIM NEWS       JAN, V64, P34
   DiffServe, 2012, DIFFSERVE SCAL END T
   Estevez-Ayres I, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P887, DOI 10.1109/ICCE.2011.5722920
   Estévez-Ayres I, 2011, CONCURR COMP-PRACT E, V23, P1816, DOI 10.1002/cpe.1766
   Gu XH, 2002, INT CON DISTR COMP S, P194
   Hossain MA, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870124
   Hossain MS, 2010, IEEE T INSTRUM MEAS, V59, P1498, DOI 10.1109/TIM.2009.2024338
   Hossain MS, 2009, CONCURR COMP-PRACT E, V21, P1450, DOI 10.1002/cpe.1400
   Hossain MS, 2011, P IEEE ICME AAMS PS
   IBM, 2009, IBM TRANSC SOL SERV
   Iqbal R, 2009, P ACM IEEE ICDSC 09
   Kandris D, 2011, AD HOC NETW, V9, P591, DOI 10.1016/j.adhoc.2010.09.001
   Kathiravan K, 2009, 2009 1ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS(CICSYN 2009), P476, DOI 10.1109/CICSYN.2009.46
   Kumar P, 2012, MULTIMED TOOLS APPL, V56, P365, DOI 10.1007/s11042-010-0672-2
   Lamy-Bergot C, 2009, ITST: 2009 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORT SYSTEMS TELECOMMUNICATIONS, P415, DOI 10.1109/ITST.2009.5399319
   Leu JS, 2011, COMPUT ELECTR ENG, V37, P1182, DOI 10.1016/j.compeleceng.2011.05.015
   Leu JS, 2009, IEEE SYS MAN CYBERN, P2498, DOI 10.1109/ICSMC.2009.5346343
   Li H, 2008, P IEEE WICOM 08 DAL
   Musunoori S, 2006, P IEEE CEC 06 VANC C, P2604
   Ohm JR, 2009, OVERVIEW SCALABLE VI
   Park K, 2008, COMPUT COMMUN, V31, P2951, DOI 10.1016/j.comcom.2008.04.003
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Singh G, 2004, IEEE MULTIMEDIA, V11, P20, DOI 10.1109/MMUL.2004.1261102
   Vetro A, 2003, MULT EXP 2003 ICME 0, P417
   Yao Y, 2010, COMPUT VIS IMAGE UND, V114, P463, DOI 10.1016/j.cviu.2010.01.003
   Yuan C.P., 2009, P 2009 34 INT C INFR, VVolume 073109, P1, DOI [10.1109/ICIMW.2009.5324786, DOI 10.1109/ICIMW.2009.5324786]
NR 35
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 169
EP 188
DI 10.1007/s11042-012-1312-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700009
DA 2024-07-18
ER

PT J
AU Han, YX
   Zhang, ZS
AF Han, Yanxiang
   Zhang, Zhisheng
TI An efficient estimation method for intensity factor of illumination
   changes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intensity correction; Illumination variations; EM Algorithm; Parameter
   estimation
AB For intensity correction under illumination changes in video sequence, one of the main problems lies in the lack of adaptive technique for the classification of stationary and non-stationary pixels in the images. In this paper, we propose an efficient estimation approach for intensity factor of illumination changes in order to perform intensity correction for dynamic sequence images. Firstly, the ratio image is obtained, where the probability density function computed on pixel values can be considered as a mixture Gaussian model. Then the process of the parameter estimations is performed based on Expectation-maximization (EM) algorithm. Under the assumption of Gaussian distribution for the values of stationary pixels, the intensity factor can be estimated by using pixels adjacent to the mean value of Gaussian distribution related to the stationary class. Finally, two experiments are carried out to verify the proposed method.
C1 [Han, Yanxiang; Zhang, Zhisheng] Southeast Univ, Sch Mech Engn, Nanjing 211189, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Zhang, ZS (corresponding author), Southeast Univ, Sch Mech Engn, Nanjing 211189, Jiangsu, Peoples R China.
EM oldbc@seu.edu.cn
RI zhang, zhisheng/KVZ-1017-2024
FU National Nature Science Foundation of China (NSFC) [50805023]; Special
   Fund of Jiangsu Province for the Transformation of Scientific and
   Technological Achievements [BA2010093]; Hexa-type Elites Peak Program of
   Jiangsu Province [2008144]
FX This work was supported by National Nature Science Foundation of China
   (NSFC) under 50805023, the Special Fund of Jiangsu Province for the
   Transformation of Scientific and Technological Achievements under
   BA2010093 and the Hexa-type Elites Peak Program of Jiangsu Province
   under 2008144.
CR Aach T, 2001, 18 C GRETSI TOUL FRA, P9
   Black MJ, 2000, COMPUT VIS IMAGE UND, V78, P8, DOI 10.1006/cviu.1999.0825
   Celik T, 2010, SIGNAL PROCESS, V90, P1471, DOI 10.1016/j.sigpro.2009.10.018
   Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566, DOI 10.1109/36.718860
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Kim YH, 2005, IMAGE VISION COMPUT, V23, P365, DOI 10.1016/j.imavis.2004.05.010
   LILLESTRAND RL, 1972, IEEE T COMPUT, VC 21, P654, DOI 10.1109/T-C.1972.223570
   Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Sayed MS, 2011, IEEE T CIRC SYST VID, V21, P1622, DOI 10.1109/TCSVT.2011.2130290
   Shulman D, 1989, WORKSH VIS MOT P IRV
   SKIFSTAD K, 1989, COMPUT VISION GRAPH, V46, P387, DOI 10.1016/0734-189X(89)90039-X
   Toth D, 2000, IM AN INT 2000 P 4 I
   van Roosmalen PMB, 1999, IEEE T CIRC SYST VID, V9, P1013, DOI 10.1109/76.795054
   Withagen PJ, 2010, INT J COMPUT VISION, V86, P33, DOI 10.1007/s11263-009-0247-8
   Withagen PJ, 2007, IEEE T INSTRUM MEAS, V56, P199, DOI 10.1109/TIM.2006.887667
   Xie BL, 2004, IMAGE VISION COMPUT, V22, P117, DOI 10.1016/j.imavis.2003.07.003
NR 19
TC 3
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2619
EP 2632
DI 10.1007/s11042-013-1521-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300024
DA 2024-07-18
ER

PT J
AU Chen, HH
   Ding, JJ
   Sheu, HT
AF Chen, Hsin-Hui
   Ding, Jian-Jiun
   Sheu, Hsin-Teng
TI Image retrieval based on quadtree classified vector quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quadtree segmentation; Vector quantization; Classified vector
   quantization; Image indexing; Content-based image retrieval
ID COLOR
AB In this paper, a color image retrieval scheme based on quadtree classified vector quantization (QCVQ) is proposed. This scheme not only captures intra-block correlation but also exploits the visual importance of image blocks to efficiently describe the content of images in a compressed domain. In the proposed algorithm, a query image is first divided by quadtree segmentation and then classified into smooth and high-detail blocks. For high-detail blocks, the local thresholding classifier with 28 edge binary templates is employed to extract a variety of visually important regions which are edge intensive. After all of the blocks in the image are encoded by the pre-trained QCVQ codebook, the indices in the compressed domain are obtained. Finally, the frequencies of indices are counted to build the index histogram as a feature of the query image. Simulation results demonstrate that our proposed scheme yields the better retrieval performance compared to the well-known vector quantization (VQ)-based image retrieval method and three other techniques. These results show that quadtree segmentation and edge style classification are indeed helpful for improving the performance of content-based image retrieval.
C1 [Chen, Hsin-Hui; Ding, Jian-Jiun] Natl Taiwan Univ, Grad Inst Commun Engn, Taipei 10617, Taiwan.
   [Sheu, Hsin-Teng] Tung Nan Univ, Dept Elect Engn, Xinbei 22202, Taiwan.
C3 National Taiwan University
RP Ding, JJ (corresponding author), Natl Taiwan Univ, Grad Inst Commun Engn, Taipei 10617, Taiwan.
EM djj@cc.ee.ntu.edu.tw
CR [Anonymous], VIS TEXT
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Daptardar AH, 2005, LECT NOTES COMPUT SC, V3804, P502
   Gray M., 1982, IEEE T INFORMATION T, V28, P157
   Hamid AM, 2005, PATTERN RECOGN, V38, P2506
   Hossein N, 2005, P WORLD ACAD SCI ENG, V3
   Hrovje D, 2000, IMAGE SIGNAL PROCESS
   IDRIS F, 1995, IEEE T CONSUM ELECTR, V41, P937, DOI 10.1109/30.468062
   Idris F, 1997, IMAGE VIDEO INDEXING
   Jing H, 1997, P C COMP VIS PATT RE, V97, P762
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Paschos G, 2003, IEEE T KNOWL DATA EN, V15, P1069, DOI 10.1109/TKDE.2003.1232264
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Qiu GP, 2003, IEEE T IMAGE PROCESS, V12, P93, DOI 10.1109/TIP.2002.807356
   Quweider MK, 1996, IEE P-VIS IMAGE SIGN, V143, P344, DOI 10.1049/ip-vis:19960779
   RAMAMURTHI B, 1986, IEEE T COMMUN, V34, P1105, DOI 10.1109/TCOM.1986.1096468
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Salih ND, 2011, P 5 INT C IT MULT UN
   Schaefer G, 2002, PROC SPIE, V4671, P959, DOI 10.1117/12.453018
   SHARMA N, 2011, SIGNAL IMAGE PROCESS, V2, P94, DOI DOI 10.5121/SIPIJ.2011.2108
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Teng SW, 2007, PATTERN RECOGN, V40, P3299, DOI 10.1016/j.patcog.2007.01.029
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang JZ, 1997, IEEE INTERNATIONAL FORUM ON RESEARCH AND TECHNOLOGY ADVANCES IN DIGITAL LIBRARIES - ADL'97 - PROCEEDINGS, P13, DOI 10.1109/ADL.1997.601196
   Yamazaki T, 2012, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2012.6288041
   Yang SH, 1996, ICSP '96 - 1996 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, PROCEEDINGS, VOLS I AND II, P1051, DOI 10.1109/ICSIGP.1996.566273
NR 32
TC 8
Z9 11
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1961
EP 1984
DI 10.1007/s11042-013-1492-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300041
DA 2024-07-18
ER

PT J
AU Huang, XL
   Ye, GD
AF Huang, Xiaoling
   Ye, Guodong
TI An image encryption algorithm based on hyper-chaos and DNA sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA sequence; Image encryption; Hyper-chaos; Complementary rule; Modular
   operation
ID SCHEME; MAPS
AB A novel image encryption algorithm making using of hyper-chaos and DNA sequence is presented here. A four-dimensional hyper-chaos system is used to generate the pseudo-random sequence, which is transformed into a biologic DNA sequence to diffuse the image blocks. A circular permutation is performed on the plain-image when it is in DNA status. Together with classical structure of permutation plus diffusion, the simulation results show that the proposed image encryption algorithm has a satisfactory performance. Moreover, our method can resist the known-plaintext and chosen-plaintext attacks with four parameters r (i) (i = 1,2,3,4) dependent on the plain-image. These parameters generate different key streams for different plain-image even if the initial conditions are the same.
C1 [Huang, Xiaoling; Ye, Guodong] Guangdong Ocean Univ, Coll Sci, Zhanjiang 524088, Guangdong, Peoples R China.
   [Ye, Guodong] City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
C3 Guangdong Ocean University; City University of Hong Kong
RP Ye, GD (corresponding author), Guangdong Ocean Univ, Coll Sci, Zhanjiang 524088, Guangdong, Peoples R China.
EM xyxhuang@hotmail.com; guodongye@gmail.com
RI Ye, Guodong/B-3322-2017
FU Science & Technology Program Foundation of Zhanjiang City of P.R. China
   [2011C3109002]; Natural Science Foundation of Guangdong Ocean University
   of P.R. China [1212334]
FX This work is part of the research project funded by the Science &
   Technology Program Foundation of Zhanjiang City of P.R. China (No.
   2011C3109002), and the Natural Science Foundation of Guangdong Ocean
   University of P.R. China (No. 1212334).
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Chang CC, 2001, J SYST SOFTWARE, V58, P83, DOI 10.1016/S0164-1212(01)00029-2
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Pisarchik AN, 2006, CHAOS, V16, DOI 10.1063/1.2242052
   Scharinger J, 1998, J ELECTRON IMAGING, V7, P318, DOI 10.1117/1.482647
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Zhang JX, 2012, NONLINEAR DYNAM, V67, P2455, DOI 10.1007/s11071-011-0159-3
NR 19
TC 153
Z9 164
U1 1
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 57
EP 70
DI 10.1007/s11042-012-1331-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800004
DA 2024-07-18
ER

PT J
AU Rodríguez-Serrano, FJ
   Carabias-Orti, JJ
   Vera-Candeas, P
   Canadas-Quesada, FJ
   Ruiz-Reyes, N
AF Jose Rodriguez-Serrano, Francisco
   Jose Carabias-Orti, Julio
   Vera-Candeas, Pedro
   Jesus Canadas-Quesada, Francisco
   Ruiz-Reyes, Nicolas
TI Monophonic constrained non-negative sparse coding using instrument
   models for audio separation and transcription of monophonic source-based
   polyphonic mixtures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-negative sparse coding (NNSC); Sparse representations; Non-negative
   matrix factorization (NMF); Spectral analysis; Harmonicity; Sparsity;
   Monophony; Music transcription; Source separation
ID MATRIX FACTORIZATION; DECOMPOSITION; ALGORITHMS; MUSIC
AB In this paper we propose a monophonic constrained signal decomposition model applied to polyphonic signals composed of several monophonic sources from different musical instruments. The harmonic constraint is particularly effective for tonal instruments because each note is associated with a unique basis. The monophonic constraint is implemented by enforcing single-non-zero gains per instrument in the factorization process. The proposed method uses previously trained instrument models with a supervised procedure. Both constraints (harmonic and monophonic) are implemented in a deterministic manner. The proposed method has been tested for two audio signal applications, Sound Source Separation and Automatic Music Transcription. Comparison with other state-of-the-art methods using a dataset of polyphonic mixtures composed of monophonic sources has produced competitive and promising results.
C1 [Jose Rodriguez-Serrano, Francisco; Jose Carabias-Orti, Julio; Vera-Candeas, Pedro; Jesus Canadas-Quesada, Francisco; Ruiz-Reyes, Nicolas] Univ Jaen, Telecommun Engn Dept, Jaen 23700, Spain.
C3 Universidad de Jaen
RP Rodríguez-Serrano, FJ (corresponding author), Univ Jaen, Telecommun Engn Dept, Alfonso 10 Sabio 28, Jaen 23700, Spain.
EM fjrodrig@ujaen.es
RI Rodriguez-Serrano, Francisco Jose J/H-9114-2015; Carabias Orti, Julio
   José/H-7552-2015; Vera-Candeas, Pedro/L-3428-2014; Cañadas-Quesada,
   Francisco Jesús/H-8839-2015; Ruiz Reyes, Nicolas/R-5878-2018; Rodriguez
   Serrano, Francisco Jose/C-2755-2014
OI Carabias Orti, Julio José/0000-0002-6296-1101; Vera-Candeas,
   Pedro/0000-0003-0866-703X; Cañadas-Quesada, Francisco
   Jesús/0000-0002-3873-6078; Ruiz Reyes, Nicolas/0000-0003-4631-5326;
   Rodriguez Serrano, Francisco Jose/0000-0002-4708-6898
FU Andalusian Business, Science and Innovation Council [P10- TIC-6762];
   (FEDER) the Spanish Ministry of Science and Innovation
   [TEC2009-14414-C03-02]; University of Jaen [R1/12/2010/64]
FX This work was supported by the Andalusian Business, Science and
   Innovation Council under project P10- TIC-6762, (FEDER) the Spanish
   Ministry of Science and Innovation under Project TEC2009-14414-C03-02,
   and the University of Jaen under Project R1/12/2010/64.
CR Abdallah S, 2004, P 5 INT SOC MUS INF
   Abdallah SA, 2006, IEEE T NEURAL NETWOR, V17, P179, DOI 10.1109/TNN.2005.861031
   [Anonymous], 2004, Proceedings of the 18th international congress on acoustics (ICA 2004)
   [Anonymous], THESIS TAMPERE U TEC
   Benaroya L, 2006, IEEE T AUDIO SPEECH, V14, P191, DOI 10.1109/TSA.2005.854110
   Bertin N, 2010, IEEE T AUDIO SPEECH, V18, P538, DOI 10.1109/TASL.2010.2041381
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Carabias-Orti JJ, 2011, IEEE J-STSP, V5, P1144, DOI 10.1109/JSTSP.2011.2159700
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Cho N, 2009, INT CONF ACOUST SPEE, P1557, DOI 10.1109/ICASSP.2009.4959894
   Dixon S, 2000, P AUSTR COMP MUS C
   Duan ZY, 2011, IEEE J-STSP, V5, P1205, DOI 10.1109/JSTSP.2011.2159701
   Duan ZY, 2010, IEEE T AUDIO SPEECH, V18, P2121, DOI 10.1109/TASL.2010.2042119
   Emiya V, 2011, IEEE T AUDIO SPEECH, V19, P2046, DOI 10.1109/TASL.2011.2109381
   Every MR, 2006, IEEE T AUDIO SPEECH, V14, P1845, DOI 10.1109/TSA.2005.858528
   Févotte C, 2011, NEURAL COMPUT, V23, P2421, DOI 10.1162/NECO_a_00168
   Févotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771
   Fitzgerald D., 2009, Proceedings of Signals and Systems Conference (ISSC 2009), IET Irish, P1
   Gainza M, 2007, INT CONF ACOUST SPEE, P69
   Gemmeke JF, 2011, IEEE T AUDIO SPEECH, V19, P2067, DOI 10.1109/TASL.2011.2112350
   Goto M, 2002, P 3 INT SOC MUS INF
   Gribonval R, 2003, IEEE T SIGNAL PROCES, V51, P101, DOI 10.1109/TSP.2002.806592
   Helen M, 2005, P EUSIPCO
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Lee D.D., 2000, NIPS 00, P535
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Marxer R, 2012, P LVA ICA
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Ozerov Alexey, 2009, 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), P121, DOI 10.1109/ASPAA.2009.5346527
   Ozerov A, 2012, IEEE T AUDIO SPEECH, V20, P1118, DOI 10.1109/TASL.2011.2172425
   Ozerov A, 2010, IEEE T AUDIO SPEECH, V18, P550, DOI 10.1109/TASL.2009.2031510
   Plumbley MD, 2003, IEEE T NEURAL NETWOR, V14, P534, DOI 10.1109/TNN.2003.810616
   Raczynski S.A., 2007, P INT C MUS INF RETR, P381
   Reyes-Gomez MJ, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P664
   Sawada H, 2011, IEEE T AUDIO SPEECH, V19, P516, DOI 10.1109/TASL.2010.2051355
   Smaragdis P, 1998, NEUROCOMPUTING, V22, P21, DOI 10.1016/S0925-2312(98)00047-2
   Vincent E, 2012, 10 INT C LAT VAR AN
   Vincent E, 2010, IEEE T AUDIO SPEECH, V18, P528, DOI 10.1109/TASL.2009.2034186
   Virtanen T., 2006, ADV MODELS ACOUSTIC
   Virtanen T, 2008, P INT C AC SPEECH SI
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   Wang B., 2005, P DMRN SUMM C GLASG
   Zibulevsky M, 2002, NIPS
NR 44
TC 7
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 925
EP 949
DI 10.1007/s11042-013-1398-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800042
DA 2024-07-18
ER

PT J
AU Ju, Y
   Lu, ZM
   Ling, DB
   Wen, XM
   Zheng, W
   Ma, WM
AF Ju, Ying
   Lu, Zhaoming
   Ling, Dabing
   Wen, Xiangming
   Zheng, Wei
   Ma, Wenmin
TI QoE-based cross-layer design for video applications over LTE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless video applications; Cross-layer; QoE; PSO; LTE
ID WIRELESS; TRANSMISSION; ALLOCATION; QUALITY
AB Video applications such as video-on-demand and videoconferencing over wireless networks require system resources to be allocated dynamically and optimally in accordance with the time-varying environment and video contents. User-perceived quality is tending to be a crucial factor in evaluating the success of video applications. The aim of this paper is to propose a cross-layer design scheme for optimizing resource allocation of video applications over Long Term Evolution (LTE) networks based on Quality of Experience (QoE) evaluation. We propose a novel mapping model between Peak Signal-to-Noise Ratio (PSNR) and Mean Opinion Score (MOS) based on a hyperbolic tangent function, which can reflect the relation between objective system parameters and subjective perceived quality simply and precisely. The cross-layer architecture presented in this paper jointly optimizes the Application (APP) layer, the Media Access Control (MAC) layer and the Physical (PHY) layer of the wireless protocol stack. On the basis of this architecture, we present a QoE prediction function and utilize the Particle Swarm Optimization (PSO) method to solve the resource allocation problem. Simulation results show that the proposed scheme significantly outperforms the traditional scheduling scheme in terms of maximizing user-perceived quality as well as maintaining fairness among users.
C1 [Ju, Ying; Lu, Zhaoming; Ling, Dabing; Wen, Xiangming; Zheng, Wei; Ma, Wenmin] Beijing Univ Posts & Telecommun, Lab Network Syst Architecture & Convergence, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Ju, Y (corresponding author), Beijing Univ Posts & Telecommun, Lab Network Syst Architecture & Convergence, Beijing 100876, Peoples R China.
EM xiaopang531@gmail.com; lzy_0372@163.com
FU National Natural Science Foundation of China [61271179]; Important
   National Science & Technology Specific Projects [2010ZX03003-001-01]
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 61271179, Co-building Project of Beijing Municipal
   Education Commission "Cooperative Communications Platform for
   Multi-agent Multimedia Communications", and Sci-tech Projects sponsored
   by Important National Science & Technology Specific Projects under Grant
   No. 2010ZX03003-001-01.
CR [Anonymous], J ADV MULTIMEDIA AM
   [Anonymous], EL P 2011 IEEE INT C
   [Anonymous], IEEE WORKSH MULT SIG
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 1984, ACM Transaction on Computer Systems
   [Anonymous], 2003, FIN REP VAL OBJ MOD
   [Anonymous], BT500 ITU R
   [Anonymous], P IEEE INT C COMM IC
   [Anonymous], P IEEE ICIP GEN IT S
   [Anonymous], JCM
   [Anonymous], 18 ITC SPEC SEM QUAL
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], P IEEE INFOCOM INFCO
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Jurca D, 2007, IEEE T MULTIMEDIA, V9, P1227, DOI 10.1109/TMM.2007.902852
   Karachontzitis S, 2011, IEEE INT CON MULTI
   Khan A, 2010, IET COMMUN, V4, P1337, DOI 10.1049/iet-com.2009.0422
   Khan Asiya, 2009, Journal of Multimedia, V4, P228, DOI 10.4304/jmm.4.4.228-239
   Khan S, 2006, IEEE COMMUN MAG, V44, P122, DOI 10.1109/MCOM.2006.1580942
   Liu QW, 2006, IEEE T VEH TECHNOL, V55, P839, DOI 10.1109/TVT.2006.873832
   Lu ZM, 2011, J NETW COMPUT APPL, V34, P1861, DOI 10.1016/j.jnca.2010.12.019
   Luo HY, 2010, IEEE COMMUN MAG, V48, P102, DOI 10.1109/MCOM.2010.5402671
   Mehmood MA, 2011, IEEE ICC
   Özcelebi T, 2007, IEEE J SEL AREA COMM, V25, P760, DOI 10.1109/JSAC.2007.070512
   Pahalawatta PV, 2007, WIREL COMMUN MOB COM, V7, P131, DOI 10.1002/wcm.469
   Shakkottai S, 2003, IEEE COMMUN MAG, V41, P74, DOI 10.1109/MCOM.2003.1235598
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Thakolsri S, 2011, IEEE ICC
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yuhui Shi, 1998, Evolutionary Programming VII. 7th International Conference, EP98. Proceedings, P591, DOI 10.1007/BFb0040810
NR 31
TC 18
Z9 18
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1093
EP 1113
DI 10.1007/s11042-013-1413-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300005
DA 2024-07-18
ER

PT J
AU Pigeon, S
   Coulombe, S
AF Pigeon, Steven
   Coulombe, Stephane
TI Quality-aware predictor-based adaptation of still images for the
   multimedia messaging service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMS; Image adaptation; JPEG; Optimization; Predictor; Dynamic
   programming; SSIM
ID PRODUCTS
AB The Multimedia Messaging Service (MMS) allows users with heterogeneous terminals to exchange structured messages composed of text, images, sound, and video. The MMS market is growing rapidly, posing the problem of MMS adaptation, which is necessary to ensure terminal interoperability. Message adaptation involves technological challenges, especially considering the high volume of messages that this service can handle. In this work, we propose novel predictor-based dynamic programming approaches to MMS adaptation, which provide a framework for explicit maximization of the user experience, rather than relying on heuristics to deliver adapted messages satisfactorily. We show that the proposed solutions lead to noticeably superior image quality and faster transcoding times than comparable algorithms offered in products currently on the market and those described in the literature.
C1 [Pigeon, Steven] Univ Quebec, Dept Informat, Rimouski, PQ G5L 3A1, Canada.
   [Coulombe, Stephane] Ecole Technol Super, Dept Software & IT Engn, Montreal, PQ, Canada.
C3 University of Quebec; University of Quebec; Ecole de Technologie
   Superieure - Canada
RP Coulombe, S (corresponding author), Ecole Technol Super, Dept Software & IT Engn, Montreal, PQ, Canada.
EM steven_pigeon@uqar.ca; stephane.coulombe@etsmtl.ca
RI Coulombe, Stephane/G-3528-2019
OI Coulombe, Stephane/0000-0003-4495-3906
FU Vantrix Corporation; Natural Sciences and Engineering Research Council
   of Canada under the Collaborative Research and Development Program
   [NSERC-CRD 428942-11]
FX This work was funded by Vantrix Corporation and by the Natural Sciences
   and Engineering Research Council of Canada under the Collaborative
   Research and Development Program (NSERC-CRD 428942-11).
CR *3GPP, 2009, 23140V6160 3GPP TS
   ACHARYA T, 2004, JPEG 2000 STANDARD I
   [Anonymous], 1963, DYNAMIC PROGRAMMING
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 1959, MEASUREMENT POWER SP
   [Anonymous], 2006, SYNTHESIS LECT IMAGE
   Chen RCS, 2010, EXPERT SYST APPL, V37, P5706, DOI 10.1016/j.eswa.2010.02.039
   Coulombe S, 2004, IEEE COMMUN MAG, V42, P120, DOI 10.1109/MCOM.2004.1316543
   COULOMBE S, 2009, P IEEE 2009 COMP INT
   Coulombe S, 2010, IEEE T IMAGE PROCESS, V19, P712, DOI 10.1109/TIP.2009.2036716
   Dieckmann A, 2009, JUDGM DECIS MAK, V4, P200
   Dugad R, 2001, IEEE T CIRC SYST VID, V11, P461, DOI 10.1109/76.915353
   DWYER J, 2011, WIRELESS WEEK
   Han R, 1998, IEEE PERS COMMUN, V5, P8, DOI 10.1109/98.736473
   Hillier FrederickS., 2009, Introduction to Operations Research, V9th
   Ishihara T., 2002, Transactions of the Japan Society for Industrial and Applied Mathematics, V12, P197
   LEE L, 2009, COMPARISON COMPENSAT
   LOUAFI H, 2012, EEE T MOBILE COMPUT, V99, P1, DOI DOI 10.1109/TMC.2012.173
   Louafi H, 2013, INT CON ADV INFO NET, P724, DOI 10.1109/AINA.2013.12
   *MOBITHINKING, 2012, GLOB MOB STAT 2012 C
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   Mukherjee J, 2002, IEEE T CIRC SYST VID, V12, P620, DOI 10.1109/TCSVT.2002.800509
   *NOK, 2003, CREAT MMS SERV
   *OP MOB ALL, 2011, OMATSMMSCONFV1320110
   *OP MOB ALL, 2011, OMAADMMSV1320110913A
   *OP MOB ALL, 2011, OMATSMMSCTRV13201109
   *OP MOB ALL, 2007, OMATSSTIV1020070515A
   Pannu Parveen., 2010, ICT4D: information communication technology for development
   Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Pigeon S., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P137, DOI 10.1109/ISM.2011.30
   Pigeon S., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P496, DOI 10.1109/IDAACS.2011.6072803
   PIGEON S, 2008, P 24 QUEENS U BIENN
   *PORT RES, 2012, MOB MESS FUT 2012 20
   REZAZADEH S, 2012, INT J COMPUT ELECTR, V4, P390
   Rezazadeh S, 2010, INT CONF ACOUST SPEE, P2438, DOI 10.1109/ICASSP.2010.5496298
   Ridge J, 2003, SIGNAL PROCESS-IMAGE, V18, P621, DOI 10.1016/S0923-5965(03)00056-0
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   SHEIKH HR, 2013, IMAGE VIDEO QUALITY
   SPRINGER MD, 1970, SIAM J APPL MATH, V18, P721, DOI 10.1137/0118065
   SPRINGER MD, 1966, SIAM J APPL MATH, V14, P511, DOI 10.1137/0114046
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WANG Z, 2005, STRUCTURAL APPROACHE
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Yan WQ, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198307
   2013, IMAGEMAGICK, V10, P2013
   2013, THEINDEPENDENT J, V10, P2013
   2012, CLARKDICKSON P, V10, P2013
NR 48
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1841
EP 1865
DI 10.1007/s11042-013-1481-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300036
DA 2024-07-18
ER

PT J
AU Singh, J
   Garg, P
   De, A
AF Singh, Jyotsna
   Garg, Parul
   De, Aloknath
TI Multiplicative watermarking of audio in DFT magnitude
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio; Correlation detector; Discrete fourier transform; Log-likelihood
   detection; Watermarking
ID SPREAD-SPECTRUM WATERMARKING
AB In this paper, watermark is multiplicatively embedded in discrete fourier transform magnitude of audio signal using spread spectrum based technique. A new perceptual model for magnitude of discrete fourier transform coefficients is developed which finds the regions of highest watermark embedding capacity with least perceptual distortion. Theoretical evaluation of detector performance using correlation detector and likelihood ratio detector is undertaken under the assumption that host feature follows Weibull distribution. Also, experimental results are presented in order to show the performance of the proposed scheme under various attacks such as presence of multiple watermarks, additive white gaussian noise and audio compression.
C1 [Singh, Jyotsna; Garg, Parul] Netaji Subhas Inst Technol, Div Elect & Commun Engn, New Delhi 110075, India.
   [De, Aloknath] Samsung India Software Operat, Bangalore 560093, Karnataka, India.
C3 Netaji Subhas University of Technology; Samsung
RP Singh, J (corresponding author), Netaji Subhas Inst Technol, Div Elect & Commun Engn, Sect 3, New Delhi 110075, India.
EM jsingh.nsit@gmail.com; parul_saini@yahoo.co.in; aloknath.de@samsung.com
CR Barni M, 2001, IEEE T IMAGE PROCESS, V10, P755, DOI 10.1109/83.918568
   Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cvejic N, 2004, SIGNAL PROCESS, V84, P207, DOI 10.1016/j.sigpro.2003.10.016
   Cvejic N, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P227, DOI 10.1109/ASPAA.2001.969584
   Fallahpour M, 2009, IEICE ELECTRON EXPR, V6, P1057, DOI 10.1587/elex.6.1057
   Fujimoto R, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P11
   GARCIA RA, 1999, 107 CONV AUD ENG SOC
   ITU-R, 1993, TECHNICAL REPORT
   Garcia-Hernandez JJ, 2008, IEICE ELECTRON EXPR, V5, P217, DOI 10.1587/elex.5.217
   Kim HW, 2010, SIGNAL PROCESS, V90, P2605, DOI 10.1016/j.sigpro.2010.02.007
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Lee SK, 2000, IEEE T CONSUM ELECTR, V46, P744, DOI 10.1109/30.883441
   Malik H, 2008, IET INFORM SECUR, V2, P129, DOI 10.1049/iet-ifs:20070145
   Megías D, 2005, LECT NOTES COMPUT SC, V3783, P427
   Megías D, 2010, SIGNAL PROCESS, V90, P3078, DOI 10.1016/j.sigpro.2010.05.012
   Neubauer C, 1998, P 105 AUD ENG SOC CO
   Painter T, 1997, DSP 97: 1997 13TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P179, DOI 10.1109/ICDSP.1997.628010
   SCHROEDER MR, 1979, J ACOUST SOC AM, V66, P1647, DOI 10.1121/1.383662
   Steinebach M, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P49, DOI 10.1109/ITCC.2001.918764
   STONE GC, 1977, IEEE T ELECTR INSUL, V12, P253, DOI 10.1109/TEI.1977.297976
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Van Trees H.L., 2013, Detection Estimation and Modulation Theory, Part I: Detection, Estimation, V2nd ed.
   WEIBULL W, 1951, J APPL MECH-T ASME, V18, P293
NR 27
TC 6
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1431
EP 1453
DI 10.1007/s11042-012-1282-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000021
DA 2024-07-18
ER

PT J
AU Durao, F
   Bayyapu, K
   Xu, GD
   Dolog, P
   Lage, R
AF Durao, Frederico
   Bayyapu, Karunakar
   Xu, Guandong
   Dolog, Peter
   Lage, Ricardo
TI Expanding user's query with tag-neighbors for effective medical
   information retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical information retrieval; Query expansion; Tagging; Health
   information system
ID SYSTEMS; EXPANSION; WEB
AB Medical information is a natural human demand. Existing search engines on the Web often are unable to handle medical search well because they do not consider its special requirements. Often a medical information searcher is uncertain about his exact questions and unfamiliar with medical terminology. Under-specified queries often lead to undesirable search results that do not contain the information needed. To overcome the limitations of under-specified queries, we utilize tags to enhance information retrieval capabilities by expanding users' original queries with context-relevant information. We compute a set of significant tag neighbor candidates based on the neighbor frequency and weight, and utilize the qualified tag neighbors to expand an entry query. The proposed approach is evaluated by using MedWorm medical article collection and results show considerable precision improvements over state-of-the-art approaches.
C1 [Durao, Frederico; Dolog, Peter; Lage, Ricardo] Aalborg Univ, Dept Comp Sci, IWIS Intelligent Web & Informat Syst, Aalborg, Denmark.
   [Bayyapu, Karunakar] Tech Univ Denmark, Dept Syst Biol, CBS Ctr Biol Sequence Anal, DK-2800 Kongens Lyngby, Denmark.
   [Xu, Guandong] Victoria Univ, Ctr Appl Informat, Melbourne, Vic 8001, Australia.
C3 Aalborg University; Technical University of Denmark; Victoria University
RP Durao, F (corresponding author), Aalborg Univ, Dept Comp Sci, IWIS Intelligent Web & Informat Syst, Room 2-2-05 Selma Lagerlofs Vej 300, Aalborg, Denmark.
EM freddurao@gmail.com; karun@cbs.dtu.dk; guandong.xu@vu.edu.au;
   dolog@cs.aau.dk; ricardol@cs.aau.dk
RI Durao, Frederico/O-4898-2015; Xu, Guandong/ABE-6430-2020; Xu,
   Guandong/HSH-3463-2023; Dolog, Peter/C-7732-2014
OI Xu, Guandong/0000-0003-4493-6663; Dolog, Peter/0000-0003-1842-9131
FU FP7 ICT project M-Eco: Medical Ecosystem Personalized Event-Based
   Surveillance [247829]
FX This work has been partially supported by FP7 ICT project M-Eco: Medical
   Ecosystem Personalized Event-Based Surveillance under grant number
   247829. This journal is a extended version of previously published paper
   at the International Conference on Information Science and Applications
   (ICISA 2011).
CR Anderson T.W, 1984, An Introduction to Multivariate Statistical Analysis
   Andreou A., 2005, THESIS
   [Anonymous], 2008, Proceedings of the 17th ACM Conference on Information and Knowledge Management (CIKM '08)
   [Anonymous], 2007, Tagging: People-powered Metadata for the Social Web
   [Anonymous], 2010, SAC 2010
   [Anonymous], 2008, P 17 ACM C INFORM KN, DOI DOI 10.1145/1458082.1458104
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bianco CE, 2009, J MED LIBR ASSOC, V97, P136, DOI 10.3163/1536-5050.97.2.012
   Carpineto C, 2001, ACM T INFORM SYST, V19, P1, DOI 10.1145/366836.366860
   Clarke SJ, 1997, ASLIB PROC, V49, P184, DOI 10.1108/eb051463
   Díaz-Galiano MC, 2009, COMPUT BIOL MED, V39, P396, DOI 10.1016/j.compbiomed.2009.01.012
   Dozier C., 2007, P 11 INT C ARTIFICIA, P253
   Durao F, 2011, INF SCI APP ICISA, V0, P1
   Efthimiadis E. N., 1993, SIGIR Forum, P146
   Fu WT, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1806923.1806926
   Gordon-Murnane L., 2006, Searcher, V14, P26
   Gruber T, 2008, J WEB SEMANT, V6, P4, DOI 10.1016/j.websem.2007.11.011
   Hatcher E., 2004, Lucene in Action (in Action Series
   Hersh WR, 1998, JAMA-J AM MED ASSOC, V280, P1347, DOI 10.1001/jama.280.15.1347
   Jain H, 2010, ENHANCING ELECT MED, P1
   Jang H, 2006, ENG MED BIOL SOC 200
   Jansen B. J., 1998, SIGIR Forum, V32, P5, DOI 10.1145/281250.281253
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jin S, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING ( GRC 2009), P300, DOI 10.1109/GRC.2009.5255110
   Johnson SB, 1999, J AM MED INFORM ASSN, V6, P205, DOI 10.1136/jamia.1999.0060205
   Kelly D, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P45
   Le DiemThi Hoang., 2007, RIVF'07, P242
   Liu Zhenyu., 2005, SAC '05: Proceedings of the 2005 ACM symposium on Applied computing, P1076
   Lu ZY, 2009, INFORM RETRIEVAL, V12, P69, DOI 10.1007/s10791-008-9074-8
   Ma H., 2008, CIKM '08, P709, DOI [10.1145/1458082.1458177, DOI 10.1145/1458082.1458177]
   Matos S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-212
   Milicevic AK, 2010, ARTIF INTELL REV, V33, P187, DOI 10.1007/s10462-009-9153-2
   Ravid G, 2007, J INF SCI, V33, P567, DOI 10.1177/0165551506076326
   Ruch P, 1999, J AM MED INFORM ASSN, V6, P205
   Strohmaier M., 2008, P 2008 ACM WORKSH SE, P35
   West J., 2007, Library Media Connection, V25, P58
   Yuan M. J., 2009, SEAM FRAMEWORK EXPER
NR 37
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 905
EP 929
DI 10.1007/s11042-012-1316-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400032
DA 2024-07-18
ER

PT J
AU Dardas, NH
   Silva, JM
   El Saddik, A
AF Dardas, Nasser H.
   Silva, Juan M.
   El Saddik, Abdulmotaleb
TI Target-shooting exergame with a hand gesture control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Posture recognition; Gesture recognition; Scale Invariant Feature
   Transform (SIFT); K-means; Bag-of-features; Support Vector Machine
   (SVM); Human-computer interaction
ID VISUAL RECOGNITION; FEATURES
AB Exertion games (exergames) pose interesting challenges in terms of user interaction techniques. Players are commonly unable to use traditional input devices such as mouse and keyboard, given the body movement requirements of this type of videogames. In this work we propose a hand gesture interface to direct actions in a target-shooting exertion game that is played while exercising on an ergo-bike. A vision-based hand gesture interface for interacting with objects in a 3D videogame is designed and implemented. The system is capable to issue game commands to any computer game that normally responds to mouse and keyboard without modifying the underlying source code of the game. The vision system combines Bag-of-features and Support Vector Machine (SVM) to achieve user-independent and real-time hand gesture recognition. In particular, a Finite State Machine (FSM) is used to build the grammar that generates gesture commands for the game. We carried out a user study to gather feedback from participants, and our preliminary results show the high level of interest from users use this multimedia system that implements a natural way of interaction. Albeit some concerns in terms of comfort, users had a positive experience using our exertion game and they expressed their positive intention to use a system like this in their daily lives.
C1 [Dardas, Nasser H.] Univ Ottawa, Ottawa, ON, Canada.
   [Silva, Juan M.] Univ Ottawa, Sch Elect Engn & Comp Sci, Comp Sci Multimedia Commun Res Lab MCRLab, Ottawa, ON, Canada.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
C3 University of Ottawa; University of Ottawa; University of Ottawa
RP Dardas, NH (corresponding author), Univ Ottawa, Ottawa, ON, Canada.
EM ndard076@uottawa.ca
RI Dardas, Nasser/H-1114-2014; /D-4159-2009
OI /0000-0002-7690-8547
CR [Anonymous], 2007, CIVR '07
   Baklouti M, 2008, LECT NOTES COMPUT SC, V5120, P123, DOI 10.1007/978-3-540-69916-3_15
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   Chen Q, 2008, IEEE T INSTRUM MEAS, V57, P1562, DOI 10.1109/TIM.2008.922070
   Chen S, 2011, MULTIMEDIA TOOLS APP
   Dardas N, 2010, HAVE 2010 9 IEEE INT
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Dardas Nasser H, 2011, The Research Bulletin of Jordan ACM, V2, P86
   Davis F.D., 1986, TECHNOLOGY ACCEPTANC
   Dumas J., 1998, Usability Testing Methods: Subjective Measures: Part II - Measuring Attitudes and Opinions, P4
   Fang GL, 2007, IEEE T SYST MAN CY A, V37, P1, DOI 10.1109/TSMCA.2006.886347
   Goshorn R., 2008, P 2 WORKSH BEH MON I
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hurst W, 2012, MULTIMEDIA TOOLS APP
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P351
   Kostomaj M, 2011, MULTIMED TOOLS APPL, V54, P499, DOI 10.1007/s11042-010-0549-4
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li K., 2011, P 2011 ACM S ROLE DE, P11
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nallaperumal K, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P436, DOI 10.1109/ICCIMA.2007.208
   Nickel K, 2007, IMAGE VISION COMPUT, V25, P1875, DOI 10.1016/j.imavis.2005.12.020
   Ntalianis KS, 2010, MULTIMED TOOLS APPL, V50, P199, DOI 10.1007/s11042-009-0369-6
   Pan ZG, 2010, P IEEE VIRT REAL ANN, P219, DOI 10.1109/VR.2010.5444787
   Silva J, 2011, ADAPTIVE GAME BASED
   Song Y, 2012, MULTIMED TOOLS APPL, V58, P663, DOI 10.1007/s11042-011-0748-7
   Sparacino F, 2008, MULTIMEDIA TOOLS APP
   Takahashi M, 2011, MULTIMEDIA TOOLS APP
   Varona J, 2009, INTERACT COMPUT, V21, P3, DOI 10.1016/j.intcom.2008.10.001
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Weng CB, 2010, LECT NOTES COMPUT SC, V6249, P497, DOI 10.1007/978-3-642-14533-9_51
   Wu Y, 1999, IEEE INT C IM PROC K
   Zarit B, 1999, ICCV 99 INT WORKSH R
NR 33
TC 3
Z9 6
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2211
EP 2233
DI 10.1007/s11042-012-1236-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500037
DA 2024-07-18
ER

PT J
AU Li, HJ
   Zhang, JS
   Wang, LH
AF Li, Hengjian
   Zhang, Jiashu
   Wang, Lianhai
TI Robust palmprint identification based on directional representations and
   compressed sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Palmprint recognition; Directional representation; Compressed sensing;
   Image processing
ID SPARSE REPRESENTATION; RECOGNITION
AB In this paper, we propose a novel approach for palmprint recognition, which contains two interesting components: directional representation and compressed sensing. Gabor wavelets can be well represented for biometric image for their similar characteristics to human visual system. However, these Gabor-based algorithms are not robust for image recognition under non-uniform illumination and suffer from the heavy computational burden. To improve the recognition performance under the low quality conditions with a fast operation speed, we propose novel palmprint recognition approach using directional representations. Firstly, the directional representation for palmprint appearance is obtained by the anisotropy filter, which is robust to drastic illumination changes and preserves important discriminative information. Then, the principal component analysis (PCA) is used for feature extraction to reduce the dimensions of the palmprint images. At last, based on a sparse representation on PCA feature, the compressed sensing is used to distinguish palms from different hands. Experimental results on the PolyU palmprint database show the proposed algorithm have better performance than that of the Gabor based methods.
C1 [Li, Hengjian; Wang, Lianhai] Shandong Comp Sci Ctr, Shandong Prov Key Lab Comp Network, Jinan 250014, Peoples R China.
   [Zhang, Jiashu] Southwest Jiaotong Univ, Sichuan Prov Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
C3 Qilu University of Technology; Southwest Jiaotong University
RP Li, HJ (corresponding author), Shandong Comp Sci Ctr, Shandong Prov Key Lab Comp Network, Jinan 250014, Peoples R China.
EM hengjianli@gmail.com
FU National Natural Science Foundation of China [51175443, 61070163];
   Shandong Province Outstanding Research Award Fund for Young Scientists
   of China [BS2011DX034]; Shandong Natural Science Foundation
   [ZR2011FQ030, ZR2011FM023]
FX This work is supported by grants by National Natural Science Foundation
   of China (Grant No. 51175443 and 61070163), by the Shandong Province
   Outstanding Research Award Fund for Young Scientists of China (Grant No.
   BS2011DX034) and the Shandong Natural Science Foundation (Grant No.
   ZR2011FQ030 and ZR2011FM023).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Ekinci M, 2007, ELECTRON LETT, V43, P1077, DOI 10.1049/el:20071688
   Ekinci M, 2007, LECT NOTES ARTIF INT, V4571, P628
   Eleyan A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/185281
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hu QH, 2008, EXPERT SYST APPL, V34, P866, DOI 10.1016/j.eswa.2006.10.043
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li H, 2012, IEEE MIC2012 INT C M, P63
   Li HJ, 2012, PROCEDIA ENGINEER, V29, P1239, DOI 10.1016/j.proeng.2012.01.120
   Li HJ, 2010, INFORM SCIENCES, V180, P3876, DOI 10.1016/j.ins.2010.06.040
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Pan X, 2008, NEUROCOMPUTING, V71, P3032, DOI 10.1016/j.neucom.2007.12.030
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   van den Berg E, 2008, SIAM J SCI COMPUT, V31, P890, DOI 10.1137/080714488
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Yue F, 2009, PATTERN RECOGN, V42, P2841, DOI 10.1016/j.patcog.2009.03.015
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
NR 26
TC 15
Z9 15
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2331
EP 2345
DI 10.1007/s11042-012-1240-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500043
DA 2024-07-18
ER

PT J
AU Rao, YB
   Hou, L
   Wang, ZH
   Chen, LT
AF Rao, Yunbo
   Hou, Lei
   Wang, Zhihui
   Chen, Leiting
TI Illumination-based nighttime video contrast enhancement using genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Video enhancement; Genetic algorithm;
   Illumination; HSI
ID LEVEL GROUPING GLG; IMAGE-ENHANCEMENT; AUTOMATIC METHOD
AB Contrast enhancement is crucial to the domain of security and surveillance where limitations in dynamic range and lack of lighting sources prevent fine details of the scene from being captured. Here, we propose a method of nighttime video contrast enhancement based on genetic algorithms. Conversion from RGB to HSI and illumination component extraction were done firstly. Illumination-based enhancement which combines chromosome, corresponding operators and genetic algorithm was then applied to enhance the contrast and details of the video according to an objective fitness criterion. Image reconstruction followed previous procedures finally. Comparison of our proposed method with other automatic enhancement techniques such as histogram equalization shows that our method produces natural looking images/videos, especially when the dynamic range of the input image is high. Results obtained, both in terms of subjective and objective evaluation, show the superiority of the proposed method.
C1 [Rao, Yunbo; Chen, Leiting] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
   [Hou, Lei] Xuzhou Inst Technol, Dept Informat & Elect Engn, Xuzhou, Jiangsu, Peoples R China.
   [Wang, Zhihui] Dalian Univ Technol, Dalian, Liaoning, Peoples R China.
C3 University of Electronic Science & Technology of China; Xuzhou
   University of Technology; Dalian University of Technology
RP Rao, YB (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
EM uestc2008@126.com; houlei806@126.com
RI wang, zhihui/HSF-6639-2023
FU Xuzhou Institute of Technology [XKY2011218]; Fundamental Research Funds
   for the Central Universities [1600-852013]; National High-Tech Program
   863 of China [2007AA010407, 2009GZ0017]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments. This work is partly supported by Xuzhou Institute of
   Technology program in 2011 (Grant no. XKY2011218), Fundamental Research
   Funds for the Central Universities (Grant no. 1600-852013), and National
   High-Tech Program 863 of China (Grant nos. 2007AA010407 and 2009GZ0017).
CR Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Bennett EP, 2005, ACM T GRAPHIC, V24, P845, DOI 10.1145/1073204.1073272
   Caselles V, 1999, IEEE T IMAGE PROCESS, V8, P220, DOI 10.1109/83.743856
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen ZY, 2006, IEEE T IMAGE PROCESS, V15, P2290, DOI 10.1109/TIP.2006.875204
   Chen ZY, 2006, IEEE T IMAGE PROCESS, V15, P2303, DOI 10.1109/TIP.2006.875201
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Holland J.H., 1975, Adaptation in Natural and Artificial Systems, V1st, P211
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1057, DOI 10.1109/TCSVT.2010.2057013
   Matsui K., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P625, DOI 10.1109/ICSMC.1999.814164
   Mittal G, 2006, P IEEE INT C VID SIG, P61
   Munteanu C, 2000, IEEE C EVOL COMPUTAT, P1535, DOI 10.1109/CEC.2000.870836
   Mustafi A, 2009, STUD COMPUT INTELL, V208, P1
   Paulinas M, 2007, INF TECHNOL CONTROL, V36, P278
   Ramponi G, 1996, J ELECTRON IMAGING, V5, P353, DOI 10.1117/12.242618
   Rao YB, 2011, VIS COMM IM PROC VCI
   Rao YB, 2011, OPT ENG, V50, DOI 10.1117/1.3579451
   Rao YB, 2010, OPT ENG, V49, DOI 10.1117/1.3520553
   Saitoh F., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P899, DOI 10.1109/ICSMC.1999.812529
   Schwefel HP, 1995, LECT NOTES ARTIF INT, V929, P893
   Wang C, 2007, EURASIP J ADV SIG PR, V2008, P1
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Yalcinoz T., 2005, Eng Int Syst, V3, P173
NR 25
TC 11
Z9 12
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2235
EP 2254
DI 10.1007/s11042-012-1226-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500038
DA 2024-07-18
ER

PT J
AU Shirehjini, AAN
   Yassine, A
   Shirmohammadi, S
AF Shirehjini, Ali Asghar Nazari
   Yassine, Abdulsalam
   Shirmohammadi, Shervin
TI Design and implementation of a system for body posture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient intelligence; Aware chair; Body posture recognition; Context
   recognition; Human-environment interaction
AB Under Ambient Intelligence auspice, many researchers have studied the area of context recognition such as location, users' identity and activities, and other parameters related to users' situation in the environment. One aspect of context that is pertained to the users' situation is body posture of a sitting person. The aim of this paper is the design and development of a novel Aware Chair system that recognizes sitting body postures. The Aware Chair is based on digital sensors mounted on the sitting and back area of the chair. The chair is tested using 50 people with different gender, body mass, and height. The design details of the system as well as test results are presented in this paper.
C1 [Shirehjini, Ali Asghar Nazari] KIT, Karlsruhe, Germany.
   [Yassine, Abdulsalam; Shirmohammadi, Shervin] Univ Ottawa, Distributed & Collaborat Virtual Environm Res Lab, SITE, Ottawa, ON, Canada.
C3 Helmholtz Association; Karlsruhe Institute of Technology; University of
   Ottawa
RP Shirehjini, AAN (corresponding author), KIT, Karlsruhe, Germany.
EM ali.nazari@kit.edu; ayassine@discover.uottawa.ca;
   shervin@discover.uottawa.ca
RI Abdulsalam, Yassine/ABA-9425-2020; Shirmohammadi, Shervin/E-6945-2012;
   Nazari Shirehjini, Ali Asghar/I-9374-2017
OI Shirmohammadi, Shervin/0000-0002-3973-4445; Nazari Shirehjini, Ali
   Asghar/0000-0001-6674-0739; Yassine, Abdulsalam/0000-0003-3539-0945
CR Addlesee MD, 1997, IEEE PERS COMMUN, V4, P35, DOI 10.1109/98.626980
   Aggarwal JK, 2011, J ACM COMPUT SURV CS, V43
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Coutinho JGF, 2007, J VLSI SIG PROC SYST, V47, P33, DOI 10.1007/s11265-006-0016-7
   Erich G, 1994, PROFESSIONAL COMPUTI
   ISTAG, 2010, SCEN AMB INT 2010
   Kapoor A, 2001, P EM INT 2 TANGL SOC
   Shirehjini AAN, 2004, COMPUT GRAPH-UK, V28, P667, DOI 10.1016/j.cag.2004.06.006
   SHIREHJINI AAN, 2005, P 2005 JOINT C SMART, P207, DOI DOI 10.1145/1107548.1107621
   Shirehjini AAN, 2009, P IEEE WORKSH ROB SE
   Shirehjini AAN, 2012, IEEE T INSTRUM MEAS, V61, P1664, DOI 10.1109/TIM.2011.2181912
   STRANG T., 2004, WORKSHOP ADV CONTEXT
   Tan HZ, 2001, IEEE-ASME T MECH, V6, P261, DOI 10.1109/3516.951364
   Vishal N, 2005, LNCS, V3804, P313
NR 14
TC 10
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1637
EP 1650
DI 10.1007/s11042-012-1137-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500012
DA 2024-07-18
ER

PT J
AU Nur, G
   Arachchi, HK
   Dogan, S
   Kondoz, AM
AF Nur, G.
   Arachchi, H. Kodikara
   Dogan, S.
   Kondoz, A. M.
TI Seamless video access for mobile devices by content-aware utility-based
   adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptation decision taking; Content-awareness; Utility Function (UF);
   Mean Opinion Score (MOS); Motion activity; Scalable Video Coding (SVC);
   Structural feature; Video adaptation
AB Today's Internet multimedia services are characterized by heterogeneous networks, a wide range of terminals, diverse user preferences, and varying natural environment conditions. Heterogeneity of terminals, networks, and user preferences impose nontrivial challenges to the Internet multimedia services for providing seamless multimedia access particularly for mobile devices (e. g., laptops, tablet PCs, PDAs, mobile phones, etc.). Thus, it is essential that advanced multimedia technologies are developed to deal with these challenges. One of these technologies is video adaptation, which has gained significant importance with its main objective of enabling seamless access to video contents available over the Internet. Adaptation decision taking, which can be considered as the "brain" of video adaptation, assists video adaptation to achieve this objective. Scalable Video Coding (SVC) offers flexibility for video adaptation through providing a comprehensive set of scalability parameters (i.e., temporal, spatial, and quality) for producing scalable video streams. Deciding the best combination of scalability parameters to adapt a scalable video stream while satisfying a set of constraints (e.g., device specifics, network bandwidth, etc.) poses challenges for the existing adaptation services to enable seamless video access. To ease such challenges, an adaptation decision taking technique employing a utility-based approach to decide on the most adequate scalability parameters for adaptation operations is developed. A Utility Function (UF), which models the relationships among the scalability parameters and weights specifying the relative importance of these parameters considering video content characteristics (i.e., motion activity and structural feature), is proposed to assist the developed technique. In order to perform the developed adaptation decision taking technique, a video adaptation framework is also proposed in this paper. The adaptation experiments performed using the proposed framework prove the effectiveness of the framework to provide an important step towards enabling seamless video access for mobile devices to enhance viewing experience of users.
C1 [Nur, G.] Kirikkale Univ, Elect & Elect Engn Dept, Kirikkale, Turkey.
   [Arachchi, H. Kodikara; Dogan, S.; Kondoz, A. M.] Univ Surrey, Ctr Vis Speech & Signal Proc, I Lab Multimedia Commun Res, Guildford GU2 7XH, Surrey, England.
C3 Kirikkale University; University of Surrey
RP Nur, G (corresponding author), Kirikkale Univ, Elect & Elect Engn Dept, Kirikkale, Turkey.
EM nur.gkc@gmail.com; h.kodikaraarachchi@surrey.ac.uk;
   s.dogan@surrey.ac.uk; a.kondoz@surrey.ac.uk
RI Dogan, Safak/JTZ-5976-2023
OI Dogan, Safak/0000-0002-1465-6495; NUR YILMAZ, Gokce/0000-0002-0015-9519
CR Akyol E., 2007, EURASIP J APPL SIG P, V2007
   [Anonymous], 2002, Methodology for the subjective assessment of the quality of television pictures
   [Anonymous], 1999, INTEL CORPORATION MI
   [Anonymous], J IMAGE VISION COMPU
   Bocheck P, 1999, P IEEE PACK VID WORK
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carvalho P, 2004, THESIS U PORTO PORTU
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   CHANG SF, 2002, TYRRH INT WORKSH DIG
   Devore J L., 1995, Probability and Statistics for Engineering and the Sciences, V4th, P474
   Eberhard M, 2007, IEEE T CSVT, V17, P50
   Fleet D, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P239
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hsiao MH, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/17179
   *ISO IEC, 2007, 2100072007 ISOIEC
   ITU-T, 2000, METH SUBJ ASS QUAL T
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Mangasarian O.L., 2004, P SIAM INT C DATA MI, P23
   Mukherjee D, 2005, IEEE T MULTIMEDIA, V7, P454, DOI 10.1109/TMM.2005.846798
   Onur OD, 2005, IEEE INT C MULT EXP
   Önür OD, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P15
   Papari G., 2006, SPIE IMAGE P ALG SYS
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Prangl M, 2007, IEEE T CIRCUITS SYST, V17
   Shechtman E, 2005, IEEE T PATTERN ANAL, V27, P531, DOI 10.1109/TPAMI.2005.85
   Sofokleous AA, 2008, MULTIMED TOOLS APPL, V40, P151, DOI 10.1007/s11042-008-0198-z
   Thang TC, 2009, SIGNAL PROCESS-IMAGE, V24, P214, DOI 10.1016/j.image.2008.12.006
   Tomasi C, 1991, DETECTION TRACKING P
   Vetro A, 2004, IEEE MULTIMEDIA, V11, P84, DOI 10.1109/MMUL.2004.1261111
   Wang Y, 2007, IEEE T MULTIMEDIA, V9, P213, DOI 10.1109/TMM.2006.886253
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolf S, 2002, NAT TEL INF ADM NTIA
   Yamazaki T, 2001, IEEE INT C MULT EXP
NR 33
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 689
EP 719
DI 10.1007/s11042-012-1120-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900006
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Liu, GY
   Zhang, YR
   Lu, KK
   Liu, LZ
AF Liu, Guanyang
   Zhang, Yuru
   Lu, Keke
   Liu, Lingzhi
TI A hybrid haptic guidance model for tank gunners in high precision and
   high speed motor skill training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haptic; High precision and high speed; Haptic-based training paradigm;
   Human motor skill training; Virtual envelope depicting
ID VIRTUAL FIXTURES
AB Haptic-based paradigms for human motor skill training which include virtual fixture, record-play method, shared control scheme and haptic disturbance have been proposed and widely used for applications like surgery, assembly, rehabilitation, motor skill and so on. However, no haptic-based training scheme applies to all types of human motor skills that new ideas and new approaches should be explored for some special training tasks. For example, tank gunners have to be rigorously trained to be able to complete the most accurate manipulation in the shortest possible time. Accuracy and operating speed are both critical for them to grasp the skill; therefore, tank gunnery is defined as a type of high precision and high speed human motor skill. In this paper, a hybrid spring-damper model which fuses haptic fixture and record-play is presented to simultaneously train accuracy and operating speed. The training approach is suitable for novices at all levels since force feedback is decomposed into two components: one for training accuracy, the other for training speed. The virtual envelope depicting is chosen as the training task for novices to validate the effectiveness of the proposed haptic-based scheme in high precision and high speed skill training. Experimental results indicate that force feedback generated based on the hybrid model can benefit novices in fast improving performances on tank gunnery.
C1 [Liu, Guanyang; Zhang, Yuru; Lu, Keke; Liu, Lingzhi] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Liu, Guanyang; Zhang, Yuru; Lu, Keke; Liu, Lingzhi] Beihang Univ, Sch Mech Engn & Automat, Inst Robot, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Liu, GY (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM gyliu@me.buaa.edu.cn
FU National Science Foundation of China [60803070]
FX This research received support of National Science Foundation of China
   under grant No. 60803070.
CR Abbott JJ, 2007, SPRINGER TRAC ADV RO, V28, P49
   Adams R.J., 2001, HAPTICS E J IEEE ROB, V2, P1
   Basdogan C, 2004, IEEE COMPUT GRAPH, V24, P56, DOI 10.1109/MCG.2004.1274062
   Basdogan C, 2001, IEEE-ASME T MECH, V6, P269, DOI 10.1109/3516.951365
   Bayart B, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P51
   Dang T, 2001, ST HEAL T, V81, P97
   Feygin D, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P40, DOI 10.1109/HAPTIC.2002.998939
   Fitts P. M., 1967, Human performance
   Gillespie R. B., 1998, Proceedings of the ASME Dynamic Systems and Control Division-1998, P171
   Grindlay G, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P397
   Gupta A, 2006, IEEE-ASME T MECH, V11, P280, DOI 10.1109/TMECH.2006.875558
   Henmi K, 1998, IEEE INT CONF ROBOT, P1275, DOI 10.1109/ROBOT.1998.677278
   Jaebong Lee, 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P335, DOI 10.1109/HAPTIC.2010.5444635
   Keke Lu, 2010, 2010 IEEE International Conference on Mechatronics and Automation (ICMA), P1449, DOI 10.1109/ICMA.2010.5588998
   LEIFER L, 1981, ROBOTIC AGE, V3, P4
   Li YF, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P332, DOI 10.1109/WHC.2009.4810873
   Marayong P, 2004, HUM FACTORS, V46, P518
   Méndez E, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P531
   Ming L, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P125, DOI 10.1109/HAPTIC.2003.1191253
   Moore CA, 2003, IEEE T ROBOTIC AUTOM, V19, P347, DOI 10.1109/TRA.2003.808866
   O'Malley MK, 2006, J DYN SYST-T ASME, V128, P75, DOI 10.1115/1.2168160
   Prada R, 2001, P 1 JOINT EUR C S HA, P1419
   ROSENBERG LB, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P76, DOI 10.1109/VRAIS.1993.380795
   Solis J, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P175
   Srimathveeravalli G, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P452
   Wentao Yu, 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2235
   Zhou MY, 2012, ADV MATER RES-SWITZ, V346, P241, DOI 10.4028/www.scientific.net/AMR.346.241
NR 27
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 1111
EP 1130
DI 10.1007/s11042-012-1179-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300024
DA 2024-07-18
ER

PT J
AU Ries, CX
   Lienhart, R
AF Ries, Christian X.
   Lienhart, Rainer
TI A survey on visual adult image recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual adult image recognition; Content-based image filters
ID COLOR; RETRIEVAL
AB We provide an overview of state-of-the-art approaches to visual adult image recognition which is a special case of one-class image classification. We present a representative selection of methods which we coarsely divide into three main groups. First we discuss color-based approaches which rely on the intuitive assumption that adult images usually feature skin-colored regions. Different ways of defining skin colors are described and example classification frameworks built on skin color models are presented. Another main group of approaches to adult image recognition is based on shape information which usually also exploit color information to find skin-colored regions of interest. Color and texture features are often used to augment such shape features. Finally we introduce approaches based on local feature descriptors.
C1 [Ries, Christian X.; Lienhart, Rainer] Univ Augsburg, D-86159 Augsburg, Germany.
C3 University of Augsburg
RP Ries, CX (corresponding author), Univ Augsburg, Univ Str 6a, D-86159 Augsburg, Germany.
EM ries@informatik.uni-augsburg.de; lienhart@informatik.uni-augsburg.de
OI Lienhart, Rainer/0000-0003-4007-6889
FU Advanced Swiss Technology Group (ATG)
FX This work was funded by Advanced Swiss Technology Group (ATG).
CR [Anonymous], 2002, P 2002 ASIAN C COMPU
   [Anonymous], P INT COMP S
   [Anonymous], 1998, P AS C COMP VIS, DOI DOI 10.1007/3-540-63931-4
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   [Anonymous], 2003, PROC GRAPHICON
   [Anonymous], P 6 AS C COMP VIS JU
   [Anonymous], P SPIE IS T EL IM VI
   Arentz WA, 2004, COMPUT VIS IMAGE UND, V94, P295, DOI 10.1016/j.cviu.2003.10.007
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Bosson A, 2002, LECT NOTES COMPUT SC, V2383, P50
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Choi B, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P659, DOI 10.1109/ICCIT.2009.43
   Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2
   Chung-hee Ka, 2009, 2009 9th International Symposium on Communications and Information Technology. ISCIT 2009, P784, DOI 10.1109/ISCIT.2009.5341136
   Dalal N., 2005, P IEEE C COMPUTER VI
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Fleck M.M., 1996, European Conference on Computer Vision, VII, P592
   GERSHON R, 1986, J OPT SOC AM A, V3, P1700, DOI 10.1364/JOSAA.3.001700
   Gomez G., 2002, Proa, of the ICML Workshop on Machine Learning in Computer Vision, P31
   Hammami M, 2006, IEEE T KNOWL DATA EN, V18, P272, DOI 10.1109/TKDE.2006.34
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu WM, 2007, IEEE T PATTERN ANAL, V29, P1019, DOI 10.1109/TPAMI.2007.1133
   Jebara TS, 1997, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.1997.609312
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kim W, 2005, LECT NOTES COMPUT SC, V3696, P481
   Kim W, 2005, LECT NOTES COMPUT SC, V3501, P222
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Lienhart R, 2009, IEEE INT CON MULTI, P1472, DOI 10.1109/ICME.2009.5202781
   Lopes Ana P. B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1552
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   McKenna SJ, 1998, PATTERN RECOGN, V31, P1883, DOI 10.1016/S0031-3203(98)00066-1
   Ou Wu, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P648, DOI 10.1109/WIIAT.2008.48
   Qing-Fang Zheng, 2004, Proceedings. Third International Conference on Image and Graphics, P150
   Ries CX, 2010, IEEE INT CON MULTI, P1067, DOI 10.1109/ICME.2010.5583878
   Rowley HA, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P290
   Ulges A., 2011, Multimedia and Expo (ICME), 2011 IEEE International Conference on, P1
   Wang J. Z., 1997, Interactive Distributed Multimedia Systems and Telecommunication Services. 4th International Workshop, IDMS '97. Proceedings, P20, DOI 10.1007/BFb0000336
   Yang JF, 2004, INT C PATT RECOG, P479, DOI 10.1109/ICPR.2004.1333806
   Yang M.-H., 1999, Proceedings o f SPIE: Conference on Storage and Retrievalfor Image and Video Databases, P458
   Yoo SJ, 2004, LECT NOTES COMPUT SC, V3213, P164
   Zheng H., 2004, Electronic Letters on Computer Vision and Image Analysis, V4, P1
   Zheng HC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1223, DOI 10.1109/ICME.2004.1394442
NR 44
TC 26
Z9 29
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 661
EP 688
DI 10.1007/s11042-012-1132-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Poonkuntran, S
   Rajesh, RS
AF Poonkuntran, S.
   Rajesh, R. S.
TI Chaotic model based semi fragile watermarking using integer transforms
   for digital fundus image authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Fundus image; Image watermarking; Image authentication;
   Integer transform
ID INVISIBLE WATERMARKING; LOSSLESS WATERMARKING
AB This paper proposes a new reversible, imperceptible, semi fragile watermarking scheme for the authentication of digital fundus images that satisfies eight mandatory requirements. They are reversible, tamper detection, localization of modification, imperceptibility, capacity, complete blind detection, semi fragility and security. The proposed scheme generates the watermark dynamically using chaotic system and it is embedded using integer transform in reversible way. It precisely locates the tampering areas in the images and detects the watermark in complete blind approach without using the knowledge of both original image and watermark. It is found subjectively that 30,000 bits is the best size of the watermark for the proposed scheme to ensure the security and it is achieved for the PSNR value of around 60 dB at an average by retaining good level of imperceptibility. The proposed scheme is sensitive to the jittering, geometrical and filtering attacks and it modifies around 40 % of bits in the watermark for jittering and geometrical attacks, around 45 % of the bits in the watermark for filtering attacks to authenticate the images.
C1 [Poonkuntran, S.] Velammal Coll Engn & Technol, Dept Informat Technol, Madurai 625009, Tamil Nadu, India.
   [Rajesh, R. S.] Manonmaniam Sundaranar Univ, Dept Comp Sci & Engn, Tirunelveli 627012, India.
C3 Manonmaniam Sundaranar University
RP Poonkuntran, S (corresponding author), Velammal Coll Engn & Technol, Dept Informat Technol, Madurai 625009, Tamil Nadu, India.
EM s_poonkuntran@yahoo.co.in; rs_rajesh1@yahoo.co.in
RI Shanmugam, Poonkuntran/S-2401-2018; RAJESH, R S/ABE-5664-2020
OI Shanmugam, Poonkuntran/0000-0002-2778-7937; RAJESH, R
   S/0000-0001-6670-4527
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   ALLAERT FA, 1994, INT J BIOMED COMPUT, V35, P201
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chen TS, 1998, IEEE T IMAGE PROCESS, V7, P1485, DOI 10.1109/83.718488
   Coatrieux G, 2001, PROC SPIE, V4314, P229, DOI 10.1117/12.435403
   Coatrieux G, 2000, ENG MED BIOL SOC ANN, P250, DOI 10.1109/ITAB.2000.892396
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fridrich J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P404, DOI 10.1109/ICIP.1998.723401
   Fujita H, 2008, COMPUT METH PROG BIO, V92, P238, DOI 10.1016/j.cmpb.2008.04.003
   Hernandez Cynthia Palma, 2011, P 8 INT C EL ENG COM, P1, DOI [10.1109/ICEEE.2011.6106601, DOI 10.1109/ICEEE.2011.6106601]
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   MACQ B, 2000, P EUSIPCO 2000 TAMP
   Ni RR, 2008, FORENSIC SCI INT, V179, P54, DOI 10.1016/j.forsciint.2008.04.016
   Poonkuntran S., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P418, DOI 10.1109/ICCSP.2011.5739350
   Poonkuntran S., 2007, P INT C TRENDS INT E
   Roux C., 2005, P 2005 IEEE ENG MED
   Shanmugam P, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P472, DOI 10.1109/ICCCE.2008.4580649
   SHI YQ, 2004, P ISCAS 04 CIRC SYST, V2, P23
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tian J, 2002, P SOC PHOTO-OPT INS, V4675, P679, DOI 10.1117/12.465329
   Tian J., 2002, Proceedings of workshop on multimedia and security p, P19
   TIAN J, 2003, P ICASSP 03 AC SPEEC, V3, P6
   WALTON S, 1995, DR DOBBS J, V20, P18
   Wu JH, 2004, IEEE IMAGE PROC, P1573
   Wu M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P437, DOI 10.1109/ICIP.1998.723413
   Yeung MM, 1998, J ELECTRON IMAGING, V7, P578, DOI 10.1117/1.482612
   ZHICHENG N, 2003, P ISCAS 03 CIRC SYST, V2, P25
NR 33
TC 12
Z9 12
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 79
EP 93
DI 10.1007/s11042-012-1227-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600006
DA 2024-07-18
ER

PT J
AU Sung, Y
   Cho, K
AF Sung, Yunsick
   Cho, Kyungeun
TI Data generation and representation method for 3D video conferencing
   using programming by demonstration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video conferencing; Programming by demonstration; Maximin Selection
   Algorithm; Virtual human; Behavior generation
AB Video conferencing provides an environment for multiple users linked on a network to have meetings. Since a large quantity of audio and video data are transferred to multiple users in real time, research into reducing the quantity of data to be transferred has been drawing attention. Such methods extract and transfer only the features of a user from video data and then reconstruct a video conference using virtual humans. The disadvantage of such an approach is that only the positions and features of hands and heads are extracted and reconstructed, whilst the other virtual body parts do not follow the user. In order to enable a virtual human to accurately mimic the entire body of the user in a 3D virtual conference, we examined what features should be extracted to express a user more clearly and how they can be reproduced by a virtual human. This 3D video conferencing estimates the user's pose by comparing predefined images with a photographed user's image and generates a virtual human that takes the estimated pose. However, this requires predefining a diverse set of images for pose estimation and, moreover, it is difficult to define behaviors that can express poses correctly. This paper proposes a framework to automatically generate the pose-images used to estimate a user's pose and the behaviors required to present a user using a virtual human in a 3D video conference. The method for applying this framework to a 3D video conference on the basis of the automatically generated data is also described. In the experiment, the framework proposed in this paper was implemented in a mobile device. The generation process of poses and behaviors of virtual human was verified. Finally, by applying programming by demonstration, we developed a system that can automatically collect the various data necessary for a video conference directly without any prior knowledge of the video conference system.
C1 [Sung, Yunsick] Dongguk Univ, Grad Sch, Dept Game Engn, Seoul 100715, South Korea.
   [Cho, Kyungeun] Dongguk Univ, Dept Multimedia Engn, Seoul 100715, South Korea.
C3 Dongguk University; Dongguk University
RP Cho, K (corresponding author), Dongguk Univ, Dept Multimedia Engn, 26,Pil Dong 3 Ga, Seoul 100715, South Korea.
EM cke@dongguk.edu
FU Dongguk University
FX This work was supported by the research program of Dongguk University.
CR Allen Cyphereditor., 1993, Watch What I Do - Programming by Demonstration
   AZARBAYEJANI A, 1996, P IMAGE COM 96
   Calinon S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2769
   Calinon S., 2005, ICML 2005 - Proceedings of the 22nd International Conference on Machine Learning, (New York, New York, USA), P105, DOI DOI 10.1145/1102351.1102365
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Dey A.K., 2004, P SIGCHI C HUM FACT, P33, DOI DOI 10.1145/985692.985697
   Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861
   Fuchs Henry., 1994, PROC 1 INT C MEDICAL, P161
   Hartmann B, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P145
   Lei BJ, 2002, EURASIP J APPL SIG P, V2002, P1067, DOI 10.1155/S1110865702206071
   Liu X, 2011, FUTURE GENER COMP SY, P16
   Mortlock A, 1997, BT TECHNOL J, V15, P120, DOI 10.1023/A:1018687630541
   Nijholt A., 2005, P IASTED INT C ART I, P579
   Sung Yun Sick, 2011, [Journal of Korea Game Society, 한국게임학회 논문지], V11, P141
   Thurau C, 2005, GAMEON-NA 2005: 1ST INTERNATIONAL NORTH-AMERICAN CONFERENCE ON INTELLIGENT GAMES AND SIMULATION, P3
   Xu LQ, 2002, BT TECHNOL J, V20, P64, DOI 10.1023/A:1014570025802
NR 16
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 71
EP 95
DI 10.1007/s11042-011-0941-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800005
DA 2024-07-18
ER

PT J
AU Zhang, DQ
   Huang, HY
   Lai, CF
   Liang, XD
   Zou, Q
   Guo, MY
AF Zhang, Daqiang
   Huang, Hongyu
   Lai, Chin-Feng
   Liang, Xuedong
   Zou, Qin
   Guo, Minyi
TI Survey on context-awareness in ubiquitous media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ubiquitous media; Context-awareness; Survey
ID SYSTEM; MIDDLEWARE; COMPUTER; DESIGN; MODEL; TECHNOLOGIES; EXPERIENCES;
   FRAMEWORK; VISION
AB Context-awareness assists ubiquitous media applications in discovering the changeable contextual information and adapting their behaviors accordingly. A wide spectrum of context-aware schemes have been proposed over the last decade. However, most of them provide partial functionalities of context-awareness in ubiquitous media applications. They are specified to a certain task and lack of systematic research on context-awareness. To this end, this survey aims at answering how close we are to developing context-aware applications in ubiquitous media in a systematic manner. This survey proposes a reference framework to identify key functionalities of context-awareness. Then, it investigates the state-of-the-art advances in every functionality of context-awareness. Finally, it points out potential directions in context-awareness research and tools for building and measuring context-aware ubiquitous media systems.
C1 [Zhang, Daqiang] Nanjing Normal Univ, Sch Comp Sci, Nanjing, Jiangsu, Peoples R China.
   [Zhang, Daqiang] Jiangsu Res Ctr Informat Secur & Confidential Eng, Nanjing, Jiangsu, Peoples R China.
   [Huang, Hongyu] Chongqing Univ, Coll Comp Sci, Chongqing 630044, Peoples R China.
   [Lai, Chin-Feng] Natl Ilan Univ, Inst Comp Sci & Informat, Ilan, Taiwan.
   [Liang, Xuedong] Univ British Columbia, Dept Elect & Comp Engn, Data Commun Grp, Vancouver, BC V5Z 1M9, Canada.
   [Zou, Qin] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China.
   [Guo, Minyi] Shanghai Jiao Tong Univ, Dept Comp Sci, Shanghai 200030, Peoples R China.
C3 Nanjing Normal University; Chongqing University; National Ilan
   University; University of British Columbia; Wuhan University; Shanghai
   Jiao Tong University
RP Huang, HY (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 630044, Peoples R China.
EM dqzhang@ieee.org; hyhuang@cqu.edu.cn; cinfon@ieee.org;
   xuedongl@ece.ubc.ca; qzou@whu.edu.cn; guo-my@cs.sjtu.edu.cn
RI Zou, Qin/AFM-0040-2022; Lai, Chin-Feng/IAP-5353-2023; Zou,
   Qin/GVU-2237-2022
OI Zhang, Daqiang/0000-0002-3812-1225; Lai, Chin-Feng/0000-0001-7138-0272;
   Zou, Qin/0000-0001-7955-0782
FU National Natural Science Foundation of China [61103185, 61003247,
   61073118]; Start-up Foundation of Nanjing Normal University
   [2011119XGQ0072]; Natural Science Foundation of the Higher Education
   Institutions of Jiangsu Province, China [11KJB520009]; Major Program of
   National Natural Science Foundation of Jiangsu Province [BK211005]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61103185, 61003247 and 61073118), the Start-up
   Foundation of Nanjing Normal University (Grant No. 2011119XGQ0072), and
   Natural Science Foundation of the Higher Education Institutions of
   Jiangsu Province, China (Grant No. 11KJB520009). This work is also
   supported by Major Program of National Natural Science Foundation of
   Jiangsu Province (Grant No. BK211005).
CR Abowd GD, 1997, WIREL NETW, V3, P421, DOI 10.1023/A:1019194325861
   Anagnostopoulos CB, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE SERVICES, P181
   [Anonymous], INT LAB DAT
   [Anonymous], 2006, VLDB
   Asadi MK, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P362, DOI 10.1109/ICME.2005.1521435
   Baldauf M, 2007, INT J AD HOC UBIQ CO, V2, P263, DOI 10.1504/IJAHUC.2007.014070
   BARR R, 2002, OPERATING SYSTEMS RE, V36, P15
   Barton J., 2001, COOLTOWN USER EXPERI
   Bellavista P, 2003, IEEE T SOFTWARE ENG, V29, P1086, DOI 10.1109/TSE.2003.1265523
   Bettini C, 2010, PERVASIVE MOB COMPUT, V6, P161, DOI 10.1016/j.pmcj.2009.06.002
   BIKAKIS A, 2007, P WORKSH ART INT MET, P15
   Bonnet P., 2001, Mobile Data Management. Second International Conference, MDM 2001. Proceedings (Lecture Notes in Computer Science Vol.1987), P3
   Boulis A, 2003, PROCEEDINGS OF MOBISYS 2003, P187, DOI 10.1145/1066116.1066121
   Bradley N, 2003, P 1 UK UBINET WOKSH, P25
   Bradley NA, 2005, HUM-COMPUT INTERACT, V20, P403, DOI 10.1207/s15327051hci2004_2
   Brown PJ, 1997, IEEE PERS COMMUN, V4, P58, DOI 10.1109/98.626984
   Brumitt B, 2000, LECT NOTES COMPUT SC, V1927, P12
   Budzik J., 2000, IUI 2000. 2000 International Conference on Intelligent User Interfaces, P44, DOI 10.1145/325737.325776
   Capra L, 2003, IEEE T SOFTWARE ENG, V29, P929, DOI 10.1109/TSE.2003.1237173
   Castelli G, 2007, FIFTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P229, DOI 10.1109/PERCOM.2007.4
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   Chang X., 2005, Proceedings of the 10th European software engineering conference held jointly with 13th ACM SIGSOFT international symposium on Foundations of software engineering (ESEC/FSE-13). ACM, New York, NY, P336, DOI DOI 10.1145/1095430.1081759
   Chang Xu, 2006, 28th International Conference on Software Engineering Proceedings, P292
   Chen G., 2000, SURVEY CONTEXT AWARE
   Chen M, 2011, P MOBIWORLD
   Chen M, 2010, P MOBIWORKD
   Chen M, 2009, IEEE COMSOC MMTC E L
   Chen M, 2007, COMPUT COMMUN, V30, P3368, DOI 10.1016/j.comcom.2007.01.016
   Chen M, 2011, MOBILE NETW APPL, V16, P171, DOI 10.1007/s11036-010-0260-8
   Chen M, 2010, IEEE INTELL SYST, V25, P12, DOI 10.1109/MIS.2010.44
   Chen M, 2010, IEEE WIREL COMMUN, V17, P37, DOI 10.1109/MWC.2010.5416348
   Cheverst K, 1999, COMPUT GRAPH-UK, V23, P883, DOI 10.1016/S0097-8493(99)00119-3
   Davis Marc., 2004, P 12 ANN ACM INT C M, P188, DOI DOI 10.1145/1027527.1027572
   DEMPSTER AP, 1968, J ROY STAT SOC B, V30, P205
   Dertouzos ML, 1999, SCI AM, V281, P52, DOI 10.1038/scientificamerican0899-52
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   DEY AK, 1998, P AAAI 1998 SPRING S, P51
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Driver C, 2004, P WORKSH CONT AW MOB
   Ducatel K, 2001, TECHNICAL REPORT
   Elnahrawy Eiman., 2003, P ACM WSNA03, P78
   Eo SH, 2007, LECT NOTES COMPUT SC, V4761, P329
   Fahy P., 2004, 3 INT C MOBILE UBIQU, V83, P213
   Finkelstein I., 2001, P 10 INT WORLD WID W, P406
   Fleury A, 2011, LECT NOTES COMPUT SC, V6770, P404, DOI 10.1007/978-3-642-21708-1_46
   Garlan D., 2002, IEEE Pervasive Computing, V1, P22, DOI 10.1109/MPRV.2002.1012334
   Ghidini C, 2001, ARTIF INTELL, V127, P221, DOI 10.1016/S0004-3702(01)00064-9
   Grimm R, 2004, ACM T COMPUT SYST, V22, P421, DOI 10.1145/1035582.1035584
   Gu T, 2008, INT CONF PERVAS COMP, P406, DOI 10.1109/PERCOM.2008.37
   Gummadi R., 2005, Proc. 20th ACM Symp. Operating Systems Principles, P1
   Gustavsen R, 2002, P WORKSH CONC MOD UB
   Haghighi PD, 2008, LECT NOTES COMPUT SC, V5279, P112
   Henricksen K, 2005, LECT NOTES COMPUT SC, V3762, P626
   Henricksen K., 2002, Pervasive Computing. First International Conference, Pervasive 2002. Proceedings (Lecture Notes in Computer Science Vol.2414), P167
   Henricksen K, 2006, PERVASIVE MOB COMPUT, V2, P37, DOI 10.1016/j.pmcj.2005.07.003
   Hu B, 2009, WIREL COMMUN MOB COM, V999, P22
   Huang YJ, 2009, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM FOR CORPORATE GOVERNANCE, BOOKS 1 AND 2, P37
   IBM China Research Lab, 2007, INTEGR ONT DEV TOOLK
   Indulska J, 2003, LECT NOTES COMPUT SC, V2574, P247
   Jacucci Carlo., 2005, PROC 200 05, P19, DOI DOI 10.1145/1094562.1094566
   Kagal L, 2001, 21ST INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P195, DOI 10.1109/CDCS.2001.918705
   Kofod-Petersen A., 2005, Revue d'Intelligence Artificielle, V19, P479
   Korpipää P, 2003, LECT NOTES ARTIF INT, V2680, P451
   Kumar M, 2003, IEEE PERVAS COMPUT, V2, P72, DOI 10.1109/MPRV.2003.1228529
   Lai R, 2011, E LETT, V6, P6743
   Lei ZJ, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P913, DOI 10.1109/CCECE.2001.933563
   Levis P, 2002, ACM SIGPLAN NOTICES, V37, P85, DOI 10.1145/605432.605407
   Levis P., 2003, SENSYS 03, P126, DOI DOI 10.1145/958491.958506
   LEVIS P, 2004, P 6 S OP SYST DES IM, P273
   Liu T, 2003, ACM SIGPLAN NOTICES, V38, P107, DOI 10.1145/966049.781516
   Madden S, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FIFTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P131, DOI 10.1145/1060289.1060303
   Madden S, 2002, FOURTH IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P49, DOI 10.1109/MCSA.2002.1017485
   Madden SR, 2005, ACM T DATABASE SYST, V30, P122, DOI 10.1145/1061318.1061322
   Mamei M, 2007, FIFTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P87, DOI 10.1109/PERCOM.2007.19
   Manzoor A, 2009, LECT NOTES COMPUT SC, V5786, P144, DOI 10.1007/978-3-642-04559-2_13
   MCCARTHY J, 1998, CSLI LECT NOTES, V81, P13
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Moran S, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 3, P327
   Moran TP, 2001, HUM-COMPUT INTERACT, V16, P87, DOI 10.1207/S15327051HCI16234_01
   Muñoz MA, 2003, COMPUTER, V36, P38, DOI 10.1109/MC.2003.1231193
   Murphy AL, 2006, ACM T SOFTW ENG METH, V15, P279, DOI 10.1145/1151695.1151698
   Paganelli F, 2007, LECT NOTES COMPUT SC, V4397, P173
   Raento M, 2005, IEEE PERVAS COMPUT, V4, P51, DOI 10.1109/MPRV.2005.29
   Ranganathan A., 2002, IEEE Pervasive Computing, V1, P51, DOI 10.1109/MPRV.2002.1037722
   Ranganathan A, 2004, IEEE PERVAS COMPUT, V3, P62, DOI 10.1109/MPRV.2004.1316821
   Ranganathan A, 2003, PERS UBIQUIT COMPUT, V7, P353, DOI 10.1007/s00779-003-0251-x
   Rekimoto J., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P269, DOI 10.1145/365024.365115
   Roman M., 2002, IEEE Pervasive Computing, V1, P74, DOI 10.1109/MPRV.2002.1158281
   Rosemann M, 2004, LECT NOTES COMPUT SC, V3288, P110
   RYAN N, 1999, CONTEXTML EXCHANGING
   Ryan N., 1999, Bar International Series, V750, P269
   Samulowitz M, 2001, INT FED INFO PROC, V70, P23
   Satoh I, 2009, INTERNATIONAL CONFERENCE ON PERVASIVE SERVICES (ICPS 2009), P199
   Satoh I, 2006, INT J DIGIT LIBRARIE, V6, P280, DOI 10.1007/s00799-006-0006-1
   Satyanarayanan M, 2001, IEEE PERS COMMUN, V8, P10, DOI 10.1109/98.943998
   Schilit B., 1994, 1994 1 WORKSHOP MOBI, P85, DOI [DOI 10.1109/WMCSA.1994.16, 10.1109/WMCSA.1994.16]
   Schmidt A, 1999, LECT NOTES COMPUT SC, V1707, P89
   Schmidt A, 2008, P 4 INT C UB COMP, P333
   Schwinger W, 2005, 1 J KEPL U
   Selker T, 2000, IBM SYST J, V39, P880, DOI 10.1147/sj.393.0880
   Shafer G, 1976, MATH THEORY EVIDENCE, DOI DOI 10.1080/00401706.1978.10489628
   Tadj C, 2006, P 3 INT C MOB TECHN, P13
   Tang W, 2011, SENSORS-BASEL, V11, P6743, DOI 10.3390/s110706743
   Thompson G, 2009, LECT NOTES BUS INF P, V29, P1
   Truong HL, 2009, INT J WEB INF SYST, V5, P5, DOI 10.1108/17440080910947295
   Wang MM, 2008, J COMPUT SCI TECH-CH, V23, P305, DOI 10.1007/s11390-008-9135-x
   Wang XH, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P18
   Want R., 1992, ACM T INFORM SYSTEMS, V10, P102
   WEISER M, 1993, COMMUN ACM, V36, P75, DOI 10.1145/159544.159617
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Welsh M., 2004, P 1 USENIX ACM S NET, P3
   WWW Consortium, 2007, COMP CAP PREF PROF S
   WWW Consortium, 2001, US AG PROF UAPR
   Xu C, 2010, ACM T SOFTW ENG METH, V19, DOI 10.1145/1656250.1656253
   Xu C, 2008, INT CON DISTR COMP S, P713, DOI 10.1109/ICDCS.2008.46
   You Y, 2008, MOBILEHCI 08, P335
   ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575
   Zhang DQ, 2011, IEEE T PARALL DISTR, V22, P558, DOI 10.1109/TPDS.2010.118
   Zhang DQ, 2010, FUTURE GENER COMP SY, V26, P207, DOI 10.1016/j.future.2009.08.005
   Zhang Daqiang., 2011, Parallel and Distributed Processing with Applications (ISPA), 2011 IEEE 9th International Symposium on, P201
   Zhuang Y., 2007, PROCEEDING 27 INT C
   [No title captured]
NR 122
TC 43
Z9 46
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 179
EP 211
DI 10.1007/s11042-011-0940-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800010
DA 2024-07-18
ER

PT J
AU Zhu, RB
   Shu, WN
   Mao, TY
   Deng, TP
AF Zhu, Rongbo
   Shu, Wanneng
   Mao, Tengyue
   Deng, Tianping
TI Enhanced MAC protocol to support multimedia traffic in cognitive
   wireless mesh networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MAC; Scheduling scheme; Multimedia traffic; Wireless mesh networks;
   Cognitive radio
ID IEEE 802.11S; VIDEO; ALLOCATION; CHANNEL
AB With the advanced physical layer techniques such as multiple-input and multiple-output (MIMO) and orthogonal frequency-division multiplexing (OFDM), transmission real-time 2D/3D contents and applications becomes more and more necessary in wireless networks for the amazing growing in demand of customers. However, the low efficiency of medium access control (MAC) protocol degrades the performance of real-time traffic greatly in multihop, wireless and mobile environment. Focusing on supporting real-time multimedia traffic in cognitive wireless mesh networks (WMNs), an enhanced MAC protocol is proposed. And the contribution of this paper is twofold: (1) An efficient carrier sense multiple access with collision avoidance (CSMA/CA) compatible time division multiple access (TDMA)-like MAC protocol called T-MAC is proposed, which aims to improve the system performance by allocating more channel access time in centralized manner and decreasing overhead. (2) An optimal adaptive scheduling scheme is proposed to support real-time multimedia applications and guarantee QoS for different priority traffic, which aims to find the optimized schedule among all possible sequences of concurrent transmissions by minimizing the occupied resources. Detailed simulation results and comparison with IEEE 802.11e MAC scheme show that the proposed T-MAC can effectively improve quality of service (QoS) for multimedia traffic in terms of throughput, end-to-end delay and packet loss rate, which also manifests that T-MAC is an efficient multimedia applications transmission scheme for mobile terminals and MAPs in cognitive WMNs.
C1 [Zhu, Rongbo; Shu, Wanneng; Mao, Tengyue] South Cent Univ Nationalities, Coll Comp Sci, Wuhan 430074, Peoples R China.
   [Deng, Tianping] Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Wuhan 430074, Peoples R China.
C3 South Central Minzu University; Huazhong University of Science &
   Technology
RP Deng, TP (corresponding author), Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Wuhan 430074, Peoples R China.
EM rongbozhu@gmail.com; tianp.deng@gmail.com
OI Zhu, Rongbo/0000-0003-1620-0560
FU National Natural Science Foundation of China [60902053]; Science and
   Technology Research Planning of Educational Commission of Hubei Province
   of China [B20110803]; Natural Science Foundation of Hubei Province of
   China [2008CDB339]; Education Research Foundation of South-Central
   University of Nationalities [20110033]
FX This work was supported by the National Natural Science Foundation of
   China (No. 60902053), the Science and Technology Research Planning of
   Educational Commission of Hubei Province of China (No. B20110803), the
   Natural Science Foundation of Hubei Province of China (No. 2008CDB339),
   and the Education Research Foundation of South-Central University of
   Nationalities (No. 20110033). The authors gratefully acknowledge the
   helpful comments and suggestions of the reviewers.
CR Akyildiz IF, 2007, J COMPUTER NETWORKS, V50, P2127
   [Anonymous], 2009, P80211ND70 IEEE
   [Anonymous], 2005, 80211E IEEE
   Avallone S, 2009, IEEE ACM T NETWORK, V17, P267, DOI 10.1109/TNET.2008.918091
   Chen QA, 2011, IEEE J-STSP, V5, P56, DOI 10.1109/JSTSP.2010.2060468
   Chowdhury KR, 2008, IEEE J SEL AREA COMM, V26, P168, DOI 10.1109/JSAC.2008.080115
   ElRakabawy SM, 2010, WIREL NETW, V16, P2191, DOI 10.1007/s11276-010-0253-3
   Ge XH, 2011, IEEE T WIREL COMMUN, V10, P3298, DOI 10.1109/TWC.2011.11.101551
   Ghaboosi K, 2011, WIRELESS PERS COMMUN, V58, P565, DOI 10.1007/s11277-010-0122-5
   Gronkvist J, 2004, IEEE VEH TECHN C MAY
   Guo XY, 2011, MULTIMEDIA SYST, V17, P287, DOI 10.1007/s00530-010-0210-0
   Hiertz GR, 2010, IEEE WIREL COMMUN, V17, P104, DOI 10.1109/MWC.2010.5416357
   Hou YT, 2008, IEEE J SEL AREA COMM, V26, P146, DOI 10.1109/JSAC.2008.080113
   Humar I, 2011, IEEE NETWORK, V25, P40, DOI 10.1109/MNET.2011.5730527
   Kompella S, 2009, IEEE ACM T NETWORK, V17, P212, DOI 10.1109/TNET.2008.925942
   Luo HY, 2010, J VIS COMMUN IMAGE R, V21, P98, DOI 10.1016/j.jvcir.2009.06.006
   Martignon F, 2011, WIREL COMMUN MOB COM, V11, P90, DOI 10.1002/wcm.917
   Nandiraju N, 2007, IEEE WIREL COMMUN, V14, P79, DOI 10.1109/MWC.2007.4300987
   Rao A, 2005, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES (MOBISYS 2005), P135, DOI 10.1145/1067170.1067185
   Rozner E, 2009, IEEE T MOBILE COMPUT, V8, P1622, DOI 10.1109/TMC.2009.82
   Salameh HAB, 2009, IEEE T MOBILE COMPUT, V8, P1339, DOI 10.1109/TMC.2009.19
   Singh SR, 2010, IEEE INFOCOM WORKSH
   Singh S, 2007, AD HOC NETW, V5, P744, DOI 10.1016/j.adhoc.2006.12.008
   Tang J, 2010, IEEE T VEH TECHNOL, V59, P1487, DOI 10.1109/TVT.2009.2038478
   Timmers M, 2010, IEEE T VEH TECHNOL, V59, P446, DOI 10.1109/TVT.2009.2029552
   Wang BB, 2011, IEEE J-STSP, V5, P5, DOI 10.1109/JSTSP.2010.2093210
   Wang XD, 2008, AD HOC NETW, V6, P970, DOI 10.1016/j.adhoc.2007.09.003
   Yackoski J, 2010, P IEEE INFOCOM
   Zhou L, 2010, IEEE J SEL AREA COMM, V28, P409, DOI 10.1109/JSAC.2010.100412
   Zhou MT, 2010, 2010 IEEE 21ST INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1436, DOI 10.1109/PIMRC.2010.5671989
   Zhou MT, 2010, IEICE T COMMUN, VE93B, P3417, DOI 10.1587/transcom.E93.B.3417
   Zhu R, 2011, ACM MOBILE NETWORK A
   Zhu RB, 2008, APPL MATH COMPUT, V205, P109, DOI 10.1016/j.amc.2008.05.052
   Zhu RB, 2011, J NETW COMPUT APPL, V34, P1449, DOI 10.1016/j.jnca.2010.08.014
NR 34
TC 7
Z9 9
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 269
EP 288
DI 10.1007/s11042-011-0942-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800014
DA 2024-07-18
ER

PT J
AU Sachan, A
   Emmanuel, S
AF Sachan, Amit
   Emmanuel, Sabu
TI Computation time efficient approach for licenses validation in DRM
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management; Violation detection; License validation
ID FREQUENT PATTERNS; RIGHTS
AB Digital rights management (DRM) systems are employed to securely deliver the digital contents from owners/creators to consumers. Often multiple middle level distributors are involved in the distribution process. Initially, the owner issues redistribution licenses to its distributors. The distributors in turn using their received redistribution licenses can issue new redistribution licenses to other distributors and usage licenses to consumers. However, distributors may be involved in violation of the rights given to them in redistribution licenses. Thus, for the rights violation detection, these newly issued licenses must be validated against the received redistribution licenses. The validation becomes complex when there exist multiple redistribution licenses for contents. Then it requires validation using an exponential number of validation inequalities and each inequality may contain up to an exponential number of summation terms. This makes the validation process computationally intensive and necessitates to do the validation efficiently. Thus, in this paper, we propose a method to reduce the validation time by deriving a relationship between different validation inequalities and then designing a data structure to do efficient validation using the derived relationship. The theoretical and experimental analysis show that the proposed method can do the validation efficiently as compared to the other existing approaches for the validation.
C1 [Sachan, Amit; Emmanuel, Sabu] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Sachan, A (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM amit0009@e.ntu.edu.sg; asemmanuel@ntu.edu.sg
RI Emmanuel, Sabu/A-3690-2011
FU A*STAR, Singapore [0721010022]
FX Thanks to A*STAR, Singapore for supporting this work under the project
   "Digital Rights Violation Detection for Digital Asset Management"
   (Project No: 0721010022).
CR Abbadi IM, 2009, 2009 THIRD INTERNATIONAL CONFERENCE ON EMERGING SECURITY INFORMATION, SYSTEMS, AND TECHNOLOGIES, P148, DOI 10.1109/SECURWARE.2009.30
   [Anonymous], 20 INT C VER LARG DA
   [Anonymous], 1998, SORTING SEARCHING
   Burdick D, 2005, IEEE T KNOWL DATA EN, V17, P1490, DOI 10.1109/TKDE.2005.183
   Chuang KT, 2008, VLDB J, V17, P1321, DOI 10.1007/s00778-007-0078-6
   Chui CK, 2007, LECT NOTES COMPUT SC, V4426, P47
   Eavis T, 2009, LECT NOTES COMPUT SC, V5463, P369, DOI 10.1007/978-3-642-00887-0_33
   García R, 2008, INT J ELECTRON COMM, V12, P99, DOI 10.2753/JEC1086-4415120404
   Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83
   Hilty M, 2007, LECT NOTES COMPUT SC, V4734, P531
   Hwang SO, 2004, J SYST SOFTWARE, V73, P533, DOI 10.1016/j.jss.2003.10.016
   Jamkhedkar PA, 2009, COMPUT ELECTR ENG, V35, P376, DOI 10.1016/j.compeleceng.2008.06.012
   Liu GM, 2004, DATA MIN KNOWL DISC, V9, P249, DOI 10.1023/B:DAMI.0000041128.59011.53
   O'Driscoll G., 2008, Next Generation IPTV Services and Technologies
   Rojas C, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P221, DOI 10.1109/WI.2007.114
   Sachan A, 2011, COMPUT SECUR, V30, P498, DOI 10.1016/j.cose.2011.05.003
   Safavi-Niani R., 2004, Proceedings of the 4th ACM Workshop on Digital Rights Management, P99
   Sans T, 2007, INT FED INFO PROC, V232, P349
   van der Veen JAA, 2005, J OPER RES SOC, V56, P757, DOI 10.1057/palgrave.jors.2601879
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 30
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 465
EP 491
DI 10.1007/s11042-012-1057-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300006
DA 2024-07-18
ER

PT J
AU Kim, J
   Kang, S
AF Kim, Jongwoo
   Kang, Sanggil
TI An ontology-based personalized target advertisement system on
   interactive TV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized target advertisement; Ontology; Interactive TV; Semantic
   relations; Shopping products; Reference group
AB We design and implement a personalized target advertisement (PTA) system in IPTV using ontology-based semantic relations between IPTV program and advertisement. In the PTA system, we focus on the development of an ontology reasoning technique of improving advertisement recommendation ability and exploiting efficient information reuse. For this purpose, we first build the IPTV program ontology and viewer profiling ontology based on the IPTV program and viewers' content consumption behavior, using OWL (Web Ontology Language) standardized by W3C. We then classify each viewer into his/her corresponding reference group using a similarity metric. After that, we define the semantic relations between advertisement and shopping products consumed by the prototype through shopping sites in IPTV. Based on these semantic relations, we infer the preferred advertisements for each viewer through our reasoning process. In the experimental section, we demonstrate a prototype of our system and the algorithm of the PTA system using various cases.
C1 [Kim, Jongwoo; Kang, Sanggil] Inha Univ, Dept Comp Sci & Informat Engn, Inchon 402751, South Korea.
C3 Inha University
RP Kang, S (corresponding author), Inha Univ, Dept Comp Sci & Informat Engn, 253 Yonghyun Dong, Inchon 402751, South Korea.
EM skytolove@inha.edu; sgkang@inha.ac.kr
FU Inha University Research
FX This work was supported by Inha University Research.
CR Athanasiadis E, 2010, J SYST SOFTWARE, V83, P1453, DOI 10.1016/j.jss.2010.02.040
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bozios Theodoros., 2001, Proceedings of the eBusiness and eWork Conference, P1025
   Chen H, 2003, KNOWL ENG REV, V18, P197, DOI 10.1017/S0269888904000025
   Deng Y, 2010, P 2010 IEEE ACM INT, DOI [10.1109/GreenCom-CPSCom.2010.144, DOI 10.1109/GREENC0M-CPSC0M.2010.144]
   Gruber T, 2008, J WEB SEMANT, V6, P4, DOI 10.1016/j.websem.2007.11.011
   Horrocks I., 2004, Proceedings of the 13th Conference on World Wide Web, May 2004, P723, DOI DOI 10.1145/988672.988771
   Jae-Hyoung Yoo, 2006, International Journal of Network Management, V16, P383, DOI 10.1002/nem.628
   Juszczyszyn K, 2010, STUD COMPUT INTELL, V289, P275
   Kalfoglou Y, 2003, KNOWL ENG REV, V18, P1, DOI 10.1017/S0269888903000651
   Kim M, 2005, LECT NOTES COMPUT SC, V3767, P202
   Lee CS, 2010, IEEE T FUZZY SYST, V18, P374, DOI 10.1109/TFUZZ.2010.2042454
   Lekakos G, 2009, ENCY MULTIMED TECHNO, P1142
   Lim J, 2008, MULTIMED TOOLS APPL, V36, P11, DOI 10.1007/s11042-006-0079-2
   López-Nores M, 2009, MULTIMED TOOLS APPL, V41, P407, DOI 10.1007/s11042-008-0239-7
   Maedche A, 2001, IEEE INTELL SYST APP, V16, P72, DOI 10.1109/5254.920602
   Milenkovic M, 1998, IEEE MULTIMEDIA, V5, P34, DOI 10.1109/93.735867
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   O'Brien J., 1999, ACM Transactions on Computer-Human Interaction, V6, P282, DOI 10.1145/329693.329698
   Resnik P, 1999, J ARTIF INTELL RES, V11, P95, DOI 10.1613/jair.514
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Vallet D, 2007, IEEE T CIRC SYST VID, V17, P336, DOI 10.1109/TCSVT.2007.890633
NR 22
TC 6
Z9 6
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 517
EP 534
DI 10.1007/s11042-011-0965-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600001
DA 2024-07-18
ER

PT J
AU Chou, JK
   Yang, CK
AF Chou, Jia-Kai
   Yang, Chuan-Kai
TI Simulation of face/hairstyle swapping in photographs with skin texture
   synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active shape model; Skin texture synthesis; Hairstyle extraction
AB The modern trend of diversification and personalization has encouraged people to boldly express their differentiation and uniqueness in many aspects, and one of the noticeable evidences is the wide variety of hairstyles that we could observe today. Given the needs for hairstyle customization, approaches or systems, ranging from 2D to 3D, or from automatic to manual, have been proposed or developed to digitally facilitate the choice of hairstyles. However, nearly all existing approaches suffer from providing realistic hairstyle synthesis results. By assuming the inputs to be 2D photos, the vividness of a hairstyle re-synthesis result relies heavily on the removal of the original hairstyle, because the co-existence of the original hairstyle and the newly re-synthesized hairstyle may lead to serious artifact on human perception. We resolve this issue by extending the active shape model to more precisely extract the entire facial contour, which can then be used to trim away the hair from the input photo. After hair removal, the facial skin of the revealed forehead needs to be recovered. Since the skin texture is non-stationary and there is little information left, the traditional texture synthesis and image inpainting approaches do not fit to solve this problem. Our proposed method yields a more desired facial skin patch by first interpolating a base skin patch, and followed by a non-stationary texture synthesis. In this paper, we also would like to reduce the user assistance during such a process as much as possible. We have devised a new and friendly facial contour and hairstyle adjusting mechanism that make it extremely easy to manipulate and fit a desired hairstyle onto a face. In addition, our system is also equipped with the functionality of extracting the hairstyle from a given photo, which makes our work more complete. Moreover, by extracting the face from the input photo, our system allows users to exchange faces as well. In the end of this paper, our re-synthesized results are shown, comparisons are made, and user studies are conducted as well to further demonstrate the usefulness of our system.
C1 [Chou, Jia-Kai; Yang, Chuan-Kai] Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM A9409004@mail.ntust.edu.tw; ckyang@cs.ntust.edu.tw
CR Active Shape Models with Stasm, 2008, ACTIVE SHAPE MODELS
   [Anonymous], SIGGRAPH 2000
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Blancato V, 1988, US Patent, Patent No. 4731743
   Blanz V, 2004, EUR 2004
   Chuang YY, 2001, PROC CVPR IEEE, P264
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, SPIE MED IMAGING
   Doi M, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P193
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   He LF, 2008, IEEE T IMAGE PROCESS, V17, P749, DOI 10.1109/TIP.2008.919369
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Kjeldsen R, 1996, FG 96 2 INT C AUT FA
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mohammed U, 2009, SIGGRAPH 2009
   Mortensen E. N., 1995, P 22 ANN C COMP GRAP, P191, DOI DOI 10.1145/218380.218442
   Naini FB, 2006, AM J ORTHOD DENTOFAC, V130, P277, DOI 10.1016/j.ajodo.2005.09.027
   Oliveira MM, 2001, VIIP INT C VIS IM IM
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   PERRETT DI, 1994, NATURE, V368, P239, DOI 10.1038/368239a0
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585
   Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Tsumura N, 2003, P 30 ANN C COMP GRAP
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang J, 2007, SIGGRAPH 2007
   Wang L, 2009, SIGGRAPH 2009
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Yang MH, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P127, DOI 10.1109/ICIP.1998.723442
NR 35
TC 2
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 729
EP 756
DI 10.1007/s11042-011-0891-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000007
DA 2024-07-18
ER

PT J
AU Mu, M
   Romaniak, P
   Mauthe, A
   Leszczuk, M
   Janowski, L
   Cerqueira, E
AF Mu, Mu
   Romaniak, Piotr
   Mauthe, Andreas
   Leszczuk, Mikolaj
   Janowski, Lucjan
   Cerqueira, Eduardo
TI Framework for the integrated video quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality metrics; Quality of experience; Content distribution
   network; Mean opinion score; Perceptual quality
AB Through years of development Content Networks (CN) have become more sophisticated and more technically diverse. Modern CN are designed to be more adaptive to communication environment, devices and user requirements. However, one open issue is the still fluctuating quality of service provision. As a result user experience can be negatively affected. In order to maintain a satisfactory level of user experience it is crucial to develop a feasible solution to measure the extent to which video services meet users' expectation. Assessing video quality with respect to users' subjective opinions is a complex task. In this paper we address challenges of this task and design an integrated framework using a number of comprehensive functional modules. Our framework integrates objective quality assessment models of Artifacts Measurement (AM) and Quality of Delivery (QoD) approaches. Only the fittest models are activated by the framework considering requirements of individual evaluation tasks. We also introduce our recent work of realising key functional modules of the framework. Joint subjective experiments between two institutes have also been carried out for the purpose of model implementation and evaluation. Results from experiments verify the concept of an integrated framework and show the effectiveness of its key modules in estimating the quality level of video services.
C1 [Romaniak, Piotr; Leszczuk, Mikolaj; Janowski, Lucjan] AGH Univ Sci & Technol, Dept Telecommun, Krakow, Poland.
   [Mauthe, Andreas] Univ Lancaster, Sch Comp & Commun, Dept Comp, Lancaster, England.
   [Cerqueira, Eduardo] Fed Univ Para, BR-66059 Belem, Para, Brazil.
C3 AGH University of Krakow; Lancaster University; Universidade Federal do
   Para
RP Romaniak, P (corresponding author), AGH Univ Sci & Technol, Dept Telecommun, Krakow, Poland.
EM romaniak@agh.edu.pl
RI Cerqueira, Eduardo/HPC-8703-2023; Romaniak, Piotr/C-7763-2011; Mu,
   Mu/W-2822-2019; Leszczuk, Mikołaj I/C-4857-2011; Janowski,
   Lucjan/B-2264-2013
OI Cerqueira, Eduardo/0000-0003-2162-6523; Mu, Mu/0000-0003-1931-7959;
   Leszczuk, Mikołaj I/0000-0001-9123-1039; Mauthe,
   Andreas/0000-0002-8727-9440; Janowski, Lucjan/0000-0002-3151-2944
FU European Community's Seventh Framework Program [218086]; Agilent
   Laboratories UK; European Commission; National Council for Scientific
   and Technological Development (CNPq Brazil); Fundacao de Amparo a
   Pesquisa do Estado do Para (FAPESPA); EPSRC [EP/H003738/1] Funding
   Source: UKRI
FX Application of Piotr Romaniak's, Mikolaj Leszczuk's and Lucjan
   Janowski's research leading to these results has received funding from
   the European Community's Seventh Framework Program (FP7/2007-2013) under
   grant agreement no218086 (INDECT). Mu Mu's work is also supported by
   Agilent Laboratories UK, European Commission within the FP7 Project:
   P2P-Next and Framework for Innovation and Research in MediaCityUK
   (FIRM). Eduardo Cerqueira was supported by The National Council for
   Scientific and Technological Development (CNPq Brazil) and Fundacao de
   Amparo a Pesquisa do Estado do Para (FAPESPA). The authors thank Piotr
   Borkowski from AGH University of Science and Technology, Roswitha
   Gostner from Lancaster University and Francisco Garcia from Agilent
   Laboratories for their input.
CR Addis B, 2006, COMPUT OPTIM APPL, V35, P287, DOI [10.1007/s10589-006-8716-2, 10.1007/S10589-006-8716-2]
   [Anonymous], ITU T P 800 METH SUB
   [Anonymous], FIN REP VID QUAL EXP
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   Botta A., 2011, 2011 IEEE Symposium on Computers and Communications (ISCC 2011), P1022, DOI 10.1109/ISCC.2011.5983976
   Botta A, 2008, QUALITY SERVICE STAT
   Brandao T, 2010, IEEE T CIRC SYST VID, V20, P1437, DOI 10.1109/TCSVT.2010.2077474
   Chan A., 2010, 2010 Proceedings IEEE INFOCOM, P1, DOI DOI 10.1109/INFCOM.2010.5461979
   Claypool M, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P508
   CMP Media LLC, 2009, MEAS IPTV QOS PERF B
   Dosselmann R, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P411, DOI 10.1109/CRV.2007.6
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Eskicioglu AM, 2000, INT CONF ACOUST SPEE, P1907, DOI 10.1109/ICASSP.2000.859201
   Farias MCQ, 2005, IEEE IMAGE PROC, P3593
   Fukumoto K, 2004, RES WORKSH APPL STAT
   Geerts D, 2010, 2 INT WORKSH QUAL MU
   ITU-R, 1998, ITU R BT 1129 SUBJ A
   ITU-R, 1998, ITU R BT 500 METH SU
   ITU-T, 1999, ITU T P 910 SUBJ VID
   Jae Cheol Kwon, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P224, DOI 10.1109/QOMEX.2010.5516127
   Jain R, 2004, IEEE MULTIMEDIA, V11, P96, DOI 10.1109/MMUL.2004.1261114
   Kangasharju J, 2008, P INT C INF NETW 200
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   Lee J.S., 1989, Geoscience and Remote Sensing Symposium, V2, P1005, DOI [DOI 10.1109/IGARSS.1989.579061, 10.1109/IGARSS.1989.579061]
   Liang YJ, 2003, P IEEE INT C AC SPEE, V5, DOI [10.1109/ICASSP.2003.1200063, DOI 10.1109/ICASSP.2003.1200063]
   Liu T, 2009, IEEE J-STSP, V3, P280, DOI 10.1109/JSTSP.2009.2015069
   MSU Graphics & Media Lab (Video Group), 2009, MSU VID QUAL MEAS TO
   Mu M, 2009, P 16 ANN MULT COMP N
   Mu M, 2008, P 1 IEEE FUT MULT NE
   Mu M, 2011, SIGNAL PROCESS-IMAGE, V26, P339, DOI 10.1016/j.image.2011.03.002
   Ohm Jens-Rainer., 1999, Bildsignalverarbeitung fuer multimedia-systeme. skript
   OPTICOM, 2007, PERC EV VID QUAL
   Pinson M, 2004, IMPACT MONITOR RESOL
   VQEG, 2004, IND VQEG TEST SEQ
   WANG Yubing., 2006, SURVEY OBJECTIVE VID
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 1998, EE 381K MULTIDIMENSI
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   WINKLER S, 2007, P EUR SIGN PROC C PO
   Wolf S, 1999, P SOC PHOTO-OPT INS, V3845, P266, DOI 10.1117/12.371210
   Yang FZ, 2010, IEEE T CIRC SYST VID, V20, P1544, DOI 10.1109/TCSVT.2010.2087433
   Yim C, 2011, SIGNAL PROCESS-IMAGE, V26, P24, DOI 10.1016/j.image.2010.11.002
NR 42
TC 20
Z9 20
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 787
EP 817
DI 10.1007/s11042-011-0946-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700014
DA 2024-07-18
ER

PT J
AU Ryu, DS
   Chung, WK
   Cho, HG
AF Ryu, Dong-Sung
   Chung, Woo-Keun
   Cho, Hwan-Gue
TI A hierarchical photo visualization system emphasizing temporal and
   color-based coherences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo management; Photo clustering; Photo visualization; EXIF
AB Most photograph management systems use a scrollable view based on a sequential grid layout that arranges photo thumbnails in some default order on the screen. Although users are very accustomed to this kind of photo layout, multiple drag and drop mouse interactions are required to search and obtain an overview of their photos. This paper describes a photo visualization system that visualizes hundreds of photos on a 2D grid space in order to help users manage their photos(.) Our system provides the following three main functions. First, it places similar photos in terms of color histogram and shoot time close together on the grid. Therefore, users can find their photos using temporal and color-based coherences relating to human sensory information such as colors that invokes similar feelings and photo shoot time. Second, our system provides a hierarchical clustering method based on a 2D grid space. This function can decrease drag and drop mouse interactions when classifying photos into small groups compared to the sequential grid layout. Finally, our system displays a representative photo from each cluster, in order to provide a summarized view of multiple photos. For evaluation of our system, we conducted seven experiments consisting of four computational and three subjective evaluations making a comparison with a sequential grid layout. The computational evaluations consider the four features of space efficiency, temporal stability and color-based consistency between neighbor photos of the grid, and cluster similarity. The evaluations establish that our system can decrease space efficiency while improving the other features. The three subjective evaluations deal with our system's ease-of-use from a subjective human perspective. Most people that participated in our experiments found that this photo visualization system was quite suited to finding and summarizing their photo content.
C1 [Ryu, Dong-Sung] Pusan Natl Univ, Dept Comp Sci & Engn, Graph Applicat Lab, Pusan, South Korea.
   [Chung, Woo-Keun] Pusan Natl Univ, Dept Comp Sci, Pusan, South Korea.
C3 Pusan National University; Pusan National University
RP Cho, HG (corresponding author), Pusan Natl Univ, Dept Comp Sci & Engn, Graph Applicat Lab, Pusan, South Korea.
EM dsryu99@pusan.ac.kr; wkchung@pusan.ac.kr; hgcho@pusan.ac.kr
FU IT R&D program of MKE/MCST/KEIT [KI001820]
FX This work was supported by the IT R&D program of MKE/MCST/KEIT
   (KI001820, Development of Computational Photography Technologies for
   Image and Video Contents).
CR ACDSystems, ACDSEE PHOT
   [Anonymous], IPHOTO
   [Anonymous], CUDA
   Bederson B. B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P71, DOI 10.1145/502348.502359
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   Girgensohn A., 2009, Proceedings of the 14th International Conference on Intelligent User Interfaces, P419, DOI DOI 10.1145/1502650.1502711
   Google, PIC WEB ALB
   Graham A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P326, DOI 10.1145/544220.544301
   Jang Chuljin., 2009, P 2009 ACM S APPL CO, P1784
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Kustanowitz J, 2006, IEEE MULTIMEDIA, V13, P62, DOI 10.1109/MMUL.2006.83
   Litten J, 1975, DESIGN FORM BASIC CO
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Mota Joao, 2008, P ACM AVI, P494
   PINHO R, 2009, SAC 09, P1757, DOI DOI 10.1145/1529282.1529679
   Platt JC, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P6
   Platt JC, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P96, DOI 10.1109/IVL.2000.853847
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   Ryu D. S., 2010, ACM SAC, P1884
   Schaefer G, 2010, MULTIMED TOOLS APPL, V47, P105, DOI 10.1007/s11042-009-0409-2
   Singh R, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1031
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
NR 23
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 523
EP 550
DI 10.1007/s11042-010-0700-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700002
DA 2024-07-18
ER

PT J
AU Akbari, AS
   Zadeh, PB
   Buggy, T
   Soraghan, J
AF Akbari, Akbar Sheikh
   Zadeh, Pooneh Bagheri
   Buggy, Tom
   Soraghan, John
TI Multiresolution, perceptual and vector quantization based video codec
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual weights; Wavelet transforms; Vector quantization and video
   codec
AB This paper presents a novel Multiresolution, Perceptual and Vector Quantization (MPVQ) based video coding scheme. In the intra-frame mode of operation, a wavelet transform is applied to the input frame and decorrelates it into its frequency subbands. The coefficients in each detail subband are pixel quantized using a uniform quantization factor divided by the perceptual weighting factor of that subband. The quantized coefficients are finally coded using a quadtree-coding algorithm. Perceptual weights are specifically calculated for the centre of each detail subband. In the inter-frame mode of operation, a Displaced Frame Difference (DFD) is first generated using an overlapped block motion estimation/compensation technique. A wavelet transform is then applied on the DFD and converts it into its frequency subbands. The detail subbands are finally vector quantized using an Adaptive Vector Quantization (AVQ) scheme. To evaluate the performance of the proposed codec, the proposed codec and the adaptive subband vector quantization coding scheme (ASVQ), which has been shown to outperform H.263 at all bitrates, were applied to six test sequences. Experimental results indicate that the proposed codec outperforms the ASVQ subjectively and objectively at all bit rates.
C1 [Akbari, Akbar Sheikh] Staffordshire Univ, Fac Comp Engn & Technol, Beacon Side ST18 0AD, Staffs, England.
   [Zadeh, Pooneh Bagheri] De Montfort Univ, Fac Technol, Dept Engn, Leicester LE1 9BH, Leics, England.
   [Buggy, Tom] Glasgow Caledonian Univ, Div Commun Networking & Elect Engn, Sch Engn & Comp, Glasgow G4 0BA, Lanark, Scotland.
   [Soraghan, John] Univ Strathclyde, Dept Elect & Elect Engn, Inst Commun & Signal Proc, Glasgow G1 1XW, Lanark, Scotland.
C3 Staffordshire University; De Montfort University; Glasgow Caledonian
   University; University of Strathclyde
RP Akbari, AS (corresponding author), Staffordshire Univ, Fac Comp Engn & Technol, Beacon Side ST18 0AD, Staffs, England.
EM a.s.akbari@staffs.ac.uk; pbz@dmu.ac.uk; t.buggy@gcal.ac.uk;
   jjs@eee.strath.ac.uk
RI Sheikh-Akbari, Akbar/AAA-7302-2022
OI Sheikh-Akbari, Akbar/0000-0003-0677-7083
CR Akbari AS, 2003, ELECTRON LETT, V39, P1044, DOI 10.1049/el:20030673
   Al-Hudhud Ghada, 2009, 2009 Second International Conference in Visualisation (VIZ), P196, DOI 10.1109/VIZ.2009.42
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Ashraf G, 1997, ISCE '97 - PROCEEDINGS OF 1997 IEEE INTERNATIONAL SYMPOSIUM ON CONSUMER ELECTRONICS, P153, DOI 10.1109/ISCE.1997.658375
   Bradley AP, 1999, IEEE T IMAGE PROCESS, V8, P717, DOI 10.1109/83.760338
   Fraunhofer Institut Nachrichtentechnik Heinrich-Hertz-Institute, H 264 AVC SOFTW VERS
   Ghanbari M., 1999, VIDEO CODING INTRO S
   Höntsch I, 2000, IEEE T IMAGE PROCESS, V9, P1472, DOI 10.1109/83.862622
   KAIA X, 2005, EUROPEAN J RADIOLOGY, V55, P139
   KATTO J, 1994, IEEE T CIRC SYST VID, V4, P328, DOI 10.1109/76.305877
   Lin Ma, 2010, 2010 IEEE International Symposium on Circuits and Systems. ISCAS 2010, P4213, DOI 10.1109/ISCAS.2010.5537571
   Maalouf Aldo, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P11, DOI 10.1109/QOMEX.2010.5518301
   Nadenau MJ, 2003, IEEE T IMAGE PROCESS, V12, P58, DOI 10.1109/TIP.2002.807358
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Pastuszak G, 2005, IEEE T CIRC SYST VID, V15, P1182, DOI 10.1109/TCSVT.2005.852720
   Samet H., 1984, ACM Comput Surv, V16
   Skodras A, 2001, IEEE SIGNAL PROCESS, V18
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Taubman D S, 2004, JPEG 2000 IMAGE COMP
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   Van Dyck RE, 1994, IEEE T CIRCUIT SYST, V4
   Voukelatos SP, 1997, IEEE T CIRC SYST VID, V7, P424, DOI 10.1109/76.564121
   YANG Xiaokang, 2005, IEEE T CIRCUITS SYST, V15
NR 23
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 569
EP 583
DI 10.1007/s11042-011-0752-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900006
DA 2024-07-18
ER

PT J
AU Lee, K
AF Lee, Kilhung
TI A backup path routing for guaranteeing bandwidth in mobile ad hoc
   networks for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Backup path; Quality of service; Bandwidth; Ad hoc routing
AB This paper suggests a backup path routing scheme in ad hoc networks for multimedia applications. A data path is established in an on-demand manner when there is a need to send data. A primary and a backup path are created as a result of a route control message exchange process. Each control message has additional information for guaranteeing the service quality. A backup path is configured around the primary path in multi-hop wireless networks. After detecting a failure when sending data, a repairing procedure occurs near the failed node of the primary path. The proposed scheme exploits the route request and reply information exchanged between nodes to create a backup path. Proposed backup routing scheme uses a one-hop search method, and the rerouted path length is two-hop at maximum. The service quality as measured by the error rate and delay is considered when establishing and repairing a route by making an allowance for the required bandwidth. Simulation results show that the proposed backup path routing scheme has a better data delivery ratio and an improved end-to-end data delay while guaranteeing the requested bandwidth for multimedia application.
C1 Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul 139743, South Korea.
C3 Seoul National University of Science & Technology
RP Lee, K (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul 139743, South Korea.
EM khlee@snut.ac.kr
CR [Anonymous], 4728 RFC
   Bernardo Vitor, 2009, 2009 IEEE Symposium on Computers and Communications (ISCC), P42, DOI 10.1109/ISCC.2009.5202392
   Chakeres I.D., 2002, ACM SIGMOBILE MOBILE, V6, P100, DOI [10.1145/581291.581309, DOI 10.1145/581291.581309]
   Chen L, 2007, IEEE NETWORK, V21, P30, DOI 10.1109/MNET.2007.4395108
   Chlamtac Imrich., 2003, Ad Hoc Networks, V1, P13, DOI DOI 10.1016/S1570-8705(03)00013-1
   Kang BS, 2010, SENSORS-BASEL, V10, P808, DOI 10.3390/s100100808
   Kulkarni NS, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P586, DOI 10.1109/IADCC.2009.4809077
   Lai WK, 2007, COMPUT COMMUN, V30, P453, DOI 10.1016/j.comcom.2006.09.011
   Lee SJ, 2000, IEEE WCNC, P1311, DOI 10.1109/WCNC.2000.904822
   Li XF, 2005, SIXTH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERNG, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING AND FIRST AICS INTERNATIONAL WORKSHOP ON SELF-ASSEMBLING WIRELESS NETWORKS, PROCEEDINGS, P308
   Li Y, 2005, I C WIREL COMM NETW, P739
   Marina MK, 2001, NETWORK PROTOCOLS, P14, DOI 10.1109/ICNP.2001.992756
   Mbarushimana C, 2008, LECT NOTES COMPUT SC, V5198, P265, DOI 10.1007/978-3-540-85209-4_21
   Mueller S, 2004, LECT NOTES COMPUT SC, V2965, P209
   Peng Yang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P1024, DOI 10.1109/CSSE.2008.905
   Perkins C., 2003, Internet RFCs
   Perkins C., 1999, P 2 IEEE WORKSH MOB, P90
   Perkins C. E., 1994, Computer Communication Review, V24, P234, DOI 10.1145/190809.190336
   Reddy LR, 2007, AD HOC NETW, V5, P162, DOI 10.1016/j.adhoc.2005.10.002
   Sung-Ju L, 2001, P IEEE ICC, P3201
   Wang L, 2000, 2000 CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, CONFERENCE PROCEEDINGS, VOLS 1 AND 2, P479, DOI 10.1109/CCECE.2000.849755
   Ye ZQ, 2003, IEEE INFOCOM SER, P270
   Zafar H, 2009, IET COMMUN, V3, P700, DOI 10.1049/iet-com.2008.0328
NR 23
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 439
EP 451
DI 10.1007/s11042-010-0699-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700012
DA 2024-07-18
ER

PT J
AU Lian, SG
   Chen, X
   Wang, JW
AF Lian, Shiguo
   Chen, Xi
   Wang, Jinwei
TI Content distribution and copyright authentication based on combined
   indexing and watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content distribution; Copyright authentication; Media index; Watermark;
   Multimedia social network; Digital right management
ID IMAGE COPY DETECTION
AB Copyright issues become more and more urgent with the wide spread of multimedia content over Internet, e.g., whether the media content is copyright-protected in multimedia social networks, or whether a media content is released on Internet illegally. To solve these problems, this paper proposes a content distribution and copyright authentication system based on media index and watermarking techniques. Before media distribution, the media content is marked (by embedding the ownership information or customer identification into the media), and the robust features that can be used both for media index and content emendation is extracted from the watermarked media and registered in a feature database. Some customer may leak out his media copy over Internet directly or after slight operations, such as rotation, shearing, scaling, translation, etc. To detect whether a media over Internet is copyright-protected or not, the following work is done. Firstly, a watermark is extracted from the media and compared with the original one. If the watermark exists, then the media is copyright-protected, and the authentication process is finished. Otherwise, a robust feature is extracted from the considered media and matched with the feature database. The matching result gives the operation parameters that are used to emend the media content. After media emendation, a watermark is extracted or detected again and used to authenticate the copyright. In this system, the robust feature is not only used to search the related media contents but also to emend the media in order to improve the robustness against such operations as adding noise, compression, rotation, shearing, scaling, translation, etc. Experimental results show that the combination of media index and watermark detection can improve the detection rate greatly.
C1 [Chen, Xi] Nanjing Univ, E Commerce Dept, Nanjing 210093, Jiangsu, Peoples R China.
   [Lian, Shiguo] France Telecom R&D Orange Labs Beijing, Beijing 100080, Peoples R China.
   [Wang, Jinwei] CETC, Res Inst 28, Nanjing 210007, Peoples R China.
C3 Nanjing University; China Electronics Technology Group
RP Chen, X (corresponding author), Nanjing Univ, E Commerce Dept, Nanjing 210093, Jiangsu, Peoples R China.
EM shiguo.lian@orange-ftgroup.com; chenx@nju.edu.cn; wjwei_2004@163.com
FU France Telecom's Invenio project [ILAB-PEK09-016]; National Natural
   Science Foundation of China [70901039]; National Postdoctoral Science
   Foundation of China [20090450144]; Jiangsu Postdoctoral Science
   Foundation [0901104C]
FX The work was partially supported by France Telecom's Invenio project
   through the grant code of ILAB-PEK09-016, National Natural Science
   Foundation of China under Grant No. 70901039, National Postdoctoral
   Science Foundation of China under Grant No. 20090450144, and Jiangsu
   Postdoctoral Science Foundation under Grant No. 0901104C.
CR Ahmad Nishat, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P825, DOI 10.1109/ISSPIT.2007.4458071
   Amsaleg L, 2001, PATTERN ANAL APPL, V4, P108, DOI 10.1007/s100440170011
   ANDONI A, 2006, P S FDN COMP SCI FOC
   [Anonymous], P 7 ACM SIGMM MIR
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   BERRANI S.-A., 2003, Proceedings of the 1st ACM international workshop on Multimedia databases, P70, DOI DOI 10.1145/951676.951690
   Bhardwaj A, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P333, DOI 10.1109/MMSP.2001.962756
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Chang EY, 1999, P SOC PHOTO-OPT INS, V3846, P281, DOI 10.1117/12.360433
   Chatterji BN, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P812
   Cheng Q, 2001, IEEE T MULTIMEDIA, V3, P273, DOI 10.1109/6046.944472
   Cheng Q, 2002, INT CONF ACOUST SPEE, P3477
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gang Xue, 2004, Digital Watermarking. Third International Workshop, IWDW 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3304), P42
   GRUHL D, 1996, ECHO HIDING PREPROCE, P295
   Harris C., 1988, ALVEY VISION C, P147151
   Hsiao JH, 2007, IEEE T IMAGE PROCESS, V16, P2069, DOI 10.1109/TIP.2007.900099
   Joumaa H, P 2005 INT C AC SPEE, V2, P805
   Kim C, 2003, SIGNAL PROCESS-IMAGE, V18, P169, DOI 10.1016/S0923-5965(02)00130-3
   Lewis AS, 1992, IEEE T IMAGE PROCESS, V1, P244, DOI 10.1109/83.136601
   LIAN S, 2009, HDB RES SECURE MULTI
   Lian SG, 2008, IEEE T CIRC SYST VID, V18, P1462, DOI 10.1109/TCSVT.2008.2002829
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lian SG, 2009, INFORM-J COMPUT INFO, V33, P3
   Liu ZX, 2008, IEEE IMAGE PROC, P409, DOI 10.1109/ICIP.2008.4711778
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Pi MH, 2005, IEEE T MULTIMEDIA, V7, P597, DOI 10.1109/TMM.2005.846796
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Sebastien G, 2003, IMAGE AUDIOVISUAL SE, Patent No. FR2843212
   Takeya F, 2004, System for searching illegitimate use of contents, Patent No. [JP2004112318, 2004112318]
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang JW, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2954129
   Wang ZJ, 2004, EURASIP J APPL SIG P, V2004, P2153, DOI 10.1155/S1110865704312151
   Weinheimer J, 2006, IEEE IMAGE PROC, P1401, DOI 10.1109/ICIP.2006.312688
   Wu M, 2004, IEEE SIGNAL PROC MAG, V21, P15
   Wu MN, 2006, FUND INFORM, V71, P351
   Wu MN, 2005, LECT NOTES ARTIF INT, V3801, P464
   Wu YD, 2005, INT CONF ACOUST SPEE, P13
   Yang ZW, 1999, IEEE T IMAGE PROCESS, V8, P934, DOI 10.1109/83.772236
NR 42
TC 12
Z9 14
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 49
EP 66
DI 10.1007/s11042-010-0521-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800004
DA 2024-07-18
ER

PT J
AU Mazurczyk, W
   Cabaj, K
   Szczypiorski, K
AF Mazurczyk, Wojciech
   Cabaj, Krzysztof
   Szczypiorski, Krzysztof
TI What are suspicious VoIP delays?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IP telephony; VoIP delays; LACK; Information hiding; Network
   steganography
AB Voice over IP (VoIP) is unquestionably the most popular real-time service in IP networks today. Recent studies have shown that it is also a suitable carrier for information hiding. Hidden communication may pose security concerns as it can lead to confidential information leakage. In VoIP, RTP (Real-time Transport Protocol) in particular, which provides the means for the successful transport of voice packets through IP networks, is suitable for steganographic purposes. It is characterised by a high packet rate compared to other protocols used in IP telephony, resulting in a potentially high steganographic bandwidth. The modification of an RTP packet stream provides many opportunities for hidden communication as the packets may be delayed, reordered or intentionally lost. In this paper, to enable the detection of steganographic exchanges in VoIP, we examined real RTP traffic traces to answer the questions, what do the "normal" delays in RTP packet streams look like? and, is it possible to detect the use of known RTP steganographic methods based on this knowledge?.
C1 [Mazurczyk, Wojciech; Cabaj, Krzysztof; Szczypiorski, Krzysztof] Warsaw Univ Technol, Fac Elect & Informat, PL-00665 Warsaw, Poland.
C3 Warsaw University of Technology
RP Mazurczyk, W (corresponding author), Warsaw Univ Technol, Fac Elect & Informat, 15-19 Nowowiejska Str, PL-00665 Warsaw, Poland.
EM W.Mazurczyk@elka.pw.edu.pl; K.Cabaj@elka.pw.edu.pl;
   K.Szczypiorski@elka.pw.edu.pl
RI Szczypiorski, Krzysztof/A-9664-2012
OI Szczypiorski, Krzysztof/0000-0001-8638-8584; Cabaj,
   Krzysztof/0000-0002-5955-5890
CR [Anonymous], 1996, Rec. ITU-T P.800
   [Anonymous], 2005, TR2005536 DARTM COLL
   [Anonymous], 2003, P TEX WORKSH SEC INF
   Begtasevic F., 2001, PAM2001 WORKSH PASS
   Birke R, 2007, IEEE INFOCOM SER, P2027, DOI 10.1109/INFCOM.2007.235
   BORELLA M, 1998, P INT C PAR PROC AUG
   Cole RG, 2001, ACM SIGCOMM COMP COM, V31, P9, DOI 10.1145/505666.505669
   F Petitcolas, 1999, PROTECTION MULTI JUL
   Fei A, 1998, P IEEE GLOBECOM 98, P1998
   GIRLING CG, 1987, IEEE T SOFTWARE ENG, V13, P292, DOI 10.1109/TSE.1987.233153
   Guha S, 2006, 6 INT WORKSH PEER TO
   *ITU T, 2002, G107 ITUT
   ITU-T, 1988, G711 ITUT
   Liang YJ, 2003, IEEE T MULTIMEDIA, V5, P532, DOI 10.1109/TMM.2003.819095
   Lubacz J, 2010, IEEE SPECTRUM, V47, P42, DOI 10.1109/MSPEC.2010.5397787
   Markopoulou AP, 2002, IEEE INF NEW YORK
   Mazurczyk W, 2008, LECT NOTES COMPUT SC, V5332, P1001
   NA S, 2002, LNCS, V2402, P469
   Narbutt M, 2003, TELETRAF SCI ENG A, V2003, P1171
   RAMJEE R, 1994, IEEE INFOCOM SER, P680, DOI 10.1109/INFCOM.1994.337672
   SCHECHTER SE, 2003, ACM WORKSH RAP MALC
   Schulzrinne H., 2003, 3550 IETF RFC
   SERVETTO S, 2001, P IEEE INT S INF THE
   Sreenan CJ, 2000, IEEE T MULTIMEDIA, V2, P88, DOI 10.1109/6046.845013
   Wu C, 2009, P ACM NOSSDAV 2009, P2009
   X-lite, X LITE
   Zhou X, 2005, HOPCOUNT E2E DELAY I
NR 27
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 109
EP 126
DI 10.1007/s11042-010-0532-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, ZN
   Cao, J
   Xia, T
   Song, YC
   Zhang, YD
   Li, JT
AF Chen, Zhineng
   Cao, Juan
   Xia, Tian
   Song, Yicheng
   Zhang, Yongdong
   Li, Jintao
TI Web video retagging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retagging; Tag recommendation; Tag refinement; Graph based model;
   Web video search; Web video categorization
ID ANNOTATION
AB Tags associated with web videos play a crucial role in organizing and accessing large-scale video collections. However, the raw tag list (RawL) is usually incomplete, imprecise and unranked, which reduces the usability of tags. Meanwhile, compared with studies on improving the quality of web image tags, tags associated with web videos are not studied to the same extent. In this paper, we propose a novel web video tag enhancement approach called video retagging, which aims at producing the more complete, precise, and ranked retagged tag list (RetL) for web videos. Given a web video, video retagging first collect its textually and visually related neighbor videos. All tags attached to the neighbors are treated as possible relevant ones and then RetL is generated by inferring the degree of relevance of the tags from both global and video-specific perspectives, using two different graph based models. Two kinds of experiments, i.e., application-oriented video search and categorization and user-based subjective studies are carried out on a large-scale web video dataset, which demonstrate that in most cases, RetL is better than RawL in terms of completeness, precision and ranking.
C1 [Chen, Zhineng; Cao, Juan; Xia, Tian; Song, Yicheng; Zhang, Yongdong; Li, Jintao] Chinese Acad Sci, Ctr Adv Comp Res, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Chen, Zhineng; Song, Yicheng] Chinese Acad Sci, Grad Univ, Beijing 100039, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Chen, ZN (corresponding author), Chinese Acad Sci, Ctr Adv Comp Res, Inst Comp Technol, Beijing 100190, Peoples R China.
EM chenzhineng@ict.ac.cn; caojuan@ict.ac.cn; txia@ict.ac.cn;
   songyicheng@ict.ac.cn; zhyd@ict.ac.cn; jtli@ict.ac.cn
RI chen, zhineng/AAD-6723-2020; XIA, Tian/A-5392-2015
FU National Basic Research Program of China (973 Program) [2007CB311100];
   National Nature Science Foundation of China [60902090]; Beijing New Star
   Project on Science Technology [2007B071]; Beijing Municipal Education
   Commission
FX This work was supported by the National Basic Research Program of China
   (973 Program, 2007CB311100), National Nature Science Foundation of China
   (60902090), Beijing New Star Project on Science & Technology (2007B071),
   Co-building Program of Beijing Municipal Education Commission.
CR Ames M., 2007, P SIGCHI C HUMAN FAC, P971
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], P ACM MULT
   [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], 2014, INT C MULTIMEDIA RET
   [Anonymous], 2006, D LIB MAGAZINE
   Cao J., 2009, MCG WEBV BENCHMARK D
   CHANG SF, 2008, P TRECVID WORKSH
   Chen Z., 2010, P 19 INT C WORLD WID, P1079
   CHUA TS, 2009, P ACM CIVR 2009
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fogarty J, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P29
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   HALVEY MJ, 2010, P ADV MULT MOD, P400
   HALVEY MJ, 2007, P 18 C HYP HYP, P217
   Hatcher E., 2008, LUCENE ACTION, VSecond
   Hsu WinstonH., 2007, ACM MM
   Jin Y., 2005, P 13 ANN ACM INT C M, P706
   Kennedy L.S., 2006, Proc. ACM Multimedia Information Retrieval, P249, DOI DOI 10.1145/1178677.1178712
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   LIU D, 2009, P 18 INT C WORLD WID, P351, DOI DOI 10.1145/1526709.1526757
   Liu L., 2008, P 17 INT C WORLD WID, P1009
   Moxley E, 2010, IEEE T MULTIMEDIA, V12, P184, DOI 10.1109/TMM.2010.2041101
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Page L., 1998, 199966 STANF U
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Rui X., 2007, Proc. 15th ACM intl. conf. on multimedia, P585, DOI DOI 10.1145/1291233.1291378
   Setz AT, 2009, IEEE INT CON MULTI, P1460, DOI 10.1109/ICME.2009.5202778
   Sevil SG, 2010, MULTIMED TOOLS APPL, V49, P81, DOI 10.1007/s11042-009-0394-5
   Siersdorfer S, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/1571941.1572010
   SMEATON AF, 2009, HIGH LEVEL FEATURE D, P151
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   TANG S, 2008, P TRECVID WORKSH
   TSIKRIKA T, 2009, P ACM CIVR 2009
   Ulges A, 2008, LECT NOTES COMPUT SC, V5008, P415
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   WANG C, 2007, P IEEE CVPR 2007 MIN, P1
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wu A. G., 2007, P ACM MM, P218
   Xu HX, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P573, DOI 10.1109/GCIS.2009.320
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
   Zhou T, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.046115
NR 43
TC 10
Z9 10
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2011
VL 55
IS 1
SI SI
BP 53
EP 82
DI 10.1007/s11042-010-0604-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 797PS
UT WOS:000293140400004
DA 2024-07-18
ER

PT J
AU Höferlin, B
   Höferlin, M
   Weiskopf, D
   Heidemann, G
AF Hoeferlin, Benjamin
   Hoeferlin, Markus
   Weiskopf, Daniel
   Heidemann, Gunther
TI Information-based adaptive fast-forward for visual surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information theory; Adaptive fast-forward; Video browsing; Video
   summarization; Visual surveillance
ID VIDEO; DIVERGENCE
AB Automated video analysis lacks reliability when searching for unknown events in video data. The practical approach is to watch all the recorded video data, if applicable in fast-forward mode. In this paper we present a method to adapt the playback velocity of the video to the temporal information density, so that the users can explore the video under controlled cognitive load. The proposed approach can cope with static changes and is robust to video noise. First, we formulate temporal information as symmetrized R,nyi divergence, deriving this measure from signal coding theory. Further, we discuss the animated visualization of accelerated video sequences and propose a physiologically motivated blending approach to cope with arbitrary playback velocities. Finally, we compare the proposed method with the current approaches in this field by experiments and a qualitative user study, and show its advantages over motion-based measures.
C1 [Hoeferlin, Benjamin; Heidemann, Gunther] Univ Stuttgart, Intelligent Syst Grp, Stuttgart, Germany.
   [Hoeferlin, Markus; Weiskopf, Daniel] Univ Stuttgart, VISUS, Stuttgart, Germany.
C3 University of Stuttgart; University of Stuttgart
RP Höferlin, B (corresponding author), Univ Stuttgart, Intelligent Syst Grp, Stuttgart, Germany.
EM benjamin.hoeferlin@vis.uni-stuttgart.de
FU German Research Foundation (DFG) [SPP 1335]
FX We'd like to thank Michael Worner for proofreading this paper. This work
   was funded by German Research Foundation (DFG) as part of the Priority
   Program "Scalable Visual Analytics" (SPP 1335).
CR [Anonymous], 2006, Elements of Information Theory
   [Anonymous], 899 IRISA
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], 2002, P IMAGE VISION COMPU
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   [Anonymous], POLICE J, DOI DOI 10.1350/POJO.2007.80.4.287
   [Anonymous], P 27 INT C HUM FACT
   [Anonymous], WEBVISION ORG RETI 9
   [Anonymous], 2002, CSPL328 U MICH
   [Anonymous], P 2006 IEEE COMP SOC
   BLYTH S, 1994, BIOMETRIKA, V81, P579
   Fairchild M.D., 2005, Color Appearance Models, V2nd
   Ghazal M, 2007, IEEE T CIRC SYST VID, V17, P1690, DOI 10.1109/TCSVT.2007.903805
   Gill M., 2005, Assessing the impact of CCTV
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kang H.-W., 2006, P IEEE C COMP VIS PA, P1331, DOI [DOI 10.1109/CVPR.2006.284, 10.1109/cvpr.2006.2842, DOI 10.1109/CVPR.2006.2842, 10.1109/cvpr.2006.284]
   Kullback S., 1959, STAT INFORM THEORY
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Neemuchwala H, 2005, SIGNAL PROCESS, V85, P277, DOI 10.1016/j.sigpro.2004.10.002
   Peker KA, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2055, DOI 10.1109/ICME.2004.1394669
   Peker KA, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P414, DOI 10.1109/ICIP.2001.958139
   Petrovic N, 2005, MULTIMED TOOLS APPL, V26, P327, DOI 10.1007/s11042-005-0895-9
   Pritch Y., 2007, P ICCV, P1
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Ramos G., 2003, Proceedings of the UIST '03 Symposium on User Interface Software and Technology, P105, DOI DOI 10.1145/964696.964708
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Schoeffmann K, 2009, INT WORK CONTENT MUL, P243, DOI 10.1109/CBMI.2009.40
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
NR 28
TC 31
Z9 32
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2011
VL 55
IS 1
SI SI
BP 127
EP 150
DI 10.1007/s11042-010-0606-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 797PS
UT WOS:000293140400007
DA 2024-07-18
ER

PT J
AU Kapela, R
   Sniatala, P
   Rybarczyk, A
AF Kapela, Rafal
   Sniatala, Pawel
   Rybarczyk, Andrzej
TI Real-time visual content description system based on MPEG-7 descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video content description; Video indexing and annotation; Video hardware
   systems; Real-time systems; MPEG-7
AB This paper presents a real-time Visual Content Description System (VCDS) based on MPEG-7 descriptors. In our approach the system's structure is divided into two parts, the first of which is the extraction of the descriptors using the VCDS. The second part uses the descriptors' values in a particular search algorithm. We propose here original solutions for both parts. The proposed system architecture could be used for real-time video indexing and retrieval, content summarization, content delivery, surveillance, personalized services, etc. The descriptor extractor IP core, which is part of the VCDS, implements four MPEG-7 visual descriptors and was designed for ASIC implementation in CMOS 0.35 mu m, which is a novel solution for a real-time content description problem. The proposed hardware architecture splits the computational burden into several threads, so that calculations are made simultaneously in order to improve the system's speed. These methods make the hardware implementation of the most computationally demanding modules of the system more time- and power-efficient. Four different variations of the basic hardware architecture are discussed. New search algorithms based on the VCDS responses are also proposed. Experimental results demonstrate the effectiveness of the hardware architectures, and the new approach to similarity-based searching methods.
C1 [Kapela, Rafal; Sniatala, Pawel; Rybarczyk, Andrzej] Poznan Univ Tech, Fac Comp Sci & Management, Dept Comp Engn, PL-60965 Poznan, Poland.
C3 Poznan University of Technology
RP Kapela, R (corresponding author), Poznan Univ Tech, Fac Comp Sci & Management, Dept Comp Engn, 3A Piotrowo St, PL-60965 Poznan, Poland.
EM Rafal.Kapela@put.poznan.pl; Pawel.Sniatala@put.poznan.pl;
   Andrzej.Rybarczyk@put.poznan.pl
RI Sniatala, Pawel/M-7801-2014; Rybarczyk, Andrzej/M-1041-2014; Kapela,
   Rafal/M-8202-2014
OI Kapela, Rafal/0000-0002-0624-7608
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 159383 ISOIEC
   [Anonymous], 2006, P 2006 IEEE INT WORK, DOI DOI 10.1109/HAVE.2006.283780
   Bae B, 2003, TENCON IEEE REGION, P1136
   Boyd JE, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, PROCEEDINGS, P798, DOI 10.1109/ITCC.2004.1286567
   Chang JY, 2004, IEEE IMAGE PROC, P2813
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   DOLLER M, 2002, P 10 ACM INT C MULT, P85
   Ebrahimi T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P600, DOI 10.1109/ICIP.2001.958190
   FERMAN AM, 2001, CORE EXPT GROUP OF F
   Kapela R, 2006, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE MIXED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, P675, DOI 10.1109/MIXDES.2006.1706669
   Kapela R, 2007, J SYST ARCHITECT, V53, P602, DOI 10.1016/j.sysarc.2006.12.004
   KASUTANI E, 2001, INT C IM PROC ICIP 2
   Koenen R, 2000, SIGNAL PROCESS-IMAGE, V16, P5, DOI 10.1016/S0923-5965(00)00014-X
   KREPPA M, 2006, MDCT IP CORE SPECIFI
   Martín O, 2001, ELECTRON LETT, V37, P1050, DOI 10.1049/el:20010704
   NDJIKINYA P, 2004, 1 EUR C VIS MED PROD, P95
   NDJIKINYA P, 2000, SUBJECTIVE EVALUATIO, P13
   SAVAKIS A, 2004, P MIX DES INT CIRC S, V1, P199
   SAVAKIS A, 2003, P MIX DES INT CIRC S, V1, P625
   SNIATALA P, 2007, EFFICIENT HARDWARE A, P1672
   STEIGER O, 2001, SMART CAMERA MPEG 7
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   XING B, 2006, HARDWARE MPEG 7 COMP
   XU H, 2002, P WORLD AUT C, P357
NR 25
TC 5
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 119
EP 150
DI 10.1007/s11042-010-0493-3
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700006
DA 2024-07-18
ER

PT J
AU Xiang, YJ
   Feng, LM
   Xie, SL
   Zhou, ZH
AF Xiang, Youjun
   Feng, Liangmou
   Xie, Shengli
   Zhou, Zhiheng
TI An efficient spatio-temporal boundary matching algorithm for video error
   concealment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Error concealment; Motion vector; Boundary matching
AB The highly error-prone channel and limited computational power of terminal devices necessitates the implementation of robust yet simple error concealment. Error concealment techniques commonly make use of the surrounding correctly received image data or motion information for concealment. In this paper, we propose an efficient spatio-temporal boundary matching algorithm (ESTBMA) which exploits both spatial and temporal information to reconstruct the lost motion vectors (MV) and also introduces a new side smoothness measurement. The motion vector corresponding to the minimum of the distortion function is used as the estimation of motion vector of the lost block. Compared to the classical average motion vector (AVMV), median motion video (MMV) and boundary matching algorithm (BMA), simulation results show that the proposed algorithm can recover the higher quality image on both subjective visual evaluation and objective numerical metrics.
C1 [Xiang, Youjun; Feng, Liangmou; Xie, Shengli; Zhou, Zhiheng] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
C3 South China University of Technology
RP Xiang, YJ (corresponding author), S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
EM yjxiang@scut.edu.cn
RI liu, yi/GXE-9662-2022; Liu, Yi/HTN-4916-2023; Xie,
   Shengli/AAZ-6354-2020; Zhou, zhiheng/HNC-4591-2023
CR Chen SY, 2009, IEEE T CIRC SYST VID, V19, P422, DOI 10.1109/TCSVT.2009.2013504
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   FENG J, 1996, P IEEE INT C COMM JU, V3, P1406
   HASKELL P, 1992, P ICASSP, V3, P545
   Kim ET, 1999, SIGNAL PROCESS, V73, P291, DOI 10.1016/S0165-1684(98)00242-4
   LAM WM, 1993, P ICASSP, V5, P417
   Lie WN, 2006, IEEE T CIRC SYST VID, V16, P982, DOI 10.1109/TCSVT.2006.879119
   Ng E. S., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P249
   SUN H, 1992, IEEE T CONSUM ELECTR, V38, P108, DOI 10.1109/30.156671
   Triantafyllidis GA, 2002, IEEE T CIRC SYST VID, V12, P877, DOI 10.1109/TCSVT.2002.804880
   Tsai TH, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P433
   Tso CD, 2003, INTERNATIONAL CONFERENCE ON POLITICS AND INFORMATION SYSTEMS: TECHNOLOGIES AND APPLICATIONS, PROCEEDINGS, P55
   Wang Y, 2002, PROCEEDINGS OF THE 2002 2ND IEEE CONFERENCE ON NANOTECHNOLOGY, P29, DOI 10.1109/NANO.2002.1032116
   Zhou Zhi-heng, 2006, Acta Electronica Sinica, V34, P628
NR 14
TC 6
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 91
EP 103
DI 10.1007/s11042-009-0457-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500008
DA 2024-07-18
ER

PT J
AU Dumic, E
   Grgic, S
   Grgic, M
AF Dumic, Emil
   Grgic, Sonja
   Grgic, Mislav
TI Comparison of HDTV formats using objective video quality measures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality; PSNR; VQM; SSIM; TSCES; HDTV; H.264/AVC; RMSE;
   Correlation
AB In this paper we compare some of the objective quality measures with subjective, in several HDTV formats, to be able to grade the quality of the objective measures. Also, comparison of objective and subjective measures between progressive and interlaced video signal will be presented to determine which scanning emission format is better, even if it has different resolution format. Several objective quality measures will be tested, to examine the correlation with the subjective test, using various performance measures.
C1 [Dumic, Emil; Grgic, Sonja; Grgic, Mislav] Univ Zagreb, Fac Elect Engn & Comp, Dept Wireless Commun, HR-10000 Zagreb, Croatia.
C3 University of Zagreb
RP Dumic, E (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Dept Wireless Commun, Unska 3-12, HR-10000 Zagreb, Croatia.
EM emil.dumic@fer.hr
RI Dumic, Emil/U-9142-2019; Grgic, Mislav/B-6128-2008
OI Dumic, Emil/0000-0002-0262-5595; Grgic, Mislav/0000-0001-6230-3734;
   Grgic, Sonja/0000-0002-0802-3288
FU Ministry of Science, Education and Sports of the Republic of Croatia
   [036-0361630-1635, 036-0982560-1643]
FX The work described in this paper was conducted under the research
   projects: "Picture Quality Management in Digital Video Broadcasting"
   (036-0361630-1635), and "Intelligent Image Features Extraction in
   Knowledge Discovery Systems" (036-0982560-1643), supported by the
   Ministry of Science, Education and Sports of the Republic of Croatia.
CR [Anonymous], 2000, DCT BASED VIDEO QUAL
   [Anonymous], 1988, Eye, brain, and vision
   [Anonymous], 2003, ADV VID COD GEN AUD
   [Anonymous], 421M2006 SMPTE
   Dennis J.E., 1977, STATE ART NUMERICAL, P269
   DUMIC E, 2009, P 51 INT S ELMAR 200
   *EBU TECHN COMM, 2004, R1122004 EBU TECHN C
   Grgic S., 2004, Journal of Electrical Engineering, V55, P3
   Hauke J., 2007, P MAT TRIAD 2007 C B
   Hoffmann H, 2008, IEEE T BROADCAST, V54, P1, DOI 10.1109/TBC.2008.916833
   Hoffmann H, 2006, IEEE T BROADCAST, V52, P420, DOI 10.1109/TBC.2006.884735
   *ITU R, 2003, BT50011 ITUR
   ITU-R, 2002, BT7095 ITUR
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   Marquadt D.W., 1963, J SOC IND APPL MATH, V11, P441
   MORE JJ, 1983, SIAM J SCI STAT COMP, V4, P553, DOI 10.1137/0904038
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   *SMPTE, 2005, 274M2005 SMPTE
   *SMPTE, 2001, 296M2001 SMPTE
   SUEHRING K, H 264 AVC SOFTWARE C
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   UNCOMPRESSED VIDEO S
NR 24
TC 11
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2010
VL 49
IS 3
SI SI
BP 409
EP 424
DI 10.1007/s11042-009-0441-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 608ZF
UT WOS:000278623800002
DA 2024-07-18
ER

PT J
AU Schedl, M
   Pohle, T
AF Schedl, Markus
   Pohle, Tim
TI Enlightening the sun
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User interface; Web mining; Multimedia information retrieval;
   Co-occurrence browser; Evaluation
AB This article presents an approach to browse collections of web pages about music artists by means of descriptive terms and multimedia content. To this end, a user interface called Three-Dimensional Co-Occurrence Browser (3D-COB) is introduced. 3D-COB automatically extracts and weights terms from artist-related web pages. This textual information is complemented with information on the multimedia content found on the web pages. For the user interface of 3D-COB, we elaborated a three-dimensional extension of the Sunburst visualization technique. The hierarchical data to be visualized is obtained by analyzing the web pages for combinations of co-occurring terms that are highly ranked by a term weighting function. We further investigated, in a first user study, different term weighting strategies to generate the visualization. A second user study was carried out to assess ergonomic aspects of 3D-COB, especially its usefulness for gaining a quick overview of a set of web pages and for efficiently browsing within this set.
C1 [Schedl, Markus; Pohle, Tim] Johannes Kepler Univ Linz, Dept Computat Percept, A-4040 Linz, Austria.
C3 Johannes Kepler University Linz
RP Schedl, M (corresponding author), Johannes Kepler Univ Linz, Dept Computat Percept, A-4040 Linz, Austria.
EM markus.schedl@jku.at; tim.pohle@jku.at
FU Austrian Fonds zur Forderung der Wissenschaftlichen Forschung (FWF)
   [L511-N15]
FX This research is supported by the Austrian Fonds zur Forderung der
   Wissenschaftlichen Forschung (FWF) under project number L511-N15.
CR Andrews K., 1998, P IEEE INF VIS 1998
   Dittenbach M, 2002, NEUROCOMPUTING, V48, P199, DOI 10.1016/S0925-2312(01)00655-5
   ECK D, 2007, P 8 INT C MUS INF RE
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Geleijnse G., 2006, P 7 INT C MUS INF RE
   Goto Masataka, 2005, P 6 INT C MUS INF RE
   JOHNSON B, 1991, P 2 IEEE C VIS SAN D
   KNEES P, 2006, P 14 ACM C MULT 2006
   Knees P., 2004, P 5 INT S MUS INF RE
   KOBSA A, 2004, P 10 IEEE S INF VIS
   Kohonen T., 2001, SPRINGER SERIES INFO, V30, P1
   Lamping J, 1995, CHI 95, P401, DOI DOI 10.1145/223904.223956
   MORCHEN F, 2005, P 6 INT C MUS INF RE
   Pampalk E., 2007, P 8 INT C MUS INF RE
   Pampalk E., 2005, P 9 EUR C RES ADV TE
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Schedl M., 2007, P 9 EUR IEEE VGTC S
   Schedl M., 2006, P 7 INT C MUS INF RE
   Sheskin David, 2011, Handbook of Parametric and Nonparametric Statistical Procedures
   Stasko J., 2000, P IEEE INF VIS 2000
   Stone D., 2005, User Interface Design and Evaluation
   VIGNOLI F, 2004, P 5 INT S MUS INF RE
   Walter JorgA., 2002, PROC ACM SIGKDD INT, P123, DOI DOI 10.1145/775047.775065
   Whitman B, 2002, P 2002 INT COMP MUS
   *WIK, 2007, LIST FIL FORM
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   YANG J, 2002, P IEEE S INF VIS 200
   Zadel M., 2004, P 5 INT S MUS INF RE
NR 28
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 101
EP 118
DI 10.1007/s11042-009-0396-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600006
DA 2024-07-18
ER

PT J
AU Wang, XY
   Wu, JF
   Yang, HY
AF Wang, Xiang-Yang
   Wu, Jun-Feng
   Yang, Hong-Ying
TI Robust image retrieval based on color histogram of local feature regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Local feature region; Color histogram; Spatial
   information; Classic transformations
AB Color histograms lack spatial information and are sensitive to intensity variation, color distortion and cropping. As a result, images with similar histograms may have totally different semantics. The region-based approaches are introduced to overcome the above limitations, but due to the inaccurate segmentation, these systems may partition an object into several regions that may have confused users in selecting the proper regions. In this paper, we present a robust image retrieval based on color histogram of local feature regions (LFR). Firstly, the steady image feature points are extracted by using multi-scale Harris-Laplace detector. Then, the significant local feature regions are ascertained adaptively according to the feature scale theory. Finally, the color histogram of local feature regions is constructed, and the similarity between color images is computed by using the color histogram of LFRs. Experimental results show that the proposed color image retrieval is more accurate and efficient in retrieving the user-interested images. Especially, it is robust to some classic transformations (additive noise, affine transformation including translation, rotation and scale effects, partial visibility, etc.).
C1 [Wang, Xiang-Yang; Wu, Jun-Feng; Yang, Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xiang-Yang] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
C3 Liaoning Normal University; Nanjing University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [60773031, 60873222]; Open
   Foundation of State Key Laboratory of Networking and Switching
   Technology of China [SKLNST-2008-1-01]; Open Foundation of State Key
   Laboratory of Information Security of China [03-06]; Open Foundation of
   State Key Laboratory for Novel Software Technology of China [A200702];
   Institutions of Higher Education of China [2008351]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 60773031 & 60873222, the Open Foundation of State
   Key Laboratory of Networking and Switching Technology of China under
   Grant No. SKLNST-2008-1-01, the Open Foundation of State Key Laboratory
   of Information Security of China under Grant No. 03-06, the Open
   Foundation of State Key Laboratory for Novel Software Technology of
   China under Grant No. A200702, and Liaoning Research Project for
   Institutions of Higher Education of China under Grant No. 2008351.
CR [Anonymous], BRIT MACH VIS C
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Castelli V., 2002, Image Databases: Search and Retrieval of Digital Imagery
   Datta AK, 2008, OPT LASER TECHNOL, V40, P1, DOI 10.1016/j.optlastec.2007.04.006
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Gong YH, 1996, MULTIMED TOOLS APPL, V2, P133, DOI 10.1007/BF00672252
   Halawani A, 2004, INT C PATT RECOG, P955, DOI 10.1109/ICPR.2004.1334417
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Lee HY, 2005, LECT NOTES COMPUT SC, V3710, P418
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mustaffa MR, 2008, MALAYS J COMPUT SCI, V21, P1
   PASCHOS G, 2003, IEEE T KNOWL DATA EN, V15
   Saykol E, 2005, IMAGE VISION COMPUT, V23, P1170, DOI 10.1016/j.imavis.2005.07.015
   SIGGELKOW S, 2002, THESIS ALBERTLUDWIGS
   SIGGELKOW S, 2001, LNCS PATTERN RECOGNI, V2191, P9
   Stottinger J., 2007, Proceedings of the 12th Computer Vision Winter Workshop, P83
   Stricker M, 1996, P SOC PHOTO-OPT INS, V2670, P29, DOI 10.1117/12.234802
   Theoharatos C, 2005, IEEE T KNOWL DATA EN, V17, P808, DOI 10.1109/TKDE.2005.85
NR 21
TC 50
Z9 55
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 2
BP 323
EP 345
DI 10.1007/s11042-009-0362-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 604OB
UT WOS:000278287300004
DA 2024-07-18
ER

PT J
AU Ballan, L
   Bertini, M
   Del Bimbo, A
   Serra, G
AF Ballan, Lamberto
   Bertini, Marco
   Del Bimbo, Alberto
   Serra, Giuseppe
TI Video event classification using string kernels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video annotation; Event classification; Bag-of-words; String kernel;
   Edit distance
ID FEATURES; RECOGNITION; CATEGORIES; SEQUENCE
AB Event recognition is a crucial task to provide high-level semantic description of the video content. The bag-of-words (BoW) approach has proven to be successful for the categorization of objects and scenes in images, but it is unable to model temporal information between consecutive frames. In this paper we present a method to introduce temporal information for video event recognition within the BoW approach. Events are modeled as a sequence composed of histograms of visual features, computed from each frame using the traditional BoW. The sequences are treated as strings (phrases) where each histogram is considered as a character. Event classification of these sequences of variable length, depending on the duration of the video clips, are performed using SVM classifiers with a string kernel that uses the Needlemann-Wunsch edit distance. Experimental results, performed on two domains, soccer videos and a subset of TRECVID 2005 news videos, demonstrate the validity of the proposed approach.
C1 [Ballan, Lamberto; Serra, Giuseppe] Univ Florence, Media Integrat & Commun Ctr, Visual Informat & Media Lab, Florence, Italy.
   [Bertini, Marco] Univ Florence, Media Integrat & Commun Ctr, Dept Syst & Informat, Florence, Italy.
   [Del Bimbo, Alberto] Univ Florence, Media Integrat & Commun Ctr, Fdn Res & Innovat, Florence, Italy.
C3 University of Florence; University of Florence; University of Florence
RP Ballan, L (corresponding author), Univ Florence, Media Integrat & Commun Ctr, Visual Informat & Media Lab, Florence, Italy.
EM ballan@dsi.unifi.it; bertini@dsi.unifi.it; delbimbo@dsi.unifi.it;
   serra@dsi.unifi.it
RI Ballan, Lamberto/B-3450-2008; Bertini, Marco/X-1325-2019; Serra,
   Giuseppe/M-3572-2015
OI Ballan, Lamberto/0000-0003-0819-851X; Bertini,
   Marco/0000-0002-1364-218X; Serra, Giuseppe/0000-0002-4269-4501; DEL
   BIMBO, ALBERTO/0000-0002-1052-8322
FU EU [FP6-045547, FP7-222267]
FX This work is partially supported by the EU IST VidiVideo Project
   (Contract FP6-045547) and IM3I Project (Contract FP7-222267). The
   authors thank Filippo Amendola for his support in the preparation of the
   experiments.
CR [Anonymous], 1981, Practical Optimization
   [Anonymous], P INT C COMP VIS ICC
   [Anonymous], P ACM INT WORKSH MUL
   BAHLMANN C, 2002, P INT WORKSH FRONT H
   BALLAN L, 2009, MULTIMEDIA IN PRESS
   BALLAN L, 2009, P IEEE INT WORKSH CO
   Berg C., 1984, Harmonic analysis on semigroups: theory of positive definite and related functions, DOI [DOI 10.1007/978-1-4612-1128-0, 10.1007/978-1-4612-1128-0]
   BERTINI M, 2008, P INT C VIS INF SYST
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   BOSER BE, 1992, P ACM INT WORKSH COM
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHEN J, 2008, P INT C MACH LEARN I
   COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137
   DOLLAR P, 2005, P INT WORKSH VS PETS
   EBADOLLAHI S, 2006, P IEEE INT C MULT EX
   Fergus R, 2003, P INT C COMP VIS PAT
   FERGUS R, 2005, P INT C COMP VIS PAT
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78
   HAUBOLD A, 2007, P ACM INT C IM VID R
   KE Y, 2005, P INT C COMP VIS ICC
   KENNEDY L, 2006, DTO CHALL WORKSH LAR
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   LESLIE C, 2003, P INT C NEUR INF PRO
   Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUSS R, 2008, P INT C NEUR INF PRO
   MIKOLAJCZYK K, 2004, INT J COMPUT VISION, V60, P144
   MORENO PJ, 2003, P INT C NEUR INF PRO
   Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Neuhaus M, 2006, PATTERN RECOGN, V39, P1852, DOI 10.1016/j.patcog.2006.04.012
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Riedel DE, 2008, PATTERN RECOGN, V41, P3481, DOI 10.1016/j.patcog.2008.04.019
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shawe-Taylor John, 2004, KERNEL METHODS PATTE
   WANG F, 2008, P ACM INT C MULT MM
   Xiang T, 2008, COMPUT VIS IMAGE UND, V111, P59, DOI 10.1016/j.cviu.2007.06.004
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   YANG J, 2006, P ACM INT WORKSH INF
   YANG J, 2007, P ACM INT WORKSH MUL
   ZHANG D, 2005, P INT C COM VIS PATT
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   ZHOU X, 2008, P ACM INT C MULT MM
NR 47
TC 24
Z9 25
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 69
EP 87
DI 10.1007/s11042-009-0351-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400005
DA 2024-07-18
ER

PT J
AU Brew, A
   Cunningham, P
AF Brew, Anthony
   Cunningham, Pedraig
TI Combining cohort and UBM models in open set speaker detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker detection; Speaker verification; Gaussian Mixture Models;
   Support Vector Machines; UBM; Cohort
AB In speaker detection it is important to build an alternative model against which to compare scores from the 'target' speaker model. Two alternative strategies for building an alternative model are to build a single global model by sampling from a pool of training data, the Universal Background (UBM), or to build a cohort of models from selected individuals in the training data for the target speaker. The main contribution in this paper is to show that these approaches can be unified by using a Support Vector Machine (SVM) to learn a decision rule in the score space made up of the output scores of the client, cohort and UBM model.
C1 [Brew, Anthony; Cunningham, Pedraig] Univ Coll Dublin, Machine Learning Grp, Sch Informat & Comp Sci, Dublin 2, Ireland.
C3 University College Dublin
RP Brew, A (corresponding author), Univ Coll Dublin, Machine Learning Grp, Sch Informat & Comp Sci, Dublin 2, Ireland.
EM anthony.brew@ucd.ie
OI Cunningham, Padraig/0000-0002-3499-0810
CR [Anonymous], 2 INT C SPOK LANG PR
   [Anonymous], 1998, STAT LEARNING THEORY
   Ariyaeeinia A.M., 1997, EUROSPEECH
   Auckenthaler R, 2000, DIGIT SIGNAL PROCESS, V10, P42, DOI 10.1006/dspr.1999.0360
   Bengio S, 2001, INT CONF ACOUST SPEE, P425, DOI 10.1109/ICASSP.2001.940858
   Bimbot F, 2004, EURASIP J APPL SIG P, V2004, P430, DOI 10.1155/S1110865704310024
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Campbell JP, 1999, INT CONF ACOUST SPEE, P829, DOI 10.1109/ICASSP.1999.759799
   CAMPBELL W, 2004, OD SPEAK LANG REC WO
   CHARLET D, 2008, INTERSPEECH
   Higgins A., 1991, Digital Signal Processing, V1, P89, DOI 10.1016/1051-2004(91)90098-6
   KHARROUBI J, 2001, EUROSPEECH
   LE Q, 2003, ICONP INT C NEUR INF, P181
   LOURADOUR J, 2006, OD SPEAK LANG REC WO
   MAGRINCHAGNOLLE.I, 2000, MULTIMEDIA EXPO ICME, V2, P881
   Moreno PJ, 2004, ADV NEUR IN, V16, P1385
   Reynolds D. A., 1997, EUROSPEECH
   Reynolds DA, 2002, INT CONF ACOUST SPEE, P4072
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Schmidt M, 1996, INT CONF ACOUST SPEE, P105, DOI 10.1109/ICASSP.1996.540301
   STANFORD V, 2003, ICASSP IEEE INT C AC, V4, P128
   STURIM D, 2005, ICASSP IEEE INT C AC, V1, P741
   Sturim DE, 2001, INT CONF ACOUST SPEE, P429, DOI 10.1109/ICASSP.2001.940859
   Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7
   Wan V, 2005, IEEE T SPEECH AUDI P, V13, P203, DOI 10.1109/TSA.2004.841042
   WAN V, 2003, THESIS U SHEFFIELD
   Zhu X, 2006, LECT NOTES COMPUT SC, V4299, P396
NR 28
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 141
EP 159
DI 10.1007/s11042-009-0381-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400009
DA 2024-07-18
ER

PT J
AU Besiris, D
   Makedonas, A
   Economou, G
   Fotopoulos, S
AF Besiris, D.
   Makedonas, A.
   Economou, G.
   Fotopoulos, S.
TI Combining graph connectivity & dominant set clustering for video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summary; Prototype set; Connectivity graph; Dominant set
ID SCHEME
AB The paper presents an automatic video summarization technique based on graph theory methodology and the dominant sets clustering algorithm. The large size of the video data set is handled by exploiting the connectivity information of prototype frames that are extracted from a down-sampled version of the original video sequence. The connectivity information for the prototypes which is obtained from the whole set of data improves video representation and reveals its structure. Automatic selection of the optimal number of clusters and hereafter keyframes is accomplished at a next step through the dominant set clustering algorithm. The method is free of user-specified modeling parameters and is evaluated in terms of several metrics that quantify its content representational ability. Comparison of the proposed summarization technique to the Open Video storyboard, the Adaptive clustering algorithm and the Delaunay clustering approach, is provided.
C1 [Besiris, D.; Makedonas, A.; Economou, G.; Fotopoulos, S.] Univ Patras, Dept Phys, Elect Lab, Rion 26500, Greece.
C3 University of Patras
RP Besiris, D (corresponding author), Univ Patras, Dept Phys, Elect Lab, Rion 26500, Greece.
EM dbes@upatras.gr
OI Economou, George/0000-0001-9938-0768
FU European Social Fund (ESF); Operational Program for Educational and
   Vocational Training II (EPEAEK II); University of Patras
FX This work was financed by the European Social Fund (ESF), Operational
   Program for Educational and Vocational Training II (EPEAEK II), and
   particularly the Program "New graduate programs of University of
   Patras".
CR [Anonymous], D LIB MAG
   BEHZARD S, 1995, P SPIE MULTIMEDIA CO, V2417, P512
   BORECZKY JS, 1996, P INT C STOR RETR ST, V5, P170
   BOVIC AC, 2000, HDB IMAGE VIDEO PROC, V9, P705
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Cooper M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P502, DOI 10.1109/ICME.2005.1521470
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Divakaran A, 2002, IEEE IMAGE PROC, P932
   Dufaux F, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P275, DOI 10.1109/ICIP.2000.899354
   GIBSON DNC, 2002, P 15 INT C VIS INT
   Girgensohn A, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P756, DOI 10.1109/MMCS.1999.779294
   Gong YH, 2003, MULTIMEDIA SYST, V9, P157, DOI 10.1007/s00530-003-0086-3
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Laskaris NA, 2008, PATTERN RECOGN, V41, P2630, DOI 10.1016/j.patcog.2008.02.005
   LATECKI LJ, 2001, P MULT SIGN PROC C F
   LIU T, 2002, P INT C MULT EXP ICM
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Liu TY, 2004, PATTERN RECOGN LETT, V25, P1451, DOI 10.1016/j.patrec.2004.05.020
   MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Ueda H., 1991, P SIGCHI C HUMAN FAC, P343
   Weibull J.W., 1997, Evolutionary Game Theory
   Xiong W, 1997, MACH VISION APPL, V10, P51, DOI 10.1007/s001380050059
   YAHIAOUI I, 2001, P CBMIR C
   Yeung MM, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA338
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
   Zhang JP, 2004, CHINESE MED J-PEKING, V117, P120
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 30
TC 24
Z9 27
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 2
BP 161
EP 186
DI 10.1007/s11042-009-0277-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 464ED
UT WOS:000267487100001
DA 2024-07-18
ER

PT J
AU Ozeki, M
   Maeda, S
   Obata, K
   Nakamura, Y
AF Ozeki, Motoyuki
   Maeda, Shunichi
   Obata, Kanako
   Nakamura, Yuichi
TI Virtual assistant: enhancing content acquisition by eliciting
   information from humans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Semantic Ambient Media Experience
CY OCT 31, 2008
CL Vancouver, CANADA
SP ACM
DE Semantic ambient media; Embodied agent; Video production; Cooking
AB In this paper, we propose the "Virtual Assistant," a novel framework for supporting knowledge capturing in videos. The Virtual Assistant is an artificial agent that simulates a human assistant shown in TV programs and prompts users to provide feedback by asking questions. This framework ensures that sufficient information is provided in the captured content while users interact in a natural and enjoyable way with the agent. We developed a prototype agent based on a chatbot-like approach and applied it to a daily cooking scene. Experimental results demonstrate the potential of the Virtual Assistant framework, as it allows a person to provide feedback easily with few interruptions and elicits a variety of useful information.
C1 [Ozeki, Motoyuki; Maeda, Shunichi; Obata, Kanako; Nakamura, Yuichi] Kyoto Univ, Acad Ctr Comp & Media Studies, Sakyo Ku, Kyoto, Japan.
C3 Kyoto University
RP Nakamura, Y (corresponding author), Kyoto Univ, Acad Ctr Comp & Media Studies, Sakyo Ku, Kyoto, Japan.
EM yuichi@media.kyoto-u.ac.jp
CR Abowd G., 2000, Proc. Conf. Human Factors in Computing Systems (CHI), P215, DOI DOI 10.1145/633292.633416
   CHI P, 2007, HUM FACT COMP SYST, P2333
   Davis Marc, 2003, P 11 ANN ACM INT C M, P602, DOI [10.1145/957013.957141, DOI 10.1145/957013.957141]
   HAMADA R, 2004, P PAC RIM C MULT, V2, P657
   Hashimoto A., 2008, P INF PROCESS MANAGE, P848
   Imai M, 2003, IEEE T IND ELECTRON, V50, P636, DOI 10.1109/TIE.2003.814769
   Ishii Hiroshi, 1998, C HUMAN FACTORS COMP, P173
   ISHII R, 2006, LECT NOTES COMPUTER, P458
   JU W, 2001, CHI 2001, P269
   LUGMAYR A, 2007, TICSP ADJ P EUROITV, P89
   Munguia Tapia E., 2004, P PERVASIVE 2004, P158, DOI DOI 10.1007/978-3-540-24646-6_
   NAKAUCHI Y, 2005, P INT C INT ROB SYST
   Ozeki M, 2005, IEE P-VIS IMAGE SIGN, V152, P437, DOI 10.1049/ip-vis:20045058
   Pinhanez CS, 1997, APPL ARTIF INTELL, V11, P285, DOI 10.1080/088395197118163
   ROUGVIE M, 2007, TICSP ADJ P EUROITV, P304
   SIIO I, 2004, HUM FACT COMP SYST, P1554
   Tran QT, 2005, INT FED INFO PROC, V178, P15
   Yamazaki T, 2004, FIRST INTERNATIONAL CONFERENCE ON TESTBEDS AND RESEARCH INFRASTRUCTURES FOR THE DEVELOPMENT OF NETWORKS AND COMMUNITIES, PROCEEDINGS, P54
NR 18
TC 2
Z9 2
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 3
BP 433
EP 448
DI 10.1007/s11042-009-0284-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 474WB
UT WOS:000268313900006
DA 2024-07-18
ER

PT J
AU Singh, VK
   Pirsiavash, H
   Rishabh, I
   Jain, R
AF Singh, Vivek K.
   Pirsiavash, Hamed
   Rishabh, Ish
   Jain, Ramesh
TI Towards Environment-to-Environment (E2E) multimedia communication
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Semantic Ambient Media Experience
CY OCT 31, 2008
CL Vancouver, CANADA
SP ACM
DE Environment-to-Environment communication; Connecting environments;
   Experiential interaction; Telepresence
ID SEMANTIC WEB; VIDEO
AB We present an approach to connect multiple remote environments over web for natural interaction among people and objects. Focus of current communication and telepresence systems severely restrict user affordances in terms of movement, interaction, peripheral vision, spatio-semantic integrity and even information flow. These systems allow information transfer rather than experiential interaction. We propose Environment-to-Environment (E2E) as a new paradigm for communication which allows users to interact in natural manner using text, audio, and video by connecting environments. Each Environment is instrumented using as many different types of sensors as may be required to detect presence and activity of objects. This object position and activity information is used by a scalable event-based multimodal information system called EventServer to share the appropriate experiential information with other environments as well as to present incoming multimedia information on right displays and speakers. This paper describes the design principles for E2E communication, discusses system architecture, and gives our experience in implementing prototypes of such systems in telemedicine and office collaboration applications. We also discuss the research challenges and a road-map for creating more sophisticated E2E applications in near future.
C1 [Singh, Vivek K.; Pirsiavash, Hamed] Univ Calif Irvine, Dept Comp Sci ICS, Irvine, CA 92717 USA.
   [Rishabh, Ish; Jain, Ramesh] Univ Calif Irvine, Bren Sch ICS, Irvine, CA USA.
   [Rishabh, Ish] Ctr Artificial Intelligence & Robot, Bangalore 560001, Karnataka, India.
   [Jain, Ramesh] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Jain, Ramesh] Univ Calif San Diego, San Diego, CA 92103 USA.
C3 University of California System; University of California Irvine;
   University of California System; University of California Irvine;
   Defence Research & Development Organisation (DRDO); Center for
   Artificial Intelligence & Robotics (CAIR); University of Michigan
   System; University of Michigan; University of California System;
   University of California San Diego
RP Singh, VK (corresponding author), Univ Calif Irvine, Dept Comp Sci ICS, Irvine, CA 92717 USA.
EM singhv@uci.edu
CR [Anonymous], MULTIMEDIA 07
   ATREY PK, 2005, VSSN 05 P ACM INT WO
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   BLY SA, 1993, COMMUN ACM, V36, P28, DOI 10.1145/151233.151235
   BOLL S, 2003, ETP 03, P21
   CHASTINE JW, 2007, GI 07, P207
   DESILVA GC, 2005, MULTIMEDIA 05, P820
   Gaver W., 1992, P ACM C HUMAN FACTOR, P27, DOI [DOI 10.1145/142750.142754, 0.1145/142750.142754]
   GREGERSEN H, 2006, APCCM 06, P35
   HEATH C, 1992, P CHI 92, P651
   Jain R, 2003, PROC INT CONF DATA, P8, DOI 10.1109/ICDE.2003.1260778
   JAIN R., 2003, ACM SIGMM WORKSHOP E, P1
   JOUPPI NP, 2004, MULTIMEDIA 04, P860
   Kankanhalli MS, 2006, IEEE T MULTIMEDIA, V8, P947, DOI 10.1109/TMM.2006.879875
   Katkere A, 1997, MULTIMEDIA SYST, V5, P69, DOI 10.1007/s005300050043
   Kelly P., 1995, PROC 3 ACE INT C MUL, P201
   Kidd CD, 1999, LECT NOTES COMPUT SC, V1670, P191
   Liu W., 2007, Proceedings of the 2nd International Conference on Digital Interactive Media in Entertainment and Arts, P65, DOI [DOI 10.1145/1306813.1306833, 10.1145/1306813, DOI 10.1145/1306813]
   Majumder A, 2005, ACM T GRAPHIC, V24, P118, DOI 10.1145/1037957.1037964
   MARK G, 2003, P EUR C COMP SUPP CO, P14
   MARK G, 2001, P IEEE WORKSH ADV CO
   MCCANNE S, 1995, MULTIMEDIA 95, P511
   Nguyen D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1465
   PACKARD H, 2007, HP HALO OVERVIEW
   PIRSIAVASH H, 2009, WORKSH MED ARTS SCI
   Ponnekanti SR, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P11, DOI 10.1109/PERCOM.2003.1192722
   RASKAR R, 1999, VISUALIZATION 99
   RASKAR R, 1998, SIGGRAPH 98, P179
   ROMAN M, 2000, EW 9, P229
   SAINI M, 2008, ACM MULT C
   SAWCHUK AA, 2003, ETP 03, P110
   SCHOOLER E, 1991, DISTRIBUTED ARCHITEC
   *SECONDLIFE, 2009, SECONDLIFE HOM
   SELLEN BBA, 1992, P CHI 92, P651
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   SHEPPARD R, 2007, MULTIMEDIA 07, P1085
   Sheth A, 2008, IEEE INTERNET COMPUT, V12, P78, DOI 10.1109/MIC.2008.87
   SINGH VK, 2008, 1 ACM INT WORKSH SEM, P31
   Stults R., 1986, Media Space
   Vertegaal R, 2000, PROC GRAPH INTERF, P95
   Vertegaal R., 2003, P SIGCHI C HUM FACT, P521
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Westermann U, 2006, INT J SEMANT WEB INF, V2, P1, DOI 10.4018/jswis.2006040101
   Yang E, 2007, EMOTION, V7, P882, DOI 10.1037/1528-3542.7.4.882
NR 45
TC 1
Z9 1
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 3
BP 361
EP 388
DI 10.1007/s11042-009-0281-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 474WB
UT WOS:000268313900003
DA 2024-07-18
ER

PT J
AU Kim, N
   Kim, J
   Uram, TD
AF Kim, Namgon
   Kim, JongWon
   Uram, Thomas D.
TI A hybrid multicast connectivity solution for multi-party collaborative
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Application-layer multicast; Multicast connectivity; UDP multicast
   tunneling protocol; Multicast island; Advanced collaboration environment
AB In multi-party collaborative environments, a group of users can share multiple media streams via IP multicasting. However, despite of the efficiency of IP multicast, it is not widely available and alternative application-layer multicast approaches are introduced. Application-layer multicast is advantageous, however, it incurs additional processing delays. In this paper, we present a new hybrid-style application-layer multicast solution that satisfies both network efficiency and easy deployment. We achieve this goal by connecting multicast islands through UDP tunnels employing UMTP (UDP multicast tunneling protocol). We also design a MPROBE protocol to remove multicast loop among multicast island in real Internet. We verify the feasibility of the proposed solution by implementing a prototype tool, AG Connector, that works on Access Grid multi-party collaborative environment.
C1 [Kim, Namgon; Kim, JongWon] GIST Networked Media Lab, Kwangju 500712, South Korea.
   [Uram, Thomas D.] Argonne Natl Lab, Argonne, IL 60439 USA.
C3 Gwangju Institute of Science & Technology (GIST); United States
   Department of Energy (DOE); Argonne National Laboratory
RP Kim, J (corresponding author), GIST Networked Media Lab, 1 Oryong Dong, Kwangju 500712, South Korea.
EM ngkim@nm.gist.ac.kr; jongwon@nm.gist.ac.kr; turam@mcs.anl.gov
FU Ministry of Knowledge Economy, Korea [IITA-2009-C1090-0902-0006]; US.
   Department of Energy [W-31-109-Eng-38]
FX This research was supported by the Ministry of Knowledge Economy, Korea,
   under the Information Technology Research Center support program
   supervised by the Institute of Information Technology Advancement (grant
   number IITA-2009-C1090-0902-0006). We thank the Futures Laboratory and
   Access Grid team at Argonne National Laboratory and The University of
   Chicago for their support. Thomas Uram's and Namgon Kim's effort has
   been provided in part by the US. Department of Energy under Contract
   W-31-109-Eng-38. Also, we would like to appreciate JaeSeung Kwak and
   JeongHoon Moon at Korea Institute of Science and Technology Information
   (KISTI) for interesting comments, encouragements, and feedbacks.
CR *AG CONN, 2009, AG CONN HOM
   *ANL FUT LAB, 2009, ACC GRID TOOLK VERS
   [Anonymous], 1112 RFC INT ENG TAS
   BANERJEE S, 2003, P IEEE INF SAN FRANC
   BANERJEE S, 2002, P ACM SIGCOMM PITTSB
   BUFORD J, 2006, SAM SCAL AD MULT RG
   CHAWATHE Y, 2000, P IEEE INF TEL AV MA
   CHU YH, 2000, P ACM SIGM SANT CLAR
   FINLAYSON R, 2003, UDP MULTICA IN PRESS
   FRANCIS P, YOID EXTENDING MULTI
   Hosseini M, 2007, IEEE COMMUN SURV TUT, V9, P58, DOI 10.1109/COMST.2007.4317616
   *IFST, 2009, IFST HOM
   *INTERNET2 MULT WO, 2007, INTERNET2 IPV4 MULT
   *ITU T, 2004, X603 ITUT
   Jannotti J, 2000, P USENIX S OP SYST D
   KIM N, 2006, P SPIE ITCOM 2006 BO
   KIM N, 2007, P IEEE WORKSH PEER T
   LAO L, 2005, P IEEE INF MIAM MARC
   *MCS FUT LAB, 2003, BRIDG SERV DES
   *NETF, 2009, NETF IPT PROJ
   PENDARAKIS D, 2001, P USENIX S INT TECHN
   *RTP TOOLS, 2009, RTP TOOLS HOM
   *RTPREPLICATE, 2009, RTPREPLICATE HOM
   Zhang BC, 2006, COMPUT NETW, V50, P781, DOI 10.1016/j.comnet.2005.07.016
NR 24
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2009
VL 44
IS 1
BP 17
EP 37
DI 10.1007/s11042-009-0266-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 457KJ
UT WOS:000266926600002
DA 2024-07-18
ER

PT J
AU Pellan, B
   Concolato, C
AF Pellan, Benoit
   Concolato, Cyril
TI Authoring of scalable multimedia documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia scalability; Scalable documents; Content adaptation
ID MODEL; ADAPTATION
AB With the diversity of usage conditions affecting the consumption of multimedia content, the adaptation of dynamic and interactive multimedia presentations is essential. The challenge consists in allowing a multimedia presentation to adapt in all its dimensions: spatially, temporally and interactively, without lessening its attractiveness and still giving the author the control over adapted versions. Additionally, the authoring of adaptable content should not increase the complexity of authoring. To address this challenge, we propose to transpose the concept of scalability to the world of multimedia documents by introducing the so-called Scalable MSTI model. In this paper, we show the properties of this model and how, from an authoring point of view, scalable multimedia documents can be created to address a wide range of usage conditions.
C1 [Pellan, Benoit; Concolato, Cyril] TELECOM ParisTech, Inst TELECOM, CNRS, LTCI, Paris, France.
C3 Centre National de la Recherche Scientifique (CNRS); IMT - Institut
   Mines-Telecom; Institut Polytechnique de Paris; Telecom Paris; IMT
   Atlantique
RP Pellan, B (corresponding author), TELECOM ParisTech, Inst TELECOM, CNRS, LTCI, Paris, France.
EM Benoit.Pellan@telecom-paristech.fr; Cyril.Concolato@telecom-paristech.fr
CR Andersson O., 2006, Scalable Vector Graphics (SVG) Tiny 1.2 Specification
   [Anonymous], 2001, DSV IS
   [Anonymous], P UIST 05
   BES F, 2001, P 8 C MULT MOD MMM A, P229
   Bilasco I, 2005, MULTIMED TOOLS APPL, V25, P361, DOI 10.1007/s11042-005-6540-9
   Boll S, 2001, IEEE T KNOWL DATA EN, V13, P361, DOI 10.1109/69.929895
   Borning A, 2000, MULTIMEDIA SYST, V8, P177, DOI 10.1007/s005300000043
   Bulterman D, 2005, SYNCHRONIZED MULTIME
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Decneut S, 2004, IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P682, DOI 10.1109/ICWS.2004.1314799
   DELTOUR R, 2006, P 1 INT WORKSH BUILD
   *ISO IEC, 14496112005 ISOIEC 2
   Jourdan M., 1998, Proceedings ACM Multimedia 98, P267, DOI 10.1145/290747.290780
   KIMIAEIASADI M, 2005, P IEEE INT C MULT EX, P362
   Laborie S, 2008, STUD COMPUT INTELL, V93, P157
   MARRIOTT K, 2005, LNCS, V2220, P380
   McCormack C, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P154
   Meijering E, 2002, P IEEE, V90, P319, DOI 10.1109/5.993400
   Metso M, 2001, J VLSI SIG PROC SYST, V29, P115, DOI 10.1023/A:1011131816588
   Nanard M, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P111
   PELLAN B, 2008, P INT C MULT EXP ICM, P389
   Pellan B, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P32
   RANSBURG M, 2008, LNCS, V101, P3
   SCHERP A, 2005, MANAGING MULTIMEDIA, P246
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sidibé M, 2008, SIGNAL IMAGE VIDEO P, V2, P307, DOI 10.1007/s11760-008-0083-2
   Sullivan T, 2000, CUU 2000 CONFERENCE PROCEEDINGS, P139, DOI 10.1145/355460.355549
   VILLARD L, 2002, P 11 INT C WORLD WID, P474, DOI DOI 10.1145/511446.511508
   VILLARD L, 2000, LNCS, V2023, P104
   WIRAG S, 1997, INTERACTIVE DISTRIBU, V1309, P420
NR 30
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2009
VL 43
IS 3
BP 225
EP 252
DI 10.1007/s11042-009-0268-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 450HY
UT WOS:000266392800003
DA 2024-07-18
ER

PT J
AU Pimentel, MD
   Bulterman, DCA
   Soares, LFG
AF Pimentel, Maria da Graca
   Bulterman, Dick C. A.
   Gomes Soares, Luiz Fernando
TI Document engineering approaches toward scalable and structured
   multimedia, web and printable documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web documents; Print documents; Multimedia documents; Scalable
   documents; Document authoring
AB Document engineering is the computer science discipline that investigates systems for documents in any form and in all media. As with the relationship between software engineering and software, document engineering is concerned with principles, tools and processes that improve our ability to create, manage, and maintain documents (http://www.documentengineering.org). The ACM Symposium on Document Engineering is an annual meeting of researchers active in document engineering: it is sponsored by ACM by means of the ACM SIGWEB Special Interest Group. In this editorial, we first point to work carried out in the context of document engineering, which are directly related to multimedia tools and applications. We conclude with a summary of the papers presented in this special issue.
C1 [Bulterman, Dick C. A.] CWI, NL-1098 XG Amsterdam, Netherlands.
   [Pimentel, Maria da Graca] Univ Sao Paulo, Inst Ciencias Matemat & Comp, BR-13560970 Sao Carlos, SP, Brazil.
   [Gomes Soares, Luiz Fernando] Pontificia Univ Catolica Rio de Janeiro, Dept Informat, BR-22453900 Rio De Janeiro, Brazil.
C3 Universidade de Sao Paulo; Pontificia Universidade Catolica do Rio de
   Janeiro
RP Bulterman, DCA (corresponding author), CWI, Sci Pk 123, NL-1098 XG Amsterdam, Netherlands.
EM mgp@icmc.usp.br; dick.bulterman@cwi.nl; lfgs@inf.puc-rio.br
RI Pimentel, Maria G C/D-2875-2009
OI Pimentel, Maria G C/0000-0001-8264-5811
CR [Anonymous], P ACM S DOC ENG
   Bagli S., 2003, P 5 INT S GIS COMP C, P58
   Bertolotti P, 2007, MULTIMED TOOLS APPL, V33, P301, DOI 10.1007/s11042-007-0102-2
   Boyer JM, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P8
   BULTERMAN DCA, 2003, P 2003 ACM S DOC ENG, P32
   CESAR P, 2006, P ACM S DOC ENG, P176
   Cesar P, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P275
   Cesar P, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P1
   Codocedo V, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P110
   COSTA RMR, 2006, P ACM S DOC ENG, P165
   Forward A., 2002, Proceedings of the 2002 ACM symposium on Document engineering, P26, DOI 10.1145/585058.585065
   Geyer W, 2005, MULTIMED TOOLS APPL, V27, P393, DOI 10.1007/s11042-005-3815-0
   Gomez Hidalgo J. M., 2006, P 2006 ACM S DOC ENG, P107, DOI [10.1145/1166160.1166191, DOI 10.1145/1166160.1166191]
   Goularte Rudinei., 2004, Proceedings o f the 2004 ACM symposium on Document engineering, Milwaukee, Wisconsin, USA, P84, DOI DOI 10.1145/1030397.1030414
   Hauglid JO, 2008, MULTIMED TOOLS APPL, V40, P183, DOI 10.1007/s11042-008-0204-5
   Hsu LH, 1999, MULTIMED TOOLS APPL, V8, P11, DOI 10.1023/A:1009643213925
   HUANG C, 2005, P ACM DOCENG 05, P149
   Hwang E, 2003, MULTIMED TOOLS APPL, V21, P103, DOI 10.1023/A:1025502824502
   Jansen J, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P18
   Lumley J, 2005, P 2005 ACM S DOC ENG, P32, DOI DOI 10.1145/1096601.1096615
   Macedo AA, 2008, MULTIMED TOOLS APPL, V37, P93, DOI 10.1007/s11042-007-0131-x
   MUNSON E, 2009, ENCY DATABA IN PRESS
   OLIVEIRA JB, 2008, P ACM DOCENG 08, P141
   Pietriga E., 2001, Proceedings of the ACM Symposium on Document Engineering (DocEng '01), P1, DOI 10.1145/502187.502189
   PIMENTEL MGC, 2006, P ACM S DOC ENG, P92
   QUINT V, 2004, P 2004 ACM S DOC ENG, P115
   Ronnau S, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P52
   Rotard M, 2008, MULTIMED TOOLS APPL, V37, P53, DOI 10.1007/s11042-007-0170-3
   Salminen A., 2001, Proceedings of the ACM Symposium on Document Engineering (DocEng '01), P85, DOI 10.1145/502187.502201
   Schroeder R, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P177
   Shirmohammadi S, 2003, MULTIMED TOOLS APPL, V19, P135, DOI 10.1023/A:1022143111606
   SIMSKE S, 2009, SIGWEB NEWSL     JAN, P1
   Sturgill M, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P263
   Thompson S, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P89
   Weibel N, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P19
   Westermann U, 2005, MULTIMED TOOLS APPL, V27, P291, DOI 10.1007/s11042-005-3810-5
NR 36
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2009
VL 43
IS 3
BP 195
EP 202
DI 10.1007/s11042-009-0288-6
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 450HY
UT WOS:000266392800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Shih, JL
   Chen, HY
AF Shih, Jau-Ling
   Chen, Hong-Yu
TI A 3D model retrieval approach using the interior and exterior 3D shape
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; ART-based elevation descriptor; Shell grid
   descriptor
ID SEARCH
AB In this paper, we will propose a new exterior shape feature, ART-based elevation descriptor (ART-ED), and a new interior shape feature, shell grid descriptor (SGD), for 3D model retrieval. ART-ED describes the elevation information of a 3D model from six different angles. Since ART-ED represents only the exterior contour of a 3D model, SGD is proposed for extracting the interior shape information. Finally, these two proposed features as well as other features are combined in an attempt to improve retrieval. Experimental results show that the proposed methods are superior to other descriptors.
C1 [Shih, Jau-Ling; Chen, Hong-Yu] Chung Hua Univ, Dept Comp Sci & Informat Engn, 707,Sec 2,WuFu Rd, Hsinchu, Taiwan.
C3 Chung Hua University
RP Shih, JL (corresponding author), Chung Hua Univ, Dept Comp Sci & Informat Engn, 707,Sec 2,WuFu Rd, Hsinchu, Taiwan.
EM sjl@chu.edu.tw
RI Chen, Hongyu/JGM-9228-2023
FU National Science Council, Taiwan [NSC 96-2221-E-216-041-MY2]
FX AcknowledgmentsThis research was supported in part by the National
   Science Council, Taiwan under Contract NSC 96-2221-E-216-041-MY2.
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   Assfalg J, 2006, MULTIMED TOOLS APPL, V31, P29, DOI 10.1007/s11042-006-0034-2
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Ip C.Y., 2003, Proc. of the 8th ACM Symposium on Solid Modeling and Applications, Seattle, Washington, USA, P322
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Kuo CT, 2007, PATTERN RECOGN, V40, P742, DOI 10.1016/j.patcog.2006.06.006
   Löffler J, 2000, IEEE INFOR VIS, P82, DOI 10.1109/IV.2000.859741
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Ohbuchi R, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P293, DOI 10.1109/PCCGA.2003.1238271
   Ohbuchi R, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P97, DOI 10.1109/TPCG.2003.1206936
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Reisert M, 2006, COMPUT GRAPH-UK, V30, P197, DOI 10.1016/j.cag.2006.01.025
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shih JL, 2005, ELECTRON LETT, V41, P179, DOI 10.1049/el:20056916
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Super BJ, 2003, PATTERN RECOGN, V36, P69, DOI 10.1016/S0031-3203(02)00023-7
   Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   Yamada A, 2001, FINAL COMMITTEE DRAF
   Yu M, 2003, PROC CVPR IEEE, P656
NR 21
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 43
IS 1
BP 45
EP 62
DI 10.1007/s11042-008-0256-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA VM1FO
UT WOS:000949357100001
DA 2024-07-18
ER

PT J
AU Orozco, M
   Graydon, M
   Shirmohammadi, S
   El Saddik, A
AF Orozco, Mauricio
   Graydon, Matthew
   Shirmohammadi, Shervin
   El Saddik, Abdulmotaleb
TI Experiments in haptic-based authentication of humans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE haptics; human authentication; human-computer interaction
AB With the rapid advancement of the technological revolution, computer technology such as faster processors, advanced graphic cards, and multi-media systems are becoming more affordable. Haptics technology is a force/tactile feedback technology growing in disciplines linked to human-computer interaction. Similar to the increasing complexity of silicon-based components, haptics technology is becoming more advanced. On the other hand, currently available commercial haptics interfaces are expensive, and their application is mostly dedicated to enormous research projects or systems. However, the trend of the market is forcing haptic developers to release products for use in conjunction with current keyboards and mice technologies. Haptics allows a user to touch, fell, manipulate, create, and/or alter simulated three-dimensional objects in a virtual environment. Most of the existing applications of haptics are dedicated to hone human physical skills such as sensitive hardware repair, medical procedures, handling hazardous substances, etc. These skills can be trained in a realistic virtual world, and describe human behavioural patterns in human-computer interaction environments. The measurement of such psychomotor patterns can be used to verify a person's identity by assessing unique-to-the-individual behavioural attributes. This paper explores the unique behaviour exhibited by different users interacting with haptic systems. Through several haptic-based applications, users' physical attributes output data from the haptic interface for use in the construction of a biometric system.
C1 [Orozco, Mauricio; Graydon, Matthew; Shirmohammadi, Shervin; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
C3 University of Ottawa
RP Orozco, M (corresponding author), Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
EM morozco@mcrlab.uottawa.ca; shervin@mcrlab.uottawa.ca;
   abed@mcrlab.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012; /D-4159-2009
OI Shirmohammadi, Shervin/0000-0002-3973-4445; /0000-0002-7690-8547
CR ADLER A, 2005, BIOM CONS C WASH DC
   Brömme A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P17
   El Saddik A, 2007, IEEE T INSTRUM MEAS, V56, P895, DOI 10.1109/TIM.2006.887174
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   Hale KS, 2004, IEEE COMPUT GRAPH, V24, P33, DOI 10.1109/MCG.2004.1274059
   IMMERSION I, 1995, LAPAROSCOPIC IMPULSE
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   JOYCE R, 1990, COMMUN ACM, V33, P168, DOI 10.1145/75577.75582
   KAHOL K, 2005, T COMPUTATIONAL LOGI, V5, P1
   Lexa M., 2004, Useful Facts about the Kullback-Leibler discrimination distance
   Monrose F., 1997, Proc. 4th ACM Conf. Comput. Commun. Secur.-CCS, P48, DOI 10.1145/266420.266434
   Orozco M., 2005, P 13 ANN ACM INT C M
   OROZCO M, 2005, P IEEE IMTC 2005 INS
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Qu T, 2003, 2ND IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2003, P83
   *SENSABLE, FREEFORM CONC SENSAB
   Shannon C. E., BELL SYSTEM TECHNICA, V27, P623
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SIGANOS D, 1996, NEURAL NETWORKS MED
   WAYMAN JL, 1999, NATL BIOMETRIC TEST, V1
   Witten I. H., 2005, DATA MINING PRACTICA
   ZIEGLER R, 1995, LECT NOTES COMPUTER, V905, P282
   ZORCOLO A, 2000, MED MEETS VIRTUAL RE, P96
NR 23
TC 10
Z9 12
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2008
VL 37
IS 1
BP 73
EP 92
DI 10.1007/s11042-007-0169-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 261AT
UT WOS:000253052200006
OA Bronze
DA 2024-07-18
ER

PT J
AU Rotard, M
   Taras, C
   Ertl, T
AF Rotard, Martin
   Taras, Christiane
   Ertl, Thomas
TI Tactile web browsing for blind people
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE accessibility; haptics; tactile graphics; web browsers
AB Information on the World Wide Web becomes more and more important for our society. For blind people this is a chance to access more information for their everyday life. In this paper we propose novel methods to present web pages including graphical information on a tactile output device. We present a Mozilla Firefox Extension for the tactile rendering of web pages and for the handling of user interactions. This approach benefits from the Firefox built-in web page handling including parsing of HTML documents, formatting with cascading style sheets (CSS), handling of dynamic web content controlled by JavaScript code, etc. Graphical information can be explored and filtered interactively in a special mode for raster images and Scalable Vector Graphics (SVG). Mathematical expressions encoded in the mathematical markup language (MathML) are transformed directly into LaTeX or into a notation for blind people. The tactile web browser supports feedback that is provided via voice output.
C1 [Rotard, Martin; Taras, Christiane; Ertl, Thomas] Univ Stuttgart, Visualizat & Interact Syst Inst, D-70569 Stuttgart, Germany.
C3 University of Stuttgart
RP Rotard, M (corresponding author), Univ Stuttgart, Visualizat & Interact Syst Inst, Univ Str 38, D-70569 Stuttgart, Germany.
EM rotard@vis.uni-stuttgart.de; taras@vis.uni-stuttgart.de;
   ertl@vis.uni-stuttgart.de
CR [Anonymous], P 3 INT ACM C ASS TE
   [Anonymous], JAWS WIND
   Berlin Brent, 1969, Basic Color Terms: Their Universality and Evolution
   Buyukkokten O, 2002, ACM T INFORM SYST, V20, P82, DOI 10.1145/503104.503109
   CHISHOLM W, 1999, WEB ACCESSIBILITY IN
   Christian K., 2000, DESIGN HAPTIC TACTIL
   DEWITT JC, 1998, P TECHN PERS DIS C C
   Diepstraten J, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P454, DOI 10.1109/CGI.2004.1309247
   Earl CL, 1999, J VISUAL IMPAIR BLIN, V93, P174, DOI 10.1177/0145482X9909300306
   GOBL C, 2002, P IEEE WORKSH SPEECH, P1
   GUNDERSON J, 1997, P RESNA ANN C
   KARSHMER AI, 2004, P ACM SIGACCESS C CO
   KAWAI Y, 1996, P 2 ANN ACM C ASS TE, P45
   KOCHANEK D, 1990, THESIS U STUTTGART
   KOTTAPALLY K, 2002, ACM SIGCAPH COMPUTER, P73
   KURZE M, 1997, TAGUNGSBAND SOFTWARE
   KURZE M, 1999, THESIS FREIE U BERLI
   MCLAREN K, 1976, J SOC DYERS COLOURIS
   *MOZ ACC PROJ, 2007, SEAM CROSS REF
   *OP SOFTW ASA, 2007, OP SMALL SCREEN REND
   Petrie H., 1997, P 8 ACM C HYPERTEX, P48
   PONTELLI E, 2002, P 5 INT ACM C ASS TE
   ROTARD M, 2003, P HCI INT C, P1325
   ROTARD M, 2004, P SVG OP C
   ROTARD M, 2004, P 9 INT C COMP HELP, P725
   Rotard M., 2005, P 16 ACM C HYP HYP
   ROTARD M, 2006, TACTILE 3D GRAPHICS
   Schweikhardt W., 1980, Information Processing 80. Proceedings of the IFIP Congress 80, P951
   SCHWEIKHARDT W, 1984, TAG INT K REL BLIND
   WEBER G, 1989, THESIS U STUTTGART
   World Wide Web Consortium, 2003, SCAL VECT GRAPH SVG
   ZAJICEK M, 1998, COMPUTERS ASSISTIVE, P161
NR 32
TC 26
Z9 29
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2008
VL 37
IS 1
BP 53
EP 69
DI 10.1007/s11042-007-0170-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 261AT
UT WOS:000253052200005
DA 2024-07-18
ER

PT J
AU Ackerman, MJ
AF Ackerman, Michael J.
TI Next generation networking: distributed multimedia information for
   healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Distributed Multimedia Systems (DMS
   03)/6th International Conference on Visual Information Systems (VIS
   2003)
CY SEP   24, 2003-SEP 26, 2006
CL Miami, FL
DE quality of service; next generation networking; distributed multimedia;
   healthcare; scalable information infrastructure; Internet2; abilene
AB This paper is derived from a keynote address given that the DMS-03 meeting. It chronicles the need and development of next generation networks (NGN) in the United States. Specific organizational examples are derived from the Internet2-Abilene Network. The technical characteristics of a next generation network versus the Internet are discussed. Examples are given from the point of view of the need for a quality of service based network to deliver distributed multimedia healthcare information to the point of need. The concepts of network trust and of a network based scalable information infrastructure for the reliable delivery of distributed multimedia information is also introduced.
C1 Natl Lib Med, Bethesda, MD 20894 USA.
C3 National Institutes of Health (NIH) - USA; NIH National Library of
   Medicine (NLM)
RP Ackerman, MJ (corresponding author), Natl Lib Med, Bethesda, MD 20894 USA.
EM ackerman@nlm.nih.gov
CR *NAT AC, 2000, NATW HLTH PRESCR INT
NR 1
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2007
VL 33
IS 1
BP 5
EP 11
DI 10.1007/s11042-006-0093-4
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 149FZ
UT WOS:000245133800002
DA 2024-07-18
ER

PT J
AU Pinquier, J
   André-Obrecht, R
AF Pinquier, Julien
   Andre-Obrecht, Regine
TI Audio indexing:: primary components retrieval -: Robust classification
   in audio documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE classification; indexing; audio documents; jingle; segmentation;
   duration; entropy; energy; spectral feature
AB This work addresses the soundtrack indexing of multimedia documents. Our purpose is to detect and locate sound unity to structure the audio dataflow in program broadcasts (reports). We present two audio classification tools that we have developed. The first one, a speech music classification tool, is based on three original features: entropy modulation, stationary segment duration (with a Forward-Backward Divergence algorithm) and number of segments. They are merged with the classical 4 Hz modulation energy. It is divided into two classifications (speech/non-speech and music/non-music) and provides more than 90% of accuracy for speech detection and 89% for music detection. The other system, a jingle identification tool, uses an Euclidean distance in the spectral domain to index the audio data flow. Results show that is efficient: among 132 jingles to recognize, we have detected 130. Systems are tested on TV and radio corpora (more than 10 h). They are simple, robust and can be improved on every corpus without training or adaptation.
C1 UPS, CNRS, INP,UMR 5505, Inst Rech Informat Toulouse, F-31062 Toulouse, France.
C3 Universite de Toulouse; Universite Federale Toulouse Midi-Pyrenees
   (ComUE); Universite Toulouse III - Paul Sabatier; Institut National
   Polytechnique de Toulouse; Universite Toulouse 1 Capitole; Universite de
   Toulouse - Jean Jaures; Centre National de la Recherche Scientifique
   (CNRS); CNRS - Institute of Physics (INP)
RP Pinquier, J (corresponding author), UPS, CNRS, INP,UMR 5505, Inst Rech Informat Toulouse, 118 Route Narbonne, F-31062 Toulouse, France.
EM Julien.Pinquier@irit.fr; Regine.Andre-Obrecht@irit.fr
RI PINQUIER, Julien/HGB-7599-2022
OI PINQUIER, Julien/0000-0003-1556-1284
CR AIGRAIN P, 1997, INTELLIGENT MULTIMED, P159
   AMARAL R, 2001, EUR C SPEECH COMM TE
   ANDREOBRECHT R, 1988, IEEE T AUDIO SPEECH, V36
   ANDREOBRECHT R, 1993, THESIS IRISA
   ANDREOBRECHT R, 1997, INT C AUD SPEECH SIG, P989
   Atal B. S., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P81
   BIMBOT F, 1988, INT C AUD SPEECH SIG, P425
   CAELEN J, 1979, THESIS UPS TOULOUSE
   Calliope, 1989, La parole et son traitement automatique
   CAMPIONE E, 1998, INT C SPOK LANG PROC, P3163
   Carey MJ, 1999, INT CONF ACOUST SPEE, P149, DOI 10.1109/ICASSP.1999.758084
   CARRIVE J, 2000, P CONT BAS MULT INF
   Foote J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P452, DOI 10.1109/ICME.2000.869637
   FRANZ M, 2001, EUR C SPEECH COMM TE, P287
   GAUVAIN JL, 1999, INT WORKSH CONT BAS, P67
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224
   Johnson N.L., 1970, DISTRIBUTIONS STAT C
   MODDEMEIJER R, 1989, SIGNAL PROCESS, V16, P233, DOI 10.1016/0165-1684(89)90132-1
   PINQUIER J, 2002, INT C SPOK LANG PROC, V3, P2005
   PINQUIER J, 2002, C REC FORM INT ART A, P163
   Rossignol S, 1999, J NEW MUSIC RES, V28, P281, DOI 10.1076/0929-8215(199912)28:04;1-O;FT281
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   SUAUDEAU N, 1994, THESIS IRISA
   Zhang T, 1998, P SOC PHOTO-OPT INS, V3527, P398, DOI 10.1117/12.325832
NR 25
TC 8
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2006
VL 30
IS 3
BP 313
EP 330
DI 10.1007/s11042-006-0027-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 089WS
UT WOS:000240913200006
DA 2024-07-18
ER

PT J
AU Nandan, A
   Parker, MG
   Pau, G
   Salomoni, P
AF Nandan, Alok
   Parker, Michael G.
   Pau, Giovanni
   Salomoni, Paola
TI On index load balancing in scalable P2P media distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE peer-peer systems; load balancing; performance
AB Peer-Peer (P2P) technologies have recently been in the limelight for their disruptive power in particular they have emerged as a powerful multimedia content distribution mechanism. However, the widespread deployment of P2P networks are hindered by several issues, especially the ones that influence end-user satisfaction, including reliability. In this paper, we propose a solution for an efficient and user-oriented keyword lookup service on P2P networks. The proposed mechanism has been designed to achieve reliability via index load balancing and address the scalability issues of extremely popular keywords in the index. The system performance have been analytically derived as well implemented using the OpenDHT framework on PlanetLab.
C1 Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
   Univ Bologna, Dipartimento Sci Informaz, I-40126 Bologna, Italy.
C3 University of California System; University of California Los Angeles;
   University of Bologna
RP Pau, G (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
EM alok@cs.ucla.edu; mgp@cs.ucla.edu; gpau@cs.ucla.edu;
   salomoni@cs.unibo.it
RI Pau, Giovanni/ISU-8786-2023
OI Pau, Giovanni/0000-0002-5798-398X; Pau, Giovanni/0000-0003-2216-7170
CR ABERER K, 2005, LNCS, V3460
   ABERER K, 2003, IC200332 EPFL
   Antony I., 2001, LECT NOTES COMPUTER, P329, DOI DOI 10.1007/3-540-45518-3_18
   BYERS J, 2004, P 16 ACM S PAR ALG A, P54
   CASTRO M, 2002, IEEE J SEL AREA COMM, P20
   GODFREY B, 2004, P IEEE INFOCOM 2004
   Handschuh H, 2001, LECT NOTES COMPUT SC, V2020, P70
   Jones P., 2001, US secure hash algorithm 1 (SHA1) RFC 3174
   Karlin Scott, 2003, JOINT PRINC ACM IEEE
   KARP B, 2003, P 3 INT WORKSH PEER
   MONDAL A, 2003, DAT ENG WORKSH
   PHILIP J, 2001, BIRTHDAY PARADOX
   Rowstron A., 2001, Networked Group Communication. Third International COST264 Workshop, NGC 2001. Proceedings (Lecture Notes in Computer Science Vol.2233), P30
   SAROIU S, 2002, P MULT COMP NETW 200
NR 14
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2006
VL 29
IS 3
BP 325
EP 339
DI 10.1007/s11042-006-0015-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 070XJ
UT WOS:000239559600007
DA 2024-07-18
ER

PT J
AU Basso, A
AF Basso, A
TI Beyond 3G video mobile video telephony: The role of 3G-324M in mobile
   video services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3G video; mobile video telephony; 3G-324M; portals; messaging;
   streaming; video call answering
AB 3G-324M is a 3(rd) Generation Partnership Project (3GPP) umbrella standard for wireless video communications, which was created to satisfy the stringent requirements of real-time, low-delay interactive conversational video services. However it is, in practice, employed today in 3G networks to enable also a variety of multimedia services including messaging, streaming video chat and portals. The unification of this variety of services under the same umbrella standard has significance for the design of the Supporting architectures and the applications that run Such services. In this paper we will discuss the current advantages and limitations of the 3G-324M standard in Supporting Such services.
C1 Univ Victoria, Dept Elect & Comp Engn, Victoria, BC, Canada.
C3 University of Victoria
RP Basso, A (corresponding author), Univ Victoria, Dept Elect & Comp Engn, Victoria, BC, Canada.
EM abasso@ece.uvic.ca
OI Basso, Andrea/0000-0002-0672-8487
NR 0
TC 2
Z9 5
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2006
VL 28
IS 2
BP 173
EP 185
DI 10.1007/s11042-006-6141-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 042MH
UT WOS:000237531600005
DA 2024-07-18
ER

PT J
AU Dong, LG
   Veeravalli, B
AF Dong, LG
   Veeravalli, B
TI GEMA: An object replacement algorithm for cooperative web proxy systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WWW; web caching; replacement algorithm; cooperative caching; proxy
   caching
ID WORKLOAD CHARACTERIZATION; CACHE PERFORMANCE; LRU
AB In this paper, we design and analyze a web object replacement algorithm, referred to as gain-based exchange and migration algorithm (GEMA) suitable for a cooperative World Wide Web proxy caching environment. In a cooperative environment where more than one proxy exists, the replacement algorithms used for single system cache cannot not be directly put in use to achieve an acceptable performance. In this paper, we first present an analytical model, which quantifies the "importance", referred to as object-caching gain, of an object at a cache. This gain is used in making replacement decisions and considers the benefit of caching at local as well as neighboring proxies. Our model efficiently exploits the advantages present in the existing the research contributions on designing replacement strategies for the single-cache environment. Further, with this model, we introduce two basic powerful primitive operations, namely the object exchange and object migration, to improve an overall performance. These two operations are carried out as an outcome of replacement decisions based on the comparison of gains among objects. Thus, the calculation of the gain and deciding on which of the operations to use constitute the main part of our algorithm GEMA. For quantifying the performance of GEMA, we carry out rigorous simulation experiments based on trace-driven and event-driven approaches. Using the event-driven simulation, we comprehensively testify the performance improvement of GEMA under a variety of performance measures such as, average access time of web objects, hit ratio, and byte hit ratio. We compare and analyze our strategies with some of the popular strategies found in the literature. We also highlight some possible extensions to the research contributions in this paper.
C1 Hangzhou Univ Commerce, Hangzhou 310035, Zhejiang, Peoples R China.
   Natl Univ Singapore, Open Source Software Lab, Singapore 119260, Singapore.
C3 Zhejiang Gongshang University; National University of Singapore
RP Dong, LG (corresponding author), Hangzhou Univ Commerce, 149 Jiaogong Rd, Hangzhou 310035, Zhejiang, Peoples R China.
EM donglg@mail.hzic.edu.cn; elebv@nus.edu.sg
CR Afonso M, 1998, COMPUT NETWORKS ISDN, V30, P2093, DOI 10.1016/S0169-7552(98)00255-4
   Aggarwal C, 1999, IEEE T KNOWL DATA EN, V11, P94, DOI 10.1109/69.755618
   Ahuja R. K., 1993, Network flows: theory, algorithms, and applications
   Almeida V, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P92, DOI 10.1109/PDIS.1996.568672
   [Anonymous], 1999, P 2 WORKSH INT SERV
   Arlitt M, 2000, IEEE NETWORK, V14, P30, DOI 10.1109/65.844498
   Arlitt M, 2000, PERFORM EVALUATION, V39, P149, DOI 10.1016/S0166-5316(99)00062-0
   ARLITT M, 1996, P ACM SIGMETRICS 96
   Arlitt MF, 1997, IEEE ACM T NETWORK, V5, P631, DOI 10.1109/90.649565
   ASAKA T, 1999, P IEEE INT C CONTR A, V2, P1620
   Barish G, 2000, IEEE COMMUN MAG, V38, P178, DOI 10.1109/35.841844
   BELLOUM A, 1998, C ISIC CIRA ISAS 98
   Bestavros A, 1997, IEEE CONCURR, V5, P56, DOI 10.1109/4434.580451
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Cao P, 1997, PROCEEDINGS OF THE USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS, P193
   CHANKHUNTHOD A, 1996, P 1996 USENIX TECHN
   DAVISON BD, 1999, P 4 INT WEB CACH WOR
   Dilley J, 1999, IEEE INTERNET COMPUT, V3, P44, DOI 10.1109/4236.806998
   DYKES SG, 1999, P 32 HAW INT C SYST
   FAN L, 1999, P JOINT INT C MEAS M
   Foong AP, 1999, IEEE INTERNET COMPUT, V3, P27, DOI 10.1109/4236.793455
   Gibson GA, 1996, ACM COMPUT SURV, V28, P779, DOI 10.1145/242223.242300
   Inohara S, 1998, INT CON DISTR COMP S, P74, DOI 10.1109/ICDCS.1998.679489
   Jia Wang, 1999, Computer Communication Review, V29, P36, DOI 10.1145/505696.505701
   JIN S, 2000, ACM SIGMETRICS 00 JU
   JIN S, 2000, P 20 INT C DISTR COM, P254
   JIN S, 2000, P 5 INT WORKSH WEB C
   Jung J, 2000, COMPUT NETW, V33, P645, DOI 10.1016/S1389-1286(00)00064-5
   Karger D, 1999, COMPUT NETW, V31, P1203, DOI 10.1016/S1389-1286(99)00055-9
   Krishnamurthy B, 1999, INT CON DISTR COMP S, P332, DOI 10.1109/ICDCS.1999.776535
   Lee D, 1997, 23RD EUROMICRO CONFERENCE - NEW FRONTIERS OF INFORMATION TECHNOLOGY, PROCEEDINGS, P106, DOI 10.1109/EMSCNT.1997.658446
   Leff A, 1996, IEEE T PARALL DISTR, V7, P191, DOI 10.1109/71.485508
   Li B, 1999, IEEE INFOCOM SER, P1282, DOI 10.1109/INFCOM.1999.752146
   LINDEMANN C, 2000, EVALUATING HARDWARE
   Luotonen Ari., 1997, WEB PROXY SERVERS, Vfirst
   MAKPANGOU M, 1999, ICDCS 99 AUST TEX MA
   MARKATOS EP, 1998, P INET 98
   Michel S, 1998, COMPUT NETWORKS ISDN, V30, P2169, DOI 10.1016/S0169-7552(98)00246-3
   Mogul JC, 2000, IEEE NETWORK, V14, P6, DOI 10.1109/65.844495
   MOGUL JC, 955 WRL DIGITAL
   ONEILL EJ, 1993, P ACM SIGMOD
   POVEY D, 1997, P 20 AUSTR COMP SCI
   RABINOVICH M, 1998, COMPUTER NETWORKS IS, V30
   RIZZO L, 2000, IEEE ACM T NETWORKIN, V8
   RODRIGUEZ P, 1999, P WCW 99
   Scheuermann P, 1997, COMPUT NETWORKS ISDN, V29, P997, DOI 10.1016/S0169-7552(97)00032-9
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   SIKELER A, 1988, LECT NOTES COMPUT SC, V303, P336
   Silberschatz Abraham., 1998, OPERATING SYSTEMS CO
   SMARAGDAKIS Y, 1999, MEASUREMENT MODELING
   TEWARI R, 1998, CS9804 UT AUST DEP C
   Watson EF, 1999, DECIS SUPPORT SYST, V25, P309, DOI 10.1016/S0167-9236(99)00017-2
   WILLIAMS S, 1996, C P APPL TECHN ARCH
   Wills CE, 1999, COMPUT NETW, V31, P1231, DOI 10.1016/S1389-1286(99)00037-7
   WOLMAN A, 1999, 17 ACM S OP SYST PRI
   Wooster RP, 1997, COMPUT NETWORKS ISDN, V29, P977, DOI 10.1016/S0169-7552(97)00041-X
   YOUNG N, 1991, PROCEEDINGS OF THE SECOND ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P241
   ZHANG J, 1999, IEEE WORKSH INT APPL, P132
NR 58
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2004
VL 23
IS 2
BP 103
EP 130
DI 10.1023/B:MTAP.0000026843.40259.28
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 818LV
UT WOS:000221247500002
DA 2024-07-18
ER

PT J
AU Färber, J
AF Färber, J
TI Traffic modelling for fast action network games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Network and System Support for Games
CY APR 16-17, 2002
CL Braunschweig, GERMANY
DE traffic characterization; traffic modelling; multiplayer games
AB A significant share of today's Internet traffic is generated by network gaming. This kind of traffic is interesting in regard to it's market potential as well as to it's real time requirements on the network. For the consideration of game traffic in network dimensioning, traffic models are required that allow to generate a characteristic load for analytical or simulative performance evaluation of networks. In this paper the fast action multiplayer game "Counter Strike" is evaluated based on one month of Internet traffic traces and traffic models for client and server are presented. The paper concludes with remarks on QoS metrics for an adequate assessment of performance evaluation results.
C1 Univ Stuttgart, Inst Commun Networks & Comp Engn, D-70569 Stuttgart, Germany.
C3 University of Stuttgart
EM faerber@ikr.uni-stuttgart.de
CR ARMITAGE G, 2001, IMW2001 WORKSH POST
   Bernier Y. W., 2001, GAM DEV C, V98033
   BETTNER P, 2001, GAM DEV C
   BONHAM S, 2000, 561 CSE U WASH
   BORELLA MS, 1999, NETW INT 99 ENG C MA
   FARBER J, 2002, NETWORK GAME TRAFFIC, P53
   Henderson T., 2001, Networked Group Communication. Third International COST264 Workshop, NGC 2001. Proceedings (Lecture Notes in Computer Science Vol.2233), P1
   Henderson T., 2001, MULTIMEDIA 2001
   MCCREARY S, 2000, ITC SPEC SEM
   NG YS, 1997, GAMASUTRA        MAY
   *SLASHD, 2001, FAST TOO SLOW STUD Q
   TRIER M, 2002, GAMESTAR GAMING  MAR, P164
NR 12
TC 41
Z9 41
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2004
VL 23
IS 1
BP 31
EP 46
DI 10.1023/B:MTAP.0000026840.45588.64
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 818LR
UT WOS:000221247100003
DA 2024-07-18
ER

EF