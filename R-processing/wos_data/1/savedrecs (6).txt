FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Zhao, ZG
   Zhu, XF
AF Zhao, Zhigen
   Zhu, Xiaofei
TI Automatic drawing technique for horizontal projection diagrams of
   exploration borehole deviations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exploration borehole; Deviation; Horizontal projection diagram;
   Automatic drawing technique; Drawing exchange file; AutoCAD software
AB The objective of this paper is to propose an automatic drawing technique for horizontal projection diagrams of exploration borehole deviation. In this study, a computer program was developed so as to achieve AutoCAD automatic creation of horizontal projection diagrams with low computational complexity. The main procedures include: the original borehole deviation data are used, the coordinates of the measuring points are calculated by using the average zenith angle and azimuth angle, the coordinates of the middle points are determined using the average borehole section length, and the final coordinates and the respective AutoCAD drawing exchange files are outputted. The conclusions are: the drawing exchange files can be called directly by the AutoCAD software, thereby achieving the automatic drawing of the horizontal projection diagrams of the borehole deviations. An example is provided to demonstrate that the proposed automatic drawing method is correct, concise, and efficient. And this automatic drawing technology provides significant advantages, avoiding the shortcomings of inefficient and error-prone method in the past.
C1 [Zhao, Zhigen] Anhui Univ Sci & Technol, Sch Surveying & Mapping, Huainan City 232001, Peoples R China.
   [Zhu, Xiaofei] Anhui Univ Sci & Technol, Sch Earth & Environm, Huainan City 232001, Peoples R China.
C3 Anhui University of Science & Technology; Anhui University of Science &
   Technology
RP Zhao, ZG (corresponding author), Anhui Univ Sci & Technol, Sch Surveying & Mapping, Huainan City 232001, Peoples R China.
EM zhgzhao@aust.edu.cn
RI zhu, xiaofei/HGE-1301-2022
FU National Natural Science Foundation of China [41172138]; Anhui
   University of Science and Technology
FX The research was financially supported by the National Natural Science
   Foundation of China (No. 41172138) and by Anhui University of Science
   and Technology's core course of graduate students in 2017 (Theory of
   Coal Geology). The authors wish to thank Professor Jiaping YAN,
   Associate Professor Liuhua TONG, and Dr. Zheng ZHANG from Anhui
   University of Science and Technology for their constructive advice. The
   authors also express their gratitude to the technical personnel from
   Exploration and Research Institute, Anhui Bureau of Coal Geology for
   their kind help and discussion.
CR Cai XJ, 2013, MINE SURV, V41, P58
   Chen Jian-hong, 2005, Journal of Central South University (Science and Technology), V36, P486
   China National Standards, 2016, GBT334442016
   Groff DD, 2013, COMPUT ED J, V23, P74
   [郝兴中 Hao Xingzhong], 2012, [地球物理学进展, Progress in Geophysiscs], V27, P2233
   Hu WL, 2008, SHAANXI COAL, V27, P31
   Jiang DS, 2011, W CHIN EXPLOR ENG, V23, P168
   Kalashnikov AO, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-06972-9
   Liang W.T., 2009, MIN ENG-LITTLETON, V7, P65
   Liang YQ, 2015, COMPUT SYST APPL, V24, P173
   Liu BG, 2013, ZHONGZHOU COAL, V35, P62
   Liu GW, 2016, LOW CARBON WORLD, V6, P94
   [刘昕 Liu Xin], 2016, [图学学报, Journal of Graphics], V37, P731
   Liu YW, 2017, COAL SCI TECHNOL MAG, V38, P52, DOI [10.1016/j.compscitech.2017.05.006, DOI 10.1016/J.COMPSCITECH.2017.05.006]
   [罗晓霞 Luo Xiaoxia], 2012, [计算机工程与科学, Computer Engineering and Science], V34, P98
   Mondini AC, 2017, INT J APPL EARTH OBS, V63, P112, DOI 10.1016/j.jag.2017.07.016
   Neta BMM, 2012, APPL SOFT COMPUT, V12, P1379, DOI 10.1016/j.asoc.2011.11.023
   Ozkaya SI, 2018, COMPUT GEOSCI-UK, V112, P9, DOI 10.1016/j.cageo.2017.11.016
   [屈召贵 Qu Zhaogui], 2017, [煤田地质与勘探, Coal Geology & Exploration], V45, P143
   Rincón M, 2015, LECT NOTES COMPUT SC, V9107, P508, DOI 10.1007/978-3-319-18914-7_53
   Su HP, 2015, NONFERROUS MINING ME, V31, P7
   Wang J, 2017, J GEOGR SCI, V27, P1413, DOI 10.1007/s11442-017-1443-z
   [王乔 Wang Qiao], 2017, [煤田地质与勘探, Coal Geology & Exploration], V45, P41
   Wang YZ, 2016, CHINA OCEAN ENG, V30, P1, DOI 10.1007/s13344-016-0001-2
   Yang H, 2017, COMPUT GRAPH-UK, V65, P45, DOI 10.1016/j.cag.2017.04.003
   Yang LJ, 2014, MIN EXPLOR, V5, P639
   Ying Bai, 2013, Information Technology Journal, V12, P3096, DOI 10.3923/itj.2013.3096.3102
   Zhang H., 2014, HCI INT 2014 POSTERS, P286
   Zhang YX, 2013, JILIN WATER RESOUR, V33, P44
   Zhao GF, 2015, EXPLOR ENG ROCK SOIL, V42, P48
   Zuo YJ, 2005, MINE CONST TECHNOL, V26, P23
NR 31
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1201
EP 1218
DI 10.1007/s11042-018-6659-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500069
DA 2024-07-18
ER

PT J
AU Belhadad, Y
   Refoufi, A
   Roose, P
AF Belhadad, Yehya
   Refoufi, Allaoua
   Roose, Philippe
TI Spatial reasoning about multimedia document for a profile based
   adaptation: Combining distances, directions and topologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content adaptation; Multimedia document; Spatial reasoning; PROLOG;
   Inference
ID MOBILE WEB; INFORMATION; CONTEXT; ACCESS; PREDICTION; MPEG-21; SYSTEM;
   TIME
AB The continuous evolution of smart devices has led to serious limitations in multimedia applications. The multimedia graphic design and animation and the increased use of rich and complex multimedia content on the web or other media have all created a need to diversify the accessibility of the content. Therefore several techniques are used today to design a universally accessible content. The main techniques that are still used to maintain accessibility is to create two parallel streams of design and development of the same content. Thus, the continuous evolution will certainly lead to create other streams. For this, the automatic reasoning on multimedia to allow a computer to modify the design according to different variables, devices capabilities, user status and context to provide personalized adapted content. In this paper, we propose an abstract document model called XMS short for XML Multimedia Specification; it describes the composition of an original multimedia document and can be extended to any document type. We present how we may use spatial information present in this document to adapt and modify the original document. We mainly focus on the spatial aspect of a web document, a combination of RCC8, qualitative distances, and directions are used to describe the layout of a set of objects. The level of granularity of the definition of the objects defines the level of details that will be processed by our PROLOG based inference system, simplified versions of algorithms from the inference system and how it works on the spatial dimension of the document are shown. In the end samples of how spatial relations manipulation algorithms work are illustrated.
C1 [Belhadad, Yehya; Refoufi, Allaoua] Univ Ferhat Abbes Setif 1, Setif 19000, Algeria.
   [Roose, Philippe] IUT Bayonne, LIUPPA, 2 Allee Parc Montaury, F-64600 Anglet, France.
C3 Universite Ferhat Abbas Setif; Universite de Pau et des Pays de l'Adour
RP Belhadad, Y (corresponding author), Univ Ferhat Abbes Setif 1, Setif 19000, Algeria.
EM belhadad.yehya@univ-setif.dz; allaoua.refoufi@univ-setif.dz;
   Philippe.Roose@iutbayonne.univ-pau.fr
RI Roose, Philippe/A-5319-2009
OI Roose, Philippe/0000-0002-2227-3283
CR Adel A, 2014, PROCEDIA COMPUT SCI, V32, P959, DOI 10.1016/j.procs.2014.05.518
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2008, SMIL 3 0 FLEXIBLE MU
   Archana P, 2015, INT J COMPUT APPL, V110, P14
   Burnett I, 2003, IEEE MULTIMEDIA, V10, P60, DOI 10.1109/MMUL.2003.1237551
   Burnett IS, 2006, THE MPEG 21 BOOK
   Cavallaro A, 2005, IGI GLOBAL, P1001
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   De Bra P., 2006, Proceedings of the seventeenth conference on Hypertext and hypermedia. 2006, P133
   Dromzee C, 2013, INTELLIGENT MULTIMED, P225
   Ellis T. J., 2001, Journal of Educational Multimedia and Hypermedia, V10, P107
   Euzenat J, 2003, P 18 INT JOINT C ART, P31
   Frank A. U., 1992, Journal of Visual Languages and Computing, V3, P343, DOI 10.1016/1045-926X(92)90007-9
   Frank AU, 1996, INT J GEOGR INF SYST, V10, P269, DOI 10.1080/026937996138043
   Freire J., 2001, P 10 INT C WORLD WID, P576
   Gerevini A, 2002, ARTIF INTELL, V137, P1, DOI 10.1016/S0004-3702(02)00193-5
   Gerevini A, 2002, FRONT ARTIF INTEL AP, V77, P312
   Geurts J, 2001, APPL SPECIFIC CONSTR
   HARDMAN L, 1994, COMMUN ACM, V37, P50, DOI 10.1145/175235.175239
   He J, 2007, IEEE T KNOWL DATA EN, V19, P127, DOI 10.1109/TKDE.2007.250590
   Held Albert., 2002, Proceedings of SCI, P167
   Jones C. B., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P387
   Katai Z, 2010, TEACH TEACH EDUC, V26, P244, DOI 10.1016/j.tate.2009.04.012
   Kissling C, 2007, TRANSFORM STATE, P30
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lasch P, 1998, CELL MOL BIOL, V44, P189
   Lei ZJ, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P913, DOI 10.1109/CCECE.2001.933563
   Li Q, 2008, IGI GLOBAL, P242
   Louafi H, 2015, MULTIMED TOOLS APPL, V74, P7883, DOI 10.1007/s11042-014-2030-2
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   Osbakk P., 2002, Adjunct Proceedings, UbiComp, P9
   Renz J., 2002, QUALITATIVE SPATIAL
   Reynolds F, 1999, COMPOSITE CAPABILITY
   Saravanaselvam N., 2015, International Journal of Advanced Networking and Applications, V6, P2398
   Scherp A, 2008, MULTIMEDIA TECHNOLOG, pIGI
   Sharma J, 1995, LECT NOTES COMPUT SC, V951, P279
   VANESSEN DC, 1992, SCIENCE, V255, P419, DOI 10.1126/science.1734518
   Vetro A, 2004, IEEE MULTIMEDIA, V11, P84, DOI 10.1109/MMUL.2004.1261111
   Wang Y, 2007, IEEE T MULTIMEDIA, V9, P213, DOI 10.1109/TMM.2006.886253
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P104, DOI 10.1109/TMM.2014.2371240
   Zhang DS, 2015, INT J NETW DISTRIB C, V3, P1
NR 43
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30437
EP 30474
DI 10.1007/s11042-018-6080-8
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600014
DA 2024-07-18
ER

PT J
AU Liu, CW
   Hou, JY
   Wu, XX
   Jia, YD
AF Liu, Cuiwei
   Hou, Jingyi
   Wu, Xinxiao
   Jia, Yunde
TI A discriminative structural model for joint segmentation and recognition
   of human actions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Action segmentation; Discriminative structural model
ID MOTION; ROBUST
AB Achieving joint segmentation and recognition of continuous actions in a long-term video is a challenging task due to the varying durations of actions and the complex transitions of multiple actions. In this paper, a novel discriminative structural model is proposed for splitting a long-term video into segments and annotating the action label of each segment. A set of state variables is introduced into the model to explore discriminative semantic concepts shared among different actions. To exploit the statistical dependences among segments, temporal context is captured at both the action level and the semantic concept level. The state variables are treated as latent information in the discriminative structural model and inferred during both training and testing. Experiments on multi-view IXMAS and realistic Hollywood datasets demonstrate the effectiveness of the proposed method.
C1 [Liu, Cuiwei] Shenyang Aerosp Univ, Sch Comp Sci, Shenyang 110136, Liaoning, Peoples R China.
   [Hou, Jingyi; Wu, Xinxiao; Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Shenyang Aerospace University; Beijing Institute of Technology
RP Liu, CW (corresponding author), Shenyang Aerosp Univ, Sch Comp Sci, Shenyang 110136, Liaoning, Peoples R China.
EM liucuiwei@sau.edu.cn
FU Natural Science Foundation of China(NSFC) [61602320, 61673062]; Liaoning
   Doctoral Startup Project [201601172]; Liaoning provincial education
   department [L201607]
FX This work was supported in part by the Natural Science Foundation of
   China(NSFC) under Grants No. 61602320 and No. 61673062, and Liaoning
   Doctoral Startup Project under Grant No. 201601172, and project of
   Liaoning provincial education department under Grant No. L201607.
CR [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], IEEE INT C WORKSH AU
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], VID AN CONT EXTR WOR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P21 ACMINT C MULT MM
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], IEEE T CIRCUITS SYST
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Cheng Y, 2014, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2014.286
   Chun S, 2016, IET COMPUT VIS, V10, P250, DOI 10.1049/iet-cvi.2015.0233
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Do Trinh-Minh-Tri., 2009, ICML '09 Proceedings of the 26th Annual International Conference on Machine Learning, P265
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646
   Harchaoui Zaid, 2009, Advances in neural information processing systems, V21
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hsu YP, 2016, PATTERN RECOGN, V60, P215, DOI 10.1016/j.patcog.2016.05.010
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kulkarni K, 2015, INT J COMPUT VISION, V112, P90, DOI 10.1007/s11263-014-0758-9
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lei J, 2016, IET COMPUT VIS, V10, P537, DOI 10.1049/iet-cvi.2015.0408
   Li S, 2015, IEEE I CONF COMP VIS, P4453, DOI 10.1109/ICCV.2015.506
   Lin WY, 2014, IEEE T CIRC SYST VID, V24, P826, DOI 10.1109/TCSVT.2013.2280849
   Liu C, 2016, MULTIMED TOOLS APPL, V75, P13023, DOI 10.1007/s11042-015-2550-4
   Liu CW, 2016, INT J COMPUT VISION, V118, P240, DOI 10.1007/s11263-016-0897-2
   Liu JW, 2017, MULTIMED TOOLS APPL, V76, P6595, DOI 10.1007/s11042-016-3342-1
   Lu GL, 2013, PATTERN RECOGN LETT, V34, P1936, DOI 10.1016/j.patrec.2012.10.023
   Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470
   Ni BB, 2015, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2015.7298993
   Ramezani M, 2016, ARTIF INTELL REV, V46, P485, DOI 10.1007/s10462-016-9473-y
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Santos L, 2015, PATTERN RECOGN, V48, P568, DOI 10.1016/j.patcog.2014.08.015
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shao L, 2012, PATTERN RECOGN LETT, V33, P438, DOI 10.1016/j.patrec.2011.05.015
   Shi Q., 2008, IEEE C COMPUTER VISI, P1
   Shi QF, 2011, INT J COMPUT VISION, V93, P22, DOI 10.1007/s11263-010-0384-0
   Simon T, 2010, PROC CVPR IEEE, P2737, DOI 10.1109/CVPR.2010.5539998
   Tejero-de-Pablos A, 2016, IEEE INT CON MULTI
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Wu D, 2017, IEEE IJCNN, P2865, DOI 10.1109/IJCNN.2017.7966210
   Wu D, 2013, IEEE T CIRC SYST VID, V23, P236, DOI 10.1109/TCSVT.2012.2203731
   Wu XX, 2013, IEEE T CIRC SYST VID, V23, P1422, DOI 10.1109/TCSVT.2013.2244794
   Xuan Xiang, 2007, P 24 INT C MACH LEAR, P1055, DOI DOI 10.1145/1273496.1273629
   Yang Y, 2013, ADV INTELL SYST, V180, P689
   Yi Y, 2017, MULTIMED TOOLS APPL, V76, P18891, DOI 10.1007/s11042-017-4416-4
   Yu T., 2009, P 26 ANN INT C MACH, P1169, DOI DOI 10.1145/1553374.1553523
   Zhou Q, 2013, IEEE I CONF COMP VIS, P2264, DOI 10.1109/ICCV.2013.281
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
NR 60
TC 4
Z9 4
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31627
EP 31645
DI 10.1007/s11042-018-6189-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000005
DA 2024-07-18
ER

PT J
AU Liu, RZ
   Tang, YY
   Chan, PPK
AF Liu, Runzong
   Tang, Yuan Yan
   Chan, Patrick P. K.
TI A fast convex hull algorithm inspired by human visual perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convex hull; Computational geometry; Affine transformation; Point
   pattern; High dimension
ID NONTENSOR PRODUCT WAVELET; RECOGNITION
AB This paper proposes a convex hull algorithm for high dimensional point set, which is faster than the well-known Quickhull algorithm in many cases. The main idea of the proposed algorithm is to exclude inner points by early detection of global topological properties. The algorithm firstly computes an initial convex hull of 2*d + 2(d) extreme points. Then, it discards all the inner points which are inside the inscribed ball of the initial convex hull. The other inner points are processed recursively according to the relationships of points and facets. Maximum inscribed circle affine transformations are also designed to accelerate the computation of the convex hull. Experimental results show that the proposed algorithm achieves a significant saving of computation time in comparison with the Quickhull algorithm in 3, 4 and 5 dimensional space. The space efficiency of the proposed algorithm is also demonstrated by experimental results.
C1 [Liu, Runzong] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
   [Tang, Yuan Yan] Univ Macau, Fac Sci & Technol, Macau, Peoples R China.
   [Chan, Patrick P. K.] South China Univ Technol, Guangzhou, Guangdong, Peoples R China.
C3 Chongqing University; University of Macau; South China University of
   Technology
RP Liu, RZ (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
EM abslrz@cqu.edu.cn
RI 刘, 润宗/HHN-0085-2022
OI Liu, Runzong/0000-0002-8100-3566
FU Fundamental Research Funds for the Central Universities
   [106112016CDJXY180002, 0903005203327, 02160011044104]; Macau
   [MYRG2015-00049-FST, MYRG2015-00050-FST, RDG009/FST-TYY/2012,
   008-2014-AMJ]
FX This work was financially supported by Project No. 106112016CDJXY180002,
   0903005203327, 02160011044104 supported by the Fundamental Research
   Funds for the Central Universities. This work was also supported by the
   Research Grants of MYRG2015-00049-FST, MYRG2015-00050-FST,
   RDG009/FST-TYY/2012; 008-2014-AMJ from Macau.
CR ANDREW AM, 1979, INFORM PROCESS LETT, V9, P216, DOI 10.1016/0020-0190(79)90072-3
   Avis D, 1997, COMP GEOM-THEOR APPL, V7, P265, DOI 10.1016/S0925-7721(96)00023-5
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Bo CJ, 2016, INT C PAR DISTRIB SY, P1221, DOI [10.1109/ICPADS.2016.162, 10.1109/ICPADS.2016.0164]
   Buliung RN, 2006, J TRANSP GEOGR, V14, P35, DOI 10.1016/j.jtrangeo.2004.10.008
   Chan TM, 1996, DISCRETE COMPUT GEOM, V16, P361, DOI 10.1007/BF02712873
   CHAND DR, 1970, J ACM, V17, P78, DOI 10.1145/321556.321564
   CHEN L, 1982, SCIENCE, V218, P699, DOI 10.1126/science.7134969
   CLARKSON KL, 1989, DISCRETE COMPUT GEOM, V4, P387, DOI 10.1007/BF02187740
   Ding S, 2017, IEEE T IND ELECTRON, P1, DOI [10.1109/TNNLS.2017.2700331, DOI 10.1109/TNNLS.2017.2700331]
   Edelsbrunner H., 1987, Algorithms in Combinatorial Geometry
   Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2
   Grunbaum B., 1963, Proc. Symp. Pure Math., V7, P233
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   He ZY, 2016, IEEE T IMAGE PROCESS, V25, P3698, DOI 10.1109/TIP.2016.2570553
   He ZY, 2015, KNOWL-BASED SYST, V86, P21, DOI 10.1016/j.knosys.2015.04.018
   Hong HJ, 2017, IEEE INT SYM BROADB, P13
   Jenq-Haur Wang, 2017, 2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P433, DOI 10.1109/ICCE-China.2017.7991181
   Khosravani HR, 2016, APPL SOFT COMPUT, V47, P515, DOI 10.1016/j.asoc.2016.06.014
   Liparulo L, 2015, ADV FUZZY SYST, V2015, DOI 10.1155/2015/265135
   Liu RZ, 2012, NEUROCOMPUTING, V77, P212, DOI 10.1016/j.neucom.2011.09.011
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Minhas R, 2007, IEEE SYS MAN CYBERN, P2992
   Motzkin TS., 1953, The double description method
   Mousse MA, 2017, MULTIMED TOOLS APPL, V76, P6801, DOI 10.1007/s11042-016-3352-z
   MURTAGH F, 1992, PUBL ASTRON SOC PAC, V104, P301, DOI 10.1086/132993
   Niu L, 2016, MULTIMED TOOLS APPL, V76, P1
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   PREPARATA FP, 1977, COMMUN ACM, V20, P87, DOI 10.1145/359423.359430
   Renold AP, 2017, IEEE SENSOR LETT, V1, DOI 10.1109/LSENS.2017.2731200
   SEIDEL R, 1991, DISCRETE COMPUT GEOM, V6, P423, DOI 10.1007/BF02574699
   Szczypinski P, 2010, ADV INTEL SOFT COMPU, V84, P263
   Takahashi T, 2011, PATTERN RECOGN LETT, V32, P2224, DOI 10.1016/j.patrec.2011.06.020
   Wang DD, 2016, MULTIMED TOOLS APPL, V75, P3177, DOI 10.1007/s11042-014-2429-9
   Wang Y, 2016, J COMPUTATIONAL THEO
   You XG, 2014, IEEE T CIRC SYST VID, V24, P1265, DOI 10.1109/TCSVT.2014.2306031
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhang D, 2009, INT J PATTERN RECOGN, V23, P521, DOI 10.1142/S0218001409007260
NR 38
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31221
EP 31237
DI 10.1007/s11042-018-6185-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600048
DA 2024-07-18
ER

PT J
AU Tao, HJ
   Lu, XB
AF Tao, Huanjie
   Lu, Xiaobo
TI Smoky vehicle detection based on multi-feature fusion and ensemble
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smoky vehicle detection; Ensemble neural networks; Multi-feature fusion;
   Local binary pattern; Histograms of oriented gradients; Integral
   projection
ID BAG-OF-FEATURES; WILDFIRE SMOKE; EMISSIONS; RECOGNITION; SCALE
AB Existing methods of smoky vehicle detection from the traffic flow are inefficiency and need a large number of workers. To solve this issue, we propose an automatic smoky vehicle detection method based on multi-feature fusion and ensemble back-propagation neural networks (E-BPNN). In this method, the Vibe background subtraction algorithm and some rules are adopted to detect vehicle objects. To obtain the key region at the back of the vehicle where may be the most possible to have black smoke, the integral projection is utilized to detect the position of the vehicle rear. The proposed LHI features, which fuse Local Binary Pattern (LBP), Histograms of Oriented Gradients (HOG) and Integral Projection (IP), are extracted from the key region. The E-BPNN are adopted to distinguish smoky vehicles and non-smoke vehicles by making classification of the extracted LHI features. The proposed algorithm framework can automatically detect smoky vehicles through analyzing road surveillance videos which obtained in the daytime with good weather conditions. The experimental results show that the proposed method of the E-BPNN with multi-feature fusion has a better performance than the method of the BPNN with single features. In addition, the proposed method also has low false alarm rates than common smoke and fire detection methods.
C1 [Tao, Huanjie; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Tao, Huanjie; Lu, Xiaobo] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
FU National Key Science & Technology Pillar Program of China
   [2014BAG01B03]; National Natural Science Foundation of China [61374194];
   Key Research and Development Program of Jiangsu Province [BE2016739];
   Postgraduate Research and Practice Innovation Program of Jiangsu
   Province; Priority Academic Program Development of Jiangsu Higher
   Education Institutions
FX This work was supported by the National Key Science & Technology Pillar
   Program of China (No.2014BAG01B03), the National Natural Science
   Foundation of China (No.61374194), Key Research and Development Program
   of Jiangsu Province (No.BE2016739), Postgraduate Research and Practice
   Innovation Program of Jiangsu Province, and a Project Funded by the
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions.
CR [Anonymous], MOD APPL SCI
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], INT C FRONTIERS INTE
   [Anonymous], ATMOS CHEM PHYS DISC
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Calderara S, 2011, MACH VISION APPL, V22, P705, DOI 10.1007/s00138-010-0272-1
   Chirico R, 2010, ATMOS CHEM PHYS, V10, P11545, DOI 10.5194/acp-10-11545-2010
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Favorskaya M, 2015, PROCEDIA COMPUT SCI, V60, P671, DOI 10.1016/j.procs.2015.08.205
   Flach PA, 2015, ADV NEUR IN, V28
   Gunay O, 2012, IEEE T IMAGE PROCESS, V21, P2853, DOI 10.1109/TIP.2012.2183141
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hawkins J.K., 1970, Picture processing and psychopictorics, P347
   Hegenbart S, 2015, PATTERN RECOGN, V48, P2633, DOI 10.1016/j.patcog.2015.02.024
   Jakovcevic T, 2013, MACH VISION APPL, V24, P707, DOI 10.1007/s00138-012-0481-x
   Ko B, 2013, IMAGE VISION COMPUT, V31, P786, DOI 10.1016/j.imavis.2013.08.001
   Konecny J, 2014, J MACH LEARN RES, V15, P2513
   Labati RD, 2013, IEEE T SYST MAN CY-S, V43, P1003, DOI 10.1109/TSMCA.2012.2224335
   Lee MH, 2016, ETRI J, V38, P502, DOI 10.4218/etrij.16.0115.0631
   Liu K, 2014, INT J COMPUT VISION, V106, P342, DOI 10.1007/s11263-013-0634-z
   Liu W, 2015, IET COMPUT VIS, V9, P13, DOI 10.1049/iet-cvi.2013.0242
   Luo YM, 2018, MULTIMED TOOLS APPL, V77, P15075, DOI 10.1007/s11042-017-5090-2
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park J, 2013, IEEE WORK APP COMP, P200, DOI 10.1109/WACV.2013.6475019
   Pyykönen P, 2016, INT C INTELL COMP CO, P233, DOI 10.1109/ICCP.2016.7737152
   Robinson AL, 2007, SCIENCE, V315, P1259, DOI 10.1126/science.1133061
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shi LF, 2017, LECT NOTES COMPUT SC, V10262, P299, DOI 10.1007/978-3-319-59081-3_36
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Bruno DOT, 2016, EXPERT SYST APPL, V55, P329, DOI 10.1016/j.eswa.2016.02.019
   Tao HJ, 2018, SIGNAL IMAGE VIDEO P, V12, P1061, DOI 10.1007/s11760-018-1254-4
   Tian H, 2011, P IEEE INT WORKSH MU, P1, DOI DOI 10.1109/VETECF.2011.6092963
   Toreyin B. Ugur, 2005, 2005 13th European Signal Processing Conference, P1
   Wang SD, 2017, J INTELL FUZZY SYST, V33, P305, DOI 10.3233/JIFS-161605
   Wu Y, 2017, SCI TOTAL ENVIRON, V574, P332, DOI 10.1016/j.scitotenv.2016.09.040
   Yang XF, 2015, ATMOS CHEM PHYS, V15, P2105, DOI 10.5194/acp-15-2105-2015
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
NR 39
TC 12
Z9 13
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32153
EP 32177
DI 10.1007/s11042-018-6248-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000029
DA 2024-07-18
ER

PT J
AU Chouhan, SS
   Kaul, A
   Singh, UP
AF Chouhan, Siddharth Singh
   Kaul, Ajay
   Singh, Uday Pratap
TI Soft computing approaches for image segmentation: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Fuzzy logic; Fuzzy c means; Genetic algorithm; Image
   segmentation; Neural network; Soft computing
ID FUZZY C-MEANS; CONVOLUTIONAL NEURAL-NETWORKS; MEANS
   CLUSTERING-ALGORITHM; BRAIN-TUMOR SEGMENTATION; GENETIC ALGORITHM;
   NEIGHBORHOOD ATTRACTION; REGION COMPETITION; CANCER-DIAGNOSIS; SATELLITE
   IMAGES; OBJECT DETECTION
AB Image segmentation is the method of partitioning an image into a group of pixels that are homogenous in some manner. The homogeneity dependents on some attributes like intensity, color etc. Segmentation being a pre-processing step in image processing have been used in the number of applications like identification of objects to medical images, satellite images and much more. The taxonomy of an image segmentation methods collectively can be divided among two categories Traditional methods and Soft Computing (SC) methods. Unlike Traditional methods, SC methods have the ability to simulate human thinking and are flexible to work with their ownership function, have been predominantly applied to the task of image segmentation. SC techniques are tolerant of partial truth, imprecision, uncertainty, and approximations. Soft Computing approaches also having advantages of providing cost-effective, high performance and steadfast solutions. In this survey paper, our emphasis is on core SC approaches like Fuzzy logic, Artificial Neural Network, and Genetic Algorithm used for image segmentation. The contribution lies in the fact to present this paper to the researchers that explore state-of-the-art elaboration of almost all dimensions associated with the image segmentation. The idea is to encapsulate various aspects like emerging topics, methods, evaluation parameters, the problem associated with different type of images, databases, segmentation applications, and other resources so that, it could be advantageous for researchers to make effort in developing new methods for segmentation. The paper accomplishes with findings and concluding remarks.
C1 [Chouhan, Siddharth Singh; Kaul, Ajay] Shri Mata Vaishno Devi Univ, Dept Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
   [Singh, Uday Pratap] Madhav Inst Sci & Technol, Dept Appl Math, Gwalior 474005, Madhya Pradesh, India.
C3 Shri Mata Vaishno Devi University; Madhav Institute of Technology &
   Science
RP Chouhan, SS (corresponding author), Shri Mata Vaishno Devi Univ, Dept Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
EM siddharth.lnct@gmail.com
RI Singh, Uday Pratap/AAW-9594-2020; Chouhan, Siddharth Singh/X-5909-2019
OI Singh, Uday Pratap/0000-0003-2077-0793; Chouhan, Siddharth
   Singh/0000-0003-3787-1857
CR Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Abedin MdZ, 2016, 19 INT C COMP INF TE, DOI [10.1109/iccitechn.2016.7860241, DOI 10.1109/ICCITECHN.2016.7860241]
   Aghajari E, 2017, APPL SOFT COMPUT, V54, P347, DOI 10.1016/j.asoc.2017.01.003
   Agrawal S, 2014, APPL SOFT COMPUT, V24, P522, DOI 10.1016/j.asoc.2014.08.011
   Al-Dmour H, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P631
   Al-Sahaf Harith, 2017, IEEE Transactions on Evolutionary Computation, V21, P83, DOI 10.1109/TEVC.2016.2577548
   Ananthi VP, 2016, SOFT COMPUT, V20, P4859, DOI 10.1007/s00500-015-1775-5
   Ananthi VP, 2016, COMPUT METH PROG BIO, V134, P165, DOI 10.1016/j.cmpb.2016.07.002
   ANDREY P, 1994, PATTERN RECOGN, V27, P659, DOI 10.1016/0031-3203(94)90045-0
   Bedruz RA, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2822, DOI 10.1109/TENCON.2016.7848557
   Bedruz RA, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P676, DOI 10.1109/TENCON.2016.7848088
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Aparajeeta J, 2016, APPL SOFT COMPUT, V41, P104, DOI 10.1016/j.asoc.2015.12.003
   Arumugadevi S, 2016, INT J AUTOM COMPUT, V13, P491, DOI 10.1007/s11633-016-0975-5
   Awad M, 2009, IET IMAGE PROCESS, V3, P52, DOI 10.1049/iet-ipr.2007.0213
   Awad M, 2007, IEEE GEOSCI REMOTE S, V4, P571, DOI 10.1109/LGRS.2007.903064
   Baazaoui A, 2017, IRBM, V38, P98, DOI 10.1016/j.irbm.2017.02.003
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Badura P, 2014, COMPUT BIOL MED, V53, P230, DOI 10.1016/j.compbiomed.2014.08.005
   Bahadure NB, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P1160
   Bai XZ, 2016, APPL SOFT COMPUT, V46, P128, DOI 10.1016/j.asoc.2016.05.004
   Balamurugan M, 2017, RENEW SUST ENERG REV, V75, P1493, DOI 10.1016/j.rser.2016.11.210
   Bali A, 2015, INT C ADV COMPUT COM, P113, DOI 10.1109/ACCT.2015.63
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Barkana BD, 2017, KNOWL-BASED SYST, V118, P165, DOI 10.1016/j.knosys.2016.11.022
   Benalcázar ME, 2014, EUR SIGNAL PR CONF, P2195
   Bertasius G, IEEE C COMP VIS PATT, DOI [10.1109/CVPR2017.650, DOI 10.1109/CVPR2017.650]
   Bhattacharyya S, 2011, APPL SOFT COMPUT, V11, P946, DOI 10.1016/j.asoc.2010.01.015
   Bhaumik H, 2016, APPL SOFT COMPUT, V46, P1008, DOI 10.1016/j.asoc.2016.03.022
   Borges VR, 2015, SOFT COMPUT, V19, P339, DOI 10.1007/s00500-014-1256-2
   Bose A, 2016, SIGNAL IMAGE VIDEO P, V10, P1089, DOI 10.1007/s11760-016-0863-z
   Brosch T, 2015, NEURAL COMPUT, V27, P211, DOI 10.1162/NECO_a_00682
   Cao HB, 2012, IEEE T FUZZY SYST, V20, P1, DOI 10.1109/TFUZZ.2011.2160025
   Caponetti L, 2008, APPL SOFT COMPUT, V8, P118, DOI 10.1016/j.asoc.2006.11.008
   Chamalis T, 2017, 2017 3 IEEE INT C CO, DOI [10.1109/ICCAR.2017.7942722, DOI 10.1109/ICCAR.2017.7942722]
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chang CY, 2011, IEEE COMPUT INTELL M, V6, P43, DOI 10.1109/MCI.2011.942756
   Chang FJ, 2016, J HYDROL, V541, P965, DOI 10.1016/j.jhydrol.2016.08.006
   Chen GC, 2013, IEEE COMPUT INTELL M, V8, P33, DOI 10.1109/MCI.2012.2228592
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Chen YL, 2015, IEEE T NEUR NET LEAR, V26, P1682, DOI 10.1109/TNNLS.2014.2351418
   Chen Y, 2016, IET IMAGE PROCESS, V10, P865, DOI 10.1049/iet-ipr.2016.0271
   Chen YJ, 2016, PATTERN RECOGN, V60, P778, DOI 10.1016/j.patcog.2016.06.020
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cheng DC, 2017, IEEE GEOSCI REMOTE S, V14, P247, DOI 10.1109/LGRS.2016.2637439
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   CHI Z, 1993, ELECTRON LETT, V29, P1841, DOI 10.1049/el:19931225
   Chinmayi P, 2018, ADV INTELL SYST, V614, P460, DOI 10.1007/978-3-319-60618-7_45
   Chinnasamy S, 2014, IET IMAGE PROCESS, V8, P319, DOI 10.1049/iet-ipr.2012.0510
   Chiranjeevi P, 2014, IEEE T IMAGE PROCESS, V23, P645, DOI 10.1109/TIP.2013.2285598
   Choy SK, 2011, IEEE T IMAGE PROCESS, V20, P1473, DOI 10.1109/TIP.2010.2095023
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   Chun DN, 1996, PATTERN RECOGN, V29, P1195, DOI 10.1016/0031-3203(95)00148-4
   Cordeiro FR, 2016, APPL SOFT COMPUT, V46, P613, DOI 10.1016/j.asoc.2015.11.040
   Das S, 2016, 2016 SECOND IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P78, DOI 10.1109/ICRCICN.2016.7813635
   De S, 2016, APPL SOFT COMPUT, V47, P669, DOI 10.1016/j.asoc.2016.05.042
   De S, 2012, APPL SOFT COMPUT, V12, P3228, DOI 10.1016/j.asoc.2012.05.011
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P1451, DOI 10.1109/JBHI.2014.2360515
   Deng WQ, 2016, J COMPUT SCI TECH-CH, V31, P501, DOI 10.1007/s11390-016-1643-5
   Dey J, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2289, DOI 10.1109/ICEEOT.2016.7755101
   Dileep G, 2017, SOL ENERGY, V141, P182, DOI 10.1016/j.solener.2016.11.034
   Ding J, 2016, IEEE GEOSCI REMOTE S, V13, P364, DOI 10.1109/LGRS.2015.2513754
   Dong J, 2014, LECT NOTES COMPUT SC, V8693, P299, DOI 10.1007/978-3-319-10602-1_20
   Dong Z, 2015, IEEE T INTELL TRANSP, V16, P2247, DOI 10.1109/TITS.2015.2402438
   Dosovitskiy A, 2017, IEEE T PATTERN ANAL, V39, P692, DOI 10.1109/TPAMI.2016.2567384
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Fakhry A, 2017, IEEE T MED IMAGING, V36, P447, DOI 10.1109/TMI.2016.2613019
   Fan Y, 2002, IEEE T MED IMAGING, V21, P904, DOI 10.1109/TMI.2002.803126
   Feng CL, 2016, J VIS COMMUN IMAGE R, V38, P517, DOI 10.1016/j.jvcir.2016.03.027
   Franklin J, 2016, IEEE INT C CL COMP, P168, DOI 10.1109/CLUSTER.2016.89
   Franklin SW, 2014, APPL SOFT COMPUT, V22, P94, DOI 10.1016/j.asoc.2014.04.024
   Fu H, 2006, IEE P-VIS IMAGE SIGN, V153, P881, DOI 10.1049/ip-vis:20060061
   Ghamisi P, 2016, IEEE GEOSCI REMOTE S, V13, P1537, DOI 10.1109/LGRS.2016.2595108
   Gharieb RR, 2017, SIGNAL IMAGE VIDEO P, V11, P541, DOI 10.1007/s11760-016-0992-4
   Ghosh P, 2016, NEUROCOMPUTING, V195, P181, DOI 10.1016/j.neucom.2015.09.123
   Gobikrishnan M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P430, DOI 10.1109/ICCSP.2016.7754172
   Gorobets AN, 2017, 2017 XI INTERNATIONAL CONFERENCE ON ANTENNA THEORY AND TECHNIQUES (ICATT), P364, DOI 10.1109/ICATT.2017.7972664
   Gotardo PFU, 2004, IEEE T SYST MAN CY B, V34, P2303, DOI 10.1109/TSMCB.2004.835082
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gwang-Gook Lee, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P277, DOI 10.1109/ICCE.2017.7889317
   Hameed S, 2016, IEEE REGION 10 SYMP, P266, DOI 10.1109/TENCONSpring.2016.7519416
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hassanien AE, 2014, APPL SOFT COMPUT, V14, P62, DOI 10.1016/j.asoc.2013.08.011
   Hata Y, 2009, APPL SOFT COMPUT, V9, P1156, DOI 10.1016/j.asoc.2009.03.001
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Helmy AK, 2016, APPL SOFT COMPUT, V40, P405, DOI 10.1016/j.asoc.2015.11.042
   Herrera J, 2011, APPL SOFT COMPUT, V11, P4738, DOI 10.1016/j.asoc.2011.07.010
   Hiziroglu A, 2013, EXPERT SYST APPL, V40, P6491, DOI 10.1016/j.eswa.2013.05.052
   Huang CW, 2015, SOFT COMPUT, V19, P459, DOI 10.1007/s00500-014-1264-2
   Huang M.-F., 2007, P OPT FIB COMM C OFC, P1, DOI DOI 10.1109/IMTC.2007.379081
   Huang WB, 2016, IEEE IJCNN, P3978, DOI 10.1109/IJCNN.2016.7727716
   Huang YB, 2010, COMPUT ELECTRON AGR, V71, P107, DOI 10.1016/j.compag.2010.01.001
   Hung CL, 2017, COMPUT ELECTR ENG, V61, P373, DOI 10.1016/j.compeleceng.2016.09.028
   Ibrahim D, 2016, PROCEDIA COMPUT SCI, V102, P34, DOI 10.1016/j.procs.2016.09.366
   Indragandhi V, 2017, RENEW SUST ENERG REV, V69, P129, DOI 10.1016/j.rser.2016.11.209
   Izadi M, 2017, J INDIAN SOC REMOTE, V45, P965, DOI 10.1007/s12524-017-0660-3
   Janc K, 2013, COMPUT METH PROG BIO, V111, P72, DOI 10.1016/j.cmpb.2013.03.012
   Javed U, 2016, IEEE T AERO ELEC SYS, V52, P181, DOI 10.1109/TAES.2015.120817
   Jeon BK, 2002, IEEE T GEOSCI REMOTE, V40, P22, DOI 10.1109/36.981346
   Ji J, 2014, IEEE J-STARS, V7, P4929, DOI 10.1109/JSTARS.2014.2308531
   Ji ZX, 2012, IEEE T INF TECHNOL B, V16, P339, DOI 10.1109/TITB.2012.2185852
   Jiang XL, 2016, NEUROCOMPUTING, V207, P22, DOI 10.1016/j.neucom.2016.03.046
   Jiao LC, 2010, IEEE COMPUT INTELL M, V5, P78, DOI 10.1109/MCI.2010.936307
   Joshi A, 2015, INT C ADV COMP COMM, DOI [10.1109/ICACCS.2015.7324127, DOI 10.1109/ICACCS.2015.7324127]
   Jothi JAA, 2017, ARTIF INTELL REV, V48, P31, DOI 10.1007/s10462-016-9494-6
   Kahali S, 2017, CCIS, V776, P323, DOI [10.1007/978-981-10-6430-2_25, DOI 10.1007/978-981-10-6430-2_25]
   Kamarudin JAM, 2017, COMM COM INF SC, V752, P83, DOI 10.1007/978-981-10-6502-6_7
   Kamiya A, 2005, APPL SOFT COMPUT, V5, P265, DOI 10.1016/j.asoc.2004.08.005
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90
   Karvonen JA, 2004, IEEE T GEOSCI REMOTE, V42, P1566, DOI 10.1109/TGRS.2004.828179
   Kateriya B, 2016, 2016 INT C COMPUTER, P1
   KAUR A, 2016, VISUAL COMPUT, P119, DOI DOI 10.1109/ICIVC.2016.7571284
   Khan A, 2015, APPL SOFT COMPUT, V32, P300, DOI 10.1016/j.asoc.2015.03.029
   Khan A, 2014, SIGNAL IMAGE VIDEO P, V8, P1233, DOI 10.1007/s11760-012-0347-8
   Khan ZF, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATICS, HEALTH & TECHNOLOGY (ICIHT), DOI 10.1109/ICIHT.2017.7899012
   Kim BK, 2017, IEEE GEOSCI REMOTE S, V14, P38, DOI 10.1109/LGRS.2016.2624820
   Kim EY, 2000, IEEE SIGNAL PROC LET, V7, P301, DOI 10.1109/97.873564
   Kim HJ, 1998, ELECTRON LETT, V34, P2394, DOI 10.1049/el:19981674
   Kim Y, 2016, IEEE GEOSCI REMOTE S, V13, P8, DOI 10.1109/LGRS.2015.2491329
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Ko M, 2010, APPL SOFT COMPUT, V10, P661, DOI 10.1016/j.asoc.2009.09.004
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Kumar S, 2018, INT J MACH LEARN CYB, V9, P163, DOI 10.1007/s13042-015-0360-7
   Kuruvilla J, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P198, DOI 10.1109/SAPIENCE.2016.7684170
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lekadir K, 2017, IEEE J BIOMED HEALTH, V21, P48, DOI 10.1109/JBHI.2016.2631401
   Leung SH, 2004, IEEE T IMAGE PROCESS, V13, P51, DOI 10.1109/TIP.2003.818116
   Li GH, 2016, INT CONF MEAS, P379, DOI 10.1109/ICMTMA.2016.97
   Li LG, 2016, IEEE ACCESS, V4, P6438, DOI 10.1109/ACCESS.2016.2613940
   Li X, 2016, FUTURE GENER COMP SY, V65, P90, DOI 10.1016/j.future.2016.03.004
   Li YL, 2010, SOFT COMPUT, V14, P123, DOI 10.1007/s00500-009-0442-0
   Liang XD, 2017, IEEE T PATTERN ANAL, V39, P115, DOI 10.1109/TPAMI.2016.2537339
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu GY, 2015, IEEE T IMAGE PROCESS, V24, P3990, DOI 10.1109/TIP.2015.2456505
   Liu J, 2017, MULTIMED TOOLS APPL, V76, P11111, DOI 10.1007/s11042-016-3657-y
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Ma H, 2017, LNCS, P453, DOI [10.1007/978-3-319-66179-7, DOI 10.1007/978-3-319-66179-7_52]
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Maji P, 2015, APPL SOFT COMPUT, V30, P705, DOI 10.1016/j.asoc.2015.01.049
   Manikandan T, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0539-9
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Máttyus G, 2016, PROC CVPR IEEE, P3611, DOI 10.1109/CVPR.2016.393
   Meftah B, 2010, NEURAL PROCESS LETT, V32, P131, DOI 10.1007/s11063-010-9149-6
   Mesejo P, 2016, APPL SOFT COMPUT, V44, P1, DOI 10.1016/j.asoc.2016.03.004
   Minto L, 2016, LECT NOTES COMPUT SC, V9915, P118, DOI 10.1007/978-3-319-49409-8_12
   Mistry VH, 2016, 2016 IE INT C ADV EL
   Mojumder JC, 2017, RENEW SUST ENERG REV, V72, P1366, DOI 10.1016/j.rser.2016.11.225
   Mondal A, 2016, APPL SOFT COMPUT, V47, P191, DOI 10.1016/j.asoc.2016.05.026
   Moniruzzaman M, 2017, LECT NOTES COMPUT SC, V10617, P150, DOI 10.1007/978-3-319-70353-4_13
   Muppidi M, 2015, INT CONF IMAG PROC, P143, DOI 10.1109/IPTA.2015.7367114
   Mylonas SK, 2016, IEEE J-STARS, V9, P1470, DOI 10.1109/JSTARS.2016.2518403
   Mylonas SK, 2015, IEEE T GEOSCI REMOTE, V53, P5352, DOI 10.1109/TGRS.2015.2421640
   Mylonas SK, 2013, KNOWL-BASED SYST, V54, P86, DOI 10.1016/j.knosys.2013.07.018
   Nagarajan G, 2016, PROCEDIA COMPUT SCI, V85, P455, DOI 10.1016/j.procs.2016.05.192
   Nambura A, 2017, APPL SOFT COMPUT, V54, P456, DOI 10.1016/j.asoc.2016.08.020
   Naz S., 2010, 2010 6th International Conference on Emerging Technologies (ICET), P181, DOI 10.1109/ICET.2010.5638492
   Nithila EE, 2016, ALEX ENG J, V55, P2583, DOI 10.1016/j.aej.2016.06.002
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Nugroho DPA, 2017, CCIS, V788, P13, DOI [10.1007/978-981-10-7242-0_2, DOI 10.1007/978-981-10-7242-0_2]
   Ortiz A, 2013, APPL SOFT COMPUT, V13, P2668, DOI 10.1016/j.asoc.2012.11.020
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Parvathi P, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P342, DOI 10.1109/ICACA.2016.7887978
   Patra S, 2014, APPL SOFT COMPUT, V23, P122, DOI 10.1016/j.asoc.2014.06.016
   Pednekar AS, 2006, IEEE T IMAGE PROCESS, V15, P1555, DOI 10.1109/TIP.2006.871165
   Pereira DC, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.014
   Pereira S, 2017, 2017 IEEE 5 PORT M B, P1
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Rajeev AA, INF COMMUN TECHNOL S, V10, P443, DOI [10.1007/978-981-10-3920-1_45, DOI 10.1007/978-981-10-3920-1_45]
   Trujillo MCR, 2017, SOFT COMPUT, V21, P611, DOI 10.1007/s00500-016-2426-1
   Rao BD, 2018, ADV INTELL SYST, V671, P35, DOI 10.1007/978-981-10-6977-2_4
   Rezaee K, 2017, APPL SOFT COMPUT, V52, P937, DOI 10.1016/j.asoc.2016.09.033
   Rezaei Z, 2017, APPL SOFT COMPUT, V53, P380, DOI 10.1016/j.asoc.2016.12.048
   Riomoros I., 2010, 2010 International Conference of Soft Computing and Pattern Recognition (SoCPaR 2010), P462, DOI 10.1109/SOCPAR.2010.5685936
   Rizvi IA, 2011, IEEE T GEOSCI REMOTE, V49, P4815, DOI 10.1109/TGRS.2011.2171695
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Roy K, 2015, IET BIOMETRICS, V4, P151, DOI 10.1049/iet-bmt.2014.0064
   Sabzi S, 2017, APPL SOFT COMPUT, V56, P107, DOI 10.1016/j.asoc.2017.03.006
   Saha R, 2016, 2016 INT C DIG IM CO, DOI [10.1109/dicta.2016.7797086, DOI 10.1109/DICTA.2016.7797086]
   Saha S, 2010, IEEE GEOSCI REMOTE S, V7, P306, DOI 10.1109/LGRS.2009.2034033
   Saito Shunsuke, 2016, EUR C COMP VIS ECCV
   Saqui D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P733, DOI 10.1109/CSCI.2016.0143
   Saridakis KM, 2008, ADV ENG INFORM, V22, P202, DOI 10.1016/j.aei.2007.10.001
   Sarkar JP, 2016, APPL SOFT COMPUT, V46, P527, DOI 10.1016/j.asoc.2016.01.040
   Satoru, 2016, 2016 IEEE S SER COMP, P1, DOI DOI 10.1109/SSCI.2016.7850135
   Sebari I, 2013, ISPRS J PHOTOGRAMM, V79, P171, DOI 10.1016/j.isprsjprs.2013.02.006
   Sevo I, 2016, IEEE GEOSCI REMOTE S, V13, P740, DOI 10.1109/LGRS.2016.2542358
   Shang RH, 2016, IEEE J-STARS, V9, P1640, DOI 10.1109/JSTARS.2016.2516014
   Shen S, 2005, IEEE T INF TECHNOL B, V9, P459, DOI 10.1109/TITB.2005.847500
   Sheta A, 2012, INT CONF MULTIMED, P83
   Shigeyoshi K, 2015, INT C CONTR AUTOMAT, P1547, DOI 10.1109/ICCAS.2015.7364602
   Shrivastava S, 2011, APPL SOFT COMPUT, V11, P1156, DOI 10.1016/j.asoc.2010.02.015
   Simhachalam B, 2016, EGYPT INFORM J, V17, P183, DOI 10.1016/j.eij.2015.10.004
   Singh A, 2017, J VIS COMMUN IMAGE R, V42, P173, DOI 10.1016/j.jvcir.2016.11.017
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Singh V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P419, DOI 10.1109/ICACEA.2015.7164741
   Singha S, 2013, IEEE J-STARS, V6, P2355, DOI 10.1109/JSTARS.2013.2251864
   Song A, 2008, EVOL COMPUT, V16, P461, DOI 10.1162/evco.2008.16.4.461
   Song T, 2007, IEEE T NEURAL NETWOR, V18, P1424, DOI 10.1109/TNN.2007.891635
   Sulaiman SN, 2010, IEEE T CONSUM ELECTR, V56, P2661, DOI 10.1109/TCE.2010.5681154
   Suomi V, 2016, IEEE ENG MED BIO, P5648, DOI 10.1109/EMBC.2016.7592008
   Swietojanski P, 2014, IEEE SIGNAL PROC LET, V21, P1120, DOI 10.1109/LSP.2014.2325781
   Takeki A, 2016, IEEE IMAGE PROC, P3977, DOI 10.1109/ICIP.2016.7533106
   Tan KS, 2013, APPL SOFT COMPUT, V13, P2017, DOI 10.1016/j.asoc.2012.11.038
   Tan KS, 2013, APPL SOFT COMPUT, V13, P1832, DOI 10.1016/j.asoc.2012.12.022
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Tang Y, 2017, IEEE T IMAGE PROCESS, V26, P994, DOI [10.1109/TIP.2016.2639440, 10.1109/TIP.2017.2656474]
   Taravat A, 2014, IEEE T GEOSCI REMOTE, V52, P2427, DOI 10.1109/TGRS.2013.2261076
   Tewari P, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3741
   Tian GJ, 2011, IEEE T INF TECHNOL B, V15, P373, DOI 10.1109/TITB.2011.2106135
   Tokmakov P, 2016, LECT NOTES COMPUT SC, V9908, P388, DOI 10.1007/978-3-319-46493-0_24
   Uy ACP, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2094, DOI 10.1109/TENCON.2016.7848395
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Vapenik R., 2016, 2016 International Conference on Emerging eLearning Technologies and Applications (ICETA). Proceedings, P365, DOI 10.1109/ICETA.2016.7802049
   Veredas F, 2010, IEEE T MED IMAGING, V29, P410, DOI 10.1109/TMI.2009.2033595
   Verma H, 2016, APPL SOFT COMPUT, V46, P543, DOI 10.1016/j.asoc.2015.12.022
   Vishnuvarthanan G, 2016, APPL SOFT COMPUT, V38, P190, DOI 10.1016/j.asoc.2015.09.016
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Vorontsov E, 2017, MED BIOL ENG COMPUT, V55, P127, DOI 10.1007/s11517-016-1495-8
   Wäldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z
   Wang C, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P1, DOI 10.1109/BigMM.2016.67
   Wang FL, 2014, IEEE T COMP PACK MAN, V4, P1245, DOI 10.1109/TCPMT.2014.2322907
   Wang L, 2016, IEEE T GEOSCI REMOTE, V54, P4524, DOI 10.1109/TGRS.2016.2543660
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wei H, 2015, IEEE T CYBERNETICS, V45, P2558, DOI 10.1109/TCYB.2014.2376939
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Xie FY, 2013, PATTERN RECOGN, V46, P1012, DOI 10.1016/j.patcog.2012.08.012
   Xu MT, 2016, IEEE INT FUZZY SYST, P1333, DOI 10.1109/FUZZ-IEEE.2016.7737844
   Xu Y, 2017, IEEE T BIO-MED ENG, V64, P2901, DOI 10.1109/TBME.2017.2686418
   Yamamoto Y, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P36, DOI 10.1109/SITIS.2016.15
   Yan C, 2016, IET COMPUT VIS, V10, P103, DOI 10.1049/iet-cvi.2015.0175
   Yardimci A, 2009, APPL SOFT COMPUT, V9, P1029, DOI 10.1016/j.asoc.2009.02.003
   Yeh JY, 2008, EXPERT SYST APPL, V34, P1285, DOI 10.1016/j.eswa.2006.12.012
   Yin SB, 2017, PATTERN RECOGN, V68, P245, DOI 10.1016/j.patcog.2017.03.012
   Yoshimura M, 1999, PATTERN RECOGN, V32, P2041, DOI 10.1016/S0031-3203(99)00004-7
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Zangeneh D, 2016, IRAN CONF ELECTR ENG, P832, DOI 10.1109/IranianCEE.2016.7585635
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P5553, DOI 10.1109/TGRS.2016.2569141
   Zhang MR, 2002, IEEE T SYST MAN CY B, V32, P571, DOI 10.1109/TSMCB.2002.1033177
   Zhang XF, 2017, SOFT COMPUT, V21, P2165, DOI 10.1007/s00500-015-1920-1
   Zhang XF, 2017, MULTIMED TOOLS APPL, V76, P7869, DOI 10.1007/s11042-016-3399-x
   Zhao F, 2015, APPL SOFT COMPUT, V30, P48, DOI 10.1016/j.asoc.2015.01.039
   Zhao QH, 2017, PATTERN RECOGN LETT, V85, P49, DOI 10.1016/j.patrec.2016.11.019
   Zheng G, 2017, LNCS, P503, DOI [10.1007/978-3-319-69923-3_54, DOI 10.1007/978-3-319-69923-3_54]
   Zhou HY, 2009, IEEE J-STSP, V3, P26, DOI 10.1109/JSTSP.2008.2010631
   Zhou XC, 2008, J CENT SOUTH UNIV T, V15, P882, DOI 10.1007/s11771-008-0161-1
   Zhou Y, 2016, IEEE GEOSCI REMOTE S, V13, P1935, DOI 10.1109/LGRS.2016.2618840
   Zhu WH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P1, DOI 10.1109/SIPROCESS.2016.7888212
NR 251
TC 65
Z9 68
U1 2
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28483
EP 28537
DI 10.1007/s11042-018-6005-6
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500031
DA 2024-07-18
ER

PT J
AU Luan, SZ
   Li, Y
   Wang, XD
   Zhang, BC
AF Luan, Shangzhen
   Li, Yan
   Wang, Xiaodi
   Zhang, Baochang
TI Object detection and tracking benchmark in industry based on improved
   correlation filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Tracking; Correlation filter; Industry 4.0; Tracking
   in industry
ID HISTOGRAMS; AVERAGE
AB Real-time object detection and tracking have shown to be the basis of intelligent production for industrial 4.0 applications. It is a challenging task because of various distorted data in complex industrial setting. The correlation filter (CF) has been used to trade off the low-cost computation and high performance. However, traditional CF training strategy can not get satisfied performance for the various industrial data; because the simple sampling(bagging) during training process will not find the exact solutions in a data space with a large diversity. In this paper, we propose Dijkstra-distance based correlation filters (DBCF), which establishes a new learning framework that embeds distribution-related constraints into the multi-channel correlation filters (MCCF). DBCF is able to handle the huge variations existing in the industrial data by improving those constraints based on the shortest path among all solutions. To evaluate DBCF, we build a new dataset as the benchmark for industrial 4.0 application. Extensive experiments demonstrate that DBCF produces high performance and exceeds the state-of-the-art methods. The dataset and source code can be found at https://github.com/bczhangbczhang.
C1 [Luan, Shangzhen; Wang, Xiaodi] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
   [Zhang, Baochang] Beihang Univ, Sch Automat Sci & Elect Engn, Sci & Technol Aircraft Control Lab, Beijing, Peoples R China.
   [Li, Yan] Beihang Univ, Sch Elect & Informat Engn, Natl Key Lab CNS ATM, Beijing, Peoples R China.
   [Zhang, Baochang] Shenzhen Acad Aerosp Technol, Shenzhen, Peoples R China.
C3 Beihang University; Beihang University; Beihang University; Shenzhen
   Academy of Aerospace Technology
RP Zhang, BC (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Sci & Technol Aircraft Control Lab, Beijing, Peoples R China.; Zhang, BC (corresponding author), Shenzhen Acad Aerosp Technol, Shenzhen, Peoples R China.
EM bczhang@139.com
FU Natural Science Foundation of China [61672079, 61473086]; Shenzhen
   Peacock Plan [KQTD2016112515134654]; Open Projects Program of National
   Laboratory of Pattern Recognition; shenzhen peacock plan
FX The work was supported by the Natural Science Foundation of China under
   Contract 61672079 and 61473086, and Shenzhen Peacock Plan
   KQTD2016112515134654. This work is supported by the Open Projects
   Program of National Laboratory of Pattern Recognition, and shenzhen
   peacock plan. Shangzhen Luan and Yan Li have the same contribution to
   this paper. We also want to thank Professor Zhu Lei of Hangzhou Dianzi
   University, who participated in writing and technical editing of the
   manuscript.
CR [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], ISPRS J PHOTOGRAMMET
   [Anonymous], 2017, 2017 IEEE INT C SIGN
   Benhimane S, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P337
   Boddeti VN, 2013, PROC CVPR IEEE, P2291, DOI 10.1109/CVPR.2013.297
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bolme DS, 2009, PROC CVPR IEEE, P2105, DOI 10.1109/CVPRW.2009.5206701
   Chen, 2017, IEEE T DEPEND SECURE, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Ding GG, 2018, IEEE T INTELL TRANSP, V19, P140, DOI 10.1109/TITS.2017.2774778
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   HESTER CF, 1980, APPL OPTICS, V19, P1758, DOI 10.1364/AO.19.001758
   Kiani H, 2014, IEEE IMAGE PROC, P1485, DOI 10.1109/ICIP.2014.7025297
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Linlin Yang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P680, DOI 10.1007/978-3-319-48896-7_67
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Ma C, 2015, IEEE INFOCOM SER
   Mahalanobis A, 1996, APPL OPTICS, V35, P3127, DOI 10.1364/AO.35.003127
   MAHALANOBIS A, 1987, APPL OPTICS, V26, P3633, DOI 10.1364/AO.26.003633
   MAHALANOBIS A, 1994, APPL OPTICS, V33, P3751, DOI 10.1364/AO.33.003751
   REFREGIER P, 1991, OPT LETT, V16, P829, DOI 10.1364/OL.16.000829
   Rodriguez A, 2013, IEEE T IMAGE PROCESS, V22, P631, DOI 10.1109/TIP.2012.2220151
   Savvides M, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P45, DOI 10.1109/AVSS.2003.1217900
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang BC, 2017, IEEE T SYST MAN CY-S, V47, P693, DOI 10.1109/TSMC.2016.2629509
   Zhang BC, 2017, IEEE T CIRC SYST VID, V27, P1515, DOI 10.1109/TCSVT.2016.2540978
   Zhang BC, 2016, INT J COMPUT VISION, V118, P364, DOI 10.1007/s11263-016-0880-y
   Zhang BC, 2015, PROC CVPR IEEE, P4557, DOI 10.1109/CVPR.2015.7299086
NR 38
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29919
EP 29932
DI 10.1007/s11042-018-6079-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800042
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ma, W
   Qin, Y
   Xu, SB
   Zhang, XP
AF Ma, Wei
   Qin, Yue
   Xu, Shibiao
   Zhang, Xiaopeng
TI Interactive stereo image segmentation via adaptive prior selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo image segmentation; Interactive segmentation; Prior selection;
   Multi-label MRF; Graph cut
AB Interactive stereo image segmentation (i.e., cutting out objects from stereo pairs with limited user assistance) is an important research topic in computer vision. Given a pair of images, users mark a few foreground/background pixels, based on which prior models are formulated for labeling unknown pixels. Note that color priors might not help if the marked foreground and background have similar colors. However, integrating multiple types of priors, e.g., color and disparity in segmenting stereo pairs, is not trivial. This is because differing pairs of images and even differing pixels in the same image might require different proportions of the priors. Besides, disparities of natural images are too noisy to be directly used. This paper presents a method that can adaptively determine the proportion of the priors (color or disparity) for each pixel. Specifically speaking, the segmentation problem is defined in the framework of MRF (Markov Random Field). We formulate an MRF energy function which is composed of clues from the two types of priors, as well as neighborhood smoothness and stereo correspondence constraints. The weights of the color and disparity priors at each pixel are treated as variables which are optimized together with the label (foreground or background) of the pixel. In order to overcome the noise problem, the weight of the disparity prior is controlled by a confidence value learned from data. The energy function is optimized by using multi-label graph cut. Experimental results show that our method performs well.
C1 [Ma, Wei; Qin, Yue] Beijing Univ Technol, Fac Informat Technol, 100 Pingleyuan St, Beijing 100124, Peoples R China.
   [Xu, Shibiao; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Beijing University of Technology; Chinese Academy of Sciences; Institute
   of Automation, CAS
RP Xu, SB; Zhang, XP (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM shibiao.xu@ia.ac.cn; xiaopeng.zhang@ia.ac.cn
FU National Natural Science Foundation of China [61771026, 61379096,
   61671451, 61502490]; Scientific Research Project of Beijing Educational
   Committee [KM201510005015]; Open Project Program of the National
   Laboratory of Pattern Recognition (NLPR) [4152006]; Beijing Municipal
   Natural Science Foundation [4152006]
FX This research is supported by National Natural Science Foundation of
   China (61771026, 61379096, 61671451, 61502490), Scientific Research
   Project of Beijing Educational Committee (KM201510005015), the Open
   Project Program of the National Laboratory of Pattern Recognition (NLPR)
   and Beijing Municipal Natural Science Foundation (4152006). Great thanks
   to Dr. Xing Su and Dr. Tong Li for helping proofread the paper.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Feng J, 2016, PROC CVPR IEEE, P156, DOI 10.1109/CVPR.2016.24
   Giró-i-Nieto X, 2014, MULTIMED TOOLS APPL, V70, P475, DOI 10.1007/s11042-013-1374-3
   Ju R, 2015, IEEE I CONF COMP VIS, P1724, DOI 10.1109/ICCV.2015.201
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim Y, 2014, IEEE T VIS COMPUT GR, V20, P957, DOI 10.1109/TVCG.2014.17
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lo W, 2010, ACM T GRAPHIC, V147, P1
   Luo SJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366201
   Ma W, 2016, COMPUT ANIMAT VIRT W, V27, P454, DOI 10.1002/cav.1671
   Ma W, 2016, IEEE SIGNAL PROC LET, V23, P1533, DOI 10.1109/LSP.2016.2605133
   Ma W, 2016, MULTIMED TOOLS APPL, V75, P10935, DOI 10.1007/s11042-015-2817-9
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Price BL, 2011, IEEE I CONF COMP VIS, P1148, DOI 10.1109/ICCV.2011.6126363
   Ran Ju, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P418, DOI 10.1007/978-3-319-03731-8_39
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Smith BM, 2009, PROC CVPR IEEE, P485, DOI 10.1109/CVPRW.2009.5206793
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xu N, 2016, PROC CVPR IEEE, P373, DOI 10.1109/CVPR.2016.47
   Zhang C, 2016, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2016.437
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2014, IET IMAGE PROCESS, V8, P509, DOI 10.1049/iet-ipr.2013.0375
NR 29
TC 1
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28709
EP 28724
DI 10.1007/s11042-018-6067-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500038
DA 2024-07-18
ER

PT J
AU Shu, X
   Jiang, HY
   Xu, HL
AF Shu, Xin
   Jiang, Haiyan
   Xu, Huanliang
TI Graph regularized supervised cross-view hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hashing; Cross-view retrieval; Spectral relaxation; Sequential learning
ID OBJECT
AB Hashing methods have received significant attention for effective and efficient large scale similarity search in computer vision and information retrieval community. However, most existing cross-view hashing methods mainly focus on either similarity preservation of data or cross-view correlation. In this paper, we propose a graph regularized supervised cross-view hashing (GSCH) to preserve both the semantic correlation and the intra-view and inter view similarity simultaneously. In particular, GSCH uses intra-view similarity to estimate inter-view similarity structure. We further propose a sequential learning approach to derive the hashing function for each view. Experimental results on benchmark datasets against state-of-the-art methods show the effectiveness of our proposed method.
C1 [Shu, Xin; Jiang, Haiyan; Xu, Huanliang] Nanjing Agr Univ, Coll Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing Agricultural University
RP Shu, X (corresponding author), Nanjing Agr Univ, Coll Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM xinshu@outlook.com
FU National Natural Science Foundation of China [61602248]; Fundamental
   Research Funds for the Central Universities [KYZ201549]; Natural Science
   Foundation of Jiangsu Province [BK20160741]
FX The authors would like to thank the anonymous referees for their
   constructive suggestions and comments. This work was supported by the
   National Natural Science Foundation of China (Grants No. 61602248), the
   Fundamental Research Funds for the Central Universities (Grants No.
   KYZ201549) and the Natural Science Foundation of Jiangsu Province
   (Grants No. BK20160741).
CR [Anonymous], 2015, P 24 INT JOINT C
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 2009, NEURIPS
   [Anonymous], ARXIV160305572
   [Anonymous], 2014, P 25 INT JOINT C ART
   [Anonymous], CVPR
   [Anonymous], CVPR
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   de Sa VR, 2010, MACH LEARN, V79, P47, DOI 10.1007/s10994-009-5157-z
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Hwang SJ, 2012, IEEE T PATTERN ANAL, V34, P1145, DOI 10.1109/TPAMI.2011.190
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu L, 2017, IEEE T IMAGE PROCESS, V26, P107, DOI 10.1109/TIP.2016.2619262
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Peng Y, 2017, NEUROCOMPUTING, V261, P242, DOI 10.1016/j.neucom.2016.05.113
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rastegari Mohammad, 2013, Book Predictable Dual-View Hashing
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen XB, 2016, NEUROCOMPUTING, V213, P14, DOI 10.1016/j.neucom.2016.01.121
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Torralba Antonio., 2008, COMPUTER VISION PATT, P1
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang Jun., 2010, ICML, P1127
   Wu CX, 2013, IEEE T KNOWL DATA EN, V25, P1380, DOI 10.1109/TKDE.2012.76
   Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
NR 43
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28207
EP 28224
DI 10.1007/s11042-018-5988-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500019
DA 2024-07-18
ER

PT J
AU Singh, A
   Singh, G
   Singh, K
AF Singh, Amneet
   Singh, Gurinder
   Singh, Kulbir
TI A Markov based image forgery detection approach by analyzing CFA
   artifacts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image interpolation; Demosaicing; CFA artifacts; Digital image
   forensics; Markov random process; Image forgery
ID EXPOSING DIGITAL FORGERIES; ENCRYPTION ALGORITHM; FORENSICS
AB The image acquisition device, the light is filtered through a Color Filter Array (CFA), where each pixel captures only one color (from Red, Green, and Blue), while others are calibrated. This process is known as interpolation process, and the artifacts introduced are called CFA or interpolation artifacts. The structure of these artifacts in the image is disturbed while a forgery is introduced in an image. In this paper, a high-order statistical approach is proposed to detect the inconsistencies in the artifacts of different parts of the image to expose any forgery present. The Markov Transition Probability Matrix (MTPM) is employed to develop various features that will detect the presence or absence of CFA artifacts in a particular region of the image. The Markov random process is applied because it provides an enhanced efficiency and reduced computational complexity for the forgery detection model. The algorithm is tested on 2 x 2 pixel block of the image which provides the results of a fine quality. There is no prior information of the location of the forged region of the image. The algorithm is tested on various images, taken from various social networking websites. The proposed forgery detection technique outperforms the existing state-of-the-art techniques for the different forgery scenarios by providing an average accuracy of 90.58%.
C1 [Singh, Amneet; Singh, Gurinder; Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, A (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM amneetsingh47@gmail.com; gurinder.singh@thapar.edu; ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019
OI Singh, Kulbir/0000-0001-8070-3395; Singh, Gurinder/0000-0002-1325-9164
CR [Anonymous], P 8 INT WORKSH INF H
   [Anonymous], P IEEE INT C IM PROC
   Bayram S, 2008, DIGIT INVEST, V5, P49, DOI 10.1016/j.diin.2008.06.004
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Cao H, 2009, IEEE INT SYMP CIRC S, P497, DOI 10.1109/ISCAS.2009.5117794
   Cao H, 2009, IEEE T INF FOREN SEC, V4, P899, DOI 10.1109/TIFS.2009.2033749
   Cheddad A, 2010, OPT COMMUN, V283, P879, DOI 10.1016/j.optcom.2009.10.106
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng SJ, 2011, COMMUN NONLINEAR SCI, V16, P3269, DOI 10.1016/j.cnsns.2010.12.016
   Dirik AE, 2009, 16 IEEE INT C IM PRO, P11
   Fan N, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P125
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Gallagher AC, 2008, IEEE COMP VIS PATT R, P21
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Kirchner M, 2010, P SPIE, V7541
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P1240, DOI 10.1109/TIFS.2017.2656823
   Li W., 2008, INT WORKSH LOC NONL, P1
   Li YT, 2013, WIRELESS PERS COMMUN, V72, P987, DOI 10.1007/s11277-013-1051-x
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Luo W, 2006, 18 INT C PATT REC IC, V4
   Mckay C, 2008, INT CONF ACOUST SPEE, P1657, DOI 10.1109/ICASSP.2008.4517945
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Singh G., 2016, MULTIMED TOOLS APPL, V75, P1
   Singh G, 2017, FORENSIC SCI INT, V277, P133, DOI 10.1016/j.forsciint.2017.06.003
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Swaminathan A, 2007, IEEE T INF FOREN SEC, V2, P91, DOI 10.1109/TIFS.2006.890307
   Xie X, 2016, P IEEE 29 INT C MICR
   Xie X, 2014, P SOL STAT SENS ACT
   Xie X, 2017, P IEEE 30 INT C MICR
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
NR 36
TC 16
Z9 17
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28949
EP 28968
DI 10.1007/s11042-018-6075-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500049
DA 2024-07-18
ER

PT J
AU Badal, T
   Nain, N
   Ahmed, M
AF Badal, Tapas
   Nain, Neeta
   Ahmed, Mushtaq
TI Online multi-object tracking: multiple instance based target appearance
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Appearance model; Motion structure; Sparse
   representation; Occlusion handling; Video analysis
ID MULTITARGET TRACKING; PARTICLE FILTER; ALGORITHM
AB The online target specific feature based state estimation method has proved its applicability in video-based multiple objects tracking. This paper proposes a multi-modal tracking approach by coupling a distance based tracker with an appearance based tracking method. This method is applicable for trajectory formation of multiple objects with complex random motion structure. Proximity measurement scheme is applied to introduce structural context information in tracking-by-detection framework. The multiple-instance framework is formulated to incorporate spatial-temporal information of a target, to select significant features and to establish the statistical correlation between a prior model of the target and its recent observation. The proposed approach improves tracking performance significantly by reducing the number of fragmented trajectories and ID switches. The quantitative, as well as qualitative performance of the proposed method, is evaluated on six benchmark video sequences with the challenging environment like random movement between objects and partial occlusion. The proposed approach performs better than other state-of-the-art methods used for multiple objects tracking.
C1 [Badal, Tapas; Ahmed, Mushtaq] Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.
   [Nain, Neeta] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur; National Institute of Technology (NIT
   System); Malaviya National Institute of Technology Jaipur
RP Badal, T (corresponding author), Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.
EM tapasbadal@gmail.com; nnain.cse@mnit.ac.in; mahmed.cse@mnit.ac.in
RI Ahmed, Mushtaq/GSN-9818-2022
OI AHMED, MUSHTAQ/0000-0002-7576-2531; Nain, Neeta/0000-0002-0550-0376
CR [Anonymous], 2015, ARXIV150401942
   [Anonymous], 2016, IEEE INT CON MULTI, DOI DOI 10.1109/JET-CAS.2016.2547681
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Badal T., 2017, 2017 IEEE INT C ID S, P1
   Badal T, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P110, DOI 10.1109/SITIS.2015.89
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Benezeth Y, 2008, INT C PATT RECOG, P237, DOI 10.1109/icpr.2008.4760998
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Czyz J, 2005, INT CONF ACOUST SPEE, P217
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Di Lascio R, 2013, COMPUT VIS IMAGE UND, V117, P892, DOI 10.1016/j.cviu.2013.04.004
   Ellis A., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P135, DOI 10.1109/AVSS.2010.89
   Fortmann T. E., 1980, Proceedings of the 19th IEEE Conference on Decision & Control Including the Symposium on Adaptive Processes, P807
   Fragkiadaki K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2073, DOI 10.1109/CVPR.2011.5995366
   Führ G, 2014, PATTERN RECOGN LETT, V39, P11, DOI 10.1016/j.patrec.2013.08.031
   Gordon N, 2004, KALMAN FILTER PARTIC, P830
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384
   Leal-Taixé L, 2014, PROC CVPR IEEE, P3542, DOI 10.1109/CVPR.2014.453
   Liu G, 2016, LECT NOTES COMPUT SC, V9948, P643, DOI 10.1007/978-3-319-46672-9_72
   Liu JJ, 2016, INT CONF MEAS, P878, DOI 10.1109/ICMTMA.2016.211
   Milan A, 2016, IEEE T PATTERN ANAL, V38, P2054, DOI 10.1109/TPAMI.2015.2505309
   Milan A, 2015, PROC CVPR IEEE, P5397, DOI 10.1109/CVPR.2015.7299178
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Papadourakis V, 2010, COMPUT VIS IMAGE UND, V114, P835, DOI 10.1016/j.cviu.2010.02.003
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Song XA, 2008, LECT NOTES COMPUT SC, V5304, P642, DOI 10.1007/978-3-540-88690-7_48
   Song Y., 2016, 2016 IEEE INT C VEHI, P1, DOI DOI 10.1109/ICVES.2016.7548171
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892
   Yang M, 2016, COMPUT VIS IMAGE UND, V153, P16, DOI 10.1016/j.cviu.2016.05.003
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
NR 39
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25199
EP 25221
DI 10.1007/s11042-018-5781-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400027
DA 2024-07-18
ER

PT J
AU Garg, D
   Garg, NK
   Kumar, M
AF Garg, Diksha
   Garg, Naresh Kumar
   Kumar, Munish
TI Underwater image enhancement using blending of CLAHE and percentile
   methodologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; CLAHE; Percentile; Blending; Contrast enhancement
ID COLOR CORRECTION
AB In this paper, a method has been proposed for enhancement of underwater images commonly suffering from low contrast and degraded shading quality. The entirety of the image is changed when we move to capture of images, from air to the water. During capturing some absorption, reflection and scattering effects are induced in the form of contrast, quality and noise as the images look hazy or blurred. This makes one shading to overwhelm the image. For use of underwater resources and overcome these factors the enhancement of the images is required. So, in this paper, we proposed a strategy for underwater image enhancement using Contrast-Limited Adaptive Histogram Equalization (CLAHE) and Percentile methodologies. Finally, these two methodologies are blended for improving the outcomes. Two parameters, namely, Root Mean Squared Error (RMSE) and entropy have been considered for comparing the experimental results of the proposed methodology with the state-of-the-art works. It has been noticed that the proposed system performs better than already existing techniques for underwater image enhancement.
C1 [Garg, Diksha; Garg, Naresh Kumar] Maharaja Ranjit Singh Punjab Tech Univ, Dept Comp Sci & Engn, GZS Campus Coll Engn & Technol, Bathinda, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, GZS Campus Coll Engn & Technol, Dept Comp Applicat, Bathinda, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, GZS Campus Coll Engn & Technol, Dept Comp Applicat, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Alex RS, 2016, OCEANS 2016 MTS IEEE, P1
   [Андреев А.В. Andreev A.V.], 2005, [Экологические системы и приборы, Ecological Systems and Devices, Ekologicheskie sistemy i pribory], P15
   [Anonymous], ABS161009462 CORR
   [Anonymous], 2013, MATH PROBL ENG
   [Anonymous], IEEE INT C SIGN PROC
   [Anonymous], P SPIE
   [Anonymous], 7 INT C INT SYST CON
   [Anonymous], 2017, Parasites Vectors, DOI DOI 10.1007/S11042-017-4752-4
   [Anonymous], P 24 INT C ART INT
   [Anonymous], SCALABLE COMPUT PRAC
   Basuki A, 2016, 2016 INTERNATIONAL CONFERENCE ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (KCIC), P120, DOI 10.1109/KCIC.2016.7883635
   Bhimani J, 2017, IEEE INT CONF CLOUD, P359, DOI 10.1109/CLOUD.2017.53
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Hitam Muhammad Suzuri, 2013, 2013 INT C COMPUTER
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li G, 2017, KNOWL-BASED SYST, V124, P46, DOI 10.1016/j.knosys.2017.02.034
   Liu H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P584, DOI 10.1109/ICDSP.2016.7868625
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Naim MJNM, 2012, APPL SOFT COMPUT, V12, P2948, DOI 10.1016/j.asoc.2012.04.028
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Schechner YY, 2004, PROC CVPR IEEE, P536
   Torres-Méndez LA, 2005, LECT NOTES COMPUT SC, V3757, P60, DOI 10.1007/11585978_5
   White EM, 2003, ANIM BEHAV, V65, P693, DOI 10.1006/anbe.2003.2117
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Xu Q, 2017, CLIN REHABIL, V31, P1583, DOI 10.1177/0269215517705689
   Yang J, 2017, CHIN CONTR CONF, P11227, DOI 10.23919/ChiCC.2017.8029148
   Yang Z, 2016, IEEE 35 INT PERFORM, P1
   Yang ZY, 2016, INT CONF CLOUD COMP, P245, DOI [10.1109/CloudCom.2016.46, 10.1109/CloudCom.2016.0049]
   Zheng LT, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P585, DOI 10.1109/ICInfA.2016.7831889
NR 31
TC 78
Z9 82
U1 2
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26545
EP 26561
DI 10.1007/s11042-018-5878-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500015
DA 2024-07-18
ER

PT J
AU Gayathri, J
   Subashini, S
AF Gayathri, J.
   Subashini, S.
TI A spatiotemporal chaotic image encryption scheme based on self adaptive
   model and dynamic keystream fetching technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Dynamic keystream fetching technique; Self adaptive
   model; Circular shift bit level permutation; Spatiotemporal chaotic
   system
ID BIT-LEVEL PERMUTATION; ALGORITHM; CIPHER; STANDARD; BREAKING; SYSTEM;
   MAP; CRYPTOSYSTEM; SECURITY
AB This paper proposes a block chaotic image encryption algorithm based on self-adaptive and dynamic key stream fetching technique (DKSFT) which makes use of a non-adjacent spatiotemporal chaotic system coupled with Tent-Sine system (NASC-TSS) for the chaotic orbit generation. The chaotic dynamics of NASC-TSS has incredible cryptographic properties contrasted with the existing 1D chaotic map. Firstly, a bit-level permutation strategy based on circular-shift operation is suggested which focuses to lessen the implications propelled by the classical permutationarchitectures. Finally, in the block based diffusion phase, a control parameter is designed to update the initial condition of the employed chaotic system. Subsequently, a unique keystream is generated for various plain-image processing which in turn elevates the complexity of breaking the proposed algorithm under known attacks. Furthermore, the pixel handling in both the permutation and the diffusion stages are done with DKSFT in which the keystream selection corresponds to the pixel position of the permutated-image. The adopted strategies such as self adaptive model and DKSFT can keep up the characteristics of the keystream fluctuating and dodge different sorts of attacks, undoubtedly the known-plaintext and chosen plaintext attacks. The investigation outcomes against a series of rigorous security analysis shows that the strong execution of the proposed cryptosystem against various attacks. These highlight an appealing security level with just a single round of encryption operation, making the algorithm impeccably appropriate for some unique interactive media applications.
C1 [Gayathri, J.; Subashini, S.] VIT Univ, Sch Elect Engn, Madras, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Gayathri, J (corresponding author), VIT Univ, Sch Elect Engn, Madras, Tamil Nadu, India.
EM gayathri.j2013@vit.ac.in; subashini.s@vit.ac.in
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   [Anonymous], APPL SOFT COMPUT
   [Anonymous], 2 IFAC C
   [Anonymous], INFORM SCIENCES
   [Anonymous], 2008, P SMCIS 2008
   [Anonymous], NONLINEAR DYN
   [Anonymous], DICOM DIG IM COMM ME
   [Anonymous], THEORY APPL COUPLED
   Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Bechikh R, 2015, SIGNAL PROCESS-IMAGE, V39, P151, DOI 10.1016/j.image.2015.09.006
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Bin Muhaya FT, 2013, TELECOMMUN SYST, V52, P573, DOI 10.1007/s11235-011-9462-z
   Caragata D, 2014, SIGNAL IMAGE VIDEO P, V8, P641, DOI 10.1007/s11760-013-0572-9
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Chen JX, 2014, OPTIK, V125, P2472, DOI 10.1016/j.ijleo.2013.12.001
   Chen JX, 2013, OPT EXPRESS, V21, P27873, DOI 10.1364/OE.21.027873
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Freedman D, 2007, Statistics, V4
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gayathri J., 2016, International Journal of Information and Computer Security, V8, P347
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   Jolfaei A, 2014, DIGIT SIGNAL PROCESS, V32, P34, DOI 10.1016/j.dsp.2014.05.011
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li CQ, 2014, SIGNAL PROCESS-IMAGE, V29, P914, DOI 10.1016/j.image.2014.06.011
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Li P, 2007, CHAOS SOLITON FRACT, V32, P1867, DOI 10.1016/j.chaos.2005.12.021
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Wang SH, 2004, INT J MOD PHYS B, V18, P2617, DOI 10.1142/S0217979204025798
   Wang XY, 2013, NONLINEAR DYNAM, V72, P707, DOI 10.1007/s11071-012-0747-x
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang XY, 2012, NONLINEAR DYNAM, V67, P365, DOI 10.1007/s11071-011-9984-7
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2014, APPL SOFT COMPUT, V22, P351, DOI 10.1016/j.asoc.2014.05.025
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang W, 2012, OPT COMMUN, V285, P2343, DOI 10.1016/j.optcom.2012.01.029
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YQ, 2013, NONLINEAR ANAL-MODEL, V18, P526, DOI 10.15388/NA.18.4.13977
   Zhang Y, 2014, OPTIK, V125, P5560, DOI 10.1016/j.ijleo.2014.07.009
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu CX, 2013, NONLINEAR DYNAM, V71, P25, DOI 10.1007/s11071-012-0639-0
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 80
TC 22
Z9 23
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24751
EP 24787
DI 10.1007/s11042-018-5675-4
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400009
DA 2024-07-18
ER

PT J
AU Chen, HT
   He, YZ
   Hsu, CC
AF Chen, Hua-Tsung
   He, Yu-Zhen
   Hsu, Chun-Chieh
TI Computer-assisted yoga training system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sports training; Multimedia system; Computer vision; Image processing;
   Yoga; Posture analysis; Body skeleton
ID TABLE-TENNIS SIMULATION; SPORTS VIDEO; GOLF
AB Self-training is essential in sports exercise. However, without the instruction of a coach, a practitioner may progress to a limited extent. Improper postures may even cause serious harm to muscles and ligaments of the body. Hence, the development of computer-assisted self-training systems for sports exercise is a recently emerging research topic. In this paper, we propose a yoga self-training system, which aims at instructing the practitioner to perform yoga poses correctly, assisting in rectifying poor postures, and preventing injury. Integrating computer vision techniques, the proposed system analyzes the practitioner's posture from both front and side views by extracting the body contour, skeleton, dominant axes, and feature points. Then, based on the domain knowledge of yoga training, visualized instructions for posture rectification are presented so that the practitioner can easily understand how to adjust his/her posture. Experiments on twelve yoga poses performed by different practitioners validate the feasibility of the proposed system in yoga training.
C1 [Chen, Hua-Tsung] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [He, Yu-Zhen; Hsu, Chun-Chieh] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
C3 Feng Chia University; National Yang Ming Chiao Tung University
RP Chen, HT (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM huatchen@fcu.edu.tw
FU [MOST-106-2221-E-009-196];  [MOST-106-2221-E-035-102]; 
   [MOST-105-2221-E-009-065];  [MOST-104-3115-E-009-001];  [ICTL-103-Q528];
    [ATU-103-W958]
FX This research is supported in part by MOST-106-2221-E-009-196,
   MOST-106-2221-E-035-102, MOST-105-2221-E-009-065,
   MOST-104-3115-E-009-001, ICTL-103-Q528, and ATU-103-W958.
CR Brunnett G, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.92
   Chen H, 2013, TISSUE BARRIERS, V1, DOI 10.4161/tisb.27463
   Chen HT, 2009, MULTIMED TOOLS APPL, V6, P641
   Chen HT, 2008, J INF SCI ENG, V24, P143
   Chen HT, 2012, J VIS COMMUN IMAGE R, V23, P932, DOI 10.1016/j.jvcir.2012.06.003
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Chen-Chiung Hsieh, 2011, Journal of Computers, V6, P2382, DOI 10.4304/jcp.6.11.2382-2388
   Chong A.K., 2008, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXXXVII, P921
   Chong AK, 2009, PHOTOGRAMM REC, V24, P51, DOI 10.1111/j.1477-9730.2009.00517.x
   Chou CW, 2009, INT CONF ACOUST SPEE, P1921, DOI 10.1109/ICASSP.2009.4959985
   Ghasemzadeh H, 2009, J AMB INTEL SMART EN, V1, P173, DOI 10.3233/AIS-2009-0021
   Harris C., 1988, Proc. of the 4th Alvey Vision Conference, P189
   Höferlin M, 2010, COMPUT GRAPH FORUM, V29, P1053, DOI 10.1111/j.1467-8659.2009.01670.x
   Hu MC, 2011, IEEE T MULTIMEDIA, V13, P266, DOI 10.1109/TMM.2010.2100373
   Hua-Tsung Chen, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457819
   Hua-Tsung Chen, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P496, DOI 10.1007/978-3-319-04114-8_42
   Kelly P., 2010, Proceedings of the 2010 ACM workshop on Surreal media and virtual cloning, P51, DOI DOI 10.1145/1878083.1878098
   King K, 2008, SENSOR ACTUAT A-PHYS, V141, P619, DOI 10.1016/j.sna.2007.08.028
   Luo ZQ, 2011, P IEEE VIRT REAL ANN, P261, DOI 10.1109/VR.2011.5759498
   Miles HC, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P56, DOI 10.1109/CW.2013.45
   Miles HC, 2012, COMPUT GRAPH-UK, V36, P714, DOI 10.1016/j.cag.2012.04.007
   Noiumkar S, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATICS AND CREATIVE MULTIMEDIA (ICICM), P310, DOI 10.1109/ICICM.2013.58
   Patil S., 2011, 2011 IEEE Control and System Graduate Research Colloquium (ICSGRC), P43, DOI 10.1109/ICSGRC.2011.5991827
   Rector Kyle, 2013, P 15 INT ACM SIGACCE, P1, DOI [https://doi.org/10.1145/2513383, DOI 10.1145/2513383.2513392]
   Rusdorf S, 2007, IEEE T VIS COMPUT GR, V13, P15, DOI 10.1109/TVCG.2007.18
   Shih C, 2012, J INTELL ROBOT SYST, V67, P25, DOI 10.1007/s10846-011-9639-4
   Sousa L., 2016, COMPUT VIS MEDIA, V2, P183, DOI DOI 10.1007/S41095-016-0047-3
   Wu W., 2010, Power and Energy Society General Meeting, 2010 IEEE, P1
   Zhu GY, 2009, SIGNALS COMMUN TECHN, P295, DOI 10.1007/978-0-387-76569-3_11
   Zhu GY, 2009, IEEE T MULTIMEDIA, V11, P49, DOI 10.1109/TMM.2008.2008918
NR 30
TC 23
Z9 25
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23969
EP 23991
DI 10.1007/s11042-018-5721-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900038
DA 2024-07-18
ER

PT J
AU Huang, XD
   Yang, L
   Song, RN
   Lu, W
AF Huang, Xiangdong
   Yang, Lin
   Song, Runan
   Lu, Wei
TI Effective pattern recognition and find-density-peaks clustering based
   blind identification for underdetermined speech mixing systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underdetermined blind identification; Phase uniformity; Harmonics;
   Find-density-peaks (FDP) clustering
ID SOURCE SEPARATION; MIXTURES; SIGNALS; ALGORITHM; RECOVERY
AB In order to achieve high-efficiency blind identification (BI) for underdetermined speech mixing systems without recovery degradation, this paper proposes a novel BI scheme based on effective pattern recognition and the find-density-peaks (FDP) clustering algorithm. To lower BI's computational complexity, a 3-step effective pattern recognition procedure is proposed, which consists of voiced-sound pattern sifting, spectrum correction based harmonic representation and phase uniformity based single-active-source (SAS) pattern recognition. Furthermore, a 5-step FDP clustering procedure is summarized and utilized to determine the souce number and estimate all the columns of the mixing matrix. Our experimental results showed that, the proposed 3-step effective pattern recognition procedure can condense the original 56383 TF patterns into only 194 effective SAS patterns, which considerably alleviates the computational burden of BI. Moreover, by means of FDP clustering, not only the source number can be intuitively and readily determined, but also the mixing matrix can be estimated with a higher recovery SNR than the existing BI schemes. Due to harmonic-like components are of wide applications, our proposed BI scheme possesses a vast potential in other harmonics-related blind-signal-separation (BSS) fields such as mechanical vibration analysis, channel estimation in communication.
C1 [Huang, Xiangdong; Yang, Lin; Song, Runan; Lu, Wei] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Huang, XD (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM xdhuang@tju.edu.cn; lin033yang@163.com; 13775991260@163.com;
   luwei@tju.edu.cn
FU Qingdao National Laboratory for Marine Science and Technology
   [QNLM2016OPR0411]
FX This work was financially supported by Qingdao National Laboratory for
   Marine Science and Technology under Grant No. QNLM2016OPR0411.
CR Abrard F, 2005, SIGNAL PROCESS, V85, P1389, DOI 10.1016/j.sigpro.2005.02.010
   Aissa-El-Bey A, 2007, IEEE T SIGNAL PROCES, V55, P897, DOI 10.1109/TSP.2006.888877
   [Anonymous], 2008, ADV DIGITAL SIGNAL P
   Bofill P, 2001, SIGNAL PROCESS, V81, P2353, DOI 10.1016/S0165-1684(01)00120-7
   Florea C, 2014, J MATH IMAGING VIS, V49, P173, DOI 10.1007/s10851-013-0449-0
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Ge SA, 2015, CIRC SYST SIGNAL PR, V34, P2935, DOI 10.1007/s00034-015-9969-8
   HAYES MH, 1980, IEEE T ACOUST SPEECH, V28, P672, DOI 10.1109/TASSP.1980.1163463
   He ZS, 2009, IEEE T SIGNAL PROCES, V57, P399, DOI 10.1109/TSP.2008.2007605
   Jourjine A, 2000, INT CONF ACOUST SPEE, P2985, DOI 10.1109/ICASSP.2000.861162
   Koeipensri T, 2016, 9 BIOM ENG INT C BMI, P1
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu BX, 2014, IEEE T SIGNAL PROCES, V62, P4947, DOI 10.1109/TSP.2014.2329646
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   O'Grady PD, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/784296
   Qiao ZJ, 2017, MECH SYST SIGNAL PR, V84, P731, DOI 10.1016/j.ymssp.2016.08.030
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Saab R, 2007, IEEE T SIGNAL PROCES, V55, P4004, DOI 10.1109/TSP.2007.895998
   Sha ZC, 2013, IET COMMUN, V7, P1456, DOI 10.1049/iet-com.2013.0276
   SIEGEL LJ, 1982, IEEE T ACOUST SPEECH, V30, P451, DOI 10.1109/TASSP.1982.1163910
   Xie SL, 2012, IEEE T NEUR NET LEAR, V23, P306, DOI 10.1109/TNNLS.2011.2177475
   Xu ZJ, 2017, IET COMMUN, V11, P1282, DOI 10.1049/iet-com.2016.1333
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
   Zhang FS, 2001, IEEE T POWER DELIVER, V16, P160, DOI 10.1109/61.915476
   Zhou GX, 2011, IEEE T NEURAL NETWOR, V22, P211, DOI 10.1109/TNN.2010.2091427
NR 29
TC 2
Z9 2
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22115
EP 22129
DI 10.1007/s11042-018-5619-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500019
DA 2024-07-18
ER

PT J
AU Shamsafar, F
   Ebrahimnezhad, H
AF Shamsafar, Faranak
   Ebrahimnezhad, Hossein
TI Understanding holistic human pose using class-specific convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human pose estimation; Holistic pose; RGB images; Unconstrained
   conditions; Deep learning; Convolutional neural network
AB This paper presents a method to capture human pose from individual real-world RGB images using a deep learning technique. The current works on estimating human pose by deep learning are designed in a detection or a regression framework, and in a part-based manner. As a new perspective, we introduce a classification scheme for this problem, which reasons the pose holistically. To the best of our knowledge, this is the first work for holistic human pose classification task that owes its feasibility to the great power of convolutional neural networks in feature learning. After training a convolutional neural network to classify the input image to one of the KeyPoses, the final pose is computed as a linear combination of several KeyPoses. In this new holistic classification attitude, the vast and high degree of freedom human pose space is divided into a finite number of subspaces and the convolutional neural network shows promising results in learning the features of each subspace. Empirical results (PCP and PCK rates) demonstrate that the proposed scheme is successfully able to understand human pose (i.e., predict a valid, true and coarse pose) in real-world unconstrained images with challenges like severe occlusion, high articulation, low quality and cluttered background. Furthermore, using the proposed method, the need for defining a complex model (such as appearance model or joints pairwise relations) is relieved. We have also verified a potential application of our proposed method in semantic image retrieval based on human pose.
C1 [Shamsafar, Faranak; Ebrahimnezhad, Hossein] Sahand Univ Technol, Comp Vis Res Lab, Elect Engn Fac, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Comp Vis Res Lab, Elect Engn Fac, Tabriz, Iran.
EM f_shamsafar@sut.ac.ir; ebrahimnezhad@sut.ac.ir
RI Ebrahimnezhad, Hossein/ACP-2704-2022; Shamsafar, Faranak/H-4681-2012;
   ebrahimnezhad, hossein/ABC-3865-2021
OI Shamsafar, Faranak/0000-0002-1146-1721; ebrahimnezhad,
   hossein/0000-0003-4071-2750
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2014, ARXIV14065212
   [Anonymous], 2013, INT C COMP VIS ICCV
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   [Anonymous], 2009, INT C COMP VIS ICCV
   [Anonymous], 2016, AAAI C ART INT
   [Anonymous], ARXIV13127302
   [Anonymous], 2014, IEEE C COMP VIS PATT
   Belagiannis V, 2015, IEEE I CONF COMP VIS, P2830, DOI 10.1109/ICCV.2015.324
   Belagiannis Vasileios, 2014, ARTICULATED MOTION D
   Berg A., 2010, Large scale visual recognition challenge
   Bütepage J, 2017, PROC CVPR IEEE, P1591, DOI 10.1109/CVPR.2017.173
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chao YW, 2017, PROC CVPR IEEE, P3643, DOI 10.1109/CVPR.2017.388
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen X., 2014, Advances in neural information processing systems, P1736, DOI DOI 10.1109/CVPR.2018.00742
   Chen Y, 2016, APPL SOFT COMPUT, V38, P1088, DOI 10.1016/j.asoc.2015.06.048
   Chu X., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1831, DOI DOI 10.1109/CVPR.2017.601
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eichner Marcin., 2009, BMVC
   Everingham M., 2010, BMVC, V2, P5
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Felzenszwalb PF, 2008, IEEE CONFERENCE ON C
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Ghodrati A, 2015, INTERNATIONAL CONFER
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He T, 2017, NEURAL COMPUT APPL, V28, P3827, DOI 10.1007/s00521-016-2277-9
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ionescu C, 2011, IEEE I CONF COMP VIS, P2220, DOI 10.1109/ICCV.2011.6126500
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   Kadkhodamohammadi A, 2015, LECT NOTES COMPUT SC, V9349, P363, DOI 10.1007/978-3-319-24553-9_45
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lifshitz I, 2016, LECT NOTES COMPUT SC, V9906, P246, DOI 10.1007/978-3-319-46475-6_16
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pfister T, 2015, IEEE C COMP VIS PATT
   Pfister T, 2015, LECT NOTES COMPUT SC, V9003, P538, DOI 10.1007/978-3-319-16865-4_35
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Pishchulin L, 2015, IEEE C COMP VIS PATT
   Ramanan D., 2006, NEURAL INFORM PROCES
   Rogez G, 2008, PROC CVPR IEEE, P2142
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Tompson Jonathan, 2014, ARXIV14062984, DOI DOI 10.5555/2968826.2969027
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Tran D, 2010, EUR C COMP VIS ECCV
   Uijlings JRR, 2015, IEEE C COMP VIS PATT
   Wang Y, 2011, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2011.5995519, DOI 10.1109/CVPR.2011.5995519]
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Ye Liu, 2012, 21 INT C PATT REC IC
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Zagoruyko S., 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhou F, 2016, IEEE T PATTERN ANAL, V38, P1492, DOI 10.1109/TPAMI.2016.2526002
NR 73
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23193
EP 23225
DI 10.1007/s11042-018-5617-1
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900006
DA 2024-07-18
ER

PT J
AU Wu, C
   Huang, C
   Chen, H
AF Wu, Chenjian
   Huang, Chengwei
   Chen, Hong
TI Text-independent speech emotion recognition using frequency adaptive
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Teager energy operator; Formant frequency; Speech emotion recognition;
   Feature extraction
AB In this paper a text-independent emotional speech feature extraction method is studied based on various spectral frequency bands of speech formants. First, the speech emotional feature analysis is performed for different text contents. Various sentences are involved to study the phonetic influences. Formant frequencies are grouped into different classes in order to reduce the text variability. These speech features are sensitive to phonetic changes in the sentence. Speaker emotions are then modeled in different formant groups. Second, adaptive fundamental frequency and Teager Energy Operator are constructed in different frequency bands. The Teager frequency bands are dynamically adapted to different pitch and formant distributions. The proposed adaptation is sensitive to emotional changes in speech, as shown in statistics of mean, variance, maximum and minimum. Statistics on the basic acoustic parameters are used as the emotional features. Experimental results show that the proposed emotional features are robust against text changes with the lowest variance value of 0.034. The final recognition results for six major emotion types are improved constantly and 5 percent improvement for sadness and 3.3 percent improvement for boredom are observed.
C1 [Wu, Chenjian] Soochow Univ, Sch Elect Informat, Suzhou 215006, Peoples R China.
   [Huang, Chengwei] Soochow Univ, Coll Phys Optoelect & Energy, Suzhou 215006, Peoples R China.
   [Chen, Hong] Soochow Univ, Sch Math Sci, Suzhou 215006, Peoples R China.
C3 Soochow University - China; Soochow University - China; Soochow
   University - China
RP Chen, H (corresponding author), Soochow Univ, Sch Math Sci, Suzhou 215006, Peoples R China.
EM cjwu@suda.edu.cn; huangcwx@vip.126.com; chenhong@suda.edu.cn
RI Huang, Chengwei/AER-6849-2022
OI Huang, Chengwei/0000-0001-9060-6361
FU National Natural Science Foundation of China [11401412]; Natural Science
   Foundation of Jiangsu Province of China [BK20150342]
FX This work was supported by the National Natural Science Foundation of
   China (No. 11401412) and Natural Science Foundation of Jiangsu Province
   of China (No. BK20150342). The authors would like to thank NVIDIA for
   their generous donation of Titan X GPU, which eased the computation
   burden for expression modeling.
CR Ali Syed Abbas, 2015, International Journal of Information Technology and Computer Science, V7, P54, DOI 10.5815/ijitcs.2015.02.07
   Augustine N, 2015, ADV RES ELECT ELECT, V2, P50
   Boudraa AO, 2004, ISCCSP : 2004 FIRST INTERNATIONAL SYMPOSIUM ON CONTROL, COMMUNICATIONS AND SIGNAL PROCESSING, P45
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Chen M, 2015, IEEE WIREL COMMUN, V22, P20, DOI 10.1109/MWC.2015.7054715
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Huang C, 2013, RES SEVEAL KEY TECHN
   Hui G, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 3, PROCEEDINGS, P394, DOI 10.1109/SNPD.2007.487
   Lanjewar RB, 2015, PROCEDIA COMPUT SCI, V49, P50, DOI 10.1016/j.procs.2015.04.226
   Li X, 2013, CHIN J SCI INSTRUM, V34, P123
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu YJ, 2016, J CHEM-NY, V2016, DOI 10.1155/2016/6903524
   Pankratova A, 2014, PERSONAL INDIVID DIF, V60, P75
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Shah M, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0049-y
   Song P, 2015, LECT NOTES COMPUT SC, V9428, P393, DOI 10.1007/978-3-319-25417-3_46
   Wang CY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1394, DOI 10.18653/v1/P17-1128
   Xiang L, 2011, J COMPUT, V6, P989, DOI 10.4304/jcp.6.5.989-998
   Zhang H, 2015, INT CONF ACOUST SPEE, P246, DOI 10.1109/ICASSP.2015.7177969
NR 22
TC 11
Z9 11
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24353
EP 24363
DI 10.1007/s11042-018-5742-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900056
DA 2024-07-18
ER

PT J
AU Ben Abdallah, T
   Guermazi, R
   Hammami, M
AF Ben Abdallah, Taoufik
   Guermazi, Radhouane
   Hammami, Mohamed
TI Facial-expression recognition based on a low-dimensional temporal
   feature space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial-expression recognition; Pyramid of uniform Temporal Local Binary
   Pattern (PTLBPu2); Principal Component Analysis (PCA); Discriminating
   sub-regions; Low-dimensional feature space
ID OPTICAL-FLOW; ALGORITHM; TEXTURE
AB This paper suggests a facial-expression recognition in accordance with face video sequences based on a newly low-dimensional feature space proposed. Indeed, we extract a Pyramid of uniform Temporal Local Binary Pattern representation, using only XT and YT orthogonal planes (PTLBP (u2)). Then, a Wrapper method is applied to select the most discriminating sub-regions, and therefore, reduce the feature space that is going to be projected on a low-dimensional feature space by applying the Principal Component Analysis (PCA). Support Vector Machine (SVM) and C4.5 algorithm have been tested for the classification of facial expressions. Experiments conducted on CK + and MMI, which are the two famous facial-expression databases, have shown the effectiveness of the approach proposed under a lab-controlled environment with more than 97% of recognition rate as well as under an uncontrolled environment with more than 92%.
C1 [Ben Abdallah, Taoufik] Univ Sfax, Fac Econ & Management Sfax FSEGS, MIR CL Lab, Sfax, Tunisia.
   [Guermazi, Radhouane] Saudi Elect Univ, Riyadh, Saudi Arabia.
   [Hammami, Mohamed] Univ Sfax, FSS, MIR CL Lab, Sfax, Tunisia.
C3 Universite de Sfax; Saudi Electronic University; Universite de Sfax
RP Ben Abdallah, T (corresponding author), Univ Sfax, Fac Econ & Management Sfax FSEGS, MIR CL Lab, Sfax, Tunisia.
EM taoufik.benabdallah@fsegs.rnu.tn; r.guermazi@seu.edu.sa;
   mohamed.hammami@fss.rnu.tn
OI Hammami, Mohamed/0000-0003-3580-0473; Guermazi,
   Radhouane/0000-0003-4230-5024
CR [Anonymous], 2005, P 13 ACM INT C MULT
   [Anonymous], THESIS
   [Anonymous], CEA 07 P INT C COMP
   [Anonymous], 2014, J INF SYST TELECOMMU
   [Anonymous], DATA CLASSIFICATION
   [Anonymous], 2004, NIPS
   [Anonymous], J INFORM COMPUTATION
   [Anonymous], FAC EXPR AN COMPL PO
   [Anonymous], 2013 6 INT C MACH VI
   [Anonymous], 1990, SUPPORT VECTOR LEARN
   [Anonymous], 2002, ADV NEURAL INFORM PR
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], 2005, Int. J. Inf. Technol.
   Branco P, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2907070
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chen Junkai., 2016, IEEE Transactions on Affective Computing
   Cheng HD, 2004, DIGIT SIGNAL PROCESS, V14, P158, DOI 10.1016/j.dsp.2003.07.002
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Donia ManarMF., 2014, Computer and Information Science, V7, P31, DOI DOI 10.5539/CIS.V7N3P31
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Ekman P., 1972, UNIVERSALS CULTURAL
   Fan XJ, 2015, PATTERN RECOGN, V48, P3407, DOI 10.1016/j.patcog.2015.04.025
   Fu XF, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P115, DOI 10.1109/ICNC.2008.94
   FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Guo YM, 2016, IEEE T IMAGE PROCESS, V25, P1977, DOI 10.1109/TIP.2016.2537215
   Happy S.L., 2012, Proceedings of the 4th international conference on intelligent human computer interaction (IHCI), P1, DOI [10.1109/ihci.2012.6481802, DOI 10.1109/IHCI.2012.6481802]
   Ji Y, 2012, PATTERN RECOGN LETT, V33, P1373, DOI 10.1016/j.patrec.2012.03.006
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Khan RA, 2012, IEEE IMAGE PROC, P2593, DOI 10.1109/ICIP.2012.6467429
   Ki-Chung Chung, 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P53, DOI 10.1109/RATFG.1999.799223
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kotsia I, 2008, PATTERN RECOGN, V41, P833, DOI 10.1016/j.patcog.2007.06.026
   Kumar J, 2015, PROCEDIA COMPUT SCI, V58, P486, DOI 10.1016/j.procs.2015.08.011
   Lee TZ, 2016, PERTANIKA J SCI TECH, V24, P191
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Mayer C., 2014, Pattern Recognition and Image Analysis, V24, P124, DOI 10.1134/S1054661814010106
   Pu XR, 2015, NEUROCOMPUTING, V168, P1173, DOI 10.1016/j.neucom.2015.05.005
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Samad R, 2011, ARTIF LIFE ROBOT, V16, P21, DOI 10.1007/s10015-011-0871-6
   Sanchez A, 2011, NEUROCOMPUTING, V74, P1272, DOI 10.1016/j.neucom.2010.07.017
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shin G, 2008, STUD COMPUT INTELL, V149, P27, DOI 10.1007/978-3-540-70560-4_3
   Suk M, 2014, IEEE COMPUT SOC CONF, P132, DOI 10.1109/CVPRW.2014.25
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Ting KC, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P792, DOI 10.1109/ICCCE.2008.4580714
   Vapnik V., 1999, NATURE STAT LEARNING
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wan SH, 2014, PATTERN RECOGN, V47, P1859, DOI 10.1016/j.patcog.2013.11.025
   Wang J, 2014, INT C PATT RECOG, P4594, DOI 10.1109/ICPR.2014.786
   Wang YM, 2015, C HUM SYST INTERACT, P362, DOI 10.1109/HSI.2015.7170694
   WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410
   Yeasin M, 2005, IEEE IJCNN, P3087
   Yu KM, 2012, IEEE INT CONF MULTI, P290, DOI 10.1109/ICMEW.2012.56
   Zhang LG, 2014, IMAGE VISION COMPUT, V32, P107, DOI 10.1016/j.imavis.2013.12.008
   Zhang X, 2015, MACH VISION APPL, V26, P467, DOI 10.1007/s00138-015-0677-y
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
NR 63
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19455
EP 19479
DI 10.1007/s11042-017-5354-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500026
DA 2024-07-18
ER

PT J
AU Hajizadeh, M
   Ebrahimnezhad, H
AF Hajizadeh, Mohammadali
   Ebrahimnezhad, Hossein
TI Eigenspace compression: dynamic 3D mesh compression by restoring fine
   geometry to deformed coarse models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Animated 3D mesh compression; Dynamic geometry; Graph laplacian; Fixed
   details; Coarse model; Details restoration
ID PREDICTIVE COMPRESSION; SPECTRAL COMPRESSION; APPROXIMATION;
   FACTORIZATION
AB Dynamic 3D mesh compression is of great practical important issues in computer graphics and multimedia applications. In this paper, an efficient compression algorithm is proposed to represent animated mesh sequences in a compact way, so that the storage and transmission of dynamic 3D meshes can be accomplished efficiently. The focus of this paper is on the animated mesh sequences with shared connectivity. The proposed method first computes coarse models (low frequency modes) of the animated sequence using the graph Laplacian matrix. Obtained coordinate weights are used at the decoder to reconstruct the coarse models of the sequence. Then, a novel approach is proposed to extract fixed details (high frequency modes or finer features) of the animated mesh. Finally, a details restoration process is applied at the decoder to add details back to the coarse models of the reconstructed sequence. The superiority of the proposed method to the current state of the arts is demonstrated in terms of low data rates for a given degree of perceived distortion.
C1 [Hajizadeh, Mohammadali; Ebrahimnezhad, Hossein] Sahand Univ Technol, Dept Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Dept Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
EM m_hajizadeh@sut.ac.ir; ebrahimnezhad@sut.ac.ir
RI ebrahimnezhad, hossein/ABC-3865-2021; Ebrahimnezhad,
   Hossein/ACP-2704-2022
OI ebrahimnezhad, hossein/0000-0003-4071-2750; 
CR Ahn JH, 2001, ELECTRON LETT, V37, P1445, DOI 10.1049/el:20010993
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   ALLIEZ P, 2003, P S MULT GEOM MOD
   Amjoun R, 2008, J VIRTUAL REAL BROAD, V5
   AMJOUN R, 2007, J WSCG, V15, P32
   Amjoun R, 2009, THESIS
   Amjoun R, 2006, LECT NOTES COMPUT SC, V4035, P606
   Amjoun R, 2009, COMPUT AIDED DESIGN, V41, P711, DOI 10.1016/j.cad.2009.02.013
   [Anonymous], 3DTV C
   Belkin M, 2008, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SGG'08), P278, DOI 10.1145/1377676.1377725
   Ben-Chen M, 2005, ACM T GRAPHIC, V24, P60, DOI 10.1145/1037957.1037961
   Bici MO, 2011, J VIS COMMUN IMAGE R, V22, P577, DOI 10.1016/j.jvcir.2011.07.006
   Boulfani-Cuisinaud Y, 2007, IEEE IMAGE PROC, P217
   Briceno H. M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P136
   Dey TK, 2012, VISUAL COMPUT, V28, P585, DOI 10.1007/s00371-012-0705-0
   Dhibi N, 2017, MULTIMED TOOLS APPL, V76, P20869, DOI 10.1007/s11042-016-3996-8
   Guskov I., 2004, Proc. 2004 ACM SIG- GRAPH/Eurographics Symp. Comput. Animation (SCA '04), P183
   Hajizadeh M, 2016, COMPUT ANIMAT VIRT W, V27, P556, DOI 10.1002/cav.1685
   He YC, 2014, MULTIMED TOOLS APPL, V72, P1441, DOI 10.1007/s11042-013-1465-1
   Heu JH, 2009, J VIS COMMUN IMAGE R, V20, P439, DOI 10.1016/j.jvcir.2009.05.003
   Hildebrandt K, 2011, COMPUT GRAPH FORUM, V30, P1513, DOI 10.1111/j.1467-8659.2011.02025.x
   Ibarria L., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P126
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Kennedy R, 2016, COMPUT VIS IMAGE UND, V150, P139, DOI 10.1016/j.cviu.2016.04.011
   Lengyel J. E., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P89, DOI 10.1145/300523.300533
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Lin Y, 2017, INT JOINT C NEUR NET
   Maglo A, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2693443
   Malik J., 2014, ADV NEURAL INFORM PR, P55
   Mamou K, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P711
   Mamou K, 2006, COMPUT ANIMAT VIRT W, V17, P337, DOI 10.1002/cav.137
   Mansouri S, 2016, MULTIMED TOOLS APPL, V75, P8347, DOI 10.1007/s11042-015-2753-8
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Min Lu, 2010, Computer Vision - ACCV 2010 Workshops. ACCV 2010 International Workshops. Revised Selected Papers, P306, DOI 10.1007/978-3-642-22819-3_31
   Müller K, 2006, SIGNAL PROCESS-IMAGE, V21, P812, DOI 10.1016/j.image.2006.07.002
   Muller K., 2005, IEEE INT C IM PROC, V1, p621 624
   Payan F., 2005, P IEEE ACIDCA ICMI
   Payan F, 2007, COMPUT GRAPH-UK, V31, P77, DOI 10.1016/j.cag.2006.09.009
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Sattler Mirko, 2005, P ACM SIGGRAPH EUR S, P209
   Shi YH, 2014, MULTIMED TOOLS APPL, V70, P2125, DOI 10.1007/s11042-012-1231-9
   STEFANOSKI N, 2007, 3DTV C 2007, P1, DOI DOI 10.1109/3DTV.2007.4379461
   Stefanoski N, 2006, IEEE IMAGE PROC, P2973, DOI 10.1109/ICIP.2006.312961
   Stefanoski N, 2010, COMPUT GRAPH FORUM, V29, P101, DOI 10.1111/j.1467-8659.2009.01547.x
   Stefanoski N, 2008, IEEE IMAGE PROC, P2696, DOI 10.1109/ICIP.2008.4712350
   Vása L, 2014, COMPUT GRAPH FORUM, V33, P145, DOI 10.1111/cgf.12304
   Vása L, 2009, COMPUT GRAPH FORUM, V28, P1529, DOI 10.1111/j.1467-8659.2008.01304.x
   Vása L, 2011, IEEE T VIS COMPUT GR, V17, P220, DOI 10.1109/TVCG.2010.38
   Vása L, 2010, COMPUT GRAPH FORUM, V29, P1921, DOI 10.1111/j.1467-8659.2010.01659.x
   Vása L, 2009, COMPUT ANIMAT VIRT W, V20, P447, DOI 10.1002/cav.227
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang M, 2016, IEEE INT C VIS COMM
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Yan Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3988
   Yang JH, 2002, IEEE T CIRC SYST VID, V12, P1178, DOI 10.1109/TCSVT.2002.806814
   Zhang H, 2010, COMPUT GRAPH FORUM, V29, P1865, DOI 10.1111/j.1467-8659.2010.01655.x
   Zhang JH, 2004, IEEE DATA COMPR CONF, P508
   Zhang JH, 2007, COMPUT GRAPH-UK, V31, P463, DOI 10.1016/j.cag.2006.12.002
NR 62
TC 7
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19347
EP 19375
DI 10.1007/s11042-017-5394-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500021
DA 2024-07-18
ER

PT J
AU Khmag, A
   Al Haddad, SAR
   Ramlee, RA
   Kamarudin, N
   Malallah, FL
AF Khmag, Asem
   Al Haddad, Syed Abdul Rahman
   Ramlee, Ridza Azri
   Kamarudin, Noraziahtulhidayu
   Malallah, Fahad Layth
TI Natural image noise removal using non local means and hidden Markov
   models in stationary wavelet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Additive noise; Non-local means; Hidden Markov model; Spatial filter;
   Image denoising; Multiscale clustering
ID NONLOCAL MEANS; PEPPER NOISE; DENOISING FILTER; ALGORITHM;
   CLASSIFICATION; MRI
AB In self-similarity digital image features, nonlocal means (NLM) exploits the major aspects when it comes to noise removal methods. Despite the high performance characteristics that NLM has proven, computational complexity yet to be highly achieved especially in case of complicated texture patches. In this regard, this study uses the clustered batches of noisy images and hidden Markov models (HMMs) in order to achieve noiseless images where the dependency between additive noise model pixels and its neighbors on stationary wavelet transform is found using HMMs. This paper is helpful and significant in order to develop a speedy and efficient plant recognition system computer-based to identify the plant species. The pivotal significant of the use of NLM and HMMs in this study is to ensure the statistical properties of the wavelet transform such as multiscale dependency among the wavelet coefficients, local correlation in neighbourhood coefficients. Practically, the experimental results present that the proposed algorithm has depicts high visual quality images in the experiments that are conducted in this study, apart from the objective analysis of the proposed algorithm, the execution time and its complexity show a competitive performance with state of the art noise removal methods in low and high noise levels.
C1 [Khmag, Asem] Zawia Univ, Fac Engn, Zawia, Libya.
   [Al Haddad, Syed Abdul Rahman; Ramlee, Ridza Azri] Univ Putra Malaysia, Fac Engn, Serdang, Malaysia.
   [Kamarudin, Noraziahtulhidayu] Univ Putra Malaysia, Fac Engn, Dept Comp & Commun Engn, Serdang, Malaysia.
   [Malallah, Fahad Layth] Cihan Univ, Fac Comp Sci, Sulaimani, Iraq.
C3 Universiti Putra Malaysia; Universiti Putra Malaysia; Cihan
   University-Erbil
RP Khmag, A (corresponding author), Zawia Univ, Fac Engn, Zawia, Libya.
EM khmaj2002@gmail.com; sar@upm.my; ridza@utem.edu.my;
   hidayu.kamarudin@gmail.com; Fahad.layth.86@gmail.com
RI Khmag, Asem/AAH-1051-2019; , null/ACB-2995-2022; Malallah, Fahad
   Layth/G-8406-2019; Al-Haddad, S. A. R./AAM-6449-2020; kamarudin,
   noraziahtulhidayu/AAQ-8508-2021
OI Khmag, Asem/0000-0002-1360-5346; Malallah, Fahad
   Layth/0000-0001-6067-7302; Kamarudin,
   Noraziahtulhidayu/0000-0001-7467-4348
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   [Anonymous], INDIAN J SCI TECHNOL
   [Anonymous], THESIS
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen GY, 2011, IEEE T GEOSCI REMOTE, V49, P973, DOI 10.1109/TGRS.2010.2075937
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Demir B, 2011, IEEE GEOSCI REMOTE S, V8, P220, DOI 10.1109/LGRS.2010.2058996
   Grewenig S, 2011, J VIS COMMUN IMAGE R, V22, P117, DOI 10.1016/j.jvcir.2010.11.001
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Khmag A, 2017, VISUAL COMPUT, V33, P1141, DOI 10.1007/s00371-016-1273-5
   Khmag A, 2016, IEEJ T ELECTR ELECTR, V11, P339, DOI 10.1002/tee.22223
   Khmag A, 2015, J MED IMAG HEALTH IN, V5, P1261, DOI 10.1166/jmihi.2015.1523
   Li ZY, 2015, NEUROCOMPUTING, V159, P172, DOI 10.1016/j.neucom.2014.12.087
   Lu CT, 2016, PATTERN RECOGN LETT, V80, P188, DOI 10.1016/j.patrec.2016.06.026
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Nayak DR, 2017, CNS NEUROL DISORD-DR, V16, P137, DOI 10.2174/1871527315666161024142036
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   Roy A, 2016, APPL SOFT COMPUT, V46, P816, DOI 10.1016/j.asoc.2015.09.032
   Salmon J, 2010, IEEE SIGNAL PROC LET, V17, P269, DOI 10.1109/LSP.2009.2038954
   Thaipanich T, 2010, IEEE T CONSUM ELECTR, V56, P2623, DOI 10.1109/TCE.2010.5681149
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang J, 2006, IEEE IMAGE PROC, P1429, DOI 10.1109/ICIP.2006.312698
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan RM, 2012, J DISP TECHNOL, V8, P212, DOI 10.1109/JDT.2011.2181487
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
   Zhang YD, 2010, J BIOL SYST, V18, P115, DOI 10.1142/S0218339010003652
NR 26
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20065
EP 20086
DI 10.1007/s11042-017-5425-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500052
DA 2024-07-18
ER

PT J
AU Liu, W
   Chen, LT
   Cai, HB
   Liu, QH
   He, J
   Fei, NX
AF Liu, Wei
   Chen, LeiTing
   Cai, HongBin
   Liu, QiHe
   He, Jin
   Fei, Nanxi
TI A canonical form-based approach to affine registration of DTI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diffusion tensor imaging; Reorientation; Canonical form; Quaternions;
   Affine registration
ID DIFFUSION TENSOR REGISTRATION; IMAGES
AB Due to the orientation feature of diffusion tensor images (DTI), tensors need to be reoriented during an affine registration. There exists two active reorientation schemes: finite strain (FS) and preserving principal direction (PPD). However, FS scheme limits its application on rigid deformation and PPD scheme suffers from computation load caused by the iteration. In order to overcome these shortcomings, we propose a canonical form-based affine registration of DTI, named as CFARD. We transform voxel sets into canonical forms where an affine registration is simplified as a rigid registration, while still preserves the effects of non-rigid components. This transforming thus extends the application of FS scheme to affine deformation. Furthermore, to reduce computation load, the quaternion technique is skillfully employed to seek a closed-form solution of the optimal rotation where no iteration is required. Extensive experiments are conducted on synthetic and real DTI data from the human brain. In contrast to four existing algorithms, the proposed CFARD improves the consistency between tensor orientation and the anatomical structures after deformation, and performs a better balance between accuracy and computational complexity.
C1 [Liu, Wei; Chen, LeiTing; Cai, HongBin; Liu, QiHe; He, Jin] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, West Hitech Zone, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
   [Liu, Wei] Chengdu Vocat & Tech Coll Ind, Tianfu New Area, 818 Daan Rd, Chengdu 610218, Sichuan, Peoples R China.
   [Chen, LeiTing] UESTC Guangdong, Inst Elect & Informat Engn, Dongguan 523808, Peoples R China.
   [Chen, LeiTing] Guangdong Prov Hlth Dept, Govt Affairs Serv Ctr, Guangzhou 510060, Guangdong, Peoples R China.
   [Liu, Wei; Fei, Nanxi] Dongguan Data Sci Software Technol Co Ltd, Dongguan 523808, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Liu, W (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, West Hitech Zone, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.; Liu, W (corresponding author), Chengdu Vocat & Tech Coll Ind, Tianfu New Area, 818 Daan Rd, Chengdu 610218, Sichuan, Peoples R China.; Liu, W (corresponding author), Dongguan Data Sci Software Technol Co Ltd, Dongguan 523808, Peoples R China.
EM WeiLiu0405@gmail.com
RI He, Jin/HTR-2324-2023
OI He, Jin/0000-0001-6017-5740
FU National High Technology Research and Development Program("863" program)
   of China [2015AA016010]; Application Science and Technology Planning
   Project of Guangdong Province [2015B010131002]; Major Science and
   Technology Projects of Dongguan [2015215102]
FX This research is supported by the National High Technology Research and
   Development Program("863" program) of China(NO. 2015AA016010),
   Application Science and Technology Planning Project of Guangdong
   Province(NO. 2015B010131002), and Major Science and Technology Projects
   of Dongguan (NO. 2015215102).
CR Alexander DC, 2000, COMPUT VIS IMAGE UND, V77, P233, DOI 10.1006/cviu.1999.0817
   [Anonymous], 2002, Quaternions and Rotation Sequences, Princeton
   [Anonymous], 1844, P ROYAL IRISH ACAD, DOI DOI 10.2307/20520177
   [Anonymous], 1985, ACM SIGGRAPH COMPUTE
   Arena P, 1997, NEURAL NETWORKS, V10, P335, DOI 10.1016/S0893-6080(96)00048-2
   Barmpoutis A, 2010, I S BIOMED IMAGING, P1385, DOI 10.1109/ISBI.2010.5490256
   Cao Yan, 2006, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2006, P67
   CHOU JCK, 1992, IEEE T ROBOTIC AUTOM, V8, P53, DOI 10.1109/70.127239
   Dai JH, 2017, IEEE T CYBERNETICS, V47, P2460, DOI 10.1109/TCYB.2016.2636339
   Dai JH, 2016, KNOWL-BASED SYST, V102, P116, DOI 10.1016/j.knosys.2016.04.002
   Du J, 2012, IEEE T MED IMAGING, V31, P1021, DOI 10.1109/TMI.2011.2178253
   Fang YC, 1998, COMPUT AIDED DESIGN, V30, P191, DOI 10.1016/S0010-4485(97)00057-2
   Gallier J, 2011, TEXTS APPL MATH, V38, P1, DOI 10.1007/978-1-4419-9961-0
   Holzapfel G, 2000, NONLINEAR SOLID MECH
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Jiang HY, 2006, COMPUT METH PROG BIO, V81, P106, DOI 10.1016/j.cmpb.2005.08.004
   Jiawei Hong, 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P82, DOI 10.1109/ICPR.1988.28177
   Keihaninejad S, 2013, NEUROIMAGE, V72, P153, DOI 10.1016/j.neuroimage.2013.01.044
   Khader M, 2017, APPL INTELL, V46, P241, DOI 10.1007/s10489-016-0833-8
   Li JN, 2014, IEEE T MED IMAGING, V33, P1005, DOI 10.1109/TMI.2013.2274051
   Liu W, 2016, OPT REV, V23, P614, DOI 10.1007/s10043-016-0231-9
   PIEGL L, 1991, IEEE COMPUT GRAPH, V11, P55, DOI 10.1109/38.67702
   Pierpaoli C, 1996, RADIOLOGY, V201, P637, DOI 10.1148/radiology.201.3.8939209
   SPRINZAK J, 1994, PATTERN RECOGN LETT, V15, P337, DOI 10.1016/0167-8655(94)90081-7
   STEJSKAL EO, 1965, J CHEM PHYS, V42, P288, DOI 10.1063/1.1695690
   Sweet A, 2010, LECT NOTES COMPUT SC, V6204, P198, DOI 10.1007/978-3-642-14366-3_18
   Van Hecke W, 2007, IEEE T MED IMAGING, V26, P1598, DOI 10.1109/TMI.2007.906786
   Wakana S, 2004, RADIOLOGY, V230, P77, DOI 10.1148/radiol.2301021640
   Wang Y, 2011, NEUROIMAGE, V55, P1577, DOI 10.1016/j.neuroimage.2011.01.038
   Woods RP, 1998, J COMPUT ASSIST TOMO, V22, P139, DOI 10.1097/00004728-199801000-00027
   Yang F, 2012, MED IMAGE ANAL, V16, P459, DOI 10.1016/j.media.2011.11.003
   Yang JZ, 2008, LECT NOTES COMPUT SC, V5242, P905, DOI 10.1007/978-3-540-85990-1_109
   Yeo BTT, 2009, IEEE T MED IMAGING, V28, P1914, DOI 10.1109/TMI.2009.2025654
   Zhang H, 2006, MED IMAGE ANAL, V10, P764, DOI 10.1016/j.media.2006.06.004
NR 34
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19697
EP 19718
DI 10.1007/s11042-017-5416-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500037
DA 2024-07-18
ER

PT J
AU Raikwar, SC
   Tapaswi, S
AF Raikwar, Suresh Chandra
   Tapaswi, Shashikala
TI An improved linear depth model for single image fog removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fog; Haze; Visibility enhancement; Light scattering; Airlight
ID CONTRAST ENHANCEMENT; VISIBILITY; RESTORATION; FRAMEWORK; VISION
AB Outdoor images lose color contrast and visibility in poor weather conditions (like fog, mist, haze and rain), which affects computer vision applications extremely. Degree of degradation at a pixel varies with the depth of a scene point from the observer. Therefore, the problem of image restoration under bad weather is expressed as depth estimation of each scene point from degraded image. The proposed work introduces a linear depth model based on color attenuation prior to estimate depth of each scene point from a single image. The proposed work is based on an observation that the difference of saturation from brightness and hue increases with scene depth and preserves structural similarity of degraded image. The proposed work is capable to preserve the existing edges and recover both the scene depth and the degraded edges. Effectiveness and accuracy of the proposed method is measured qualitatively and quantitatively. The experimental result analysis proves that the proposed method outruns in comparison to the live state of art methods.
C1 [Raikwar, Suresh Chandra] ABV IIITM, Informat Technol, Gwalior, Madhya Pradesh, India.
   [Tapaswi, Shashikala] ABV IIITM, Dept Informat Technol, Gwalior, Madhya Pradesh, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   ABV-Indian Institute of Information Technology & Management, Gwalior
RP Raikwar, SC (corresponding author), ABV IIITM, Informat Technol, Gwalior, Madhya Pradesh, India.
EM sureshc@iiitm.ac.in
RI Raikwar, Suresh Chandra/AAO-5844-2021; TAPASWI, SHASHIKALA/AGZ-7714-2022
OI Raikwar, Suresh Chandra/0000-0001-5139-217X; 
CR [Anonymous], 2003, The SSIM index for image quality assessment
   [Anonymous], 2016, IEEE C COMP VIS PATT
   Bhimani J, 2017, 2017 IEEE 21 INT C H
   Bhimani J, 2017, IEEE INT CONF CLOUD, P359, DOI 10.1109/CLOUD.2017.53
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hongyu Zhao, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P158, DOI 10.1109/JAS.2015.7081655
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Jha DK, 2016, IET COMPUT VIS, V10, P331, DOI 10.1049/iet-cvi.2014.0449
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Ling ZG, 2017, NEUROCOMPUTING, V224, P82, DOI 10.1016/j.neucom.2016.10.050
   Liu SL, 2017, COMPUT ELECTR ENG, V62, P345, DOI 10.1016/j.compeleceng.2016.11.021
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mi ZT, 2016, IET IMAGE PROCESS, V10, P206, DOI 10.1049/iet-ipr.2015.0112
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Narasimhan SG, 2004, AAI3115363
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Nayar SK, 2003, P IEEE WORKSH COL PH
   Qingzhen X, 2013, MATH PROBL ENG, V2013, P6
   Qingzhen X, 2014, MATH PROBL ENG, V2014, P9
   Qingzhen X, 2017, MULTIMED TOOLS APPL
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tan KK, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P788, DOI 10.1109/ICIP.2000.899827
   Tan R T, 2008, P IEEE C COMP VIS PA, P24
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang R, 2016, SIGNAL PROCESS, V127, P24, DOI 10.1016/j.sigpro.2016.02.003
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Yang J, 2017, MULTIMED TOOLS APPL
   Yang Z, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/7364216
   Yang ZY, 2016, INT CONF CLOUD COMP, P245, DOI [10.1109/CloudCom.2016.46, 10.1109/CloudCom.2016.0049]
   Zhang YQ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-220
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 45
TC 10
Z9 12
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19719
EP 19744
DI 10.1007/s11042-017-5398-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500038
DA 2024-07-18
ER

PT J
AU Tuncer, T
AF Tuncer, Turker
TI A probabilistic image authentication method based on chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic symmetric network based watermark generation; Probabilistic
   image authentication; Neural network; Chaotic maps; Fragile
   watermarking; DWT-SVD based image recovery
ID FRAGILE WATERMARKING SCHEME; TAMPER LOCALIZATION; DIGITAL IMAGES;
   STEGANOGRAPHY; ALGORITHM; RECOVERY; MAP; CAPABILITY; ROBUST
AB Fragile watermarking methods have been used as active image authentication methods. These methods must have capabilities like high capacity, high visual quality, high image authentication ability and image recovery capability. Many of the fragile watermarking methods suggested in the literature do not provide all of these capabilities. In this article, a new probabilistic image authentication method with high capacity, high visual quality, high image authenticity ability and image recovery capability is proposed. Chaotic pseudo random number generators, a new watermark generation network which similar to neural network, modulo based watermark embedding functions, modulo based watermark extraction functions, tamper detection algorithm and perceptual hash based image recovery algorithm are utilized for creating a new probabilistic image authentication method in this article. The proposed method is a block based authentication method and 3 x 3 size of overlapping neighborhood blocks are used in this method. The proposed watermark generation network uses symmetric pixels as inputs and weights to generate predicted pixel. In this step, modulo operator and random numbers are used for calculating embeddable value. Owing to chaotic random number generator, the proposed method gains probabilistic and nonlinear structure. To generate random number, logistic map is used as random number generator in the proposed image watermarking method. Then, a modulo based watermark embedding function is used for embedding embeddable value (generated watermark). In the watermark extraction step, modulo operator is used. If the predicted value differs from the extracted value, tamper detection is performed. Otherwise, image authentication is success. A new image recovery algorithm is proposed in this method. This algorithm provides image recovery for tampered areas with high visual quality. The proposed image watermarking method can authenticate grayscale and color images. The experimental results demonstrated that, the proposed method has high payload capacity, high visual quality and high image authentication ability.
C1 [Tuncer, Turker] Firat Univ, Fac Technol, Dept Digital Forens Engn, Elazig, Turkey.
C3 Firat University
RP Tuncer, T (corresponding author), Firat Univ, Fac Technol, Dept Digital Forens Engn, Elazig, Turkey.
EM turkertuncer@firat.edu.tr
RI TUNCER, Turker/W-4846-2018; TUNCER, Türker/ABG-1146-2020
CR Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Hemalatha S., 2013, INT J CRYPTOGRAPHY I, V3, P17
   Huo YR, 2012, OPT COMMUN, V285, P1759, DOI 10.1016/j.optcom.2011.12.044
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin GS, 2010, IEEE T MULTIMEDIA, V12, P345, DOI 10.1109/TMM.2010.2051243
   Lin YC, 2012, IEEE T IMAGE PROCESS, V21, P273, DOI 10.1109/TIP.2011.2157515
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Mao Q, 2014, DIGIT SIGNAL PROCESS, V25, P248, DOI 10.1016/j.dsp.2013.11.001
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Özkaynak F, 2015, OPTIK, V126, P5434, DOI 10.1016/j.ijleo.2015.09.098
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P442, DOI 10.1016/j.dsp.2009.07.004
   Preda RO, 2015, ELECTRON LETT, V51, P1873, DOI 10.1049/el.2015.2522
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Roldan LR, 2016, IEEE LAT AM T, V14, P1050, DOI 10.1109/TLA.2016.7437257
   Saha B, 2012, DEFENCE SCI J, V62, P11, DOI 10.14429/dsj.62.1436
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Tarasova VV, 2017, CHAOS SOLITON FRACT, V95, P84, DOI 10.1016/j.chaos.2016.12.012
   Tuncer T, 2017, J FAC ENG ARCHIT GAZ, V32, P877, DOI 10.17341/gazimmfd.337637
   Walia E, 2013, IET COMPUT VIS, V7, P9, DOI 10.1049/iet-cvi.2012.0109
   Wang N, 2012, COMPUT AIDED DESIGN, V44, P320, DOI 10.1016/j.cad.2011.11.001
   Wójtowicz W, 2016, J VIS COMMUN IMAGE R, V38, P1, DOI 10.1016/j.jvcir.2016.02.006
   Wu WC, 2016, J VIS COMMUN IMAGE R, V38, P18, DOI 10.1016/j.jvcir.2016.02.005
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Zhang L, 2017, OPTIK, V130, P1327, DOI 10.1016/j.ijleo.2016.11.142
NR 35
TC 6
Z9 6
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21463
EP 21480
DI 10.1007/s11042-017-5569-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300050
DA 2024-07-18
ER

PT J
AU Zhou, DX
   Yang, D
   Zhang, XH
AF Zhou, Daoxiang
   Yang, Dan
   Zhang, Xiaohong
TI Exploring joint encoding of multi-direction local binary patterns for
   image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Feature representation; Direction local binary
   patterns; Co-occurrence; Joint encoding
ID MULTIRESOLUTION GRAY-SCALE; FACE-RECOGNITION; TEXTURE CLASSIFICATION;
   DESCRIPTOR; EIGENFACES; FRAMEWORK
AB Local binary pattern (LBP) has been investigated as prominent feature in image classification for decades because of its strong discriminative ability and simple computation complexity, however, it extracts patterns in local circular space, ignoring the patterns located in local line-geometry space. In this paper, we propose a novel feature named joint encoding of multi-direction LBP (JEMDLBP) for image representation. Concretely, due to direction information are highly valuable to reflect the fundamental properties of images, we firstly develop direction LBP (DLBP) codes in local line space of four directions, including 0 degrees, 45 degrees, 90 degrees and 135 degrees directions. Secondly, the DLBP dominant patterns are generated by employing statistical analysis based on the occurrence rates of DLBP codes, which has high adaptive power to database and direction. Thirdly, we employ joint encoding strategy to capture co-occurrence patterns between adjacent directions with the hope that stronger local line structure can be extracted. Finally, to validate the effectiveness and efficiency of JEMDLBP, extensive experiments are carried out on eight databases (four face recognition, one face expression recognition, one palmprint recognition, two texture classification). Excellent results show that JEMDLBP achieves a performance that is competitive or better than several related LBP-like descriptors.
C1 [Zhou, Daoxiang; Yang, Dan; Zhang, Xiaohong] Chongqing Univ, Sch Software Engn, Chongqing 401331, Peoples R China.
   [Zhang, Xiaohong] Minist Educ, Cyber Phys Soc, Key Lab Dependable Serv Comp, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Zhou, DX (corresponding author), Chongqing Univ, Sch Software Engn, Chongqing 401331, Peoples R China.
EM dxzhou@cqu.edu.cn
RI YANG, Dan/HHD-2733-2022; Zhang, Xiaohong/A-3060-2015
FU National Natural Science Foundation of China [61772093, 61402062,
   61602068]; Program for Changjiang Scholars and Innovative Research Team
   in University [IRT1196]
FX The work described in this paper was partially supported by the National
   Natural Science Foundation of China (Grant no. 61772093, 61402062,
   61602068), Program for Changjiang Scholars and Innovative Research Team
   in University (Grant No. IRT1196).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], 2012, P AS C COMP VIS
   [Anonymous], INF SCI
   [Anonymous], 2013, P 2013 INT C INFORM
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Brodatz P., 1996, TEXTURES PHOTOGRAPHI
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N., 2005, P IEEE COMPUTER SOC
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hegenbart S, 2015, PATTERN RECOGN, V48, P2633, DOI 10.1016/j.patcog.2015.02.024
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang G.B., 2008, PROC WORKSHOP FACES
   Jabid T, 2010, IEEE IMAGE PROC, P1605, DOI 10.1109/ICIP.2010.5652374
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Kylberg G, EXTERNAL REPORT BLU
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Li J, 2016, SIGNAL PROCESS-IMAGE, V41, P40, DOI 10.1016/j.image.2015.12.003
   Li WB, 2012, LECT NOTES COMPUT SC, V7575, P345, DOI 10.1007/978-3-642-33765-9_25
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao S., 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, P1301, DOI DOI 10.1109/CVPR.2010.5539817
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Martinez A. M., 1998, THE AR FACE DATABASE
   Nanni L, 2010, EXPERT SYST APPL, V37, P7888, DOI 10.1016/j.eswa.2010.04.048
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan BB, 2011, PATTERN RECOGN, V44, P2800, DOI 10.1016/j.patcog.2011.03.023
   Pan ZB, 2015, IEEE T IMAGE PROCESS, V24, P5379, DOI 10.1109/TIP.2015.2476955
   Perumal RS, 2016, EXPERT SYST APPL, V63, P66, DOI 10.1016/j.eswa.2016.06.031
   Petpon A, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P533, DOI 10.1109/ICIG.2009.123
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Qi XB, 2015, IMAGE VISION COMPUT, V43, P16, DOI 10.1016/j.imavis.2015.07.005
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Ramalingam SP, 2018, J AMB INTEL HUM COMP, V9, P95, DOI 10.1007/s12652-016-0408-x
   Ramalingam SP, 2016, INT J BIOMETRICS, V8, P52, DOI 10.1504/IJBM.2016.077150
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Werghi N, 2015, IEEE T IMAGE PROCESS, V24, P220, DOI 10.1109/TIP.2014.2370253
   Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
   Zhu CR, 2012, INFORM SCIENCES, V187, P93, DOI 10.1016/j.ins.2011.10.014
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
NR 67
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 18957
EP 18981
DI 10.1007/s11042-017-5319-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500004
DA 2024-07-18
ER

PT J
AU Anand, N
   Varma, S
   Sharma, G
   Vidalis, S
AF Anand, Niharika
   Varma, Shirshu
   Sharma, Gaurav
   Vidalis, Stilianos
TI Enhanced reliable reactive routing (ER3) protocol for multimedia
   applications in 3D wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3-D sensor networks; Multimedia applications; Reactive routing;
   Opportunistic routing; Greedy forwarding
ID RANDOM FORWARDING GERAF; AD HOC; ENERGY; DIVERSITY; DELIVERY
AB Sensor networks designed especially for the multimedia applications require high data rate and better Quality of Service (QoS). Offering a reliable and energy efficient routing technique in a harsh and complex three-dimensional (3-D) environment for multimedia applications is a challenging job. Geo-routing and geometric routing have been efficient routing schemes for two-dimensional (2-D), but are unable to work properly for 3-D sensor networks. In order to enhance the resilience to link the dynamics in the 3-D sensor network, in this research an Enhanced Reliable Reactive Routing (ER3) is proposed. ER3 is an advancement to the existing reactive routing schemes, to provide energy efficient and reliable routing of data packets in the complex 3-D sensor networks for multimedia applications. The major attraction of ER3 is its backoff scheme, which occurs in the route discovery phase. In backoff scheme robust pilot paths formed between the source and destination are calculated to enable cooperative forwarding of the data packets. The data packets in ER3 are forwarded greedily to the destination from the source and doesn't require any prior location information of the nodes. The encompassing simulations suggest that the ER3 outperforms the existing routing protocols on the basis of energy efficiency, low latency and high packet delivery ratio.
C1 [Anand, Niharika] IIIT, Dept Informat Technol IT, Allahabad, Uttar Pradesh, India.
   [Varma, Shirshu] IIIT, Allahabad, Uttar Pradesh, India.
   [Sharma, Gaurav] Univ Hertfordshire, Cyber Secur Res Grp, Sch Comp Sci, Hatfield, Herts, England.
   [Vidalis, Stilianos] Univ Hertfordshire, Developing Training Courses Cyber Secur Cyber Int, Hatfield, Herts, England.
C3 Indian Institute of Information Technology Allahabad; Indian Institute
   of Information Technology Allahabad; University of Hertfordshire;
   University of Hertfordshire
RP Anand, N (corresponding author), IIIT, Dept Informat Technol IT, Allahabad, Uttar Pradesh, India.
EM niharikaanand84@gmail.com; varmashirshu@gmail.com;
   gauravsharama88@gmail.com; s.vidalis@herts.ac.uk
RI Anand, Niharika/I-4650-2018; sharma, gaurav/JXX-2424-2024
OI sharma, gaurav/0000-0003-2523-1297
CR Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   [Anonymous], INT J COMMUN SYST
   [Anonymous], NICTA NATL
   [Anonymous], 27 C COMP COMM IEEE
   [Anonymous], SECUR COMMUN NETWORK
   Biswas S, 2005, ACM SIGCOMM COMP COM, V35, P133, DOI 10.1145/1090191.1080108
   Bruckner D, 2012, IEEE T IND INFORM, V8, P291, DOI 10.1109/TII.2012.2186142
   Bruno R, 2010, COMPUT COMMUN, V33, P269, DOI 10.1016/j.comcom.2009.09.003
   Cao Q, 2007, IEEE INFOCOM SER, P1928, DOI 10.1109/INFCOM.2007.224
   Chachulski S., 2007, Trading structure for randomness in wireless opportunistic routing, V37
   Coronel P, 2007, GLOB TELECOMM CONF, P646
   Durocher S, 2008, LECT NOTES COMPUT SC, V4904, P546
   Fang Q, 2005, IEEE INFOCOM SER, P339
   Gungor VC, 2009, IEEE T IND ELECTRON, V56, P4258, DOI 10.1109/TIE.2009.2015754
   Huang HJ, 2013, INT J COMMUN SYST, V26, P100, DOI 10.1002/dac.1335
   Huang XX, 2008, IEEE T WIREL COMMUN, V7, P5278, DOI 10.1109/T-WC.2008.060680
   Karp B., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P243, DOI 10.1145/345910.345953
   Katti S, 2006, ACM SIGCOMM COMP COM, V36, P243, DOI 10.1145/1151659.1159942
   Lam S.S., 2011, PROCEEDING ACM SIGME, P257
   Mao XF, 2011, IEEE T PARALL DISTR, V22, P1934, DOI 10.1109/TPDS.2011.70
   Marina MK, 2001, NETWORK PROTOCOLS, P14, DOI 10.1109/ICNP.2001.992756
   Perkins CE, 1999, WMCSA '99, SECOND IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P90, DOI 10.1109/MCSA.1999.749281
   Perkins CharlesE., 2003, RFC3561
   Royer EM, 1999, IEEE PERS COMMUN, V6, P46, DOI 10.1109/98.760423
   Rozner E, 2009, IEEE T MOBILE COMPUT, V8, P1622, DOI 10.1109/TMC.2009.82
   Saleh AMS, 2014, T EMERG TELECOMMUN T, V25, P1184, DOI 10.1002/ett.2679
   Sanchez J., 2007, MOBILE ADHOC SENSOR, P1
   Sarkar R, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), P121
   Shah RC, 2005, THIRD IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, WORKSHOPS, P350, DOI 10.1109/PERCOMW.2005.90
   Shu L, 2010, TELECOMMUN SYST, V44, P79, DOI 10.1007/s11235-009-9227-0
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Sun YJ, 2009, SENSYS 09: PROCEEDINGS OF THE 7TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P43, DOI 10.1145/1644038.1644044
   Sun ZY, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-58
   Wang JF, 2004, IEEE MILIT COMMUN C, P258
   Watfa M, 2010, INT J COMMUN SYST, V23, P41, DOI 10.1002/dac.1043
   Zeng K, 2007, MOBILE NETW APPL, V12, P347, DOI 10.1007/s11036-008-0051-7
   Zeng Wei., 2010, INFOCOM, 2010 Proceedings IEEE, P1
   Zorzi M, 2003, IEEE T MOBILE COMPUT, V2, P337, DOI 10.1109/TMC.2003.1255648
   Zorzi M, 2003, IEEE T MOBILE COMPUT, V2, P349, DOI 10.1109/TMC.2003.1255650
NR 39
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16927
EP 16946
DI 10.1007/s11042-017-5261-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300042
DA 2024-07-18
ER

PT J
AU Ayas, S
   Ekinci, M
AF Ayas, Selen
   Ekinci, Murat
TI Single image super resolution based on sparse representation using
   discrete wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super resolution; Sparse representation; Discrete wavelet
   transform; Dictionary learning; Sparse coding
ID PARALLEL FRAMEWORK; SUPERRESOLUTION; HEVC; DICTIONARIES
AB Single image super resolution (SR) based on sparse representation is a promising technique where the SR problem is solved by searching for the most robust representation of a signal in terms of atoms in a dictionary. However, first and second-order derivatives are always used as features for patches to be trained as dictionaries and super-resolved patches are reconstructed using dictionaries and sparse representation of these features. In this paper, a novel single image SR algorithm based on sparse representation with considering the effect of significant features is proposed. Therefore, high frequency details are preserved using discrete wavelet transform (DWT). In addition, an intermediate process is also proposed to learn finer dictionaries and thereby estimate the sharper and more detailed super-resolved image. The dictionaries are constructed from the distinctive features using K-SVD dictionary learning algorithm. The intermediate process uses approximation subband. Thus, constructed dictionaries contain so much more significant information and the interpolated high frequency components are corrected. Therefore, the intermediate process restores the high frequency details better in super-resolved images. The proposed algorithm was tested on 'Set14' dataset. Owing to DWT, the proposed algorithm recovers the edges better as well as improving the computational efficiency. The quantitative and visual results show the superiority and competitiveness of the proposed method over the simplest techniques and state-of-art SR algorithms. Experimental time comparisons with the state-of-art algorithms validate the effectiveness of the proposed approach.
C1 [Ayas, Selen; Ekinci, Murat] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University
RP Ayas, S (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM selenguven@ktu.edu.tr
RI Ekinci, Murat/A-9653-2012; Ayas, Selen/AAJ-8030-2021
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], IEEE P 6 INT S IM SI
   [Anonymous], CAN J ELECT COMPUT E
   Babacan SD, 2011, IEEE T IMAGE PROCESS, V20, P984, DOI 10.1109/TIP.2010.2080278
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Dai S., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383028
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Nazzal M, 2015, SIGNAL IMAGE VIDEO P, V9, P1491, DOI 10.1007/s11760-013-0602-7
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Rubinstein R, 2008, Tech. rep.
   Sun J, 2003, PROC CVPR IEEE, P729
   Villena S, 2013, DIGIT SIGNAL PROCESS, V23, P530, DOI 10.1016/j.dsp.2012.10.002
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhu ZL, 2014, IEEE T MULTIMEDIA, V16, P2178, DOI 10.1109/TMM.2014.2364976
NR 28
TC 10
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16685
EP 16698
DI 10.1007/s11042-017-5233-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300031
DA 2024-07-18
ER

PT J
AU Byun, J
   Sung, TE
   Park, HW
AF Byun, Jeongeun
   Sung, Tae-Eung
   Park, Hyun-woo
TI A network analysis of strategic alliance drivers in ICT open ecosystem:
   with focus on mobile, cloud computing, and multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile; Cloud computing; Multimedia; Ecosystem; Strategic alliance; ANP
ID PERSPECTIVES; VIEW; ANP
AB As the phenomenon of convergence in the field of information and communication technology (ICT) and services is accelerated with the development of science and technology, the ecosystem of the ICT industry is gradually evolving into an open ecosystem. This study analyzes the strategic alliance mechanism in the ICT industry, taking the view that active strategic alliances should be pursued for co-evolution between the companies in an open ecosystem. Based on previous studies and expert opinions, the objectives of a strategic alliance are classified into main evaluation categories such as strategy-oriented, cost-oriented, resource-oriented and learning-oriented, and the detailed subcategories are presented. Through an analysis of the ecosystem of the ICT industry, multimedia contents (production, distribution), platform (cloud computing, mobile cloud computing), network (wired network, wireless network), device (home electronics, mobile) are identified as the agents to be analyzed. By applying the analytic network process (ANP) based on the above, the priority of the objectives of strategic alliances in the ICT industry is determined by the agent. This study is expected to promote the development of a business model and co-opetition between the companies to create sustainable competitive advantages in the future open ecosystem, and to contribute to the creation of corporate and national profits.
C1 [Byun, Jeongeun] Univ Sci & Technol, Korea Inst Sci & Technol Informat, Dept Sci & Technol Management Policy, 66 Hoegi Ro, Seoul 02456, South Korea.
   [Sung, Tae-Eung; Park, Hyun-woo] Korea Inst Sci & Technol Informat, Technol Valuat LAB, 66 Hoegi Ro, Seoul 02456, South Korea.
C3 Korea Institute of Science & Technology Information (KISTI); Korea
   Institute of Science & Technology Information (KISTI)
RP Park, HW (corresponding author), Korea Inst Sci & Technol Informat, Technol Valuat LAB, 66 Hoegi Ro, Seoul 02456, South Korea.
EM jebyun@kisti.re.kr; ts322@kisti.re.kr; hpark@kisti.re.kr
CR Byun J, 2017, MULTIMED TOOLS APPL, V76, P19665, DOI 10.1007/s11042-016-3369-3
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chen HM, 2002, J BUS RES, V55, P1007, DOI 10.1016/S0148-2963(02)00284-9
   Chen SH, 2008, MANAGE DECIS, V46, P449, DOI 10.1108/00251740810863889
   Cheng B, 2015, MULTIMED TOOLS APPL, V74, P10847, DOI 10.1007/s11042-014-2210-0
   Das TK, 2000, J MANAGE, V26, P31, DOI 10.1016/S0149-2063(99)00037-9
   Eisenhardt KM, 1996, ORGAN SCI, V7, P136, DOI 10.1287/orsc.7.2.136
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   Ibukun E., 2015, International Journal of Multimedia and Ubiquitous Engineering, V10, P135, DOI DOI 10.14257/IJMUE.2015.10.12.15
   Kim KI, 2015, WIREL COMMUN MOB COM, V15, P475, DOI 10.1002/wcm.2361
   KOGUT B, 1988, STRATEGIC MANAGE J, V9, P319, DOI 10.1002/smj.4250090403
   Lai HC, 2013, ASIAN J TECHNOL INNO, V21, P136, DOI 10.1080/19761597.2013.815481
   Lee YG, 2008, ASIAN J TECHNOL INNO, V16, P45, DOI 10.1080/19761597.2008.9668646
   Moore J.F., 1996, DEATH COMPETITION
   Nachira F., 2007, DIGITAL BUSINESS ECO
   Nielsen B.B., 2003, EUR MANAG J, V21, P301, DOI DOI 10.1016/S0263-2373(03)00043-4
   OHMAE K, 1989, HARVARD BUS REV, V67, P143
   Saaty R.W., 2003, DECISION MAKING COMP
   Saaty T.L., 1996, DECISION MAKING DEPE
   Saaty T. L., 1999, ISAHP KOB JAP AUG 12
   Saaty T.L., 1980, ANAL HIERARCHY PROCE
   SAATY TL, 1990, EUR J OPER RES, V48, P9, DOI 10.1016/0377-2217(90)90057-I
   Tansley AG, 1935, ECOLOGY, V16, P284, DOI 10.2307/1930070
   Wang YT, 2015, WIRELESS PERS COMMUN, V80, P1607, DOI 10.1007/s11277-014-2102-7
   Yüksel I, 2007, INFORM SCIENCES, V177, P3364, DOI 10.1016/j.ins.2007.01.001
NR 25
TC 3
Z9 4
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14725
EP 14744
DI 10.1007/s11042-017-5059-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200011
DA 2024-07-18
ER

PT J
AU Han, CL
   Xue, R
   Zhang, R
   Wang, XQ
AF Han, Chunling
   Xue, Rui
   Zhang, Rui
   Wang, Xueqing
TI A new audio steganalysis method based on linear prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear prediction; Audio steganalysis; Steganography; Support vector
   machine
ID SUPPORT VECTOR MACHINE; GENETIC ALGORITHM; CLASSIFICATION; PARAMETERS
AB Steganography and Steganalysis have attracted a lot of attention in decades. Recently, voice communication has been more and more popular, which provides ways to covert communication. However, the existing audio steganalysis methods can only gain good detection accuracies when the hidden ratio is high. Besides, majority of the audio steganalysis methods can not provide a general evaluation, only provide the detection accuracies according to several high hidden ratios. In this paper, we proposed a new method for audio steganalysis by introducing linear prediction method, a technique from signal coding and speaker identification filed, into audio steganalysis, which can bring significant differences between covers and stegos. The linear prediction based features are utilized as the classification features loaded in a support vector machine for detection. In our work we used hidden message to cover ratio to replace the concept of hidden ratio, providing a uniform criterion to compare the performance among steganalysis methods. Furthermore, we exploited a general dataset, in which the hidden message size ranges from several bits to the maximum hiding capacity for a general evaluation on steganalysis methods. Experiment results show that our method delivers a better performance than previous two prestigious methods and brings above 96% accuracy. In general evaluation, our method gains a higher score than the other two methods. Steganalysis is a challenging work, this linear prediction based method maybe an approach to bring improvement to this filed and provide inspiration for other form of media steganalysis.
C1 [Han, Chunling; Xue, Rui; Zhang, Rui; Wang, Xueqing] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Informat Engn,Sch Cyber Secur, State Key Lab Informat Secur,Inst Informat Engn, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Xue, R (corresponding author), Univ Chinese Acad Sci, Chinese Acad Sci, Inst Informat Engn,Sch Cyber Secur, State Key Lab Informat Secur,Inst Informat Engn, Beijing, Peoples R China.
EM xuerui@iie.ac.cn
OI Han, Chunling/0000-0003-0137-4648
FU National Natural Science Foundation of China [61402471, 61472414]
FX The authors are supported by National Natural Science Foundation of
   China (No. 61402471, 61472414). We wish to thank Professor Tang and
   Professor Zuo for their substantial support, insightful comments and
   suggestions, Dr. Chen Gong, Dr. Hailong Zhang and Professor Li for their
   discussion and guidance. Special thanks goes to Mr and Mrs Han for their
   understanding and support.
CR [Anonymous], INFORM TECHNOLOGY J
   [Anonymous], 2016, INT J IMAGE PROCESS
   Avci E, 2009, EXPERT SYST APPL, V36, P1391, DOI 10.1016/j.eswa.2007.11.014
   Couellan N, 2015, EXPERT SYST APPL, V42, P4284, DOI 10.1016/j.eswa.2015.01.028
   Djebbar Fatiha, 2012, Information and Communication Security. 14th International Conference (ICICS 2012). Proceedings, P1, DOI 10.1007/978-3-642-34129-8_1
   Du SC, 2015, IEEE T INSTRUM MEAS, V64, P2590, DOI 10.1109/TIM.2015.2418684
   Geiser B, 2008, INT CONF ACOUST SPEE, P4005, DOI 10.1109/ICASSP.2008.4518532
   Ghasemzadeh H, 2016, DIGIT SIGNAL PROCESS, V51, P133, DOI 10.1016/j.dsp.2015.12.015
   Ghasemzadeh H, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P679, DOI 10.1109/ICCKE.2014.6993347
   Kraetzer C, P SPIE INT SOC OPT E, V6505
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu D, 2014, RENEW ENERG, V62, P592, DOI 10.1016/j.renene.2013.08.011
   Liu QZ, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000492
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Miao HB, 2012, COMPUT ELECTR ENG, V38, P1490, DOI 10.1016/j.compeleceng.2012.05.003
   Molau S, 2001, INT CONF ACOUST SPEE, P73, DOI 10.1109/ICASSP.2001.940770
   Nouri A, 2016, ADV COMPUT SCI INT J, V5, P33
   Özer H, 2003, PROC SPIE, V5020, P55, DOI 10.1117/12.477313
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qiao MY, 2013, INFORM SCIENCES, V231, P123, DOI 10.1016/j.ins.2012.10.013
   Ren YZ, 2016, INT CONF ACOUST SPEE, P2139, DOI 10.1109/ICASSP.2016.7472055
   Ren YJ, 2016, PEER PEER NETW APPL, V9, P854, DOI 10.1007/s12083-015-0346-y
   Ru XM, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P3937
   Srivastava S, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P685, DOI 10.1109/SPIN.2014.6777042
   [唐步天 TANG Butian], 2008, [声学技术, Technical Acoustics], V27, P533
   Tian H, 2017, SIGNAL PROCESS, V134, P9, DOI 10.1016/j.sigpro.2016.11.013
   Tint Yawai, 2012, International Journal of Research and Reviews in Computer Science, V3, P1593
   Wu AX, 2016, J VIS COMMUN IMAGE R, V34, P103, DOI 10.1016/j.jvcir.2015.10.013
   Wu CH, 2007, EXPERT SYST APPL, V32, P397, DOI 10.1016/j.eswa.2005.12.008
   Wu Q, 2010, EXPERT SYST APPL, V37, P194, DOI 10.1016/j.eswa.2009.05.011
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yan DQ, 2013, DIGIT SIGNAL PROCESS, V23, P1181, DOI 10.1016/j.dsp.2013.02.013
   Yavanoglu U, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P233, DOI 10.1109/ICMLA.2012.150
   Yu X, 2012, J COMPUT INF SYST, V8, P4241
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zhai SJ, 2015, NEUROCOMPUTING, V149, P573, DOI 10.1016/j.neucom.2014.08.017
NR 37
TC 10
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15431
EP 15455
DI 10.1007/s11042-017-5123-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200044
DA 2024-07-18
ER

PT J
AU Kumar, R
   Chand, S
   Singh, S
AF Kumar, Rajeev
   Chand, Satish
   Singh, Samayveer
TI An Improved Histogram-Shifting-Imitated reversible data hiding based on
   HVS characteristics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Human Visual System; Peak Points; embeddable
   pixel; PSNR; capacity
ID DIFFERENCE EXPANSION; WATERMARKING; IMAGES
AB In this paper, we propose a reversible data hiding scheme to hide a secret message into a cover image by considering the characteristics of Human Visual System (HVS) in order to improve the visual imperceptibility. The human eyes are more sensitive to the changes in the low intensity pixels than the higher intensity ones. Therefore, we divide the intensity levels (0-255) into four groups: the first group contains 0-79 intensity level; second, third, and fourth group contain, respectively, 80-151, 152-215, and 216-255 intensity levels. We further divide first group into segments of size 2 elements, second, third, and fourth group into 3, 4, and 5 elements sized segments, respectively. After constructing the segments, we scan the image in raster order to identify the peak points for each segment, which are used to embed the secret data. The secret data is also divided into the four segments according to the identified peak points per group. The first segment data is converted into base2 representation, second, third and fourth segment secret data into 3, 4, and 5 base representation, respectively. The first segment of secret data is embedded into the peak points belonging to first group, second, third and fourth group secret data is embedded into the peak points of second, third and fourth group, respectively. Thus, our scheme makes least changes into the pixels belonging to the first group which have least intensity values and most to the fourth group pixels which have highest intensity values. Experimentally, our scheme provides better quality stego image and hides more secret data than the other state of the art schemes. We also build a location map for all the peak points to ensure the reversibility of the proposed scheme.
C1 [Kumar, Rajeev] Netaji Subhas Inst Technol, Div Comp Engn, New Delhi, India.
   [Chand, Satish] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Delhi, India.
   [Singh, Samayveer] Bennett Univ, Dept Comp Sci Engn, Greater Noida, UP, India.
C3 Netaji Subhas University of Technology; Jawaharlal Nehru University, New
   Delhi
RP Kumar, R (corresponding author), Netaji Subhas Inst Technol, Div Comp Engn, New Delhi, India.
EM rajivgarg@outlook.com; schand20@gmail.com; samayveersingh@gmail.com
RI Kumar, Rajeev/IUP-5006-2023; Singh, Samayveer/X-8119-2019
OI Kumar, Rajeev/0000-0002-5000-7644; Singh, Samayveer/0000-0002-4199-721X
CR Awranjeb M, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1877523
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   COX IJ, 2008, MKS MULTIMED INFORM, P1
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fridrich J, 2001, P 4 INF HID WORKSH P, V2137, P27
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jin HL, 2007, IEICE T FUND ELECTR, VE90A, P771, DOI 10.1093/ietfec/e90-a.4.771
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Karybali IG, 2006, IEEE T INF FOREN SEC, V1, P256, DOI 10.1109/TIFS.2006.873652
   Kekre HB, 2009, P ACM INT C ADV COMP, P342
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim P-H, 2015, P INF TECHN NEW GEN
   Kuhn M, JBIG KIT JBIG1
   Kuo WC, 2007, LECT NOTES ARTIF INT, V4682, P1152
   Kuribayashi M, 2008, IEICE T FUND ELECTR, VE91A, P1780, DOI 10.1093/ietfec/e91-a.7.1780
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Park H, 2006, P IEEE INT C MULT EX
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P867, DOI 10.1109/TCSVT.2003.815943
   Popa R, 1998, THESIS, P26
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 28
TC 27
Z9 31
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13445
EP 13457
DI 10.1007/s11042-017-4960-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900017
DA 2024-07-18
ER

PT J
AU Ye, YY
   He, XH
   Teng, QZ
   Qing, LB
   Lin, HW
   Xia, DC
AF Ye, Yuyun
   He, Xiaohai
   Teng, Qizhi
   Qing, Linbo
   Lin, Hongwei
   Xia, Dechun
TI Adaptive Gradient Information and BFGS Based Inter Frame Rate Control
   for High Efficiency Video Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High Efficiency Video Coding; Rate control; Adaptive gradient
   information; BFGS; Linear regression
ID H.264
AB In order to meet the emerging demands of high-fidelity video services, a new video coding standard - High Efficiency Video Coding (HEVC) is developed to improve the compression performance of high definition (HD) videos and save half of the bitrate for the same perceptual video quality compared with H.264/Advanced Video Coding (AVC). Rate control still plays a significant role in HD video data transmission via the communication channel. However, R-lambda model based HEVC rate control algorithm does not take the relationship between the encoding complexity and Human Visual System (HVS) into account, what's more, the convergence speed of Least Mean Square (LMS) algorithm is slow. In this paper, an adaptive gradient information and Broyden Fletcher Goldfarb Shanno (BFGS) based R-lambda model (GBRL) is proposed for the inter frame rate control, where the gradient based on Sobel operator can effectively measure the frame-content complexity and BFGS algorithm converges speedily than LMS algorithm. Experimental results show that the proposed GBRL method can achieve bitrate error reduction and peak signal to noise ratio (PSNR) improvement especially for the sequences with large motion, compared to the state-of-the-art rate control methods. In addition, if the optimal initial quantization parameter (QP) prediction model based on linear regression can be incorporated into the proposed GBRL method, the performance of rate control can be further improved.
C1 [Ye, Yuyun; He, Xiaohai; Teng, Qizhi; Qing, Linbo; Lin, Hongwei; Xia, Dechun] Sichuan Univ, Coll Elect & Informat Engn, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Sichuan, Peoples R China.
   [Lin, Hongwei] Northwest Univ Nationalities, Coll Elect Engn, 1 Xibeixincun Rd, Lanzhou 730030, Gansu, Peoples R China.
C3 Sichuan University; Northwest Minzu University
RP He, XH (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Sichuan, Peoples R China.
EM hxh@scu.edu.cn
RI Ye, Yuyun/ABH-2987-2021
OI Ye, Yuyun/0000-0003-3395-2174
FU National Natural Science Foundation of China [61471248]; Science and
   Technology Program of Sichuan Province [2015JY0189]; 2014 Graduate
   education reform and innovation project of Sichuan Department of
   Education [2014-Edu-034]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61471248), the Science and Technology Program of
   Sichuan Province (Grant No. 2015JY0189), and the 2014 Graduate education
   reform and innovation project of Sichuan Department of Education (Grant
   No. 2014-Edu-034).
CR [Anonymous], 2013, PROC VIS COMMUN IMAG
   Cheng X, 1997, J ZHEJIANG U TECHNOL, V25, P230
   Choi H, 2012, RATE CONTROL BASED U
   Gao J, 2005, J ZHENGZHOU U LIGHT, V20, P100
   Gao W, 2016, IEEE T CIRC SYST VID, V26, P139, DOI 10.1109/TCSVT.2015.2444671
   Jing X, 2008, IEEE SIGNAL PROC LET, V15, P373, DOI 10.1109/LSP.2008.920010
   Jing XA, 2006, IEEE INT SYMP CIRC S, P5019
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Lee B, 2011, IEEE SIGNAL PROC LET, V18, P571, DOI 10.1109/LSP.2011.2163935
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Lin HW, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043008
   Liu G, 1994, J QUFU NORMAL U, V20, P1
   Shi C, 2012, THESIS, P1
   Sun H, 2008, COMPUT KNOWL TECHNOL, P1105, DOI [10.3969/j.issn.1009-3044.2008.15.054, DOI 10.3969/J.ISSN.1009-3044.2008.15.054]
   Wang Hai-ying, 2008, Journal of Beijing University of Posts and Telecommunications, V31, P99
   Wang HL, 2008, IEEE T CIRC SYST VID, V18, P140, DOI 10.1109/TCSVT.2007.913757
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   Wu S., 2012, J CHANG U, V26, P1
   Yoon Y, 2012, IEEE INT S BROADB MU, P1, DOI [10.1109/BMSB.2012.6264268, DOI 10.1109/BMSB.2012.6264268]
   Zhang ZW, 2017, IEEE ACCESS, V5, P13677, DOI 10.1109/ACCESS.2017.2676125
NR 20
TC 5
Z9 5
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14557
EP 14577
DI 10.1007/s11042-017-5047-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200004
DA 2024-07-18
ER

PT J
AU He, FL
   Guo, YC
   Gao, C
AF He, Fuliang
   Guo, Yongcai
   Gao, Chao
TI Human segmentation of infrared image for mobile robot search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared image; Mobile robot; Human segmentation; Curvature gravity
   gradient tensor; Pulse coupled neural network; Morphology
ID GRAVITY GRADIENT TENSOR; EDGE-DETECTION
AB In the search robotics field, human target segmentation method plays a basic pre-processing step in the visual guidance. However, with the wide application of the infrared sensor on robot vision, traditional segmentation methods are facing more challenges of low-contrast, overlapping and blurring targets, and complex background. This paper introduces an infrared human segmentation approach that integrates the improved pulse coupled neural network (PCNN), the curvature gravity gradient tensor (CGGT) and the mathematical morphology to address these above problems. This approach starts with an improved PCNN segmentation model. Local dynamic synapse weights are designed to enhance the synchronous pulsing ability of the improved PCNN model with similar inputs, and a reformed threshold is conducted to guide the process of segmentation. Moreover, eigenvalues of CGGT are guaranteed in this model as linking coefficients, in order to capture the edges and details of human target more exactly in segmentation. Lastly, the segmentation result is repaired by morphology operators, to ensure the integrity of the target region and the independent noise removal. Experiments on 200 real infrared images captured by the mobile robot CQSearcher I, demonstrate that our method is superior over the other classic segmentation methods in both the subjective visual performance and the objective indicators of misclassification error and f-measure.
C1 [He, Fuliang; Guo, Yongcai; Gao, Chao] Chongqing Univ, Coll Optoelect Engn, Minist Educ, Key Lab Optoelect Technol & Syst, Chongqing 40044, Peoples R China.
   [He, Fuliang] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Chongqing University; Southwest University - China
RP He, FL (corresponding author), Chongqing Univ, Coll Optoelect Engn, Minist Educ, Key Lab Optoelect Technol & Syst, Chongqing 40044, Peoples R China.; He, FL (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM lighter@swu.edu.cn
FU Ph.D. Programs Foundation of Ministry of Education of China
   [20130191110021]; Fundamental Research Funds for the Central
   Universities of China [XDJK2013C157]; Program of Study Abroad for Young
   Scholar Sponsored by China Scholarship Council [201506995083]
FX This work was supported by the Ph.D. Programs Foundation of Ministry of
   Education of China (Grant No. 20130191110021), the Fundamental Research
   Funds for the Central Universities of China(Grant No. XDJK2013C157), and
   the Program of Study Abroad for Young Scholar Sponsored by China
   Scholarship Council (Grant No. 201506995083).
CR [Anonymous], TELKOMNIKA INDONESIA
   [Anonymous], 2016, PRENSA MED
   Bai XZ, 2016, IEEE T CYBERNETICS, V46, P3259, DOI 10.1109/TCYB.2015.2501848
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen HC, 2016, MULTIMED TOOLS APPL, V75, P15
   Chen HC, 2016, MULTIMED TOOLS APPL, V75, P15327, DOI 10.1007/s11042-015-2518-4
   Chen M, 2016, MULTIMED TOOLS APPL, V75, P10335, DOI 10.1007/s11042-015-3008-4
   Chen YL, 2015, IEEE T NEUR NET LEAR, V26, P1682, DOI 10.1109/TNNLS.2014.2351418
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Gao C, 2014, NEURAL PROCESS LETT, V39, P81, DOI 10.1007/s11063-013-9291-z
   Gómez W, 2016, NEUROCOMPUTING, V175, P877, DOI 10.1016/j.neucom.2015.04.121
   Hansen RO, 2006, GEOPHYSICS, V71, pL61, DOI 10.1190/1.2357831
   Huimin Lu, 2010, Proceedings of the 2010 International Conference on Intelligent Control and Information Processing (ICICIP 2010), P79, DOI 10.1109/ICICIP.2010.5564346
   박정길, 2016, [Journal of Institute of Control, Robotics and Systems, 제어.로봇.시스템학회 논문지], V22, P288, DOI 10.5302/J.ICROS.2016.16.8003
   Li Y, 2014, MULTIMED TOOLS APPL, V71, P1179, DOI 10.1007/s11042-012-1258-y
   Li YZ, 2016, PROCEEDINGS OF PYHPC2016: 6TH WORKSHOP ON PYTHON FOR HIGH-PERFORMANCE AND SCIENTIFIC COMPUTING, P52, DOI [10.1109/PyHPC.2016.011, 10.1109/PyHPC.2016.7]
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lindblad T., 1998, Image Processing Using Pulse-Coupled Neural Networks
   Liu JY, 2014, INFRARED PHYS TECHN, V67, P387, DOI 10.1016/j.infrared.2014.07.024
   Liu YG, 2013, J INTELL ROBOT SYST, V72, P147, DOI 10.1007/s10846-013-9822-x
   Liu ZY, 2014, PATTERN RECOGN, V47, P2839, DOI 10.1016/j.patcog.2014.03.005
   Marzec M, 2015, MULTIMED TOOLS APPL, V74, P4351, DOI 10.1007/s11042-013-1745-9
   Oruç B, 2013, J APPL GEOPHYS, V88, P105, DOI 10.1016/j.jappgeo.2012.10.006
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Powers DMW, 2008, J MACH LEARN TECHNOL, V2, P2229
   Sakagami Norimitsu., 2016, Proceedings of the ISCIE International Symposium on Stochastic Systems Theory and its Applications. Vol. 2016. The ISCIE Symposium on Stochastic Systems Theory and Its Applications, P259
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Stahlschmidt C, 2016, MULTIMED TOOLS APPL, V75, P10769, DOI 10.1007/s11042-014-2260-3
   Tan WC, 2015, C IND ELECT APPL, P192, DOI 10.1109/ICIEA.2015.7334109
   Wang J, 2015, J APPL GEOPHYS, V118, P106, DOI 10.1016/j.jappgeo.2015.04.013
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1
   Yin JL, 2016, INFRARED PHYS TECHN, V77, P302, DOI 10.1016/j.infrared.2016.06.004
   Zhao G, 2007, INT S MULT IM PROC P, p[678, 717, 717]
   Zhou DG, 2016, INFRARED PHYS TECHN, V74, P81, DOI 10.1016/j.infrared.2015.12.003
   Zhou DG, 2015, SOFT COMPUT, V19, P3261, DOI 10.1007/s00500-014-1481-8
   Zhou WN, 2013, J APPL GEOPHYS, V98, P237, DOI 10.1016/j.jappgeo.2013.09.008
   Zhou YL, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3094-4
NR 39
TC 5
Z9 10
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10701
EP 10714
DI 10.1007/s11042-017-4872-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900019
DA 2024-07-18
ER

PT J
AU Ou, WH
   Long, F
   Tan, Y
   Yu, SJ
   Wang, PP
AF Ou, Weihua
   Long, Fei
   Tan, Yi
   Yu, Shujian
   Wang, Pengpeng
TI Co-regularized multiview nonnegative matrix factorization with
   correlation constraint for representation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonnegative matrix factorization; Co-regularization; Correlation
   constraint; Consistent; Complementary
AB With the increasing availability of multiview nonnegative data in real applications, multiview representation learning based on nonnegative matrix factorization (NMF) has attracted more and more attentions. However, existing NMF-based methods are sensitive to noises and are difficult to generate discriminative features with noisy views. To address these problems, we propose a co-regularized multiview nonnegative matrix factorization method with correlation constraint for nonnegative representation learning, which jointly exploits consistent and complementary information across different views. Different from previous works, we aim at integrating information from multiple views efficiently and making it more robust to the presence of noisy views. More specifically, we exploit the complementary information of multiple views through the co-regularization to accommodate the presence of the noisy views. Meanwhile, correlation constraint is imposed on the low-dimensional space to learn a common latent representation shared by different views. For the induced objective function, we derive an alternative algorithm to solve the optimization problem. The experimental results on four real datasets demonstrate the effectiveness and robustness of the proposed algorithm.
C1 [Ou, Weihua] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang 550025, Guizhou, Peoples R China.
   [Long, Fei] Guizhou Inst Technol, Sch Elect & Informat Engn, Guiyang 550003, Guizhou, Peoples R China.
   [Tan, Yi; Wang, Pengpeng] Guizhou Univ, Coll Big Data & Informat Engn, Guiyang 550025, Guizhou, Peoples R China.
   [Yu, Shujian] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 Guizhou Normal University; Guizhou Institute of Technology; Guizhou
   University; State University System of Florida; University of Florida
RP Ou, WH (corresponding author), Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang 550025, Guizhou, Peoples R China.
EM ouweihuahust@gmail.com
RI Ou, Weihua/T-9156-2019; Ou, Weihua/AAD-9887-2020
OI Ou, Weihua/0000-0001-5241-7703; 
FU National Nature Science Foundation of China [61402122, 61263005,
   61461008]; Natrual Science Fundataion of Guizhou Province [[2017]1130];
   Program for New Century Excellent Talents in Chinese University
   [NCET-12-0657]; Innovation Fund for Graduate Student of Guizhou
   University [2015080]; Ph.D. Recruitment Program of Guizhou Normal
   University; Outstanding Innovation Talents of Science and Technology
   Award Scheme of Education Department in Guizhou Province [[2015]487];
   China Scholarship Council [201508525007]; Foundation of Guizhou
   Educational Department [KY[2016]027]
FX This work is partly supported by the National Nature Science Foundation
   of China (Grant No. 61402122, 61263005, 61461008), the Natrual Science
   Fundataion of Guizhou Province No.[2017]1130, the Program for New
   Century Excellent Talents in Chinese University under Grant No.
   NCET-12-0657, the Innovation Fund for Graduate Student of Guizhou
   University (No. 2015080), the 2014 Ph.D. Recruitment Program of Guizhou
   Normal University, the Outstanding Innovation Talents of Science and
   Technology Award Scheme of Education Department in Guizhou Province
   (Qianjiao KY word [2015]487), the China Scholarship Council (No.
   201508525007), Foundation of Guizhou Educational Department
   (KY[2016]027).
CR Akata C, 2011, COMP VIS WINT WORKSH
   [Anonymous], 2011, INT C MACHINE LEARNI
   [Anonymous], 2011, INT C NEURAL INF PRO
   [Anonymous], J MACHINE LEARNING R
   [Anonymous], ARXIV13045634
   [Anonymous], COMPUT VIS ECCV
   [Anonymous], 2013, P 2013 SIAM INT C DA
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chang WY, 2014, INT C PATT RECOG, P1272, DOI 10.1109/ICPR.2014.228
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64
   Chen X, 2013, OPEN J APPL SCI, V3, P365
   CORNUEJOLS G, 1986, J COMB THEORY B, V40, P285, DOI 10.1016/0095-8956(86)90085-7
   Ding C, 2008, COMPUT STAT DATA AN, V52, P3913, DOI 10.1016/j.csda.2008.01.011
   Ding C, 2012, INT CONF ACOUST SPEE, P2033, DOI 10.1109/ICASSP.2012.6288308
   Gui J, 2014, IEEE T IMAGE PROCESS, V23, P3126, DOI 10.1109/TIP.2014.2326001
   Gupta S.K., 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, P1169, DOI DOI 10.1145/1835804.1835951
   Gupta SK, 2013, DATA MIN KNOWL DISC, V26, P57, DOI 10.1007/s10618-011-0244-8
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He XN, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P771, DOI 10.1145/2566486.2567975
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   Jing XY, 2014, AAAI CONF ARTIF INTE, P1882
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134
   Lanckriet Gert, 2002, ICML'02: Proceedings of the Nineteenth International Conference on Machine Learning, V5, P323, DOI 10.1023/B:JODS.0000012018.62090.a7
   Li J, 2017, INT J FUZZY SYST, V19, P355, DOI 10.1007/s40815-016-0172-2
   Li SZ, 2001, PROC CVPR IEEE, P207
   Li X, 2016, KNOWL-BASED SYST, V113, P88, DOI 10.1016/j.knosys.2016.09.014
   Liu H, ARXIV160305572
   Liu J, 2015, IEEE T NEUR NET LEAR, V26, P1233, DOI 10.1109/TNNLS.2014.2335234
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Ma YY, 2016, IEEE INT C BIOINFORM, P625, DOI 10.1109/BIBM.2016.7822591
   Ou WH, 2016, NEUROCOMPUTING, V204, P116, DOI 10.1016/j.neucom.2015.09.133
   Rad R, 2017, J VIS COMMUN IMAGE R, V46, P1, DOI 10.1016/j.jvcir.2017.03.005
   Shao W, ARXIV161100481
   Shao WX, 2015, LECT NOTES ARTIF INT, V9284, P318, DOI 10.1007/978-3-319-23528-8_20
   Tang J., 2013, P SIAM INT C DAT MIN, P270, DOI [DOI 10.1137/1.9781611972832.30, 10.1137/1.9781611972832.30]
   Wang JJY, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-107
   Wang J, 2016, LECT NOTES COMPUT SC, V9948, P435, DOI 10.1007/978-3-319-46672-9_49
   Wang XC, 2013, IEEE T IMAGE PROCESS, V22, P2646, DOI 10.1109/TIP.2013.2255300
   Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51
   Wang ZF, 2015, IEEE IMAGE PROC, P3500, DOI 10.1109/ICIP.2015.7351455
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Yin QY, 2015, NEUROCOMPUTING, V156, P12, DOI 10.1016/j.neucom.2015.01.017
   You XG, 2016, IEEE T IMAGE PROCESS, V25, P4782, DOI 10.1109/TIP.2016.2598653
   You XG, 2015, IEEE T NEUR NET LEAR, V26, P2760, DOI 10.1109/TNNLS.2015.2393886
   Zafeiriou S, 2006, IEEE T NEURAL NETWOR, V17, P683, DOI 10.1109/TNN.2006.873291
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhu Z., 2014, INFORM HIDING MULTIM, V5, P546
   Zong LL, 2017, NEURAL NETWORKS, V88, P74, DOI 10.1016/j.neunet.2017.02.003
NR 55
TC 19
Z9 20
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12955
EP 12978
DI 10.1007/s11042-017-4926-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100058
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, SW
   Zhang, LQ
AF Zhang, Shanwen
   Zhang, Liqing
TI Combining weighted adaptive CS-LBP and local linear discriminant
   projection for gait recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Local binary pattern (LBP); Weighted adaptive center
   symmetric local binary pattern (WACS-LBP); Local linear discriminate
   projection (LLDP)
ID BINARY PATTERNS; FACE RECOGNITION
AB With the increasing demands of the remote surveillance system, the gait based personal identification research has obtained more and more attention from biometric recognition researchers. The gait sequence is easier to be affected by factors than other biometric feathers. In order to achieve better performance of the gait based identification system, in the paper, a local discriminant gait recognition method is proposed by integrating weighted adaptive center symmetric local binary pattern (WACS-LBP) with local linear discriminate projection (LLDP). The proposed method consists of two stages. In the first stage, the robust local weighted histogram feature vector is extracted from each gait image by WACS-LBP. In the second stage, the dimensionality of the extracted feature vector is reduced by LLDP. The highlights of the proposed method are (1) the extracted feature is robust to rotation invariant, and is also tolerant to illumination and pose changes; (2) the low dimensional feature vector reduced by LLDP can preserve the discriminating ability; and (3) the small-sample-size (SSS) problem is avoided naturally. The proposed method is validated and compared with the existing algorithms on a public gait database. The experimental results show that the proposed method is not only effective, but also can be clearly interpreted.
C1 [Zhang, Shanwen] Xijing Univ, Dept Informat Engn, Xian 710123, Shaanxi, Peoples R China.
   [Zhang, Shanwen; Zhang, Liqing] Virginia Tech, Dept Comp Sci, Blacksburg, VA 24061 USA.
C3 Xijing University; Virginia Polytechnic Institute & State University
RP Zhang, SW (corresponding author), Xijing Univ, Dept Informat Engn, Xian 710123, Shaanxi, Peoples R China.; Zhang, SW (corresponding author), Virginia Tech, Dept Comp Sci, Blacksburg, VA 24061 USA.
EM wjdw716@163.com
OI zhang, shanwen/0000-0002-4534-5358
FU China National Natural Science Foundation [61473237]; Shaanxi Natural
   Science Foundation Research Project [2014JM2-6096]; Tianjin Research
   Program of Application Foundation and Advanced Technology
   [14JCYBJC42500]; Tianjin science and technology correspondent project
   [16JCTPJC47300]
FX This work is supported by the China National Natural Science Foundation
   under grant Nos. 61473237. It is also supported by the Shaanxi Natural
   Science Foundation Research Project under grant No. 2014JM2-6096,
   Tianjin Research Program of Application Foundation and Advanced
   Technology No. 14JCYBJC42500 and Tianjin science and technology
   correspondent project No. 16JCTPJC47300. The authors would like to thank
   the gait CASIA subset and all the editors and anonymous reviewers for
   their constructive advices.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P INT C EL COMM SYST
   [Anonymous], MACH VIS APPL
   Chetty G, 2015, INT J INTELL INFO PR, V5, P1
   Deng MQ, 2017, PATTERN RECOGN, V67, P186, DOI 10.1016/j.patcog.2017.02.014
   Fan ZZ, 2016, PATTERN RECOGN, V58, P100, DOI 10.1016/j.patcog.2016.03.029
   Fan ZZ, 2011, IEEE T NEURAL NETWOR, V22, P1119, DOI 10.1109/TNN.2011.2152852
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   김사문, 2014, [Journal of Korean Institute of Intelligent Systems, 한국지능시스템학회 논문지], V24, P622
   Liu XK, 2017, PATTERN RECOGN, V67, P287, DOI 10.1016/j.patcog.2017.02.015
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Luo J, 2015, INT J OPT, V2015, DOI 10.1155/2015/763908
   Mu Y, 2010, NEUROCOMPUTING, V73, P895, DOI 10.1016/j.neucom.2009.09.017
   Nagendraswamy HS, 2014, SIGNAL IMAGE PROCESS, V5, P15
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pepler PT, 2017, COMMUN STAT-SIMUL C, V46, P4812, DOI 10.1080/03610918.2015.1134568
   Tafazzoli F, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013036
   Wahida Banu R. S. D., 2015, INT J APPL ENG RES, V10, P5443
   Xing XL, 2015, IEEE SIGNAL PROC LET, V22, P2349, DOI 10.1109/LSP.2015.2481930
   Xu Y, 2004, PATTERN RECOGN, V37, P2091, DOI 10.1016/j.patcog.2004.02.016
   Xue ZJ, 2010, PATTERN RECOGN, V43, P2904, DOI 10.1016/j.patcog.2010.03.011
   Yun Shi, 2015, Applied Mechanics and Materials, V701-702, P274, DOI 10.4028/www.scientific.net/AMM.701-702.274
   Zhang D, 2016, INT J COMPUT SCI ENG, V13, P13, DOI 10.1504/IJCSE.2016.10000005
   Zhang SW, 2015, INFORMATICA-LITHUAN, V26, P357, DOI 10.15388/Informatica.2015.52
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng S, 2012, PATTERN RECOGN, V45, P3603, DOI 10.1016/j.patcog.2012.03.008
NR 27
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12331
EP 12347
DI 10.1007/s11042-017-4884-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100031
DA 2024-07-18
ER

PT J
AU Chi, LP
   Wu, CH
   Chang, HP
AF Chi, Li-Pin
   Wu, Chang-Han
   Chang, Hsung-Pin
TI Reversible data hiding in dual Stegano-image using an improved center
   folding strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual stego-image reversible data embedding; Center folding strategy;
   Joint neighboring coding; Dynamic encoding
ID PREDICTION; WATERMARKING; EXPANSION
AB In recent years, the dual stego-image reversible data embedding methods have been developed rapidly, e.g., exploiting modification direction, magic matrix, least significant bit matching, and center folding strategy. The kind of method can effectively embed secret data into two stego-images and maintain excellent image quality and enhance the security. In 2015, Lu et al. proposed a center folding strategy that can effectively encode messages as the smaller digits. The encoding procedure reduces the modification level of pixels, thereby maintaining good image quality. However, their strategy does not use the relationship between the adjacent digits to reduce the number of the largest digits. Inspired by joint neighboring coding, we proposed a dynamic encoding strategy to improve the center folding strategy. The encoding strategy can reduce the secret digits and decrease the occurrence frequency of the maximum digits, thereby substantially reducing the modification level of pixels. The advantage makes that the proposed method can achieve a higher PSNR value than previous methods under the same embedding rate.
C1 [Chi, Li-Pin] Natl Chung Shan Inst Sci & Technol, Aeronaut Res Lab, Taichung 40722, Taiwan.
   [Wu, Chang-Han; Chang, Hsung-Pin] Natl Chung Hsing Univ, Dept Comp Sci & Engn, 250 Kuo Kuang Rd, Taichung 40227, Taiwan.
C3 National Chung Hsing University
RP Wu, CH (corresponding author), Natl Chung Hsing Univ, Dept Comp Sci & Engn, 250 Kuo Kuang Rd, Taichung 40227, Taiwan.
EM cp531220@ms23.hinet.net; phd9712@cs.nchu.edu.tw; hpchang@cs.nchu.edu.tw
OI Chang, Hsung-Pin/0000-0002-2680-8556
CR Chang CJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/526806
   Chang CC, 2007, INT J INNOV COMPUT I, V3, P1145
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Horng G, 2014, J INFORM HIDING MULT, V5, P152
   Huang YH, 2014, MULTIMED TOOLS APPL, V70, P1439, DOI 10.1007/s11042-012-1176-z
   Jana Biswapati, 2016, International Journal of Network Security, V18, P633
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Lu TC, 2007, MULTIMEDIA SECURITY
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2015, SECUR COMMUN NETW, V8, P899, DOI 10.1002/sec.1046
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 25
TC 28
Z9 28
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8785
EP 8803
DI 10.1007/s11042-017-4774-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800045
DA 2024-07-18
ER

PT J
AU Santhi, S
   Malarchelvi, PDSK
AF Santhi, S.
   Malarchelvi, P. D. Sheba Kezia
TI Self-Similar key generation for secure communication in multimedia
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese Remainder Theorem; Diffie Hellman; Elliptic Curve Cryptography;
   Group Key Management
ID DISTRIBUTION PROTOCOL; MANAGEMENT; SCHEME
AB Long term research activities focus on the provision of fundamental understanding and easy deployment of multimedia services on the multimedia communication. The rapid growth of digital communication and electronic data exchange provides the intensive data transfer without concentrating on the security issues. Secure communication with the minimal computational and storage overhead is the challenging task with the large size members nowadays. The Group Key Management (GKM) protocols offer numerous solutions to the security issues with an efficient interaction of group members controlling them. The groups participated in secure communication belongs to open or close scenario. The participation of registered members in close group is beneficial than the open group. With the increase in number of participants, the key size and the number of key generations will increase the computational overhead. To alleviate these issues, this paper proposes the novel self-similar key generation and distribution scheme on the basis of the Elliptic Curve Diffie Hellman (ECDH) and Chinese Reminder Theorem (CRT). The assigning permission to each node to generate their own key at the specified time by the ECDH prevents the unnecessary distribution of keys that reduces the communication overhead. Then, the application of CRT theorem reduces the mathematical burden of key generation. Finally, the integration of the Elliptic Curve Cryptography (ECC) with the above mechanisms validates the number of messages transferred among the participants in both sender and receiver side. The prior key generation using ECDH and the CRT-based self-similar key generation reduces the computational and communication overhead effectively. The comparative analysis between the proposed SSKG with the existing schemes in terms of overhead, complexity assures the effectiveness of proposed schemes in secure multicast communication.
C1 [Santhi, S.] Valivalam Desikar Polytech Coll, Dept Comp Engn, Nagapattinam 611001, Tamil Nadu, India.
   [Malarchelvi, P. D. Sheba Kezia] JJ Coll Engn & Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
RP Santhi, S (corresponding author), Valivalam Desikar Polytech Coll, Dept Comp Engn, Nagapattinam 611001, Tamil Nadu, India.
EM shanthi20111@gmail.com
RI P D, P D Sheba Kezia Malarchelvi/HHZ-0739-2022
OI P D, P D Sheba Kezia Malarchelvi/0000-0002-5100-9924
CR Ahmad I, 2016, INT J, V5
   Barsoum A, 2013, IEEE T PARALL DISTR, V24, P2375, DOI 10.1109/TPDS.2012.337
   Benmalek M, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P183, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.27
   Ch SA, 2015, MULTIMED TOOLS APPL, V74, P1711, DOI 10.1007/s11042-014-2283-9
   Chakraborty TK, 2013, IEEE INT ADV COMPUT, P101
   Chen XF, 2014, IEEE T PARALL DISTR, V25, P2386, DOI 10.1109/TPDS.2013.180
   Depeng Li, 2016, International Journal of Network Security, V18, P946
   Jaiswal P, 2015, ADV INTELL SYST COMP, V339, P167, DOI 10.1007/978-81-322-2250-7_17
   Kumar A, 2014, INT J COMPUT APPL, V86
   Kumar V., 2016, ARXIV160301542
   Lee NY, 2013, 2013 IEEE 37TH ANNUAL COMPUTER SOFTWARE AND APPLICATIONS CONFERENCE WORKSHOPS (COMPSACW), P11, DOI 10.1109/COMPSACW.2013.7
   Li XP, 2016, IEEE T INFORM THEORY, V62, P7491, DOI 10.1109/TIT.2016.2614322
   Lin HY, 2016, INT J COMPUT SCI ENG, V12, P47, DOI 10.1504/IJCSE.2016.074558
   Malik MY, 2012, ARXIV12113502
   Mapoka TT, 2013, INT J COMPUT APPL, V84
   Naranjo JAM, 2012, J COMPUT APPL MATH, V236, P3042, DOI 10.1016/j.cam.2011.02.015
   Naresh VS, 2015, SADHANA-ACAD P ENG S, V40, P2143, DOI 10.1007/s12046-015-0434-y
   Porambage P, 2015, IEEE ACCESS, V3, P1503, DOI 10.1109/ACCESS.2015.2474705
   Sadananda P, 2013, INT J COMPUT APPL, V82
   Thangavelu S, 2016, INT ARAB J INF TECHN, V13, P492
   Tirthani N, 2014, IACR CRYPTOL EPRINT, P49
   Veltri L, 2013, AD HOC NETW, V11, P2724, DOI 10.1016/j.adhoc.2013.05.009
   Vijayakumar P, 2013, COMPUT MATH APPL, V65, P1360, DOI 10.1016/j.camwa.2012.01.038
   Vijayakumar P, 2013, KSII T INTERNET INF, V7, P878, DOI 10.3837/tiis.2013.04.016
   Vijayakumar P., 2012, NETW SCI, V1, P39
   Vijayakumar P, 2014, IET INFORM SECUR, V8, P179, DOI 10.1049/iet-ifs.2012.0352
   Wang H, 2012, IET INFORM SECUR, V6, P281, DOI 10.1049/iet-ifs.2011.0281
   Yadav M, 2016, 2016 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ELECTRICAL ELECTRONICS & SUSTAINABLE ENERGY SYSTEMS (ICETEESES), P196, DOI 10.1109/ICETEESES.2016.7581384
NR 28
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10329
EP 10346
DI 10.1007/s11042-018-5688-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200060
DA 2024-07-18
ER

PT J
AU El Mallahi, M
   Zouhri, A
   Mesbah, A
   Berrahou, A
   El Affar, I
   Qjidaa, H
AF El Mallahi, Mostafa
   Zouhri, Amal
   Mesbah, Abderrahim
   Berrahou, Aissam
   El Affar, Imad
   Qjidaa, Hassan
TI Radial invariant of 2D and 3D Racah moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D/3D discrete orthogonal radial Racah moments; Radial Racah
   polynomials; 2D/3D image reconstruction; 2D/3D scaling, rotation and
   translation moment invariants, 2D/3D pattern recognition
ID MANY-CORE PROCESSOR; HEVC; ROTATION
AB In this paper, we introduce new sets of 2D and 3D rotation, scaling and translation invariants based on orthogonal radial Racah moments. We also provide theoretical mathematics to derive them. Thus, this work proposes in the first case a new 2D radial Racah moments based on polar representation of an object by one-dimensional orthogonal discrete Racah polynomials on non-uniform lattice, and a circular function. In the second case, we present new 3D radial Racah moments using a spherical representation of volumetric image by one-dimensional orthogonal discrete Racah polynomials and a spherical function. Further 2D and 3D invariants are extracted from the proposed 2D and 3D radial Racah moments respectively will appear in the third case. To validate the proposed approach, we have resolved three problems. The 2D/ 3D image reconstruction, the invariance of 2D/3D rotation, scaling and translation, and the pattern recognition. The result of experiments show that the Racah moments have done better than the Krawtchouk moments, with and without noise. Simultaneously, the mentioned reconstruction converges rapidly to the original image using 2D and 3D radial Racah moments, and the test 2D/3D images are clearly recognized from a set of images that are available in COIL-20 database for 2D image, and PSB database for 3D image.
C1 [El Mallahi, Mostafa; Zouhri, Amal; Mesbah, Abderrahim; Berrahou, Aissam; El Affar, Imad; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar el Mahraz, CED ST Ctr Doctoral Studies Sci & Technol, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP El Mallahi, M (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar el Mahraz, CED ST Ctr Doctoral Studies Sci & Technol, Fes, Morocco.
EM mostafa.elmallahi@usmba.ac.ma
RI ZOUHRI, Amal/AAA-4511-2022
OI Hassan, qjidaa/0000-0003-4505-5243; ZOUHRI, Amal/0000-0002-8748-484X; El
   Mallahi, Mostafa/0000-0001-6405-4129; berrahou,
   aissam/0000-0003-2787-3138; El Mallahi, Mostafa/0000-0001-9735-6799
CR Canterakis N., 1999, PROC 11 SCANDINAVIAN, P85
   Cyganski D, 1988, OBJECT RECOGNITION O, V7, P662
   El Mallahi M, 2015, IEEE INTELLIGENT SYS
   Fehr Janis, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1381, DOI 10.1109/ICPR.2010.341
   Fehr J., 2008, P 19 INT C PATT REC, P1, DOI DOI 10.1109/ICPR.2008.4761098
   Flusser J, 2003, IEEE T PATTERN ANAL, V25, P234, DOI 10.1109/TPAMI.2003.1177154
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   Kakarala R, 2010, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2010.5540222
   Kazhdan M, 2007, IEEE T PATTERN ANAL, V29, P1221, DOI 10.1109/TPAMI.2007.1032
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   Mesbah A, 2016, LECT NOTES ELECT ENG, V1
   Princeton, 2013, PRINC SHAP BENCHM
   Qjidaa, 2014, WSEAS T CIRCUITS SYS, V13, P368
   REISS TH, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P493, DOI 10.1109/ICPR.1992.202032
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   Skibbe Henrik, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P142, DOI 10.1007/978-3-642-23123-0_15
   Suk T, 2011, LECT NOTES COMPUT SC, V6855, P212, DOI 10.1007/978-3-642-23678-5_24
   Westenberg MA, 2007, IEEE T IMAGE PROCESS, V16, P2943, DOI 10.1109/TIP.2007.909317
   Xu D, 2008, PATTERN RECOGN, V41, P240, DOI 10.1016/j.patcog.2007.05.001
   Xuan Guo, 1993, Computer Analysis of Images and Patterns. 5th International Conference, CAIP '93 Proceedings, P518
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan C, 2013, DATA COMPRESSION CON
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 28
TC 18
Z9 18
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6583
EP 6604
DI 10.1007/s11042-017-4573-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700007
DA 2024-07-18
ER

PT J
AU Jiang, RQ
   Zhang, WM
   Hou, DD
   Wang, H
   Yu, NH
AF Jiang, Ruiqi
   Zhang, Weiming
   Hou, Dongdong
   Wang, Hui
   Yu, Nenghai
TI Reversible data hiding for 3D mesh models with three-dimensional
   prediction-error histogram modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh models; Reversible data hiding; Histogram modification;
   Recursive construction coding; Prediction error
ID EXPANSION; SCHEME
AB This study proposes a reversible data hiding (RDH) algorithm for 3D mesh models based on the optimal three-dimensional prediction-error histogram (PEH) modification with recursive construction coding (RCC). Firstly, we design a double-layered prediction scheme to divide all the vertices of 3D mesh model into the "embedded" set and the "referenced" set, according to the odd-even property of indices into the vertex list. Thanks to the geometrical similarity among neighboring vertices, we obtain the prediction errors (PEs) with a sharp histogram. Then we combine every three adjacent PEs into one prediction-error triplet (PET) and construct the three-dimensional PEH with smaller entropy than one-dimensional PEH by utilizing the correlation among PEs. Next we project the three-dimensional PEH into one-dimensional space for scalar PET sequence which is suitable for using RCC. And also, we define the distortion metrics for 3D mesh models, by which we can estimate the optimal probability transition matrix (OTPM) indicating the optimal PEH modification manner. After that, we modify the PET sequence and embed data by RCC according to OTPM. The experimental results show that our method is superior to two state-of-the-art spatial-domain RDH algorithms for 3D mesh models a lot.
C1 [Jiang, Ruiqi; Zhang, Weiming; Hou, Dongdong; Wang, Hui; Yu, Nenghai] Univ Sci & Technol China, Chinese Acad Sci, Sch Informat Sci & Technol, Key Lab Electromagnet Space Informat, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Chinese Acad Sci, Sch Informat Sci & Technol, Key Lab Electromagnet Space Informat, Hefei 230026, Anhui, Peoples R China.
EM zhangwm@ustc.edu.cn
RI wang, huimin/HDM-8421-2022
FU Natural Science Foundation of China [U1636201, 61502007, 61572452];
   China Postdoctoral Science Foundation [2015M582015]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1636201, 61572452, 61502007, and in part by the China
   Postdoctoral Science Foundation under Grant 2015M582015.
CR Chou D, 2009, INT J INNOV COMPUT I, V5, P1893
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Hu XC, 2013, IEEE T INF FOREN SEC, V8, P779, DOI 10.1109/TIFS.2013.2256131
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang YH, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0051-x
   Kalker T, 2003, PROC SPIE, V5020, P604, DOI 10.1117/12.473164
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin SJ, 2012, IEEE T INF FOREN SEC, V7, P1155, DOI 10.1109/TIFS.2012.2197614
   Luo H, 2006, 2006 IEEE International Symposium on Signal Processing and Information Technology, Vols 1 and 2, P863, DOI 10.1109/ISSPIT.2006.270919
   Luo H, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P487
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sun Z, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P593
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wu HT, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P801
   Wu HT, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P774
   Zhang WM, 2015, IEEE T IMAGE PROCESS, V24, P294, DOI 10.1109/TIP.2014.2358881
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
   Zhe-Ming Lu, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P233
NR 25
TC 20
Z9 22
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5263
EP 5280
DI 10.1007/s11042-017-4430-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800008
DA 2024-07-18
ER

PT J
AU Chen, HY
   Xie, K
   Wang, H
   Zhao, CX
AF Chen, Haiyan
   Xie, Ke
   Wang, Huan
   Zhao, Chunxia
TI Scene image classification using locality-constrained linear coding
   based on histogram intersection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SPM; Sparse coding; Histogram intersection; Image classification
ID EXTREME LEARNING-MACHINE; FACE RECOGNITION; REGRESSION CLASSIFICATION;
   SUPPORT; REPRESENTATION; ENTROPY; TRANSFORM; ALGORITHM
AB Recently linear Spatial Pyramid Matching (SPM) method based on sparse coding has achieved great success in image classification. The raise of Locality-constrained Linear Coding (LLC) proves the importance of locality. In this paper, we propose an improved feature coding scheme called Locality-constrained Linear Coding Based on Histogram Intersection (HILLC). HILLC uses histogram intersection to describe the distance between feature vector and codebook. For each feature vector, search the KNN nearest neighbors to construct a local codebook. Compared with LLC, HILLC can obtain more robust codes. Experimental results demonstrate that our proposed method outperforms other related coding methods.
C1 [Chen, Haiyan; Wang, Huan; Zhao, Chunxia] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Xie, Ke] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Southeast University - China
RP Wang, H (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM huan_wang_nust@163.com
RI Li, Shiyue/KFA-3709-2024; Wang, Yue/JRY-8962-2023; Chen,
   Haiyan/HGB-6216-2022
OI Wang, Yue/0000-0001-8673-6358; 
FU NSF of China [61202134, 31671006]; Natural Science Foundation of Jiangsu
   Province [BK20140638, BK2012437]
FX This project is partly supported by NSF of China (61202134, 31671006),
   the Natural Science Foundation of Jiangsu Province (No. BK20140638,
   BK2012437).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], 2009, P ADV NEUR INF PROC
   Barla A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P513
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y, 2008, J MATH IMAGING VIS, V30, P133, DOI 10.1007/s10851-007-0042-5
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3813, DOI 10.1007/s11042-016-4161-0
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Duan FF, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1054-z
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gu B., 2016, IEEE Transactions on Neural Networks and Learning Systems, DOI DOI 10.1109/TNNLS.2016.2527796
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2010, NEUROCOMPUTING, V74, P155, DOI 10.1016/j.neucom.2010.02.019
   Huang SM, 2013, IEEE SIGNAL PROC LET, V20, P443, DOI 10.1109/LSP.2013.2250957
   Huang SM, 2012, INT CONF ACOUST SPEE, P1945, DOI 10.1109/ICASSP.2012.6288286
   Huang SM, 2013, IEEE SIGNAL PROC LET, V20, P91, DOI 10.1109/LSP.2012.2230257
   Huang SM, 2012, IEEE SIGNAL PROC LET, V19, P179, DOI 10.1109/LSP.2012.2185492
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   Li CH, 2012, IEEE T GEOSCI REMOTE, V50, P784, DOI 10.1109/TGRS.2011.2162246
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moustakidis S, 2012, IEEE T GEOSCI REMOTE, V50, P149, DOI 10.1109/TGRS.2011.2159726
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shen FM, 2013, NEUROCOMPUTING, V101, P104, DOI 10.1016/j.neucom.2012.08.007
   WANG Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI DOI 10.1109/TNNLS.2015.2477537
   Wang SH, 2017, CNS NEUROL DISORD-DR, V16, P11, DOI 10.2174/1871527315666161111123024
   Wang SH, 2017, CNS NEUROL DISORD-DR, V16, P116, DOI 10.2174/1871527315666161111123638
   Wang SH, 2016, PEERJ, V4, DOI 10.7717/peerj.2207
   Wang SH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060169
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang WK, 2017, MULTIMED TOOLS APPL, V76, P4491, DOI 10.1007/s11042-016-3446-7
   Yang WK, 2016, NEUROCOMPUTING, V213, P183, DOI 10.1016/j.neucom.2015.11.134
   Yang WK, 2016, NEUROCOMPUTING, V175, P198, DOI 10.1016/j.neucom.2015.10.049
   Yang WK, 2015, PATTERN RECOGN, V48, P20, DOI 10.1016/j.patcog.2014.07.009
   Zhang L., 2017, IEEE transactions on neural networks and learning systems, V28, P3045, DOI DOI 10.1109/TNNLS.2016.2607757
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2014, PROG ELECTROMAGN RES, V144, P171, DOI 10.2528/PIER13121310
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 56
TC 10
Z9 11
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 4081
EP 4092
DI 10.1007/s11042-017-4830-7
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600064
DA 2024-07-18
ER

PT J
AU Fang, S
   Achard, C
   Dubuisson, S
AF Fang, Sheng
   Achard, Catherine
   Dubuisson, Severine
TI Modeling the synchrony between interacting people: application to role
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Role recognition; Influence model; Interaction modelling; Synchrony
ID HIDDEN MARKOV-MODELS; FRAMEWORK
AB The study of social interactions has attracted increasing attentions. The role recognition is one of its possible applications and the core of this study. This article proposes some approaches to automatically recognize the role of the participants of a meeting by modeling the synchrony of temporal nonverbal audio features. In our approache the Influence Model (IM), a Hidden Markov Model (HMM)-like, is used to model this synchrony and to extract from input data a feature vector that contains both information about temporal transitions (intra-personal data) and interaction between participants (inter-personal data). This modeling of the meeting is used as input of a Random Forests (RFs) for the role recognition task. The experiments are performed on 138 meetings (approximately 45 hours of recordings) from Augmented Multiparty Interaction (AMI) Corpus. Accuracy scores show that this combination of generative (IM) and discriminative (RFs) approaches permits to outperform state-of-the-art role recognition rates.
C1 [Fang, Sheng; Achard, Catherine; Dubuisson, Severine] UPMC Univ Paris 06, Sorbonne Univ, UMR 7222, CNRS, F-75005 Paris, France.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)
RP Fang, S (corresponding author), UPMC Univ Paris 06, Sorbonne Univ, UMR 7222, CNRS, F-75005 Paris, France.
EM fang@isir.upmc.fr; catherine.achard@isir.upmc.fr;
   severine.dubuisson@isir.upmc.fr
RI Achard, Catherine/AAK-2130-2021
OI Achard, Catherine/0000-0002-5790-0830
FU French state funds [ANR-11-LABX-65, ANR-11-IDEX-0004-02]
FX This work was performed within the Labex SMART (ANR-11-LABX-65)
   supported by French state funds managed by the ANR within the
   Investissements d'Avenir programme under reference ANR-11-IDEX-0004-02.
CR [Anonymous], 2008, P 10 INT C MULT INT
   [Anonymous], 2008, Proc. ACM Multimedia, DOI [10.1145/1459359.1459462, DOI 10.1145/1459359.1459462]
   [Anonymous], 2000, THESIS
   [Anonymous], 1994, SOCIAL NETWORK ANAL
   Banerjee S, 2004, INT C AC SPEECH SIGN
   Banerjee S, 2004, INT C SPOK LANG PROC, P1
   Basu S, 2001, C NEUR INF PROC SYST
   Bishop C.M., 2007, Bayesian Stat., V8, P3, DOI [DOI 10.1007/978-3-642-93220-5_6, 10.1093/oso/9780199214655.003.0001, DOI 10.1093/OSO/9780199214655.003.0001]
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Cristani M, 2011, PATTERN RECOGN, V44, P1785, DOI 10.1016/j.patcog.2011.01.013
   Delaherche E, 2012, IEEE T AFFECT COMPUT, V3, P349, DOI 10.1109/T-AFFC.2012.12
   Dong W, 2013, IEEE T MULTIMEDIA, V15, P83, DOI 10.1109/TMM.2012.2225039
   Dong W, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P271
   Holub A, 2005, PROC CVPR IEEE, P664
   Laskowski Kornel., 2008, P ISCA ACL SIGDIAL W, P148
   Liu Y., 2006, Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, P81
   McCowan I., 2005, MEASURING BEHAV, V88
   McDowell LK, 2009, J MACH LEARN RES, V10, P2777
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Pianesi F, 2007, LANG RESOUR EVAL, V41, P409, DOI 10.1007/s10579-007-9060-6
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rosales R, 2006, INT J COMPUT VISION, V67, P251, DOI 10.1007/s11263-006-5165-4
   Salamin H, 2009, IEEE T MULTIMEDIA, V11, P1373, DOI 10.1109/TMM.2009.2030740
   Salzmann M, 2010, PROC CVPR IEEE, P647, DOI 10.1109/CVPR.2010.5540155
   Sanchez-Cortes D, 2011, MULTIMODAL CORPORA
   Sanchez-Cortes D, 2012, IEEE T MULTIMEDIA, V14, P816, DOI 10.1109/TMM.2011.2181941
   Thorndike EL, 1920, Harper's Magazine, V140, P227
   Varni G, 2010, IEEE T MULTIMEDIA, V12, P576, DOI 10.1109/TMM.2010.2052592
   Vinciarelli A, 2007, IEEE T MULTIMEDIA, V9, P1215, DOI 10.1109/TMM.2007.902882
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Zancanaro M., 2006, Proceedings of the 8th international conference on Multimodal interfaces, P28
NR 31
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 503
EP 518
DI 10.1007/s11042-016-4267-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400021
DA 2024-07-18
ER

PT J
AU Hu, WC
   Chen, CH
   Chen, TY
   Peng, MY
   Su, YJ
AF Hu, Wu-Chih
   Chen, Chao-Ho
   Chen, Tsong-Yi
   Peng, Min-Yang
   Su, Yi-Jen
TI Real-time video stabilization for fast-moving vehicle cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stabilization; Fast-moving camera; Traffic video
ID SURVEILLANCE; TRACKING
AB Most previous methods of real-time video stabilization are only effective for low-vibrating frames which are usually captured by in-vehicle camera at the low-speed moving. To overcome their ineffectiveness on high-vibrating frames, this paper presents a real-time video stabilization system for the video sequences captured by a fast-moving in-vehicle camera without additional sensors. The proposed method is composed of four parts: frame-shaking judgment, feature classification, evaluating global motion and rotation angle, and frame compensation. Feature points and their motion vectors are employed for judging whether the current frame is shaking or not, and then a conversion matrix is deduced through the perspective projection for classifying such feature points into background or foreground type. Next, the optical flows of background's feature points are mapped to polar coordinates for obtaining the representative optical-flow cluster of the background. Finally, such a cluster is utilized to calculate the global motion and rotation angle for compensation followed by the Kalman filtering in order to provide the better video stabilization. Experimental results show that the proposed method has good real-time video stabilization for a vehicle camera moving at various speeds and better stabilization performance than other methods for high-vibrating frames when both real-time processing and acceptable stabilization result are considered.
C1 [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Magong, Penghu, Taiwan.
   [Chen, Chao-Ho; Chen, Tsong-Yi; Peng, Min-Yang] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung, Taiwan.
   [Su, Yi-Jen] Shu Te Univ, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.
C3 National Penghu University of Science & Technology; National Kaohsiung
   University of Science & Technology; Shu-Te University
RP Chen, CH (corresponding author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung, Taiwan.
EM wchu@npu.edu.tw; thouho@cc.kuas.edu.tw; chentso@cc.kuas.edu.tw;
   j198811@gmail.com; iansu@stu.edu.tw
FU Ministry of Science and Technology, Taiwan [MOST105-2221-E-346-009,
   MOST104-2221-E-151-008, MOST104-2622-E-151-015-CC3]
FX This work was partly supported by the Ministry of Science and
   Technology, Taiwan, under grants MOST105-2221-E-346-009,
   MOST104-2221-E-151-008, and MOST104-2622-E-151-015-CC3. The authors wish
   to express the appreciation to Mr. Jhih-Bin Guo and Prof. Tong-Yee Lee
   for their help with the experiments. The authors also gratefully
   acknowledge the helpful comments and suggestions of reviewers, which
   have improved the quality and presentation.
CR Aguilar WG, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-46
   [Anonymous], 2014, ADV INTELLIGENT SYST
   Chen CH, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON ROBOT, VISION AND SIGNAL PROCESSING (RVSP), P10, DOI 10.1109/RVSP.2015.11
   Choi WG, 2013, IEEE T PATTERN ANAL, V35, P1577, DOI 10.1109/TPAMI.2012.248
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Hu WC, 2011, J VIS COMMUN IMAGE R, V22, P543, DOI 10.1016/j.jvcir.2011.03.009
   Hu WC, 2011, INT J INNOV COMPUT I, V7, P1845
   Huang D-Y, 2016, J INFORM HIDING MULT, V7, P101
   Jia C, 2014, IEEE T SIGNAL PROCES, V62, P3293, DOI 10.1109/TSP.2014.2325795
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim SK, 2013, IEEE T CONSUM ELECTR, V59, P267, DOI 10.1109/TCE.2013.6490269
   Liang YM, 2004, IEEE T VEH TECHNOL, V53, P1636, DOI 10.1109/TVT.2004.836923
   Licsár A, 2003, LECT NOTES COMPUT SC, V2756, P230
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Marcenaro L, 2001, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2001.959025
   Nicolescu M, 2005, IEEE T PATTERN ANAL, V27, P739, DOI 10.1109/TPAMI.2005.91
   Shen Y, 2009, IEEE T CONSUM ELECTR, V55, P1714, DOI 10.1109/TCE.2009.5278047
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Wang Y., 2011, Proceedings of the 12th IAPR Conference on Machine Vision Applications, MVA 2011, P336
   Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11
   Zhang YF, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P204, DOI 10.1109/WKDD.2010.112
NR 27
TC 9
Z9 10
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1237
EP 1260
DI 10.1007/s11042-016-4291-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400051
DA 2024-07-18
ER

PT J
AU Kajo, I
   Kamel, N
   Malik, AS
AF Kajo, Ibrahim
   Kamel, Nidal
   Malik, Aamir Saeed
TI An adaptive block-based matching algorithm for crowd motion sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Social force model; Search points; Surveillance;
   Predicted motion vector
ID SEARCH ALGORITHM; IMAGE
AB For crowd analytics and surveillance systems, motion estimation is an essential first step. Lots of crowd motion estimation algorithms have been presented in the last years comprising pedestrian motion. However, algorithms based on optical flow and background subtraction have numerous limitations such as the complexity of the computation in the presence of high dense crowd and sudden motion changes. Therefore, a novel estimation algorithm is proposed to measure the motion of crowd with less computational complexity and satisfy the real time requirements. The proposed algorithm is based on block-based matching, particle advection, and social force model. By the block-based matching, the motion is estimated in each frame, and the corresponding motion field is created. The particle advection process provides more information about the behavior of pedestrians groups, their tracked trajectories and the boundary of each group segment. Relying on the social force model, a predicted direction of the motion vectors (MV) could be measured significantly. Subsequently, the block-based technique is combined with the social force model to obtain the accurate motion vector with the less possible number of search points. The experimental results indicate that the proposed method achieves high performance by reducing the search points, particularly when many collision situations or obstacles exist in the scenes. Considering the reduction in the computational complexity, the quality of degradation is very low. In all cases, average PSNR degradation of the proposed algorithm is only 0.09.
C1 [Kajo, Ibrahim; Kamel, Nidal; Malik, Aamir Saeed] Univ Teknol PETRONAS, Dept Elect & Elect, Ctr Intelligent Signal & Imaging Res, Tronoh 31750, Perak, Malaysia.
C3 Universiti Teknologi Petronas
RP Kamel, N (corresponding author), Univ Teknol PETRONAS, Dept Elect & Elect, Ctr Intelligent Signal & Imaging Res, Tronoh 31750, Perak, Malaysia.
EM nidalkamel@petronas.com.my
RI Malik, Aamir S/C-6904-2009; kajo, ibrahim/U-1413-2019
OI Malik, Aamir S/0000-0003-1085-3157; 
CR Ali S, 2007, PROC CVPR IEEE, P65
   [Anonymous], OBJECT LEVEL MOTION
   [Anonymous], 2015, 2015 9 INT C SIGNAL, DOI DOI 10.1109/ICSPCS.2015.7391778
   [Anonymous], OVERVIEW PETS 2009 C
   [Anonymous], 2015, COMPOUND RANK K PROJ
   [Anonymous], 2014, ARXIV14116233
   [Anonymous], EMPIRICAL STUDY BLOC
   [Anonymous], 2001, CONDMAT0112117 ARXIV
   Basset A, 2014, IEEE IMAGE PROC, P184, DOI 10.1109/ICIP.2014.7025036
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P267, DOI 10.1109/AFGR.2002.1004165
   Chaker R, 2015, IEEE IMAGE PROC, P1280, DOI 10.1109/ICIP.2015.7351006
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Cong Y, 2015, MACH VISION APPL, V26, P633, DOI 10.1007/s00138-015-0688-8
   Crivelli T, 2008, LECT NOTES COMPUT SC, V5302, P113, DOI 10.1007/978-3-540-88682-2_10
   DAAMEN W., 2002, C P EUROSIW, P24
   Duives DC, 2013, TRANSPORT RES C-EMER, V37, P193, DOI 10.1016/j.trc.2013.02.005
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Huang SY, 2005, IEEE T CIRC SYST VID, V15, P1373, DOI 10.1109/TCSVT.2005.856931
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Jou SY, 2015, IEEE T CIRC SYST VID, V25, P1533, DOI 10.1109/TCSVT.2015.2389472
   Lam THW, 2007, PATTERN RECOGN, V40, P2563, DOI 10.1016/j.patcog.2006.11.014
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Li B, 2003, J COMPUT SCI TECHNOL, V18, P14, DOI 10.1007/BF02946646
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lin LL, 2016, SIGNAL IMAGE VIDEO P, V10, P171, DOI 10.1007/s11760-014-0723-7
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Luo J, 2015, MULTIMED TOOLS APPL, V74, P11821, DOI 10.1007/s11042-014-2280-z
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Pan JS, 2015, MULTIMED TOOLS APPL, V74, P9191, DOI 10.1007/s11042-014-2076-1
   Paul A, 2015, J SIGNAL PROCESS SYS, V79, P257, DOI 10.1007/s11265-013-0841-4
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Richardson Iain E, 2011, The H. 264 advanced video compression standard
   Salmane H, 2015, IEEE T INTELL TRANSP, V16, P596, DOI 10.1109/TITS.2014.2331347
   Shi ZR, 2011, IEEE T CONSUM ELECTR, V57, P1354, DOI 10.1109/TCE.2011.6018894
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Tourapis AM, 2002, PROC SPIE, V4671, P1069, DOI 10.1117/12.453031
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Xin YH, 2014, OPTIK, V125, P5690, DOI 10.1016/j.ijleo.2014.06.092
   Xiong M., 2009, P 2009 SPRING SIM MU, P17, DOI DOI 10.5555/1639809.1639827
   Yang JF, 2002, IEEE T CIRC SYST VID, V12, P948, DOI 10.1109/TCSVT.2002.804892
   Yang LB, 2005, IEEE T CIRC SYST VID, V15, P784, DOI 10.1109/TCSVT.2005.848306
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 44
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1783
EP 1809
DI 10.1007/s11042-016-4327-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400014
DA 2024-07-18
ER

PT J
AU Mahmood, S
   Khan, YD
   Mahmood, MK
AF Mahmood, Salman
   Khan, Yaser Daanial
   Mahmood, M. Khalid
TI A treatise to vision enhancement and color fusion techniques in night
   vision devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Night vision; Vision enhancement; Color fusion
AB In this article a vast literary and ample historic review has been examined to provide in detail introduction, knowledge and comparison of night vision imaging techniques. It unveils night vision enhancement methods described in the recent times such as contrast enhancement; color transfer based clustering, fast color contrast enhancement and pseudo-color fusion algorithm for self-adaptive enhancement system along many others. Furthermore, the scientific and mathematical details are elaborated along with the mechanisms used image fusion techniques, color mapping, histogram matching and statistical evaluation. Conclusively, the channel based color fusion technique stood out through statistical and perceptual analysis.
C1 [Mahmood, Salman; Khan, Yaser Daanial] Univ Management & Technol, Sch Sci & Technol, Lahore, Pakistan.
   [Khan, Yaser Daanial] Univ Management & Technol, Sch Sci & Technol, Dept Comp Sci, UMT Rd, Lahore 54500, Punjab, Pakistan.
   [Mahmood, M. Khalid] Univ Punjab, Dept Math, Lahore, Pakistan.
C3 University of Management & Technology (UMT); University of Management &
   Technology (UMT); University of Punjab
RP Khan, YD (corresponding author), Univ Management & Technol, Sch Sci & Technol, Lahore, Pakistan.; Khan, YD (corresponding author), Univ Management & Technol, Sch Sci & Technol, Dept Comp Sci, UMT Rd, Lahore 54500, Punjab, Pakistan.
EM 13021050002@umt.edu.pk; yaser.khan@umt.edu.pk; Khalid.math@pu.edu.pk
RI Khan, Yaser Daanial/ABB-7928-2020
OI Khan, Yaser/0000-0002-2482-275X; Mahmood, Salman/0000-0003-2860-4095
CR [Anonymous], SPIE P C
   [Anonymous], 3 NAT C COMP VIS PAT
   [Anonymous], COMPUTERS ELECT ENG
   [Anonymous], 21 INT C PATT REC
   [Anonymous], INFRARED PHYS TECHNO
   [Anonymous], 8 INT C COMP SCI ED
   [Anonymous], 2011, IMAGE FUSION ITS APP
   [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], OPTICAL ENG
   [Anonymous], SPIE P
   [Anonymous], 2008, PHOTONIK INT
   [Anonymous], SIGN PROC 2002 6 INT
   [Anonymous], INT C SIGN IM PROC I
   [Anonymous], INT S OPT MECH TECHN
   [Anonymous], SPIE P
   [Anonymous], INFRARED PHYS TECHNO
   [Anonymous], INT J MULTIMEDIA ITS
   [Anonymous], OPT COMMUN
   [Anonymous], P IEEE CONT IN PRESS
   [Anonymous], 6 INT S COMP INT DES
   [Anonymous], 4 INT C DIG MAN AUT
   [Anonymous], 2014, SCI WORLD J
   Anwar, 2012, World Applied Sciences Journal, V16, P678
   Baird E, 2011, BIOL LETTERS, V7, P499, DOI 10.1098/rsbl.2010.1205
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Jin X, 2012, J SOFTWARE, V7, P6, DOI DOI 10.1371/J0URNAL.P0NE.0041892
   Khan YD, 2014, NEURAL COMPUT APPL, V24, P1735, DOI 10.1007/s00521-013-1410-2
   Khan YD, 2014, NEURAL COMPUT APPL, V24, P1519, DOI 10.1007/s00521-013-1372-4
   Kriesel JM, 2010, PROC SPIE, V7697, DOI 10.1117/12.849575
   Ma M, 2005, OPT ENG, V44, DOI 10.1117/1.2011088
   MORRONE MC, 1986, NATURE, V324, P250, DOI 10.1038/324250a0
   Sameh S, 2013, INT J SPEECH TECHNOL, V16, P203, DOI 10.1007/s10772-012-9174-0
   Taher GM, 2013, INT J ADV COMPUT SC, V4, P10
   Toet A, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.4.043101
   Wang R, 2011, OPT ENG, V50, DOI 10.1117/1.3579459
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yuan YH, 2011, OPT ENG, V50, DOI 10.1117/1.3549928
   Zhang Haichao., 2011, ICCV
   Zheng Y., 2011, Image fusion and its applications
   Zheng Y, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.103401
   Zheng YF, 2013, PROC SPIE, V8745, DOI 10.1117/12.2016643
NR 42
TC 6
Z9 8
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2689
EP 2737
DI 10.1007/s11042-017-4365-y
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400052
DA 2024-07-18
ER

PT J
AU Yan, XH
   Lu, YL
AF Yan, Xuehu
   Lu, Yuliang
TI Progressive visual secret sharing for general access structure with
   multiple decryptions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Progressive visual secret sharing; Random grids;
   General access structure; Multiple decryptions
ID RANDOM GRIDS; CRYPTOGRAPHY SCHEMES; IMAGE ENCRYPTION
AB Visual secret sharing (VSS) for general access structure (GAS) owns wider applications than (k,n) threshold VSS. VSS with multiple decryptions realizes the functionalities of both OR-based VSS (OVSS) and XOR-based VSS (XVSS), which can broaden the applications compared to one recovery method-based VSS. In this paper, we propose a progressive VSS (PVSS) scheme for GAS with the features of both OR and XOR decryptions based on random grid (RG). The different regions of the secret image and corresponding genearted random bits are employed to gain progressive property as well as GAS with OR and XOR decryptions. For the qualified sets, we can reconstruct the secret by stacking. On the other hand, if a device with XOR operation is available, we can improve the visual quality of the recovered secret image as well as reconstruct the secret image losslessly when we collect all the n shares. In addition, our scheme has neither pixel expansion nor codebook design due to RG. The effectiveness of the proposed scheme is shown in terms of experimental results and analyses.
C1 [Yan, Xuehu; Lu, Yuliang] Hefei Elect Engn Inst, Hefei 230037, Anhui, Peoples R China.
RP Yan, XH (corresponding author), Hefei Elect Engn Inst, Hefei 230037, Anhui, Peoples R China.
EM publictiger@126.com
RI Yan, Xuehu/AAG-1718-2022; Yan, Xuehu/AFK-3139-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61602491]
FX The authors would like to thank the anonymous reviewers for their
   valuable discussions and comments. This work is supported by the
   National Natural Science Foundation of China (Grant Number: 61602491) A
   preliminary short version of this paper appeared under the same title in
   Proceeding of 2016 8-th International Conference on IT in Medicine and
   Education (ITME 2016).
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Fu Z.-x., 2014, VISUAL CRYPTOGRAPHY, P109
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Horng SJ, 2013, IEEE T INF FOREN SEC, V8, P1860, DOI 10.1109/TIFS.2013.2277471
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Khan MK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9954-3
   Kumar S., 2013, INT J COMPUTER APPL, V83, P1
   Lee YS, 2013, IET IMAGE PROCESS, V7, P137, DOI 10.1049/iet-ipr.2012.0338
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Naor M, 1995, P ADV CRYPT EUR, P1
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2013, IEEE T CIRC SYST VID, V23, P414, DOI 10.1109/TCSVT.2012.2204940
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu X, 2012, IET INFORM SECUR, V6, P299, DOI 10.1049/iet-ifs.2012.0046
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Wu XT, 2014, SIGNAL PROCESS, V97, P64, DOI 10.1016/j.sigpro.2013.10.023
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yan X., 2014, MULTIMED TOOLS APPL, P1
   Yan X, 2013, J CHEM-NY, V2013, DOI 10.1155/2013/476236
   Yan XY, 2015, J SENSORS, V2015, DOI 10.1155/2015/908956
   Yan XH, 2015, J VIS COMMUN IMAGE R, V26, P94, DOI 10.1016/j.jvcir.2014.11.003
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 33
TC 26
Z9 26
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2653
EP 2672
DI 10.1007/s11042-017-4421-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400050
DA 2024-07-18
ER

PT J
AU Isaac, MM
   Wilscy, M
AF Isaac, Meera Mary
   Wilscy, M.
TI Multiscale Local Gabor Phase Quantization for image forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Gabor wavelets; Local phase quantization; Non-negative
   matrix factorization; Support vector machine
ID AUTHENTICATION; TRANSFORM; DCT
AB Image Forgery is a field that has attracted the attention of a significant number of researchers in the recent years. The widespread popularity of imagery applications and the advent of powerful and inexpensive cameras are among the numerous reasons that have contributed to this upward spike in the reach of image manipulation. A considerable number of features - including numerous texture features - have been proposed by various researchers for identifying image forgery. However, detecting forgery in images utilizing texture-based features have not been explored to its full potential - especially a thorough evaluation of the texture features have not been proposed. In this paper, features based on image textures are extracted and combined in a specific way to detect the presence of image forgery. First, the input image is converted to YCbCr color space to extract the chroma channels. Gabor Wavelets and Local Phase Quantization are subsequently applied to these channels to extract the texture features at different scales and orientations. These features are then optimized using Non-negative Matrix Factorization (NMF) and fed to a Support Vector Machine (SVM) classifier. This method leads to the classification of images with accuracies of 99.33%, 96.3%, 97.6%, 85%, and 96.36% for the CASIA v2.0, CASIA v1.0, CUISDE, IFS-TC and Unisa TIDE datasets respectively showcasing its ability to identify image forgeries under varying conditions. With CASIA v2.0, the detection accuracy outperforms the recent state-of-the-art methods, and with the other datasets, it gives a comparable performance with much reduced feature dimensions.
C1 [Isaac, Meera Mary; Wilscy, M.] Univ Kerala, Dept Comp Sci, Kariyavattom, Kerala, India.
C3 University of Kerala
RP Isaac, MM (corresponding author), Univ Kerala, Dept Comp Sci, Kariyavattom, Kerala, India.
EM meerathu@gmail.com; wilsyphilipose@hotmail.com
CR Al-Hammadi MH, 2013, LECT NOTES COMPUT SC, V8034, P503, DOI 10.1007/978-3-642-41939-3_49
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   [Anonymous], 2012, EURASIP J ADV SIG PR, DOI DOI 10.1186/1687-6180-2012-1
   Cattaneo G, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON NETWORK-BASED INFORMATION SYSTEMS (NBIS 2014), P279, DOI 10.1109/NBiS.2014.82
   Cattaneo G, 2014, LECT NOTES COMPUT SC, V8407, P643, DOI 10.1007/978-3-642-55032-4_66
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chi Ho Chan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P633, DOI 10.1109/ICCVW.2009.5457642
   Dong J, 2009, LECT NOTES COMPUT SC, V5450, P76, DOI 10.1007/978-3-642-04438-0_7
   Dong Jing., 2011, CASIA TAMPERED IMAGE
   El-Alfy ESM, 2015, PATTERN ANAL APPL, V18, P713, DOI 10.1007/s10044-014-0396-4
   Farid H, 2016, PHOTO TAMPERING HIST
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Fu DD, 2006, LECT NOTES COMPUT SC, V4283, P177
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Ng T.T., 2004, ADVENT Technical Report
   Ng TT, 2004, IEEE IMAGE PROC, P1169
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Saleh SQ, 2013, LECT NOTES COMPUT SC, V8034, P416, DOI 10.1007/978-3-642-41939-3_40
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Sutthiwan P, 2011, LECT NOTES COMPUT SC, V6730, P1, DOI 10.1007/978-3-642-24556-5_1
   Sutthiwan P, 2010, IEEE INT CON MULTI, P1463, DOI 10.1109/ICME.2010.5583264
   Venkatesh S. K., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P211, DOI 10.1109/NCVPRIPG.2011.52
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Wang W, 2010, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2010.5652660
   Xiubin Zhu, 2014, Journal of Networks, V9, P1617, DOI 10.4304/jnw.9.6.1617-1623
   Yan Li, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P601, DOI 10.1007/978-3-642-37444-9_47
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
   Zhou SR, 2013, NEUROCOMPUTING, V116, P260, DOI 10.1016/j.neucom.2012.05.036
NR 36
TC 3
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25851
EP 25872
DI 10.1007/s11042-017-5189-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500017
DA 2024-07-18
ER

PT J
AU Cao, MW
   Li, SJ
   Jia, W
   Li, SL
   Liu, XP
AF Cao, Mingwei
   Li, Shujie
   Jia, Wei
   Li, Shanglin
   Liu, Xiaoping
TI Robust bundle adjustment for large-scale structure from motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bundle adjustment; Structure from motion; Camera tracking;
   3D-reconstruction; Levenberg-marquardt
ID RECONSTRUCTION; OPTIMIZATION; FRAMEWORK; SFM
AB Bundle adjustment (BA) is the problem of refining a visual reconstruction to produce jointly optimal 3D structure and viewing parameter (camera pose and or calibration) estimates, and it is almost always used as the last step of feature-based 3D reconstruction algorithm. Generally, the result of Structure from Motion (SFM) mainly relies on the quality of BA. The problem of BA is often formulated as a nonlinear least squares problem, where the data arises from keypoints matching. For 3D reconstruction, mismatched keypoints may cause serious problems, even a single mismatch will affect the entire reconstruction. Therefore, to further impove the robustness of BA algorithm is very necessary. In this paper, we propose a robust Bundle Adjustment (RBA) algorithm to optimize the initial 3D point-clouds and camera parameters which are produced by the SFM system. In the proposed RBA algorithm, we firstly use the Huber loss function to potentially down-weight outliers. Secondly, we split a large-scale bundle adjustment problem into some small ones by making use of the sparsity between 3D points and the cameras for reducing the requirements of memory. Thirdly, according to the inherent property of the matrix after it spare decompose, we use a fast matrix factorization algorithm to solve the normal equation to avoid calculating the inverse of large-scale matrix. Finally, we evaluate the proposed RBA method and compare it with the state-of-the-art methods on the synthetic dataset, BAL benchmark and real image datasets, respectively. Experimental results show that the proposed RBA method clearly outperforms the state-of-the-art methods on both computational cost and precision.
C1 [Cao, Mingwei; Li, Shujie; Jia, Wei; Li, Shanglin; Liu, Xiaoping] Hefei Univ Technol, Sch Comp & Informat, NingGuo St, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Liu, XP (corresponding author), Hefei Univ Technol, Sch Comp & Informat, NingGuo St, Hefei 230009, Anhui, Peoples R China.
EM cmwqq2008@mail.hfut.edu.cn; lisjhfut@hfut.edu.cn; china.jiawei@139.com;
   lsldd@163.com; lxp@hfut.edu.cn
FU National Science Foundation of China [61370167, 61673157, 61305093,
   61402018]; Natural Science Foundation of Anhui Province [KJ2014ZD27,
   JZ2015AKZR0664]; National Key Research and Development Plan
   [2016YFC0800100]
FX This work is partly supported by the grants of the National Science
   Foundation of China, Nos. 61370167, 61673157, 61305093, and 61402018,
   the grant of the Natural Science Foundation of Anhui Province, Nos.
   KJ2014ZD27 and JZ2015AKZR0664, and also supported by the National Key
   Research and Development Plan under Grant No. 2016YFC0800100. The
   authors would like to thank anonymous reviewers for their helpful and
   constructive comments that greatly improve the paper.
CR Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3
   Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Albl C, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P555
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P 2011 IE C COMP VIS
   [Anonymous], P 2016 IE C COMP VIS
   [Anonymous], P 14 EUR C COMP VIS
   [Anonymous], 1944, Q APPL MATH, DOI DOI 10.1090/QAM/10666
   [Anonymous], P 2014 BRIT MACH VIS
   [Anonymous], ETH V3D STRUCTURE AN
   [Anonymous], J OPHTHALMOL
   [Anonymous], MACHINE VISION APPL
   [Anonymous], P 2014 BRIT MACH VIS
   [Anonymous], 2015, ARXIV151008012
   [Anonymous], P 2012 AS C COMP VIS
   [Anonymous], P 9 EUR C VIS MED PR
   [Anonymous], P 2012 IE C COMP VIS
   [Anonymous], 2016, P 21 INT C WEB3D TEC
   [Anonymous], P 2016 IE C COMP VIS
   Bao S. Y., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2025, DOI 10.1109/CVPR.2011.5995462
   Blanco JL, 2013, IEEE INT CONF ROBOT, P70, DOI 10.1109/ICRA.2013.6630558
   Boyd S., 2004, CONVEX OPTIMIZATION
   Brunier G, 2016, GEOMORPHOLOGY, V261, P76, DOI 10.1016/j.geomorph.2016.02.025
   Byröd M, 2010, LECT NOTES COMPUT SC, V6312, P114, DOI 10.1007/978-3-642-15552-9_9
   Byrod Martin, 2009, P BRIT MACH VIS C, P1
   Byröd M, 2007, LECT NOTES COMPUT SC, V4844, P549
   Cai Shen, 2013, Journal of Shanghai Jiaotong University (Science), V18, P1, DOI 10.1007/s12204-013-1361-x
   Ceylan D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2517348
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Crandall D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3001, DOI 10.1109/CVPR.2011.5995626
   de la Puente P, 2014, AUTON ROBOT, V37, P243, DOI 10.1007/s10514-014-9386-z
   Dellaert F, 2010, IEEE INT C INT ROBOT, P2566, DOI 10.1109/IROS.2010.5650422
   Dong ZL, 2009, IEEE I CONF COMP VIS, P1538
   Engels C, 2006, PHOTOGRAMMETRIC COMP, V2
   Eriksson A, 2015, IEEE WINT CONF APPL, P310, DOI 10.1109/WACV.2015.48
   Eudes Alexandre, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2411, DOI 10.1109/CVPRW.2009.5206824
   Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27
   Garrigues M, 2016, J REAL-TIME IMAGE PR, V11, P785, DOI 10.1007/s11554-014-0415-0
   Gong YZ, 2015, OPT EXPRESS, V23, P10771, DOI 10.1364/OE.23.010771
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   Heinly J, 2015, PROC CVPR IEEE, P3287, DOI 10.1109/CVPR.2015.7298949
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Heung-Yeung Shum, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P538, DOI 10.1109/CVPR.1999.784733
   Holmes Steven, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P2264, DOI 10.1109/ROBOT.2009.5152596
   HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503
   Im S, 2015, IEEE I CONF COMP VIS, P837, DOI 10.1109/ICCV.2015.102
   Indelman V, 2013, 2013 IEEE WORKSHOP ON ROBOT VISION (WORV), P221, DOI 10.1109/WORV.2013.6521942
   Jian YD, 2011, IEEE I CONF COMP VIS, P295, DOI 10.1109/ICCV.2011.6126255
   Jiang J, 2011, IEEE SYS MAN CYBERN, P2720, DOI 10.1109/ICSMC.2011.6084084
   Kang L, 2014, PATTERN RECOGN, V47, P2974, DOI 10.1016/j.patcog.2014.03.022
   Klein George, 2007, P1
   Klingner B, 2013, IEEE I CONF COMP VIS, P953, DOI 10.1109/ICCV.2013.122
   Konolige K., 2010, BMVC, V10, P102, DOI DOI 10.5244/C.24.102
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   Lee T, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P145
   Li WB, 2017, IEEE ROBOT AUTOM LET, V2, P231, DOI 10.1109/LRA.2016.2592513
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Lourakis MIA, 2005, IEEE I CONF COMP VIS, P1526
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733
   Lu GY, 2014, IEEE IJCNN, P2367, DOI 10.1109/IJCNN.2014.6889923
   Lu GY, 2016, NEUROCOMPUTING, V173, P83, DOI 10.1016/j.neucom.2015.07.106
   Lu GY, 2015, MULTIMED TOOLS APPL, V74, P479, DOI 10.1007/s11042-014-1977-3
   Lu GY, 2013, LECT NOTES COMPUT SC, V8033, P312, DOI 10.1007/978-3-642-41914-0_31
   Lu Guoyu., 2016, International Conference on Multimedia Modelling (MMM), P218
   Lv ZH, 2016, IEEE ACCESS, V4, P407, DOI 10.1109/ACCESS.2016.2517076
   Moisan L, 2012, IMAGE PROCESS ON LIN, V2, P56, DOI 10.5201/ipol.2012.mmm-oh
   Moulon P, 2013, IEEE I CONF COMP VIS, P3248, DOI 10.1109/ICCV.2013.403
   Mouragnon E., 2006, 2006 IEEE COMP SOC C, V1, P363, DOI DOI 10.1109/CVPR.2006.236
   Ni K, 2007, P 11 IEEE INT C COMP, P1
   Ni K, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P144, DOI 10.1109/3DIMPVT.2012.47
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nurutdinova I, 2015, IEEE I CONF COMP VIS, P2363, DOI 10.1109/ICCV.2015.272
   Poling B, 2014, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2014.441
   Powell M.J.D., 1970, Numerical methods for nonlinear algebraic equations, P87
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Resch B, 2015, PROC CVPR IEEE, P3936, DOI 10.1109/CVPR.2015.7299019
   Saponaro P, 2014, IEEE IMAGE PROC, P1847, DOI 10.1109/ICIP.2014.7025370
   Shah R., 2015, ARXIV151206235
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sorensen S, 2015, IEEE IMAGE PROC, P1712, DOI 10.1109/ICIP.2015.7351093
   Steedly D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P996
   Steedly D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P223, DOI 10.1109/ICCV.2001.937628
   Su TY, 2016, ADV ENG SOFTW, V95, P7, DOI 10.1016/j.advengsoft.2016.01.009
   Svärm L, 2012, INT C PATT RECOG, P2116
   Sweeney C, 2015, IEEE I CONF COMP VIS, P801, DOI 10.1109/ICCV.2015.98
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Wang TFY, 2015, COMPUT GRAPH FORUM, V34, P177, DOI 10.1111/cgf.12706
   Wilson K, 2014, LECT NOTES COMPUT SC, V8691, P61, DOI 10.1007/978-3-319-10578-9_5
   Wu C., 2011, SIFTGPU GPU IMPLEMEN
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Xi YZ, 2014, SIAM J MATRIX ANAL A, V35, P974, DOI 10.1137/130914966
   Xia YJ, 2016, NEUROCOMPUTING, V181, P1, DOI 10.1016/j.neucom.2015.10.121
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Ylimäki M, 2015, IET COMPUT VIS, V9, P576, DOI 10.1049/iet-cvi.2014.0281
   Zach C, 2014, LECT NOTES COMPUT SC, V8693, P772, DOI 10.1007/978-3-319-10602-1_50
   Zhang GC, 2015, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2015.7298743
   Zhao L, 2015, INT J ROBOT RES, V34, P493, DOI 10.1177/0278364914551583
   Zhao LM, 2015, AAAI CONF ARTIF INTE, P3864
   Zheng EL, 2015, IEEE I CONF COMP VIS, P2075, DOI 10.1109/ICCV.2015.240
   Zheng MT, 2016, IEEE GEOSCI REMOTE S, V13, P880, DOI 10.1109/LGRS.2016.2551739
NR 108
TC 19
Z9 21
U1 3
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 21843
EP 21867
DI 10.1007/s11042-017-4581-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200002
DA 2024-07-18
ER

PT J
AU Khan, M
   Shah, T
   Batool, SI
AF Khan, Majid
   Shah, Tariq
   Batool, Syeda Iram
TI A new approach for image encryption and watermarking based on
   substitution box over the classes of chain rings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Watermarking; S-boxes; Galois ring; Algebraic
   structures
ID CYCLIC CODES; BCH CODES
AB The meanings of passing information from one side to other side by a conventional way is been changed because of internet and communication technology. The issues of the security and the uprightness of information increase due to fast developments in digital world. Presently digital communication has become an important part of transmission of information securely. There are various internet applications which are utilized to convey covertly. As an outcome, the security of data against unapproved access has turned into a prime target. This leads to parts of advancement of different systems for information hiding. Cryptography and watermarking are famous techniques for hiding information accessible to conceal information safely. Our main goal here is to develop an innovative algebraic structures for the construction of nonlinear components of block cipher namely substitution boxes (S-boxes); and also use these components in image encryption and watermarking applications. Different types of S-boxes were introduced in literature based on Galois field and chaos theory in order to add confusion in any cryptosystems. The present construction is entirely based on Galois ring which enrich the existing algebraic structures of S-box theory.
C1 [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad 44000, Pakistan.
   [Shah, Tariq; Batool, Syeda Iram] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad 44000, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Abu Dahrouj FM, 2008, THESIS
   Abualrub T, 2007, DESIGN CODE CRYPTOGR, V42, P273, DOI 10.1007/s10623-006-9034-5
   Adams C., 1990, Journal of Cryptology, V3, P27, DOI 10.1007/BF00203967
   Al-Ashker M., 2005, J MATH, V29, P221
   Al-Ashker M, 2013, PALESTINE J MATH, V2, P72
   Al-Ashker MM, 2005, ARAB J SCI ENG, V30, P277
   Al-Ashker M, 2011, TURK J MATH, V35, P737, DOI 10.3906/mat-1001-71
   Anees A, 2015, WIRELESS PERS COMMUN, V82, P1497, DOI 10.1007/s11277-015-2295-4
   Bilgin B, 2012, LECT NOTES COMPUT SC, V7428, P76, DOI 10.1007/978-3-642-33027-8_5
   Bonnecaze A, 1999, IEEE T INFORM THEORY, V45, P1250, DOI 10.1109/18.761278
   Cohen S, 2009, FINITE FIELDS APPL
   Cui L., 2007, INT J INNOV COMPUT I, VI 3, P45
   DAEMEN J, BLOCK CIPHER RIJNDAE
   de Andrade AA, 1999, LINEAR ALGEBRA APPL, V286, P69, DOI 10.1016/S0024-3795(98)10163-5
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Naji A, 2002, 2 C ISL U MATH SCI G
   Qian JF, 2005, IEICE T FUND ELECTR, VE88A, P795, DOI 10.1093/ietfec/e88-a.3.795
   Qian JF, 2006, APPL MATH LETT, V19, P820, DOI 10.1016/j.aml.2005.10.011
   Qian JF, 2006, IEICE T FUND ELECTR, VE89A, P1863, DOI 10.1093/ietfec/e89-a.6.1863
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Sajjad M, 2014, MULTIMED TOOLS APPL, V72, P2063, DOI 10.1007/s11042-012-1325-4
   Selvarajah S., 2011, INT J LATEST TRENDS, V2, P108
   Shah T, 2013, Z NATURFORSCH A, V68, P567, DOI 10.5560/ZNA.2013-0021
   Shanbhag AG, 1996, IEEE T INFORM THEORY, V42, P250, DOI 10.1109/18.481796
   SHANKAR P, 1979, IEEE T INFORM THEORY, V25, P480, DOI 10.1109/TIT.1979.1056063
   Tran MT, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P253, DOI 10.1109/CIS.2008.205
   Yi X, 2002, INT C INF NETW APPL, V2, P14
NR 31
TC 30
Z9 30
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24027
EP 24062
DI 10.1007/s11042-016-4090-y
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700041
DA 2024-07-18
ER

PT J
AU Raajan, NR
   Deepika, MM
AF Raajan, Narasimhan Ranga
   Deepika, Manickavasagam Malini
TI Human-vision-based real-time stereopsis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anaglyph; Depth; Stereopsis; Monocular; Binocular
ID IMAGE; VIDEO
AB The progression in the field of stereoscopic imaging has resulted in impressive 3D videos. This technology is now used for commercial and entertainment purposes and sometimes even for medical applications. Currently, it is impossible to produce quality anaglyph video using a single camera under different moving and atmospheric conditions with the corresponding depth, local colour, and structural information. The proposed study challenges the previous researches by introducing single camera based method for anaglyph reconstruction and it mainly concentrates on human visual perception, where as the previous methods used dual camera, depth sensor, multi view, which demand not only long duration they also suffer from photometric distortion due to variation in angular alignment. This study also contributes clear individual image without any occlusion with another image. We use an approach based on human vision to determine the corresponding depth information. The source frames are shifted slightly in opposite directions as the distance between the pupils increases. We integrate the colour components of the shifted frames to generate contrasting colours for each one of the marginally shifted frames. The colour component images are then reconstructed as a cyclopean image. We show the results of our method by applying it to quickly varying video sequences and compare its performance to other existing methods.
C1 [Raajan, Narasimhan Ranga; Deepika, Manickavasagam Malini] SASTRA Univ, Sch Elect & Elect Engn, Thanjavur, Tamil Nadu, India.
   [Deepika, Manickavasagam Malini] SASTRA Univ, Dept Elect & Commun Engn, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Deepika, MM (corresponding author), SASTRA Univ, Sch Elect & Elect Engn, Thanjavur, Tamil Nadu, India.; Deepika, MM (corresponding author), SASTRA Univ, Dept Elect & Commun Engn, Thanjavur, Tamil Nadu, India.
EM nrraajan@ece.sastra.edu; malinideepika@gmail.com
RI deepika, malini/ABB-4612-2021; Renga Raajan, Narasimhan/IST-5582-2023; N
   R, Dr. RAAJAN/HDN-4829-2022
OI deepika, malini/0000-0003-1873-3395; N R, Dr. RAAJAN/0000-0002-9537-1140
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Anonymous Submission, 2016, 3D LABELING STEREO M
   Bhatti A, 2008, STEREO CORRES ESTIMA
   Chen M, 2011, STUDY DISTORTION CON, P24
   Geiger D., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P306
   Giribabu D, 2013, DEM GENERATION USING, P431
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hartley RI, THEORY PRACTICE PROJ
   Hoshino M, 2011, RES PAPERS DEV XRAY, P569
   Huang XS, 2015, LECT NOTES COMPUT SC, V9315, P14, DOI 10.1007/978-3-319-24078-7_2
   Ideses I, 2007, J REAL-TIME IMAGE PR, V2, P3, DOI 10.1007/s11554-007-0038-9
   Ideses L, 2005, J OPT A-PURE APPL OP, V7, P755, DOI 10.1088/1464-4258/7/12/008
   Kandrika S, 2013, J INDIAN SOC REMOTE, V41, P731, DOI 10.1007/s12524-012-0259-7
   Konrad J, 2000, IEEE T IMAGE PROCESS, V9, P897, DOI 10.1109/83.841535
   Ladicky L, 2010, JOINT OPTIMISATION O, P1
   Li SN, 2013, SIGNAL PROCESS-IMAGE, V28, P597, DOI 10.1016/j.image.2013.03.004
   Li X, 2007, CREATING STEREOSCOPI, P258
   Loop C, 2001, COMPUTING RECTIFYING, V1, P125
   Matsuura F, 2008, J VISUAL-JAPAN, V11, P79, DOI 10.1007/BF03181917
   Moretti S, 2015, 2 HIGGS BOSONS NEAR, P22
   Nam KW, 2012, HEALTHC INFORM RES, V18, P158, DOI 10.4258/hir.2012.18.3.158
   Perazzi F, SALIENCY FILTERS CO
   Pujari AK, 1993, SADHANA, V8, P325
   Raajan NR, 2012, STEREOSCOPIC MODELLI, P538
   Ramos-Diaz E, 2011, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2011-106
   Remote N, 2015, CARTOSAT 1
   Renga N, STEREOSCOPIC MODELLI, P538
   Saxena A, LEARNING 3 D SCENE S
   Woods AJ, 2004, GHOSTING ANAGLYPHIC, P5291
NR 29
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23481
EP 23497
DI 10.1007/s11042-016-4120-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700016
DA 2024-07-18
ER

PT J
AU Wang, CQ
   Zhang, X
   Zheng, ZM
AF Wang, Chengqi
   Zhang, Xiao
   Zheng, Zhiming
TI An improved biometrics based authentication scheme using extended
   chaotic maps for multimedia medicine information systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia medicine information system; Extended Chebyshev chaotic map;
   Biometrics; Authentication; Key agreement
ID KEY AGREEMENT PROTOCOL; PASSWORD AUTHENTICATION; FUZZY EXTRACTORS;
   PROVABLY SECURE; CRYPTANALYSIS
AB With the increase of security requirements, numerous biometrics based authentication schemes that apply the smart card technology are proposed for multimedia medicine information systems in the last several years. Recently, Lu et al. presented a biometrics based authentication and key agreement scheme using extended Chebyshev chaotic maps. Unfortunately, we find that their scheme is still insecure with respect to issues such as flaws in the both login phase and password change phase. And we show that their scheme is vulnerable to the Denial-of-Service attack, user impersonation attack and server masquerade attack, which also fails to achieve the user anonymity. In order to remedy these weaknesses, we retain the useful properties of Lu et al.'s scheme to propose a robust biometrics based authentication and key agreement scheme for multimedia medicine information systems. The informal and formal security analysis of our scheme are given respectively, which demonstrate that our scheme satisfies the desirable security requirements. Furthermore, the proposed scheme provides some significant features which are not considered in most of the related schemes, such as, biometric information protection and user re-registration or revocation. Thus, our scheme resists the known attacks and is efficient for practical applications in the multimedia medicine information systems.
C1 [Wang, Chengqi; Zhang, Xiao; Zheng, Zhiming] Beihang Univ, Key Lab Math Informat & Behav Semant, Minist Educ, New Main Bldg,Block F,Room 427,37 XueYuan Rd, Beijing 100191, Peoples R China.
   [Wang, Chengqi; Zhang, Xiao; Zheng, Zhiming] Beihang Univ, Sch Math & Syst Sci, New Main Bldg,Block F,Room 427,37 XueYuan Rd, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zhang, X (corresponding author), Beihang Univ, Key Lab Math Informat & Behav Semant, Minist Educ, New Main Bldg,Block F,Room 427,37 XueYuan Rd, Beijing 100191, Peoples R China.; Zhang, X (corresponding author), Beihang Univ, Sch Math & Syst Sci, New Main Bldg,Block F,Room 427,37 XueYuan Rd, Beijing 100191, Peoples R China.
EM ChengqiWang@buaa.edu.cn; 09621@buaa.edu.cn; zzheng@pku.edu.cn
FU Major Program of National Natural Science Foundation of China
   [11290141]; National Natural Science Foundation of China [61402030];
   Fundamental Research of Civil Aircraft [MJ-F-2012-04]
FX Authors thank the editor and reviewers a lot for their valuable
   suggestions. This research is supported by the Major Program of National
   Natural Science Foundation of China (No.: 11290141), the National
   Natural Science Foundation of China (No.: 61402030), and the Fundamental
   Research of Civil Aircraft (No.: MJ-F-2012-04).
CR [Anonymous], J MED SYST
   [Anonymous], J MED SYST
   [Anonymous], J MED SYST
   [Anonymous], IEEE SYST J
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   Arshad H, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0259-6
   Benhammadi F, 2014, IMAGE VISION COMPUT, V32, P487, DOI 10.1016/j.imavis.2014.04.014
   Bergamo P, 2005, IEEE T CIRCUITS-I, V52, P1382, DOI 10.1109/TCSI.2005.851701
   Chaudhry SA, 2016, MULTIMED TOOLS APPL, V75, P12705, DOI 10.1007/s11042-015-3194-0
   Chen TH, 2011, FUTURE GENER COMP SY, V27, P377, DOI 10.1016/j.future.2010.08.007
   Dang Q, 2013, CRYPTOLOGIA, V37, P69, DOI 10.1080/01611194.2012.687431
   Das AK, 2011, IET INFORM SECUR, V5, P145, DOI 10.1049/iet-ifs.2010.0125
   Das AK, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0027-z
   Das AK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9969-9
   Davis DL, 2016, MEANING OF HORSES: BIOSOCIAL ENCOUNTERS, P1
   Dodis Y, 2008, SIAM J COMPUT, V38, P97, DOI 10.1137/060651380
   Dodis Y, 2012, IEEE T INFORM THEORY, V58, P6207, DOI 10.1109/TIT.2012.2200290
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Giri D, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0145-7
   Guo C, 2013, COMMUN NONLINEAR SCI, V18, P1433, DOI 10.1016/j.cnsns.2012.09.032
   Hao XH, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9919-y
   He DB, 2018, IEEE SYST J, V12, P64, DOI 10.1109/JSYST.2015.2428620
   He DB, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-5469-5
   He DB, 2015, INT J AD HOC UBIQ CO, V18, P67, DOI 10.1504/IJAHUC.2015.067774
   He DB, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0116-z
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   Hu L, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0336-x
   Huang H, 2011, SECUR COMMUN NETW, V4, P1153, DOI 10.1002/sec.241
   Islam SKH, 2014, NONLINEAR DYNAM, V78, P2261, DOI 10.1007/s11071-014-1584-x
   Islam SKH, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0135-9
   Islam SKH, 2013, INT J COMPUT MATH, V90, P2244, DOI 10.1080/00207160.2013.776674
   Islam SKH, 2012, ANN TELECOMMUN, V67, P547, DOI 10.1007/s12243-012-0296-9
   Jiang Q, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0012-6
   Kim JS, 2015, MULTIMED TOOLS APPL, P1
   Kocher P, 2011, J CRYPTOGR ENG, V1, P5, DOI 10.1007/s13389-011-0006-y
   Kounga G, 2012, SECUR COMMUN NETW, V5, P87, DOI 10.1002/sec.279
   Kumari S, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9952-5
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Lee TF, 2014, COMPUT METH PROG BIO, V117, P464, DOI 10.1016/j.cmpb.2014.09.006
   Li CS, 2011, J STAT COMPUT SIM, V81, P1081, DOI 10.1080/00949651003677410
   Li CT, 2015, J INF SCI ENG, V31, P1975
   Li X, 2015, NONLINEAR DYNAM, V80, P1209, DOI 10.1007/s11071-015-1937-0
   Li X, 2011, J NETW COMPUT APPL, V34, P73, DOI 10.1016/j.jnca.2010.09.003
   Lin HY, 2015, COMMUN NONLINEAR SCI, V20, P482, DOI 10.1016/j.cnsns.2014.05.027
   Lou DC, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0240-4
   Lu YR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126323
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mishra D, 2016, PEER PEER NETW APPL, V9, P171, DOI 10.1007/s12083-014-0321-z
   Moon J, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0422-0
   Siddiqui Z, 2014, J MED SYST, V38, DOI 10.1007/s10916-013-9997-5
   Ustaoglu B, 2011, INT J INF SECUR, V10, P201, DOI 10.1007/s10207-011-0136-3
   Wei JH, 2012, J MED SYST, V36, P3597, DOI 10.1007/s10916-012-9835-1
   Wu ZY, 2012, J MED SYST, V36, P1529, DOI 10.1007/s10916-010-9614-9
   Xu J, 2011, COMPUT COMMUN, V34, P319, DOI 10.1016/j.comcom.2010.04.041
   Xu X, 2014, J MED SYST, V38, DOI 10.1007/s10916-013-9994-8
   Xue KP, 2012, COMMUN NONLINEAR SCI, V17, P2969, DOI 10.1016/j.cnsns.2011.11.025
   Yau WC, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9993-9
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
   Zhang M, 2015, SECUR COMMUN NETW, V8, P682, DOI 10.1002/sec.1016
NR 59
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24315
EP 24341
DI 10.1007/s11042-016-4198-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700053
DA 2024-07-18
ER

PT J
AU Wang, YD
   See, J
   Oh, YH
   Phan, RCW
   Rahulamathavan, Y
   Ling, HC
   Tan, SW
   Li, XJ
AF Wang, Yandan
   See, John
   Oh, Yee-Hui
   Phan, Raphael C-W
   Rahulamathavan, Yogachandran
   Ling, Huo-Chong
   Tan, Su-Wei
   Li, Xujie
TI Effective recognition of facial micro-expressions with video motion
   magnification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expressions; Motion magnification; EVM; CASME II; Local binary
   patterns
ID CLASSIFICATION
AB Facial expression recognition has been intensively studied for decades, notably by the psychology community and more recently the pattern recognition community. What is more challenging, and the subject of more recent research, is the problem of recognizing subtle emotions exhibited by so-called micro-expressions. Recognizing a micro-expression is substantially more challenging than conventional expression recognition because these micro-expressions are only temporally exhibited in a fraction of a second and involve minute spatial changes. Until now, work in this field is at a nascent stage, with only a few existing micro-expression databases and methods. In this article, we propose a new micro-expression recognition approach based on the Eulerian motion magnification technique, which could reveal the hidden information and accentuate the subtle changes in micro-expression motion. Validation of our proposal was done on the recently proposed CASME II dataset in comparison with baseline and state-of-the-art methods. We achieve a good recognition accuracy of up to 75.30 % by using leave-one-out cross validation evaluation protocol. Extensive experiments on various factors at play further demonstrate the effectiveness of our proposed approach.
C1 [Wang, Yandan; Li, Xujie] Wenzhou Univ, Sch Phys & Elect Informat Engn, Wenzhou 325035, Zhejiang, Peoples R China.
   [See, John] Multimedia Univ, Fac Comp & Informat, Jalan Multimedia, Cyberjaya 63100, Selangor, Malaysia.
   [Oh, Yee-Hui; Phan, Raphael C-W; Tan, Su-Wei] Multimedia Univ, Fac Engn, Jalan Multimedia, Cyberjaya 63100, Selangor, Malaysia.
   [Rahulamathavan, Yogachandran] City Univ London, Informat Secur Grp, London EC1V 0HB, England.
   [Ling, Huo-Chong] Curtin Univ, Dept Elect & Comp Engn, CDT 250, Miri Sarawak 98009, Malaysia.
C3 Wenzhou University; Multimedia University; Multimedia University; City
   University London; Curtin University Malaysia
RP Wang, YD (corresponding author), Wenzhou Univ, Sch Phys & Elect Informat Engn, Wenzhou 325035, Zhejiang, Peoples R China.
EM yandan.wang@wzu.edu.cn
RI Rahulamathavan, Yogachandran/AFL-1700-2022; Ling, Huo-Chong/A-7993-2011;
   Phan, Raphael C.-W./I-7266-2013; Rahulamathavan,
   Yogachandran/AAT-9468-2020; See, John/C-8633-2013
OI Rahulamathavan, Yogachandran/0000-0002-1722-8621; Ling,
   Huo-Chong/0000-0002-3173-0562; Rahulamathavan,
   Yogachandran/0000-0002-1722-8621; See, John/0000-0003-3005-4109; Phan,
   Raphael C.-W./0000-0001-7448-4595
FU Zhejiang Provincial Natural Science Foundation of China [LQ17F020002,
   LQ14F020006]; UbeAware; 2beAware; MOHE [FRGS/1/2016/ICT02/MMU/02/2]
FX This work is supported by Zhejiang Provincial Natural Science Foundation
   of China (Grant Nos. LQ17F020002 and LQ14F020006), TM Grant under
   project UbeAware and 2beAware, and MOHE Grant
   FRGS/1/2016/ICT02/MMU/02/2. The authors would like to thank the Chinese
   Academy of Sciences for the CASME II micro-expression database and
   Su-Jing Wang for providing more details of their CASME II work in [49].
CR Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], 2014, Proceedings of the Asian Conference on Computer Vision
   [Anonymous], ANN M INT COMM UNPUB
   [Anonymous], 2010, 2010 INT C INT ADV S, DOI DOI 10.1109/ICIAS.2010.5716228
   [Anonymous], 2013, 2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG), DOI [DOI 10.1109/FG.2013.6553799, DOI 10.1109/FG.2013.6553799.IEEE]
   [Anonymous], 2009, The philosophy of deception, DOI DOI 10.1093/ACPROF:OSO/9780195327939.003.0008
   Azmi R, 2012, IR C EL ENG ICEE, P742
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Fehr J, 2008, INT C PATT RECOG, P616
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Li X, 2013, SCI WORLD J, DOI 10.1155/2013/364730
   Liao S, 2007, LECT NOTES COMPUT SC, V4844, P672
   Liong ST, 2014, I S INTELL SIG PROC, P180, DOI 10.1109/ISPACS.2014.7024448
   Liong ST, 2015, LECT NOTES COMPUT SC, V9009, P644, DOI 10.1007/978-3-319-16631-5_47
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliveira LS, 2003, INT J PATTERN RECOGN, V17, P903, DOI 10.1142/S021800140300271X
   Oliveira LS, 2011, COMPUT SCI ENG, V13, P9, DOI 10.1109/MCSE.2010.149
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Park S, 2008, P 8 POSTECH KYUTECH, P653
   Park SY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P911, DOI 10.1145/2733373.2806362
   Park S, 2009, PATTERN RECOGN LETT, V30, P708, DOI 10.1016/j.patrec.2009.02.005
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Rahulamathavan Y, 2013, DEPENDABLE SECURE CO, V99, P467
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Russell TA, 2006, BRIT J CLIN PSYCHOL, V45, P579, DOI 10.1348/014466505X90866
   Samarawickrame K, 2013, INT CONF ADV ICT, P51, DOI 10.1109/ICTer.2013.6761154
   Schopler E., 1998, ASPERGER SYNDROME HI
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451
   SHREVE M., 2009, 2009 WORKSH APPL COM, P1, DOI [10.1109/WACV.2009.5403044, DOI 10.1109/WACV.2009.5403044]
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Wang YD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124674
   Wang YF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124812
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 54
TC 60
Z9 60
U1 3
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21665
EP 21690
DI 10.1007/s11042-016-4079-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400060
OA Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Hung, JCS
   Chiang, KH
   Huang, YH
   Lin, KC
AF Hung, Jason Chi-Shun
   Chiang, Kun-Hsiang
   Huang, Yi-Hung
   Lin, Kuan-Cheng
TI Augmenting teacher-student interaction in digital learning through
   affective computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Cognitive load; Facial expression; Digital
   learning; Teacher-student interaction
ID COGNITIVE LOAD
AB Interactions between teachers and students can be effectively enhanced if teachers can capture the spontaneous nonverbal behaviors (e.g., facial expressions and body language) of their students in real time, thereby effectively improving teaching strategies and the learning effectiveness of students. In this study, we implemented an expression-response analysis system (ERAS) to analyze facial expressions. The ERAS employs a web camera to capture the facial images of students. Their facial expressions are analyzed to assess their attitude toward progressively more difficult course content, and to determine the relationship between their social interactions and learning effectiveness. The ERAS identified 10 facial feature points that form 11 facial action units (AUs). Subsequently, the AUs were classified as positive, neutral, and negative social interactions by applying a rule-based expert system, and cognitive load theory was applied to verify the classifications. The experimental results showed that student with high coding abilities could adapt to the multimedia digital learning content, as evidenced by the comparatively higher expression of neutral and positive social interactions, whereas students with low coding abilities reported a higher frequency of negative social interactions resulting from the increase in cognitive load. Simultaneously, the real time detection of social interactions can provide a basis for diagnosing student learning difficulties and assist teachers in adjusting their teaching strategies.
C1 [Hung, Jason Chi-Shun] Overseas Chinese Univ, Dept Informat Technol, Taichung, Taiwan.
   [Chiang, Kun-Hsiang; Lin, Kuan-Cheng] Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung, Taiwan.
   [Huang, Yi-Hung] Natl Taichung Univ Educ, Dept Math Educ, Taichung, Taiwan.
C3 National Chung Hsing University; National Taichung University of
   Education
RP Lin, KC (corresponding author), Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung, Taiwan.
EM kclin@nchu.edu.tw
CR Bolme DS, 2007, P INT S WORKL CHAR, P114
   Bousmalis K, 2013, IMAGE VISION COMPUT, V31, P203, DOI 10.1016/j.imavis.2012.07.003
   Brünken R, 2003, EDUC PSYCHOL-US, V38, P53, DOI 10.1207/S15326985EP3801_7
   Ekman P., 1978, Facial action coding system
   Ekman Paul., 2003, EMOTIONS REVEALED
   Gerjets P, 2003, EDUC PSYCHOL-US, V38, P33, DOI 10.1207/S15326985EP3801_5
   Ghanem K, INT J TOMOGRAPHY STA, V17, P72
   Lin K-C, 3 IEEE INT C UBI MED
   Lin K-C, 2012, 2 INT C FUT COMP ED
   Loh MP, 2006, P INT C ADV LEARN TE
   Mayer R.E., 2005, The Cambridge Handbook of Multimedia Learning, DOI [DOI 10.1017/CBO9780511816819.016, 10.1017/CBO9781139547369.017, DOI 10.1017/CBO9781139547369]
   Nosu K, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3811
   Picard RW, 1995, TR321 MIT MED LAB
   Shen LP, 2009, EDUC TECHNOL SOC, V12, P176
   Shen XB, 2012, J ZHEJIANG UNIV-SC B, V13, P221, DOI 10.1631/jzus.B1100063
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27
   Whitehill J, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P97
   Yanwen Wu, 2009, Journal of Software, V4, P859, DOI 10.4304/jsw.4.8.859-866
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
NR 20
TC 11
Z9 13
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18361
EP 18386
DI 10.1007/s11042-016-4101-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800009
DA 2024-07-18
ER

PT J
AU Ji, XX
   Zhang, G
AF Ji, Xiuxia
   Zhang, Gong
TI Image fusion method of SAR and infrared image based on Curvelet
   transform with adaptive weighting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SAR image; Infrared image; Image fusion; Adaptive weighting; Curvelet
   transform
AB This paper analyses the characteristics of infrared detection imaging, with the specific application of multi-scale analysis theory for SAR and infrared image fusion. After learning and discussing the research results in image fusion area at home and abroad, it proposes an adaptive weighted image fusion method which combines the idea of fuzzy theory based on Curvelet transform, i.e., defines the membership function with fuzzy logic variables, makes different weights to transform coefficients of different levels, and designs a kind of adaptive weighted image fusion strategy. Experimental results validate the reliability and credibility of this method in term of visual quality and objective evaluation, and it can effectively improve the fusion quality.
C1 [Ji, Xiuxia; Zhang, Gong] Nanjing Univ Aeronaut & Astronaut, Minist Educ, Nanjing Univ Aeronaut Astronaut, Key Lab Radar Imaging & Microwave Photon, Nanjing 210016, Jiangsu, Peoples R China.
   [Ji, Xiuxia] Nanjing Univ Aeronaut & Astronaut, Jincheng Coll, Nanjing 211156, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Aeronautics & Astronautics
RP Ji, XX (corresponding author), Nanjing Univ Aeronaut & Astronaut, Minist Educ, Nanjing Univ Aeronaut Astronaut, Key Lab Radar Imaging & Microwave Photon, Nanjing 210016, Jiangsu, Peoples R China.; Ji, XX (corresponding author), Nanjing Univ Aeronaut & Astronaut, Jincheng Coll, Nanjing 211156, Jiangsu, Peoples R China.
EM 104066779@qq.com
FU National Science Foundation of China [61471191]; Natural Science
   Foundation of Jiangsu colleges and universities [14KJD510004,
   15KJB590001]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments and advices which contributed much to the improvement
   of this paper. The work was jointly supported by the National Science
   Foundation of China under grant No. 61471191, the Natural Science
   Foundation of Jiangsu colleges and universities under grant No.
   14KJD510004, 15KJB590001.
CR Barron DR, 2001, ELECTRON LETT, V37, P746, DOI 10.1049/el:20010536
   Bhatnagar G, 2013, EXPERT SYST APPL, V40, P1708, DOI 10.1016/j.eswa.2012.09.011
   Chanussor J, 1993, IEEE T GEOSCI REMOTE, V7, P1292
   Jia Y.-H., 1998, REMOTE SENS TECHNOL, V13, P46
   Jin B, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.080599
   Kong WW, 2015, INFRARED PHYS TECHN, V71, P87, DOI 10.1016/j.infrared.2015.02.008
   Liu Gang, 2006, Journal of Zhejiang University (Science), V7, P117, DOI 10.1631/jzus.2006.A0117
   Mehra I, 2014, OPT EXPRESS, V22, P5474, DOI 10.1364/OE.22.005474
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Ramac LC, 1998, P SOC PHOTO-OPT INS, V3376, P110, DOI 10.1117/12.303671
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Toet A, 1996, OPT ENG, V35, P650, DOI 10.1117/1.600657
   Wang J, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043019
   Yu ML, 2015, MULTIMED TOOLS APPL, V74, P2745, DOI 10.1007/s11042-013-1660-0
   Yu Z, 2015, CYBERN INF TECHNOL, V15, P116, DOI 10.1515/cait-2015-0010
   ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4
   [郑伟 Zheng Wei], 2015, [光电工程, Opto-Electronic Engineering], V42, P77
NR 17
TC 26
Z9 30
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17633
EP 17649
DI 10.1007/s11042-015-2879-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800002
DA 2024-07-18
ER

PT J
AU Yang, HK
   Kim, JM
   Jeong, HY
AF Yang, Ho-Kyung
   Kim, Jin-Mook
   Jeong, Hwa-Young
TI Design of mVoIP service based authentication system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE mVoIP; AA server; WiFi; QoS; Authentication
AB SIP of mVoIP services transmit media data such as video and voice, allowing for the provision of additional services, and the amount of usage on a wireless Internet such as WiFi is gradually increasing. While an increase in the user base is expected for mVoIP, a packet network is an open network which means anyone can easily gain access and so there can be various problems. In this paper, an authentication system was designed by adding the AA Server to the existing VoIP session configuration stage to provide differentiated services according to user access, and to add security.
C1 [Yang, Ho-Kyung; Kim, Jin-Mook] Sunmoon Univ, Div IT Educ, 221 Sunmoon Ro, Asan 336708, Chungnam, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 24 Kyungheedae Ro, Seoul 130701, South Korea.
C3 Sun Moon University; Kyung Hee University
RP Kim, JM (corresponding author), Sunmoon Univ, Div IT Educ, 221 Sunmoon Ro, Asan 336708, Chungnam, South Korea.
EM calf0425@sunmoon.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], 1998, 2402 RFC IETF
   [Anonymous], 2001, 3029 RFC IETF
   [Anonymous], 3261 RFC
   Cho S-W, SCH COMPUTER ENG
   Kwon S-H, 2011, WIRE WIRELESS VOIP H
   *RFC, 1999, 2617 RFC IETF
   Stallings W., 2003, CRYPTOGRAPHY NETWORK
   Yang H-K, 2006, DESIGN USER ACCESS A, P7
NR 8
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17985
EP 18000
DI 10.1007/s11042-016-3645-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800023
DA 2024-07-18
ER

PT J
AU Melo, M
   Barbosa, L
   Bessa, M
   Debattista, K
   Chalmers, A
AF Melo, Miguel
   Barbosa, Luis
   Bessa, Maximino
   Debattista, Kurt
   Chalmers, Alan
TI Context-aware HDR video distribution for mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range video; Mobile devices; Video delivery; Tone-mapping;
   Video streaming; Context-aware
AB HDR video on mobile devices is in its infancy and there are no solutions yet that can achieve full HDR video reproduction due to computational power limitations. In this paper we present a novel and versatile solution that allows the delivery of HDR video on mobile devices by taking into account contextual information and retro-compatibility for devices that do not have the computational power to decode HDR video. The proposed solution also enables the remote transmission of HDR video to mobile devices in real-time. This context-aware HDR video distribution solution for mobile devices is evaluated and discussed by considering the impact of HDR videos over conventional low dynamic range videos on mobile devices as well as the challenge of playing HDR videos directly locally or remotely.
C1 [Melo, Miguel; Barbosa, Luis; Bessa, Maximino] INESC TEC, Campus FEUP,Rua Dr Roberto Frias, P-4200465 Oporto, Portugal.
   [Melo, Miguel; Barbosa, Luis; Bessa, Maximino] Univ Tras Os Montes & Alto Douro, P-5000801 Quinta De Prados, Vila Real, Portugal.
   [Debattista, Kurt; Chalmers, Alan] Univ Warwick, Int Mfg Ctr, WMG, Coventry CV4 7AL, W Midlands, England.
C3 INESC TEC; University of Tras-os-Montes & Alto Douro; University of
   Warwick
RP Melo, M (corresponding author), INESC TEC, Campus FEUP,Rua Dr Roberto Frias, P-4200465 Oporto, Portugal.; Melo, M (corresponding author), Univ Tras Os Montes & Alto Douro, P-5000801 Quinta De Prados, Vila Real, Portugal.
EM emekapa@sapo.pt
RI Barbosa, Luis/S-3953-2019; Bessa, Maximino/B-4729-2012; Melo,
   Miguel/AAN-1855-2020
OI Barbosa, Luis/0000-0002-6478-6669; Bessa, Maximino/0000-0002-3002-704X;
   Melo, Miguel/0000-0003-4050-3473
FU TEC4Growth - Pervasive Intelligence, Enhancers and Proofs of Concept
   with Industrial Impact - North Portugal Regional Operational Programme
   (NORTE) under PORTUGAL [NORTE-01-0145-FEDER-000020]; European Regional
   Development Fund (ERDF); MASSIVE - Multimodal Acknowledgeable
   multiSenSorial Immersive Virtual Environments - European Union (COMPETE)
   [REC II/EEI-SII/0360/2012]; MASSIVE - Multimodal Acknowledgeable
   multiSenSorial Immersive Virtual Environments - European Union (QREN);
   MASSIVE - Multimodal Acknowledgeable multiSenSorial Immersive Virtual
   Environments - European Union (FEDER); Royal Society
FX This work is supported by the project "TEC4Growth - Pervasive
   Intelligence, Enhancers and Proofs of Concept with Industrial
   Impact/NORTE-01-0145-FEDER-000020" is financed by the North Portugal
   Regional Operational Programme (NORTE 2020), under the PORTUGAL 2020
   Partnership Agreement, and through the European Regional Development
   Fund (ERDF). This work is also supported by the project REC
   II/EEI-SII/0360/2012 entitled "MASSIVE - Multimodal Acknowledgeable
   multiSenSorial Immersive Virtual Environments" financed by the European
   Union (COMPETE, QREN and FEDER). Chalmers and Debattista are supported
   by Royal Society Industrial Fellowships.
CR AndroidPit, 2014, ANDR 5 0 LOLL BEST F
   [Anonymous], GLOB VID IND Q3 2014
   [Anonymous], P SPIE
   Banterle F, 2011, [Video data compression, US Patent App], Patent No. [12/984.992, 12984992]
   Castro TK, 2011, EUROGRAPHICS 2011 AR, DOI [10.2312/EG2011/areas/075-076, DOI 10.2312/EG2011/AREAS/075-076]
   Design B, 2012, ULTRASTUDIO MINIRECO
   Eilertsen G, 2013, COMPUT GRAPH FORUM, V32, P275, DOI 10.1111/cgf.12235
   Entner, 2011, INT COMP HANDS REPL
   goHDR, 2014, ENC
   IMDB, 2013, IMDB INT
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Meira C, 2013, HDRI2013
   Melo M, 2015, COMPUTER GRAPHICS FO
   Melo M, 2014, SIGNAL PROCESS-IMAGE, V29, P247, DOI 10.1016/j.image.2013.09.010
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   Wanat R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601150
NR 16
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16605
EP 16623
DI 10.1007/s11042-016-3940-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100024
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Rabie, T
AF Rabie, Tamer
TI Color-secure digital image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color-preserving; Color-secure; Image compression; Lab color space; RGB
   color space; DCT frequency domain
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; MANY-CORE PROCESSORS;
   BLOCKING ARTIFACTS; JPEG; QUANTIZATION; PHASE; VIDEO
AB The wide spread acquisition and use of ultra-high resolution color images obtained from high-resolution imaging sensors introduces open problems of optimal storage and transmission while securing important color information as well as preserving fine details in these high quality images. This paper describes a steganography-based paradigm for high-quality compression of fine-detailed color megapixel images highly applicable to forensic imaging applications. Our scheme combines space-domain and frequency-domain image processing operations where in the space domain, color-brightness separation is exploited, and in the frequency domain, discrete cosine transform energy compaction properties of the transformed luminance image is exploited. Experimental results as well as empirical observations show that our technique is very competitive with the highest quality JPEG image compression standard in the overall fidelity of the decompressed image while achieving high compression ratios. However, the main purpose of this new compression scheme is not to compete with the JPEG standard in terms of visual quality measures, but to provide a means for securing vital color information in the original image from potential tampering while allowing high compression ratios without loss of important fine details.
C1 [Rabie, Tamer] Univ Sharjah, Dept Elect & Comp Engn, Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah
RP Rabie, T (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Comp Engn, Sharjah, U Arab Emirates.
EM trabie@sharjah.ac.ae
FU College of Graduate Studies and Research at the University of Sharjah
FX The authors would like to thank the anonymous reviewers for their
   valuable suggestions that helped improve the original manuscript. This
   work was supported by the College of Graduate Studies and Research at
   the University of Sharjah.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2003, INT J DIG EVID
   [Anonymous], 2013, Colour Appearance Models
   Ayyalasomayajula P, 2012, IEEE IMAGE PROC, P2441, DOI 10.1109/ICIP.2012.6467391
   Bracamonte J, 2005, LECT NOTES COMPUT SC, V3568, P154
   Bracamonte J., 2004, P 6 COST, V276, P88
   Campisi P, 2002, EURASIP J APPL SIG P, V2002, P152, DOI 10.1155/S1110865702000550
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Cernik RJ, 2008, J R SOC INTERFACE, V5, P477, DOI 10.1098/rsif.2007.1249
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chang CC, 2008, SOFT COMPUT, V13, P21
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chaumont M, 2006, EUSIPCO 06 EUR SIGN, P5
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Forssen PE, 2002, LITHISYR2418
   HARDING G, 1990, PHYS MED BIOL, V35, P33, DOI 10.1088/0031-9155/35/1/004
   Ito I, 2007, INT CONF ACOUST SPEE, P1237
   Kang SU, 2013, SIGN INF PROC ASS AN, P1
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   Nallaperumal K, 2006, IFIP INT C WIR OPT C, P4
   Nosratinia A, 2001, J VLSI SIG PROCESS S, V27, P69, DOI 10.1023/A:1008167430544
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qazanfari K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043009
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Rabie T, 2004, J ELECTRON IMAGING, V13, P264, DOI 10.1117/1.1668279
   Rabie T., 2007, International Journal of Advanced Media and Communication, V1, P298, DOI 10.1504/IJAMC.2007.013952
   Rabie T, 2006, IEEE INT C INN INF T, P1
   Rabie T, 2015, MULTIMED TOOLS APPL, V75, DOI [10.1007/s11,042-015-2557-x, DOI 10.1007/S11,042-015-2557-X]
   Rabie T, 2016, MULTIMED TOOLS APPL, V76, DOI [10.1007/s11,042-016-3301-x, DOI 10.1007/S11,042-016-3301-X]
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2015, INT J ADV COMPUT SC, V6, P114
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Singh S, 2007, DIGIT SIGNAL PROCESS, V17, P225, DOI 10.1016/j.dsp.2005.08.003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   WATSON AB, 1990, J OPT SOC AM A, V7, P1943, DOI 10.1364/JOSAA.7.001943
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Xiong ZX, 1997, IEEE T CIRC SYST VID, V7, P433, DOI 10.1109/76.564123
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhang XP, 2015, IET IMAGE PROCESS, V9, P54, DOI 10.1049/iet-ipr.2014.0321
   Zhao Y, 2004, IEEE T IMAGE PROCESS, V13, P428, DOI 10.1109/TIP.2003.821552
NR 45
TC 7
Z9 7
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16657
EP 16679
DI 10.1007/s11042-016-3942-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100026
DA 2024-07-18
ER

PT J
AU Sogaard, J
   Shahid, M
   Pokhrel, J
   Brunnström, K
AF Sogaard, Jacob
   Shahid, Muhammad
   Pokhrel, Jeevan
   Brunnstrom, Kjell
TI On subjective quality assessment of adaptive video streaming via
   crowdsourcing and laboratory based experiments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive video streaming; Crowdsourcing; Subjective quality assessment;
   Quality of experience
ID PARAMETERS
AB Video streaming services are offered over the Internet and since the service providers do not have full control over the network conditions all the way to the end user, streaming technologies have been developed to maintain the quality of service in these varying network conditions i.e. so called adaptive video streaming. In order to cater for users' Quality of Experience (QoE) requirements, HTTP based adaptive streaming solutions of video services have become popular. However, the keys to ensure the users a good QoE with this technology is still not completely understood. User QoE feedback is therefore instrumental in improving this understanding. Controlled laboratory based perceptual quality experiments that involve a panel of human viewers are considered to be the most valid method of the assessment of QoE. Besides laboratory based subjective experiments, crowdsourcing based subjective assessment of video quality is gaining popularity as an alternative method. This article presents insights into a study that investigates perceptual preferences of various adaptive video streaming scenarios through crowdsourcing based and laboratory based subjective assessment. The major novel contribution of this study is the application of Paired Comparison based subjective assessment in a crowdsourcing environment. The obtained results provide some novel indications, besides confirming the earlier published trends, of perceptual preferences for adaptive scenarios of video streaming. Our study suggests that in a network environment with fluctuations in the bandwidth, a medium or low video bitrate which can be kept constant is the best approach. Moreover, if there are only a few drops in bandwidth, one can choose a medium or high bitrate with a single or few buffering events.
C1 [Sogaard, Jacob] Tech Univ Denmark, Lyngby, Denmark.
   [Shahid, Muhammad] Blekinge Inst Technol, Karlskrona, Sweden.
   [Shahid, Muhammad] Prince Sultan Univ, Dept Commun & Networks Engn, Riyadh, Saudi Arabia.
   [Pokhrel, Jeevan] Montimage, Paris, France.
   [Brunnstrom, Kjell] Acreo Swedish ICT AB, Kista, Sweden.
   [Brunnstrom, Kjell] Mid Sweden Univ, Sundsvall, Sweden.
C3 Technical University of Denmark; Blekinge Institute Technology; Prince
   Sultan University; Acreo AB; Mid-Sweden University
RP Sogaard, J (corresponding author), Tech Univ Denmark, Lyngby, Denmark.
EM chubbi1968@gmail.com; muhammad.shahid@ieee.org; jeevanpokhrel@gmail.com;
   kjell.brunnstrom@acreo.se
RI Shahid, Muhammad/L-9331-2014; Brunnström, Kjell/T-9793-2019
OI Brunnström, Kjell/0000-0001-5060-9402
CR [Anonymous], 2014, PROC ACM WORKSHOP QU
   [Anonymous], 2013, VISUAL COMMUNICATION
   [Anonymous], 2015, SCIENCE, DOI [DOI 10.1126/SCIENCE.AAC4716, DOI 10.1126/science.aac4716]
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   Brunnstrom K, 2014, VQEGPlayer: open source software for subjective video quality experiments in windows
   Chen KT, 2010, IEEE NETWORK, V24, P28, DOI 10.1109/MNET.2010.5430141
   Coolican H., 2014, Research methods and statistics in psychology
   Cranley N, 2006, DIGITAL MULTIMEDIA P, P244
   Garcia M.-N, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P141, DOI 10.1109/QoMEX.2014.6982310
   Gardlo B, 2014, IEEE ICC, P1070, DOI 10.1109/ICC.2014.6883463
   Grafl M., 2013, Proceedings of the 4th International Workshop on Perceptual Quality of Systems (PQS 2013), P178
   Hossfeld Tobias, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P111, DOI 10.1109/QoMEX.2014.6982305
   Hossfeld T, 2012, INT WORK QUAL MULTIM, P1, DOI 10.1109/QoMEX.2012.6263849
   Hossfeld T, 2014, T-LAB SER TELECOMMUN, P315, DOI 10.1007/978-3-319-02681-7_21
   Hossfeld T, 2014, IEEE T MULTIMEDIA, V16, P541, DOI 10.1109/TMM.2013.2291663
   Keimel C, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P245, DOI 10.1109/PCS.2012.6213338
   Lee J.-S., 2010, Proceedings of ACM international conference on Multimedia, MULTIMEDIA '10, P65, DOI DOI 10.1145/1873951.1873981
   Lee JS, 2011, IEEE T MULTIMEDIA, V13, P882, DOI 10.1109/TMM.2011.2157333
   Lewcio B., 2011, P IEEE INT WORKSH TE, P1
   Li J, 2013, IEEE 11 IVMSP WORKSH
   Li J, 2012, IEEE IMAGE PROC, P629, DOI 10.1109/ICIP.2012.6466938
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Rainer B, 2013, INT WORK QUAL MULTIM, P24, DOI 10.1109/QoMEX.2013.6603196
   Robinson DC, 2012, BELL LABS TECH J, V16, P5, DOI 10.1002/bltj.20531
   Rodríguez DZ, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-216
   Rosskopf A., 2014, IEEE Int. Elec. Drives Prod. Conf. (EDPC), P1, DOI [10.1007/s13398-014-01737.2, DOI 10.1016/J.NEUROPSYCHOLOGIA.2015.01.019]
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Shahid M., 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P53, DOI 10.1109/QoMEX.2014.6982289
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Sogaard J, 2014, INTERFACE TEMPLATE S
   Staelens N, 2014, IEEE T BROADCAST, V60, P707, DOI 10.1109/TBC.2014.2359255
   Tavakoli Samira, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P63, DOI 10.1109/QoMEX.2014.6982294
   Tavakoli S, 2015, P HUM VIS EL IM 20, V9394
   Tavakoli S, 2014, P IM QUAL SYST PERF, V9016
   Tavakoli S, 2015, SIGNAL PROCESS-IMAGE, V39, P432, DOI 10.1016/j.image.2015.05.001
   Thang TC, 2012, 2012 FOURTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P322, DOI 10.1109/CCE.2012.6315921
   Van Kester S, 2011, P SPIE IS T HUM VIS, V7865
   Wickelmaier F, 2004, BEHAV RES METH INS C, V36, P29, DOI 10.3758/BF03195547
   Yao J, 2011, LECT NOTES COMPUT SC, V6640, P92, DOI 10.1007/978-3-642-20757-0_8
   Yen Y-C, 2013, P 9 AS INT ENG C, P65
NR 40
TC 5
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16727
EP 16748
DI 10.1007/s11042-016-3948-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100030
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Liu, J
   Mei, JH
   Zhang, XR
   Lu, X
   Huang, J
AF Liu, Jia
   Mei, Jianhui
   Zhang, Xiaorui
   Lu, Xiong
   Huang, Jing
TI Augmented reality-based training system for hand rehabilitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Hand rehabilitation; Stroke; Marker
AB This study designs a training system for hand rehabilitation on the basis of augmented reality technology, which enables patients to simultaneously interact with real and virtual environments. The system framework is introduced, and four rehabilitation programs, namely, trajectory training, shelf training, batting training, and spile training, are presented. As a requirement of hand rehabilitation training, a color marker that is suitable for hand rehabilitation training is adopted. Following the Hamming coding principle, this marker is designed as a 7 x 7 square that is filled up by four designated colors with a binary bit of ''0" or "1". The check code in each row of the color marker is applied to restore the occluded binary bits, solve the occlusion issue of color markers, and complete the tracking registration of the color markers. The effectiveness of the developed system is evaluated via a usability study and questionnaires. The evaluation provides positive results. Therefore, the developed system has potential as an effective rehabilitation system for upper limb impairment.
C1 [Liu, Jia; Mei, Jianhui; Zhang, Xiaorui; Huang, Jing] Nanjing Univ Informat Sci & Technol, B DAT, Nanjing 210044, Jiangsu, Peoples R China.
   [Liu, Jia; Mei, Jianhui; Zhang, Xiaorui; Huang, Jing] Nanjing Univ Informat Sci & Technol, Sch Informat & Control, CICAEET, Nanjing 210044, Jiangsu, Peoples R China.
   [Lu, Xiong] Nanjing Univ Aeronaut & Astronaut, Sch Automat Engn, Nanjing 210016, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Aeronautics & Astronautics
RP Liu, J (corresponding author), Nanjing Univ Informat Sci & Technol, B DAT, Nanjing 210044, Jiangsu, Peoples R China.; Liu, J (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Informat & Control, CICAEET, Nanjing 210044, Jiangsu, Peoples R China.
EM liujia0926_nuist@163.com
RI jiang, lei/IWE-1124-2023; Liu, Jiacheng/GNW-5828-2022
FU National Natural Science Foundation of China [61203316, 61203319,
   61502240]; Natural Science Foundation of Jiangsu Province [BK20141002];
   Jiangsu Government Scholarship for Overseas Studies; Jiangsu Students'
   Project for Innovation and Entrepreneurship Training Program
   [201510300090]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61203316, 61203319, 61502240), the Natural Science Foundation
   of Jiangsu Province (BK20141002), Jiangsu Government Scholarship for
   Overseas Studies, and the Jiangsu Students' Project for Innovation and
   Entrepreneurship Training Program (No. 201510300090).
CR Alamri A., 2010, INT C AUTONOMOUS INT, P1
   Alamri A, 2010, IEEE T INSTRUM MEAS, V59, P2554, DOI 10.1109/TIM.2010.2057750
   Aung YM, 2014, IEEE ENG MED BIO, P3614, DOI 10.1109/EMBC.2014.6944405
   Aung YM, 2012, P IEEE RAS-EMBS INT, P213, DOI 10.1109/BioRob.2012.6290680
   Burke J. W., 2010, 2010 2nd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2010), P75, DOI 10.1109/VS-GAMES.2010.21
   Carbonaro N, 2014, IEEE J BIOMED HEALTH, V18, P1788, DOI 10.1109/JBHI.2014.2324293
   Choi YS, 2011, P AM MATH SOC, V139, P3257, DOI 10.1090/S0002-9939-2011-10801-3
   Collins J, 2014, P 10 INT C DIS VIRT, P181
   Cramer SC, 2011, BRAIN, V134, P1591, DOI 10.1093/brain/awr039
   Hoermann S., 2012, P INT C DIS VIRT REA, P1
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Langhorne P, 2009, LANCET NEUROL, V8, P741, DOI 10.1016/S1474-4422(09)70150-4
   Luo X, 2005, INT C REHAB ROBOT, P329
   Luo X, 2005, P ANN INT IEEE EMBS, P6855
   MATHIOWETZ V, 1985, OCCUP THER J RES, V5, P24, DOI 10.1177/153944928500500102
   Mousavi Hondori Hossein, 2013, Stud Health Technol Inform, V184, P279
   Ong SK, 2011, HANDBOOK OF AUGMENTED REALITY, P603, DOI 10.1007/978-1-4614-0064-6_28
   PONS TP, 1991, SCIENCE, V252, P1857, DOI 10.1126/science.1843843
   Regenbrecht H., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P219, DOI 10.1109/ISMAR.2011.6092389
   Regenbrecht H, 2014, P IEEE, V102, P170, DOI 10.1109/JPROC.2013.2294178
   Shen Y., 2009, International convention for rehabilitation engineering and assistive technology, P1
   Sucar LE, 2008, HEALTHINF 2008: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON HEALTH INFORMATICS, VOL 2, P107
   Takeuchi N, 2013, STROKE RES TREAT, V2013, DOI 10.1155/2013/128641
   Yee Mon Aung, 2011, Proceedings of the 2011 11th International Conference on Hybrid Intelligent Systems (HIS 2011), P641, DOI 10.1109/HIS.2011.6122181
   Zhang D, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P346, DOI 10.1109/CW.2010.31
   Zhou JM, 2012, CLIN UTILITY HAND FU, P8
NR 26
TC 13
Z9 16
U1 0
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14847
EP 14867
DI 10.1007/s11042-016-4067-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400017
DA 2024-07-18
ER

PT J
AU Qian, WH
   Xu, D
   Yue, K
   Guan, Z
   Pu, YY
   Shi, YJ
AF Qian, Wenhua
   Xu, Dan
   Yue, Kun
   Guan, Zheng
   Pu, Yuanyuan
   Shi, Yongjie
TI Gourd pyrography art simulating based on non-photorealistic rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-photorealistic rendering; Gourd pyrography; Style simulation; Image
   deformation
ID IMAGE; DEFORMATION
AB Non-photorealistic rendering (NPR) is a field in computer science which can create effective illustrations and appealing artistic imagery. Some researchers have proposed NPR methods to simulate different artistic illustrations. However, simulating the new art styles remains extremely challenging. National pyrography is a very famous artistic work in China, and few algorithms have been put forward to illustrate this style. Some exist rendering methods can not demonstrate the main characters of the real pyrography, and the rendering speed is time-consuming using texture synthesis technique. This paper proposes a non-photorealistic rendering technique that automatically generates a gourd pyrography style from a 2D photograph. Similar to the existing exemplar-based methods, an input natural image is regarded as the foreground image, and an input gourd image is taken as the background image. To avoid time-consuming methods like texture synthesis or analogy, this paper simulates character of real pyrography through image abstraction and enhancement from the foreground image. The foreground image will be deformed using equilateral triangle mesh to match the gourd image and mapped to this background image. Experimental results demonstrate the effectiveness of our methods in producing gourd pyrography stylistic illustrations. Meanwhile, the proposed method is simple, fast, and easy to implement.
C1 [Qian, Wenhua; Xu, Dan; Yue, Kun; Guan, Zheng; Pu, Yuanyuan; Shi, Yongjie] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Peoples R China.
C3 Yunnan University
RP Qian, WH (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Peoples R China.
EM qwhua003@sina.com; danxu@sina.com; kyue@ynu.edu.cn; gz_627@sina.com;
   16149912@qq.com; 78330383@qq.com
RI Xu, Dan/KPA-7396-2024
OI Xu, Dan/0000-0003-4602-3550
FU Research Natural Science Foundation of China [61462093, 61163019,
   61271361]; Research Foundation of Yunnan Province [2014FA021,
   2014FB113]; Research Foundation of New Teacher Fund for Doctor Station;
   Ministry of Education [20125301120008]; Research Foundation of the
   Educational Department of Yunnan Province [2015Z012, 2015Y225]
FX This research was funded by the grants (No. 61462093, 61163019,
   61271361) from the Research Natural Science Foundation of China, the
   Research Foundation of Yunnan Province (No. 2014FA021, 2014FB113), the
   Research Foundation of New Teacher Fund for Doctor Station, the Ministry
   of Education (No. 20125301120008), the Research Foundation of the
   Educational Department of Yunnan Province (No. 2015Z012, 2015Y225).
CR Anjyo K, 2003, IEEE COMPUT GRAPH, V23, P54, DOI 10.1109/MCG.2003.1210865
   Capell S, 2002, ACM T GRAPHIC, V21, P586, DOI 10.1145/566570.566622
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   Durand F., 2014, ACM T GRAPHIC, V33, P1935
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fu SJ, 2008, CHINESE J ELECTRON, V17, P56
   Gao H, 2006, COMPUT ENG APPL, V47, P177
   Gooch A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P447, DOI 10.1145/280814.280950
   Grabli S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731056
   Han X.W., 2011, J YANGTZE U, V34, P9
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kang H, 2008, COMPUT GRAPH FORUM, V27, P1773, DOI 10.1111/j.1467-8659.2008.01322.x
   Kim Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409109
   Kuwahara M., 1976, Digital Processing of Biomedical Images, P187, DOI [DOI 10.1007/978-1-4684-0769-3_13, 10.1007/978-1-4684-0769-313, DOI 10.1007/978-1-4684-0769-313, 10.1007/978-1-4684-0769-3_13]
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Larussi E, 2015, ACM T GRAPHIC, V34, P1
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lu Cewu., 2012, Proc. NPAR, P65
   MacCracken R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P181, DOI 10.1145/237170.237247
   Orzan A, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P103
   Papari G, 2007, IEEE T IMAGE PROCESS, V16, P2449, DOI 10.1109/TIP.2007.903912
   Perona P, 1991, T PATTERN ANAL MACHI, P629
   Sederberg T, 2010, ACM SIGGRAPH COMPUT, V20, P151
   Seiller N, 2010, MULTIMED TOOLS APPL, V70, P2347
   Son MJ, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P333, DOI 10.1109/PG.2007.63
   Song YB, 2014, LECT NOTES COMPUT SC, V8694, P800, DOI 10.1007/978-3-319-10599-4_51
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Dong, 2010, Journal of System Simulation, V22, P2929
   Wang Dong, 2010, Journal of Computer Applications, V30, P2473, DOI 10.3724/SP.J.1087.2010.02473
   [王雪松 Wang Xuesong], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P937
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Yan HB, 2006, LECT NOTES COMPUT SC, V4035, P66
   [杨莹 YANG Ying], 2011, [计算机工程与设计, Computer Engineering and Design], V32, P732
   Yin LW, 2001, INT J IMAGE GRAPHICS, V1, P565, DOI DOI 10.1142/S0219467801000396
   Yong Jie Shi, 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P432, DOI 10.1109/ICDH.2012.16
   [喻扬涛 Yu Yangtao], 2015, [图学学报, Journal of Graphics], V36, P159
   Zhang Zhenting, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P1010, DOI 10.3724/SP.J.1089.2010.10859
NR 41
TC 9
Z9 9
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14559
EP 14579
DI 10.1007/s11042-016-3801-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400002
DA 2024-07-18
ER

PT J
AU Yang, B
   Xiang, XQ
   Xu, DQ
   Wang, XH
   Yang, X
AF Yang, Bing
   Xiang, Xueqin
   Xu, Duanqing
   Wang, Xiaohua
   Yang, Xin
TI 3D palmprint recognition using shape index representation and fragile
   bits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bioinformatics; 3D palmprint recognition; Shape index; Gabor wavelet
   features; Fragile bits information
ID LINE; 2D
AB Recent years have witnessed a growing interesting in developing automatic palmprint recognition methods. Most of the previous works have concentrated on two dimensional (2D) palmprint recognition in the past decade. However, the shape information is lost in 2D plamprint images. What's more, 2D plamprint recognition is not robust enough in practice since its data could be easily counterfeited or contaminated by noise. Consequently, three dimensional (3D) palmprint recognition is treated as an important alternative road to both enhance the performance and robustness of current available palmprint recognition systems. In this paper, we first explore geometrical information of 3D palmprint data by employing shape index formulation, from which Gabor wavelet features are then extracted. Furthermore, we first discover that by incorporating fragile bits information, the performance of coding strategy related 3D recognition method can be further improved. Experiments conducted on the public available 3D plamprint database validate that our method can obtain the highest recognition performance among the state-of-the-art methods estimated.
C1 [Yang, Bing; Xiang, Xueqin; Wang, Xiaohua] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
   [Xu, Duanqing] Zhejiang Univ, Coll Comp Sci, Yuquan Rd, Hangzhou 310007, Zhejiang, Peoples R China.
   [Wang, Xiaohua] China Jiliang Univ, Xueyuan St, Hangzhou 310018, Peoples R China.
   [Yang, Xin] Dalian Univ Technol, Comp Sci & Technol Coll, Linggong Rd, Dalian 116024, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University; China Jiliang
   University; Dalian University of Technology
RP Yang, B (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
EM yb@hdu.edu.cn
OI , Xin/0000-0002-8046-722X; yang, bing/0000-0002-0585-0579; xiang,
   xueqin/0009-0004-4767-8078
FU National Natural Science Foundation of China [61402143, 61300084];
   Natural Science Foundation of Zhejiang Province [Q14F020040]; School
   Scientific Research Fund [KYS055613014]
FX This work was supported by the National Natural Science Foundation of
   China, under Grant Nos. 61402143 and 61300084, by the Natural Science
   Foundation of Zhejiang Province, under Grant No Q14F020040 and by the
   School Scientific Research Fund, under Grant No. KYS055613014.
CR Benedikt L, 2010, IEEE T SYST MAN CY A, V40, P449, DOI 10.1109/TSMCA.2010.2041656
   Brown BJ, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276404, 10.1145/1239451.1239472]
   Cui JR, 2015, MULTIMED TOOLS APPL, V74, P10989, DOI 10.1007/s11042-014-1887-4
   Fischer S, 2007, INT J COMPUT VISION, V75, P231, DOI 10.1007/s11263-006-0026-8
   Hetzel G, 2001, PROC CVPR IEEE, P394
   Hollingsworth KP, 2011, IEEE T PATTERN ANAL, V33, P2465, DOI 10.1109/TPAMI.2011.89
   Hollingsworth KP, 2009, IEEE T PATTERN ANAL, V31, P964, DOI 10.1109/TPAMI.2008.185
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kuhnel W, 2006, AM MATH SOC, P198
   Li W, 2012, IEEE T SYST MAN CY A, V42, P443, DOI 10.1109/TSMCA.2011.2164066
   Li W, 2011, IEEE T SYST MAN CY C, V41, P274, DOI 10.1109/TSMCC.2010.2055849
   Li W, 2010, PROC CVPR IEEE, P795, DOI 10.1109/CVPR.2010.5540134
   Michael GKO, 2008, IMAGE VISION COMPUT, V26, P1551, DOI 10.1016/j.imavis.2008.06.010
   Murphy KP, 2012, MACHINE LEARNING PRO, P101
   Ribaric S, 2005, IEEE T PATTERN ANAL, V27, P1698, DOI 10.1109/TPAMI.2005.209
   Saldner HO, 1997, APPL OPTICS, V36, P2770, DOI 10.1364/AO.36.002770
   Snelick R, 2005, IEEE T PATTERN ANAL, V27, P450, DOI 10.1109/TPAMI.2005.57
   SRINIVASAN V, 1984, APPL OPTICS, V23, P3105, DOI 10.1364/AO.23.003105
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Wu XQ, 2006, IEEE T SYST MAN CY A, V36, P978, DOI 10.1109/TSMCA.2006.871797
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2000, AUTOMATED BIOMETRICS, P216
   Zhang D, 2010, PATTERN RECOGN, V43, P358, DOI 10.1016/j.patcog.2009.04.026
   Zhang D, 2009, IEEE T SYST MAN CY C, V39, P505, DOI 10.1109/TSMCC.2009.2020790
   Zhang L, 2015, IEEE T PATTERN ANAL, V37, P1730, DOI 10.1109/TPAMI.2014.2372764
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
NR 31
TC 18
Z9 22
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15357
EP 15375
DI 10.1007/s11042-016-3832-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900008
DA 2024-07-18
ER

PT J
AU Chin, YH
   Tai, TC
   Zhao, JH
   Wang, KY
   Hong, CT
   Wang, JC
AF Chin, Yu-Hao
   Tai, Tzu-Chiang
   Zhao, Jia-Hao
   Wang, Kuang-Yao
   Hong, Chao-Tse
   Wang, Jia-Ching
TI Program Guardian: screening system with a novel speaker recognition
   approach for smart TV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust principal component analysis; Sparse representation classifier;
   Speaker recognition; Supervector
ID FACE RECOGNITION; VARIABILITY; FRAMEWORK
AB This paper presents Program Guardian, which is a speaker recognition-based screening system for smart TV. The system identifies a specific person from his or her voice such that the smart TV can provide suitable programs for that person. This system is based on a robust speaker recognition system that uses robust principal component analysis (RPCA) and a sparse representation classifier (SRC). First, i-vectors that are generated from supervectors of Gaussian mixture models (GMMs) are used to generate the basic atoms of an over-complete dictionary. The i-vectors are then transformed using RPCA. The SRC is produced from transformed i-vector-based RPCA vectors. Finally, the sparse representation classifier corresponding to the target speaker with the least reconstruction error is constructed. NIST speaker recognition evaluation data base is used in our experiment. The results show that the proposed speaker recognition system is feasible and offers advantages over accuracy.
C1 [Chin, Yu-Hao; Zhao, Jia-Hao; Wang, Kuang-Yao; Wang, Jia-Ching] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
   [Tai, Tzu-Chiang] Providence Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Hong, Chao-Tse] Natl Chung Shan Inst Sci & Technol, Taoyuan, Taiwan.
C3 National Central University; Providence University - Taiwan
RP Wang, JC (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
EM tctai@pu.edu.tw; menro821@gmail.com; jcw@csie.ncu.edu.tw
CR [Anonymous], 2010, UILUENG092215 UIUC
   Bahari MH, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P506
   Campbell WM, 2006, INT CONF ACOUST SPEE, P97
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   Huanjun B, 2008, J TSINGHUA U SCI TEC, V48, P693
   Jeong JW, 2014, IEEE T CONSUM ELECTR, V60, P92, DOI 10.1109/TCE.2014.6780930
   Kanagasundaram A., 2011, INTERSPEECH 2011 12, V2011, P2341
   Ke QF, 2005, PROC CVPR IEEE, P739
   Kenny P, 2008, IEEE T AUDIO SPEECH, V16, P980, DOI 10.1109/TASL.2008.925147
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GX, 2010, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INNOVATION AND MANAGEMENT, VOLS I AND II, P1
   Naseem Imran, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4460, DOI 10.1109/ICPR.2010.1083
   Potamitis I., 2003, EUROSPEECH 2003 8 EU, V3, P2197
   Povey D, 2008, INT CONF ACOUST SPEE, P4561, DOI 10.1109/ICASSP.2008.4518671
   Vergin R, 1999, IEEE T SPEECH AUDI P, V7, P525, DOI 10.1109/89.784104
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yongkoo Han, 2011, 2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC 2011), P4581, DOI 10.1109/AIMSEC.2011.6010202
   Zeinali H., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P45, DOI 10.1109/ISSPA.2012.6310594
   Zuo F, 2005, IEEE ICCE, P35, DOI 10.1109/ICCE.2005.1429704
   Zuo F, 2005, IEEE T CONSUM ELECTR, V51, P183, DOI 10.1109/TCE.2005.1405718
NR 27
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13881
EP 13896
DI 10.1007/s11042-016-3764-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800009
DA 2024-07-18
ER

PT J
AU Shirehjini, AAN
   Semsar, A
AF Shirehjini, Ali Asghar Nazari
   Semsar, Azin
TI Human interaction with IoT-based smart environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile 3D UIs; Real-world evaluation of 3D UIs; Applications of 3D UI
   techniques; Internet of Things
ID NETWORKS; INTERNET
AB This paper describes concepts, design, implementation, and performance evaluation of a 3D-based user interface for accessing IoT-based Smart Environments (IoT-SE). The generic interaction model of the described work addresses some major challenges of Human-IoT-SE-Interaction such as cognitive overload associated with manual device selection in complex IoT-SE, loss of user control, missing system image or over-automation. To address these challenges we propose a 3D-based mobile interface for mixed-initiative interaction in IoT-SE. The 3D visualization and 3D UI, acting as the central feature of the system, create a logical link between physical devices and their virtual representation on the end user's mobile devices. By so doing, the user can easily identify a device within the environment based on its position, orientation, and form, and access the identified devices through the 3D interface for direct manipulation within the scene. This overcomes the problem of manual device selection. In addition, the 3D visualization provides a system image for the IoT-SE, which supports users in understanding the ambience and things going on in it. Furthermore, the mobile interface allows users to control the amount and the way the IoT-SE automates the environment. For example, users can stop or postpone system triggered automatic actions, if they don't like or want them. Users also can remove a rule forever. By so doing, users can delete smart behaviors of their IoT-SE. This helps to overcome the automation challenges. In this paper, we present the design, implementation and evaluation of the proposed interaction system. We chose smart meeting rooms as the context for prototyping and evaluating our interaction concepts. However, the presented concepts and methods are generic and could be adapted to similar environments such as smart homes. We conducted a subjective usability evaluation (ISO-Norm 9241/110) with 16 users. All in one the study results indicate that the proposed 3D-User Interface achieved a good high score according to the ISO-Norm scores.
C1 [Shirehjini, Ali Asghar Nazari; Semsar, Azin] Sharif Univ Technol, Comp Engn Dept, Tehran, Iran.
C3 Sharif University of Technology
RP Shirehjini, AAN (corresponding author), Sharif Univ Technol, Comp Engn Dept, Tehran, Iran.
EM shirehjini@sharif.edu
RI Nazari Shirehjini, Ali Asghar/I-9374-2017
OI Nazari Shirehjini, Ali Asghar/0000-0001-6674-0739
CR Aart E. H., 2006, TRUE VISIONS EMERGEN
   Aarts Emile., 2009, Ambient intelligence
   Adrian RAA, 2008, THESIS
   Amendola S, 2014, IEEE INTERNET THINGS, V1, P144, DOI 10.1109/JIOT.2014.2313981
   [Anonymous], TECH REP
   [Anonymous], 2014, P COMPANION PUBLICAT, DOI [DOI 10.1145/2556420.2557640, 10.1145/2556420.2557640]
   [Anonymous], P INT BCC HUM COMP I
   [Anonymous], 1996, P80211 IEEE
   [Anonymous], 2004, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications
   Balta-Ozkan N, 2013, ENERG POLICY, V63, P363, DOI 10.1016/j.enpol.2013.08.043
   Bandyopadhyay D, 2011, WIRELESS PERS COMMUN, V58, P49, DOI 10.1007/s11277-011-0288-5
   Belimpasakis P, 2014, MULTIMED TOOLS APPL, V70, P1899, DOI 10.1007/s11042-012-1221-y
   Ben Allouch S, 2009, LECT NOTES COMPUT SC, V5538, P77, DOI 10.1007/978-3-642-01516-8_7
   Bilgin A, 2013, IEEE SYS MAN CYBERN, P2887, DOI 10.1109/SMC.2013.492
   Bonino D, 2011, J AMB INTEL SMART EN, V3, P111, DOI 10.3233/AIS-2011-0099
   Burmeister D, 2015, LARGE SCALE MODEL BA, V16
   Condado PA, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P33, DOI 10.1145/2700648.2809839
   Gilman E, 2013, J AMB INTEL SMART EN, V5, P5, DOI 10.3233/AIS-120189
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hervás R, 2013, J UNIVERS COMPUT SCI, V19, P1334
   Hoff K.A., 2014, HUMAN FACTORS J HUMA
   Horvitz E. J., 2007, AI MAG, V28, P3
   Hossain MA, 2013, MULTIMED TOOLS APPL, V67, P409, DOI 10.1007/s11042-012-1008-1
   Kashyap H, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P245, DOI 10.1109/ICACEA.2015.7164704
   Martin ZAA, 2008, THESIS
   Mattern Friedemann, 2003, TOTAL VERNETZT, P1
   Mostafazadeh A, 2015, LECT NOTES COMPUT SC, V9194, P456, DOI 10.1007/978-3-319-20913-5_42
   Petzold M., 2013, CHI 13 EXTENDED ABST, P49
   Portet F, 2013, PERS UBIQUIT COMPUT, V17, P127, DOI 10.1007/s00779-011-0470-5
   Poslad S., 2011, Ubiquitous computing: Smart devices, environments and interactions
   Rahimi H, 2011, CONTEXT AWARE PRIORI
   Sadri F, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978815
   Savazzi S, 2014, IEEE INTERNET THINGS, V1, P180, DOI 10.1109/JIOT.2014.2313459
   Schmitt F, 2011, LECT NOTES ARTIF INT, V6967, P278, DOI 10.1007/978-3-642-24279-3_29
   Shirehjini A. A. N., 2008, THESIS
   Shirehjini AAN, 2004, COMPUT GRAPH-UK, V28, P667, DOI 10.1016/j.cag.2004.06.006
   Shirehjini AAN, 2015, CLUTCH 2 HANDED MOBI
   Shirehjini AAN, 2005, P 2005 JOINT C SMART, P207
   Shirehjini AAN, 2016, HCI INT 2016
   Shirehjini AAN, 2007, LECT NOTES COMPUT SC, V4552, P431
   Shirehjini AAN, 2012, IEEE T INSTRUM MEAS, V61, P1664, DOI 10.1109/TIM.2011.2181912
   Shirehjini AAN, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENT AND GAMES, P186, DOI 10.1109/HAVE.2009.5356120
   Shneiderman B., 1997, IUI97. 1997 International Conference on Intelligent User Interfaces, P33, DOI 10.1145/238218.238281
   Stankovic JA, 2014, IEEE INTERNET THINGS, V1, P3, DOI 10.1109/JIOT.2014.2312291
   Tang J, 2015, MULTIMED TOOLS APPL, V74, P10761, DOI 10.1007/s11042-014-2205-x
   Vacher Michel, 2015, Smart Health. Open Problems and Future Challenges: LNCS 8700, P161, DOI 10.1007/978-3-319-16226-3_7
   Yu J., 2015, MULTIMED TOOLS APPL, P1, DOI [10.1007/s11042-015-2785-0, DOI 10.1007/S11042-015-2785-0]
   Zeidler C, 2013, LECT NOTES COMPUT SC, V8117, P702
NR 48
TC 22
Z9 24
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13343
EP 13365
DI 10.1007/s11042-016-3697-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900019
DA 2024-07-18
ER

PT J
AU Chang, CC
   Huang, YH
   Lu, TC
AF Chang, Chin-Chen
   Huang, Ying-Hsuan
   Lu, Tzu-Chuen
TI A difference expansion based reversible information hiding scheme with
   high stego image visual quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Difference expansion; Reversible steganography; Least significant bit
   substitution
ID WATERMARKING
AB Reversible data hiding can embed secret data into the cover image to cheat hackers, thereby avoiding the interception attack. The previous methods modify non-embeddable pixels to create hiding spaces, which decreases the quality of the stego image. In order to improve the image quality, we keep the non-embeddable pixels and use a few flag bits to discriminate between the embedded pixels and the non-embeddable pixels. Experimental results showed that the proposed method can achieve better image quality than the reversible steganographic methods that proposed recently.
C1 [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Huang, Ying-Hsuan] Natl Chung Shan Inst Sci & Technol, Aeronaut Res Lab, Taichung 407, Taiwan.
   [Lu, Tzu-Chuen] Chaoyang Univ Technol, Dept Informat Management, Taichung 41349, Taiwan.
C3 Feng Chia University; Chaoyang University of Technology
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com; ying.hsuan0909@gmail.com; tclu@cyut.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Huang YH, 2014, MULTIMED TOOLS APPL, V70, P1439, DOI 10.1007/s11042-012-1176-z
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
NR 16
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12659
EP 12681
DI 10.1007/s11042-016-3689-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200022
DA 2024-07-18
ER

PT J
AU Xu, Z
   Liu, YH
   Xuan, JY
   Chen, HY
   Mei, L
AF Xu, Zheng
   Liu, Yunhuai
   Xuan, Junyu
   Chen, Haiyan
   Mei, Lin
TI Crowdsourcing based social media data analysis of urban emergency events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowdsourcing; Socialmedia analysis; Urban emergency events
ID TIME
AB An urban emergency event requires an immediate reaction or assistance for an emergency situation. With the popularity of the World Wide Web, the internet is becoming a major information provider and disseminator of emergency events and this is due to its real-time, open, and dynamic features. However, faced with the huge, disordered and continuous nature of web resources, it is impossible for people to efficiently recognize, collect and organize these events. In this paper, a crowdsourcing based burst computation algorithm of an urban emergency event is developed in order to convey information about the event clearly and to help particular social groups or governments to process events effectively. A definition of an urban emergency event is firstly introduced. This serves as the foundation for using web resources to compute the burst power of events on the web. Secondly, the different temporal features of web events are developed to provide the basic information for the proposed computation algorithm. Moreover, the burst power is presented to integrate the above temporal features of an event. Empirical experiments on real datasets show that the burst power can be used to analyze events.
C1 [Xu, Zheng; Liu, Yunhuai; Mei, Lin] Minist Publ Secur, Res Inst 3, Shanghai, Peoples R China.
   [Xu, Zheng] Tsinghua Univ, Beijing, Peoples R China.
   [Xuan, Junyu] Shanghai Univ, Shanghai, Peoples R China.
   [Chen, Haiyan] East China Univ Polit Sci & Law, Shanghai, Peoples R China.
C3 Ministry of Public Security (China); Tsinghua University; Shanghai
   University; East China University Political Science & Law
RP Xu, Z (corresponding author), Minist Publ Secur, Res Inst 3, Shanghai, Peoples R China.
EM xuzheng@shu.edu.cn
RI cai, wen/JWP-4797-2024; Chen, Haiyan/HGB-6216-2022
OI Xuan, Junyu/0000-0002-8367-6908
FU National Science and Technology Major Project [2013ZX01033002-003];
   National High Technology Research and Development Program of China (863
   Program) [2013AA014601, 2013AA014603]; National Key Technology Support
   Program [2012BAH07B01]; National Science Foundation of China [61300202,
   61300028]; Ministry of Public Security [2014JSYJB009]; China
   Postdoctoral Science Foundation [2014 M560085]; Shanghai Municipal
   Commission of Economy and Information [12GA-19]; Science Foundation of
   Shanghai [13ZR1452900]
FX This work was supported in part by the National Science and Technology
   Major Project under Grant 2013ZX01033002-003, in part by the National
   High Technology Research and Development Program of China (863 Program)
   under Grant 2013AA014601, 2013AA014603, in part by National Key
   Technology Support Program under Grant 2012BAH07B01, in part by the
   National Science Foundation of China under Grant 61300202, 61300028, in
   part by the Project of the Ministry of Public Security under Grant
   2014JSYJB009, in part by the China Postdoctoral Science Foundation under
   Grant 2014 M560085, the project of Shanghai Municipal Commission of
   Economy and Information under Grant 12GA-19, and in part by the Science
   Foundation of Shanghai under Grant 13ZR1452900.
CR Abonyi J, 2005, FUZZY SET SYST, V149, P39, DOI 10.1016/j.fss.2004.07.008
   Allan J., 2000, TOPIC DETECTION TRAC
   Allan J., 1998, P DARPA BROADC NEWS
   [Anonymous], FUTURE GENERATION CO
   [Anonymous], INTRO EMERGENCY MANA
   [Anonymous], P 15 INT C WORLD WID
   Fung GPC, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P300
   He Q, 2010, IEEE T PATTERN ANAL, V32, P1795, DOI 10.1109/TPAMI.2009.203
   Himberg J, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P203, DOI 10.1109/ICDM.2001.989520
   Hristidis V., 2006, P 2006 ACM CIKM INT, P802
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Jess F., 2012, P 15 INT C NETW BAS, P1
   Jin X., 2010, Proceedings of the 19th international conference on World Wide Web, P481
   Jo Y, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P370
   Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669
   Leskovec J., 2008, P 17 INT C WORLD WID, DOI 10.1145/1367497.1367620
   Leskovec J, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P420
   Liu X, 2014, ACM T SOFTW ENG METH, V23, DOI 10.1145/2559938
   Liu YH, 2011, IEEE T PARALL DISTR, V22, P2100, DOI 10.1109/TPDS.2011.113
   Luo XF, 2011, IEEE T AUTOM SCI ENG, V8, P482, DOI 10.1109/TASE.2010.2094608
   Makkonen J., 2003, P C N AM CHAPTER ASS, P43
   Mei Qiaozhu., 2005, KDD 05, P198, DOI DOI 10.1145/1081870.1081895
   Nallapati R., 2004, P 13 ACM INT C INF K, P446, DOI DOI 10.1145/1031171.1031258
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sung C, 2012, IEEE T SYST MAN CY C, V42, P532, DOI 10.1109/TSMCC.2011.2135850
   Tang JH, 2012, MULTIMED TOOLS APPL, V56, P1, DOI 10.1007/s11042-011-0822-1
   Wang C., P 17 C INF KNOWL MAN, P1033
   Wang LZ, 2013, FUTURE GENER COMP SY, V29, P739, DOI 10.1016/j.future.2012.09.001
   Wei CP, 2007, IEEE T SYST MAN CY A, V37, P273, DOI 10.1109/TSMCA.2006.886377
   Wei X, 2015, IEEE T FUZZY SYST, V23, P72, DOI 10.1109/TFUZZ.2015.2390226
   Wu XA, 2011, IEEE MULTIMEDIA, V18, P38, DOI 10.1109/MMUL.2011.12
   Xiong PC, 2009, IEEE T AUTOM SCI ENG, V6, P311, DOI 10.1109/TASE.2008.2009103
   Xu Z, 2015, FUTURE GENER COMP SY, V43-44, P40, DOI 10.1016/j.future.2014.04.002
   Yang CC, 2009, IEEE T SYST MAN CY A, V39, P850, DOI 10.1109/TSMCA.2009.2015885
   Yen NY, 2015, MULTIMED TOOLS APPL, V74, P5007, DOI 10.1007/s11042-015-2461-4
   Yin XX, 2008, IEEE T KNOWL DATA EN, V20, P796, DOI 10.1109/TKDE.2007.190745
   Zhao Q., 2006, ACM SIGKDD INT C KNO, P484
NR 37
TC 47
Z9 47
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11567
EP 11584
DI 10.1007/s11042-015-2731-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000026
DA 2024-07-18
ER

PT J
AU Aytekin, C
   Ozan, EC
   Kiranyaz, S
   Gabbouj, M
AF Aytekin, Caglar
   Ozan, Ezgi Can
   Kiranyaz, Serkan
   Gabbouj, Moncef
TI Extended quantum cuts for unsupervised salient object extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency; Salient object detection; Quantum mechanics; Spectral
   graph theory; Schrodinger's equation
ID VISUAL-ATTENTION; MODEL
AB In this manuscript, an unsupervised salient object extraction algorithm is proposed for RGB and RGB-Depth images. Saliency estimation is formulated as a foreground detection problem. To this end, Quantum-Cuts (QCUT), a recently proposed spectral foreground detection method is investigated and extended to formulate the saliency estimation problem more efficiently. The contributions of this work are as follows: (1) a new proof for QCUT from spectral graph theory point of view is provided, (2) a detailed analysis of QCUT and comparison to well-known graph clustering methods are conducted, (3) QCUT is utilized in a multiresolution framework, (4) a novel affinity matrix construction scheme is proposed for better encoding of saliency cues into the graph representation and (5) a multispectral analysis for a richer set of salient object proposals is investigated. With the above improvements, we propose Extended Quantum Cuts, which consistently achieves an exquisite performance over all benchmark saliency detection datasets, containing around 18 k images in total. Finally, the proposed approach also outperforms the state-of-the-art on a recently announced RGB-Depth saliency dataset.
C1 [Aytekin, Caglar; Ozan, Ezgi Can; Gabbouj, Moncef] Tampere Univ Technol, Dept Signal Proc, POB 553, FI-33101 Tampere, Finland.
   [Kiranyaz, Serkan] Qatar Univ, Dept Elect Engn, POB 2713, Doha, Qatar.
C3 Tampere University; Qatar University
RP Aytekin, C (corresponding author), Tampere Univ Technol, Dept Signal Proc, POB 553, FI-33101 Tampere, Finland.
EM caglar.aytekin@tut.fi
RI Kiranyaz, Serkan/AAK-1416-2021; Gabbouj, Moncef/G-4293-2014
OI Gabbouj, Moncef/0000-0002-9788-2323; kiranyaz,
   serkan/0000-0003-1551-3397
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007, PROC CVPR IEEE, P359
   [Anonymous], 2003, Introductory Quantum Mechanics
   Aytekin Ç, 2014, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2014.29
   Aytekin Ç, 2013, IEEE IMAGE PROC, P2489, DOI 10.1109/ICIP.2013.6738513
   Borji A, 2014, IEEE TIP
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Casares M, 2010, COMPUT VIS IMAGE UND, V114, P1223, DOI 10.1016/j.cviu.2010.03.023
   Cheng M. - M, 2013, VISUAL COMPUTER
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Gao D, 2007, CONF NEURAL INF PROC
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Han JW, 2014, NEUROCOMPUTING, V145, P140, DOI 10.1016/j.neucom.2014.05.049
   Harel J, 2006, C NEUR INF PROC SYST
   Hou X., 2007, ADV NEURODYN, P999
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang B, 2013, INTERNATIONAL CONFER
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang Z, 2013, IEEE CONF COMPUT VIS
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kiranyaz S, 2006, IEEE T IMAGE PROCESS, V15, P3759, DOI 10.1109/TIP.2006.881966
   Klein D. A., 2011, INT C COMP VIS
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Margolin R, 2013, VISUAL COMPUT, V29, P381, DOI 10.1007/s00371-012-0740-x
   Peng H., 2014, P 13 EUR C COMP VIS
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rigas I, 2015, COMPUT VIS IMAGE UND, V134, P33, DOI 10.1016/j.cviu.2015.01.007
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tong YB, 2011, COGN COMPUT, V3, P241, DOI 10.1007/s12559-010-9094-8
   Valenti R, 2009, INT C COMP VIS
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang L., 2011, INT C COMP VIS
   WEI YC, 1991, IEEE T COMPUT AID D, V10, P911, DOI 10.1109/43.87601
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, COMP VIS PATT REC
   Yang C, 2013, COMP VIS PATT REC
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou W., 2013, BMVC
NR 45
TC 8
Z9 9
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10443
EP 10463
DI 10.1007/s11042-016-3431-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400009
DA 2024-07-18
ER

PT J
AU Grailu, H
AF Grailu, Hadi
TI Improving the fingerprint verification performance of set partitioning
   coders at low bit rates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Verification performance; Fingerprint image compression; Set
   partitioning coders; Signal-to-noise ratio; Low bit rate compression
ID COMPRESSION; QUALITY
AB Wavelet transform combined with the set partitioning coders (SPC) are the most widely used fingerprint image compression approach. Many different SPC coders have been proposed in the literature to encode the wavelet transform coefficients a common feature of which is trying to maximize the global peak-signal-to-noise ratio (PSNR) at a given bit rate. Unfortunately, they have not considered the local variations of SNR within the compressed fingerprint image; therefore, different regions in the compressed image will have different ridge-valley qualities. This problem causes the verification performance to be decreased because minutiae and other useful features cannot be extracted precisely from the low-bit-rate-compressed fingerprint images. Contrast variation within the original image worsens the problem. This paper deals with those applications of fingerprint image compression in which high compression ratios and preserving or improving the verification performance of the compressed images are the main concern. We propose a compression scheme in which the local-SNR (signal-to-noise ratio) variations within the compressed image are minimized (and thus, general quality is maximized everywhere) by means of an iterative procedure. The proposed procedure can be utilized in conjunction with any SPC coder without the need to modify the SPC coder's algorithm. In addition, we used image enhancement to further improve the ridge-valley quality as well as the verification performance of the compressed fingerprint images through alleviating the leakage effect. We evaluated the compression and verification performances of some conventional and modern SPC coders including STW, EZW, SPIHT, WDR, and ASWDR combined with the proposed scheme. This evaluation was performed on the FVC2004 dataset with respect to measures including average PSNR curve versus bit rate, verification accuracy, detection error trade-off (DET) curve, and correlation of matching scores versus the average quality of involved fingerprint images. Simulation results showed considerable improvement on verification performance of all examined SPC coders, especially the SPIHT coder, by using the proposed scheme.
C1 [Grailu, Hadi] Shahrood Univ Technol, Elect & Robot Engn Dept, Shahrood, Iran.
C3 Shahrood University of Technology
RP Grailu, H (corresponding author), Shahrood Univ Technol, Elect & Robot Engn Dept, Shahrood, Iran.
EM grailu@shahroodut.ac.ir
CR Al-Asmari AK, 2002, INT J IMAG SYST TECH, V12, P211, DOI 10.1002/ima.10025
   [Anonymous], 2005, P INT C IM PROC
   [Anonymous], 2012, INT J COMPUTER SCI E
   Anurakphanawan N., 2015, 2015 6 INT C INF COM, P1
   Beleznai C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P463, DOI 10.1109/ICIP.2001.958528
   Bradley JN, 1993, SPIE P VISUAL INFORM, P293
   CAPPELLI R, 2002, P 16 ICPR
   Chen TP, 2004, IEEE IMAGE PROC, P1253
   Chen Y, 2005, LECT NOTES COMPUT SC, V3546, P160
   CHONG MMS, 1992, PATTERN RECOGN, V25, P1199, DOI 10.1016/0031-3203(92)90021-A
   Dhawan S., 2011, Int. J. Electron. Commun. Technol, V2, P22
   Esakkirajan S., 2006, INT J BIOL MED SCI, V1, P140
   Fernandez F. A., 2007, IEEE T INF FOREN SEC, V2, P734
   Gonzales R., 2007, DIGITAL IMAGE PROCES, V3rd
   Gonzalo AR, 1999, P IASTED INT C SIGN
   Goraale S.S., 2008, International Journal of Computer Science and Security, V1, No, P35
   Gornale S.S., 2007, INT J IMAGING SCI EN, V1, P16
   Grasemann U, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P1961
   Jain A K, 2011, Introduction to Biometrics
   Kambli MM, 2010, SIGN IMAGE PROCESS I, V1, P27
   Kampfer M, 2007, P SPIE SAN JOSE CA, V6508
   Kasaei S, 2002, IEEE T IMAGE PROCESS, V11, P1365, DOI 10.1109/TIP.2002.802534
   KIDD RC, 1995, J ELECTRON IMAGING, V4, P31, DOI 10.1117/12.195010
   Lepley MA, 2004, 04B0000022 MTR
   Lim E, 2002, IEEE IMAGE PROC, P469
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Nguyen TRUONG Q., 2001, WAVELET BASED IMAGE
   Pearlman W., 2011, Digital Signal Compression: Principles and Practice
   Pearlman WA, 2008, FOUND TRENDS SIGNAL, V2, P181, DOI 10.1561/2000000014
   Pearlman WA, 2008, FOUND TRENDS SIGNAL, V2, P95, DOI 10.1561/2000000013
   Perumal V, 2009, INT J COMPUT SCI INF, V6, P149
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SAID A, 1993, 1993 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS : PROCEEDINGS, VOLS 1-4 ( ISCAS 93 ), P279, DOI 10.1109/ISCAS.1993.393712
   Selvakumarasamy K, 2013, ITSI T ELECT ELECT E, V1, P64
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Sherlock BG, 1996, P INT C AC SPEECH SI
   Sherlock BG, 1997, IEE C IMAGE PROCESS, V5-8
   TABASSI E, 2004, 7151 NISTIR
   Tian J, 1996, P DAT COMPR C SNOWB, P456
   Walker JS, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P182, DOI 10.1109/ICIP.2000.899325
   WATSON C, 2004, USERS GUIDE FINGERPR
   Zhao S, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P660, DOI 10.1109/WKDD.2009.146
NR 43
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9959
EP 9991
DI 10.1007/s11042-016-3590-0
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300039
DA 2024-07-18
ER

PT J
AU Otero, B
   Rodriguez, E
   Ventura, J
AF Otero, Beatriz
   Rodriguez, Eva
   Ventura, Jacint
TI SURF-based mammalian species identification system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Species identification; Image recognition system; OpenCV; SURF
AB The development of tools for the automated identification of species will reduce the burden of routine identifications conducted by many biologists. The design of these tools is difficult because it depends on the proper extraction of those most relevant characteristics of the image, namely, those unequivocally identify its species. The appropriate software for such extraction does not exist in all cases. This work proposes an architecture for the automated identification of the skulls of different mammalian species belonging to the order Eulipotyphla, which includes shrews, moles and hedgehogs, among others. Our system determines nine species of this mammalian group using existing object recognition techniques, identifying them based on a set of images of the skulls of these species in a digital image database. To validate the proposed architecture, mobile and web applications have been developed. These applications use the image recognition technology provided by the OpenCV library for the detection of the keypoints and matching of the images. The application extracts the descriptor of the input image using the Speed Up Robust Features (SURF) method and compares this descriptor against the image database for matching using a Euclidean distance based on the nearest-neighbor approach. The initial tests have achieved a reliability of 98 %.
C1 [Otero, Beatriz; Rodriguez, Eva] Univ Politecn Cataluna, Dept Arquitectura Comp, Campus Nord,Modul C6,Despatx 204,Jordi Girona 1-3, E-08034 Barcelona, Spain.
   [Ventura, Jacint] Univ Politecn Cataluna, Fac Biociencies, Dept Biol Anim Biol Vegetal & Ecol, Cerdanyola Del Valles, Spain.
C3 Universitat Politecnica de Catalunya; Universitat Politecnica de
   Catalunya
RP Otero, B (corresponding author), Univ Politecn Cataluna, Dept Arquitectura Comp, Campus Nord,Modul C6,Despatx 204,Jordi Girona 1-3, E-08034 Barcelona, Spain.
EM botero@ac.upc.edu
RI Rodríguez, Eva/JKI-6335-2023; Rodriguez, Eva/J-8660-2017; Otero,
   Beatriz/L-2315-2017
OI Rodriguez, Eva/0000-0001-5904-7039; Otero, Beatriz/0000-0002-9194-559X
CR [Anonymous], 2006, P 1 INT WORKSH MOB V
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Churchfield S., 1990, The Natural History of Shrews
   Ke Y., 2004, P 2004 IEEE COMP SOC, V2, pII
   Kim Y.D., 2014, International Journal of Software Engineering and Its Applications, V8, P11, DOI DOI 10.14257/IJSEIA.2014.8.3.02
   Lee YH, 2015, MULTIMED TOOLS APPL, V74, P2289, DOI 10.1007/s11042-014-2129-5
   Loos A, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-49
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Murphy K, 2006, LECT NOTES COMPUT SC, V4170, P382
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Ruf B., 2008, LECT NOTES COMPUTER, P170, DOI DOI 10.1007/978-3-642-14758-6_14
   Sixta T, 2011, THESIS, P50
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
NR 16
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10133
EP 10147
DI 10.1007/s11042-016-3602-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300047
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Quan, YN
   Song, JF
   Guo, X
   Miao, QG
   Yang, Y
AF Quan, Yining
   Song, Jianfeng
   Guo, Xue
   Miao, Qiguang
   Yang, Yun
TI Filtering LiDAR data based on adjacent triangle of triangulated
   irregular network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LiDAR data; TIN; Adjacent triangle; Region growing
ID MORPHOLOGICAL FILTER; AIRBORNE; ALGORITHMS
AB The filtering of LiDAR points cloud data is a fundamental procedure in the production of Digital Elevation Model. Against the lack of using the relationship between the adjacent terrain and the points to be judged in the point cloud filtering, a LiDAR points cloud data filtering algorithm based on adjacent triangles in TIN (Triangulated Irregular Network) is proposed. It utilizes the elevation information of each triangle's adjacent triangles to detect the building edge points, and acquires the building points by region growing, then detects the isolated points with the morphological filtering algorithm, finally determines the ground point set and generates DEM. We evaluate the performance of the proposed method on the ISPRS LiDAR reference dataset. Experimental results show that the algorithm can effectively remove non-ground points, keep the ground points and minimize total error rates effectively while maintaining acceptable Type I and Type II error rates.
C1 [Quan, Yining; Song, Jianfeng; Guo, Xue; Miao, Qiguang] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Yang, Yun] Xian Res Inst Surveying & Mapping, Xian 710054, Shaanxi, Peoples R China.
   [Yang, Yun] State Key Lab Geoinformat Engn, Xian 710054, Shaanxi, Peoples R China.
C3 Xidian University
RP Quan, YN (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM ynquan@xidian.edu.cn
OI Miao, Qiguang/0000-0002-2872-388X
FU National Natural Science Foundations of China [61472302, 61272280,
   U1404620, 41271447]; Program for New Century Excellent Talents in
   University [NCET-12-0919]; Fundamental Research Funds for the Central
   Universities [K5051203020, K5051303018, JB150313, JB150317, BDY081422];
   Natural Science Foundation of Shaanxi Province [2014JM8310, 2010JM8027];
   Creative Project of the Science and Technology State of xi'an
   [CXY1441(1)]; State Key Laboratory of Geo-information Engineering
   [SKLGIE2014-M-4-4]
FX The work was jointly supported by the National Natural Science
   Foundations of China under grant No. 61472302,61272280, U1404620, and
   41271447; The Program for New Century Excellent Talents in University
   under grant No. NCET-12-0919; The Fundamental Research Funds for the
   Central Universities under grant No. K5051203020, K5051303018, JB150313,
   JB150317, and BDY081422,; Natural Science Foundation of Shaanxi
   Province, under grant No.2014JM8310 and, 2010JM8027; The Creative
   Project of the Science and Technology State of xi'an under grant No.
   CXY1441(1); The State Key Laboratory of Geo-information Engineering
   under grant No.SKLGIE2014-M-4-4.
CR Axelsson P., 2000, The International Archives of the Photogrammetry and Remote Sensing, Amsterdam, The Netherlands, VXXXIII, P110, DOI DOI 10.1016/J.ISPRSJPRS.2005.10.005
   Chen Q, 2007, PHOTOGRAMM ENG REM S, V73, P175, DOI 10.14358/PERS.73.2.175
   Cheng L, 2013, OPT COMMUN, V286, P244, DOI 10.1016/j.optcom.2012.08.028
   Feng Y., 2009, P URB REM SENS JOINT, P1, DOI DOI 10.1109/URS.2009.5137643
   Gong MG, 2015, IEEE T NEUR NET LEAR, V26, P3263, DOI 10.1109/TNNLS.2015.2469673
   Haugerud R.A., 2001, INT ARCH PHOTOGRAMME, V34, P211
   Kilian J., 1996, International Archives of Photogrammetry and Remote Sensing, V31, P383
   Kraus K, 1998, ISPRS J PHOTOGRAMM, V53, P193, DOI 10.1016/S0924-2716(98)00009-4
   Meng XL, 2010, REMOTE SENS-BASEL, V2, P833, DOI 10.3390/rs2030833
   Pingel TJ, 2013, ISPRS J PHOTOGRAMM, V77, P21, DOI 10.1016/j.isprsjprs.2012.12.002
   Shao L, 2004, SCI SURV MAPP, V29, P68
   Sithole G, 2004, ISPRS J PHOTOGRAMM, V59, P85, DOI 10.1016/j.isprsjprs.2004.05.004
   Sithole G., 2005, Segmentation and classification of airborne laser scanner data
   Vosselman George., 2000, IAPRS, V33, P935942, DOI [10.1016/S0924-2716(98)00009-4, 10 1016/S0924-2716(98)00009-4]
   Wang H, 2013, URBAN REMONTE SENSIN
   [吴丛丛 Wu Congcong], 2013, [测绘通报, Bulletin of Surveying and Mapping], P32
   Wu H., 2012, 2012 SPRING C ENG TE, P1
   Yu Huang, 2010, 2010 IEEE 3rd International Nanoelectronics Conference (INEC 2010), DOI 10.1109/INEC.2010.5424529
   Zhang JX, 2013, ISPRS J PHOTOGRAMM, V81, P44, DOI 10.1016/j.isprsjprs.2013.04.001
   Zhang KQ, 2003, IEEE T GEOSCI REMOTE, V41, P872, DOI 10.1109/TGRS.2003.810682
NR 20
TC 10
Z9 11
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 11051
EP 11063
DI 10.1007/s11042-016-3465-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400042
DA 2024-07-18
ER

PT J
AU Nguyen, T
   O'Dea, B
   Larsen, M
   Phung, D
   Venkatesh, S
   Christensen, H
AF Thin Nguyen
   O'Dea, Bridianne
   Larsen, Mark
   Dinh Phung
   Venkatesh, Svetha
   Christensen, Helen
TI Using linguistic and topic analysis to classify sub-groups of online
   depression communities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Mental health; Depression; Web community; Web-logs;
   Feature extraction; Textual cues; Language styles; Topics
ID SOCIAL NETWORKING; MENTAL-DISORDERS; HEALTH; HETEROGENEITY; STUDENTS;
   EMOTION; MEDIA
AB Depression is a highly prevalent mental health problem and is a co-morbidity of other mental, physical, and behavioural disorders. The internet allows individuals who are depressed or caring for those who are depressed, to connect with others via online communities; however, the characteristics of these discussions have not yet been fully explored. This work aims to explore the textual cues of online communities interested in depression. A total of 5,000 posts were randomly selected from 24 online communities. Five subgroups of online communities were identified: Depression, Bipolar Disorder, Self-Harm, Grief/Bereavement, and Suicide. Psycholinguistic features and content topics were extracted from the posts and analysed. Machine learning techniques were used to discriminate the online conversations in the depression communities from the other subgroups. Topics and psycholinguistic features were found to be highly valid predictors of community subgroup. Clear discrimination between linguistic features and topics, alongside good predictive power is an important step in understanding social media and its use in mental health.
C1 [Thin Nguyen; Dinh Phung; Venkatesh, Svetha] Deakin Univ, Ctr Pattern Recognit & Data Analyt, Geelong, Vic 3216, Australia.
   [O'Dea, Bridianne; Larsen, Mark; Christensen, Helen] Univ New South Wales, Black Dog Inst, Randwick, NSW 2031, Australia.
C3 Deakin University; Black Dog Institute; University of New South Wales
   Sydney
RP Nguyen, T (corresponding author), Deakin Univ, Ctr Pattern Recognit & Data Analyt, Geelong, Vic 3216, Australia.
EM thin.nguyen@deakin.edu.au; b.odea@blackdog.org.au;
   mark.larsen@blackdog.org.au; dinh.phung@deakin.edu.au;
   svetha.venkatesh@deakin.edu.au; h.christensen@blackdog.org.au
RI Christensen, Helen/F-5053-2012; Nguyen, Thin/IXD-7832-2023; Phung, Dinh
   Q/D-1328-2012
OI Christensen, Helen/0000-0003-0435-2065; Nguyen,
   Thin/0000-0003-3467-8963; O'Dea, Bridianne/0000-0003-1731-210X;
   Venkatesh, Svetha/0000-0001-8675-6631; Phung, Dinh/0000-0002-9977-8247
CR [Anonymous], 2009, GLOBAL HEALTH RISKS: MORTALITY AND BURDEN OF DISEASE ATTRIBUTABLE TO SELECTED MAJOR RISKS, P1
   Arguello J., 2006, P SIGCHI C HUM FACT, P959, DOI DOI 10.1145/1124772.1124916
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chen LS, 2000, J AFFECT DISORDERS, V59, P1, DOI 10.1016/S0165-0327(99)00132-9
   Coppersmith G, 2014, P INT AAAI C WEBL SO
   Coppersmith G, 2015, P WORKSH COMP LING C
   Coppersmith G., 2014, P WORKSH COMP LING C, P51, DOI [10.3115/v1/w14-3207, DOI 10.3115/V1/W14-3207]
   Cruwys T, 2014, PERSONALITY SOCIAL P
   Culotta A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1335, DOI 10.1145/2556288.2557139
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   De Choudhury M., 2013, P SIGCHI C HUM FACT, P3267, DOI [10.1145/2470654.2466447, https://doi.org/10.1145/2470654.2466447, DOI 10.1145/2470654.2466447]
   De Choudhury M., 2013, P 2013 C COMP SUPP C, P1431, DOI [10.1145/2441776.2441937, DOI 10.1145/2441776.2441937]
   De Choudhury M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1365, DOI 10.1145/2556288.2557214
   De Choudhury Munmun, 2013, ICWSM, P128, DOI [10.1109/IRI.2012.6302998, DOI 10.1109/IRI.2012.6302998, DOI 10.3109/01460862.2013.798190]
   Eggly S, 2014, J LANG SOC PSYCHOL
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   George DR, 2013, COMPUT HUM BEHAV, V29, P559, DOI 10.1016/j.chb.2012.12.008
   Giles J, 2012, NATURE, V488, P448, DOI 10.1038/488448a
   Goldberg D, 2011, WORLD PSYCHIATRY, V10, P226
   Grajales FJ III, 2014, J MED INTERNET RES, V16, DOI 10.2196/jmir.2912
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hollenbaugh EE, 2011, CYBERPSYCH BEH SOC N, V14, P13, DOI 10.1089/cyber.2009.0403
   Houston TK, 2002, AM J PSYCHIAT, V159, P2062, DOI 10.1176/appi.ajp.159.12.2062
   Johnson GJ, 2006, COMMUN ACM, V49, P107, DOI 10.1145/1107458.1107463
   Kessler RC, 2008, AM J PSYCHIAT, V165, P703, DOI 10.1176/appi.ajp.2008.08010126
   Klonsky ED, 2003, AM J PSYCHIAT, V160, P1501, DOI 10.1176/appi.ajp.160.8.1501
   Larsen ME, 2015, IEEE J BIOMED HEALTH, V19, P1246, DOI 10.1109/JBHI.2015.2403839
   Laserna CM, 2014, UM WHO SAYS YOU KNOW
   McDaniel BT, 2012, MATERN CHILD HLTH J, V16, P1509, DOI 10.1007/s10995-011-0918-2
   Moreno MA, 2011, DEPRESS ANXIETY, V28, P447, DOI 10.1002/da.20805
   Mundt JC, 2012, BIOL PSYCHIAT, V72, P580, DOI 10.1016/j.biopsych.2012.03.015
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   O'Dea Bridianne, 2015, Internet Interventions, V2, P183, DOI 10.1016/j.invent.2015.03.005
   Park M, 2013, P AAAI INT C WEBL SO
   Parker G, 2015, J AFFECT DISORDERS, V176, P43, DOI 10.1016/j.jad.2015.01.063
   Patrick K, 2013, MEDICINE, V2
   Paul MJ, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0103408, 10.1371/currents.outbreaks.90b9ed0f59bae4ccaa683a39865d9117]
   Pennebaker J. W., 2007, Linguistic inquiry and word count (LIWC2007)
   Powell J, 2003, BMC PSYCHIATRY, V3, DOI 10.1186/1471-244X-3-19
   Preotiuc-Pietro D, 2015, P WORKSH COMP LING C
   Ramirezesparza N., 2008, Proceedings of the Ninth International AAAI Conference on Web and Social Media, V2, P102, DOI DOI 10.1609/ICWSM.V2I1.18623
   Rodriguez AJ, 2010, J PERS, V78, P575, DOI 10.1111/j.1467-6494.2010.00627.x
   Rude SS, 2004, COGNITION EMOTION, V18, P1121, DOI 10.1080/02699930441000030
   Schwartz Hansen Andrew, 2013, P INT AAAI C WEB SOC, P583
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Song XM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2371
   Stirman SW, 2001, PSYCHOSOM MED, V63, P517
   Thin Nguyen, 2015, Web Information Systems Engineering - WISE 2015. 16th International Conference. Proceedings: LNCS 9419, P216, DOI 10.1007/978-3-319-26187-4_17
   Nguyen T, 2015, IEEE T AFFECT COMPUT, V6, P312, DOI 10.1109/TAFFC.2015.2400912
   Nguyen T, 2014, IEEE T AFFECT COMPUT, V5, P217, DOI 10.1109/TAFFC.2014.2315623
   Tsuya A, 2014, J MED INTERNET RES, V16, P110, DOI 10.2196/jmir.3298
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinod Vydiswaran VG, 2014, P INT AAAI C WEBL SO
   Volkova S, 2015, P 29 C ART INT
   Wang PS, 2007, WORLD PSYCHIATRY, V6, P177
   Wang S, 2014, SIGNAL PROCESS
   WAXER P, 1976, J CONSULT CLIN PSYCH, V44, P493, DOI 10.1037/0022-006X.44.3.493
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yan Yan, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P2842, DOI 10.1109/ICIP.2013.6738585
   Youn SJ, 2013, INT J CLIN HLTH PSYC, V13, P74, DOI 10.1016/S1697-2600(13)70010-3
NR 65
TC 43
Z9 47
U1 8
U2 121
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10653
EP 10676
DI 10.1007/s11042-015-3128-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400020
DA 2024-07-18
ER

PT J
AU Yan, WQ
   Hou, CP
   Wang, BL
   Wang, LH
AF Yan, Weiqing
   Hou, Chunping
   Wang, Baoliang
   Wang, Laihua
TI Content-aware disparity adjustment for different stereo displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic image; Disparity mapping; Content-aware; Salient region; 3D
   image warping
AB In this paper, we present an effective disparity mapping method for binocular stereoscopic image. It is inspired by the observation that its displayed depth would change, when a stereoscopic image is displayed on different size screens. The phenomenon may bring an uncomfortable experience for viewers. To make a comfortable stereoscopic image for viewers, moreover to adapt a stereoscopic image to a target display screen, we propose a content-aware disparity adjustment method. Firstly, the disparity mapping is established to control and retarget the depth of a stereoscopic scene. Then, the relationship between the disparity editing and image content editing is established to guide the proposed warping model. At last, to implement the disparity mapping operator, we propose a content-aware stereoscopic mesh warping model, which can simultaneously avoid the salient region distortion and adjust disparity to a target range by establishing the relationship. Experimental results show that the proposed method can effectively adjust disparity of stereoscopic image, which not only avoids the salient region distortion and adjusts disparity to a target range.
C1 [Yan, Weiqing; Hou, Chunping; Wang, Baoliang; Wang, Laihua] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Yan, Weiqing] Univ Calif Berkeley, Berkeley, CA 94720 USA.
C3 Tianjin University; University of California System; University of
   California Berkeley
RP Yan, WQ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.; Yan, WQ (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.
EM wqyan@tju.edu.cn
FU National Natural Science Foundation of China [61471262]; Natural Science
   Foundation key international (regional) cooperation research projects
   [61520106002]; Ph.D. Programs Foundation of Ministry of Education of
   China [20130032110010]; China Scholarship Council (CSC)
FX This work is supported by the National Natural Science Foundation of
   China under Grants 61471262, by Natural Science Foundation key
   international (regional) cooperation research projects 61520106002, and
   by Ph.D. Programs Foundation of Ministry of Education of China under
   Grants 20130032110010, by China Scholarship Council (CSC).
CR [Anonymous], ACM SIGGRAPH ASIA SK
   [Anonymous], NONLINEAR DEPTH SCAL
   [Anonymous], THEATERS BARELY DIGI
   [Anonymous], TECHNICAL REPORT
   Chan HM, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P708
   Chang CH, 2011, IEEE T MULTIMEDIA, V13, P589, DOI 10.1109/TMM.2011.2116775
   Dekel T, 2013, IEEE T PATTERN ANAL, V35, P2513, DOI 10.1109/TPAMI.2013.46
   Frohlich B., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P169, DOI 10.1109/VISUAL.1999.809884
   Getty DJ, 2008, LECT NOTES COMPUT SC, V5116, P74, DOI 10.1007/978-3-540-70538-3_11
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Heckbert Paul S., 1989, THESIS
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Jiang GY, 2015, MULTIMED TOOLS APPL, V74, P8197, DOI 10.1007/s11042-014-2051-x
   Jung C, 2015, ELECTRON LETT, V51, P482, DOI 10.1049/el.2014.3913
   Kang K, 2016, MULTIMED TOOLS APPL, V75, P1443, DOI 10.1007/s11042-014-2142-8
   Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812
   Liu F, 2013, IEEE T MULTIMEDIA, V15, P129, DOI 10.1109/TMM.2012.2225033
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Luo SJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366201
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Smolic A, 2011, P IEEE, V99, P607, DOI 10.1109/JPROC.2010.2098350
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang L, 2008, P IEEE C COMPUTER VI, P1
   Yoo JW, 2013, IEEE SIGNAL PROC LET, V20, P519, DOI 10.1109/LSP.2013.2252165
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 26
TC 5
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10465
EP 10479
DI 10.1007/s11042-016-3442-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400010
DA 2024-07-18
ER

PT J
AU Malathi, T
   Bhuyan, MK
AF Malathi, T.
   Bhuyan, M. K.
TI Performance analysis of Gabor wavelet for extracting most informative
   and efficient features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Gabor wavelet; Mean square error and Correlation
   coefficients
ID FACIAL EXPRESSION RECOGNITION; FACE RECOGNITION; TEXTURE CLASSIFICATION;
   REPRESENTATION; IMAGES
AB Gabor wavelet can extract most informative and efficient texture features for different computer vision and multimedia applications. Features extracted by Gabor wavelet have similar information as visualized by the receptive field of simple cells in the visual cortex of the mammalian brains. This motivates researchers to use Gabor wavelet for feature extraction. Gabor wavelet features are used for many multimedia applications such as stereo matching, face and facial expression recognition (FER), texture representation for segmentation. This motivates us to analyze Gabor features to evaluate their effectiveness in representing an image. In this paper, three major characteristics of Gabor features are established viz., (i) Real coefficients of Gabor wavelet alone is sufficient enough to represent an image; (ii) Local Gabor wavelet features with overlapping regions represent an image more accurately as compared to the global Gabor features and the local features extracted for the non-overlapping regions; and (iii) Real coefficients of overlapping regions are more robust to radiometric changes as compared to the features extracted from both global and local (non-overlapping regions) by using real, imaginary and magnitude information of a Gabor wavelet. The efficacy and effectiveness of these findings are evaluated by reconstructing the original image using the extracted features, and subsequently the reconstructed image is compared with the original image. Experimental results show that the local Gabor wavelet features extracted from overlapping regions represent an image more efficiently than the global and non-overlapping region-based features. Experimental results also show that the real coefficients alone is sufficient enough to represent an image more accurately as compared to the imaginary and magnitude informations.
C1 [Malathi, T.; Bhuyan, M. K.] Indian Inst Technol Guwahati, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Bhuyan, MK (corresponding author), Indian Inst Technol Guwahati, Gauhati 781039, India.
EM malathi@iitg.ernet.in; mkb@iitg.ernet.in
RI Bhuyan, Manoj Kumar/D-1562-2012
CR Ali AM, 2014, IEEE T INF FOREN SEC, V9, P2158, DOI 10.1109/TIFS.2014.2362299
   [Anonymous], LIGHT SCATTERING REV
   Bhagavathy S, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P745
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   Jahanbin S, 2011, IEEE T INF FOREN SEC, V6, P1287, DOI 10.1109/TIFS.2011.2162585
   Jiang W, 2009, IEEE T SYST MAN CY B, V39, P1036, DOI 10.1109/TSMCB.2008.2011646
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kosov S, 2009, IEEE IMAGE PROC, P1221, DOI 10.1109/ICIP.2009.5413675
   Kumar A, 2000, OPT ENG, V39, P3176, DOI 10.1117/1.1327837
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   LIEBELT J, 2006, P IEEE C COMP VIS PA, V2, P2483
   Lin L, 2012, PATTERN RECOGN, V45, P231, DOI 10.1016/j.patcog.2011.06.011
   Loizou CP, 2004, IEEE MEDITERR ELECT, P395, DOI 10.1109/MELCON.2004.1346891
   Malathi T, 2015, IET COMPUT VIS, V9, P595, DOI 10.1049/iet-cvi.2014.0210
   Moghaddam HA, 2013, PATTERN ANAL APPL, V16, P163, DOI 10.1007/s10044-011-0230-1
   Mohamed MA, 2014, IEEE T CIRC SYST VID, V24, P1499, DOI 10.1109/TCSVT.2014.2308628
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng Z, 2015, MATH PROBL ENG, V2015, DOI [10.1155/2015/802505, 10.1155/2015/916418]
   Rajadell O, 2009, LECT NOTES COMPUT SC, V5876, P509, DOI 10.1007/978-3-642-10520-3_48
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D, 2007, PROCEEDING INT C COM, P1
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Shen LL, 2011, IEEE T GEOSCI REMOTE, V49, P5039, DOI 10.1109/TGRS.2011.2157166
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Tou JY, 2009, LECT NOTES COMPUT SC, V5507, P745, DOI 10.1007/978-3-642-03040-6_91
   Tou JingYi., 2007, MMU International Symposium on Information and Communications Technologies, P197
   Xie XD, 2009, PATTERN RECOGN, V42, P1003, DOI 10.1016/j.patcog.2008.08.034
   Xu CH, 2009, PATTERN RECOGN, V42, P1895, DOI 10.1016/j.patcog.2009.01.001
   Yang M, 2013, PATTERN RECOGN, V46, P1865, DOI 10.1016/j.patcog.2012.06.022
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang LG, 2014, NEUROCOMPUTING, V145, P451, DOI 10.1016/j.neucom.2014.05.008
   Zuñiga AG, 2014, PATTERN RECOGN LETT, V36, P135, DOI 10.1016/j.patrec.2013.09.023
NR 37
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8449
EP 8469
DI 10.1007/s11042-016-3414-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800037
DA 2024-07-18
ER

PT J
AU Roininen, MJ
   Leppänen, J
   Eronen, AJ
   Curcio, IDD
   Gabbouj, M
AF Roininen, Mikko J.
   Leppanen, Jussi
   Eronen, Antti J.
   Curcio, Igor D. D.
   Gabbouj, Moncef
TI Modeling the timing of cuts in automatic editing of concert videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic video editing; Cut timing; Example-based modeling; Live music
   content analysis
ID GENERATION
AB Increasing amount of video content is being recorded by people in public events. However, the editing of such videos can be challenging for the average user. We describe an approach for modeling the shot cut timing of professionally edited concert videos. We analyze the temporal positions of cuts in relation to the music meter grid and form Markov chain models from the found switching patterns and their occurrence frequencies. The stochastic Markov chain models are combined with audio change point analysis and cut deviation models for automatically generating temporal editing cues for unedited concert video recordings. Videos edited according to the modeling are compared in a user study against a baseline automatic editing method as well as against videos edited by hand. The study results show that users prefer the cut timing from the proposed system over the baseline with a clear margin, whereas a much smaller difference is observed in the preference of hand-made videos over the proposed method.
C1 [Roininen, Mikko J.; Gabbouj, Moncef] Tampere Univ Technol, Dept Signal Proc, Korkeakoulunkatu 10, Tampere 33720, Finland.
   [Leppanen, Jussi; Eronen, Antti J.; Curcio, Igor D. D.] Nokia Technol, Visiokatu 3, Tampere 33720, Finland.
C3 Tampere University; Nokia Corporation; Nokia Finland
RP Roininen, MJ (corresponding author), Tampere Univ Technol, Dept Signal Proc, Korkeakoulunkatu 10, Tampere 33720, Finland.
EM mikko.roininen@tut.fi
RI Gabbouj, Moncef/G-4293-2014
OI Gabbouj, Moncef/0000-0002-9788-2323
CR [Anonymous], 1998, Cambridge Series in Statistical and Probabilistic Mathematics
   [Anonymous], 2011, P 8 SOUND MUS COMP C, DOI DOI 10.5281/ZENODO.849903
   [Anonymous], 2012, P 20 ACM INT C MULT, DOI DOI 10.1145/2393347.2396495
   Cai R, 2007, INT CONF ACOUST SPEE, P737
   Chu WT, 2007, IEEE MULTIMEDIA, V14, P36, DOI 10.1109/MMUL.2007.66
   Dwelle T, 1994, MUSIC VIDEO 101 HOME
   Ellis DPW, 2007, J NEW MUSIC RES, V36, P51, DOI 10.1080/09298210701653344
   Eronen AJ, 2010, IEEE T AUDIO SPEECH, V18, P50, DOI 10.1109/TASL.2009.2023165
   Foote J., 2002, P ACM MULTIMEDIA 200, P553, DOI DOI 10.1145/641007.641119
   Gillet O, 2007, IEEE T CIRC SYST VID, V17, P347, DOI 10.1109/TCSVT.2007.890831
   Hua X. -S., 2004, PROC 12 ANN ACM INT, P472
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P572, DOI 10.1109/TCSVT.2004.826750
   Kennedy Lyndon., 2009, WWW 09, P311, DOI [DOI 10.1145/1526709.1526752, 10.1145/1526709.1526752]
   Klapuri AP, 2006, IEEE T AUDIO SPEECH, V14, P342, DOI 10.1109/TSA.2005.854090
   Lai PS, 2005, P 9 INT C KNOWL BAS, P1238
   Liao C, 2008, P 15 INT MULT MOD C, P401, DOI [10.1007/978-3-540-92892-841, DOI 10.1007/978-3-540-92892-841]
   MATSUO Y, 2002, P 10 ACM INT C MULT, P255, DOI DOI 10.1145/641007.641058
   Naci U, 2010, THESIS
   Nitta N, 2011, MULTIMED TOOLS APPL, V51, P649, DOI 10.1007/s11042-010-0633-9
   Ohya H, 2013, 2013 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE AND COMPUTING 2013), P157, DOI 10.1109/CultureComputing.2013.44
   Ojala J., 2014, P 13 INT C MOB UB MU, P170, DOI [10.1145/2677972.2677975, DOI 10.1145/2677972.2677975]
   Peeters G, 2011, IEEE T AUDIO SPEECH, V19, P1754, DOI 10.1109/TASL.2010.2098869
   Saini M.K., 2012, Proceedings of the 20th International Conference on Multimedia, P139, DOI DOI 10.1145/2393347.2393373
   Saini Mukesh., 2013, Proceedings of the 4th ACM multimedia systems conference, P108
   Shamma D. A., 2005, 13th Annual ACM International Conference on Multimedia, P563, DOI 10.1145/1101149.1101278
   Shao Xi, 2006, ACM T MULTIM COMPUT, V2, P2, DOI DOI 10.1145/1142020.1142023
   Shrestha P., 2010, Proceedings of the international conference on Multimedia (MM '10), P541, DOI DOI 10.1145/1873951.1874023
   Tomás B, 2011, MULTIMED TOOLS APPL, V55, P627, DOI 10.1007/s11042-010-0582-3
   Vihavainen S, 2011, WE WANT MORE HUMAN C
   Wang J C, 2012, P 20 ACM INT C MULT, P1379, DOI [10.1145/2393347.2396494, DOI 10.1145/2393347.2396494]
   Wang JJ, 2007, IEEE T MULTIMEDIA, V9, P576, DOI 10.1109/TMM.2006.888013
   Xu SH, 2008, IEEE INT SYM MULTIM, P214, DOI 10.1109/ISM.2008.39
   Yoon JC, 2009, MULTIMED TOOLS APPL, V41, P197, DOI 10.1007/s11042-008-0225-0
   Young StevenJ., 1994, Entropic Cambridge Research Laboratory, V2, P2
NR 34
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6683
EP 6707
DI 10.1007/s11042-016-3304-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400027
DA 2024-07-18
ER

PT J
AU Wang, XY
   Liang, LL
   Li, YW
   Yang, HY
AF Wang, Xiang-Yang
   Liang, Lin-Lin
   Li, Yong-Wei
   Yang, Hong-Ying
TI Image retrieval based on exponent moments descriptor and localized
   angular phase histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Exponent moments descriptor; Localized
   angular phase histogram; Combination
ID COLOR; SHAPE; REPRESENTATION; SCALE
AB Multiple feature extraction and combination is one of the most important issues in the content-based image retrieval (CBIR). In this paper, we propose a new content-based image retrieval method based on an efficient combination of shape and texture features. As its shape features, exponent moments descriptor (EMD), which has many desirable properties such as expression efficiency, robustness to noise, geometric invariance, fast computation etc., is adopted in RGB color space. As its texture features, localized angular phase histogram (LAPH) of the intensity component, which is robust to illumination, scaling, and image blurring, is used in hue saturation intensity (HSI) color space. The combination of above shape and texture information provides a robust feature set for color image retrieval. Experimental results on well known databases show significant improvements in retrieval rates using the proposed method compared with some current state-of-the-art approaches.
C1 [Wang, Xiang-Yang; Liang, Lin-Lin; Li, Yong-Wei; Yang, Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Liang, Li-Lin/AAB-3538-2022; Yang, Jing/JFK-4046-2023
OI Liang, Li-Lin/0000-0002-1585-9067; Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [61472171, 61272416];
   Liaoning Research Project for Institutions of Higher Education of China
   [L2013407]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. No. 61472171 & 61272416, and Liaoning Research
   Project for Institutions of Higher Education of China under Grant No.
   L2013407.
CR Alvarez S, 2012, COMPUT VIS IMAGE UND, V116, P54, DOI 10.1016/j.cviu.2011.08.004
   Amanatiadis A, 2011, IET IMAGE PROCESS, V5, P493, DOI 10.1049/iet-ipr.2009.0246
   [Anonymous], J INNER MONGOLIA NOR
   Anuar FM, 2013, EXPERT SYST APPL, V40, P105, DOI 10.1016/j.eswa.2012.07.031
   Aptoula E, 2014, IEEE T GEOSCI REMOTE, V52, P3023, DOI 10.1109/TGRS.2013.2268736
   Aptoula E, 2009, IEEE T IMAGE PROCESS, V18, P2505, DOI 10.1109/TIP.2009.2027363
   Atto AM, 2013, IEEE T IMAGE PROCESS, V22, P2495, DOI 10.1109/TIP.2013.2246524
   Chen WT, 2010, IEEE T IMAGE PROCESS, V19, P2005, DOI 10.1109/TIP.2010.2051753
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Farsi H, 2013, IET IMAGE PROCESS, V7, P212, DOI 10.1049/iet-ipr.2012.0203
   Gholamreza A, 2005, LECT NOTES COMPUT SC, V3804, P462, DOI [10.1007/11595755_56, DOI 10.1007/11595755_56]
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Iqbal K, 2012, J COMPUT SYST SCI, V78, P1258, DOI 10.1016/j.jcss.2011.10.013
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jun Y, 2012, IEEE T SYST MAN CY B, V42, P1413
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   Li CR, 2013, IEEE SIGNAL PROC LET, V20, P799, DOI 10.1109/LSP.2013.2247596
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu MZ, 2012, IEEE T PATTERN ANAL, V34, P2407, DOI 10.1109/TPAMI.2012.44
   Pappas TN, 2013, P IEEE, V101, P2044, DOI 10.1109/JPROC.2013.2262912
   Park U, 2014, IEEE SIGNAL PROC LET, V21, P962, DOI 10.1109/LSP.2014.2321755
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   Rakvongthai Y, 2013, SIGNAL PROCESS-IMAGE, V28, P1494, DOI 10.1016/j.image.2013.06.005
   Saipullah KM, 2012, MULTIMED TOOLS APPL, V59, P717, DOI 10.1007/s11042-011-0766-5
   Seetharaman K, 2014, J VIS COMMUN IMAGE R, V25, P727, DOI 10.1016/j.jvcir.2014.01.004
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Singh C, 2011, OPT LASER ENG, V49, P1384, DOI 10.1016/j.optlaseng.2011.07.009
   Singha M, 2012, IET IMAGE PROCESS, V6, P1221, DOI 10.1049/iet-ipr.2011.0453
   Talib A, 2013, J VIS COMMUN IMAGE R, V24, P345, DOI 10.1016/j.jvcir.2013.01.007
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Yap PT, 2006, IEE P-VIS IMAGE SIGN, V153, P17, DOI 10.1049/ip-vis:20045064
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 44
TC 22
Z9 23
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7633
EP 7659
DI 10.1007/s11042-016-3416-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800003
DA 2024-07-18
ER

PT J
AU Sharma, D
   Saxena, R
   Singh, N
AF Sharma, Deepak
   Saxena, Rajiv
   Singh, Narendra
TI Dual domain robust watermarking scheme using random DFRFT and least
   significant bit technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Least significant bit; Multiple parameter discrete fractional Fourier
   transform; Random discrete fractional Fourier transform; Watermark
ID FRACTIONAL FOURIER-TRANSFORM; DISCRETE WAVELET TRANSFORM; SINGULAR-VALUE
   DECOMPOSITION; IMAGE WATERMARKING; MULTIPLE WATERMARKING; DIGITAL
   WATERMARKING; ALGORITHM
AB This paper presents a novel image watermarking scheme that uses multipleparameter discrete fractional Fourier transform (MPDFRFT) with random DFRFT and least significant bit (LSB) technique. The proposed scheme uses the LSB technique to embed watermark image in an original image, while RDFRFT and MPDFRFT are used to enhance the security of the watermarked image. The presented method aims to make the system more robust and secure at two different levels along with faster embedding and extraction process. The MPDFRFT is input data points of order DFRFT parameters. The MPDFRFT can be converted to the DFRFT when all of its order parameters have same values. On the other hand, RDFRFT is kernel matrix with random values of their DFT eigenvectors and Eigenvalues. Random magnitude and phase of its transformed output are unique features of RDFRFT that utilised to enhance security. LSB technique is preferred for watermark embedding because of its lesser effect on the image perceptibility. In proposed scheme, the cover image is converted into sub-images and MPDFRFT is applied to each sub-image. Then RDFRFT is applied in tandem to transformed sub-images in order to enhance robustness followed by watermark embedding using LSB technique. In watermark extraction process the inverse of MPDFRFT and RDFRFT is applied for reconstruction of original images along with LSB extraction mechanism. The performance of the proposed system is evaluated by using MATLAB software under various attacks and distortions. The simulation results validate that the embedding scheme presented in this work has better performance in terms of robustness along with perceptibility and security over contemporary existing schemes.
C1 [Sharma, Deepak; Singh, Narendra] Jaypee Univ Engn & Technol, Raghogarh 473226, India.
   [Saxena, Rajiv] Jaypee Univ, Anupshahr 203390, India.
RP Sharma, D (corresponding author), Jaypee Univ Engn & Technol, Raghogarh 473226, India.
EM deepakforu23@rediffmail.com
RI Singh, Narendra/AAH-5380-2021; SAXENA, RAJIV/AAO-7587-2020; Sharma, Dr.
   Deepak/G-5636-2016
OI Sharma, Dr. Deepak/0000-0002-0461-7900
CR Al-Otum HM, 2010, SIGNAL PROCESS, V90, P2498, DOI 10.1016/j.sigpro.2010.02.017
   ALMEIDA LB, 1994, IEEE T SIGNAL PROCES, V42, P3084, DOI 10.1109/78.330368
   Campisi P, 2004, IEEE SIGNAL PROC LET, V11, P826, DOI 10.1109/LSP.2004.835463
   Candan Ç, 2000, IEEE T SIGNAL PROCES, V48, P1329, DOI 10.1109/78.839980
   Cui DL, 2009, PROCEEDINGS OF THE 2009 SECOND PACIFIC-ASIA CONFERENCE ON WEB MINING AND WEB-BASED APPLICATION, P51, DOI 10.1109/WMWA.2009.60
   Deng C, 2010, SIGNAL PROCESS, V90, P3256, DOI 10.1016/j.sigpro.2010.05.032
   DICKINSON BW, 1982, IEEE T ACOUST SPEECH, V30, P25, DOI 10.1109/TASSP.1982.1163843
   Findik O, 2010, OPT COMMUN, V283, P4916, DOI 10.1016/j.optcom.2010.07.020
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Huang FJ, 2004, PATTERN RECOGN LETT, V25, P1769, DOI 10.1016/j.patrec.2004.07.003
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Lagzian S., 2011, 2011 International Symposium on Artificial Intelligence and Signal Processing (AISP), P48, DOI 10.1109/AISP.2011.5960985
   Lagzian S., 2011, International Journal of Intelligent Information Processing, V2, P22, DOI DOI 10.4156/IJIIP
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lang J, 2012, INT C COMP SCI SERV, P692
   Lang J, 2014, OPT LASER ENG, V53, P112, DOI 10.1016/j.optlaseng.2013.08.021
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu ZJ, 2007, OPT LETT, V32, P478, DOI 10.1364/OL.32.000478
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Ni RR, 2008, FORENSIC SCI INT, V179, P54, DOI 10.1016/j.forsciint.2008.04.016
   Nishchal NK, 2009, J OPT-INDIA, V38, P22, DOI 10.1007/s12596-009-0003-z
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Pei SC, 1999, IEEE T SIGNAL PROCES, V47, P1335, DOI 10.1109/78.757221
   Pei SC, 1997, OPT LETT, V22, P1047, DOI 10.1364/OL.22.001047
   Pei SC, 2006, IEEE SIGNAL PROC LET, V13, P329, DOI 10.1109/LSP.2006.871721
   Pei SC, 2009, IEEE SIGNAL PROC LET, V16, P1015, DOI 10.1109/LSP.2009.2027646
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   SAHIN A, 1995, OPT COMMUN, V120, P134, DOI 10.1016/0030-4018(95)00438-E
   Savelonas MA, 2010, SIGNAL PROCESS, V90, P2521, DOI 10.1016/j.sigpro.2010.02.021
   Sharma D, 2014, INT J SECUR APPL, V8, P439, DOI 10.14257/ijsia.2014.8.5.38
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Sun J-Y, 2012, 5 INT C IM SIGN PROC, P553
   Tang LL, 2015, MULTIMED TOOLS APPL, V74, P4397, DOI 10.1007/s11042-013-1531-8
   Tirkel A. Z., 1993, Conference Proceedings DICTA-93 Digital Image Computing: Techniques and Applications, P666
NR 43
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3921
EP 3942
DI 10.1007/s11042-016-4095-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200036
DA 2024-07-18
ER

PT J
AU Ghazi, MM
   Erdogan, H
AF Ghazi, Mostafa Mehdipour
   Erdogan, Hakan
TI Image noise level estimation based on higher-order statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise level estimation; Image denoising; Method of moments; Generalized
   Gaussian distribution
ID DISTRIBUTIONS; VARIANCE
AB Noise level estimation is a required step for many preprocessing algorithms in computer vision such as image denoising. In this paper, a model-based technique for additive white Gaussian noise level estimation is proposed via matching moments of eligible transform coefficients of a single image. We assume that noise and image signals are independent and seek to use an image transform that preserves distribution characteristics of noise. This transform should also result in coefficients with a generalized Gaussian distribution for the image itself. We use block-based discrete cosine transform (DCT) and discrete wavelet transform (DWT) which are shown to satisfy these requirements. The proposed method fits the histogram of AC coefficients of all DCT blocks or histogram of all high frequency wavelet coefficients with a generalized Gaussian distribution and attempts to estimate the noise variance through matching the estimated and true values of moments. Since the modeled distributions are symmetric and hence all odd moments are zero, our approach involves solving a nonlinear system of equations based on the method of moments using only even moments. The performance of the proposed method is compared to those of the best prevalent algorithms proposed for noise level estimation using patch-based and model-based techniques. The results on three different image databases show that the proposed scheme outperforms previous techniques in general.
C1 [Ghazi, Mostafa Mehdipour; Erdogan, Hakan] Sabanci Univ, Fac Engn & Nat Sci, Istanbul, Turkey.
C3 Sabanci University
RP Ghazi, MM (corresponding author), Sabanci Univ, Fac Engn & Nat Sci, Istanbul, Turkey.
EM mehdipour@sabanciuniv.edu; haerdogan@sabanciuniv.edu
OI Mehdipour Ghazi, Mostafa/0000-0002-8473-281X
CR Aja-Fernández S, 2009, IMAGE VISION COMPUT, V27, P756, DOI 10.1016/j.imavis.2008.08.002
   Banham MR, 1996, IEEE T IMAGE PROCESS, V5, P619, DOI 10.1109/83.491338
   Buades A, 2010, SIAM REV, V52, P113, DOI 10.1137/090773908
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Corner BR, 2003, INT J REMOTE SENS, V24, P689, DOI 10.1080/01431160210164271
   Danielyan A, 2009, LNLA: 2009 INTERNATIONAL WORKSHOP ON LOCAL AND NON-LOCAL APPROXIMATION IN IMAGE PROCESSING, P41, DOI 10.1109/LNLA.2009.5278404
   De Stefano A, 2004, EURASIP J APPL SIG P, V2004, P2400, DOI 10.1155/S1110865704401218
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Duijster A, 2009, IEEE T GEOSCI REMOTE, V47, P3892, DOI 10.1109/TGRS.2009.2031103
   Forouzanfar M, 2008, INT J WAVELETS MULTI, V6, P653, DOI 10.1142/S0219691308002562
   Goljan M, 2006, PROC SPIE, V6072, DOI 10.1117/12.643254
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Hamza AB, 2002, IEEE SIGNAL PROC MAG, V19, P37, DOI 10.1109/MSP.2002.1028351
   Huang XT, 2016, MULTIMED TOOLS APPL, V75, P2713, DOI 10.1007/s11042-015-2452-5
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lee J.S., 1989, Geoscience and Remote Sensing Symposium, V2, P1005, DOI [DOI 10.1109/IGARSS.1989.579061, 10.1109/IGARSS.1989.579061]
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Liu XH, 2012, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2012.6466947
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   OLSEN SI, 1993, CVGIP-GRAPH MODEL IM, V55, P319, DOI 10.1006/cgip.1993.1022
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Qian Z, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P50
   Rank K, 1999, IEE P-VIS IMAGE SIGN, V146, P80, DOI 10.1049/ip-vis:19990238
   Rosin PL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P274, DOI 10.1109/ICCV.1998.710730
   Shin DH, 2005, IEEE T CONSUM ELECTR, V51, P218, DOI 10.1109/TCE.2005.1405723
   Simoncelli E.P., 1999, Bayesian Inference in Wavelet-Based Models, P291, DOI DOI 10.1007/978-1-4612-0567-8
   Uss M, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/806516
   VARANASI MK, 1989, J ACOUST SOC AM, V86, P1404, DOI 10.1121/1.398700
   Yu S., 2012, Journal of Computational Information Systems, V8, P9055
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 33
TC 22
Z9 26
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2379
EP 2397
DI 10.1007/s11042-015-3169-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000035
DA 2024-07-18
ER

PT J
AU Guo, LJ
   Cheng, TT
   Huang, YJ
   Zhao, JY
   Zhang, R
AF Guo, Lijun
   Cheng, Tingting
   Huang, Yuanjie
   Zhao, Jieyu
   Zhang, Rong
TI Unsupervised video object segmentation by spatiotemporal graphical model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised; Spatiotemporal smoothness; Supervoxel; Conditional random
   field
ID SALIENT REGION DETECTION; FEATURES
AB We propose a novel spatiotemporal graphical model for unsupervised video object segmentation. The core of our model is a layered-CRF (conditional random field) that contains two layers, i.e., pixel layer and supervoxel layer. First, the heat diffusion based segmentation and salient region detection is integrated to obtain the segmentation results of the first frame. The results are used as input seeds to train dual probabilistic models of each object class. In the spatiotemporal layered-CRF framework we extend binary segmentation to multiple object segmentation. We add intra-frame spatial matching potential and inter-frame temporal supervoxels consistent potential to link the pixel layer and the supervoxel layer. This improves the spatiotemporal smoothing throughout the video sequence in the proposed model. The proposed unsupervised method lightens the burden of labeling training samples and obtains a smooth and accurate object boundary in video segmentation. The experiments on two public datasets demonstrate that our method outperforms several state-of-the-art methods in both single and multiple foreground cases.
C1 [Guo, Lijun; Cheng, Tingting; Huang, Yuanjie; Zhao, Jieyu; Zhang, Rong] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Guo, LJ (corresponding author), Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM guolijun@nbu.edu.cn
FU National Natural Science Foundation of China [NSFC: 61175026];
   Inte-rnational Science and Technology Cooperation Special Programme
   [2013DFG12810]; Ningbo Municipal Natural Science Foundation of China
   [2014A610031, 2014A610032]; Open Research Fund of Zhejiang
   First-foremost Key Subject-Information and Communications Engineering of
   China [XKXL1316]; C.Wong Magna Fund in Ningbo University; Open Fund of
   Zhejiang Provincial Key Academic Project
FX This work is supported by National Natural Science Foundation of China
   (NSFC: 61175026), Inte-rnational Science and Technology Cooperation
   Special Programme (No. 2013DFG12810), Ningbo Municipal Natural Science
   Foundation of China (2014A610031, 2014A610032), Open Research Fund of
   Zhejiang First-foremost Key Subject-Information and Communications
   Engineering of China(XKXL1316), C.Wong Magna Fund in Ningbo University,
   Open Fund of Zhejiang Provincial Key Academic Project(first level).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akamine K, 2012, COMPUT J, V55, P3, DOI 10.1093/comjnl/bxq075
   [Anonymous], STREAMING HIERARCHIC
   [Anonymous], VIDEO OBJECT CO SEGM
   [Anonymous], C COMP VIS PATT REC
   Badrinarayanan V, 2013, IEEE T PATTERN ANAL, V35, P2751, DOI 10.1109/TPAMI.2013.54
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cheng HT, 2012, PROC CVPR IEEE, P741, DOI 10.1109/CVPR.2012.6247744
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Chiu WC, 2013, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.2013.48
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Fu HZ, 2014, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2014.405
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719
   Kae A, 2014, PROC CVPR IEEE, P272, DOI 10.1109/CVPR.2014.42
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kohli Pushmeet., 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587417
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735
   Parikh S., 2007, 2007 IEEE Sarnoff Symposium, P1, DOI 10.1109/SARNOF.2007.4567370
   Raza SH, 2013, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2013.396
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Torralba A, 2004, PROC CVPR IEEE, P762
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
NR 28
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1037
EP 1053
DI 10.1007/s11042-015-3100-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000045
DA 2024-07-18
ER

PT J
AU Khan, S
   Hussain, M
   Aboalsamh, H
   Bebis, G
AF Khan, Salabat
   Hussain, Muhammad
   Aboalsamh, Hatim
   Bebis, George
TI A comparison of different Gabor feature extraction approaches for mass
   classification in mammography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mass detection; Gabor filter bank; Directional features; Digital
   mammography; Feature transformation and reduction; SEL weighted SVM;
   PCA; LDA
ID FALSE-POSITIVE REDUCTION; STATISTICAL COMPARISONS; TEXTURE FEATURES;
   BREAST-TISSUE; MICROCALCIFICATIONS; SEGMENTATION; CLASSIFIERS
AB We investigate the performance of six different approaches for directional feature extraction for mass classification problem in digital mammograms. These techniques use a bank of Gabor filters to extract the directional textural features. Directional textural features represent structural properties of masses and normal tissues in mammograms at different orientations and frequencies. Masses and micro-calcifications are two early signs of breast cancer which is a major leading cause of death in women. For the detection of masses, segmentation of mammograms results in regions of interest (ROIs) which not only include masses but suspicious normal tissues as well (which lead to false positives during the discrimination process). The problem is to reduce the false positives by classifying ROIs as masses and normal tissues. In addition, the detected masses are required to be further classified as malignant and benign. The feature extraction approaches are evaluated over the ROIs extracted from MIAS database. Successive Enhancement Learning based weighted Support Vector Machine (SELwSVM) is used to efficiently classify the generated unbalanced datasets. The average accuracy ranges from 68 to 100 % as obtained by different methods used in our paper. Comparisons are carried out based on statistical analysis to make further recommendations.
C1 [Khan, Salabat] Comsats Inst Informat Technol, Dept Comp Sci, Attock, Pakistan.
   [Hussain, Muhammad; Aboalsamh, Hatim] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11543, Saudi Arabia.
   [Bebis, George] Univ Nevada, Dept Comp Sci & Engn, Reno, NV 89557 USA.
C3 COMSATS University Islamabad (CUI); King Saud University; Nevada System
   of Higher Education (NSHE); University of Nevada Reno
RP Khan, S (corresponding author), Comsats Inst Informat Technol, Dept Comp Sci, Attock, Pakistan.
EM salabat.khan@nu.edu.pk
RI Hussain, Muhammad/A-8487-2014; Aboalsamh, Hatim/AAO-6311-2021; Hussain,
   Muhammad/AAD-2380-2022; Hussain, Muhammad/KGL-0395-2024
OI Hussain, Muhammad/0000-0002-5847-8539; Aboalsamh,
   Hatim/0000-0002-8000-5105; 
FU NSTIP strategic technologies programs in the Kingdom of Saudi Arabia
   [08-INF325-02]
FX This project was supported by NSTIP strategic technologies programs,
   grant number 08-INF325-02 in the Kingdom of Saudi Arabia.
CR [Anonymous], 2010, CANCER
   [Anonymous], INT J BIOL BIOMED EN
   [Anonymous], TECH REP
   [Anonymous], 2010, TECHNICAL REPORT
   Bhangale T, 2000, IEEE IMAGE PROC, P184, DOI 10.1109/ICIP.2000.900925
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Braz G, 2009, COMPUT BIOL MED, V39, P1063, DOI 10.1016/j.compbiomed.2009.08.009
   Buciu I, 2011, BIOMED SIGNAL PROCES, V6, P370, DOI 10.1016/j.bspc.2010.10.003
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Costa DD, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-55
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Domínguez AR, 2009, PATTERN RECOGN, V42, P1138, DOI 10.1016/j.patcog.2008.08.006
   Duda R. O., 2000, PATTERN CLASSIFICATI
   El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569
   Elter M, 2009, MED PHYS, V36, P2052, DOI 10.1118/1.3121511
   Eltoukhy MM, 2010, COMPUT MED IMAG GRAP, V34, P269, DOI 10.1016/j.compmedimag.2009.11.002
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   García S, 2008, J MACH LEARN RES, V9, P2677
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Hussain M, 2012, IET IMAGE PROC, V1- 5
   Hussain M, 2014, NEURAL COMPUT APPL, V25, P83, DOI 10.1007/s00521-013-1450-7
   Kruizinga P, 1999, IEEE T IMAGE PROCESS, V8, P1395, DOI 10.1109/83.791965
   Lahmiri S., 2011, 2011 IEEE 9th International New Circuits and Systems Conference (NEWCAS 2011), P53, DOI 10.1109/NEWCAS.2011.5981217
   Lladó X, 2009, COMPUT MED IMAG GRAP, V33, P415, DOI 10.1016/j.compmedimag.2009.03.007
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Moayedi F, 2010, COMPUT BIOL MED, V40, P373, DOI 10.1016/j.compbiomed.2009.12.006
   Nunes AP, 2010, INT J SIGNAL IMAGING, V3, P40, DOI 10.1504/IJSISE.2010.034631
   Oliver A, 2010, MED IMAGE ANAL, V14, P87, DOI 10.1016/j.media.2009.12.005
   Rangayyan R. M., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), P170, DOI 10.1109/SIBGRA.2000.883910
   Reyad YA, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0100-7
   Rogova GL, 1999, PROC SPIE, V3661, P1426, DOI 10.1117/12.348542
   Sampaio WB, 2011, COMPUT BIOL MED, V41, P653, DOI 10.1016/j.compbiomed.2011.05.017
   de Oliveira FSS, 2015, COMPUT BIOL MED, V57, P42, DOI 10.1016/j.compbiomed.2014.11.016
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062
   Szekely N, 2006, IEEE T INSTRUM MEAS, V55, P944, DOI 10.1109/TIM.2006.870104
   Tang JS, 2009, IEEE T INF TECHNOL B, V13, P236, DOI 10.1109/TITB.2008.2009441
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   TURNER MR, 1986, BIOL CYBERN, V55, P71
   VAPNIK V, 1995, STAT LEARNING THEORY
   Wang Y, 2007, IEEE SENS J, V7, P1347, DOI 10.1109/JSEN.2007.905045
   WEI DT, 1995, MED PHYS, V22, P1501, DOI 10.1118/1.597418
   Zheng YF, 2010, ALGORITHMS, V3, P44, DOI 10.3390/a3010044
NR 44
TC 41
Z9 41
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 33
EP 57
DI 10.1007/s11042-015-3017-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000003
DA 2024-07-18
ER

PT J
AU Lai, YR
   Tsai, PC
   Yao, CY
   Ruan, SJ
AF Lai, Yu-Ren
   Tsai, Ping-Chuan
   Yao, Chih-Yuan
   Ruan, Shanq-Jang
TI Improved local histogram equalization with gradient-based weighting
   process for edge preservation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Local histogram equalization; Edge preservation;
   Brightness preservation; Bilateral Bezier curve; Gradient information
ID CONTRAST ENHANCEMENT; IMAGE-ENHANCEMENT; REPRESENTATION
AB This paper presents a novel local histogram equalization by combining the transformation functions of the non-overlapped sub-images based on the gradient information for edge preservation and better visualization. To ameliorate the problems of the over- and under-enhancement produced by conventional local histogram equalization, the bilateral Bezier curve-based histogram modification strategy is first employed to modify the significant and insufficient changes of each cumulative distribution in each sub-image. Yet, the gradient information has not been considered, and the cumulative distribution of some enhanced sub-images are still significant or insufficient because of the over- and under-enhancement, respectively. Therefore, the key insight of the proposed method is that the transformation functions of the partitioned sub-images will be weighed and combined based on the proportion of gradients to preserve the image texture. In addition, the input image is separated into the non-overlapped sub-images for reducing the time complexity. Based on the eight representative test images and mean opinion score, the experimental results demonstrate that the proposed method is quite competitive with four state-of-the-art histogram equalization methods in the literature. Furthermore, according to the subjective evaluation, it is observed that the proposed method can also apply to the practical applications and achieve good visual quality.
C1 [Lai, Yu-Ren; Yao, Chih-Yuan] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
   [Tsai, Ping-Chuan; Ruan, Shanq-Jang] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Yao, CY (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM D9715011@mail.ntust.edu.tw; M10002139@mail.ntust.edu.tw;
   cyuan.yao@csie.ntust.edu.tw; sjruan@mail.ntust.edu.tw
CR Çelebi AT, 2015, IEEE T CONSUM ELECTR, V61, P119, DOI 10.1109/TCE.2015.7064119
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Cheng F. C., 2013, J DISP TECHNOL, V9, P44, DOI DOI 10.1109/JDT.2012.2226234
   Choi HI, 1999, EXPERT SYST APPL, V17, P213, DOI 10.1016/S0957-4174(99)00035-4
   de la Torre A, 2005, IEEE T SPEECH AUDI P, V13, P355, DOI 10.1109/TSA.2005.845805
   Eramian M, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P397, DOI 10.1109/CRV.2005.47
   Franco A, 2009, EXPERT SYST APPL, V36, P8946, DOI 10.1016/j.eswa.2008.11.006
   Ghanekar U, 2010, IEEE SIGNAL PROC LET, V17, P1, DOI 10.1109/LSP.2009.2032479
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kang M, 2009, OPT ENG, V48, DOI 10.1117/1.3191785
   Kao WC, 2009, IEEE T CONSUM ELECTR, V55, P15, DOI 10.1109/TCE.2009.4814408
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lamberti F, 2006, IEEE T CONSUM ELECTR, V52, P966, DOI 10.1109/TCE.2006.1706495
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Nikolova M, 2014, IEEE T IMAGE PROCESS, V23
   Panetta KA, 2008, IEEE T SYST MAN CY B, V38, P174, DOI 10.1109/TSMCB.2007.909440
   Pei SC, 2004, IEEE T IMAGE PROCESS, V13, P414, DOI 10.1109/TIP.2003.821347
   Sakellaropoulos P, 2003, PHYS MED BIOL, V48, P787, DOI 10.1088/0031-9155/48/6/307
   Shin J, 2015, IEEE SIGNAL PROC LET, V22, P1293, DOI 10.1109/LSP.2015.2399612
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Tsai PS, 2009, IEEE T CIRC SYST VID, V19, P574, DOI 10.1109/TCSVT.2009.2014022
   Wahab A, 1998, IEE P-VIS IMAGE SIGN, V145, P160, DOI 10.1049/ip-vis:19981809
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Xu HT, 2014, IEEE T MULTIMEDIA, V16, P68, DOI 10.1109/TMM.2013.2283453
NR 31
TC 23
Z9 24
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1585
EP 1613
DI 10.1007/s11042-015-3147-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000069
DA 2024-07-18
ER

PT J
AU Misra, S
   Laskar, RH
   Baruah, U
   Das, TK
   Saha, P
   Choudhury, SP
AF Misra, Songhita
   Laskar, Rabul Hussain
   Baruah, U.
   Das, T. K.
   Saha, P.
   Choudhury, S. P.
TI Analysis and extraction of LP-residual for its application in speaker
   verification system under uncontrolled noisy environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LP-residual; Telephonic database; Auto associative neural network; FCM
   model; K-Means model; LBG model; Voice-segment level approach; Sentence
   level analysis; Text dependent speaker verification system
ID LINEAR PREDICTION; COMBINING EVIDENCE; SPEECH; VOWEL; EXCITATION;
   SPECTRUM; INSTANTS; FEATURES; PHASE
AB Sub-segmental analysis of excitation source may contain significant speaker-specific information pertaining to speaker verification. In this paper, the excitation source feature has been explored for design of speaker verification system (SVS). The baseline of the system is extraction of speaker-specific information from LP-residual features by modelling the speakers through different supervised and unsupervised models, based on which they will be accepted or rejected. Direct LP-residual (DLR) as well as DCT coefficients of LP-residual (DCTLR) are approximated as the excitation source features for the system. The models are processed in two different level of analysis, namely, sentence level analysis as well as voice-segment level approach (VSLA), with the variations in the frame size of the input. Effects of the change of frame size in the input vectors are observed. Studies are carried over telephonic database collected in practical environment. A comparative analysis has been presented for the combination of models, features and the two levels of analysis for the given data. The experimental study suggests that application of VSLA on unsupervised models with DCTLR as input, provides a performance which is 14.21 % better than sentence level analysis of the models.
C1 [Misra, Songhita] Natl Inst Technol, Speech & Image Lab, Silchar, India.
   [Laskar, Rabul Hussain; Baruah, U.; Das, T. K.; Saha, P.; Choudhury, S. P.] Natl Inst Technol Silchar, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; National Institute of Technology (NIT System);
   National Institute of Technology Silchar
RP Misra, S (corresponding author), Natl Inst Technol, Speech & Image Lab, Silchar, India.
EM msonghita@gmail.com; rabul18@yahoo.com
RI MISRA, SONGHITA/AAF-7585-2020; Laskar, Rabul Hussain/AFU-7180-2022
OI MISRA, SONGHITA/0000-0002-0341-2655; Laskar, Rabul
   Hussain/0000-0003-3988-394X
FU Department of Electronics & Information Technology (DeitY), Ministry of
   Communications and Information Technology, Government of India
FX The authors highly acknowledge the Department of Electronics &
   Information Technology (DeitY), Ministry of Communications and
   Information Technology, Government of India for the resources provided
   and also their never ending support and motivation for the research
   work.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   ANANTHAPADMANABHA TV, 1979, IEEE T ACOUST SPEECH, V27, P309, DOI 10.1109/TASSP.1979.1163267
   Anjani A. V. N. S., 2000, THESIS
   Bajpai A, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P305
   Bajpai A, 2008, IEEE REG 10 C TENCON, P1
   Bengio S, 2005, 1 INT WORKSH, V2004, P21
   Berglund B, 1996, J ACOUST SOC AM, V99, P2985, DOI 10.1121/1.414863
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   BLINN JF, 1993, IEEE COMPUT GRAPH, V13, P78, DOI 10.1109/38.219457
   Chauhan Arun, 2010, Proceedings of the 2010 IEEE Students' Technology Symposium (TechSym 2010), P255, DOI 10.1109/TECHSYM.2010.5469162
   Chetouani M, 2009, PATTERN RECOGN, V42, P487, DOI 10.1016/j.patcog.2008.08.008
   CUPERMAN V, 1985, IEEE T COMMUN, V33, P685, DOI 10.1109/TCOM.1985.1096372
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Furui S., 2001, DIGITAL SPEECH PROCE, V2nd
   Ghosh S, 2013, INT J ADV COMPUT SC, V4, P35
   Gupta C. S., 2003, THESIS
   Hayakawa S, 1997, SPEAKER IDENTIFICATI
   Hui X., 2009, IEEE Transactions on Systems, Man, and cybernetics, V39, P319
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jayanna HS, 2009, SADHANA-ACAD P ENG S, V34, P717, DOI 10.1007/s12046-009-0042-9
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Marvan J, 2007, Google Patents, US Patent App, Patent No. [11/672, 106, 11672106]
   Mittal VK, 2014, J ACOUST SOC AM, V136, P1932, DOI 10.1121/1.4894789
   Moreno PJ, 1994, IEEE IEEE INT C AC S, V94, P1
   Muralishankar R, 2004, SPEECH COMMUN, V42, P143, DOI 10.1016/j.specom.2003.05.001
   Murty KSR, 2009, IEEE SIGNAL PROC LET, V16, P469, DOI 10.1109/LSP.2009.2016829
   Murty KR, 2006, IEEE SIGNAL PROC LET, V13, P52, DOI 10.1109/LSP.2005.860538
   Paliwal KK, 2005, SPEECH COMMUN, V45, P153, DOI 10.1016/j.specom.2004.08.001
   Pati D, 2011, INT J SPEECH TECHNOL, V14, P49, DOI 10.1007/s10772-010-9087-8
   Plumpe MD, 1999, IEEE T SPEECH AUDI P, V7, P569, DOI 10.1109/89.784109
   Prasanna S. R. M., 2004, IEEE INT C AC SPEECH, V1, P1
   Prasanna SRM, 2006, SPEECH COMMUN, V48, P1243, DOI 10.1016/j.specom.2006.06.002
   Prasanna SRM, 2011, IEEE T AUDIO SPEECH, V19, P2552, DOI 10.1109/TASL.2011.2155061
   Prasanna SRM, 2009, IEEE T AUDIO SPEECH, V17, P556, DOI 10.1109/TASL.2008.2010884
   Prasanna SRM, SPEAKER INFORM USING, P311
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rahman MM, 2012, INT J ADV COMPUT SC, V3, P131
   Rank E, 2001, NONLINEAR SYNTHESIS, P746
   Rao KS, 2006, IEEE T AUDIO SPEECH, V14, P972, DOI 10.1109/TSA.2005.858051
   Reddy K. S., 2004, THESIS
   SMITS R, 1995, IEEE T SPEECH AUDI P, V3, P325, DOI 10.1109/89.466662
   Strang G, 1999, SIAM REV, V41, P135, DOI 10.1137/S0036144598336745
   WAKITA H, 1976, IEEE T ACOUST SPEECH, V24, P270, DOI 10.1109/TASSP.1976.1162797
   Wu KL, 2012, PATTERN RECOGN, V45, P407, DOI 10.1016/j.patcog.2011.07.012
   Yegnanarayana B, 2005, IEEE T SPEECH AUDI P, V13, P575, DOI 10.1109/TSA.2005.848892
   Yegnanarayana B, 2000, IEEE T SPEECH AUDI P, V8, P267, DOI 10.1109/89.841209
   Yegnanarayana B, 2002, INT CONF ACOUST SPEE, P541
   Yegnanarayana B, 2001, INT CONF ACOUST SPEE, P409, DOI 10.1109/ICASSP.2001.940854
NR 50
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 757
EP 784
DI 10.1007/s11042-015-3020-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000033
DA 2024-07-18
ER

PT J
AU Su, PC
   Wu, CS
AF Su, Po-Chyi
   Wu, Chin-Song
TI Efficient copy detection for compressed digital videos by spatial and
   temporal feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy detection; Video coding; Feature extraction; Content management;
   Multimedia databases; Copyright protection
ID SHOT DETECTION; ROBUST; RETRIEVAL
AB This research aims at developing a practical video copy detection mechanism to determine whether an investigated video is a duplicated copy that may infringe the intellectual property rights. The significant features of original videos are extracted and stored in the server. Given an uploaded video, the same feature is extracted and compared with the stored ones to seek a possible match. Both the spatial and temporal features of compressed videos are employed in the proposed scheme. The scene-change detection is applied to select the key frames, from which the robust spatial features are extracted to help search visually similar frames. The shot lengths are used as the temporal features to further ensure the matching accuracy. To ensure that the proposed method is practical in considered applications, the size of stored features in the server, efficiency and accuracy of matching features are the major design principles. The experimental results by testing a large number of compressed videos demonstrate the feasibility of the proposed scheme.
C1 [Su, Po-Chyi; Wu, Chin-Song] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taiwan.
C3 National Central University
RP Su, PC (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taiwan.
EM pochyisu@csie.ncu.edu.tw
RI SU, PO-CHYI/GWC-9682-2022
OI Su, Po-Chyi/0000-0002-7457-8409
FU Ministry of Science and Technology in Taiwan, ROC [MOST
   103-2221-E-008-080, MOST 104-2221-E-008-075]
FX This research is supported by the Ministry of Science and Technology in
   Taiwan, ROC, under Grants MOST 103-2221-E-008-080 and MOST
   104-2221-E-008-075.
CR Awad G, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2629531
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Ferman AM, 2002, IEEE T IMAGE PROCESS, V11, P497, DOI 10.1109/TIP.2002.1006397
   Gersho A., 2003, Vector Quantization and Signal Compression
   Hsu W, 1995, P ACM MULT
   Kang LW, 2010, IEEE INT CON MULTI, P1248, DOI 10.1109/ICME.2010.5582615
   Kashino K, 2003, IEEE T MULTIMEDIA, V5, P348, DOI 10.1109/TMM.2003.813281
   Katsavounidis I, 1994, IEEE SIGNAL PROC LET, V1, P144, DOI 10.1109/97.329844
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Ling HF, 2012, IEEE MULTIMEDIA, V19, P60, DOI 10.1109/MMUL.2011.75
   Liu H, 2013, IEEE T KNOWL DATA EN, V25, P1706, DOI 10.1109/TKDE.2012.92
   Liu JJ, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501658
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Su PC, 2009, IEEE T CIRC SYST VID, V19, P668, DOI 10.1109/TCSVT.2009.2017404
   Swain M, 1991, INT J COMPUT VIS, V7
   Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133, DOI 10.1109/76.825867
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   Wang T, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P590
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Wu P-H, 2009, IEEE INT C AC SPEECH
   Zargari F, 2010, IEEE T CONSUM ELECTR, V56, P728, DOI 10.1109/TCE.2010.5505994
   Zhou XM, 2009, IEEE T MULTIMEDIA, V11, P879, DOI 10.1109/TMM.2009.2021794
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 29
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1331
EP 1353
DI 10.1007/s11042-015-3132-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000058
DA 2024-07-18
ER

PT J
AU Jung, H
   Yoo, S
   Kim, D
   Park, S
AF Jung, Hyosook
   Yoo, Sujin
   Kim, Doyeon
   Park, Seongbin
TI A grammar based approach to introduce the Semantic Web to novice users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic Web; Grammar; Education
AB The Semantic Web is an extension of the Web where information is represented in a machine processable way. Since the idea of the Semantic Web was introduced in the late 1990's, many tools and applications that can be used on the Semantic Web have been developed and many people agree that it is relatively an ordered environment in which information units are hyperlinked according to their semantic relationships. On the other hand, there are still a group of users who do not even know the existence of the Semantic Web. The components of the Semantic Web include RDF (Resource Description Framework) documents, OWL (Web Ontology Language) ontologies, etc. and since the number of RDF documents has been increasing, it is not unusual that users encounter RDF documents while surfing the Web. In this paper, we propose an approach to introduce the Semantic Web to novice users. To this end, we have built an easy-to-use system that helps users create simple RDF documents and construct a small-scale Semantic Web like environment. Our system can take an input that a user provides and creates an RDF document and all that the user needs to do is define a string for the RDF document according to the grammar that we propose. Users can also define simple rules using the grammar and practice programming using RDF documents. We have experimented the proposed system with non-expert users who did not know the Semantic Web and experimental results indicated that they could have a concrete image about the Semantic Web even without knowing the technical details because they were able to create and modify RDF documents easily and they understood what is meant by representing information in a machine understandable way.
C1 [Jung, Hyosook; Yoo, Sujin; Kim, Doyeon; Park, Seongbin] Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.
C3 Korea University
RP Park, S (corresponding author), Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.
EM hyperspace@korea.ac.kr
FU College of Education, Korea University
FX This research was supported by the College of Education, Korea
   University Grant in 2013 and the corresponding author is Seongbin Park.
CR [Anonymous], IEEE T KNOWL DATA EN
   Antoniou Grigoris, 2004, A Semantic Web Primer
   Augusto JC, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-12
   Benlamri R, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0012-z
   Berners-Lee T., 2006, P 3 INT SEM WEB US I
   Berners-Lee T., 2001, The Semantic Web
   Bryant B. R., 1991, Proceedings of the Fifteenth Annual International Computer Software and Applications Conference (Cat. No.91CH3023-9), P155, DOI 10.1109/CMPSAC.1991.170167
   BRYANT BR, 2002, P 35 HAW INT C SYST
   Cho H, 2014, J CONVERGENCE
   EDUPUGANTY B, 1989, COMPUT J, V32, P36, DOI 10.1093/comjnl/32.1.36
   Ferre S, 2011, SEWELIS EXPLORING ED
   GAGNON E, 1998, P TECHN OBJ OR LANG
   Ge W, 2010, LNCS, V6098, P257
   Greibach S. A., 1974, International Journal of Computer & Information Sciences, V3, P289, DOI 10.1007/BF00978977
   Gupta P, 2013, J INF PROCESS SYST
   Han L, 2008, LNCS, V5318
   Hsueh HY, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-7
   Jeong J-S, 2014, J INF PROCESS SYST
   Kim J, 2013, J CONVERGENCE
   Mirizzi R, 2011, BREADCRUMS FOREST TO
   Onto M, 2013, J INF PROCESS SYST
   REYNOLDS F, 2001, P 2 INT WORKSH SEM W
   RODRIGUEZ MA, 2007, COMPUTING RES REPOSI
   Schraefel MC, 2007, NEWSLETTER ACM SIGWE
   Shin E, 2013, P DUTCH BELG WORKSH
   Sipser M., 2006, INTRO THEORY COMPUTA
   Vavliakis K. N., 2013, ORIGINAL RES ARTICLE, V86, P86
   Weng M, 2013, J CONVERGENCE
NR 28
TC 2
Z9 2
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15587
EP 15600
DI 10.1007/s11042-015-2898-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700029
DA 2024-07-18
ER

PT J
AU Kaur, H
   Khanna, P
AF Kaur, Harkeerat
   Khanna, Pritee
TI Biometric template protection using cancelable biometrics and visual
   cryptography techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric template protection; Cancelable biometrics; Biometric salting;
   Non-invertible transforms; Visual cryptography; Visual secret sharing
ID SECURITY; BIOHASH
AB Wide spread use of biometric based authentication implies the need to secure biometric reference data. Various template protection schemes have been introduced to prevent biometric forgery and identity thefts. Cancelable biometrics and visual cryptography are two recent technologies introduced to address the concerns regarding privacy of biometric data, and to improve public confidence and acceptance of biometric systems. Cancelable biometrics is an important technique that allows generation of revocable biometric templates. As the number of biometric instances are limited and once compromised they are lost forever. Cancelable biometrics allows templates to be cancelled and revoked like passwords innumerable times. Recently, various approaches that utilize visual cryptography to secure the stored template and impart privacy to the central databases have been introduced. This work attempts to summarize the existing approaches in literature making use of these two technologies to protect biometric templates.
C1 [Kaur, Harkeerat] PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur 482005, Madhaya Pradesh, India.
   [Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur 482005, Madhaya Pradesh, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Indian Institute of Information Technology Design &
   Manufacturing, Jabalpur
RP Khanna, P (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur 482005, Madhaya Pradesh, India.
EM harkeerat.kaur@iiitdmj.ac.in; pkhanna@iiitdmj.ac.in
RI Khanna, Pritee/V-5418-2019
OI Khanna, Pritee/0000-0003-0518-2133
CR Ang R, 2005, LECT NOTES COMPUT SC, V3574, P242
   [Anonymous], 2011 INT C HAND BAS
   [Anonymous], COMMUN ACM
   [Anonymous], 2012, INFORM KNOWLEDGE MAN
   [Anonymous], J COMPUT APPL
   [Anonymous], SPIE DEF SEC S
   [Anonymous], 2011, NEW TECHNOLOGIES DIG
   [Anonymous], 2009 BIOMETRICS
   [Anonymous], P 19 EUR SIGN P C EU
   [Anonymous], CONCURRENCY COMPUTAT
   [Anonymous], 2012, INT J SOFTW SCI COMP, DOI DOI 10.4018/jssci.2012070102
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], 2010, 25 INT C IMAGE VISIO, DOI DOI 10.1109/IVCNZ.2010.6148818
   [Anonymous], COMPUTERS SECURITY
   [Anonymous], 2007, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2007.383110
   [Anonymous], INT C SEC CRYPT SECR
   [Anonymous], 2009, CANCELABLE BIOMETRIC
   [Anonymous], EXTENDED VISUAL CRYP
   [Anonymous], BIOMETRICS METHODS A
   [Anonymous], INT J COMPUT APPL
   [Anonymous], BIOMETRIC TECHNOLOGY
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], 2010, ARXIV10041748
   [Anonymous], 2002, BIOMETRIC SYSTEM SEC
   [Anonymous], INT J COMMUNICATIONS
   [Anonymous], CIB 2009 IEEE
   [Anonymous], 2012, INT J EMERG TECHNOL
   [Anonymous], 2008, IEEE 19 INT C PATT R
   [Anonymous], INT J INFORM TECHNOL
   [Anonymous], VIS COMPUT
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Belguechi R., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P196, DOI 10.1109/ICB.2012.6199808
   Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3
   Bringer J, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P1, DOI 10.1109/BTAS.2007.4401904
   Bringer J, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P494
   Bringer J, 2008, SCI COMPUT PROGRAM, V74, P43, DOI 10.1016/j.scico.2008.09.016
   Cheung KH, 2005, CISST '05: PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY: COMPUTER GRAPHICS, P40
   Cheung KH, 2005, LECT NOTES ARTIF INT, V3683, P1168
   Chin CS, 2006, COMPUT VIS IMAGE UND, V102, P169, DOI 10.1016/j.cviu.2006.01.002
   Clancy T.C., 2003, P 2003 ACM SIGMM WOR, P45
   Connie T, 2005, INFORM PROCESS LETT, V93, P1, DOI 10.1016/j.ipl.2004.09.014
   Dacheng Xu, 2010, 2010 IEEE International Conference on Mechatronics and Automation (ICMA), P329, DOI 10.1109/ICMA.2010.5589066
   Canuto AMD, 2014, IET BIOMETRICS, V3, P29, DOI 10.1049/iet-bmt.2012.0032
   Dey N, 2013, IEEE INT ADV COMPUT, P732
   Fan TY, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.4.043018
   Farooq F., 2007, Conference Proceedings presented in Signal Processing and Its Applications, P1
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Gaddam SV., 2010, IJ NETWORK SECURITY, V11, P61
   Goh A, 2003, LECT NOTES COMPUT SC, V2828, P1
   Hämmerle-Uhl J, 2009, LECT NOTES COMPUT SC, V5735, P135, DOI 10.1007/978-3-642-04474-8_11
   Hao Feng, 2002, Information Management & Computer Security, V10, P159, DOI 10.1108/09685220210436949
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Hirano T, 2012, 2012 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS (ISITA 2012), P421
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Hua-Hong Zhu, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P560, DOI 10.1109/ICMLC.2012.6358984
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jeong M., 2006, 2006 BIOMETRICS S SP, P1
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Jin Teoh AndrewBeng., 2006, 9th International Conference on Control, Automation, Robotics and Vision, (ICARCV'06), P1, DOI DOI 10.1109/ICARCV.2006.345404
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Kanak A, 2009, LECT NOTES COMPUT SC, V5707, P276, DOI 10.1007/978-3-642-04391-8_36
   Kim Y., 2007, 1 INT C BIOMETRICS T, P1
   Kuan YW, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/59125
   Kümmel K, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P67
   Lalithamani N, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P47, DOI 10.1109/ARTCom.2009.193
   Lee C, 2010, J NETW COMPUT APPL, V33, P236, DOI 10.1016/j.jnca.2009.12.011
   Li HJ, 2012, PROCEDIA ENGINEER, V29, P1239, DOI 10.1016/j.proeng.2012.01.120
   Li Q., 2006, P 8 WORKSHOP MULTIME, P56
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Maiorana E, 2011, ANN IEEE SYST CONF, P495
   Maiorana E, 2010, IEEE T SYST MAN CY A, V40, P525, DOI 10.1109/TSMCA.2010.2041653
   Martinez-Diaz M, 2006, CAR C SECUR, P151, DOI 10.1109/CCST.2006.313444
   Monoth T, 2010, PROCEDIA COMPUT SCI, V2, P143, DOI 10.1016/j.procs.2010.11.018
   Nagar A, 2009, IEEE INT WORKS INFOR, P81, DOI 10.1109/WIFS.2009.5386477
   Nandakumar K, 2007, IEEE T INF FOREN SEC, V2, P744, DOI 10.1109/TIFS.2007.908165
   Nanni L, 2006, NEUROCOMPUTING, V69, P2390, DOI 10.1016/j.neucom.2006.05.001
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Othmani A., 2011, Proceedings of SilviLaser 2011, 11th International Conference on LiDAR Applications for Assessing Forest Ecosystems, University of Tasmania, Australia, 16-20 October 2011, P1
   Patel VM, 2010, I C CONT AUTOMAT ROB, P1, DOI 10.1109/ICARCV.2010.5707955
   Ratha N, 2006, INT C PATT RECOG, P370
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Roberts C, 2007, COMPUT SECUR, V26, P14, DOI 10.1016/j.cose.2006.12.008
   Ross A, 2011, IEEE T INF FOREN SEC, V6, P70, DOI 10.1109/TIFS.2010.2097252
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Shin SW, 2009, ETRI J, V31, P628, DOI 10.4218/etrij.09.0209.0137
   Simoens K., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P498, DOI 10.1109/ICB.2012.6199799
   Sinduja R., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P650
   Soutar C, 1998, P SOC PHOTO-OPT INS, V3314, P178, DOI 10.1117/12.304705
   Suryadevara S., 2011, 2011 2nd International Conference on Computer and Communication Technology, P412, DOI 10.1109/ICCCT.2011.6075146
   Sutcu Y., 2005, P 7 WORKSHOP MULTIME, P111
   Sutcu Y, 2007, IEEE T INF FOREN SEC, V2, P503, DOI 10.1109/TIFS.2007.902022
   Takahashi K., 2011, 2011 IEEE WORKSH COM, P145, DOI 10.1109/CIBIM.2011.5949210
   Teoh A, 2006, INFORM PROCESS LETT, V100, P145, DOI 10.1016/j.ipl.2006.06.010
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   Tulyakov S, 2005, LECT NOTES COMPUT SC, V3687, P30
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Vielhauer C, 2002, INT C PATT RECOG, P123, DOI 10.1109/ICPR.2002.1044628
   Wang YJ, 2007, 2007 BIOMETRICS SYMPOSIUM, P7, DOI 10.1109/ICDCS.2007.129
   Wu XQ, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1533, DOI 10.1109/IIH-MSP.2008.83
   Xi Chen, 2013, Intelligent Science and Intelligent Data Engineering. Third Sino-foreign-interchange Workshop, IScIDE 2012. Revised Selected Papers, P605, DOI 10.1007/978-3-642-36669-7_74
   Xu WH, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P412, DOI 10.1109/ISECS.2008.100
   Xu WH, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P826
   Yang W., 2013, CYBERSPACE SAFETY SE, P81, DOI DOI 10.1007/978-3-319-03584-0_7
   Yongjin Lee, 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P1818, DOI 10.1109/ICCIT.2007.372
NR 109
TC 35
Z9 35
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16333
EP 16361
DI 10.1007/s11042-015-2933-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700065
DA 2024-07-18
ER

PT J
AU Park, CS
   Kim, C
   Lee, J
   Kwon, GR
AF Park, Chun-Su
   Kim, Changjae
   Lee, Jihoon
   Kwon, Goo-Rak
TI Rotation and scale invariant upsampled log-polar fourier descriptor for
   copy-move forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forgery; Copy-move forgery; Upsampled log-polar Fourier
   features; Common processing pipeline
AB Digital image forgery is becoming increasingly popular with the rapid progress of digital media editing tools. Copy-move forgery (CMF) is one of the most common methods of digital image forgery. For CMF detection (CMFD), we propose an upsampled log-polar Fourier (ULPF) descriptor that is robust to several geometric transformations including rotation, scaling, sheering, and reflection. We first describe the theoretical background of the ULPF representation. Then, we propose a feature extraction algorithm that can extract rotation and scale invariant features from the ULPF representation. In addition, we analyze the common CMFD processing pipeline and improve a part of processing pipeline to efficiently handle various types of tampering attacks. In our simulation, we present comparative results between the proposed feature descriptor and state-of-the-art ones with proven performance guarantees.
C1 [Park, Chun-Su] Sejong Univ, Dept Software, Seoul 209, South Korea.
   [Kim, Changjae] Myongji Univ, Dept Civil & Environm Engn, Yongin 116, South Korea.
   [Lee, Jihoon] Sangmyung Univ, Dept Informat & Commun Engn, Cheonan 31, South Korea.
   [Kwon, Goo-Rak] Chosun Univ, Dept Informat & Commun Engn, Gwangju, South Korea.
C3 Sejong University; Myongji University; Sangmyung University; Chosun
   University
RP Kwon, GR (corresponding author), Chosun Univ, Dept Informat & Commun Engn, Gwangju, South Korea.
EM grkwon@chosun.ac.kr
RI Lee, Jihoon/AAE-6841-2019
OI Lee, Jihoon/0000-0003-3126-9005
CR Alexandre A, 2012, IEEE C COMPUT VISION, V1, P16
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2008, Using OpenMP: Portable Shared Memory Parallel Programming
   [Anonymous], INT J COMPUT SCI APP
   [Anonymous], INT C IM PROC ICIP
   [Anonymous], 2010, International Journal on Computer Science and Engineering
   [Anonymous], 2003, P DIG FOR RES WORKSH
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Christlein V, 2010, IEEE INT WORKS INFOR
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Kirchner M, 2015, PROC SPIE, V9409, DOI 10.1117/12.2082789
   Kwon GR, 2016, MULTIMED TOOLS APPL, V75, P6697, DOI 10.1007/s11042-015-2563-z
   Langille A., 2006, CRV '06: Proceedings of the The 3rd Canadian Conference on Computer and Robot Vision, Washington, DC, USA, IEEE Computer Society, P64, DOI DOI 10.1109/CRV.2006.9
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li WH, 2010, IEEE IMAGE PROC, P2113, DOI 10.1109/ICIP.2010.5652519
   Liu W, 2016, MULTIMED TOOLS APPL, V75, P1481, DOI 10.1007/s11042-014-2004-4
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo Y, 2016, IEEE T IMAGE PROCESS, V25, P414, DOI 10.1109/TIP.2015.2495116
   Luo Y, 2013, IEEE T IMAGE PROCESS, V22, P523, DOI 10.1109/TIP.2012.2218825
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Oppenheim A. V., 1999, DISCRETE TIME SIGNAL, DOI DOI 10.1049/EP.1977.0078
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Sekhar R., 2016, The International Conference on Soft Computing Systems, P223
   SORENSEN HV, 1987, IEEE T ACOUST SPEECH, V35, P849, DOI 10.1109/TASSP.1987.1165220
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wu QM, 2010, LECT NOTES ARTIF INT, V6421, P100, DOI 10.1007/978-3-642-16693-8_11
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Yaroslavsky L, 2000, SIGN PROC C, P1
NR 43
TC 14
Z9 14
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16577
EP 16595
DI 10.1007/s11042-016-3575-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700075
DA 2024-07-18
ER

PT J
AU You, SD
   Wu, YC
   Peng, SH
AF You, Shingchern D.
   Wu, Yi-Chung
   Peng, Shih-Hsien
TI Comparative study of singing voice detection methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MFCC; LPCC; HMM; vocal; bootstrapping; music identification
AB Detecting Singing segments in a segment of a soundtrack is an important and useful technique in musical signal processing and retrieval. In this paper, we study the accuracy of detecting singing segments using the HMM (Hidden Markov Model) classifier with various features, including MFCC (Mel Frequency Cepstral Coefficients), LPCC (Linear Predictive Cepstral Coefficients), and LPC (Linear Prediction Coefficients). Simulation results show that detecting singing segments in a soundtrack is more difficult than detecting them among pure-instrument segments. In addition, combining MFCC and LPCC yield higher accuracy. The bootstrapping technique has only limited accuracy improvement to detect all singing segments in a soundtrack. To be complete, we also conduct an experiment to show that the time to perform music identification can be reduced by more than 40 % if we incorporate the singing-voice detection mechanism into the identification process.
C1 [You, Shingchern D.; Wu, Yi-Chung; Peng, Shih-Hsien] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
C3 National Taipei University of Technology
RP You, SD (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
EM you@csie.ntut.edu.tw
RI You, Shingchern/AAG-6401-2020
FU National Science Council (NSC); Ministry of Science and Technology
   (MOST) of Taiwan [NSC 101-2221-E-027-127, MOST 103-2221-E-027-092]
FX This work was supported in part by National Science Council (NSC) and
   Ministry of Science and Technology (MOST) of Taiwan through Grants NSC
   101-2221-E-027-127 and MOST 103-2221-E-027-092.
CR [Anonymous], 1987, Speech communication: Human and machine
   Becchetti C., 1999, Speech Recognition, Theory and C++ Implementation
   Berenzweig AL, 2001, IEEE WORKSH APPL SIG, P21
   Cano P, 2005, J VLSI SIG PROC SYST, V41, P271, DOI 10.1007/s11265-005-4151-3
   Casey M, 2001, IEEE T CIRC SYST VID, V11, P737, DOI 10.1109/76.927433
   Casey MA, 2001, P WORKSH CONS REL AC, P167
   Cho H., 2014, J CONVERGENCE, V5, P32
   ISO/IEC, 2003, INF TECHN MULT CONT
   ISO/IEC, 2002, 159384 ISOIEC
   Lindsay P., 1977, Human information processing: an introduction to psychology, V2nd
   Lukashevich H, 2007, P 10 INT C DIG AUD E, P10
   Murrphy K, HIDDEN MARKOV MODEL
   New TL, 2004, P 12 ANN ACM INT C M, P1
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rocamora M, 2007, P 11 BRAZ S COMP MUS, P1
   Tzanetakis G, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2027, DOI 10.1109/ICME.2004.1394662
   Vembu S., 2005, P INT SOC MUS INF RE, P1
   Yoon SH, 2013, J INF PROCESS SYST, V9, P621, DOI 10.3745/JIPS.2013.9.4.621
   You SD, 2015, ACM T MULTIM COMPUT, V12, P22
   You SD, 2015, MULTIMED TOOLS APPL, V74, P3579, DOI 10.1007/s11042-013-1670-y
   You SD, 2013, SCI WORLD J, DOI 10.1155/2013/752464
NR 21
TC 10
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15509
EP 15524
DI 10.1007/s11042-015-2894-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700024
DA 2024-07-18
ER

PT J
AU Zhang, S
   Gao, TG
AF Zhang, Shun
   Gao, Tiegang
TI An image encryption scheme based on DNA coding and permutation of
   hyper-image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Hyper-image; DNA complementary rule; Hyper-chaotic
   system
ID SEQUENCE OPERATION; ALGORITHM; CHAOS
AB An image encryption algorithm based on substitution and permutation is proposed in this paper. The original image is encoded into DNA sequence and hyper-image respectively for better disposal. The encryption algorithm is composed of substitution in the DNA format and permutation in the hyper-image format, both of which have eliminated the relation between adjacent pixels in the image and adjacent bit planes in one pixel sufficiently. Besides, a random sequence generator based on the hyper-chaotic system is proposed, which has been utilized both in deciding the complementary 'nucleoside' in the substitution process and in constructing the hyper-image for the permutation process. Large quantities of experiments have demonstrated the validity and efficiency of the proposed scheme.
C1 [Zhang, Shun; Gao, Tiegang] Nankai Univ, Coll Software, Wei Jin Rd 94, Tianjin 300071, Peoples R China.
RP Zhang, S (corresponding author), Nankai Univ, Coll Software, Wei Jin Rd 94, Tianjin 300071, Peoples R China.
EM shentengvip@gmail.com
RI Gao, Tiegang/AAT-9599-2021
FU Key program of National Science Fund of Tianjin, China [11JCZDJC16000]
FX The work described in this paper was supported by Key program of
   National Science Fund of Tianjin, China (Grant NO. 11JCZDJC16000).
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   CRICK F, 1970, NATURE, V227, P561, DOI 10.1038/227561a0
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gao TG, 2006, INT J MOD PHYS C, V17, P471, DOI 10.1142/S0129183106008625
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Lian SG, 2009, NEUROCOMPUTING, V72, P1296, DOI 10.1016/j.neucom.2008.11.005
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Qian Wang, 2010, 2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA), P132, DOI 10.1109/BICTA.2010.5645338
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2012, INT J MOD PHYS B, V26, DOI 10.1142/S0217979212501755
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2012, SCI WORLD J, DOI 10.1100/2012/286741
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 25
TC 27
Z9 29
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17157
EP 17170
DI 10.1007/s11042-015-2982-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600020
DA 2024-07-18
ER

PT J
AU Hu, H
   Shen, G
   Fu, ZX
   Yu, B
   Wang, JJ
AF Hu, Hao
   Shen, Gang
   Fu, Zhengxin
   Yu, Bin
   Wang, Jingjing
TI General construction for XOR-based visual cryptography and its extended
   capability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Strong access structure; XOR operation; Perfect
   reconstruction; Region incrementing
ID RANDOM GRIDS; SCHEMES
AB A visual cryptography scheme (VCS) can be realized by Boolean operations OR and XOR, respectively. The monotone property of OR operation reduces the visual quality of recovered image. To overcome this problem, some advanced XOR based VCSs (VCSXOR) were further designed to provide some favorable features such as high contrast and good resolution. However, they are all confined to non-strong access structures. In this paper, we focus on strong access structures and propose a general construction of VCSXOR, which provides flexible sharing strategies, perfect reconstruction of secret image. Furthermore, a new region incrementing VCS based on XOR (RIVCSXOR) is presented, which exploits the proposed VCSXOR. Experimental results show that our schemes further enrich the application scenarios and outperform previous schemes significantly.
C1 [Hu, Hao; Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Peoples R China.
   [Shen, Gang; Fu, Zhengxin] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
   [Wang, Jingjing] Anhui Jimin Canc Hosp, Dept Radiol, Hefei, Anhui, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Hu, H (corresponding author), Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Peoples R China.; Shen, G (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
EM wjjhh_908@163.com; Shenqi0123@163.com
RI WANG, JINGYI/GSJ-1241-2022; wang, jing/GRS-7509-2022; Fu,
   Zhengxin/AAD-7881-2019
OI Fu, Zhengxin/0000-0001-8587-0942; Hu, Hao/0000-0003-4888-6368
FU Natural Science Foundation of China [61070086]; Foundation of Science
   and Technology on Information Assurance Laboratory of China [KJ-13-107]
FX This work was supported by Natural Science Foundation of China under
   Grant NO. 61070086 and Foundation of Science and Technology on
   Information Assurance Laboratory of China under Grant NO. KJ-13-107. The
   authors would like to thank the anonymous reviewers for their valuable
   comments.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Biham E, 1997, DAGST SEM CRYPT
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Ching-Nung Yang, 2011, Proceedings of the 2011 International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV 2011), P323
   De Bonis A, 2004, THEOR COMPUT SCI, V314, P351, DOI 10.1016/j.tcs.2003.12.018
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   Fu ZX, 2014, LECT NOTES COMPUT SC, V8389, P109, DOI 10.1007/978-3-662-43886-2_8
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lee YS, 2013, IET IMAGE PROCESS, V7, P137, DOI 10.1049/iet-ipr.2012.0338
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Shyu SJ, 2012, IEEE T CIRC SYST VID, V22, P769, DOI 10.1109/TCSVT.2011.2180769
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang RZ, 2009, IEEE SIGNAL PROC LET, V16, P659, DOI 10.1109/LSP.2009.2021334
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yu B, 2014, MULTIMED TOOLS APPL, V72, P1867, DOI 10.1007/s11042-013-1479-8
NR 25
TC 10
Z9 12
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13883
EP 13911
DI 10.1007/s11042-016-3250-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800047
DA 2024-07-18
ER

PT J
AU Kim, Y
AF Kim, Youngmo
TI Secure code design against collusion attacks for protecting digital
   content rights
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collusion-Secure; Forensic mark; BIBD; Balanced Incomplete Block Design
   (BIBD)
AB This paper proposes a group-based collusion-secure code design technique for protecting copyrights on digital contents. Designing collusion-secure codes were difficult and there were problems in creating these codes in large numbers, as these codes should enable detecting collusion attacks when occurring in content with inserted forensic marks. In addition, there was a problem in applying these codes to actual services in that unique user-specific codes could not be issued. This paper proposes group anti-collusion codes (ACCs) made by introducing the concept of groups to existing balanced incomplete block design (BIBD) matrices. This would solve the problem of complexity in code design and increase the number of collusion-secure codes. For the group ACCs, problems in securing the uniqueness and verification of codes were overcome using set operations. Using the group ACCs, code complexity can be reduced when compared to existing collusion-secure codes, and code quantities can be increased when compared to code lengths.
C1 [Kim, Youngmo] Soongsil Univ, Sch Comp Sci & Engn, 369 Sangdo Ro, Seoul 156743, South Korea.
C3 Soongsil University
RP Kim, Y (corresponding author), Soongsil Univ, Sch Comp Sci & Engn, 369 Sangdo Ro, Seoul 156743, South Korea.
EM ymkim828@ssu.ac.kr
OI Kim, Youngmo/0000-0003-1415-3908
CR Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Dittmann J, 2000, J ELECTRON IMAGING, V9, P456, DOI 10.1117/1.1287729
   Jiang XM, 2013, MULTIMED TOOLS APPL, V62, P545, DOI 10.1007/s11042-011-0857-3
   Korea Copyright Commission, 2010, COP TECHN DIG AG
   Korea Copyright Commission, 2010, CONT DISTR PATH RESP
   Lian SG, 2012, MULTIMED TOOLS APPL, V57, P49, DOI 10.1007/s11042-010-0521-3
   Poon HT, 2009, MULTIMED TOOLS APPL, V42, P161, DOI 10.1007/s11042-008-0232-1
   Stone H.S., 1996, ANAL ATTACKS IMAGE W
   Trappe W, 2003, IEEE T SIGNAL PROCES, V51, P1069, DOI 10.1109/TSP.2003.809378
   WAHADANIAH V, 2002, P IWDW, P88
   Wu M, 2004, IEEE SIGNAL PROC MAG, V21, P15
   Yoshioka K, 2003, LECT NOTES COMPUT SC, V2851, P408
NR 12
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14143
EP 14159
DI 10.1007/s11042-016-3242-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500009
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, D
   Qiao, LY
   Kim, J
AF Li, De
   Qiao, Luyan
   Kim, Jongweon
TI A video zero-watermarking algorithm based on LPM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermark; Discrete wavelet transform; Discrete cosine transform;
   Log-polar transform; Logistic Map Encryption
AB To resist geometrical attacks, the video zero watermarking algorithm based on log-polar transform presented in this paper. In our method, an original image transformed in logpolar coordinate after transformation of 2D DWT and 3D DCT. In experiment, the proposed method was evaluated the performance of resistance against attacks such as noise attack, rotation attack, compression attack and frame attack. The experiment results show that this algorithm can effectively resist against geometric attacks, and it has high robustness to the noise, filtering, compression and other common attacks. The bit error rate of the proposed algorithm is less than 0.06 for all tested attacks.
C1 [Li, De; Qiao, Luyan] Yanbian Univ, Dept Comp Sci, Yanji, Peoples R China.
   [Kim, Jongweon] Sangmyung Univ, Dept Contents & Copyright, Seoul, South Korea.
C3 Yanbian University; Sangmyung University
RP Kim, J (corresponding author), Sangmyung Univ, Dept Contents & Copyright, Seoul, South Korea.
EM leader1223@ybu.edu.cn; leslie1295615290@163.com; jwkim@smu.ac.kr
RI Kim, Jongweon/AAO-2221-2020
OI Kim, Jongweon/0000-0002-8916-6431
FU Ministry of Culture, Sports and Tourism (MCST); Korea Copyright
   Commission
FX This research project was supported by the Ministry of Culture, Sports
   and Tourism (MCST) and the Korea Copyright Commission in 2014.
CR [Anonymous], 2009, MATLAB WAVELET ANAL
   Chang HT, 2005, APPL OPTICS, V44, P6211, DOI 10.1364/AO.44.006211
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   He B., 2010, MICROCOMPUTER APPL, V31, P1
   Hu Yu-feng, 2008, Journal of Zhejiang University, V42, P593
   Pu Peng-cheng, 2008, Computer Engineering, V34, P198
   Ruan B, 2008, THESIS, P19
   Ten Daubechies I., 1992, lecture on wavelets
   Wanhong N, 2009, APPL COMPUT SYST, V18, P66
   Wen Q., 2003, CHINESE J ELECTRON, V1, P214
   [徐达文 XU Da-wen], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P1825
   [徐涛 XU Tao], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P1819
   [杨树国 Yang Shuguo], 2003, [中国图象图形学报. A, Journal of image and graphics], V8, P664
   Yu Bo, 2008, Journal of Computer Applications, V28, P3126
   Zhang C, 2007, THESIS, P21
   Zhao HY, 2011, COAL TECHNOL, V30, P164
   [周支元 Zhou Zhiyuan], 2010, [微计算机信息, Microcomputer Information.], V26, P82
NR 17
TC 8
Z9 8
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13093
EP 13106
DI 10.1007/s11042-015-2733-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800007
DA 2024-07-18
ER

PT J
AU Hwang, TG
   Park, CS
   Hong, JH
   Kim, SK
AF Hwang, Tae-Gyu
   Park, Chan-Soo
   Hong, Jeong-Hwa
   Kim, Sung Kwon
TI An algorithm for movie classification and recommendation using genre
   correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative filtering; Genre correlation; Movie classification; Movie
   recommendation
AB Collaborative filtering (CF), a technique used by recommendation systems, predicts and recommends items (information, products or services) that the user might like. Amazon.com's recommender system is one of the most famous examples of CF. Recommendation systems are popular in both commercial and research sectors, and they are applied in a variety of applications such as movies, music, books, social connections and venues. In particular, movie recommendation systems produce personal recommendations for movies. Existing CF algorithms employed in movie recommendation systems predict the unknown rating of a given user for a movie using only the ratings (i.e., preferences) of other like-minded users who have seen the movie. In such approaches, there exist certain limits in improving the accuracy of recommendation systems. This paper proposes an algorithm for movie recommendation that exploits the genre of the movie to enhance the accuracy of rating predictions. The proposed algorithm 1) numerically measures the correlation between movie genres using movie rating information; 2) classifies movies using the genre correlations and generates a list of recommended movies for the target user with the classified movies; and finally 3) predicts the ratings of the movies in the list using traditional CF algorithms. The experimental results show that the proposed algorithm yields higher accuracy in movie rating predictions than existing movie recommendation algorithms.
C1 [Hwang, Tae-Gyu; Park, Chan-Soo; Hong, Jeong-Hwa; Kim, Sung Kwon] Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
C3 Chung Ang University
RP Kim, SK (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
EM tghwang@alg.cse.cau.ac.kr; cspark@alg.cse.cau.ac.kr;
   jhhong@alg.cse.cau.ac.kr; skkim@cau.ac.kr
OI Hwang, Tae-Gyu/0000-0002-6887-2409
FU National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [NRF-2015R1D1A1A01059937]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (NRF-2015R1D1A1A01059937).
CR [Anonymous], 2005, Proceedingsofthe14th ACM International Conference on Information and Knowledge Management. CIKM '05, DOI DOI 10.1145/1099554.1099689
   Bell RM, 2008, STAT RES DEP AT T RE
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Cacheda F, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921593
   Choi SM, 2012, EXPERT SYST APPL, V39, P8079, DOI 10.1016/j.eswa.2012.01.132
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   I-Chin Wu, 2013, Human Interface and the Management of Information. Information and Interaction for Learning, Culture, Collaboration and Business. 15th International Conference, HCI International 2013. Proceedings: LNCS 8018, P639, DOI 10.1007/978-3-642-39226-9_70
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Santos E.B., P ACM S APPL COMP GY, P919, DOI [10.1145/2554850.2555017, DOI 10.1145/2554850.2555017]
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Soares M, 2015, MULTIMED TOOLS APPL, V74, P7015, DOI 10.1007/s11042-014-1950-1
   Zheng QR, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P702, DOI 10.1109/WI-IAT.2012.70
NR 13
TC 18
Z9 22
U1 7
U2 76
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12843
EP 12858
DI 10.1007/s11042-016-3526-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700032
DA 2024-07-18
ER

PT J
AU Nguyen, TV
   Sepulveda, J
AF Nguyen, Tam V.
   Sepulveda, Jose
TI Augmented immersion: video cutout and gesture-guided embedding for
   gaming applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive system; Human computer interaction; Gaming applications
AB This paper introduces a novel framework, Gesture and Appearance Cutout Embedding (GACE), that supports real-time integration of human appearance and gesture-guided control within a game. It aims to enhance immersion since it allows game users to see their personal appearance in a real-time manner. In addition, we exploit the gesture-based control to allow user interaction with other in-game characters. With the goal to make implementation easier, we address the challenges in the whole pipeline of video processing, gesture recognition, and communication. The system is successfully integrated into both entertainment and serious games. Extensive experiments show that the proposed system runs reliably and comfortably with a commodity setting. Meanwhile, the user impression study indicates our system is favored by end users.
C1 [Nguyen, Tam V.; Sepulveda, Jose] Singapore Polytech, ARTIC Ctr, Singapore 139651, Singapore.
C3 Singapore Polytechnic
RP Nguyen, TV (corresponding author), Singapore Polytech, ARTIC Ctr, Singapore 139651, Singapore.
EM vantam@gmail.com; sepulveda_jose@sp.edu.sg
RI Nguyen, Tam/AAU-6504-2020; Nguyen, Tam/HSG-3007-2023
OI Nguyen, Tam/0000-0003-0236-7992; 
FU Singapore Ministry of Education [MOE2012-TIF-2-G-016]
FX This work was supported by Singapore Ministry of Education under
   research Grant MOE2012-TIF-2-G-016.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], 2007, Journal of Applied Educational Technology
   [Anonymous], ACM MULTIMEDIA
   Cavazza M, 2004, IEEE MULTIMEDIA, V11, P30, DOI 10.1109/MMUL.2004.11
   Chambel T, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1255, DOI 10.1145/2647868.2647875
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Henry P., 2014, RGB-D Mapping: Using Depth Cameras for Dense 3D Modeling of Indoor Environments, P477, DOI [DOI 10.1007/978-3-642-28572-1_33, DOI 10.1007/978-3-642-28572-1, 10.1007/978-3-642-28572-133]
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Jorg S., 2012, Proceedings of the ACM Symposium on Applied Perception, SAP '12, P33, DOI DOI 10.1145/2338676.2338683
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Lange Belinda, 2011, Virtual and Mixed Reality - Systems and Applications. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P243, DOI 10.1007/978-3-642-22024-1_27
   Likert R., ARCH PSYCHOL, P1
   Lu J. B., 2011, ACM MULTIMEDIA, P1309
   Nguyen TV, 2014, J COMPUT SCI TECH-CH, V29, P777, DOI 10.1007/s11390-014-1467-0
   Nguyen TV, 2014, P 2 ACM INT WORKSH I, P41
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Soltani F., 2012, 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), P491, DOI 10.1109/CISIS.2012.55
   Tangade SS, 2012, ANNU IEEE IND CONF, P525
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Yang YL, 2011, PROC IEEE MICR ELECT, P79, DOI 10.1109/MEMSYS.2011.5734366
NR 23
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12351
EP 12363
DI 10.1007/s11042-016-3435-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700005
DA 2024-07-18
ER

PT J
AU Szczuko, P
AF Szczuko, Piotr
TI Simple gait parameterization and 3D animation for anonymous visual
   monitoring based on augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual monitoring; Gait; Privacy; Augmented reality; Computer animation
ID MOTION CAPTURE; RECOGNITION; FRAMEWORK; TRACKING
AB The article presents a method for video anonymization and replacing real human silhouettes with virtual 3D figures rendered on a screen. Video stream is processed to detect and to track objects, whereas anonymization stage employs animating avatars accordingly to behavior of detected persons. Location, movement speed, direction, and person height are taken into account during animation and rendering phases. This approach requires a calibrated camera, and utilizes results of visual object tracking. A procedure for transforming objects visual features and bounding boxes into gait parameters for animated figures is presented. Conclusions and future work perspectives are provided.
C1 [Szczuko, Piotr] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Szczuko, P (corresponding author), Gdansk Univ Technol, Fac Elect Telecommun & Informat, Gdansk, Poland.
EM szczuko@sound.eti.pg.gda.pl
RI Szczuko, Piotr/AAB-4822-2020
OI Szczuko, Piotr/0000-0003-3703-8734
FU ARTEMIS Joint Undertaking; Polish National Centre of Research and
   Development as a part of the COPCAMS project [332913]
FX This work has been partially funded by the ARTEMIS Joint Undertaking and
   the Polish National Centre of Research and Development as a part of the
   COPCAMS project (http://copcams.eu) under Grant Agreement No. 332913.
CR Anders MJ, 2010, BLENDER 2 49 SCRIPTI
   [Anonymous], 1996, METHODS SUBJECTIVE D
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   Atrey PK, 2011, MULTIMED TOOLS APPL, V51, P697, DOI 10.1007/s11042-010-0649-1
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   Bratt Benjamin, 2011, ROTOSCOPING TECHNIQU
   Cederberg JN, 2001, UNDERGRADUATE TEXTS, P213
   Cichowski J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1971, DOI 10.1109/ICCVW.2011.6130490
   Czyewski A., 2011, VIDEO SURVEILLANCE, P145, DOI [10.5772/16088, DOI 10.5772/16088]
   Dalka Piotr, 2006, Machine Graphics & Vision, V15, P339
   Dalka P, 2010, SMART INNOV SYST TEC, V3, P241
   Gao T, 2012, MULTIMED TOOLS APPL, V58, P1, DOI 10.1007/s11042-010-0676-y
   Ghazal M, 2012, MULTIMED TOOLS APPL, V58, P585, DOI 10.1007/s11042-011-0751-z
   Goffredo M, 2010, MULTIMED TOOLS APPL, V50, P75, DOI 10.1007/s11042-009-0378-5
   Guo CS, 2014, MULTIMED TOOLS APPL, V72, P2633, DOI 10.1007/s11042-013-1566-x
   Höferlin B, 2011, MULTIMED TOOLS APPL, V55, P127, DOI 10.1007/s11042-010-0606-z
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Kakadiaris I, 2000, IEEE T PATTERN ANAL, V22, P1453, DOI 10.1109/34.895978
   Kehl R, 2006, COMPUT VIS IMAGE UND, V104, P190, DOI 10.1016/j.cviu.2006.07.010
   Kotus J, 2013, SIG P ALGO ARCH ARR, P100
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   Kriechbaum A, 2010, MULTIMED TOOLS APPL, V50, P7, DOI 10.1007/s11042-009-0366-9
   Krolewski J, 2011, MAN MACH INTERACT, V2
   Lalos C, 2014, MULTIMED TOOLS APPL, V69, P277, DOI 10.1007/s11042-012-0994-3
   LAVEAU S, 1996, LECT NOTES COMPUTER, V1064, P147
   Lavee G, 2007, MULTIMED TOOLS APPL, V35, P109, DOI 10.1007/s11042-007-0117-8
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Moshkovitz M, 2000, VIRTUAL STUDIO TECHN
   Mullen T., 2012, MASTERING BLENDER, V2nd ed.
   Novaes RD, 2011, REV BRAS FISIOTER, V15, P117, DOI 10.1590/S1413-35552011000200006
   Ntalianis KS, 2010, MULTIMED TOOLS APPL, V50, P199, DOI 10.1007/s11042-009-0369-6
   PETS, 2006, IEEE C COMP VIS PATT
   Roth D, 2010, MULTIMED TOOLS APPL, V50, P29, DOI 10.1007/s11042-009-0365-x
   Ruminski D, 2013, BUS INF SYST WORKSH
   Samangooei S, 2010, MULTIMED TOOLS APPL, V49, P195, DOI 10.1007/s11042-009-0391-8
   Schreer O, 2005, 3D VIDEOCOMMUNICATION: ALGORITHMS, CONCEPTS AND REAL-TIME SYSTEMS IN HUMAN CENTRED COMMUNICATION, P1, DOI 10.1002/0470022736
   Simon C, 2010, MULTIMED TOOLS APPL, V50, P95, DOI 10.1007/s11042-009-0364-y
   Szczuko P, 2014, MULTIMED TOOLS APPL, V68, P177, DOI 10.1007/s11042-012-1147-4
   Szczuko P, 2011, COMM COM INF SC, V149, P82
   Szwoch G, 2011, WIAMIS 2011 12 INT W
   Szwoch G, 2013, J IMAGING SCI TECHN, V57, DOI 10.2352/J.ImagingSci.Technol.2013.57.2.020507
   Szwoch G, 2011, INTELL DECIS TECHNOL, V5, P177, DOI 10.3233/IDT-2011-0105
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   University of Maryland, GUID AUTH MED GROUND
   Uustal H., 2004, PHYS MED REHABILITAT
   Wikitude, AUGM REAL PLATF DOC
NR 48
TC 1
Z9 1
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10561
EP 10581
DI 10.1007/s11042-015-2874-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800022
DA 2024-07-18
ER

PT J
AU Zhao, SC
   Yao, HX
   Zhao, SD
   Jiang, XS
   Jiang, XL
AF Zhao, Sicheng
   Yao, Hongxun
   Zhao, Sendong
   Jiang, Xuesong
   Jiang, Xiaolei
TI Multi-modal microblog classification via multi-task learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microblog classification; Multi-modal classification; Multi-task
   learning; Structural regularization; Social media analysis
ID IMAGE; RETRIEVAL
AB Recent years have witnessed the flourishing of social media platforms (SMPs), such as Twitter, Facebook, and Sina Weibo. The rapid development of these SMPs has resulted in increasingly large scale multimedia data, which has been proved with remarkable marketing values. It is in an urgent need to classify these social media data into a specified list of concerned entities, such as brands, products, and events, to analyze their sales, popularity or influences. But this is a rather challenging task due to the shortness, conversationality, the incompatibility between images and text, and the data diversity of microblogs. In this paper, we present a multi-modal microblog classification method in a multi-task learning framework. Firstly features of different modalities are extracted for each microblog. Specifically, we extract TF-IDF features for each microblog text and low-level visual features and high-level semantic features for each microblog image. Then multiple related classification tasks are learned simultaneously for each feature to increase the sample size for each task and improve the prediction performance. Finally the outputs of each feature are integrated by a Support Vector Machine that learns how to optimally combine and weight each feature. We evaluate the proposed method on Brand-Social-Net to classify the contained 100 brands. Experimental results demonstrate the superiority of the proposed method, as compared to the state-of-the-art approaches.
C1 [Zhao, Sicheng; Yao, Hongxun; Zhao, Sendong; Jiang, Xuesong; Jiang, Xiaolei] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
C3 Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
EM zsc@hit.edu.cn; h.yao@hit.edu.cn; sdzhao@hit.edu.cn; xsjiang@hit.edu.cn;
   xljiang@hit.edu.cn
FU National Natural Science Foundation of China [61472103]; Ph.D.
   Short-Term Overseas Visiting Scholar Program of Harbin Institute of
   Technology;  [61133003]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61472103) and Key Program (No. 61133003). Sicheng Zhao was
   also supported by the Ph.D. Short-Term Overseas Visiting Scholar Program
   of Harbin Institute of Technology.
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], LEARNING THEORY KERN
   [Anonymous], ADVANCES IN NEURAL I
   [Anonymous], 2012, INT J COMPUT VISION, DOI DOI 10.1007/s11263-011-0472-9
   [Anonymous], FRONTIER FUTURE DEV
   [Anonymous], INT C MULT MOD
   [Anonymous], ACM T INTEL IN PRESS
   [Anonymous], MULTIMODAL GENDER CL
   [Anonymous], 2009, PROGR NATURAL SCI
   [Anonymous], 2013, IET INT RADAR C 2013, DOI DOI 10.1049/CP.2013.0307
   [Anonymous], DEIM FORUM
   [Anonymous], SIGNAL PROCESSING
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], 2012, MALSAR: Multi-tAsk Learning via StructurAl Regularization
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], ACM INT C MULT
   [Anonymous], INT AAAI C WEBL SOC
   [Anonymous], P 5 ACM C MULT SYST
   [Anonymous], THESIS
   Argyriou A., 2007, NIPS, P41
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Bickel S., 2008, P 25 INT C MACH LEAR, P56
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Chen C., 2011, SIGMOD, P649, DOI DOI 10.1145/1989323.1989391
   Chen MY, 2004, ACM-IEEE J CONF DIG, P212
   Chen Y., 2012, P 24 INT C COMPUTATI, P561
   Chunmei Gu, 2012, 2012 International Conference on Business Computing and Global Informatization (BCGIN), P537, DOI 10.1109/BCGIN.2012.146
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dunker Peter, 2008, P ACM INT C MULT INF, P97
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gaonkar S, 2008, MOBISYS'08: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P174
   Gong Pinghua, 2012, KDD, V2012, P895
   Gray KR, 2013, NEUROIMAGE, V65, P167, DOI 10.1016/j.neuroimage.2012.09.065
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nagmoti Rinkesh, 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P153, DOI 10.1109/WI-IAT.2010.170
   Naveed Nasir., 2011, Proceedings of the 20th ACM international conference on Information and knowledge management, P183
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pronobis A., 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2394, DOI 10.1109/IROS.2007.4399493
   Pronobis A, 2010, INT J ROBOT RES, V29, P298, DOI 10.1177/0278364909356483
   Reuter T., 2012, PROC ANN ACM INT C M, P22
   Rowlands T., 2010, P 19 INT C WORLD WID, P1293
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Skowron A, 2006, LECT NOTES COMPUT SC, V4100, P224
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sui Yue, 2010, 2010 Second International Conference on Communication Systems, Networks and Applications (ICCSNA 2010), P164, DOI 10.1109/ICCSNA.2010.5588676
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang YH, 2008, LECT NOTES COMPUT SC, V5353, P70, DOI 10.1007/978-3-540-89796-5_8
   Yang Y, 2014, INFORM SCIENCES, V281, P601, DOI 10.1016/j.ins.2014.03.016
   Zhao S., 2013, INT C MULT MOD MMM 2, P7732, DOI DOI 10.1007/978-3-642-35725-1_34
   Zhou Jiayu, 2012, KDD, V2012, P1095
   Zhou Jiayu, 2011, P 17 ACM SIGKDD INT, P814, DOI DOI 10.1145/2020408.2020549
NR 57
TC 25
Z9 26
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8921
EP 8938
DI 10.1007/s11042-014-2342-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500006
DA 2024-07-18
ER

PT J
AU Roudaki, A
   Kong, J
   Reetz, S
AF Roudaki, Amin
   Kong, Jun
   Reetz, Shane
TI SmartCamera: a low-cost and intelligent camera management system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic camera management; Video conferencing; 3D camera
ID GESTURE
AB Intelligent camera management systems were developed to automatically record meetings for videoconferencing. These systems provided many benefits, such as reducing the production cost and conveniently documenting events. However, automatically recorded videos in general were not visually engaging. This paper presents a novel approach that intelligently controls camera shots and angles to improve the visual interest. We use 3D infrared images captured by a Kinect sensor to recognize active speakers and their positions in a meeting. A movable camera, constructed by placing a wireless PTZ (pan-tilt-zoom) camera on top of a motorized rail, can automatically move its position to frame an active speaker in the center of the screen. Without interrupting the meeting, a speaker can seamlessly switch video sources through gesture-based commands. We have summarized and implemented a set of heuristic rules to simulate a human director. These rules can be visually edited through a graphical user interface. The customization of a virtual director makes our system applicable in various scenarios. We conducted a user study, and the evaluation results justified the quality of an automated video.
C1 [Roudaki, Amin; Kong, Jun; Reetz, Shane] North Dakota State Univ, Dept Comp Sci, Fargo, ND 58102 USA.
C3 North Dakota State University Fargo
RP Kong, J (corresponding author), North Dakota State Univ, Dept Comp Sci, Fargo, ND 58102 USA.
EM amin.roudaki@ndsu.edu; jun.kong@ndsu.edu; shane.reetz@ndsu.edu
FU NSF [CNS-1126570]
FX We thank the volunteer participants in this investigation. The authors
   would like to thank the anonymous reviewers for their insightful and
   constructive comments that helped to significantly improve the
   presentation. This work is in part supported by NSF under grant
   CNS-1126570.
CR [Anonymous], 2002, P 10 ACM INT C MULTI
   [Anonymous], 1998, P JOINT DARPA NIST S
   Basili V.R., 1994, Technical Report
   Brandstein M., 2001, MICROPHONE ARRAYS SI
   Cutler R., 2002, MULTIMEDIA 02, P503, DOI DOI 10.1145/641007.641112
   Foote J., 2000, ACM MULTIMEDIA, P487
   GADANAC D, 2014, P MIPRO, P485
   Heck R, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198306
   Howell A. J., 2002, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop, GW 2001. Revised Papers (Lecture Notes in Artificial Intelligence Vol.2298), P272
   Inoue T., 1995, Eighth Annual Symposium on User Interface Software and Technology. UIST '95. Proceedings of the ACM Symposium on User Interface Software and Technology, P147, DOI 10.1145/215585.215967
   Jones A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531370
   Kuney Jack., 1990, TAKE ONE TELEVISION
   Lee Dar-Shyang., 2002, P 10 ACM INT C MULT, P493
   Motlicek P, 2013, ADV MULTIMED, V2013, DOI 10.1155/2013/175745
   Mukhopadhyay S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P477, DOI 10.1145/319463.319690
   Nagai T., 2009, P 37 ANN ACMSIGUCCS, P47
   Nickel K., 2005, Proceedings of the ACM International Conference on Multimodal Interfaces, P61
   Norris James, 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P627, DOI 10.1145/2207676.2207765
   Poltrock S. E., 1997, GROUP '97. Proceedings of the International ACM SIGGROUP Conference on Supporting Group Work. The Integration Challenge, P61, DOI 10.1145/266838.266862
   Qiong Liu, 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P442
   Ranjan A., 2006, Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work, CSCW '06, P403
   Ranjan A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P227
   Ranjan Abhishek., 2010, Proceedings of Graphics Interface 2010. GI '10, P47
   Ronzhin AL, 2010, LECT NOTES COMPUT SC, V6294, P102, DOI 10.1007/978-3-642-14891-0_10
   Rubin AM., 2002, MEDIA EFFECTS ADV TH, P525, DOI DOI 10.4324/9780429491146
   Rui Y., 2003, ACM CHI, P457
   Rui Yong., 2001, Proceedings of the SIGCHI conference on Human factors in computing systems, P450
   Song MS, 2011, IEEE T MULTIMEDIA, V13, P844, DOI 10.1109/TMM.2011.2162581
   Suau X, 2012, IEEE T MULTIMEDIA, V14, P575, DOI 10.1109/TMM.2012.2189853
   Takahashi M, 2013, MULTIMED TOOLS APPL, V62, P761, DOI 10.1007/s11042-011-0870-6
   Tang John., 2012, P SIGCHI C HUMAN FAC, P3111, DOI DOI 10.1145/2207676.2208725
   Wang F, 2008, IEEE T MULTIMEDIA, V10, P926, DOI 10.1109/TMM.2008.922871
   Wang F, 2007, IEEE T MULTIMEDIA, V9, P397, DOI 10.1109/TMM.2006.886292
   Williamson B.M., 2012, Proceedings of the Interservice/Industry Training, Simulation, and Education Conference (I/ITSEC) 2012, P1727, DOI DOI 10.1016/J.JPAA.2010.12.013
   Yu ZW, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1667062.1667065
   Zhang J. R., 2012, P 20 ACM INT C MULTI, P1389, DOI [10.1145/2393347.23964991,2, DOI 10.1145/2393347.23964991,2]
NR 36
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7831
EP 7854
DI 10.1007/s11042-015-2700-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600018
DA 2024-07-18
ER

PT J
AU Shah, AJ
   Gupta, SB
AF Shah, Amisha J.
   Gupta, Suryakant B.
TI Adaptive directional decomposition in non sub sample contourlet
   transform domain for single image super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super resolution; Non sub sampled contourlet transform;
   Edge smoothness prior
ID SUPERRESOLUTION
AB The crucial point of research about single-image super-resolution is to enhance the size of an image without fiddle its quality. To conserve the quality of an enhanced image, a novel learning based approach in Non Sub Sampled Contourlet Transform (NSCT) domain is proposed in this paper. The NSCT constitute multiscale -multidirectional decomposition of an image. An algorithm, proposed for adaptive multidirectional decomposition picks up the optimal benefit of the directionality offered by NSCT. A sharp initialization, obtained via learning in NSCT domain, is able to generate a high resolution image with minimum edge artifacts. Experiments on various images show the effectiveness of the proposed algorithm.
C1 [Shah, Amisha J.] CKPCET, Surat, India.
   [Gupta, Suryakant B.] Inst Plasma Res, FCIPT, Gandhinagar, India.
C3 Institute for Plasma Research (IPR)
RP Shah, AJ (corresponding author), CKPCET, Surat, India.
EM amisha.janak@gmail.com; guptasuryakant@yahoo.com
RI Gupta, Suryakant/ABA-5950-2020
CR Aguena M. L. S., 2011, Proceedings of the 2011 24th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2011), P258, DOI 10.1109/SIBGRAPI.2011.17
   [Anonymous], NOVEL IMAGE FUSION M
   [Anonymous], 2013, INT J COMPUT APPL, DOI [10.5120/10735-5580, DOI 10.5120/10735-5580]
   Ashikaga H, 2014, IEEE J TRANSL ENG HE, V2, DOI 10.1109/JTEHM.2014.2303806
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chan TM, 2009, PATTERN RECOGN LETT, V30, P494, DOI 10.1016/j.patrec.2008.11.008
   Dai SY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1039
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Fan W., 2007, Proc. of the CVPR, P1, DOI DOI 10.1109/CVPR.2007.383001
   Hong Yu, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P494, DOI 10.1049/cp:20080364
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Liu XT, 2008, PROC WRLD ACAD SCI E, V27, P208
   Lu Y, 2006, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2006.312657
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Matsuo Y, 2013, IEEE INT SYM MULTIM, P279, DOI [10.1109/ISM.2013.53, 10.7763/IJCTE.2013.V5.693]
   Ogawa T, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/852934
   Rushdi M, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P262, DOI 10.1109/ICMLA.2012.52
   Su K, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P1123
   Tang Y, 2011, INT J MACH LEARN CYB, V2, P15, DOI 10.1007/s13042-011-0011-6
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Xie Qinlan, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1204, DOI 10.1109/CISP.2010.5647223
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MC, 2013, IEEE T MULTIMEDIA, V15, P498, DOI 10.1109/TMM.2012.2232646
   Zhang HY, 2012, SIGNAL PROCESS, V92, P2082, DOI 10.1016/j.sigpro.2012.01.020
   Zhang J, 2012, IEEE INT SYMP CIRC S, P1688
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 29
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8443
EP 8467
DI 10.1007/s11042-015-2765-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300014
DA 2024-07-18
ER

PT J
AU Zhang, XF
   Yang, S
   Tang, YY
   Zhang, WS
AF Zhang, Xinfeng
   Yang, Su
   Tang, Yuan Yan
   Zhang, Weishan
TI A thermodynamics-inspired feature for anomaly detection on crowd motions
   in surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Boltzmann Entropy; Crowd; Collective behavior; Abnormal event detection;
   Anomaly detection
ID ABNORMAL EVENT DETECTION; BEHAVIOR DETECTION; SCENES; MODEL
AB Identification of abnormal behaviors in surveillance videos of crowds plays an important role in public security monitoring. However, detecting abnormal crowd behaviors is challenging in that movements of individuals are usually random and unpredictable, and the occlusions caused by over-crowding make the task more difficult. In this paper, we introduce thermodynamic micro-statistics theory to detect and localize abnormal behaviors in crowded scenes based on Boltzmann Entropy. For this purpose, the scene of interest is modeled as moving particles turned out from a general optical flow algorithm. The particles are grouped into a set of prototypes according to their speeds and directions of moving, and a histogram is established to figure out how the particles distribute over the prototypes. Here, Boltzmann Entropy is computed from the histogram for each video clip to characterize the chaos degree of crowd motion. By means of such feature extraction, the crowd motion patterns can be represented as a time series. We find that when most people behave anomaly in an area under surveillance, the corresponding entropy value will increase remarkably in comparison with those of normal cases. This motives us to make use of Boltzmann Entropy to distinguish the collective behaviors of people under emergent circumstances from their normal behaviors by evaluating how significantly the current feature value fits into the Gaussian model of normal cases. We validate our method extensively for anomaly detection and localization. The experimental results show promising performance compared with the state of the art methods.
C1 [Zhang, Xinfeng; Yang, Su] Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Coll Comp Sci, Shanghai 201203, Peoples R China.
   [Tang, Yuan Yan] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
   [Zhang, Weishan] China Univ Petr, Dept Software Engn, Qingdao 266580, Peoples R China.
C3 Fudan University; University of Macau; China University of Petroleum
RP Yang, S (corresponding author), Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Coll Comp Sci, Shanghai 201203, Peoples R China.
EM 10110240026@fudan.edu.cn; suyang@fudan.edu.cn; yytang@umac.mo;
   zhangws@upc.edu.cn
RI liu, sha/JXL-6600-2024; Zhang, Xinfeng/X-8148-2019
FU NSFC [61472087]
FX This work is supported by NSFC under grant No. 61472087.
CR Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], IM PROC ICIP 2012 19
   [Anonymous], P 1 ACM INT WORKSH M
   [Anonymous], FUNDAMENTALS PHYS
   [Anonymous], 2015, AAAI C ART INT
   [Anonymous], ROB BIOM ROBIO 2009
   Basharat A, 2008, PROC CVPR IEEE, P1301
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gu XX, 2014, OPTIK, V125, P3428, DOI 10.1016/j.ijleo.2014.01.041
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Helbing D, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046109
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nam Y, 2014, MULTIMED TOOLS APPL, V72, P3001, DOI 10.1007/s11042-013-1593-7
   Pathan SS, 2011, LECT NOTES COMPUT SC, V6468, P370
   Raghavendra R., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P136, DOI 10.1109/ICCVW.2011.6130235
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Susan S, 2015, SIGNAL IMAGE VIDEO P, V9, P511, DOI 10.1007/s11760-013-0464-z
   Tu P, 2008, LECT NOTES COMPUT SC, V5305, P691, DOI 10.1007/978-3-540-88693-8_51
   Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Wu S, 2014, IEEE T CIRC SYST VID, V24, P85, DOI 10.1109/TCSVT.2013.2276151
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   Xiong GG, 2012, NEUROCOMPUTING, V83, P121, DOI 10.1016/j.neucom.2011.12.007
   Yang S, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P465, DOI 10.1109/ICCIAS.2006.294178
NR 32
TC 14
Z9 15
U1 0
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8799
EP 8826
DI 10.1007/s11042-015-3101-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300030
DA 2024-07-18
ER

PT J
AU Bano, S
   Cavallaro, A
AF Bano, Sophia
   Cavallaro, Andrea
TI ViComp: composition of user-generated videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video composition; User-generated videos; Audio-visual analysis; Camera
   selection; Subjective evaluation
ID QUALITY ASSESSMENT; STATISTICS; IMAGES
AB We propose ViComp, an automatic audio-visual camera selection framework for composing uninterrupted recordings from multiple user-generated videos (UGVs) of the same event. We design an automatic audio-based cut-point selection method to segment the UGV. ViComp combines segments of UGVs using a rank-based camera selection strategy by considering audio-visual quality and camera selection history. We analyze the audio to maintain audio continuity. To filter video segments which contain visual degradations, we perform spatial and spatio-temporal quality assessment. We validate the proposed framework with subjective tests and compare it with state-of-the-art methods.
C1 [Bano, Sophia; Cavallaro, Andrea] Queen Mary Univ London, Ctr Intelligent Sensing, London E1 4NS, England.
C3 University of London; Queen Mary University London
RP Bano, S (corresponding author), Queen Mary Univ London, Ctr Intelligent Sensing, London E1 4NS, England.
EM s.bano@qmul.ac.uk; a.cavallaro@qmul.ac.uk
OI Bano, Sophia/0000-0003-1329-4565
FU Erasmus Mundus Joint Doctorate in Interactive and Cognitive Environments
   - Education, Audiovisual and Culture Executive Agency (FPA) [2010-0012];
   UK Engineering and Physical Science Research Council (EPSRC)
   [EP/K007491/1]; EPSRC [EP/K007491/1] Funding Source: UKRI
FX S. Bano was supported by the Erasmus Mundus Joint Doctorate in
   Interactive and Cognitive Environments, which is funded by the
   Education, Audiovisual and Culture Executive Agency (FPA no. 2010-0012).
   The authors acknowledge the support of the UK Engineering and Physical
   Science Research Council (EPSRC), under grant EP/K007491/1.
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   Almeida J, 2009, LECT NOTES COMPUT SC, V5875, P435, DOI 10.1007/978-3-642-10331-5_41
   [Anonymous], 1999, SUBJ VID QUAL ASS ME
   [Anonymous], 2001, INTERSPEECH
   Arev I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601198
   Bano S, 2014, ELSEVIER INFORM SCI, V302, P108
   Beerends JG, 1999, J AUDIO ENG SOC, V47, P355
   Bowen ChristopherJ., 2013, Grammar of the Edit
   Campanella M, 2007, ELECT IMAGING, V6506
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   Daniyal F, 2010, MULTIMED TOOLS APPL, V46, P235, DOI 10.1007/s11042-009-0355-z
   Dickson PE, 2009, ITICSE 2009: PROCEEDING OF THE 2009 ACM SIGSE ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P298, DOI 10.1145/1595496.1562968
   Dmytryk Edward., 1984, ON FILM EDITING
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Giannakopoulos T., 2009, STUDY APPL ACOUSTIC
   Hochberg Yosef, 1987, Multiple comparison procedures
   Hua X.S., 2003, P 11 ACM INT C MULTI, P490
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P572, DOI 10.1109/TCSVT.2004.826750
   Israel D., 2009, Data Analysis in Business Research: A Step-By-Step Nonparametric Approach
   Kenney JF, 1962, MATH STAT 1
   Lerch A, 2012, INTRO AUDIDO CONTENT
   Lu Lie., 2001, Proceedings of the ninth ACM international conference on Multimedia, P203
   Mei T, 2007, IEEE T CIRC SYST VID, V17, P699, DOI 10.1109/TCSVT.2007.896640
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nagasaka A., 1999, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ82D-II, P1572
   Ranjan Abhishek., 2010, Proceedings of Graphics Interface 2010. GI '10, P47
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saini M.K., 2012, Proceedings of the 20th International Conference on Multimedia, P139, DOI DOI 10.1145/2393347.2393373
   Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129
   Schubert E., 2004, Proceedings of the international conference on music perception and cognition, North Western University, Illinois, P112
   Schuller B., 2013, INTELLIGENT AUDIO AN, V1, P17
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Shrestha P., 2010, Proceedings of the international conference on Multimedia (MM '10), P541, DOI DOI 10.1145/1873951.1874023
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Suthaharan S, 2009, SIGNAL PROCESS, V89, P1647, DOI 10.1016/j.sigpro.2009.02.007
   Wang JJ, 2008, MULTIMEDIA SYST, V14, P179, DOI 10.1007/s00530-008-0112-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilk S, 2014, P IEEE INT C MULT EX, P1
   Winkler MB, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P471, DOI 10.1109/ISM.2012.96
   Yu ZW, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1667062.1667065
   Zettl H., 2011, SIGHT SOUND MOTION A, V6th
   Zhang J, 2011, SIGNAL PROCESS-IMAGE, V26, P13, DOI 10.1016/j.image.2010.11.003
NR 43
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7187
EP 7210
DI 10.1007/s11042-015-2641-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400024
OA hybrid
DA 2024-07-18
ER

PT J
AU Oh, JM
   Hong, SJ
   Moon, N
AF Oh, Jung-Min
   Hong, Sangjin
   Moon, Nammee
TI Embedded intention scripts representation and real-time interpretation
   metrics extraction methodology with gaze annotation on visual content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Embedded intention representation; Multi-dimensional analysis;
   Evaluation metric tree; Gaze behavior tracking; Content usage profiling
ID BEHAVIORAL INTENTION
AB This paper proposes a system platform with a capability of analyzing and measuring the degree of similarities and differences of the gaze behaviors of the multiple users with the intention of the provider in real-time. In the proposed system platform, a video content incorporates the intention flow script, which describes the intended sequence and duration of the information embedded into the visual content. The video content also incorporates the intention weight script for assigning importance values to individual object information so that the significance of the gaze behavior can be assesses. In this paper, a set of evaluation metrics and their usages are defined, which can be used to evaluate the degree of gazing behavior closeness and deviation from the intention. The proposed method can be applied in many applications, such as in educational and commercial domains, where the information contents are usually designed with a specific intent. In the paper, we verified the proposed method by incorporation intention script into a sequence of educational image frames to analyze the gaze behavior of multiple users.
C1 [Oh, Jung-Min; Hong, Sangjin] SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
   [Moon, Nammee] Hoseo Univ, Dept Comp Engn, Asan 336795, South Korea.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; Hoseo University
RP Moon, N (corresponding author), Hoseo Univ, Dept Comp Engn, Asan 336795, South Korea.
EM nammee01@gmail.com
FU 'Cross-Ministry Giga KOREA Project' of the Ministry of Science, ICT and
   Future Planning, Republic of Korea (ROK) [GK15P0100]
FX This research was supported by the 'Cross-Ministry Giga KOREA Project'
   of the Ministry of Science, ICT and Future Planning, Republic of Korea
   (ROK) [GK15P0100, Development of Tele-Experience Service SW Platform
   based on Giga Media].
CR [Anonymous], 2010, EYE TRACKING RES APP, DOI [DOI 10.1145/1743666.1743703, 10.1145/1743666.1743703]
   [Anonymous], 1999, Intention, Plans, and Practical Reason
   Bock GW, 2005, MIS QUART, V29, P87, DOI 10.2307/25148669
   Buscher G, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P42
   CASTAGNOS S, 2010, IUI, P1
   Chua HF, 2005, P NATL ACAD SCI USA, V102, P12629, DOI 10.1073/pnas.0506162102
   Dumais SusanT., 2010, Proceedings of IIiX, P185, DOI [DOI 10.1145/1840784.1840812, 10.1145/1840784.1840812]
   Eivazi S., 2012, P S EYE TRACK RES AP, P377, DOI [DOI 10.1145/2168556, 10.1145/2168556.2168641, DOI 10.1145/2168556.2168641]
   Hasse Catrin., 2012, Proceedings of the Symposium on Eye Tracking Research and Applications, ETRA '12, P409, DOI DOI 10.1145/2168556.2168649
   Komogortsev OV, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1386109.1386116
   Kuo YF, 2009, COMPUT HUM BEHAV, V25, P103, DOI 10.1016/j.chb.2008.07.007
   Lagun D, 2014, P 37 INT ACM SIGIR C
   Lin JCC, 2000, INT J INFORM MANAGE, V20, P197, DOI 10.1016/S0268-4012(00)00005-0
   Mei T, 2007, IEEE T MULTIMEDIA, V9, P66, DOI 10.1109/TMM.2006.886357
   Oh JM, 2016, MULTIMED TOOLS APPL, V75, P15211, DOI 10.1007/s11042-014-2285-7
   Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218
   Shard B., 2012, P S EYE TRACK RES AP, P381
   Sharma K., 2014, P EUR MOOCS STAK SUM, P1
   Yoshitaka A, 2007, LECT NOTES COMPUT SC, V4351, P126
NR 19
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7271
EP 7291
DI 10.1007/s11042-015-2644-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400027
DA 2024-07-18
ER

PT J
AU Zhang, C
   Hou, CP
   Wang, XY
   Wang, ZY
AF Zhang, Cheng
   Hou, Chunping
   Wang, Xiaoyan
   Wang, Zhiyuan
TI A setup for panoramic stereo imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Panoramic image; Stereo image; Image stitching
ID VIDEO; SYSTEM; IMAGES
AB In this paper, based on the proposed basic implementation of circular projection, a multi-camera setup which can be used for panoramic stereo imaging is presented. Firstly, we get multiple stereo pairs instantly by fixing multiple cameras on the proposed setup, which is an approximate implementation of circular projection. We then prove that the influence on the resultant stereo pairs generated by this approximate setup is slight based on similar triangles and structural similarity (SSIM). With these stereo pairs, the automatic panoramic image stitching algorithm is applied to generate panoramas for both eyes. In addition, with reasonable distance between cameras and the scene, physical dimensions of this setup are given. Finally, experimental results demonstrate that our scheme can be used to generate cylindrical stereo panoramic image with proper scene depth, which can provide viewers with distinguishing stereoscopic experience. The device can be installed on the mobile equipment and captures panoramic stereo image in a moment without stopping. In the future, the proposed setup can be used in the field of network navigation, video monitor and virtual reality.
C1 [Zhang, Cheng; Hou, Chunping; Wang, Xiaoyan; Wang, Zhiyuan] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Zhang, Cheng] Tianjin Nav Instrument Res Inst, Sci & Technol Dev Dept, Tianjin 300131, Peoples R China.
C3 Tianjin University
RP Hou, CP (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM zhangchengtju707@foxmail.com; hcp@tju.edu.cn
RI zhou, chuyue/JOJ-9001-2023; Wang, Zhiyuan/GLT-1605-2022
OI Wang, Zhiyuan/0000-0002-1611-2053
FU National Natural Science Foundation of China [61471262]; National 863
   Program [2012AA03A301]; Ph.D. Programs Foundation of Ministry of
   Education of China [20110032110029, 20130032110010]; Key Projects in the
   Tianjin Science & Technology Pillar Program [11ZCKFGX02000]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61471262, by National 863 Program (No. 2012AA03A301),
   and by Ph.D. Programs Foundation of Ministry of Education of China (No.
   20110032110029, 20130032110010) and Key Projects in the Tianjin Science
   & Technology Pillar Program (grant 11ZCKFGX02000).
CR [Anonymous], 2010, P INT S EXP ROB ISER
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Cha JH, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P29, DOI 10.1109/ICCE.2012.6161723
   Chakareski J, 2013, IEEE COMMUN MAG, V51, P94, DOI 10.1109/MCOM.2013.6515052
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Cyganek B., 2011, INTRO 3D COMPUTER VI
   Du X, 2013, SPIE OPTICAL ENG APP
   Fahmy AA, 2013, INT J VIDEO IMAGE PR, V13, P1
   Gu FF, 2013, SPIE OPTICAL METROLO
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Jang G, 2006, OPT LETT, V31, P41, DOI 10.1364/OL.31.000041
   JIANG W., 2006, CVPR '06 : Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P371
   Jung JI, 2014, J VIS COMMUN IMAGE R, V25, P698, DOI 10.1016/j.jvcir.2013.04.008
   Kang T, 2013, INT J ADV ROBOT SYST, V10, P799
   Kumara WGCW, 2013, INT CONF ADV ICT, P8, DOI 10.1109/ICTer.2013.6761148
   Laganiere Robert, 2010, Machine Graphics & Vision, V19, P339
   Noguera JM, 2014, COMPUTER GRAPHICS FO
   Peer P, 2002, INT J COMPUT VISION, V47, P149, DOI 10.1023/A:1014541807682
   Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880
   Seo D, 2014, MULTIMEDIA SYST, V20, P707, DOI 10.1007/s00530-013-0333-1
   Svoboda T., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P218, DOI 10.1007/BFb0055669
   Tong RF, 2013, IEEE T VIS COMPUT GR, V19, P1375, DOI 10.1109/TVCG.2012.319
   Tzavidas S, 2005, IEEE T MULTIMEDIA, V7, P880, DOI 10.1109/TMM.2005.854430
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 24
TC 1
Z9 2
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6945
EP 6962
DI 10.1007/s11042-015-2621-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400013
DA 2024-07-18
ER

PT J
AU Zhang, T
   Yang, ZJ
   Jia, WJ
   Yang, BQ
   Yang, J
   He, XJ
AF Zhang, Tao
   Yang, Zhijie
   Jia, Wenjing
   Yang, Baoqing
   Yang, Jie
   He, Xiangjian
TI A new method for violence detection in surveillance scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Violence detection; Surveillance scenes; Gaussian
   model of optical flow (GMOF); Orientation histogram of optical flow
   (OHOF)
ID RECOGNITION; BEHAVIOR; REPRESENTATION; PROPAGATION; SPACE
AB Violence detection is a hot topic for surveillance systems. However, it has not been studied as much as for action recognition. Existing vision-based methods mainly concentrate on violence detection and make little effort to determine the location of violence. In this paper, we propose a fast and robust framework for detecting and localizing violence in surveillance scenes. For this purpose, a Gaussian Model of Optical Flow (GMOF) is proposed to extract candidate violence regions, which are adaptively modeled as a deviation from the normal behavior of crowd observed in the scene. Violence detection is then performed on each video volume constructed by densely sampling the candidate violence regions. To distinguish violent events from nonviolent events, we also propose a novel descriptor, named as Orientation Histogram of Optical Flow (OHOF), which are fed into a linear SVM for classification. Experimental results on several benchmark datasets have demonstrated the superiority of our proposed method over the state-of-the-arts in terms of both detection accuracy and processing speed, even in crowded scenes.
C1 [Zhang, Tao; Yang, Zhijie; Yang, Baoqing; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 800 Dongchuan Rd, Shanghai 200000, Peoples R China.
   [Jia, Wenjing; He, Xiangjian] Univ Technol Sydney, Fac Engn & Informat Technol, POB 123, Sydney, NSW 2007, Australia.
C3 Shanghai Jiao Tong University; University of Technology Sydney
RP Zhang, T; Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 800 Dongchuan Rd, Shanghai 200000, Peoples R China.
EM zhb827@sjtu.edu.cn; jieyang@sjtu.edu.cn
RI Yang, Jie/JCD-9867-2023; Jia, Weijia/W-6152-2019; Yang,
   Zhijie/ACH-5951-2022; He, Xiangjian/CAA-1461-2022
OI Yang, Zhijie/0000-0003-1905-9742; He, Xiangjian/0000-0001-8962-540X;
   Jia, Wenjing/0000-0002-0940-3338
FU NSFC, China [61273258, 61105001]
FX This research is partly supported by NSFC, China (No: 61273258,
   61105001).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 10 IEEE PAC RIM C MU
   [Anonymous], 2009, MOSIFT RECOGNIZING H
   [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], P SPIE
   [Anonymous], 1999, INTEL CORPORATION MI
   [Anonymous], IEEE WORKSH MOT VID
   [Anonymous], 2005, DOVE DETECTION MOVIE
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen DT, 2008, IEEE ENG MED BIO, P5238, DOI 10.1109/IEMBS.2008.4650395
   Cheng W.-H., 2003, P 5 ACM SIGMM INT WO, P109, DOI DOI 10.1145/973264.973282
   Cristani M, 2007, IEEE T MULTIMEDIA, V9, P257, DOI 10.1109/TMM.2006.886263
   Cupillard F, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P177, DOI 10.1109/ACV.2002.1182178
   Dai P, 2008, IEEE T SYST MAN CY B, V38, P275, DOI 10.1109/TSMCB.2007.909939
   Damen D, 2009, PROC CVPR IEEE, P927, DOI 10.1109/CVPRW.2009.5206636
   Datta A, 2002, INT C PATT RECOG, P433, DOI 10.1109/ICPR.2002.1044748
   de Souza F. D. M., 2010, Proceedings of the 23rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2010), P224, DOI 10.1109/SIBGRAPI.2010.38
   Gong SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P742, DOI 10.1109/ICCV.2003.1238423
   Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492
   Gupta Abhinav., 2007, CVPR
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Huesmann LR, 2003, DEV PSYCHOL, V39, P201, DOI 10.1037/0012-1649.39.2.201
   Intille SS, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P518
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Minnen D, 2003, PROC CVPR IEEE, P626
   Moore D, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P770
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Nevatia R., 2003, P C COMP VIS PATT RE, V4, P39
   Nguyen NT, 2005, PROC CVPR IEEE, P955
   Oikonomopoulos A, 2007, LECT NOTES COMPUT SC, V4451, P133
   Oliver N, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P3, DOI 10.1109/ICMI.2002.1166960
   Pinhanez CS, 1998, PROC CVPR IEEE, P898, DOI 10.1109/CVPR.1998.698711
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Ryoo MS, 2009, INT J COMPUT VISION, V82, P1, DOI 10.1007/s11263-008-0181-1
   Shechtman E, 2005, PROC CVPR IEEE, P405
   Shi YF, 2004, PROC CVPR IEEE, P862
   Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42
   Vishwakarma S., 2011, IEEE INT C SIGNAL PR, P1
   Wang H., 2009, BMVC
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yu E, 2006, INT C PATT RECOG, P375
   Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735
   Zhang JM, 2007, 2007 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY: ENHANCING CRITICAL INFRASTRUCTURE DEPENDABILITY, P64, DOI 10.1109/WI-IATW.2007.84
NR 47
TC 82
Z9 84
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7327
EP 7349
DI 10.1007/s11042-015-2648-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400029
DA 2024-07-18
ER

PT J
AU Mao, JF
   Niu, XX
   Xiao, G
   Sheng, WG
   Zhang, NN
AF Mao Jia-Fa
   Niu Xin-Xin
   Xiao Gang
   Sheng Wei-Guo
   Zhang Na-Na
TI A steganalysis method in the DCT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Fisher linear discriminate analysis; AC coefficient
   energy; AC coefficient statistical characteristic
ID IMAGE
AB In this paper, we propose a steganalysis method based on the principle of additive operator, which chooses non-zero AC coefficients as carriers, with secret information independent of the carrier information flow. In the proposed method, AC coefficient statistical and energy features are initially extracted and used to construct a 3D feature vector. By employing the principle of Fisher linear discriminate analysis, a flexible discriminate classifier suitable for the extracted features is designed to improve detection performance. We infer and confirm theory of change in the statistical and energetic characteristics of the AC coefficient before and after additive steganography. The effectiveness of the proposed method is proven by the experiments. Moreover, the proposed method consistently outperforms related methods.
C1 [Mao Jia-Fa; Xiao Gang; Sheng Wei-Guo] ZheJiang Univ Technol, Coll Comp Sci & Technol, Liuhe Rd 180, Hangzhou 310023, Zhejiang, Peoples R China.
   [Niu Xin-Xin] Beijing Univ Posts & Telecommun, Informat Secur Ctr, Beijing 100876, Peoples R China.
   [Zhang Na-Na] Shanghai Jianqiao Univ, Dept Informat Technol, Shanghai 201315, Peoples R China.
C3 Zhejiang University of Technology; Beijing University of Posts &
   Telecommunications
RP Mao, JF (corresponding author), ZheJiang Univ Technol, Coll Comp Sci & Technol, Liuhe Rd 180, Hangzhou 310023, Zhejiang, Peoples R China.
EM maojia@zjut.edu.cn; xxniu@bupt.edu.cn; xg@zjut.edu.cn;
   wsheng@zjut.edu.cn; nanazhang2004@163.com
FU National Natural Science Foundation of China [61170271, 61272310,
   61203288]; ZheJiang province Natural Science Foundation of China
   [LY15F020032, LY12F02031]
FX The authors thank Jiangqun Ni research team in Sun Yat-sen University,
   China, they provide EBS steganography tool software. This work is
   supported by the National Natural Science Foundation of China (No.
   61170271, 61272310, 61203288) and the ZheJiang province Natural Science
   Foundation of China (No. LY15F020032, LY12F02031).
CR [Anonymous], ADV COMPUTER SCI ENG
   Awrangjeb M, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P717
   Bian ZQ, 2005, PATTERN RECOGN, P87
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Chen GM, 2014, MULTIMED TOOLS APPL, V71, P497, DOI 10.1007/s11042-013-1522-9
   Cheng Q, 2001, IEEE T MULTIMEDIA, V3, P273, DOI 10.1109/6046.944472
   Dai Zhonghua, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P415, DOI 10.1109/IIH-MSP.2012.107
   Fridrich J, 2005, MULTIMEDIA SYST, V11, P98, DOI 10.1007/s00530-005-0194-3
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Giannoula A, 2006, IEEE T CIRCUITS-II, V53, P359, DOI 10.1109/TCSII.2006.870213
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hou XD, 2014, SIGNAL PROCESS-IMAGE, V29, P385, DOI 10.1016/j.image.2014.01.006
   Jafari R, 2013, EXPERT SYST APPL, V40, P6918, DOI 10.1016/j.eswa.2013.06.008
   Lee YK, 2006, IASTED INT CONF SIGN, P201
   Li B, 2009, IEEE T INF FOREN SEC, V4, P369, DOI 10.1109/TIFS.2009.2025841
   Lie WN, 2005, IEEE T MULTIMEDIA, V7, P1007, DOI 10.1109/TMM.2005.858377
   Lin YK, 2014, COMPUT STAND INTER, V36, P855, DOI 10.1016/j.csi.2013.12.013
   Lingyun X, 2014, MULTIMEDIA TOOLS APP, V71
   Liu QZ, 2013, APPL INTELL, V39, P705, DOI 10.1007/s10489-013-0430-z
   Liu QZ, 2010, INFORM SCIENCES, V180, P1643, DOI 10.1016/j.ins.2010.01.001
   Ogihara T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P675, DOI 10.1109/ICPR.1996.546908
   Ou ZH, 2014, INFORM SCIENCES, V276, P343, DOI 10.1016/j.ins.2013.12.024
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Wang C, 2012, INT CONF ACOUST SPEE, P1785, DOI 10.1109/ICASSP.2012.6288246
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yang HJ, 2007, IEEE T MULTIMEDIA, V9, P475, DOI 10.1109/TMM.2006.887990
   Yu LF, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-014-5106-8
NR 33
TC 6
Z9 7
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5999
EP 6019
DI 10.1007/s11042-015-2708-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600030
DA 2024-07-18
ER

PT J
AU Zeng, L
   Liu, RR
   Zhang, LY
   Liu, YS
   Wong, KW
AF Zeng, Li
   Liu, Renren
   Zhang, Leo Yu
   Liu, Yuansheng
   Wong, Kwok-Wo
TI Cryptanalyzing an image encryption algorithm based on scrambling and
   Veginere cipher
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image scrambling; Cryptanalysis; Known-plaintext attack;
   Chosen-plaintext attack
ID ONLY MULTIMEDIA CIPHERS; QUANTITATIVE CRYPTANALYSIS; SCHEME; CHAOS;
   SECURITY
AB Recently, an image encryption algorithm based on scrambling and Veginere cipher has been proposed. However, it was soon cryptanalyzed by Zhang et al. using a method composed of both chosen-plaintext attack and differential attacks. This paper briefly reviews the two attack approaches proposed by Zhang et al. and outlines their mathematical interpretations. Based on these approaches, we present an improved chosen-plaintext attack to further reduce the number of chosen-plaintexts required, which is proved to be optimal. Moreover, it is found that an elaborately designed known-plaintext attack can efficiently compromise the image cipher under study. This finding is confirmed by both mathematical analysis and numerical simulations. The cryptanalyzing techniques developed in this paper provide some insights for designing secure and efficient multimedia ciphers.
C1 [Zeng, Li; Liu, Renren; Liu, Yuansheng] Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Hunan, Peoples R China.
   [Zhang, Leo Yu; Wong, Kwok-Wo] City Univ Hong Kong, Dept Elect Engn, Kowloon Tong, Hong Kong, Peoples R China.
C3 Xiangtan University; City University of Hong Kong
RP Zeng, L (corresponding author), Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Hunan, Peoples R China.
EM lily173864258@gmail.com
RI Liu, Yuansheng/GSM-8000-2022; Zhang, Leo Yu/K-2043-2013
OI Zhang, Leo Yu/0000-0001-9330-2662
CR Alvarez G, 2004, PHYS LETT A, V326, P211, DOI 10.1016/j.physleta.2004.04.018
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2002, Introduction to Cryptography with Coding Theory
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   BIHAM E, 1991, LECT NOTES COMPUT SC, V537, P2
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen Y, 2006, IEEE T CIRCUITS-II, V53, P527, DOI 10.1109/TCSII.2006.875319
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Ji S., 2012, ADV DIFFER EQU, V2012, P1, DOI DOI 10.1016/J.CAGE0.2012.01.004
   Kim H, 2011, IEEE T CIRC SYST VID, V21, P1733, DOI 10.1109/TCSVT.2011.2138850
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Li SJ, 2003, COMPUT PHYS COMMUN, V153, P52, DOI 10.1016/S0010-4655(02)00875-5
   Li WH, 2009, IEEE SYS MAN CYBERN, P3694, DOI 10.1109/ICSMC.2009.5346875
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Riad AM, 2012, P 8 INT C INF SYST I, P36
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Yang YG, 2015, SCI REP-UK, V5, DOI 10.1038/srep07784
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang LY, 2012, J SYST SOFTWARE, V85, P2077, DOI 10.1016/j.jss.2012.04.002
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YS, 2014, MULTIMED TOOLS APPL, V73, P1885, DOI 10.1007/s11042-013-1684-5
   Zhang YS, 2014, NONLINEAR DYNAM, V78, P235, DOI 10.1007/s11071-014-1435-9
NR 28
TC 12
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5439
EP 5453
DI 10.1007/s11042-015-2511-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhao, J
   Li, ZT
   Feng, B
AF Zhao, Juan
   Li, Zhi-Tang
   Feng, Bing
TI A novel two-dimensional histogram modification for reversible data
   embedding into stereo H.264 video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data embedding; Reversible data hiding; Histogram
   modification; Stereo H.264 video
ID GENERALIZED INTEGER TRANSFORM; PREDICTION-ERROR EXPANSION; FRAME
   DISTORTION DRIFT; DATA HIDING ALGORITHM; DIFFERENCE EXPANSION; LOSSLESS
   WATERMARKING; SCHEME; ROBUST; AUTHENTICATION; CONCEALMENT
AB Histogram modification (HM) is an efficient technique for reversible data embedding (RDE) into stereo H.264 video. Nevertheless, in the traditional HM, the value of a coefficient is singly modified for embedding data, i.e., the relationships among coefficients are not considered. In this paper, to make full use of the correlation between two coefficients, we present a novel two-dimensional (2D) HM strategy for stereo H.264 video. Firstly, two quantized discrete cosine transform (QDCT) alternating current (AC) coefficients are randomly selected from each embeddable 4x4 luminance block. The values of coefficient pairs are classified into nonoverlapping sets. According to the sets of coefficient pairs, the generated 2D histogram is modified to embed data. When the value of one QDCTAC coefficient is modified by adding or subtracting 1, only one data bit at most could be hidden by using the traditional HM, whereas up to three bits of information can be simultaneously embedded by employing the proposed scheme. The better capacity-distortion performance of the proposed strategy is proved by experiments.
C1 [Zhao, Juan; Li, Zhi-Tang; Feng, Bing] Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Li, ZT (corresponding author), Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
EM lzt@hust.edu.cn
FU National Natural Science Foundation of China [61272407, 61370230]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61272407 and 61370230).
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   [Anonymous], 2013, VIDEO TEST SEQUENCES
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Hsu FH, 2013, MULTIMED TOOLS APPL, V67, P571, DOI 10.1007/s11042-012-1047-7
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Jawad K, 2013, J SYST SOFTWARE, V86, P2742, DOI 10.1016/j.jss.2013.06.023
   Jeni M, 2013, REVERSIBLE DATA HIDI
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu YC, 2011, MULTIMED TOOLS APPL, V52, P263, DOI 10.1007/s11042-010-0496-0
   Liu YX, 2014, MULTIMED TOOLS APPL, V72, P613, DOI 10.1007/s11042-013-1393-0
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YJ, 2013, OPTIK, V124, P3827, DOI 10.1016/j.ijleo.2012.11.078
   Lin SFD, 2007, ELE COM ENG, P112
   Suhring K, 2012, H 264 AVC SOFTWARE C
   Thabit R, 2014, J SYST SOFTWARE, V88, P74, DOI 10.1016/j.jss.2013.09.033
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang CT, 2012, MULTIMED TOOLS APPL, V61, P299, DOI 10.1007/s11042-011-0838-6
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Xu DW, 2014, J VIS COMMUN IMAGE R, V25, P410, DOI 10.1016/j.jvcir.2013.12.008
   Zeng XA, 2011, J INF SCI ENG, V27, P465
   Zeng XA, 2011, MULTIMED TOOLS APPL, V52, P465, DOI 10.1007/s11042-010-0476-4
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 40
TC 14
Z9 19
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5959
EP 5980
DI 10.1007/s11042-015-2558-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600028
DA 2024-07-18
ER

PT J
AU Zhou, RJ
   Khemmarat, S
   Gao, LX
   Wan, J
   Zhang, JL
AF Zhou, Renjie
   Khemmarat, Samamon
   Gao, Lixin
   Wan, Jian
   Zhang, Jilin
TI How YouTube videos are discovered and its impact on video views
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YouTube; View sources; View diversity; View growth; Recommendation
   system; Referrer videos; Search; Highlight
ID POPULARITY
AB As the largest video sharing site around the world, YouTube has been changing the way people entertain, gain popularity, and advertise. Discovering the major sources that drive views to a video and understanding how they impact the view growth pattern have become interesting topics for researchers as well as advertisers, media companies, or anyone who wish to have a shortcut to stardom. The work of this paper is to identify three major view sources, related video recommendation, YouTube search, and video highlight such as popular video list on YouTube homepage or video embedding on social networking sites, and examine the patterns of views from each view source. First, the impact of each view source on the view diversity and on the view share of each individual video is analyzed. It is found that while search and highlight create an effect of rich-get-richer, the related video recommendation equalizes the view distribution and helps users find niche videos. Second, the contribution of the three view sources to video popularity growth is investigated. The investigation reveals that search and related video recommendation are the two major sources that persistently drive views to a video. The view rates from recommendation and search are generally stabilized to be constant view rates. Third, the underlying factors that affect the long-term view rate from referrer videos are explored. The results indicate that the top referrer video set of a video is fairly stable and the view rate from recommendation is mainly determined by view rates of top referrer videos. Finally, whether highlight increases the view rate of a video after the duration of promotion is studied. The observations suggest that video highlight does not directly impact the view rate of a video after the event finishes. The findings presented in the paper provide several key insights into the impact and patterns of view contributions for each major source of the video views.
C1 [Zhou, Renjie; Wan, Jian; Zhang, Jilin] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Zhou, Renjie; Wan, Jian; Zhang, Jilin] Minist Educ, Key Lab Complex Syst Modeling & Simulat, Hangzhou, Zhejiang, Peoples R China.
   [Khemmarat, Samamon; Gao, Lixin] Univ Massachusetts, Dept Elect & Comp Engn, Amherst, MA 01003 USA.
C3 Hangzhou Dianzi University; University of Massachusetts System;
   University of Massachusetts Amherst
RP Zhang, JL (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.; Zhang, JL (corresponding author), Minist Educ, Key Lab Complex Syst Modeling & Simulat, Hangzhou, Zhejiang, Peoples R China.
EM jilin.zhang@hdu.edu.cn
RI li, xiaomin/KCX-9845-2024
FU NSF of Zhejiang [LQ13F020017, LY16F020018]; NSF of China [61300211,
   61202094, 61572163, 61472112]; National Key Technology Research and
   Development Program of China [2014BAK14B00]
FX The authors are grateful to the anonymous reviewers for their valuable
   comments and constructive suggestions, and also to the editors for their
   careful checking of the publication details that improved this paper.
   This work was supported by NSF of Zhejiang under grant NO.LQ13F020017,
   LY16F020018, and NSF of China under grant NO.61300211, 61202094,
   61572163, 61472112, and National Key Technology Research and Development
   Program of China under grant No.2014BAK14B00.
CR Ahmed Mohamed, 2013, P 6 ACM INT C WEB SE, P607, DOI [DOI 10.1145/2433396.2433473, 10.1145/2433396.2433473]
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI [DOI 10.1145/2433396.2433489, 10.1145/2433396.2433489]
   [Anonymous], 7 EUR C SYNTH AP RAD
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI DOI 10.1145/2433396.2433443
   Borghol Y., 2012, ACM SIGKDD International Knowledge Discovery and Data Mining, P1186, DOI [DOI 10.1145/2339530.2339717, 10.1145/2339530.2339717]
   Borghol Y, 2011, PERFORM EVALUATION, V68, P1037, DOI 10.1016/j.peva.2011.07.008
   Brodersen Anders, 2012, P 21 INT C WORLD WID, P241, DOI DOI 10.1145/2187836.2187870
   CHA M, 2007, P ACM INT MEAS C IMC
   Cha M, 2009, IEEE ACM T NETWORK, V17, P1357, DOI 10.1109/TNET.2008.2011358
   Chatzopoulou G., 2010, P IEEE INFOCOM, DOI [DOI 10.1109/INFCOMW.2010.5466701, 10.1109/INFCOMW.2010.5466701]
   Chen LZ, 2014, ADV DIFFER EQU-NY, DOI 10.1186/1687-1847-2014-251
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Cheng X, 2009, IEEE INFOCOM SER, P1152, DOI 10.1109/INFCOM.2009.5062028
   Crane R, 2008, P NATL ACAD SCI USA, V105, P15649, DOI 10.1073/pnas.0803685105
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   Figueiredo F, 2014, ACM T INTERNET TECHN, V14, DOI 10.1145/2665065
   Figueiredo Flavio, 2011, P 4 ACM INT C WEB SE, P745, DOI DOI 10.1145/1935826.1935925
   Fleder D, 2009, MANAGE SCI, V55, P697, DOI 10.1287/mnsc.1080.0974
   Jiang L., 2014, P INT C MULTIMEDIA R, P193
   Leem B, 2014, EXPERT SYST APPL, V41, P1723, DOI 10.1016/j.eswa.2013.08.071
   Lerman K., 2010, P 19 INT C WORLD WID, P621, DOI DOI 10.1145/1772690.1772754
   Lerman K., 2008, P ACM SIGCOMM WORKSH, P7
   Nie B, 2014, IEEE CONF COMPUT, P97, DOI 10.1109/INFCOMW.2014.6849175
   Paul A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2423636.2423643
   Paul A, 2012, ACM T EMBED COMPUT S, V11, DOI 10.1145/2331147.2331149
   Ratkiewicz J, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.158701
   SSeder D, 2007, P 8 ACM C EL COMM, P199
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhou Renjie, 2010, P 10 ACM SIGCOMM C I, P404, DOI DOI 10.1145/1879141.1879193
NR 31
TC 51
Z9 56
U1 3
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 6035
EP 6058
DI 10.1007/s11042-015-3206-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600032
DA 2024-07-18
ER

PT J
AU Bouagar, S
   Larabi, S
AF Bouagar, Saliha
   Larabi, Slimane
TI Efficient descriptor for full and partial shape matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape description; Shape retrieval; Shape matching; Partial matching;
   Full matching
ID RECOGNITION; RETRIEVAL; REPRESENTATION
AB In this paper we present a new approach for full and partial shape retrieval based on a shape descriptor invariant to geometric transformations, reflection and deformation. The proposed description is a set of features that capture simultaneously global and local properties of the shape. To achieve the best matching, we propose a novel matching algorithm based on Dynamic Time Warping. The proposed method is evaluated in two cases: partial and full matching. The experimental results demonstrate that our approach outperforms existing methods of partial shape retrieval and gives comparable results for full shape retrieval.
C1 [Bouagar, Saliha; Larabi, Slimane] USTHB Univ, Dept Comp Sci, BP 32 Alia, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Larabi, S (corresponding author), USTHB Univ, Dept Comp Sci, BP 32 Alia, Algiers, Algeria.
EM sbouagar@usthb.dz; slarabi@usthb.dz
RI Larabi, Slimane/AAD-7871-2020
OI larabi, slimane/0000-0001-8994-5980
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   ADAMEK T, 2004, IEEE T CIRCUITS SYST, V14
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Alajlan N, 2010, ARTIF LIFE ROBOT, V15, P309, DOI 10.1007/s10015-010-0814-7
   Andaló FA, 2010, PATTERN RECOGN, V43, P26, DOI 10.1016/j.patcog.2009.06.012
   [Anonymous], 1994, P AAAI 94 WORKSH KNO
   [Anonymous], 2003, KDD
   ATKINSON J, 2000, MPEG 7
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chetverikov D., 1999, 23 WORKSHOP AUSTRIAN, P175
   Cui M, 2009, PATTERN RECOGN LETT, V30, P1, DOI 10.1016/j.patrec.2008.08.013
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Daliri MR, 2010, COMPUT VIS IMAGE UND, V114, P1097, DOI 10.1016/j.cviu.2010.07.002
   Das G., 2003, P 1 PKDD S, P88
   Demirci MF, 2010, INT C PATT REC
   Drew MS, 2009, IMAGE VISION COMPUT, V27, P748, DOI 10.1016/j.imavis.2008.07.011
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   Hu RX, 2012, PATTERN RECOGN, V45, P3222, DOI 10.1016/j.patcog.2012.02.020
   Latecki LJ, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P701
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Latecki LJ, 2005, IMAGE VISION COMPUT, V23, P227, DOI 10.1016/j.imavis.2004.06.015
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Latecki LJ, 2007, PATTERN RECOGN, V40, P3069, DOI 10.1016/j.patcog.2007.03.004
   Lemuz-López R, 2008, LECT NOTES COMPUT SC, V5008, P323
   LING H, 2005, CVPR
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu HR, 2008, INT J COMPUT VISION, V80, P104, DOI 10.1007/s11263-008-0131-y
   Liu W, 2010, IEEE 10 INT C SIGN P
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Longbin Chen, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563078
   Mai F, 2010, IEEE IMAGE PROC, P4605, DOI 10.1109/ICIP.2010.5651645
   Michel D, 2011, IMAGE VISION COMPUT, V29, P459, DOI 10.1016/j.imavis.2011.01.008
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   Mokhtarian F, 1996, INT WORKSH IM DAT MU
   Mori G, 2003, CVPR, V1, P1063
   Saber E, 2005, PATTERN RECOGN, V38, P1560, DOI 10.1016/j.patcog.2005.03.027
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Sakoe H., 1971, P 7 INT C AC BUD
   Sarfraz M, 2006, COMPUT IMAGING VIS, V32, P528
   Schmidt FR, 2007, IEEE I CONF COMP VIS, P1479
   Tanase M., 2005, 13th Annual ACM International Conference on Multimedia, P543, DOI 10.1145/1101149.1101272
   Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Yu Cao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2345, DOI 10.1109/CVPR.2011.5995588
NR 45
TC 6
Z9 7
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 2989
EP 3011
DI 10.1007/s11042-014-2417-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600004
DA 2024-07-18
ER

PT J
AU Hwang, G
   Yoon, SH
   Park, S
AF Hwang, Gyuhyun
   Yoon, Seung-Hyun
   Park, Sanghun
TI Video-based weathering gallery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weathering; Video-based techniques; Appearance manifolds; Material
   appearance; Photorealistic rendering; Augmented video production
ID APPEARANCE
AB We present a simple and effective method for constructing a gallery that consists of weathering effect elements called time-dependent appearance manifolds (TDAMs). Since TDAMs are computed from sample video clips showing dynamic weathering phenomena, they represent very smooth changes in the appearance of weathered pixels over time. Once a gallery with a variety of weathering effects is prepared, users can interactively choose and apply the predefined effects onto the surface of 3D graphic models and then finally assign the most appropriate one. This video-based weathering method can be implemented with very simple algorithms and it supports predictable, intuitive, and natural effects. Our system allows users to produce photorealistic augmented videos that include 3D graphic models weathered by our method. Moreover, users can easily enhance the realism of the augmented videos by manipulating rendering parameters such as the degree of weathering, texturing, lighting, and shadowing through user-friendly graphical user interfaces (GUIs).
C1 [Hwang, Gyuhyun; Park, Sanghun] Dongguk Univ, Dept Multimedia, 30 Pil Dong 1st St, Seoul 100715, South Korea.
   [Yoon, Seung-Hyun] Dongguk Univ, Dept Multimedia Engn, 30 Pil Dong 1st St, Seoul 100715, South Korea.
C3 Dongguk University; Dongguk University
RP Park, S (corresponding author), Dongguk Univ, Dept Multimedia, 30 Pil Dong 1st St, Seoul 100715, South Korea.
EM spony@dongguk.edu; shyun@dongguk.edu; mshpark@dongguk.edu
FU National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [NRF-2012R1A1A2006486]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (NRF-2012R1A1A2006486).
CR Adobe Systems Software, 2013, AD SYST SOFTW EFF CC
   An XB, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024181
   Bandeira D, 2009, SIBGRAPI, P32, DOI 10.1109/SIBGRAPI.2009.38
   Bosch C, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966399
   Chen YY, 2005, ACM T GRAPHIC, V24, P1127, DOI 10.1145/1073204.1073321
   Cutler B, 2002, ACM T GRAPHIC, V21, P302
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Glondu L, 2012, COMPUT GRAPH FORUM, V31, P1547, DOI 10.1111/j.1467-8659.2012.03151.x
   Gu JW, 2006, ACM T GRAPHIC, V25, P762, DOI 10.1145/1141911.1141952
   Kider JT, 2011, COMPUT GRAPH FORUM, V30, P257, DOI 10.1111/j.1467-8659.2011.01857.x
   Liu YQ, 2012, COMPUT ANIMAT VIRT W, V23, P395, DOI 10.1002/cav.1459
   Lu J., 2005, EGNP, P7, DOI DOI 10.2312/NPH/NPH05/007-016
   Lu JY, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1189762.1189765, 10.1145/1186644.1186647]
   Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343
   Merillou N, 2010, WSCG 2010
   Merillou N, 2012, IEEE COMPUT GRAPH, V32, P44, DOI 10.1109/MCG.2011.107
   Mérillou S, 2008, COMPUT GRAPH-UK, V32, P159, DOI 10.1016/j.cag.2008.01.003
   Rosenberger A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618453
   Sun B, 2007, IEEE T VIS COMPUT GR, V13, P595, DOI 10.1109/TVCG.2007.1013
   van den Hengel A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239537, 10.1145/1276377.1276485]
   Wang JP, 2006, ACM T GRAPHIC, V25, P754, DOI 10.1145/1141911.1141951
   Xia L, 2011, P VRCAI 2011, P117
   Xue S, 2008, COMPUT GRAPH FORUM, V27, P617
   Xue S, 2011, COMPUT GRAPH FORUM, V30, P1189, DOI 10.1111/j.1467-8659.2011.01977.x
NR 24
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3391
EP 3407
DI 10.1007/s11042-014-2440-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600022
DA 2024-07-18
ER

PT J
AU Shen, X
   Tian, XM
AF Shen, Xu
   Tian, Xinmei
TI Multi-modal and multi-scale photo collection summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo collection summarization; Event segmentation; Key photo selection
ID REPRESENTATION
AB With the proliferation of digital cameras and mobile devices, people are taking much more photos than ever before. However, these photos can be redundant in content and varied in quality. Therefore there is a growing need for tools to manage the photo collections. One efficient photo management way is photo collection summarization which segments the photo collection into different events and then selects a set of representative and high quality photos (key photos) from those events. However, existing photo collection summarization methods mainly consider the low-level features for photo representation only, such as color, texture, etc, while ignore many other useful features, for example high-level semantic feature and location. Moreover, they often return fixed summarization results which provide little flexibility. In this paper, we propose a multi-modal and multi-scale photo collection summarization method by leveraging multi-modal features, including time, location and high-level semantic features. We first use Gaussian mixture model to segment photo collection into events. With images represented by those multi-modal features, our event segmentation algorithm can generate better performance since the multi-modal features can better capture the inhomogeneous structure of events. Next we propose a novel key photo ranking and selection algorithm to select representative and high quality photos from the events for summarization. Our key photo ranking algorithm takes the importance of both events and photos into consideration. Furthermore, our photo summarization method allows users to control the scale of event segmentation and number of key photos selected. We evaluate our method by extensive experiments on four photo collections. Experimental results demonstrate that our method achieves better performance than previous photo collection summarization methods.
C1 [Shen, Xu] Univ Sci & Technol China, Elect Engn, Hefei 230026, Peoples R China.
   [Tian, Xinmei] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Tian, XM (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Peoples R China.
EM shenxu@mail.ustc.edu.cn; xinmei@ustc.edu.cn
FU NSFC [61201413, 61390514]; Specialized Research Fund for the Doctoral
   Program of Higher Education [WJ2100060003]; Fundamental Research Funds
   for the Central Universities [WK2100060011, WK2100100021]
FX This work is supported by the NSFC under the contract No. 61201413 and
   61390514, the Specialized Research Fund for the Doctoral Program of
   Higher Education No. WJ2100060003, the Fundamental Research Funds for
   the Central Universities No. WK2100060011, WK2100100021.
CR [Anonymous], 2011, ACM T MULTIM COMPUT, DOI DOI 10.1145/2043612.2043613
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chu Wei-Ta., 2008, P 16 ACM INT C MULTI, P829, DOI DOI 10.1145/1459359.1459498
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   Gong B, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P71, DOI 10.1109/ICSC.2007.88
   Gozali JP, 2012, IEEE INT CONF MULTI, P25, DOI 10.1109/ICMEW.2012.12
   Graham A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P326, DOI 10.1145/544220.544301
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu H., 2012, Proceedings_of_the_20th_ACM_ International_Conference_on_Multimedia, MM'12, P9
   Loui AC, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1125, DOI 10.1109/ICME.2000.871558
   Loui AC, 1999, P ACM MULT 99 ORL FL, P159
   Mei T, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1757, DOI 10.1109/ICME.2006.262891
   MURRAY N, 2012, PROC CVPR IEEE, P2408, DOI DOI 10.1109/CVPR.2012.6247954
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Platt JC, 2000, AUTOALBUM CLUSTERING
   Platt JC, 2003, PHOTOTOC AUTOMATIC C, P21
   Richang H, 2013, IEEE T IMAGE PROCESS, V22, P2013
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tao M, 2014, ACM COMPUT SURV, V46
   Teng L, 2009, SIGNAL PROCESS, V89
   Ullas G, 2003, P 5 ACM SIGMM INT WO, P47
   Yangqing J, 2013, CAFFE OPEN SOURCE CO
   Zhiwei Li, 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P106
NR 27
TC 4
Z9 5
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2527
EP 2541
DI 10.1007/s11042-015-2658-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000008
DA 2024-07-18
ER

PT J
AU Aparajeya, P
   Leymarie, FF
AF Aparajeya, Prashant
   Leymarie, Frederic Fol
TI Point-based medialness for 2D shape description and identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D shape analysis; Dominant points; Information retrieval; Medialness
   representation; Shape compression; Planar articulated movement
ID RECOGNITION; CONTOUR; REPRESENTATION; CLASSIFICATION; SIMILARITY;
   FEATURES; CONTEXT; LINE
AB We propose a perception-based medial point description of a natural form (2D: static or in articulated movement) as a framework for a shape representation which can then be efficiently used in biological species identification and matching tasks. Medialness is defined by adapting and refining a definition first proposed in the cognitive science literature when studying the visual attention of human subjects presented with articulated biological 2D forms in movement, such as horses, dogs and humans (walking, running). In particular, special loci of high medialness for the interior of a form in movement, referred to as "hot spots", prove most attractive to the human perceptual system. We propose an algorithmic process to identify such hot spots. In this article we distinguish exterior from interior shape representation. We further augment hot spots with extremities of medialness ridges identifying significant concavities (from outside) and convexities (from inside). Our representation is strongly footed in results from cognitive psychology, but also inspired by know-how in art and animation, and the algorithmic part is influenced by techniques from more traditional computer vision. A robust shape matching algorithm is designed that finds the most relevant targets from a database of templates by comparing feature points in a scale, rotation and translation invariant way. The performance of our method has been tested on several databases. The robustness of the algorithm is further tested by perturbing the data-set at different levels.
C1 [Aparajeya, Prashant; Leymarie, Frederic Fol] Univ London, Dept Comp, London SE14 6NW, England.
C3 University of London
RP Aparajeya, P (corresponding author), Univ London, Dept Comp, London SE14 6NW, England.
EM p.aparajeya@gold.ac.uk; ffl@gold.ac.uk
OI Leymarie, Frederic/0000-0002-3221-8966
FU European Union [258749]
FX This work was partially funded by the European Union (FP7-ICT; Grant
   Agreement #258749; CEEDs project). Thanks to Prof. Stefan Rueger and
   Prof. Ilona Kovacs for useful discussions.
CR [Anonymous], 1992, Symmetry, Causality, Mind
   Aparajeya P., 2014, P 1 INT WORKSH ENV M, P14
   Arnheim R., 1974, Art and Visual Perception, a Psychology of the Creative Eye
   Bai X, 2009, IEEE I CONF COMP VIS, P575, DOI 10.1109/ICCV.2009.5459188
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058
   Biederman I, 2000, SPATIAL VISION, V13, P241, DOI 10.1163/156856800741063
   BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6
   Bookstein FL., 1991, Morphometric Tools for Landmark Data: Geometry and Biology, P435
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Caputo B, 2013, LECT NOTES COMPUT SC, V8138, P250, DOI 10.1007/978-3-642-40802-1_26
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073
   Dougherty ER, 2003, TUTORIAL TEXTS OPTIC, VTT59
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   Guay M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508397
   Heimann T, 2009, MED IMAGE ANAL, V13, P543, DOI 10.1016/j.media.2009.05.004
   Hu RX, 2012, PATTERN RECOGN, V45, P3222, DOI 10.1016/j.patcog.2012.02.020
   Kayaert G, 2011, FRONT SYST NEUROSCI, V5, DOI 10.3389/fnsys.2011.00051
   KELLY MF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1016, DOI 10.1109/ICCV.1995.466823
   Keustermans J, 2014, S STAT SHAP MOD APPL
   Kimia BB, 2003, J PHYSIOL-PARIS, V97, P155, DOI 10.1016/j.jphysparis.2003.09.003
   Kovács I, 1998, VISION RES, V38, P2323, DOI 10.1016/S0042-6989(97)00321-0
   Kovacs I., 2010, DYNAMIC COORDINATION, P215
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Layton OW, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00972
   LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013
   Leymarie F. F., 2014, P 1 ACM INT WORKSH M, P31
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu Z, 2011, SPIE, V8350
   Longbin Chen, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563078
   Loomis Andrew., 1951, Successful Drawing
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mouine S., 2012, ICMR, DOI [10.1145/2324796.2324853, DOI 10.1145/2324796.2324853]
   Nanni Loris, 2014, International Journal of Advanced Intelligence Paradigms, V6, P136, DOI 10.1504/IJAIP.2014.062177
   Park J, 2008, J SYST SOFTWARE, V81, P71, DOI 10.1016/j.jss.2007.05.001
   Pizer SM, 2003, INT J COMPUT VISION, V55, P155, DOI 10.1023/A:1026135101267
   Pizer SM, 2003, INT J COMPUT VISION, V55, P85, DOI 10.1023/A:1026313132218
   Premachandran V, 2013, PATTERN RECOGN, V46, P2092, DOI 10.1016/j.patcog.2013.01.030
   RICHARDS W, 1985, COMPUT VISION GRAPH, V31, P265, DOI 10.1016/0734-189X(85)90031-3
   Rijsbergen C. J. V., 1979, Information Retrieval
   Roman-Rangel E, 2011, ACM MULTIMEDIA
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Serra J., 1988, IMAGE ANAL MATH MORP
   Shen W, 2014, COMM COM INF SC, V483, P391
   SIMMONS Seymour., 1977, Drawing: the creative process
   Srestasathiern P, 2011, COMPUT VIS IMAGE UND, V115, P1525, DOI 10.1016/j.cviu.2011.07.004
   Tang J, 2014, IEEE WINT CONF APPL, P17, DOI 10.1109/WACV.2014.6836123
   van Tonder GJ, 2003, IEEE T SYST MAN CY B, V33, P535, DOI 10.1109/TSMCB.2003.810952
   Van Wamelen PB, 2004, PATTERN RECOGN, V37, P1699, DOI 10.1016/j.patcog.2003.12.009
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Wang XG, 2014, PATTERN RECOGN, V47, P2116, DOI 10.1016/j.patcog.2013.12.008
   Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005
   Yang M., 2008, PATTERN RECOGN, P43, DOI DOI 10.5772/6237
NR 56
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1667
EP 1699
DI 10.1007/s11042-015-2605-6
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600018
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Hao, SJ
   Wang, M
   Hong, RC
   Jiang, JG
AF Hao, Shijie
   Wang, Meng
   Hong, Richang
   Jiang, Jianguo
TI Spatially guided local Laplacian filter for nature image detail
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Image content; Local Laplacian filter; Distance
   transform
ID 3-D OBJECT RETRIEVAL; SEARCH
AB Nature images make up a significant proportion of the ever growing volume of social media. In this context, automatic and rapid image enhancement is always among the favorable techniques for photographers. Among the image representation models, the Gaussian and Laplacian image pyramids based on isotropic Gaussian kernels were once considered to be inappropriate for image enhancement tasks. The recently proposed Local Laplacian Filter (LLF) updates this view by designing a point-wise intensity remapping process. However, this model filters an image with a consistent strength instead of a dynamical way which takes image contents into account. In this paper, we propose a spatially guided LLF by extending the single-value key parameter into a multi-value matrix that dynamically assigns filtering strengths according to image contents. Since it is still very challenging to recognize arbitrary image contents with machine learning methods, we propose a simple but effective technique, which only approximates the richness of image details instead of specific contents. This trade-off between concrete semantics and algorithm efficiency enables filtering strengths to be spatially guided in the LLF process with little extra computational cost. Experimental results validate our method in terms of visual effects and a conditionally faster LLF implementation.
C1 [Hao, Shijie; Wang, Meng; Hong, Richang; Jiang, Jianguo] Hefei Univ Technol, Sch Comp & Informat, Hefei, Peoples R China.
   [Hao, Shijie] Hefei Univ Technol, Comp Sci & Technol Postdoctoral Res Stn, Hefei, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Hao, SJ (corresponding author), Hefei Univ Technol, Comp Sci & Technol Postdoctoral Res Stn, Hefei, Peoples R China.
EM hfut.hsj@gmail.com; eric.mengwang@gmail.com; hongrc@hfut.edu.cn;
   jgjiang@hfut.edu.cn
RI Wang, Meng/ITR-8699-2023
FU National Natural Science Fund of China [61301222]; China Postdoctoral
   Science Foundation [2013M541821]; Fundamental Research Funds for the
   Central Universities [2013HGQC0018, 2013HGBH0027, 2013HGBZ0166]
FX The authors sincerely appreciate the useful comments and suggestions
   from the anonymous reviewers. This work was supported by National
   Natural Science Fund of China (Grant No. 61301222), China Postdoctoral
   Science Foundation (Grant No. 2013M541821), Fundamental Research Funds
   for the Central Universities (Grant No. 2013HGQC0018, 2013HGBH0027,
   2013HGBZ0166)
CR [Anonymous], P EUR C COMP VIS
   Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048
   Buades A, 2006, IEEE T IMAGE PROCESS, V15, P1499, DOI 10.1109/TIP.2006.871137
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239502, 10.1145/1276377.1276441]
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gu HX, 2012, P EUR C COMP VIS
   Hong RC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037681
   Li HJ, 2010, IEEE T CIRC SYST VID, V20, P351, DOI 10.1109/TCSVT.2009.2035833
   Li HJ, 2011, P ACM MULT
   Ling Y, 2012, VISUAL COMPUT, V28, P733, DOI 10.1007/s00371-012-0691-2
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Paris S., 2011, P ACM SIGGRAPH
   Paris S, 2009, FDN TRENDS COMPUT GR
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Yang KY, 2011, IEEE T MULTIMEDIA, V13, P662, DOI 10.1109/TMM.2011.2147777
NR 22
TC 4
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1529
EP 1542
DI 10.1007/s11042-014-2058-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600011
DA 2024-07-18
ER

PT J
AU Liu, HP
   Liu, YL
   Sun, FC
AF Liu, Huaping
   Liu, Yulong
   Sun, Fuchun
TI Video key-frame extraction for smart phones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video key-frame; Smart phone; User's intention; Accelerometer
ID SYSTEM; ACCELEROMETER; RECOGNITION
AB In this paper, the key-frame extraction for video clips which are captured by smart phones are investigated. Different from existing work which exploits the image contents, this work utilizes the sensors embedded in the smart phone, such as accelerometers and the touch screen surface, to infer the user's intention. Those intentions are further analyzed to extract the meaningful video key-frames. The proposed method is not only fast enough for on-device implementation, but it also can improve the key-frame extraction performance. Finally, a prototype is developed in a smart phone and extensive experimental validations are provided to show the advantages of the proposed method.
C1 [Liu, Huaping; Liu, Yulong; Sun, Fuchun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Liu, Huaping; Liu, Yulong; Sun, Fuchun] TNLIST, State Key Lab Intelligent Technol & Syst, Beijing, Peoples R China.
C3 Tsinghua University
RP Liu, HP (corresponding author), TNLIST, State Key Lab Intelligent Technol & Syst, Beijing, Peoples R China.
EM hpliu@tsinghua.edu.cn
FU National Key Project for Basic Research of China [2013CB329403];
   Tsinghua Self-innovation Project [20111081111]; Tsinghua University
   Initiative Scientific Research Program [20131089295]
FX This work was supported in part by the National Key Project for Basic
   Research of China under Grant 2013CB329403; in part by the Tsinghua
   Self-innovation Project under Grant 20111081111; and in part by the
   Tsinghua University Initiative Scientific Research Program under Grant
   20131089295.
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   [Anonymous], 2013, PROC IEEE INT C MULT
   Atzori L, 2012, P INT CONF OPTIM EL, P1158, DOI 10.1109/OPTIM.2012.6231975
   Bai YW, 2012, IEEE T CONSUM ELECTR, V58, P1269, DOI 10.1109/TCE.2012.6414995
   Chung M, 2014, MULTIMEDIA TOOLS APP
   Cricri F, MULTIMEDIA IN PRESS
   Alvarez AD, 2014, IEEE INTEL TRANSP SY, V6, P44, DOI 10.1109/MITS.2014.2322651
   Fuentes D, 2012, EXPERT SYST APPL, V39, P2461, DOI 10.1016/j.eswa.2011.08.098
   Gao Y, 2008, IEEE T CONSUM ELECTR, V54, P521, DOI 10.1109/TCE.2008.4560124
   Guo Y, 2013, IEEE INFOCOM SER, P365
   Hanning G., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1, DOI 10.1109/ICCVW.2011.6130215
   Hua G, 2012, INT J COMPUT VISION, V96, P277, DOI 10.1007/s11263-011-0506-3
   Huang JC, 2004, IEEE T CONSUM ELECTR, V50, P911, DOI 10.1109/TCE.2004.1341699
   Jiang RM, 2009, IEEE T CONSUM ELECTR, V55, P1551, DOI 10.1109/TCE.2009.5278026
   Kim S, 2013, SCI WORLD J, DOI 10.1155/2013/175702
   Kosmopoulos DI, 2013, IEEE T IND INFORM, V9, P161, DOI 10.1109/TII.2012.2212712
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   Lee W, 2011, IEEE T CIRC SYST VID, V21, P1487, DOI 10.1109/TCSVT.2011.2162767
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   Schoeffmann K, 2014, MULTIMEDIA TOOLS APP
   Sentinelli A, 2013, IEEE INT CONF MULTI
   Shangguan LF, 2014, IEEE T PARALL DISTR, V25, P2731, DOI 10.1109/TPDS.2013.236
   Tian Y, 2013, IEEE T CONSUM ELECTR, V59, P220, DOI 10.1109/TCE.2013.6490263
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Yong S, 2013, MULTIMEDIA TOOLS APP
NR 26
TC 2
Z9 2
U1 6
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2031
EP 2049
DI 10.1007/s11042-014-2390-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000014
DA 2024-07-18
ER

PT J
AU Tsikrika, T
   Moumtzidou, A
   Vrochidis, S
   Kompatsiaris, I
AF Tsikrika, Theodora
   Moumtzidou, Anastasia
   Vrochidis, Stefanos
   Kompatsiaris, Ioannis
TI Focussed crawling of environmental Web resources based on the
   combination of multimedia evidence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Focussed crawling; Environmental data; Link context; Image
   classification; Heatmaps
ID RETRIEVAL
AB Focussed crawlers enable the automatic discovery of Web resources about a given topic by automatically navigating the Web link structure and selecting the hyperlinks to follow by estimating their relevance to the topic based on evidence obtained from the already downloaded pages. This work proposes a classifier-guided focussed crawling approach that estimates the relevance of a hyperlink to an unvisited Web resource based on the combination of textual evidence representing its local context, namely the textual content appearing in its vicinity in the parent page, with visual evidence associated with its global context, namely the presence of images relevant to the topic within the parent page. The proposed focussed crawling approach is applied towards the discovery of environmental Web resources that provide air quality measurements and forecasts, since such measurements (and particularly the forecasts) are not only provided in textual form, but are also commonly encoded as multimedia, mainly in the form of heatmaps. Our evaluation experiments indicate the effectiveness of incorporating visual evidence in the link selection process applied by the focussed crawler over the use of textual features alone, particularly in conjunction with hyperlink exploration strategies that allow for the discovery of highly relevant pages that lie behind apparently irrelevant ones.
C1 [Tsikrika, Theodora; Moumtzidou, Anastasia; Vrochidis, Stefanos; Kompatsiaris, Ioannis] CERTH, Inst Informat Technol, Thessaloniki, Greece.
C3 Centre for Research & Technology Hellas
RP Tsikrika, T (corresponding author), CERTH, Inst Informat Technol, Thessaloniki, Greece.
EM theodora.tsikrika@iti.gr; moumtzid@iti.gr; stefanos@iti.gr; ikom@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015; Moumtzidou, Anastasia/IXN-7950-2023
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Vrochidis,
   Stefanos/0000-0002-2505-9178; Moumtzidou, Anastasia/0000-0001-7615-8400;
   Tsikrika, Theodora/0000-0003-4148-9028
FU European Commission [FP7-610411, FP7-312388]
FX This work was supported by MULTISENSOR (contract no. FP7-610411) and
   HOMER (contract no. FP7-312388) projects, partially funded by the
   European Commission.
CR Cao RN, 2002, LECT NOTES COMPUT SC, V2390, P167
   Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cho J, 1998, COMPUT NETWORKS ISDN, V30, P161, DOI 10.1016/S0169-7552(98)00108-1
   Davison B. D., 2000, SIGIR Forum, V34, P272
   DEBRA PME, 1994, COMPUT NETWORKS ISDN, V27, P183, DOI 10.1016/0169-7552(94)90132-5
   Epitropou V., 2010, P GI FOR S EXH APPL, P58
   Henderson Thomas C., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P376, DOI 10.1109/ICDAR.2009.31
   Karatzas K., 2000, J ENV ASSESSMENT POL, V2, P263
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Moumtzidou Anastasia, 2012, Multidisciplinary Information Retrieval. Proceedings 5th Information Retrieval Facility Conference. IRFC 2012, P58, DOI 10.1007/978-3-642-31274-8_5
   Moumtzidou A, 2013, ENCY INFORM IN PRESS
   Moumtzidou A, 2013, P 20 IEEE INT C IM P
   Olston Christopher, 2010, Foundations and Trends in Information Retrieval, V4, P175, DOI 10.1561/1500000017
   Over P., 2007, TRECVID 2007 WORKSH
   Oyama S, 2004, IEEE T KNOWL DATA EN, V16, P17, DOI 10.1109/TKDE.2004.1264819
   Pant G, 2006, IEEE T KNOWL DATA EN, V18, P107, DOI 10.1109/TKDE.2006.12
   Pant G, 2005, ACM T INFORM SYST, V23, P430, DOI 10.1145/1095872.1095875
   PANT G, 2002, P 2 INT WORKSH WEB D
   San José R, 2008, DEV INTEG ENVIRON, V3, P247, DOI 10.1016/S1574-101X(08)00614-5
   Sidiropoulos P, 2011, PATTERN RECOGN, V44, P739, DOI 10.1016/j.patcog.2010.09.014
   Srinivasan P, 2005, INFORM RETRIEVAL, V8, P417, DOI 10.1007/s10791-005-6993-5
   Tang T. T., 2005, P 14 ACM INT C INF K, P147, DOI DOI 10.1145/1099554.1099583
   Tang TT, 2004, P 9 AUSTR DOC COMP S, P1
   Tsikrika T., 2014, P INT WORKSH ENV MUL, P61
   Yuan J, 2007, TRECVID 2007 WORKSH
NR 28
TC 6
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1563
EP 1587
DI 10.1007/s11042-015-2624-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600014
DA 2024-07-18
ER

PT J
AU Hung, CS
   Ruan, SJ
AF Hung, Chia-Shao
   Ruan, Shanq-Jang
TI Efficient adaptive thresholding algorithm for in-homogeneous document
   background removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document image analysis; Document image binarization; Adaptive
   thresholding; High speed; Low computational cost
ID SYSTEM; IMAGES
AB Image binarization refers to convert gray-level images into binary ones, and many binarization algorithms have been developed. The related algorithms can be classified as either high quality computation or high speed performance. This paper presents an algorithm that ensures both benefits at the same time. The proposed algorithm intelligently segments input images into several different sized sub-images by using a Sobel like matrix. After which each sub-image will be classified into background set or foreground set according to it's feature. Finally the foreground set sub-images will be binarized by Otsu's method independently. Experimental results reveal that our algorithm provides the appropriate quality with the medium speed.
C1 [Hung, Chia-Shao; Ruan, Shanq-Jang] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Ruan, SJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM sjruan@mail.ntust.edu.tw
CR Beucher S, 1994, COMP IMAG VIS, V2, P69
   Cheriet M, 1995, P 3 INT C DOC AN REC, V1, P210
   Chiu YH, 2012, PATTERN RECOGN, V45, P4250, DOI 10.1016/j.patcog.2012.02.023
   Hegt HA, 1998, IEEE SYS MAN CYBERN, P4357, DOI 10.1109/ICSMC.1998.727533
   Manousakas IN, 1998, COMPUT BIOMED RES, V31, P393, DOI 10.1006/cbmr.1998.1489
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pai YT, 2010, PATTERN RECOGN, V43, P3177, DOI 10.1016/j.patcog.2010.03.014
   Suen CY, 1996, INT J IMAG SYST TECH, V7, P392, DOI 10.1002/(SICI)1098-1098(199624)7:4<392::AID-IMA14>3.0.CO;2-Y
NR 8
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1243
EP 1259
DI 10.1007/s11042-014-2366-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700025
DA 2024-07-18
ER

PT J
AU Jabeen, F
   Khusro, S
   Majid, A
   Rauf, A
AF Jabeen, Fouzia
   Khusro, Shah
   Majid, Amna
   Rauf, Azhar
TI Semantics discovery in social tagging systems: A review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantics in folksonomy; Folksonomy enrichment; Search precision;
   Navigation
ID TAG; SEARCH; FOLKSONOMY; WEB; ONTOLOGIES; SPAM
AB Web 2.0 has brought many collaborative and novel applications which transformed the web as a medium and resulted in its exponential growth. Tagging systems are one of these killer applications. Tags are in free-form but represent the link between objective information and users' cognitive information. However, tags have ambiguity problem reducing precision. Hence search and retrieval pose a challenge on folksonomy systems which have flat, unstructured, non-hierarchical organization with unsupervised vocabulary. We present a brief survey of different approaches for adding semantics in folksonomies thus bringing structure and precision in search and navigation. We did comparative analysis to estimate the significance of each source of semantics. Then, we have categorized the approaches in a systematic way and summarized the feature set support. Based on the survey we end up with recommendations. Our survey and conclusion will prove to be relevant and beneficial for engineers and designers aiming to design and maintain well structured folksonomy with precise search and navigation results.
C1 [Jabeen, Fouzia; Khusro, Shah; Majid, Amna; Rauf, Azhar] Univ Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
C3 University of Peshawar
RP Jabeen, F (corresponding author), Univ Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
EM fouzia.jabeen@gmail.com
RI Khusro, Shah/C-1661-2014; Jabeen, Fouzia/AAJ-6916-2020
OI Khusro, Shah/0000-0002-7734-7243; Jabeen, Fouzia/0000-0003-2191-6512
CR Abbasi R., 2011, P 5 INT C SEM DIG ME, P1
   Abbasi RA, 2010, THESIS
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2010, Proceedings of the 21st ACM conference on Hypertext and hypermedia
   [Anonymous], 2011, P 20 ACM INT C INF K
   [Anonymous], 2006, COLL WEB TAGG WORKSH
   [Anonymous], P 3 INT WORKSH SEARC
   [Anonymous], 2011, REVOLUTIONARY NEW PL
   [Anonymous], 2006, AAAI
   [Anonymous], 2008, AIRWeb'08: Proceedings of the 4th international workshop on Adversarial information retrieval on the web
   [Anonymous], 2010, ACM Sigkdd Explorations Newsletter
   Aras H., 2010, WORKSH VIS INT SOC S
   Aschke R, 2008, WEB SEMANT SCI SERV, V6, P38
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Awawdeh R, 2010, LECT NOTES ARTIF INT, V6291, P378, DOI 10.1007/978-3-642-15280-1_35
   Awawdeh R, 2009, INT CONF INTELL SYST, P288, DOI 10.1109/ISDA.2009.170
   Baba Y, EXTRACTING TIME LOCA
   Bartolini I, 2013, MULTIMED TOOLS APPL, V63, P357, DOI 10.1007/s11042-011-0948-1
   Benz D, 2008, DAGST SEM 08391 WORK
   Benz D, 2011, LECT NOTES COMPUT SC, V6644, P360, DOI 10.1007/978-3-642-21064-8_25
   Bindelli S, 2008, LECT NOTES COMPUT SC, V5333, P76
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Braun S, 2009, INT C SEM SYST I SEM, P445
   Braun Simone, 2007, EMERGENT SEMANTICS O, V292, P5
   Cantador I, 2011, J WEB SEMANT, V9, P1, DOI 10.1016/j.websem.2010.10.001
   Cattuto C, 2008, P 3 WORKSH ONT LEARN, P39
   Cattuto C, 2008, LECT NOTES COMPUT SC, V5318, P615, DOI 10.1007/978-3-540-88564-1_39
   Chandramouli K, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P248
   Chen JP, 2014, INFORM SCIENCES, V280, P16, DOI 10.1016/j.ins.2014.04.048
   Ching-man Au Yeung, 2008, 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Workshops, P659, DOI 10.1109/WIIAT.2008.265
   Choudhury S, 2009, LECT NOTES COMPUT SC, V5823, P747, DOI 10.1007/978-3-642-04930-9_47
   Cucerzan S., 2007, P 2007 JOINT C EMPIR, P708, DOI DOI 10.1145/2187836.2187900
   Daud A., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P516, DOI 10.1109/WI-IAT.2010.10
   Dellschaft K, 2009, 8 INT SEM WEB C ISWC
   Di Matteo NR, 2009, INT CONF INTELL SYST, P279, DOI 10.1109/ISDA.2009.125
   Ding Y, 2010, J AM SOC INF SCI TEC, V61, P505, DOI 10.1002/asi.21271
   Donghee Yoo, 2010, Proceedings of the Second International Conference on Communication Software and Networks (ICCSN 2010), P160, DOI 10.1109/ICCSN.2010.36
   Ebrahimi T, 2014, SECURITY TRUST SOCIA
   Echarte F, 2004, ONT FOLKS NEW MOD ME, V289
   Eda T, 2009, WORLD WIDE WEB, V12, P421, DOI 10.1007/s11280-009-0069-1
   Ennan Zhai, 2011, Proceedings of the 2011 Fifth International Conference on Secure Software Integration and Reliability Improvement (SSIRI 2011), P174, DOI 10.1109/SSIRI.2011.30
   Ennan Zhai, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P429, DOI 10.1109/CSE.2009.154
   Federica C, 2013, ACM T INTELL SYST TE, V4
   Fujimura Ko., 2008, WWW '08, P1087, DOI DOI 10.1145/1367497.1367669
   Garcia A., 2009, KNOWLEDGE CAPTURE K
   Garcia-Silva A, 2012, DISCOVERING TAG SEMA
   Giannakidou Eirini, 2008, 2008 Second IEEE International Conference on Semantic Computing (ICSC), P128, DOI 10.1109/ICSC.2008.73
   Giles J, 2005, NATURE, V438, P900, DOI 10.1038/438900a
   Gobbo F, 2008, IMPROVING FLICKR DIS
   Golbeck J, 2011, J AM SOC INF SCI TEC, V62, P1750, DOI 10.1002/asi.21522
   Halpin H, EVOLVING ONTOLOGIES
   Han Z, 2010, ED INF TECHN ICEIT 2, pV3
   Haridas M, 2009, LECT NOTES COMPUT SC, V5871, P1238, DOI 10.1007/978-3-642-05151-7_35
   Harvey M, 2010, ECIR, V2010, P432
   Hayati P, 2009, IEEE INTL CONF IND I, P875, DOI 10.1109/INDIN.2009.5195918
   Iijima C, 2010, LECT NOTES ARTIF INT, V6278, P264, DOI 10.1007/978-3-642-15393-8_30
   Java A., 2008, P 10 WORKSH WEB MIN
   Javanmardi S, 2009, NETWORKING APPL WORK
   Jung JJ, 2010, LECT NOTES ARTIF INT, V6097, P39, DOI 10.1007/978-3-642-13025-0_5
   Kangpyo Lee, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P729, DOI 10.1109/CSE.2009.454
   Kawakubo H., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P330, DOI 10.1109/ISM.2010.57
   Kiran GVR, 2010, LECT NOTES ARTIF INT, V6277, P11
   Kittur A, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P37
   Kobilarov G., 2009, P DEV TRACK 18 INT W
   Korner Christian., 2010, Proceedings of the 19th International Conference on World Wide Web, WWW '10, P521
   Koutrika G, 2008, ACM T WEB, V2, DOI 10.1145/1409220.1409225
   Kyoung-Jun Sung, 2010, 2010 6th International Conference on Advanced Information Management and Service (IMS 2010), P297
   Lee K., 2008, P 17 INT C WORLD WID, P1093, DOI DOI 10.1145/1367497.1367672
   Lee K, 2009, SNPD 2009: 10TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCES, NETWORKING AND PARALLEL DISTRIBUTED COMPUTING, PROCEEDINGS, P24, DOI 10.1109/SNPD.2009.80
   Lee S, 2010, SIGNAL PROCESS-IMAGE, V25, P761, DOI 10.1016/j.image.2010.10.002
   Lee SS, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P294
   Lifshits Y, 2007, WEB MINING BLOGSPACE, P3
   Lin HR, 2010, LECT NOTES COMPUT SC, V6089, P472
   Liu B, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING, P95, DOI 10.1109/ASONAM.2009.43
   Loong J, 2012, FOLKSONOMY TAG COLLI
   Lops P, 2013, J INTELL INF SYST, V40, P41, DOI 10.1007/s10844-012-0215-6
   Lu C., 2009, PROC CIKM 09, P1545
   MAGUITMAN AG, 2005, P 14 INT C WORLD WID
   Marchetti A., 2007, WORKSH TAGG MET SOC, P8
   Markines B., 2009, P 18 INT C WORLD WID, P641
   Markines B, 2009, P 5 INT WORKSHOP ADV, P41, DOI 10.1145/1531914.1531924
   Mathes A., 2004, Computer M ediated Communication, V47, P1
   Mika P, 2007, J WEB SEMANT, V5, P5, DOI 10.1016/j.websem.2006.11.002
   Milicic V, 2008, W3C SEMANTIC WEB USE
   Min QX, 2010, COMPUTER AUTOMATION, V2, P815
   Mirizzi R, 2010, P 3 WORKSHOP PHD STU, P39
   Mirizzi R, 2010, LECT NOTES COMPUT SC, V6385s, P138, DOI 10.1007/978-3-642-16985-4_13
   Mirizzi R, 2010, LECT NOTES BUS INF P, V61, P36
   Mirizzi R, 2010, LECT NOTES COMPUT SC, V6189, P337, DOI 10.1007/978-3-642-13911-6_23
   Mo Q, 2010, ADV COMPUTER THEORY, pV2
   Moldvay J, 2010, P 4 ACM C REC SYST R, P345
   Mousselly-Sergieh Hatem, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P159, DOI 10.1007/978-3-319-04114-8_14
   OBRIEN JM, 2006, RACE CREATE SMART GO
   Passant A, 2007, P 1 INT C WEBL SOC M
   Pirrone R, 2010, C HUM SYST INTERACT, P543, DOI 10.1109/HSI.2010.5514514
   Poorgholami Maryam, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P56, DOI 10.1109/ICSESS.2013.6615254
   Quattrone G, 2011, P C SEK QUATTRONEMC1, P385
   Rastocny K, 2013, J UNIVERSAL COMPUTER, V19
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   Rong Pan, 2013, Agents and Data Mining Interaction. 8th International Workshop, ADMI 2012. Revised Selected Papers, P115, DOI 10.1007/978-3-642-36288-0_11
   Ronzano F, 2008, SWKM
   Scheau C, 2010, 9TH ROEDUNET IEEE INTERNATIONAL CONFERENCE, P151
   Si X., 2010, P 23 INT C COMPUTATI, P1011
   Simpson E, CLUSTERING TAGS ENTE
   Solskinnsbakk G, 2010, LECT NOTES COMPUT SC, V6427, P975, DOI 10.1007/978-3-642-16949-6_22
   Stampouli A, 2010, LECT NOTES COMPUT SC, V6193, P252, DOI 10.1007/978-3-642-14589-6_26
   Strohmaier M, 2012, J WEB SEMANT, V17, P1, DOI 10.1016/j.websem.2012.09.003
   Tan S. S, 2009, CIKM SWSM, P17
   Tang J, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2089
   Tibély G, 2012, NEW J PHYS, V14, DOI 10.1088/1367-2630/14/5/053009
   TOMURO N., 2009, Proceedings of the Workshop on The People's Web Meets NLP (People's Web '09), P42
   Trabelsi C., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P369, DOI 10.1109/ICDMW.2010.72
   Trant J., 2009, Journal of Digital Information, V10
   Tsui E, 2007, INFORM PROCESS MANAG, V46, P44
   Uddin MN, 2013, EXPERT SYST APPL, V40, P1645, DOI 10.1016/j.eswa.2012.09.006
   Wen-hao Chen, 2010, Proceedings of the 2010 International Conference on Computational Science and Its Applications (ICCSA 2010), P331, DOI 10.1109/ICCSA.2010.78
   Wu C, 2011, COMPUT INFORM, V30, P165
   Wu C, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P760, DOI 10.1109/NISS.2009.150
   Xia ZQ, 2014, J SIGNAL PROCESS SYS, V74, P5, DOI 10.1007/s11265-013-0756-0
   Xu GD, 2015, J INTELL INF SYST, V45, P95, DOI 10.1007/s10844-013-0262-7
   Xu HX, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P573, DOI 10.1109/GCIS.2009.320
   Xu Z, 2014, J NETW COMPUT APPL, V43, P42, DOI 10.1016/j.jnca.2014.04.002
   Yang HC, 2010, 2010 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2010), P441, DOI 10.1109/ASONAM.2010.11
   Yao JJ, 2010, PROC INT CONF DATA, P780, DOI 10.1109/ICDE.2010.5447922
   Yeung CMA, 2007, LECT NOTES COMPUT SC, V4825, P966
   Yoo D, 2013, J INF SCI, V39, P593, DOI 10.1177/0165551513480309
   Zhang H, 2012, P WSDM 2012 ACM
   Zhang Haipeng., 2012, Proceedings of the fifth ACM International Conference on Web Search and Data Mining, P33
   Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204
NR 129
TC 13
Z9 15
U1 0
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 573
EP 605
DI 10.1007/s11042-014-2309-3
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500026
DA 2024-07-18
ER

PT J
AU Li, ZK
   Ding, LX
   Wang, Y
AF Li, Zhaokui
   Ding, Lixin
   Wang, Yan
TI Score level fusion method based on multiple oblique gradient operators
   for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple oblique gradient operators; Score level fusion; Linear
   discriminant analysis; Face recognition
ID DISCRIMINANT-ANALYSIS; EIGENFACES
AB The traditional gradient is calculated along y and x axes, and its main object is to obtain vertical and horizontal edges in local image patch. However, there exist a lot of oblique edges in image patch besides vertical and horizontal edges. In order to obtain these oblique edges, we introduce multiple oblique gradient operators. By performing the multiple oblique gradient operators, an image can be transformed into multiple gradient orientation images which display different spatial locality and orientation properties. Each class orientation images are normalized by "z-score" method over the corresponding orientation image set. Then, linear discriminant analysis is performed to extract the corresponding low-dimensional features, and the results are used to compute the corresponding distance scores. The different weighted coefficients are calculated for different orientation images based on training samples. A weighted score fusion method is used to combine different distance scores according to their respective salience. Experimental results show that our methods significantly outperform popular methods, and achieve state-of-the-art performance for difficult problems such as illumination and occlusion-robust face recognition.
C1 [Li, Zhaokui; Wang, Yan] Shenyang Aerosp Univ, Sch Comp, Shenyang 110136, Peoples R China.
   [Ding, Lixin] Wuhan Univ, Sch Comp, State Key Lab Software Engn, Wuhan 430072, Peoples R China.
C3 Shenyang Aerospace University; Wuhan University
RP Li, ZK (corresponding author), Shenyang Aerosp Univ, Sch Comp, Shenyang 110136, Peoples R China.
EM lmy52wy@163.com; lxding@whu.edu.cn; lovelast@sina.com
FU Special Project on Integration of Industry, Education and Research of
   Guangdong Province of China [2011B090400477]; Special Project on
   Integration of Industry, Education and Research of Zhuhai of China
   [2011A050101005, 2012D0501990016]; Key Laboratory Key Technologies R & D
   Program of Zhuhai of China [2012D0501990026]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions to improve the quality of this paper.
   This work was supported by the Special Project on the Integration of
   Industry, Education and Research of Guangdong Province of China Grant
   No. 2011B090400477; the Special Project on the Integration of Industry,
   Education and Research of Zhuhai of China Grant No.
   2011A050101005,2012D0501990016; the Key Laboratory Key Technologies R &
   D Program of Zhuhai of China Grant No. 2012D0501990026.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   An GY, 2010, INT CONF SIGN PROCES, P670, DOI 10.1109/ICOSP.2010.5655743
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Calignano F, 2010, AESTHET PLAST SURG, V34, P200, DOI 10.1007/s00266-009-9410-4
   Cevikalp H, 2006, IEEE T NEURAL NETWOR, V17, P1550, DOI 10.1109/TNN.2006.881485
   Chih-Jen Lee, 2010, Proceedings of the 2010 Sixth International Conference on Networked Computing and Advanced Information Management (NCM 2010), P622
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goudelis G, 2007, IEEE T INF FOREN SEC, V2, P570, DOI 10.1109/TIFS.2007.902915
   Hanai Y, 2009, 2009 IEEE 13TH DIGITAL SIGNAL PROCESSING WORKSHOP & 5TH IEEE PROCESSING EDUCATION WORKSHOP, VOLS 1 AND 2, PROCEEDINGS, P675, DOI 10.1109/DSP.2009.4786008
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lei YQ, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P145, DOI 10.1109/ICMV.2009.61
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Logoglu K. B., 2010, LECT NOTES ELECT ENG, P245
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Martinez A. M., 1998, THE AR FACE DATABASE
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Poh N, 2010, IEEE T INF FOREN SEC, V5, P781, DOI 10.1109/TIFS.2010.2077627
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   Shin H, 2006, I C CONT AUTOMAT ROB, P614
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Tzimiropoulos G, 2012, IEEE T PATTERN ANAL, V34, P2454, DOI 10.1109/TPAMI.2012.40
   Vezzetti E, 2010, J PLAST RECONSTR AES, V63, P218, DOI 10.1016/j.bjps.2008.09.031
   Wang YM, 2006, LECT NOTES COMPUT SC, V3851, P581
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 39
TC 3
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 819
EP 837
DI 10.1007/s11042-014-2327-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700006
DA 2024-07-18
ER

PT J
AU Chu, WT
   Chao, YC
   Chang, YS
AF Chu, Wei-Ta
   Chao, Ying-Chieh
   Chang, Yi-Sheng
TI Street sweeper: detecting and removing cars in street view images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cascade deformable partmodel; Grabcut; Road structure propagation;
   Hierarchical texture propagation; Randomized texture propagation
AB To protect privacy of individuals or companies that may be leaked in street view images, we present a system to automatically detect and remove cars as if they had never been there. Although street view service providers have made efforts on blurring human faces and license plates, we argue that remaining features, such as license numbers and phone numbers printed on car bodies, could cause privacy leak. Given a sequence of street view images, this system first detects cars by the deformable part model, and then determines foreground/background seeds for the GrabCut image segmentation module in order to facilitate automatic car segmentation. After removing cars, an exemplar-based inpainting method is developed with special designs on filling priority determination and road structure propagation. Hierarchical texture propagation and randomized texture propagation are integrated to implement the inpainting process, so that aesthetically pleasing inpainting results as well as privacy protection can be accomplished.
C1 [Chu, Wei-Ta; Chao, Ying-Chieh; Chang, Yi-Sheng] Natl Chung Cheng Univ, Min Hsiung, Taiwan.
C3 National Chung Cheng University
RP Chu, WT (corresponding author), Natl Chung Cheng Univ, Min Hsiung, Taiwan.
EM wtchu@cs.ccu.edu.tw; raff1219@hotmail.com; kero033@yahoo.com.tw
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
FU National Science Council of Taiwan [NSC101-2221-E-194-055-MY2]
FX The work was partially supported by the National Science Council of
   Taiwan under the grants NSC101-2221-E-194-055-MY2.
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   [Anonymous], 2010, 2010 IEEE COMP VIS P
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Frome A, 2009, IEEE I CONF COMP VIS, P2373, DOI 10.1109/ICCV.2009.5459413
   Guy Richard, 2012, P SIGCHI C HUM FACT, P405, DOI [10.1145/2207676.2207733, DOI 10.1145/2207676.2207733]
   He KM, 2012, LECT NOTES COMPUT SC, V7573, P16, DOI 10.1007/978-3-642-33709-3_2
   Hota RN, 2010, P 3 ANN ACM BANG C
   Huang J-B, 2014, P ACM SIGGRAPH
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   KOPF J, 2010, ACM T GRAPH, V29
   Kuo C-H, 2009, P WORKSH APPL COMP V
   Le Meur O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3401, DOI 10.1109/ICIP.2011.6116441
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tschumperle D, 2005, IEEE T PAMI, V27, P206
   Vincent L, 2007, COMPUTER, V40, P118, DOI 10.1109/MC.2007.442
   Wei Zheng, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2703, DOI 10.1109/CVPRW.2009.5206642
   Weir J, 2010, IEEE INT SYMP CIRC S, P1695, DOI 10.1109/ISCAS.2010.5537511
   Yoshimoto Y., 2011, P ACM INT C INTERACT, P254, DOI [10.1145/2076354.2076402, DOI 10.1145/2076354.2076402]
NR 28
TC 4
Z9 4
U1 0
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10965
EP 10988
DI 10.1007/s11042-014-2213-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700036
DA 2024-07-18
ER

PT J
AU Li, Y
   Qin, Z
   Xu, WR
   Guo, J
AF Li, Yan
   Qin, Zhen
   Xu, Weiran
   Guo, Jun
TI A holistic model of mining product aspects and associated sentiments
   from online reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Aspect-based sentiment summarization; Aspect extraction; Feature
   clustering; Opinion collocation orientation; Sentiment strength
AB Online product reviews are considered a significant information resource useful for both potential customers and product manufacturers. In order to extract the fundamental product aspects and their associated sentiments from those reviews of plain texts, aspect-based sentiment analysis has emerged and has been regarded as a promising technology. This paper proposes a novel model to realize aspect-based sentiment summarization in an integrative way: composing the system with consistently designed feature extraction and clustering, collocation orientation disambiguation, and sentence sentiment strength calculation. Collocations of product features and opinion words are initially extracted through pattern-based bootstrapping. A novel confidence estimation method considering two measurements, Prevalence and Reliability, is exploited to assess both patterns and features. The obtained features are further clustered into aspects. Each cluster is assigned a weight based on arithmetic means of feature similarities and confidences. The orientations of dynamic sentiment ambiguous adjectives (DSAAs) are then determined within opinion collocations. Finally, sentiment strengths of opinion clauses for each aspect are computed according to a set of fine-grained and stratified scoring formulae. Experimental results on a benchmark data set validates the effectiveness of the proposed model.
C1 [Li, Yan; Qin, Zhen; Xu, Weiran; Guo, Jun] Beijing Univ Posts & Telecommun, Sch Informat & Telecommun Engn, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Li, Y (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Telecommun Engn, Xitucheng Rd 10, Beijing 100876, Peoples R China.
EM buptliyan@gmail.com; qinzhenbupt@gmail.com; xuweiran@bupt.edu.cn;
   guojun@bupt.edu.cn
RI Guo, Jun/AAB-9166-2022
OI Guo, Jun/0000-0001-6944-0731
FU 111 Project of China [B08004]; key project of ministry of science and
   technology of China [2011ZX03002-005-01]; National Natural Science
   Foundation of China [61273217]; Ph.D. Programs Foundation of Ministry of
   Education of China [20130005110004]
FX This work was supported by 111 Project of China under Grant No. B08004,
   key project of ministry of science and technology of China under Grant
   No. 2011ZX03002-005-01, National Natural Science Foundation of China
   (61273217) and the Ph.D. Programs Foundation of Ministry of Education of
   China (20130005110004).
CR Agichtein E, 2000, P 6 SIAM INT C DAT M, P539
   [Anonymous], 2011, P 2011 SIAM INT C DA
   [Anonymous], 2008, Proceedings of ACL-08: HLT
   [Anonymous], 2008, P 17 INT C WORLD WID, DOI DOI 10.1145/1367497.1367513
   [Anonymous], 2010, COL 2010 23 INT C CO
   Baccianella S, 2009, LECT NOTES COMPUT SC, V5478, P461, DOI 10.1007/978-3-642-00958-7_41
   Beineke P., 2004, AAAI SPRING S EXPL A
   Brin S, 1999, LECT NOTES COMPUT SC, V1590, P172
   Carenini G., 2005, Proceedings of the 3rd international conference on Knowledge capture (K-CAP '05), P11
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI [DOI 10.1145/1341531.1341561, 10.1145/1341531.1341561]
   Greenwood M., 2006, Proceedings of theWorkshop on Information Extraction beyond the Document, P29
   Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073
   Jo Y, 2010, P 3 INT C WEB SEARCH, P815
   Lu Y, 2009, P 18 INT C WORLD WID, P131, DOI [10.1145/1526709.1526728, DOI 10.1145/1526709.1526728]
   Mei Q., 2007, WWW, DOI DOI 10.1145/1242572.1242596
   Moghaddam Samaneh., 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, P1825, DOI DOI 10.1145/1871437.1871739
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Pantel P, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P113
   Popescu A.-M., 2005, P C HUM LANG TECHN E, P339, DOI DOI 10.3115/1220575.1220618
   Qu L., 2010, COLING, P913
   Riloff E, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P474
   Sudo K, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P224
   Thet TT, 2010, J INF SCI, V36, P823, DOI 10.1177/0165551510388123
   Wilson T., 2005, P HUMAN LANGUAGE TEC, P347, DOI DOI 10.3115/1220575.1220619
   Xu Feiyu., 2010, Proceedings of the 23rd International Conference on Computational Linguistics: Posters, P1354
   Xu Feiyu., 2007, ACL, V7, P584
   Yangarber R, 2001, THESIS
   Zhuang L, 2006, INT C INF KNOWL MAN, V2006, P43, DOI [DOI 10.1145/1183614.1183625, 10.1145/1183614.1183625]
NR 29
TC 24
Z9 25
U1 0
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10177
EP 10194
DI 10.1007/s11042-014-2158-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700001
DA 2024-07-18
ER

PT J
AU Hu, J
   Luo, YP
AF Hu, Jing
   Luo, Yupin
TI Noise-robust video super-resolution using an adaptive spatial-temporal
   filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video super-resolution; Interpolation-based; Mobile-neighborhood
   strategy; Adaptive sharpening
ID KERNEL REGRESSION; IMAGE
AB In this paper, we introduce a new interpolation-based super-resolution scheme for super-resolving a low-resolution video that contains large-scale local motions and/or heavy noise. Our scheme leverages an efficient space-time descriptor to adapt the interpolation kernel to the video's spatial and temporal structures. Nevertheless, in the presence of large-scale local motions, the kernel suffers from tracking the motions incorrectly, leading to inaccurate temporal averaging. To address this problem, prior to computing the interpolation kernel, a mobile-neighborhood strategy that can identify the appropriate neighborhoods in adjacent frames is applied to neutralize the large-scale motions. Furthermore, we incorporate an adaptive sharpening technique into the kernel computation to remove the background noise and enhance the fine details simultaneously. Extensive experimental results on real-world videos show that the proposed method outperforms certain other state-of-the-art video super-resolution algorithms both visually and quantitatively, particularly in the presence of large-scale motions and/or heavy noise.
C1 [Hu, Jing; Luo, Yupin] Tsinghua Univ, Dept Automat, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Hu, J (corresponding author), Tsinghua Univ, Dept Automat, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.
EM j-hu09@mails.tsinghua.edu.cn
FU Brother Industries, Ltd., Japan
FX The work in this paper was supported by Brother Industries, Ltd., Japan.
   We would like to thank Mr. Masaki Kondo for the constructive comments
   and encouragement. We are also grateful to Mr. Zhou for sending us the
   code of [39].
CR [Anonymous], P 16 ACM INT C MULT
   [Anonymous], 2011, Super-Resolution Imaging
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cheng MH, 2011, SIGNAL PROCESS, V91, P1284, DOI 10.1016/j.sigpro.2010.12.016
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deledalle CA, 2012, INT J COMPUT VISION, V99, P86, DOI 10.1007/s11263-012-0519-6
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Ferreira RU, 2012, IEEE IMAGE PROC, P877, DOI 10.1109/ICIP.2012.6467000
   Gao XB, 2011, IEEE T IMAGE PROCESS, V20, P2738, DOI 10.1109/TIP.2011.2134859
   Gupta G, 1995, IEEE T CIRC SYST VID, V5, P477, DOI 10.1109/76.475890
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Kim SH, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1924510
   Kotera H, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1866147
   Krinidis M, 2007, IEEE T CIRC SYST VID, V17, P876, DOI 10.1109/TCSVT.2007.897463
   Lee I-H, 2010, P IEEE INT C IM PROC, P26
   Liu C, 2013, IEEE T PATT IN PRESS
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shahar O, 2011, P IEEE COMP SOC C CO, V1, P20
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409106
   Shen HF, 2007, IEEE T IMAGE PROCESS, V16, P479, DOI 10.1109/TIP.2006.888334
   Song HY, 2013, SIGNAL PROCESS-IMAGE, V28, P763, DOI 10.1016/j.image.2013.03.008
   Su H, 2012, IEEE T IMAGE PROCESS, V21, P1782, DOI 10.1109/TIP.2011.2173204
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Takeda H, 2009, IEEE T IMAGE PROCESS, V18, P1958, DOI 10.1109/TIP.2009.2023703
   Vrigkas M, 2013, SIGNAL PROCESS-IMAGE, V28, P494, DOI 10.1016/j.image.2012.12.008
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang HC, 2013, IEEE T CYBERNETICS, V43, P1035, DOI 10.1109/TSMCB.2012.2222375
   Zhang HC, 2010, LECT NOTES COMPUT SC, V6313, P566
   Zhang LP, 2011, J OPT SOC AM A, V28, P381, DOI 10.1364/JOSAA.28.000381
   Zhao WY, 2002, LECT NOTES COMPUT SC, V2350, P599
   Zhong L, 2013, P IEEE COMP SOC C CO
   Zhou F, 2012, IEEE T IMAGE PROCESS, V21, P3312, DOI 10.1109/TIP.2012.2189576
   Zhu X., 2011, IEEE Workshop on Applications of Computer Vision WACV, P103
NR 39
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9259
EP 9278
DI 10.1007/s11042-014-2079-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200009
DA 2024-07-18
ER

PT J
AU Zhang, T
   Yang, ZJ
   Jia, WJ
   Wu, Q
   Yang, J
   He, XJ
AF Zhang, Tao
   Yang, Zhijie
   Jia, Wenjing
   Wu, Qiang
   Yang, Jie
   He, Xiangjian
TI Fast and robust head detection with arbitrary pose and occlusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head detection; Gaussian energy function; Omega shape; Improved GMM;
   Arbitrary pose and occlusion
ID FACE; TRACKING
AB Head detection in images and videos plays an important role in a wide range of computer vision and surveillance applications. Aiming to detect heads with arbitrarily occluded faces and head pose, in this paper, we propose a novel Gaussian energy function based algorithm for elliptical head contour detection. Starting with the localization of head and shoulder by an improved Gaussian Mixture Model (GMM) approach, the precise head contour is obtained by making use of the Omega shape formed from the head and shoulder. Experimental results on several benchmark datasets demonstrate the superiority of the proposed idea over the state-of-the-art in both detection accuracy and processing speed, even though there are various types of severe occlusions in faces.
C1 [Zhang, Tao; Yang, Zhijie; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200000, Peoples R China.
   [Jia, Wenjing; Wu, Qiang; He, Xiangjian] Univ Technol Sydney, Fac Engn & Informat Technol, Broadway, NSW 2007, Australia.
C3 Shanghai Jiao Tong University; University of Technology Sydney
RP Zhang, T (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 800 Dongchuan Rd, Shanghai 200000, Peoples R China.
EM zhb827@sjtu.edu.cn
RI Yang, Jie/JCD-9867-2023; He, Xiangjian/CAA-1461-2022; Jia,
   Weijia/W-6152-2019; Yang, Zhijie/ACH-5951-2022
OI Yang, Zhijie/0000-0003-1905-9742; Jia, Wenjing/0000-0002-0940-3338; Wu,
   Qiang/0000-0001-5641-2483; He, Xiangjian/0000-0001-8962-540X
FU NSFC, China [61273258, 61105001]
FX This research is partly supported by NSFC, China (No: 61273258,
   61105001).
CR Ba SO, 2004, IEEE INT C PATT REC
   Barth A, 2005, LECT NOTES COMPUT SC, V3663, P442
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Blanz V, 2005, PROC CVPR IEEE, P454
   Chen ML, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P483
   Dong Ligeng., 2010, IEEE Conf. on Acoustics, Speech, P1470
   Gourier N, 2006, CLEAR WORKSH CONJ FA
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Hu CL, 2013, IEEE INT CON MULTI
   Hu CL, 2014, MULTIMED TOOLS APPL, V73, P1863, DOI 10.1007/s11042-013-1676-5
   Ishii Y, 2004, INT C PATT RECOG, P298, DOI 10.1109/ICPR.2004.1334526
   Jinfu Yang, 2012, 2012 IEEE International Conference on Mechatronics and Automation (ICMA), P658, DOI 10.1109/ICMA.2012.6283220
   Kim G, 2010, I C CONT AUTOMAT ROB, P627, DOI 10.1109/ICARCV.2010.5707762
   Li H, 2009, IEEE IMAGE PROC, P3181, DOI 10.1109/ICIP.2009.5414398
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Liu J., 2013, MATH PROBL ENG, V2013, P1
   Liu XW, 2012, RECENT ADV COMPUT SC, V125, P147
   Liyu Gong, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2366, DOI 10.1109/CVPRW.2009.5206506
   Maggio E, 2007, INT CONF ACOUST SPEE, P1101
   Marciniak T, 2015, MULTIMED TOOLS APPL, V74, P4329, DOI 10.1007/s11042-013-1568-8
   Nanda H, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/AFGR.2004.1301577
   Tao Yang, 2004, Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788), P1910
   Wu J, 2008, PATTERN RECOGN, V41, P1138, DOI 10.1016/j.patcog.2007.07.017
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yao ZR, 2006, IMAGE VISION COMPUT, V24, P573, DOI 10.1016/j.imavis.2005.09.007
   Yoon H, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4558, DOI 10.1109/IROS.2006.282159
   Zhang JM, 2007, 2007 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY: ENHANCING CRITICAL INFRASTRUCTURE DEPENDABILITY, P64, DOI 10.1109/WI-IATW.2007.84
   Zhang SC, 2005, PATTERN RECOGN, V38, P273, DOI 10.1016/j.patcog.2004.03.014
   Zhang Z, 2008, IEEE IMAGE PROC, P1644, DOI 10.1109/ICIP.2008.4712087
   Zou W, 2009, J VIS COMMUN IMAGE R, V20, P217, DOI 10.1016/j.jvcir.2009.01.005
NR 31
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9365
EP 9385
DI 10.1007/s11042-014-2110-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200014
DA 2024-07-18
ER

PT J
AU Kang, SK
   Chung, KY
   Lee, JH
AF Kang, Sung-Kwan
   Chung, Kyung-Yong
   Lee, Jung-Hyun
TI Ontology-based inference system for adaptive object recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object recognition; Context-awareness; Context modeling; Inference
AB This paper presents a statistical ontology approach for adaptive object recognition in a situation-variant environment. We propose a context model based on statistical ontology that is concentrated on object recognition. Due to the effects of illumination on a supreme obstinate designing context-sensitive recognition system, we focused on designing a context-variant system using statistical ontology. Ontology, a collection of concepts and their interrelationships, provides an abstract view of an application domain. Researchers produce ontologies in order to understand and explain underlying principles and environmental factors. In this paper, we propose an ontology-based inference system for adaptive object recognition. The proposed method utilizes context ontology, context modeling, context adaptation, and context categorization to design the ontology based on illumination criteria for surveillance. After selecting the proper ontology domain, a set of actions is selected that produces better performance in that domain. We also carried out extensive experiments on these concepts in the area of object recognition in a dynamic changing environment, achieving enormous success that will enable us to proceed with our basic concepts.
C1 [Kang, Sung-Kwan] Inha Univ, Dept Comp & Informat Engn, HCI Lab, Inchon 402751, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
   [Lee, Jung-Hyun] Inha Univ, Dept Comp & Informat Engn, Inchon 402751, South Korea.
C3 Inha University; Sangji University; Inha University
RP Kang, SK (corresponding author), Inha Univ, Dept Comp & Informat Engn, HCI Lab, Yonghyeon 1,4 Dong, Inchon 402751, South Korea.
EM kskk1111@empas.com; dragonhci@hanmail.net; jhlee@inha.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
FU Korea Foundation for the Advancement of Science & Creativity (KOFAC);
   Korean Government (MOE)
FX This work was supported by the Korea Foundation for the Advancement of
   Science & Creativity (KOFAC), and funded by the Korean Government (MOE).
CR Abdel-Mottaleb M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P622, DOI 10.1109/ICIP.1999.817190
   [Anonymous], STAT MODELS APPEARAN
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2015, MULTIMED TOOLS APPL, V74, P8893
   Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   Bezdek J. C., 1997, Soft Computing, V1, P166, DOI 10.1007/s005000050019
   Celentano A, 2006, MULTIMED TOOLS APPL, V29, P7, DOI 10.1007/s11042-006-7811-9
   Chen Q., 1998, P IEEE INT C AUT FAC
   Davidson Lallman Bundick., 2001, Proceedings of 2001 AIAA Guidance, Navigation, and Control Conference and Exhibit, P1, DOI 10.31399/asm.tb.aub.9781627082976
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Gomez A, 2004, ONTOLOGICAL ENG
   Ha OK, 2014, PERS UBIQUIT COMPUT, V18, P553, DOI 10.1007/s00779-013-0675-x
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jung EY, 2013, WIRELESS PERS COMMUN, V73, P207, DOI 10.1007/s11277-013-1231-8
   Kang SK, 2012, P 2 INT C IT CONV SE, P843
   Kang SK, 2011, LNEE, V120, P295
   Kang SK, 2014, PERS UBIQUIT COMPUT, V18, P515, DOI 10.1007/s00779-013-0668-9
   Kapoor Ashish., 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, P1
   Kawato S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P40, DOI 10.1109/AFGR.2000.840610
   Kim GH, 2015, MULTIMED TOOLS APPL, V74, P8745, DOI 10.1007/s11042-013-1536-3
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim SH, 2015, MULTIMED TOOLS APPL, V74, P8939, DOI 10.1007/s11042-013-1584-8
   Kim SH, 2014, MULTIMED TOOLS APPL, V68, P455, DOI 10.1007/s11042-013-1356-5
   Ko JW, 2015, MULTIMED TOOLS APPL, V74, P8907, DOI 10.1007/s11042-013-1581-y
   Lee JE, 2015, MULTIMED TOOLS APPL, V74, P9067, DOI 10.1007/s11042-013-1594-6
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Liu DH, 2005, PATTERN RECOGN, V38, P1705, DOI 10.1016/j.patcog.2005.03.009
   LUMIA R, 1983, COMPUT VISION GRAPH, V22, P287, DOI 10.1016/0734-189X(83)90071-3
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Oh SY, 2014, CLUSTER COMPUT, V17, P893, DOI 10.1007/s10586-013-0284-5
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Pitas I., 1993, DIGITAL IMAGE PROCES
   Qing LY, 2005, INT J PATTERN RECOGN, V19, P513, DOI 10.1142/S0218001405004186
   Shin DK, 2015, MULTIMED TOOLS APPL, V74, P9043, DOI 10.1007/s11042-013-1539-0
   Song CW, 2014, MULTIMED TOOLS APPL, V71, P813, DOI 10.1007/s11042-013-1362-7
   Tan WZ, 2003, EXPERT SYST APPL, V25, P461, DOI 10.1016/S0957-4174(03)00088-5
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Yang T, 2004, P WORLD C INT CONTR
NR 38
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8893
EP 8905
DI 10.1007/s11042-013-1738-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600013
DA 2024-07-18
ER

PT J
AU Oh, SY
   Chung, KY
AF Oh, Sang-Yeob
   Chung, Kyung-Yong
TI Traffic hazard prediction based on neighbor nodes for vehicle safety
   communications on a highway
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VSC; Back-off; Broadcasting; Emergency message; Vehicle safety
AB Vehicle safety communications is an important technology for protecting against automobile accidents. The number of neighbor nodes is important in the automobile industry, which is becoming increasingly more customer-oriented. For this, many protocols that forward a safe message have been studied to protect against chain-reaction collisions when an automobile accident occurs. In this paper, we propose a traffic hazard prediction model based on neighbor nodes for vehicle safety communications on a highway. Highways have high potential of 'chain-reaction collisions' due to the high velocity of vehicles. As a preventive method against chain-reaction collisions, native and intelligent broadcasting sends emergency messages to rear vehicles. However, these methods are ineffective when vehicles are concentrated in one area. This paper offers a broadcasting method considering stopping distance that features an improved back-off algorithm based on the number of neighbor nodes. In comparing the two different methods, our broadcasting method showed a 7 % improvement in frame reception success rate than native and intelligent broadcasting. Finally, this paper suggests empirical applications to verify the adequacy and validity of this system.
C1 [Oh, Sang-Yeob] Gachon Univ, Dept Interact Media, Songnam 461701, Gyeonggi Do, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
C3 Gachon University; Sangji University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
EM syoh@gachon.ac.kr; dragonhci@hanmail.net
RI Chung, Kyungyong/JAC-2276-2023
FU Basic Science Research Program through National Research Foundation of
   Korea - Ministry of Education, Science and Technology [2012-0004478]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Education, Science and Technology (No. 2012-0004478).
CR An X, 2006, COLLABORATIVE TECHNO, P256
   Biswas S, 2006, IEEE COMMUN MAG, V44, P74, DOI 10.1109/MCOM.2006.1580935
   Chen W, 2005, IEEE COMMUN MAG, V43, P100, DOI 10.1109/MCOM.2005.1421912
   Dagan E, 2004, INT VEH S, P14
   Fukuhara T, 2005, IEEE WCNC, P2252
   Hasegawa T, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P810, DOI 10.1109/ITSC.2004.1399006
   Jalali M, 2010, EXPERT SYST APPL, V37, P6201, DOI 10.1016/j.eswa.2010.02.105
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kim JH, 2012, MULTIMEDIA TOOLS APP, DOI 10.1007/s11042-011-0920-0
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P827, DOI 10.1007/s11042-012-1195-9
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim SH, 2014, MULTIMED TOOLS APPL, V68, P455, DOI 10.1007/s11042-013-1356-5
   Kim TH, 2005, LECT NOTES ARTIF INT, V3809, P1150
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Manaseer S, 2006, TECHNICAL REPORT
   MICHAEL T, 1997, MACHING LEARNING, P154
   Nithya B, 2012, PROC TECH, V1, P840, DOI 10.1016/j.protcy.2012.10.102
   Oh SY, 2012, P INT C IT CONV SEC, P569
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rackley S., 2007, WIRELESS NETWORKING
   Seiler P., 1998, SAE Special Publications, V1332, P97
   Sichitiu ML, 2008, IEEE COMMUN SURV TUT, V10, P88, DOI 10.1109/COMST.2008.4564481
   Song CW, 2014, MULTIMED TOOLS APPL, V71, P813, DOI 10.1007/s11042-013-1362-7
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Wu SL, 2000, I-SPAN 2000: INTERNATIONAL SYMPOSIUM ON PARALLEL ARCHITECTURES ALGORITHMS AND NETWORKS, PROCEEDINGS, P232, DOI 10.1109/ISPAN.2000.900290
NR 25
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8781
EP 8790
DI 10.1007/s11042-013-1514-9
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600005
DA 2024-07-18
ER

PT J
AU Baskaran, VM
   Chang, YC
   Loo, J
   Wong, K
AF Baskaran, Vishnu Monn
   Chang, Yoong Choon
   Loo, Jonathan
   Wong, KokSheik
TI Design and implementation of parallel video combiner architecture for
   multi-user video conferencing at ultra-high definition resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video combiner; Parallel processing architecture; Balanced workload;
   Multi-user video conferencing; Ultra-high definition resolution
ID PROGRAMMING-MODELS; LOW-COMPLEXITY; MULTIPOINT; SURVEILLANCE
AB In software driven multi-user video conferencing systems, consumer progression towards ultra-high definition (i.e., 8 k) resolution introduces new challenges to the video combination process in sustaining smooth combined video playback at high frame rates. As such, this paper analyzes the underlying architecture of a conventional video combiner to identify the performance impact of combined video frame rates at ultra-high definition resolutions. Then, two straightforward parallel video combination architectures using software application threads, namely PVC-1 and PVC-2, are studied as a benchmark. In PVC-1, the number of application threads tallies with the number of client videos to be combined, which improves playback performance at the expense of inconsistencies in inset client frame rates within a combined video. PVC-2 includes a synchronizer to address these inconsistencies, but exhibits marginal performance gains. To address the aforementioned problems, a balanced workload parallel video combiner architecture is proposed, namely PVC-3. In this architecture, a balanced workload management algorithm stitches client videos into an ultra-high definition combined frame, based on the number of available logical processors on a multi-core processor. This method improves frame rate performance and sustains consistent client frame rates within a combined video. Experimental results suggest that PVC-3 is superior over PVC-2 and achieves a frame rate performance gain of 27 % against a conventional video combiner for a combined video of 16 clients (each at a resolution of 720p) and zero standard deviation in combined frame rate consistency.
C1 [Baskaran, Vishnu Monn; Chang, Yoong Choon] Multimedia Univ, Fac Engn, Persiaran Multimedia, Cyberjaya 63100, Selangor, Malaysia.
   [Loo, Jonathan] Middlesex Univ, Sch Sci & Technol, London NW4 4BT, England.
   [Wong, KokSheik] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
C3 Multimedia University; Middlesex University; Universiti Malaya
RP Baskaran, VM (corresponding author), Multimedia Univ, Fac Engn, Persiaran Multimedia, Cyberjaya 63100, Selangor, Malaysia.
EM vishnu.monn@gmail.com; ycchang@mmu.edu.my; J.Loo@mdx.ac.uk;
   koksheik@um.edu.my
RI Loo, Jonathan/E-6075-2019; Wong, KokSheik/B-9796-2011
OI Loo, Jonathan/0000-0002-2197-8126; Wong, KokSheik/0000-0002-4893-2291;
   CHANG, Yoong Choon/0000-0002-4065-1639
FU University Malaya Research Collaboration Grant (Title: Realistic
   Video-based Assistive Living) under the purview of University of Malaya
   Research [CG009-2013]; Multimedia University Residual Fund
FX This work was supported by the University Malaya Research Collaboration
   Grant (Title: Realistic Video-based Assistive Living, Grant Number:
   CG009-2013) under the purview of University of Malaya Research, and the
   Multimedia University Residual Fund. The authors would like to thank the
   anonymous reviewers for their constructive and invaluable comments in
   improving the quality of this article.
CR Amer I, 2009, IEEE SIGNAL PROC MAG, V26, P113, DOI 10.1109/MSP.2009.934107
   Banerji AK, 2006, J VIS COMMUN IMAGE R, V17, P490, DOI 10.1016/j.jvcir.2005.05.007
   Baskaran VM, 2010, PROCEEDINGS OF THE 2010 IEEE ASIA PACIFIC CONFERENCE ON CIRCUIT AND SYSTEM (APCCAS), P156, DOI 10.1109/APCCAS.2010.5774918
   Baskaran VM, 2013, J NETW COMPUT APPL, V36, P336, DOI 10.1016/j.jnca.2012.05.008
   Bhandarkar SM, 2004, PARALLEL COMPUT, V30, P1233, DOI 10.1016/j.parco.2004.05.002
   Chen JYC, 2007, IEEE T SYST MAN CY A, V37, P1063, DOI 10.1109/TSMCA.2007.904779
   Cucchiara R, 2010, LECT NOTES COMPUT SC, V5960, P89, DOI 10.1007/978-3-642-12349-8_6
   Cycon Hans L., 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P890, DOI 10.1109/ISCE.2009.5157038
   Diaz J, 2012, IEEE T PARALL DISTR, V23, P1369, DOI 10.1109/TPDS.2011.308
   El Saddik A, 2008, MULTIMED TOOLS APPL, V39, P353, DOI 10.1007/s11042-007-0165-0
   Fung KT, 2004, IEEE T MULTIMEDIA, V6, P31, DOI 10.1109/TMM.2003.819761
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   Halák J, 2011, FUTURE GENER COMP SY, V27, P886, DOI 10.1016/j.future.2010.11.014
   Hyun W., 2011, P IEEE ASIA PACIFIC, P327
   Jie Y, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1980
   Kalva H, 2011, MULTIMED TOOLS APPL, V51, P801, DOI 10.1007/s11042-010-0656-2
   Kim CG, 2014, MULTIMED TOOLS APPL, V68, P237, DOI 10.1007/s11042-011-0906-y
   Kitamura M, 2011, FUTURE GENER COMP SY, V27, P952, DOI 10.1016/j.future.2010.11.025
   Li P, 2005, IEEE T CIRC SYST VID, V15, P1098, DOI 10.1109/TCSVT.2005.852627
   Lin CW, 2003, IEEE T CIRC SYST VID, V13, P982, DOI 10.1109/TCSVT.2003.816505
   Lin D, 2009, IEEE SIGNAL PROC MAG, V26, P103, DOI 10.1109/MSP.2009.934116
   Lo WY, 2011, IEEE T CIRC SYST VID, V21, P1769, DOI 10.1109/TCSVT.2011.2130250
   Lu Y, 2010, LECT NOTES COMPUT SC, V6091, P96, DOI 10.1007/978-3-642-12963-6_8
   Meier R, 2012, SIGNAL PROCESS-IMAGE, V27, P457, DOI 10.1016/j.image.2012.02.008
   Rodríguez A, 2006, PAR ELEC 2006: INTERNATIONAL SYMPOSIUM ON PARALLEL COMPUTING IN ELECTRICAL ENGINEERING, PROCEEDINGS, P363
   Rodríguez-Sánchez R, 2013, MULTIMED TOOLS APPL, V66, P361, DOI 10.1007/s11042-012-1056-6
   Shirai D, 2011, FUTURE GENER COMP SY, V27, P986, DOI 10.1016/j.future.2010.11.021
   Sodan AC, 2010, COMPUTER, V43, P24, DOI 10.1109/MC.2010.75
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun MT, 1997, IEEE T CIRC SYST VID, V7, P855, DOI 10.1109/76.644065
   Tien Anh Le, 2010, 2010 Second International Conference on Ubiquitous and Future Networks (ICUFN), P394, DOI 10.1109/ICUFN.2010.5547169
   Varoglu S, 2011, PARALLEL COMPUT, V37, P26, DOI 10.1016/j.parco.2010.08.006
   Vatavu RD, 2010, HUM-COMPUT INT-SPRIN, P121, DOI 10.1007/978-1-84882-701-1_12
   Zhu QF, 1999, IEEE T CIRC SYST VID, V9, P666, DOI 10.1109/76.767130
NR 34
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6589
EP 6622
DI 10.1007/s11042-014-1907-4
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800001
DA 2024-07-18
ER

PT J
AU Hsieh, HJ
   Chen, B
   Hung, JW
AF Hsieh, Hsin-Ju
   Chen, Berlin
   Hung, Jeih-weih
TI Histogram equalization of contextual statistics of speech features for
   robust speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic speech recognition; Noise robustness; Histogram equalization;
   Feature contextual statistics
ID ENHANCEMENT; NOISE
AB In the recent past, we have witnessed a flurry of research activity aimed at the development of novel and ingenious robustness methods for automatic speech recognition (ASR). Among them, histogram equalization (HEQ) of speech features constitutes one most prominent and successful line of research due to its inherent neat formulation and remarkable performance. In this paper, we adopt an effective modeling framework for joint equalization of spatial-temporal contextual statistics of speech features. On top of that, we explore various combinations of simple differencing and averaging operations to render the contextual relationships of feature vector components, not only between different dimensions but also between consecutive speech frames, in the HEQ process. Furthermore, several variants of HEQ are investigated and integrated into the proposed modeling framework to efficiently compensate for the effects of noise interference on the feature vector components. In addition, the utilities of the methods deduced from this framework and several existing robustness methods are analyzed and compared extensively. All experiments were carried out on the Aurora-2 database and task, and were further verified on the Aurora-4 database and task. Empirical experimental results suggest that our proposed methods can offer substantial improvements over the baseline system and achieve performance competitive to or better than some of the existing noise robustness methods in speech recognition.
C1 [Hsieh, Hsin-Ju; Chen, Berlin] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Hsieh, Hsin-Ju; Hung, Jeih-weih] Natl Chi Nan Univ, Dept Elect Engn, Nantou, Taiwan.
C3 National Taiwan Normal University; National Chi Nan University
RP Chen, B (corresponding author), Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM berlin@csie.ntnu.edu.tw
FU "Aim for the Top University Project" of National Taiwan Normal
   University (NTNU) - Ministry of Education, Taiwan; National Science
   Council, Taiwan [NSC 101-2221-E-003-024-MY3, NSC 102-2221-E-003-014-,
   NSC 101-2511-S-003-057-MY3, NSC 101-2511-S-003-047-MY3, NSC
   103-2911-I-003-301]
FX This work is supported in part by the "Aim for the Top University
   Project" of National Taiwan Normal University (NTNU), sponsored by the
   Ministry of Education, Taiwan, and in part by the National Science
   Council, Taiwan, under Grants NSC 101-2221-E-003-024-MY3, NSC
   102-2221-E-003-014-, NSC 101-2511-S-003-057-MY3, NSC
   101-2511-S-003-047-MY3 and NSC 103-2911-I-003-301.
CR Acharya T, 2005, IMAGE PROCESSING: PRINCIPLES AND APPLICATIONS, P1, DOI 10.1002/0471745790
   Alpaydin E, 2010, BOOK INTRO MACHINE L, P288
   [Anonymous], 1996, THESIS CARNEGIE MELL
   [Anonymous], 2006, The HTK book (for HTK version 3.4) [Computer software manual]
   ATAL BS, 1974, J ACOUST SOC AM, V55, P1304, DOI 10.1121/1.1914702
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Buera L, 2007, IEEE T AUDIO SPEECH, V15, P1098, DOI 10.1109/TASL.2006.885244
   Chen B, 2010, BOOK RECENT ADV ROBU
   Chen B, 2013, INFORM PROCESS MANAG, V49, P1, DOI 10.1016/j.ipm.2011.12.002
   Chen B, 2012, IEEE T AUDIO SPEECH, V20, P2602, DOI 10.1109/TASL.2012.2208628
   Chen WH, 2008, P ANN C INT SPEECH C, P2204
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   de la Torre A, 2005, IEEE T SPEECH AUDI P, V13, P355, DOI 10.1109/TSA.2005.845805
   Dharanipragada S., 2000, P ICSLP, V4, P556
   Droppo J., 2008, Springer Handbook of Speech Processing, P653
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530
   GALES MJ, 1995, THESIS CAMBRIDGE U
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J
   Hilger F, 2006, IEEE T AUDIO SPEECH, V14, P845, DOI 10.1109/TSA.2005.857792
   Hirsch HG, 2002, P ISCA ITRW ASR 2002
   Hirsch HG, 2002, EXPT FRAMEWORK PERFO
   Hsieh H.-J., 2012, P ANN C INT SPEECH C
   Hsu CW, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P197
   Hung JW, 2009, IEEE SIGNAL PROC LET, V16, P806, DOI 10.1109/LSP.2009.2024113
   Junqua JC, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2262, DOI 10.1109/ICSLP.1996.607257
   Kanedera N., 1997, P EUR, P1079
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010
   LIM JS, 1979, P IEEE, V67, P1586, DOI 10.1109/PROC.1979.11540
   Lin SH, 2009, IEEE T AUDIO SPEECH, V17, P84, DOI 10.1109/TASL.2008.2007612
   Macho D., 2002, P ICSLP, P17
   Molau S, 2003, SPEECH COMMUN, V41, P579, DOI 10.1016/S0167-6393(03)00085-2
   Saon G, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P329
   Segura JC, 2004, IEEE SIGNAL PROC LET, V11, P517, DOI 10.1109/LSP.2004.826648
   Suk YH, 1999, ELECTRON LETT, V35, P527, DOI 10.1049/el:19990215
   Viikki O, 1998, SPEECH COMMUN, V25, P133, DOI 10.1016/S0167-6393(98)00033-8
   Vikas J., 2011, P INTERSPEECH FLOR I, P1661
   Wu J, 2006, IEEE T AUDIO SPEECH, V14, P2147, DOI 10.1109/TASL.2006.872616
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
NR 40
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6769
EP 6795
DI 10.1007/s11042-014-1929-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800010
DA 2024-07-18
ER

PT J
AU Kolivand, H
   Sunar, MS
AF Kolivand, Hoshang
   Sunar, Mohd Shahrizal
TI Anti-aliasing in image based shadow generation techniques: a
   comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anti-aliasing; Shadow generation; Real-time shadows; Image based shadows
ID REAL-TIME; SOFT SHADOW; ALGORITHMS
AB This research provides an overview of popular and widely used techniques to overcome aliasing in image based shadow generation techniques. Aliasing is a critical drawback of image based techniques in shadow generation. Many techniques are proposed to enhance the anti-aliasing. We have classified and systemized these techniques. The main goal of this paper is to provide researchers with background on a variety of techniques to reduce the aliasing so as make it easier for them to choose the method best suited to their aims. During categorizing the anti-aliasing techniques, well-known techniques to enhance aliasing is described detail, along with a discussion of the advantages and drawbacks of each. The algorithms are also comprehensively summarized and analysed in depth. It is also hoped that our analysis helps researchers find solutions to the shortcomings of each technique.
C1 [Kolivand, Hoshang; Sunar, Mohd Shahrizal] Univ Teknol Malaysia, UTM IRDA Digital Media Ctr, MaGIC Media & Games Innovat Ctr Excellence X, Skudai 81310, Kagawa, Malaysia.
C3 Universiti Teknologi Malaysia
RP Kolivand, H (corresponding author), Univ Teknol Malaysia, UTM IRDA Digital Media Ctr, MaGIC Media & Games Innovat Ctr Excellence X, Skudai 81310, Kagawa, Malaysia.
EM shahinkey@yahoo.com
RI Kolivand, Hoshang/F-4736-2011; Sunar, Mohd Shahrizal/AFQ-7366-2022;
   Kolivand, Hoshang/B-2501-2016
OI Sunar, Mohd Shahrizal/0000-0002-0244-1622; Kolivand,
   Hoshang/0000-0001-5460-5679
CR Aila Timo., 2004, Proceedings of the Fifteenth Eurographics Conference on Rendering Techniques, P161
   Annen T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360633
   Annen Thomas., 2007, Proc. Eurographics Symposium on Ren- dering, P51
   Annen Thomas., 2008, P GRAPHICS INTERFACE, P155
   [Anonymous], 2012, MATH PROBLEMS ENG
   Arvo J, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P240, DOI 10.1109/CGI.2004.1309216
   Bao GB, 2012, COMPUT GRAPH-UK, V36, P140, DOI 10.1016/j.cag.2012.01.005
   Boulanger K., 2008, THESIS
   Bouville C., 1988, EUROGRAPHICS '88. Proceedings of the European Computer Graphics Conference and Exhibition, P483
   Brabec S, 2003, COMPUT GRAPH FORUM, V22, P433, DOI 10.1111/1467-8659.00691
   BRABEC S, 2002, J GRAPHICS TOOLS, V7, P9
   Bruneton E, 2012, COMPUT GRAPH FORUM, V31, P373, DOI 10.1111/j.1467-8659.2012.03016.x
   Chong HamiltonY., 2004, P EUROGRAPHICS S REN, P167
   Chong HY, 2007, SCENE OPTIMIZED SHAD
   Chong HY-I, 2003, TECHNICAL REPORT
   COOK RL, 1986, ACM T GRAPHIC, V5, P51, DOI 10.1145/7529.8927
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Crow F.C., 1977, ACM SIGGRAPH COMPUT, V11, P242, DOI [DOI 10.1145/965141.563901, DOI 10.1145/563858.563901]
   CROW FC, 1977, COMMUN ACM, V20, P799, DOI 10.1145/359863.359869
   Cruz DD, 2003, SHADOW MAPS A SURVEY
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dimitrov R, 2007, TECHNICAL REPORT
   Eisemann E., 2011, Real-time shadows, DOI DOI 10.1201/B11030
   Eisemann E., 2009, ACM_SIGGRAPH_ASIA_2009_Courses_on_-_SIGGRAPH_ASIA_'09, P21
   Fernando R, 2001, COMP GRAPH, P387, DOI 10.1145/383259.383302
   FERNANDO R., 2005, ACM SIGGRAPH 2005 SK
   Giegl Markus, 2007, Proceedings Graphics Interface 2007, P159, DOI 10.1145/1268517.1268545
   GIEGL M, 2007, P ACM SIGGRAPH 2007, P65
   Gumbau J, 2011, P 10 INT C VIRT REAL, P75, DOI DOI 10.1145/2087756.2087766>
   Gumbau J, 2013, COMPUT GRAPH
   Haeberli P., 1990, Computer Graphics, V24, P309, DOI 10.1145/97880.97913
   Haines Eric., 2001, J GRAPHICS TOOLS, V6, P19
   Hasenfratz JM, 2003, COMPUT GRAPH FORUM, V22, P753, DOI 10.1111/j.1467-8659.2003.00722.x
   HOURCADE JC, 1985, COMPUT GRAPH, V9, P259, DOI 10.1016/0097-8493(85)90052-4
   Isaza C, 2013, MULTIMED TOOLS APPL, P1
   Jia N, 2013, P 19 ACM S VIRT REAL, P209
   Kolic I, 2012, VIRTUAL REAL-LONDON, V16, P289, DOI 10.1007/s10055-012-0207-4
   Kolivand Hoshang, 2011, Journal of Computer Sciences, V7, P980, DOI 10.3844/jcssp.2011.980.985
   Kolivand H, 2011, INT J MULTIMED APPL, V3, P980
   Kolivand H, 2013, MULTIMED TOOLS APPL, P1
   Kolivand H., 2011, INT J COMPUTER GRAPH, V2, P1
   Kolivand H, 2013, IETE TECH REV, V30, P38, DOI 10.4103/0256-4602.107338
   Kolivand H, 2012, INT J INNOV COMPUT I, V8, P7169
   Kozlov S., 2004, GPU GEMS, P217
   Lauritzen A, 2010, ADV REAL TIME RENDER
   Lauritzen A., 2011, Symposium on Interactive 3D graphics and games (I3D' 11), P97
   Lauritzen Andrew., 2008, P GRAPHICS INTERFACE, P139
   Lecocq P, 2011, SUBPIXEL SHADOW MAPP
   Lefohn AE, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289611
   Li S, 2007, INT C COMP AID DES C, P161
   Li S, 2008, COMPUT GRAPH-UK, V32, P660, DOI 10.1016/j.cag.2008.09.011
   Liang XH, 2011, J COMPUT SCI TECH-CH, V26, P176, DOI 10.1007/s11390-011-9424-7
   Lloyd B, 2007, THESIS U N CAROLINA
   Lloyd Brandon., 2004, P 15 EUROGRAPHICS WO, P197
   Lloyd Brandon., 2006, P EUROGRAPHICS S REN, V2006, P215
   Lloyd DB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409628
   Lokovic T, 2000, COMP GRAPH, P385, DOI 10.1145/344779.344958
   Lu Liu, 2011, 2011 International Conference on Multimedia Technology, P5464
   Luisier F, 2011, IEEE T IMAGE PROCESS, V20, P696, DOI 10.1109/TIP.2010.2073477
   Martin Tobias., 2004, P EUROGRAPHICS S REN, P153
   Maule M., 2012, 2012 XXV SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T), P50, DOI 10.1109/SIBGRAPI-T.2012.9
   McGuire Morgan., 2003, Fast, practical and robust shadows
   McGuire Morgan, 2011, S INTERACTIVE 3D GRA, P89, DOI [DOI 10.1145/1944745.1944760, 10.1145/19447451944760, DOI 10.1145/19447451944760]
   Nan Liu, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P488, DOI 10.1109/WCSE.2009.716
   Nishita T., 1985, Computer Graphics, V19, P23, DOI 10.1145/325165.325169
   Olshausen BA, 2000, ALIASING PSC 129 SEN, P3
   OSMAN B., 2006, P 2006 ACM SIGGRAPH, P103
   Pan MH, 2009, COMPUT GRAPH FORUM, V28, P1927, DOI 10.1111/j.1467-8659.2009.01571.x
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Reeves W, 1987, P SIGGRAPH 87, V21, P557
   Salvi M, 2010, COMPUT GRAPH FORUM, V29, P1289, DOI 10.1111/j.1467-8659.2010.01724.x
   Scherzer D, 2011, COMPUT GRAPH FORUM, V30, P169, DOI 10.1111/j.1467-8659.2010.01841.x
   Shang T, 2012, APPL MECH MATER, V174-177, P1927, DOI 10.4028/www.scientific.net/AMM.174-177.1927
   Shen L, 2013, COMPUT GRAPH FORUM, V32, P107, DOI 10.1111/cgf.12156
   Shen L, 2011, COMPUT GRAPH FORUM, V30, P493, DOI 10.1111/j.1467-8659.2011.01875.x
   Sintorn E, 2008, COMPUT GRAPH FORUM, V27, P1285, DOI 10.1111/j.1467-8659.2008.01267.x
   Stamminger M, 2002, P SIGGRAPH
   Tessman T, 1989, CASTING SHADOWS FLAT, P16
   Vanek Juraj, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P421
   Whitted T., 2005, ACM SIGGRAPH 2005 CO, P4, DOI [10.1145/1198555.1198743, DOI 10.1145/1198555.1198743]
   William D., 2006, P 2006 S INT 3D GRAP, P161, DOI DOI 10.1145/1111411.1111440
   Williams L., 1978, P ANN C COMP GRAPH I, P270
   Wimmer M, 2006, SHADERX 4 ADV RENDER
   Wimmer Michael., 2004, Proceedings of the 15th Eurographics Conference on Rendering Techniques, P143, DOI DOI 10.2312/EGWR/EGSR04/143-151
   WOO A, 1990, IEEE COMPUT GRAPH, V10, P13, DOI 10.1109/38.62693
   Yang BG, 2010, COMPUT GRAPH FORUM, V29, P2127, DOI 10.1111/j.1467-8659.2010.01800.x
   Zhang CX, 2003, IEEE T VIS COMPUT GR, V9, P139, DOI 10.1109/TVCG.2003.1196002
   Zhang F, 2009, SHADERX, V7, P305
   Zhang F., 2007, GPU GEMS, V3, P203
   Zhang F., 2006, Proceedings of the 2006 ACM international conference on virtual reality continuum and its applications, ACM Press, P311, DOI 10.1145/1128923.1128975
   Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328
NR 91
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7461
EP 7487
DI 10.1007/s11042-014-1987-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200003
DA 2024-07-18
ER

PT J
AU Llorente, S
   Delgado, J
   Maronas, X
   Florido, J
AF Llorente, Silvia
   Delgado, Jaime
   Maronas, Xavier
   Florido, Jonathan
TI Definition of standards-based building blocks for multimedia content
   management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Standards; Building Blocks; MPEG-M; MIPAMS; Android; Demonstration
AB The emergence of new ways of rendering multimedia content from a multiplicity of devices like tablets, smartphones, consoles or smart TVs, opens a complete set of new opportunities for multimedia services providers. It is important that the development of those disruptive services is done in an interoperable way. Existing service-oriented middleware platforms and recently developed standards devoted to the definition and implementation of complex multimedia services may speed up its development. In this context, the identification of different content management scenarios including the high-level functionalities they require is an important aspect to be able to implement services in a flexible and interoperable way. Use of standards and standards-based architectures will be a key aspect to combine services offered by different providers. In this paper, we propose the definition of standards-based building blocks based on the high-level functionalities required by content management and distribution scenarios. This will facilitate provision of complex new services specially focused, but not limited to, the management and distribution of multimedia content.
C1 [Llorente, Silvia; Delgado, Jaime; Maronas, Xavier; Florido, Jonathan] Univ Politecn Cataluna, BarcelonaTECH, DAC, DMAG, ES-08034 Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Llorente, S (corresponding author), Univ Politecn Cataluna, BarcelonaTECH, DAC, DMAG, C Jordi Girona 1-3, ES-08034 Barcelona, Spain.
EM silviall@ac.upc.edu; jaime.delgado@ac.upc.edu; xmaronas@ac.upc.edu;
   jflorido@ac.upc.edu
RI Llorente, Silvia/B-1212-2012; Delgado, Jaime/AAA-8489-2019
OI Llorente, Silvia/0000-0003-2000-6912; Delgado, Jaime/0000-0003-1366-663X
FU Spanish government [TEC2011-22989]
FX This work has been partially supported by the Spanish government through
   the project "Proteccion, busqueda e interoperabilidad de contenidos
   multimedia: Nuevas tecnicas y aplicaciones" (PBInt) (TEC2011-22989).
CR [Anonymous], 1985, 959 RFC INT ENG TASK
   [Anonymous], 2010, HL7 CLIN DOC ARCH CD
   [Anonymous], 2008, 136061 ISO
   [Anonymous], 2005, Oasis extensible access control markup language (xacml)
   Delgado J, 2013, 103 MPEG M HELD GEN
   Delgado J, 2010, 2 ACM WORKSH SOC MED
   Delgado J, 2011, TRUSTWORTHY INTERNET, P335, DOI 10.1007/978-88-470-1818-1_25
   Delgado J, 2012, CONSUM COMM NETWORK, P527, DOI 10.1109/CCNC.2012.6181035
   Eggersmann M, 2008, LECT NOTES COMPUT SC, V4970, P126, DOI 10.1007/978-3-540-70552-9_7
   Fang CF, 2009, KNOWL-BASED SYST, V22, P271, DOI 10.1016/j.knosys.2009.01.003
   Gartner, 2013, DEF SERV OR ARCH SOA
   Gartner, 2013, DEF BUS PROC MAN BPM
   Internet Engineering Task Force (IETF), 2002, 3280 IETF RFC
   ISO/IEC, 2013, 2100020 ISOIEC IS
   ISO/IEC, 2005, 210002 ISOIEC IS 2
   ISO/IEC, 2008, 1593812 ISOIEC IS 12
   ISO/IEC, 2004, 210005 ISOIEC IS 5
   ISO/IEC, 23006 ISOIEC
   ISO/IEC, 2013, 230065 ISOIEC IS 5
   ISO/IEC, 2011, 907512011 ISOIEC 1
   ISO/IEC, 2006, 2100015 ISOIEC IS 15
   ISO/IEC, 2003, 210003 ISOIEC IS 3
   ISO/IEC, 2006, 210004 ISOIEC IS 4
   ISO/IEC JTC1 SC29/WG11 MPEG, 2013, MOV PICT EXP GROUP
   Kudumakis P., 2013, SIGNAL PROCESSING IM
   Llorente S, 2010, P 8 INT WORKSH TECHN
   Llorente S, 2013, IEEE MULTIMEDIA, V20, P62, DOI 10.1109/MMUL.2012.58
   Maronas X, 2012, 7 INT ICST C MOBIMED, P266
   Maronas X, 2011, P 9 INT WORKSH TECHN
   OASIS, 2005, SEC ASS MARK LANG SA
   Palkovits S, 2003, LECT NOTES COMPUT SC, V2739, P213
   Doncel VR, 2011, MULTIMED TOOLS APPL, V53, P303, DOI 10.1007/s11042-010-0513-3
   Rodriguez E, 2011, P 9 INT WORKSH TECHN
   Simon B, 2003, BUILDING INTEROPERAB
   Torres V, 2004, LECT NOTES COMPUT SC, V3311, P252
   World Wide Web Consortium (W3C), 1999, HYP TRANSF PROT HTTP
   World Wide Web Consortium (W3C) Community and Business Groups, 2002, OP DIG RIGHTS LANG O
NR 37
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7661
EP 7683
DI 10.1007/s11042-014-2005-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, SH
   Lin, T
   Zhou, KL
   Zhang, PJ
   Chen, XY
AF Wang, Shuhui
   Lin, Tao
   Zhou, Kailun
   Zhang, Peijun
   Chen, Xianyi
TI Pseudo-2D-matching based enhancement to high efficiency video coding for
   screen contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Screen content coding; Hybrid coding; String matching; Line segment
   matching
AB Computer screens are rich in discontinuous-tone content besides traditional continuous-tone content. Thus, new video coding tools coherently united into traditional hybrid coding tools are needed to effectively compress screen contents. This paper proposes a Pseudo-2D-matching (P2M) coder based enhancement to High Efficiency Video Coding for screen contents. An input Largest Coding Unit (LCU) is simultaneously fed into a P2M coder and a traditional hybrid coder. The coder minimizing rate-distortion is selected as the final coder for the LCU. The P2M coder breaks an LCU into many horizontal or vertical line segments and searches matching line segments in the searching-window consisting of previously coded pixels. Since the searching-window is large (a few kilobytes to megabytes) to increase the chance to find a good matching, a hash-table is used to speedup the search. In the P2M coder, three matching modes are used: 1) vertically scanned string matching; 2) horizontally scanned 2D-shape-preserved matching; and 3) vertically scanned 2D-shape-preserved matching. All three matching modes are used to code an LCU and the mode minimizing rate-distortion is selected in the P2M coder. The P2M based enhancement achieves significant Bitrate-distortion rate (BD-rate) and subjective visual quality improvement over traditional hybrid coding for screen contents.
C1 [Wang, Shuhui; Lin, Tao; Zhou, Kailun; Zhang, Peijun; Chen, Xianyi] Tongji Univ, VLSI Lab, Shanghai 200092, Peoples R China.
C3 Tongji University
RP Wang, SH (corresponding author), Tongji Univ, VLSI Lab, Shanghai 200092, Peoples R China.
EM shw@tongji.edu.cn; lintao@tongji.edu.cn
FU NSFC [61201226, 61271096]; Natural Science Foundation of Shanghai
   [12ZR1433800]; China university doctorial special funding project
   [20130072110054]; Fundamental Research Funds for the Central
   Universities of China [2810219002, 2810219003]
FX This work was supported in part by NSFC under Grant No. 61201226 and
   Grant No. 61271096, the Natural Science Foundation of Shanghai under
   Grant No. 12ZR1433800, China university doctorial special funding
   project under Grant No. 20130072110054 and the Fundamental Research
   Funds for the Central Universities of China under Grant No. 2810219002
   and Grant No. 2810219003.
CR [Anonymous], 2011, JCTVCE145
   Bjontegaard G, 2001, Q6 ITUT SG16
   Cao J., 2012, JCTVCH0294
   Chen X., 2012, JCTVCJ0353
   Flynn D., 2012, JCTVCK1006
   Lan CL, 2010, IEEE T IMAGE PROCESS, V19, P946, DOI 10.1109/TIP.2009.2038636
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Lin T., 2013, JCTVCL0303
   Lin T., 2012, JCTVCI0272
   Lin T, 2013, INT J AD HOC UBIQUIT, V12
   Lin T., 2012, JCTVCH0065
   Lin T., 2012, JCTVCJ0233
   Lin T, 2013, IEEE T CIRC SYST VID, V23, P173, DOI 10.1109/TCSVT.2012.2223871
   Lin T, 2009, IEEE INT CON MULTI, P1801
   Lin Tao, 2012, JCTVCK0133
   Lu Y, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.33
   Pang C, 2013, JCTVCN0256
   Shuhui Wang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P566, DOI 10.1109/CISP.2010.5647270
   Wang S., 2012, JCTVCH0073
   Wang S., 2012, JCTVCK0207
   Wang S., 2013, JCT-VC, document JCTVC-L0317
   Wang SQ, 2009, PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2, P1, DOI 10.1109/PLASMA.2009.5227540
   Zhang P., 2012, JCTVCI0336
   Zhang P., 2012, JCTVCJ0352
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
NR 25
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7753
EP 7771
DI 10.1007/s11042-014-2021-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200016
DA 2024-07-18
ER

PT J
AU Chung, MB
   Choo, H
AF Chung, Myoung Beom
   Choo, Hyunseung
TI Near wireless-control technology between smart devices using inaudible
   high-frequencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near wireless-control; Smart device; Inaudible frequency; High
   frequency; Mobile communication
AB For wireless control between smart devices, recent studies have mainly used Wi-Fi or Bluetooth technology. However, for Wi-Fi, the user requires extra infrastructure such as an access point. For Bluetooth, both users must have the same mobile operating system (OS), and several seconds elapse when pairing the smart devices. This paper proposes a near wireless control technology between smart devices using a microphone and the speaker of a smart device at near distances, to solve these problems. The control signals of the proposed method use the inaudible high frequencies of an audible domain that cannot be recognized by humans. The other smart device receives the control signals and then executes the specific function. Currently, if only a high frequency is used for the control signal, errors owing to unexpected sounds in the environment can occur. Therefore, our method uses two types of frequency signals. One signal is based on an audio file of the signals, and the other signal is a low-latency audio frequency. To evaluate the efficacy of the proposed method, we experimented with a near wireless-controlled camera in various situations and at various distances. The success rate was about 96 %. Then, we conducted an experiment to determine whether or not the people located around the device recognized the control signals when we used it. The percentage of people who were not conscious of the control signals was 97 %. Therefore, the proposed method is a useful technique for many types of near wireless-control between smart devices.
C1 [Chung, Myoung Beom; Choo, Hyunseung] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 440746, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Chung, MB (corresponding author), Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 440746, South Korea.
EM nzin@ssu.ac.kr; choo@skku.edu
FU MSIP; MOE, Korean government, under IT R&D Program[SmartTV 2.0 Software
   Platform] through KEIT [10041244]; Basic Science Research Program
   through NRF [NRF-2013R1A1A2061478]; PRCP through NRF [NRF-2010-0020210]
FX This research was supported in part by MSIP and MOE, Korean government,
   under IT R&D Program[10041244, SmartTV 2.0 Software Platform] through
   KEIT, Basic Science Research Program (NRF-2013R1A1A2061478) and
   PRCP(NRF-2010-0020210) through NRF, respectively.
CR [Anonymous], 2010, P 2 INT WORKSH MOB O
   [Anonymous], P IEEE SENS APPL S S, DOI DOI 10.1109/SAS.2012.6166305
   Bihler Pascal., 2011, Procedia Computer Science, V5, P586, DOI DOI 10.1016/J.PROCS.2011.07.076
   Ching-Yu Wang, 2011, Edutainment Technologies. Educational Games and Virtual Reality/Augmented Reality Applications. Proceedings 6th International Conference on E-learning and Games, Edutainment 2011, P92, DOI 10.1007/978-3-642-23456-9_17
   Chiu-Chiao Chung, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P309, DOI 10.1109/IBICA.2011.82
   Chung M, 2011, J ZHEJIANG U-SCI C, V12, P836, DOI 10.1631/jzus.C1000396
   Daniel A, 2010, WIFI CAMERA
   Eberhard S, 2012, SOUND ENG CALCULATOR
   Faber Acoustical LLC, 2010, IPH 4 AUD FREQ RES L
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Jeo W, 2012, WHY SMARTPHONE OWNER
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   김진복, 2012, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V22, P327
   Magic Jungle Software, 2011, CHOPP 2
   Maiti S., 2011, Proceedings of the Second International Conference on Emerging Applications of Information Technology (EAIT 2011), P239, DOI 10.1109/EAIT.2011.50
   Moser T, 2010, THESIS U ZURICH
   Tung NH, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P684, DOI 10.1109/ICCE.2012.6162028
   Panasonic Inc, 2012, PAN REM CAM CONTR AP
   Ryu CJ, 2012, LECT NOTES ELECT ENG, V203, P525, DOI 10.1007/978-94-007-5699-153
   Spanner S, 2011, BLUTOOTH FILE SHARIN
   Studer A, 2011, 27TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2011), P333
   Sung Wook Moon, 2011, 2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI 2011), P211, DOI 10.1109/URAI.2011.6145963
   Tysowski PK, 2011, INT WIREL COMMUN, P1445, DOI 10.1109/IWCMC.2011.5982751
   van Nieuwpoort RV, 2005, CONCURR COMP-PRACT E, V17, P1079, DOI 10.1002/cpe.860
   Wi-Fi Alliance, 2010, WI FI DIR
   Young-Hoon Jeon, 2011, 2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI 2011), P764, DOI 10.1109/URAI.2011.6146007
NR 26
TC 7
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5955
EP 5971
DI 10.1007/s11042-014-1901-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100029
DA 2024-07-18
ER

PT J
AU Pan, X
   Ye, YQ
   Wang, JH
   Gao, XD
   Zhou, X
AF Pan, Xiang
   Ye, Yongqiang
   Wang, Jianhong
   Gao, Xudong
   Zhou, Xin
TI Noncausal fractional directional differentiator and blind
   deconvoluation: motion blur estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion blur; Blind deconvolution; Noncausal fractional-order directional
   derivative; Blur direction; Blur extent
ID IMAGE; IDENTIFICATION; ALGORITHM
AB The problem of blind estimation of motion blur parameters from a single image is addressed. The blur direction and extent of motion-blurred image, which are introduced by relative motion between a camera and its object scene, are needed in the methods of image restoration, such as blind deconvolution. As an extension to the fractional-order derivative, a noncausal fractional-order directional derivative operator is devised, which is robust to noise. Based on this new operator, a novel method identifying blur parameters is developed in this work. The performance comparison between the proposed method and the state-of-the-art method is also presented, demonstrating that the former provides better immunity to noise and capacity to identify motion blur extent, especially for large blur length.
C1 [Pan, Xiang; Ye, Yongqiang; Wang, Jianhong; Gao, Xudong; Zhou, Xin] Nanjing Univ Aeronaut & Astronaut, Nanjing 210016, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Ye, YQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, 29 Yudao St, Nanjing 210016, Jiangsu, Peoples R China.
EM xiang_pan@nuaa.edu.cn; melvinye@nuaa.edu.cn; wang.jhong@ntu.edu.cn;
   sumarial001@gmail.com; xzhou@nuaa.edu.cn
RI Jiang, Yalin/ITV-2565-2023; wang, jian/GVS-0711-2022
OI Jiang, Yalin/0009-0003-3726-8828; 
FU NSFC [61074161, 61034005, 61102138]; SRFDP [20103218120014]; Jiangsu
   Innovation Program for Graduate Education [CXLX12 0157, CXZZ12 0158];
   Fundamental Research Funds for the Central Universities
FX The work was supported by NSFC under Grants 61074161, 61034005, and
   61102138, SRFDP under Grant 20103218120014, and by Funding of Jiangsu
   Innovation Program for Graduate Education under Grants CXLX12 0157 and
   CXZZ12 0158, and the Fundamental Research Funds for the Central
   Universities.
CR Almeida MSC, 2013, IEEE T IMAGE PROCESS, V22, P3074, DOI 10.1109/TIP.2013.2258354
   Almeida MSC, 2010, IEEE T IMAGE PROCESS, V19, P36, DOI 10.1109/TIP.2009.2031231
   [Anonymous], VISION INTERFACE
   [Anonymous], OPT ENG
   [Anonymous], IEEE T IMAG IN PRESS
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bracewell RN., 1995, 2 DIMENSIONAL IMAGIN
   CANNON M, 1976, IEEE T ACOUST SPEECH, V24, P58, DOI 10.1109/TASSP.1976.1162770
   Carasso AS, 2001, SIAM J APPL MATH, V61, P1980, DOI 10.1137/S0036139999362592
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479
   Dai S., 2008, CVPR
   Damkat C, 2011, SIGNAL IMAGE VIDEO P, V5, P343, DOI 10.1007/s11760-010-0205-5
   Dobes M, 2010, DIGIT SIGNAL PROCESS, V20, P1677, DOI 10.1016/j.dsp.2010.03.012
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255
   Jang EG, 2012, MULTIMED TOOLS APPL, V57, P407, DOI 10.1007/s11042-011-0738-9
   Ji H, 2008, IEEE C COMPUTER VISI, P1
   Krahmer F, 2006, Blind image deconvolution: Motion blur estimation
   Kriechbaum A, 2010, MULTIMED TOOLS APPL, V50, P7, DOI 10.1007/s11042-009-0366-9
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   LAGENDIJK RL, 1990, OPT ENG, V29, P422, DOI 10.1117/12.55611
   Oliveira JP, 2007, LECT NOTES COMPUT SC, V4478, P604
   Oliveira JP, 2009, SIGNAL PROCESS, V89, P1683, DOI 10.1016/j.sigpro.2009.03.018
   Pavlovic G, 1992, IEEE T IMAGE PROCESS, V1, P496, DOI 10.1109/83.199919
   Savakis AE, 1993, IEEE T IMAGE PROCESS, V2, P141, DOI 10.1109/83.217219
   Shao L, 2011, SIGNAL IMAGE VIDEO P, V5, P269, DOI 10.1007/s11760-010-0206-4
   Starck JL., 2010, SPARSE IMAGE SIGNAL
   TAN KC, 1991, CVGIP-GRAPH MODEL IM, V53, P291, DOI 10.1016/1049-9652(91)90051-K
   Tian YS, 2012, MULTIMED TOOLS APPL, V60, P519, DOI 10.1007/s11042-011-0821-2
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892
NR 31
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4849
EP 4872
DI 10.1007/s11042-013-1845-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400019
DA 2024-07-18
ER

PT J
AU Stoianov, N
   Urueña, M
   Niemiec, M
   Machnik, P
   Maestro, G
AF Stoianov, Nikolai
   Uruena, Manuel
   Niemiec, Marcin
   Machnik, Petr
   Maestro, Gema
TI Integrated security infrastructures for law enforcement agencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Law enforcement agency (LEA); Public key infrastructure (PKI); Virtual
   private network (VPN); INDECT block cipher (IBC); X.509 certificates;
   Smart card (SC); Federated identity management; Transport layer security
   (TLS)
AB This paper provides an overview of the security architecture for Law Enforcement Agencies (LEAs) designed by the INDECT project, and in particular the security infrastructures that have been deployed so far. These security infrastructures can be organized in the following main areas: Public Key Infrastructure (PKI) and user management, communications security, and new cryptographic algorithms. This paper presents the new ideas, architectures and deployed testbeds for these areas. In particular, it explains the inner structure of the INDECT PKI employed for federated identity management, the different technologies employed in the VPN testbed, the INDECT Block Cipher (IBC) - a novel cryptographic algorithm that has being integrated into OpenSSL library, and how IBC-enabled TLS/SSL sessions and X.509 certificates are employed to protect INDECT applications. All proposed mechanisms have been designed to work in an integrated fashion as the security foundation of all systems being developed by the INDECT project for LEAs.
C1 [Stoianov, Nikolai] Tech Univ Sofia, INDECT Project Team, 8 KlimentOhridski St, Sofia 1000, Bulgaria.
   [Uruena, Manuel] Univ Carlos III Madrid, Dept Telemat Engn, Madrid 28911, Spain.
   [Niemiec, Marcin] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
   [Machnik, Petr] VSB Tech Univ Ostrava, Dept Telecommun, Ostrava 70833, Czech Republic.
   [Maestro, Gema] APIF Moviqu SA Madrid, Madrid, Spain.
C3 Technical University Sofia; Universidad Carlos III de Madrid; AGH
   University of Krakow; Technical University of Ostrava
RP Stoianov, N (corresponding author), Tech Univ Sofia, INDECT Project Team, 8 KlimentOhridski St, Sofia 1000, Bulgaria.
EM nkl_stnv@tu-sofia.bg; muruenya@it.uc3m.es; niemiec@kt.agh.edu.pl;
   petr.machnik@vsb.cz; gmm@moviquity.com
RI Stoianov, Nikolai/AAA-3724-2019; Urueña, Manuel/J-3189-2012; Niemiec,
   Marcin/D-1271-2011; Machnik, Petr/G-5341-2017
OI Stoianov, Nikolai/0000-0002-4953-4172; Urueña,
   Manuel/0000-0001-7834-5998; Niemiec, Marcin/0000-0002-3909-9592;
   Machnik, Petr/0000-0003-0021-9777
FU EU Project INDECT [218086]
FX This work has been funded by the EU Project INDECT (Intelligent
   information system supporting observation, searching and detection for
   security of citizens in urban environment)-grant agreement number:
   218086.
CR Dierks T., 2008, 5246 RFC
   Hickman K., 1995, THE SSL PROTOCOL
   INDECT Consortium, 2009, D8 1 SPEC REQ SEC CO
   Niemiec M, 2012, PROC 5TH INTERNATION
   Niemiec M, 2012, IV INTERNATIONAL CONGRESS ON ULTRA MODERN TELECOMMUNICATIONS AND CONTROL SYSTEMS 2012 (ICUMT), P474, DOI 10.1109/ICUMT.2012.6459712
   OpenSSL, 2012, OP SOURC TOOLK SSL T
   Stoianov N, 2012, COMM COM INF SC, V287, P304
   Thomas S.A., 2000, SSL TLS Essentials: Securing the Web
   Uruena M, 2012, MULTIMEDIA TOOLS APP
   Zhelyazkov D., 2009, CIO COMMUNICATION IN, P19
NR 10
TC 7
Z9 7
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4453
EP 4468
DI 10.1007/s11042-013-1532-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600016
OA Green Published
DA 2024-07-18
ER

PT J
AU Lee, JH
   Han, WS
   An, KH
   Sung, KB
AF Lee, Jeong-Hoon
   Han, Wook-Shin
   An, Kyoung Hwan
   Sung, Kyung Bok
TI Towards intelligent in-vehicle sensor database management systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE In-vehicle DBMS; Requirement; System architecture; Query processing
AB Due to the evolution of technologies for sensor and wireless communication, there has been increasing attention to research on an intelligent vehicle that supports safe driving by exploiting large traffic data gathered from traffic environments such as vehicles and road side units, as well as data gathered from sensors mounted on the vehicle. In this paper, we study an in-vehicle sensor database management system (DBMS). In the proposed approach, simply called in-vehicle DBMS approach, DBMS inside the ego-vehicle manages, gathers, and processes traffic and sensor data onboard such as signal data and multimedia data including map and image data. We classify the requirements of applications using the in-vehicle DBMS into data modeling and query processing. We also propose a system architecture for an in-vehicle DBMS which solves those issues and discuss database techniques offered by the system.
C1 [Lee, Jeong-Hoon; Han, Wook-Shin] POSTECH, Dept Creat IT Engn, Pohang, South Korea.
   [Han, Wook-Shin] POSTECH, Dept Comp Sci & Engn, Pohang, South Korea.
   [An, Kyoung Hwan; Sung, Kyung Bok] Elect & Telecommun Res Inst, Ind IT Convergence Res Dept, Taejon 305606, South Korea.
C3 Pohang University of Science & Technology (POSTECH); Pohang University
   of Science & Technology (POSTECH); Electronics & Telecommunications
   Research Institute - Korea (ETRI)
RP Han, WS (corresponding author), POSTECH, Dept Creat IT Engn, Pohang, South Korea.
EM handolleejh@gmail.com; wshan@postech.ac.kr; mobileguru@etri.re.kr;
   kbsung@etri.re.kr
FU National Research Foundation of Korea (NRF) - Korea government (MEST)
   [NRF-2011-0016520]; MKE/ISTK [Mega Convergence Core Technology
   Development]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MEST) (NRF-2011-0016520) and
   MKE/ISTK [Mega Convergence Core Technology Development].
CR Acharya S., 1995, SIGMOD Record, V24, P199, DOI 10.1145/568271.223816
   [Anonymous], 2003, VLDB C
   [Anonymous], J CONVERG
   Arasu A., 2003, IEEE DATA ENG B, V26, P19
   Bartolini I, 2005, IEEE T PATTERN ANAL, V27, P142, DOI 10.1109/TPAMI.2005.21
   CHONG RM, 2010, J CONVERGENCE, V1, P49
   Chow C.Y., 2007, P 23 INT C DAT ENG, P1499
   Christian B, 2011, J INFORM PROCESS SYS, V8, P539
   Christian Z, 2008, P 15 WORLD C INT TRA, P1
   Darms M., 2008, AUTOREG 2008 STEUER, P521
   Fang H, 2011, J INF PROCESS SYST, V7, P519, DOI 10.3745/JIPS.2011.7.3.519
   Frigioni D, 2000, J ALGORITHMS, V34, P251, DOI 10.1006/jagm.1999.1048
   Hiyama M, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-3
   Jain Navendu., 2006, SIGMOD 06 P 2006 ACM, P431, DOI DOI 10.1145/1142473.1142522
   Jiang D, 2008, IEEE VTS VEH TECHNOL, P2036, DOI 10.1109/VETECS.2008.458
   Kaempchen N, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P825
   Kim Y., 2012, Journal of Computational Science Education, V3, P47, DOI DOI 10.22369/ISSN.2153-4136/3/1/6
   Likhachev M., 2005, P ICAPS, V5, P262
   Narváez P, 2001, IEEE ACM T NETWORK, V9, P706, DOI 10.1109/90.974525
   Piao J., 2008, IET Road Transport Information and Control-RTIC 2008 and ITS United Kingdom Members' Conference pp, P1
   Samuel M, 2005, ACM T DATABASE SYST, V30, P122
   Shin WS, 2006, J INF PROCESS SYST, V2, P52
   Singh B, 2012, HUM-CENT COMPUT INFO, V2, DOI 10.1186/2192-1962-2-13
   Tseng FH, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-4
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255
   Urmson C, 2008, IEEE INTELL SYST, V23, P66, DOI 10.1109/MIS.2008.34
   Yang X, 2008, COMPUT-AIDED CIV INF, V23, P575, DOI 10.1111/j.1467-8667.2008.00557.x
NR 27
TC 3
Z9 3
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3599
EP 3615
DI 10.1007/s11042-013-1672-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000023
DA 2024-07-18
ER

PT J
AU Masala, E
   De Vito, F
   De Martin, JC
AF Masala, Enrico
   De Vito, Fabio
   De Martin, Juan Carlos
TI On the effects of sender-receiver concealment mismatch on multimedia
   communication optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; Concealment mismatch; Concealment assumption; Distortion
   estimation
ID VIDEO TRANSMISSION; DISTORTION; NETWORKS
AB A large number of performance optimization algorithms for multimedia communications, including rate-distortion optimized schemes, rely on knowing the decoder behavior in case of data loss, i.e., the decoder-side error concealment technique. However, for the specific case of video coding, standards do not specify it, thus different decoders may - and typically do - use different concealment techniques. This work investigates the impact of assuming, in the transmission optimization phase, a concealment algorithm different from the one that is actually used by the decoder, in order to determine which are the best assumptions to use at the transmitter. Firstly, we investigate the typical performance provided by ten concealment techniques belonging to three widely used algorithmic families (spatial, temporal and mixed). Then, we assess the impact that an incorrect concealment assumption causes, in terms of both packet transmission policy changes and video quality degradation, using a simple rate-distortion transmission optimization technique that targets a generic two QoS-level network. Simulation results over several standard video sequences show that the performance impact of incorrectly assuming the decoder-side concealment technique may be significant but it is limited if the two techniques belong to the same algorithmic family. Moreover, the impact on performance caused by incorrect assumptions is strongly mitigated if the decoder employs a high-performance concealment algorithm. Finally, the impact on the performance of several parameters such as the encoding pattern, the packet loss statistics (uniform and burst losses) and the amount of high-priority traffic is evaluated, showing that the conclusions can be confidently applied to actual multimedia communication scenarios.
C1 [Masala, Enrico; De Vito, Fabio; De Martin, Juan Carlos] Politecn Torino, Control & Comp Engn Dept, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Masala, E (corresponding author), Politecn Torino, Control & Comp Engn Dept, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
EM masala@polito.it; fabio.devito@polito.it; demartin@polito.it
RI Masala, Enrico/B-6973-2008
OI Masala, Enrico/0000-0001-8906-354X
CR [Anonymous], 1998, An Architecture for Differentiated Services, RFC 2475 Informational
   Baldi M, 2008, IEEE T BROADCAST, V54, P542, DOI 10.1109/TBC.2008.2000553
   Bucciol P, 2007, ADV MULTIMED, V2007, DOI 10.1155/2007/13969
   Chakareski J, 2005, IEEE T CIRC SYST VID, V15, P1257, DOI 10.1109/TCSVT.2005.854227
   Chen ZF, 2012, IEEE T CIRC SYST VID, V22, P636, DOI 10.1109/TCSVT.2011.2171262
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   Côté G, 2000, IEEE J SEL AREA COMM, V18, P952, DOI 10.1109/49.848249
   Cui Z., 2012, J COMPUT INF SYST, V8, P8807
   De Vito F, 2005, P EUR SIGN PROC C EU, P1588
   Demirtas AM, 2011, IEEE IMAGE PROC, P949, DOI 10.1109/ICIP.2011.6116718
   Gao SS, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P128, DOI 10.1109/ISM.2012.32
   Hand J, 2012, P IEEE INT C MULT EX, P67
   Hand J, 2011, P IEEE INT C AC SPEE, P825
   ITU-T & ISO/IEC, 2005, H2641449610 ITUT ISO
   Joint Video Team (JVT) of ISO/IEC MPEG & ITU-T VCEG, 2011, JOINT MOD NUMB 8 2 J
   Koloda J, 2013, IEEE T MULTIMEDIA, V15, P957, DOI 10.1109/TMM.2013.2238524
   Maani E, 2010, IEEE T CIRC SYST VID, V20, P407, DOI 10.1109/TCSVT.2009.2035846
   Masala E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P345
   Masala E, 2009, IEEE T MULTIMEDIA, V11, P972, DOI 10.1109/TMM.2009.2021784
   Midya A, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P416, DOI 10.1109/PACRIM.2011.6032929
   Purandare R, 2011, P INT C IM INF PROC
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Superiori L, 2012, ELEKTROTECH INFORMAT, V129, P387, DOI 10.1007/s00502-012-0053-9
   Yang H, 2007, IEEE T CIRC SYST VID, V17, P845, DOI 10.1109/TCSVT.2007.897116
   Yang Q, 2012, P 8 INT C WIR COMM N
   Zhang YB, 2012, IEEE T CIRC SYST VID, V22, P12, DOI 10.1109/TCSVT.2011.2130450
   Zhou J, 2011, IEEE T BROADCAST, V57, P75, DOI 10.1109/TBC.2010.2086771
NR 27
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 2879
EP 2898
DI 10.1007/s11042-013-1751-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jeong, OR
AF Jeong, Ok-Ran
TI SNS-based recommendation mechanisms for social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SNS (Social Network Service); Recommendation; Intimacy; Social media
AB Recently, the necessity of search or recommendation for using mass quantity of web contents at a number of social media websites, etc. as the usage of social network service has rapidly increased. An effective recommendation method based on social network is to predict the preference and use the social network relationship information of a user after identifying the propensity of user. In this study, a recommendation algorithm based on the intimacy between users has been proposed using the information on the social network having correlation with the user. Also, the proposed methodology has been applied on Podcast which is in a form of multimedia file rising as new social media nowadays to be implemented as a system and shows the experiment result.
C1 Gachon Univ, Dept Software Design & Management, Songnam, South Korea.
C3 Gachon University
RP Jeong, OR (corresponding author), Gachon Univ, Dept Software Design & Management, Songnam, South Korea.
EM orjeong@gachon.ac.kr
RI Azonnoudo, Seyido/ISU-7505-2023
FU Gachon University Research Fund; Basic Science Research Program through
   the National Research Foundation of Korea (NRF) - Ministry of Science,
   ICT and Future Planning [2013-008339]
FX This research was supported by Gachon University Research Fund in 2013
   and by Basic Science Research Program through the National Research
   Foundation of Korea (NRF) funded by the Ministry of Science, ICT and
   Future Planning (2013-008339).
CR Albert R, 2000, PHYS REV LETT, V85, P5234, DOI 10.1103/PhysRevLett.85.5234
   [Anonymous], 8 STEP GUIDE PODCAST
   [Anonymous], P 39 KISS KOR INF SC
   [Anonymous], STUDY ALGORITHM SELE
   [Anonymous], STUDY MEDIA CONTENTS
   [Anonymous], MOBILE MULTIMEDIA SE
   [Anonymous], ICISA 2013 P 2013 IN
   [Anonymous], 4 ACM C REC SYST BAR
   [Anonymous], LNCS
   [Anonymous], ICISA 2013 P 2013 IN
   [Anonymous], PDCAT 10 P 2010 INT
   [Anonymous], BLOGS WIKIS PODCASTS
   [Anonymous], MEDIA SOC
   Boulos M., 2006, BMC MED ED
   Burke R., 2007, The adaptive web: methods and strategies of web personalization, P377, DOI [10.1007/978-3-540-72079-9_12, DOI 10.1007/978-3-540-72079-9_12]
   Godwin-Jones R, 2005, LANG LEARN TECHNOL, V9, P9
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   Pham HX, 2013, MULTIMED TOOLS APPL, V65, P119, DOI 10.1007/s11042-012-1119-8
   Indyk W, 2013, MULTIMED TOOLS APPL, V65, P63, DOI 10.1007/s11042-012-1149-2
   Kim HN, 2012, MULTIMED TOOLS APPL, V56, P63, DOI 10.1007/s11042-010-0557-4
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Lam C., 2004, Proceedings of the 5th ACM conference on Electronic commerce, P254
   Lawton G, 2001, IEEE T COMPUT, V34, P216
   Liu Q, 2012, LECT NOTES COMPUT SC, V7332, P164, DOI 10.1007/978-3-642-31020-1_20
   McDonald DavidW., 2003, P ACM C HUMAN FACTOR, P593, DOI DOI 10.1145/642611.642714
   Musial K, 2008, LECT NOTES ARTIF INT, V5288, P364, DOI 10.1007/978-3-540-87781-3_40
   Naaman M, 2012, MULTIMED TOOLS APPL, V56, P9, DOI 10.1007/s11042-010-0538-7
   Newman MEJ, 2005, CONTEMP PHYS, V46, P323, DOI 10.1080/00107510500052444
   Palau J, 2004, LECT NOTES ARTIF INT, V3191, P137
   Rainie L., 2005, Pew Internet American Life Project
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Suchal J, 2010, IFIP ADV INF COMM TE, V331, P165
NR 32
TC 5
Z9 5
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2433
EP 2447
DI 10.1007/s11042-014-1884-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200016
DA 2024-07-18
ER

PT J
AU Rho, MJ
   Yoon, KH
   Kim, HS
   Choi, IY
AF Rho, Mi Jung
   Yoon, Kun Ho
   Kim, Hun-Sung
   Choi, In Young
TI Users' perception on telemedicine service: a comparative study of public
   healthcare and private healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telemedicine service; Public healthcare; Private healthcare; Perceived
   risk; Satisfaction; Continuous intention to use
ID MOBILE; ACCEPTANCE; PATIENT
AB Telemedicine services have been applied in public healthcare and private healthcare. Despite the different characteristics of healthcare services, the service models have been designed very similarly. Telemedicine services should be designed to reflect the characteristics of their own and their users' perceptions of service. Thus, this comparative study was undertaken to examine the perceptions of telemedicine services between public healthcare users and private healthcare users. This study collected 192 samples, using paper-based surveys, from two groups: public (n = 101) and private healthcare service users (n = 81). We performed two independent samples t-tests depending on the group to measure the differences in satisfaction and continuous intention to use, as well as the perception of the telemedicine service. Multiple regression analysis was performed to compare influential factors in continuous intention to use regarding public healthcare users and private healthcare users. The two groups had significantly different perceptions of both perceived risk and satisfaction (p < 0.05). Private healthcare users expressed greater satisfaction with telemedicine services than did public healthcare users, whereas private healthcare users felt less worry about perceived risk. Both groups perceived that telemedicine was useful and easy to use for healthcare service, expressing higher intentions to use. In both groups, perceived usefulness and ease of use had positive effects on continuous intention to use (p < 0.05). In public healthcare users only, satisfaction was found to be an important variable that increased intention to use (p < 0.05). Perceived risk had no relationship with continuous intention to use in either group. This study provides insight into understanding the users of telemedicine services and guidelines for developing appropriate telemedicine service models, depending whether it is public healthcare or private healthcare.
C1 [Rho, Mi Jung; Choi, In Young] Catholic Univ Korea, Coll Med, Dept Med Informat, Seoul 137701, South Korea.
   [Yoon, Kun Ho; Kim, Hun-Sung] Catholic Univ Korea, Coll Med, Seoul St Marys Hosp, Dept Endocrinol, Seoul 137701, South Korea.
   [Yoon, Kun Ho; Kim, Hun-Sung] Catholic Univ, Catholic Inst Ubiquitous Hlth Care, Seoul 137701, South Korea.
C3 Catholic University of Korea; Catholic University of Korea; Seoul St.
   Mary's Hospital; Catholic University of Korea
RP Choi, IY (corresponding author), Catholic Univ Korea, Coll Med, Dept Med Informat, Songeui Campus,222 Banpo Daero, Seoul 137701, South Korea.
EM iychoi@catholic.ac.kr
FU R&D Program for Society of the National Research Foundation (NRF) -
   Ministry of Science, ICT & Future Planning [2013M3C8A2A02078508]
FX This research was supported by the R&D Program for Society of the
   National Research Foundation (NRF) funded by the Ministry of Science,
   ICT & Future Planning (Grant number: 2013M3C8A2A02078508).
CR Abd Manaf NH, 2012, INT J PUBLIC SECT MA, V25, P6, DOI 10.1108/09513551211200258
   Bahaadinbeigy K, 2010, J TELEMED TELECARE, V16, P176, DOI 10.1258/jtt.2010.004003
   Basoglu N, 2012, J MED SYST, V36, P1389, DOI 10.1007/s10916-010-9601-1
   Buysse HEC, 2010, INT J MED INFORM, V79, P576, DOI 10.1016/j.ijmedinf.2010.05.005
   Cardozo L, 2010, TELEMED J E-HEALTH, V16, P49, DOI 10.1089/tmj.2009.0058
   Rezende EJC, 2013, TELEMED E-HEALTH, V19, P613, DOI 10.1089/tmj.2012.0179
   Cho JH, 2009, J TELEMED TELECARE, V15, P77, DOI 10.1258/jtt.2008.080412
   Cocosila M, 2009, BLED 2009 P 22 BLED
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Hung SY, 2014, DECIS SUPPORT SYST, V57, P331, DOI 10.1016/j.dss.2013.09.016
   Jen WY, 2010, TELEMED J E-HEALTH, V16, P490, DOI 10.1089/tmj.2009.0126
   Jorgensen H.R., 2011, INT J INTEGR CARE S, V11, pe105
   Jung EY, 2013, WIRELESS PERS COMMUN, V73, P207, DOI 10.1007/s11277-013-1231-8
   Kang JM, 2006, J TELEMED TELECARE, V12, P422, DOI 10.1258/135763306779378744
   Kearns JW, 2012, TELEMED E-HEALTH, V18, P347, DOI 10.1089/tmj.2011.0165
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Lee J, 2013, HEALTHC INFORM RES, V19, P167
   Lim N., 2003, ELECTRON COMMER R A, V2, P216, DOI [10.1016/s1567-4223(03)00025-5, DOI 10.1016/S1567-4223(03)00025-5]
   Lim S, 2011, DIABETES METAB J, V35, P50, DOI 10.4093/dmj.2011.35.1.50
   Littman- Quinn R, 2011, IST AFR C P 2011
   Mair FS, 2005, J TELEMED TELECARE, V11, P95, DOI 10.1258/1357633054461976
   Mariappan M., 2013, INT J NETW COMMUN, V3, P12
   Martínez A, 2006, J TELEMED TELECARE, V12, P234, DOI 10.1258/135763306777889109
   Nunnally JC, 1978, PSYCHOMETRIC THEORY
   Paim J, 2011, LANCET, V377, P1778, DOI 10.1016/S0140-6736(11)60054-8
   Park H, 2011, TELEMED E-HEALTH, V17, P442, DOI 10.1089/tmj.2010.0201
   Rai A, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2635
   Rho MJ, 2013, J CONVERG INF TECHNO, V8, DOI [10. 4156/ jcit. vol8. issue12. 2, DOI 10.4156/JCIT.V0L8.ISSUE12.2]
   Rimner T, 2011, J TELEMED TELECARE, V17, P235, DOI 10.1258/jtt.2011.101013
   Singh R, 2010, HEALTH SERV RES, V45, P985, DOI 10.1111/j.1475-6773.2010.01116.x
   Talukdar R, 2012, ENDOSCOPY, V44, P186, DOI 10.1055/s-0031-1291612
   Teijeiro T, 2013, EXPERT SYST APPL, V40, P2607, DOI 10.1016/j.eswa.2012.11.001
   van Bon Arianne C, 2010, J Diabetes Sci Technol, V4, P596
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Whitten Pamela, 2005, J Palliat Med, V8, P730, DOI 10.1089/jpm.2005.8.730
   Kim Byongcheol, 2011, [Journal of Media Economics & Culture, 미디어 경제와 문화], V9, P65
NR 36
TC 6
Z9 10
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2483
EP 2497
DI 10.1007/s11042-014-1966-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200019
DA 2024-07-18
ER

PT J
AU Zeng, W
   Lu, X
   Tan, X
AF Zeng, W.
   Lu, X.
   Tan, X.
TI A local structural adaptive partial differential equation for image
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial differential equations (PDE); Local discontinuity; Contextual
   discontinuity; Image denoising
ID NOISE REMOVAL; EDGE-DETECTION; DIFFUSION; MODEL; RESTORATION;
   ALGORITHMS; FILTER; SPACE
AB In this paper, we propose a local and contextual controlled (LCC) fourth order partial differential equation (PDE) method for noise removal. First, a region based fourth order PDE is proposed, which conductance coefficients are chosen adaptively in terms of the domain type. Thus, the proposed method can preserve the advantages of forth order PDE and avoid leaving isolated black and white speckles. Furthermore, the region based fourth order PDE and two discontinuity measures are incorporated into a LCC fourth order PDE, where the joint use of the two discontinuity measures leads to a complementary effect for edge preservation. The proposed LCC fourth order PDE is tested on two typical images, including texture image and natural scene image, which show the superiority of the proposed method.
C1 [Zeng, W.; Lu, X.] Southeast Univ, Sch Automat, Nanjing, Jiangsu, Peoples R China.
   [Tan, X.] Nanjing Inst Ind Technol, Dept Humanity & Math & Phys, Nanjing, Jiangsu, Peoples R China.
C3 Southeast University - China; Nanjing Vocational University of Industry
   Technology
RP Lu, X (corresponding author), Southeast Univ, Sch Automat, Nanjing, Jiangsu, Peoples R China.
EM zengwlj@yahoo.com.cn; xblu2013@126.com; tanxh@niit.edu.cn
OI Zeng, Weili/0000-0002-5266-2423
FU National Natural Science Foundation of China [61374194]; National Key
   Technologies R & D Program of China [2009BAG13A06]; Scientific
   Innovation Research of College Graduate in Jiangsu Province [CXZZ_0163];
   Scientific Research Foundation of Graduate School of Southeast
   University [YBPY1212]
FX The authors thank the editor and the reviewers for carefully reading the
   early version of this paper and offering valuable suggestions and
   comments. This work was supported by National Natural Science Foundation
   of China (61374194), the National Key Technologies R & D Program of
   China (2009BAG13A06), the Scientific Innovation Research of College
   Graduate in Jiangsu Province (CXZZ_0163), and the Scientific Research
   Foundation of Graduate School of Southeast University (YBPY1212).
CR Ben Hamza A, 1999, J MATH IMAGING VIS, V11, P161, DOI 10.1023/A:1008395514426
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chen K, 2005, IEEE T PATTERN ANAL, V27, P1552, DOI 10.1109/TPAMI.2005.190
   Chen Q, 2010, SIGNAL PROCESS, V90, P1963, DOI 10.1016/j.sigpro.2009.12.015
   Didas S, 2009, J MATH IMAGING VIS, V35, P208, DOI 10.1007/s10851-009-0166-x
   Greer JB, 2004, SIAM J MATH ANAL, V36, P38, DOI 10.1137/S0036141003427373
   Greer JB, 2003, DISRET CONTINUOUS DY, V9, P349
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Liu Q, 2007, NONLINEAR ANAL-THEOR, V67, P1908, DOI 10.1016/j.na.2006.08.016
   Liu QR, 2007, ENERGY ENVIRON ENG S, P1
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Own CM, 2006, IMAGING SCI J, V54, P3, DOI 10.1179/174313106X93778
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rajan J, 2008, J MATH IMAGING VIS, V31, P73, DOI 10.1007/s10851-008-0067-4
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Saha PK, 2001, IEEE T PATTERN ANAL, V23, P689, DOI 10.1109/34.935844
   Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813
   Wang Y, 2011, ELECTRON LETT, V47, P592, DOI 10.1049/el.2010.3505
   Wei GW, 1999, IEEE SIGNAL PROC LET, V6, P165, DOI 10.1109/97.769359
   Wu J, 2011, IEEE T IMAGE PROCESS, V20, P2428, DOI 10.1109/TIP.2011.2131664
   Wu YD, 2007, IET IMAGE PROCESS, V1, P85, DOI 10.1049/iet-ipr:20050383
   You Y., 1998, IEEE T IMAGE PROCE, V5, P1539
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zeng W, 2011, J APPL MAT, V2011, P20
   Zeng WL, 2013, IMAGING SCI J, V61, P268, DOI 10.1179/1743131X11Y.0000000064
   Zeng WL, 2011, ELECTRON LETT, V47, P1125, DOI 10.1049/el.2011.2456
   Zhu W, 2012, SIAM J IMAGING SCI, V5, P1, DOI 10.1137/110822268
NR 27
TC 18
Z9 18
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 743
EP 757
DI 10.1007/s11042-013-1692-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400005
DA 2024-07-18
ER

PT J
AU Yu, LT
   Shao, J
   Xu, XS
   Shen, HT
AF Yu, Litao
   Shao, Jie
   Xu, Xin-Shun
   Shen, Heng Tao
TI Max-margin adaptive model for complex video pattern recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video pattern recognition; Max-margin adaptive model; Event detection
ID EVENT DETECTION
AB Pattern recognition models are usually used in a variety of applications ranging from video concept annotation to event detection. In this paper we propose a new framework called the max-margin adaptive (MMA) model for complex video pattern recognition, which can utilize a large number of unlabeled videos to assist the model training. The MMA model considers the data distribution consistence between labeled training videos and unlabeled auxiliary ones from the statistical perspective by learning an optimal mapping function which also broadens the margin between positive labeled videos and negative labeled videos to improve the robustness of the model. The experiments are conducted on two public datasets including CCV for video object/event detection and HMDB for action recognition. Our results demonstrate that the proposed MMA model is very effective on complex video pattern recognition tasks, and outperforms the state-of-the-art algorithms.
C1 [Yu, Litao; Shen, Heng Tao] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
   [Shao, Jie] Natl Univ Singapore, Dept Comp Sci, Singapore 117417, Singapore.
   [Xu, Xin-Shun] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
C3 University of Queensland; National University of Singapore; Shandong
   University
RP Yu, LT (corresponding author), Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
EM l.yu4@uq.edu.au; shaojie@nus.edu.sg; xuxinshun@sdu.edu.cn;
   shenht@itee.uq.edu.au
RI Shen, Heng Tao/ABD-5331-2021
CR Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Charles J., 2013, P BRIT MACH VIS C
   Chen B, 2013, IEEE T PATTERN ANAL, V35, P1284, DOI 10.1109/TPAMI.2012.243
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Jie L, 2011, IEEE I CONF COMP VIS, P1863, DOI 10.1109/ICCV.2011.6126454
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1057, DOI 10.1109/TCSVT.2010.2057013
   Lin YY, 2011, IEEE T PATTERN ANAL, V33, P1147, DOI 10.1109/TPAMI.2010.183
   Ma ZG, 2013, PROC CVPR IEEE, P2627, DOI 10.1109/CVPR.2013.339
   Ma Z, 2013, IEEE T MULTIMEDIA, V15, P1628, DOI 10.1109/TMM.2013.2264928
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814
   Obozinski G, 2010, STAT COMPUT, V20, P231, DOI 10.1007/s11222-008-9111-x
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Quattoni A, 2008, PROC CVPR IEEE, P2300
   Rohrbach M., 2013, Advances in neural information processing systems, P46
   Sugiyama M, 2010, MACH LEARN, V78, P35, DOI 10.1007/s10994-009-5125-7
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   van Erp M, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P195, DOI 10.1109/IWFHR.2002.1030908
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yao Y, 2010, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2010.5539857
   Younessian E, 2013, P SOC PHOTO-OPT INS, V8667
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 30
TC 2
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 505
EP 521
DI 10.1007/s11042-014-2010-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300011
DA 2024-07-18
ER

PT J
AU Friedel, R
   Figuerola, O
   Kalva, H
   Furht, B
AF Friedel, Reena
   Figuerola, Oscar
   Kalva, Hari
   Furht, Borko
TI Asset identification using image descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Asset management; Image descriptors; Data center; Complexity reduction;
   SIFT; SURF; FAST
ID RECOGNITION
AB Managing Information Technology (IT) assets in data centers is a time consuming and error prone process. IT personnel typically identify misplaced assets manually by cross checking and visually inspecting assets. An automated way of keeping track of assets using portable devices reduces human error and improves productivity. The proposed asset management application on the tablet captures images of assets and searches an annotated database to identify the asset. Matching performance and response time of asset matching is evaluated using three different image feature descriptors. Methods to reduce feature extraction and matching complexity were developed. Performance and accuracy tradeoffs were studied, domain specific problems were identified, and optimizations for portable platforms were made. The results show that the proposed methods reduce complexity of asset matching by 67 % when compared to the matching process using standard image feature descriptors.
C1 [Friedel, Reena; Figuerola, Oscar; Kalva, Hari; Furht, Borko] Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Kalva, H (corresponding author), Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
EM hari.kalva@fau.edu
FU NSF Industry/University Cooperative Research Center for Advanced
   Knowledge Enablement at Florida Atlantic University, NSF [0934339];
   Direct For Computer & Info Scie & Enginr; Division Of Computer and
   Network Systems [0934339] Funding Source: National Science Foundation
FX This project was funded by the NSF Industry/University Cooperative
   Research Center for Advanced Knowledge Enablement at Florida Atlantic
   University, NSF award No. 0934339.
CR [Anonymous], INT C COMP VIS PATT
   [Anonymous], 2004, ECCV INT WORKSH STAT
   [Anonymous], EE368 STANF U
   Bay H, 2005, P UB COMP UBICOMP
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chen D, 2011, MMSYS 11 SAN JOS CAL
   Chen D, 2010, P ACM MULT 2010
   CHEN D, 2010, P ACM MULT
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Fergus R, 2003, PROC CVPR IEEE, P264
   Gauglitz S, 2011, EVALUATION INTEREST
   Ibach P, 2005, P IADIS INT C COMM, P1, DOI DOI 10.13140/RG.2.1.1133.8001
   ISO/MPEG, 2011, N12201 ISOMPEG
   Kim DN, 2006, IFOST 2006: 1ST INTERNATIONAL FORUM ON STRATEGIC TECHNOLOGY, PROCEEDINGS, P305
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   McCathie L., 2005, Proceedings of the Collaborative Electronic Commerce Technology and Research Conference LatAm, P1
   Ouertani M.Z., 2008, INT J COMPUTER SCI A, V5, P25
   Patil A, 2008, COMPUT COMMUN, V31, P1067, DOI 10.1016/j.comcom.2008.01.041
   Psyllos AP, 2010, IEEE T INTELL TRANSP, V11, P322, DOI 10.1109/TITS.2010.2042714
   Quoc NH, 2009, LECT NOTES COMPUT SC, V5754, P386, DOI 10.1007/978-3-642-04070-2_44
   Ruf B, 2009, P SING FRENCH IP S S
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Takacs G, P IEEE C COMP VIS AP
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
NR 27
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2201
EP 2221
DI 10.1007/s11042-013-1688-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200049
DA 2024-07-18
ER

PT J
AU Luo, T
   Jiang, GY
   Wang, XD
   Yu, M
   Shao, F
   Peng, ZJ
AF Luo, Ting
   Jiang, Gangyi
   Wang, Xiaodong
   Yu, Mei
   Shao, Feng
   Peng, Zongju
TI Stereo image watermarking scheme for authentication with self-recovery
   capability using inter-view reference sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three dimensional video; Stereo image watermarking; Block matching;
   Inter-view reference sharing
ID TAMPER DETECTION; VIDEO
AB Advances in three dimensional video is a strong stimulus for research in authentication of stereo image to avoid illegal modification. In this paper, a stereo image watermarking scheme is proposed for authentication with self-recovery capability using inter-view reference sharing. A mechanism of inter-view reference sharing in stereo image pairs is designed to reduce bits for recovery reference generation compared with independent references. Discrete wavelet transform coefficients are employed to generate the references, and two reference copies of each block embedded in two different mapping blocks are prepared for recover tamper. Moreover, detail information from high frequency coefficients is also embedded so as to improve the quality of tamper recovery. For the purpose of resisting collage attack and increasing the probability of tamper detection, disparities between pairs of matched blocks are checked to conduct tamper detection. Experimental results show that the proposed scheme can detect tampered blocks with the probabilities of more than 99 % after collage attack. When stereo images are cropped from 10 to 70 % with randomly tampering, they are recovered without losing main visual information and qualities of recovery are better than those of existing monocular image watermarking schemes extended to stereo images.
C1 [Luo, Ting; Jiang, Gangyi; Wang, Xiaodong; Yu, Mei; Shao, Feng; Peng, Zongju] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Yu, Mei] Nanjing Univ, Natl Key Lab Software New Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Ningbo University; Nanjing University
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM luoting@nbu.edu.cn; jianggangyi@126.com; wangxiaodong@nbu.edu.cn;
   yumei2@126.com; shaofeng@nbu.edu.cn; pengzongju@nbu.edu.cn
RI Peng, Zongju/AAA-2914-2020; jiang, gang/KII-8233-2024
OI Peng, Zongju/0000-0001-8286-538X; 
FU Natural Science Foundation of China [61171163, 61071120, 61271270,
   61271021, 61111140392]; Natural Science Foundation of Zhejiang Province
   [Y1101240]; Natural Science Foundation of Ningbo [2011A610200,
   2011A610197, 2012A610045]; Scientific Research Fund of Zhejiang
   Provincial Education Department [Y201222910]
FX This work was supported by Natural Science Foundation of China
   (61171163, 61071120, 61271270, 61271021, 61111140392), Natural Science
   Foundation of Zhejiang Province (Y1101240), Natural Science Foundation
   of Ningbo (2011A610200, 2011A610197, 2012A610045), and Scientific
   Research Fund of Zhejiang Provincial Education Department (Y201222910).
CR Campisi P, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3009554
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   De Vleeschouwer C, 2002, P IEEE, V90, P64, DOI 10.1109/5.982406
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   He HJ, 2011, MULTIMED TOOLS APPL, V52, P307, DOI 10.1007/s11042-010-0474-6
   Huo YR, 2012, OPT COMMUN, V285, P1759, DOI 10.1016/j.optcom.2011.12.044
   Hur N, 2011, IEEE T BROADCAST, V57, P395, DOI 10.1109/TBC.2011.2114710
   Hwang DC, 2003, P SOC PHOTO-OPT INS, V5241, P233, DOI 10.1117/12.511615
   Hwang DC, 2004, PROC SPIE, V5208, P196, DOI 10.1117/12.506616
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2011, COMPUT ELECTR ENG, V37, P927, DOI 10.1016/j.compeleceng.2011.09.007
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Liu H, 2010, EUR J ANAESTH, V27, P740, DOI 10.1097/EJA.0b013e328337bb56
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Sabater N, 2012, IEEE T PATTERN ANAL, V34, P930, DOI 10.1109/TPAMI.2011.207
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Tanimoto M, 2012, P IEEE, V100, P905, DOI 10.1109/JPROC.2011.2182101
   Yaqing Niu, 2011, 2011 3rd European Workshop on Visual Information Processing, P211, DOI 10.1109/EuVIP.2011.6045546
   Zhang XP, 2009, SIGNAL PROCESS, V89, P675, DOI 10.1016/j.sigpro.2008.10.001
   Zhou Y, 2012, COMPUT ELECTR ENG, V38, P217, DOI 10.1016/j.compeleceng.2011.12.011
NR 22
TC 10
Z9 12
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1077
EP 1102
DI 10.1007/s11042-013-1435-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200002
DA 2024-07-18
ER

PT J
AU Duan, FQ
   Yang, S
   Huang, DH
   Hu, YL
   Wu, ZK
   Zhou, MQ
AF Duan, Fuqing
   Yang, Sen
   Huang, Donghua
   Hu, Yongli
   Wu, Zhongke
   Zhou, Mingquan
TI Craniofacial reconstruction based on multi-linear subspace analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-linear subspace analysis; Partial least squares regression;
   Craniofacial reconstruction
AB Craniofacial reconstruction aims to estimate an individual's facial appearance from its skull. It can be applied in many multimedia services such as forensic medicine, archaeology, face animation etc. In this paper, a statistical learning based method is proposed for 3D craniofacial reconstruction. In order to well represent the craniofacial shape variation and better utilize the relevance between different local regions, two tensor models are constructed for the skull and the face skin respectively, and multi-linear subspace analysis is used to extract the craniofacial subspace features. A partial least squares regression (PLSR) based mapping from skull subspace to skin subspace is established with the attributes such as age and BMI being considered. For an unknown skull, the 3D face skin is reconstructed using the learned mapping with the help of the skin tensor model. Compared with some other statistical learning based method in literature, the proposed method more directly and properly reflects the shape relationship between the skull and the face. In addition, the proposed method has little manual intervention. Experimental results show that the proposed method is valid.
C1 [Duan, Fuqing; Yang, Sen; Huang, Donghua; Wu, Zhongke; Zhou, Mingquan] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
   [Hu, Yongli] Beijing Univ Technol, Beijing Key Lab Multimedia & Intelligent Software, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
C3 Beijing Normal University; Beijing University of Technology
RP Duan, FQ (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
EM fqduan@bnu.edu.cn
OI Hu, Yongli/0000-0003-0440-438X
FU National Natural Science Foundation of China [61272363, 61171169,
   61003133]; National High-Tech Research and Development 863 Plan of China
   [2008AA01Z301]
FX This work was partially supported by the National Natural Science
   Foundation of China (Nos. 61272363, 61171169, 61003133), National
   High-Tech Research and Development 863 Plan of China (No. 2008AA01Z301).
CR [Anonymous], CIS
   [Anonymous], CIT
   [Anonymous], FORENSIC SCI INT
   [Anonymous], P 6 INT VIS MOD VIS
   [Anonymous], CVPR 2007
   [Anonymous], 3 STAT FACIAL RECONS
   [Anonymous], 2003, PROC CVPR IEEE
   [Anonymous], FRANKF PLAN
   [Anonymous], P 14 EUR UK C
   [Anonymous], CIT
   Berar M, 2011, FORENSIC SCI INT, V210, P228, DOI 10.1016/j.forsciint.2011.03.010
   Claes P, 2010, FORENSIC SCI INT, V201, P138, DOI 10.1016/j.forsciint.2010.03.008
   Claes P, 2010, FORENSIC SCI INT, V201, P146, DOI 10.1016/j.forsciint.2010.03.009
   Geenens G, 2011, STAT SURV, V5, P30, DOI 10.1214/09-SS049
   Hu YL, 2013, MULTIMED TOOLS APPL, V64, P345, DOI 10.1007/s11042-012-1005-4
   Kähler K, 2003, ACM T GRAPHIC, V22, P554, DOI 10.1145/882262.882307
   Lei Z, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2008.4587341
   Lorensen W.E., 1987, P 14 ANN C COMP GRAP, P163
   Paysan P, 2009, LECT NOTES COMPUT SC, V5748, P232, DOI 10.1007/978-3-642-03798-6_24
   Pei Y, 2008, COMPUT GRAPH FORUM, V27, P1711, DOI 10.1111/j.1467-8659.2008.01315.x
   Quatrehomme G, 1997, J FORENSIC SCI, V42, P649
   Rana S, 2009, PATTERN RECOGN, V42, P2850, DOI 10.1016/j.patcog.2009.03.018
   Tilotta FM, 2010, FORENSIC SCI INT, V200, P50, DOI 10.1016/j.forsciint.2010.03.029
   Vanezis P, 2000, FORENSIC SCI INT, V108, P81, DOI 10.1016/S0379-0738(99)00026-2
   Wilkinson C., 2004, Forensic Facial Reconstruction
   WOLD S, 1989, CHEMOMETR INTELL LAB, V7, P53, DOI 10.1016/0169-7439(89)80111-X
NR 26
TC 21
Z9 27
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 809
EP 823
DI 10.1007/s11042-012-1351-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700011
DA 2024-07-18
ER

PT J
AU Hsu, FS
   Lin, WY
   Tsai, TW
AF Hsu, Fu-Song
   Lin, Wei-Yang
   Tsai, Tzu-Wei
TI Facial expression recognition using bag of distances
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag of distances; Facial expression recognition; Facial features
ID LOCAL BINARY PATTERNS; INFORMATION; TEXTURE
AB The automatic recognition of facial expressions is critical to applications that are required to recognize human emotions, such as multimodal user interfaces. A novel framework for recognizing facial expressions is presented in this paper. First, distance-based features are introduced and are integrated to yield an improved discriminative power. Second, a bag of distances model is applied to comprehend training images and to construct codebooks automatically. Third, the combined distance-based features are transformed into mid-level features using the trained codebooks. Finally, a support vector machine (SVM) classifier for recognizing facial expressions can be trained. The results of this study show that the proposed approach outperforms the state-of-the-art methods regarding the recognition rate, using a CK+ dataset.
C1 [Hsu, Fu-Song; Lin, Wei-Yang] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
   [Tsai, Tzu-Wei] Natl Taichung Univ Sci & Technol, Dept Multimedia Design, Taichung, Taiwan.
C3 National Chung Cheng University; National Taichung University of Science
   & Technology
RP Lin, WY (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM wylin@cs.ccu.edu.tw
CR Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chew SW, 2012, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2012.6247973
   Chew SW, 2011, LECT NOTES COMPUT SC, V7088, P311, DOI 10.1007/978-3-642-25346-1_28
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Delaunay B., 1934, IZV AKAD NAUK SSSR O, V7, P1
   Ekman P, 1978, FACIAL ACTION CODING
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Ionita Mircea C., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P453, DOI 10.1109/ICCVW.2011.6130276
   Jun B, 2011, PATTERN RECOGN, V44, P532, DOI 10.1016/j.patcog.2010.10.008
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kotsia I, 2008, PATTERN RECOGN, V41, P833, DOI 10.1016/j.patcog.2007.06.026
   Lee CC, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/596842
   Li ZS, 2009, IEEE SYS MAN CYBERN, P1353, DOI 10.1109/ICSMC.2009.5346254
   Liao S, 2006, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2006.312418
   Licsár A, 2009, IEEE MULTIMEDIA, V16, P48, DOI 10.1109/MMUL.2009.41
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mu-Chun Su, 2007, WSEAS Transactions on Computers, V6, P763
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Platt JC, 2000, ADV NEUR IN, P61
   Raducanu B, 2010, IEEE INT CONF ROBOT, P156, DOI 10.1109/ROBOT.2010.5509290
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Shin G, 2008, STUD COMPUT INTELL, V149, P27, DOI 10.1007/978-3-540-70560-4_3
   Shrinivasa CLN, 2012, COMM COM INF SC, V292, P244
   Tanchotsrinon C., 2011, 2011 Proceedings of IEEE International Conference on Imaging Systems and Techniques (IST 2011), P331, DOI 10.1109/IST.2011.5962229
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Xiao R, 2011, PATTERN RECOGN, V44, P107, DOI 10.1016/j.patcog.2010.07.017
   Yang SF, 2012, IEEE T SYST MAN CY B, V42, P980, DOI 10.1109/TSMCB.2012.2192269
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhi RC, 2008, NEUROCOMPUTING, V71, P1730, DOI 10.1016/j.neucom.2007.12.002
NR 33
TC 10
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 309
EP 326
DI 10.1007/s11042-013-1616-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700016
DA 2024-07-18
ER

PT J
AU Park, SW
   Kim, JN
   Shin, SU
AF Park, Su-Wan
   Kim, Jeong Nyeo
   Shin, Sang Uk
TI Efficient DRM mechanism of scalable contents based on H.264/SVC in
   convergence environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DRM; Scalable video coding; Home network
AB This paper proposes a scalable video coding (SVC) DRM mechanism considering the convergence environment that redistributes the adaptive content for devices which may have different display size and computing capabilities between users or in the home network. The proposed SVC DRM mechanism uses the SVC content that is compressed by H.264/SVC scheme which has been standardized recently and encrypted by SVC encryption scheme so that each device gets a content of suitable level according to its own device capability. For the secure and efficient superdistribution of SVC content, moreover, this paper defines four requirements for SVC DRM and proposes a mechanism which satisfies these requirements by using another license called 'Ticket'. In addition, our system allows devices to redistribute the contents freely in the home network since the devices in the domain are managed by the domain key.
C1 [Park, Su-Wan; Kim, Jeong Nyeo] Elect & Telecommun Res Inst, Cyber Secur Res Dept, Taejon, South Korea.
   [Shin, Sang Uk] Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Pusan, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Pukyong National University
RP Shin, SU (corresponding author), Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Pusan, South Korea.
EM parksw10@etri.re.kr; jnkim@etri.re.kr; shinsu@pknu.ac.kr
FU KEIT/MOTIE/MSIP, Korea [10043959]
FX This work was supported by the IT R&D program (10043959, Development of
   EAL 4 level military fusion security solution for protecting against
   unauthorized accesses and ensuring a trusted execution environment in
   mobile devices) of KEIT/MOTIE/MSIP, Korea.
CR Abbadi IMA, 2008, DIGITAL RIGHTS MANAG
   Aikebaier A, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-6
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 2003, ADV VID COD GEN AUD
   [Anonymous], 2007, N8750 ISOIEC JTC 1SC
   Bocan V, 2006, SOFTCOM 2006: INTERNATIONAL CONFERENCE ON SOFTWARE, TELECOMMUNICATIONS AND COMPUTER NETWORKS, P182
   Hwang SO, 2008, ETRI J, V30, P565, DOI 10.4218/etrij.08.0107.0323
   Kamperman FLAJ, 2007, CONSUM COMM NETWORK, P935, DOI 10.1109/CCNC.2007.189
   Kim H, 2007, LECT NOTES COMPUT SC, V4846, P78
   Lee YG, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P139, DOI 10.1109/ICHIT.2008.199
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Park SW, 2009, IEICE T INFORM SYSTE, VE92-D
   Popescu B.C., 2004, P 4 ACM WORKSHOP DIG, P1
   Vakili A., 2011, Journal of Convergance (JoC), V2, P43
   Wang PC, 2010, ETRI J, V32, P577, DOI 10.4218/etrij.10.0109.0622
   Wang Xiaolin., 2011, JoC, V2, P19
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 17
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 841
EP 855
DI 10.1007/s11042-013-1452-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700013
DA 2024-07-18
ER

PT J
AU Zghal, HB
   Moreno, A
AF Zghal, Hajer Baazaoui
   Moreno, Antonio
TI A system for information retrieval in a medical digital library based on
   modular ontologies and query reformulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ontology; Semantic information retrieval; Medical digital library; Query
   reformulation
AB Ontologies have proven to be useful in the area of Information Retrieval and the biomedical informatics community has acknowledged, in recent years, their utility. However, building and updating manually ontologies is a long and tedious task. This paper proposes a system that allows any search engine to develop its semantic layer by applying ontology learning techniques on Web snippets and applies it to a well-known medical digital library, PubMed. The new system (SemPubMed) automatically builds new ontology fragments related to the user's query and then it reformulates queries using the new concepts in order to improve information retrieval. Our system has endured a twofold evaluations. On the one hand, we have evaluated the quality of the modular ontologies built by the system. On the other hand, we have studied how the semantic reformulation of the queries has led to an improvement of the quality of the results given by PubMed, both in terms of precision and recall. Obtained results show that adding semantic layer to PubMed enables an improvement of query reformulation and predicted ranking score.
C1 [Zghal, Hajer Baazaoui] Manouba Univ, Riadi GDL Lab, Tunis, Tunisia.
   [Moreno, Antonio] Univ Rovira & Virgili, ITAKA Res Grp, E-43007 Tarragona, Spain.
C3 Universite de la Manouba; Universitat Rovira i Virgili
RP Zghal, HB (corresponding author), Manouba Univ, Riadi GDL Lab, Tunis, Tunisia.
EM hajer.baazaouizghal@riadi.rnu.tn; antonio.moreno@urv.cat
RI Moreno, Antonio/N-6972-2019
OI Moreno, Antonio/0000-0003-3945-2314; Baazaoui, Hajer/0000-0002-2151-7397
FU Spanish-Tunisian AECID [A/030058/10]
FX This research work has been supported by the Spanish-Tunisian AECID
   project number A/030058/10, "A framework for the integration of Ontology
   Learning and Semantic Search".
CR Baruzzo A., 2009, J DIGIT INF
   Ben Mustapha Nesrine, 2012, Model and Data Engineering. Proceedings of the 2nd International Conference, MEDI 2012, P79, DOI 10.1007/978-3-642-33609-6_9
   Ben Mustapha N, 2011, LECT NOTES COMPUT SC, V6882, P538, DOI 10.1007/978-3-642-23863-5_55
   Berland M., 1999, P 37 ANN M ASS COMPU, P57, DOI DOI 10.3115/1034678.1034697
   Bettembourg C, 2012, J BIOMED SEMANT, V3, DOI 10.1186/2041-1480-3-7
   Boldi P, 2011, INFORM RETRIEVAL, V14, P257, DOI 10.1007/s10791-010-9155-3
   Christopher D.Manning., 1999, FDN STAT NATURAL LAN
   Corby O, 2004, FRONT ARTIF INTEL AP, V110, P705
   El Kafsi S, 2012, FRONT ARTIF INTEL AP, V243, P1932, DOI 10.3233/978-1-61499-105-2-1932
   Elloumi-Chaabene M, 2011, ICSOFT 2011: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SOFTWARE AND DATABASE TECHNOLOGIES, VOL 1, P305
   Ferran N, 2005, LIBR MANAGE, V26, P206, DOI 10.1108/01435120510596062
   Kiefer S, 2011, LECT NOTES COMPUT SC, V7046, P382
   Mastora Anna., 2008, Lecture Notes in Computer Science, V5173 LNCS, P427, DOI DOI 10.1007/978-3-540-87599-4_54
   Mayr P, 2007, REDUCING SEMANTIC CO, P213
   Perez-Carballo J, 2011, DESIGN PRINCIPLES HE
   Price C, 2010, INT J BIOMED ENG TEC, V3, P375, DOI 10.1504/IJBET.2010.032701
   Sanchez David, 2007, International Journal of Metadata, Semantics and Ontologies, V2, P112, DOI 10.1504/IJMSO.2007.016805
   Sánchez D, 2008, AI COMMUN, V21, P27
   Sánchez D, 2008, DATA KNOWL ENG, V64, P600, DOI 10.1016/j.datak.2007.10.001
   Sánchez D, 2012, EXPERT SYST APPL, V39, P5792, DOI 10.1016/j.eswa.2011.11.088
   Suomela S, 2005, LECT NOTES COMPUT SC, V3408, P315
   Swe Thinn Mya Mya, 2011, COMPUTER SCI INFORM, V1-2
   Tan P. N., 2016, INTRO DATA MINING
   Turney P. D., 2001, P 12 EUR C MACH LEAR, P491, DOI DOI 10.1007/3-540-44795-4_42
   Vallet D, 2005, LECT NOTES COMPUT SC, V3532, P455
   Yu Hwanjo., 2009, Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM 2009, Hong Kong, China, November 2-6, 2009, P2099
   Zhao PX, 2005, LECT NOTES COMPUT SC, V3453, P699, DOI 10.1007/11408079_64
NR 27
TC 8
Z9 8
U1 0
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2393
EP 2412
DI 10.1007/s11042-013-1527-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300016
DA 2024-07-18
ER

PT J
AU Natgunanathan, I
   Xiang, Y
   Rong, Y
   Peng, DZ
AF Natgunanathan, Iynkaran
   Xiang, Yong
   Rong, Yue
   Peng, Dezhong
TI Robust patchwork-based watermarking method for stereo audio signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Patchwork; Stereo audio signal; Discrete Fourier
   transform
ID BLIND SEPARATION; SPREAD-SPECTRUM; VECTOR; SCHEME
AB This paper presents a patchwork-based watermarking method for stereo audio signals, which exploits the similarity of the two sound channels of stereo signals. Given a segment of stereo signal, we first compute the discrete Fourier transforms (DFTs) of the two sound channels, which yields two sets of DFT coefficients. The DFT coefficients corresponding to certain frequency range are divided into multiple subsegment pairs and a criterion is proposed to select those suitable for watermark embedding. Then a watermark is embedded into the selected subsegment pairs by modifying their DFT coefficients. The exact way of modification is determined by a secret key, the watermark to be embedded, and the DFT coefficients themselves. In the decoding process, the subsegment pairs containing watermarks are identified by another criterion. Then the secret key is used to extract the watermark from the watermarked subsegments. Compared to the existing patchwork methods for audio watermarking, the proposed method does not require knowledge of which segments of the watermarked audio signal contain watermarks and is more robust to conventional attacks.
C1 [Natgunanathan, Iynkaran; Xiang, Yong] Deakin Univ, Sch Informat Technol, Melbourne, Vic 3125, Australia.
   [Rong, Yue] Curtin Univ, Dept Elect & Comp Engn, Bentley, WA 6102, Australia.
   [Peng, Dezhong] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
C3 Deakin University; Curtin University; Sichuan University
RP Xiang, Y (corresponding author), Deakin Univ, Sch Informat Technol, Burwood Campus, Melbourne, Vic 3125, Australia.
EM iynkaran.n@research.deakin.edu.au; yxiang@deakin.edu.au;
   y.rong@curtin.edu.au; pengdz@scu.edu.cn
RI Rong, Yue/K-3368-2013
OI Rong, Yue/0000-0002-5831-7479
FU Australian Research Council [DP1095498, DP110102076]; National Basic
   Research Program of China (973 Program) [2011CB302201]; National Natural
   Science Foundation of China [61172180]; Australian Research Council
   [DP1095498] Funding Source: Australian Research Council
FX This work was supported in part by the Australian Research Council under
   grants DP1095498 and DP110102076, the National Basic Research Program of
   China (973 Program) under grant 2011CB302201, and the National Natural
   Science Foundation of China under grant 61172180.
CR Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   [Anonymous], 2001, REC B S 1387 INT TEL
   Arnold M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1013, DOI 10.1109/ICME.2000.871531
   Baras C, 2006, IEEE T AUDIO SPEECH, V14, P1772, DOI 10.1109/TASL.2006.879808
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Cao W, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P603, DOI 10.1109/NISS.2009.234
   Chen OTC, 2008, IEEE T AUDIO SPEECH, V16, P629, DOI 10.1109/TASL.2007.913022
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Erçelebi E, 2009, DIGIT SIGNAL PROCESS, V19, P265, DOI 10.1016/j.dsp.2008.11.007
   Erfani Y, 2009, DIGIT SIGNAL PROCESS, V19, P809, DOI 10.1016/j.dsp.2009.04.003
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Foo S, 2008, TRANSPORT RES REC, P1, DOI 10.3141/2047-01
   Huang CH, 2009, IEEE T INF FOREN SEC, V4, P193, DOI 10.1109/TIFS.2009.2020778
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Kalantari NK, 2009, IEEE T AUDIO SPEECH, V17, P1133, DOI 10.1109/TASL.2009.2019259
   Kirbiz Serap, 2006, P 2006 IEEE INT C AC, V5, P761
   Kirovski D, 2001, INT CONF ACOUST SPEE, P1345, DOI 10.1109/ICASSP.2001.941177
   Ko BS, 2005, IEEE T MULTIMEDIA, V7, P212, DOI 10.1109/TMM.2005.843366
   Kondo K, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P624, DOI 10.1109/IIH-MSP.2008.35
   Lakshmi D., 2008, P 2008 IEEE REG 10 C, P1
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu CS, 2005, MULTIMEDIA SECURITY
   Lu W, 2012, MULTIMED TOOLS APPL, V60, P31, DOI 10.1007/s11042-011-0794-1
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Natgunanathan I, 2012, IEEE T AUDIO SPEECH, V20, P2232, DOI 10.1109/TASL.2012.2199111
   Oppenheim A.V., 1998, DISCRETE TIME SIGNAL
   Peng DZ, 2010, DIGIT SIGNAL PROCESS, V20, P581, DOI 10.1016/j.dsp.2009.08.014
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Singh J, 2012, MULTIMED TOOLS APPL, V59, P921, DOI 10.1007/s11042-011-0783-4
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Takahashi A, 2005, IEEE T SIGNAL PROCES, V53, P806, DOI 10.1109/TSP.2004.839901
   Valizadeh A., 2011, IEEE Transactions on Information Forensics and Security, V6, P267, DOI 10.1109/TIFS.2010.2103061
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wang XY, 2007, IEEE T AUDIO SPEECH, V15, P2270, DOI 10.1109/TASL.2007.906192
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang Y, 2008, COMPUT ELECTR ENG, V34, P416, DOI 10.1016/j.compeleceng.2007.12.002
   Xiang Y, 2013, IEEE T NEUR NET LEAR, V24, P94, DOI 10.1109/TNNLS.2012.2224671
   Xiang Y, 2012, IEEE T INF FOREN SEC, V7, P383, DOI 10.1109/TIFS.2011.2173678
   Xiang Y, 2011, IEEE T MULTIMEDIA, V13, P2, DOI 10.1109/TMM.2010.2080668
   Yeo IK, 2003, IEEE T SPEECH AUDI P, V11, P381, DOI 10.1109/TSA.2003.812145
NR 47
TC 11
Z9 13
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1387
EP 1410
DI 10.1007/s11042-013-1454-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yuan, XC
   Pun, CM
AF Yuan, Xiao-Chen
   Pun, Chi-Man
TI Feature extraction and local Zernike moments based geometric invariant
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geometric invariant; Feature extraction; SIFT; Local Zernike transform;
   Inverse Zernike transform
ID TRANSLATION RESILIENT WATERMARKING; IMAGE; ROBUST; SCALE; ROTATION;
   RECOGNITION
AB A robust and geometric invariant digital image watermarking scheme based on robust feature detector and local Zernike transform is proposed in this paper. The robust feature extraction method is proposed based on the Scale Invariant Feature Transform (SIFT) algorithm, to extract circular regions/patches for watermarking use. Then a local Zernike moments-based watermarking scheme is raised, where the watermarked regions/patches can be obtained directly by inverse Zernike Transform. Each extracted circular patch is decomposed into a collection of binary patches and Zernike transform is applied to the appointed binary patches. Magnitudes of the local Zernike moments are calculated and modified to embed the watermarks. Experimental results show that the proposed watermarking scheme is very robust against geometric distortion such as rotation, scaling, cropping, and affine transformation; and common signal processing such as JPEG compression, median filtering, and low-pass Gaussian filtering.
C1 [Yuan, Xiao-Chen; Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Macau, Macau Sar, Peoples R China.
C3 University of Macau
RP Yuan, XC (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Macau Sar, Peoples R China.
EM yb07417@umac.mo; cmpun@umac.mo
RI Yuan, Xiaochen/ABH-5255-2020; Pun, Chi Man/GRJ-3703-2022
OI Yuan, Xiaochen/0000-0002-7490-6695; Pun, Chi-Man/0000-0003-1788-3746
FU Science and Technology Development Fund of Macau SAR [034/2010/A2];
   Research Committee of the University of Macau
FX The authors would like to thank the referees for their valuable
   comments. This work was supported in part by the Science and Technology
   Development Fund of Macau SAR (Project No. 034/2010/A2) and the Research
   Committee of the University of Macau.
CR ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bas P, 2000, PROC SPIE, V3971, P99, DOI 10.1117/12.385013
   Cox I. J., 2002, Digital Watermarking
   Dong P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P489, DOI 10.1109/ICIP.2002.1039014
   DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Lee HY, 2006, OPT ENG, V45, DOI 10.1117/1.2181887
   Lee HY, 2005, LECT NOTES COMPUT SC, V3710, P418
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Lin YT, 2011, IET IMAGE PROCESS, V5, P328, DOI 10.1049/iet-ipr.2009.0264
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   O'Ruanaidh J., 1998, Signal Processing, V66, P303, DOI DOI 10.1016/S0165-1684(98)00012-7
   PERANTONIS SJ, 1992, IEEE T NEURAL NETWOR, V3, P241, DOI 10.1109/72.125865
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087
   REEVES AP, 1988, IEEE T PATTERN ANAL, V10, P937, DOI 10.1109/34.9115
   Scagliola M, 2009, COMM COM INF SC, V48, P345
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Seo JS, 2004, PATTERN RECOGN, V37, P1365, DOI 10.1016/j.patcog.2003.12.013
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Tsai JS, 2012, SIGNAL PROCESS, V92, P1431, DOI 10.1016/j.sigpro.2011.11.033
   Tsai JS, 2011, IEEE T IMAGE PROCESS, V20, P735, DOI 10.1109/TIP.2010.2073475
   Viet Quoc Pham, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P473
   Wang XY, 2009, SCI CHINA SER F, V52, P1605, DOI 10.1007/s11432-009-0125-6
   Xin YQ, 2004, INT C PATT RECOG, P861, DOI 10.1109/ICPR.2004.1333908
   Yuan XC, 2012, INT J SECUR APPL, V6, P217
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zheng D, 2003, IEEE T CIRC SYST VID, V13, P753, DOI 10.1109/TCSVT.2003.815959
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
NR 39
TC 21
Z9 21
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 777
EP 799
DI 10.1007/s11042-013-1405-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800035
DA 2024-07-18
ER

PT J
AU Subramanyam, AV
   Emmanuel, S
AF Subramanyam, A. V.
   Emmanuel, Sabu
TI Partially compressed-encrypted domain robust JPEG image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed-encrypted domain watermarking; JPEG watermarking
ID COEFFICIENTS; PROTOCOL; RC4
AB Digital media is often handled in a compressed and encrypted form in Digital Asset Management Systems. And watermarking of the compressed encrypted media items in the compressed-encrypted domain itself is required sometimes for copyright violation detection or other purposes. In this paper, we propose a robust image watermarking technique for partially compressed-encrypted JPEG images. However, arbitrary embedding of a watermark in a partially compressed encrypted image can cause drastic degradation of the quality as the underlying change may result in random decrypted values. In addition, due to the encryption the compression efficiency may become very low. Thus the challenge is to design a watermarking technique that provides good watermarked image quality and at the same time gives good compression efficiency. While the proposed technique embeds watermark in the partially compressed-encrypted domain, the extraction of watermark can be done in the encrypted or decrypted domains. The experiments show that the watermarked image quality is good and the reduction in compression efficiency is low. The proposed watermarking technique is robust to common signal processing attacks. The watermark detection performance of the proposed scheme is better than the existing encrypted domain watermarking techniques.
C1 [Subramanyam, A. V.; Emmanuel, Sabu] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Subramanyam, AV (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM subr0021@ntu.edu.sg; asemmanuel@ntu.edu.sg
RI Emmanuel, Sabu/A-3690-2011
CR Cancellaro M, 2008, PROC SPIE, V6819, DOI 10.1117/12.766650
   Castelluccia C, 2005, PROCEEDINGS OF MOBIQUITOUS 2005, P109
   Deng MN, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P9
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   Klein A, 2008, DESIGN CODE CRYPTOGR, V48, P269, DOI 10.1007/s10623-008-9206-6
   Kuribayashi M, 2005, IEEE T IMAGE PROCESS, V14, P2129, DOI 10.1109/TIP.2005.859383
   Li SJ, 2010, IEEE IMAGE PROC, P2085, DOI 10.1109/ICIP.2010.5653467
   Lian SG, 2006, OPT ENG, V45, DOI 10.1117/1.2333510
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Paul G, 2008, DESIGN CODE CRYPTOGR, V49, P123, DOI 10.1007/s10623-008-9177-7
   Piva A, 2010, IEEE T INF FOREN SEC, V5, P13, DOI 10.1109/TIFS.2009.2038761
   Prins JP, 2007, EURASIP J INF SECUR, V2007, P1
   REININGER RC, 1983, IEEE T COMMUN, V31, P835, DOI 10.1109/TCOM.1983.1095893
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Said A, 2005, P IEEE INT C IM PROC, P1123
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Thomas T, 2009, IEEE T INF FOREN SEC, V4, P758, DOI 10.1109/TIFS.2009.2033229
   Uehara T, 2006, IEEE T IMAGE PROCESS, V15, P3592, DOI 10.1109/TIP.2006.881939
   Zhao B, 2010, INFORM SCIENCES, V180, P4672, DOI 10.1016/j.ins.2010.08.003
NR 20
TC 6
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1311
EP 1331
DI 10.1007/s11042-012-1272-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000016
DA 2024-07-18
ER

PT J
AU Kim, KB
   Park, HJ
   Kim, GH
AF Kim, Kwang Baek
   Park, Hyun Jun
   Kim, Gwang Ha
TI An analysis of muscles from ultrasound image using morphological
   information of fascia and thoracic vertebra
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Muscles analysis; Ultrasound image; Fascia; Thoracic vertebra
ID UNITED-STATES; RELIABILITY; TECHNOLOGY; DISORDERS
AB In this paper, we propose a new fully computerized image analysis method for measuring the thickness of muscles from ultrasound image obtained by muscle endurance test using morphological information of fascia and thoracic vertebra. Firstly, we divide the image into lumbar region and thoracolumbar region by the difference of density in image for measuring the thickness of muscles. In lumbar region, we notice that the intensity of fascia is relatively higher than other parts. Thus, we measure the thickness of muscles surrounding the fascia area. In the process, we apply median filter to candidate fascia areas for extracting candidate muscle layers between fascias. Then, the thickness of muscles we measure is that of the third layer. In thoracolumbar region, we apply region expansion method for classifying the region into subcutaneous fat part and part including thoracic vertebra. Then, we apply counting method and evolutionary computation search model to find the measuring location that is in between subcutaneous fat area and thoracic vertebra. In experiment, the proposed method is effective in measuring the thickness of muscles and avoids failures of previous studies. The performance of this approach is sufficiently comparable to that of medical experts.
C1 [Kim, Kwang Baek] Silla Univ, Dept Comp Engn, Pusan 617736, South Korea.
   [Park, Hyun Jun] Pusan Natl Univ, Dept Comp Engn, Pusan 609735, South Korea.
   [Kim, Gwang Ha] Pusan Natl Univ, Sch Med, Dept Internal Med, Pusan 602739, South Korea.
   [Kim, Gwang Ha] Pusan Natl Univ Hosp, Biomed Res Inst, Pusan 602739, South Korea.
C3 Silla University; Pusan National University; Pusan National University;
   Pusan National University Hospital; Pusan National University; Pusan
   National University Hospital
RP Kim, GH (corresponding author), Pusan Natl Univ, Sch Med, Dept Internal Med, Ami Dong 1 Ga, Pusan 602739, South Korea.
EM gbkim@silla.ac.kr; hyunjun@pusan.ac.kr; doc0224@pusan.ac.kr
RI Kim, Gwang Ha/ABF-3932-2021
OI Kim, Gwang Ha/0000-0001-9721-5734
FU National R&D Program for Cancer Control, Ministry for Health, Welfare
   and Family affairs, Republic of Korea [0920050]
FX This study was supported by a grant from the National R&D Program for
   Cancer Control, Ministry for Health, Welfare and Family affairs,
   Republic of Korea (0920050).
CR [Anonymous], 2006, Evolutionary Computation: A Unified Approach
   Conley MS, 1997, EUR J APPL PHYSIOL, V75, P443, DOI 10.1007/s004210050186
   Costa LOP, 2009, PHYS THER, V89, P756, DOI 10.2522/ptj.20080331
   Hebert JJ, 2009, SPINE, V34, pE848, DOI 10.1097/BRS.0b013e3181ae625c
   Katz JN, 2006, J BONE JOINT SURG AM, V88A, P21, DOI 10.2106/JBJS.E.01273
   Kim KB, 2010, NEURAL NETW WORLD, V20, P405
   Koppenhaver SL, 2009, ARCH PHYS MED REHAB, V90, P87, DOI 10.1016/j.apmr.2008.06.022
   Kremkau F, 2002, DIAGNOSTIC ULTRASOUN
   Lawrence RC, 1998, ARTHRITIS RHEUM-US, V41, P778, DOI 10.1002/1529-0131(199805)41:5<778::AID-ART4>3.0.CO;2-V
   Leigh JP, 1997, ARCH INTERN MED, V157, P1557, DOI 10.1001/archinte.157.14.1557
   Rezasoltani A, 2002, J REHABIL RES DEV, V39, P423
   Stokes M, 2005, MANUAL THER, V10, P116, DOI 10.1016/j.math.2004.08.013
   Whittaker JL, 2007, J ORTHOP SPORT PHYS, V37, P434, DOI 10.2519/jospt.2007.2350
   Whittaker JL, 2011, J ORTHOP SPORT PHYS, V41, P572, DOI 10.2519/jospt.2011.3682
NR 14
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 931
EP 945
DI 10.1007/s11042-013-1773-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400033
DA 2024-07-18
ER

PT J
AU Muñoz-Gea, JP
   Nafaa, A
   Malgosa-Sanahuja, J
   Rohmer, T
AF Pedro Munoz-Gea, Juan
   Nafaa, Abdelhamid
   Malgosa-Sanahuja, Josemaria
   Rohmer, Thibaud
TI Design and analysis of a peer-assisted VOD provisioning system for
   managed networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video-on-Demand; P2P streaming; Set-top boxes; Resource allocation
ID REPLICATION; CAPACITY; SERVICES
AB With the rise of VOD (Video-on-Demand) services provisioning as a successful service on the Internet and managed networks, we are witnessing a drive towards cost-efficiency and economies of scale. Many broadband operators around the world are experimenting with P2P (Peer-to-Peer) systems centered on STBs (Set-Top-Boxes) to increase the competitiveness of their VOD services offering. By leveraging the storage and uplink bandwidth capacities available at a certain number of STBs operated by the broadband operator, the savings in terms of backend streaming capacities will represent sizable and decisive gains in cost. In these systems, video contents are usually fragmented into a number of complementary content fragments, called sub-streams, which are randomly injected in the network of STBs, and the VOD service is essentially provisioned through multisource streaming sessions from neighboring STBs to the requesting STB. One of the main challenges in such peer-assisted streaming systems remains the maximization of the utilization of STB resources utility for a given content popularity pattern. In this paper, we specifically focus on the content injection strategy and how the different content fragments should be dispatched in the network to achieve the highest performance in the VOD services provisioning epoch. We demonstrate that the random injection strategy is not appropriate for maximizing the number of simultaneous VOD streaming sessions in the network. Our objective is to first gain a better understanding of the factors driving P2P-based VOD streaming systems and provide guidelines to better operate such systems and ultimately give service operators the tools to achieve different performance objectives and/or fit specific network configurations. Further, we propose a new content dispatching strategy that maximizes the number of served VOD sessions by balancing the streaming load among the different STBs. Finally, we propose a complementary streaming resources reprovisioning mechanism that acts in real-time to reprovision the resources for serving VOD sessions to new STBs and to release trapped resources for new incoming VOD service requests.
C1 [Pedro Munoz-Gea, Juan; Malgosa-Sanahuja, Josemaria] Univ Politecn Cartagena, Dept Informat Technol & Commun, Cartagena, Spain.
   [Nafaa, Abdelhamid; Rohmer, Thibaud] Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 2, Ireland.
C3 Universidad Politecnica de Cartagena; University College Dublin
RP Muñoz-Gea, JP (corresponding author), Univ Politecn Cartagena, Dept Informat Technol & Commun, Cartagena, Spain.
EM juanp.gea@upct.es; nafaa@ieee.org; josem.malgosa@upct.es;
   thibaud.rohmer@ucd.ie
RI Malgosa-Sanahuja, Josemaria/E-3550-2016; Muñoz-Gea, Juan
   Pedro/D-7353-2016
OI Malgosa-Sanahuja, Josemaria/0000-0001-8137-1089; Muñoz-Gea, Juan
   Pedro/0000-0001-8342-4797
FU MICINN/FEDER [TEC2010-21405-C02-02/TCM]
FX This research has been supported by the MICINN/FEDER project grant
   TEC2010-21405-C02-02/TCM (CALM) and it is also developed in the
   framework of "Programa de Ayudas a Grupos de Excelencia de la Region de
   Murcia, de la Fundacion Seneca, Agencia de Ciencia y Tecnologia de la RM
   (Plan Regional de Ciencia y Tecnologia 2007/2010)".
CR Boufkhad Y., 2008, Proceedings of the 7th International Conference on Peer-to-peer Systems, IPTPS'08, P1
   Cha M, 2008, P 7 INT C PEER TO PE, P1
   Chellouche SA, 2012, P 2012 IEEE INT C CO, P1
   Chen YF, 2009, MULTIMEDIA SYST, V15, P19, DOI 10.1007/s00530-008-0127-z
   Chen YFR, 2010, MULTIMEDIA SYST, V16, P199, DOI 10.1007/s00530-010-0184-y
   Choe Y.R., 2007, MULTIMEDIA 07 P 15 I, P117
   Cisco, 2009, VIS NETW IND FOR MET
   Defrance S, 2011, IEEE INT CONF PEER, P142, DOI 10.1109/P2P.2011.6038671
   Dyaberi JM, 2010, P 1 ANN ACM SIGMM C, P59
   Han D., 2011, 2011 International Conference on Management and Service Science, Management and Service Science (MASS), 2011 International Conference On, P1, DOI 10.1109/ICMSS.2011.5998114
   He JY, 2009, COMPUT NETW, V53, P153, DOI 10.1016/j.comnet.2008.10.014
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   Janardhan V., 2007, Proceedings of the 2007 workshop on Peer-to-peer streaming and IP-TV, P335
   Jayasundara C, 2011, P IEEE GLOB 2011, P1
   Kasenna, 2006, OBS DEM US PATT ITS
   Kelényi I, 2011, IEEE COMMUN MAG, V49, P142, DOI 10.1109/MCOM.2011.5783999
   Kikuchi Y, 2000, RFC 3016 RTP PAYLOAD
   Laoutaris N, 2008, ACM SIGCOMM COMP COM, V38, P51, DOI 10.1145/1341431.1341442
   Liu FM, 2013, IEEE T COMPUT, V62, P351, DOI 10.1109/TC.2011.222
   Liu FM, 2011, IEEE INFOCOM SER, P936, DOI 10.1109/INFCOM.2011.5935320
   May M, 2011, P ACM SIGCOMM 2011 C, P471
   Nafaa A, 2012, MULTIMED TOOLS APPL, V59, P169, DOI 10.1007/s11042-011-0755-8
   Nafaa A, 2008, IEEE COMMUN MAG, V46, P47, DOI 10.1109/MCOM.2008.4689207
   Netflix Inc., 2006, NETFL PRIZ
   Pussep Konstantin, 2010, 6th International Conference on Network and Service Management (CNSM 2010), P166, DOI 10.1109/CNSM.2010.5691312
   Suh K, 2007, IEEE J SEL AREA COMM, V25, P1706, DOI 10.1109/JSAC.2007.071209
   Tan B, 2011, IEEE INFOCOM SER, P694, DOI 10.1109/INFCOM.2011.5935250
   Valancius V., 2009, PROC CONEXT 09, P37, DOI DOI 10.1145/1658939.1658944
   Wang Kai., 2009, 2009 P 18 INT C COMP, P1
   Wu WJ, 2011, IEEE INFOCOM SER, P1206, DOI 10.1109/INFCOM.2011.5934900
   Zhou YP, 2012, IEEE INFOCOM SER, P1530, DOI 10.1109/INFCOM.2012.6195520
   Zhou YP, 2011, IEEE INFOCOM SER, P945, DOI 10.1109/INFCOM.2011.5935322
NR 32
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1363
EP 1398
DI 10.1007/s11042-012-1171-4
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500001
DA 2024-07-18
ER

PT J
AU Cheng, H
   Liu, ZC
   Zhao, Y
   Ye, G
   Sun, XH
AF Cheng, Hong
   Liu, Zicheng
   Zhao, Yang
   Ye, Guo
   Sun, Xinghai
TI Real world activity summary for senior home monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Activity summary; Senior home monitoring; Health
   care; Feature filtering; Temporal smoothing
ID ACTIVITY RECOGNITION
AB It is a common knowledge that the daily activities of senior people tell a lot about their health condition. Thus, we believe that analysing their activities at home will improve the health care. Toward this goal, we propose a senior home activity summary system. There are two challenging problems in such a real world application. First, the amount of data for different activity categories is extremely unbalanced, which severely degrades the classifying performance. Second, senior's activities are usually accompanied by nurse's walking. It is impractical to predefine and label all the possible activities of all the potential visitors. Consequently, we propose a technique called subspace Naive-Bayesian Mutual Information Maximization (sNBMIM). It divides the feature space into a number of subspaces and allows the kernel and normalization parameters to vary between different subspaces. Moreover, we propose a novel feature filtering technique to reduce or eliminate the effects of the interest points that belong to other people. To evaluate the proposed activity summary system, we have collected a Senior home Activity Recognition dataset (UESTC-SAR), and performed activity recognition for eight categories. The experimental results show that the proposed system provides quite accurate activity summaries for a real world application scenario.
C1 [Cheng, Hong; Zhao, Yang; Ye, Guo; Sun, Xinghai] Univ Elect Sci & Technol China, Chengdu 611731, Peoples R China.
   [Liu, Zicheng] Microsoft Res Redmond, Redmond, WA 98052 USA.
C3 University of Electronic Science & Technology of China; Microsoft
RP Cheng, H (corresponding author), Univ Elect Sci & Technol China, Chengdu 611731, Peoples R China.
EM hcheng@uestc.edu.cn; zliu@microsoft.com; zhaoyang1025@gmail.com;
   yeguo0112@gmail.com; sunxinghai1216@gmail.com
OI Ye, Guo/0000-0001-9361-9977
FU NSFC [61075045]; Program for New Century Excellent Talents in University
   [NECT-10-0292]; National Basic Research Program of China [2011CB707000];
   Fundamental Research Funds for the Central Universities
FX This research was partially supported by the grant from NSFC (No.
   61075045), the Program for New Century Excellent Talents in University
   (NECT-10-0292), the National Basic Research Program of China (No.
   2011CB707000), and the Fundamental Research Funds for the Central
   Universities. We also thank the Jinrui Honghe Garden for the seniors and
   anonymous reviewers for their valuable suggestions.
CR Amini S, 2009, CMUCYLAB10003
   [Anonymous], IEEE CVPR
   [Anonymous], IEEE ICCV WORKSH
   [Anonymous], IEEE CVPR
   Atrey PK, 2006, MULTIMEDIA SYST, V12, P239, DOI 10.1007/s00530-006-0063-8
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Behmo R, 2010, LECT NOTES COMPUT SC, V6314, P171, DOI 10.1007/978-3-642-15561-1_13
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blank Moshe., 2005, IEEE ICCV
   Boiman O, 2008, IEEE CVPR
   BULLING A, 2011, IEEE T PATTERN ANAL, V33, P741, DOI DOI 10.1109/TPAMI.2010.86
   Bussmann JBJ, 2001, BEHAV RES METH INS C, V33, P349, DOI 10.3758/BF03195388
   Cao L, 2010, IEEE CVPR
   Cheng H, 2011, IEEE INT CON MULTI
   Choudhury T, 2008, IEEE PERVAS COMPUT, V7, P32, DOI 10.1109/MPRV.2008.39
   Consolvo S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1797
   Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870
   Duong T., 2005, IEEE CVPR
   Gu T, 2010, DATA KNOWL ENG, V69, P533, DOI 10.1016/j.datak.2010.01.004
   Hu D.H., 2008, ACM UBICOMP
   Hu Y, 2009, IEEE ICCV
   Ke Y., 2007, IEEE ICCV
   Kim E, 2010, IEEE PERVAS COMPUT, V9, P48, DOI 10.1109/MPRV.2010.7
   Kovashka A, 2010, IEEE CVPR
   Krafft M, 2009, THESIS
   Lai C, 2010, IEEE INTELL SYST, V99, P1172
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lazebnik S, 2006, IEEE CVPR
   Liao L, THESIS
   Litvak D, 2008, INT C ENG MED BIOL S
   Liu J., 2009, IEEE CVPR
   Matsumoto N, 2009, LECT NOTES COMPUT SC, V5611, P341, DOI 10.1007/978-3-642-02577-8_37
   Messing R, 2009, IEEE ICCV
   Miluzzo E, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P337
   Nambu M, 2005, IEEE ENG MED BIOL, V24, P38, DOI 10.1109/MEMB.2005.1463394
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Palmes P, 2010, PERVASIVE MOB COMPUT, V6, P43, DOI 10.1016/j.pmcj.2009.10.004
   Pirsiavash H., 2012, IEEE CVPR
   Prabhakar S, 2003, IEEE SAF PRIV
   Ramasso E, 2006, IEEE ICASSP
   Ravi N, 2005, P NAT C ART INT
   Rialle V, 2003, COMPUT METH PROG BIO, V72, P257, DOI 10.1016/S0169-2607(02)00161-X
   Schuldt C, 2004, IEEE ICPR
   Seon-Woo Lee, 2002, IEEE Pervasive Computing, V1, P24, DOI 10.1109/MPRV.2002.1037719
   Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158, DOI 10.1007/978-3-540-24646-6_10
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   United Nations Population Division, 2002, WORLD POP AG
   Wang P, 2009, IEEE ICCV
   Ward JA, 2006, IEEE T PATTERN ANAL, V28, P1553, DOI 10.1109/TPAMI.2006.197
   Yuan J., 2009, IEEE CVPR
   Yuan J, 2009, P 1 ACM INT WORKSH E
   Yuan JS, 2010, IEEE SIGNAL PROC MAG, V27, P136, DOI 10.1109/MSP.2010.937496
   Zigel Y, 2009, IEEE T BIO-MED ENG, V56, P2858, DOI 10.1109/TBME.2009.2030171
NR 53
TC 12
Z9 12
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 177
EP 197
DI 10.1007/s11042-012-1162-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300008
DA 2024-07-18
ER

PT J
AU Wang, JQ
   Wang, B
   Duan, LY
   Tian, Q
   Lu, HQ
AF Wang, Jinqiao
   Wang, Bo
   Duan, Ling-yu
   Tian, Qi
   Lu, Hanqing
TI Interactive ads recommendation with contextual search on product topic
   space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video advertising; Video analysis; Visual-textual search
AB The rapid popularization of various online media services have attracted large amounts of consumers and shown us a large potential market of video advertising. In this paper, we propose interactive service recommendation based on ad concept hierarchy and contextual search. Instead of traditional ODP (Open Directory Project) based approach, we built a ad domain based concept hierarchy to make the most of the product details over the e-commerce sites. Firstly, we capture the summarization images related to the advertising product in the video content and search visually similar product images from the built product image database. Then, we aggregate the visual tags and textual tags with K-line clustering. Finally, we map them to the product concept space and make keywords suggestion, and users can interactively select keyframes or keywords to personalize their intentions by textual re-search. Experiments and comparison show that the system can accurately provide effective advertising suggestions.
C1 [Wang, Jinqiao; Wang, Bo; Lu, Hanqing] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Duan, Ling-yu] Peking Univ, Sch EE&CS, Inst Digital Media, Beijing 100871, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Peking
   University; University of Texas System; University of Texas at San
   Antonio (UTSA)
RP Wang, JQ (corresponding author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
EM jqwang@nlpr.ia.ac.cn; bwang@nlpr.ia.ac.cn; lingyu@pku.edu.cn;
   qitian@cs.utsa.edu; luhq@nlpr.ia.ac.cn
FU National Natural Science Foundation of China [60905008, 60833006,
   61070104, 90920303]; National Basic Research Program (973) of China
   [2010CB327905]
FX The research is supported by National Natural Science Foundation of
   China (Grant Nos.: 60905008, 60833006, 61070104, 90920303), and National
   Basic Research Program (973) of China under Contract No. 2010CB327905.
CR [Anonymous], P ICDM WORKSH INT MU
   [Anonymous], P NIPS 08
   [Anonymous], P ACM MM 06
   [Anonymous], INTERACTIVE MEDIA NE
   [Anonymous], P ICIMCS 10
   [Anonymous], D91 SECURESCM
   [Anonymous], INTERNET OVERTAKES T
   [Anonymous], P VIS REC CHALL WORK
   [Anonymous], EURASIP J IMAGE VIDE
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berg AC, 2001, PROC CVPR IEEE, P607
   Bo Wang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3252, DOI 10.1109/ICPR.2010.795
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Chang CH, 2010, J VIS COMMUN IMAGE R, V21, P595, DOI 10.1016/j.jvcir.2010.03.006
   Chen Yifan, 2008, WSDM, P251
   Haibin Ling, 2007, 2007 11th IEEE International Conference on Computer Vision
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li YN, 2010, IEEE T MULTIMEDIA, V12, P814, DOI 10.1109/TMM.2010.2066960
   Liu HY, 2009, IEEE IMAGE PROC, P3105, DOI 10.1109/ICIP.2009.5414457
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mei T., 2008, P 16 ACM INT C MULT, P439, DOI [https://doi.org/10.1145/1459359.1459418, DOI 10.1145/1459359.1459418]
   Mei Tao., 2007, Proceedings of the 15th International Conference on Multimedia, P1075
   SHECHTMAN E., 2007, IEEE C COMPUTER VISI
   Wang JQ, 2009, IEEE INT CON MULTI, P274, DOI 10.1109/ICME.2009.5202488
   Wang JQ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1161, DOI 10.1109/ICME.2008.4607646
   Wang X., 2009, Proc. 3rd international Workshop on Data Mining and Audience Intelligence for Advertising, P18
   Zhongming MA, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1198296.1198301
NR 28
TC 6
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 799
EP 820
DI 10.1007/s11042-011-0866-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900011
DA 2024-07-18
ER

PT J
AU Xu, M
   Wang, JQ
   He, XJ
   Jin, JS
   Luo, SH
   Lu, HQ
AF Xu, Min
   Wang, Jinqiao
   He, Xiangjian
   Jin, Jesse S.
   Luo, Suhuai
   Lu, Hanqing
TI A three-level framework for affective content analysis and its case
   studies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective content analysis; Mid-level representation; Multiple modality
AB Emotional factors directly reflect audiences' attention, evaluation and memory. Recently, video affective content analysis attracts more and more research efforts. Most of the existing methods map low-level affective features directly to emotions by applying machine learning. Compared to human perception process, there is actually a gap between low-level features and high-level human perception of emotion. In order to bridge the gap, we propose a three-level affective content analysis framework by introducing mid-level representation to indicate dialog, audio emotional events (e. g., horror sounds and laughters) and textual concepts (e.g., informative keywords). Mid-level representation is obtained from machine learning on low-level features and used to infer high-level affective content. We further apply the proposed framework and focus on a number of case studies. Audio emotional event, dialog and subtitle are studied to assist affective content detection in different video domains/genres. Multiple modalities are considered for affective analysis, since different modality has its own merit to evoke emotions. Experimental results shows the proposed framework is effective and efficient for affective content analysis. Audio emotional event, dialog and subtitle are promising mid-level representations.
C1 [Xu, Min; He, Xiangjian] Univ Technol Sydney, Ctr Innovat IT Serv & Applicat, Sydney, NSW 2007, Australia.
   [Xu, Min; Wang, Jinqiao; Lu, Hanqing] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   [Jin, Jesse S.; Luo, Suhuai] Univ Newcastle, Sch Design Commun & IT, Callaghan, NSW 2308, Australia.
C3 University of Technology Sydney; Chinese Academy of Sciences; Institute
   of Automation, CAS; University of Newcastle
RP Xu, M (corresponding author), Univ Technol Sydney, Ctr Innovat IT Serv & Applicat, Sydney, NSW 2007, Australia.
EM min.xu25@gmail.com; jinqiao@nlpr.ia.ac.cn; xiangjian.he@uts.edu.au;
   jesse.jin@newcastle.edu.au; suhuai.luo@newcastle.edu.au;
   luhq@nlpr.ia.ac.cn
RI He, Xiangjian/CAA-1461-2022
OI He, Xiangjian/0000-0001-8962-540X; Xu, Min/0000-0001-9581-8849; Luo,
   Suhuai/0000-0002-6185-6035
FU National Natural Science Foundation of China [61003161, 60905008]; UTS
   ECR Grant
FX This research was supported by National Natural Science Foundation of
   China No. 61003161, No. 60905008 and UTS ECR Grant.
CR [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 2001, P 9 ACM INT C MULT
   [Anonymous], 1999, PASSIONATE VIEWS FIL
   Arifin S., 2007, Proceedings of the 15th International Conference on Multimedia, P68
   Arifin S, 2006, IEEE IMAGE PROC, P433, DOI 10.1109/ICIP.2006.312450
   Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127
   Berry MW, 1999, SIAM REV, V41, P335, DOI 10.1137/S0036144598347035
   Ching Hau Chan, 2005, 13th Annual ACM International Conference on Multimedia, P427, DOI 10.1145/1101149.1101243
   Frantzidis CA, 2010, IEEE T INF TECHNOL B, V14, P309, DOI 10.1109/TITB.2009.2038481
   Gales M, 2006, ICASSP TUT
   Gruhne M, 2009, P 3 INT WORKSH LEARN, P91
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Jiang H, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1507, DOI 10.1109/ICME.2000.871053
   Jonghwa Kim, 2008, 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2008), P114, DOI 10.1109/MFI.2008.4648119
   Kang H.-B., 2003, Proceedings of the 11th ACM International Conference on Multimedia, P259
   Kovecses Z., 2003, METAPHOR EMOTION LAN
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Money AG, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823751
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Rasheed Z, 2005, IEEE T CIRC SYST VID, V15, P52, DOI 10.1109/TCSVT.2004.839993
   Sebe N, 2006, INT C PATT RECOG, P1136
   Smith Jef., 1998, SOUNDS COMMERCE MARK
   SOLEYMANI M, 2009, P INT C AFF COMP INT
   Soleymani M, 2008, IEEE INT SYM MULTIM, P228, DOI 10.1109/ISM.2008.14
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Xu M, 2004, LECT NOTES COMPUT SC, V3333, P566
   Xu M, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P189
   Xu M., 2003, PROCEEDINGS OF INTER, V2, P143
   Xu M, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352015
   Yu-Hao Chen, 2006, 2006 Digest of Technical Papers. International Conference on Consumer Electronics, P151, DOI 10.1109/ICCE.2006.1598355
   Zeng ZH, 2007, IEEE T MULTIMEDIA, V9, P424, DOI 10.1109/TMM.2006.886310
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
NR 33
TC 28
Z9 29
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 757
EP 779
DI 10.1007/s11042-012-1046-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900009
DA 2024-07-18
ER

PT J
AU Choupani, R
   Wong, S
   Tolun, M
AF Choupani, Roya
   Wong, Stephan
   Tolun, Mehmet
TI Multiple description coding for SNR scalable video transmission over
   unreliable networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable video coding; Multiple description coding; Multimedia
   transmission
ID SVC
AB Streaming multimedia data on best-effort networks such as the Internet requires measures against bandwidth fluctuations and frame loss. Multiple Description Coding (MDC) methods are used to overcome the jitter and delay problems arising from frame losses by making the transmitted data more error resilient. Meanwhile, varying characteristics of receiving devices require adaptation of video data. Data transmission in multiple descriptions provides the feasibility of receiving it partially and hence having a scalable and adaptive video. In this paper, a new method based on integrating MDC and signal-to-noise ratio (SNR) scalable video coding algorithms is proposed. Our method introduces a transform on data to permit transmitting them using independent descriptions. Our results indicate that on average 1.71dB reduction in terms of Y-PSNR occurs if only one description is received.
C1 [Choupani, Roya; Wong, Stephan] Delft Univ Technol, Dept Comp Engn, Delft, Netherlands.
   [Choupani, Roya] Cankaya Univ, Dept Comp Engn, Ankara, Turkey.
   [Tolun, Mehmet] TED Univ, Dept Comp Engn, Ankara, Turkey.
C3 Delft University of Technology; Cankaya University; Ted University
RP Choupani, R (corresponding author), Cankaya Univ, Dept Comp Engn, Ankara, Turkey.
EM roya@cankaya.edu.tr; J.S.S.M.Wong@tudelft.nl; mehmet.tolun@tedu.edu.tr
RI Tolun, Mehmet Resit/KCJ-5958-2024; Tolun, Mehmet Resit/AAX-2456-2021
OI Tolun, Mehmet Resit/0000-0002-8478-7220; Tolun, Mehmet
   Resit/0000-0002-8478-7220
CR Abanoz TB, 2009, SIGNAL PROCESS-IMAGE, V24, P691, DOI 10.1016/j.image.2009.07.003
   Akyol E, 2007, IEEE J-STSP, V1, P231, DOI 10.1109/JSTSP.2007.901527
   Andreopoulos Y, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P417
   Ardestani MR, 2011, SIGNAL PROCESS-IMAGE, V26, P143, DOI 10.1016/j.image.2011.01.003
   Choupani R, 2009, LECT NOTES COMPUT SC, V5657, P58, DOI 10.1007/978-3-642-03138-0_7
   Choupany R., 2011, Proceedings of the 2011 7th International Conference on Digital Content, Multimedia Technology and its Applications (IDCTA 2011), P5
   Conklin GJ, 2001, IEEE T CIRC SYST VID, V11, P269, DOI 10.1109/76.911155
   López-Fuentes FD, 2011, INT J AP MAT COM-POL, V21, P295, DOI 10.2478/v10006-011-0022-1
   Folli M, 2008, GTTI 08 SESS EL SEGN
   Franchi N, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P253
   GIROD B, 1987, IEEE J SEL AREA COMM, V5, P1140, DOI 10.1109/JSAC.1987.1146632
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Kim CS, 2001, IEEE T CIRC SYST VID, V11, P999, DOI 10.1109/76.946517
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Puri R., 1999, Conference Record of the Thirty-Third Asilomar Conference on Signals, Systems, and Computers (Cat. No.CH37020), P342, DOI 10.1109/ACSSC.1999.832349
   Reguant VD, 2008, P IEEE INT S CONS EL, P1
   Reibman AR, 2002, IEEE T CIRC SYST VID, V12, P193, DOI 10.1109/76.993440
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Tillo T, 2004, IEEE SIGNAL PROC LET, V11, P908, DOI 10.1109/LSP.2004.836949
   Tillo T, 2007, IEEE T IMAGE PROCESS, V16, P673, DOI 10.1109/TIP.2007.891152
   Venkataramani R, 2003, IEEE T INFORM THEORY, V49, P2106, DOI 10.1109/TIT.2003.815767
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   Xiang W, 2009, IEEE T CIRC SYST VID, V19, P1730, DOI 10.1109/TCSVT.2009.2022787
   Yang XG, 2000, IEEE T INFORM THEORY, V46, P2477, DOI 10.1109/18.887859
NR 29
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 843
EP 858
DI 10.1007/s11042-012-1150-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300013
OA hybrid
DA 2024-07-18
ER

PT J
AU Zou, KS
   Ip, WH
   Wu, CH
   Chen, ZQ
   Yung, KL
   Chan, CY
AF Zou, Kuan-Sheng
   Ip, Wai-Hung
   Wu, Chun-Ho
   Chen, Zeng-Qiang
   Yung, Kai-Leung
   Chan, Ching-Yuen
TI A novel 3D model retrieval approach using combined shape distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Shape distribution; Principal plane analysis;
   Combined shape distribution; Sequential quadratic programming
ID SIMILARITY SEARCH; CLASSIFICATION
AB With the rapid development of 3D digital shape information, content-based 3D model retrieval has become an important research field. 3D models are likely to be as prevalent as other multimedia data types in the future. There is a pressing need for effective content-based 3D model retrieval methods. In this paper, a novel combined shape distribution (CSD) descriptor is proposed for 3D model retrieval based on principal plane analysis and group integration. Firstly, based on principal plane analysis, the second principal plane is obtained by using sequential quadratic programming. Secondly, two novel 3D shape descriptors are proposed by introducing the plane normal vectors to other shape distributions. Thirdly, since the histogram of the proposed descriptors can be classified as belonging to one of three types: positive, negative, or crossed with each principal plane, further improvements to the descriptors are presented by integrating these three types of histograms. Finally, a CSD descriptor based on the synthesis of the above descriptors is proposed. Several retrieval performance measures and visual experimental results show that the new methods achieved good retrieval performance.
C1 [Zou, Kuan-Sheng; Ip, Wai-Hung; Wu, Chun-Ho; Yung, Kai-Leung; Chan, Ching-Yuen] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Kln, Hong Kong, Peoples R China.
   [Zou, Kuan-Sheng; Chen, Zeng-Qiang] Nankai Univ, Dept Automat, Tianjin 300071, Peoples R China.
C3 Hong Kong Polytechnic University; Nankai University
RP Zou, KS (corresponding author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Kln, Hong Kong, Peoples R China.
EM zoukuansheng@163.com; mfwhip@inet.polyu.edu.hk;
   jack.wu@connect.polyu.hk; chenzq@nankai.edu.cn;
   mfklyung@inet.polyu.edu.hk; mfcychan@inet.polyu.edu.hk
RI WU, Chun Ho/H-8815-2012; IP, W.H./J-2941-2013
OI WU, Chun Ho/0000-0003-1259-4048; IP, W.H./0000-0001-6609-0713; YUNG, Kai
   Leung/0000-0001-9091-6140; Ching Yuen, Chan/0000-0001-6145-0409
FU Department of Industrial and Systems Engineering of the Hong Kong
   Polytechnic University [G-YG44]; Natural Science Foundation of China
   [61174094, 60904064]; Specialized Research Fund for the Doctoral Program
   of Higher Education of China [20090031110029]
FX Our gratitude is extended to the research committee and the Department
   of Industrial and Systems Engineering of the Hong Kong Polytechnic
   University for support in this project (G-YG44). This work was supported
   in part by the Natural Science Foundation of China under Grants of
   61174094 and 60904064, the Specialized Research Fund for the Doctoral
   Program of Higher Education of China under Grant 20090031110029.
CR Akgül CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Atmosukarto I, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P334, DOI 10.1109/MMMC.2005.39
   Axenopoulos A, 2009, 30 INT C EUR 2009 WO
   Boggs P.T., 1995, Acta numerica, V4, P1, DOI [10.1017/S0962492900002518, DOI 10.1017/S0962492900002518]
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Bustos B, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P215, DOI 10.1109/TDPVT.2004.1335197
   Bustos B, 2007, IEEE COMPUT GRAPH, V27, P22, DOI 10.1109/MCG.2007.80
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Daras P, 2006, IEEE T MULTIMEDIA, V8, P101, DOI 10.1109/TMM.2005.861287
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P374, DOI 10.1109/TMM.2011.2176111
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Daras P, 2009, INT WORK CONTENT MUL, P115, DOI 10.1109/CBMI.2009.15
   DUTAGACI H, 2005, P 5 INT C 3D DIG IM
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2010, NEUROCOMPUTING, V73, P1900, DOI 10.1016/j.neucom.2009.11.050
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   Kuo CT, 2007, PATTERN RECOGN, V40, P742, DOI 10.1016/j.patcog.2006.06.006
   Ling H., 2006, CVPR, V1, P246, DOI DOI 10.1109/CVPR.2006.99
   Mademlis A, 2009, PATTERN RECOGN, V42, P2447, DOI 10.1016/j.patcog.2009.04.024
   Mahmoudi S, 2007, PATTERN RECOGN LETT, V28, P1705, DOI 10.1016/j.patrec.2007.04.012
   Ohbuchi R, 2006, P WSCG 2006 PLZEN CZ
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Ohbuchi R, 2005, INT J COMPUT APPL T, V23, P70, DOI 10.1504/IJCAT.2005.006466
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Reisert M, 2006, COMPUT GRAPH-UK, V30, P197, DOI 10.1016/j.cag.2006.01.025
   Ronneberger O, 2002, INT C PATT RECOG, P290, DOI 10.1109/ICPR.2002.1048297
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   SHIH JL, 2009, MULTIMED TOOLS APPL, V43, P45, DOI DOI 10.1007/S11042-008-0256-6
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Stavropoulos G, 2010, IEEE T MULTIMEDIA, V12, P692, DOI 10.1109/TMM.2010.2053023
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Vranic DV, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P963
   Vranic DV, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P757
   VRANIC DV, 2004, THESIS U LEIPZIG
   Zou KS, 2011, SCI RES ESSAYS, V6, P4330
NR 43
TC 22
Z9 26
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 799
EP 818
DI 10.1007/s11042-012-1130-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300011
DA 2024-07-18
ER

PT J
AU Lechervy, A
   Gosselin, PH
   Precioso, F
AF Lechervy, Alexis
   Gosselin, Philippe-Henri
   Precioso, Frederic
TI Boosted kernel for image categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image categorization; Kernel machines; Boosting
ID SIMILARITY
AB Recent machine learning techniques have demonstrated their capability for identifying image categories using image features. Among these techniques, Support Vector Machines (SVM) present good results for example in Pascal Voc challenge 2011 [8], particularly when they are associated with a kernel function [28, 35]. However, nowadays image categorization task is very challenging owing to the sizes of benchmark datasets and the number of categories to be classified. In such a context, lot of effort has to be put in the design of the kernel functions and underlying semantic features. In the following of the paper we call semantic features the features describing the (semantic) content of an image. In this paper, we propose a framework to learn an effective kernel function using the Boosting paradigm to linearly combine weak kernels. We then use a SVM with this kernel to categorize image databases. More specifically, this method create embedding functions to map images in a Hilbert space where they are better classified. Furthermore, our algorithm benefits from boosting process to learn this kernel with a complexity linear with the size of the training set. Experiments are carried out on popular benchmarks and databases to show the properties and behavior of the proposed method. On the PASCAL VOC2006 database, we compare our method to simple early fusion, and on the Oxford Flowers databases we show that our method outperforms the best Multiple Kernel Learning (MKL) techniques of the literature.
C1 [Lechervy, Alexis; Gosselin, Philippe-Henri] Univ Cergy Pontoise, ETIS, ENSEA, CNRS, F-95014 Cergy Pontoise, France.
   [Precioso, Frederic] UNS, CNRS, I3S, UMR7271, F-06903 Sophia Antipolis, France.
C3 CY Cergy Paris Universite; Centre National de la Recherche Scientifique
   (CNRS); Universite Cote d'Azur; Centre National de la Recherche
   Scientifique (CNRS)
RP Lechervy, A (corresponding author), Univ Cergy Pontoise, ETIS, ENSEA, CNRS, BP44, F-95014 Cergy Pontoise, France.
EM alexis.lechervy@ensea.fr; philippe-henri.gosselin@ensea.fr;
   precioso@polytech.unice.fr
FU DGA agency
FX Thanks to DGA agency for funding.
CR [Anonymous], ICML 09
   [Anonymous], THESIS DEA INFORM LO
   [Anonymous], 2010, PROC EUR C COMPUT VI
   [Anonymous], 1982, ESTIMATION DEPENDENC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2004, INT C MACH LEARN
   [Anonymous], 2011, PASCAL VISUAL OBJECT
   [Anonymous], 2008, P IND C COMP VIS GRA
   [Anonymous], INT C MACH LEARN
   Awais M, 2011, BRIT MACH VIS C, P601
   Cortes Corinna, 2010, INT C MACH LEARN
   Crammer K, 2001, ADV NEURAL INFORM PR, P537
   Cristianini N, 2002, ADV NEUR IN, V14, P367
   Davis JV, 2007, INT C MACH LEARN, V227
   Figueiras-Vidal A. R., 2012, EUR S ART NEUR NETW
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Gosselin PH, 2011, PATTERN RECOGN, V44, P2244, DOI 10.1016/j.patcog.2010.12.006
   Gosselin PH, 2006, PATTERN RECOGN, V39, P1839, DOI 10.1016/j.patcog.2006.04.017
   Gosselin PH, 2008, COMPUT VIS IMAGE UND, V110, P403, DOI 10.1016/j.cviu.2007.09.018
   Hazen TJ, 2010, INT CONF ACOUST SPEE, P5350, DOI 10.1109/ICASSP.2010.5494948
   Kawanabe M., 2009, ACM INT C IM VID RET
   Kloft M, 2011, J MACH LEARN RES, V12, P953
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Madzarov G, 2008, J INFORM, V33, P233
   Orabona F., 2011, International Conference on Machine Learning (ICML-11), P249, DOI DOI 10.5555/3104482.3104514[12]Z
   Picard D, 2012, EUR S ART NEUR NETW
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Scholkopf B., 2002, Encyclopedia of Biostatistics
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824
   Yu S, 2011, METHODS APPL BIOINFO, V345
NR 35
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 471
EP 490
DI 10.1007/s11042-012-1328-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, CG
   Kim, JG
   Lee, DH
AF Kim, Cheong Ghil
   Kim, Jeom Goo
   Lee, Do Hyeon
TI Optimizing image processing on multi-core CPUs with Intel parallel
   programming technologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-core; Streaming SIMD extension; Threading building block; Sobel
   operator; Sub-word parallelism; Task-level parallelism; Multimedia
ID EXTENSION
AB The rapid advance of computer hardware and popularity of multimedia applications enable multi-core processors with sub-word parallelism instructions to become a dominant market trend in desk-top PCs as well as high end mobile devices. This paper presents an efficient parallel implementation of 2D convolution algorithm demanding high performance computing power in multi-core desktop PCs. It is a representative computation intensive algorithm, in image and signal processing applications, accompanied by heavy memory access; on the other hand, their computational complexities are relatively low. The purpose of this study is to explore the effectiveness of exploiting the streaming SIMD (Single Instruction Multiple Data) extension (SSE) technology and TBB (Threading Building Block) run-time library in Intel multi-core processors. By doing so, we can take advantage of all the hardware features of multi-core processor concurrently for data-and task-level parallelism. For the performance evaluation, we implemented a 3x3 kernel based convolution algorithm using SSE2 and TBB with different combinations and compared their processing speeds. The experimental results show that both technologies have a significant effect on the performance and the processing speed can be greatly improved when using two technologies at the same time; for example, 6.2, 6.1, and 1.4 times speedup compared with the implementation of either of them are suggested for 256x256, 512x512, and 1024x1024 data sets, respectively.
C1 [Kim, Cheong Ghil; Kim, Jeom Goo] Namseoul Univ, Dept Comp Sci, Cheonan 331707, Choongnam, South Korea.
   [Lee, Do Hyeon] Namseoul Univ, IT Convergence Technol Res & Educ Ctr, Cheonan 331707, Choongnam, South Korea.
C3 Namseoul University; Namseoul University
RP Lee, DH (corresponding author), Namseoul Univ, IT Convergence Technol Res & Educ Ctr, 21 Maeju Ri, Cheonan 331707, Choongnam, South Korea.
EM cgkim@nsu.ac.kr; jgoo@nsu.ac.kr; dohyeon@gmail.com
FU Namseoul University
FX Funding for this paper was provided by Namseoul University.
CR Akhter S., 2006, MULTICORE PROGRAMMIN, V1st
   [Anonymous], 2003, Computer Architecture
   Baker CG, 2010, P 18 EUR INT C PAR D
   Bosi B, 1999, IEEE T VLSI SYST, V7, P299, DOI 10.1109/92.784091
   Chhugani J, 2008, PROC VLDB ENDOW, V1, P1313
   Conti G, 2008, LECT NOTES COMPUT SC, V5210, P1, DOI 10.1007/978-3-540-85933-8_1
   David M, 2009, DIGITAL SIGNAL PROCE
   Diefendorff K, 2000, IEEE MICRO, V20, P85, DOI 10.1109/40.848475
   Falcou J, 2006, PARALLEL COMPUT, V32, P604, DOI 10.1016/j.parco.2006.06.001
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hecht V., 1991, 1991 IEEE International Sympoisum on Circuits and Systems (Cat. No.91CH3006-4), P1897, DOI 10.1109/ISCAS.1991.176778
   Kayi A., 2007, IPDPS 07, P1
   Kim CG, 2004, IEICE T INF SYST, VE87D, P1766
   Kim W, 2011, IEEE SOFTWARE, V28, P23, DOI 10.1109/MS.2011.12
   Kirschenmann W, 2010, PARA 2010 STATE ART
   Kohn L, 1995, TECHNOLOGIES INFORM, P462
   Lee RB, 2002, SIGN PROC COMMUN SER, V13, P91
   Ma WC, 2002, P 3 IEEE PAC RIM C M
   Nicole R, 2001, DESKTOP PERFORMANCE
   Oberman S, 1999, IEEE MICRO, V19, P37, DOI 10.1109/40.755466
   Paxson Vern, 2007, 2007 IEEE Sarnoff Symposium, P1, DOI 10.1109/SARNOF.2007.4567341
   Peleg A, 1996, IEEE MICRO, V16, P42, DOI 10.1109/40.526924
   Perri S, 2005, MICROPROCESS MICROSY, V29, P381, DOI 10.1016/j.micpro.2004.10.004
   Reinders James, 2007, Intel threading building blocks-outfitting C++ for multi-core processor parallelism
   Robison A, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P598
NR 25
TC 19
Z9 23
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 237
EP 251
DI 10.1007/s11042-011-0906-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400003
DA 2024-07-18
ER

PT J
AU Lim, S
   Lee, D
   Shin, BS
AF Lim, Sukhyun
   Lee, Daesung
   Shin, Byeong-Seok
TI An image division approach for volume ray casting in multi-threading
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Volume visualization; Volume ray casting; Space leaping; Parallel
   rendering
AB For an efficient parallel volume ray casting suitable for recent multi-core CPUs, we propose an image-ordered approach by using a cost function to allocate loaded tasks impartially per each processing node. At the first frame, we divide an image space evenly, and we compute a cost function. By applying the frame coherence property, we divide the image space unevenly using the computed previous cost function since the next frame. Conventional image-ordered parallel approaches have focused on dividing and compositing volume datasets. However, the divisions and accumulations are negligible for recent multi-core CPUs because they are performed inside one physical CPU. As a result, we can reduce the rendering time without deteriorating the image quality by applying a cost function reflecting on all time-consuming steps of the volume ray casting.
C1 [Lim, Sukhyun] ETRI, Knowledge E Learning Team, Taejon, South Korea.
   [Lee, Daesung] Kyonggi Univ, Ind Secur Dept, Suwon, Kyonggi Do, South Korea.
   [Shin, Byeong-Seok] Inha Univ, Dept Comp Engn, Media Lab, Inchon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Kyonggi University; Inha University
RP Shin, BS (corresponding author), Inha Univ, Dept Comp Engn, Media Lab, 253 Yonghyun Dong, Inchon, South Korea.
EM cgwizard@hotmail.com; xdilemma@naver.com; bsshin@inha.ac.kr
RI Lee, Daesung/P-7946-2018
OI Lee, Daesung/0000-0002-2435-6867
FU INHA UNIVERSITY; National Research Foundation of Korea(NRF); Korea
   government(MEST) [2011-0015779]
FX This work was supported by INHA UNIVERSITY Research Grant.; This work
   was supported by the National Research Foundation of Korea(NRF) grant
   funded by the Korea government(MEST) (2011-0015779).
CR Challinger J., 1993, Proceedings. 1993 Parallel Rendering Symposium (IEEE Cat. No.93TH0592-6), P81, DOI 10.1109/PRS.1993.586091
   Corrie B., 1993, Proceedings. 1993 Parallel Rendering Symposium (IEEE Cat. No.93TH0592-6), P23, DOI 10.1109/PRS.1993.586081
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Engel K, 2006, Real-Time Volume Graphics
   Grimm S, 2004, IEEE SYMPOSIUM ON VOLUME VISUALIZATION AND GRAPHICS 2004, PROCEEDINGS, P1
   Grimm S, 2004, COMPUT GRAPH-UK, V28, P719, DOI 10.1016/j.cag.2004.06.010
   Hadwiger M, 2005, COMPUT GRAPH FORUM, V24, P303, DOI 10.1111/j.1467-8659.2005.00855.x
   Hsu W, 1993, P PAR REND S, P93
   Kaufman Arie., 1994, Scientific Visualization, Advances and Challenges
   Kwan-Liu Ma, 1995, 1995 Parallel Rendering Symposium (PRS 95) (IEEE Cat. No. 95TB8134), P23
   Law A, 1996, PROC GRAPH INTERF, P70
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Lim S, 2005, IEICE T INF SYST, VE88D, P2864, DOI 10.1093/ietisy/e88-d.12.2864
   Lim S, 2004, LECT NOTES ENG COMPU, V4487, P505
   Lim S, 2007, IEICE T INF SYST, V90, P117
   Lim S, 2008, VISUAL COMPUT, V24, P229, DOI 10.1007/s00371-007-0203-y
   Montani C., 1992, PROC ACM WORKSHOP VO, P9
   Nieh J., 1992, P 1992 WORKSHOP VOLU, P17
   Park JS, 2005, IEEE T MED IMAGING, V24, P352, DOI 10.1109/TMI.2004.842454
   Parker S, 1998, VISUALIZATION '98, PROCEEDINGS, P233, DOI 10.1109/VISUAL.1998.745713
   Whitman S., 1993, Proceedings. 1993 Parallel Rendering Symposium (IEEE Cat. No.93TH0592-6), P27, DOI 10.1109/PRS.1993.586082
NR 22
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 211
EP 223
DI 10.1007/s11042-011-0879-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400001
DA 2024-07-18
ER

PT J
AU Park, SB
   Lee, JD
   You, E
   Lee, D
AF Park, Seung-Bo
   Lee, Jae-Dong
   You, Eunsoon
   Lee, Daesung
TI Movie browsing system based on character and emotion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character; Emotion; Browsing system; Scene; Similarity
AB A variety of research is in progress to detect wanted scenes from videos. A method of detecting scenes wanted by a user through scene rearrangement based on calculated visual similarity is limited in that such a method does not reflect elements along the storyline through which a user remembers a movie. A movie's story is built up by characters, and such build-up is closely related with emotions of characters in a film. A movie browsing system based on storyline is executable by applying characters and those characters' emotions. Thus, methods of extracting key characters in each scene and of clustering scenes through extraction of emotion vectors from dialogues in each scene are hereby suggested. This paper also proposes to develop a movie browsing method and a system based on emotions of characters.
C1 [Park, Seung-Bo] Kyung Hee Univ, Seoul, South Korea.
   [Lee, Jae-Dong; You, Eunsoon] Dankook Univ, Yongin, Gyeonggi Do, South Korea.
   [Lee, Daesung] Catholic Univ Pusan, Pusan, South Korea.
C3 Kyung Hee University; Dankook University; Catholic University Pusan
RP Lee, D (corresponding author), Catholic Univ Pusan, Pusan, South Korea.
EM molaal@naver.com; letsdoit@dankook.ac.kr; eunsoony@hotmail.com;
   dslee@cup.ac.kr
RI Lee, Daesung/P-7946-2018; You, Eun-Soon/E-7686-2015
OI Lee, Daesung/0000-0002-2435-6867; You, Eun-Soon/0000-0001-8827-1232
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science and Technology
   [2012R1A1A2002839]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2012R1A1A2002839).
CR Allen R. B., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P11, DOI 10.1145/336597.336615
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Chen L, 2008, INTERACT COMPUT, V20, P17, DOI 10.1016/j.intcom.2007.06.003
   Ekman P., 2000, Handbook of cognition and emotion pp, P45, DOI 10.1002/0470013494.ch3
   Park HJ, 2010, IEEE MTT S INT MICR, P49, DOI 10.1109/MWSYM.2010.5518084
   Park S-B, 2011, LECT NOTES ELECT ENG, P507
   Park SB, 2011, LECT NOTES ARTIF INT, V6592, P130, DOI 10.1007/978-3-642-20042-7_14
   Park SB, 2011, INFORMATION-TOKYO, V14, P3843
   Park SB, 2012, MULTIMED TOOLS APPL, V59, P601, DOI 10.1007/s11042-011-0725-1
   Salway A., 2003, P 11 ACM INT C MULTI, P299
   Yeung M, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P296, DOI 10.1109/MMCS.1996.534991
   Yi HR, 2006, INFORM SYST, V31, P638, DOI 10.1016/j.is.2005.12.005
NR 12
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 391
EP 400
DI 10.1007/s11042-012-1320-9
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400013
DA 2024-07-18
ER

PT J
AU Hatim, A
   Belkouch, S
   El Aakif, M
   Hassani, MM
   Chabini, N
AF Hatim, Anas
   Belkouch, Said
   El Aakif, Mohamed
   Hassani, Moha M'rabet
   Chabini, Noureddine
TI Design optimization of the quantization and a pipelined 2D-DCT for
   real-time applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discret cosine transform; JPEG compression; FPGA; Optimisation; Video
   compression
ID DCT; ARCHITECTURE; REALIZATION; ALGORITHM; PARALLEL
AB The Discrete Cosine Transform (DCT) is one of the most widely used techniques for image compression. Several algorithms are proposed to implement the DCT-2D. The scaled SDCT algorithm is an optimization of the DCT-1D, which consists in gathering all the multiplications at the end. In this paper, in addition to the hardware implementation on an FPGA, an extended optimization has been performed by merging the multiplications in the quantization block without having an impact on the image quality. A simplified quantization has been performed also to keep higher the performances of the all chain. Tests using MATLAB environment have shown that our proposed approach produces images with nearly the same quality of the ones obtained using the JPEG standard. FPGA-based implementations of this proposed approach is presented and compared to other state of the art techniques. The target is an an Altera Cyclone II FPGA using the Quartus synthesis tool. Results show that our approach outperforms the other ones in terms of processing-speed, used resources and power consumption. A comparison has been done between this architecture and a distributed arithmetic based architecture.
C1 [Hatim, Anas; Belkouch, Said; El Aakif, Mohamed] Univ Cadi Ayyad, Natl Sch Appl Sci, Marrakech, Morocco.
   [Hassani, Moha M'rabet] Univ Cadi Ayyad, Technol Elect & Instrumentat Lab, Fac Sci & Tech, Marrakech, Morocco.
   [Chabini, Noureddine] Royal Mil Coll Canada, Dept Elect & Comp Engn, Kingston, ON, Canada.
C3 Cadi Ayyad University of Marrakech; Cadi Ayyad University of Marrakech;
   Royal Military College - Canada
RP Hatim, A (corresponding author), Univ Cadi Ayyad, Natl Sch Appl Sci, PB 575,Av Abdelkarim Khattabi, Marrakech, Morocco.
EM hatim.anas@hotmail.com; belkouch@ensa.ac.ma; elaakif@gmail.com;
   hassani@ucam.ac.ma; Noureddine.Chabini@rmc.ca
OI Hatim, Anas/0000-0002-3540-8036
CR Agostini LV, 2001, 14TH SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN, PROCEEDINGS, P226, DOI 10.1109/SBCCI.2001.953032
   Andraka R., 1998, FPGA'98. ACM/SIGDA International Symposium on Field Programmable Gate Arrays, P191, DOI 10.1145/275107.275139
   [Anonymous], 2009, 2009 INT C MICR ICM
   [Anonymous], 2010, P 2010 INT S INFORM
   Arai Y., 1988, Transactions of the Institute of Electronics, Information and Communication Engineers E, VE71, P1095
   Belkouch S, 2010, P 5 INT S I V COMM M, P1, DOI 10.1109/ISVC.2010.5656248
   Chen J, 1998, IEEE T CIRCUITS-II, V45, P653, DOI 10.1109/82.673651
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Chiu CT, 1992, IEEE T CIRC SYST VID, V2, P25, DOI 10.1109/76.134369
   El Aakif M., 2011, 2011 Faible Tension Faible Consommation (FTFC 2011) [2011 Low Voltage, Low Power Consumption], P63, DOI 10.1109/FTFC.2011.5948920
   FEIG E, 1992, IEEE T INFORM THEORY, V38, P1387, DOI 10.1109/18.144722
   Haggag MN, 2010, IEEE IMAGE PROC, P3769, DOI 10.1109/ICIP.2010.5653484
   Huang J, 2009, ACM T EMBED COMPUT S, V9, DOI 10.1145/1596532.1596541
   Ismail Y, 2010, IEEE IMAGE PROC, P1249, DOI 10.1109/ICIP.2010.5652335
   Kassem A, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS, P320, DOI 10.1109/ACTEA.2009.5227881
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   LINZER E, 1991, INT CONF ACOUST SPEE, P2201, DOI 10.1109/ICASSP.1991.150851
   Loeffer C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P988, DOI 10.1109/ICASSP.1989.266596
   PELED A, 1974, IEEE T ACOUST SPEECH, VAS22, P456, DOI 10.1109/TASSP.1974.1162619
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Tumeo A, 2007, IEEE COMP SOC ANN, P331, DOI 10.1109/ISVLSI.2007.13
   Wahid KA, 2007, IEEE T CIRCUITS-II, V54, P700, DOI 10.1109/TCSII.2007.898891
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WANG ZD, 1984, IEEE T ACOUST SPEECH, V32, P803
   WHITE SA, 1989, IEEE ASSP MAG, V6, P5
   Wu ZG, 2009, IEEE T CONSUM ELECTR, V55, P685, DOI 10.1109/TCE.2009.5174440
   Xiuhua J, 2011, MULTIMED TOOLS APPL, V63, P1
NR 28
TC 3
Z9 3
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 667
EP 685
DI 10.1007/s11042-012-1043-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900008
DA 2024-07-18
ER

PT J
AU Kazmi, S
   Ikram, N
AF Kazmi, Shagufta
   Ikram, Nassar
TI Chaos based key expansion function for block ciphers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Binary sequences; Chaotic maps; Key Expansion Function;
   Correlation; Weak keys
ID EXTERNAL KEY; CRYPTOGRAPHY; SYSTEMS; MAPS
AB The Key Expansion Function is a vital constituent component of any block cipher. Many of Key Expansion Functions generate subkeys through the algorithms which are based on Feistel or Substitution Permutation Network (SPN) structures against which cryptanalytic methods have been well researched. In this very paper, an efficient method for generating subkeys based on chaotic maps has been suggested. The phenomenon behind the proposed Key Expansion Function is the mixing property of Tent Map. Using chaotic binary sequences, the proposed Key Expansion Function satisfies the specific statistical and cryptographic properties of chaotic generators. A new Bit Extraction Technique based on IEEE-754 Floating-point Standard (binary32) is used to extract the bits of subkeys from the chaotic binary sequences. The generated subkeys are then analyzed. The results show that the given Chaos-based Key Expansion Function is well protected and fully strengthened in all respects.
C1 [Kazmi, Shagufta; Ikram, Nassar] Natl Univ Sci & Technol, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Kazmi, S (corresponding author), Natl Univ Sci & Technol, Islamabad, Pakistan.
EM shaguftakazmi_2007@hotmail.com; dr_nassar_ikram@yahoo.com
CR Alvarez G, 2003, PHYS LETT A, V319, P334, DOI 10.1016/j.physleta.2003.10.044
   Alvarez G., 1999, Proceedings IEEE 33rd Annual 1999 International Carnahan Conference on Security Technology (Cat. No.99CH36303), P332, DOI 10.1109/CCST.1999.797933
   [Anonymous], 1992, INT J BIFURCATION CH, DOI DOI 10.1142/S0218127492000823
   Cristea B, 2008, SYSTEMS MAN CYBERN A
   Faraoun K, 2010, INT ARAB J INFORM TE, V7
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   HABUTSU T, 1991, P EUR 91, P127
   Halle KS, 1993, SPREAD SPECTRUM COMM, P379
   Halle KS, 1993, CHUAS CIRCUIT PARADI
   Hasler M, 1998, INT J BIFURCAT CHAOS, V8, P647, DOI 10.1142/S0218127498000450
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Jing Q, 2007, P 8 ACIS INT C SOFTW, V03, P522
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kristina K, 2005, INT S NONL THEOR ITS
   Li CQ, 2008, CHAOS SOLITON FRACT, V37, P299, DOI 10.1016/j.chaos.2006.08.025
   Li S., 2003, THESIS XIAN JIAOTONG
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Mao Y, 2003, INT J BIFURC CHAOS
   Muhammad A, 2008, ETRI J, V30
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   PECORA LM, 1990, PHYS REV LETT, V64, P821, DOI 10.1103/PhysRevLett.64.821
   Ranjan B, 1999, 7 INT C ADV COMM COM
   Schmitz R, 2001, J FRANKLIN I, V338, P429, DOI 10.1016/S0016-0032(00)00087-9
   Silva CP, 2000, AEROSP CONF PROC, P279, DOI 10.1109/AERO.2000.879402
   Wei J, 2007, COMMUN NONLINEAR SCI, V12, P814, DOI 10.1016/j.cnsns.2005.06.001
   Yang T., 2004, Int. J. Comput. Cogn., P81
   Zhou H, 1997, IEEE T CIRCUITS-I, V44, P268, DOI 10.1109/81.557386
NR 29
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 267
EP 281
DI 10.1007/s11042-011-0767-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000008
DA 2024-07-18
ER

PT J
AU Mustaquim, MM
AF Mustaquim, Moyen Mohammad
TI Automatic speech recognition- an approach for designing inclusive games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design for all; Inclusive design; Universal design; Accessibility; Game
AB Computer games are now a part of our modern culture. However, certain categories of people are excluded from this form of entertainment and social interaction because they are unable to use the interface of the games. The reason for this can be deficits in motor control, vision or hearing. By using automatic speech recognition systems (ASR), voice driven commands can be used to control the game, which can thus open up the possibility for people with motor system difficulty to be included in game communities. This paper aims at find a standard way of using voice commands in games which uses a speech recognition system in the backend, and that can be universally applied for designing inclusive games. Present speech recognition systems however, do not support emotions, attitudes, tones etc. This is a drawback because such expressions can be vital for gaming. Taking multiple types of existing genres of games into account and analyzing their voice command requirements, a general ASRS module is proposed which can work as a common platform for designing inclusive games. A fuzzy logic controller proposed then is to enhance the system. The standard voice driven module can be based on algorithm or fuzzy controller which can be used to design software plug-ins or can be included in microchip. It then can be integrated with the game engines; creating the possibility of voice driven universal access for controlling games.
C1 Uppsala Univ, Dept Informat & Media, S-75120 Uppsala, Sweden.
C3 Uppsala University
RP Mustaquim, MM (corresponding author), Uppsala Univ, Dept Informat & Media, Ekonomikum Plan 3,Kyrkogardsg 10 Box 513, S-75120 Uppsala, Sweden.
EM moyen.mustaquim@im.uu.se
RI Mustaquim, Moyen M/C-9322-2014
CR Carbonell N, 2003, UNIVERSAL ACCESS INF, V2, P89
   Clarkson J, 2003, INCLUSIVE DESIGN DES, P88
   Crawford C., 1982, ART COMPUTER GAME DE
   Czaja Sara J., 2007, Universal Access in the Information Society, V5, P341, DOI 10.1007/s10209-006-0060-x
   Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X
   Eurostat, 2006, EUR INT US EU25 2005
   Goodman J., 2006, Gerontechnology, V4, P229
   Goodman-Deane J, 2009, UNIVERSAL ACCESS INF, V8, P1, DOI 10.1007/s10209-008-0125-0
   Hawthorn D, 2000, INTERACT COMPUT, V12, P507, DOI 10.1016/S0953-5438(99)00021-1
   Hinckley K, 2003, INPUT TECHNOLOGIES T
   Holzinger Andreas, 2008, Universal Access in the Information Society, V7, P195, DOI 10.1007/s10209-008-0120-5
   Langdon Patrick, 2007, Universal Access in the Information Society, V6, P117, DOI 10.1007/s10209-007-0080-1
   Neerincx MA, 2009, UNIVERSAL ACCESS INF, V8, P109, DOI 10.1007/s10209-008-0136-x
   Picard R. W., 1997, AFFECTIVE COMPUTING
   van Leeuwen DA, 2006, COMPUT SPEECH LANG, V20, P128, DOI 10.1016/j.csl.2005.07.001
   Van Wijngaarden S.J., 2001, P EUR 2001 AALB SEPT, P1675
   YING HO, 1993, AUTOMATICA, V29, P1579, DOI 10.1016/0005-1098(93)90025-O
NR 17
TC 8
Z9 10
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 1
BP 131
EP 146
DI 10.1007/s11042-011-0918-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 163DZ
UT WOS:000320317200008
DA 2024-07-18
ER

PT J
AU Vatavu, RD
AF Vatavu, Radu-Daniel
TI On designing interactivity awareness for ambient displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient displays; Interaction; Ambient media; Public displays; Ambient
   content; Interactivity awareness; Affordances; Study; Perception
ID NATURAL INTERACTION; MEDIA
AB In the not-so-distant world in which ambient displays will likely become prevalent, immediate awareness of their interaction affordances to passerbies will be decisive for their usability. However, how to address awareness at user perception level represents a challenge for which little progress has been made so far in contrast with considerable advances in designing interaction techniques for such displays. Even though many interactive ambient displays exist with properly designed interfaces, people may not always be aware of their interactivity. This work addresses the problem of interactivity awareness by focusing on two important questions: How can people tell whether a public display is interactive or not? and, assuming interactivity, How can people tell what the interface is? A study was conducted in order to investigate factors potentially related to perceived interactivity. Results show that people's evaluations are correct in most cases but they also tend to form incorrect perceptions in many other situations. We found that location, installation, reachability, and displayed content are factors that can influence people's perceptions. Our findings are complemented with a discussion of techniques that can be used in the practice of designing for interactivity awareness.
C1 Univ Stefan Cel Mare Suceava, Suceava 720229, Romania.
C3 Stefan cel Mare University of Suceava
RP Vatavu, RD (corresponding author), Univ Stefan Cel Mare Suceava, Str Univ 13, Suceava 720229, Romania.
EM vatavu@eed.usv.ro
RI Vatavu, Radu-Daniel/AAA-3282-2022; Vatavu, Radu-Daniel/F-1820-2017
OI Vatavu, Radu-Daniel/0000-0002-7631-6445
FU Progress and development through post-doctoral research and innovation
   in engineering and applied sciences- PRiDE [POSDRU/89/1.5/S/57083];
   European Social Fund through Sectorial Operational Program Human
   Resources
FX This paper was supported by the project "Progress and development
   through post-doctoral research and innovation in engineering and applied
   sciences- PRiDE - Contract no. POSDRU/89/1.5/S/57083", project co-funded
   from European Social Fund through Sectorial Operational Program Human
   Resources 2007-2013.
CR Agamanolis S, 2002, WORKSH PUBL COMM SIT
   [Anonymous], 2004, P ACM S US INT SOFTW
   [Anonymous], 2008, Being Human: Human-Computer Interaction in the year 2020
   [Anonymous], 2012, REMOTEPAD IPHONE
   [Anonymous], 1994, UNDERSTANDING MEDIA
   [Anonymous], 2006, EVERYWARE DAWNING AG
   Ballagas R, 2006, IEEE PERVAS COMPUT, V5, P70, DOI 10.1109/MPRV.2006.18
   Ballagas R, 2004, P UB DISPL ENV UB 20
   Ballagas R., 2005, CHI 05 CHI 05 EXTEND, P1200
   Baraldi S, 2008, MULTIMED TOOLS APPL, V38, P385, DOI 10.1007/s11042-007-0195-7
   Block F, 2004, LECT NOTES COMPUT SC, V3295, P207
   Boring S., 2009, P 21 ANN C AUSTR COM, V411, P161, DOI 10.1145/1738826.1738853
   Brignull Harry, 2003, Proc. Interact, V53, P17
   Campbell S., 2007, INT J COMMUN-US, V1, P738
   Dachselt R., 2009, CHI EA 09 P 27 INT C, P3253, DOI DOI 10.1145/1520340.1520467
   Dovgan E, 2011, ZDR VESTN, V80, P824
   Echtler F, 2009, PERS UBIQUIT COMPUT, V13, P609, DOI 10.1007/s00779-009-0246-3
   Fogarty J., 2005, ACM Transactions on Computer-Human Interaction, V12, P119, DOI 10.1145/1057237.1057243
   Gibbs WW, 2005, SCI AM, V292, P54, DOI 10.1038/scientificamerican0105-54
   Gustafson Sean, 2010, P 23ND ANN ACM S USE, P3, DOI DOI 10.1145/1866029.1866033
   Hinckley K., 2000, UIST. Proceedings of the 13th Annual ACM Symposium on User Interface Software and Technology, P91, DOI 10.1145/354401.354417
   Ishii H., 2008, Tangible bits: beyond pixels. In Proceedings of the 2nd international conference on Tangible and embedded interaction, pxv, DOI DOI 10.1145/1347390.1347392
   Jota R., 2010, Graphics Interface, DOI [DOI 10.11575/PRISM/30630, 10.5555/1839214.18392612,3, DOI 10.5555/1839214.18392612,3]
   Ju W, 2008, DES ISSUES, V24, P72, DOI 10.1162/desi.2008.24.3.72
   Kray C, 2008, P WORKSH DES EV MOB
   Lantz Ed, 2007, P 2007 WORKSH EM DIS, DOI [10.1145/1278240.1278241, DOI 10.1145/1278240.1278241]
   Lee JC, 2008, IEEE PERVAS COMPUT, V7, P39, DOI 10.1109/MPRV.2008.53
   LEPINSKI J, 2011, P 5 INT C TANG EMB E, P285, DOI DOI 10.1145/1935701.1935765
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P337, DOI 10.1007/s11042-009-0282-z
   Mistry P., 2009, P CHI 09 EXTENDED AB, P4111, DOI [DOI 10.1145/1520340.1520626, 10.1145/1520340.1520626]
   Miyaoku K., 2004, Proc. UIST, P147, DOI DOI 10.1145/1029632.1029657
   Myers B. A., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P285, DOI 10.1145/289444.289503
   Patel S.N., 2004, Proceedings of the Symposium on User Interface Software and Technology, P157, DOI [10.1145/1029632.1029658, DOI 10.1145/1029632.1029658]
   Patel SN, 2003, LECT NOTES COMPUT SC, V2864, P200
   Peiris Roshan Lalintha., 2009, ACM SIGGRAPH 2009 Emerging Technologies, P1, DOI 10.1145/1597956.1597957
   Peltonen P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1285
   Petrescu S, 2011, P 18 INT C CONTR SYS
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P399, DOI 10.1007/s11042-011-0917-8
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Popovici DM, 2008, PROC INT C VIRTUAL L, P307
   Rakkolainen IsmoK., 2007, ACE '07, P95
   Rico J, 2009, P MOBILEHCI 09
   Rico J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P887
   Saffer D, 2009, DESIGNIGN GESTURAL I
   Shoemaker G, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P53
   Silfverberg M., 2001, P GRAPHICS INTERFACE, P119, DOI DOI 10.5555/780986.781001
   Sippl A, 2010, LECT NOTES COMPUT SC, V6439, P167, DOI 10.1007/978-3-642-16917-5_17
   Song Y, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133371
   Streitz N., 2003, P HCI INT
   Vatavu RD, 2012, J AMB INTEL SMART EN, V4, P79, DOI 10.3233/AIS-2012-0137
   Vatavu RD, 2009, STUD COMPUT INTELL, V231, P145
   Vatavu RD, 2012, MULTIMED TOOLS APPL, V59, P113, DOI 10.1007/s11042-010-0698-5
   Vatavu RD, 2011, PRESENCE BUBBLES SUP, DOI [10.1007/s11042-010-0674-0, DOI 10.1007/S11042-010-0674-0]
   Vogel D., 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   Wang JJ, 2006, NSREC: 2006 IEEE RADIATION EFFECTS DATA WORKSHOP, WORKSHOP RECORD, P101
   Wilson Andrew D., 2007, Proceedings Graphics Interface 2007, P119, DOI 10.1145/1268517.1268539
NR 56
TC 5
Z9 6
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 1
BP 59
EP 80
DI 10.1007/s11042-012-1140-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 163DZ
UT WOS:000320317200004
DA 2024-07-18
ER

PT J
AU El Hamdouni, N
   Adib, A
   Larbi, SD
   Turki, M
AF El Hamdouni, Nawal
   Adib, Abdellah
   Larbi, Sonia Djaziri
   Turki, Monia
TI A blind digital audio watermarking scheme based on EMD and UISA
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Perceptual audio watermarking; Empirical mode
   decomposition; Under-determined independent subspace analysis
ID SOURCE SEPARATION; SPECTRUM
AB In this paper, a new perceptual spread spectrum audio watermarking scheme is discussed. The watermark embedding process is performed in the Empirical Mode Decomposition (EMD) domain, and the hybrid watermark extraction process is based on the combination of EMD and ISA (Independent Subspace Analysis) techniques, followed by the generic detection system, i.e. inverse perceptual filter, predictor filter and correlation based detector. Since the EMD decomposes the audio signal into several oscillating components-the intrinsic mode functions (IMF)-the watermark information can be inserted in more than one IMF, using spread spectrum modulation, allowing hence the increase of the insertion capacity. The imperceptibility of the inserted data is ensured by the use of a psychoacoustical model. The blind extraction of the watermark signal, from the received watermarked audio, consists in the separation of the watermark from the IMFs of the received audio signal. The separation is achieved by a new proposed under-determined ISA method, here referred to as UISA. The proposed hybrid watermarking system was applied to the SQAM (Sound Quality Assessment Material) audio database (Available at http://sound.media.mit.edu/mpeg4/audio/sqam and proved to have efficient detection performances in terms of Bit Error Rate (BER) compared to a generic perceptual spread spectrum watermarking system. The perceptual quality of the watermarked audio was objectively assessed using the PEMO-Q (Tool for objective perceptual assessment of audio quality) algorithm. Also, using our technique, we can extract the different watermarks without using any information of original signal or the inserted watermark. Experimental results exhibit that the transparency and high robustness of the watermarked audio can be achieved simultaneously with a substantial increase of the amount of information transmitted. A reliability of 1.8 10(-4) (against 1.5 10(-2) for the generic system), for a bit rate of 400 bits/s, can be achieved when the channel is not disturbed.
C1 [El Hamdouni, Nawal] Lab Associated CNRST, LRIT, Fac Sci, Rabat, Morocco.
   [Adib, Abdellah] LIM II FSTM, Mohammadia 20650, Morocco.
   [Larbi, Sonia Djaziri; Turki, Monia] ENIT, U2S, Tunis, Tunisia.
C3 Mohammed V University in Rabat; Centre National de la Recherche
   Scientifique & Technologique (CNRST); Universite de Tunis-El-Manar;
   Ecole Nationale d'Ingenieurs de Tunis (ENIT)
RP El Hamdouni, N (corresponding author), Lab Associated CNRST, LRIT, Fac Sci, Av Ibn Battouta,BP 1014, Rabat, Morocco.
EM nawaldouni@gmail.com; adib@fstm.ac.ma; sonia.larbi@enit.rnu.tn;
   m.turki@enit.rnu.tn
RI ADIB, Abdellah/HTQ-2801-2023; Turki-Hadj Alouane, Monia/HLV-7462-2023
OI ADIB, Abdellah/0000-0002-0670-7221; Turki-Hadj Alouane,
   Monia/0000-0002-6375-0824
CR Adib A, 2005, SIGNAL PROCESS, V85, P1943, DOI 10.1016/j.sigpro.2005.04.004
   [Anonymous], 2003, PROC ICA
   Baras C, 2006, IEEE T AUDIO SPEECH, V14, P1772, DOI 10.1109/TASL.2006.879808
   Bas P, 2004, J3EA3, V3, P16
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Casey Michael A, 2000, ICMC, P154
   Flandrin P, 2010, ADV COMPLEX SYST, V13, P439, DOI 10.1142/S0219525910002554
   Frank I., 1994, Data analysis handbook
   Guerrero L, 2004, THESIS ECOLE DOCTORA
   Hamdouni NE, 2010, ISIVC 10
   Hamdouni NE, 2008, ISIVC SPAIN
   Hamdouni NE, 2010, ISCCSP 10 LIM CYPR
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Huber R, 2006, IEEE T AUDIO SPEECH, V14, P1902, DOI 10.1109/TASL.2006.883259
   Larbi S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P949
   Larbi SD, 2005, THESIS ECOLE NATL IN
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lienard J, 2001, GRETSI TOULOUSE FRAN, P473
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu YW, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P200
   Malik H, 2009, INFORM-J COMPUT INFO, V33, P49
   Parvaix M, 2010, IEEE T AUDIO SPEECH, V18, P1464, DOI 10.1109/TASL.2009.2035216
   Rilling G., 2003, Proc. IEEE-EURASIP Workshop on Nonlinear Signal and Image Processing
   Taoufiki M, 2010, DIGIT SIGNAL PROCESS, V20, P269, DOI 10.1016/j.dsp.2009.03.005
NR 28
TC 8
Z9 8
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 809
EP 829
DI 10.1007/s11042-012-0988-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600015
DA 2024-07-18
ER

PT J
AU Verborgh, R
   Steiner, T
   Van Deursen, D
   De Roo, J
   Van de Walle, R
   Vallés, JG
AF Verborgh, Ruben
   Steiner, Thomas
   Van Deursen, Davy
   De Roo, Jos
   Van de Walle, Rik
   Gabarro Valles, Joaquim
TI Capturing the functionality of Web services with functional descriptions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic Web; Service description; Service discovery
AB Many have left their footprints on the field of semantic RESTful Web service description. Albeit some of the propositions are even W3C Recommendations, none of the proposed standards could gain significant adoption with Web service providers. Some approaches were supposedly too complex and verbose, others were considered not RESTful, and some failed to reach a significant majority of API providers for a combination of the reasons above. While we neither have the silver bullet for universal Web service description, with this paper, we want to suggest a lightweight approach called RESTdesc. It expresses the semantics of Web services by pre- and postconditions in simple N3 rules, and integrates existing standards and conventions such as Link headers, HTTP OPTIONS, and URI templates for discovery and interaction. This approach keeps the complexity to a minimum, yet still enables service descriptions with full semantic expressiveness. A sample implementation on the topic of multimedia Web services verifies the effectiveness of our approach.
C1 [Verborgh, Ruben; Van Deursen, Davy; Van de Walle, Rik] Univ Ghent, ELIS Multimedia Lab, IBBT, B-9050 Ledeberg Ghent, Belgium.
   [Steiner, Thomas; Gabarro Valles, Joaquim] Univ Politecn Cataluna, Dept LSI, ES-08034 Barcelona, Spain.
   [De Roo, Jos] Agfa Healthcare, B-9000 Ghent, Belgium.
C3 Ghent University; Universitat Politecnica de Catalunya; Agfa-Gevaert
RP Verborgh, R (corresponding author), Univ Ghent, ELIS Multimedia Lab, IBBT, Gaston Crommenlaan 8 Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM ruben.verborgh@ugent.be; tsteiner@lsi.upc.edu; davy.vandeursen@ugent.be;
   jos.deroo@agfa.com; rik.vandewalle@ugent.be; gabarro@lsi.upc.edu
RI ; Verborgh, Ruben/P-6571-2014
OI Steiner, Thomas/0000-0001-7482-6129; Verborgh, Ruben/0000-0002-8596-222X
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research Flanders (FWO
   Flanders); European Union; European Commission [248296]; FORMALISM
   [TIN-2007-66523]; ALBCOM [SGR 2009-2015]
FX The research activities as described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), the Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT), the Fund for Scientific Research Flanders
   (FWO Flanders), and the European Union.; This work was partially
   supported by the European Commission under Grant No. 248296 FP7 I-SEARCH
   project. Joaquim Gabarro is partially supported by TIN-2007-66523
   (FORMALISM), and SGR 2009-2015 (ALBCOM).
CR Alarcon R, 2010, P 3 INT WORKSH LINK
   [Anonymous], 2010, MULTIMEDIA SYSTEMS
   Ballinger Keith., 2001, WEB SERVICES INSPECT
   BELLWOOD T, 2004, UDDI VERSION 3 0 2
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Berners-Lee T, 2008, THEOR PRACT LOG PROG, V8, P249, DOI 10.1017/S1471068407003213
   Brickley D., 2010, FOAF Vocabulary Specification 0.98
   Chinnici Roberto., 2007, Web services description language (wsdl) version 2.0 part 1: Core language
   CHRISTENSEN E, 2000, WEB SERVICES DESCRIP
   Clinton D, 2007, OPENSEARCH SPECIFICA
   Connolly D., 2011, W3C team submission
   De Roo J, 2012, EULER PROOF MECH
   Dean M., 2004, SWRL: a semantic web Rule Language combining OWL and RuleML
   Fielding R., 1999, Hypertext transfer protocol-http/1.1. Tech. rep
   Fielding R. T, 2002, ACM Transactions on Internet Technology (TOIT), V2, P115, DOI [DOI 10.1145/514183.514185, 10.1145/514183.514185]
   Gao S, 2008, W3C XML SCHEMA DEF 1
   Generereth MR, 1998, KNOWLEDGE INTERCHANG
   Gonzalez JL, 2011, J CONVERGENCE, V2, P79
   Gregorio J, 2010, URI TEMPLATE
   Gregorio J, 2007, DO WE NEED WADL
   Gudgin M., 2007, SOAP VERSION 1 2 1
   Hadley Marc., 2009, Web Application Description Language
   Klyne G, 2004, Resource description framework (RDF): Concepts and abstract syntax
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   Koch J, 2009, HTTP VOCABULARY RDF
   Kopecky J, 2007, IEEE INTERNET COMPUT, V11, P60, DOI 10.1109/MIC.2007.134
   Krill P., 2005, Microsoft, IBM, SAP discontinue UDDI registry effort
   Krummenacher R, 2010, LECT NOTES COMPUT SC, V6369, P68
   Lafon Y, 2009, TEAM COMMENT WEB APP
   Lindstrom N, 2011, COIN VOCABULARY
   Martin D, 2004, W3C MEMBER SUBMISSIO, V22
   McDermott D, 2002, LECT NOTES COMPUT SC, V2342, P250
   MCDERMOTT D, 2004, DRS SET CONVENTIONS
   McGuinness D. L., 2004, OWL WEB ONTOLOGY LAN, DOI DOI 10.2004-03
   Minar N, 2006, WHY SOAP SUCKS
   Peterson D, 2008, W3C XML SCHEMA DEF 2
   Pyshkin E, 2011, JOC, V1, P1
   Sathappan O. L., 2011, International Journal of Information Technology, Communications and Convergence, V1, P146, DOI 10.1504/IJITCC.2011.039282
   Seaborne A., 2008, SPARQL Query Language for RDF
   Steiner T, 2011, P 2 INT WORKSH RESTF
   Verborgh R, 2010, P 4 INT WORKSH SERV
   Verborgh R, 2012, MULTIMED TOOLS APPL, V61, P105, DOI 10.1007/s11042-010-0709-6
NR 42
TC 14
Z9 19
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 365
EP 387
DI 10.1007/s11042-012-1004-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200009
DA 2024-07-18
ER

PT J
AU Kim, SK
AF Kim, Soo-Kyun
TI Extraction of ridge and valley lines from unorganized points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ridges and Valleys; Feature Extraction; Curvature Extrema;
   Movingleastsquares
ID SURFACE; SYSTEM
AB Given an unstructured point set, we use an MLS (moving least-squares) approximation to estimate the local curvatures and their derivatives at a point by means of an approximating surface. Then, we compute neighbor information using a Delaunay tessellation. Ridge and valley points can then be detected as zero-crossings, and connected using curvature directions. We demonstrate our method on several large point-sampled models, rendered by point-splatting, on which the ridge and valley lines are rendered with line width determined from curvatures.
C1 Paichai Univ, Dept Game Engn, Taejon, South Korea.
C3 Pai Chai University
RP Kim, SK (corresponding author), Paichai Univ, Dept Game Engn, Taejon, South Korea.
EM kimsk@pcu.ac.kr
OI Kim, Soo Kyun/0000-0001-6071-8231
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   [Anonymous], 2001, P IMR 2001 NEWP BEAC
   Belyaev AG, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P530, DOI 10.1109/CGI.1998.694306
   DeCarlo D, 2007, P 5 INT S NONPH AN R
   Gopi M, 2000, COMPUT GRAPH FORUM, V19, pC467, DOI 10.1111/1467-8659.00439
   Hao W, 2010, P 9 ACM SIGGRAPH C V
   Judd T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239470
   Kim SK, 2004, 2004 AUSTRALIAN SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P87, DOI 10.1145/1012807.1012832
   Levin D, 2004, MATH VISUAL, P37
   Liu B, 2009, APPL MECH MATER, V16-19, P420, DOI 10.4028/www.scientific.net/AMM.16-19.420
   Ma KL, 1997, VISUALIZATION '97 - PROCEEDINGS, P285, DOI 10.1109/VISUAL.1997.663894
   Monga O., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P354, DOI 10.1109/CVPR.1992.223165
   Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768
   Ohtake Y, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P153
   Pauly M, 2003, COMPUT GRAPH FORUM, V22, P281, DOI 10.1111/1467-8659.00675
   Pennec X, 2000, BIOMED EN S, P499
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Stylianou G, 2004, GEOMETRIC MODELING S, P269
   THIRION JP, 1993, 2149 INRIA
   Tricoche X, 2008, IEEE T VIS COMPUT GR, V14, P1627, DOI 10.1109/TVCG.2008.148
   Zhang L, 2009, P ACM S INT 3D GRAPH
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
   Zwicker M, 2001, COMP GRAPH, P371, DOI 10.1145/383259.383300
NR 23
TC 20
Z9 27
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 265
EP 279
DI 10.1007/s11042-012-0999-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400017
DA 2024-07-18
ER

PT J
AU Agius, H
   Angelides, MC
   Zad, DD
AF Agius, Harry
   Angelides, Marios C.
   Zad, Damon Daylamani
TI Experimenting with tagging and context for collaborative MPEG-7 metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metadata; MPEG-7; Tagging; Annotation; Collaborative systems;
   Folksonomy; Experiment; Multimedia
ID SEMANTIC IMAGE ANNOTATION; VIDEO; EXTRACTION; QUALITY; SYSTEM
AB Whether unstructured or structured, tagging of multimedia resources is a laborious and time-consuming process when carried out in the context of a single individual. However, effort can be greatly reduced and the detail, quality and volume of metadata increased within the context of a web community. Despite this, little empirical research has been carried out to understand how users individually or collaboratively work with multimedia tagging tools, whether structured or unstructured. Consequently, we explore how to effectively achieve collaborative multimedia tagging through the results of an experiment that collected data from 51 users using both unstructured folksonomy (Flickr, YouTube and del.icio.us) and structured MPEG-7 tools (COSMOSIS). We contribute a detailed analysis of the use of the multimedia tagging tools used in the experiment and show the relationships between user behaviours, resultant outcomes of these behaviours, and subsequent implications for future collaborative multimedia MPEG-7 tagging tools.
C1 [Agius, Harry; Angelides, Marios C.; Zad, Damon Daylamani] Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Agius, H (corresponding author), Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
EM harryagius@acm.org; marios.angelides@brunel.ac.uk;
   damon.zad@brunel.ac.uk
RI Daylamani-Zad, Damon/JXM-8824-2024
OI Daylamani-Zad, Damon/0000-0001-7849-458X
FU UK Engineering and Physical Sciences Research Council (EPSRC)
   [EP/E034578/1]; EPSRC [EP/E034578/1] Funding Source: UKRI
FX This research was supported by the UK Engineering and Physical Sciences
   Research Council (EPSRC), grant no. EP/E034578/1.
CR Agius H., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1348, DOI 10.1145/1141277.1141591
   Agius H, 2007, MULTIMEDIA SYST, V13, P155, DOI 10.1007/s00530-007-0088-7
   Agius H, 2009, MULTIMED TOOLS APPL, V41, P375, DOI 10.1007/s11042-008-0238-8
   [Anonymous], ADAPTIVILY PERSONALI
   [Anonymous], 2010, P 19 INT C WORLD WID, DOI DOI 10.1145/1772690.1772748
   [Anonymous], 2010, P ACM INT C IM VID R
   [Anonymous], 2006, P INN INF TECHN, DOI DOI 10.1109/INNOVATIONS.2006.301927
   Aurnhammer M, 2006, LECT NOTES COMPUT SC, V4273, P58
   Begelman G, 2006, P WORKSH COLL WEB TA
   Blankinship E, 2007, P 6 INT C INT DES CH, P175
   Burt R. S., 2005, BROKERAGE CLOSURE IN
   Carneiro G, 2005, PROC CVPR IEEE, P163
   Celebi Erbug, 2005, 2nd European Workshop on the Integration of Knowledge, Semantics and Digital Media Technology (EWIMT 2005), P219, DOI 10.1049/ic.2005.0735
   Corbin J., 2008, QUAL RES, DOI DOI 10.4135/9781452230153.N10
   Dickerson J. A., 1993, IEEE Virtual Reality Annual International Symposium (Cat. No.93CH3336-5), P471, DOI 10.1109/VRAIS.1993.380742
   Ding GG, 2010, INFORM PROCESS LETT, V110, P692, DOI 10.1016/j.ipl.2010.05.027
   Edvardsen LFH, 2009, ACM-IEEE J CONF DIG, P29
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   Goulding C., 1998, Qualitative Marketing Research: An International Journal, V1, P50, DOI DOI 10.1108/13522759810197587
   Haslhofer B, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1667062.1667064
   ISO/IEC, 2005, 159385AMD2 ISOIEC
   ISO/IEC, 2004, 159385AMD2 ISOIEC
   ISO/IEC, 2003, 159385 ISOIEC
   Jung Y, 2008, P 41 ANN HAW INT C S
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kosko B., 1997, FUZZY ENG
   Ku W, 2006, IEEE INT SYM MULTIM, P341
   Kwon O, 2009, EXPERT SYST APPL, V36, P11957, DOI 10.1016/j.eswa.2009.03.070
   Lee SS, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P294
   Li QF, 2008, IEEE MULTIMEDIA, V15, P14, DOI 10.1109/MMUL.2008.54
   Li ZX, 2011, PATTERN RECOGN LETT, V32, P516, DOI 10.1016/j.patrec.2010.11.015
   Lu Y, 2008, PATTERN RECOGN, V41, P1159, DOI 10.1016/j.patcog.2007.07.015
   Maleewong Krissada, 2008, 2008 Fourth International Conference on Semantics, Knowledge and Grid (SKG), P64, DOI 10.1109/SKG.2008.80
   Matavire R., 2008, PROC ACM C S AFRICAN, P139, DOI DOI 10.1145/1456659.1456676
   Mayernik M.S., 2011, Proceedings of the 2011 iConference, Seattle, P417, DOI DOI 10.1145/1940761.1940818
   Mika P, 2007, J WEB SEMANT, V5, P5, DOI 10.1016/j.websem.2006.11.002
   Min HS, 2010, IEEE INT CON MULTI, P1364, DOI 10.1109/ICME.2010.5583219
   Mishra S., 2010, Proceedings of the 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology - Workshops (WI-IAT 2010), P257, DOI 10.1109/WI-IAT.2010.96
   Naaman M, 2008, IEEE MULTIMEDIA, V15, P34, DOI 10.1109/MMUL.2008.69
   Névéol A, 2011, J BIOMED INFORM, V44, P310, DOI 10.1016/j.jbi.2010.11.001
   Ohmukai I, 2005, P 4 INT SEM WEB C IS
   Ojokoh B, 2011, INFORM SCIENCES, V181, P1538, DOI 10.1016/j.ins.2011.01.014
   Otsuka I, 2005, IEEE T CONSUM ELECTR, V51, P112, DOI 10.1109/TCE.2005.1405707
   Pea R., 2006, Proceedings of the 7th international conference on Learning sciences, ICLS '06, P516
   Qiu JP, 2008, 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND INFORMATION TECHNOLOGY, PROCEEDINGS, P703, DOI 10.1109/MMIT.2008.59
   Rodriguez MA, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1462198.1462199
   Ryu Jeewoong., 2002, MULTIMEDIA'02: Proceedings of the tenth ACM international conference on Multimedia, P267
   Saathoff C, 2010, P 19 INT C WORLD WID, P831, DOI [10.1145/1772690.1772775, DOI 10.1145/1772690.1772775]
   Shin Y, 2010, IMAGE VISION COMPUT, V28, P526, DOI 10.1016/j.imavis.2009.08.009
   Smoliar S. W., 1994, IEEE Multimedia, V1, P62, DOI 10.1109/93.311653
   Tang L., 2008, ACM Transactions on Knowledge Discovery from Data (TKDD), V1, P1
   Tao C, 2009, DATA KNOWL ENG, V68, P683, DOI 10.1016/j.datak.2009.02.010
   Ulges A, 2008, LECT NOTES COMPUT SC, V5008, P415
   Viitaniemi V, 2007, SIGNAL PROCESS-IMAGE, V22, P557, DOI 10.1016/j.image.2007.05.003
   Voss J., 2007, Proceedings of the International Symposium of Information Science, P234
   Wu RS, 2011, EXPERT SYST APPL, V38, P3040, DOI 10.1016/j.eswa.2010.08.094
   Yamamoto D, 2008, IEEE MULTIMEDIA, V15, P22, DOI 10.1109/MMUL.2008.67
   Yang D., 2008, Hawaii International Conference on System Sciences, Proceedings of the 41st Annual, P24
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P287, DOI 10.1016/j.image.2010.02.001
   Zhang XY, 2009, IEEE T MULTIMEDIA, V11, P272, DOI 10.1109/TMM.2008.2009689
   Zhou HY, 2010, NEUROCOMPUTING, V73, P1718, DOI 10.1016/j.neucom.2009.09.022
NR 61
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 143
EP 177
DI 10.1007/s11042-011-0984-x
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800008
DA 2024-07-18
ER

PT J
AU Lee, BG
   Seo, H
   Om, SY
   Oh, J
   Seol, J
AF Lee, Bong Gyou
   Seo, Hyunsik
   Om, Soung Young
   Oh, Junseok
   Seol, Jeongseon
TI Developing a strategic framework for the WiBro service in the global
   market
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WiBro; Global market strategies; Delta Model; ANP
AB This research presents a strategic framework, associated with a standardization strategy, to achieve successful commercialization of the WiBro (brand service name for WiMAX) service on the global market. Although WiBro was the first wireless broadband internet technology in the world to be developed, commercialized and subsequently designated as an international standard, its performance on the global market has been without notable success and no active research is taking place to change this current state. In order to escape from a narrow domestic market and get to launch abroad, it is important to suggest a strategic roadmap with policy supports of a government as well as to introduce the policy for Wibro standardization. This research analyzed the effects of standardization on business strategies. Based on the Delta Model, this research devises strategies for the WiBro service's commercialization on the global market and presents a strategic framework based on empirical research using the ANP methodology. The analysis results in this study suggest a strategic roadmap for global commercialization of WiBro.
C1 [Lee, Bong Gyou; Om, Soung Young] Yonsei Univ, Grad Sch Informat, Seoul 120749, South Korea.
   [Seo, Hyunsik] Yonsei Univ, Communicat Policy Res Ctr, Seoul 120749, South Korea.
   [Oh, Junseok] Penn State Univ, University Pk, PA 16802 USA.
   [Seol, Jeongseon] Korea Telecommun Operators Assoc, Seoul, South Korea.
C3 Yonsei University; Yonsei University; Pennsylvania Commonwealth System
   of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania
   State University - University Park
RP Lee, BG (corresponding author), Yonsei Univ, Grad Sch Informat, Seoul 120749, South Korea.
EM bglee@yonsei.ac.kr; seohs@yonsei.ac.kr; syom@yonsei.ac.kr; jsoh@psu.edu;
   12jss@ktoa.or.kr
CR [Anonymous], 2003, J STRATEGIC MANAGEME
   Ansoff I., 2007, Strategic management: classic edition
   Hax AC, 1999, SLOAN MANAGE REV, V40, P11
   Heedong Y, 2004, CALS EC E BIZ WORLD
   Jin HC, 2005, STANDARDIZATION STRA
   Kang IS, 2009, COMMUN POLICY, V21, P5
   Kim HK, 2006, INF COMMUN MAG, V23, P4
   Kim YS, 2004, FDN KOREAN INF IND, V229, P30
   Lee BG, 2009, TELECOMMUN POLICY, V33, P296, DOI 10.1016/j.telpol.2009.02.006
   Lyytinen K, 2002, TELECOMMUN POLICY, V26, P97, DOI 10.1016/S0308-5961(02)00002-2
   Nelson KT, 2004, INFORM SYST, V14, P111
   Saaty T.L., 2001, DECISION MAKING DEPE
   Seol JS, 2009, THESIS KOREA U
   Shin HS, 2004, TTA J, V95, P21
   Tilson D, 2006, TELECOMMUN POLICY, V30, P569, DOI 10.1016/j.telpol.2006.09.002
NR 15
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 131
EP 144
DI 10.1007/s11042-010-0705-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000008
DA 2024-07-18
ER

PT J
AU Park, K
   Jee, H
   Lee, T
   Jung, S
   Lim, H
AF Park, Kinam
   Jee, Hyesung
   Lee, Taemin
   Jung, Soonyoung
   Lim, Heuiseok
TI Automatic extraction of user's search intention from web search logs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Search engine; Intention map; User's search log; Clustering; Knowledge
   representation
AB Web search users complain of the inaccurate results produced by current search engines. Most of these inaccurate results are due to a failure to understand the user's search goal. This paper proposes a method to extract users' intentions and to build an intention map representing these extracted intentions. The proposed method makes intention vectors from clicked pages from previous search logs obtained on a given query. The components of the intention vector are weights of the keywords in a document. It extracts user's intentions by using clustering the intention vectors and extracting intention keywords from each cluster. The extracted the intentions on a query are represented in an intention map. For the efficiency analysis of intention map, we extracted user's intentions using 2,600 search log data a current domestic commercial search engine. The experimental results with a search engine using the intention maps show statistically significant improvements in user satisfaction scores.
C1 [Park, Kinam; Jee, Hyesung; Lee, Taemin; Jung, Soonyoung; Lim, Heuiseok] Korea Univ, Dept Comp Educ, Seoul, South Korea.
C3 Korea University
RP Lim, H (corresponding author), Korea Univ, Dept Comp Educ, Anam Dong 5 Ga, Seoul, South Korea.
EM spknn@korea.ac.kr; Hyesung84@korea.ac.kr; persuade@korea.ac.kr;
   jsy@korea.ac.kr; limhseok@korea.ac.kr
RI Park, Kinam/E-9186-2012; Heuiseok, Lim/IUP-5678-2023
FU National Research Foundation of Korea; Korean Government [2010-0014325]
FX This work was supported by National Research Foundation of Korea Grant
   funded by the Korean Government (2010-0014325)
CR [Anonymous], 1983, INTRO MODERN INFORM
   Daniel R, 2004, P 13 INT C WORLD WID, P17
   Dreilinger D, 1997, ACM T INFORM SYST, V15, P195, DOI 10.1145/256163.256164
   Fausett V, 1994, FUNDAMENTALS NEURAL
   Gose E., 1996, PATTERN RECOGNITION
   Jansen BJ, 2006, INFORM PROCESS MANAG, V42, P248, DOI 10.1016/j.ipm.2004.10.007
   Jansen BJ, 2000, INFORM PROCESS MANAG, V36, P207, DOI 10.1016/S0306-4573(99)00056-4
   Jinxi Xu, 1996, SIGIR Forum, P4
   Kohone T, 1995, SELF ORG MAPS
   Lee U., 2005, Proceedings of the 14th international conference on World Wide Web, WWW '05, P391, DOI DOI 10.1145/1060745.1060804
   Mel'cuk I., 1988, Dependency syntax: theory and practice
   Park GW, 2008, WSEAS INT C APPL COM, V7, P205
   Rumelhart E, 1980, SCHEMATA BUILDING BL
   Spink A, 2001, J AM SOC INF SCI TEC, V52, P226, DOI 10.1002/1097-4571(2000)9999:9999<::AID-ASI1591>3.0.CO;2-R
   Zheng Chen, 2002, World Wide Web, V5, P181, DOI 10.1023/A:1020980528899
NR 15
TC 5
Z9 8
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 145
EP 162
DI 10.1007/s11042-010-0723-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000009
DA 2024-07-18
ER

PT J
AU Tak, YS
   Rho, S
   Hwang, E
   Lee, H
AF Tak, Yoon-Sik
   Rho, Seungmin
   Hwang, Eenjun
   Lee, Hanku
TI Tertiary hash tree-based index structure for high dimensional multimedia
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tertiary hash tree; Extendible hash; Content-based; Image retrieval;
   Multidimensional data
AB Dominant features for the content-based image retrieval usually have high-dimensionality. So far, many researches have been done to index such values to support fast retrieval. Still, many existing indexing schemes are suffering from performance degradation due to the curse of dimensionality problem. As an alternative, heuristic algorithms have been proposed to calculate the answer with 'high probability' at the cost of accuracy. In this paper, we propose a new hash tree-based indexing structure called tertiary hash tree for indexing high-dimensional feature data. Tertiary hash tree provides several advantages compared to the traditional extendible hash structure in terms of resource usage and search performance. Through extensive experiments, we show that our proposed index structure achieves outstanding performance.
C1 [Tak, Yoon-Sik; Rho, Seungmin; Hwang, Eenjun] Korea Univ, Dept Elect Engn, Sch Elect Engn, Seoul, South Korea.
   [Lee, Hanku] Konkuk Univ, Div Internet & Multimedia Engn, Seoul, South Korea.
   [Lee, Hanku] Konkuk Univ, Social Media Cloud Comp Res Ctr, Seoul, South Korea.
C3 Korea University; Konkuk University; Konkuk University
RP Hwang, E (corresponding author), Korea Univ, Dept Elect Engn, Sch Elect Engn, Seoul, South Korea.
EM life993@korea.ac.kr; smrho@korea.ac.kr; ehwang04@korea.ac.kr;
   hlee@konkuk.ac.kr
RI Rho, Seungmin/HTP-6683-2023
FU MKE (Ministry of Knowledge Economy), Korea, under the ITRC (Information
   Technology Research Center) [NIPA-2010-C1090-1001-0008]
FX This research was supported by the MKE (Ministry of Knowledge Economy),
   Korea, under the ITRC (Information Technology Research Center) support
   program supervised by the NIPA (National IT Industry Promotion Agency)
   (NIPA-2010-C1090-1001-0008)
CR [Anonymous], 1994, The VLDB Journal, DOI DOI 10.1007/BF01231606
   [Anonymous], 1990, SIGMOD, DOI DOI 10.1145/93597.98741
   Beckmann N, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P799
   Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28
   Berchtold S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P577, DOI 10.1109/ICDE.2000.839456
   Chakrabarti K, 1999, PROC INT CONF DATA, P440, DOI 10.1109/ICDE.1999.754960
   Fagin R., 1979, ACM Transactions on Database Systems, V4, P315, DOI 10.1145/320083.320092
   Faloutsos C., 1995, SIGMOD Record, V24, P163, DOI 10.1145/568271.223812
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   KATAYAMA N, 1997, P 1997 ACM SIGMOD IN, P69
   Sellis T, 1987, P C VER LARG DAT BAS
   Shu Lin, 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P221
   Slaney M, 2008, IEEE SIGNAL PROC MAG, V25, P128, DOI 10.1109/MSP.2007.914237
   Tak Y, 2009, INDEXING MATCHING SC, P60
   Wang H, 2001, P 5 PAC AS C KNOWL D
   White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
NR 17
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 51
EP 68
DI 10.1007/s11042-010-0687-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000004
DA 2024-07-18
ER

PT J
AU de Fez, I
   Fraile, F
   Belda, R
   Guerri, JC
AF de Fez, Ismael
   Fraile, Francisco
   Belda, Roman
   Guerri, Juan C.
TI Performance evaluation of AL-FEC LDPC codes for push content
   applications in wireless unidirectional environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LDPC; FLUTE; AL-FEC; Push content download service; Wi-Fi; Broadcast
AB FEC (Forward Error Correction) mechanisms improve IP content transmission reliability through the recovery of packets lost in transmission. Opposite to ARQ (Automatic Repeat Request), FEC mechanisms are especially suited to unidirectional environments or to multicast environments where multiple receivers perceived different channel losses, thus making difficult the implementation of mechanisms based on feedback information. Among the different types of FEC codes, this paper presents a thorough performance evaluation of LDPC (Low Density Parity Check) codes, based on an implementation developed by the authors, according to the specifications defined by RFC 5170 for the usage of LDPC codes by push content applications based on the FLUTE protocol. LDPC codes provide a good trade-off between performance and complexity, hence, they are appropriate for mobile applications. Contributions of this paper include tests conducted with commercial mobile phones connected to the push content download server over a Wi-Fi network. The evaluation highlights the advantages of using packet level FEC encoding in file transmission over unidirectional networks and provides with a comparison between two kinds of LDPC structures: Staircase and Triangle. This is accomplished by calculating the inefficiency ratio of these LDPC structures in different environments. Results show that the implemented LDPC codes can provide inefficiency ratios close to one when the different coding parameters (as the code rate or the number of blocks) are configured to an optimal value that depends on the packet loss rate.
C1 [de Fez, Ismael; Fraile, Francisco; Belda, Roman; Guerri, Juan C.] Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, E-46071 Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Guerri, JC (corresponding author), Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Camino Vera, E-46071 Valencia, Spain.
EM isdefez@iteam.upv.es; ffraile@iteam.upv.es; robelor@iteam.upv.es;
   jcguerri@dcom.upv.es
RI de+Fez+Lava, Ismael/AAJ-1048-2020; Belda, Román/IAM-8676-2023; Fraile,
   Francisco/AAM-6680-2020; Guerri, Juan Carlos/K-9659-2014
OI Fraile, Francisco/0000-0003-0852-8953; Belda, Roman/0000-0003-2244-2371;
   de Fez, Ismael/0000-0002-1337-1973; Guerri, Juan
   Carlos/0000-0002-5807-1923
FU Ministry of Industry, Tourism and Trade of the Government of Spain,
   under project "Redes Hibridas para la Provision de Servicios Turisticos"
   [TSI-020302-2010-165]
FX This work was supported in part by the Ministry of Industry, Tourism and
   Trade of the Government of Spain, under project "Redes Hibridas para la
   Provision de Servicios Turisticos" (TSI-020302-2010-165).
CR [Anonymous], 2008, 5170 IETF RFC
   [Anonymous], 80216 IEEE
   [Anonymous], 25346 3GPP TS
   [Anonymous], 2006, 22146 3GPP TS
   [Anonymous], 5053 IETF RFC
   [Anonymous], 2004, 3926 IETF RFC
   [Anonymous], 2012, 802112012 IEEE
   [Anonymous], 5052 IETF RFC
   [Anonymous], 2009, INTEGRATED MOBILE BR
   [Anonymous], 2009, 5510 RFC IETF
   Bai Haowei, 2003, IEEE Communications Surveys & Tutorials, V5, P2, DOI 10.1109/COMST.2003.5341334
   Cunche M, 2008, P 10 IEEE INT WORKSH
   CUNCHE M, 2008, RR6473 INRIA
   Cunche M., 2010, IEEE INT S INF THEOR
   Faria G, 2006, P IEEE, V94, P194, DOI 10.1109/JPROC.2005.861011
   Fraile F, 2011, IEEE INT C CONS EL L
   Gallager R G, 1962, IEEE T INFORM THEOR, V8
   Gil A, 2010, IEEE T CONSUM ELECTR, V56, P211, DOI 10.1109/TCE.2010.5439147
   HANDLEY M, 1998, 2327 IEFT RFC
   INRIA Planete Research Team, 2006, LDPC LARG BLOCK FEC
   LUBY M, 2002, P IEEE S FDN COMP SC
   Luby M., 2010, 5775 IEFT RFC
   Luby M., 2009, 5651 IEFT RFC
   MacKay D.J, 1995, LNCS, V1025
   Park S, 1990, COMMUN ACM, V33, P87
   ROCA V, 2004, RR5225 INRIA
   Shokrollahi A., 2006, IEEE Transactions on Information Theory
   Watson M., 2009, 5445 IETF RFC
NR 28
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 669
EP 688
DI 10.1007/s11042-011-0841-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300010
OA Green Published
DA 2024-07-18
ER

PT J
AU Aly, R
   Hiemstra, D
   de Jong, F
   Apers, PMG
AF Aly, Robin
   Hiemstra, Djoerd
   de Jong, Franciska
   Apers, Peter M. G.
TI Simulating the future of concept-based video retrieval under improved
   detector performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concept-based retrieval; Simulation; Performance prediction; Concept
   detection
ID LEVEL SEMANTIC FEATURES
AB In this paper we address the following important questions for concept-based video retrieval: (1) What is the impact of detector performance on the performance of concept-based retrieval engines, and (2) will these engines be applicable to real-life search tasks if detector performance improves in the future? We use Monte Carlo simulations to answer these questions. To generate the simulation input, we propose to use a probabilistic model of two Gaussians for the confidence scores that concept detectors emit. Modifying the model's parameters affects the detector performance and the search performance. We study the relation between these two performances on two video collections. For detectors with similar discriminative power and a concept vocabulary of around 100 concepts, the simulation reveals that in order to achieve a search performance of 0.20 mean average precision (MAP)-which is considered sufficient performance for real-life applications-one needs detectors with at least 0.60 MAP . We also find that, given our simulation model and low detector performance, MAP is not always a good evaluation measure for concept detectors since it is not strongly correlated with the search performance.
C1 [Aly, Robin; Hiemstra, Djoerd; de Jong, Franciska; Apers, Peter M. G.] Univ Twente, NL-7500 AE Enschede, Netherlands.
C3 University of Twente
RP Aly, R (corresponding author), Univ Twente, POB 217, NL-7500 AE Enschede, Netherlands.
EM r.aly@ewi.utwente.nl
RI Hiemstra, Djoerd/L-1863-2016
OI Hiemstra, Djoerd/0000-0003-4967-2900
FU CTIT strategic research orientation Natural Interaction in
   Computer-mediated Environments (SRO-NICE)
FX This research was funded by the CTIT strategic research orientation
   Natural Interaction in Computer-mediated Environments
   (SRO-NICE).<SUP>5</SUP> We want to thank the anonymous reviewers for
   their valuable feedback.
CR Aly R, 2009, TRCTIT0940 U TWENTE
   Aly R., 2009, CIVR 09
   [Anonymous], INT C IM VID RETR
   [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 7 ACM INT C CONT BAS
   Arndt C, 2001, INFORM MEASURES INFO
   Ayache S, 2007, SIGNAL PROCESS-IMAGE, V22, P692, DOI 10.1016/j.image.2007.05.010
   Bather J, 2000, WILEY INTERSCIENCE S
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Christel MG, 2005, LECT NOTES COMPUT SC, V3568, P134
   Croft WB, 1992, P 3 ANN S DOC AN INF, P115
   Hastie T., 1996, CLASSIFICATION PAIRW
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   Hawking D., 2000, NIST special publication 500-249: the ninth text retrieval conference (TREC 9), P87
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   METROPOLIS N, 1949, J AM STAT ASSOC, V44, P335, DOI 10.2307/2280232
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Platt JC, 2000, ADV NEUR IN, P61
   Press W. H, 1992, NUMERICAL RECIPES C
   Robertson S.E., 1981, INFORM RETRIEVAL RES, P35
   Ross S. M., 2014, INTRO PROBABILITY MO
   Sangswang A, 2003, IEEE IND ELEC, P1870
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Snoek CGM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1966
   Snoek CGM, 2009, P 9 TRECVID WORKSH G
   Taylor JohnR., 1996, INTRO ERROR ANAL
   Toharia P, 2009, CAIP 2009
   Witbrock M, 1997, P DARAP SPEECH REC W, P2
   Yan R., 2003, P 11 ACM INT C MULT, V3, P339, DOI DOI 10.1145/957013.957086
   Yan R, 2006, THESIS C MELLON U
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
   Zheng WJ, 2006, LECT NOTES COMPUT SC, V4071, P370
NR 36
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 203
EP 231
DI 10.1007/s11042-011-0818-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500010
OA Green Submitted, Green Published, hybrid
DA 2024-07-18
ER

PT J
AU El'Arbi, M
   Koubaa, M
   Charfeddine, M
   Ben Amar, C
AF El'Arbi, Maher
   Koubaa, Mohamed
   Charfeddine, Maha
   Ben Amar, Chokri
TI A dynamic video watermarking algorithm in fast motion areas in the
   wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Motion analysis; Fast motion areas; Moving objects;
   Motion adaptation factor
ID COMPENSATION
AB In this paper, we propose a video watermarking algorithm which embeds different parts of a single watermark into different shots of a video under the wavelet domain. Based on a Motion Activity Analysis, different regions of the original video are separated into perceptually distinct categories according to motion information and region complexity. Thus, the localizations of the watermark are adjusted adaptively in accordance with the human visual system and signal characteristics, which makes them perceptually invisible and less vulnerable to automated removal. In addition, contrary to traditional methods where the watermark remains at a fixed position on the screen, the watermark moves along with moving objects and thus motion artefacts can be avoid. The multi-frame based extraction strategy ensures that the watermark can be correctly recovered from a very short segment of video. Individual frames extracted from the video also contain watermark information. Experimental results show that the inserted watermark is not only less perceptible but also robust against common video processing attacks.
C1 [El'Arbi, Maher; Koubaa, Mohamed; Charfeddine, Maha; Ben Amar, Chokri] Univ Sfax, Res Grp Intelligent Machines, ENIS, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP El'Arbi, M (corresponding author), Univ Sfax, Res Grp Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
EM maher.elarbi@gmail.com; mohamed.koubaa@gmail.com;
   charfeddine.maha@ieee.org; chokri.benamar@ieee.org
RI charfeddine, maha/AAC-7422-2021; Chokri, BEN AMAR/K-5237-2012
OI charfeddine, maha/0000-0003-2996-4113; 
FU General Direction of Scientific Research (DGRST), Tunisia
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR ALATTAAR A, 2003, P INT C AC SPEECH SI
   [Anonymous], 2008, IPTA IMAGE PROCESSIN
   Ben Amar C., 2006, T SYSTEMS SIGNALS DE, V1, P275
   Ben Soltana Wael, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P55
   BOFF KR, 1986, HDB PERCEPTION HUMAN, V1, P1
   CAFFORIO C, 1994, SIGNAL PROCESS-IMAGE, V6, P123, DOI 10.1016/0923-5965(94)90011-6
   Chan PW, 2003, LECT NOTES COMPUT SC, V2836, P202
   CHARFEDDINE M, 2008, IEEE INT S COMM CONT, P1138
   CHEVEAU L, 2001, EBU TECHNICAL RE MAR, P8
   CHOONGHOON L, 2000, P SPIE SECURITY WATE, V2, P209
   Dittmann J., 1998, Proceedings ACM Multimedia 98, P71, DOI 10.1145/290747.290757
   El'arbi M., 2007, Proceedings of IEEE International Conference on Image Processing, V5, P481
   El'Arbi M, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P1131
   ELARBI M, 2010, INT J COMPUTATIONAL, P34
   ELARBI M, 2006, IEEE INT C MULT EXP
   Hussein J., 2009, INT J COMPUTER SCI I, V6, P44
   Koubaa M, 2006, IEEE INT SYM MULTIM, P161
   Koubaa M, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P1143
   Liu Z, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2358
   Mejdoub Mahmoud, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1799
   Mejdoub Mahmoud, 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P365, DOI 10.1109/CBMI.2008.4564970
   Othmani M, 2010, INT J WAVELETS MULTI, V8, P149, DOI 10.1142/S0219691310003353
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qiao LT, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P276, DOI 10.1109/MMCS.1998.693656
   SCHIMMEL S, 2001, 2001825 DELFT U TECH
   SUN DW, 2003, J KOREAN I COMMUNICA, V28, P397
   Sun ZW, 2009, NEURAL COMPUT APPL, V18, P507, DOI 10.1007/s00521-009-0253-3
   Swanson MD, 1998, IEEE J SEL AREA COMM, V16, P540, DOI 10.1109/49.668976
   Wang HX, 2005, INT J INNOV COMPUT I, V1, P247
   ZAFAR S, 1993, IEEE J SEL AREA COMM, V11, P24, DOI 10.1109/49.210541
   Zaied M, 2005, J DECIS SYST, V14, P109, DOI 10.3166/jds.14.109-122
   Zhang YQ, 1992, IEEE T CIRC SYST VID, V2, P285, DOI 10.1109/76.157160
   [No title captured]
NR 33
TC 34
Z9 35
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 579
EP 600
DI 10.1007/s11042-010-0580-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600010
DA 2024-07-18
ER

PT J
AU De Bruyne, S
   Hosten, P
   Concolato, C
   Asbach, M
   De Cock, J
   Unger, M
   Le Feuvre, J
   Van de Walle, R
AF De Bruyne, Sarah
   Hosten, Peter
   Concolato, Cyril
   Asbach, Mark
   De Cock, Jan
   Unger, Michael
   Le Feuvre, Jean
   Van de Walle, Rik
TI Annotation based personalized adaptation and presentation of videos for
   mobile applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Annotation; Adaptation; Rich media presentation; Personalized multimedia
ID SEMANTIC ANNOTATION; ARCHITECTURES
AB Personalized multimedia content which suits user preferences and the usage environment, and as a result improves the user experience, gains more importance. In this paper, we describe an architecture for personalized video adaptation and presentation for mobile applications which is guided by automatically generated annotations. By including this annotation information, more intelligent adaptation techniques can be realized which primarily reduce the quality of unimportant regions in case a bit rate reduction is necessary. Furthermore, a presentation layer is added to enable advanced multimedia viewers to adequately present the interesting parts of a video in case the user wants to zoom in. This architecture is the result of collaborative research done in the EU FP6 IST INTERMEDIA project.
C1 [De Bruyne, Sarah; De Cock, Jan; Van de Walle, Rik] Univ Ghent, IBBT, Dept Elect & Informat Syst, Multimedia Lab, B-9050 Ledeberg Ghent, Belgium.
   [Hosten, Peter; Asbach, Mark; Unger, Michael] Rhein Westfal TH Aachen, Inst Commun Engn, D-52056 Aachen, Germany.
   [Concolato, Cyril; Le Feuvre, Jean] Telecom ParisTech, Signal & Image Proc Dept, Multimedia Grp, F-75013 Paris, France.
C3 Ghent University; RWTH Aachen University; IMT - Institut Mines-Telecom;
   Institut Polytechnique de Paris; Telecom Paris
RP De Bruyne, S (corresponding author), Univ Ghent, IBBT, Dept Elect & Informat Syst, Multimedia Lab, Gaston Crommenlaan 8 Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM sarah.debruyne@ugent.be
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research-Flanders
   (FWOFlanders); Belgian Federal Science Policy Office (BFSPO); European
   Union [IST-038419]
FX The research activities that have been described in this paper were
   co-funded by Ghent University, the Interdisciplinary Institute for
   Broadband Technology (IBBT), the Institute for the Promotion of
   Innovation by Science and Technology in Flanders (IWT), the Fund for
   Scientific Research-Flanders (FWOFlanders), the Belgian Federal Science
   Policy Office (BFSPO), and the European Union (within the framework of
   the NoE INTERMEDIA, IST-038419).
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], MOV CONT AN
   BACCICHET P, 2006, P PICT COD S
   Bertini M, 2005, MULTIMED TOOLS APPL, V26, P345, DOI 10.1007/s11042-005-0893-y
   Bolla R, 2008, IEEE INT C EMERG, P1354, DOI 10.1109/ETFA.2008.4638575
   Boreczky JS, 1996, J ELECTRON IMAGING, V5, P122, DOI 10.1117/12.238675
   Burnett I.S., 2006, MPEG 21 BOOK, V1st
   Cavallaro A, 2005, IEEE T CIRC SYST VID, V15, P1200, DOI 10.1109/TCSVT.2005.854240
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   Cucchiara R., 2002, P 10 ACM INT C MULTI, P223
   De Cock J, 2010, SIGNAL PROCESS-IMAGE, V25, P235, DOI 10.1016/j.image.2010.01.006
   De Zutter S, 2008, VISUAL COMPUT, V24, P735, DOI 10.1007/s00371-008-0255-7
   FENG WC, 2008, P ACM INT C MULT, P745
   Hata Toshihiko, 2005, P 7 IEEE WORKSH MULT, P1, DOI DOI 10.1109/MMSP.2005.248636
   *INTERMEDIA, 2006, EUR 6 FRAM PROGR FP6
   *ISO IEC, 2005, 14496112005 ISOIEC
   Knoche H, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1556134.1556137
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Lefol D, 2007, SIGNAL PROCESS-IMAGE, V22, P421, DOI 10.1016/j.image.2007.02.002
   Magalhaes J, 2004, SIGNAL PROCESS-IMAGE, V19, P437, DOI 10.1016/j.image.2004.02.004
   Manjunath B., INTRO MPEG 7 MULTIME
   MAVLANKAR A, 2007, P 15 EUR SIGN PROC C, P1275
   Minh Khiem Ngo Quang., 2010, Proceedings of the first annual ACM SIGMM conference on Multimedia systems, P259, DOI DOI 10.1145/1730836.1730868
   Notebaert S, 2009, MULTIMED TOOLS APPL, V44, P39, DOI 10.1007/s11042-009-0273-0
   Pereira F, 1997, IEEE T CIRC SYST VID, V7, P32, DOI 10.1109/76.554416
   Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   SHEN H, 2006, P PICT COD S
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   UNGER M, 2008, INT WORKSH IM AN MUL, P167
   Unger M, 2008, IEEE IMAGE PROC, P2708, DOI 10.1109/ICIP.2008.4712353
   VANRIJSSELBERGE.D, 2009, INT WORKSH IM AN MUL, P296
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Vetro A, 1999, IEEE T CIRC SYST VID, V9, P186, DOI 10.1109/76.744285
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 37
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2011
VL 55
IS 2
SI SI
BP 307
EP 331
DI 10.1007/s11042-010-0575-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 808HU
UT WOS:000293969500007
OA Green Published
DA 2024-07-18
ER

PT J
AU Barricelli, BR
   Mussio, P
   Padula, M
   Scala, PL
AF Barricelli, Barbara Rita
   Mussio, Piero
   Padula, Marco
   Scala, Paolo Luigi
TI TMS for multimodal information processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Task management system; Component-based systems; Workflow; Multimodal
   information; Reusability; Tailorability
ID SOFTWARE; SYSTEMS
AB Many working processes are complex and composed by heterogeneous atomic tasks, e.g. editing, assembling data from different sources (as databases or laboratory's devices) with texts, images or learning objects, or submitting them to software components to retrieve information, to render them, re-format, submit to computations, and other types of information processing. All these processes heavily require procedural knowledge which is tacit as owned by experts of the working activity; they are complex and are extremely difficult to be modeled and automatized without having a flexible, multimodular evolutionary system in place. Support to information from different modalities increases the performance of a computer system originally designed for a task with a unimodular nature. In this paper, we discuss the idea of task management system (TMS) as a component-based system which offers a virtual workbench to search, acquire, describe and assemble computational agents performing single autonomous tasks into working processes. We sustain that TMS is a cutting edge platform to develop software solutions for problems related to workflow automatization and design. The architecture we propose follows the conceptual track of the TMS to allow composition and arrangement of atomic modules into a complex system. A configuration of the workflow can be implemented and extended with a set of task/components, chunks of activities which are considered basic elements of the workflow. By interacting with the TMS in editing mode, the workflow designer selects the relevant chunks from system repositories, drags them into a working system area and assembles them into a working process. As the main actor of the system, the workflow designer is provided with an environment resembling an artisan's workshop, to let her/him select the relevant chunks from system repositories, drags them into a working area and assembles them into a working TMS instance, which represents the working process. Global interaction modality of the TMS instance is moulded and specialized on the base of the specific modalities of the task/components which have been retrieved from the system repositories and each time negotiated. Complex activities could be formally described, implemented and applied with a consequent advantage for personnel re-organization toward more conceptual activities.
C1 [Barricelli, Barbara Rita; Mussio, Piero] Univ Milan, Dipartimento Informat & Comunicaz, I-20135 Milan, Italy.
   [Padula, Marco; Scala, Paolo Luigi] CNR, Ist Tecnol Costruz, I-20133 Milan, Italy.
C3 University of Milan; Consiglio Nazionale delle Ricerche (CNR); Istituto
   per le Tecnologie della Costruzione (ITC-CNR)
RP Scala, PL (corresponding author), Univ Milan, Dipartimento Informat & Comunicaz, Via Comel 39-41, I-20135 Milan, Italy.
EM barricelli@dico.unimi.it; mussio@dico.unimi.it; padula@itc.cnr.it;
   scala@itc.cnr.it
RI padula, marco/AAY-5096-2020; Barricelli, Barbara Rita/AAT-2374-2020
OI padula, marco/0000-0002-5671-3451; Barricelli, Barbara
   Rita/0000-0001-9575-5542
CR Ahmad S., 2004, P 4 INT C LANGUAGE R, P1049
   ANKOLENKAR A, 2001, 1 SEM WEB WORK S STA, P411
   [Anonymous], END USER DEV
   [Anonymous], P CSCW 90
   [Anonymous], RDF XML SYNTAX SPECI
   [Anonymous], OWL S SEMANTIC MARKU
   [Anonymous], COMMUNICATIONS ACM
   [Anonymous], 1994, Human-Computer Interaction
   Arias E., 2000, INT ICSC S INTERACTI, P567
   Armour PG, 2001, COMMUN ACM, V44, P13, DOI 10.1145/383845.383849
   Armour PG, 2009, COMMUN ACM, V52, P23, DOI 10.1145/1435417.1435427
   BARRICELLI BR, 2009, HDB RES MULTIMODAL H, P243
   Bianchi A, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P91, DOI 10.1109/MMCS.1999.779126
   Charfi A, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, VOLS 1 AND 2, P35, DOI 10.1109/ICWS.2009.125
   Chinthaka E, 2009, 2009 IEEE CONGRESS ON SERVICES (SERVICES-1 2009), VOLS 1 AND 2, P352, DOI 10.1109/SERVICES-I.2009.51
   Costabile MF, 2007, IEEE T SYST MAN CY A, V37, P1029, DOI 10.1109/TSMCA.2007.904776
   COSTABILE MF, 2006, END USER DEV, P183, DOI DOI 10.1007/1-4020-5386-X_9
   Desouza KC, 2003, COMMUN ACM, V46, P85, DOI 10.1145/777313.777317
   FOX J, 2003, SOA WORLD MAGAZINE
   Georgolios P, 2007, INT J INTELL SYST, V22, P501, DOI 10.1002/int.20211
   GINIGE A, 2003, P SOFTW ENG KNOWL EN, P1
   Ha Y, 2006, FOURTH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS, PROCEEDINGS, P315
   HARTSON HR, 1989, COMPUT SURV, V21, P5
   Henderson A., 1991, Design At Work: Cooperative Design of Computer Systems, P219
   Herzum P., 2000, BUSINESS COMPONENT F
   Huang JC, 2003, IEEE T ENG MANAGE, V50, P89, DOI 10.1109/TEM.2002.808297
   Mentzas G, 2007, COMMUN ACM, V50, P53, DOI 10.1145/1290958.1290962
   MILLER NG, 2000, Patent No. 6101481
   Ncube C, 2008, IEEE SOFTWARE, V25, P38, DOI 10.1109/MS.2008.153
   Oshri Ilan, 2007, Communications of the ACM, V50, P63, DOI 10.1145/1323688.1323696
   Oviatt S, 1997, HUM-COMPUT INTERACT, V12, P93, DOI 10.1207/s15327051hci1201&2_4
   Oviatt S., 2003, HUM FAC ER, P286
   Sarter NB, 2006, INT J IND ERGONOM, V36, P439, DOI 10.1016/j.ergon.2006.01.007
   Scheer A.-W., 2000, Business Process Management - Models, Techniques, and Empirical Studies, P366
   SHALIL M, 2004, IEEE INT C WEB SERV, P514
   Sycara Katia., 2003, WEB SEMANTICS SCI SE, V1, P27
   SZYPERSKI C, 2002, COMPONENT SOFTWARE
   SZYPERSKI C, 1997, SPECIAL ISSUE OBJECT
   Szyperski Clemens., 2000, Foundations of Component-Based Systems, P1
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Wenger E., 2002, GUIDE MANAGING KNOWL
   OWLWEB ONTOLOGY LANG
NR 42
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 97
EP 120
DI 10.1007/s11042-010-0527-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100006
DA 2024-07-18
ER

PT J
AU Kim, K
   Fox, GC
AF Kim, Kangseok
   Fox, Geoffrey C.
TI Modeling, simulation, and practice of floor control for synchronous and
   ubiquitous collaboration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Floor control; Ubiquitous collaboration; Synchronous collaboration;
   Mobile devices
AB Floor control refers to the need for coordinating activities occurred in synchronously cooperating applications shared among collaborators. We address this for ubiquitous collaboration-the capability of multiple users to link together with disparate access device anytime and anywhere. Floor control has been studied for years but most researchers focus on relaxed coordination mechanisms with stationary devices that allow updates by any user on any object and resolve the uncoordinated updates. In this paper we present a floor control mechanism, called XGSP-Floor, which implements a coordination mechanism at application level for enabling users to consistently share the same resource in real time (synchronous collaboration) in ubiquitous collaboration environment. The implementation platform on cell phone devices may not be new. But we believe the implementation and experiment for XGSP-Floor on cell phone devices is a new challenge in ubiquitous collaboration environment even though the coordination mechanism can intuitively impose a tremendous overhead in worst case. We also describe the results of the modeling of XGSP-Floor and formal verification to prove the correctness of the modeling using Colored Petri Nets. We describe lessons learned and discuss future work.
C1 [Kim, Kangseok; Fox, Geoffrey C.] Indiana Univ, Community Grids Lab, Bloomington, IN 47405 USA.
   [Kim, Kangseok; Fox, Geoffrey C.] Indiana Univ, Dept Comp Sci, Bloomington, IN 47405 USA.
   [Fox, Geoffrey C.] Indiana Univ, Sch Informat, Bloomington, IN 47405 USA.
C3 Indiana University System; Indiana University Bloomington; Indiana
   University System; Indiana University Bloomington; Indiana University
   System; Indiana University Bloomington
RP Kim, K (corresponding author), Indiana Univ, Community Grids Lab, Bloomington, IN 47405 USA.
EM kakim@indiana.edu; gcf@indiana.edu
CR [Anonymous], MOORES LAW
   [Anonymous], 2002, 3261 RFC INT ENG TAS
   Banavar G., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P266, DOI 10.1145/345910.345957
   Berry L., 2005, Proceedings of the 18th annual ACM symposium on User interface software and technology, P23, DOI DOI 10.1145/1095034.1095039
   BFar R, 2005, MOBILE COMPUTING PRINCIPLES: DESIGNING AND DEVELOPING MOBILE APPLICATIONS WITH UML AND XML, P1
   Bishop Matt., 2004, INTRO COMPUTER SECUR, V1st
   DOMMEL HP, 1997, ACM MULT SYST JAN 19, V5
   DOMMEL HP, 1995, P SPIE MULTIMEDIA NE, P305
   Edwards W. E., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P139, DOI 10.1145/263407.263533
   Foster I, 2001, INT J HIGH PERFORM C, V15, P200, DOI 10.1177/109434200101500302
   Fox G, 2003, P 1 INT WORKSH MIDDL
   GALLASCH G, 2001, P CPN 2001 WORKSH
   GREENBERG S, 1991, PROCEEDINGS OF THE SECOND EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK : ECSCW 91, P17
   Greenberg S, 1994, P ACM CSCW C COMP SU
   HANDLEY M, 1995, ACM C SIGCOMM AUG
   Jensen K., 1997, MONOGRAPHS THEORETIC, V1-3
   Johanson B, 2002, FOURTH IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P83, DOI 10.1109/MCSA.2002.1017488
   KATRINIS K, 2004, 10 INT C DISTR MULT
   KIM K, 2007, FRAMEWORK SYNCHRONOU
   Malpani R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P155, DOI 10.1145/266180.266356
   Morris M.R., 2004, Proceedings of the 2004 ACM conference on Computer supported cooperative work, P262
   Pallickara S, 2005, P IEEE ACM GRID 2005, P25
   Qiu Xiaohong., 2005, Message-based MVC Architecture for Distributed and Desktop Applications
   STEFIK M, 1987, ACM T INFORM SYST, V5, P147, DOI 10.1145/27636.28056
   SUN C, 1998, CSCW 98, P59
   Weiser Mark, 1991, SCI AM           SEP
   WU W, 2004, J NEURAL PARALLEL SC, V12, P391
   [No title captured]
NR 28
TC 5
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 213
EP 236
DI 10.1007/s11042-010-0508-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700009
DA 2024-07-18
ER

PT J
AU Badem, MB
   Fernando, WAC
   Kondoz, AM
AF Badem, M. B.
   Fernando, W. A. C.
   Kondoz, A. M.
TI Transform domain distributed video coding with spatial correlations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Wyner-Ziv coding
AB Distributed Video Coding is a new coding technique which has been evolving very fast recently. However the rate distortion performances of current solutions are below the expectations especially for high motion sequences even at a group of picture (GOP) size of 2. Main reason of this problem is the temporal prediction of the Wyner-Ziv (WZ) frames at the decoder. In this paper we propose a novel transform domain DVC codec architecture which splits each frame into two sub-frames and they are encoded separately as key sub-frame and WZ sub-frame. Pixel interpolation or median prediction techniques are utilized to generate the side information at the decoder. Simulation results show that a significant rate distortion improvement can be obtained with the proposed algorithm over the current DVC solutions.
C1 [Badem, M. B.; Fernando, W. A. C.; Kondoz, A. M.] Univ Surrey, Ctr Commun Syst Res, Guildford GU2 7XH, Surrey, England.
C3 University of Surrey
RP Badem, MB (corresponding author), Univ Surrey, Ctr Commun Syst Res, Guildford GU2 7XH, Surrey, England.
EM M.Badem@surrey.ac.uk; W.Fernando@surrey.ac.uk; A.Kondoz@surrey.ac.uk
CR Aaron A., 2002, P AS C SIGN SYST COM
   AARON A, 2003, P IEEE INT C IM PROC
   AARON A, 2004, P VCIP SAN JOS US
   ADIKARI ABB, 2006, IEE ELECT LETT, V42, P396
   [Anonymous], P 40 ALL C COMM CONT
   AREIA JD, 2008, ELMAR S ZAD CROAT
   Ascenso J, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P593
   ASCENSO J, IMPROVING FRAME INTE
   BERROU C, 1993, IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS 93 : TECHNICAL PROGRAM, CONFERENCE RECORD, VOLS 1-3, P1064, DOI 10.1109/ICC.1993.397441
   Brites C., 2006, P IEEE ICASSP, V2, P525
   DALAI M, 2006, P IEEE ICASSP, V3, P257
   GIROD B, 2003, P IEEE SPEC ISS ADV, V93, P1
   GUO X, 2006, P IEEE ISCAS
   Ishwar P, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P687
   NATARIO L, EXTRAPOLATING SIDE I
   SCHONBERG D, 2002, P ALL CON COMM CONTR
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   TAGLIASACCCHI M, 2005, VISUAL COMMUNICATION
   UNGERBOECK G, 1982, IEEE T INFORM THEORY, V28, P55, DOI 10.1109/TIT.1982.1056454
   WEERAKKODY WAR, 2006, P IEEE ICIP ATL US
   Wu B, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P165, DOI 10.1109/ICME.2006.262595
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Zhong H, 2005, IEEE T CIRCUITS-I, V52, P766, DOI 10.1109/TCSI.2005.844113
NR 23
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2010
VL 48
IS 3
SI SI
BP 369
EP 379
DI 10.1007/s11042-009-0317-5
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 587VP
UT WOS:000277023100002
DA 2024-07-18
ER

PT J
AU Chen, HT
   Tsai, WJ
   Lee, SY
AF Chen, Hua-Tsung
   Tsai, Wen-Jiin
   Lee, Suh-Yin
TI Contour-based strike zone shaping and visualization in broadcast
   baseball video: providing reference for pitch location positioning and
   strike/ball judgment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sports video; Semantic analysis; Game statistics; Visual enrichment;
   Object segmentation; Multimedia system
ID SPORTS VIDEO; FRAMEWORK; MOTION
AB The strike zone plays a crucial role in baseball. Pitches which pass through the strike zone count as strikes, three of which strike out the batter. Besides strike/ball judgment, the strike zone also provides the reference for positioning pitch locations, about which sports fans and professionals have an intense interest in compiling statistics. This paper presents contour-based strike zone shaping and visualization in broadcast baseball video. We first detect the home plate, which determines the vertical limits of the strike zone. Then, an efficient algorithm is designed for batter contouring and the points of curvature extremes on the batter's contour are computed to locate the dominant points which determine the horizontal limits of the strike zone. The experiments show that the proposed framework is able to shape the strike zone fairly well in various baseball sequences, needless of manual operation and additional camera setting. The proposed strike zone shaping and visualization will be able to assist in pitch analysis and statistics compiling.
C1 [Chen, Hua-Tsung; Tsai, Wen-Jiin; Lee, Suh-Yin] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, HT (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM huatsung@cs.nctu.edu.tw
CR [Anonymous], 2007, P 15 ACM INT C MULTI
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Chen HS, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1423
   Chen HT, 2008, IEEE INT SYMP CIRC S, P3522, DOI 10.1109/ISCAS.2008.4542219
   Chen HT, 2008, J INF SCI ENG, V24, P143
   Chen HT, 2007, INT CONF ACOUST SPEE, P1097
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   Denman H, 2003, COMPUT VIS IMAGE UND, V92, P176, DOI 10.1016/j.cviu.2003.06.005
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Guéziec A, 2002, COMPUTER, V35, P38, DOI 10.1109/2.989928
   Luo Y, 2003, COMPUT VIS IMAGE UND, V92, P196, DOI 10.1016/j.cviu.2003.08.001
   Mei T, 2008, MULTIMED TOOLS APPL, V40, P89, DOI 10.1007/s11042-007-0186-8
   Piegl L., 1997, The Nurbs Book, Vsecond
   *QUESTEC, UMP INF SYST
   Tien MC, 2007, INT CONF ACOUST SPEE, P1085
   Wang JR, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P102, DOI 10.1109/MMMC.2005.20
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   ZHONG D, 2001, P IEEE INT C MULT EX, P713
NR 21
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2010
VL 47
IS 2
BP 239
EP 255
DI 10.1007/s11042-009-0321-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 576IY
UT WOS:000276139000002
DA 2024-07-18
ER

PT J
AU Abhari, A
   Soraya, M
AF Abhari, Abdolreza
   Soraya, Mojgan
TI Workload generation for YouTube
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User generated content; YouTube; Web 2.0; Synthetic workload generator;
   Video on demand; Peer-to-peer
AB This paper introduces a workload characterization study of the most popular short video sharing service of Web 2.0, YouTube. Based on a vast amount of data gathered in a five-month period, we analyzed characteristics of around 250,000 YouTube popular and regular videos. In particular, we collected lists of related videos for each video clip recursively and analyzed their statistical behavior. Understanding YouTube traffic and similar Web 2.0 video sharing sites is crucial to develop synthetic workload generators. Workload simulators are required for evaluating the methods addressing the problems of high bandwidth usage and scalability of Web 2.0 sites such as YouTube. The distribution models, in particular Zipf-like behavior of YouTube popular video files suggests proxy caching of YouTube popular videos can reduce network traffic and increase scalability of YouTube Web site. YouTube workload characteristics provided in this work enabled us to develop a workload generator to evaluate the effectiveness of this approach.
C1 [Abhari, Abdolreza] Ryerson Univ, Dept Comp Sci, Toronto, ON M5B 2K3, Canada.
   [Soraya, Mojgan] Ryerson Univ, Dept Elect Engn, Toronto, ON M5B 2K3, Canada.
C3 Toronto Metropolitan University; Toronto Metropolitan University
RP Abhari, A (corresponding author), Ryerson Univ, Dept Comp Sci, Toronto, ON M5B 2K3, Canada.
EM aabhari@scs.ryerson.ca; msoraya@ryerson.ca
RI Abhari, Abdolreza/AAA-1577-2022
CR [Anonymous], 2007, IMC 07 P 2007 ACM SI, DOI DOI 10.1145/1298306.1298310
   [Anonymous], SIMULATION MODELING
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   CHATTOPADHYAY S, 2007, P 15 INT C MULT GERM
   Cheng X, 2007, ARXIV07073670V1CSNI
   Gomes L, 2006, WALL STREET J
   HALVEY MartinJ., 2007, P 16 INT C WORLD WID
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   *WIK, WALL STREET J
   *WIK, YOUTUBE VID FORM
   *YOUTUBE, API DOC
   ZINK M, 2008, P ACM SPIE MMCN 08 C, V6818, P5
NR 12
TC 67
Z9 72
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 1
BP 91
EP 118
DI 10.1007/s11042-009-0309-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 537DQ
UT WOS:000273093600005
DA 2024-07-18
ER

PT J
AU Buyukkaya, E
   Abdallah, M
AF Buyukkaya, Eliya
   Abdallah, Maha
TI Efficient triangulation for P2P networked virtual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Networked virtual environments; Peer-to-peer systems; Delaunay
   triangulation
AB Peer-to-peer (P2P) architectures have recently become a popular design choice for building scalable Networked Virtual Environments (NVEs). In P2P-based NVEs, system and data management is distributed among all participating users. Towards this end, a Delaunay Triangulation can be used to provide connectivity between the different NVE users depending on their positions in the virtual world. However, a Delaunay Triangulation clearly suffers from high maintenance cost as it is subject to high connection change rate due to continuous users' movement. In this paper, we propose a new triangulation algorithm that provides network connectivity to support P2P NVEs while dramatically decreasing maintenance overhead by reducing the number of connection changes due to users' insertion and movement. Performance evaluations show that our solution drastically reduces overlay maintenance cost in highly dynamic NVEs. More importantly, and beyond its quantitative advantages, this work questions the well accepted Delaunay Triangulation as a reference means for providing connectivity in NVEs, and paves the way for more research towards more practical alternatives for NVE applications.
C1 [Buyukkaya, Eliya; Abdallah, Maha] Univ Paris 06, LIP6, F-75016 Paris, France.
C3 Sorbonne Universite
RP Buyukkaya, E (corresponding author), Univ Paris 06, LIP6, 104 Ave President Kennedy, F-75016 Paris, France.
EM Eliya.Buyukkaya@lip6.fr; Maha.Abdallah@lip6.fr
CR [Anonymous], 2001, Pastry: Scalable, decentralized object location, and routing for large-scale peer-to-peer systems, DOI DOI 10.1007/3-540-45518-3_18
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   BUYUKKAYA E, 2008, P IEEE INT WORKSH DI, P1050
   Castro M, 2002, IEEE J SEL AREA COMM, V20, P1489, DOI 10.1109/JSAC.2002.803069
   de Berg M., 2000, COMPUTATIONAL GEOMET
   Frey D., 2008, INT WORKSHOP MASSIVE, P29
   Hu S.-Y., 2004, Proceedings of NetGames, Association for Computer Machinery, P129
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   HU SY, 2008, P NIME
   Iimura T., 2004, P 3 ACM SIGCOMM WORK, P116, DOI DOI 10.1145/1016540.1016549
   JIANG JR, 2008, P ICDCSW CDS
   Kawahara Y, 2002, ICCS 2002: 8TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS SYSTEMS, VOLS 1 AND 2, PROCEEDINGS, P957, DOI 10.1109/ICCS.2002.1183275
   Keller J, 2003, PDPTA'03: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING TECHNIQUES AND APPLICATIONS, VOLS 1-4, P262
   Knutsson B, 2004, IEEE INFOCOM SER, P96
   LIANG H, 2008, AVATAR MOBILITY NETW
   Varvello M., 2007, P 6 ACM SIGCOMM WORK, P105
   Yu A., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P99, DOI 10.1145/1065983.1066007
NR 17
TC 6
Z9 8
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 291
EP 312
DI 10.1007/s11042-009-0301-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900013
DA 2024-07-18
ER

PT J
AU Petlund, A
   Beskow, P
   Pedersen, J
   Paaby, ES
   Griwodz, C
   Halvorsen, P
AF Petlund, Andreas
   Beskow, Paul
   Pedersen, Jon
   Paaby, Espen Sogard
   Griwodz, Carsten
   Halvorsen, Pal
TI Improving SCTP retransmission delays for time-dependent thin streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Latency compensation; Networked games; Transport protocols; Thin streams
AB A large number of network services rely on IP and reliable transport protocols. For applications that provide abundant data for transmission, loss is usually handled satisfactorily, even if the application is latency-sensitive (Wang et al. 2004). For data streams where small packets are sent intermittently, however, applications can occasionally experience extreme latencies (Griwodz and Halvorsen 2006). As it is not uncommon that such thin-stream applications are time-dependent, any unnecessarily induced delay can have severe consequences for the service provided. Massively Multiplayer Online Games (MMOGs) are a defining example of thin streams. Many MMOGs (like World of Warcraft and Age of Conan) use TCP for the benefits of reliability, in-order delivery and NAT/firewall traversal. It has been shown that TCP has several shortcomings with respect to the latency requirements of thin streams because of the way it handles retransmissions (Griwodz and Halvorsen 2006). As such, an alternative to TCP may be SCTP (Stewart et al. 2000), which was originally developed to meet the requirements of signaling transport. In this paper, we evaluate the Linux-kernel SCTP implementation in the context of thin streams. To address the identified latency challenges, we propose sender-side only enhancements that reduce the application-layer latency in a manner that is compatible with unmodified receivers. These enhancements can be switched on by applications and are used only when the system identifies the stream as thin. To evaluate the latency performance, we have performed several tests over various real networks and over an emulated network, varying parameters like RTT, packet loss and amount of competing cross traffic. When comparing our modifications with SCTP on Linux and FreeBSD and TCP New Reno, our results show great latency improvements and indicate the need for a separate handling of thin and thick streams.
C1 [Petlund, Andreas; Beskow, Paul; Pedersen, Jon; Paaby, Espen Sogard; Griwodz, Carsten; Halvorsen, Pal] Simula Res Lab, N-1364 Fornebu, Norway.
   [Petlund, Andreas; Beskow, Paul; Pedersen, Jon; Paaby, Espen Sogard; Griwodz, Carsten; Halvorsen, Pal] Univ Oslo, Dept Informat, N-0373 Oslo, Norway.
C3 University of Oslo
RP Petlund, A (corresponding author), Simula Res Lab, Martin Linges Vei 17, N-1364 Fornebu, Norway.
EM apetlund@ifi.uio.no; paulbb@ifi.uio.no; jonped@ifi.uio.no;
   espensp@ifi.uio.no; griff@ifi.uio.no; paalh@ifi.uio.no
OI Halvorsen, Pal/0000-0003-2073-7029
CR ALLMAN M, 1999, 3390 RFC
   ALLMAN M, 2001, 3042 RFC
   [Anonymous], 2000, 2960 RFC
   Barford P., 1998, Performance Evaluation Review, V26, P151, DOI 10.1145/277858.277897
   BASTO V, 2005, INT NETW C INC
   BRENNAN R, 2001, P INT TEL C ITC 17
   CARDOSO K, 2002, HTTP TRAFFIC MODELIN
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   COENE L, 2006, 4166 RFC
   EKSTROM H, 2004, INFOCOM
   Fall K., 1996, Computer Communication Review, V26, P5, DOI 10.1145/235160.235162
   GRINNEMO K.-J., 2004, P ADV SIM TECHN C AS
   Griwodz Carsten., 2006, NOSSDAV 06, P1
   HARCSIK S, 2007, WORKSH NETW SYST SUP, P129
   *IKSCTP PROJ, 2004, LIN KERN STREAM CONT
   ITU-T Recommendation G.114,, 2003, G114 ONE WAY TRANSMI
   KARN P, 1988, COMPUT COMMUN REV, V17, P2
   LADHA S, 2004, ACM COMPUT COMMUN RE, V34, P23
   Ong L., 1999, 2719 RFC
   Parsa C., 1999, Proceedings Seventh International Conference on Network Protocols (ICNP'99), P213, DOI 10.1109/ICNP.1999.801940
   Paxson Vern., 2000, Computing tcp's retransmission timer
   Pedersen J, 2006, C LOCAL COMPUT NETW, P135
   SAT B, 2007, ACM INT MULT C ACM M, P137
   SHIRMOHAMMADI S, 2001, COMPUT NETWORKS, V35, P2
   Stewart R., 2004, Rfc3758: Stream control transmission protocol (sctp) partial reliability extension
   Wang B., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P908
   Woodcock B.S., 2009, ANAL MMOG SUBSCRIPTI
   Zink M., 2005, P ACM WORKSHOP END T, P37
NR 28
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 33
EP 60
DI 10.1007/s11042-009-0286-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900003
OA hybrid
DA 2024-07-18
ER

PT J
AU Hossain, MA
   Parra, J
   Atrey, PK
   El Saddik, A
AF Hossain, M. Anwar
   Parra, Jorge
   Atrey, Pradeep K.
   El Saddik, Abdulmotaleb
TI A framework for human-centered provisioning of ambient media services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Semantic Ambient Media Experience
CY OCT 31, 2008
CL Vancouver, CANADA
SP ACM
DE Ambient media; Context awareness; Personalization; Smart environment;
   Service provision; Smart phone
ID CONTEXT
AB The provisioning of ambient media in the user's environment requires that a system handles the different aspects related to the media selection process. For example, ambient media is delivered to the user depending on their context and hence, the system needs to dynamically determine the context and provide media that are relevant therein. To set the premise of ambient media, a system may also need to customize the physical environment, for example, by dimming the lighting level or by lowering the volume. Besides, users' need for media services changes over time and space that requires mechanisms to continually update their preferences based on their mobility in the environment. In this paper, we propose an ambient media service provisioning framework that incorporates the above requirements while keeping the user at the center of the media selection loop. To demonstrate the usefulness of this framework, we show experimental results by considering real-life scenario in a smart home environment.
C1 [Hossain, M. Anwar; El Saddik, Abdulmotaleb] Univ Ottawa, Sch Informat Technol & Engn, Multimedia Commun Res Lab, Ottawa, ON, Canada.
   [Parra, Jorge] Software Technol, Ikerlan Technol Res Ctr IK4, Arrasate Mondragon, Spain.
   [Atrey, Pradeep K.] Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
C3 University of Ottawa; University of Winnipeg
RP Hossain, MA (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Multimedia Commun Res Lab, Ottawa, ON, Canada.
EM anwar@mcrlab.uottawa.ca; JParra@ikerlan.es;
   P.K.Atreyp.atrey@uwinnipeg.ca; abed@mcrlab.uottawa.ca
RI ; /D-4159-2009; Hossain, M. Anwar/J-9601-2013
OI Parra, Jorge/0000-0001-6688-891X; /0000-0002-7690-8547; Hossain, M.
   Anwar/0000-0002-7673-8410
CR Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   Aroyo L, 2008, MULTIMED TOOLS APPL, V36, P71, DOI 10.1007/s11042-006-0078-3
   Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781
   Ducatel K., 2001, SCENARIOS AMBIENT IN
   Gellersen H.-W., 1999, Personal Technologies, V3, P199, DOI 10.1007/BF01540553
   Hossain MA, 2008, MOBILE NETW APPL, V13, P599, DOI 10.1007/s11036-008-0092-y
   HOSSAIN MA, 2008, P 1 ACM INT WORKSH S, P49
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Ishii H., 1998, P CHI 98 C SUMMARY H, P173, DOI DOI 10.1145/286498.286652
   Jaimes A, 2006, IEEE MULTIMEDIA, V13, P12, DOI 10.1109/MMUL.2006.8
   Jaimes A, 2007, COMPUTER, V40, P30, DOI 10.1109/MC.2007.169
   LUGMAYR A, 2007, TICSP ADJ P EUROITV, V35, P89
   Millard I, 2005, LECT NOTES COMPUT SC, V3479, P189, DOI 10.1007/11426646_18
   PARK MH, 2007, 4 INT C UB INT COMP, P549
   Qin WJ, 2008, LECT NOTES COMPUT SC, V5061, P187
   Resnick P, 2000, COMMUN ACM, V43, P45, DOI 10.1145/355112.355122
   Schilit B., 1994, 1994 1 WORKSHOP MOBI, P85, DOI [DOI 10.1109/WMCSA.1994.16, 10.1109/WMCSA.1994.16]
   Schmidt A, 1999, COMPUT GRAPH-UK, V23, P893, DOI 10.1016/S0097-8493(99)00120-X
   Ugalde JB, 2007, CONSUM COMM NETWORK, P885, DOI 10.1109/CCNC.2007.179
   *WIK, 2009, X10 WIK
   XU K., 2008, Proceedings of the IEEE Global Telecommunications Conf. (GLOBECOM 2008) (New Orleans, LA, USA, P1
   Yu ZW, 2006, IEEE PERVAS COMPUT, V5, P68, DOI 10.1109/MPRV.2006.61
   YU ZW, 2005, P 9 INT C KNOWL BAS, P236
   Zhu ML, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P324
   Zukerman I, 2001, USER MODEL USER-ADAP, V11, P5, DOI 10.1023/A:1011175525451
NR 25
TC 15
Z9 17
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 3
BP 407
EP 431
DI 10.1007/s11042-009-0285-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 474WB
UT WOS:000268313900005
DA 2024-07-18
ER

PT J
AU Notebaert, S
   De Cock, J
   Beheydt, S
   De Lameillieure, J
   Van De Walle, R
AF Notebaert, Stijn
   De Cock, Jan
   Beheydt, Samie
   De Lameillieure, Jan
   Van de Walle, Rik
TI Mixed architectures for H.264/AVC digital video transrating
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video signal processing; Transcoding; Transrating; Requantization;
   H.264/AVC
ID MPEG-2; REQUANTIZATION; COMPENSATION
AB In this paper, we investigate transrating architectures for H.264/AVC video streams. Basic architectures are presented with their strengths and weaknesses. None of the existing architectures provide an appropriate solution for H.264/AVC transrating with an optimal balance between visual quality and complexity. In order to find such an appropriate solution, we propose the use of mixed transrating architectures. These architectures combine different transrating techniques which are applied depending on the picture/macroblock type. The intra-predicted pictures are decoded and re-encoded, while open-loop transrating or transrating with compensation is applied to motion-compensated pictures. Performance results show that the mixed architecture which applies spatial compensation to motion-compensated pictures gives rate-distortion results which approach the cascade of decoder and re-encoder with a complexity only slightly higher than the open-loop transrater. Adding temporal compensation for motion-compensated pictures further improves the visual quality, albeit to a lower extent, at the expense of increased complexity.
C1 [Notebaert, Stijn; De Cock, Jan; Van de Walle, Rik] Univ Ghent, Dept Elect & Informat Syst, Multimedia Lab, IBBT, B-9050 Ledeberg Ghent, Belgium.
   [Beheydt, Samie; De Lameillieure, Jan] Cisco, Serv Provider Video Technol Grp, B-8500 Kortrijk, Belgium.
C3 Ghent University; Cisco Systems Inc
RP Notebaert, S (corresponding author), Univ Ghent, Dept Elect & Informat Syst, Multimedia Lab, IBBT, Gaston Crommenlaan 8,Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM stijn.notebaert@ugent.be
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT-Flanders); Fund for Scientific
   Research-Flanders (FWO-Flanders); European Union
FX The research activities that have been described in this paper were
   funded by Ghent University, the Interdisciplinary Institute for
   Broadband Technology (IBBT), the Institute for the Promotion of
   Innovation by Science and Technology in Flanders (IWT-Flanders), the
   Fund for Scientific Research-Flanders (FWO-Flanders), and the European
   Union.
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   De Cock J, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P448
   DECOCK J, 2007, P IEEE INT S SIGN PR
   DECOCK J, 2006, LECT NOTES COMPUTER
   Flierl M, 2003, IEEE T CIRC SYST VID, V13, P587, DOI 10.1109/TCSVT.2003.814963
   Fung KT, 2002, IEEE T IMAGE PROCESS, V11, P886, DOI 10.1109/TIP.2002.800890
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   *ITU T IEC JTC 1, 2003, H264 ITUT ISOIEC JTC
   Jones GA, 2006, P IEEE, V94, P22, DOI 10.1109/JPROC.2005.861003
   Keesman G, 1996, SIGNAL PROCESS-IMAGE, V8, P481, DOI 10.1016/0923-5965(95)00067-4
   Lefol D, 2006, IEEE T CONSUM ELECTR, V52, P215
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   NOTEBAERT S, 2006, LECT NOTES COMPUTER
   Qian TJ, 2006, IEEE T CIRC SYST VID, V16, P523, DOI 10.1109/TCSVT.2006.871392
   Schwarz H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1929, DOI 10.1109/ICME.2006.262934
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen B, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P317, DOI 10.1109/ICME.2006.262462
   Shen B, 2007, MULTIMED TOOLS APPL, V35, P163, DOI 10.1007/s11042-007-0127-6
   Shen GB, 2006, IEEE T CIRC SYST VID, V16, P1460, DOI 10.1109/TCSVT.2006.884008
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   Tourapis AM, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P700
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wedi T, 2003, IEEE T CIRC SYST VID, V13, P577, DOI 10.1109/TCSVT.2003.815171
   WEE S, 1997, IEEE WORKSH MULT SIG
   Werner O, 1999, IEEE T IMAGE PROCESS, V8, P179, DOI 10.1109/83.743853
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu YY, 2006, P IEEE, V94, P8, DOI 10.1109/JPROC.2005.861000
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Yin P, 2002, IEEE T CIRC SYST VID, V12, P1009, DOI 10.1109/TCSVT.2002.805509
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
NR 31
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2009
VL 44
IS 1
BP 39
EP 64
DI 10.1007/s11042-009-0273-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 457KJ
UT WOS:000266926600003
OA Green Published
DA 2024-07-18
ER

PT J
AU Sun, HM
   Shu, LC
AF Sun, Huey-Min
   Shu, LihChyun
TI Optimization scheduling of MPEG-4 FGS video coding stream under the
   feasible mandatory constraint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time scheduling; Imprecise computation; Optimization; MPEG-4 FGS
   framework
AB MPEG-4 video coding stream with Fine Granularity Scalability (FGS) can be flexibly dropped by very fine granularity so as to adapt to the available network bandwidth. The MPEG-4 FGS model is similar to the imprecise computation model originally proposed in the real-time scheduling field. In both models, it is required that all the mandatory tasks be completely scheduled before their deadlines even in the worst case, which is called the feasible mandatory constraint. The problem is how to maximize the number of the scheduled tasks based on the importance of tasks and to satisfy the feasible mandatory constraint. We adapt the existing unit-time tasks scheduling algorithm to address the problem by using a weighted assignment scheme that adds constant weights to mandatory tasks. Under the feasible mandatory constraint, we prove that the proposed algorithm maximizes the total weights of the scheduled tasks, and all mandatory tasks are guaranteed to be completely scheduled before their deadlines. The experimental results show the performance of the video quality for our scheduling algorithm by the measurements of Peak Signal to Noise Ratio (PSNR).
C1 [Shu, LihChyun] Natl Cheng Kung Univ, Dept Accounting, Tainan 701, Taiwan.
   [Sun, Huey-Min] Chang Jung Christian Univ, Dept Informat Management, Tainan 711, Taiwan.
C3 National Cheng Kung University; Chang Jung Christian University
RP Shu, LC (corresponding author), Natl Cheng Kung Univ, Dept Accounting, Tainan 701, Taiwan.
EM prince@mail.cjcu.edu.tw; shulc@mail.ncku.edu.tw
FU NSC [95-2221-E-309-014]
FX This work was supported, in part, by NSC grant NSC 95-2221-E-309-014.
CR [Anonymous], INTRO ALGORITHMS
   Baruah S. K., 1995, Proceedings 9th International Parallel Processing Symposium (Cat. No.95TH8052), P280, DOI 10.1109/IPPS.1995.395946
   Baruah SK, 1997, FOURTH INTERNATIONAL WORKSHOP ON REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P73, DOI 10.1109/RTCSA.1997.629176
   CHAKARESKI J, 2005, IEEE INT C MULT EXP, P1066
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   FENG WC, 1995, COMPUT COMMUN, V18, P709, DOI 10.1016/0140-3664(95)98484-M
   FENG WC, 1997, 16 ANN JOINT C IEEE, V1
   Gao K, 2003, PIMRC 2003: 14TH IEEE 2003 INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS PROCEEDINGS, VOLS 1-3 2003, P2711, DOI 10.1109/PIMRC.2003.1259232
   Gao K, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P824
   GAO K, 2003, 4 PAC RIM C MULT INF, V3, P1351
   HAMDAOUI M, 1995, IEEE T COMPUT, V44, P1443, DOI 10.1109/12.477249
   Koren G, 1995, IEEE REAL TIME, P110, DOI 10.1109/REAL.1995.495201
   Kozlovsky AM, 2005, PETROLOGY+, V13, P16
   Lai HL, 2005, IEEE T CIRC SYST VID, V15, P221, DOI 10.1109/TCSVT.2004.841687
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   LIU GJ, 1991, MACROMOLECULES, V24, P68, DOI 10.1021/ma00001a011
   *MICR, 2004, 14496 ISOIEC
   Moir M., 1999, Proceedings 20th IEEE Real-Time Systems Symposium (Cat. No.99CB37054), P294, DOI 10.1109/REAL.1999.818857
   Özcelebi T, 2007, IEEE J SEL AREA COMM, V25, P760, DOI 10.1109/JSAC.2007.070512
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   SHIH WK, 1989, REAL-TIME SYSTEMS SYMPOSIUM, PROCEEDINGS, P12
   SUN HM, 2005, 18 IPPR C COMP VIS G, P1475
   WEST R, 2000, P 21 IEEE REAL TIM S
   Wu J, 2007, IEEE SIGNAL PROC LET, V14, P715, DOI 10.1109/LSP.2007.896376
   Zhang H., 2008, IEEE INT C MULT EXP
   Zhang JB, 1998, COMPUT COMMUN, V21, P375, DOI 10.1016/S0140-3664(97)00170-9
NR 27
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2009
VL 44
IS 1
BP 111
EP 131
DI 10.1007/s11042-009-0279-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 457KJ
UT WOS:000266926600006
DA 2024-07-18
ER

PT J
AU Ah-Pine, J
   Bressan, M
   Clinchant, S
   Csurka, G
   Hoppenot, Y
   Renders, JM
AF Ah-Pine, Julien
   Bressan, Marco
   Clinchant, Stephane
   Csurka, Gabriela
   Hoppenot, Yves
   Renders, Jean-Michel
TI Crossing textual and visual content in different application scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-image information processing; Trans-media similarities;
   Cross-content information retrieval and browsing; Image auto-annotation;
   Multimedia document generation
AB This paper deals with multimedia information access. We propose two new approaches for hybrid text-image information processing that can be straightforwardly generalized to the more general multimodal scenario. Both approaches fall in the trans-media pseudo-relevance feedback category. Our first method proposes using a mixture model of the aggregate components, considering them as a single relevance concept. In our second approach, we define trans-media similarities as an aggregation of monomodal similarities between the elements of the aggregate and the new multimodal object. We also introduce the monomodal similarity measures for text and images that serve as basic components for both proposed trans-media similarities. We show how one can frame a large variety of problem in order to address them with the proposed techniques: image annotation or captioning, text illustration and multimedia retrieval and clustering. Finally, we present how these methods can be integrated in two applications: a travel blog assistant system and a tool for browsing the Wikipedia taking into account the multimedia nature of its content.
C1 [Ah-Pine, Julien; Bressan, Marco; Clinchant, Stephane; Csurka, Gabriela; Hoppenot, Yves; Renders, Jean-Michel] Xerox Res Ctr Europe, F-38240 Meylan, France.
C3 Xerox
RP Csurka, G (corresponding author), Xerox Res Ctr Europe, 6 Chem Maupertuis, F-38240 Meylan, France.
EM Gabriela.Csurka@xrce.xerox.com
RI Bressan, Marco/G-6997-2018
OI Ah-Pine, Julien/0000-0001-6898-3961
CR AHPINE J, 2008, 2008 CLEF WORKSH AAR
   [Anonymous], 2001, CIKM
   [Anonymous], CVPR
   [Anonymous], 1999, 1 INT WORKSHOP MULTI
   [Anonymous], 1998, SIGIR
   [Anonymous], CVPR
   [Anonymous], 2007, CVPR
   [Anonymous], 2003, **NON-TRADITIONAL**
   [Anonymous], P 14 INT WORLD WID W
   [Anonymous], 2004, ECCV WORKSHOPS
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei D.M., 2003, ACM SIGIR
   Carbonetto P., 2004, ECCV
   CHANG YC, 2006, CLEF 2006 WORKING NO
   CLINCHAT S, 2007, 2007 CLEF WORKSH
   Duygulu Pinar., 2002, ECCV
   Feng S.L., 2004, CVPR
   Grubinger M., 2007, 2007 CLEF WORKSH
   IYENGAR G, 2005, P ACM MULT SING 6 11
   Jeon J., 2003, ACM SIGIR
   LI J, 2005, CVPR 05, V2, P1208
   Li Li-Jia., 2007, CVPR
   LI X, 2006, P 14 ANN ACM INT C M
   MAILLOT N, 2006, CLEF 2006 WORKING NO
   MONAY F, 2004, ACM MM
   PAN J, 2004, CVPR WORKSH MULT DAT
   Rocchio J., 1971, SMART RETRIEVAL SYST, P313
   Tao T., 2006, SIGIR 06
   Vinokourov A., 2003, 4 INT S IND COMP AN
   YANAI K, 2005, P ACM MULT WORKSH MU
NR 30
TC 24
Z9 26
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2009
VL 42
IS 1
SI SI
BP 31
EP 56
DI 10.1007/s11042-008-0246-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 403XX
UT WOS:000263116400003
DA 2024-07-18
ER

PT J
AU Bustos, B
   Navarro, G
AF Bustos, Benjamin
   Navarro, Gonzalo
TI Improving the space cost of <i>k</i>-NN search in metric spaces by using
   distance estimators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity search; Metric spaces; k-NN search
ID SIMILARITY SEARCH; INDEX
AB Similarity searching in metric spaces has a vast number of applications in several fields like multimedia databases, text retrieval, computational biology, and pattern recognition. In this context, one of the most important similarity queries is the k nearest neighbor (k-NN) search. The standard best-first k-NN algorithm uses a lower bound on the distance to prune objects during the search. Although optimal in several aspects, the disadvantage of this method is that its space requirements for the priority queue that stores unprocessed clusters can be linear in the database size. Most of the optimizations used in spatial access methods (for example, pruning using MinMaxDist) cannot be applied in metric spaces, due to the lack of geometric properties. We propose a new k-NN algorithm that uses distance estimators, aiming to reduce the storage requirements of the search algorithm. The method stays optimal, yet it can significantly prune the priority queue without altering the output of the query. Experimental results with synthetic and real datasets confirm the reduction in storage space of our proposed algorithm, showing savings of up to 80% of the original space requirement.
C1 [Bustos, Benjamin; Navarro, Gonzalo] Univ Chile, Dept Comp Sci, Ctr Web Res, Santiago, Chile.
C3 Universidad de Chile
RP Bustos, B (corresponding author), Univ Chile, Dept Comp Sci, Ctr Web Res, Santiago, Chile.
EM bebustos@dcc.uchile.cl; gnavarro@dcc.uchile.cl
RI Navarro, Gonzalo/J-3731-2016; Bustos, Benjamin/G-1170-2010
OI Bustos, Benjamin/0000-0002-3955-361X
CR [Anonymous], 1995, P 1995 ACM SIGMOD IN, DOI DOI 10.1145/223784.223794
   [Anonymous], 2006, ADV DATABASE SYSTEMS
   Baroni M, 2007, J CHEM INF MODEL, V47, P279, DOI 10.1021/ci600253e
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Bustos B, 2006, INT J DIGIT LIBRARIE, V6, P39, DOI 10.1007/s00799-005-0122-3
   Chávez E, 2005, PATTERN RECOGN LETT, V26, P1363, DOI 10.1016/j.patrec.2004.11.014
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Dohnal V, 2003, MULTIMED TOOLS APPL, V21, P9, DOI 10.1023/A:1025026030880
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279
   HETTICH S, 1999, UCI KDD ARCHIVE
   Hinneburg A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506
   Hjaltason G., 2000, CSTR4199 U MAR COMP
   Hjaltason GR, 2003, ACM T DATABASE SYST, V28, P517, DOI 10.1145/958942.958948
   Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83
   Keim DA, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P419, DOI 10.1145/304181.304219
   Navarro G, 2002, VLDB J, V11, P28, DOI 10.1007/s007780200060
   Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365
   Samet H, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P486, DOI 10.1109/ICIAP.2003.1234097
   Samet H, 2006, FDN MULTIDIMENSIONAL
   Santos RF, 2001, PROC INT CONF DATA, P623, DOI 10.1109/ICDE.2001.914877
   UHLMANN J, 1991, 5570 NRL
NR 23
TC 7
Z9 8
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 2
BP 215
EP 233
DI 10.1007/s11042-008-0226-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387NI
UT WOS:000261958500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Furini, M
AF Furini, Marco
TI Digital audiobook: from passive to active pursuit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE entertainment applications; interactive applications
AB The digital home entertainment market is growing at an exceptional speed and, although limited to passive listeners, audiobook applications are growing at an annual rate of nearly 20% and hence are playing an important role inside this market. In this paper we propose an architecture to produce interactive audiobooks, so as to transform a passive listener into a story director. Our approach allows interacting with the storyline and the story develops according to the user choices. To ensure transparency the approach uses AAC/MP3 format for the audio stream encoding, the MPEG7 MDS for the audio description and the ISO Base Media File Format for the audiobook file format. A security mechanism protects contents from piracy and malicious alterations. The simplicity of our approach, along with the growing usage of portable devices, may increase the attractiveness and the popularity of audiobooks.
C1 Univ Piemonte Orientale, I-15100 Alessandria, Italy.
C3 University of Eastern Piedmont Amedeo Avogadro
RP Furini, M (corresponding author), Univ Piemonte Orientale, I-15100 Alessandria, Italy.
EM marco.furini@mfn.unipmn.it
RI Furini, Marco/O-2867-2016
OI Furini, Marco/0000-0003-1094-6521
CR BAREL H, 2004, P 2 IEEE SEC MOB COM
   BIDDLE K, 2002, P ACM WORKSH DIG RIG
   CHENG S, 2002, P IEEE INT C AC SPEE, V4, P3728
   FURINI M, 2007, P IEEE CONS COMM NET
   He S., 2004, P 38 C INF SCI SYST, P827
   Li X, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P397, DOI 10.1109/ICME.2000.869624
   LI X, 2000, ITCC, P74
   McIvor C, 2003, CONF REC ASILOMAR C, P379
   MERMELSTEIN B, 2005, P IEEE INT WORKSH WI, P359
   *MPEG, 2002, MPEG 4 OV
   NIKLAS KHM, 2006, LNCS, V4326, P358
   Ravi S., 2004, ACM T EMBED COMPUT S, V3, P461, DOI [DOI 10.1145/1015047.1015049, 10.1145/1015047.1015049]
   SCHNEIDER O, 2002, P INT C CENTR EUR CO, P405
   SCHONBERG D, 2004, MULTIMEDIA 04, P788
   Seok J, 2002, ETRI J, V24, P181, DOI 10.4218/etrij.02.0102.0301
   Theotokis D., 1997, SIGCSE Bulletin, V29, P111, DOI 10.1145/268809.268852
NR 16
TC 7
Z9 7
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2008
VL 40
IS 1
BP 23
EP 39
DI 10.1007/s11042-007-0183-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 339KO
UT WOS:000258576700002
DA 2024-07-18
ER

PT J
AU Gennaro, C
AF Gennaro, Claudio
TI Regia: a metadata editor for audiovisual documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE metadata; metadata editor; IFLA/FRBR; audiovisual content; digital video
   library; MPEG-7
AB Although the Metadata Editor is an important part of any digital library, it becomes fundamental in the presence of audiovisual content. This is because the metadata produced by automated support tools (such as speech recognizers and shot detection procedures) is error-prone and often needs correction. In addition, scenes are manually annotated. This paper describes Regia, a prototype application for manually editing metadata for audiovisual documents developed in the ECHO project. Regia allows the user to manually edit textual metadata and to hierarchically organize the segmentation of the audiovisual content. An important feature of this metadata editor is that it is not hard-wired with a particular metadata attributes set. To achieve this feature the XML schema of the metadata model is used by the editor as a configuration file.
C1 CNR, ISTI, I-56100 Pisa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)
RP Gennaro, C (corresponding author), CNR, ISTI, I-56100 Pisa, Italy.
EM claudio.gennaro@isti.cnr.it
RI Gennaro, Claudio/AAH-5171-2019
OI Gennaro, Claudio/0000-0002-3715-149X
CR AGIUS H, 2004, SAC 04, P1248
   AGNEW G, 2003, SURA VIDE 5 ANN DIG
   Amato G, 2004, LECT NOTES COMPUT SC, V3232, P14
   AMATO G, 2000, P 4 EUR C ECDL, P328
   FATEMI N, 2001, P 8 INT C MULT MOD M, P49
   MUNCHEN KGS, 1998, FUNCTIONAL REQUIREME
   Ryu Jeewoong., 2002, MULTIMEDIA'02: Proceedings of the tenth ACM international conference on Multimedia, P267
   Schroeter R, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P346, DOI 10.1109/MULMM.2004.1265006
   YAO A, 2001, CRPITS 00, P39
   *ZGDV, V2DET3 V2D DESCR TOO
NR 10
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2008
VL 36
IS 3
BP 185
EP 201
DI 10.1007/s11042-007-0129-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 249TV
UT WOS:000252253600001
DA 2024-07-18
ER

PT J
AU Peng, YX
   Ngo, CW
   Xiao, JG
AF Peng, Yuxin
   Ngo, Chong-Wah
   Xiao, Jianguo
TI OM-based video shot retrieval by one-to-one matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Intelligent Multimedia Computing and
   Networking
CY JUL, 2005
CL Salt Lake City, UT
DE shot-based retrieval; OM; color and motion similarity
ID QUERY
AB This paper proposes a new approach for shot-based retrieval by optimal matching (OM), which provides an effective mechanism for the similarity measure and ranking of shots by one-to-one matching. In the proposed approach, a weighted bipartite graph is constructed to model the color similarity between two shots. Then OM based on Kuhn-Munkres algorithm is employed to compute the maximum weight of a constructed bipartite graph as the shot similarity value by one-to-one matching among frames. To improve the speed efficiency of OM, two improved algorithms are also proposed: bipartite graph construction based on subshots and bipartite graph construction based on the same number of keyframes. Besides color similarity, motion feature is also employed for shot similarity measure. A motion histogram is constructed for each shot, the motion similarity between two shots is then measured by the intersection of their motion histograms. Finally, the shot similarity is based on the linear combination of color and motion similarity. Experimental results indicate that the proposed approach achieves better performance than other methods in terms of ranking and retrieval capability.
C1 Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Peking University; City University of Hong Kong
RP Peng, YX (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM pengyuxin@icst.pku.edu.cn; cwngo@cs.cityu.edu.hk;
   xiaojianguo@icst.pku.edu.cn
RI Peng, Yuxin/U-7376-2019; Xiao, Jian/GYU-4351-2022; peng,
   yu/GXW-2071-2022
OI Ngo, Chong Wah/0000-0003-4182-8261
CR [Anonymous], 2003, Combinatorial optimization: polyhedra and efficiency
   CHEN L, 2001, INT C MULT EXP
   Deng Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P534, DOI 10.1109/ICIP.1997.638826
   Fan JP, 2004, IEEE T MULTIMEDIA, V6, P70, DOI 10.1109/TMM.2003.819583
   HAUPTMANN A, CONFOUNDED EXPECTION
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   LIENHART R, 1998, SPIE C STOR RETR IM, P271
   Lin T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P592, DOI 10.1109/ICIP.2001.958188
   LIU X, 1998, ACM MULT C
   *MPEG VID GROUP, 1999, MPEG98M2819 ISOMPEGJ
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   Ngo CW, 2001, IEEE T CIRC SYST VID, V11, P941, DOI 10.1109/76.937435
   OVER P, TREC 2005 VIDEO RETR
   Peng YX, 2006, IEEE T CIRC SYST VID, V16, P612, DOI 10.1109/TCSVT.2006.873157
   SMEATON A, TRECVID 2005 SEARCH
   SMEATON A, TRECVID 2004 SEARCH
   SOUVANNAVONG F, 2004, 6 ACM INT WORKSH MUL, P243
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Taskiran C, 2004, IEEE T MULTIMEDIA, V6, P103, DOI 10.1109/TMM.2003.819783
   WU Y, 2000, ACM MULT C
   XIAO WS, 1993, GRAPH THEORY ITS ALG
   Yuan J., 2004, PROC ACM MULTIMEDIA, P61, DOI DOI 10.1145/1026711.1026722
   ZHAO L, 2000, ACM SIGMM INT WORKSH
NR 23
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2007
VL 34
IS 2
BP 249
EP 266
DI 10.1007/s11042-006-0085-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 178AX
UT WOS:000247194700008
OA Green Published
DA 2024-07-18
ER

PT J
AU Ryu, SH
   Kim, HJ
   Park, JS
   Kwon, YW
   Jeong, CS
AF Ryu, So-Hyun
   Kim, Hyung-Jun
   Park, Jin-Sung
   Kwon, Yong-won
   Jeong, Chang-Sung
TI Collaborative object-oriented visualization environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Workshop on Groupware
CY SEP 28-OCT 02, 2003
CL AUTRANS, FRANCE
SP CNRS, Inst Informat & Math Appl Grenoble, Conseil Reg Rhone Alpes, Mairie Grenoble, Conseil Gen Savoie, Inst Natl Polytech Grenoble, Univ Savoie, Univ Joseph Fourier, CINVESTAV IPAN, CICESE
DE collaborative visualization; parallel computing; distributed object
AB In this paper, we present a Collaborative Object-oriented Visualization Environment (COVE) which provides a flexible and extensible framework for collaborative visualization. COVE integrates collaborative and parallel computing environments based on a distributed object model. It is built as a collection of concurrent objects: collaborative and application objects which interact with one another to construct collaborative parallel computing environments. The former enables COVE to execute various collaborative functions, while the latter allows it to execute fast parallel visualization in various modes. Also, flexibility and extensibility are provided by plugging the proper application objects into COVE at run-time, and making them interact with one another through collaboration objects. For our experiment, three visualization modes for volume rendering are designed and implemented to support the fast and flexible analysis of volume data in a collaborative environment.
C1 Korea Univ, Dept Elect Engn, Seoul 136701, South Korea.
C3 Korea University
RP Jeong, CS (corresponding author), Korea Univ, Dept Elect Engn, 5 Ka, Seoul 136701, South Korea.
EM csjeong@charlie.korea.ac.kr
CR Anupam V., 1993, Proceedings ACM Multimedia 93, P447, DOI 10.1145/166266.168458
   ANUPAM V, 1995, THESIS U PURDUE INDI
   Corbit M., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P65, DOI 10.1145/351006.351014
   DANSKIN J, 1970, J THEOR BIOL, V29, P471
   DEOLIVEIRA JC, 2000, VIRTUAL REALITY 2000, P288
   DONGARRA J, 1994, INT J SUPERCOMPUT AP, V8, P165, DOI 10.1177/109434209400800301
   Downing T., 1998, JAVA RMI REMOTE METH
   Foster I, 2000, INT WORKSH QUAL SERV, P181, DOI 10.1109/IWQOS.2000.847954
   FRANK E, 1997, DCOM MICROSOFT DISTR
   FREY J, 2002, UNPUB OPEN GRID SERV
   GEIST A, 1994, ORNLTM12187
   Goel V, 1996, VISUAL COMPUT, V12, P26
   ISENHOUR PL, 1997, IEEE VIS 97 LAT BREA
   JO SU, 2000, PARALLEL VOLUME VISU, P398
   Kim HD, 2000, LECT NOTES COMPUT SC, V1823, P12
   Kose C, 1997, PARALLEL COMPUT, V23, P943, DOI 10.1016/S0167-8191(97)00036-7
   LEVOY M, 1990, IEEE COMPUT GRAPH, V10, P33, DOI 10.1109/38.50671
   Lewis M, 1996, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, P551, DOI 10.1109/HPDC.1996.546226
   *OBJ MAN GROUP INC, 1998, 22 OMG INC
   Pang A, 1997, IEEE COMPUT GRAPH, V17, P32, DOI 10.1109/38.574676
   Shirmohammadi S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P541, DOI 10.1109/MMCS.1997.609767
   TURNER S, 2000, CVE 2000 ACM NEW YOR, P209
   WANG W, 2001, VRST 01 BAN ALB CAN, P25
   Woo YJ, 2003, LECT NOTES COMPUT SC, V2668, P562
   YUN TH, 1997, P 1997 PAC WORKSH DI
NR 25
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2007
VL 32
IS 2
BP 209
EP 234
DI 10.1007/s11042-006-0066-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 129ZR
UT WOS:000243769100005
DA 2024-07-18
ER

PT J
AU Shahabi, C
   Safar, M
AF Shahabi, Cyrus
   Safar, Maytham
TI An experimental study of alternative shape-based image retrieval
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE shape representation; shape similarity; similarity measure; image
   retrieval
AB Besides traditional applications (e.g., CAD/CAM and Trademark registry), new multimedia applications such as structured video, animation, and MPEG-7 standard require the storage and management of well-defined objects. These object databases are then queried and searched for different purposes. A sample query might be "find all the scenes that contain a certain object." Shape of an object is an important feature for image and multimedia similarity retrievals. Therefore, in this study we focus on shape-based object retrieval and conduct a comparison study on four of such techniques (i.e., Fourier descriptors, grid based, Delaunay triangulation, and our proposed MBC-based methods (e.g., MBC-TPVAS)). We measure the effectiveness of the similarity retrieval of the four different shape representation methods in terms of recall and precision. Our results show that the similarity retrieval accuracy of our method (MBC-TPVAS) is as good as that of the other methods, while it observes the lowest computation cost to generate the shape signatures of the objects. Moreover, it has low storage requirement, and a comparable computation cost to compute the similarity between two shape signatures. In addition, MBC-TPVAS requires no normalization of the objects, and is the only method that has direct support for S-RST query types. In this paper, we also propose a new shape description taxonomy.
C1 Univ So Calif, Dept Comp Sci, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
   Kuwait Univ, Dept Comp Engn, Kuwait, Kuwait.
C3 University of Southern California; Kuwait University
RP Shahabi, C (corresponding author), Univ So Calif, Dept Comp Sci, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
EM shahabi@usc.edu; maytham@eng.kuniv.edu.kw
RI Safar, Maytham H/E-9238-2010; Shahabi, Cyrus/C-5199-2014
OI Shahabi, Cyrus/0000-0001-9118-0681
CR AGRAWAL R, 1993, P INT C FODO CHIC IL
   BERCHTOLD S, 1997, P ACM SIGMOD INT C M, P333
   EAKINS JP, 1994, P INT C EL LIB VIS I, P101
   FALOUTSOS C, 1994, P ACM SIGMOD INT C M
   GARY J, 1993, P INT C DAT ENG ICDE, P108
   GARY JM, 1995, IEEE COMPUT, V28, P57
   GHANDEHARIZADEH.S, 1995, MULTIMEDIA DB SYSTEM
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926
   JAGADISH HV, 1991, P ACM SIGMOD INT C M, P208
   Korn F, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P215
   Lu GJ, 1999, MULTIMEDIA SYST, V7, P165, DOI 10.1007/s005300050119
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Mokhtarian F., 1996, Proceedings of International Workshop on Image Databases and Multimedia Search, P35
   Pitas I., 1993, DIGITAL IMAGE PROCES
   Sajjanhar A., 1998, International Conference on Computational Intelligence and Multimedia Applications 1998. ICCIMA 1998, P854
   Sajjanhar A, 1997, AUST COMPUT J, V29, P131
   Sajjanhar A, 1997, P SOC PHOTO-OPT INS, V3164, P188, DOI 10.1117/12.279554
   SAJJANHAR A, 1997, P 2 AUSTR DOC COMP S, P46
   Shahabi C, 1999, PROC INT CONF DATA, P259, DOI 10.1109/ICDE.1999.754939
   Shahabi C, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P611, DOI 10.1109/MMCS.1999.779270
   Sul CW, 1998, IEEE MULTIMEDIA, V5, P42, DOI 10.1109/93.682524
   Tan C.H., 2000, P IEEE INT DAT ENG A
   TAO Y, 1999, P 7 SPIE S STOR RETR, P631
   TAO Y, 1999, P INT C DAT SEM DS, V8, P59
NR 25
TC 14
Z9 15
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2007
VL 32
IS 1
BP 29
EP 48
DI 10.1007/s11042-006-0070-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 119YC
UT WOS:000243049400002
DA 2024-07-18
ER

PT J
AU Cha, KA
   Kim, S
AF Cha, KA
   Kim, S
TI MPEG-4 STUDIO: An object-based authoring system for MPEG-4 contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-4 contents; MPEG-4 content authoring; multimedia authoring; MPEG-4
   systems
ID MULTIMEDIA STANDARD; MODELS; TIME
AB An MPEG-4 audio-visual scene is composed of various types of media data represented as individual objects. It includes a scene description that refers to the spatio-temporal specification and behavior of individual objects. In this paper, we propose an MPEG-4 contents authoring system for generating MPEG-4 audio-visual scenes, by providing the visual environment for building the spatio-temporal scenario of media objects comprising the scene. The system, called MPEG-4 STUDIO, provides a comprehensive set of facilitative editing tools for composing MPEG-4 scenes, as well as tools for the automatic generation of creative MPEG-4 contents. The system's authoring environment and the process of generating MPEG-4 contents are presented in detail.
C1 Kyungpook Natl Univ, Dept Comp Sci, Comp Languages & Multimedia Lab, Taegu, South Korea.
C3 Kyungpook National University
RP Cha, KA (corresponding author), Informat & Commun Univ, Taejon, South Korea.
EM chaka@woorisol.knu.ac.kr; swkim@woorisol.knu.ac.kr
CR *AD, PREM 6 0
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], 2001, JTC1SC29WG11N4030 IS
   [Anonymous], 1997, 147722 ISOIEC
   Battista S, 1999, IEEE MULTIMEDIA, V6, P74, DOI 10.1109/93.809236
   Bertino E, 2000, IEEE T KNOWL DATA EN, V12, P102, DOI 10.1109/69.842254
   Bertino E, 1998, IEEE T KNOWL DATA EN, V10, P612, DOI 10.1109/69.706060
   CANDAN K, 1996, P 4 ACM INT MULT C B, P329
   DARAS P, 2001, P 2 INT WORKSH DIG C
   Dospisil J, 2000, COMPUT COMMUN, V23, P1484, DOI 10.1016/S0140-3664(00)00192-4
   HARDMAN L, 1994, COMMUN ACM, V37, P50, DOI 10.1145/175235.175239
   HIRZALLA N, 1995, IEEE MULTIMEDIA, V2, P24, DOI 10.1109/93.410508
   *ISO IEC, 2000, JTC1SC29WG11N3747 IS
   *ISO IEC, 1997, 10744 ISOIEC
   *ISO IEC, 1999, 144961 ISOIEC 1
   Kneip J, 1999, IEEE MICRO, V19, P64, DOI 10.1109/40.809379
   Kwon YM, 1999, DATA KNOWL ENG, V30, P217, DOI 10.1016/S0169-023X(99)00012-9
   LITTLE TDC, 1993, IEEE T KNOWL DATA EN, V5, P551, DOI 10.1109/69.234768
   Puri A., 1998, Mobile Networks and Applications, V3, P5, DOI 10.1023/A:1019160312366
   Song JW, 1999, MULTIMEDIA SYST, V7, P424, DOI 10.1007/s005300050143
NR 20
TC 6
Z9 6
U1 0
U2 4
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2005
VL 25
IS 1
BP 111
EP 131
DI 10.1023/B:MTAP.0000046384.83647.54
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 866VY
UT WOS:000224802700005
DA 2024-07-18
ER

PT J
AU Snoek, CGM
   Worring, M
AF Snoek, CGM
   Worring, M
TI Multimodal video indexing: A review of the state-of-the-art
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE review; multimodal video indexing; video segmentation; multimodal
   integration; analysis framework
ID HIDDEN MARKOV-MODELS; DETECTING FACES; RETRIEVAL; AUDIO; TEXT;
   CLASSIFICATION; SPEECH; IMAGES; SEGMENTATION; RECOGNITION
AB Efficient and effective handling of video documents depends on the availability of indexes. Manual indexing is unfeasible for large video collections. In this paper we survey several methods aiming at automating this time and resource consuming process. Good reviews on single modality based video indexing have appeared in literature. Effective indexing, however, requires a multimodal approach in which either the most appropriate modality is selected or the different modalities are used in collaborative fashion. Therefore, instead of separately treating the different information sources involved, and their specific algorithms, we focus on the similarities and differences between the modalities. To that end we put forward a unifying and multimodal framework, which views a video document from the perspective of its author. This framework forms the guiding principle for identifying index types, for which automatic methods are found in literature. It furthermore forms the basis for categorizing these different methods.
C1 Univ Amsterdam, Inst Informat, Intelligent Sensory Informat Syst, NL-1098 SJ Amsterdam, Netherlands.
C3 University of Amsterdam
RP Univ Amsterdam, Inst Informat, Intelligent Sensory Informat Syst, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.
EM cgmsnoek@science.uva.nl; worring@science.uva.nl
RI Worring, Marcel/JRW-7059-2023
OI Worring, Marcel/0000-0003-4097-4136; Snoek, Cees/0000-0001-9092-1556
CR Abney S, 1997, TEXT SPEECH LANG TEC, V2, P118
   Adali S, 1996, MULTIMEDIA SYST, V4, P172, DOI 10.1007/s005300050021
   Alatan AA, 2001, MULTIMED TOOLS APPL, V14, P137, DOI 10.1023/A:1011395131992
   Altunbasak Y, 1998, GRAPH MODEL IM PROC, V60, P13, DOI 10.1006/gmip.1997.0453
   [Anonymous], 1998, IEEE INT WORKSH CONT
   [Anonymous], IMAGE VIDEO DATABASE
   [Anonymous], **NON-TRADITIONAL**
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   ARACENO C, 1998, IEEE INT C IM PROC C
   Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bertini M, 2001, PATTERN RECOGN LETT, V22, P503, DOI 10.1016/S0167-8655(00)00113-6
   Bikel DM, 1999, MACH LEARN, V34, P211, DOI 10.1023/A:1007558221122
   BOGGS J, 2000, ART WATCHING FILMS
   Bolle RM, 1998, IBM J RES DEV, V42, P233, DOI 10.1147/rd.422.0233
   BONZANINI A, 2001, IEEE C MULT EXP, P1208
   BROWN M, 1995, ACM MULTIMEDIA 1995
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   Christel MG, 2000, IEEE MULTIMEDIA, V7, P60, DOI 10.1109/93.839312
   Colombo C, 1999, IEEE MULTIMEDIA, V6, P38, DOI 10.1109/93.790610
   DAVENPORT G, 1991, IEEE COMPUT GRAPH, V11, P67, DOI 10.1109/38.126883
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dimitrova N., 2000, EUR SIGN PROC C TAMP
   Eickeler S, 1999, INT CONF ACOUST SPEE, P2997, DOI 10.1109/ICASSP.1999.757471
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   FISCHER S, 1995, ACM MULTIMEDIA, P295
   Furht B., 1996, VIDEO IMAGE PROCESSI
   GHIAS A, 1995, ACM MULTIMEDIA 1995
   GONG Y, 1995, IEEE INT C MULT COMP, P167
   GUNSEL B, 1996, 3 IEEE WORKSH APPL C
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   HAMPAPUR A, 1995, IFIP 2 6 3 WORK C VI
   HANJALIC A, 2001, IS T SPIE ELECT IMAG
   HAUPTMANN AG, 1998, ADV DIGITAL LIB, P168
   HAUPTMANN AG, 1999, ACM DL SIGIR MIDAS W
   HUANG J, 1999, IEEE WORKSH MULT SIG
   IDE I, 1999, LECT NOTES COMPUTER, V1554
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jain R., 1994, SIGMOD Record, V23, P27, DOI 10.1145/190627.190638
   Jang PJ, 1999, IEEE INTELL SYST APP, V14, P51, DOI 10.1109/5254.796090
   Jasinschi RS, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P366, DOI 10.1109/ICIP.2001.958127
   JAVED O, 2001, IEEE INT C COMP VIS
   Kobla V, 2000, PROC SPIE, V3972, P332
   LACASCIA M, 1998, IEEE WORKSH CONT BAS
   Li DG, 2001, PATTERN RECOGN LETT, V22, P533, DOI 10.1016/S0167-8655(00)00119-7
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Lienhart R, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P509, DOI 10.1109/MMCS.1997.609763
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Minami K, 1998, IEEE MULTIMEDIA, V5, P17, DOI 10.1109/93.713301
   MIYAMORI H, 2000, IEEE INT C AUT FAC G, P26
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   MONCRIEFF S, 2001, IEEE INT C MULT EXP, P1192
   Nack F, 1999, IEEE MULTIMEDIA, V6, P64, DOI 10.1109/93.809235
   Nack F, 1999, IEEE MULTIMEDIA, V6, P65, DOI 10.1109/93.790612
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Nam JH, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P550, DOI 10.1109/ICIP.1997.638830
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Nguyen HT, 2000, IEEE T IMAGE PROCESS, V9, P137, DOI 10.1109/83.817605
   NIGAY L, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P172
   Oard DW, 1997, USER MODEL USER-ADAP, V7, P141, DOI 10.1023/A:1008287121180
   PAN H, 2001, IEEE INT C AC SPEECH
   Patel NV, 1996, P SOC PHOTO-OPT INS, V2670, P373, DOI 10.1117/12.234776
   PATEL NV, 1997, IS T SPIE P STOR RET
   Pearl J., 1988, PROBABILISTIC REASON
   PEKER AK, 2000, IEEE INT C MULT EXP
   Pentland A., 1994, IEEE INT C COMP VIS
   Pfeiffer S., 1996, Proceedings ACM Multimedia 96, P21, DOI 10.1145/244130.244139
   Pfeiffer S, 2001, MULTIMED TOOLS APPL, V15, P59, DOI 10.1023/A:1011315803415
   PHAM TV, 2000, 200011 U AMST
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Sahouria E, 1999, IEEE T CIRC SYST VID, V9, P1290, DOI 10.1109/76.809163
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Saur DD, 1997, P SOC PHOTO-OPT INS, V3022, P176, DOI 10.1117/12.263406
   SCHNEIDERMAN H, 2000, IEEE COMPUTER VISION
   SHEARER K, 2000, ACM INT C KNOWL DISC, P46
   Shim JC, 1998, INT C PATT RECOG, P618, DOI 10.1109/ICPR.1998.711219
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SRIHARI RK, 1995, COMPUTER, V28, P49, DOI 10.1109/2.410153
   SUDHIR G, 1998, IEEE INT WORKSH CONT
   TRUONG BT, 2000, IEEE INT C PATT REC
   TRUONG BT, 2001, IEEE INT C MULT EXP, P61
   Tsekeridou S, 2001, IEEE T CIRC SYST VID, V11, P522, DOI 10.1109/76.915358
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   VAILAYA A, 2000, P SPIE, V3972
   Vendrig J, 2002, IEEE T MULTIMEDIA, V4, P492, DOI 10.1109/TMM.2002.802021
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   Westerveld T., 2000, P CONTENT BASED MULT, P276
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Wu L, 1996, SIGNAL PROCESS-IMAGE, V8, P513, DOI 10.1016/0923-5965(96)00004-5
   XU P, 2001, IEEE C MULT EXP, P928
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yeung MM, 1997, P SOC PHOTO-OPT INS, V3022, P45, DOI 10.1117/12.263440
   Zhang T, 1999, INT CONF ACOUST SPEE, P3001, DOI 10.1109/ICASSP.1999.757472
   ZHONG D, 2001, IEEE C MULT EXP, P920
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
   ZHOU W, 2000, ACM MULTIMEDIA 2000
   ZHU W, 2001, IEEE INT C MULT EXP, P1036
   [No title captured]
NR 100
TC 203
Z9 241
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2005
VL 25
IS 1
BP 5
EP 35
DI 10.1023/B:MTAP.0000046380.27575.a5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 866VY
UT WOS:000224802700001
DA 2024-07-18
ER

PT J
AU Zhu, HM
   Wei, HC
   Wei, J
AF Zhu, Hengmin
   Wei, Hongcheng
   Wei, Jing
TI Understanding users' information dissemination behaviors on Douyin, a
   short video mobile application in China
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Short videos; Douyin; Community network; Information dissemination;
   Sentiment transmission
ID SOCIAL NETWORKS; DIFFUSION
AB Douyin as a popular Chinese short-video app has revolutionized social interactions in daily life. To explore users' information dissemination behaviors in short-video social networks, a music community network is constructed from Douyin. Firstly, we crawl a total of 881,454 comments associated with six music topics, i.e., folk, rock, light music, pop, hip-hop, and English music. By extracting comment and mention relations from the dataset, we construct a music community network consisting of 5,433 nodes and 12,775 edges. Secondly, we examine the music community to gain insights into the characteristics of the social network. Finally, we analyze users' information dissemination behaviors in terms of their sentiments, interests, and geographic locations. The results show the music short-video community network on Douyin is characterized by community, small world and scale-free. There exists consistent sentiment transmission between users, accounting for 86% of the sentiment chains. Users with similar interests are more likely to interact, but information sharing between user pairs with different interests should not be ignored. Moreover, the users' social contact has broken through the limitation of geographical distance, of which 93% are cross-province user pairs and only 2% are same-city ones. The results are helpful to understand the characteristics of users' information dissemination behaviors on Douyin.
C1 [Zhu, Hengmin; Wei, Hongcheng; Wei, Jing] Nanjing Univ Posts & Telecommun, Sch Management, Nanjing 210003, Peoples R China.
   [Zhu, Hengmin] Jiangsu Univ, Philosophy & Social Sci Key Res Base, Informat Ind Integrat Innovat & Emergency Manageme, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Jiangsu University
RP Wei, HC (corresponding author), Nanjing Univ Posts & Telecommun, Sch Management, Nanjing 210003, Peoples R China.
EM whc1799@163.com
OI Wei, Hongcheng/0000-0002-0025-7709
FU National Natural Science Foundation of China
FX We are very thankful to the editor and people whose valuable suggestions
   and comments helped us to improve the article.
CR Akrouf Samir, 2013, International Journal of Future Computer and Communication, V2, P246, DOI 10.7763/IJFCC.2013.V2.161
   Alassad M, 2019, LECT NOTES COMPUT SC, V11549, P224, DOI 10.1007/978-3-030-21741-9_23
   Benevenuto F., 2008, 16 ACM INT C MULTIME, P761
   Berry C, 2020, IEEE INT CONF BIG DA, P5636, DOI 10.1109/BigData50022.2020.9377772
   Cao J, 2016, NEUROCOMPUTING, V172, P53, DOI 10.1016/j.neucom.2014.10.103
   Cerruto F, 2022, 30 ITALIAN S ADV DAT, P3194
   Cerruto F, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00566-7
   Chen Z, 2020, Papers Appl Geogr, V6, P471
   Fei DZ, 2019, SAFETY SCI, V118, P757, DOI 10.1016/j.ssci.2019.06.004
   Fu CL, 2020, IEEE ACCESS, V8, P95170, DOI 10.1109/ACCESS.2020.2995411
   Han JW, 2021, 2021 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI 2021), P1432, DOI 10.1109/CSCI54926.2021.00285
   Han X, 2015, DECIS SUPPORT SYST, V69, P92, DOI 10.1016/j.dss.2014.11.008
   He ZB, 2018, IEEE T VEH TECHNOL, V67, P665, DOI 10.1109/TVT.2017.2738018
   Hming Z., 2016, J Syst Simul, V28, P1506
   Hong L, 2021, INTELL AUTOM SOFT CO, V29, P437, DOI 10.32604/iasc.2021.016259
   Huang WD, 2020, MULTIMED TOOLS APPL, V79, P10383, DOI 10.1007/s11042-019-07779-8
   Jia SJ, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12061305
   Jiang HL, 2021, Arxiv, DOI arXiv:2010.02973
   Jingga F, 2023, 2023 27 INT C INF TE, P1
   Jun L., 2021, News Outpost, V8, P51
   Kumar Ankit, 2020, 2020 6th International Conference on Signal Processing and Communication (ICSC), P363, DOI 10.1109/ICSC48311.2020.9182719
   Li Y., 2023, ACM Computing Surveys, V55, P1
   Liu J, 2022, P INT C EL BUS ICEB, P406
   Liu L, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7050189
   Macwan K., 2021, Handbook of Research on Digital Transformation and Challenges to Data Security and Privacy, P119
   Meng KS, 2021, TELECOMMUN POLICY, V45, DOI 10.1016/j.telpol.2021.102172
   Park SJ, 2015, TECHNOL FORECAST SOC, V95, P208, DOI 10.1016/j.techfore.2015.02.003
   Peng HX, 2022, LECT NOTES COMPUT SC, V13315, P170, DOI 10.1007/978-3-031-05061-9_13
   Perifanis V, 2023, INFORM SCIENCES, V623, P767, DOI 10.1016/j.ins.2022.12.024
   Ren XX, 2016, LECT NOTES COMPUT SC, V9994, P349, DOI 10.1007/978-3-319-48051-0_30
   Shi R, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15032448
   Stai Eleni, 2015, Comput Soc Netw, V2, P18, DOI 10.1186/s40649-015-0025-4
   Stefano C, 2023, IS EUD 9 INT S END U, P3408
   Teh PL, 2020, IEEE INT SYMP PARAL, P1481, DOI 10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00223
   Warmbrodt J., 2008, P 41 ANN HAW INT C S, P291
   Wu J, 2021, 2021 INT C SOC DEV M, P231
   Yan L, 2019, INT CONF ADV COMMUN, P81, DOI [10.23919/ICACT.2019.8701897, 10.23919/icact.2019.8701897]
   Yang Shuang-Hong, 2011, P 20 INT C WORLD WID, P537, DOI 10.1145/1963405.1963481
   Yin FL, 2022, INFORM SCIENCES, V594, P118, DOI 10.1016/j.ins.2022.02.029
   Yu TY, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P40, DOI 10.1109/BigMM.2015.70
   Yyun X., 2019, New Media Res, V5, P21
   Zhang C, 2022, IEEE ACCESS, V10, P40999, DOI 10.1109/ACCESS.2022.3167687
   Zhao Xiuming, 2022, 2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), P1311, DOI 10.1109/PRAI55851.2022.9904183
   Zuo H., 2019, FRONTIERS ART RES, V1, P1, DOI DOI 10.25236/FAR.20190301
NR 44
TC 1
Z9 1
U1 37
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17831-3
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600007
DA 2024-07-18
ER

PT J
AU Paul, RK
   Misra, D
   Sen, S
   Chandran, S
AF Paul, Raj Kumar
   Misra, Dipankar
   Sen, Shibaprasad
   Chandran, Saravanan
TI Optimization of microscopy image compression using convolutional neural
   networks and removal of artifacts by deep generative adversarial
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Microscopy image; CR; Deep-GAN; BRISQUE; PSNR; SSIM; Optimized-CNN
ID RESTORATION; CLASSIFICATION; INSPECTION; FRAMEWORK; CNN
AB Nowadays, microscopy images are significant in medical research and clinical studies. However, storage and transmission of data such as microscopy images are challenging. Microscopy image compression is a vital area of digital microscope imaging in which image processing approaches are applied to capture the image by the microscope. It becomes accessible to interface the microscope to an image processing system because of technical advances in the microscope. Multiple application areas of microscope imaging, namely cancer research, drug testing, metallurgy, medicine, biological research, test-tube baby, etc., need microscopy image processing for analysis purposes. The microscopy image compression leads to complicated compression artifacts, like contouring, blocking, and ringing artifacts. Due to this problem, we select optimized Convolution Neural Networks (optimized-CNN), followed by Deep generative adversarial networks Deep-GAN, as a solution to reduce diverse compression artifacts. This research covers the compression of microscopy images and the removal of artifacts from a compressed microscopy image Optimized-CNN Deep-GAN based on Optimized-CNN and Deep-GAN. The concept of microscope image acquisition techniques and their analysis is also discussed. The performance of the Optimized-CNN Deep-GAN approach is measured using Peak Signal to Noise Ratio(PSNR), Compression Ratio(CR), Structural Similarity Index Measurement(SSIM), and Blind/Reference less Image Spatial Quality Evaluator(BRISQUE) and differentiated with state-of-the-art techniques. The experimental outcomes indicate the Optimized-CNN Deep-GAN technique acquires higher SSIM, BRISQUE, reduced space complexity, and better image quality than the existing image compression system. The proposed new model achieved CR 13.88, PSNR 40.6799 (dB), SSIM 0.9541, and BRISQUE 18.7645 values.
C1 [Paul, Raj Kumar; Chandran, Saravanan] Natl Inst Technol, Comp Sci & Engn, Durgapur, West Bengal, India.
   [Misra, Dipankar] Budge Budge Inst Technol, Comp Sci & Engn, Budge Budge 700137, West Bengal, India.
   [Sen, Shibaprasad] Techno Main Salt Lake, Comp Sci & Engn AIML, Kolkata 700091, West Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Sen, S (corresponding author), Techno Main Salt Lake, Comp Sci & Engn AIML, Kolkata 700091, West Bengal, India.
EM rajkumar.rkp@gmail.com; dipankar.misra@gmail.com; shibubiet@gmail.com;
   cs@cse.nitdgp.ac.in
OI sen, shibaprasad/0000-0003-4815-6621; PAUL, RAJ
   KUMAR/0000-0003-0626-6910
CR [Anonymous], 2006, Introduction to Data Compression
   Chen C, 2021, IONICS, V27, P1, DOI 10.1007/s11581-020-03796-y
   Chen T, 2023, IEEE T CIRC SYST VID, V33, P7842, DOI 10.1109/TCSVT.2023.3276442
   Chen T, 2021, IEEE T IMAGE PROCESS, V30, P3179, DOI 10.1109/TIP.2021.3058615
   Chen WX, 2021, IEEE T MED IMAGING, V40, P527, DOI 10.1109/TMI.2020.3031289
   Chen X, 2021, IEEE T COMPUT IMAG, V7, P700, DOI 10.1109/TCI.2021.3093788
   Chen XJ, 2021, IEEE T MED IMAGING, V40, P3205, DOI 10.1109/TMI.2021.3080695
   Chen ZX, 2021, IEEE SIGNAL PROC LET, V28, P1280, DOI 10.1109/LSP.2021.3090249
   Cheng ZY, 2023, Arxiv, DOI arXiv:2301.13487
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Chung KJ, 2020, IEEE SIGNAL PROC LET, V27, P141, DOI 10.1109/LSP.2019.2961072
   Cui K, 2021, IEEE J-STSP, V15, P174, DOI 10.1109/JSTSP.2020.3043148
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Fabi G, 2021, IEEE T MICROW THEORY, V69, P2662, DOI 10.1109/TMTT.2021.3060756
   Fu W, 2020, IEEE T GEOSCI REMOTE, V58, P268, DOI 10.1109/TGRS.2019.2936229
   Galteri L, 2019, IEEE T MULTIMEDIA, V21, P2131, DOI 10.1109/TMM.2019.2895280
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   He X, 2020, IEEE T IMAGE PROCESS, V29, P6829, DOI 10.1109/TIP.2020.2994412
   Hingot V, 2021, IEEE T MED IMAGING, V40, P3812, DOI 10.1109/TMI.2021.3097150
   Jin Z, 2021, IEEE T CIRC SYST VID, V31, P467, DOI 10.1109/TCSVT.2020.2982174
   Katakol S, 2021, IEEE T IMAGE PROCESS, V30, P3069, DOI 10.1109/TIP.2021.3058545
   Khan S, 2021, IEEE ACCESS, V9, P10657, DOI 10.1109/ACCESS.2020.3048172
   Kim T, 2021, IEEE ACCESS, V9, P90881, DOI 10.1109/ACCESS.2021.3091975
   Kim Y, 2020, IEEE T CIRC SYST VID, V30, P1121, DOI 10.1109/TCSVT.2019.2901919
   Kim Y, 2020, IEEE ACCESS, V8, P20160, DOI 10.1109/ACCESS.2020.2968944
   Ko H, 2020, IEEE T IMAGE PROCESS, V29, P5964, DOI 10.1109/TIP.2020.2987180
   Li JW, 2020, IEEE SIGNAL PROC LET, V27, P2134, DOI 10.1109/LSP.2020.3039932
   Li JW, 2020, IEEE T IMAGE PROCESS, V29, P8842, DOI 10.1109/TIP.2020.3020389
   Li X, 2020, IEEE ACCESS, V8, P214605, DOI 10.1109/ACCESS.2020.3041416
   Liu DN, 2021, IEEE T MED IMAGING, V40, P154, DOI 10.1109/TMI.2020.3023466
   Liu HS, 2021, IEEE PHOTONICS J, V13, DOI [10.1109/JPHOT.2021.3056574, 10.1109/jphot.2021.3056574]
   Liu JY, 2020, IEEE T IMAGE PROCESS, V29, P7845, DOI 10.1109/TIP.2020.3007828
   Lv M, 2021, IEEE J BIOMED HEALTH, V25, P3041, DOI 10.1109/JBHI.2021.3050483
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Mardani M, 2019, IEEE T MED IMAGING, V38, P167, DOI 10.1109/TMI.2018.2858752
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Mu J, 2020, IEEE T IMAGE PROCESS, V29, P5374, DOI 10.1109/TIP.2020.2975931
   Niu BB, 2021, IEEE SIGNAL PROC LET, V28, P324, DOI 10.1109/LSP.2021.3052097
   Noll A, 2021, IEEE T HAPTICS, V14, P316, DOI 10.1109/TOH.2021.3078889
   Nousias S, 2020, IEEE ACCESS, V8, P169982, DOI 10.1109/ACCESS.2020.3023167
   Paul Raj Kumar, 2022, Data Engineering and Intelligent Computing: Proceedings of 5th ICICC 2021. Lecture Notes in Networks and Systems (446), P327, DOI 10.1007/978-981-19-1559-8_33
   Paul Raj Kumar, 2022, Innovations in Computational Intelligence and Computer Vision: Proceedings of ICICV 2021. Advances in Intelligent Systems and Computing (1424), P47, DOI 10.1007/978-981-19-0475-2_5
   Paul RK, 2022, J ENG RES-KUWAIT, V10, DOI 10.36909/jer.ICMET.17163
   Pei RH, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3073022
   Prajapati K, 2021, IEEE T IMAGE PROCESS, V30, P8251, DOI 10.1109/TIP.2021.3113783
   Qi ZY, 2021, IEEE ACCESS, V9, P62593, DOI 10.1109/ACCESS.2021.3073202
   Rossinelli D, 2021, IEEE T MED IMAGING, V40, P607, DOI 10.1109/TMI.2020.3033456
   Samore A, 2020, IEEE T INSTRUM MEAS, V69, P6766, DOI 10.1109/TIM.2020.2973913
   Song Q, 2020, IEEE T IMAGE PROCESS, V29, P7399, DOI 10.1109/TIP.2020.3002452
   Talebi H, 2021, IEEE T IMAGE PROCESS, V30, P6673, DOI 10.1109/TIP.2021.3096085
   Tellez D, 2021, IEEE T PATTERN ANAL, V43, P567, DOI 10.1109/TPAMI.2019.2936841
   Tian YJ, 2020, IEEE SIGNAL PROC LET, V27, P1615, DOI 10.1109/LSP.2020.3023341
   Pham TT, 2020, IEEE ACCESS, V8, P215157, DOI 10.1109/ACCESS.2020.3040416
   Uhm KH, 2021, IEEE ACCESS, V9, P137824, DOI 10.1109/ACCESS.2021.3116702
   Wan S, 2020, IEEE T CIRC SYST VID, V30, P4769, DOI 10.1109/TCSVT.2019.2959815
   Wang J, 2021, IEEE T IMAGE PROCESS, V30, P4225, DOI 10.1109/TIP.2021.3065244
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Wei H, 2023, Arxiv, DOI arXiv:2209.15179
   Yang JX, 2020, IEEE T INSTRUM MEAS, V69, P8032, DOI 10.1109/TIM.2020.2986875
   Zhang XF, 2020, IEEE ACCESS, V8, P11570, DOI 10.1109/ACCESS.2019.2963369
   Zhang XY, 2020, IEEE ACCESS, V8, P104728, DOI 10.1109/ACCESS.2020.2999965
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhang YM, 2021, IEEE T MULTIMEDIA, V23, P1069, DOI 10.1109/TMM.2020.2992940
   Zhang ZM, 2019, IEEE ACCESS, V7, P37228, DOI 10.1109/ACCESS.2019.2905000
   Zhao ZY, 2021, IEEE J BIOMED HEALTH, V25, P3744, DOI 10.1109/JBHI.2021.3052320
   Zheng BL, 2020, IEEE T CIRC SYST VID, V30, P3982, DOI 10.1109/TCSVT.2019.2931045
NR 66
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17494-0
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200009
DA 2024-07-18
ER

PT J
AU Tewari, AS
   Kumari, P
AF Tewari, Anand Shanker
   Kumari, Priya
TI Lightweight modified attention based deep learning model for cassava
   leaf diseases classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Leaf disease classification; Convolutional neural network; Attention;
   Deep learning
ID BROWN STREAK DISEASE; BIOLOGICAL-CONTROL; BACTERIAL-BLIGHT; THREAT;
   PESTS
AB The primary cause of decline in cassava production are various diseases on cassava leaves. It has direct adverse impact on farmers' income. The detection of diseases in cassava leaves traditionally relies on laboratory tests or expert intervention, that is time-consuming and costly. To address these challenges, an intelligent system that can be capable of accurately and efficiently identifying cassava leaf diseases is needed. In this research, a lightweight deep learning model is proposed that take fewer parameters and gives higher accuracy for the classification of cassava leaf diseases. The proposed model incorporates depthwise separable convolution, channel, spatial attention, and a novel modified channel attention module to reduce parameters and improve classification accuracy. All the training and testing images are from the agricultural field with natural background. The model has used the dedicated testing dataset to get the real effectiveness of the model. The testing images are separate images that not used for training and validation purposes. The proposed model has achieved the 98% validation accuracy and 75% testing accuracy. The primary objective of this proposed model is to promptly identify cassava leaf diseases directly from the agricultural field to address the need of farmers. A mobile application is developed to deploy the proposed lightweight deep learning model to address farmer requirements.
C1 [Tewari, Anand Shanker; Kumari, Priya] Natl Inst Technol Patna, Comp Sci & Engn Dept, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Tewari, AS (corresponding author), Natl Inst Technol Patna, Comp Sci & Engn Dept, Patna 800005, India.
EM anand@nitp.ac.in; priyak.mca21@nitp.ac.in
RI KUMARI, PRIYA/ISV-4765-2023
OI KUMARI, PRIYA/0000-0003-0802-1802
CR Aishwarya N, 2023, MULTIMED TOOLS APPL, V82, P18799, DOI 10.1007/s11042-022-14272-2
   Ayu HR., 2021, In J Phys, V1751
   Bi C, 2022, Mob Netw Appl, P1
   Boher B., 1994, African Crop Science Journal, V2, P505
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chen WR, 2022, MULTIMED TOOLS APPL, V81, P20797, DOI 10.1007/s11042-022-12620-w
   Chikoti PC, 2019, J PLANT PATHOL, V101, P467, DOI 10.1007/s42161-019-00255-0
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Ezenwaka L, 2018, CROP SCI, V58, P1907, DOI 10.2135/cropsci2018.01.0024
   Fanou AA, 2018, CASSAVA
   Gao F, 2021, 2021 7 INT C SYST IN, P1
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   GUTIERREZ AP, 1988, J APPL ECOL, V25, P901, DOI 10.2307/2403754
   HAHN SK, 1980, EUPHYTICA, V29, P673, DOI 10.1007/BF00023215
   Hassan SM, 2022, IEEE ACCESS, V10, P5390, DOI 10.1109/ACCESS.2022.3141371
   HERREN HR, 1991, ANNU REV ENTOMOL, V36, P257, DOI 10.1146/annurev.en.36.010191.001353
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Thai HT, 2021, PROC INT CONF ADV, P33, DOI 10.1109/ATC52653.2021.9598303
   JAMERSON J. D., 1964, EAST AFR AGR FOREST J, V29, P208
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Ke Dong, 2020, 2020 2nd International Conference on Information Technology and Computer Application (ITCA), P476, DOI 10.1109/ITCA52113.2020.00106
   Koonce Brett., 2021, ResNet 50. Convolutional neural networks with swift for tensorflow: image recognition and dataset categorization, P63
   Lai Y., 2019, J Phys, V1314
   Lilhore UK, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10040580
   López CE, 2012, TROP PLANT BIOL, V5, P117, DOI 10.1007/s12042-011-9092-3
   LOZANO JC, 1986, PLANT DIS, V70, P1089, DOI 10.1094/PD-70-1089
   Lv Q, 2022, ADV MULTIMED, V2022, DOI 10.1155/2022/3351256
   Mbanzibwa DR, 2011, J GEN VIROL, V92, P974, DOI 10.1099/vir.0.026922-0
   Methil A, 2021, 2021 12 INT C COMP C, P1
   Mwebaze E, 2019, Arxiv, DOI arXiv:1908.02900
   Nandhini S, 2022, NEURAL COMPUT APPL, V34, P5513, DOI 10.1007/s00521-021-06714-z
   Pati BL, 2015, J GEN VIROL, V96, P956, DOI 10.1099/vir.0.000014
   Rahman SU, 2023, MULTIMED TOOLS APPL, V82, P9431, DOI 10.1007/s11042-022-13715-0
   Ravi V, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12862
   Sambasivam G, 2021, EGYPT INFORM J, V22, P27, DOI 10.1016/j.eij.2020.02.007
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sanida T, 2022, MULTIMED TOOLS APPL, V81, P15041, DOI 10.1007/s11042-022-12461-7
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Sinha D, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P280, DOI 10.1109/uemcon47517.2019.8993089
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Taiwo KA, 2006, FOOD REV INT, V22, P29, DOI 10.1080/87559120500379787
   Tang Z, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105735
   Tao M, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105431
   Tarek H, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010140
   Thakur PS, 2023, MULTIMED TOOLS APPL, V82, P497, DOI 10.1007/s11042-022-13144-z
   Thresh JM, 2005, PLANT PATHOL, V54, P587, DOI 10.1111/j.1365-3059.2005.01282.x
   Tomlinson KR, 2018, MOL PLANT PATHOL, V19, P1282, DOI 10.1111/mpp.12613
   Winter S, 2010, J GEN VIROL, V91, P1365, DOI 10.1099/vir.0.014688-0
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao ZY, 2023, IEEE ACCESS, V11, P48248, DOI 10.1109/ACCESS.2023.3272985
   Yu HL, 2022, MULTIMED TOOLS APPL, V81, P7759, DOI 10.1007/s11042-022-11915-2
NR 51
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17459-3
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200012
DA 2024-07-18
ER

PT J
AU Yang, ZJ
   Yuan, PT
   Zhang, Y
   Sun, YM
   Liu, SD
AF Yang, Zhenjian
   Yuan, Peitao
   Zhang, Yan
   Sun, Yemei
   Liu, Shudong
TI Residual aggregation U-shaped network for image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image super-resolution; Multi-scale features; Residual aggregation;
   Vanishing gradient; Convolutional neural network
AB Recent research on image super-resolution (SR) task has greatly progressed with the development of convolutional neural networks (CNNs). Most previous studies with single-scale feature enhance expressiveness by increasing network depth. However, most of them do not adequately extract and utilize multi-scale features. In this paper, we propose a novel residual aggregation U-shaped network (RAU), which fully utilizes multi-scale features to help reconstruct high-quality images. First, we use progressive downsampling structure to obtain multi-scale features and capture context information, and use progressive upsampling structure to fuse multi-scale features and fill detail texture. Second, we introduce auxiliary supervision in the middle layer to provide additional regularization and accelerate the convergence speed. Third, we propose a lightweight model for our network, and we replace the traditional convolution with the Ghost module in multiple locations of network. Extensive experiments on the challenge datasets confirmed the effectiveness of the proposed network. Our algorithm can restore high-quality high-resolution (HR) images and outperform other methods by a large margin.
C1 [Yang, Zhenjian; Yuan, Peitao; Zhang, Yan; Sun, Yemei; Liu, Shudong] Tianjin Chengjian Univ, Sch Comp & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin Chengjian University
RP Zhang, Y; Sun, YM (corresponding author), Tianjin Chengjian Univ, Sch Comp & Informat Engn, Tianjin, Peoples R China.
EM zhangyan@tcu.edu.cn; sunyemei1216@163.com
RI li, xinyi/KEI-6391-2024
FU Tianjin Key Laboratory of Optoelectronic Detection Technology and System
   Open Project [2019LODTS006]
FX This work was supported by the Tianjin Key Laboratory of Optoelectronic
   Detection Technology and System Open Project[2019LODTS006]. The authors
   also acknowledge the anonymous reviewers for their helpful comments on
   the manuscript.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Choi JH., 2021, IEEE Access, VPP, P1
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Haris M., 2018, arXiv
   Hu XD, 2019, IEEE COMPUT SOC CONF, P505, DOI 10.1109/CVPRW.2019.00073
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li Z, 2019, IEEE
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Lu ZY, 2022, SIGNAL IMAGE VIDEO P, V16, P1143, DOI 10.1007/s11760-021-02063-5
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tian C, 2020, Knowl.-Based Syst.
   Tian CW, 2022, IEEE T SYST MAN CY-S, V52, P3718, DOI 10.1109/TSMC.2021.3069265
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang LG, 2021, PROC CVPR IEEE, P4915, DOI 10.1109/CVPR46437.2021.00488
   Wang X, 2021, IEEE Trans. Cybern
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhang Y., 2021, Appl Intell, P1
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhang Yulun, 2021, Advances in Neural Information Processing Systems, V34, P2695
NR 37
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-14875-3
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200014
DA 2024-07-18
ER

PT J
AU Gao, YH
   Liu, JY
   Chen, SQ
AF Gao, Yuhui
   Liu, Jingyi
   Chen, Shiqiang
TI Image encryption algorithms based on two-dimensional discrete
   hyperchaotic systems and parallel compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; 2D discrete chaotic system; Parallel compressive
   sensing; Security analysis
ID CHAOTIC SYSTEM; MAP
AB In this paper, a new two-dimensional discrete hyperchaotic system is proposed. Verification using the phase-track map, bifurcation map and Lyapunov exponent of the chaotic system shows that the chaotic system has better traversal, hyperchaos, unpredictability and wider chaotic region compared with the existing two-dimensional discrete chaotic systems. To improve the efficiency and security of the image encryption algorithm, this paper firstly uses parallel compressive sensing-aware image processing to greatly improve the efficiency of the image encryption. Secondly, index scrambling and forward and backward diffusion using a combination of a subset of discrete data sequences generated by a two-dimensional discrete hyperchaotic system improves the security of the image encryption algorithm. In addition ,the initial key and the sum of some pixel values of the original image are used to generate the initial values and control parameters of the 2D-SLS chaotic sequence using the hash of SHA-512, making the proposed algorithm robust to known plaintext and selected plaintext attacks. Simulation and experimental results show that the proposed algorithm is more efficient and secure than recently proposed encryption algorithms.
C1 [Gao, Yuhui] Hubei Minzu Univ, Sch Math & Stat, Enshi 445000, Hubei, Peoples R China.
   [Liu, Jingyi; Chen, Shiqiang] Hubei Minzu Univ, Coll Intelligent Syst Sci & Engn, Enshi 445000, Hubei, Peoples R China.
C3 Hubei Minzu University; Hubei Minzu University
RP Chen, SQ (corresponding author), Hubei Minzu Univ, Coll Intelligent Syst Sci & Engn, Enshi 445000, Hubei, Peoples R China.
EM 2209135946@qq.com; 369417266@qq.com; 1997013@hbmzu.edu.cn
RI LIU, JING-YI/IWM-7889-2023
OI LIU, JING-YI/0000-0002-9710-5006
CR Ajagbe SA., 2020, CPJ, V26, P98
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Brahim AH, 2023, MULTIMED TOOLS APPL, V82, P42087, DOI 10.1007/s11042-023-15171-w
   Cai J, 2023, MULTIMED TOOLS APPL, V82, P22189, DOI 10.1007/s11042-022-13346-5
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chen SH, 2002, PHYS LETT A, V299, P353, DOI 10.1016/S0375-9601(02)00522-4
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   [邓文博 Deng Wenbo], 2022, [计算机工程与科学, Computer Engineering and Science], V44, P1574
   Dong WL, 2021, OPT COMMUN, V499, DOI 10.1016/j.optcom.2021.127211
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fay R, 2016, INT CONF INTERNET, P119, DOI 10.1109/ICITST.2016.7856681
   Fei L, 2017, IEEE T GEOSCI REMOTE, V55, P6937, DOI 10.1109/TGRS.2017.2737033
   Gan ZH, 2020, NEURAL COMPUT APPL, V32, P14113, DOI 10.1007/s00521-020-04808-8
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hafsa A, 2021, MULTIMED TOOLS APPL, V80, P19769, DOI 10.1007/s11042-021-10700-x
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   HY W, 2010, 2010 8 WORLD C INTEL
   Jiang DH., 2022, J Xi'an Jiaotong Univ, V56, P140
   Li CL, 2021, MULTIMED TOOLS APPL, V80, P18479, DOI 10.1007/s11042-021-10631-7
   Liu GZ, 2022, J ELECTRON INF TECHN, V44, P3602, DOI 10.11999/JEIT210763
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu JL, 2021, MULTIMED TOOLS APPL, V80, P25433, DOI 10.1007/s11042-021-10884-2
   Liu SC, 2022, J ELECTRON INF TECHN, V44, P1754, DOI 10.11999/JEIT210270
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Mohimani GH, 2007, LECT NOTES COMPUT SC, V4666, P389
   Musanna F, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102560
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Shi H, 2019, ACTA PHYS SIN-CH ED, V68, DOI 10.7498/aps.68.20190553
   Sun FY, 2022, MULTIMED TOOLS APPL, V81, P3959, DOI 10.1007/s11042-021-11690-6
   Sun KH., 2015, Principle and technology of chaotic secure communication
   Tang ZJ, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8694678
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang ZP, 2023, MULTIMED TOOLS APPL, V82, P21561, DOI 10.1007/s11042-022-14176-1
   Wei DY, 2021, OPTIK, V238, DOI 10.1016/j.ijleo.2021.166748
   Wu WS, 2023, J Hangzhou Dianzi Univ (Nat Sci), V43, P34
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Xu J, 2022, VISUAL COMPUT, V38, P1509, DOI 10.1007/s00371-021-02085-7
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
NR 45
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17745-0
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5L8
UT WOS:001129325100001
DA 2024-07-18
ER

PT J
AU Verma, A
   Singh, N
   Khanna, V
   Singh, BP
   Singh, NP
AF Verma, Aryan
   Singh, Nishi
   Khanna, Vikram
   Singh, Balendra Pratap
   Singh, Nagendra Pratap
TI Automated tongue contour extraction from ultrasound sequences using
   signal enhancing neural network and energy minimized spline
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ultrasound; Artificial intelligence; Tongue contour; Medical image
   processing; Generative models; Deep learning
ID TRACKING
AB Ultrasonography is widely used in linguistic study, speech therapy, language training, and impaired speech production. Real-time visualization of the shape, contour, and motion of the tongue provides essential information about tongue articulation during speech. The study of tongue motion requires precise recording of the tongue contour. It is challenging to analyze the tongue contour using ultrasound sequences because of indiscreet noise, rapidly changing tongue surface, and time-consuming manual labeling, which often results in faulty data interpretation. Therefore, we propose a novel automatic tongue contour extraction approach from ultrasound image sequences with minimal manual annotation. This study discovers a lightweight encoder-decoder-based neural network architecture that removes the ultrasound image's noise and enhance the image. This enhanced image is run through a robust post-processing algorithm that involves anomaly removal, skeletonization, and fitting a deformable spline using an active contour model that finally delineates the tongue surface and outputs the contour for the tongue. Unlike other works in tongue contour detection, we train the neural network only to clean noise, which forms its base for multiple domain adaptation. Our proposed model has the least parameters and excellent performance with a mean squared distance of 0.93mm/3.152 pixels from expert annotated contours. Expert prosthodontists, after verifying the results of our approach, find it to be extremely useful in decision making and robust to subjective variability of hand labeling.
C1 [Verma, Aryan] Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur 177005, HP, India.
   [Singh, Nishi] King Georges Med Univ, Dept Conservat Dent & Endodont, Lucknow 226003, UP, India.
   [Khanna, Vikram; Singh, Balendra Pratap] King Georges Med Coll, Dept Prosthodont, Lucknow 226003, UP, India.
   [Singh, Nagendra Pratap] Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar 144011, Panjab, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; King George's Medical University; King George's
   Medical University; National Institute of Technology (NIT System); Dr B
   R Ambedkar National Institute of Technology Jalandhar
RP Verma, A (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur 177005, HP, India.
EM 195011@nith.ac.in; nishibp003@gmail.com; drvikramkhanna@gmail.com;
   balendra02@yahoo.com; singhnp@nitj.ac.in
CR Adler-Bock M, 2007, AM J SPEECH-LANG PAT, V16, P128, DOI 10.1044/1058-0360(2007/017)
   Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Ahmed S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112739
   Bernhardt B, 2005, CLIN LINGUIST PHONET, V19, P605, DOI 10.1080/02699200500114028
   Bernhardt B, 2005, CAN J SPEECH-LANG PA, V29, P169
   Fasel I., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1493, DOI 10.1109/ICPR.2010.369
   Jaumard-Hakoun A, 2016, Arxiv, DOI arXiv:1605.05912
   Karimi E, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103335
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Katusic SK, 2009, PEDIATRICS, V123, P1306, DOI 10.1542/peds.2008-2098
   Laporte C, 2018, MED IMAGE ANAL, V44, P98, DOI 10.1016/j.media.2017.12.003
   Li M, 2005, CLIN LINGUIST PHONET, V19, P545, DOI 10.1080/02699200500113616
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mozaffari MH, 2020, IEEE INT C BIOINFORM, P2785, DOI 10.1109/BIBM49941.2020.9313262
   Mozaffari MH, 2019, IEEE INT C BIOINFORM, P707, DOI [10.1109/bibm47256.2019.8983002, 10.1109/BIBM47256.2019.8983002]
   Mozaffari MH, 2018, IEEE INT CONF COMP
   Mozaffari MH, 2019, J ACOUST SOC AM, V146, pEL431, DOI 10.1121/1.5133665
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ribeiro MS, 2021, IEEE W SP LANG TECH, P1109, DOI 10.1109/SLT48900.2021.9383619
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Singh Samridhi, 2022, 2022 6th International Conference on Trends in Electronics and Informatics (ICOEI), P1381, DOI 10.1109/ICOEI53556.2022.9777133
   Singh S, 2023, Multimed Tools Appl, P1
   Singh S, 2022, Int J Pattern Recognit Artif Intell
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Tang L, 2012, MED IMAGE ANAL, V16, P1503, DOI 10.1016/j.media.2012.07.001
   Verma Aryan, 2023, International Journal of Information Technology, P1453, DOI 10.1007/s41870-023-01166-1
   Verma A, 2021, arXiv
   Xu KL, 2016, CLIN LINGUIST PHONET, V30, P313, DOI 10.3109/02699206.2015.1110714
   Zhu J, 2019, Arxiv, DOI arXiv:1907.10210
NR 29
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17813-5
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L6
UT WOS:001155145800004
DA 2024-07-18
ER

PT J
AU Luu, ST
   Van Nguyen, K
   Nguyen, NLT
AF Luu, Son T.
   Van Nguyen, Kiet
   Nguyen, Ngan Luu-Thuy
TI An approach of data augmentation to improve the performance of BERTology
   models for vietnamese hate speech detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hate speech detection; Machine learning; Text classification; Text
   pre-processing; Imbalance data; Data augmentation; Bertology
AB Hate speech detection on social media networks is the classification task that automatically detects harmful comments from users and prevents the appearance of those toxic comments on social sites. The profit of the hate speech detection task is preventing harassment and toxicity content on the social networks site to protect the users that join the social media networks. Many attempts to solve the problem of hate speech detection in Vietnamese social texts have been proposed and achieved optimal results. However, with the robust ability of BERTology, the advantage of popular text pre-processing methods is not as significant as traditional models. In this paper, we investigate the effect of text pre-processing methods to the BERTology models on the two Vietnamese hate speech detection datasets - the ViHSD and the UIT-ViCTSD. The results show that the popular text pre-processing methods are not efficient in the performance of the classification models. Besides, we propose a new approach for the EDA data augmentation that has more benefit for the BERTology models when training with the imbalance dataset. Moreover, we also implement the Focal loss for BERTology models to investigate the efficiency in imbalanced classification. From the empirical results, our proposed EDA method is good for both multiclass and binary classification, while the Focal loss shows its robustness for only the multiclass classification when working with imbalanced data.
C1 [Luu, Son T.; Van Nguyen, Kiet; Nguyen, Ngan Luu-Thuy] Univ Informat Technol, Fac Informat Sci & Engn, Ho Chi Minh City, Vietnam.
   [Luu, Son T.; Van Nguyen, Kiet; Nguyen, Ngan Luu-Thuy] Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City
RP Nguyen, NLT (corresponding author), Univ Informat Technol, Fac Informat Sci & Engn, Ho Chi Minh City, Vietnam.; Nguyen, NLT (corresponding author), Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
EM sonlt@uit.edu.vn; kietnv@uit.edu.vn; ngannlt@uit.edu.vn
RI Luu, Son T./AAY-5897-2020
OI Luu, Son T./0000-0002-1231-5865
FU VNUHCM-University of Information Technology's Scientific Research
   Support Fund
FX This research was supported by The VNUHCM-University of Information
   Technology's Scientific Research Support Fund.
CR Ali Aida, 2013, Int. J. Adv. Soft Comput. Appl., V5
   Anjum, 2022, International Conference on Artificial Intelligence and Sustainable Engineering: Select Proceedings of AISE 2020. Lecture Notes in Electrical Engineering (836), P381, DOI 10.1007/978-981-16-8542-2_29
   Anjum Katarya R, 2022, 2022 INT C ADV TECHN, P1, DOI [10.1109/ICONAT53423.2022.9726098, DOI 10.1109/ICONAT53423.2022.9726098]
   Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223
   Nguyen TB, 2019, Arxiv, DOI arXiv:1910.05608
   Bisht A., 2020, Recent trends in image and signal processing in computer vision, V1124, P243, DOI 10.1007/978-981-15-2740-1_17
   Bui T. V., 2020, P 34 PACIFIC ASIA C, P13
   Clark K, 2020, Arxiv, DOI arXiv:2003.10555
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Conneau Alexis., 2020, P 58 ANN M ASS COMP, P8440, DOI [10.18653/v1/2020.acl-main.747, DOI 10.18653/V1/2020.ACL-MAIN.747]
   Nguyen DQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1037
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhamija Tashvik, 2021, Advances in Mechanical Engineering. Select Proceedings of CAMSE 2020. Lecture Notes in Mechanical Engineering (LNME), P509, DOI 10.1007/978-981-16-0942-8_48
   Dwivedy V, 2023, MULTIMED TOOLS APPL, V82, P36279, DOI 10.1007/s11042-023-14850-y
   Feng SY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P968
   Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Gupta A, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104920
   Nguyen HD, 2021, FRONT ARTIF INTEL AP, V337, P444, DOI 10.3233/FAIA210043
   Hoang SN, 2022, 2022 14 INT C KNOWL, P1, DOI [10.1109/KSE56063.2022.9953615, DOI 10.1109/KSE56063.2022.9953615]
   Huynh HD, 2020, P 34 PACIFIC ASIA C, P420
   Jain PK, 2022, IEEE T COMPUT SOC SY, V9, P1777, DOI 10.1109/TCSS.2022.3200890
   Jain PK, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3457206
   Kim J, 2020, J SCH NURS, V36, P251, DOI 10.1177/1059840518824395
   Luan Thanh Nguyen, 2021, Advances and Trends in Artificial Intelligence. Artificial Intelligence Practices: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Proceedings. Lecture Notes in Computer Science, P572, DOI 10.1007/978-3-030-79457-6_49
   Luu ST, 2020, IEEE RIVF INT CONF, P1, DOI 10.1109/rivf48685.2020.9140745
   Moudjari L, 2021, COMPUT SPEECH LANG, V70, DOI 10.1016/j.csl.2021.101240
   Mundra S, 2023, MULTIMED TOOLS APPL, V82, P11337, DOI 10.1007/s11042-022-13668-4
   Naseem U, 2021, MULTIMED TOOLS APPL, V80, P35239, DOI 10.1007/s11042-020-10082-6
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Nath Keshav, 2021, 2021 International Conference on Recent Trends on Electronics, Information, Communication & Technology (RTEICT), P434, DOI 10.1109/RTEICT52294.2021.9573583
   Nguyen LT, 2022, Arxiv, DOI arXiv:2209.10482
   Nguyen N. L. T, 2020, P 34 PAC AS C LANG I
   Nguyen TC, 2021, Arxiv, DOI arXiv:2101.12672
   Nguyen TN, 2020, GEND TECHNOL DEV, V24, P174, DOI 10.1080/09718524.2020.1719598
   Nikolaou D, 2017, J HEALTH ECON, V56, P30, DOI 10.1016/j.jhealeco.2017.09.009
   Poletto F, 2021, LANG RESOUR EVAL, V55, P477, DOI 10.1007/s10579-020-09502-8
   Priyadarshini I, 2023, MULTIMED TOOLS APPL, V82, P27473, DOI 10.1007/s11042-023-14481-3
   QuocTran K, 2022, Neural Comput Appl, P1
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Schmidt A., 2017, P 5 INT WORKSH NAT L, P1
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Son T Luu, 2021, Advances and Trends in Artificial Intelligence. Artificial Intelligence Practices: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Proceedings. Lecture Notes in Computer Science, P415, DOI 10.1007/978-3-030-79457-6_35
   Sreelakshmi K., 2020, Procedia Computer Science, V171, P737, DOI 10.1016/j.procs.2020.04.080
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Teller V, 2000, COMPUT LINGUIST, V26, P638, DOI 10.1162/089120100750105975
   Do HTT, 2019, Arxiv, DOI arXiv:1911.03648
   Thuy HDL, 2020, VNU J Sci Econ Bus, V36
   To HQ, 2021, P 35 PACIFIC ASIA C, P692
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Van Huynh Tin, 2019, arXiv
   VanThin D., 2021, arXiv
   Vu T., 2018, P 2018 C N AM CHAPTE, V5, P56, DOI [DOI 10.18653/V1/N18-5012, DOI 10.18653/V1/N18-5012.HTTPS]
   Vu X-S, 2019, P VLSP 2019
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382
   Yanling Li, 2010, 2010 Proceedings of the Third International Symposium on Information Processing (ISIP 2010), P301, DOI 10.1109/ISIP.2010.47
   Zaib M, 2020, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2020), DOI 10.1145/3373017.3373028
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
NR 59
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 13
PY 2023
DI 10.1007/s11042-023-16968-5
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB1N3
UT WOS:001122700100006
DA 2024-07-18
ER

PT J
AU Khediri, N
   Ben Ammar, M
   Kherallah, M
AF Khediri, Nouha
   Ben Ammar, Mohamed
   Kherallah, Monji
TI A Real-time Multimodal Intelligent Tutoring Emotion Recognition System
   (MITERS)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intelligent affective tutoring system; Multimodal emotion recognition;
   Decision fusion; Face; Text; Speech
AB Emotion recognition can be used in a wide range of applications. We are interested in the E-learning system because of the several benefits of learning anywhere and anytime. Despite important advances, students' emotions can influence the learning process, and this is the case with both traditional learning as well as E-learning. Emotion can limit and blocks our ability to learn, think, and solve problems. On the contrary, it can drive us to success by boosting our innate mental ability when we love what we do and when we are affected by happiness and excitement. In recent years, a large number of studies have addressed the problem of emotion recognition based on different modalities. But the information provided by student emotion recognition based on single-modal data like face is insufficient. Additionally, selecting one affective state over another might be challenging at times. To remove these ambiguities, we propose an Intelligent Affective Tutoring System named "Multimodal Intelligent Tutoring Emotion Recognition System" MITERS that merges three modalities such as face, text, and speech simultaneously. Our System is a real-time-based system that detects the emotion of students and gives adequate feedback. For this purpose, we use deep learning techniques. Among these are (a) Deep Convolution Neural Network (DCNN) used to detect emotion from face modality, (b) Bidirectional Long Short Memory (BiLSTM) for predicting emotions from text information, and (c) Convolutional Neural Network (CNN) which is used to detect emotions from speech modality. The experimental results are compared with some of the well-known approaches and the proposed MITERS has performed well with a classification accuracy of 97% in MELD which is a multimodal database.
C1 [Khediri, Nouha] Univ Tunis El Manar, Fac Sci Tunis, Dept Comp Sci, Tunis, Tunisia.
   [Khediri, Nouha; Ben Ammar, Mohamed] Northern Border Univ, Fac Comp & IT, Dept Informat Syst, Rafha, Saudi Arabia.
   [Kherallah, Monji] Univ Sfax, Fac Sci, Sfax, Tunisia.
C3 Universite de Tunis-El-Manar; Faculte des Sciences de Tunis (FST);
   Northern Border University; Universite de Sfax; Faculty of Sciences Sfax
RP Khediri, N (corresponding author), Univ Tunis El Manar, Fac Sci Tunis, Dept Comp Sci, Tunis, Tunisia.; Khediri, N (corresponding author), Northern Border Univ, Fac Comp & IT, Dept Informat Syst, Rafha, Saudi Arabia.
EM Nouha.khediri@fst.utm.tn; Mohammed.Ammar@nbu.edu.sa;
   Monji.kherallah@fss.usf.tn
RI Khediri, Nouha/JXX-4669-2024; Ben Ammar, Mohamed/KCK-7056-2024
OI Ben Ammar, Mohamed/0000-0001-8990-3924
FU Deanship of Scientific Research at Northern Border University, Arar, KSA
   [NBU-FFR-2023-0133]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at Northern Border University, Arar, KSA for funding this
   research work through the project number "NBU-FFR-2023-0133".
CR Ai H, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P797
   Ajibola Alim S., 2018, From Natural to Artificial Intelligence - Algorithms and Applications, P3, DOI DOI 10.5772/INTECHOPEN.80419
   Bahreini K, 2016, INT J HUM-COMPUT INT, V32, P415, DOI 10.1080/10447318.2016.1159799
   Ben Ammar M, 2010, EXPERT SYST APPL, V37, P3013, DOI 10.1016/j.eswa.2009.09.031
   Cao SX, 2023, VISUAL COMPUT, V39, P6553, DOI 10.1007/s00371-022-02748-z
   Cassano F, 2019, ADV INTELL SYST, V804, P156, DOI 10.1007/978-3-319-98872-6_19
   Choi JH, 2019, INFORM FUSION, V51, P259, DOI 10.1016/j.inffus.2019.02.010
   Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024
   D'Errico F, 2018, INT J EMOT EDUC, V10, P89
   D'Mello SK, 2011, J EXP PSYCHOL-APPL, V17, P1, DOI 10.1037/a0022674
   De Carolis B., 2021, Recognizing cognitive emotions in e-learning environment, In International Workshop on Higher Education Learning Methodologies and Technologies Online, P17
   Filali H, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6030095
   Ghosal D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2470
   Hazarika D., 2022, J Posit School Psychol, V6, P5291
   Khediri N, 2021, 2021 IEEE 21 INT C C
   Khediri N, 2017, INT AR C INF TECHN A
   Khediri N., 2023, Int J Comput Inf Eng, V17, P132
   Khediri N, 2022, LECT NOTES ARTIF INT, V13501, P75, DOI 10.1007/978-3-031-16014-1_7
   Kingsley A.O., 2022, IAES International Journal of Robotics and Automation, V11, P21
   LAM L, 1994, INT C PATT RECOG, P418, DOI 10.1109/ICPR.1994.576970
   Lin HCK, 2012, TURK ONLINE J EDUC T, V11, P418
   Litman D, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P25, DOI 10.1109/ASRU.2003.1318398
   Liu MC, 2023, EDUC INF TECHNOL, V28, P7845, DOI 10.1007/s10639-022-11479-6
   Luna-Jiménez C, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227665
   Ma WT, 2014, J EDUC PSYCHOL, V106, P901, DOI 10.1037/a0037123
   Maatuk AM, 2022, J COMPUT HIGH EDUC, V34, P21, DOI 10.1007/s12528-021-09274-2
   Mousavinasab E, 2021, INTERACT LEARN ENVIR, V29, P142, DOI 10.1080/10494820.2018.1558257
   Muthamilselvan T, 2023, MULTIMED TOOLS APPL, V82, P19945, DOI 10.1007/s11042-022-14124-z
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Namrata D, 2013, Int J Adv Res Eng Technol, V1
   Nandi A, 2020, 2020 INT C OMN INT S, ppp1
   Petrakos M, 2001, IEEE T GEOSCI REMOTE, V39, P2539, DOI 10.1109/36.964992
   Petrovica S, 2017, PROCEDIA COMPUT SCI, V104, P437, DOI 10.1016/j.procs.2017.01.157
   Poria S, 2019, Arxiv, DOI arXiv:1810.02508
   Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P527
   Ratnadeep D., 2015, Int J Sci Eng Res, V6, P143
   Reimers F., 2020, OECD
   Sekkate S, 2023, MULTIMED TOOLS APPL, V82, P11443, DOI 10.1007/s11042-022-14051-z
   Siddiqui HUR, 2023, MULTIMED TOOLS APPL, V82, P18565, DOI 10.1007/s11042-022-14091-5
   Siriwardhana S, 2020, IEEE ACCESS, V8, P176274, DOI 10.1109/ACCESS.2020.3026823
   Tang K, 2014, CAN CON EL COMP EN
   Le TH, 2023, VIETNAM J COMPUT SCI, V10, P243, DOI 10.1142/S2196888822500397
   Veni S, 2021, IOP C SERIES MAT SCI
   Wang HH, 2023, EDUC INF TECHNOL, V28, P9113, DOI 10.1007/s10639-022-11555-x
   Xie BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144913
NR 45
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-16424-4
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200012
DA 2024-07-18
ER

PT J
AU Raufmehr, F
   Salehi, MR
   Abiri, E
AF Raufmehr, Farhad
   Salehi, Mohammad Reza
   Abiri, Ebrahim
TI A neuro-fuzzy QP estimation approach for H.266/VVC-based live video
   broadcasting systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bit rate; Buffer; QP; H.266/VVC; Neuro-Fuzzy; Dynamic Programming
ID PARTICLE SWARM OPTIMIZATION; SERVICE COMPOSITION; ALGORITHM; FRAMEWORK;
   STRATEGY; RANKING
AB Live video broadcasting is a popular application properly considered in lately developed standard, Versatile Video Coding (H.266/VVC). In live video broadcasting, both the bandwidth and buffer volume are limited, while a high quality level is demanded. In order to solve these problems, a Quantization Parameter Estimation Algorithm (QEA) is proposed. The core of the proposed algorithm is a neuro-fuzzy system that changes the Quantization Parameter (QP) gradually to produce a bandwidth-compliant bit rate and prohibit buffer saturation and starvation while providing high quality. The estimation is conducted according to the proportional, integral, and derivative components of the bit error. In other words, the proposed QEA is a Proportional-Integral-Derivative (PID) controller. The optimal parameters of the neuro-fuzzy system are obtained through the training process. The required data set for the training process is established by taking advantage of dynamic programming. The experiments affirm that the proposed approach achieves the target rate with an average error equal to 1.41% and fully respects the buffering boundaries. This method has at least a 2.48% bit rate reduction rather than other QEAs. Meanwhile, the proposed QEA is faster than other algorithms.
C1 [Raufmehr, Farhad; Salehi, Mohammad Reza; Abiri, Ebrahim] Shiraz Univ Technol, Dept Elect Engn, Shiraz, Iran.
   [Raufmehr, Farhad] Shahid Sattari Aeronaut Univ Sci & Technol, Dept Elect Engn, Tehran, Iran.
C3 Shiraz University of Technology
RP Raufmehr, F (corresponding author), Shiraz Univ Technol, Dept Elect Engn, Shiraz, Iran.; Raufmehr, F (corresponding author), Shahid Sattari Aeronaut Univ Sci & Technol, Dept Elect Engn, Tehran, Iran.
EM f.raufmehr@sutech.ac.ir; salehi@sutech.ac.ir; abiri@sutech.ac.ir
RI Al-Khafaji, Hamza Mohammed Ridha/D-6335-2019
OI Al-Khafaji, Hamza Mohammed Ridha/0000-0003-3620-581X; Raufmehr,
   Farhad/0000-0002-0423-482X
CR A-Masri E, 2007, IEEE IC COMP COM NET, P529
   Asghari S, 2019, INT J BIO-INSPIR COM, V13, P257, DOI 10.1504/IJBIC.2019.100139
   Bai X, 2021, IEEE T AERO ELEC SYS, V57, P3279, DOI 10.1109/TAES.2021.3074204
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P3832, DOI 10.1109/TITS.2020.3048844
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P3841, DOI 10.1109/TITS.2021.3059455
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P2133, DOI 10.1109/TITS.2020.3040909
   Cao B, 2021, IEEE INTERNET THINGS, V8, P3099, DOI 10.1109/JIOT.2020.3033473
   Cao B, 2020, IEEE T FUZZY SYST, V28, P939, DOI 10.1109/TFUZZ.2020.2972207
   Cao B, 2020, IEEE T IND INFORM, V16, P3597, DOI 10.1109/TII.2019.2952565
   Cao B, 2020, SWARM EVOL COMPUT, V53, DOI 10.1016/j.swevo.2019.100626
   Chen GM, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/3215337
   Clerc M, 2012, Innovations and developments of swarm intelligence applications, P1
   Comesaña-Campos A, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17228644
   Dahan F, 2021, IEEE ACCESS, V9, P95208, DOI 10.1109/ACCESS.2021.3092288
   Dai XX, 2023, IEEE T IND INFORM, V19, P662, DOI 10.1109/TII.2022.3186641
   Darbandi M., 2017, Published by Journal of Computer Sciences and Applications, V5, P11, DOI DOI 10.12691/JCSA-5-1-2
   Darbandi M., 2017, HCTL International Journal of Technology Innovations and Research, V23, P10, DOI DOI 10.5281/ZENODO.345288
   Darbandi M., 2017, Published by HCTL, Int. J. Technol. Innov. Res, V24, P1, DOI DOI 10.5281/ZENODO.1034475
   de Gyves Avila S, 2014, CLOSER
   Dhanachandra N, 2020, MULTIMED TOOLS APPL, V79, P18839, DOI 10.1007/s11042-020-08699-8
   Dimolitsas I, 2021, IEEE COMMUN MAG, V59, P28, DOI 10.1109/MCOM.211.2001056
   Gao J, 2022, CONCURRENT ENG-RES A, V30, P46, DOI 10.1177/1063293X211032343
   Garg SK, 2013, FUTURE GENER COMP SY, V29, P1012, DOI 10.1016/j.future.2012.06.006
   Kashani MH, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4340
   Hayyolalam V, 2018, 1 INT COMPR COMP C E
   Hsiao I.-H., 2022, J. Artif. Intell. Technol, V2, P47, DOI [10.37965/jait.2022.0090, DOI 10.37965/JAIT.2022.0090]
   Hu Q., 2022, J. Artif. Intell.Technol., V2, P80, DOI 10.37965/jait.2022.0105
   Jatoth C, 2017, IEEE T SERV COMPUT, V10, P475, DOI 10.1109/TSC.2015.2473840
   Jeya S., 2021, Ilkogretim Online, V20, P12
   Karimi MB, 2017, J SUPERCOMPUT, V73, P1387, DOI 10.1007/s11227-016-1814-8
   Krishnamoorthy C. S., 2018, Artificial intelligence and expert systems for engineers
   Li A, 2021, IEEE T COMMUN, V69, P291, DOI 10.1109/TCOMM.2020.3031616
   Li B, 2022, IEEE T AUTOMAT CONTR, V67, P5762, DOI 10.1109/TAC.2021.3124750
   Li SY, 2023, MACHINES, V11, DOI 10.3390/machines11080837
   Li WJ, 2019, IEEE ACCESS, V7, P34207, DOI 10.1109/ACCESS.2019.2904081
   Li XT, 2020, NEURAL COMPUT APPL, V32, P1765, DOI 10.1007/s00521-019-04566-2
   Lv ZH, 2021, IEEE INTERNET THINGS, V8, P6273, DOI 10.1109/JIOT.2020.3004469
   Lv ZH, 2020, COMPUT COMMUN, V153, P42, DOI 10.1016/j.comcom.2020.01.060
   Ma K, 2021, IEEE INTERNET THINGS, V8, P13343, DOI 10.1109/JIOT.2021.3065966
   Majumder A, 2013, J MECH SCI TECHNOL, V27, P2143, DOI 10.1007/s12206-013-0524-x
   MAMDANI EH, 1977, IEEE T COMPUT, V26, P1182, DOI 10.1109/TC.1977.1674779
   Mansouri N, 2019, COMPUT IND ENG, V130, P597, DOI 10.1016/j.cie.2019.03.006
   Mendel J.M., 2017, Uncertain Rule-Based Fuzzy Systems Introduction and New Directions, V2e, DOI DOI 10.1007/978-3-319-51370-6
   Naseri A, 2019, J AMB INTEL HUM COMP, V10, P1851, DOI 10.1007/s12652-018-0773-8
   Nezhadkian M., 2023, Jour- 2 nal of Computational and Cognitive Engineering, V2, P124
   Ni QF, 2022, IEEE T NETW SCI ENG, V9, P1187, DOI 10.1109/TNSE.2021.3137353
   Piltan F, 2011, Int J Robot Autom, V2, P283
   Qian L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12084073
   Ren XJ, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5967
   Sakamoto S, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS CISIS 2015, P254, DOI 10.1109/CISIS.2015.39
   Sarkar A., 2022, Journal of Computational and Cognitive Engineering, V1, P109, DOI [10.47852/bonviewJCCE2202162, DOI 10.47852/BONVIEWJCCE2202162]
   Sefati SS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134873
   Shang M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18042101
   Shi JY, 2023, J LIGHTWAVE TECHNOL, V41, P2381, DOI 10.1109/JLT.2023.3236400
   Song FZ, 2022, IEEE T NEUR NET LEAR, V33, P1594, DOI 10.1109/TNNLS.2020.3042975
   Song YJ, 2023, FUTURE GENER COMP SY, V145, P77, DOI 10.1016/j.future.2023.03.020
   Sun Y, 2023, CAAI Trans Intell Technol
   Tabrizchi H, 2020, J SUPERCOMPUT, V76, P9493, DOI 10.1007/s11227-020-03213-1
   Tan JL, 2023, IEEE T DEPEND SECURE, V20, P4719, DOI 10.1109/TDSC.2022.3232537
   Tavousi F, 2022, CLUSTER COMPUT, V25, P303, DOI 10.1007/s10586-021-03406-0
   Wang X, 2020, Arxiv, DOI [arXiv:2002.07920, DOI 10.47852/BONVIEWJCCE2202320]
   Wang YQ, 2023, CAAI T INTELL TECHNO, V8, P849, DOI 10.1049/cit2.12106
   Wang ZC, 2022, SMART INNOV SYST TEC, V268, P183, DOI 10.1007/978-981-16-8048-9_18
   Xie N, 2021, J IND INF INTEGR, V23, DOI 10.1016/j.jii.2021.100211
   Xie Y, 2023, IEEE T SERV COMPUT, V16, P4183, DOI 10.1109/TSC.2023.3311785
   Yao Y., 2023, IEEE Trans. Intell. Transport. Syst.
   Yazdanjue N, 2020, COMPUT J, V63, P1039, DOI 10.1093/comjnl/bxz069
   Yu Q, 2015, COMPUT ELECTR ENG, V41, P18, DOI 10.1016/j.compeleceng.2014.12.004
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zanbouri K, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4259
   Zhang JZ, 2023, IEEE T ROBOT, V39, P1496, DOI 10.1109/TRO.2022.3208503
   Zhang Y, 2022, RES TRANSP ECON, V92, DOI 10.1016/j.retrec.2021.101095
   Zhang Z., 2022, J Artif Intell Technol, V2, P111, DOI [DOI 10.37965/JAIT.2022.0106, 10.37965/jait.2022.0106]
   Zhang ZC, 2023, CAAI T INTELL TECHNO, V8, P987, DOI 10.1049/cit2.12141
   Zheng YZ, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10101399
   Zhou GQ, 2021, IEEE ACCESS, V9, P27140, DOI 10.1109/ACCESS.2021.3057719
   Zhou JJ, 2018, INFORM SCIENCES, V456, P50, DOI 10.1016/j.ins.2018.05.009
NR 78
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17795-4
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800004
DA 2024-07-18
ER

PT J
AU Alturki, N
   Umer, M
   Alshardan, A
   Saidani, O
   Abate, AF
   Ashraf, I
AF Alturki, Nazik
   Umer, Muhammad
   Alshardan, Amal
   Saidani, Oumaima
   Abate, Andrea F.
   Ashraf, Imran
TI Convolutional neural network and ensemble machine learning model for
   optimizing performance of emotion recognition in wild
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE In-the-wild emotion recognition; Facemask; Deep learning; Image
   processing; Region of interest detection
ID COVID-19; CLASSIFICATION; IMPACT
AB Emotions play a pivotal role in our everyday interactions, serving as a crucial indicator of a speaker's influence. Among various means of expression, facial emotions hold a special prominence compared to hand gestures, body movements, and more. The expressions on the face serve as a primary canvas for conveying these emotions. Numerous studies have introduced approaches and models for recognizing emotions. However, it is important to note that many of these approaches have been predominantly tested on datasets gathered in controlled environments. In contrast, real-world environments are dynamic and unpredictable, introducing numerous challenges to emotion recognition. The current study pursues a two-way approach to emotion recognition. Firstly, the research introduces a novel face mask dataset, which is designed for emotion recognition in a real-time setting. This dataset is utilized in conjunction with a convolutional neural network (CNN), and multiple image processing techniques are applied to the manually labeled face mask dataset. The second phase explores emotion recognition through textual data, employing a range of features, including hand-crafted, Word Embedding, Fast Text embedding, and Transformer models. The study compares the models' performance using original features versus convoluted features. The study aims to provide valuable insights into emotion recognition through both textual and face-masked data, contributing to our understanding of this important field.
C1 [Alturki, Nazik; Umer, Muhammad; Alshardan, Amal; Saidani, Oumaima] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Syst, POB 84428, Riyadh 11671, Saudi Arabia.
   [Umer, Muhammad; Saidani, Oumaima] Islamia Univ Bahawalpur, Dept Comp Sci, Bahawalpur 63100, Pakistan.
   [Abate, Andrea F.] Univ Salerno, Dept Comp Sci, I-84084 Fisciano, Italy.
   [Ashraf, Imran] Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 Princess Nourah bint Abdulrahman University; Islamia University of
   Bahawalpur; University of Salerno; Yeungnam University
RP Ashraf, I (corresponding author), Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
EM namalturki@pnu.edu.sa; umer.sabir@iub.edu.pk; amalshardan@pnu.edu.sa;
   ocsaidani@pnu.edu.sa; abate@unisa.it; imranashraf@ynu.ac.kr
RI Umer, Muhammad/KHU-2339-2024; Alshardan, Amal/KVZ-0940-2024; Alturki,
   Nazik/HKN-4309-2023; Umer, Muhammad/AAX-4594-2020
OI Umer, Muhammad/0009-0001-8751-6100; Alturki, Nazik/0000-0002-8434-7292;
   Umer, Muhammad/0000-0002-6015-9326; Alshardan, Amal/0000-0003-3523-9102;
   Ashraf, Imran/0000-0002-8271-6496
FU Princess Nourah bint Abdulrahman University Researchers Supporting
   Project [PNURSP2023R333]; Princess Nourah bint Abdulrahman University,
   Riyadh, Saudi Arabia
FX This research was funded by Princess Nourah bint Abdulrahman University
   Researchers Supporting Project number (PNURSP2023R333), Princess Nourah
   bint Abdulrahman University, Riyadh, Saudi Arabia.
CR Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1
   Ahmad AR, 2020, J MED INTERNET RES, V22, DOI 10.2196/19556
   Al-Zaman Md Sayeed, 2021, JOURNAL MEDIA, V2, P100, DOI DOI 10.3390/JOURNALMEDIA2010007
   Almaev T, 2020, Symmetry, V12, P1665
   Apuke OD, 2021, TELEMAT INFORM, V56, DOI 10.1016/j.tele.2020.101475
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Asif Sohaib, 2021, 2021 4th International Conference on Artificial Intelligence and Big Data (ICAIBD), P70, DOI 10.1109/ICAIBD51990.2021.9459008
   Bai Y, 2020, JAMA-J AM MED ASSOC, V323, P1406, DOI 10.1001/jama.2020.2565
   Bani M, 2021, MED SCI EDUC, V31, P1273, DOI 10.1007/s40670-021-01317-8
   Barkur G, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102089
   Bourke L, 2023, J EXP CHILD PSYCHOL, V226, DOI 10.1016/j.jecp.2022.105580
   Bow S.-T., 2002, PATTERN RECOGN
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chakraborty K, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106754
   Chauhan R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P278, DOI 10.1109/ICSCCC.2018.8703316
   Chintalapudi N, 2021, INFECT DIS REP, V13, P329, DOI 10.3390/idr13020032
   Depoux A, 2021, Covid-19 coronavirus / death toll
   Depoux A, 2020, J TRAVEL MED, V27, DOI 10.1093/jtm/taaa031
   Drias HH, 2020, medRxiv
   Lopez CE, 2020, Arxiv, DOI arXiv:2003.10359
   Feng S, 2020, LANCET RESP MED, V8, P434, DOI 10.1016/S2213-2600(20)30134-X
   Feng YH, 2020, Arxiv, DOI arXiv:2006.08581
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao JL, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231924
   Garcia LP, 2020, EPIDEMIOL SERV SAUDE, V29, DOI [10.1590/S1679-49742020000400019, 10.1590/s1679-49742020000400019]
   GARDNER WA, 1984, SIGNAL PROCESS, V6, P113, DOI 10.1016/0165-1684(84)90013-6
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Grahlow M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262840
   Guo YR, 2020, MILITARY MED RES, V7, DOI 10.1186/s40779-020-00240-0
   Hackeling G, 2017, Mastering Machine Learning with Scikit-Learn
   Hung M, 2020, J MED INTERNET RES, V22, DOI 10.2196/22590
   Imamah, 2020, 2020 6th Information Technology International Seminar (ITIS), P238, DOI 10.1109/ITIS50118.2020.9320958
   Karim M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12063203
   Khalid M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082788
   Kleinberg B, 2020, Arxiv, DOI [arXiv:2004.04225, DOI arXiv:2004.04225.v2, DOI 10.48550/ARXIV.2004.04225]
   Lades LK, 2020, BRIT J HEALTH PSYCH, V25, P902, DOI 10.1111/bjhp.12450
   Lamsal R, 2021, APPL INTELL, V51, P2790, DOI 10.1007/s10489-020-02029-z
   learn S, 2017, Scikit-learn classification and regression models
   learn S, 2018, Scikit-learn feature extraction with tf/idf
   Leung NHL, 2020, NAT MED, V26, P676, DOI 10.1038/s41591-020-0843-2
   Li I., 2020, P 40 SGAI INT C ART, V12498, DOI [10.1007/978-3-030-63799-6_27, DOI 10.1007/978-3-030-63799-6_27]
   Li SJ, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17062032
   Li TP, 2022, ENTERP INF SYST-UK, V16, P472, DOI 10.1080/17517575.2020.1797180
   Li ZH, 2022, IEEE T SYST MAN CY-S, V52, P5816, DOI 10.1109/TSMC.2021.3131482
   Liu X, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01816-6
   Liu Y, 2023, IEEE T PATTERN ANAL, V45, P11624, DOI 10.1109/TPAMI.2023.3284038
   Liu Z, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3294636
   Manzoor M, 2021, IEEE ACCESS, V9, P128359, DOI 10.1109/ACCESS.2021.3112546
   Marini M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84806-5
   Mittal M, 2020, INT MARIT HEALTH, V71, P213, DOI 10.5603/IMH.2020.0038
   Mohan Puranjay, 2021, Innovations in Electrical and Electronic Engineering. Proceedings of ICEEE 2021. Lecture Notes in Electrical Engineering (LNEE 756), P657, DOI 10.1007/978-981-16-0749-3_52
   Mukhiddinov M, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031080
   Naseem U., 2022, arXiv
   Naseem U., 2020, 2020 INT JOINT C NEU
   Naseem U, 2021, 2021 INT JOINT C NEU, P1
   Naseem U, 2021, IEEE T COMPUT SOC SY, V8, P1003, DOI 10.1109/TCSS.2021.3051189
   Naseem U, 2019, LECT NOTES ARTIF INT, V11919, P381, DOI 10.1007/978-3-030-35288-2_31
   Nie W., 2023, IEEE Trans. Multimed.
   Pazhoohi F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0257740
   Pérez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002
   Rupapara V, 2021, IEEE ACCESS, V9, P78621, DOI 10.1109/ACCESS.2021.3083638
   Rustam F, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12061474
   Samuel J, 2020, INFORMATION, V11, DOI 10.3390/info11060314
   Sharaff A, 2019, Advances in computer communication and computational sciences, P189
   Sriram B, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/1835449.1835643
   Staszkiewicz P, 2020, IEEE ACCESS, V8, P106009, DOI 10.1109/ACCESS.2020.2999614
   Stein RA, 2019, INFORM SCIENCES, V471, P216, DOI 10.1016/j.ins.2018.09.001
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tzirakis P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5089, DOI 10.1109/ICASSP.2018.8462677
   Xue J, 2020, Arxiv, DOI [arXiv:2005.12830, 10.2196/20550, DOI 10.2196/20550]
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P33, DOI 10.1016/j.patrec.2017.09.011
   Zhang X, 2023, CAAI T INTELL TECHNO, V8, P1480, DOI [10.1049/cit2.12174, 10.7633/j.issn.1003-6202.2023.06.001]
   Zhou XX, 2022, APPL INTELL, V52, P12556, DOI 10.1007/s10489-021-03121-8
NR 73
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17744-1
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9MN6
UT WOS:001115250300001
DA 2024-07-18
ER

PT J
AU Siddamllappa, UK
   Gandhewar, N
AF Siddamllappa, U. Kumar
   Gandhewar, Nisarg
TI Hybrid optimization technique to improve feature selection in image
   classification technique using RBFNN and ABC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ESSO; RBFNN; ORBFNN; ABC
ID MODEL
AB Feature selection is one of the major components of the data processing flow that correctly selects real-time entities for categorization. It is utilized in numerous research fields, including the machine learning approach (Med Biol Eng Comput (Springer) 59(02):333-353 [1]). Feature selection and classification are beneficial to the processing of biomedical data in high-importance, high-dimensional datasets. Due to numerous obstacles in research, the current implementations are inadequate for predicting classification accuracy. To handle the classification challenge, we require dedicated neural network and classification model approaches (J Comput Mater Continua (CMC) 72(1):243-259 [2]). Initial features are selected using a method called "fuzzy c-means clustering with rough set theory" and are subsequently classified using "support vector machines." In addition, the current approach is extremely time-consuming. The proposed solution used efficient feature subset selection in high-dimensional data to fix these problems. To begin with, our recommended method used Enhanced Social Spider Optimization (ESSO) computation to select the best highlights (IEEE Trans Circuits Syst Video Technol (TCSVT) 28(2):454-467 [3]). When categorizing data, the Optimal Radial Basis Function Neural Network (ORBFNN) is used. Methods for calculating Artificial Bee Colony (ABC) are used to streamline RBFNN's sufficiency in characterizing smaller scale show information.
C1 [Siddamllappa, U. Kumar] Davangere Univ, Dept Studies Comp Sci, Davangere 577007, Karnataka, India.
   [Siddamllappa, U. Kumar; Gandhewar, Nisarg] Dr APJ Abdul Kalam Univ, Dept Comp Sci & Engn, Indore 452016, India.
C3 Davanagere University
RP Siddamllappa, UK (corresponding author), Davangere Univ, Dept Studies Comp Sci, Davangere 577007, Karnataka, India.; Siddamllappa, UK (corresponding author), Dr APJ Abdul Kalam Univ, Dept Comp Sci & Engn, Indore 452016, India.
EM siddamallappa90867@gmail.com
RI gandhewar, nisarg/T-5347-2017
OI gandhewar, nisarg/0000-0002-9974-985X
CR Abualigah L., 2019, INT J SCI APPL INF T, V8, P139
   Agrawal P, 2022, COMPLEX INTELL SYST, V8, P43, DOI 10.1007/s40747-021-00351-8
   Allam M., 2017, International Journal on Computer Science and Engineering, V9, P75
   Alomari OA, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107034
   [Anonymous], 2016, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), V12
   Arslan S, 2019, APPL SOFT COMPUT, V78, P515, DOI 10.1016/j.asoc.2019.03.014
   Azhagu Sundari B, 2013, Int J Innovative Technol Exploring Eng (IJITEE), V2, P2
   Basavaprasad B, 2014, IJRET Int J Res Eng Technol, V3, P155
   BenSaid F, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107629
   El-Hasnony IM, 2020, IEEE ACCESS, V8, P66989, DOI 10.1109/ACCESS.2020.2986232
   Cruz DPF, 2016, NEUROCOMPUTING, V172, P427, DOI 10.1016/j.neucom.2015.03.106
   Houari R, 2016, EXPERT SYST APPL, V64, P247, DOI 10.1016/j.eswa.2016.07.041
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Karthik S, 2022, CMC-COMPUT MATER CON, V72, P243, DOI 10.32604/cmc.2022.023864
   Katsaggelos AK, 2012, Digital image restoration, P24
   Liu Y, 2019, IEEE ACCESS, V7, P81794, DOI 10.1109/ACCESS.2019.2923846
   Mansour NA, 2022, J AMB INTEL HUM COMP, V13, P41, DOI 10.1007/s12652-020-02883-2
   Mazaheri S., 2020, Iran J Comput Sci, P1, DOI DOI 10.1007/S42044-019-00038-X
   Mehmood H, 2018, Pakistan J Art Cult, V1
   Pan JS, 2021, ENERGY, V226, DOI 10.1016/j.energy.2021.120329
   Qaraad M, 2021, IEEE ACCESS, V9, P42884, DOI 10.1109/ACCESS.2021.3065341
   Robert J, 1989, Digital image processing and computer vision, V286
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami O, 2021, COMPUTAT GEOSCI, V25, P911, DOI 10.1007/s10596-020-10030-1
   Shu XB, 2018, IEEE T CIRC SYST VID, V28, P454, DOI 10.1109/TCSVT.2016.2607345
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Singh LK, 2021, MED BIOL ENG COMPUT, V59, P333, DOI 10.1007/s11517-020-02307-5
   Too J, 2021, J SUPERCOMPUT, V77, P2844, DOI 10.1007/s11227-020-03378-9
   Xie H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051816
   Yan CH, 2019, ANAL CHIM ACTA, V1080, P35, DOI 10.1016/j.aca.2019.07.012
NR 30
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 5
PY 2023
DI 10.1007/s11042-023-17427-x
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8R0
UT WOS:001121582900001
DA 2024-07-18
ER

PT J
AU Cheng, YR
   Ren, H
   Zhang, R
   Lu, H
AF Cheng, Yunrui
   Ren, Hao
   Zhang, Rui
   Lu, Hong
TI Context-aware coarse-to-fine network for single image desnowing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image desnowing; Coarse-to-fine; Context interaction; Contrastive
   learning
ID RAIN; REMOVAL
AB Image desnowing is a challenging task in computer vision, as it requires the removal of snow from images while preserving the underlying scene structure and content. In order to achieve high performance, desnowing methods need to be able to effectively capture both local and global information in the image. The proposed method addresses this challenge by introducing a novel Context-aware Feature Aggregation (CFA) module. The CFA module is designed to capture both local and global information by aggregating features of the network in latent space. This allows the method to better understand the contextual relationships in the image, which is essential for accurate snow removal. In addition to the CFA module, the proposed method also introduces a Selective Refinement Head (SRH). The SRH is designed to adaptively fuse coarse features from the encoder and decoder of the network. This allows the method to refine the output by incorporating relevant information from both low-level and high-level representations. Finally, the proposed method leverages the capabilities of contrastive learning to better align the desnow images and ground-truth images in perceptual space. This leads to improved image quality and desnowing performance. Extensive experiments on both synthetic and real-world datasets show that the proposed method achieves state-of-the-art results on image desnowing task.
C1 [Cheng, Yunrui; Ren, Hao; Zhang, Rui; Lu, Hong] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai, Peoples R China.
C3 Fudan University
RP Lu, H (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai, Peoples R China.
EM yunruicheng21@m.fudan.edu.cn; hren17@fudan.edu.cn;
   zhangrui@fudan.edu.cn; honglu@fudan.edu.cn
RI , leftthomas/AIC-3992-2022
OI , leftthomas/0000-0002-5639-450X; Lu, Hong/0000-0002-4572-2854
FU National Natural Science Foundation of China [62072112]; National Key R
   &D Program of China [2020AAA0108301]; Key Area Support Plan of Guangdong
   Province for Jihua Laboratory [X190051TB190]
FX This work was supported by National Natural Science Foundation of China
   (No.62072112), National Key R &D Program of China (2020AAA0108301), and
   Key Area Support Plan of Guangdong Province for Jihua Laboratory
   (X190051TB190).
CR Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen WT, 2022, PROC CVPR IEEE, P17632, DOI 10.1109/CVPR52688.2022.01713
   Chen WT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4176, DOI 10.1109/ICCV48922.2021.00416
   Chen X, IEEE C COMPUTER VISI, P2017
   Chen Z. He, 2023, arXiv
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Ding XH, 2016, MULTIMED TOOLS APPL, V75, P2697, DOI 10.1007/s11042-015-2657-7
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fazlali H, 2022, MULTIMED TOOLS APPL, V81, P14105, DOI 10.1007/s11042-022-12012-0
   Gao GW, 2022, IEEE T CIRC SYST VID, V32, P2550, DOI 10.1109/TCSVT.2020.3042178
   He ZW, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108274
   Henaff OJ, 2020, PR MACH LEARN RES, V119
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Jaw DW, 2021, IEEE T CIRC SYST VID, V31, P1342, DOI 10.1109/TCSVT.2020.3003025
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kingma D. P., 2014, arXiv
   Lee H, 2022, CVPR, P2139
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li Z, 2019, IEEE ACCESS, V7, P25016, DOI 10.1109/ACCESS.2019.2900323
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu Y, 2021, PROC CVPR IEEE, P13360, DOI 10.1109/CVPR46437.2021.01316
   Liu YF, 2018, IEEE T IMAGE PROCESS, V27, P3064, DOI 10.1109/TIP.2018.2806202
   Loshchilov I, 2016, ARXIV
   Pei S-C, 2014, IEEE INT C MULT EXP, P1
   Qi YH, 2022, MULTIMED TOOLS APPL, V81, P35935, DOI 10.1007/s11042-022-13342-9
   Quan Y, 2023, IEEE Trans Circuit Syst Video Technol
   Quan YH, 2019, IEEE I CONF COMP VIS, P2463, DOI 10.1109/ICCV.2019.00255
   Rajderkar D, 2013, INT C TREND COMPUT C, P576, DOI 10.1109/ICE-CCN.2013.6528565
   Ramachandran P, 2019, ANN C NEUR INF PROC
   Shafiee MJ, 2017, arXiv
   Sharma PK, 2021, MULTIMED TOOLS APPL, V80, P1075, DOI 10.1007/s11042-020-09642-7
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Valanarasu JMJ, 2022, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR52688.2022.00239
   Wang C, 2017, MULTIMED TOOLS APPL, V76, P2019, DOI 10.1007/s11042-015-3195-z
   Wang C, 2020, MULTIMED TOOLS APPL, V79, P19595, DOI 10.1007/s11042-020-08855-0
   Wang MH, 2018, MULTIMED TOOLS APPL, V77, P25905, DOI 10.1007/s11042-018-5825-8
   Wang X, 2023, NEURAL COMPUT APPL, V35, P8589, DOI 10.1007/s00521-022-08132-1
   Wang YL, 2017, IEEE T IMAGE PROCESS, V26, P3936, DOI 10.1109/TIP.2017.2708502
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Wei-Ting Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P754, DOI 10.1007/978-3-030-58589-1_45
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Xianhui Zheng, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P258, DOI 10.1007/978-3-642-42051-1_33
   Xu J., 2012, CANADIAN CTR SCI ED, V5, P49, DOI DOI 10.5539/CIS.V5N3P49
   Yadav S, 2021, MULTIMED TOOLS APPL, V80, P36491, DOI 10.1007/s11042-021-11442-6
   Yeh CH, 2018, MULTIMED TOOLS APPL, V77, P20001, DOI 10.1007/s11042-017-5430-2
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zheng Y, 2023, PROC CVPR IEEE, P5785, DOI 10.1109/CVPR52729.2023.00560
   Zhu D, 2022, Multimed Tool Appl, P1
   Zhu X., 2021, INT C LEARNING REPRE
NR 55
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 4
PY 2023
DI 10.1007/s11042-023-17674-y
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8Q2
UT WOS:001121582100001
DA 2024-07-18
ER

PT J
AU Mailka, H
   Abouzahir, M
   Ramzi, M
AF Mailka, Hamza
   Abouzahir, Mohamed
   Ramzi, Mustapha
TI An efficient end-to-end EKF-SLAM architecture based on LiDAR, GNSS, and
   IMU data sensor fusion for autonomous ground vehicles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE State estimation; Simultaneous localisation and mapping (SLAM); Extended
   kalman filter (EKF); Multi-sensor data fusion; Scan correlation;
   Autonomous driving
ID VISUAL LOCALIZATION; VERSATILE
AB The autonomous ground vehicle's successful navigation with a high level of performance is dependent on accurate state estimation, which may help in providing excellent decision-making, planning, and control tasks. Outside factors like air bias and multipath effects have an impact on the GPS data, obtaining accurate pose estimation remains challenging. To obtain a highly precise pose estimation, the authors propose using an end-to-end simultaneous localization and mapping architecture based on scan matching and an extended Kalman filter to perform a successful prediction using lidar, GNSS and IMU data sensor fusion. In terms of pose estimation efficiency, the obtained results from EKF are compared to the UKF filter in different sequences on the Kitti dataset to more thoroughly evaluate our designed approach. The EKF filter has a good improvement, with approximately 0.29, 0.31, 0.24, 0.34, and 0.27 of the mean RMSE error of the trajectories 09_30_drive_0018, 09_30_drive_0020, 09_30_drive_0027, 10_03_drive_0033, and 10_03_drive_0034, respectively. The proposed approach was evaluated not only on KITTI dataset but also using our data recording platform called KONA Platform.
C1 [Mailka, Hamza; Abouzahir, Mohamed; Ramzi, Mustapha] Mohammed V Univ Rabat, High Sch Technol Sale, Lab Syst Anal Informat Proc & Ind Management, Rabat, Morocco.
C3 Mohammed V University in Rabat
RP Mailka, H (corresponding author), Mohammed V Univ Rabat, High Sch Technol Sale, Lab Syst Anal Informat Proc & Ind Management, Rabat, Morocco.
EM haamza.mailka@gmail.com
RI Mailka, Hamza/KVZ-0617-2024
OI Mailka, Hamza/0000-0003-3537-7150
FU Moroccan National Center for Scientific and Technical Research (CNRST)
   [37 UM5R2022]
FX In the first, we would like to express our gratitude to the Moroccan
   National Center for Scientific and Technical Research (CNRST) for its
   encouragement, as well as for its financial support (grant number: 37
   UM5R2022). Additionally, we are immensely grateful to the region of
   Rabat-Sale-Kenitra for their invaluable financial contributions, which
   significantly contributed to the realization of this work. We also wish
   to acknowledge the dedicated efforts and collaboration with the company
   FAAR-PRONERGY, without which this work would not have been possible.
CR Abouzahir M, 2018, ROBOT AUTON SYST, V100, P14, DOI 10.1016/j.robot.2017.10.019
   [Anonymous], 1990, Autonomous Robot Vehicles, DOI 10.1007/978-1-4613-8997-2{}14
   Bian JW, 2019, ADV NEUR IN, V32
   Bian JW, 2021, INT J COMPUT VISION, V129, P2548, DOI 10.1007/s11263-021-01484-6
   Chen XY, 2023, IEEE COMPUT SOC CONF, P172, DOI 10.1109/CVPRW59228.2023.00022
   Cvisic I, 2022, ROBOT AUTON SYST, V155, DOI 10.1016/j.robot.2022.104189
   Darbha S, 2019, IEEE T INTELL TRANSP, V20, P1954, DOI 10.1109/TITS.2018.2859765
   Elsanhoury M, 2021, I NAVIG SAT DIV INT, P2754, DOI 10.33012/2021.17961
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Engel J, 2013, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2013.183
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Fresk E, 2013, 2013 EUROPEAN CONTROL CONFERENCE (ECC), P3864
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Giorgi G, 2019, ADV SPACE RES, V64, P1256, DOI 10.1016/j.asr.2019.06.010
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486
   Guney MA, 2020, J ROBOT, V2020, DOI 10.1155/2020/6217409
   Hein GW, 2020, SATELLITE NAVIG, V1, DOI 10.1186/s43020-020-00023-x
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777
   Kohlbrecher S, 2014, LECT NOTES ARTIF INT, V8371, P624, DOI 10.1007/978-3-662-44468-9_58
   Konatowski S., 2016, ANN NAVIGATION, V23, P69, DOI [10.1515/aon-2016-0005, DOI 10.1515/AON-2016-0005]
   Konolige K., 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P22, DOI 10.1109/IROS.2010.5649043
   Lal N, 2022, MULTIMED TOOLS APPL, V81, P6373, DOI 10.1007/s11042-021-11834-8
   Lee JH, 2015, MULTIMED TOOLS APPL, V74, P3599, DOI 10.1007/s11042-013-1672-9
   Lee Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247022
   Leung KT, 2011, MECH SYST SIGNAL PR, V25, P1988, DOI 10.1016/j.ymssp.2010.08.003
   Li MY, 2013, IEEE INT CONF ROBOT, P5709, DOI 10.1109/ICRA.2013.6631398
   Li T, 2022, IEEE Robot Autom Lett
   Liang J, 2022, IEEE-CAA J AUTOMATIC, V9, P1083, DOI 10.1109/JAS.2022.105632
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Liu DF, 2021, INT C PATT RECOG, P3170, DOI 10.1109/ICPR48806.2021.9411961
   Liu DF, 2020, IEEE IJCNN, DOI [10.1145/3334480.3382998, 10.1109/ijcnn48605.2020.9207265]
   Liu YK, 2022, IEEE T INTELL VEHICL, V7, P210, DOI 10.1109/TIV.2021.3103695
   Liu Zhijian, 2023, 2023 IEEE International Conference on Robotics and Automation (ICRA), P2774, DOI 10.1109/ICRA48891.2023.10160968
   Lu YW, 2021, INT C PATT RECOG, P6343, DOI 10.1109/ICPR48806.2021.9412565
   Lu YW, 2019, IEEE IMAGE PROC, P2571, DOI [10.1109/icip.2019.8803247, 10.1109/ICIP.2019.8803247]
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nath AG, 2022, IEEE SENS J, V22, P707, DOI 10.1109/JSEN.2021.3130183
   Qin T, 2019, Arxiv, DOI arXiv:1901.03638
   Qin T, 2019, Arxiv, DOI arXiv:1901.03642
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Rana K, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15090-w
   Reid TGR, 2020, IEEE POSITION LOCAT, P342, DOI [10.1109/plans46316.2020.9109938, 10.1109/PLANS46316.2020.9109938]
   Shao H., 2023, P C ROB LEARN, P726, DOI DOI 10.48550/ARXIV.2207.14024
   Shi JQ, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4524, DOI 10.1109/IROS.2016.7759666
   Stühmer J, 2010, LECT NOTES COMPUT SC, V6376, P11
   Sun R, 2020, GPS SOLUT, V24, DOI 10.1007/s10291-020-01000-2
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Wang WC, 2022, MULTIMED TOOLS APPL, V81, P39873, DOI 10.1007/s11042-022-12300-9
   Wen ZY, 2023, IEEE T IND ELECTRON, V70, P3136, DOI 10.1109/TIE.2022.3169714
   Yan LQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2220, DOI 10.1109/ICASSP39728.2021.9414517
   Yong Z, 2023, IEEE Access
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zhan HY, 2021, Arxiv, DOI arXiv:2103.00933
   Zhan HY, 2020, IEEE INT CONF ROBOT, P4203, DOI [10.1109/icra40945.2020.9197374, 10.1109/ICRA40945.2020.9197374]
   Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 59
TC 1
Z9 1
U1 10
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17595-w
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700004
DA 2024-07-18
ER

PT J
AU Zabihzadeh, D
   Masoudifar, M
AF Zabihzadeh, Davood
   Masoudifar, Mina
TI ZS-DML: Zero-Shot Deep Metric Learning approach for plant leaf disease
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plant Diseases; Automated visual crops analysis; Deep metric learning;
   Zero-shot learning; Transfer learning
ID PEST DETECTION
AB Automatic plant disease detection plays an important role in food security. Deep learning methods are able to detect precisely various types of plant diseases but at the expense of using huge amounts of resources (processors and data). Therefore, employing few-shot or zero-shot learning methods is unavoidable. Deep Metric Learning (DML) is a widely used technique for few/zero shot learning. Existing DML methods extract features from the last hidden layer of a pre-trained deep network, which increases the dependence of the specific features on the observed classes. In this paper, the general discriminative feature learning method is used to learn general features of plant leaves. Moreover, a proxy-based loss is utilized that learns the embedding without sampling phase while having a higher convergence rate. The network is trained on the Plant Village dataset where the images are split into 32 and 6 classes as source and target, respectively. The knowledge learned from the source domain is transferred to the target in a zero-shot setting. A few samples of the target domain are presented to the network as a gallery. The network is then evaluated on the target domain. The experimental results show that by presenting few or even only one sample of new classes to the network without fine-tuning step, our method can achieve a classification accuracy of 99%/80.64% for few/one image(s) per class.
C1 [Zabihzadeh, Davood; Masoudifar, Mina] Hakim Sabzevari Univ, Dept Biol, Sabzevar 9617976487, Iran.
RP Masoudifar, M (corresponding author), Hakim Sabzevari Univ, Dept Biol, Sabzevar 9617976487, Iran.
EM masoudi@hsu.ac.ir
OI masoudifar, mina/0000-0002-9609-1853
CR Abade A, 2021, COMPUT ELECTRON AGR, V185, DOI 10.1016/j.compag.2021.106125
   Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Al-Kaabi K, 2023, APPL INTELL, V53, P8693, DOI 10.1007/s10489-022-03959-6
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Bedi P, 2021, ARTIF INTELL AGR, V5, P90, DOI 10.1016/j.aiia.2021.05.002
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Espejo-Garcia B, 2021, BIOSYST ENG, V204, P79, DOI 10.1016/j.biosystemseng.2021.01.014
   Fina F, 2013, INT J ADV BIOTECHNOL, V4, P189
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Janarthan S, 2020, IEEE ACCESS, V8, P162588, DOI 10.1109/ACCESS.2020.3021487
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kim S, 2020, PROC CVPR IEEE, P3235, DOI 10.1109/CVPR42600.2020.00330
   Li LL, 2021, IEEE ACCESS, V9, P56683, DOI 10.1109/ACCESS.2021.3069646
   Li Y, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106055
   Liang XHZ, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00813-7
   Lin Hong, 2022, 2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), P114, DOI 10.1109/PRAI55851.2022.9904046
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47
   Hughes DP, 2016, Arxiv, DOI [arXiv:1511.08060, DOI 10.48550/ARXIV.1511.08060]
   Qian Q, 2019, IEEE I CONF COMP VIS, P6459, DOI 10.1109/ICCV.2019.00655
   Schuler J. P. S., 2022, Mendel, V28, P55, DOI [10.13164/mendel.2022.1.055, DOI 10.13164/MENDEL.2022.1.055]
   Shen T, 2018, AAAI CONF ARTIF INTE, P5446
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang B, 2019, IEEE ACCESS, V7, P151754, DOI 10.1109/ACCESS.2019.2947510
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Yang M-M, 2017, 2017 IEEE 2 INFORM T
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Zabihzadeh D, 2021, arXiv
   Zhai DM, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472809
   Zhong FM, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105828
NR 33
TC 0
Z9 0
U1 10
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17136-5
EA NOV 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700001
DA 2024-07-18
ER

PT J
AU Wang, S
   Zhang, HL
   Yang, GB
   Guo, ZQ
   Chen, JY
AF Wang, Shuai
   Zhang, Hanling
   Yang, Gaobo
   Guo, Zhiqing
   Chen, Jiyou
TI A two-stage fake face image detection algorithm with expanded attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deepfake detection; Image forensics; Face forgery detection; Ensemble
   learning
ID MANIPULATION; LOCALIZATION; NETWORKS
AB Convolutional neural networks (CNNs) have achieved impressive successes in fake face image detection. However, CNNs ignore tampering traces outside their attention scope. Moreover, example forgetting events can also pose negative impacts on the face forgery detection accuracy. To address these issues, this paper proposes an attention-expanded two-stage face forgery detector, named Attention-expanded Deepfake Spotter (ADS). In the first stage, the manipulated regions are preliminarily located by utilizing the Region Score Maps (RSMs) generated by the modified CNN. In the second stage, the Expanding and Undetectable Regions (EUR) loss function is designed to encourage another modified CNN to mine manipulation traces outside the manipulated areas exposed in the first stage. To fuse the manipulation traces extracted from different regions in the two stages and mitigate the problems caused by example forgetting events, RSM-weighted accumulation is adopted to integrate the detection information from both stages and obtain the final detection result. The proposed algorithm's effectiveness for each component is analyzed through ablation experiments, and the method is evaluated on four publicly available datasets: FF++, HFF, DFDC, and Celeb-DF. The experimental results demonstrate that the proposed method has high detection rates and superior transferability, outperforming most existing algorithms.
C1 [Wang, Shuai; Yang, Gaobo; Chen, Jiyou] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Zhang, Hanling] Hunan Univ, Sch Design, Changsha 410082, Peoples R China.
   [Guo, Zhiqing] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830017, Peoples R China.
C3 Hunan University; Hunan University; Xinjiang University
RP Zhang, HL (corresponding author), Hunan Univ, Sch Design, Changsha 410082, Peoples R China.
EM jt_hlzhang@hnu.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Afchar D, 2018, Arxiv, DOI arXiv:1809.00888
   Akhtar Z, 2023, J IMAGING, V9, DOI 10.3390/jimaging9010018
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Ding J, 2018, IEEE SIGNAL PROC MAG, V35, P16, DOI 10.1109/MSP.2018.2867638
   Dolhansky B, 2019, Arxiv, DOI arXiv:1910.08854
   FaceSwapDevs, 2022, Deepfakes
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo Z., 2022, arXiv
   Guo ZQ, 2023, COMPUT VIS IMAGE UND, V226, DOI 10.1016/j.cviu.2022.103587
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   Nguyen HH, 2019, Arxiv, DOI arXiv:1910.12467
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Huang YH, 2022, IEEE T INF FOREN SEC, V17, P2657, DOI 10.1109/TIFS.2022.3141262
   Jaskowiak PA, 2022, DATA MIN KNOWL DISC, V36, P1219, DOI 10.1007/s10618-022-00829-0
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kong CQ, 2022, IEEE T INF FOREN SEC, V17, P1741, DOI 10.1109/TIFS.2022.3169921
   Kowalski M., 2018, Faceswap
   Lee S, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107256
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YZ, 2019, Arxiv, DOI arXiv:1811.00656
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Liu HG, 2021, PROC CVPR IEEE, P772, DOI 10.1109/CVPR46437.2021.00083
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Miao CT, 2022, IEEE T INF FOREN SEC, V17, P3008, DOI 10.1109/TIFS.2022.3198275
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nguyen HH, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185974
   Kingma DP, 2018, Arxiv, DOI [arXiv:1807.03039, 10.48550/arXiv.1807.03039]
   Perarnau G, 2016, Arxiv, DOI [arXiv:1611.06355, 10.48550/arXiv.1611.06355]
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Rossler A, 2019, Ffcode
   R”ssler A, 2018, Arxiv, DOI arXiv:1803.09179
   Shang ZH, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107950
   Shiohara K, 2022, PROC CVPR IEEE, P18699, DOI 10.1109/CVPR52688.2022.01816
   Nguyen TT, 2022, COMPUT VIS IMAGE UND, V223, DOI 10.1016/j.cviu.2022.103525
   Thies J, 2016, SPECIAL INTEREST GRO, p5:1, DOI [10.1145/2929464.2929475, DOI 10.1145/2929464.2929475]
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Toneva Mariya, 2019, 7 INT C LEARNING REP
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang CR, 2021, PROC CVPR IEEE, P14918, DOI 10.1109/CVPR46437.2021.01468
   Wang J, 2022, IEEE T INF FOREN SEC, V17, P2425, DOI 10.1109/TIFS.2022.3186803
   Wang JK, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2022, P615, DOI 10.1145/3512527.3531415
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yu MM, 2022, NEUROCOMPUTING, V501, P583, DOI 10.1016/j.neucom.2022.06.013
   Yujun Shen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9240, DOI 10.1109/CVPR42600.2020.00926
   Yuyang Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P86, DOI 10.1007/978-3-030-58610-2_6
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
   Zhao TC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15003, DOI 10.1109/ICCV48922.2021.01475
   Zhu DF, 2019, Arxiv, DOI arXiv:1907.11418
NR 56
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 29
PY 2023
DI 10.1007/s11042-023-17672-0
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8A7
UT WOS:001120006300002
DA 2024-07-18
ER

PT J
AU Fan, JY
   Wang, Y
   Song, WW
   Pan, ZB
AF Fan, Jingya
   Wang, Yang
   Song, Wenwen
   Pan, Zhibin
TI Flexible product quantization for fast approximate nearest neighbor
   search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Approximate nearest neighbor search; Product quantization; The number of
   sub-vectors; Sub-vector concatenation; Flexible product quantization
AB Product quantization (PQ) is an effective solution to approximate nearest neighbor (ANN) search. The idea of PQ is to decompose the space into Cartesian product of several low-dimensional subspaces and quantize each subspace separately. Database vectors are represented by short codes with different length composed of their subspace quantization indices. A vector is encoded to a short code consisting of its subspace quantization indices. PQ allows to generate a large size codebook with very low memory and time cost, and the selection of the number M of sub-vectors is the most essential and important problem, but is easily neglected. Motivated by this observation, we propose a method named Flexible Product quantization (FPQ) to optimize PQ-based methods that fix M for all vectors. FPQ achieves flexible M by concatenating the sub-vector pairs through constrains on quantization distortion. The concatenating operation is implemented individually among different database vectors and can lead to far less additions in the search process. Different from existing PQ-based fast search methods, this operation of our proposed FPQ is to reduce the computational complexity for searching each single database vector, which provides a new perspective to better accelerate ANN search. Experimental results show that our method for product quantization based methods can significantly reduce nearly 25% computational complexity by using appropriate parameters, while the search accuracy can be guaranteed.
C1 [Fan, Jingya; Song, Wenwen; Pan, Zhibin] Jiaotong Univ, Fac Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
   [Wang, Yang] Xian Univ Technol, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
   [Pan, Zhibin] Xi An Jiao Tong Univ, Res Inst, Hangzhou 311215, Zhejiang, Peoples R China.
C3 Xi'an University of Technology; Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Jiaotong Univ, Fac Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.; Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Res Inst, Hangzhou 311215, Zhejiang, Peoples R China.
EM zbpan@xjtu.edu.cn
FU This work is supported in part by the National Natural Science
   Foundation of China (Grant No. U1903213), The Ph.D. Stand-up Fund of
   Xi'an University of Technology (Grant No. 108-451121002) and the
   Zhejiang Provincial Commonweal Project (Grant No. LGF21F030 [U1903213];
   National Natural Science Foundation of China [108-451121002]; Stand-up
   Fund of Xi'an University of Technology [LGF21F030002]; Zhejiang
   Provincial Commonweal Project
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant No. U1903213), The Ph.D. Stand-up Fund of
   Xi'an University of Technology (Grant No. 108-451121002) and the
   Zhejiang Provincial Commonweal Project (Grant No. LGF21F030002).
CR An S, 2019, PATTERN RECOGN LETT, V125, P187, DOI 10.1016/j.patrec.2019.04.017
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Ercoli S, 2017, IEEE T MULTIMEDIA, V19, P2521, DOI 10.1109/TMM.2017.2697824
   Fan JY, 2022, NEUROCOMPUTING, V507, P107, DOI 10.1016/j.neucom.2022.08.002
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Heo JP, 2019, IEEE T PATTERN ANAL, V41, P2084, DOI 10.1109/TPAMI.2018.2853161
   Hong WX, 2020, IEEE T PATTERN ANAL, V42, P1783, DOI 10.1109/TPAMI.2019.2925347
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jin L, 2023, IEEE T NEUR NET LEAR, V34, P1838, DOI 10.1109/TNNLS.2020.2997020
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Li LH, 2018, IEEE T CIRC SYST VID, V28, P3504, DOI 10.1109/TCSVT.2017.2759277
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Ning QQ, 2017, IEEE T MULTIMEDIA, V19, P586, DOI 10.1109/TMM.2016.2625260
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Pan YW, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105088
   Pan ZB, 2020, NEUROCOMPUTING, V401, P59, DOI 10.1016/j.neucom.2020.03.016
   Song WW, 2023, INFORM SCIENCES, V642, DOI 10.1016/j.ins.2023.119216
   Wang J, 2011, Personalized commodity recommending method and system which integrate attributes and structural similarity
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
NR 22
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 16
PY 2023
DI 10.1007/s11042-023-17564-3
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9GJ6
UT WOS:001101450500001
DA 2024-07-18
ER

PT J
AU Li, XM
   Wang, SS
   Gu, FM
   Lin, ZB
AF Li, Xuanmiao
   Wang, Shengsheng
   Gu, Fangming
   Lin, Zhanbo
TI Enhancing signed social recommendation via extracting auxiliary textual
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommender systems; Graph convolutional network; Signed social network;
   Natural language processing
AB Real-world applications are increasingly using personalized suggestions to guide users toward interesting content. Graphic Convolutional Neural Network (GCN) has been a great success as a new collaborative filter technology. Nevertheless, the majority of GCN-based systems currently in use can only record historical data about user clicks or transactions, which only reflects a single part of user preferences and item characteristics and ignores numerous important factors like information about the user or item. There is a need to further enrich the potential factors of items from like or related items because goods are not autonomous and may be similar and connected. Moreover, the majority of GCN only function on unsigned networks with only positive linkages available. The process of transferring these models to signed networks is difficult and has received little attention in research despite being extensively observed in practice. In this paper, we suggest a model for extracting auxiliary textual information called Enhancing Signed Social Recommendation Via Extracting Auxiliary Textual Information (E-EATI). By fusing auxiliary information,we can obtain better representation vectors .To combine useful auxiliary information from users or items, We use the BERT model to preprocess the auxiliary textual information and introduce the item2item aggregation operation in our model. Next, we build a signed network using similar and dissimilar individuals of items, By learning the node embedding of the convolutional network of signed graphs, we can get a better embedding representation by integrating different hidden semantic information generated by positive and negative links.In this process, we solve the problem of noise caused by too much information by using similar and dissimilar nodes.We use three standard datasets on on E-EATI : Movielens-1m, Amazon-book, and Yelp2018. The experiment's findings demonstrate that, when compared to the most advanced GCN models, E-EATI significantly improves NDCG and Recall.
C1 [Li, Xuanmiao; Wang, Shengsheng; Gu, Fangming; Lin, Zhanbo] Jilin Univ, Coll Software, Changchun, Peoples R China.
   [Wang, Shengsheng; Gu, Fangming] Jilin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.
   [Wang, Shengsheng; Gu, Fangming] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Gu, FM (corresponding author), Jilin Univ, Coll Software, Changchun, Peoples R China.; Gu, FM (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.; Gu, FM (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Peoples R China.
EM lxm21@mails.jlu.edu.cn; wss@jlu.edu.cn; gufm@jlu.edu.cn;
   linzb20@mails.jlu.edu.cn
FU This work is supported by the Innovation Capacity Construction Project
   of Jilin Province Development and Reform
   Commission(2021FGWCXNLJSSZ10,2019C053-3),the National Key Research and
   Development Program of China (No. 2020YFA0714103) and the Fundamental
   Res [2021FGWCXNLJSSZ10,2019C053-3]; Innovation Capacity Construction
   Project of Jilin Province Development and Reform Commission
   [2020YFA0714103]; National Key Research and Development Program of
   China; Fundamental Research Funds for the Central Universities
FX This work is supported by the Innovation Capacity Construction Project
   of Jilin Province Development and Reform
   Commission(2021FGWCXNLJSSZ10,2019C053-3),the National Key Research and
   Development Program of China (No. 2020YFA0714103) and the Fundamental
   Research Funds for the Central Universities,JLU.
CR CARTWRIGHT D, 1956, PSYCHOL REV, V63, P277, DOI 10.1037/h0046049
   Derr T, 2018, IEEE DATA MINING, P929, DOI 10.1109/ICDM.2018.00113
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Wenzhi Fan, 2021, IEEE Transactions on Geoscience and Remote Sensing, V59, P76, DOI [10.1109/TKDE.2020.3008732, 10.1109/TGRS.2020.2990791]
   Gao C, 2022, ACM Trans Recommend Syst
   Gao Y, 2020, Arxiv, DOI arXiv:2004.00387
   Gopalan P, 2014, ADV NEUR IN, V27
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Heider F, 1946, J PSYCHOL, V21, P107, DOI 10.1080/00223980.1946.9917275
   Hinton GE, 1986, P 8 ANN C C SCI SOC, V1, P12
   Jain PK, 2022, IEEE T COMPUT SOC SY, V9, P1777, DOI 10.1109/TCSS.2022.3200890
   Jain PK, 2022, MULTIMED TOOLS APPL, V81, P6979, DOI 10.1007/s11042-022-11972-7
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   Jain PK, 2021, WIRELESS PERS COMMUN, V118, P2469, DOI 10.1007/s11277-021-08136-5
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jin BW, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P659, DOI 10.1145/3397271.3401072
   Kong XJ, 2021, IEEE T EMERG TOP COM, V9, P226, DOI 10.1109/TETC.2018.2830698
   Leskovec J, 2010, Signed networks in social media, P1361
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Liu K, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3544106
   Ma JX, 2019, PR MACH LEARN RES, V97
   Mao KL, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P1253, DOI 10.1145/3459637.3482291
   Mei DH, 2021, IEEE ACCESS, V9, P34433, DOI 10.1109/ACCESS.2021.3061915
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Ravanifard R, 2021, APPL INTELL, V51, P3353, DOI 10.1007/s10489-020-01945-4
   Rendle S, 2012, Arxiv, DOI arXiv:1205.2618
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Sedhain S, 2014, Social collaborative filtering for cold-start recommendations, P345
   Sun JN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1289, DOI 10.1145/3397271.3401123
   Tang J, 2015, Negative link prediction in social media, P87
   Tang JL, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2956185
   Tang JL, 2013, SOC NETW ANAL MIN, V3, P1113, DOI 10.1007/s13278-013-0141-9
   van den Berg R, 2017, Arxiv, DOI arXiv:1706.02263
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wu F, 2019, PMLR 6861-6871
   Wu SW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3535101
   Xia PP, 2015, INFORM SCIENCES, V307, P39, DOI 10.1016/j.ins.2015.02.024
   [闫昭 Yan Zhao], 2022, [中国科学. 信息科学, Scientia Sinica Informationis], V52, P1069
   Yang JH, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P140, DOI 10.1145/3240323.3240381
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yu SS, 2019, IEEE ACCESS, V7, P176600, DOI 10.1109/ACCESS.2019.2953990
   Zhang H, 2021, index, P1718
NR 47
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17414-2
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100011
DA 2024-07-18
ER

PT J
AU Barman, H
   Kishor, NR
   Kothuri, SSK
   Kukudala, M
   Raju, USN
AF Barman, Hillol
   Kishor, Netalkar Rohan
   Kothuri, Satya Sai Karthik
   Kukudala, Mounika
   Raju, U. S. N.
TI Distributed compression and decompression for big image data: JPEG and
   CCITT Group-3
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Distributed System; Spark; Compression; Decompression; JPEG; CCITT
ID SYSTEM
AB In today's era, digital data is being created and transmitted majorly in the form of images and videos. Storing such a huge number of images and transmitting them requires a lot of computer resources. Instead of storing the image data as is, if we compress and store it, it saves a lot of resources. Image compression is the act of removing the maximum possible redundant data from an image and maintaining only the non-redundant data. In this paper, to compress and decompress such big image data, a distributed environment with a map-reduce paradigm using Hadoop Distributed File System (HDFS) and Spark is used. In addition to these, Microsoft Azure cloud environment is also used. Various setups like a single system, 1 + 4, 1 + 15, and 1 + 18 node clusters are used to show the time comparisons among these setups with the self-created large image dataset. On these four self-made clusters, more than 200 million (219,340,800) images are compressed and decompressed; the execution times are compared with two of the traditional image compression methods: JPEG and CCITT Group-3. To evaluate the efficiency of these two compression methods: Compression Ratio, Root Mean Square Error (RMSE), and Peak Signal to Noise Ratios (PSNR) are used.
C1 [Barman, Hillol; Kishor, Netalkar Rohan; Kothuri, Satya Sai Karthik; Kukudala, Mounika; Raju, U. S. N.] Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Raju, USN (corresponding author), Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
EM hillol7797@gmail.com; netalkarrohan@gmail.com;
   karthikkothuri2009@gmail.com; kmounika1@student.nitw.ac.in;
   usnraju@nitw.ac.in
RI Raju, U S N/AAN-7582-2020
OI Raju, U S N/0000-0003-1049-7949
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Andrews H.C., 1968, Proc. Hawaii Int.Conf. System Sciences, P677
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gonzalez RC, 2021, About us
   hadoop.apache, 2020, Welcome to Apache Hadoop
   Harrison C.W., 1952, BELL SYST TECH J, V31, P764, DOI [DOI 10.1002/J.1538-7305.1952.TB01405.X, 10.1002/j.1538-7305.1952.tb01405.x]
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Im H, 2016, INT CONF BIG DATA, P525, DOI 10.1109/BIGCOMP.2016.7425985
   Khan MAUD, 2014, 2014 ZONE 1 CONFERENCE OF THE AMERICAN SOCIETY FOR ENGINEERING EDUCATION (ASEE ZONE 1)
   Kishor Netalkar Rohan, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1535, DOI 10.1109/ICAIS50930.2021.9396008
   Kobayashi K, 2015, COMM COM INF SC, V516, P269, DOI 10.1007/978-3-662-46742-8_25
   Koppad SH, 2016, PROCEEDINGS OF IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2016)
   Kwitt R, 2021, Salzburg Texture Image Dataset
   Le Dong, 2016, IEEE Transactions on Big Data, V2, P297, DOI 10.1109/TBDATA.2016.2613992
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Mao Chen, 2015, 2015 International Conference on Intelligent Transportation, Big Data and Smart City (ICITBS). Proceedings, P47, DOI 10.1109/ICITBS.2015.18
   Mayer-Schonberger V., 2014, BIG DATA REVOLUTION
   Perera S., 2013, Hadoop MapReduce Cookbook
   PRATT WK, 1969, P IEEE, V57, P58, DOI 10.1109/PROC.1969.6869
   ProjectPro, 2021, Healthcare applications of Hadoop and big data
   Raju USN, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P432, DOI 10.1109/BigMM.2016.94
   Rothpearl A, 2010, J DIGIT IMAGING, V23, P81, DOI 10.1007/s10278-008-9166-4
   Shafer T, 2017, The 42V's of BIG Data and Data Science
   Simplilearn, 2021, Top 10 big data applications across industries
   Stuchi JA, 2017, IEEE INT WORKS MACH
   Sugrue M, 2015, CCTVThe challenge of sifting through big data
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Turkington G., 2013, Hadoop Beginner's Guide
   Venter F., 2012, Analytics: Driving better business decisions
   Wang WN, 2015, SIGNAL PROCESS-IMAGE, V39, P499, DOI 10.1016/j.image.2015.07.006
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Xia DW, 2022, MULTIMED TOOLS APPL, V81, P4015, DOI 10.1007/s11042-021-11639-9
   Xia DW, 2021, NEURAL COMPUT APPL, V33, P2393, DOI 10.1007/s00521-020-05076-2
   Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210
NR 36
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17266-w
EA NOV 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600001
DA 2024-07-18
ER

PT J
AU ul Huda, N
   Javed, A
   Maswadi, K
   Alhazmi, A
   Ashraf, R
AF ul Huda, Noor
   Javed, Ali
   Maswadi, Kholoud
   Alhazmi, Ali
   Ashraf, Rehan
TI Fake-checker: A fusion of texture features and deep learning for
   deepfakes detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deepfakes; Deep Convolutional Neural Networks; Generative Adversarial
   Networks
AB The evolution of sophisticated deep learning algorithms such as Generative Adversarial Networks has made it possible to create deepfakes videos with convincing reality. Deepfake identification is important to address internet disinformation campaigns and lessen negative social media effects. Existing studies either use handcrafted features or deep learning-based models for deepfake detection. To effectively combine the attributes of both approaches, this paper presents a fusion of deep features with handcrafted texture features to create a powerful fused feature vector for accurate deepfakes detection. We propose a Directional Magnitude Local Hexadecimal Pattern (DMLHP) to extract the 320-D texture features and extract the deep feature vector of 2048-D using inception V3. Next, we employ the Principal Component Analysis to reduce the feature dimensions to 320 for a balanced representation of features after fusion. The deep and handcrafted features are combined to form a fused feature vector of 640-D. Further, we employ the proposed features to train the XGBoost model for the classification of frames as genuine or forged. We evaluated our proposed model on Faceforensic + + and Deepfake Detection Challenge Preview (DFDC-P) datasets. Our method achieved the accuracy and area under the curve of 97.7% and 99.3% on Faceforensic + + , whereas 90.8% and 93.1% on the DFDC-P dataset, respectively. Moreover, we performed a cross-set and cross-dataset evaluation to show the generalization capability of our model.
C1 [ul Huda, Noor] Univ Engn & Technol, Dept Comp Sci, Taxila 47050, Pakistan.
   [Javed, Ali] Univ Engn & Technol, Dept Software Engn, Taxila 47050, Pakistan.
   [Maswadi, Kholoud] Jazan Univ, Dept Management Informat Syst, Jazan 45142, Saudi Arabia.
   [Alhazmi, Ali] Jazan Univ, Coll Comp Sci & Informat Technol, Jazan 45142, Saudi Arabia.
   [Ashraf, Rehan] Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila; Jazan University; Jazan University; National
   Textile University - Pakistan
RP Ashraf, R (corresponding author), Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
EM rehan@ntu.edu.pk
RI JAVED, ALI/X-3334-2019; Alhazmi, Ali/IAP-4420-2023
OI Alhazmi, Ali/0000-0003-4694-7323; Ashraf, Rehan/0000-0002-6627-9820
FU This work was supported by the grant of the Punjab Higher Education
   Commission (PHEC) of Pakistan via Award No. (PHEC/ARA/PIRCA/20527/21).
   [PHEC/ARA/PIRCA/20527/21]; Punjab Higher Education Commission (PHEC) of
   Pakistan
FX This work was supported by the grant of the Punjab Higher Education
   Commission (PHEC) of Pakistan via Award No. (PHEC/ARA/PIRCA/20527/21).
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P IEEE C COMP VIS PA, P38, DOI DOI 10.1109/ICCV.2015.425
   Agarwal S, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360904
   Amerini Irene, 2020, IH&MMSec '20: Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security, P97, DOI 10.1145/3369412.3395070
   Aslam N, 2024, VISUAL COMPUT, V40, P1729, DOI 10.1007/s00371-023-02882-2
   Aslam N, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103598
   Aslam N, 2022, MULTIMED TOOLS APPL, V81, P42457, DOI 10.1007/s11042-022-13496-6
   Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287
   Cozzolino D, 2019, Arxiv, DOI arXiv:1812.02510
   Dolhansky B, 2019, Arxiv, DOI arXiv:1910.08854
   Guera D, 2019, Arxiv, DOI arXiv:1906.08743
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Heo YJ, 2021, Arxiv, DOI arXiv:2104.01353
   Hu J, 2022, AAAI CONF ARTIF INTE, P951
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Ilyas H, 2023, INT CONF AUT ROBOT A, P368, DOI 10.1109/ICARA56516.2023.10125801
   Jack K., 2011, Video Demystified: A Handbook for the Digital Engineer
   Jung T, 2020, IEEE ACCESS, V8, P83144, DOI 10.1109/ACCESS.2020.2988660
   Khalid Fatima, 2023, Proceedings of International Conference on Information Technology and Applications: ICITA 2022. Lecture Notes in Networks and Systems (614), P239, DOI 10.1007/978-981-19-9331-2_20
   Khalid F, 2023, EXPERT SYST APPL, V222, DOI 10.1016/j.eswa.2023.119843
   Khan SA., 2022, arXiv
   Khormali A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12062953
   Lee S, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3500, DOI 10.1145/3485447.3512245
   Li XD, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1864, DOI 10.1145/3394171.3414034
   Li YZ, 2019, Arxiv, DOI arXiv:1811.00656
   Liu HG, 2021, PROC CVPR IEEE, P772, DOI 10.1109/CVPR46437.2021.00083
   Ma J, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102578
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Montserrat DM, 2020, IEEE COMPUT SOC CONF, P2851, DOI 10.1109/CVPRW50498.2020.00342
   Nguyen HH, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185974
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Shao J., 2020, Thinking in frequency: Face forgery detection by mining frequency-aware clues, P86
   Tolosana Ruben, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12665), P442, DOI 10.1007/978-3-030-68821-9_38
   Wang R, 2020, Arxiv, DOI arXiv:1909.06122
   Xu BZ, 2021, CMC-COMPUT MATER CON, V68, P1375, DOI 10.32604/cmc.2021.016760
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P15, DOI 10.1109/SIPROCESS.2017.8124497
NR 41
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17586-x
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500005
DA 2024-07-18
ER

PT J
AU Diwakar, RK
   Kumari, P
   Saxena, P
   Poddar, R
AF Diwakar, Rajnish Kumar
   Kumari, Pammi
   Saxena, Priyank
   Poddar, Raju
TI An efficient multitasking cascade network for arteriovenous segmentation
   using dual-modal fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Arteriole and venule segmentation; Retinal vessels; Monochrome images;
   Dual-Modal dataset; Cascade supervised miniature U-Net; Fundus images
ID SIMULTANEOUS ARTERIOLE; VENULE SEGMENTATION; RETINAL IMAGES
AB Our eyesight does not remain the same throughout our lives. Certain diseases start affecting our vision with age, such as diabetic retinopathy, hypertension, and glaucoma. This has varied effects on the structure of the retinal blood vessels. Therefore, studying these retinal blood vessels is vital for pre-diagnosis and diagnosing ophthalmic disease. Low contrast, complicated vessel structure, and inhomogeneous background lighting across subjects pose complex challenges in classifying vessels from retinal images. This paper proposes a cascade-supervised miniature U-Net (CSMi-UNet) to perform arteriovenous segmentation on Dual-Modal fundus images. The Dual-Modal contains monochrome images acquired at two different wavelengths (570 nm and 610 nm) based on hemoglobin absorption spectra, other than the regular RGB fundus images. Because of the high similarity in the arteriole and venule (AV) morphological structure, single modal (RGB) fundus images often result in misclassification. The AV structures are more detailed in the monochromic images and contribute significantly to arteriovenous analysis. The proposed CSMi-UNet utilizes the information with considerably fewer parameters and attains state-of-the-art performance, making it suitable for portable devices. We achieved an arteriovenous classification accuracy of 98.36%, F1-scores of 82.46%, and 82.53% for AV, significantly outperforming previous studies on the Dual-Modal dataset.
C1 [Diwakar, Rajnish Kumar; Kumari, Pammi; Saxena, Priyank] Birla Inst Technol, Dept Elect & Commun Engn, Ranchi, India.
   [Poddar, Raju] Birla Inst Technol, Dept Bioengn & Biotechnol, Ranchi, India.
C3 Birla Institute of Technology Mesra; Birla Institute of Technology Mesra
RP Kumari, P; Saxena, P (corresponding author), Birla Inst Technol, Dept Elect & Commun Engn, Ranchi, India.
EM phdec10003.19@bitmesra.ac.in; priyanksaxena@bitmesra.ac.in
RI Saxena, Priyank/ADG-7631-2022; poddar, raju/R-1671-2018
OI Saxena, Priyank/0000-0003-0227-0488; poddar, raju/0000-0001-6945-9555
CR Abdulsahib AA, 2021, NETW MODEL ANAL HLTH, V10, DOI 10.1007/s13721-021-00294-7
   AlBadawi S, 2018, LECT NOTES COMPUT SC, V10882, P659, DOI 10.1007/978-3-319-93000-8_75
   Islam MA, 2017, Arxiv, DOI [arXiv:1703.00551, DOI 10.48550/ARXIV.1703.00551]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen Wenting, 2020, Med Image Comput Comput Assist Interv-MICCAI, V12265
   Dashtbozorg B, 2013, COMP MED SY, P512, DOI 10.1109/CBMS.2013.6627854
   Dashtbozorg B, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2263809
   Gao HY, 2020, IEEE T PATTERN ANAL, V42, P1218, DOI 10.1109/TPAMI.2019.2893965
   Girard F, 2019, ARTIF INTELL MED, V94, P96, DOI 10.1016/j.artmed.2019.02.004
   Hemelings R, 2019, COMPUT MED IMAG GRAP, V76, DOI 10.1016/j.compmedimag.2019.05.004
   Hu JF, 2022, IEEE J BIOMED HEALTH, V26, P3896, DOI 10.1109/JBHI.2022.3165867
   Hu JF, 2021, FRONT CELL DEV BIOL, V9, DOI 10.3389/fcell.2021.659941
   Joshi GD, 2011, IEEE T MED IMAGING, V30, P1192, DOI 10.1109/TMI.2011.2106509
   Karlsson RA, 2022, COMPUT METH PROG BIO, V216, DOI 10.1016/j.cmpb.2022.106650
   Kumar KS, 2023, MULTIMED TOOLS APPL, V82, P7679, DOI 10.1007/s11042-022-13388-9
   Lepetit-Aimon G, 2018, LECT NOTES COMPUT SC, V11039, P201, DOI 10.1007/978-3-030-00949-6_24
   Lim LS, 2012, LANCET, V379, P1728, DOI 10.1016/S0140-6736(12)60282-7
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma Wenao, 2019, MED IMAGE COMPUT COM, V11764
   Meyer MI, 2018, LECT NOTES COMPUT SC, V10882, P622, DOI 10.1007/978-3-319-93000-8_71
   Narasimha-Iyer H, 2007, IEEE T BIO-MED ENG, V54, P1427, DOI 10.1109/TBME.2007.900804
   Nguyen TT, 2009, CURR DIABETES REP, V9, P277, DOI 10.1007/s11892-009-0043-4
   Raj PK, 2020, I S BIOMED IMAGING, P1262, DOI [10.1109/ISBI45749.2020.9098580, 10.1109/isbi45749.2020.9098580]
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Seidelmann SB, 2016, CIRCULATION, V134, P1328, DOI 10.1161/CIRCULATIONAHA.116.023425
   Shen JH, 2019, PROC SPIE, V10950, DOI 10.1117/12.2513394
   Wang N, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020262
   Wang ZW, 2020, IEEE T MED IMAGING, V39, P2904, DOI 10.1109/TMI.2020.2980117
   Welikala RA, 2017, COMPUT BIOL MED, V90, P23, DOI 10.1016/j.compbiomed.2017.09.005
   Wu YC, 2020, Arxiv, DOI [arXiv:2010.04428, DOI 10.48550/ARXIV.2010.04428]
   Xu XY, 2018, COMM COM INF SC, V894, P333, DOI 10.1007/978-3-319-95921-4_31
   Xu XY, 2018, BIOMED OPT EXPRESS, V9, P3153, DOI 10.1364/BOE.9.003153
   Zhang SL, 2019, IEEE ACCESS, V7, P57561, DOI 10.1109/ACCESS.2019.2914319
NR 34
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17343-0
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900004
DA 2024-07-18
ER

PT J
AU Velankar, M
   Kulkarni, P
AF Velankar, Makarand
   Kulkarni, Parag
TI Employing cumulative rewards based reinforcement machine learning for
   personalized music recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Music recommendation; Reinforcement machine learning; Q learning;
   Personalization
AB Music streaming services have transformed the way people listen to music in recent years. The current streaming services majorly rely on collaborative and hybrid filtering techniques, which predominantly recommend popular songs. However, most present systems lack musical contents, user taste changes, and novelty parameters. In this paper, we propose a music recommendation using reinforcement learning with personalizing the individual results. The proposed method implements a Q-learning model derived from the incremental reinforcement learning algorithm based on the cumulative reward from similar songs played and liked during the session. The user profile is modeled using implicit and explicit feedback from the individual musical interactions with the system. The cumulative reward obtained from the experimental outcomes demonstrates that a combination of reinforcement learning and personalized recommendation potentially broadens the scope of recommendations by including freshness and novelty. The experimental result shows average interaction time improvement of 35% compared with existing apps.
C1 [Velankar, Makarand; Kulkarni, Parag] MKSSS Cummins Coll Engn women, Informat Technol Dept, Karvenagar, Pune 411052, Maharashtra, India.
   [Velankar, Makarand; Kulkarni, Parag] Iknowlat Res Labs Pvt Ltd, Pune 411016, Maharashtra, India.
RP Velankar, M (corresponding author), MKSSS Cummins Coll Engn women, Informat Technol Dept, Karvenagar, Pune 411052, Maharashtra, India.; Velankar, M (corresponding author), Iknowlat Res Labs Pvt Ltd, Pune 411016, Maharashtra, India.
EM makarand.velankar@cumminscollege.in; paragindia@gmail.com
FU Authors acknowledge the help provided by Urja Sonchhatra, Anushree
   Pathak, Siddhi Choudhary and Shivani Thakre for testing the system.
FX Authors acknowledge the help provided by Urja Sonchhatra, Anushree
   Pathak, Siddhi Choudhary and Shivani Thakre for testing the system.
CR Bai XY, 2020, Arxiv, DOI arXiv:1911.03845
   Chang JW, 2021, MULTIMED TOOLS APPL, V80, P34037, DOI 10.1007/s11042-019-08356-9
   Cheng D, 2020, Currently Under Review
   Chi CY, 2010, CONF TECHNOL APPL, P60, DOI 10.1109/TAAI.2010.21
   Craw S, 2015, 24 INT JOINT C ART I
   Dutta A, 2021, 2021 12 INT C COMP C, P1
   Fessahaye F, 2019, I SYMP CONSUM ELECTR, DOI 10.1109/icce.2019.8662028
   Goud Kaira Nithin, 2021, Proceedings of the Sixth International Conference on Mathematics and Computing. ICMC 2020. Advances in Intelligent Systems and Computing (AISC 1262), P55, DOI 10.1007/978-981-15-8061-1_5
   Hassan Muhammad Umair, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P239, DOI 10.1007/978-981-16-7618-5_21
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hong DC, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1721, DOI 10.1145/3397271.3401225
   Hu Z, 2022, IEEE Transactions on Multimedia
   Khalaji M, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1071-6
   Kim HG, 2019, IEEE T CONSUM ELECTR, V65, P349, DOI 10.1109/TCE.2019.2924177
   Koren Y, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P447
   Kulkarni A, 2022, Modern approaches in machine learning & cognitive science: a walkthrough, P317
   Kulkarni P, 2017, INTEL SYST REF LIBR, V128, P49, DOI 10.1007/978-3-319-55312-2_3
   Lee JS, 2007, LECT NOTES COMPUT SC, V4836, P45
   Liebman E, 2015, Arxiv, DOI arXiv:1401.1880
   Afsar MM, 2022, Arxiv, DOI arXiv:2101.06286
   Mittal Shubham, 2022, Advances in Communication, Devices and Networking: Proceedings of ICCDN 2020. Lecture Notes in Electrical Engineering (776), P267, DOI 10.1007/978-981-16-2911-2_29
   Park HS, 2006, LECT NOTES COMPUT SC, V4223, P970
   Pichl M, 2021, MULTIMED TOOLS APPL, V80, P22509, DOI 10.1007/s11042-020-09890-7
   Sakurai K, 2022, ITE TRANS MEDIA TECH, V10, P8, DOI 10.3169/mta.10.8
   Sarin Eva, 2022, 2021 4th International Conference on Recent Trends in Computer Science and Technology (ICRTCST), P373, DOI 10.1109/ICRTCST54752.2022.9781862
   Schedl M., 2015, Recommender Systems Handbook, V2nd, P453, DOI DOI 10.1007/978-1-4899-7637-6_13
   Schedl M, 2018, INT J MULTIMED INF R, V7, P95, DOI 10.1007/s13735-018-0154-2
   Soleymani M, 2015, IEEE INT CON MULTI
   Song Y., 2012, 9 INT S COMP MUS MOD, V4, P395
   Srifi M, 2020, INFORMATION, V11, DOI 10.3390/info11060317
   Srikanth B., 2020, Int J Innov Sci Res Tech, V5, P390
   Sun J, 2022, Computational Intelligence and Neuroscience, V2022
   Sunitha M., 2022, Computer Networks, Big Data and IoT: Proceedings of ICCBI 2021. Lecture Notes on Data Engineering and Communications Technologies (117), P517, DOI 10.1007/978-981-19-0898-9_41
   Symeonidis P., 2008, Proceedings of the 9th International Conference on Music Information Retrieval (ISMIR 2008), P219
   Tahmasebi F, 2021, MULTIMED TOOLS APPL, V80, P2339, DOI 10.1007/s11042-020-09768-8
   Tao S, 2022, Knowl-Based Syst
   Vall Portabella A, 2018, Machine learning approaches to hybrid music recommender systems
   Velankar M, 2020, DE GR FRONT COMPU IN, V5, P43, DOI 10.1515/9783110610987-005
   Wang Y, 2020, LECT NOTES ARTIF INT, V12084, P91, DOI 10.1007/978-3-030-47426-3_8
   Wangwatcharakul C, 2020, IEEE ACCESS, V8, P86433, DOI 10.1109/ACCESS.2020.2993289
   Wen XL, 2021, SOFT COMPUT, V25, P3087, DOI 10.1007/s00500-020-05364-y
   Wishwanath Champika H. P. D., 2020, Social Computing and Social Media. Participation, User Experience, Consumer Experience, and Applications of Social Computing. 12th International Conference, SCSM 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12195), P616, DOI 10.1007/978-3-030-49576-3_45
   Xiao J, 2018, J AMB INTEL HUM COMP, V9, P667, DOI 10.1007/s12652-017-0466-8
   Xin X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P931, DOI 10.1145/3397271.3401147
   Xinxi Wang, 2014, ACM Transactions on Multimedia Computing, Communications and Applications, V11, DOI 10.1145/2623372
   Yoshii K., 2006, ISMIR, P296
   Zhao X, 2022, J ELECTR COMPUT ENG, V2022, DOI 10.1155/2022/9870505
   Zheng E, 2018, EXPERT SYST APPL, V106, P244, DOI 10.1016/j.eswa.2018.04.014
NR 48
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17448-6
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500012
DA 2024-07-18
ER

PT J
AU Shekari, M
   Rostamian, M
AF Shekari, Motahare
   Rostamian, Milad
TI Brain tumor segmentation from MRI using FCM clustering, morphological
   reconstruction, and active contour
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MRI; Morphological operation; Fuzzy c-means; Brain tumor segmentation;
   Medical image processing
ID CONVOLUTIONAL NEURAL-NETWORKS; IMAGE-ANALYSIS; DRIVEN; MODEL
AB Brain tumors are a leading cause of death in humans of various ages, making early detection and treatment crucial for improving patient outcomes. It is important to accurately determine the precise location, size, and dimensions of the tumor for successful radiotherapy. One reliable method for diagnosing brain tumors is Magnetic Resonance Imaging (MRI), as it can detect small, non-invasive lesions in the brain with great clarity and contrast. However, manual segmentation of tumors on MRI images is time-consuming, despite its accuracy. To address this challenge, computerized techniques can provide more precise and extensive results in less time. In this article, we propose a three-part method for segmenting tumors on MRI images. In the pre-processing stage, the contrast of the image is improved by matching the histogram, removing noise, and sharpening the image. In the next step, the tumor-related cluster is identified using fuzzy clustering. In the post-processing stage, the tumor areas are delineated using morphological reconstruction and active contour techniques. The proposed approach is evaluated on the training portions of two datasets: BraTS 2012 and BraTS 2013. This approach has shown robustness against noise, and intensity non-uniformity in experiments. Additionally, it is quick and more precise than other state-of-the-art segmentation methods, with an average running time of 2.33 s. Additionally, the average segmentation Sensitivity, Dice, Precision, Accuracy, Jaccard, and Hausdorff distance are 92.10%, 0.92, 92.05%, and 99.06%, 0.86, 3.60, respectively. The proposed method demonstrates satisfactory results for Glioma brain tumor segmentation due to fuzzy c-means clustering, morphological reconstruction, and active contour accurate segmentation results and short time. Since most medical images suffer from these issues, this method has the potential to be more effective in the segmentation of complex medical images.
C1 [Shekari, Motahare] Univ Tehran, Sch Elect & Comp Engn, Tehran, Iran.
   [Rostamian, Milad] Iran Univ Sci & Technol, Sch Comp Engn, Tehran, Iran.
C3 University of Tehran; Iran University Science & Technology
RP Rostamian, M (corresponding author), Iran Univ Sci & Technol, Sch Comp Engn, Tehran, Iran.
EM motahareshekari@yahoo.com; milad_rostamian@comp.iust.ac.ir
OI Rostamian, Milad/0000-0002-2196-8948
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Anandgaonkar G, 2014, Int J Sci Res, V3, P814
   [Anonymous], 2013, P NCI MICCAI BRATS
   Aslam H.A., 2013, INT J ADV RES COMPUT, V2, P1429
   Baid U, 2016, COMP STUDY K MEANS G, P583, DOI DOI 10.2991/ICCASP-16.2017.85
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Chen GX, 2020, NEUROIMAGE, V211, DOI 10.1016/j.neuroimage.2020.116620
   Cheng J., 2007, IAENG Int J Appl Math, V36, P2
   Dandil E, 2015, Advances in intelligent systems and computing, V311, DOI [10.1007/978-3-319-09879-1_16, DOI 10.1007/978-3-319-09879-1_16]
   Davy A., 2014, BRATS MICCAI 2014, P1
   Dvorák P, 2016, LECT NOTES COMPUT SC, V9601, P59, DOI 10.1007/978-3-319-42016-5_6
   El-Melegy MT, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-21
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hamamci A, 2012, IEEE T MED IMAGING, V31, P790, DOI 10.1109/TMI.2011.2181857
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Havaei M, 2016, INT J COMPUT ASS RAD, V11, P777, DOI 10.1007/s11548-015-1311-1
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Janani V., 2013, International Journal of Computer Science and Mobile Computing, V2, P244
   Kabade S., 2013, Int J Comput Sci Eng Technol, V4, P524
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kaur Jaskirat, 2012, International Journal of Image, Graphics and Signal Processing, V4, P26, DOI 10.5815/ijigsp.2012.11.04
   Kwon D, 2014, LECT NOTES COMPUT SC, V8673, P763, DOI 10.1007/978-3-319-10404-1_95
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li CM, 2007, PROC CVPR IEEE, P339
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Makropoulos A, 2014, IEEE T MED IMAGING, V33, P1818, DOI 10.1109/TMI.2014.2322280
   MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mohan P, 2013, Int J Innovat Res Comput Commun Eng, V1, P2143
   NAIK D, 2014, INT J COMPUTER SCI I, V5, P3289
   Narmatha C, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02470-5
   Patil PG, 2022, AIP C P, V2494
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Ranjbarzadeh R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90428-8
   Reza S., 2013, Medical Image Computing and Computer Assisted Intervention, P38
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajid S, 2019, ARAB J SCI ENG, V44, P9249, DOI 10.1007/s13369-019-03967-8
   Shahvaran Z, 2021, J NEUROSCI METH, V362, DOI 10.1016/j.jneumeth.2021.109296
   Sheela CJJ, 2022, J KING SAUD UNIV-COM, V34, P557, DOI 10.1016/j.jksuci.2019.04.006
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Urban G., 2014, P MICCAI BRATS BRAIN, P31, DOI DOI 10.1007/978-3-319-12057-3_4
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Wilson B., 2014, Int J Comput Appl, V104, P36
   Xu CY, 1999, IEEE T MED IMAGING, V18, P467, DOI 10.1109/42.781013
   Yazdani S, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/829893
   Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500
   Yousuf M, 2020, Communications in Computer and Information Science, V1198, P562, DOI [10.1007/978-981-15-5232-8_48, DOI 10.1007/978-981-15-5232-8_48]
   Zhang DW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107562
   Zhang DW, 2020, IEEE T IMAGE PROCESS, V29, P9032, DOI 10.1109/TIP.2020.3023609
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhou CH, 2020, IEEE T IMAGE PROCESS, V29, P4516, DOI 10.1109/TIP.2020.2973510
   Zikic D., 2014, Proc. MICCAI-BRATS, V36, P36
NR 54
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17233-5
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW2V2
UT WOS:001155653100001
DA 2024-07-18
ER

PT J
AU An, SM
   Huang, XX
   Cao, LJ
   Wang, LL
AF An, Shunmin
   Huang, Xixia
   Cao, Lujia
   Wang, Linling
TI A comprehensive survey on image dehazing for different atmospheric
   scattering models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Atmospheric imaging; Dehazing dataset; Image dehazing; Thin and dense
   fog
ID WEATHER; RESTORATION; DEGRADATION; EXPLORATION; VISIBILITY; VISION;
   LIGHT
AB Image dehazing techniques are widely used in complex outdoor environments and are commonly categorized based on learning mechanisms. However, the imaging mechanism reveals the reasons for the degradation of hazy images, and the imaging physics process is essential for solving clean image reconstruction. Therefore, different from the previous categorization based solely on learning mechanisms, we propose a more fundamental approach that divides the techniques based on the imaging models used and analyze the advantages and disadvantages of various imaging models to find reasonable computational methods for image reconstruction. This paper focuses on analyzing the principles of different atmospheric imaging models and discusses the dehazing methods based on these models. In addition, we also discuss the development of atmospheric scattering models and the application of different atmospheric imaging models in image dehazing. Finally, this paper presents the application effects of different atmospheric scattering models on thin fog and dense fog datasets. Various issues and challenges faced by existing image dehazing techniques are described, and further research questions are proposed.
C1 [An, Shunmin; Huang, Xixia; Cao, Lujia; Wang, Linling] Shanghai Maritime Univ, Shanghai, Peoples R China.
C3 Shanghai Maritime University
RP An, SM (corresponding author), Shanghai Maritime Univ, Shanghai, Peoples R China.
EM 1029217533@qq.com
OI An, Shunmin/0000-0003-0747-1983
FU We thank the following project for funding: Shanghai Maritime University
   Postgraduate Top Innovative Talent Training Program. the authors would
   also like to sincerely thank the relevant open source websites for
   providing information on the dataset, and the; Shanghai Maritime
   University Postgraduate Top Innovative Talent Training Program
FX We thank the following project for funding: Shanghai Maritime University
   Postgraduate Top Innovative Talent Training Program. the authors would
   also like to sincerely thank the relevant open source websites for
   providing information on the dataset, and the authors would like to
   thank their teachers and colleagues for their valuable advice and
   guidance in the experimental and mathematical analysis The authors would
   like to thank their teachers and colleagues for their valuable advice
   and guidance during the experimental and mathematical analysis.
CR Albishry N, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5061059
   Almalawi A, 2022, CHEMOSPHERE, V303, DOI 10.1016/j.chemosphere.2022.134960
   An Shunmin, 2022, 2022 International Conference on Machine Learning and Knowledge Engineering (MLKE), P202, DOI 10.1109/MLKE55170.2022.00046
   An SM, 2021, APPL OPTICS, V60, P7858, DOI 10.1364/AO.426651
   An SM, 2022, VISUAL COMPUT, V38, P2041, DOI 10.1007/s00371-021-02265-5
   An SM, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253214
   An SM, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251337
   Ancuti C, 2018, P IEEE C COMP VIS PA, P891
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], 2002, COMPUTER VISION ECCV
   Ben Letaifa S, 2015, J BUS RES, V68, P1414, DOI 10.1016/j.jbusres.2015.01.024
   Bowers DG, 2006, ESTUAR COAST SHELF S, V67, P219, DOI 10.1016/j.ecss.2005.11.010
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   CHAVEZ PS, 1988, REMOTE SENS ENVIRON, V24, P459, DOI 10.1016/0034-4257(88)90019-3
   Costabile F, 2009, ATMOS CHEM PHYS, V9, P3163, DOI 10.5194/acp-9-3163-2009
   Dai CG, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107257
   Du R, 2015, IEEE T VEH TECHNOL, V64, P273, DOI 10.1109/TVT.2014.2321010
   Dudhane A, 2018, IEEE WINT CONF APPL, P1397, DOI 10.1109/WACV.2018.00157
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Flynn MJ, 1999, J DIGIT IMAGING, V12, P50, DOI 10.1007/BF03168843
   Fournier GR, 1999, P SOC PHOTO-OPT INS, V3761, P62, DOI 10.1117/12.366488
   Furukawa Y, 2000, 2000 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, P113, DOI 10.1109/ITSC.2000.881027
   Garcia-Garcia A, 2017, Arxiv, DOI [arXiv:1704.06857, DOI 10.48550/ARXIV.1704.06857]
   GOETZ AFH, 1983, ECON GEOL, V78, P573, DOI 10.2113/gsecongeo.78.4.573
   Greene JD, 2016, SCIENCE, V352, P1514, DOI 10.1126/science.aaf9534
   Haque A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113320
   Harald K., 1924, Theorie der horizontalen sichtweite: Kontrast und sichtweite, V12
   Hassan HM, 2011, TRANSPORT RES F-TRAF, V14, P614, DOI 10.1016/j.trf.2011.07.002
   He RJ, 2013, C IND ELECT APPL, P733
   He SM, 2021, EARTH SCI INFORM, V14, P2037, DOI 10.1007/s12145-021-00672-9
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   HUO B, 2015, INT J MULTIPHASE UBI, V10, P13, DOI DOI 10.14257/IJMUE.2015.10.3.02
   Irshad K, 2020, IEEE ACCESS, V8, P99709, DOI 10.1109/ACCESS.2020.2985036
   ISRAEL H, 1959, Die Sichtweite im Nebel und die Moglichkeiten Ihrer Kunstlichen Beeinflussung, P7
   Javed AR, 2021, IEEE T NETW SCI ENG, V8, P1456, DOI 10.1109/TNSE.2021.3059881
   Ju MY, 2017, NEUROCOMPUTING, V260, P180, DOI 10.1016/j.neucom.2017.04.034
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   Karnath HO, 1998, BRAIN, V121, P2357, DOI 10.1093/brain/121.12.2357
   Khan AI, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.104996
   Kim G, 2018, IEEE IMAGE PROC, P2845, DOI 10.1109/ICIP.2018.8451252
   Kim M., 2020, Electron Imaging, V2020, p81, DOI [10.2352/ISSN.2470-1173.2020.16.AVM-081, DOI 10.2352/ISSN.2470-1173.2020.16.AVM-081]
   Kim M, 2021, IEEE ACCESS, V9, P76135, DOI 10.1109/ACCESS.2021.3082175
   Kissinger HA, 1955, FOREIGN AFF, V33, P416, DOI 10.2307/20031108
   Knöbelreiter P, 2017, PROC CVPR IEEE, P1456, DOI 10.1109/CVPR.2017.159
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li CY, 2018, IEEE ACCESS, V6, P24877, DOI 10.1109/ACCESS.2018.2818882
   Li JJ, 2018, IEEE ACCESS, V6, P26831, DOI 10.1109/ACCESS.2018.2833888
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu XP, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P239, DOI 10.1109/ICSPCC.2014.6986190
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Munguía R, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030372
   Narasimhan S, 2004, ACM Trans Graph, P1
   Narasimhan SG, 2003, PROC CVPR IEEE, P665
   Narasimhan SG, 2001, PROC CVPR IEEE, P186
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Pan Wei, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P249, DOI 10.1109/CISP.2010.5646397
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Perkins D., 1985, EDUC RESEARCHER, V14, P11, DOI DOI 10.3102/0013189X014007011
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qiu X, 2017, OPTOELECTRON LETT, V13, P386, DOI 10.1007/s11801-017-7074-x
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang CM, 2021, SIGNAL IMAGE VIDEO P, V15, P411, DOI 10.1007/s11760-020-01761-w
   Wang R, 2018, IEEE I C NETW INFRAS, P81, DOI 10.1109/ICNIDC.2018.8525532
   Wang R, 2016, SIGNAL PROCESS, V127, P24, DOI 10.1016/j.sigpro.2016.02.003
   WRIGHT DL, 1990, J SPORT EXERCISE PSY, V12, P406, DOI 10.1123/jsep.12.4.406
   Yang Y, 2021, SIGNAL IMAGE VIDEO P, V15, P1443, DOI 10.1007/s11760-021-01876-8
   Yeh CH, 2018, ASIAPAC SIGN INFO PR, P1609, DOI 10.23919/APSIPA.2018.8659733
   Zhan Yuan, 2020, EITCE 2020: Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering, P454, DOI 10.1145/3443467.3444709
   Zhang J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2355, DOI 10.1145/3394171.3413763
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zheng ZR, 2021, PROC CVPR IEEE, P16180, DOI 10.1109/CVPR46437.2021.01592
NR 84
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17292-8
EA OCT 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800019
DA 2024-07-18
ER

PT J
AU Li, CB
   Li, HJ
   Zhang, GA
AF Li, Chaobo
   Li, Hongjun
   Zhang, Guoan
TI Grey-adversary perceptual network for anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anomaly detection; Grey relation; Perceptual units; Discrimination
   network
ID FRAME PREDICTION
AB The task of anomaly detection in surveillance videos is challenging due to the sparsity and diversity. In order to perceive more discriminative features and further improve performance, a grey-adversary perceptual network is proposed for anomaly detection. Our method is designed as a combination of frame prediction stage and frame optimization stage. The former stage introduces a grey perceptual unit based on Deng's grey relation, which perceives encoding features from encoder and outputs perceptual features for decoder, improving the capacity of anomaly perception. The latter one designs a discrimination network to learn more detailed features for small abnormal regions, and the grey absolute relation is imported to enhance the robustness against illumination, reducing the false detection. The training stage is performed by adversarial learning. Extensive experiments on UCSD Ped2, CUHK Avenue and ShanghaiTech datasets reach the averaged AUC of 97.6%, 88.9% and 73.7%, respectively. The comparison results with state-of-the-art methods demonstrate that the effectiveness and advantage of our method in anomaly detection.
C1 [Li, Chaobo; Li, Hongjun; Zhang, Guoan] Nantong Univ, Sch Informat Sci & Technol, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nantong University; Nanjing University
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM 1811310007@yjs.ntu.edu.cn; lihongjun@ntu.edu.cn; gzhang@ntu.edu.cn
OI Zhang, Guoan/0000-0001-8439-3478; Li, Chaobo/0000-0003-3772-3344; li,
   hongjun/0000-0001-7500-4979
FU National Natural Science Foundation of China [61871241, 61971245,
   61976120]; Nanjing University State Key Lab [KFKT2019B15]; Nantong
   Science and Technology Program [JC2021131]; Postgraduate Research and
   Practice Innovation Program of Jiangsu Province [KYCX22_3340]
FX This work is supported by National Natural Science Foundation of China
   (NO.61871241, NO.61971245, NO.61976120); Nanjing University State Key
   Lab. for Novel Software Technology (KFKT2019B15); Nantong Science and
   Technology Program (JC2021131); Postgraduate Research and Practice
   Innovation Program of Jiangsu Province (KYCX22_3340).
CR Aggarwal A. K., 2020, J COMPUT SCI-NETH, V16, P651, DOI DOI 10.3844/JCSSP.2020.651.659
   Cai YH, 2021, NEUROCOMPUTING, V423, P264, DOI 10.1016/j.neucom.2020.10.044
   Cho M, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108703
   De Paepe D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020913
   Fang ZW, 2021, IEEE T MULTIMEDIA, V23, P4106, DOI 10.1109/TMM.2020.3037538
   Garg M, 2021, ARTIF INTELL REV, V54, P4731, DOI 10.1007/s10462-021-10010-6
   Georgescu MI, 2022, IEEE T PATTERN ANAL, V44, P4505, DOI 10.1109/TPAMI.2021.3074805
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Guo AB, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104391
   Guo XH, 2022, GREY SYST, V12, P117, DOI 10.1108/GS-09-2020-0124
   Huang C, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, DOI 10.1145/3503161.3548369
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jian MW, 2023, MULTIMED TOOLS APPL, V82, P427, DOI 10.1007/s11042-022-13125-2
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jiaxu Leng, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P6746, DOI 10.1145/3503161.3548000
   Li CB, 2022, J GREY SYST-UK, V34, P1
   Li CB, 2023, APPL INTELL, V53, P542, DOI 10.1007/s10489-022-03488-2
   Li DH, 2022, PATTERN RECOGN LETT, V156, P183, DOI 10.1016/j.patrec.2022.03.004
   Li HJ, 2021, J GREY SYST-UK, V33, P30
   Li LJ, 2021, J INTELL FUZZY SYST, V40, P4013, DOI 10.3233/JIFS-200344
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Li P, 2023, COMPUT IND ENG, V175, DOI 10.1016/j.cie.2022.108861
   Li S, 2021, IEEE T CIRC SYST VID, V31, P1283, DOI 10.1109/TCSVT.2020.2984783
   Liu Sifeng, 1991, Journal of Grey Systems, V3, P39
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu YW, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909850
   Luo WX, 2022, IEEE T PATTERN ANAL, V44, P7505, DOI 10.1109/TPAMI.2021.3129349
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Lv H, 2021, IEEE T IMAGE PROCESS, V30, P4505, DOI 10.1109/TIP.2021.3072863
   Miswan NH, 2021, GREY SYST, V11, P796, DOI 10.1108/GS-12-2020-0168
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Ning X, 2023, AUTOMAT CONSTR, V150, DOI 10.1016/j.autcon.2023.104831
   Slavic G, 2022, IEEE T MULTIMEDIA, V24, P1399, DOI 10.1109/TMM.2021.3065232
   Song H, 2020, IEEE T MULTIMEDIA, V22, P2138, DOI 10.1109/TMM.2019.2950530
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Tran TM, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3544014
   Wang WQ, 2022, SIGNAL IMAGE VIDEO P, V16, P1747, DOI 10.1007/s11760-021-02131-w
   Wang WQ, 2021, NEUROCOMPUTING, V433, P37, DOI 10.1016/j.neucom.2020.12.025
   Wang Y, 2023, NEUROCOMPUTING, V532, P141, DOI 10.1016/j.neucom.2023.02.027
   Yan SY, 2020, IEEE T COGN DEV SYST, V12, P30, DOI 10.1109/TCDS.2018.2883368
   Yu J, 2022, IEEE T NEUR NET LEAR, V33, P3572, DOI 10.1109/TNNLS.2021.3053563
   Yu Q, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/155014772181256
   Zavrtanik V, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107706
   Zhang Y, 2021, IEEE T CIRC SYST VID, V31, P3694, DOI 10.1109/TCSVT.2020.3039798
   Zhao LT, 2022, PROCESS SAF ENVIRON, V166, P617, DOI 10.1016/j.psep.2022.08.035
   Zhong YH, 2022, IEEE T CIRC SYST VID, V32, P8285, DOI 10.1109/TCSVT.2022.3190539
   Zhou Z, 2023, IEEE T CIRC SYST VID, V33, P3173, DOI 10.1109/TCSVT.2023.3234266
NR 52
TC 0
Z9 0
U1 9
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17253-1
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800018
DA 2024-07-18
ER

PT J
AU Otair, M
   Abualigah, L
   Tawfiq, S
   Alshinwan, M
   Ezugwu, AE
   Zitar, RA
   Sumari, P
AF Otair, Mohammad
   Abualigah, Laith
   Tawfiq, Saif
   Alshinwan, Mohammad
   Ezugwu, Absalom E.
   Zitar, Raed Abu
   Sumari, Putra
TI Adapted arithmetic optimization algorithm for multi-level thresholding
   image segmentation: a case study of chest x-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image segmentation; Multi-level thresholding; Meta-heuristic algorithms;
   Arithmetic optimization algorithm
AB Particularly in recent years, there has been increased interest in determining the ideal thresholding for picture segmentation. The best thresholding values are found using various techniques, including Otsu and Kapur-based techniques. These techniques work well for bi-level thresholding, but when used to find the appropriate thresholds for multi-level thresholding, there will be issues with long calculation times, high computational costs, and the need for accuracy improvements. This work investigates the capability of the Arithmetic Optimization Algorithm to discover the best multilayer thresholding for picture segmentation to circumvent this issue. The leading mathematical arithmetic operators' distributional nature is used by the AOA method. The picture histogram was used to construct the candidate solutions in the modified algorithms, which were then updated according to the algorithm's features. The solutions are evaluated using Otsu's fitness function throughout the optimization process. The picture histogram is used to display the algorithm's potential solutions. The proposed approach is tested on five frequent photos from the Berkeley University database. The fitness function, root-mean-squared error, peak signal-to-noise ratio, and other widely used assessment metrics were utilized to assess the performance of the suggested segmentation approach. Many benchmark pictures were employed to verify the suggested technique's effectiveness and evaluate it against other well-known optimization methods described in the literature.
C1 [Otair, Mohammad; Tawfiq, Saif] Khawarizmi Univ Tech Coll, Amman 11953, Jordan.
   [Abualigah, Laith] Al Al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.
   [Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Abualigah, Laith] Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.
   [Abualigah, Laith] Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
   [Abualigah, Laith; Sumari, Putra] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Abualigah, Laith] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.
   [Alshinwan, Mohammad] Appl Sci Private Univ, Fac Informat Technol, Amman 11931, Jordan.
   [Ezugwu, Absalom E.] North West Univ, Unit Data Sci & Comp, 11 Hoffman St, ZA-2520 Potchefstroom, South Africa.
   [Zitar, Raed Abu] Sorbonne Univ Abu Dhabi, Sorbonne Ctr Artificial Intelligence, Abu Dhabi 38044, U Arab Emirates.
C3 Al al-Bayt University; Al-Ahliyya Amman University; Middle East
   University; Sunway University; Universiti Sains Malaysia; Lebanese
   American University; North West University - South Africa
RP Abualigah, L (corresponding author), Al Al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.; Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.; Abualigah, L (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.; Abualigah, L (corresponding author), Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.; Abualigah, L (corresponding author), Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.; Abualigah, L (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.
EM Dean@khawarizmi.edu.jo; aligah.2020@gmail.com; moshanwan@yahoo.com;
   Ezugwua@ukzn.ac.za; raed.zitar@sorbonne.ae; putra@usm.my
RI Sumari, Putra/I-1070-2016; Abualigah, Laith/ABC-9695-2020; Ezugwu,
   Absalom El-Shamir/AIE-3466-2022
OI Abualigah, Laith/0000-0002-2203-4549; Ezugwu, Absalom
   El-Shamir/0000-0002-3721-3400
CR Abd Elaziz M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2020.113201
   Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Abualigah L, 2023, J BIONIC ENG, V20, P1766, DOI 10.1007/s42235-023-00332-2
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Abualigah L, 2021, ARTIF INTELL REV, V54, P2567, DOI 10.1007/s10462-020-09909-3
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P15533, DOI 10.1007/s00521-020-04789-8
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P11195, DOI 10.1007/s00521-019-04629-4
   Al-Shourbaji I, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00279-6
   Alaiad AI, 2023, J MED BIOL ENG, V43, P135, DOI 10.1007/s40846-023-00783-2
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Chakraborty S, 2023, ARCH COMPUT METHOD E, V30, P985, DOI 10.1007/s11831-022-09825-5
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Dinkar SK, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114766
   Dirami A, 2013, SIGNAL PROCESS, V93, P139, DOI 10.1016/j.sigpro.2012.07.010
   Hui KF, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108230
   Liu QX, 2023, ARTIF INTELL REV, V56, P159, DOI 10.1007/s10462-023-10498-0
   Mohammadi M, 2016, ENG APPL ARTIF INTEL, V50, P1, DOI 10.1016/j.engappai.2015.12.009
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Mohsen Z., 2023, Decis. Anal. J, V7, P100251
   Nama S, 2023, SWARM EVOL COMPUT, V79, DOI 10.1016/j.swevo.2023.101304
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Senthilkumaran N., 2016, COMPUT SCI ENG INT J, V6, P1, DOI [DOI 10.5121/CSEIJ.2016.6101, 10.5121/cseij.2016, DOI 10.5121/CSEIJ.2016]
   Singh S, 2020, NEURAL COMPUT APPL, V32, P16681, DOI 10.1007/s00521-020-04989-2
   Wang ZB, 2020, ARTIF INTELL REV, V53, P5637, DOI 10.1007/s10462-020-09830-9
   Wang ZY, 2021, IET IMAGE PROCESS, V15, P3573, DOI 10.1049/ipr2.12232
   Yang ZL, 2020, NEURAL COMPUT APPL, V32, P12011, DOI 10.1007/s00521-019-04210-z
   Ye Q, 2003, 2003 INT C MULT EXP
   Yin SL, 2018, IEEE ACCESS, V6, P26069, DOI 10.1109/ACCESS.2018.2834960
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
NR 32
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17221-9
EA OCT 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800001
DA 2024-07-18
ER

PT J
AU Fang, LL
   Qiao, H
AF Fang, Lingling
   Qiao, Huan
TI Retinal multi-disease classification using the varices feature-based
   dual-channel network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Retinal varices features; PCA; VAM-DCN; Varices attention mechanism;
   Multi-disease classification
ID DIABETIC-RETINOPATHY
AB Fundus disease is the main cause of visual defect in the cases of non-congenital visual disability, where diabetic retinopathy, ischemic optic neuropathy, optic neuritis, and glaucoma are the most common diseases. Early detection and treatment are the key to control fundus lesions. At present, manual diagnosis may lead to the problem of wasting time and misdiagnosis. On this basis, this paper proposes a dual-channel network for multi-disease diagnosis based on retinal varices features and presents a complete fundus retinal image-assisted diagnosis solution. Firstly, on the advice of ophthalmologists, the retinal varices features of various diseases are extracted. Then, combined with the varices attention mechanism, a dual-channel network retinal multi-disease classification model (VAM-DCN) is constructed. Finally, the retinal varices features are put into a dual channel for network learning and training. The proposed method is verified on the clinical data (normal retina, diabetic retinopathy, ischemic optic neuropathy, optic neuritis, and glaucoma) of Dalian NO.3 People's Hospital, and the precision, recall, F1-score, and accuracy can reach 99.44%, 99.39%, 99.41%, and 99.4%, respectively. The proposed method can help ophthalmologist realize the multi-disease classification of fundus retinal images, reduce the possibility of misdiagnosis and missed diagnosis, which has certain clinical medical value.
C1 [Fang, Lingling; Qiao, Huan] Liaoning Normal Univ, Sch Comp Sci & Artificial Intelligence, Dalian, Liaoning, Peoples R China.
C3 Liaoning Normal University
RP Fang, LL (corresponding author), Liaoning Normal Univ, Sch Comp Sci & Artificial Intelligence, Dalian, Liaoning, Peoples R China.
EM fanglingling@lnnu.edu.cn
RI Fang, Lingling/N-1534-2018
OI Fang, Lingling/0000-0002-4397-7212
FU This work was supported by Natural Science Foundation of Liaoning
   Province under Grant 2021-MS-272, and Educational Committee project of
   Liaoning Province under Grant LJKQZ2021088. Thanks to Siyu Sun,
   ophthalmologist of Dalian NO.3 Peopleapos;s Hospital, [2021-MS-272];
   Natural Science Foundation of Liaoning Province [LJKQZ2021088];
   Educational Committee project of Liaoning Province
FX This work was supported by Natural Science Foundation of Liaoning
   Province under Grant 2021-MS-272, and Educational Committee project of
   Liaoning Province under Grant LJKQZ2021088. Thanks to Siyu Sun,
   ophthalmologist of Dalian NO.3 People & apos;s Hospital, for providing
   clinical data for this paper.
CR Adem K, 2018, EXPERT SYST APPL, V114, P289, DOI 10.1016/j.eswa.2018.07.053
   Al-Antary MT, 2021, IEEE ACCESS, V9, P54190, DOI 10.1109/ACCESS.2021.3070685
   Almustafa KM, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104357
   Anushiadevi R, 2023, J INF SECUR APPL, V72, DOI 10.1016/j.jisa.2022.103407
   Aqsa A, 2023, fundus images, V36, DOI [10.32604/iasc.2023.034041, DOI 10.32604/IASC.2023.034041]
   Chen J, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422520206
   Chen XX, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102444
   Cheng J, 2023, MICROMACHINES-BASEL, V14, DOI 10.3390/mi14010098
   Da rocha Douglas Abreu, 2022, Research on Biomedical Engineering, V38, P761, DOI 10.1007/s42600-022-00200-8
   Fang LL, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103810
   Förster A, 2019, J CLIN NEUROSCI, V68, P268, DOI 10.1016/j.jocn.2019.05.050
   Gong J, 2022, BIOANALYSIS, V14, P1479, DOI 10.4155/bio-2022-0195
   Grassmann F, 2018, OPHTHALMOLOGY, V125, P1410, DOI 10.1016/j.ophtha.2018.02.037
   Ho E, 2022, TRANSL VIS SCI TECHN, V11, DOI 10.1167/tvst.11.10.39
   Huan XL, 2022, INMATEH-AGRIC ENG, V66, P19, DOI [10.35633/inmateh-66-02, 10.4018/IJCINI.313442]
   Lopes FS, 2019, BMC OPHTHALMOL, V19, DOI 10.1186/s12886-019-1054-9
   Moorthy J, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6040117
   Naidana K, 2023, Comput Syst Sci Eng, V47, DOI [10.32604/csse.2023.036744, DOI 10.32604/CSSE.2023.036744]
   Omodaka K, 2022, BMC OPHTHALMOL, V22, DOI 10.1186/s12886-022-02587-5
   Parthiban K, 2023, MULTIMED TOOLS APPL, V82, P18947, DOI 10.1007/s11042-022-14234-8
   Playout C, 2022, MED IMAGE ANAL, V82, DOI 10.1016/j.media.2022.102608
   Polizzi S, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031520
   Saranya P, 2022, VISUAL COMPUT, V38, P977, DOI 10.1007/s00371-021-02062-0
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Sonar R, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00334-6
   World Health Organization, 2019, WORLD REP VIS
   You HX, 2022, J FUNCT SPACE, V2022, DOI 10.1155/2022/8326626
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhu SJ, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.808402
NR 29
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-17127-6
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100012
DA 2024-07-18
ER

PT J
AU Ren, F
   Hao, YL
   Pang, KX
   Wu, ZY
AF Ren, Fang
   Hao, Yanli
   Pang, Kexin
   Wu, Ziyi
TI Reversible data hiding scheme in encrypted images based on homomorphic
   encryption and pixel value ordering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Reversible data hiding; Homomorphic encryption; Pixel value ordering;
   Encrypted images
AB With the growing demands of cloud computing and privacy protection, reversible data hiding in encrypted images (RDHEI) has been gradually developed. This paper proposes a RDHEI scheme based on reserving room before encryption (RRBE). The scheme is divided into three types of users: image owner, data hider and receiver. First, the image owner preprocesses the image using a median-prediction-based pixel value ordering algorithm (M-PVO), and then encrypts the image using the Paillier homomorphic cryptosystem, and the data hider performs two stages of data embedding on the encrypted image. According to the key held by the receiver, the data embedded in different stages can be extracted and the original image can be recovered lossless. The experimental results show that the embedding rate of the first stage is about 0.7 bpp, and the embedding rate of the second stage can reach 12 bpp. Compared with other schemes, the proposed scheme has better image quality at the same embedding rate.
C1 [Ren, Fang; Hao, Yanli; Pang, Kexin; Wu, Ziyi] Xian Univ Posts & Telecommun, Sch Cyberspace secur, Xian 710121, Shannxi, Peoples R China.
   [Ren, Fang; Hao, Yanli] Xian Univ Posts & Telecommun, Natl Engn Lab Wireless Secur, Xian 710121, Shannxi, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of
   Posts & Telecommunications
RP Hao, YL (corresponding author), Xian Univ Posts & Telecommun, Sch Cyberspace secur, Xian 710121, Shannxi, Peoples R China.; Hao, YL (corresponding author), Xian Univ Posts & Telecommun, Natl Engn Lab Wireless Secur, Xian 710121, Shannxi, Peoples R China.
EM 76487690@qq.com; 1982471453@qq.com; 2252246606@qq.com; 861232640@qq.com
RI Wu, Ziyi/S-7457-2017; Wu, Ziyi/HZI-1669-2023
OI hao, haoyanli/0009-0009-9284-5337
FU This paper was supported by the National Nature Science Foundation of
   China (Program No. 62202377), the Natural Science Basic Research Plan of
   Shaanxi Province of China (Program No. 2021JM-463, 2022JM-353), the
   Graduate Innovation Fund of Xi'an University [62202377]; National Nature
   Science Foundation of China [2021JM-463, 2022JM-353]; Natural Science
   Basic Research Plan of Shaanxi Province of China [CXJJDL2022015];
   Graduate Innovation Fund of Xi'an University of Posts and
   Telecommunications
FX This paper was supported by the National Nature Science Foundation of
   China (Program No. 62202377), the Natural Science Basic Research Plan of
   Shaanxi Province of China (Program No. 2021JM-463, 2022JM-353), the
   Graduate Innovation Fund of Xi'an University of Posts and
   Telecommunications (CXJJDL2022015).
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Amine K, 2023, MULTIMED TOOLS APPL, V82, P35401, DOI 10.1007/s11042-023-14792-5
   [Anonymous], 2006, The usc-sipi image database
   Anushiadevi R, 2023, MULTIMED TOOLS APPL, V82, P46269, DOI 10.1007/s11042-023-15455-1
   Bas PFT, 2021, The BOWS-2 Image Database
   Bas PPT, 2011, The BOSSbase Image Database
   Bhardwaj R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03299-2
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen B, 2023, MULTIMED TOOLS APPL, V82, P1203, DOI 10.1007/s11042-022-13266-4
   Chen B, 2019, SIGNAL PROCESS, V164, P48, DOI 10.1016/j.sigpro.2019.05.036
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Gao ED, 2019, INFORM SCIENCES, V505, P549, DOI 10.1016/j.ins.2019.07.101
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Leelavathi R, 2022, INT C COMP COMM EL B, P517
   Li FY, 2023, MULTIMED TOOLS APPL, V82, P6013, DOI 10.1007/s11042-022-13406-w
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Puyang Y, 2018, IEEE INT WORKS INFOR
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Ren F, 2023, Multimed Tools Appl, P1
   Sabeen Govind P, 2022, INN COMP INT COMP VI, ppp231
   Sayah Moad Med, 2023, Research on Biomedical Engineering, P167, DOI 10.1007/s42600-023-00261-3
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai CS, 2022, MULTIMED TOOLS APPL, V81, P18807, DOI 10.1007/s11042-022-12684-8
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wang YM, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118600
   Wu HT, 2019, J VIS COMMUN IMAGE R, V62, P87, DOI 10.1016/j.jvcir.2019.04.015
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xiao D, 2017, FRONT INFORM TECH EL, V18, P1732, DOI 10.1631/FITEE.1601067
   Yang CH, 2022, SOFT COMPUT, V26, P1727, DOI 10.1007/s00500-022-06745-1
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Ying QC, 2019, IEEE ACCESS, V7, P46506, DOI 10.1109/ACCESS.2019.2909560
   Zhang LM, 2022, MULTIMED TOOLS APPL, V81, P29347, DOI 10.1007/s11042-022-12710-9
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 50
TC 1
Z9 1
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-17242-4
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100006
DA 2024-07-18
ER

PT J
AU Artuger, F
   Özkaynak, F
AF Artuger, Firat
   Ozkaynak, Fatih
TI A new algorithm to generate aes-like substitution boxes based on sine
   cosine optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Security; S-box; Sine-cosine algorithm; High nonlinearity; AES;
   Symmetric encryption
ID CHAOTIC MAP
AB Symmetric encryption approaches are generally used for data encryption. One of the basic requirements for symmetric encryption algorithms to provide security is strong s-box structures. Because s-box is a nonlinear unit in these encryption algorithms and provides the requirement called confusion. In this article, a new technique is developed to produce effective s-boxes like the 16*16 s-box structure used in the AES algorithm. In the proposed method, the sine cosine algorithm (SCA), one of the recently developed optimization algorithms, is used. SCA is a suitable option for generating strong s-boxes because of its strong randomness and ease of implementation. The proposed method first uses a logistic map to generate the initial population. Then, the nonlinearity value is optimized with the help of the sine cosine algorithm. The proposed method reaches the highest nonlinearity value (112) by relocating 126 values in the s-box structure produced initially. Looking at the results, it is seen that the proposed method gives better results than other optimization-based s-box creation methods. This new method has significant potential to improve the security of symmetric encryption algorithms and make data encryption processes stronger.
C1 [Artuger, Firat] Munzur Univ, Dept Comp Engn, TR-62200 Tunceli, Turkiye.
   [Ozkaynak, Fatih] Fırat Univ, Dept Software Engn, TR-23119 Elazig, Turkiye.
C3 Munzur University
RP Artuger, F (corresponding author), Munzur Univ, Dept Comp Engn, TR-62200 Tunceli, Turkiye.
EM firatartuger@munzur.edu.tr; ozkaynak@firat.edu.tr
RI artuğer, fırat/AET-3815-2022
FU Scientific and Technological Research Council of Turkey [121E600,
   122E337]
FX Fatih Ozkaynak was supported in part by The Scientific and Technological
   Research Council of Turkey under Grant 121E600 and 122E337.
CR Ahmad Musheer, 2020, Entropy (Basel), V22, DOI 10.3390/e22070717
   Ahmad M, 2020, IEEE ACCESS, V8, P116132, DOI 10.1109/ACCESS.2020.3004449
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Alhadawi HS, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102671
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Alzaidi AA, 2018, COMPLEXITY, DOI 10.1155/2018/9389065
   Artuger F, 2023, WIRELESS PERS COMMUN, V131, P835, DOI 10.1007/s11277-023-10456-7
   Artuger F, 2022, NEURAL COMPUT APPL, V34, P20203, DOI 10.1007/s00521-022-07589-4
   Artuger F, 2021, INFORM SCIENCES, V576, P577, DOI 10.1016/j.ins.2021.07.036
   Artuger F, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040571
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Biham E., 2012, DIFFERENTIAL CRYPTAN
   Chen G, 2008, CHAOS SOLITON FRACT, V36, P1028, DOI 10.1016/j.chaos.2006.08.003
   Cusick TW, 2017, CRYPTOGRAPHIC BOOLEAN FUNCTIONS AND APPLICATIONS, 2ND EDITION, P1
   Daemen J, 2001, DR DOBBS J, V26, P137
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Forouzandeh S, 2022, FUZZY INF ENG, V14, P26, DOI 10.1080/16168658.2021.2019430
   Forouzandeh S, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104325
   Hematpour N, 2021, NEURAL COMPUT APPL, V33, P5111, DOI 10.1007/s00521-020-05304-9
   Hua ZY, 2022, IEEE T SYST MAN CY-S, V52, P4402, DOI 10.1109/TSMC.2021.3096967
   Hua ZY, 2022, IEEE T CIRCUITS-I, V69, P784, DOI 10.1109/TCSI.2021.3117865
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Hussain I, 2013, NEURAL COMPUT APPL, V23, P97, DOI 10.1007/s00521-012-0914-5
   Kang M, 2022, IEEE ACCESS, V10, P10898, DOI 10.1109/ACCESS.2022.3144458
   Khan H, 2023, MULTIMED TOOLS APPL, V82, P6943, DOI 10.1007/s11042-022-13612-6
   Khan LS, 2021, CHINESE J PHYS, V72, P558, DOI 10.1016/j.cjph.2021.03.029
   Lambic D, 2014, CHAOS SOLITON FRACT, V58, P16, DOI 10.1016/j.chaos.2013.11.001
   Malik MSM, 2020, IEEE ACCESS, V8, P35682, DOI 10.1109/ACCESS.2020.2973679
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Özkaynak F, 2019, NEURAL COMPUT APPL, V31, P3317, DOI 10.1007/s00521-017-3287-y
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Wang Y, 2020, INFORM SCIENCES, V523, P152, DOI 10.1016/j.ins.2020.03.025
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Ye Tian, 2017, Mathematical Problems in Engineering, V2017, DOI 10.1155/2017/6969312
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
   Zamli KZ, 2023, ICT EXPRESS, V9, P619, DOI 10.1016/j.icte.2022.11.005
   Zamli KZ, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115305
   Zamli KZ, 2021, NEURAL COMPUT APPL, V33, P16641, DOI 10.1007/s00521-021-06260-8
   Zamli KZ, 2023, Neural Comput Applic, P1
NR 42
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17200-0
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600004
DA 2024-07-18
ER

PT J
AU Aiswarya, MA
   Rajan, R
AF Aiswarya, M. A.
   Rajan, Rajeev
TI A review on tonic estimation algorithms in indian art music
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Tonic pitch; Raga; Indian art music; Modified group delay; Pitch;
   CompMusic project group
ID GROUP DELAY FUNCTIONS; SPEECH; IDENTIFICATION; RAGA
AB Tonic is one of the basic concepts in music. The tonic pitch is normally entrenched by the main performers, depending on their vocal range and the range of the accompanying instruments. Hence, it varies among artists as well as performances. Tonic identification is a key task to be performed since it plays an important role in solving other problems like raga recognition, tuning analysis, etc. In this paper, we review some of the latest tonic identification approaches in Indian art music. We study the performance of each method in the context of music tradition using the Indian art music dataset. We analyzed the performance of the cepstral-based method of tonic pitch estimation with and without optimal selection of frames, non-negative matrix factorization (NMF), frequency-ratio method, and group delay-based algorithm. Furthermore, we show that the modified group delay-based methods outperform the conventional tonic estimation methods. We also present a detailed error analysis of each method which will be helpful for future research.
C1 [Aiswarya, M. A.; Rajan, Rajeev] APJ Abdul Kalam Technol Univ, Coll Engn Trivandrum, Thiruvananthapuram, India.
C3 College of Engineering, Trivandrum
RP Aiswarya, MA (corresponding author), APJ Abdul Kalam Technol Univ, Coll Engn Trivandrum, Thiruvananthapuram, India.
EM aiswaryama98@gmail.com; rajeev@cet.ac.in
CR Aiswarya M. A., 2023, 2023 International Conference on Intelligent Systems for Communication, IoT and Security (ICISCoIS), P527, DOI 10.1109/ICISCoIS56541.2023.10100503
   Alison A., 1998, The garland encyclopedia of world music: South Asia: the Indian subcontinent, (vol 1)
   Anantapadmanabhan A, 2013, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.2013.6637633
   Atli HS, 2015, 5 INT WORKSH FOLK MU, P119
   Bellur A, 2013, Journal of new music research, IEEE, P1
   Bogert B., 1963, P S TIME SERIES ANAL, P209
   Bor Joep., 2010, Hindustani Music: Thirteenth to Twentieth Centuries
   Camacho A, 2008, J ACOUST SOC AM, V124, P1638, DOI 10.1121/1.2951592
   Caudhuri VR, 2000, The dictionary of Hindustani classical music, V8
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Deva BC, 1980, The music of India: A scientific study
   Gulati S, 2012, P 2 COMPMUSIC WORKSH, P119
   Gulati S, 2014, J NEW MUSIC RES, V43, P53, DOI 10.1080/09298215.2013.875042
   Koduri GK, 2012, J NEW MUSIC RES, V41, P337, DOI 10.1080/09298215.2012.735246
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Madhusudhan S. T., 2019, P 20 INT SOC MUS INF, P533
   Manjabhat SS, 2017, J NEW MUSIC RES, V46, P229, DOI 10.1080/09298215.2017.1330351
   Murthy HA, 2011, SADHANA-ACAD P ENG S, V36, P745, DOI 10.1007/s12046-011-0045-1
   Oppenheim A. V., 1999, DISCRETE TIME SIGNAL, DOI DOI 10.1049/EP.1977.0078
   Pawar Mahesh Y., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P733, DOI 10.1007/978-981-13-3600-3_70
   Rabiner Lawrence, 2010, Digital Processing of Speech Signals
   Rajan R, 2017, SPEECH COMMUN, V89, P37, DOI 10.1016/j.specom.2017.02.004
   Rajan R, 2013, INT CONF ACOUST SPEE, P186, DOI 10.1109/ICASSP.2013.6637634
   Ranjani HG, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P29, DOI 10.1109/ASPAA.2011.6082295
   Salamon J, 2012, ISMIR 2012
   Salamon J, 2012, IEEE T AUDIO SPEECH, V20, P1759, DOI 10.1109/TASL.2012.2188515
   Schmidt MN, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2614
   Senturk S, 2013, P 14 INT SOC MUS INF
   Smaragdis P, 2003, 2003 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS PROCEEDINGS, P177, DOI 10.1109/ASPAA.2003.1285860
   Tzanetakis George., 2007, J INTERDISCIPLINARY, V1, P1
   Unnikrishnan G., 2018, Int J Res Eng Innov, V2, P293
   Viswanathan T, 2004, Music in South India: the Karn atak concert tradition and beyond: experiencing music, expressing culture, Patent No. i9780195145908
   Wade BonnieC., 1998, Imaging Sound: An Ethnomusicological Study of Music, Art, and Culture in Mughal India
   YEGNANARAYANA B, 1984, IEEE T ACOUST SPEECH, V32, P610, DOI 10.1109/TASSP.1984.1164365
NR 34
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17161-4
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900011
DA 2024-07-18
ER

PT J
AU Ziani, S
   Suchetha, M
   Rizal, A
AF Ziani, Said
   Suchetha, M.
   Rizal, Achmad
TI Time-scale image analysis for detection of fetal electrocardiogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Time-scale analysis; Segmentation; Fetal electrocardiogram
ID ECG EXTRACTION
AB The model presented in this paper is founded on the equivalence between the signal under investigation and its time-scale distribution (TSI). Therefore, separating the signal into multiple sources requires differentiating this TSI into multiple independent TSIs that are intended to represent the individual sources. For instance, when applying the continuous wavelet transform to an electrocardiogram signal that simultaneously encompasses the electrical activities of both the fetal hearts (FECG) and the maternal heart (MECG), a highly intricate energy domain is generated, comprising distinct energy sub-domains. These sub-domains can be effectively separated, extracted, and transformed using a segmentation method, resulting in multiple time-scale images that can be analytically inverted into meaningful electrical signals. The presented method will permit the extraction of the fetal contribution to the FECG with optimal filtering of noise and undesirable electrical interference. Furthermore, the provided algorithms yield unequivocal numerical results, as demonstrated through their application to internationally recognized databases, such as the Daisy database and the Fetal ECG Synthetic database from PhysioNet. The obtained Signal-to-Noise Ratio (SNR) and Fetal R Peak Detection Accuracy (FRPDA) values serve to illustrate the efficacy of these techniques in isolating FECG signals from unwanted components and noise, thus enhancing the analysis and interpretation of fetal cardiac health.
C1 [Ziani, Said] Mohammed V Univ, ENSAM, Rabat 10090, Morocco.
   [Suchetha, M.] Vellore Inst Technol, Ctr Healthcare Advancement Innovat & Res, Chennai 10587, India.
   [Rizal, Achmad] Telkom Univ, Sch Elect Engn, Bandung 610101, Indonesia.
C3 Mohammed V University in Rabat; Telkom University
RP Ziani, S (corresponding author), Mohammed V Univ, ENSAM, Rabat 10090, Morocco.
EM s.ziani@um5r.ac.ma; suchetha.m@vit.ac.in;
   achmadrizal@telkomuniversity.ac.id
RI Rizal, Achmad/K-8328-2019; said, ziani/AFV-0087-2022
OI Rizal, Achmad/0000-0001-9712-965X; said, ziani/0000-0001-9586-4511
CR Agostinelli Angela, 2017, Open Biomed Eng J, V11, P17, DOI 10.2174/1874120701711010017
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P554, DOI 10.1109/LGRS.2010.2041324
   Chen HY, 2023, MULTIMED TOOLS APPL, V82, P10833, DOI 10.1007/s11042-022-14097-z
   da Costa PÜ, 2021, IEEE T BIOMED CIRC S, V15, P898, DOI 10.1109/TBCAS.2021.3120237
   De Moor B., 1997, Journal A, V38, P4
   Dhas DE, 2022, IEEE T BIOMED CIRC S, V16, P981, DOI 10.1109/TBCAS.2022.3204993
   Guo TT, 2022, IEEE ACCESS, V10, P58869, DOI 10.1109/ACCESS.2022.3179517
   Gurve D, 2020, IEEE J BIOMED HEALTH, V24, P669, DOI 10.1109/JBHI.2019.2920356
   Hatai I, 2013, 2013 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL ENGINEERING (ICAEE 2013), P160, DOI 10.1109/ICAEE.2013.6750325
   Jaros R, 2019, 2019 INTERNATIONAL SYMPOSIUM ON ADVANCED ELECTRICAL AND COMMUNICATION TECHNOLOGIES (ISAECT), DOI 10.1109/isaect47714.2019.9069682
   Jebastine J, 2023, CIRC SYST SIGNAL PR, V42, P6058, DOI 10.1007/s00034-023-02386-3
   Kanjilal PP, 1997, IEEE T BIO-MED ENG, V44, P51, DOI 10.1109/10.553712
   Kaya Y, 2021, INT ARAB J INF TECHN, V18, P279, DOI 10.34028/iajit/18/3/3
   Kiymaç E, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119162
   Krupa AJD, 2021, BIOMED ENG-BIOMED TE, V66, P503, DOI 10.1515/bmt-2020-0313
   Lampros T, 2023, AIAI 2023 IFIP WG 12, V677, P45
   Li H, 2020, IEEE GEOSCI REMOTE S, V17, P1411, DOI 10.1109/LGRS.2019.2947220
   Manzke R, 2010, IEEE T MED IMAGING, V29, P260, DOI 10.1109/TMI.2009.2021946
   Mirza S, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P157, DOI [10.1109/CSPA48992.2020.9068696, 10.1109/cspa48992.2020.9068696]
   Mohebbian MR, 2022, IEEE J BIOMED HEALTH, V26, P515, DOI 10.1109/JBHI.2021.3111873
   Morales DP, 2013, MED ENG PHYS, V35, P1005, DOI 10.1016/j.medengphy.2012.09.011
   Nakatani S, 2022, IEEE GLOB COMM CONF, P2266, DOI 10.1109/GLOBECOM48099.2022.10001697
   Rodriguez RRB, 2021, 2021 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL, CONTROL AND INSTRUMENTATION ENGINEERING (IEEE ICECIE'2021), DOI 10.1109/ICECIE52348.2021.9664665
   Said Z, 2020, TRAIT SIGNAL, V37, P379, DOI 10.18280/ts.370304
   Salehi SSM, 2018, I S BIOMED IMAGING, P720, DOI 10.1109/ISBI.2018.8363675
   Sato M, 2007, IEEE T BIO-MED ENG, V54, P49, DOI 10.1109/TBME.2006.883791
   Shankar H, 2022, I S BIOMED IMAGING, DOI 10.1109/ISBI52829.2022.9761493
   Shi Xintong, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P1296, DOI 10.1109/EMBC48229.2022.9870908
   Singh R, 2023, MULTIMED TOOLS APPL, V82, P39669, DOI 10.1007/s11042-022-13534-3
   Taha L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123536
   Taha LY, 2020, CAN J ELECT COMPUT E, V43, P295, DOI 10.1109/CJECE.2020.2984602
   Tavoosi P, 2022, CIRC SYST SIGNAL PR, V41, P2027, DOI 10.1007/s00034-021-01870-y
   Wang X, 2022, IEEE T BIOMED CIRC S, V16, P1387, DOI 10.1109/TBCAS.2022.3217464
   Weisheng Gao, 2019, 2019 International Conference on Information Technology and Computer Application (ITCA). Proceedings, P211, DOI 10.1109/ITCA49981.2019.00053
   Xu L, 2023, INFORMATION, V14, DOI 10.3390/info14020112
   Yangyang Wang, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P466, DOI 10.1109/IMCEC.2018.8469501
   Zhao L, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P2593, DOI [10.1109/itnec48623.2020.9084658, 10.1109/ITNEC48623.2020.9084658]
   Ziani S, 2018, 2018 4 INT C OPTIMIZ, P1, DOI [10.1109/ICOA.2018.8370548, DOI 10.1109/ICOA.2018.8370548]
   Ziani S, 2020, Lecture notes in networks and systems, V81, DOI [10.1007/978-3-030-23672-4-26, DOI 10.1007/978-3-030-23672-4-26]
   Ziani S, 2023, An NMF based method for detecting RR interval. Big data and smart digital environment, P342, DOI [10.1007/978-3-030-12048-1-35, DOI 10.1007/978-3-030-12048-1-35]
   Ziani S, 2019, 2019 5 INT C OPTIMIZ, DOI [10.1109/ICOA.2019.8727619, DOI 10.1109/ICOA.2019.8727619]
   Ziani S, 2023, BIG DATA MIN ANAL, V6, P301, DOI 10.26599/BDMA.2022.9020035
   Ziani S, 2022, TRAIT SIGNAL, V39, P2055, DOI 10.18280/ts.390617
   Ziani S, 2018, PROCEDIA COMPUT SCI, V134, P322, DOI 10.1016/j.procs.2018.07.179
   Ziani S, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT 2017)
NR 45
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17165-0
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900004
DA 2024-07-18
ER

PT J
AU Dhanaraj, RK
   Ali, MA
   Sharma, AK
   Nayyar, A
AF Dhanaraj, Rajesh Kumar
   Ali, Md. Akkas
   Sharma, Anupam Kumar
   Nayyar, Anand
TI Deep Multibranch Fusion Residual Network and IoT-based pest detection
   system using sound analytics in large agricultural field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pest detection; Deep learning; DMF-ResNet; LPC; IoT; Sound analytics
ID LEARNING APPROACH; CLASSIFICATION; RECOGNITION; LOCALIZATION
AB In the modern era, agriculture is necessary for human existence globally, and it is imperative to work toward increasing agricultural yields. Yet, crop production may be affected due to the presence of pests, which can cause injury to crops or slow the growth of crops. As a result, pest detection and control in agriculture fields must begin immediately. Pest monitoring methods are labor-intensive, dangerous, and require a lot of physical labor. With the newest AI and IoT breakthroughs, specific upkeep jobs can be controlled automatically and radically, improving performance and reliability for pest detection in the agricultural field. This research offers a real-time remote pest detection strategy utilizing the IoT and DL architectures. The IoT and DMF-ResNet, part of the integrated pest detection approach, are the primary components that make up the architecture of the remote pest detection system. The DMF-ResNet pest detection technique is trained with the help of the sounds made by pests. The findings of this research offer new perspectives on the ambition of IoT and AI for pest monitoring in the field, and maintaining vigilance almost necessitates no active participation from a human being. The recommended DMF-ResNet system accurately automate the detection of agricultural pests based on results from experiments in large agricultural fields. It outscored the traditional works DenseNet, VGG-16, YOLOv5, DCNN, ANN, KNN, Faster RCNN, and ResNet-50 approaches for pest detection with 99.75% accuracy, 98.64% sensitivity, 98.48% specificity, 99.08% recall, 99.18% precision, and an F1 score of 99.11%.
C1 [Dhanaraj, Rajesh Kumar] Symbiosis Int Deemed Univ, Symbiosis Inst Comp Studies & Res, Pune, India.
   [Ali, Md. Akkas; Sharma, Anupam Kumar] Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
   [Ali, Md. Akkas] Bangabandhu Sheikh Mujibur Rahman Sci & Technol Un, Gopalganj, Bangladesh.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang, Vietnam.
C3 Symbiosis International University; Symbiosis Institute of Computer
   Studies & Research (SICSR); Galgotias University; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang, Vietnam.
EM sangeraje@gmail.com; akkas.gu@gmail.com;
   anupam.sharma@galgotiasuniversity.edu.in; anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015; Dhanaraj, Rajesh Kumar/AAQ-6545-2021
OI Nayyar, Anand/0000-0002-9821-6146; Dhanaraj, Rajesh
   Kumar/0000-0002-2038-7359
CR Ai Y, 2020, IEEE ACCESS, V8, P171686, DOI 10.1109/ACCESS.2020.3025325
   Albanese A, 2021, IEEE J EM SEL TOP C, V11, P458, DOI 10.1109/JETCAS.2021.3101740
   Amrani A, 2023, CROP PASTURE SCI, V74, P615, DOI 10.1071/CP21710
   Azfar S, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031851
   Bayrakdar ME, 2019, IEEE SENS J, V19, P10892, DOI 10.1109/JSEN.2019.2931816
   Butera L, 2022, IEEE-CAA J AUTOMATIC, V9, P246, DOI 10.1109/JAS.2021.1004317
   Lima MCF, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10050161
   Chen C, 2022, COMPUT ELECTRON AGR, V201, DOI 10.1016/j.compag.2022.107302
   Chen YS, 2020, IEEE ACCESS, V8, P92490, DOI 10.1109/ACCESS.2020.2992520
   Cheng ZY, 2024, Arxiv, DOI arXiv:2304.14614
   Cheng ZY, 2023, Arxiv, DOI arXiv:2301.13487
   Chodey MD, 2022, J PLANT DIS PROTECT, V129, P635, DOI 10.1007/s41348-022-00584-w
   Chu JY, 2023, AGRICULTURE-BASEL, V13, DOI 10.3390/agriculture13020364
   Cui Y., 2021, P IEEECVF INT C COMP, P8138
   data.nal.usda, About us
   Dewari S, 2023, LECT NOTE NETW SYST, V608, P287, DOI 10.1007/978-981-19-9225-4_22
   Doan T.N., 2022, International Journal of Advanced Computer Science and Applications, V13, DOI 10.14569/IJACSA.2022.0130605
   Domingues T, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12091350
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Feng FX, 2022, IEEE ACCESS, V10, P40888, DOI 10.1109/ACCESS.2022.3167397
   Gong H, 2023, AGRONOMY-BASEL, V13, DOI 10.3390/agronomy13020410
   Guo QW, 2023, PRECIS AGRIC, V24, P436, DOI 10.1007/s11119-022-09952-w
   Gutierrez A, 2019, J SENSORS, V2019, DOI 10.1155/2019/5219471
   Hadi MK, 2021, IEEE ACCESS, V9, P67391, DOI 10.1109/ACCESS.2021.3074083
   Hadipour-Rokni R, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106611
   Hanat Y, 2022, Int J Adv Vet Res Pract, V3
   Johnson JB, 2020, J STORED PROD RES, V86, DOI 10.1016/j.jspr.2019.101558
   Karar ME, 2022, ALEX ENG J, V61, P5309, DOI 10.1016/j.aej.2021.10.050
   Kasinathan Thenmozhi, 2021, [Information Processing in Agriculture, 农业信息处理], V8, P446
   Le-Qing Z., 2011, 2011 International Conference on Multimedia and Signal Processing, DOI [DOI 10.1109/CMSP.2011.100, 10.1109/CMSP.2011.100]
   Li JT, 2022, IEEE ACCESS, V10, P70269, DOI 10.1109/ACCESS.2022.3188282
   Li R, 2019, IEEE ACCESS, V7, P160274, DOI 10.1109/ACCESS.2019.2949852
   Li W, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12071065
   Li WY, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.915543
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Liu DF, 2023, IEEE T IMAGE PROCESS, V32, P2678, DOI 10.1109/TIP.2023.3272826
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu J, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00722-9
   Liu L, 2019, IEEE ACCESS, V7, P45301, DOI 10.1109/ACCESS.2019.2909522
   Lyu ZW, 2021, IEEE ACCESS, V9, P43202, DOI 10.1109/ACCESS.2021.3066510
   Mallick MT, 2023, MULTIMED TOOLS APPL, V82, P12017, DOI 10.1007/s11042-022-13673-7
   Mamdouh N, 2021, IEEE ACCESS, V9, P84252, DOI 10.1109/ACCESS.2021.3088075
   Mankin R, 2021, INSECTS, V12, DOI 10.3390/insects12030259
   Fernández RM, 2022, PLANT BIOTECHNOL J, V20, P25, DOI 10.1111/pbi.13685
   Mekha J, 2022, AUTOM CONTROL COMPUT, V56, P283, DOI 10.3103/S0146411622030038
   Pang HT, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17826-4
   Prasath B, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.105985
   Qian SW, 2023, SIGNAL IMAGE VIDEO P, V17, P563, DOI 10.1007/s11760-022-02261-9
   Qiang Z, 2022, J PLANT DIS PROTECT, V129, P533, DOI 10.1007/s41348-021-00562-8
   Ramalingam B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185280
   Rimal K, 2023, INT J ENVIRON SCI TE, V20, P4003, DOI 10.1007/s13762-022-04277-7
   Sangeetha T., 2022, Publ. Issue, V71, P1399
   Santiago RMC, 2017, TENCON IEEE REGION, P2542, DOI 10.1109/TENCON.2017.8228290
   Turkoglu M, 2022, SIGNAL IMAGE VIDEO P, V16, P301, DOI 10.1007/s11760-021-01909-2
   Ung HT, 2021, Arxiv, DOI arXiv:2107.12189
   Várkonyi DT, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118850
   Waheed H, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12060742
   Wang KL, 2022, ECOL INFORM, V69, DOI 10.1016/j.ecoinf.2022.101620
   Wang W., 2022, Adv. Neural Inf. Process. Syst., V35, P12826
   Yazgac BG, 2016, 2016 5 INT C AGR AGR, P1
   Zhu DJ, 2023, INTERNET THINGS-NETH, V21, DOI 10.1016/j.iot.2022.100649
NR 63
TC 1
Z9 1
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 4
PY 2023
DI 10.1007/s11042-023-16897-3
EA OCT 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4GC2
UT WOS:001077578000003
DA 2024-07-18
ER

PT J
AU Maheswari, SU
   Dhenakaran, SS
AF Maheswari, S. Uma
   Dhenakaran, S. S.
TI Improved ensemble based deep learning approach for sarcastic opinion
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sarcastic sentiment; Natural Language Processing; Bi-LSTM;
   Agglomerative; TF-IDF; Hybrid model
ID IDENTIFICATION; SENTIMENT; TWEETS
AB Sarcastic tweets or reviews confuse the public those who interested to buy the products from online and prior know about the customer's opinion about the products. E-Commerce business people also come across this problem to understand the customer's sarcastic opinion. To remove this problem and to help the online customers also to help the business people to know the customer's opinion is sarcastic or non sarcastic this research work carried out identify the sarcastic opinion. In many existing methods for detecting sarcastic statements commonly followed the part of speech (POS) -Tag, N-Gram methods for extract the features, as well as represented the features by Term Frequency-Inverse Document Frequency (TF-IDF) and binary methods, and for feature selection utilized chi squared, information gain methods. Other than the above mentioned methods authors didn't use the features such as Likes count, ReTweet count, Replies count from Tweets. Outlier from the features can be identified and detected; typically the outlier removed features will provide the best performance. Not but least, many researchers followed imbalanced dataset for sarcastic detection. These limitations are identified by this proposed work. The novelty of this proposed work is followed the hybrid techniques such as agglomerative clustering method for outlier detection, and outlier removed dataset fed as input to stacked auto encoder (SAE), finally classification and prediction completed by Ensemble of Logistic Regression, Random forest and Bi-Directional Long Short Term Memory(Bi-LSTM). Existing work doesn't follow the outlier removal method with Deep Learning (DL) method for sarcastic opinion detection. The proposed work is completed with aid of Natural Language Processing (NLP), Python Libraries and Tweets about E-Commerce Amazon products. Proposed model obtained 99.3% accuracy in sarcasm prediction, this outperforming existing sarcasm detection algorithm. This result suggests that the proposed model was successful in detecting and analyzing sarcastic sentiment.
C1 [Maheswari, S. Uma; Dhenakaran, S. S.] Alagappa Univ, Dept Comp Sci, Karaikkudi, Tamil Nadu, India.
C3 Alagappa University
RP Maheswari, SU (corresponding author), Alagappa Univ, Dept Comp Sci, Karaikkudi, Tamil Nadu, India.
EM 17umeshrani@gmail.com; ssdarvind@yahoo.com
OI Maheswari, S Uma/0000-0001-7650-2240
CR Abarna S., 2022, Meas.: Sens, V24, P100434
   Ahmed K, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122312380
   Ahuja R, 2018, PROCEDIA COMPUT SCI, V143, P411, DOI 10.1016/j.procs.2018.10.412
   Alita S. Priyanta, 2019, J. Inf.Syst. Eng. Bus. Intell., V5, P100
   Amelio A, 2022, APPL SOFT COMPUT, V130, DOI 10.1016/j.asoc.2022.109687
   Banerjee A, 2020, MULTIMED TOOLS APPL, V79, P35995, DOI 10.1007/s11042-020-09138-4
   Banfield SR, 2006, COMMUN EDUC, V55, P63, DOI 10.1080/03634520500343400
   Bark O., 2017, DEEP LEARNING APPROA
   Bharti SK, 2016, DIGIT COMMUN NETW, V2, P108, DOI 10.1016/j.dcan.2016.06.002
   Burstein J, 2019, P 2019 C N AM CHAPT, V1
   Chawla V, 2023, MULTIMED TOOLS APPL, V82, P30831, DOI 10.1007/s11042-023-14730-5
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dharwal P, 2017, PROCEEDINGS OF THE 2017 3RD INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P29, DOI 10.1109/ICATCCT.2017.8389102
   Ding N, 2022, MULTIMED TOOLS APPL, V81, P8597, DOI 10.1007/s11042-022-12122-9
   Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z
   Du Y, 2022, Cognit Comput, P1
   Eke CI, 2019, IEEE ACCESS, V7, P144907, DOI 10.1109/ACCESS.2019.2944243
   Eke CI, 2020, ARTIF INTELL REV, V53, P4215, DOI 10.1007/s10462-019-09791-8
   Goel P, 2022, MULTIMED TOOLS APPL, V81, P43229, DOI 10.1007/s11042-022-12930-z
   Hiai S, 2019, INT J DATA WAREHOUS, V15, P66, DOI 10.4018/IJDWM.2019100104
   Jain D, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106198
   Kandasamy V, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227582
   Karthik E, 2022, J SUPERCOMPUT, V78, P5333, DOI 10.1007/s11227-021-04028-4
   Kumar A, 2020, IEEE ACCESS, V8, P6388, DOI 10.1109/ACCESS.2019.2963630
   Kumar HMK, 2018, PROCEDIA COMPUT SCI, V143, P378, DOI 10.1016/j.procs.2018.10.409
   Son LH, 2019, IEEE ACCESS, V7, P23319, DOI 10.1109/ACCESS.2019.2899260
   Mahendran S, 2019, INT J AMBIENT ENERGY, DOI 10.1080/01430750.2019.1662841
   Majumder N, 2019, IEEE INTELL SYST, V34, P38, DOI 10.1109/MIS.2019.2904691
   Manohar MY, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P618, DOI 10.1109/ICCONS.2017.8250536
   Mehndiratta P, 2019, J DATA INFO SCI, V4, P56, DOI 10.2478/jdis-2019-0021
   Mehndiratta P, 2017, SCALABLE COMPUT-PRAC, V18, P219, DOI 10.12694/scpe.v18i3.1302
   Naz F, 2019, J INTELL FUZZY SYST, V37, P6815, DOI 10.3233/JIFS-190596
   Pandey Avinash Chandra, 2019, Advances in Signal Processing and Communication. Select Proceedings of ICSC 2018. Lecture Notes in Electrical Engineering (LNEE 526), P559, DOI 10.1007/978-981-13-2553-3_54
   Pandey R, 2023, J INTELL INF SYST, V60, P235, DOI 10.1007/s10844-022-00755-z
   Pandey R, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107348
   Potamias RA, 2020, NEURAL COMPUT APPL, V32, P17309, DOI 10.1007/s00521-020-05102-3
   Prasanna MSM, 2023, MULTIMED TOOLS APPL, V82, P32789, DOI 10.1007/s11042-023-14909-w
   Prasanna MSM, 2021, MULTIMED TOOLS APPL, V80, P20151, DOI 10.1007/s11042-020-10422-6
   Rajadesingan A, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P97, DOI 10.1145/2684822.2685316
   Ray P, 2017, 2017 1ST IEEE INTERNATIONAL CONFERENCE ON DATA MANAGEMENT, ANALYTICS AND INNOVATION (ICDMAI), P211, DOI 10.1109/ICDMAI.2017.8073512
   Ren L, 2020, NEUROCOMPUTING, V401, P320, DOI 10.1016/j.neucom.2020.03.081
   Saha S., 2017, INDIAN J SCI TECHNOL, V10, P1, DOI [DOI 10.17485/ijst/2017/v10i25/114443, 10.17485/ijst/2017/v10i25/114443]
   Samonte MJC, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON INDUSTRIAL AND BUSINESS ENGINEERING (ICIBE 2018), P181, DOI 10.1145/3288155.3288172
   Schifanella R., 2016, P 24 ACM INT C MULT, P1136
   Shrawankar Urmila, 2019, International Journal of Technology Diffusion, V10, P1, DOI 10.4018/IJTD.2019070101
   Suhaimin Mohd Suhairi Md, 2019, TELKOMNIKA Indonesian Journal of Electrical Engineering, V13, P1175
   Sundararajan K, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/2860479
   Tan YY, 2023, WIRELESS PERS COMMUN, V129, P2213, DOI 10.1007/s11277-023-10235-4
   Tarigan J, 2018, Int J Adv Comput Res, V8, P354, DOI [10.19101/IJACR.2018.839002, DOI 10.19101/IJACR.2018.839002]
   TUNGTHAMTHITI P., 2014, Proceedings of the 28th Pacific Asia conference on language, information and computing, P404
   Vinoth D, 2022, J SUPERCOMPUT, V78, P10575, DOI 10.1007/s11227-022-04312-x
   Yavanoglu U, 2018, INT J SEMANT COMPUT, V12, P457, DOI 10.1142/S1793351X18300017
   Zia T., 2016, P 52 IRES INT C KUAL, P27
NR 53
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 4
PY 2023
DI 10.1007/s11042-023-16891-9
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4GC2
UT WOS:001077578000004
DA 2024-07-18
ER

PT J
AU Duan, SH
   Qian, YH
   Liu, JJ
   Wang, HW
   Zhou, XY
AF Duan, Shaohua
   Qian, Yuhan
   Liu, Junjie
   Wang, Hanwen
   Zhou, Xiaoyi
TI Reversible robust fragile multi-watermarking scheme for color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible multi-watermarking; Integer wavelet transform; Differential
   histogram shift; Prediction error length map; Tamper detection map
   correction
ID AUTHENTICATION; FRAMEWORK
AB This research introduced a reversible multi-watermarking scheme for color images with robustness and fragility. The robust watermarking can be used for copyright protection while the fragile watermarking is used to decide whether the image is tampered. The scheme divides the color image into R, G and B layers. The first two layers are embedded with a robust watermark via integer wavelet transform (IWT) and differential histogram shift. Then the embedded layers are used to generate a hash sequence as a fragile watermark. Layer B is used to embed fragile watermark. In order to enhance the watermark invisibility, the prediction error extension (PEE) algorithm is optimized by prediction error length mapping (PELM). To improve the extraction accuracy for tamper detection, a mapping correction scheme is proposed. The performance of the proposed scheme is evaluated using Kodak and USC-ISUI data set. Experimental results show that the proposed scheme has balanced imperceptibility and robustness, and also achieved reversibility and high detection rate. Specifically, the peak signal-to-noise ratio(PSNR) which is used to verify the imperceptibility of the watermarked image is 43.234db. The average normalized correlation coefficient (NC) of the extracted watermark is greater than 0.91, even it suffers from common attacks such as JPEG, noise attack and filter attack. And the accuracy of tamper detection is higher than 90% under malicious attacks.
C1 [Duan, Shaohua; Qian, Yuhan; Liu, Junjie; Wang, Hanwen; Zhou, Xiaoyi] Hainan Univ, Haikou, Hainan, Peoples R China.
C3 Hainan University
RP Zhou, XY (corresponding author), Hainan Univ, Haikou, Hainan, Peoples R China.
EM smartjack10101@gmail.com; qianyuhan077@gmail.com;
   liujunjie10055@gmail.com; asd781263509@gmail.com; xy.zhou.xy@gmail.com
OI Duan, Shaohua/0000-0002-1847-3864; , xiaoyi/0000-0003-3777-9479
FU Hainan Province Basic, Applied Basic Research Program (Natural Science
   Field) High-level Talent Project [2019RC044]; Hainan Province Key RD
   plan project [ZDYF2022GXJS224]
FX The research was supported by Hainan Province Basic, Applied Basic
   Research Program (Natural Science Field) High-level Talent Project
   (Grant No. 2019RC044) and Hainan Province Key R&D plan project(No.
   ZDYF2022GXJS224).
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Ansari IA, 2017, MULTIMED TOOLS APPL, V76, P18001, DOI 10.1007/s11042-016-3680-z
   Darwish SM, 2021, J EXP THEOR ARTIF IN, V33, P945, DOI 10.1080/0952813X.2020.1801853
   Duan SH, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8840779
   Fan GJ, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107888
   Girdhar A, 2019, J AMB INTEL HUM COMP, V10, P4947, DOI 10.1007/s12652-019-01179-4
   Hassan FS, 2021, ARAB J SCI ENG, V46, P8441, DOI 10.1007/s13369-021-05529-3
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Kaw JA, 2019, INT J INFORM MANAGE, V45, P262, DOI 10.1016/j.ijinfomgt.2018.09.008
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P7339, DOI 10.1007/s11042-019-08314-5
   Kumar R, 2020, INFORM SCIENCES, V512, P96, DOI 10.1016/j.ins.2019.09.062
   Lee CF, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS), P56, DOI 10.1109/CCOMS.2018.8463244
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liang XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107584
   Meng LZ, 2021, MULTIMED TOOLS APPL, V80, P711, DOI 10.1007/s11042-020-09686-9
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Parah SA, 2020, FUTURE GENER COMP SY, V108, P935, DOI 10.1016/j.future.2018.02.023
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Roy Soumitra, 2018, International Journal of Information and Computer Security, V10, P216
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Valandar MY, 2020, SOFT COMPUT, V24, P771, DOI 10.1007/s00500-019-04524-z
   Wang H, 2021, INT C ART INT SEC, P312
   Wang WQ, 2020, MULTIMED TOOLS APPL, V79, P5965, DOI 10.1007/s11042-019-08255-z
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   Yue Z, 2019, ACM Trans Internet Technol, V37, P1
   Zhang J, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/7817809
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhang ZW, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0450-7
   Zhou K, 2021, MULTIMED TOOLS APPL, V80, P1123, DOI 10.1007/s11042-020-09374-8
   Zhou XY, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091024
   Zhou XY, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/2685739
NR 36
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38613
EP 38637
DI 10.1007/s11042-023-14717-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LE2S3
UT WOS:001185044500001
DA 2024-07-18
ER

PT J
AU Kumar, P
   Kumar, R
AF Kumar, Pardeep
   Kumar, Raghavendra
TI A hybrid framework for time series trends: embedding social network's
   sentiments and optimized stacked LSTM using evolutionary algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Time series forecasting; Stock trends; Sentiment polarity; Stacked LSTM
ID SHORT-TERM-MEMORY; DIFFERENTIAL EVOLUTION; STOCK-PRICE; MODE
   DECOMPOSITION; NEURAL-NETWORK; PREDICTION; MACHINE
AB Stipulated time intervals and stochastic behavior in data patterns make the stock market a best fit use case for time series analysis. Embedding social network's sentiments and the historical price of the stock market is the major challenge due to the temporal relationship and stock behavior. The objective of this paper is to propose a deep learning-based hybrid framework based on Differential Evolution (DE) algorithm and Stacked-Long Short Term Memory (S-LSTM) that imposes the market sentiments for future prediction. As an original contribution, hyperparameters of stacked LSTM units are optimized with DE algorithm and the obtained result of the hybrid framework is validated with Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) algorithm. For the experiments, Apple Inc. indices of NASDAQ GS, Nikkei 225 index (N225) listed in the Tokyo Stock Exchange (TSE), Dow Jones Industrial Average index (DJIA) and S&P 500 index are identified as reported datasets. Result analysis proves that sentiment polarity plays a significant role in DE optimized stacked LSTM and obtains improved forecasting accuracy in the form of Mean Absolute Percentage Error (MAPE) and Mean Absolute Error (MAE) as 5.43% and 9.14%, respectively. As other insights, the proposed model DE-S-LSTM improves the mean MAPE, MAE and RMSE for the selected four stock indexes as 29.10%, 28.86% and 23.28%, respectively.
C1 [Kumar, Pardeep] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Waknaghat, India.
   [Kumar, Raghavendra] AdGlobal360 India Pvt Ltd, Gurugram, India.
C3 Jaypee University of Information Technology
RP Kumar, P (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Waknaghat, India.
EM pardeepkumarkhokhar@gmail.com; raghavendra.dwivedi@gmail.com
OI Kumar, Pardeep/0000-0001-5303-7219
CR Bisoi R, 2019, APPL SOFT COMPUT, V74, P652, DOI 10.1016/j.asoc.2018.11.008
   Chung H, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103765
   Dwivedi RK, 2019, LECT NOTE NETW SYST, V56, P57, DOI 10.1007/978-981-13-2354-6_7
   Fischer T, 2018, EUR J OPER RES, V270, P654, DOI 10.1016/j.ejor.2017.11.054
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Ghimire S, 2022, ENG APPL ARTIF INTEL, V112, DOI 10.1016/j.engappai.2022.104860
   Göçken M, 2019, NEURAL COMPUT APPL, V31, P577, DOI 10.1007/s00521-017-3089-2
   Göçken M, 2016, EXPERT SYST APPL, V44, P320, DOI 10.1016/j.eswa.2015.09.029
   Guresen E, 2011, EXPERT SYST APPL, V38, P10389, DOI 10.1016/j.eswa.2011.02.068
   Hiransha M., 2018, Procedia Computer Science, V132, P1351, DOI 10.1016/j.procs.2018.05.050
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoseinzade E, 2019, EXPERT SYST APPL, V129, P273, DOI 10.1016/j.eswa.2019.03.029
   Hossain E, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117706
   Jin ZG, 2020, NEURAL COMPUT APPL, V32, P9713, DOI 10.1007/s00521-019-04504-2
   Khan W, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01839-w
   Kosana V, 2022, NEURAL COMPUT APPL, V34, P12653, DOI 10.1007/s00521-022-07125-4
   Kumar Raghavendra, 2022, International Journal of Information Technology, V14, P359, DOI 10.1007/s41870-021-00741-8
   Kumar R, 2022, NEURAL COMPUT APPL, V34, P18421, DOI 10.1007/s00521-022-07431-x
   Kumar R, 2021, INT J GRID UTIL COMP, V12, P573, DOI 10.1504/IJGUC.2021.120120
   Kumar R, 2022, MULTIMED TOOLS APPL, V81, P34595, DOI 10.1007/s11042-021-11029-1
   Kumar R, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P877, DOI 10.1109/Confluence51648.2021.9377158
   Kumar R, 2020, PROCEDIA COMPUT SCI, V167, P373, DOI 10.1016/j.procs.2020.03.240
   Peng L, 2018, ENERGY, V162, P1301, DOI 10.1016/j.energy.2018.05.052
   Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706
   Qin Y, 2017, Arxiv, DOI [arXiv:1704.02971, DOI 10.48550/ARXIV.1704.02971]
   Ruan YF, 2018, KNOWL-BASED SYST, V145, P207, DOI 10.1016/j.knosys.2018.01.016
   Schumaker RP, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1462198.1462204
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P18569, DOI 10.1007/s11042-016-4159-7
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Wang L, 2015, EXPERT SYST APPL, V42, P855, DOI 10.1016/j.eswa.2014.08.018
   Wang ZJ, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S021812662150122X
   Wang ZJ, 2021, SOFTWARE PRACT EXPER, V51, P2290, DOI 10.1002/spe.2940
   Yang FM, 2019, APPL SOFT COMPUT, V80, P820, DOI 10.1016/j.asoc.2019.03.028
   Zhang X, 2018, KNOWL-BASED SYST, V143, P236, DOI 10.1016/j.knosys.2017.12.025
   Zhou F, 2019, EXPERT SYST APPL, V115, P136, DOI 10.1016/j.eswa.2018.07.065
NR 37
TC 0
Z9 0
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16997-0
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000021
DA 2024-07-18
ER

PT J
AU Swaroop, CR
   Raja, K
AF Swaroop, Chigurupati Ravi
   Raja, K.
TI Sequential data analysis and outlier prediction using hybrid seagull
   optimized neural network and extreme value analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outlier; Extreme value theory; Convolutional neural networks; Prediction
   policies; Data points
ID FEATURE-EXTRACTION; MODEL
AB With the rapid development of deep learning approaches, outlier detection is essential and used in a variety of applications. It is challenging to predict the boundaries from the original and abnormal regions due to the unlabelled dataset. Complexity also arises with the noise identified in real-time data and the tendency of the newer data included in the dataset. These challenges are resolved with a novel approach hybrid seagull optimized Convolutional Neural Network with Extreme Value Theory (CNN-EVT), by measuring the deviation of the dataset from the original distribution. The deviation and the probability of extreme values are estimated for the uni-variate data streams and peak threshold. The proposed approach is simulated in a MATLAB environment and evaluated with the performance metrics such as prediction accuracy, specificity, sensitivity, G-mean, Matthews correlation coefficient (MCC), Mean Square Error (MSE) and K-2 is evaluated. Using the proposed approach increases the accuracy by 95.6% with a mean square error of 0.049. The proposed approach is compared with the existing state of the approaches. The comparison results show that the proposed approach outperforms the existing approaches in terms of performance metrics.
C1 [Swaroop, Chigurupati Ravi; Raja, K.] Annamalai Univ, FEAT, Dept Informat Technol, Chidambaram 608001, Tamil Nadu, India.
C3 Annamalai University
RP Swaroop, CR (corresponding author), Annamalai Univ, FEAT, Dept Informat Technol, Chidambaram 608001, Tamil Nadu, India.
EM raviswaroop.chigurupati@gmail.com; rajakapit@gmail.com
OI Ravi Swaroop, Chigurupati/0000-0003-0547-9033
CR Alghushairy O, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5010001
   Belhadi A, 2021, INFORM FUSION, V65, P13, DOI 10.1016/j.inffus.2020.08.003
   Bhatti MA, 2020, J COMMUN NETW-S KOR, V22, P236
   Bull LA, 2019, J SOUND VIB, V453, P126, DOI 10.1016/j.jsv.2019.03.025
   Cabana E, 2021, STAT PAP, V62, P1583, DOI 10.1007/s00362-019-01148-1
   Chakraborty D, 2019, PATTERN RECOGN, V89, P161, DOI 10.1016/j.patcog.2019.01.002
   Danda S, 2020, IEEE INT CONF BIG DA, P5655, DOI 10.1109/BigData50022.2020.9378046
   Dhiman G, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114150
   Djenouri Y, 2019, IEEE ACCESS, V7, P10015, DOI 10.1109/ACCESS.2019.2891933
   Dong JX, 2021, IEEE T IMAGE PROCESS, V30, P1799, DOI 10.1109/TIP.2020.3048679
   Dzyubak B, 2021, J MAGN RESON IMAGING, V54, P122, DOI 10.1002/jmri.27549
   Gao W, 2020, BRAIN BEHAV, V10, DOI 10.1002/brb3.1846
   Gu JA, 2022, IEEE T DEPEND SECURE, V19, P3686, DOI 10.1109/TDSC.2021.3104900
   Hamedpour V, 2020, SENSOR ACTUAT B-CHEM, V322, DOI 10.1016/j.snb.2020.128571
   Hashmi AS, 2022, J KING SAUD UNIV-COM, V34, P1768, DOI 10.1016/j.jksuci.2019.09.007
   Holmes EJ, 2021, N AM J FISH MANAGE, V41, P446, DOI 10.1002/nafm.10533
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Izonin I, 2021, ENG SCI TECHNOL, V24, P749, DOI 10.1016/j.jestch.2020.10.005
   Izonin I, 2019, PROCEDIA COMPUT SCI, V160, P578, DOI 10.1016/j.procs.2019.11.044
   Jian SL, 2019, IEEE T KNOWL DATA EN, V31, P853, DOI 10.1109/TKDE.2018.2848902
   Kandanaarachchi S, 2020, DATA MIN KNOWL DISC, V34, P309, DOI 10.1007/s10618-019-00661-z
   Kim CM, 2021, IEEE ACCESS, V9, P86096, DOI 10.1109/ACCESS.2021.3086103
   Moustafa N, 2019, IEEE T INF FOREN SEC, V14, P1975, DOI 10.1109/TIFS.2018.2890808
   Papadopoulos AA, 2021, NEUROCOMPUTING, V441, P138, DOI 10.1016/j.neucom.2021.02.007
   Ranjan KG, 2021, INT J NUMER MODEL EL, V34, DOI 10.1002/jnm.2816
   Singh Gurpinder, 2022, Intelligent Computing Techniques for Smart Energy Systems: Proceedings of ICTSES 2021. Lecture Notes in Electrical Engineering (862), P609, DOI 10.1007/978-981-19-0252-9_55
   Souza JFL, 2020, IEEE ACCESS, V8, P120447, DOI 10.1109/ACCESS.2020.3005916
   Tian L, 2020, SCRIPTA MATER, V186, P185, DOI 10.1016/j.scriptamat.2020.05.038
   Tkachenko R., 2021, Int. J. Sensor. Wireless Commun. Control, V11, P531, DOI [10.2174/2210327910999200813151904, DOI 10.2174/2210327910999200813151904]
   Wang B, 2019, INFORM FUSION, V51, P244, DOI 10.1016/j.inffus.2019.02.006
   Yang P, 2019, IEEE ACCESS, V7, P115914, DOI 10.1109/ACCESS.2019.2922004
   Yen C-H, 2023, IEEE T COMPUT AIDED
   Zhao YM, 2021, IEEE ROBOT AUTOM LET, V6, P4457, DOI 10.1109/LRA.2021.3068885
NR 33
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32873
EP 32893
AR s11042-023-16749-0
DI 10.1007/s11042-023-16749-0
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070523100002
DA 2024-07-18
ER

PT J
AU Sharma, BK
   Kumar, M
   Meena, RS
AF Sharma, Bhuvnesh Kumar
   Kumar, Mithilesh
   Meena, R. S.
TI Development of a speech separation system using frequency domain blind
   source separation technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Teleconferencing; Frequency domain blind source separation technique;
   Frequency domain analysis; Speech signal
ID LEARNING APPROACH; SOUND SOURCES; LOCALIZATION; TRACKING
AB Professionals can interact while communicating remotely with teleconferencing. It enables communication between users using computers, smartphones, tablets, and other virtual devices. Even though researchers are adopting a variety of blind source techniques to separate and recognize speech, the problem and the greatest difficulty still lie in assuming that communication comes from multiple speakers. The process of extracting target speech from background noise is known as speech separation. In this research, a speech separation system using the frequency domain Blind source separation technique (BSS technique) is used for the separation of the original speech signals from the user. Frequency domain analysis is used for the comprehensive analysis of the signal properties and along with that the frequency range of the signals in the room is also determined. Determining the frequential spectra of the sources included in a sound recording as well as their temporal activations helps in improving the speech signal of the user. Blind source techniques help in retrieving the original sound by eliminating external noises and selecting the best frequency signal. The total impulse response of the system is evaluated The speech signals along with the Room Impulse Response, magnitude, and Phasor plot are graphically represented for the efficient analysis of the system.
C1 [Sharma, Bhuvnesh Kumar] Govt Engn Coll Jhalawar, Dept Elect & Commun Engn, Jhalrapatan, Rajasthan, India.
   [Kumar, Mithilesh; Meena, R. S.] Rajasthan Tech Univ Kota, Dept Elect Engn, Kota 324010, Rajasthan, India.
C3 Rajasthan Technical University
RP Sharma, BK (corresponding author), Govt Engn Coll Jhalawar, Dept Elect & Commun Engn, Jhalrapatan, Rajasthan, India.
EM bk_knowledge@yahoo.com; mkumar@rtu.ac.in; rsmeena@rtu.ac.in
RI Sharma, Bhuvanesh Kumar/AAH-9697-2021
OI Sharma, Bhuvanesh Kumar/0000-0002-8133-6758
CR Berouti M., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P208
   Chen M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156858
   Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544
   Doblinger G., 1995, P EUR, P1513
   Duangpummet S, 2022, APPL ACOUST, V185, DOI 10.1016/j.apacoust.2021.108372
   Foy C, 2021, J ACOUST SOC AM, V150, P1286, DOI 10.1121/10.0005888
   Hold C, 2022, J AUDIO ENG SOC, V70, P526, DOI 10.17743/jaes.2022.0017
   Hsu YC, 2023, Arxiv, DOI arXiv:2303.06867
   KLEINER M, 1993, J AUDIO ENG SOC, V41, P861
   Ko T, 2017, INT CONF ACOUST SPEE, P5220, DOI 10.1109/ICASSP.2017.7953152
   Kondoz AM., 2004, Digital Speech: Coding for Low Bite Rate Communication Systems, V2, DOI [10.1002/0470870109, DOI 10.1002/0470870109]
   Kothapally V, 2023, ICASSP 2023 2023 IEE, P1
   Kovalyov A, 2023, IEEE ACCESS, V11, P4350, DOI [10.1109/access.2023.3235948, 10.1109/ACCESS.2023.3235948]
   Li GA, 2023, IEEE-ACM T AUDIO SPE, V31, P2707, DOI 10.1109/TASLP.2023.3294705
   Loizou P. C., 2007, Speech Enhancement: Theory and Practice
   Mi H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12062823
   Rabiner L, 1997, PROC IEEE INT CONF A, P323
   Ratnarajah A, 2022, INT CONF ACOUST SPEE, P571, DOI 10.1109/ICASSP43922.2022.9747846
   Ratnarajah A, 2021, 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P259, DOI 10.1109/ASRU51503.2021.9688304
   Richey C, 2018, INTERSPEECH, P1566, DOI 10.21437/Interspeech.2018-1454
   Scherer SA, 2012, IEEE INT CONF ROBOT, P5216, DOI 10.1109/ICRA.2012.6224864
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100
   Su JQ, 2020, INT CONF ACOUST SPEE, P426, DOI [10.1109/ICASSP40776.2020.9054701, 10.1109/icassp40776.2020.9054701]
   Szöke I, 2019, IEEE J-STSP, V13, P863, DOI 10.1109/JSTSP.2019.2917582
   Vary P., 2006, Digital speech transmission: enhancement, coding and error concealment, DOI [10.1002/0470031743, DOI 10.1002/0470031743]
   Zhao JH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042061
NR 26
TC 0
Z9 0
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32857
EP 32872
DI 10.1007/s11042-023-16600-6
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100012
DA 2024-07-18
ER

PT J
AU Bybordi, A
   Thampan, T
   Linhares, CDG
   Ponciano, JR
   Travençolo, BAN
   Paiva, JGS
   Etemadpour, R
AF Bybordi, Arezoo
   Thampan, Terri
   Linhares, Claudio D. G.
   Ponciano, Jean R.
   Travencolo, Bruno A. N.
   Paiva, Jose Gustavo S.
   Etemadpour, Ronak
TI Canonical correlation and visual analytics for water resources analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Canonical correlation; Visual analytics; Temporal graphs; Water
   resources; Water stations
ID MULTISTAGE ATTENTION-GAN; BRAIN; SEGMENTATION
AB In the last decades, urbanization and population growth substantially increased water consumption for agricultural, industrial, and residential purposes. Characterizing the interplay between environmental variables and water resources plays a critical role in establishing effective water management policies. In this paper, we apply Canonical Correlation Analysis (CCA) in a set of climate and hydrological indicators to investigate the behavior of these environmental variables over time in different geographical regions of California, as well as the relationship among these regions. CCA served as a base to establish a temporal graph that models the relationship between the stations over time, and advanced graph visualization techniques are used to produce patterns that aid in the comprehension of the underlying phenomena. Our results identified important temporal patterns, such as heterogeneous behavior in the dry season and lower correlation between the stations in La Nina years. We show that the combination of CCA and visual analytics can assist water experts in identifying important climate and hydrological events in different scenarios.
C1 [Bybordi, Arezoo; Thampan, Terri; Etemadpour, Ronak] CUNY, Grad Ctr, New York, NY 10016 USA.
   [Linhares, Claudio D. G.; Ponciano, Jean R.] Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, SP, Brazil.
   [Travencolo, Bruno A. N.; Paiva, Jose Gustavo S.] Univ Fed Uberlandia, Fac Comp Sci, Uberlandia, MG, Brazil.
   [Etemadpour, Ronak] Univ New Mexico, Dept Radiol Hlth & Sci, Albuquerque, NM 87131 USA.
C3 City University of New York (CUNY) System; Universidade de Sao Paulo;
   Universidade Federal de Uberlandia; University of New Mexico
RP Etemadpour, R (corresponding author), CUNY, Grad Ctr, New York, NY 10016 USA.; Travençolo, BAN (corresponding author), Univ Fed Uberlandia, Fac Comp Sci, Uberlandia, MG, Brazil.; Etemadpour, R (corresponding author), Univ New Mexico, Dept Radiol Hlth & Sci, Albuquerque, NM 87131 USA.
EM a.bybordi@gmail.com; territhampan@gmail.com; claudiodgl@gmail.com;
   jeanrobertop@gmail.com; travencolo@gmail.com; gustavo@ufu.br;
   retemadpour@ccny.cuny.edu
RI Travençolo, Bruno/F-6752-2010; Linhares, Claudio/AAJ-8869-2021
OI Travençolo, Bruno/0000-0001-7690-301X; Ponciano, Jean
   Roberto/0000-0003-4629-3542; Linhares, Claudio/0000-0001-7012-4461
FU We express our sincere gratitude to Dr. Indrani Pal at the CUNY Remote
   Sensing Earth System Institute (CREST Institute) for their invaluable
   contributions to the development of this paper. Dr. Pal's expertise and
   insights were instrumental in normalizing t
FX We express our sincere gratitude to Dr. Indrani Pal at the CUNY Remote
   Sensing Earth System Institute (CREST Institute) for their invaluable
   contributions to the development of this paper. Dr. Pal's expertise and
   insights were instrumental in normalizing the data, and we are grateful
   for her guidance. We also extend our thanks to the other members of her
   research team for their valuable ideas and assistance throughout the
   project.
CR Abatzoglou J, 2017, Climatology lab
   Agarwal A, 2020, HYDROL EARTH SYST SC, V24, P2235, DOI 10.5194/hess-24-2235-2020
   AghaKouchak A, 2015, NATURE, V524, P409, DOI 10.1038/524409a
   AghaKouchak A, 2014, GEOPHYS RES LETT, V41, P8847, DOI 10.1002/2014GL062308
   Alipour MH, 2019, HYDROLOG SCI J, V64, P1038, DOI 10.1080/02626667.2019.1626991
   Allan JC, 2002, J COASTAL RES, V18, P175
   Bartlett MS, 1938, P CAMB PHILOS SOC, V34, P33, DOI 10.1017/S0305004100019897
   Bekchanov M, 2017, J WATER RES PLAN MAN, V143, DOI 10.1061/(ASCE)WR.1943-5452.0000793
   Bilenko NY, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00049
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Braga AC, 2016, PHYSICA A, V444, P1003, DOI 10.1016/j.physa.2015.10.102
   Bureau USC, 2021, 2020 Census apportionment results
   California Water Data Maintainer, 2021, USGS Current Water Data for California
   Chang FJ, 2015, J ENVIRON MANAGE, V151, P87, DOI 10.1016/j.jenvman.2014.12.014
   DeCicco LA, 2016, Data retrieval R package USGS
   Desai S, 2021, J HYDROL, V594, DOI 10.1016/j.jhydrol.2020.125861
   Falcone J.A., 2011, GAGES 2 GEOSPATIAL A, DOI DOI 10.3133/70046617
   Fang KR, 2017, J HYDROL, V545, P478, DOI 10.1016/j.jhydrol.2016.11.056
   Forootan E, 2019, SCI TOTAL ENVIRON, V650, P2587, DOI 10.1016/j.scitotenv.2018.09.231
   Halverson MJ, 2015, HYDROL EARTH SYST SC, V19, P3301, DOI 10.5194/hess-19-3301-2015
   Han XD, 2018, GEOSCI LETT, V5, DOI 10.1186/s40562-018-0109-8
   Jung K, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10110695
   Kamienski C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020276
   Kapnick S, 2010, J CLIMATE, V23, P3446, DOI 10.1175/2010JCLI2903.1
   Kasiviswanathan KS, 2016, MODEL EARTH SYST ENV, V2, DOI 10.1007/s40808-016-0079-9
   Li X, 2018, J HYDROINFORM, V20, P191, DOI 10.2166/hydro.2017.189
   Linhares C. D. G., 2017, P S APPL COMP SAC 17, P187, DOI [DOI 10.1145/3019612.3019686, 10.1145/3019612.3019686]
   Linhares CDG, 2020, PR I-A I C AD S N A, P933, DOI 10.1109/ASONAM49781.2020.9381304
   Linhares CDG, 2019, COMPUT GRAPH-UK, V84, P185, DOI 10.1016/j.cag.2019.08.006
   Lund NSV, 2018, CRIT REV ENV SCI TEC, V48, P279, DOI 10.1080/10643389.2018.1455484
   Meng EH, 2019, J HYDROL, V568, P462, DOI 10.1016/j.jhydrol.2018.11.015
   Null J., 2018, El Nino and La Nina years and intensities based on Oceanic Nino index (ONI)
   Oo HT, 2020, CIV ENG J-TEHRAN, V6, P194, DOI 10.28991/cej-2020-03091464
   Ouali D, 2016, STOCH ENV RES RISK A, V30, P449, DOI 10.1007/s00477-015-1092-7
   Ouarda TBMJ, 2008, J HYDROL, V348, P40, DOI 10.1016/j.jhydrol.2007.09.031
   Ouarda TBMJ, 2001, J HYDROL, V254, P157, DOI 10.1016/S0022-1694(01)00488-7
   Papaioannou G, 2015, WATER RESOUR MANAG, V29, P399, DOI 10.1007/s11269-014-0817-6
   Pierce DW, 2005, California energy commission CEC-500-2005-002, PIER project report
   Qin YW, 2020, ENVIRON RES COMMUN, V2, DOI 10.1088/2515-7620/ab915e
   Rice R.M., 1972, Bull.Int.Assoc.Hydrol.Sci, VXVII, P315, DOI 10.1080/02626667209493837
   Schanze J, 2006, NATO SCI S SS IV EAR, V67, P1
   Schwarz A, 2018, Climate change risk faced by the California central valley water resource system a report for: California's fourth climate change assessment, P1
   Serinaldi F, 2016, PHYSICA A, V450, P585, DOI 10.1016/j.physa.2016.01.043
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sivakumar B, 2014, HYDROL EARTH SYST SC, V18, P4565, DOI 10.5194/hess-18-4565-2014
   Sivakumar B, 2015, ENVIRON MODELL SOFTW, V69, P55, DOI 10.1016/j.envsoft.2015.02.020
   Stewart IT, 2020, J HYDROL X, V7, DOI 10.1016/j.hydroa.2020.100054
   Tukimat NNA, 2019, IOP C SER EARTH ENV, V365, DOI 10.1088/1755-1315/365/1/012025
   Tumiran SA, 2021, STOCH ENV RES RISK A, V35, P561, DOI 10.1007/s00477-020-01936-4
   Uurtio V, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136624
   Vicente-Serrano SM, 2018, J CLIMATE, V31, P5371, DOI [10.1175/jcli-d-17-0775.1, 10.1175/JCLI-D-17-0775.1]
   Xu HW, 2022, ENVIRON MODELL SOFTW, V153, DOI 10.1016/j.envsoft.2022.105396
   Xu YR, 2020, WATER-SUI, V12, DOI 10.3390/w12061739
   Yasmin N, 2021, STOCH ENV RES RISK A, V35, P579, DOI 10.1007/s00477-020-01931-9
   Yasmin N, 2018, J HYDROL, V564, P59, DOI 10.1016/j.jhydrol.2018.06.072
   Zhang JW, 2020, INT J CLIMATOL, V40, P6219, DOI 10.1002/joc.6573
NR 56
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32453
EP 32473
DI 10.1007/s11042-023-16926-1
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100007
DA 2024-07-18
ER

PT J
AU Sharma, A
   Gautam, R
   Singh, J
AF Sharma, Aanchal
   Gautam, Rahul
   Singh, Jaspal
TI Real time face mask detection on a novel dataset for COVID-19 prevention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Computer Vision; Face Mask Detection; Deep Learning; Object
   Detection; YOLO
AB The WHO (World Health Organization) declared COVID-19 a pandemic on March 11, 2020, and it is still ongoing, thereby severely affecting the whole world. "WHO" recommends wearing "facial masks" to manage the pandemic. In such situations, it's difficult and unsafe to manually monitor everyone. In order to prevent the outbreak, an autonomous real-time face mask monitoring system with the use of deep learning algorithm is essential. Advancement in the domain of face mask detection is motivated by exciting and challenging datasets, and in this modern world, it is more difficult for a face mask detection system to identify a face mask as people not only prefer to wear medical face masks but also use masks with a variety of designs, patterns, and colors. So, due to the unavailability of such a versatile dataset, building a novel dataset was necessary. The proposed novel dataset includes different types of masks, masked faces in different weather conditions and crowded environments, masked and non-masked faces at different angles, and various boundary conditions. And, to determine the effectuality of our dataset, we have trained five variants of YOLO, a prominent real-time one-stage detector, in which the latest YOLOv5 has achieved the highest mAP value of 80.80%.
C1 [Sharma, Aanchal; Gautam, Rahul; Singh, Jaspal] St Longowal Inst Engn & Technol, Longowal, Punjab, India.
C3 Sant Longowal Institute of Engineering & Technology (SLIET)
RP Gautam, R (corresponding author), St Longowal Inst Engn & Technol, Longowal, Punjab, India.
EM bhardwajaanchal321@gmail.com; rahulgautam@sliet.ac.in;
   jaspalsingh@sliet.ac.in
RI Gautam, Rahul/JPA-5220-2023
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Alpha Makesense, US
   [Anonymous], US YOL V5 OBJ DET AL
   [Anonymous], YOLOV4 VS YOLOV4 TIN
   [Anonymous], LARX FAC MASK DET DA
   Arie L. G., PRACT GUID OBJ DET Y
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bu W, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P458, DOI 10.1109/ICCIS.2017.8274819
   Buttar PK., 2022, INT J ADV RES COMPUT, V13, P32, DOI [10.26483/ijarcs.v13i2.6808, DOI 10.26483/IJARCS.V13I2.6808]
   Ejaz M.S., 2019, 2019 1 INT C ADV SCI, P1
   Fan XQ, 2021, IEEE SYS MAN CYBERN, P832, DOI 10.1109/SMC52423.2021.9659271
   Feng S, 2020, LANCET RESP MED, V8, P434, DOI 10.1016/S2213-2600(20)30134-X
   Feng X, 2019, INTEGRATION, V69, P309, DOI 10.1016/j.vlsi.2019.07.005
   Goyal H, 2022, MULTIMED TOOLS APPL, V81, P14999, DOI 10.1007/s11042-022-12166-x
   Howard J, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2014564118
   Hu Y.Q., 2021, ARXIV
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   M K, 2021, INT J PHARM SCI REV, V67, P24, DOI [10.47583/ijpsrr.2021.v67i01.004, DOI 10.47583/IJPSRR.2021.V67I01.004]
   Mijwil MM, 2021, Iraqi J. Sci., P2099, DOI 10.24996/ijs.2021.62.6.35
   Nieto-Rodríguez A, 2015, LECT NOTES COMPUT SC, V9117, P138, DOI 10.1007/978-3-319-19390-8_16
   Peng G.S., 2019, Performance and Accuracy Analysis in Object Detection
   Redmon A., YOLOV3 TINY
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Roy Biparnak, 2020, Trans Indian Natl Acad Eng, V5, P509, DOI 10.1007/s41403-020-00157-z
   Thuan D, 2021, EVOLUTION YOLO ALGOR, P61
   Verma S, 2020, PHYS FLUIDS, V32, DOI 10.1063/5.0016018
   Wu PS, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104341
   YOLO V5, YOLO V5 EXPL DEM
   YOLO-V5, US
   Zou Z, 2019, OBJECT DETECTION 20, P1
NR 33
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32387
EP 32410
DI 10.1007/s11042-023-16692-0
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100005
DA 2024-07-18
ER

PT J
AU Hu, JH
   Wang, QR
   Li, DS
   Gao, Y
AF Hu, Jinhui
   Wang, Qianrui
   Li, Dengshi
   Gao, Yu
TI STDC-Net: A spatial-temporal deformable convolution network for
   conference video frame interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video Conference; Video Frame Interpolation; Spatial-Temporal Features;
   Deformable Convolution
AB Video conference communication can be seriously affected by dropped frames or reduced frame rates due to network or hardware restrictions. Video frame interpolation techniques can interpolate the dropped frames and generate smoother videos. However, existing methods can not generate plausible results in video conferences due to the large motions of the eyes, mouth and head. To address this issue, we propose a Spatial-Temporal Deformable Convolution Network (STDC-Net) for conference video frame interpolation. The STDC-Net first extracts shallow spatial-temporal features by an embedding layer. Secondly, it extracts multi-scale deep spatial-temporal features through Spatial-Temporal Representation Learning (STRL) module, which contains several Spatial-Temporal Feature Extracting (STFE) blocks and downsample layers. To extract the temporal features, each STFE block splits feature maps along the temporal pathway and processes them with Multi-Layer Perceptron (MLP). Similarly, the STFE block splits the temporal features along horizontal and vertical pathways and processes them by another two MLPs to get spatial features. By splitting the feature maps into segments of varying lengths in different scales, the STDC-Net can extract both local details and global spatial features, allowing it to effectively handle large motions. Finally, Frame Synthesis (FS) module predicts weights, offsets and masks using the spatial-temporal features, which are used in deformable convolution to generate the intermediate frames. Experimental results demonstrate the STDC-Net outperforms state-of-the-art methods in both quantitative and qualitative evaluations. Compared to the baseline, the proposed method achieved a PSNR improvement of 0.13 dB and 0.17 dB on the Voxceleb2 and HDTF datasets, respectively.
C1 [Hu, Jinhui] China Elect Technol Grp Corp, Smart City Res Inst, Shenzhen 518038, Peoples R China.
   [Hu, Jinhui] Natl Ctr Appl Math Shenzhen, Shenzhen 518000, Peoples R China.
   [Wang, Qianrui; Li, Dengshi; Gao, Yu] Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
C3 China Electronics Technology Group; Jianghan University
RP Li, DS (corresponding author), Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
EM cn.hjh@163.com; Piscesrr@stu.jhun.edu.cn; reallds@jhun.edu.cn;
   gaoyu122@stu.jhun.edu.cn
RI Hu, Jinhui/HGD-6767-2022
OI Hu, Jinhui/0000-0002-0879-8729
FU Natural Science Foundation of China [U22A2035]; Application Foundation
   Frontier Special Project of Wuhan Science and Technology Plan Project
   [61701194]; Doctoral Research Foundation of Jianghan University
   [2020010601012288]; Nature Science Foundation of Hubei Province
   [2019029];  [2017CFB756]
FX This research was funded by Natural Science Foundation of China
   (U22A2035, No. 61701194), Application Foundation Frontier Special
   Project of Wuhan Science and Technology Plan Project
   (No.2020010601012288), Doctoral Research Foundation of Jianghan
   University (2019029), Nature Science Foundation of Hubei Province
   (2017CFB756)
CR Bao WB, 2019, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2019.00382
   Cheng XH, 2022, IEEE T PATTERN ANAL, V44, P7029, DOI 10.1109/TPAMI.2021.3100714
   Cheng XH, 2020, AAAI CONF ARTIF INTE, V34, P10607
   Choi M, 2020, AAAI CONF ARTIF INTE, V34, P10663
   Chung Joon Son, 2018, arXiv
   Danier D, 2022, IEEE IMAGE PROC, P1396, DOI 10.1109/ICIP46576.2022.9897929
   Danier D, 2022, PROC CVPR IEEE, P3511, DOI 10.1109/CVPR52688.2022.00351
   Ding T., 2021, P IEEE C COMP VIS PA, P8001
   Dutta S, 2022, IEEE COMPUT SOC CONF, P1725, DOI 10.1109/CVPRW56347.2022.00180
   Figueirêdo P, 2023, IEEE WINT CONF APPL, P218, DOI 10.1109/WACV56688.2023.00030
   Hu MS, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P2145, DOI 10.1145/3503161.3547875
   Hu MS, 2022, IEEE T CIRC SYST VID, V32, P3390, DOI 10.1109/TCSVT.2021.3110796
   Hu MS, 2020, INT CONF ACOUST SPEE, P4347, DOI [10.1109/ICASSP40776.2020.9053223, 10.1109/icassp40776.2020.9053223]
   Hu P, 2022, PROC CVPR IEEE, P3543, DOI 10.1109/CVPR52688.2022.00354
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Jin X, 2023, IEEE WINT CONF APPL, P5038, DOI 10.1109/WACV56688.2023.00502
   Junheum Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P109, DOI 10.1007/978-3-030-58568-6_7
   Kalluri T, 2023, IEEE WINT CONF APPL, P2070, DOI 10.1109/WACV56688.2023.00211
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Khalifeh I, 2022, IEEE COMPUT SOC CONF, P724, DOI 10.1109/CVPRW56347.2022.00088
   Kingma D. P., 2014, arXiv
   Kong LT, 2022, IEEE SIGNAL PROC LET, V29, P2338, DOI 10.1109/LSP.2022.3221350
   Kong LT, 2022, PROC CVPR IEEE, P1968, DOI 10.1109/CVPR52688.2022.00201
   Lee H, 2020, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR42600.2020.00536
   Li H-D, 2022, Appl Intell, P1
   Li Y, 2022, INT J COMPUT VISION, V130, P2980, DOI 10.1007/s11263-022-01683-9
   Liu JF, 2022, IEEE IMAGE PROC, P1486, DOI 10.1109/ICIP46576.2022.9897981
   Niklaus S, 2023, IEEE WINT CONF APPL, P713, DOI 10.1109/WACV56688.2023.00078
   Niklaus S, 2021, IEEE WINT CONF APPL, P1098, DOI 10.1109/WACV48630.2021.00114
   Niklaus S, 2020, PROC CVPR IEEE, P5436, DOI 10.1109/CVPR42600.2020.00548
   Niklaus S, 2018, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2018.00183
   Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37
   Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244
   Park J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14519, DOI 10.1109/ICCV48922.2021.01427
   Shi ZH, 2022, PROC CVPR IEEE, P17461, DOI 10.1109/CVPR52688.2022.01696
   Shi ZH, 2022, IEEE T MULTIMEDIA, V24, P426, DOI 10.1109/TMM.2021.3052419
   Sim Hyeonjun, 2021, P IEEECVF INT C COMP, P14489
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wijma R, 2021, IEEE INT CONF COMP V, P1127, DOI 10.1109/ICCVW54120.2021.00132
   Xiao J, 2022, IEEE T MULTIMEDIA
   Xing JB, 2021, COMPUT VIS MEDIA, V7, P393, DOI 10.1007/s41095-021-0208-x
   Xu XY, 2019, ADV NEUR IN, V32
   Yihao Liu, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12538), P41, DOI 10.1007/978-3-030-66823-5_3
   Zhang DJ, 2022, LECT NOTES COMPUT SC, V13695, P230, DOI 10.1007/978-3-031-19833-5_14
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang ZM, 2021, PROC CVPR IEEE, P3660, DOI 10.1109/CVPR46437.2021.00366
NR 48
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 19
PY 2023
DI 10.1007/s11042-023-16266-0
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S1WZ2
UT WOS:001069156900016
OA hybrid
DA 2024-07-18
ER

PT J
AU Siva, R
   Kaliraj, S
   Hariharan, B
   Premkumar, N
AF Siva, R.
   Kaliraj, S.
   Hariharan, B.
   Premkumar, N.
TI Automatic software bug prediction using adaptive golden eagle optimizer
   with deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Golden Eagle Optimizer; Opposition-based learning; Long Short-Term
   Memory; Recurrent neural network and Matthews Correlation Coefficient;
   Software Fault Prediction
ID FAULT PREDICTION; NEURAL-NETWORK; SYSTEM
AB In the software maintenance and development process, the software bug detection is an essential problem because it related with the complete software successes. So, the earlier software bug detection is essential to enhance the software efficiency, reliability, software quality and software cost. Moreover, the efficient software bug prediction is a critical as well as challenging operation. Hence, the efficient software bug prediction model is developed in this article. To achieve this objective, optimized long short-term memory is developed. The important stages of the proposed model is preprocessing, feature selection and bug detection. At first the input bug dataset is preprocessed. In preprocessing, the duplicate data instances are removed from the dataset. After the preprocessing, the feature selection is done by Adaptive Golden Eagle Optimizer (AGEO). Here the traditional GEO algorithm is altered by means of opposition-based learning (OBL). Finally, the proposed approach utilizes a long short-term memory (LSTM) based recurrent neural network (RNN) for bug prediction. Long Short-Term Memory (LSTM) network is a type of recurrent neural network. The promise and NASA dataset are considered as the input for bug prediction. the performance of proposed approach is analysed based on various metrics namely, accuracy, F- measure, G-measure and Matthews Correlation Coefficient (MCC).
C1 [Siva, R.; Hariharan, B.] SRM Inst Sci & Technol, Coll Engn & Technol, Sch Comp, Dept Computat Intelligence, Kattankulathur 603203, Tamil Nadu, India.
   [Kaliraj, S.] Manipal Inst Technol, Acad Higher Educ, Dept Informat & Commun Technol, Manipal 576104, Karnataka, India.
   [Premkumar, N.] Kongunadu Coll Engn & Technol, Dept Informat Technol, Trichy, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; Manipal Academy of Higher
   Education (MAHE); Kongunadu College of Engineering & Technology
RP Kaliraj, S (corresponding author), Manipal Inst Technol, Acad Higher Educ, Dept Informat & Commun Technol, Manipal 576104, Karnataka, India.
EM kaliraj.s@manipal.edu
RI S, KALIRAJ/P-6234-2016; B, HARIHARAN/AAV-7239-2020
OI S, KALIRAJ/0000-0003-4212-8427; B, HARIHARAN/0000-0002-9920-6011; R,
   Siva/0000-0002-2006-8753; N, PREMKUMAR/0000-0003-4839-0645
FU The author with a deep sense of gratitude would thank the supervisor for
   his guidance and constant support rendered during this research.
FX The author with a deep sense of gratitude would thank the supervisor for
   his guidance and constant support rendered during this research.
CR Afric P, 2023, IEEE ACCESS, V11, P11732, DOI 10.1109/ACCESS.2023.3242045
   Balogun A.O., 2018, J. Eng. Technol., V3, P50
   Choetkiertikul M, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-020-09898-5
   Chouhan SS, 2021, IEEE T RELIAB, V70, P626, DOI 10.1109/TR.2021.3052510
   Cynthia S. T., 2022, 15 INN SOFTW ENG C, P1
   Di Nucci D, 2018, IEEE T SOFTWARE ENG, V44, P5, DOI 10.1109/TSE.2017.2659747
   Fang S, 2021, IEEE T RELIAB, V70, P563, DOI 10.1109/TR.2021.3074412
   Giray G, 2023, J SYST SOFTWARE, V195, DOI 10.1016/j.jss.2022.111537
   Gupta Anurag, 2023, 2023 13th International Conference on Cloud Computing, Data Science & Engineering (Confluence), P636, DOI 10.1109/Confluence56041.2023.10048825
   Gupta Anurag, 2023, 2023 13th International Conference on Cloud Computing, Data Science & Engineering (Confluence), P278, DOI 10.1109/Confluence56041.2023.10048829
   Gupta DL, 2017, SADHANA-ACAD P ENG S, V42, P655, DOI 10.1007/s12046-017-0629-5
   Hammouri A, 2018, INT J ADV COMPUT SC, V9, P78
   Iqbal A, 2019, INT J ADV COMPUT SC, V10, P300
   Johnson F, 2023, INNOV SYST SOFTW ENG, V19, P91, DOI 10.1007/s11334-022-00506-x
   Juneja K, 2019, APPL SOFT COMPUT, V77, P696, DOI 10.1016/j.asoc.2019.02.008
   Khan F, 2020, IEEE ACCESS, V8, P20954, DOI 10.1109/ACCESS.2020.2968362
   Lamba T., 2019, Int J Intell Syst Appl, V10, P36
   Mahajan G, 2022, SOFT COMPUT, V26, P13651, DOI 10.1007/s00500-022-07341-z
   Mohammadi-Balani A, 2021, COMPUT IND ENG, V152, DOI 10.1016/j.cie.2020.107050
   Moustafa S, 2018, ALEX ENG J, V57, P2763, DOI 10.1016/j.aej.2018.01.003
   Panda RR, 2023, ENG APPL ARTIF INTEL, V122, DOI 10.1016/j.engappai.2023.106110
   Pandey SK, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113085
   Qiao L, 2020, NEUROCOMPUTING, V385, P100, DOI 10.1016/j.neucom.2019.11.067
   Ramay WY, 2019, IEEE ACCESS, V7, P46846, DOI 10.1109/ACCESS.2019.2909746
   Rani Geeta, 2023, International Journal of Information Technology, P355, DOI 10.1007/s41870-022-01047-z
   Rathore SS, 2017, COMPUTING, V99, P255, DOI 10.1007/s00607-016-0489-6
   Rathore SS, 2017, EXPERT SYST APPL, V82, P357, DOI 10.1016/j.eswa.2017.04.014
   Rathore SS, 2017, KNOWL-BASED SYST, V119, P232, DOI 10.1016/j.knosys.2016.12.017
   Shepperd M, 2014, IEEE T SOFTWARE ENG, V40, P603, DOI 10.1109/TSE.2014.2322358
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Sivapurnima S, 2023, COMPUT SYST SCI ENG, V45, P1234
   Tantithamthavorn C, 2019, IEEE T SOFTWARE ENG, V45, P683, DOI 10.1109/TSE.2018.2794977
   Turabieh H, 2019, EXPERT SYST APPL, V122, P27, DOI 10.1016/j.eswa.2018.12.033
   Wahono R. S., 2015, Journal of Software Engineering, V1, P1
   Wang ZX, 2023, COMPLEX INTELL SYST, V9, P3835, DOI 10.1007/s40747-022-00848-w
   Xu Z, 2019, INFORM SOFTWARE TECH, V106, P182, DOI 10.1016/j.infsof.2018.10.004
NR 36
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 5
PY 2023
DI 10.1007/s11042-023-16666-2
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q7BA0
UT WOS:001059026300016
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Xiao, JY
   Wu, WW
   Zhang, SC
AF Zhang, Qi
   Xiao, Jingyu
   Wu, Weiwei
   Zhang, Shichao
TI An adaptive CNN for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Adaptive block; Consolidate loss; Deformable kernels; Switchable
   normalization; Image denoising
ID NORM MINIMIZATION; NETWORK
AB Convolutional neural network techniques have shown great promise in many low-level image processing tasks. However, due to the reduced impact of convolution operations in deep layers on the original inputs, the image denoising task suffers from effective information loss during forward propagation. To address this issue, this paper proposes an adaptive denoising CNN (ACNN) with a deep feature block (DFB), an adaptive block (AB), and a construction block (CB). The DFB utilizes a stacked architecture to ensure the learning ability of ACNN. The AB dynamically adjusts its learning strategy by using a deformable convolutional filter and a switchable normalization (SN) to extract more powerful features. CB gathers DFB and AB to extract complementary features for images. Also, CB can be used to construct a clean image. Moreover, a consolidate loss function utilizes mean squared error (MSE) and structure similarity index measure (SSIM) to further alleviate smooth problem. Experimental analysis shows the superiority of the proposed ACNN in terms of qualitative analysis and quantitative metrics.
C1 [Zhang, Qi] Harbin Inst Technol Weihai, Sch Econ & Management, Weihai, Peoples R China.
   [Xiao, Jingyu; Zhang, Shichao] Cent South Univ, Sch Comp Sci, Changsha, Peoples R China.
   [Wu, Weiwei] Harbin Inst Technol, Sch Management, Harbin, Peoples R China.
C3 Harbin Institute of Technology; Central South University; Harbin
   Institute of Technology
RP Wu, WW (corresponding author), Harbin Inst Technol, Sch Management, Harbin, Peoples R China.
EM wuweiwei@hit.edu.cn
RI Zhang, Shichao/JXW-9650-2024
FU Natural Science Foundation of Shandong Province [ZR2023QG074]; Key
   Project of NSFC [61836016]; National Natural Science Foundation of China
   [72072047]; Fundamental Research Funds for the Central Universities
   [HIT.HSS.ESD202310]
FX This work was supported in part by the Natural Science Foundation of
   Shandong Province under Grant ZR2023QG074, in part by Key Project of
   NSFC under Grant 61836016, in part by the National Natural Science
   Foundation of China under Grant 72072047, in part by the Fundamental
   Research Funds for the Central Universities under Grant
   HIT.HSS.ESD202310.
CR Agarap AF, 2018, arXiv, DOI 10.48550/arXiv.1803.08375
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chen TH, 2022, IEEE T NEUR NET LEAR, V33, P7367, DOI 10.1109/TNNLS.2021.3084900
   Chen Y., 2016, IEEE Transact Pattern Anal Mach Intell, VPP, P1
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dey S, 2021, ALGORITHMS, V14, DOI 10.3390/a14040109
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Gurrola-Ramos J, 2021, IEEE ACCESS, V9, P31742, DOI 10.1109/ACCESS.2021.3061062
   He K., 2021, arXiv, DOI 10.48550/arXiv.2107.02451 2107.02451
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ioffe S, 2017, Arxiv, DOI [arXiv:1702.03275, 10.48550/arXiv.1702.03275, DOI 10.48550/ARXIV.1702.03275]
   Kingma D. P., 2014, arXiv
   Lee B, 2021, IEEE ACCESS, V9, P91974, DOI 10.1109/ACCESS.2021.3091971
   Lei Ba J., 2016, arXiv
   Liang J., 2021, Journal of Physics: Conference Series, V1802
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu PJ, 2019, IEEE ACCESS, V7, P74973, DOI 10.1109/ACCESS.2019.2921451
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Luo EM, 2015, IEEE T IMAGE PROCESS, V24, P2167, DOI 10.1109/TIP.2015.2414873
   Luo P, 2019, Arxiv, DOI [arXiv:1806.10779, 10.48550/arXiv.1806.10779]
   Lyu ZY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115727
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mäkitalo M, 2013, IEEE T IMAGE PROCESS, V22, P91, DOI 10.1109/TIP.2012.2202675
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nam S, 2016, PROC CVPR IEEE, P1683, DOI 10.1109/CVPR.2016.186
   Park B, 2019, IEEE COMPUT SOC CONF, P2104, DOI 10.1109/CVPRW.2019.00263
   Paszke A., 2017, Computer software vers, V1, P1
   Rad MS, 2019, IEEE I CONF COMP VIS, P2710, DOI 10.1109/ICCV.2019.00280
   Roth S, 2005, PROC CVPR IEEE, P860
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Scetbon M, 2021, IEEE T IMAGE PROCESS, V30, P5944, DOI 10.1109/TIP.2021.3090531
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Shao WQ, 2019, PROC CVPR IEEE, P443, DOI 10.1109/CVPR.2019.00053
   Su YC, 2020, INFORM SCIENCES, V537, P162, DOI 10.1016/j.ins.2020.05.049
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tang YB, 2021, CIRC SYST SIGNAL PR, V40, P5381, DOI 10.1007/s00034-021-01720-x
   Tian CW, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.106949
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian CW, 2019, CAAI T INTELL TECHNO, V4, P17, DOI 10.1049/trit.2018.1054
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang GR, 2018, Arxiv, DOI [arXiv:1802.03133, 10.48550/arXiv.1802.03133]
   Wang YM, 2021, IET IMAGE PROCESS, V15, P1260, DOI 10.1049/ipr2.12102
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei F, 2023, MEMET COMPUT, V15, P219, DOI 10.1007/s12293-022-00385-6
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Xiaohe Wu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P352, DOI 10.1007/978-3-030-58548-8_21
   Xu J., 2018, arXiv
   Xu K, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3566125
   Xu MY, 2022, SIGNAL IMAGE VIDEO P, V16, P175, DOI 10.1007/s11760-021-01965-8
   Xue T, 2023, APPL INTELL, V53, P6753, DOI 10.1007/s10489-022-03785-w
   Yang HB, 2022, LECT NOTES COMPUT SC, V13433, P292, DOI 10.1007/978-3-031-16437-8_28
   Yang XH, 2020, IEEE T IMAGE PROCESS, V29, P5038, DOI 10.1109/TIP.2020.2978645
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Young LD, 2022, IEEE WINT CONF APPL, P709, DOI 10.1109/WACVW54805.2022.00078
   Yu S, 2019, IEEE COMPUT SOC CONF, P2095, DOI 10.1109/CVPRW.2019.00262
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Yuan D, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3486678
   Yuan D, 2021, IEEE T IMAGE PROCESS, V30, P976, DOI 10.1109/TIP.2020.3037518
   Yue ZS, 2019, ADV NEUR IN, V32
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Q, 2023, CAAI T INTELL TECHNO, V8, P331, DOI 10.1049/cit2.12110
   Zhao DD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092000
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 72
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 28
PY 2023
DI 10.1007/s11042-023-16452-0
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q9BE6
UT WOS:001060390500002
DA 2024-07-18
ER

PT J
AU Kim, WY
   Hum, YC
   Tee, YK
   Yap, WS
   Mokayed, H
   Lai, KW
AF Kim, Wong Yoke
   Hum, Yan Chai
   Tee, Yee Kai
   Yap, Wun-She
   Mokayed, Haman
   Lai, Khin Wee
TI A modified single image dehazing method for autonomous driving vision
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haze removal; Autonomous driving vision system; Random forest;
   Transmission estimation; Quad-tree decomposition atmospheric light
   prediction
ID HAZE; ENHANCEMENT; FEATURES; FUSION
AB Managing unforeseen situations, particularly in low-visibility environments caused by weather degradation, continues to be a significant challenge for the autonomous driving vision system. This paper aims to enhance the visibility of degraded images captured by the system's sensors by removing haze. To achieve this goal, we propose an algorithm that predicts transmission from a regression model using random forest and atmospheric light using a quad-tree decomposition method. We evaluate the performance of the haze removal algorithm on three benchmark datasets (FRIDA2, D-HAZY, and RESIDE) using both quantitative and qualitative analyses. Our proposed method yields the lowest count of saturated pixels ( n-ary sumation ) in blind contrast enhancement assessment, with n-ary sumation = 0.0001. The implications of our approach are significant. By utilizing the RF-transmission estimation and quad-based atmospheric light prediction, the proposed haze removal algorithm demonstrates greater robustness in preventing unintended black or white color pixels in the dehazed image. This improvement can contribute to safer autonomous driving, particularly in low-visibility conditions, where the reliability of image processing systems is paramount.
C1 [Kim, Wong Yoke; Hum, Yan Chai; Tee, Yee Kai] Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Dept Mechatron & Biomed Engn, Selangor, Malaysia.
   [Yap, Wun-She] Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Dept Elect & Elect Engn, Selangor, Malaysia.
   [Mokayed, Haman] Lulea Univ Technol, Dept Comp Sci Elect & Space Engn, Lulea, Sweden.
   [Lai, Khin Wee] Univ Malaya, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Tunku Abdul Rahman (UTAR); Universiti Tunku Abdul Rahman
   (UTAR); Lulea University of Technology; Universiti Malaya
RP Hum, YC (corresponding author), Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Dept Mechatron & Biomed Engn, Selangor, Malaysia.
EM humyc@utar.edu.my
RI Lai, Khin Wee/A-2997-2011; Tee, Yee Kai/O-1677-2015; Hum, Yan
   Chai/H-9021-2018
OI Lai, Khin Wee/0000-0002-8602-0533; Tee, Yee Kai/0000-0002-0263-6358;
   Hum, Yan Chai/0000-0002-9657-8311
FU Universiti Tunku Abdul Rahman Research Fund
   [IPSR/RMC/UTARRF/2022-C1/H02]
FX This work was supported by the Universiti Tunku Abdul Rahman Research
   Fund (IPSR/RMC/UTARRF/2022-C1/H02).
CR Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39
   Ancuti CO, 2018, IEEE COMPUTER SOC C, P1581, DOI [10.1109/CVPRW.2018.00211, DOI 10.1109/CVPRW.2018.00211]
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Choi LK, 2014, IEEE SW SYMP IMAG, P165, DOI 10.1109/SSIAI.2014.6806055
   Choi LK, 2014, PROC SPIE, V9014, DOI 10.1117/12.2036477
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194011
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Glon R, 2020, HIST SELF DRIVING CA
   Hardin W, 2018, VISION SYSTEMS CRUIS
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Koul S, 2022, MULTIMED TOOLS APPL, V81, P11259, DOI 10.1007/s11042-022-11974-5
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Liu JT, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/1651958
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan S, 2009, ACM SIGGRAPH 2009 CO, DOI [10.1145/1667239.1667260, DOI 10.1145/1667239.1667260]
   Narasimhan SG, 2002, LECT NOTES COMPUT SC, V2352, P148
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Song R, 2020, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON VEHICLE TECHNOLOGY AND INTELLIGENT TRANSPORT SYSTEMS (VEHITS), P331, DOI 10.5220/0009354503310341
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Valeriano LC, 2018, 2018 COL VIS COMP S, DOI [10.1109/CVCS.2018.8496520, DOI 10.1109/CVCS.2018.8496520]
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wang WC, 2017, IEEE-CAA J AUTOMATIC, V4, P410, DOI 10.1109/JAS.2017.7510532
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Zheng MY, 2020, IEEE SENS J, V20, P8062, DOI 10.1109/JSEN.2020.2981719
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 42
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25867
EP 25899
DI 10.1007/s11042-023-16547-8
EA AUG 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060201500002
DA 2024-07-18
ER

PT J
AU Shreya, S
   Chatterjee, K
AF Shreya, Shashi
   Chatterjee, Kakali
TI GAN-enable latent fingerprint enhancement model for human identification
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automated system; Data perturbation; Denoising; DL model; UNET plus
ID IMAGE-ENHANCEMENT
AB There is a growing demand for a human identification system to solve different societal crimes and issues from available shreds of evidence. This paper considers an automated human identification system based on latent fingerprint biometric traits. Latent fingerprints are the fingerprint generated by the experts from the surfaces claimed to be part of the evidence to find the required person's existence. The identification rate and system accuracy are low in this biometric trait as latent images are excessively noisy because it is lifted from surfaces like glass, wood, ceramic, plastic, or metallic. Besides noise, dullness, blurriness, and unclear view of fingerprint features in the image are also responsible for low identification. So a strong and effective enhancement technique for the latent fingerprint is required to reduce the noise and preserve the features. The traditional enhancement techniques for latent fingerprints are performed by orientation field approximation followed by contextual filters application like the Gabor filter. But in the era of Deep-Learning (DL) models, the attention is shifted to developing models capable of denoising and missing ridge reconstruction without hampering the orientation field. So, a Generative Adversarial Network (GAN) based approach is used that shows an improvement in matching performance compared to existing works. The identification rate of the enhanced image through the proposed model is 34.7%, whereas the raw image is only 10.7%. Other evolution metrics results are, Structural Similarity Index Metric (SSIM) is 0.996, Root Mean Square Error (RMSE) is 0.988, and Universal Quality Index (UQI) is 0.002.
C1 [Shreya, Shashi; Chatterjee, Kakali] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Shreya, S (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
EM shashis.phd19.cs@nitp.ac.in
CR Cao K, 2020, IEEE T INF FOREN SEC, V15, P880, DOI 10.1109/TIFS.2019.2930487
   Cao K, 2015, INT CONF BIOMETR, P349, DOI 10.1109/ICB.2015.7139060
   Cao K, 2014, IEEE T PATTERN ANAL, V36, P1847, DOI 10.1109/TPAMI.2014.2302450
   Chikkerur S, 2005, LECT NOTES COMPUT SC, V3687, P20
   Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Huang XJ, 2020, IEEE COMPUT SOC CONF, P3481, DOI 10.1109/CVPRW50498.2020.00408
   Joshi I, 2021, AI DEEP LEARNING BIO, P51
   Joshi I, 2019, IEEE WINT CONF APPL, P895, DOI 10.1109/WACV.2019.00100
   Li J, 2018, SIGNAL PROCESS-IMAGE, V60, P52, DOI 10.1016/j.image.2017.08.010
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maltoni D., 2009, Handbook of Fingerprint Recognition, DOI [10.1007/978-3-030-83624-5, DOI 10.1007/978-3-030-83624-5]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sankaran A, 2017, INFORM FUSION, V34, P1, DOI 10.1016/j.inffus.2016.05.002
   Sankaran A, 2014, IEEE ACCESS, V2, P982, DOI 10.1109/ACCESS.2014.2349879
   Song W, 2019, IEEE ACCESS, V7, P82744, DOI 10.1109/ACCESS.2019.2923753
   Soni R., 2021, Generative Adversarial Networks for Image-to-Image Translation, P99
   Verma P, 2022, VISUAL COMPUT, V38, P2417, DOI 10.1007/s00371-021-02120-7
   Verma P, 2021, COMP M BIO BIO E-IV, V9, P600, DOI 10.1080/21681163.2021.1902400
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yoon S, 2010, PROC SPIE, V7667, DOI 10.1117/12.851411
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu YN, 2023, IMMUNOL INVEST, V52, P298, DOI 10.1080/08820139.2023.2173077
NR 25
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27565
EP 27588
DI 10.1007/s11042-023-16510-7
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600011
DA 2024-07-18
ER

PT J
AU Wang, JH
   Wang, ZY
   Zhuang, SN
   Hao, YQ
   Wang, H
AF Wang, Jiahui
   Wang, Zhengyou
   Zhuang, Shanna
   Hao, Yaqian
   Wang, Hui
TI Cross-enhancement transformer for action segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action segmentation; Self-attention mechanism; Temporal structure;
   Transformer
AB Temporal convolutions have been the paradigm of choice in action segmentation, which enhances long-term receptive fields by increasing convolution layers. However, deep convolution layers cause a loss of local information required for frame recognition. To solve the above problem, a new encoder-decoder structure is proposed in this paper, called Cross Enhancement Transformer. Our approach can be effective learning of temporal structure representation with interactive self-attention mechanism and concatenate each layer convolutional feature maps in encoder with a set of features in decoder produced via self-attention. Therefore, local and global information are excavated in a series of frame actions simultaneously. In addition, a new loss function is proposed to enhance the training process whick can penalize over-segmentation errors. Experiments show that our framework performs state-ofthe-art on three challenging datasets: 50Salads, Georgia Tech Egocentric Activities and the Breakfast dataset. Codes are available at https://github.com/Wangjhdeveloper/CETNet.
C1 [Wang, Jiahui; Wang, Zhengyou; Zhuang, Shanna; Hao, Yaqian; Wang, Hui] Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang 050043, Peoples R China.
   [Wang, Zhengyou; Zhuang, Shanna; Wang, Hui] Hebei Key Lab Electromagnet Environm Effects & Inf, Shijiazhuang 050043, Peoples R China.
C3 Shijiazhuang Tiedao University
RP Wang, ZY (corresponding author), Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang 050043, Peoples R China.; Wang, ZY (corresponding author), Hebei Key Lab Electromagnet Environm Effects & Inf, Shijiazhuang 050043, Peoples R China.
EM zhengyouwang@stdu.edu.cn
FU Innovation Research Funds for Shijiazhuang Tiedao University
   [YC2022057]; National Nature Science Foundation of China [61972267];
   Nature Science Foundation of Hebei Province [F2019210306]
FX AcknowledgementsThis work is supported by the Innovation Research Funds
   for Shijiazhuang Tiedao University (No. YC2022057), the National Nature
   Science Foundation of China (No. 61972267), and the Nature Science
   Foundation of Hebei Province (No. F2019210306).
CR Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   Ahn H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16282, DOI 10.1109/ICCV48922.2021.01599
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chen M.-H., 2020, P IEEE CVF C COMP VI, P9454
   Chen WY, 2022, ADVERS RESIL SCI, V3, P335, DOI 10.1007/s42844-022-00076-8
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   Fathi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3281, DOI 10.1109/CVPR.2011.5995444
   Fayyaz M, 2020, PROC CVPR IEEE, P498, DOI 10.1109/CVPR42600.2020.00058
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Ishikawa Y, 2021, IEEE WINT CONF APPL, P2321, DOI 10.1109/WACV48630.2021.00237
   Jiang GH, 2021, APPL INTELL, V51, P7043, DOI 10.1007/s10489-021-02195-8
   Karaman S, 2014, ECCV THUMOS Workshop, V1, P5
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuehne H, 2016, IEEE WINT CONF APPL
   Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lei P, 2018, PROC CVPR IEEE, P6742, DOI 10.1109/CVPR.2018.00705
   Li SJ, 2023, IEEE T PATTERN ANAL, V45, P6647, DOI 10.1109/TPAMI.2020.3021756
   Li X., 2021, IEEE Trans Cogn Develop Syst, P1
   Li YH, 2021, NEUROCOMPUTING, V454, P373, DOI 10.1016/j.neucom.2021.04.121
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Ma MJ, 2022, APPL INTELL, V52, P10692, DOI 10.1007/s10489-021-03010-0
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Oord A., 2016, ARXIV160903499
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Singhania D, 2021, PREPRINT
   Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Vo NN, 2014, PROC CVPR IEEE, P2641, DOI 10.1109/CVPR.2014.338
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Yang DW, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02293-6
   Yang JL, 2022, ASIA EUR J, V20, P357, DOI 10.1007/s10308-021-00643-1
   Yi F, 2021, PREPRINT
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhenzhi Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P34, DOI 10.1007/978-3-030-58595-2_3
NR 43
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25643
EP 25656
DI 10.1007/s11042-023-16041-1
EA AUG 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Prabakaran, N
   Devi, RP
AF Prabakaran, N.
   Devi, R. Prameela
TI An improved deep learning framework for enhancing mimo-Noma system
   performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DNN; Mayfly; Harris hawks optimization; NOMA; MIMO; AGWN
ID JOINT CHANNEL ESTIMATION; MULTIUSER DETECTION; OPTIMIZATION
AB Non-orthogonal multiple access (NOMA) is an effective mechanism based on the multiple access technique. Here, the MIMO-NOMA system is considered to deal with problems especially energy and spectral efficiency. To improve the performance based on energy and spectral efficiency, the proposed technique is incorporated with a deep learning-based technique with a hybrid Meta-heuristic algorithm. The algorithms including Harris Hawks Optimization (HHO) and Mayfly optimization (MF) are considered for enhancing the MIMI-NOMA system. Moreover, with this proposed model, the automatic encoding, decoding, and channel detection in an Additive White Gaussian Noise (AWGN) channel. The deep learning technique incorporated with DNN is based on conventional user activity and data detection techniques. In specific, the user activity and data in the environment are in a non-linear form that can be approximated by the proposed model. The proposed HHMF-DNN-NOMA is implemented into the platform of MATLAB 2020a and the proposed model is evaluated with the existing model to prove the performance is better than existing.
C1 [Prabakaran, N.; Devi, R. Prameela] Koneru Lakshmaiah Educ Fdn, Dept ECE, Vaddeswaram, Andhra Pradesh, India.
   [Devi, R. Prameela] CVR Coll Engn, Dept ECE, Hyderabad, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Prabakaran, N (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept ECE, Vaddeswaram, Andhra Pradesh, India.
EM prabakaran@kluniversity.in
OI , PRAMEELA DEVI/0000-0003-2917-6272
CR Ahmed T., 2018, INT J COMPUT SCI ENG, V8, P1, DOI [10.5121/ijcseit.2018.8601, DOI 10.5121/IJCSEIT.2018.8601]
   Cao KR, 2021, IEEE T VEH TECHNOL, V70, P1978, DOI 10.1109/TVT.2021.3053093
   Dai LL, 2019, IEEE J SEL AREA COMM, V37, P131, DOI 10.1109/JSAC.2018.2872364
   Du Y, 2018, IEEE WIREL COMMUN LE, V7, P682, DOI 10.1109/LWC.2018.2810278
   Huang HJ, 2020, IEEE T WIREL COMMUN, V19, P5373, DOI 10.1109/TWC.2020.2992786
   Huang L, 2022, IEEE T VEH TECHNOL, V71, P12104, DOI 10.1109/TVT.2022.3189699
   Kyuhyuk Chung, 2020, The International Journal of Internet, Broadcasting and Communication, V12, P37, DOI 10.7236/IJIBC.2020.12.2.37
   Li F, 2021, IEEE WIREL COMMUN LE, V10, P246, DOI 10.1109/LWC.2020.3025771
   Li XW, 2020, IEEE WIREL COMMUN LE, V9, P17, DOI 10.1109/LWC.2019.2939309
   Lin C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112526
   Murakami K, 2021, J TEXTURE STUD, V52, P303, DOI [10.1111/jtxs.12593, 10.1080/15440478.2021.1929652]
   Pan J, 2020, DEEP LEARNING AIDED
   Rahman MH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22186994
   Sharma S, 2019, IEEE COMMUN LETT, V23, P971, DOI 10.1109/LCOMM.2019.2911082
   Tian XJ, 2020, PHYS COMMUN-AMST, V43, DOI 10.1016/j.phycom.2020.101227
   Vu TH, 2022, IEEE INTERNET THINGS, V9, P2253, DOI 10.1109/JIOT.2021.3091208
   Xia B, 2018, IEEE T VEH TECHNOL, V67, P6711, DOI 10.1109/TVT.2018.2813524
   Xie WW, 2020, Arxiv, DOI arXiv:2005.11684
   Yuan WJ, 2020, IEEE T COMMUN, V68, P2963, DOI 10.1109/TCOMM.2020.2975169
   Zewde TA, 2018, IEEE T GREEN COMMUN, V2, P679, DOI 10.1109/TGCN.2018.2830347
   Zhang HJ, 2020, IEEE J SEL AREA COMM, V38, P2074, DOI 10.1109/JSAC.2020.3000888
   Zhao W, 2019, IEEE ACCESS, V7, P72062, DOI 10.1109/ACCESS.2019.2919965
NR 22
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16259-z
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700015
DA 2024-07-18
ER

PT J
AU Cai, MS
   Du, YH
   Tan, YJ
   Lu, X
AF Cai, Mengsi
   Du, Yonghao
   Tan, Yuejin
   Lu, Xin
TI Aspect-based classification method for review spam detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Aspect features; Aspect extraction; Spam reviews; Review spam detection
ID FRAMEWORK
AB Online reviews have become available for consumers' reference to make purchase decisions, but a large number of spam reviews have damaged e-commerce reputations. Previous research has addressed review spam detection with classification models using textual features, behavior features, and relational features. However, the fine-grained aspect features related to the product attributes in online reviews have been overlooked and have not yet been thoroughly studied. Therefore, this study proposes a review spam detection model based on a list of novel aspect features. The basic idea is that since spam reviews are usually written by users without real experience, the product aspects depicted in spam reviews will be different from those in genuine reviews. First, we use the Bi-LSTM model to automatically extract massive aspect words, which are then clustered into different aspect categories by the K-means algorithm. Further, we propose nine novel aspect features to train a machine learning model for review spam detection. Experimental results on two labeled Yelp datasets show that the proposed aspect features can significantly improve the accuracy of review spam detection by about 16.11% to 38.86% compared with textual and behavior features.
C1 [Cai, Mengsi; Du, Yonghao; Tan, Yuejin; Lu, Xin] Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China
RP Lu, X (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Peoples R China.
EM xin.lu.lab@outlook.com
RI Lu, Xin/C-1940-2009
OI Lu, Xin/0000-0002-3547-6493
FU National Natural Science Foundation of China [72201272, 72025405,
   72088101, 22ZDA102]; Hunan Science and Technology Plan Project
   [2020TP1013, 2020JJ4673, 2023JJ40685]; Shenzhen Basic Research Project
   for Development of Science and Technology [JCYJ20200109141218676,
   202008291726500001]; Innovation Team Project of Colleges in Guangdong
   Province [2020KCXTD040]; Social Science Foundation of Hunan Province
   [20YBA012]
FX This work was supported by the National Natural Science Foundation of
   China (72201272, 72025405, 72088101), the National Social Science
   Foundation of China (22ZDA102), the Hunan Science and Technology Plan
   Project (2020TP1013, 2020JJ4673, 2023JJ40685), the Shenzhen Basic
   Research Project for Development of Science and Technology
   (JCYJ20200109141218676, 202008291726500001), the Innovation Team Project
   of Colleges in Guangdong Province (2020KCXTD040), and the Social Science
   Foundation of Hunan Province (20YBA012). The authors declare that they
   have no conflict of interest.
CR Akoglu Leman., 2013, ICWSM, P2
   Bajaj S, 2017, PROCEDIA COMPUT SCI, V122, P1009, DOI 10.1016/j.procs.2017.11.467
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Bhuvaneshwari P, 2021, MULTIMED TOOLS APPL, V80, P18107, DOI 10.1007/s11042-021-10602-y
   Buettner R, 2017, ELECTRON MARK, V27, P247, DOI 10.1007/s12525-016-0228-z
   Cai MS, 2022, IEEE SYST J, V16, P566, DOI 10.1109/JSYST.2021.3067334
   Chua AYK, 2016, COMPUT HUM BEHAV, V54, P547, DOI 10.1016/j.chb.2015.08.057
   Dong MQ, 2020, PATTERN RECOGN LETT, V132, P21, DOI 10.1016/j.patrec.2018.07.013
   Etaiwi W, 2017, PROCEDIA COMPUT SCI, V113, P273, DOI 10.1016/j.procs.2017.08.368
   Fei Geli., 2013, ICWSM
   Feng S., 2012, P 50 ANN M ASS COMP, V2, P171
   Gao Y, 2021, IEEE T MULTIMEDIA, V23, P784, DOI 10.1109/TMM.2020.2990085
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He DJ, 2020, IEEE NETWORK, V34, P298, DOI 10.1109/MNET.001.1900542
   Fusilier DH, 2015, INFORM PROCESS MANAG, V51, P433, DOI 10.1016/j.ipm.2014.11.001
   Hernández-Castañeda A, 2017, SOFT COMPUT, V21, P585, DOI 10.1007/s00500-016-2409-2
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Hussain N, 2020, IEEE ACCESS, V8, P53801, DOI 10.1109/ACCESS.2020.2979226
   Jia SH, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2018), P280, DOI 10.1109/INFOMAN.2018.8392850
   Jindal N., 2007, P 16 INT WORLD WID W, P1189, DOI DOI 10.1145/1242572.1242759
   Jindal N., 2008, WSDM 08, P219, DOI [DOI 10.1145/1341531.1341560, 10.1145/1341531.1341560]
   Karami A., 2015, P ICONFERENCE 2015
   Li A, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2703, DOI 10.1145/3357384.3357820
   Li F., 2011, P 22 INT JOINT C ART, P2488, DOI [10.5555/2283696, DOI 10.5591/978-1-57735-516-8/IJCAI11-414, 10.5591/978-1-57735-516-8/IJCAI11-]
   Li HY, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1063, DOI 10.1145/3038912.3052582
   Li HY, 2014, COMPUT SIST, V18, P467
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Lim E.P., 2010, P ACM INT C INFORM K, P939, DOI DOI 10.1145/1871437.1871557
   Lu Y., 2013, P 5 ANN ACM WEB SCI, P225, DOI DOI 10.1145/2464464.2464470
   Luo Y, 2019, INT J HOSP MANAG, V80, P144, DOI 10.1016/j.ijhm.2019.02.008
   Mukherjee A, 2012, P 21 INT C WORLD WID, P191
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Mukherjee Arjun, 2013, P INT AAAI C WEB SOC, DOI DOI 10.1609/ICWSM.V7I1.14389
   Mukherjee Arjun., 2011, P 20 INT C COMPANION, P93
   Mukherjee S., 2016, Joint European Conference on Machine Learning and Knowledge Discovery in Databases, P195, DOI DOI 10.1007/978-3-319-46227-1_13
   Noekhah S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102140
   Noekhah S, 2018, LECT NOTE DATA ENG, V5, P78, DOI 10.1007/978-3-319-59427-9_9
   Ott M., 2013, P 2013 C N AM CHAPT, P497
   Rastogi A, 2017, J INF KNOWL MANAG, V16, DOI 10.1142/S0219649217500368
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Santosh KC, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P369, DOI 10.1145/2872427.2883087
   Shahariar GM, 2019, 2019 IEEE 10TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P27, DOI [10.1109/IEMCON.2019.8936148, 10.1109/iemcon.2019.8936148]
   Shehnepoor S, 2017, IEEE T INF FOREN SEC, V12, P1585, DOI 10.1109/TIFS.2017.2675361
   Shojaee S, 2013, INT CONF INTELL SYST, P53, DOI 10.1109/ISDA.2013.6920707
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Tang XY, 2020, INFORM SCIENCES, V526, P274, DOI 10.1016/j.ins.2020.03.063
   Thapa R, 2021, IEEE COMP SOC ANN, P84, DOI 10.1109/ISVLSI51109.2021.00026
   Tsai CF, 2020, TOURISM MANAGE, V80, DOI 10.1016/j.tourman.2020.104122
   Wang G, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2337542.2337546
   Wang H, 2010, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P783, DOI [DOI 10.1145/1835804.1835903, 10.1145/1835804.1835903]
   Wang XP, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P366, DOI 10.18653/v1/P17-1034
   Xie S., 2012, P 18 ACM SIGKDD INT, P823, DOI DOI 10.1145/2339530.2339662
   Xue H, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3305258
   Yang Y, 2016, TOURISM MANAGE, V56, P40, DOI 10.1016/j.tourman.2016.03.021
   Ye JT, 2015, LECT NOTES ARTIF INT, V9284, P267, DOI 10.1007/978-3-319-23528-8_17
   Yilmaz CM, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P306, DOI 10.1109/ASONAM.2018.8508314
   You L, 2020, FUTURE GENER COMP SY, V102, P163, DOI 10.1016/j.future.2019.07.044
   Yuan CY, 2019, IEEE DATA MINING, P1444, DOI 10.1109/ICDM.2019.00188
   Zhang M, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102389
   Zhang W, 2018, INFORM PROCESS MANAG, V54, P576, DOI 10.1016/j.ipm.2018.03.007
NR 61
TC 0
Z9 0
U1 9
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20931
EP 20952
DI 10.1007/s11042-023-16293-x
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043360000003
DA 2024-07-18
ER

PT J
AU Kaur, M
   Vijay, S
AF Kaur, Maninder
   Vijay, Sandip
TI Deep learning with invariant feature based species classification in
   underwater environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater species; Image enhancement; Segmentation; Surf; Genetic
   algorithm; Deep learning; Convolutional Neural Network
ID ENHANCEMENT
AB Researchers are paying more attention these days to research on the detection and classification of underwater species from images. The main goal of the researchers is to make a pre-processing algorithm that uses an enhancement mechanism to find the exact region of species. It is crucial for marine researchers and scientists to estimate the region of species for classification on a regular basis, but this is a challenging task due to uncleanly captured images. The main causes of such a problem are variation in light of the underwater environment, species concealment, irregular backgrounds, low resolution, and indirect variations between some species patterns. To address these issues, we propose an Invariant Feature-based Species Classification (IFSC) model that employs a pattern-net-based Convolutional Neural Network (CNN) as a deep learning model in an underwater environment. We focused on two types of species: octopus and crabs, each with eight subclasses, and the dataset used was self-collected from the Poppe Image Marine Iconography. To achieve maximum classification accuracy, this study focuses on appropriate segmentation and invariant feature extraction. Following the extraction of invariant features, the concept of a genetic algorithm (GA) is used to select only the most relevant features based on their class. The invariant feature extraction approach known as the Speed Up Robust Feature (SURF) descriptor performed well, and the model achieved an overall accuracy of 95.04%, which is higher than the existing work of 1.71%. As far as we know, the results we got are the best ones that have been published on the collected dataset in the past few years, which shows that our strategy works better than others.
C1 [Kaur, Maninder] Uttarakhand Tech Univ Uttrakhand, Dehra Dun, India.
   [Vijay, Sandip] Tulas Inst, Dehra Dun, Uttarakhand, India.
C3 Tula's Institute
RP Kaur, M (corresponding author), Uttarakhand Tech Univ Uttrakhand, Dehra Dun, India.
EM dhaliwalmaninderkaur@gmail.com; vijaysandip@gmail.com
RI Vijay, Sandip/F-7922-2010
OI Vijay, Sandip/0000-0002-8996-7263
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   [Anonymous], 2006, CMM 06
   Gao YK, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043014
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Han F, 2020, MATH PROBLEMS ENG, V2020
   Iqbal N, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030395
   Jalal A, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101088
   Jin LL, 2017, OCEANS-IEEE
   Kaur M, 2022, MULTIMED TOOLS APPL, V81, P19445, DOI 10.1007/s11042-022-12535-6
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liu S, 2018, 2018 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Salman A, 2020, ICES J MAR SCI, V77, P1295, DOI 10.1093/icesjms/fsz025
   Salman A, 2016, LIMNOL OCEANOGR-METH, V14, P570, DOI 10.1002/lom3.10113
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Spampinato C., 2010, P 1 ACM INT WORKSH A, P45, DOI [DOI 10.1145/1877868, DOI 10.1145/1877868.1877881]
   Sung M, 2017, OCEANS-IEEE
   Verma K, 2015, PROCEDIA COMPUT SCI, V48, P29, DOI 10.1016/j.procs.2015.04.106
   Villon S, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101320
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang NB, 2019, CMC-COMPUT MATER CON, V58, P169, DOI 10.32604/cmc.2019.03709
   Wenwei Xu, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P313, DOI 10.1109/CSCI46756.2018.00067
   Yang HH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051104
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zion B, 2007, COMPUT ELECTRON AGR, V56, P34, DOI 10.1016/j.compag.2006.12.007
NR 25
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19587
EP 19608
DI 10.1007/s11042-023-15896-8
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037377100004
DA 2024-07-18
ER

PT J
AU Zouhri, A
   Kririm, S
   El Mallahi, M
   Hmamed, A
AF Zouhri, Amal
   Kririm, Said
   El Mallahi, Mostafa
   Hmamed, Abdelaziz
TI New algorithm for control optimal filter design of 3D systems described
   by the Fornasini-Marchesini Second Model and hybrid descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Control optimal; Filter design; Hybrid descriptor; Hybrid polynomials;
   Noise eliminator; Transmission; Real-time systems; Fornasini-Marchesini
   model; 3D system
ID RESTORATION; 2D
AB The issue of noise filtering for 3D systems is extremely important in voluminous data transmission. The challenge of this method is to regenerate unknown 3D noisy objects with distant transmission channels. This canal is modeled by convolution system and deconvolution filter to rebuild the output 3D object. To resolve this issue, firstly, we use the hybrid moments based on three Tchibechef, Krawtchouk, and Hahn polynomials to extract the feature vectors for generating the input system with the minimum information. Next, we implement the system with the model of Fornasini-Marchesini for convolution and deconvolution. However, the free matrix variables are used to eliminate coupling between Lyapunov matrix and system matrices to obtain sufficient conditions in linear matrix inequality form to ensure the desired stability and performance of the error systems. Furthermore, the 3D filtering error system is asymptotically stable and satisfies the H8 performance index. A comparative study was carried out to show the robustness of the MSE of the proposed method of hybrid descriptor of optimal order obtained by the maximum of maximum entropy for parameters p = 50, alpha = 50, and beta = 50 compared to Tchebichef, Krawtchouk for p = 50, Hahn descriptors for alpha = 50, and beta = 50 parameters. The proposed method is more efficient with a test MSE of 3.45, also the PSNR = 2, and ET IR of 48.1137 for 3D object with Zero-mean Gaussian noise of variance=0,1.
C1 [Zouhri, Amal] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Lab Informat Signaux Automat & Cognitivisme, Fes, Morocco.
   [Kririm, Said] Ibn Zohr Univ, Higher Sch Technol Guelmim, Lab Mat Signals Syst & Phys Modeling, Agadir, Morocco.
   [El Mallahi, Mostafa] Sidi Mohamed Ben Abdellah Univ, High Normal Sch, Dept Math & Comp Sci, Fes, Morocco.
   [Hmamed, Abdelaziz] Campus Private Univ Fez, Fes 30040, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Ibn Zohr University of
   Agadir; Sidi Mohamed Ben Abdellah University of Fez
RP Kririm, S (corresponding author), Ibn Zohr Univ, Higher Sch Technol Guelmim, Lab Mat Signals Syst & Phys Modeling, Agadir, Morocco.
EM Amal.zouhri@usmba.ac.ma; s.kririm@uiz.ac.ma;
   mostafa.elmallahi@usmba.ac.ma; hmamed@upf.ac.ma
CR Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Amakdouf H, 2020, MULTIMED TOOLS APPL, V79, P26571, DOI 10.1007/s11042-020-09120-0
   Amakdouf H, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Boukili B, 2022, PATTERN ANAL APPL, V25, P63, DOI 10.1007/s10044-021-01030-7
   Boukili B, 2021, OPTIM CONTR APPL MET, V42, P1337, DOI 10.1002/oca.2730
   Boyd S., 1994, LINEAR MATRIX INEQUA, V1st
   BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412
   Chen L, 2022, INT J COMPUT VISION, V25, P567, DOI 10.9876543210
   CHO ZH, 1977, IEEE T NUCL SCI, V24, P886, DOI 10.1109/TNS.1977.4328803
   El Mallahi M., 2017, Pattern Recognition and Image Analysis, V27, P810
   El Mallahi M, 2017, PATTERN RECOGNITION
   El Mallahi M, 2018, NEURAL COMPUT APPL, V30, P2283, DOI 10.1007/s00521-016-2782-x
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P169, DOI 10.1007/s11633-017-1105-8
   El Mallahi M, 2018, MULTIMED TOOLS APPL, V77, P6583, DOI 10.1007/s11042-017-4573-5
   Griffa A., 2010, GIT Imaging Microscopy, V12, P43
   Hmamed A, 2014, 15 INT C SCI TECHN A
   Kririm Said, 2015, WSEAS Transactions on Systems and Control, V10, P396
   Kririm S, 2016, PROC 5 INT C SYST CO
   Kririm S, 2019, 8 INT C SYSTEMS CONT
   Kririm S, 2021, NEURAL COMPUT APPL, V33, P16865, DOI 10.1007/s00521-021-06533-2
   Kririm S, 2016, CIRC SYST SIGNAL PR, V35, P1579, DOI 10.1007/s00034-015-0139-9
   Kririm S, 2015, CIRC SYST SIGNAL PR, V34, P2213, DOI 10.1007/s00034-015-9967-x
   Kurka D. Burth, 2020, INT ZURICH SEMINAR I, P90
   Lacerda MJ, 2011, SIGNAL PROCESS, V91, P1115, DOI 10.1016/j.sigpro.2010.10.013
   Lu WS., 1992, TOW DIMENSIONAL DIGI
   Mallahi ME, 2021, MULTIMED TOOLS APPL, V80, P25965, DOI 10.1007/s11042-021-10845-9
   McNally JG, 1999, METHODS, V19, P373, DOI 10.1006/meth.1999.0873
   Mesbah A, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0113-8
   Patwary N, 2015, BIOMED OPT EXPRESS, V6, P3826, DOI 10.1364/BOE.6.003826
   Poczekajlo P, 2018, IET SIGNAL PROCESS, V12, P857, DOI 10.1049/iet-spr.2017.0450
   Sarder P, 2006, IEEE SIGNAL PROC MAG, V23, P32, DOI 10.1109/MSP.2006.1628876
   Smith John., 2023, Journal of Software Engineering, V15, P123, DOI DOI 10.1080/78901234.2023.456789
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766
   TSUI ET, 1979, IEEE T NUCL SCI, V26, P2687, DOI 10.1109/TNS.1979.4330513
   Xiao GQ, 2020, J PARALLEL DISTR COM, V141, P49, DOI 10.1016/j.jpdc.2020.03.012
   Xie LH, 2002, IEEE T SIGNAL PROCES, V50, P2319, DOI 10.1109/TSP.2002.800401
   Xu JL, 2022, IEEE T CIRC SYST VID, V32, P2315, DOI 10.1109/TCSVT.2021.3082521
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Zhang H, 2023, P IEEE C COMP VIS PA, P1234, DOI 10.0123456789
NR 39
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19817
EP 19840
DI 10.1007/s11042-023-15374-1
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800008
DA 2024-07-18
ER

PT J
AU Nagdeote, S
   Prabhu, S
AF Nagdeote, Sushma
   Prabhu, Sapna
TI A model to perform prediction based on feature extraction of
   histopathological images of the breast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BRCA; Features; Mathematical Model; Machine Learning; Classification;
   Data-Driven Simulation
ID CANCER; CLASSIFICATION; SEGMENTATION; DATASET; NUCLEI
AB One of the most common and life-threatening cancers is that of the breast among women. The first step to successful treatment and better survival rates for breast cancer patients is prompt and precise assessment of cancer. Predicting cancer from biopsy images is challenging task. In the past few years, machine learning (ML), deep learning (DL), forecasting and response to the treatment therapy models were developed by several researchers to examine breast cancer histopathology images to boost the diagnostic precision. Current exemplar incorrectly classifies false positive pixels and does not extensively make use of existing clinical data. This paper proposes a novel mathematical model for breast cancer (BRCA) prediction. Additionally, the proposed model is integrated with ML approach to improve the accuracy of prediction. Mathematical models are fed with features of breast cancer cells and classify them into benign and malignant cases. We used publicly accessible dataset of BRCA histopathology images to test the proposed method. Different ML models were used to classify the extracted features. It was found that proposed mathematical model combined with different machine learning techniques achieved superior performance. This approach can be diversified to different cancer types and imaging modalities. In a nutshell, the proposed method has a lot of potential for enhancing the precision and efficacy of BRCA using histopathology images.
C1 [Nagdeote, Sushma; Prabhu, Sapna] Fr Conceicao Rodrigues Coll Engn, Mumbai, Maharashtra, India.
RP Nagdeote, S (corresponding author), Fr Conceicao Rodrigues Coll Engn, Mumbai, Maharashtra, India.
EM sushman@fragnel.edu.in
RI Nagdeote, Sushma/ABY-8706-2022
OI Nagdeote, Sushma/0000-0002-7701-4916
CR Abernathy K, 2020, DIFFER EQUAT DYN SYS, V28, P791, DOI 10.1007/s12591-017-0346-x
   Agossou C, 2022, MATH BIOSCI ENG, V19, P1697, DOI 10.3934/mbe.2022080
   Alameddine AK, 2018, CANCER INFORM, V17, DOI 10.1177/1176935118799754
   Benzekry S, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003800
   Bian K, 2020, FRONT GENET, V11, DOI 10.3389/fgene.2020.566057
   Botesteanu DA, 2016, WIRES SYST BIOL MED, V8, P337, DOI 10.1002/wsbm.1343
   Carvalho RHD, 2020, INT CONF SYST SIGNAL, P39, DOI [10.1109/iwssip48289.2020.9145129, 10.1109/IWSSIP48289.2020.9145129]
   de Matos J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10050562
   Esener II, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3895164
   Fathoni MIA, 2019, AIP CONF PROC, V2192, DOI 10.1063/1.5139153
   Fukuma K, 2016, PROCEDIA COMPUT SCI, V96, P1202, DOI 10.1016/j.procs.2016.08.164
   Gu YC, 2019, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2019), P186, DOI 10.1145/3310986.3311010
   Hao Y, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.657560
   Hasan MK, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P574, DOI 10.1109/ICIEV.2016.7760068
   Huang QH, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3088421
   Huang QH, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101657
   Jarrett AM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49073-5
   Kumar A, 2020, CANCER MANAG RES, V12, P4573, DOI 10.2147/CMAR.S248166
   Kumar N, 2017, IEEE T MED IMAGING, V36, P1550, DOI 10.1109/TMI.2017.2677499
   Kumar Rajesh, 2015, J Med Eng, V2015, P457906, DOI 10.1155/2015/457906
   Li J, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152322
   Mirzaei NM, 2021, J PERS MED, V11, DOI 10.3390/jpm11101031
   Mittal S, 2018, EXPERT REV MOL DIAGN, V18, P227, DOI 10.1080/14737159.2018.1439382
   Nagdeote S, 2023, INT C POWER INSTRUME, P1, DOI [10.1109/PIECON56912.2023.10085880, DOI 10.1109/PIECON56912.2023.10085880]
   Namazi H, 2015, SCI REP-UK, V5, DOI 10.1038/srep13583
   Naser MA., 2018, J BIOMED SCI, V7, P5, DOI [10.4172/2254-609X.100084, DOI 10.4172/2254-609X.100084]
   Nave O, 2020, INT J COMPUT MATH-CO, V5, P159, DOI 10.1080/23799927.2020.1792552
   Nave O, 2020, BIOSYSTEMS, V197, DOI 10.1016/j.biosystems.2020.104191
   Novitasari D.C.R., 2019, Advances in Science, Technology and Engineering Systems Journal (ASTESJ), V4, P115, DOI [10.25046/astesj, DOI 10.25046/AJ040413]
   Oke SI, 2018, MATH COMPUT APPL, V23, DOI 10.3390/mca23020021
   Piretto E, 2020, MATH MODEL NAT PHENO, V15, DOI 10.1051/mmnp/2019031
   Qiao MY, 2022, IEEE J BIOMED HEALTH, V26, P3059, DOI 10.1109/JBHI.2022.3140236
   Rockne RC, 2019, JCO CLIN CANCER INFO, V3, DOI 10.1200/CCI.19.00010
   Roy SD, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113628
   Sahran S, 2018, BREAST CANC SURG, DOI [10.5772/intechopen.79446, DOI 10.5772/INTECHOPEN.79446]
   Sharma S, 2020, J DIGIT IMAGING, V33, P632, DOI 10.1007/s10278-019-00307-y
   Shubhangi AJ, 2021, LIBR PHILOS PRACT E, P5376
   Solís-Pérez JE, 2019, CHAOS SOLITON FRACT, V127, P38, DOI 10.1016/j.chaos.2019.06.027
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Tabassum S, 2019, J PHYS CONF SER, V1366, DOI 10.1088/1742-6596/1366/1/012018
   Yan R, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-020-01340-6
   Zarella MD, 2019, ARCH PATHOL LAB MED, V143, P222, DOI 10.5858/arpa.2018-0343-RA
NR 42
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18119
EP 18146
DI 10.1007/s11042-023-16245-5
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700005
DA 2024-07-18
ER

PT J
AU Zahid, A
   Qasim, T
   Bhatti, N
   Zia, M
AF Zahid, Ariba
   Qasim, Tehreem
   Bhatti, Naeem
   Zia, Muhammad
TI A data-driven approach for road accident detection in surveillance
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Road accident detection; Video surveillance; Transfer
   learning; Data preparation
ID ABNORMAL EVENT DETECTION; INTELLIGENCE; ALGEBRA
AB The use of machine learning and computer vision techniques for detecting road accidents is a challenging task due to the limited availability of accident data for training. Staging fake accidents with real cars is expensive, and car crashes are rare incidents in roadside CCTV footage. Therefore, simulating fake car crashes using computers can be a feasible option. As such, we look at the following question in this paper; how successful can manually generated fake accident data be in terms of enabling a machine learning algorithm to detect real accidents?. In this work, we manually construct fake accident video frames from normal video traffic footage by creating simulated accidents. We do so by following predefined principles that maintain consistency with the scene context of normal frames. In order to detect real accidents in video footage, we fine-tune pre-trained deep convolutional neural networks on the manually generated fake accident frames. We use four pre-trained models i.e., AlexNet, GoogleNet, SqueezeNet and ResNet-50 on both normal and abnormal traffic video frames during the learning phase. The experimental results show that the fine-tuned AlexNet outperforms other models providing an 80% percent true positive rate when detecting anomalies (accidents) in real-world surveillance videos of UCF-Crime dataset. This demonstrates the validity of our hypothesis that simulated accident data could be valuable for training machine learning algorithms to detect real-world accidents.
C1 [Zahid, Ariba; Bhatti, Naeem; Zia, Muhammad] Quaid i Azam Univ, Dept Elect, Islamabad, Pakistan.
   [Qasim, Tehreem] SZABIST, Dept Comp Sci, Islamabad, Pakistan.
C3 Quaid I Azam University; Shaheed Zulfikar Ali Bhutto Institute of
   Science & Technology
RP Qasim, T (corresponding author), SZABIST, Dept Comp Sci, Islamabad, Pakistan.
EM dr.tehreem@szabist-isb.edu.pk
RI Zia, Muhammad/C-8412-2013
CR Amin MS, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P640, DOI 10.1109/ICIEV.2012.6317382
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Biradar K, 2019, ARXIV
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   crcv.ucf, US
   GUPTA A, 2022, MULTIMED TOOLS APPL, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang XH, 2020, ACM TRANS SPAT ALGOR, V6, DOI 10.1145/3373647
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ilyas Z, 2021, MULTIMED TOOLS APPL, V80, P24053, DOI 10.1007/s11042-021-10785-4
   Ki YK, 2007, IEEE T INTELL TRANSP, V8, P188, DOI 10.1109/TITS.2006.890070
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DH, 2022, PATTERN RECOGN LETT, V156, P183, DOI 10.1016/j.patrec.2022.03.004
   Li NN, 2022, NEUROCOMPUTING, V481, P154, DOI 10.1016/j.neucom.2022.01.026
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Ma X, 2022, COMPUT INTEL NEUROSC
   Mohammadi S, 2016, LECT NOTES COMPUT SC, V9911, P3, DOI 10.1007/978-3-319-46478-7_1
   Nasaruddin N, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00365-y
   Parvathy R, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC 2013), P58, DOI 10.1109/ICACC.2013.18
   Prabakaran A, 2019, 2019 FIFTEENTH INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICINPRO): INTERNET OF THINGS, P34, DOI 10.1109/icinpro47689.2019.9092161
   Qasim T, 2021, INT C PATT RECOG, P2763, DOI 10.1109/ICPR48806.2021.9412953
   Qasim T, 2019, PATTERN RECOGN LETT, V128, P220, DOI 10.1016/j.patrec.2019.09.003
   Qasim T, 2019, MATH COMPUT SIMULAT, V166, P245, DOI 10.1016/j.matcom.2019.05.014
   Rasheed N, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P61, DOI 10.1109/WAINA.2014.18
   Ryan D., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P230, DOI 10.1109/AVSS.2011.6027327
   Singh D, 2019, IEEE T INTELL TRANSP, V20, P879, DOI 10.1109/TITS.2018.2835308
   Singh Karuna, 2022, Mycotoxins and mycotoxicoses, P1, DOI 10.1007/978-981-19-2370-8_1
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan HL, 2016, INT CONF ACOUST SPEE, P1976, DOI 10.1109/ICASSP.2016.7472022
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Vatti NR, 2018, 2018 INT C CURRENT T, P1, DOI DOI 10.1109/ICCTCT.2018.8551179
   Wei J, 2018, IEEE COMPUT SOC CONF, P129, DOI 10.1109/CVPRW.2018.00025
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P1198, DOI 10.1109/TITS.2016.2601655
   Zhang Q, 2022, MULTIMED TOOLS APPL, P1
   Zhu Yi, 2019, BMVC
NR 40
TC 2
Z9 2
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17217
EP 17231
DI 10.1007/s11042-023-16193-0
EA JUL 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035582300007
DA 2024-07-18
ER

PT J
AU Mittal, P
   Sharma, A
   Singh, R
AF Mittal, Payal
   Sharma, Akashdeep
   Singh, Raman
TI Deep learning based high performance classification architecture for
   low-altitude aerial images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Object classification; Dilated convolutions; Feature
   fusion; Aerial data; Computer vision
ID NEURAL-NETWORK; PLANT; FEATURES; UAVS
AB One of the major factors creating advance prospects in the aerial imaging classification solutions market is the recently published drone policies by Government of India and availability of artificial intelligence-based technologies. The images in low-altitude aerial datasets are inherently different from standard datasets in terms of the appearance cues and the number of bounding box hypotheses. The appearance cues exist due to the present challenges in low-altitude aerial images such as change in viewpoints, arbitrarily orientation and occluded objects. The wide coverage of objects in low-altitude aerial images accounts for a large number of objects in aerial images resulting in complex and multiple bounding boxes. These challenges trigger a need for powerful classification architectures for low-altitude aerial images. This research paper discusses high-performance classification technique based on powerful feature extractor proposed for low-altitude aerial images. The proposed classification architecture makes use of the new improved VGG16 network and dilated ResNet50 model in which fusion takes place between various transformed feature maps. The fusion helps in embedding extra semantic information which further aids in accurate classification of low-altitude aerial images. The performance evaluation is done on approximately 23 k images with different classes of objects gathered from various benchmark low-altitude aerial datasets. The proposed classification architecture achieved a validation accuracy of 99.70% and test-set accuracy of 96.23% which is better than other classification models.
C1 [Mittal, Payal] Thapar Inst Engn & Technol, Patiala, India.
   [Sharma, Akashdeep] Panjab Univ Chandigarh, UIET, Chandigarh, India.
   [Singh, Raman] Univ West Scotland, Cyber Secur, Paisley, Lanark, Scotland.
C3 Thapar Institute of Engineering & Technology; Panjab University;
   University of West Scotland
RP Sharma, A (corresponding author), Panjab Univ Chandigarh, UIET, Chandigarh, India.
EM payalmittal6792@gmail.com; akashdeep@pu.ac.in; raman.singh@uws.ac.uk
OI mittal, payal/0000-0001-6187-7509
CR Adams S.M., 2011, 9 INT WORKSHOP REMOT, P8
   Al-Dosari K, 2023, STUD COMPUT INTELL, V1056, P793, DOI 10.1007/978-3-031-12382-5_43
   AL-Dosari K, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7030210
   Amarasinghe A, 2017, PROCEEDINGS OF THE 15TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS'17), DOI 10.1145/3131672.3136986
   Andrew W, 2017, IEEE INT CONF COMP V, P2850, DOI 10.1109/ICCVW.2017.336
   Audebert N, 2016, ARXIV
   Bah MD, 2019, ADV INTELL SYST, V857, P176, DOI 10.1007/978-3-030-01177-2_13
   Baykara HC, 2017, PROC INT C TOOLS ART, P945, DOI 10.1109/ICTAI.2017.00145
   Bazi Y, 2019, INT GEOSCI REMOTE SE, P2443, DOI [10.1109/IGARSS.2019.8898895, 10.1109/igarss.2019.8898895]
   Boonpook W, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113921
   Caglayan A, 2013, LECT NOTES COMPUT SC, V8157, P161, DOI 10.1007/978-3-642-41184-7_17
   Chew R, 2020, DRONES-BASEL, V4, DOI 10.3390/drones4010007
   Du DW, 2019, IEEE INT CONF COMP V, P213, DOI 10.1109/ICCVW.2019.00030
   George Eobin Alex, 2013, 2013 IEEE Global Humanitarian Technology Conference: South Asia Satellite (GHTC-SAS), P270, DOI 10.1109/GHTC-SAS.2013.6629929
   Hanni A, 2017, 2017 INT C TECHNOLOG, P1, DOI DOI 10.1109/TAPENERGY.2017.8397254
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heidari A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571728
   Hsieh MR, 2017, IEEE I CONF COMP VIS, P4165, DOI 10.1109/ICCV.2017.446
   Huang HS, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196302
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Kanellakis C, 2017, J INTELL ROBOT SYST, V87, P141, DOI 10.1007/s10846-017-0483-z
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
   Kim BK, 2017, IEEE GEOSCI REMOTE S, V14, P38, DOI 10.1109/LGRS.2016.2624820
   Kyrkou C, 2020, IEEE J-STARS, V13, P1687, DOI 10.1109/JSTARS.2020.2969809
   Lalrochunga D, 2020, J DISCRET MATH SCI C, V23, P237, DOI 10.1080/09720529.2020.1721887
   Li Suhao, 2018, Procedia Computer Science, V131, P564, DOI 10.1016/j.procs.2018.04.281
   Liang Yilong., 2016, 2016 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), P1, DOI DOI 10.1109/AIPR.2016.8010600
   Liu H., 2018, IOP Conference Series: Materials Science and Engineering, V322
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Long J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167365
   Margapuri V, 2021, 20TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2021), P116, DOI 10.1109/ICMLA52953.2021.00026
   Marmanis D, 2016, ISPRS ANN PHOTO REM, V3, P473, DOI 10.5194/isprsannals-III-3-473-2016
   Mehta PL, 2021, WIRELESS PERS COMMUN, V118, P301, DOI 10.1007/s11277-020-08014-6
   Miller A, 2008, LECT NOTES COMPUT SC, V4625, P215
   Mittal P, 2022, EXPERT SYST APPL, V199, DOI 10.1016/j.eswa.2022.117106
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Motlagh NH, 2017, IEEE COMMUN MAG, V55, P128, DOI 10.1109/MCOM.2017.1600587CM
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Natesan S., 2019, International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives, V42, P475, DOI [DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W13-475-2019, 10.5194/isprs-archives-XLII-2-W13-475-2019]
   Puri A., 2005, Ph.D. dissertation, P1
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seidaliyeva U, 2020, 2020 FOURTH IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2020), P465, DOI 10.1109/IRC.2020.00088
   Semsch E, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P82
   Shah STH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167614
   Shirvani RA, 2015, ARAB J SCI ENG, V40, P397, DOI 10.1007/s13369-014-1444-5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soleimani A, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1005, DOI 10.23919/ICIF.2018.8455494
   Sommer L, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Srivastava Saurabh, 2020, Proceedings of UASG 2019. Unmanned Aerial System in Geomatics. Lecture Notes in Civil Engineering (LNCE 51), P315, DOI 10.1007/978-3-030-37393-1_27
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang J, 2014, ARAB J SCI ENG, V39, P8409, DOI 10.1007/s13369-014-1368-0
   Tetila EC, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105836, 10.1016/j.compag.2020.105836]
   Treneska S, 2021, P 18 INT C INF INF T, P1
   Umair M, 2021, ARAB J SCI ENG, V46, P5179, DOI 10.1007/s13369-020-05199-7
   Varghese A, 2017, IEEE IJCNN, P1681, DOI 10.1109/IJCNN.2017.7966053
   Wang JW, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P439, DOI 10.23919/ICIF.2018.8455565
   Wu Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030871
   Xu YZ, 2017, J ADV TRANSPORT, DOI 10.1155/2017/2823617
   Yalcin H, 2016, INT CONF AGRO-GEOINF, P233
   Yang Liu, 2018, 2018 IEEE Third International Conference on Data Science in Cyberspace (DSC). Proceedings, P317, DOI 10.1109/DSC.2018.00052
   Yang WG, 2021, COMPUT ELECTRON AGR, V180, DOI 10.1016/j.compag.2020.105866
   Yin R, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE, COMPUTER TECHNOLOGY AND TRANSPORTATION (ISCTT 2020), P238, DOI 10.1109/ISCTT51595.2020.00048
   Yousefi E, 2017, COMPUT ELECTRON AGR, V140, P70, DOI 10.1016/j.compag.2017.05.031
   Yu F., 2015, ARXIV
   Zhang JS, 2017, INT CONF MACH LEARN, P189
   Zhang XD, 2019, IEEE INT CONF COMP V, P118, DOI 10.1109/ICCVW.2019.00020
   Zhao ZF, 2018, ACSR ADV COMPUT, V78, P1
   Zortea BH, 2018, C GRAPH PATT IM 31 S, P1
NR 70
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16849
EP 16868
DI 10.1007/s11042-023-16195-y
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001032703400002
DA 2024-07-18
ER

PT J
AU Tian, RJ
   Li, JJ
   Zhang, WS
   Wang, F
AF Tian, Ruijie
   Li, Jiajun
   Zhang, Weishi
   Wang, Fei
TI A distributed framework for large-scale semantic trajectory similarity
   join
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic trajectory; Similarity join; Distributed process
ID TOP-K; SEARCH
AB The similarity join is a common yet expensive operator for large-scale semantic trajectories analytics. In this paper, we propose DFST, an efficient framework for semantic trajectory similarity join in distributed systems. We devise ITS index and summary index, which consider textual, temporal, and spatial domains, and theoretically demonstrate that they can effectively prune pairs of dissimilar trajectories. Moreover, DFST can support most existing similarity functions to quantify the spatial similarity between semantic trajectories. We have conducted extensive experiments on real world datasets, and experimental results show that DFST achieves a 13.6% improvement of join performance compared to existing semantic trajectory similarity join methods.
C1 [Tian, Ruijie; Li, Jiajun; Zhang, Weishi; Wang, Fei] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian 116026, Liaoning, Peoples R China.
   [Zhang, Weishi; Wang, Fei] Key Lab Intelligent Software, Dalian 116026, Liaoning, Peoples R China.
C3 Dalian Maritime University
RP Zhang, WS; Wang, F (corresponding author), Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian 116026, Liaoning, Peoples R China.; Zhang, WS; Wang, F (corresponding author), Key Lab Intelligent Software, Dalian 116026, Liaoning, Peoples R China.
EM trj@dlmu.edu.cn; jiajunli@dlmu.edu.cn; teesiv@dlmu.edu.cn;
   feiwang@dlmu.edu.cn
RI Li, Jiajun/ABH-1814-2021
OI Tian, Ruijie/0000-0001-8913-9057
FU National Key Research and Development Program of China [2020YFF0410947];
   National Natural Science Foundation of China [62103072]; China
   Postdoctoral Science Foundation [2021M690502]; Fundamental Research
   Funds for the Central Universities [3132022647]
FX AcknowledgementsThis work was supported by the National Key Research and
   Development Program of China (2020YFF0410947) and the National Natural
   Science Foundation of China (62103072). Additional funding was provided
   by the China Postdoctoral Science Foundation (2021M690502) and
   Fundamental Research Funds for the Central Universities (3132022647).
CR Alarabi Louai, 2018, SIGSPATIAL Special, V10, P2, DOI 10.1145/3307599.3307601
   Alarabi Louai., 2017, Proceedings of the 2017 ACM International Conference on Management of Data, P40
   [Anonymous], 2013, P 16 INT C EXT DAT T
   Belesiotis A, 2018, VLDB J, V27, P297, DOI 10.1007/s00778-018-0498-5
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bouros P, 2012, PROC VLDB ENDOW, V6, P1
   Chen L, 2005, P 2005 ACM SIGMOD IN, P491, DOI [10.1145/1066157.1066213, DOI 10.1145/1066157.1066213]
   Chen LS, 2020, PROC INT CONF DATA, P997, DOI 10.1109/ICDE48307.2020.00091
   Ding H, 2008, PROC VLDB ENDOW, V1, P1542
   Ferrante M, 2019, THEORETICAL APPL STA, P91, DOI [10.1007/978-3-030-05420-5_10, DOI 10.1007/978-3-030-05420-5_10]
   Hu HQ, 2016, IEEE T KNOWL DATA EN, V28, P551, DOI 10.1109/TKDE.2015.2485213
   Li RY, 2023, IEEE T KNOWL DATA EN, V35, P1013, DOI 10.1109/TKDE.2021.3079880
   Liu S, 2012, CIKM, P2194, DOI 10.1145/2396761.2398600
   Liu ST, 2014, IEEE T KNOWL DATA EN, V26, P2354, DOI 10.1109/TKDE.2013.83
   Mark DeBerg., 2008, Computational geometry: algorithms and applications
   Parent C, 2021, SEMANTIC TRAJECTORIE, V45, P42, DOI [10.1145/2501654.2501656, DOI 10.1145/2501654.2501656]
   Rao J., 2014, Proc of the 3rd ACM Int. Workshop on Analytics for Big Geospatial Data, P40
   Shang S, 2018, VLDB J, V27, P395, DOI 10.1007/s00778-018-0502-0
   Shang ZY, 2018, INT CONF MANAGE DATA, P725, DOI 10.1145/3183713.3183743
   Ta N, 2017, IEEE T KNOWL DATA EN, V29, P870, DOI 10.1109/TKDE.2017.2651821
   Tampakis P, 2020, ACM TRANS SPAT ALGOR, V6, DOI 10.1145/3373642
   Toohey K., 2015, SIGSPA-TIAL Special, V7, P43
   Vu T, 2018, 26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018), P532, DOI 10.1145/3274895.3274984
   Wang N, 2020, DISTRIB PARALLEL DAT, V38, P649, DOI 10.1007/s10619-020-07289-9
   Wang X, 2017, VLDB J, V26, P301, DOI 10.1007/s00778-016-0453-2
   Wang XY, 2013, DATA MIN KNOWL DISC, V26, P275, DOI 10.1007/s10618-012-0250-5
   Yang SY, 2017, VLDB J, V26, P151, DOI 10.1007/s00778-016-0445-2
   Yuan J, 2013, IEEE T KNOWL DATA EN, V25, P220, DOI 10.1109/TKDE.2011.200
   Zhang Y, 2014, IEEE NETWORK, V28, P52, DOI 10.1109/MNET.2014.6863132
   Zheng BL, 2014, IEEE INT CONF MOB DA, P259, DOI 10.1109/MDM.2014.38
   Zheng BL, 2015, PROC INT CONF DATA, P975, DOI 10.1109/ICDE.2015.7113349
   Zheng K, 2017, WORLD WIDE WEB, V20, P749, DOI 10.1007/s11280-016-0414-0
   Zheng K, 2013, PROC INT CONF DATA, P230, DOI 10.1109/ICDE.2013.6544828
NR 35
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16205
EP 16229
DI 10.1007/s11042-023-15236-w
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yaganoglu, M
   Bozkurt, F
   Günay, FB
   Kul, S
   Simsek, E
   Öztürk, G
   Karaman, S
AF Yaganoglu, Mete
   Bozkurt, Ferhat
   Gunay, F. Baturalp
   Kul, Sinan
   Simsek, Emrah
   Ozturk, Goekhan
   Karaman, Selcuk
TI Design and validation of IoT based smart classroom
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE New generation classroom; Smart classroom; Anomaly detection; IoT
ID PHYSICAL-ENVIRONMENT; INTERNET; SYSTEM; THINGS; UNIVERSITY; QUALITY;
   SCHEME; IMPACT
AB The smart campus is an educational campus concept that uses innovative technologies such as the Internet of Things (IoT), cloud computing, with integrated information systems to support learning, teaching and administrative activities. It is one of the important outputs of smart campus applications that these technologies support students, lecturers, and administrators by performing multi-tasking in multi-functional buildings. It is an important step to create smart classrooms with intelligent systems with the aim of developing a smart campus. For this reason, it is necessary to create smart classrooms for a smart campus and to expand it throughout the campus. In this study, it is aimed to monitor the environmental parameters in the classroom environments in real time and to develop a smart classroom concept that provides energy savings and air conditioning based on the analysis of these data. It is expected that an educational effect will occur on the attention span of the students through the automatic improvement of physical conditions as well as administrative convenience in terms of ensuring security and increasing savings in company with an efficient and applicable system architecture. In this study, tests were performed for 7 different scenarios and the best accuracy and sensitivity were calculated as 98%, and the best specifity as 100%.
C1 [Yaganoglu, Mete; Bozkurt, Ferhat; Gunay, F. Baturalp] Ataturk Univ, Fac Engn, Dept Comp Engn, Erzurum, Turkiye.
   [Kul, Sinan] Ataturk Univ, Fac Open Educ, Erzurum, Turkiye.
   [Simsek, Emrah] Erzurum Tech Univ, Fac Engn, Comp Engn, Erzurum, Turkiye.
   [Ozturk, Goekhan] Ataturk Univ, Fac Engn, Elect & Elect Engn, Erzurum, Turkiye.
   [Karaman, Selcuk] Ankara Haci Bayram Veli Univ, Dept Management Informat Syst, Ankara, Turkiye.
C3 Ataturk University; Ataturk University; Erzurum Technical University;
   Ataturk University; Ankara Haci Bayram Veli University
RP Yaganoglu, M (corresponding author), Ataturk Univ, Fac Engn, Dept Comp Engn, Erzurum, Turkiye.
EM yaganoglu@atauni.edu.tr; fbozkurt@atauni.edu.tr; baturalp@atauni.edu.tr;
   sinan.kul@atauni.edu.tr; emrah.simsek@erzurum.edu.tr;
   gokhan.ozturk@atauni.edu.tr; selcuk.karaman@hbv.edu.tr
RI Bozkurt, Ferhat/GYR-3398-2022; Simsek, Emrah/KLC-5191-2024; KUL,
   Sinan/ABH-8290-2020
OI Bozkurt, Ferhat/0000-0003-0088-5825; Simsek, Emrah/0000-0002-1652-9553;
   KUL, Sinan/0000-0002-7824-756X; KARAMAN, SELCUK/0000-0002-0493-3444;
   ozturk, gokhan/0000-0001-8106-0053
FU Atatuuml;rk University Scientific Research Projects Coordination Unit
   [FOA-2020-7563]
FX AcknowledgementsThis study was supported by Ataturk University
   Scientific Research Projects Coordination Unit. Project number:
   FOA-2020-7563.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdel-Basset M, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4515
   Aju O.G., 2015, Int. J. Comput. Appl, V130, P47
   Albarakati AJ., 2014, INT J COMPUTER SCI M, V3, P558
   Aldowah H, 2017, J PHYS CONF SER, V892, DOI 10.1088/1742-6596/892/1/012017
   [Anonymous], 1988, INT J LIFELONG EDUC, DOI DOI 10.1080/0260137880070303
   [Anonymous], 2017, 2017 GLOBAL INTERNET, DOI DOI 10.1109/GIOTS.2017.8016214
   Anoopa S, 2022, MATER TODAY-PROC, V58, P162, DOI 10.1016/j.matpr.2022.01.171
   Bagheri M, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P435, DOI 10.1109/SITIS.2016.74
   Brittany A, 2011, CLASSROOM ENV SILENT
   Cata M, 2015, ROEDUNET IEEE, P195, DOI 10.1109/RoEduNet.2015.7311993
   Chen Yinjie., 2011, WOWMOM, P1, DOI DOI 10.1109/WICOM.2011.6040344
   CHENG YC, 1994, J EXP EDUC, V62, P221, DOI 10.1080/00220973.1994.9943842
   Coley D.A., 2002, Int. J. Vent., V1, P45, DOI [10.1080/14733315.2002.11683621, DOI 10.1080/14733315.2002.11683621]
   Darbyshire JL, 2013, CRIT CARE, V17, DOI 10.1186/cc12870
   Enugala VPR, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P193, DOI 10.1109/PDGC.2018.8745883
   Gao J, 2014, LECT NOTES ELECTR EN, V261, P203, DOI 10.1007/978-3-642-39584-0_23
   Garg R, 2018, WIRELESS PERS COMMUN, V103, P2019, DOI 10.1007/s11277-018-5894-z
   Goldena NJ, 2022, ESSENTIALS INTERNET, P49
   Griffiths M, 2008, ENERG BUILDINGS, V40, P556, DOI 10.1016/j.enbuild.2007.04.013
   Gul S, 2017, INT J COMPUT SCI NET, V17, P159
   Hasan MT., 2020, J MULTIDISCIPLINARY, V7, P12121
   Hentschel K, 2016, 2016 IEEE 4TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2016), P58, DOI 10.1109/FiCloud.2016.16
   Heo YJ, 2015, 2015 3RD INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD) AND INTERNATIONAL CONFERENCE ON OPEN AND BIG (OBD), P526, DOI 10.1109/FiCloud.2015.29
   Hill M.C., 2010, Academy of Educational Leadership Journal, V14, P65
   Huang LS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091837
   Imran K, 2022, CMC-COMPUT MATER CON, V70, P1033, DOI 10.32604/cmc.2022.018589
   Kolokotsa D, 2016, ENERG BUILDINGS, V123, P119, DOI 10.1016/j.enbuild.2016.04.038
   Lajevardi SM, 2012, SIGNAL IMAGE VIDEO P, V6, P159, DOI 10.1007/s11760-010-0177-5
   Lau BPL, 2018, IEEE INTERNET THINGS, V5, P473, DOI 10.1109/JIOT.2017.2748987
   Li BP, 2015, LECT N EDUC TECHNOL, P45, DOI 10.1007/978-3-662-44188-6_6
   Marques G, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030438
   Maxwell L.E., 2002, J MUS EDUC, V27, P3, DOI DOI 10.1080/10598650.2002.11510454
   Murugesan San, 2008, IT Professional, V10, P24, DOI 10.1109/MITP.2008.10
   Palma D, 2014, SENSORS-BASEL, V14, P6998, DOI 10.3390/s140406998
   Poysner LarryR., 1983, An Examination of the Classroom Physical Environment
   Rajagulasingam Christina, 2021, 2021 APWG Symposium on Electronic Crime Research (eCrime), P1, DOI 10.1109/eCrime54498.2021.9738794
   Ramli NH, 2013, PROCD SOC BEHV, V101, P221, DOI 10.1016/j.sbspro.2013.07.195
   Rathore MM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON AUTOMATICA (ICA-ACCA)
   Razzaq AN, 2021, 2021 INT C ADV TECHN, P1, DOI [10.1109/ICOTEN52080.2021.9493444, DOI 10.1109/ICOTEN52080.2021.9493444]
   Revathi AR, 2017, SIGNAL IMAGE VIDEO P, V11, P291, DOI 10.1007/s11760-016-0935-0
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sahin IT, 2011, EGIT ARAST, V11, P185
   Saini MK, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3365757
   Savolainen T, 2013, IEEE SENS J, V13, P3511, DOI 10.1109/JSEN.2013.2259691
   Taylor K., 2008, NEW DIRECTIONS ADULT, V119, P49, DOI DOI 10.1002/ACE.305
   Tomar R, 2021, JAVASCRIPT SYNTAX PR
   Uzelac A, 2018, TELEMAT INFORM, V35, P579, DOI 10.1016/j.tele.2017.06.014
   Uzelac A, 2015, COMPUT HUM BEHAV, V53, P427, DOI 10.1016/j.chb.2015.07.023
   Wang T, 2018, MULTIMED TOOLS APPL, V77, P17375, DOI 10.1007/s11042-017-5309-2
   Wang Y, 2017, 2017 IEEE 8TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (UEMCON), P498, DOI 10.1109/UEMCON.2017.8249106
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   Yang Z, 2013, BUILD ENVIRON, V70, P171, DOI 10.1016/j.buildenv.2013.08.030
   Zhang D., 2017, 2017 C LASERS ELECTR, P1
   Zhang MB, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/5438878
NR 55
TC 0
Z9 0
U1 18
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 13
PY 2023
DI 10.1007/s11042-023-15872-2
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M0YP8
UT WOS:001027492600008
DA 2024-07-18
ER

PT J
AU Li, JR
   Zhou, L
   Chen, J
AF Li, Jiarui
   Zhou, Li
   Chen, Jie
TI MobileFaceFormer: a lightweight face recognition model against face
   variations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; MobileFaceFormer; Deep learning; CNNs; Visual
   transformers
AB In recent years, the study of lightweight models has been one of the most significant application streams of face recognition tasks due to practical life demands. However, typical lightweight face recognition models become less effective when dealing with large face feature variations (e.g. age variation, pose variation). In this paper, we present a lightweight face recognition model, namely MobileFaceFormer. It takes advantage of both convolutional neural networks' (CNNs) effectiveness in capturing local features and visual transformers' effectiveness in computing global dependencies for more enriched and abundant interpretations of facial features. To achieve this, both CNN branches and visual transformer branches are parallelized, and a bi-directional feature fusion bridge connecting dual branches is designed to concurrently retain local facial features and global facial interpretations. To enhance feature interpretations on dual branch, a convolutional token initialization method is proposed at transformer branch to perceive long-range facial information, also depthwise separable convolution and attention mechanisms are adopted at CNN branch to enhance local facial feature extraction. Further, an attentive global depthwise convolution (AGDC) is proposed to encourage the concentration of key facial information. Experiments across state-of-the-art FR datasets show MobileFaceFormer achieves higher recognition performance, e.g. MobileFaceFormer achieves 99.60% at LFW dataset, compared to 99.28 % of MobileFaceNets; Meanwhile, MobileFaceFormer shows more lightweight model complexity, e.g. in terms of computation cost, MobileFaceFormer has 65M Multiply-Accumulate Operations (MAdds) than 221M of MobileFaceNets under similar parameter sizes.
C1 [Li, Jiarui; Zhou, Li; Chen, Jie] Chinese Acad Sci, Inst Microelect, Beijing 100029, Peoples R China.
   [Li, Jiarui] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Microelectronics, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Li, JR; Chen, J (corresponding author), Chinese Acad Sci, Inst Microelect, Beijing 100029, Peoples R China.; Li, JR (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM lijiarui@ime.ac.cn; zhouli@ime.ac.cn; jchen@ime.ac.cn
RI Li, Jiarui/GVS-6633-2022
OI LI, Jiarui/0000-0002-8134-3819
FU National Key Research and Development Program of China [2019YFB2204200];
   National Natural Science Foundation of China( [U1832217]
FX This work was supported by the National Key Research and Development
   Program of China(2019YFB2204200) and National Natural Science Foundation
   of China(U1832217)
CR Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46
   Chen YP, 2022, PROC CVPR IEEE, P5260, DOI 10.1109/CVPR52688.2022.00520
   d'Ascoli S, 2021, PR MACH LEARN RES, V139, DOI 10.1088/1742-5468/ac9830
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Duong CN, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185981
   Graham B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12239, DOI 10.1109/ICCV48922.2021.01204
   Guo J, DATASETZOO
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Han K., 2021, Adv. Neural Inf. Process. Syst., V34, P15908, DOI DOI 10.48550/ARXIV.2103.00112
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, V2
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Li, 2021, PREPRINT
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Luo P, 2016, AAAI CONF ARTIF INTE, P3560
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sengupta S, 2016, IEEE WINT CONF APPL
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Yi D., 2014, PREPRINT
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhang J., 2019, PREPRINT
   Zhang QL, 2021, ADV NEUR IN, V34
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zheng T, 2017, PREPRINT
   Zheng T., 2018, Tech. Rep., V5
   Zhong Y, 2021, PREPRINT
   Zhou D.-W., 2021, PREPRINT
NR 37
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12669
EP 12685
DI 10.1007/s11042-023-15954-1
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001022083300008
DA 2024-07-18
ER

PT J
AU Fan, SJ
   Chen, KK
   Tian, JF
AF Fan, Sujuan
   Chen, Keke
   Tian, Junfeng
TI A novel image encryption algorithm based on coupled map lattices model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; CML model; Intermediate chaotic sequences; Forward
   diffusion; Reverse diffusion
ID RECOMMENDATION SYSTEM; CHAOTIC SYSTEM; DIFFUSION; SEQUENCES
AB This paper proposes a novel image encryption method based on coupled map lattice (CML) model. The main idea of this method is to solve the initial conditions of the CML system by combining the hash value of plaintext image with external keys. Then, the CML system is iterated to produce F intermediate chaotic sequences of f(x) map and X the chaotic sequences of CML system, respectively. The plaintext image is scrambled and diffused by using F chaotic sequences and the X chaotic sequences. Using the intermediate chaotic sequences F generated by CML system can effectively reduce the length of CML system and save the iteration time of chaotic sequence. Moreover, in the diffusion stage, forward diffusion and reverse diffusion are used to diffuse the image, which further enhances the security of the encryption algorithm. Experimental results indicate that the correlation coefficient of adjacent pixels in Lena's cipher image are 0.0005, 0.0065 and 0.0009 in the horizontal, vertical and diagonal directions respectively, and the information entropy is 7.9995, which is closer to ideal value 8. Experimental results and security analysis show that the proposed algorithm has high security performance and can resist various attacks.
C1 [Fan, Sujuan] Henan Univ, Informat Management Off, Kaifeng 475004, Peoples R China.
   [Chen, Keke; Tian, Junfeng] Henan Univ, Key Lab Big Data Anal & Proc Henan Prov, Kaifeng 475004, Peoples R China.
   [Chen, Keke; Tian, Junfeng] Henan Univ, Coll Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Tian, Junfeng] Henan Univ, Henan Prov Engn Res Ctr Spatial Informat Proc, Kaifeng 475004, Peoples R China.
C3 Henan University; Henan University; Henan University; Henan University
RP Tian, JF (corresponding author), Henan Univ, Key Lab Big Data Anal & Proc Henan Prov, Kaifeng 475004, Peoples R China.; Tian, JF (corresponding author), Henan Univ, Coll Comp & Informat Engn, Kaifeng 475004, Peoples R China.; Tian, JF (corresponding author), Henan Univ, Henan Prov Engn Res Ctr Spatial Informat Proc, Kaifeng 475004, Peoples R China.
EM tjf328@126.com
OI TIAN, Jun-feng/0000-0002-9704-0089
FU National Basic Research Program of China [2019YFE0126600]; Major Project
   of Science and Technology of Henan Province [201400210300]
FX AcknowledgementsThis work is supported by grants from National Basic
   Research Program of China [grant number 2019YFE0126600], the Major
   Project of Science and Technology of Henan Province [grant number
   201400210300].
CR Almalkawi IT, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102384
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Demirtas M, 2022, OPTIK, V266, DOI 10.1016/j.ijleo.2022.169624
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Ge X, 2011, PHYS LETT A, V375, P908, DOI 10.1016/j.physleta.2010.12.065
   Hu GZ, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107790
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   KANEKO K, 1985, PROG THEOR PHYS, V74, P1033, DOI 10.1143/PTP.74.1033
   Khan JS, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102711
   Li JY, 2022, OPT LASER TECHNOL, V152, DOI 10.1016/j.optlastec.2022.108127
   Li XJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422500353
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Lyle M, 2022, MULTIMED TOOLS APPL, V81, P8179, DOI 10.1007/s11042-022-11917-0
   Nasir Q., 2012, INT J COMMUN NETW SY, V5, P548
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P9355, DOI 10.1007/s11042-018-6516-1
   Som S, 2013, 2013 1ST INTERNATIONAL CONFERENCE ON EMERGING TRENDS AND APPLICATIONS IN COMPUTER SCIENCE (ICETACS), P108, DOI 10.1109/ICETACS.2013.6691405
   Tian JF, 2021, MULTIMED TOOLS APPL, V80, P32841, DOI 10.1007/s11042-021-11218-y
   Wang XY, 2009, COMMUN NONLINEAR SCI, V14, P574, DOI 10.1016/j.cnsns.2007.10.011
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2021, CHAOS SOLITON FRACT, V143, DOI 10.1016/j.chaos.2020.110582
   Wang XY, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106837
   Wang XY, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110309
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wang XY, 2012, NONLINEAR DYNAM, V67, P365, DOI 10.1007/s11071-011-9984-7
   Wheeler DD., 1989, CRYPTOLOGIA, V13, P243, DOI DOI 10.1080/0161-118991863934
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Yavuz E, 2019, OPT LASER TECHNOL, V114, P224, DOI 10.1016/j.optlastec.2019.01.043
   Ye GD, 2021, NONLINEAR DYNAM, V104, P2807, DOI 10.1007/s11071-021-06422-2
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zheng YF, 2015, MULTIMED TOOLS APPL, V74, P7803, DOI 10.1007/s11042-014-2024-0
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 47
TC 2
Z9 2
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11557
EP 11572
DI 10.1007/s11042-023-15964-z
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015963500001
DA 2024-07-18
ER

PT J
AU Tripathi, VR
   Tibdewal, MN
   Mishra, R
AF Tripathi, Vijay R. R.
   Tibdewal, Manish N. N.
   Mishra, Ravi
TI Denoising of motion artifacted MRI scans using conditional generative
   adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CGAN; Motion artifacted images; Pix2Pix
AB Patient motion causes image distortion during Magnetic Resonance Imaging (MRI) capture. These distorted motion artifact induced MRI scans are difficult to read and sometimes lead to a faulty diagnosis. The simplest solution to remove these artifacts in motion-blurred scans is to re-scan the patient. But this method is costly, time-consuming, and cannot guarantee a successful scan even after re-scanning the MRI, because the patient can still move involuntarily. Hence, correction in the motion artifact induced images is an important part of the medical imaging domain. Here we have modified a well-known conditional Generative Adversarial Network called Pix2Pix for removing motion artifacts from MRI scans. We have modified the structure of the original network and fine-tuned the parameters with the help of a database that we have created. The database was collected from a local hospital consisting of 436 images that include motion artifact induced scans and their corresponding artifact-free scans obtained by re-scanning the patients. The proposed method could achieve RMSE of 0.004 and PSNR of 27.97 dB with accuracy greater than 96 %. We expect that this method will help radiologists to save time and cost of re-scanning and will eventually help the doctors in diagnosis.
C1 [Tripathi, Vijay R. R.; Tibdewal, Manish N. N.; Mishra, Ravi] GH Raisoni Univ, Amaravati 444701, India.
   [Tibdewal, Manish N. N.] Shri St Gajanan Maharaj Coll Engn, Shegoan, India.
   [Mishra, Ravi] GH Raisoni Inst Engn & Technol, Nagpur, India.
RP Tripathi, VR (corresponding author), GH Raisoni Univ, Amaravati 444701, India.
EM vijayrtripathi@rediffmail.com
CR Armanious K, 2019, HELL J NUCL MED, V22, P179, DOI 10.1967/s002449911053
   Bucher SF, 1997, ANN NEUROL, V41, P32, DOI 10.1002/ana.410410108
   Carter KM, 2011, REV FISH BIOL FISHER, V21, P51, DOI 10.1007/s11160-010-9188-0
   Cormier JN, 2004, CA-CANCER J CLIN, V54, P94, DOI 10.3322/canjclin.54.2.94
   Fowler KA, 2001, BRAIN RES PROTOC, V7, P87, DOI 10.1016/S1385-299X(00)00051-9
   GLOVER GH, 1992, MAGNET RESON MED, V28, P275, DOI 10.1002/mrm.1910280209
   Goodfellow I. J., 2014, ARXIV
   Higaki T, 2019, JPN J RADIOL, V37, P73, DOI 10.1007/s11604-018-0796-2
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kidoh M, 2020, MAGN RESON MED SCI, V19, P195, DOI 10.2463/mrms.mp.2019-0018
   Kim BG, 2015, JAMA OTOLARYNGOL, V141, P45, DOI 10.1001/jamaoto.2014.2926
   Kim KH, 2018, RADIOLOGY, V287, P658, DOI 10.1148/radiol.2017171154
   Küstner T, 2019, MAGN RESON MED, V82, P1527, DOI 10.1002/mrm.27783
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Nguyen Xuan V, 2020, Top Magn Reson Imaging, V29, P175, DOI 10.1097/RMR.0000000000000249
   Reuter M, 2015, NEUROIMAGE, V107, P107, DOI 10.1016/j.neuroimage.2014.12.006
   Rotman M, 2021, PROC SPIE, V11595, DOI 10.1117/12.2580869
   Slavkovsky P, 2004, Bratisl Lek Listy, V105, P245
   Thali MJ, 2003, J FORENSIC SCI, V48, P386
   Tian Y, 2020, MAGN RESON MED, V84, P3071, DOI 10.1002/mrm.28337
   Uetani H, 2021, NEURORADIOLOGY, V63, P63, DOI 10.1007/s00234-020-02513-w
   Walker PM, 1998, ARCH PHYS MED REHAB, V79, P1391, DOI 10.1016/S0003-9993(98)90233-7
   Zaitsev M, 2015, J MAGN RESON IMAGING, V42, P887, DOI 10.1002/jmri.24850
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
NR 24
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11923
EP 11941
DI 10.1007/s11042-023-15705-2
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900004
DA 2024-07-18
ER

PT J
AU Balakrishnan, V
   Ramanathan, G
   Zhou, SY
   Wong, CK
AF Balakrishnan, Vimala
   Ramanathan, Ghayathri
   Zhou, Siyi
   Wong, Chee Kuan
TI Optimized support vector regression predicting treatment duration among
   tuberculosis patients in Malaysia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tuberculosis; Treatment duration; Machine learning; Risk factors;
   Malaysia
ID COMBINATIONS; GUIDELINES; CARE
AB Machine learning models have emerged as an advanced tool for predicting diseases and their outcomes. This study developed a machine learning model to predict the treatment duration for Tuberculosis patients in Malaysia based on a real-life patient dataset. Six regression models, namely Support Vector Regression, Linear Regression, Lasso Regression, Ridge Regression, Random Forest Regression, and Gradient Boosting Regression were initially developed and then optimized through hyperparameter tuning to determine the best predictive model. Using a dataset of 435 Malaysian Tuberculosis patients, we compared our results with data from countries with high Tuberculosis prevalence rates, namely Belarus, Nigeria, and Georgia. Experimentations revealed Support Vector Regression emerged as the best performing model as it can predict treatment duration with the lowest error rates (Mean Absolute Error = 69.70; Root Mean Squared Error = 109.49). Eight significant risk factors were identified for the Malaysian dataset through Pearson correlation, namely, treatment outcome, treatment status, fixed dose combination dosage, maintenance phase regimen, chest X-ray findings, tuberculin skin test, location of treatment initiation, and levofloxacin-based regimen. Comparison with data from other countries confirmed the consistent performance of the optimized Support Vector Regression model in predicting Tuberculosis treatment duration, hence rendering the model generalizable. To the best of our knowledge, this is the first study to demonstrates the effectiveness of machine learning in predicting Tuberculosis treatment duration based on potential risk factors. These findings will help clinicians make informed decisions about the optimal treatment duration, prepare patients' expectations, and estimate the cost of Tuberculosis treatment.
C1 [Balakrishnan, Vimala; Ramanathan, Ghayathri; Zhou, Siyi] Univ Malaya, Fac Comp Sci & Informat Technol, Data Sci Res Grp, Kuala Lumpur 50603, Malaysia.
   [Wong, Chee Kuan] Univ Malaya, Fac Med, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya; Universiti Malaya
RP Balakrishnan, V (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Data Sci Res Grp, Kuala Lumpur 50603, Malaysia.
EM vimala.balakrishnan@um.edu.my
RI Wong, Chee Kuan/GRS-1870-2022; Balakrishnan, Vimala/F-4037-2011
OI Wong, Chee Kuan/0000-0002-8678-4664; Balakrishnan,
   Vimala/0000-0002-6859-4488
CR Alsaffar M, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/7424836
   Althomsons SP, 2022, AM J ROENTGENOL, V186, P227
   An L, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030821
   Asad M, 2020, TUBERCULOSIS, V123, DOI 10.1016/j.tube.2020.101944
   Atif M, 2015, PUBLIC HEALTH, V129, P777, DOI 10.1016/j.puhe.2015.04.010
   Avoi R, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18189740
   Awad M., 2015, Neural Information Processing-Letters and Reviews, P67, DOI [DOI 10.1007/978-1-4302-5990-94, 10.1007/978-1-4302-5990-9_4, DOI 10.1007/978-1-4302-5990-9_4]
   Banga A, 2023, INT J SYST ASSUR ENG, V14, P732, DOI 10.1007/s13198-020-01049-9
   Bangalore S, 2007, AM J MED, V120, P713, DOI 10.1016/j.amjmed.2006.08.033
   Bartholomay P, 2016, REV PANAM SALUD PUBL, V39, P3
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Brindha GR, 2022, COMPUT METH PROG BIO, V224, DOI 10.1016/j.cmpb.2022.107027
   Brownlee J, 2019, How to Choose a Feature Selection Method For Machine Learning
   Centers for Disease Control and Prevention, 2020, TARG TB TEST INT SKI
   Chen ML, 2019, EBIOMEDICINE, V43, P356, DOI 10.1016/j.ebiom.2019.04.016
   Govindarajan S, 2021, COMPUT METH PROG BIO, V204, DOI 10.1016/j.cmpb.2021.106058
   Haddad MB, 2020, AM J PREV MED, V58, P858, DOI 10.1016/j.amepre.2019.12.010
   Huang JC, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105536
   Iqbal A, 2022, TUBERCULOSIS, V136, DOI 10.1016/j.tube.2022.102234
   Karumbi J, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003343.pub4
   Kulwant KK., 2020, MALAYSIAN J MED HLTH, V18, P52
   Kumari K., 2018, Journal of the practice of Cardiovascular Sciences, V4, P33, DOI DOI 10.4103/JPCS.JPCS_8_18
   Lai HH, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170104
   Lim RBT, 2020, BMC PUBLIC HEALTH, V20, DOI 10.1186/s12889-019-7969-5
   Luo Y, 2022, J INFECTION, V84, P648, DOI 10.1016/j.jinf.2021.12.046
   Sauer CM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207491
   Meraj S.S., 2019, Int J Adv Sci Eng Infor Tech., V9, P81, DOI [10.18517/ijaseit.9.1.7567, DOI 10.18517/IJASEIT.9.1.7567]
   Mohidem NA, 2021, INT J MICROBIOL, DOI [10.4103/ijmy.ijmy, DOI 10.4103/IJMY.IJMY]
   Nahid P, 2016, CLIN INFECT DIS, V63, pe147, DOI 10.1093/cid/ciw376
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00021
   Norval PY, 1999, INT J TUBERC LUNG D, V3, pS292
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/502007
   Potdar K., 2017, International journal of computer applications, V175, P7, DOI 10.5120/ijca2017915495
   Pusch T, 2014, BMC INFECT DIS, V14, DOI 10.1186/1471-2334-14-115
   Rajendran M, 2020, TUBERCULOSIS, V122, DOI 10.1016/j.tube.2020.101925
   Richesson RL, 2013, J AM MED INFORM ASS, V20
   Rocha MS, 2018, REV PANAM SALUD PUBL, V42, DOI 10.26633/RPSP.2018.112
   Rosenthal A, 2017, J CLIN MICROBIOL, V55, P3267, DOI 10.1128/JCM.01013-17
   Salat R, 2013, COMPUT METH PROG BIO, V111, P330, DOI 10.1016/j.cmpb.2013.04.018
   Schober P, 2018, ANESTH ANALG, V126, P1763, DOI 10.1213/ANE.0000000000002864
   Seo D, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105418
   Sharma A, 2022, BRAZ J INFECT DIS, V26, DOI 10.1016/j.bjid.2022.102332
   Siddiqa A, 2022, CMC-COMPUT MATER CON, V70, P5519, DOI 10.32604/cmc.2022.021666
   Singh H, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228712
   Timimi H, 2012, J AM MED INFORM ASSN, V19, P939, DOI 10.1136/amiajnl-2011-000755
   Tok PSK, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231986
   Wang S., 2016, Encyclopedia of machine learning and data mining, DOI DOI 10.1007/978-1-4899-7502-7_101-1
   World Health Organization, 2022, DRUG RES TB
NR 48
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11831
EP 11844
DI 10.1007/s11042-023-16028-y
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800010
DA 2024-07-18
ER

PT J
AU Han, FR
   Abdelaziz, IIM
   Ghazali, KH
   Zhao, Y
AF Han, Fengrong
   Abdelaziz, Izzeldin Ibrahim Mohamed
   Ghazali, Kamarul Hawari
   Zhao, Yue
TI Effect of fitness function on localization performance in range-free
   localization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor network (WSNs); DV-Hop Localization algorithm;
   Metaheuristic optimization algorithm; Fitness function; Particle Swarm
   Optimization (PSO)
ID DV-HOP; OPTIMIZATION; TOPOLOGY; SEARCH; MODEL
AB The problem of solving the nonlinear equations in the range-free localization algorithm has been transformed into an optimal solution problem. Meta-heuristic optimization method has been widely adopted to tackle above issues. How to choose the best localization fitness function for a specific target is a key factor in determining whether the localization algorithm is accurate or not. However, so far there is no literature to investigate the effect of fitness function on rang-free localization algorithm. Firstly, this study comprehensively reviews and classifies the frequently-used localization fitness function in range-free localization scheme. Next, multiple experiments are carried out for each typical localization fitness function. The experimental results are analyzed in terms of accuracy and stability. Besides, the advantage and disadvantage of each localization fitness function are also given. Finally, an advanced localization fitness function is proposed based on the above experimental results, which will provide a guide and reference for selection and improvement of the fitness function in range-free localization algorithm.
C1 [Han, Fengrong] Baoji Univ Arts & Sci, Sch Comp, Baoji 721000, Peoples R China.
   [Abdelaziz, Izzeldin Ibrahim Mohamed] Univ Malaysia Pahang, Coll Engn, Kuantan 26300, Pahang, Malaysia.
   [Ghazali, Kamarul Hawari] Univ Malaysia Pahang, Fac Elect & Elect Engn, Pekan 26600, Pahang, Malaysia.
   [Zhao, Yue] Baoji Univ Arts & Sci, Coll Geog & Environm, Baoji 721016, Peoples R China.
C3 Baoji University of Arts & Sciences; Universiti Malaysia Pahang
   Al-Sultan Abdullah (UMPSA); Universiti Malaysia Pahang Al-Sultan
   Abdullah (UMPSA); Baoji University of Arts & Sciences
RP Han, FR (corresponding author), Baoji Univ Arts & Sci, Sch Comp, Baoji 721000, Peoples R China.
EM hfr825@163.com
FU Universiti Malaysia Pahang Postgraduate Research Grants [PGRS1903143];
   Natural Science Basic Research Program of Shaanxi [2019JQ-899]; Special
   Scientific Research Project of Shaanxi Provincial Education Department
   [22JK0246]
FX This research is supported by Universiti Malaysia Pahang Postgraduate
   Research Grants, grant number PGRS1903143. This study is also supported
   by the Natural Science Basic Research Program of Shaanxi (No.
   2019JQ-899) and the Special Scientific Research Project of Shaanxi
   Provincial Education Department under Grant (No. 22JK0246).
CR Agrawal P, 2021, IEEE ACCESS, V9, P26766, DOI 10.1109/ACCESS.2021.3056407
   Chai QW, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/9255810
   Chen TF, 2019, J SENSORS, V2019, DOI 10.1155/2019/1464513
   Cui LZ, 2018, APPL SOFT COMPUT, V68, P39, DOI 10.1016/j.asoc.2018.03.036
   Cui ZH, 2017, J PARALLEL DISTR COM, V103, P42, DOI 10.1016/j.jpdc.2016.10.011
   Dokeroglu T, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106040
   Hadir A, 2021, IEEE ACCESS, V9, P149906, DOI 10.1109/ACCESS.2021.3123360
   Han FR, 2020, INT J ONLINE BIOMED, V16, P4, DOI [10.3991/ijoe.v16i08.14379, 10.3991/ijoe.v16108.14379]
   Han GJ, 2016, IEEE COMMUN SURV TUT, V18, P2220, DOI 10.1109/COMST.2016.2544751
   Hao Huang, 2016, 2016 IEEE International Workshop on Electromagnetics (iWEM): Applications and Student Innovation Competition, P1, DOI 10.1109/iWEM.2016.7504919
   Huang HJ, 2017, I C COMM SOFTW NET, P311, DOI 10.1109/ICCSN.2017.8230126
   Huang XM, 2020, COMPUT COMMUN, V152, P282, DOI 10.1016/j.comcom.2020.01.052
   Jacob SS, 2022, CMC-COMPUT MATER CON, V70, P1229, DOI 10.32604/cmc.2022.019019
   Kanwar V, 2021, WIREL NETW, V27, P91, DOI 10.1007/s11276-020-02446-5
   Kanwar V, 2021, J SUPERCOMPUT, V77, P3044, DOI 10.1007/s11227-020-03385-w
   Kanwar V, 2020, J AMB INTEL HUM COMP, V11, P5513, DOI 10.1007/s12652-020-01907-1
   Laoudias C, 2018, IEEE COMMUN SURV TUT, V20, P3607, DOI 10.1109/COMST.2018.2855063
   Lei WL, 2016, INT J FUTUR GENER CO, V9, P289, DOI 10.14257/ijfgcn.2016.9.9.26
   Li JP, 2021, WIREL NETW, V27, P2081, DOI 10.1007/s11276-021-02563-9
   Li XJ, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01698-1
   Liu GQ, 2019, CHINA COMMUN, V16, P200, DOI 10.23919/j.cc.2019.06.016
   Liu Y, 2016, INT C INTEL HUM MACH, P456, DOI 10.1109/IHMSC.2016.216
   Munadhil Z, 2021, ARAB J SCI ENG, V46, P9345, DOI 10.1007/s13369-020-05283-y
   Niculescu D, 2003, TELECOMMUN SYST, V22, P267, DOI 10.1023/A:1023403323460
   Peng B, 2015, COGN NEURODYNAMICS, V9, P249, DOI 10.1007/s11571-014-9324-y
   Phoemphon S, 2018, APPL SOFT COMPUT, V65, P101, DOI 10.1016/j.asoc.2018.01.004
   Rawat P, 2022, J PLANT GROWTH REGUL, V41, P2449, DOI 10.1007/s00344-021-10458-4
   Shahzad F, 2017, IEEE T MOBILE COMPUT, V16, P2494, DOI 10.1109/TMC.2016.2632715
   Shahzad F, 2016, J AMB INTEL HUM COMP, V7, P445, DOI 10.1007/s12652-016-0349-4
   Sharma G, 2018, IETE J RES, V64, P124, DOI 10.1080/03772063.2017.1333467
   Sharma G, 2018, TELECOMMUN SYST, V67, P163, DOI 10.1007/s11235-017-0328-x
   Shit RC, 2018, IEEE COMMUN SURV TUT, V20, P2028, DOI 10.1109/COMST.2018.2798591
   Singh SP, 2019, IETE J RES, V65, P502, DOI 10.1080/03772063.2018.1436472
   Singh SP, 2018, WIRELESS PERS COMMUN, V98, P487, DOI 10.1007/s11277-017-4880-1
   Song L, 2019, J SENSORS, V2019, DOI 10.1155/2019/2986954
   Sun HB, 2023, WIRELESS PERS COMMUN, V130, P2149, DOI 10.1007/s11277-023-10376-6
   Wang F, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/731894
   Wang PH, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7020184
   Wei C, 2016, INT J FUTUR GENER CO, V9, P125, DOI 10.14257/ijfgcn.2016.9.11.12
   Yadav P, 2023, INT J COMMUN SYST, V36, DOI 10.1002/dac.5397
   Yang J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143242
   Yang XY, 2015, CHEM ENGINEER TRANS, V46, P223, DOI 10.3303/CET1546038
   Yang XY, 2016, CYBERN INF TECHNOL, V16, P89, DOI 10.1515/cait-2016-0007
   Yang XY, 2015, INT J ONLINE ENG, V11, P17, DOI 10.3991/ijoe.v11i9.5059
   Zhang HQ, 2018, INT J ONLINE ENG, V14, P31, DOI 10.3991/ijoe.v14i05.8649
   Zhang Y, 2016, CHIN CONTR CONF, P8346, DOI 10.1109/ChiCC.2016.7554686
   Zhou CQ, 2019, MULTIMED TOOLS APPL, V78, P4299, DOI 10.1007/s11042-018-5674-5
   Zhou F, 2018, LECT NOTES ELECTR EN, V423, P541, DOI 10.1007/978-981-10-3229-5_57
   Zhou GQ, 2016, CHIN CONT DECIS CONF, P2390, DOI 10.1109/CCDC.2016.7531385
NR 49
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9761
EP 9784
DI 10.1007/s11042-023-16030-4
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800004
DA 2024-07-18
ER

PT J
AU Jain, RK
   Sharma, PK
   Gaj, S
   Sur, A
   Ghosh, P
AF Jain, Rohit Kumar
   Sharma, Prasen Kumar
   Gaj, Sibaji
   Sur, Arijit
   Ghosh, Palash
TI Knee osteoarthritis severity prediction using an attentive multi-scale
   deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Deep learning; Hrnet; Kellgren lawrence grade; Knee
   osteoarthritis; Knee x-ray; Osteo hrnet
ID DIAGNOSIS
AB Knee Osteoarthritis (OA) is a destructive joint disease identified by joint stiffness, pain, and functional disability concerning millions of lives across the globe. It is generally assessed by evaluating physical symptoms, medical history, and other joint screening tests like radiographs, Magnetic Resonance Imaging (MRI), and Computed Tomography (CT) scans. Unfortunately, the conventional methods are very subjective, which forms a barrier in detecting the disease progression at an early stage. This paper presents a deep learning-based framework, namely OsteoHRNet, that automatically assesses the Knee OA severity in terms of Kellgren and Lawrence (KL) grade classification from X-rays. As a primary novelty, the proposed approach is built upon one of the most recent deep models, called the High-Resolution Network (HRNet), to capture the multi-scale features of knee X-rays. In addition, an attention mechanism has been incorporated to filter out the counterproductive features and boost the performance further. Our proposed model has achieved the best multi-class accuracy of 71.74% and MAE of 0.311 on the baseline cohort of the OAI dataset, which is a remarkable gain over the existing best-published works. Additionally, Gradient-based Class Activation Maps (Grad-CAMs) have been employed to justify the proposed network learning.
C1 [Jain, Rohit Kumar; Sharma, Prasen Kumar; Sur, Arijit] Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati, India.
   [Gaj, Sibaji] Cleveland Clin, Cleveland, OH USA.
   [Ghosh, Palash] Indian Inst Technol Guwahati, Dept Math, Gauhati, India.
   [Ghosh, Palash] Indian Inst Technol Guwahati, Jyoti & Bhupat Mehta Sch Hlth Sci & Technol, Gauhati, India.
   [Ghosh, Palash] Natl Univ Singapore, Ctr Quantitat Med, Duke NUS Med Sch, Singapore, Singapore.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Cleveland Clinic Foundation; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati; National
   University of Singapore
RP Jain, RK (corresponding author), Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati, India.
EM jkrohit03@gmail.com
RI Sur, Arijit/AAB-4216-2020
OI Sur, Arijit/0000-0002-9038-8138; Gaj, Sibaji/0000-0002-6997-5717
CR Abd Razak HR, 2014, OPEN ORTHOPAEDICS J, P8
   Antony J, 2016, INT C PATT RECOG, P1195, DOI 10.1109/ICPR.2016.7899799
   Braun HJ, 2012, BONE, V51, P278, DOI 10.1016/j.bone.2011.11.019
   Chen P, 2018, KNEE OSTEOARTHRITIS
   Chen PJ, 2019, COMPUT MED IMAG GRAP, V75, P84, DOI 10.1016/j.compmedimag.2019.06.002
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dubois R, 2021, ARTHRITIS RES THER, P23
   Gorriz M, 2019, ASSESSING KNEE OA SE, V102, P08
   Huang G, 2018, WEINBERGER DENSELY C
   Kashyap S, 2018, IEEE T MED IMAGING, V37, P1103, DOI 10.1109/TMI.2017.2781541
   Kaur S, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P386, DOI 10.1109/BigMM50055.2020.00066
   KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494
   Khalid H, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080518
   Kohn MD, 2016, CLIN ORTHOP RELAT R, V474, P1886, DOI 10.1007/s11999-016-4732-4
   Kokkotis C, 2020, Osteoarthr Cartil Open, V2, P100069, DOI 10.1016/j.ocarto.2020.100069
   Kundu S, 2020, P NATL ACAD SCI USA, V117, P24709, DOI 10.1073/pnas.1917405117
   Lespasio Michelle J, 2017, Perm J, V21, P16, DOI 10.7812/TPP/16-183
   Liu X., 2020, IEEE T PATTERN ANAL, V44, P955
   Mathur M, 2020, MULTIMED TOOLS APPL, V79, P31625, DOI 10.1007/s11042-020-09371-x
   Michael JWP, 2010, DTSCH ARZTEBL INT, V107, P152, DOI 10.3238/arztebl.2010.0152
   Oconnor NE, 2017, AUTOMATIC DETECTION
   Oka H, 2008, OSTEOARTHR CARTILAGE, V16, P1300, DOI 10.1016/j.joca.2008.03.011
   Paszke A, 2019, ADV NEUR IN, V32
   Peterfy CG, 2008, OSTEOARTHR CARTILAGE, V16, P1433, DOI 10.1016/j.joca.2008.06.016
   Rajpurkar Pranav, 2017, ARXIV170701836
   Ramprasaath Rs, 2016, GRAD CAM WHY DID YOU, P11
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shamir L, 2009, OSTEOARTHR CARTILAGE, V17, P1307, DOI 10.1016/j.joca.2009.04.010
   Shamir L, 2009, IEEE T BIO-MED ENG, V56, P407, DOI 10.1109/TBME.2008.2006025
   Shetty, 2017, INT J SCI DEV RES IJ, V2, P416
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Swiecicki A, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104334
   Tang C, 2021, IEEE T MULTIMEDIA, V23, P624, DOI 10.1109/TMM.2020.2985541
   Tiulpin A, 2017, LECT NOTES COMPUT SC, V10270, P290, DOI 10.1007/978-3-319-59129-2_25
   Tiulpin A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20132-7
   Vaishya Raju, 2016, J Clin Orthop Trauma, V7, P170, DOI 10.1016/j.jcot.2016.05.005
   van Noord N, 2017, PATTERN RECOGN, V61, P583, DOI 10.1016/j.patcog.2016.06.005
   van Oudenaarde K, 2018, RADIOLOGY, V288, P170, DOI 10.1148/radiol.2018171383
   Wang Jingdong, 2020, IEEE transactions on pattern analysis and machine intelligence, P1, DOI [DOI 10.1109/TPAMI.2020.2983686, 10.1109/tpami.2020.2983686, 10.1109/TPAMI.2020.2983686]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yong CW, 2022, MULTIMED TOOLS APPL, V81, P41497, DOI 10.1007/s11042-021-10557-0
   Zhang BF, 2020, I S BIOMED IMAGING, P731, DOI [10.1109/isbi45749.2020.9098456, 10.1109/ISBI45749.2020.9098456]
NR 44
TC 5
Z9 5
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6925
EP 6942
DI 10.1007/s11042-023-15484-w
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001015589400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ouyang, JH
   Zhang, ZJ
   Meng, QY
   Li, XM
   Thanh, DNH
AF Ouyang, Jihong
   Zhang, Zhengjie
   Meng, Qingyi
   Li, Ximing
   Thanh, Dang Ngoc Hoang
TI Adaptive prototype and consistency alignment for semi-supervised domain
   adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaption; Image classification; Deep learning; Transfer learning
AB Unsupervised Domain Adaptation (UDA) aims to transfer knowledge from a label-rich source domain to an unlabeled target domain whose data distributions are different. There is a more realistic scenario where a few target labels are available, namely Semi-Supervised Domain Adaptation (SSDA). The existing methods reduce the inter-domain discrepancy by ignoring the class-level information, which may lead to cross-domain feature mismatch. Therefore, the model fails to learn discriminative feature representation for the target domain. In this paper, we propose a novel SSDA method, namely Adaptive Prototype and Consistency Alignment (APCA). To be specific, the Adaptive Prototype Alignment (APA) strategy employs a novel prototypical loss to realize the class-level alignment and further reduce the inter-domain discrepancy. Moreover, we apply Consistency Alignment (CA) to improve the robustness of the model and produce a robust cluster core which is beneficial to class-level alignment and thus facilitates the reduction of inter-domain discrepancy. We evaluate our approach on four domain adaptation datasets and the experimental results demonstrate the effectiveness of our proposed approach.
C1 [Ouyang, Jihong; Zhang, Zhengjie; Meng, Qingyi; Li, Ximing] Jilin Univ, Coll Comp Sci & Technolog, Jilin, Peoples R China.
   [Ouyang, Jihong; Zhang, Zhengjie; Meng, Qingyi; Li, Ximing] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Jilin, Peoples R China.
   [Thanh, Dang Ngoc Hoang] Univ Econ Ho Chi Minh City, Coll Technol & Design, Ho Chi Minh City, Vietnam.
C3 Jilin University; Jilin University; Ho Chi Minh City University
   Economics
RP Li, XM (corresponding author), Jilin Univ, Coll Comp Sci & Technolog, Jilin, Peoples R China.; Li, XM (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Jilin, Peoples R China.; Thanh, DNH (corresponding author), Univ Econ Ho Chi Minh City, Coll Technol & Design, Ho Chi Minh City, Vietnam.
EM ouyj@jlu.edu.cn; zhengjiezhang18@gmail.com; mengqy19@gmail.com;
   liximing86@gmail.com; thanhdnh@ueh.edu.vn
RI Thanh, Dang Ngoc Hoang/J-4415-2015
OI Thanh, Dang Ngoc Hoang/0000-0003-2025-8319
FU National Natural Science Foundation of China [62276113]; University of
   Economics Ho Chi Minh City (UEH), Vietnam
FX This work was supported by the National Natural Science Foundation of
   China (No.62276113). Fund receiver: Dr. Ximing Li. This work is funded
   by the University of Economics Ho Chi Minh City (UEH), Vietnam. Fund
   receiver: Dr. Dang Ngoc Hoang Thanh.
CR Berthelot D, 2019, ADV NEUR IN, V32
   Chen YB, 2018, LECT NOTES COMPUT SC, V11205, P275, DOI 10.1007/978-3-030-01246-5_17
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Cui KW, 2022, AAAI CONF ARTIF INTE, P499
   Edeh MO, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-25109-1
   Ganin Y, 2016, J MACH LEARN RES, V17
   Goodfellow I. J., 2014, ARXIV
   Grandvalet Y, 2004, Advances in neural information processing systems, V17
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Gupta, 2022, INFORMATICA, V46
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hu LQ, 2018, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2018.00162
   Huang JX, 2021, PROC CVPR IEEE, P6887, DOI 10.1109/CVPR46437.2021.00682
   Huang ZW, 2017, MULTIMED TOOLS APPL, V76, P6785, DOI 10.1007/s11042-016-3354-x
   Jiang P, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P934
   Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503
   Ke Mei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P415, DOI 10.1007/978-3-030-58574-7_25
   Kim Y, 2021, INT C PATT RECOG, P1059, DOI 10.1109/ICPR48806.2021.9413022
   Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053
   Li B, 2021, PROC CVPR IEEE, P1104, DOI 10.1109/CVPR46437.2021.00116
   Li C.-L., 2020, Advances in neural information processing systems, V33, P596
   Li D., 2020, COMPUTER VISION ECCV, P382
   Li JC, 2021, PROC CVPR IEEE, P2505, DOI 10.1109/CVPR46437.2021.00253
   Li K, 2021, P IEEE CVF INT C COM, P8578, DOI DOI 10.1109/ICASSP39728.2021.9414376
   Liang J, 2021, PROC CVPR IEEE, P16627, DOI 10.1109/CVPR46437.2021.01636
   Lin ZR, 2022, MULTIMED TOOLS APPL, V81, P5989, DOI 10.1007/s11042-021-11814-y
   Liu Hong, 2021, Advances in Neural Information Processing Systems, V34
   Long MS, 2016, ADV NEUR IN, V29
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long Mingsheng, 2018, Advances in Neural Information Processing Systems, V31
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Ngo BH, 2021, IEEE ACCESS, V9, P128467, DOI 10.1109/ACCESS.2021.3110605
   Onyema EM, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00305-6
   Onyema EM, 2022, COMPUT INTEL NEUROSC, V2022
   Ouyang J, 2022, INT JOINT C ARTIFICI, P3373
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Peng X., 2017, ARXIV
   Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149
   Qin C., 2021, P 2021 SIAM INT C DA, P576
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2019, IEEE I CONF COMP VIS, P8049, DOI 10.1109/ICCV.2019.00814
   Saito Kuniaki, 2020, Adv. Neural Inf. Process. Syst.
   Singh A, 2021, Advances in Neural Information Processing Systems, V34
   Singh A, 2021, IEEE COMPUT SOC CONF, P2703, DOI 10.1109/CVPRW53098.2021.00305
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Taekyung Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P591, DOI 10.1007/978-3-030-58568-6_35
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xiang SC, 2020, MULTIMED TOOLS APPL, V79, P19769, DOI 10.1007/s11042-020-08723-x
   Xie Q., 2020, ADV NEURAL INFORM PR, V33, P6256, DOI DOI 10.48550/ARXIV.1904.12848
   Xie S., 2018, P 35 INT C MACHINE L, P5423
   Xu MH, 2020, AAAI CONF ARTIF INTE, V34, P6502
   Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151
   Yang LY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8886, DOI 10.1109/ICCV48922.2021.00878
   Zhang P, 2021, PROC CVPR IEEE, P12409, DOI 10.1109/CVPR46437.2021.01223
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 61
TC 0
Z9 0
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9307
EP 9328
DI 10.1007/s11042-023-15749-4
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000002
DA 2024-07-18
ER

PT J
AU Mao, L
   Wang, M
   Yang, DW
   Zhang, RB
AF Mao, Lin
   Wang, Meng
   Yang, Dawei
   Zhang, Rubo
TI Mutual learning generative adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-to-image translation; Regroup and redistribution; Mutual feature;
   Cross-domain interaction
AB It is the key to realize high fidelity image-to-image translation to realize the precise disentangling of single domain feature based on the establishment of the internal correlation between source and target domain. In order to improve the problem of difficult disentanglement and weak correlation with cross-domain features, this paper designs a feature regroup and redistribution module, to achieve feature hierarchical processing and feature interaction in a mutual space for controllable image-to-image translation. In the feature regroup unit, pyramid with different frequency intervals are designed to extract content feature such as multi-level spatial structure and global color semantic information. Further, the output of frequency pyramid is mapped into mutual pool for cross-domain feature difference comparison and similarity learning to achieve accurate analysis. In the redistribution unit, the mutual pool output and single domain feature are fused in the form of spatial attention to correct content and style feature transmission error. We also design a mutual learning generative adversarial network based on the RR module, which can satisfy minimum errors image-to-image translation in real scenes. The experiment results on BDD100K and Sim10k datasets show that FID, IS, KID_mean, and KID_stddev have greatly improved.
C1 [Mao, Lin; Wang, Meng; Yang, Dawei; Zhang, Rubo] Dalian Minzu Univ, Liaohe Rd, Dalian 116600, Liaoning, Peoples R China.
C3 Dalian Minzu University
RP Wang, M (corresponding author), Dalian Minzu Univ, Liaohe Rd, Dalian 116600, Liaoning, Peoples R China.
EM wang_meng0301@163.com
FU National Natural Science Foundation of China [61673084]; Natural Science
   Foundation of Liaoning Province [20170540192, 20,180,550,866,
   2020-mzlh-24]
FX This work is sponsored by the National Natural Science Foundation of
   China (grant no. 61673084), Natural Science Foundation of Liaoning
   Province (grant no. 20170540192, 20,180,550,866 and 2020-mzlh-24).
CR Alharbi Y, 2020, PROC CVPR IEEE, P5133, DOI 10.1109/CVPR42600.2020.00518
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Daras Giannis, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14519, DOI 10.1109/CVPR42600.2020.01454
   Elad R, 2021, ARXIV
   Emami H, 2021, IEEE T MULTIMEDIA, V23, P391, DOI 10.1109/TMM.2020.2975961
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Hazama Toshiki, 2020, 2020 IEEE 9th Global Conference on Consumer Electronics (GCCE), P670, DOI 10.1109/GCCE50665.2020.9291836
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Hyunsu K, 2021, ARXIV
   Karnewar Animesh, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7796, DOI 10.1109/CVPR42600.2020.00782
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim J., 2020, ARXIV
   Kwon G, 2021, ICCV
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Li H, 2020, IEEE ACCESS, V8, P62448, DOI 10.1109/ACCESS.2020.2981496
   Li XY, 2021, PROC CVPR IEEE, P8635, DOI 10.1109/CVPR46437.2021.00853
   Liu MY, 2017, ADV NEUR IN, V30
   Liu W., 2021, IEEE J SEL TOP QUANT, V14, P3063911, DOI [10.1109/JSTARS.2021, DOI 10.1109/JSTARS.2021]
   Park T, 2020, NEURIPS, V33
   Pizzati F, 2021, PROC CVPR IEEE, P14283, DOI 10.1109/CVPR46437.2021.01406
   Raymond Y, 2017, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ryota I, 2020, P IEEECVF C COMPUTER
   Sangwoo M, 2019, ARXIV
   Sun N, 2019, IEEE T CIRC SYST VID, V29, P1715, DOI 10.1109/TCSVT.2018.2848543
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yanbo X, 2022, PROCEEDING COMPUTER
   Yichun S, 2021, P COMPUTER VISION PA
   Yue K, 2019, P IEEE VIS COMM IM P, P1, DOI DOI 10.1109/VCIP47243.2019.8966069
   Zhou XR, 2021, PROC CVPR IEEE, P11460, DOI 10.1109/CVPR46437.2021.01130
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu P, 2021, TOG
NR 36
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7479
EP 7503
DI 10.1007/s11042-023-15951-4
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003484200004
DA 2024-07-18
ER

PT J
AU Gaire, S
   Alsadoon, A
   Prasad, PWC
   Alsallami, N
   Bajaj, SK
   Dawoud, A
   Vo, TH
AF Gaire, Sabitri
   Alsadoon, Abeer
   Prasad, P. W. C.
   Alsallami, Nada
   Bajaj, Simi Kamini
   Dawoud, Ahmed
   Vo, Trung Hung
TI Enhanced cluster detection and noise reduction for geospatial time
   series data of COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Geospatial time series data; Space-time analysis;
   Spatial-temporal analysis; Poisson prospective distribution
AB Spatial-temporal analysis of the COVID-19 cases is critical to find its transmitting behaviour and to detect the possible emerging clusters. Poisson's prospective space-time analysis has been successfully implemented for cluster detection of geospatial time series data. However, its accuracy, number of clusters, and processing time are still a major problem for detecting small-sized clusters. The aim of this research is to improve the accuracy of cluster detection of COVID-19 at the county level in the U.S.A. by detecting small-sized clusters and reducing the noisy data. The proposed system consists of the Poisson prospective space-time analysis along with Enhanced cluster detection and noise reduction algorithm (ECDeNR) to improve the number of clusters and decrease the processing time. The results of accuracy, processing time, number of clusters, and relative risk are obtained by using different COVID-19 datasets in SaTScan. The proposed system increases the average number of clusters by 7 and the average relative risk by 9.19. Also, it provides a cluster detection accuracy of 91.35% against the current accuracy of 83.32%. It also gives a processing time of 5.69 minutes against the current processing time of 7.36 minutes on average. The proposed system focuses on improving the accuracy, number of clusters, and relative risk and reducing the processing time of the cluster detection by using ECDeNR algorithm. This study solves the issues of detecting the small-sized clusters at the early stage and enhances the overall cluster detection accuracy while decreasing the processing time.
C1 [Gaire, Sabitri; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.; Bajaj, Simi Kamini; Dawoud, Ahmed] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Alsallami, Nada] Worcester State Univ, Comp Sci Dept, Worcester, MA USA.
   [Vo, Trung Hung] Univ Technol & Educ Univ Danang UTE UDN, Danang, Vietnam.
C3 Charles Sturt University; Western Sydney University; Massachusetts
   System of Public Higher Education; Worcester State University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Balamchi S, 2021, SPAT STAT-NETH, V42, DOI 10.1016/j.spasta.2020.100425
   Chen CC, 2016, INT J HEALTH GEOGR, V15, DOI 10.1186/s12942-016-0072-6
   Cordes J, 2020, SPAT SPATIO-TEMPORAL, V34, DOI 10.1016/j.sste.2020.100355
   Corizzo R, 2019, BIG DATA RES, V16, P18, DOI 10.1016/j.bdr.2019.04.001
   Desjardins MR, 2020, APPL GEOGR, V118, DOI 10.1016/j.apgeog.2020.102202
   Dong ES, 2020, LANCET INFECT DIS, V20, P533, DOI 10.1016/S1473-3099(20)30120-1
   Greene SK, 2016, EMERG INFECT DIS, V22, P1808, DOI 10.3201/eid2210.160097
   Guemes A, SYNDROMIC SURVEILLAN, DOI [10.1101/2020.08.18.20177295, DOI 10.1101/2020.08.18.20177295]
   Guliyev H, 2020, SPAT STAT-NETH, V38, DOI 10.1016/j.spasta.2020.100443
   Hammad TA, 2021, CATHETER CARDIO INTE, V97, P208, DOI 10.1002/ccd.28997
   Hohl A, 2020, SPAT SPATIO-TEMPORAL, V34, DOI 10.1016/j.sste.2020.100354
   Hu RY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102782
   Huang C, 2020, LANCET, V395, P496, DOI 10.1016/S0140-6736(20)30252-X
   Johns Hopkins University, COVID 19 NOV COR COV
   Jones RC, 2006, PUBLIC HEALTH REP, V121, P133, DOI 10.1177/003335490612100206
   Krivoruchko K, 2020, SPAT STAT-NETH, V35, DOI 10.1016/j.spasta.2019.100396
   Kulldorff M, 1998, AM J PUBLIC HEALTH, V88, P1377, DOI 10.2105/AJPH.88.9.1377
   Kulldorff M, 1997, COMMUN STAT-THEOR M, V26, P1481, DOI 10.1080/03610929708831995
   Kulldorff M, 2015, STAT MED, V34, P1094, DOI 10.1002/sim.6430
   Lakhani A, 2020, J PAIN SYMPTOM MANAG, V60, pE41, DOI 10.1016/j.jpainsymman.2020.03.041
   Lansiaux É, 2020, SPAT SPATIO-TEMPORAL, V35, DOI 10.1016/j.sste.2020.100362
   Leevy JL, 2020, J BIG DATA-GER, V7, DOI [10.1186/s40537-020-00312-x, 10.1186/s40537-020-00382-x]
   Mahase E, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m641
   Mollalo A, 2020, SCI TOTAL ENVIRON, V728, DOI 10.1016/j.scitotenv.2020.138884
   Mulatti P, 2015, EPIDEMIOL INFECT, V143, P202, DOI 10.1017/S0950268814000442
   Neill D.B., 2005, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), P218, DOI [DOI 10.1145/1081870.1081897, 10.1145/1081870.1081897]
   Robertson C, 2010, SPAT SPATIO-TEMPORAL, V1, P105, DOI 10.1016/j.sste.2009.12.001
   Ruan QR, 2020, INTENS CARE MED, V46, P846, DOI 10.1007/s00134-020-05991-x
   Saeed TU, 2020, GEOGR ANAL, V52, P394, DOI 10.1111/gean.12216
   Tango Toshiro, 2005, Int J Health Geogr, V4, P11, DOI 10.1186/1476-072X-4-11
   U. S. C. Bureau, 2010, IND PROGR SURV POP D
NR 31
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 4
PY 2023
DI 10.1007/s11042-023-15901-0
EA JUN 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I1AI5
UT WOS:001000166200001
PM 37362721
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Alsadoon, A
   Al-Naymat, G
   Islam, MR
AF Alsadoon, Abeer
   Al-Naymat, Ghazi
   Islam, Md Rafiqul
TI Deep learning models for human age prediction to prevent, treat and
   extend life expectancy: DCPV taxonomy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Classification; Taxonomy; Human age prediction; Pattern
   recognition; Feature extraction; Neural networks
ID DNA METHYLATION; GENDER CLASSIFICATION; FACE IMAGES; FRAMEWORK
AB The implementation of Deep Learning (DL) Prediction techniques for Human Age Prediction (HAP) has been widely researched and studied to prevent, treat, and extend life expectancy. While most algorithms rely on facial images, MRI scans, and DNA methylation for training and testing, they are seldom implemented due to a lack of significant validation and evaluation in real-world scenarios, low performance, and technical challenges. To address these issues, this paper proposes the Data, Classification Technique, Prediction, and View (DCPV) taxonomy, which outlines the primary components required to implement and validate a deep learning model for predicting human age. By providing a common baseline for end-users and researchers, this taxonomy offers a clearer view of the constituents of deep learning prediction approaches, enabling the development of similar systems in the health domain. In contrast to existing machine learning methods, the proposed taxonomy emphasizes the value of deep learning practices based on performance, accuracy, and efficiency in predicting human age. To validate the DCPV taxonomy, the study examines 31 state-of-the-art research journal articles within the HAP system domain, assessing the taxonomy's performance, accuracy, robustness, and model comparisons.
C1 [Alsadoon, Abeer; Islam, Md Rafiqul] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, Australia.
   [Alsadoon, Abeer] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, Australia.
   [Al-Naymat, Ghazi] Ajman Univ, Coll Engn & IT, Ajman, U Arab Emirates.
C3 Charles Sturt University; Western Sydney University; Ajman University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Islam,
   Rafiqul/0000-0001-8317-5727
CR Abousaleh FS, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0151-4
   Agbo-Ajala O, 2022, FRONT BIG DATA, V5, DOI 10.3389/fdata.2022.1025806
   Al-Omoush R, 2022, 2022 INT C EM TRENDS, DOI [10.1109/ETCEA57049.2022.10009688, DOI 10.1109/ETCEA57049.2022.10009688]
   Alsadoon A, 2021, NEURAL PROCESS LETT, V53, P2665, DOI 10.1007/s11063-021-10485-y
   Angulu R, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0278-6
   [Anonymous], 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on
   Badem H, 2017, NEUROCOMPUTING, V266, P506, DOI 10.1016/j.neucom.2017.05.061
   Becker J, 2020, INT J LEGAL MED, V134, P721, DOI 10.1007/s00414-019-02054-9
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen DP, 2010, J BIOMED INFORM, V43, P358, DOI 10.1016/j.jbi.2009.11.007
   Chen LM, 2018, SIGNAL IMAGE VIDEO P, V12, P1531, DOI 10.1007/s11760-018-1309-6
   Chen SX, 2018, IEEE T MULTIMEDIA, V20, P2209, DOI 10.1109/TMM.2017.2786869
   Chen YL, 2019, NEUROCOMPUTING, V367, P346, DOI 10.1016/j.neucom.2019.08.034
   Choi SE, 2017, EXPERT SYST APPL, V80, P107, DOI 10.1016/j.eswa.2017.03.008
   Cole JH, 2017, TRENDS NEUROSCI, V40, P681, DOI 10.1016/j.tins.2017.10.001
   Cole JH, 2017, NEUROIMAGE, V163, P115, DOI 10.1016/j.neuroimage.2017.07.059
   Dalbah LM, 2022, 2022 INT C EM TRENDS, DOI [10.1109/ETCEA57049.2022.10009818, DOI 10.1109/ETCEA57049.2022.10009818]
   Dong Y, 2016, NEUROCOMPUTING, V187, P4, DOI 10.1016/j.neucom.2015.09.115
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Fang J, 2019, NEUROCOMPUTING, V334, P114, DOI 10.1016/j.neucom.2018.12.073
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   González-Briones A, 2018, COMPUT VIS IMAGE UND, V172, P98, DOI 10.1016/j.cviu.2018.01.012
   Günay A, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P378
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Hu ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3087, DOI 10.1109/TIP.2016.2633868
   Jana R, 2015, PROCEDIA COMPUT SCI, V46, P1754, DOI 10.1016/j.procs.2015.02.126
   Jang HS, 2017, GENES-BASEL, V8, DOI 10.3390/genes8060148
   Jung SE, 2017, BMB REP, V50, P546, DOI 10.5483/BMBRep.2017.50.11.175
   Li K, 2017, PATTERN RECOGN, V66, P95, DOI 10.1016/j.patcog.2017.01.007
   Li X, 2018, MULTIMED TOOLS APPL, V77, P28333, DOI 10.1007/s11042-018-6049-7
   Li XY, 2018, GENES-BASEL, V9, DOI 10.3390/genes9090424
   Liang YX, 2011, IEEE IMAGE PROC, P565, DOI 10.1109/ICIP.2011.6116611
   Liao HB, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1712686
   Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026
   Lou ZY, 2018, IEEE T PATTERN ANAL, V40, P365, DOI 10.1109/TPAMI.2017.2679739
   Naue J, 2017, FORENSIC SCI INT-GEN, V31, P19, DOI 10.1016/j.fsigen.2017.07.015
   Naveen KB, 2019, INT J ENG RES TECHNO, V08
   Ng CC, 2018, IMAGE VISION COMPUT, V69, P92, DOI 10.1016/j.imavis.2017.08.005
   Park JL, 2016, FORENSIC SCI INT-GEN, V23, P64, DOI 10.1016/j.fsigen.2016.03.005
   Pontes JK, 2016, PATTERN RECOGN, V54, P34, DOI 10.1016/j.patcog.2015.12.003
   Qawaqneh Z, 2017, EXPERT SYST APPL, V85, P76, DOI 10.1016/j.eswa.2017.05.037
   Qawaqneh Z, 2017, KNOWL-BASED SYST, V115, P5, DOI 10.1016/j.knosys.2016.10.008
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Sajedi H, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1401-7
   Shah B, 2021, MULTIMED TOOLS APPL, V80, P21339, DOI 10.1007/s11042-021-10769-4
   Spizhevoi A. S., 2015, Pattern Recognition and Image Analysis, V25, P547, DOI 10.1134/S1054661815030244
   Tan ZC, 2018, IEEE T PATTERN ANAL, V40, P2610, DOI 10.1109/TPAMI.2017.2779808
   Tian Q, 2018, IMAGE VISION COMPUT, V69, P9, DOI 10.1016/j.imavis.2017.10.003
   Valizadeh SA, 2017, HUM BRAIN MAPP, V38, P997, DOI 10.1002/hbm.23434
   Vidaki A, 2017, FORENSIC SCI INT-GEN, V28, P225, DOI 10.1016/j.fsigen.2017.02.009
   Wang ZC, 2017, J BIOMED INFORM, V76, P59, DOI 10.1016/j.jbi.2017.11.003
   Weidner CI, 2014, GENOME BIOL, V15, DOI 10.1186/gb-2014-15-2-r24
   Xing JH, 2017, PATTERN RECOGN, V66, P106, DOI 10.1016/j.patcog.2017.01.005
   Xu Y, 2019, COMPUT METH PROG BIO, V171, P11, DOI 10.1016/j.cmpb.2019.02.010
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang JL, 2015, SCI REP-UK, V5, DOI 10.1038/srep15145
   Yu W, 2014, SIGNAL IMAGE VIDEO P, V8, pS155, DOI 10.1007/s11760-014-0652-5
   Zaghbani S, 2018, COMPUT ELECTR ENG, V68, P337, DOI 10.1016/j.compeleceng.2018.04.012
   Zaghlool SB, 2015, CLIN EPIGENETICS, V7, DOI 10.1186/s13148-014-0040-6
   Zhang HY, 2019, PATTERN RECOGN LETT, V125, P271, DOI 10.1016/j.patrec.2019.05.002
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhu ZJ, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0353-z
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 69
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15889-7
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300011
DA 2024-07-18
ER

PT J
AU Fanfakh, A
   Noura, H
   Couturier, R
AF Fanfakh, Ahmed
   Noura, Hassan
   Couturier, Raphael
TI Simultaneous encryption and authentication of messages over GPUs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Encryption and authentication; GPU
ID EFFICIENT; LIGHTWEIGHT
AB There has recently been a rising interest in inventing new efficient cryptographic algorithms, thanks to advances in the field of Graphics Processing Unit (GPU) technology. Current cryptographic algorithms have been implemented with GPUs, including the Advanced Encryption Standard algorithm (AES) and the Secure-Hash Algorithm 3 (SHA3). However, the currently available cryptographic approaches cannot fully benefit from the GPU's capabilities, as they are not designated in accordance with the GPU characteristics. Therefore, they are not carried out in an efficient manner. Thus, the need to design new cryptographic algorithms that can achieve the best performances without degrading the security level. In this work, a new message Encryption and Authentication Algorithm (MEAA) is specifically proposed for graphics processing units (GPUs). It consists of one-round encryption and authentication functions that are based on the dynamic key-dependent scheme. Experimental results indicate that the proposed approach reaches a throughput of over 580 GB/s over the GPU Tesla A100. Additionally, it demonstrates that the performance improvement ratio is better than that of existing methods. On the other hand, the proposed MEAA is impervious to well-known cryptanalysis attacks since it is based on the dynamic key strategy, and different primitives of cryptography, which are employed for each new input message.
C1 [Fanfakh, Ahmed] Univ Babylon, Hillah, Iraq.
   [Noura, Hassan; Couturier, Raphael] Univ Franche Comte, Inst FEMTO ST, CNRS, F-90000 Belfort, France.
C3 University of Babylon; Universite de Franche-Comte; Centre National de
   la Recherche Scientifique (CNRS); Universite de Technologie de
   Belfort-Montbeliard (UTBM)
RP Couturier, R (corresponding author), Univ Franche Comte, Inst FEMTO ST, CNRS, F-90000 Belfort, France.
EM raphael.couturier@univ-fcomte.fr
RI Fanfakh, Ahmed/N-4768-2019; Noura, Hassan/U-8729-2018
OI Fanfakh, Ahmed/0000-0002-6177-0012; Couturier,
   Raphael/0000-0003-1490-9592
FU Ministry of Higher Education and Scientific Research of Iraq; EIPHI
   Graduate School [ANR-17-EURE-0002]; GENCI-IDRIS [20XX-AD011012913]
FX This paper is partially supported by the Ministry of Higher Education
   and Scientific Research of Iraq. It was partially supported by the EIPHI
   Graduate School (contract "ANR-17-EURE-0002"). We would also like to
   thank the Mesocentre de Calcul de Franche-Comte and the GENCI-IDRIS
   (Grant 20XX-AD011012913) for their supercomputer resources.
CR Akhavan A, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-126
   Amin M, 2009, CHAOS SOLITON FRACT, V42, P767, DOI 10.1016/j.chaos.2009.02.001
   [Anonymous], 2013, DESIGNING SCI APPL G
   [Anonymous], 2009, Advanced Encryption Standard
   [Anonymous], 2017, J CRYPTOGR ENG
   [Anonymous], 2018, MULTIMEDIA TOOLS APP
   Beaulieu R, 2015, DES AUT CON, DOI 10.1145/2744769.2747946
   Beaulieu Ray, 2015, Report 2015/585
   Chen L, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P310, DOI 10.1109/ISECS.2008.77
   Couturier R, 2020, MULTIMED TOOLS APPL, V79, P13559, DOI 10.1007/s11042-020-08613-2
   Cvitic I, 2021, INT J MACH LEARN CYB, V12, P3179, DOI 10.1007/s13042-020-01241-0
   Daemen J., 2013, DESIGN RIJNDAEL AES
   DAMGARD IB, 1990, LECT NOTES COMPUT SC, V435, P416
   Denis T S, 2007, CRYPTOGRAPHY DEV
   Fanfakh A, 2022, J SUPERCOMPUT, V78, P11744, DOI 10.1007/s11227-022-04335-4
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Guo GL, 2015, IEEE I C EMBED SOFTW, P1848, DOI 10.1109/HPCC-CSS-ICESS.2015.215
   Guyeux C, 2015, J SUPERCOMPUT, V71, P3877, DOI 10.1007/s11227-015-1479-8
   Jonathan Katz Y L, 2021, INTRO MODERN CRYPTOG, V3rd
   Kanso A, 2015, NONLINEAR DYNAM, V81, P27, DOI 10.1007/s11071-015-1970-z
   Lee W-K., 2018, CONCURR COMP-PRACT E, V31, P11
   Lee WK, 2016, CLUSTER COMPUT, V19, P335, DOI 10.1007/s10586-016-0536-2
   Li QJ, 2012, IEEE I C EMBED SOFTW, P843, DOI 10.1109/HPCC.2012.119
   Lim Rone Kwei, 2016, The New Codebreakers Essays Dedicated to David Kahn on the Occasion of His 85th Birthday. LNCS 9100, P125, DOI 10.1007/978-3-662-49301-4_8
   Maitra S, 2016, DISCRETE APPL MATH, V208, P88, DOI 10.1016/j.dam.2016.02.020
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mani N, 2021, INT J SOFTW SCI COMP, V13, P72, DOI 10.4018/IJSSCI.2021010105
   Menezes A., 1996, Cryptography
   Noura H N, 2018, MULTIMED TOOLS APPL, P1
   Noura H, 2019, MULTIMED TOOLS APPL, V78, P16527, DOI 10.1007/s11042-018-7000-7
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P15457, DOI 10.1007/s11042-017-5124-9
   Noura HN, 2022, J AMB INTEL HUM COMP, V13, P483, DOI 10.1007/s12652-021-02913-7
   nvidia, NVID CUDA C PROGR GU
   Runtong Zhang, 2008, 2008 IEEE International Symposium on Industrial Electronics (ISIE 2008), P1463, DOI 10.1109/ISIE.2008.4676931
   Sleem L, 2020, MULTIMED TOOLS APPL, V79, P24075, DOI 10.1007/s11042-020-09108-w
   Soyata T., 2018, GPUParallel ProgramDevelopmentUsingCUDA
   Stallings W., 2017, Cryptography and Network Security: Principles and Practice, V7th ed.
   Tewari A, 2020, INT J SEMANT WEB INF, V16, P20, DOI 10.4018/IJSWIS.2020070102
   Wang XY, 2005, LECT NOTES COMPUT SC, V3494, P19
   Yang B, 2009, 2009 GLOBAL MOBILE CONGRESS, P135
   Zhou ZL, 2022, IEEE INTERNET THINGS, V9, P9332, DOI 10.1109/JIOT.2021.3103779
NR 41
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15451-5
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300002
DA 2024-07-18
ER

PT J
AU Ali, QW
AF Ali, Qazi Waqar
TI An improved H infinity controller using hybrid optimization for PV
   integrated MMC-HVDC system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MMC; H-infinity controller; Jaya optimization insisted explored chimp;
   Circulating current; Jaya optimization algorithm; Chimp optimization
   algorithm
ID MODULAR MULTILEVEL CONVERTERS; CONTROL SCHEME; ALGORITHM; VOLTAGE;
   SIMULATION
AB Generally, circulating current is generated in a Modular Multilevel Converter (MMC) by fluctuations in the capacitor voltage of sub-modules. Therefore, this research work seeks to build the Photo Voltaic (PV) integrated MMC-High-Voltage Direct Current (HVDC) systems with optimal H-infinity controller which is appropriate for 3-phase system. To verify the unstable voltages of sub-modules, the reference current is initially set to zero, as well as the unstable currents in each phase are monitored with a current sensor as well as contrasted to the reference current, resulting in the generation of an incorrect circulating current. The main contribution is to reduce the error among the reference current as well as the actual circulating current. In the H-infinity controller, the gains are optimally tuned via a new hybrid algorithm referred as Jaya Optimization Insisted Explored Chimp (JOI-EC) algorithm, which is the hybridized version of the Jaya Optimization Algorithm (JOA) and the Chimp Optimization Algorithm (ChOA). Moreover, the performance of the proposed model is examined through control analysis, converter performance analysis, as well as capacitor voltage analysis in addition to the circulating current. The result of simulation shows the robust performance of the proposed controller with respect to minimum circulating current, voltage, and stability analysis.
C1 [Ali, Qazi Waqar] Inst Appl Technol, Abu Dhabi, U Arab Emirates.
RP Ali, QW (corresponding author), Inst Appl Technol, Abu Dhabi, U Arab Emirates.
EM qaziwaqara098@gmail.com
CR Bashir SB, 2018, INT J ELEC POWER, V95, P550, DOI 10.1016/j.ijepes.2017.09.002
   Beddard A, 2015, ENRGY PROCED, V80, P201, DOI 10.1016/j.egypro.2015.11.423
   Bozicek A, 2017, INT J ELEC POWER, V91, P209, DOI 10.1016/j.ijepes.2017.03.015
   CRETNIK J, 1992, IFAC SYMP SERIES, P123
   Tavakoli SD, 2022, IEEE T POWER DELIVER, V37, P786, DOI 10.1109/TPWRD.2021.3071211
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, P286, DOI [10.22266/ijies2020.1031.26, DOI 10.22266/IJIES2020.1031.26]
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, DOI DOI 10.22266/IJIES2020.1231.32
   Dehghani M., 2019, International Journal of Innovative Technology and Exploring Engineering, V9, P5306, DOI [10.35940/ijitee.A4215.119119, DOI 10.35940/IJITEE.A4215.119119]
   Dehghani M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186173
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Dhiman G, 2021, ENG COMPUT-GERMANY, V37, P323, DOI 10.1007/s00366-019-00826-w
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Ghadi RJ, 2021, INT J ELEC POWER, V129, DOI 10.1016/j.ijepes.2021.106778
   Gil E-S, 2017, INT J MECH ENG ROBOT, V6, DOI [10.18178/ijmerr.6.2.104-107, DOI 10.18178/IJMERR.6.2.104-107]
   Hossain MI, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207186
   Iacca G, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113902
   Ishfaq M, 2019, ENERGIES, V12, DOI 10.3390/en12061118
   Isik S., 2018, 2018 IEEE Electronic Power Grid (eGrid), P1, DOI [DOI 10.1109/EGRID.2018.8598692, 10.1109/egrid.2018.8598692]
   Johari Nur Farahlina, 2013, Applied Mechanics and Materials, V421, P512, DOI 10.4028/www.scientific.net/AMM.421.512
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Lacerda VA, 2020, INT J ELEC POWER, V118, DOI 10.1016/j.ijepes.2019.105750
   Li GQ, 2018, INT J ELEC POWER, V99, P69, DOI 10.1016/j.ijepes.2017.12.013
   Li JK, 2017, ELECTR POW SYST RES, V152, P211, DOI 10.1016/j.epsr.2017.07.003
   Li R, 2017, ELECTR POW SYST RES, V143, P544, DOI 10.1016/j.epsr.2016.11.004
   Liu CR, 2014, INT J ELEC POWER, V56, P198, DOI 10.1016/j.ijepes.2013.11.010
   mathworks, About us
   Mehrasa M, 2018, INT J ELEC POWER, V96, P194, DOI 10.1016/j.ijepes.2017.10.006
   Rachananjali K, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100402
   Ramirez D, 2020, INT J ELEC POWER, V119, DOI 10.1016/j.ijepes.2020.105951
   Ramirez D, 2017, RENEW ENERG, V101, P945, DOI 10.1016/j.renene.2016.09.050
   Shi K, 2018, ISA T, V72, P44, DOI 10.1016/j.isatra.2017.10.013
   Torres-Olguin RE, 2017, ENRGY PROCED, V137, P391, DOI 10.1016/j.egypro.2017.10.363
   Uddin W, 2019, ENERGIES, V12, DOI 10.3390/en12214084
   Wang Y, MODULAR MULTILEVEL C
   Wu WJ, 2020, ISA T, V106, P318, DOI 10.1016/j.isatra.2020.07.016
   Xia XY, 2016, INT J ELEC POWER, V82, P207, DOI 10.1016/j.ijepes.2016.02.050
   Xiao Q, 2021, APPL ENERG, V282, DOI 10.1016/j.apenergy.2020.116154
   Xin YC, 2021, INT J ELEC POWER, V131, DOI 10.1016/j.ijepes.2021.107076
   Xu JZ, 2016, INT J ELEC POWER, V83, P7, DOI 10.1016/j.ijepes.2016.03.062
   Zhang HT, 2019, ELECTR POW SYST RES, V171, P36, DOI 10.1016/j.epsr.2019.01.041
   Zhang JP, 2016, ELECTR POW SYST RES, V140, P528, DOI 10.1016/j.epsr.2016.05.021
NR 46
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15415-9
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7MY7
UT WOS:000990968000003
DA 2024-07-18
ER

PT J
AU Vatansever, F
   Hatun, M
AF Vatansever, Fahri
   Hatun, Metin
TI Stability analysis tool for discrete-time systems in control education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer-aided instruction; Distance and interactive training;
   Discrete-time system; Stability
ID ZERO LOCATION; UNIT-CIRCLE; PLATFORM; RESPECT; TABLE
AB Computers are widely used for the purpose of education along with the developing technology as in every field. Students can learn and understand theoretical information individually with computer tools such as lectures, animations, solved/unsolved examples, simulations, interactive simulators, online support. In this study, a new software tool has been designed which contains many methods for stability analysis in discrete-time systems and is not available in the literature/application. By using this computer tool, which includes eleven stability analysis methods, related lectures, interactive analysis and application (exercise) simulators; it is aimed that students learn and understand the knowledge in the related field in a simple and easy way on their own.
C1 [Vatansever, Fahri; Hatun, Metin] Bursa Uludag Univ, Dept Elect Elect Engn, Bursa, Turkiye.
C3 Uludag University
RP Vatansever, F (corresponding author), Bursa Uludag Univ, Dept Elect Elect Engn, Bursa, Turkiye.
EM fahriv@uludag.edu.tr
RI Vatansever, Fahri/AAG-8425-2021; Hatun, Metin/AAH-2199-2021
OI Vatansever, Fahri/0000-0002-3885-8622; Hatun, Metin/0000-0003-0279-5508
CR [Anonymous], 1964, Theory and application of the z-transform method
   [Anonymous], 2014, The MathWorks
   Benidir M, 1996, SIGNAL PROCESS, V53, P75, DOI 10.1016/0165-1684(96)00077-1
   BISTRITZ Y, 1983, IEEE T CIRCUITS SYST, V30, P917, DOI 10.1109/TCS.1983.1085318
   BISTRITZ Y, 1984, P IEEE, V72, P1131, DOI 10.1109/PROC.1984.12993
   Bistritz Y, 1996, CIRC SYST SIGNAL PR, V15, P111, DOI 10.1007/BF01187696
   Cech M, 2019, IFAC PAPERSONLINE, V52, P200, DOI 10.1016/j.ifacol.2019.08.196
   Chipart Lienard, 1914, J MATH PURE APPL, V10, P291
   Coma-Tatay I, 2019, MULTIMED TOOLS APPL, V78, P6093, DOI 10.1007/s11042-018-6395-5
   de la Peña DM, 2022, IFAC PAPERSONLINE, V55, P79, DOI 10.1016/j.ifacol.2022.09.228
   Redondo RPD, 2021, MULTIMED TOOLS APPL, V80, P3121, DOI 10.1007/s11042-020-09523-z
   Fadali MS, 2013, Digital Control Engineering Analysis and Design, V2nd
   Google, 2022, Google docs
   Guzmán JL, 2016, IEEE CONTR SYST MAG, V36, P63, DOI 10.1109/MCS.2015.2495092
   Heradio R, 2016, ANNU REV CONTROL, V42, P1, DOI 10.1016/j.arcontrol.2016.08.001
   HU XH, 1994, SYST CONTROL LETT, V22, P385, DOI 10.1016/0167-6911(94)90036-1
   Hwang J, 2016, MULTIMED TOOLS APPL, V75, P13149, DOI 10.1007/s11042-015-2994-6
   JURY EI, 1962, P IRE, V50, P1493, DOI 10.1109/JRPROC.1962.288193
   Juuso EK, 2018, OPEN ENG, V8, P41, DOI 10.1515/eng-2018-0006
   Kim BH, 2017, MULTIMED TOOLS APPL, V76, P6051, DOI 10.1007/s11042-016-3495-y
   Kuo BenjaminC., 1992, Digital Control Systems
   Leva A, 2020, IFAC PAPERSONLINE, V53, P17179, DOI 10.1016/j.ifacol.2020.12.1728
   Levine W.S., 1999, The Control Handbook
   Guzmán JL, 2018, IFAC PAPERSONLINE, V51, P190, DOI 10.1016/j.ifacol.2018.06.064
   Marden M., 1949, GEOMETRY ZEROS POLYN
   Marin L, 2020, IEEE ACCESS, V8, P170183, DOI 10.1109/ACCESS.2020.3023910
   Matisak J, 2020, J AUTOMATION MOBILE, V14, P42, DOI [10.14313/JAMRIS/3-2020/32, DOI 10.14313/JAMRIS/3-2020/32]
   Nan RJ, 2019, MULTIMED TOOLS APPL, V78, P35651, DOI 10.1007/s11042-019-08187-8
   Neogi B., 2010, INT J ENGG RES INDU, V3, P411
   Ogata K., 1995, Discrete-Time Control Systems
   Pittarello F, 2017, MULTIMED TOOLS APPL, V76, P4895, DOI 10.1007/s11042-016-3782-7
   RAIBLE RH, 1974, IEEE T AUTOMAT CONTR, VAC19, P248, DOI 10.1109/TAC.1974.1100574
   Riera B, 2017, IFAC PAPERSONLINE, V50, P9144, DOI 10.1016/j.ifacol.2017.08.1719
   Rossiter JA, 2018, EUR J ENG EDUC, V43, P801, DOI 10.1080/03043797.2018.1428530
   Rossiter J.A., 2014, IFAC PROC VOL, V47, P10568, DOI [10.3182/20140824-6-ZA-1003.00264, DOI 10.3182/20140824-6-ZA-1003.00264]
   Samin Wahid M., 1991, International Journal of Applied Engineering Education, V7, P392
   Sobota J, 2019, IFAC PAPERSONLINE, V52, P68, DOI 10.1016/j.ifacol.2019.08.126
   Stanisavljevic Z, 2015, MULTIMED TOOLS APPL, V74, P3843, DOI 10.1007/s11042-013-1802-4
   Sui T, 2019, MULTIMED TOOLS APPL, V78, P1183, DOI 10.1007/s11042-018-6646-5
   Vámos T, 2018, MED C CONTR AUTOMAT, P78, DOI 10.1109/MED.2018.8442604
   Vatansever F, 2019, ULUDAG U J FACULTY E, V24, P229, DOI [10.17482/uumfd.545361, DOI 10.17482/UUMFD.545361]
   Vatansever F, 2019, ACAD PERSPECTIVE PRO, V2, P476, DOI [10.33793/acperpro.02.03.37, DOI 10.33793/ACPERPRO.02.03.37]
   Vatansever F, 2017, COMPUT APPL ENG EDUC, V25, P625, DOI 10.1002/cae.21826
   Wang CB, 2019, MULTIMED TOOLS APPL, V78, P1149, DOI 10.1007/s11042-018-6520-5
   Zhang ZN, 2021, MULTIMED TOOLS APPL, V80, P575, DOI 10.1007/s11042-020-09684-x
NR 45
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15338-5
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400020
DA 2024-07-18
ER

PT J
AU Singh, N
   Bhat, A
AF Singh, Nishant
   Bhat, Aruna
TI A robust model for improving the quality of underwater images using
   enhancement techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Underwater image enhancement; Contrast Improvement; Color Improvement;
   Comparative Universal Stretching (CUS)
ID COLOR
AB Underwater image enhancement is an important research field that is now being addressed across the world. The primary reason for this is that water scatters and absorbs light, resulting in images with extremely low contrast and color cast. Hence, in order to overcome this issue with underwater images, we designed a simple and effective method. This method is split into two parts. The first section focuses on boosting contrast, while the second on improving color. To begin with, under the RGB colour model, contrast enhancement equalizes the G and B channels. Each R, G, and B channel's histogram is then redistributed using effective parameters connected with the intensity distribution in the input image and the wavelength attenuation of various colors underwater. The noise is subsequently reduced using a bilateral filtering technique, which only keeps important facts in an underwater image but also increases local information. In the second section, the color is enhanced by increasing the L component and modifying the 'a' and 'b' components of the CIE lab color space. Experiment findings show that the suggested method outperforms alternative strategies. Our enhanced results stand out for their brilliant color, greater contrast, and enhanced features. When compared to other approaches, the values of entropy, mean square error (MSE), peak signal to noise ratio (PSNR), underwater color image quality evaluation (UCIQE), and underwater image quality measures are 7.88, 920.20, 18.92, 0.596, and 2.734, respectively. This technique improves image quality by increasing entropy, PSNR, and UCIQE values while lowering MSE. It is an entirely algorithm-based technique that is independent by image datasets. The images used to evaluate the results come from a variety of datasets, and their enhanced performance confirms their robustness. Because of its single image-based approach, our method is very compelling in terms of processing speed. Comprehensive findings on a variety of underwater image datasets demonstrate that our approach outperforms the vast majority of them. For these reasons, the Comparative Universal Stretching approach is better than others.
C1 [Singh, Nishant] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 110042, Delhi, India.
   [Bhat, Aruna] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 110042, Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Bhat, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 110042, Delhi, India.
EM aruna.bhat@dtu.ac.in
RI Bhat, Aruna/GSI-4485-2022; Singh, Nishant/AAT-9718-2020
OI Bhat, Aruna/0000-0002-5475-8664; Singh, Nishant/0000-0003-2597-7726
CR [Anonymous], 2016, Journal of Telecommunication, Electronic and Computer Engineering
   Ben Tamou A, 2018, LECT NOTES COMPUT SC, V10884, P275, DOI 10.1007/978-3-319-94211-7_30
   Bhat A, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9417963
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chen BH, 2020, IEEE SIGNAL PROC LET, V27, P1670, DOI 10.1109/LSP.2020.3024990
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu ZQ, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116622
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Ghani ASA, 2014, INT J NAV ARCH OCEAN, V6, P840, DOI 10.2478/IJNAOE-2013-0217
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Han RY, 2020, IEEE ACCESS, V8, P218838, DOI 10.1109/ACCESS.2020.3041280
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Islam MJ, 2020, Arxiv, DOI arXiv:2002.01155
   Kareem Hana H., 2019, IOP Conference Series: Materials Science and Engineering, V571, DOI 10.1088/1757-899X/571/1/012125
   Lai YT, 2022, FRONT MAR SCI, V9, DOI 10.3389/fmars.2022.1047053
   Lee ZP, 2015, REMOTE SENS ENVIRON, V169, P139, DOI 10.1016/j.rse.2015.08.002
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu CW, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9455997
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Middleton W.E.K, 1957, Vision Through the Atmosphere, P254, DOI [10.1007/978-3-642-45881-1_3, DOI 10.1007/978-3-642-45881-1_3]
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Peng LT, 2022, Arxiv, DOI arXiv:2111.11843
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Shen LH, 2019, IEEE T MULTIMEDIA, V21, P1093, DOI 10.1109/TMM.2018.2871955
   Singh N., 2021, 2021 INT C ARTIFICIA, P1, DOI [10.1109/AIMV53313.2021.9670938, DOI 10.1109/AIMV53313.2021.9670938]
   Soni OK, 2020, INT CONF COMM SYST, P333, DOI [10.1109/CSNT.2020.61, 10.1109/CSNT48778.2020.9115732]
   Ulutas G, 2021, MULTIMED TOOLS APPL, V80, P15067, DOI 10.1007/s11042-020-10426-2
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang WD, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.106981
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
NR 39
TC 0
Z9 0
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15617-1
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600002
DA 2024-07-18
ER

PT J
AU Tenali, N
   Babu, GRM
AF Tenali, Nagamani
   Babu, Gatram Rama Mohan
TI HQDCNet: Hybrid Quantum Dilated Convolution Neural Network for detecting
   covid-19 in the context of Big Data Analytics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Quantum; Convolution Neural Network; Big Data; Clustering; Distributed
   Computing Server; Map-Reduce
AB Medical care services are changing to address problems with the development of big data frameworks as a result of the widespread use of big data analytics. Covid illness has recently been one of the leading causes of death in people. Since then, related input chest X-ray image for diagnosing COVID illness have been enhanced by diagnostic tools. Big data technological breakthroughs provide a fantastic option for reducing contagious Covid disease. To increase the model's confidence, it is necessary to integrate a large number of training sets, however handling the data may be difficult. With the development of big data technology, a unique method to identify and categorise covid illness is now found in this research. In order to manage incoming big data, a massive volume of chest x-ray images is gathered and analysed using a distributed computing server built on the Hadoop framework. In order to group identical groups in the input x-ray images, which in turn segments the dominating portions of an image, the fuzzy empowered weighted k-means algorithm is then employed. A hybrid quantum dilated convolution neural network is suggested to classify various kinds of covid instances, and a Black Widow-based Moth Flame is also shown to improve the performance of the classifier pattern. The performance analysis of COVID-19 detection makes use of the COVID-19 radiography dataset. The suggested HQDCNet approach has an accuracy of 99.01. The experimental results are evaluated in Python using performance metrics such as accuracy, precision, recall, f-measure, and loss function.
C1 [Tenali, Nagamani] Acharya Nagarjuna Univ, YS Rajasekhar Reddy Univ Coll Engn & Technol, Dept CSE, Guntur, India.
   [Babu, Gatram Rama Mohan] RVR & JC Coll Engn, Comp Sci & Engn AI&ML, Guntur, India.
C3 Acharya Nagarjuna University; RVR & JC College of Engineering
RP Tenali, N (corresponding author), Acharya Nagarjuna Univ, YS Rajasekhar Reddy Univ Coll Engn & Technol, Dept CSE, Guntur, India.
EM tenalinagamani@gmail.com; rmbgatram@gmail.com
RI Gatram, Rama Mohan Babu/Q-1888-2015; Tenali, Nagamani/AEM-6225-2022
OI Tenali, Nagamani/0000-0003-1220-5858
CR Aboughazala L.M., 2020, Al-Azhar Univ. J. Virus Res. Stud, V2, P1
   Acter T, 2020, SCI TOTAL ENVIRON, V730, DOI 10.1016/j.scitotenv.2020.138996
   Amen B, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108404
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Awan MJ, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph181910147
   Awasthi N, 2021, IEEE T ULTRASON FERR, V68, P2023, DOI 10.1109/TUFFC.2021.3068190
   Bandaru SB, 2022, INT J COMPUT SCI NET, V22, P671, DOI 10.22937/IJCSNS.2022.22.4.78
   Bhatt DP, 2021, J INTERDISCIP MATH, V24, P381, DOI 10.1080/09720502.2021.1884385
   Chmielewska B, 2021, LANCET GLOB HEALTH
   Dairi A, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3130675
   Deng W, 2020, BMC INFECT DIS, V20, DOI 10.1186/s12879-020-05151-y
   Dhiman G, 2022, J BIOMOL STRUCT DYN, V40, P5836, DOI 10.1080/07391102.2021.1875049
   Dong SJ, 2021, IEEE T NEUR NET LEAR, V32, P3401, DOI 10.1109/TNNLS.2021.3086570
   Guo GY, 2021, IEEE J BIOMED HEALTH, V25, P1347, DOI 10.1109/JBHI.2021.3060035
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jasim H.A., 2022, 2022 INT C HUMAN COM, P1
   Kooraki S, 2020, J AM COLL RADIOL, V17, P447, DOI 10.1016/j.jacr.2020.02.008
   Kumar MD, 2021, MULTIMED TOOLS APPL, V80, P7939, DOI 10.1007/s11042-020-10000-w
   Kumar Mikkili Dileep, 2021, Ann Romanian Soc Cell Biol, P1536
   Mehta Nishita, 2022, SN Comput Sci, V3, P54, DOI 10.1007/s42979-021-00923-y
   Mikkili DK., 2023, MULTIMEDIA TOOLS APP, DOI [10.1007/s11042-023-14605-9, DOI 10.1007/S11042-023-14605-9]
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Panetta K, 2021, IEEE J BIOMED HEALTH, V25, P1852, DOI 10.1109/JBHI.2021.3069798
   Prasad KS, 2022, 2022 INT C COMPUTER, P1, DOI [10.1109/ICCCI54379.2022.9741050, DOI 10.1109/ICCCI54379.2022.9741050]
   Prasad KS, 2019, INT J EMERG TECHNOL, V10, P467
   Roy S, 2021, MODEL EARTH SYST ENV, V7, P1385, DOI 10.1007/s40808-020-00890-y
   Shah V, 2021, EMERG RADIOL, V28, P497, DOI 10.1007/s10140-020-01886-y
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Tang SJ, 2021, IEEE T IND INFORM, V17, P6539, DOI 10.1109/TII.2021.3057683
   Tenali N, 2023, NEW GENERAT COMPUT, V41, P243, DOI 10.1007/s00354-023-00211-8
   Tian SF, 2020, J THORAC ONCOL, V15, P700, DOI 10.1016/j.jtho.2020.02.010
   Zhao X, 2020, CLIN RADIOL, V75, P335, DOI 10.1016/j.crad.2020.03.002
NR 32
TC 3
Z9 3
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15515-6
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600010
PM 37362720
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Gautam, S
   Singhai, J
AF Gautam, Swati
   Singhai, Jyoti
TI Critical review on deep learning methodologies employed for water-body
   segmentation through remote sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Water body segmentation; Image segmentation; Remote sensing imagery;
   Deep learning; Satellite imagery
ID SEMANTIC SEGMENTATION; SATELLITE IMAGES; NEURAL-NETWORK; EXTRACTION;
   BODIES; MODEL; INDEX
AB In remote sensing along with image interpretation, water body segmentation (WBS) is a significant problem. Over the course of a long period of time, the researchers have been studying about the remotely sensed image's potentiality for researching the natural resources like water. The scientific group has a vast curiosity in learning about water as it is an indispensable natural resource that needs to be preserved. Owing to the critical variations in the water bodies' shape, size, color and texture, the WBS in higher-resolution satellite imagery is highly challenging. To extract the water body from Remote Sensing Images (RSIs), numerous WBS models have been developed in the past. Nevertheless, water boundaries' accurate position was not obtained by fundamental methodologies. Evolvement of Deep Learning (DL) architectures caused a boom in the field of remote sensing image analysis with their magnificent results in terms of accuracy, robustness, speed etc. The emerging DL methodologies signified advanced execution on numerous public data sets, even though phenomenal actions have been dedicated on improving pixel-level accuracy. This study focusses on critically reviewing the deep learning architectures for WBS with the proper enlisting of their results, advantages and disadvantages to make the information available on single platform for readers. Also, how DL models tried to resolve the imperfect extraction faced by fundamental WBS models is discussed. The main difficulty of finding large and benchmarking datasets required for training of DL models is faced by the researchers. Thus, to make the review innovative, a novel idea of enlisting the detailed information on availability of datasets along with their source is presented in this review. Comparison of different DL models on various evaluation parameters provides the researchers with a patterned development on WBS using DL done so far. Finally, the discussion has been described succeeded by the conclusion and future scope.
C1 [Gautam, Swati; Singhai, Jyoti] Maulana Azad Natl Inst Technol, Dept Elect & Commun Engn, Bhopal, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Gautam, S (corresponding author), Maulana Azad Natl Inst Technol, Dept Elect & Commun Engn, Bhopal, India.
EM swati.gautam050@gmail.com; j.singhai@gmail.com
RI Singhai, Jyoti/AAU-2844-2021
OI Singhai, Jyoti/0000-0002-7096-9269; Gautam, Swati/0000-0003-0887-408X
CR Acharya TD, 2017, MULTIDISCIPL DIGIT P, V1, P1, DOI [10.3390/ecsa-3-E005, DOI 10.3390/ECSA-3-E005]
   Acharya TD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082580
   Acharya TD, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071075
   Aher S., 2017, REMOTE SENS LAND, V1, P41, DOI [10.21523/gcj1.17010103, DOI 10.21523/GCJ1.17010103]
   Baig MHA, 2013, INT GEOSCI REMOTE SE, P2876, DOI 10.1109/IGARSS.2013.6723425
   Basaeed E, 2016, KNOWL-BASED SYST, V99, P19, DOI 10.1016/j.knosys.2016.01.028
   Behnamian A, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121209
   Bijeesh TV., 2020, J ADV RES DYN CONTRO, V12, P207, DOI [10.5373/JARDCS/V12I3/20201184, DOI 10.5373/JARDCS/V12I3/20201184]
   Boschetti M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088741
   Sánchez GC, 2018, IEEE ACCESS, V6, P72952, DOI 10.1109/ACCESS.2018.2881430
   Chen Y, 2018, WATER-SUI, V10, DOI 10.3390/w10050585
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cordeiro MCR, 2021, REMOTE SENS ENVIRON, V253, DOI 10.1016/j.rse.2020.112209
   d'Angelo P, 2019, INT GEOSCI REMOTE SE, P5053, DOI [10.1109/IGARSS.2019.8899795, 10.1109/igarss.2019.8899795]
   Demir N, 2019, GEO-MAR LETT, V39, P401, DOI 10.1007/s00367-019-00608-9
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Du Y, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040354
   Duan LH, 2020, IEEE GEOSCI REMOTE S, V17, P686, DOI 10.1109/LGRS.2019.2926412
   Ekbote M, 2017, ADV INTELL SYST, V469, P819, DOI 10.1007/978-981-10-1678-3_79
   El-naggar AM, 2018, ALEX ENG J, V57, P3089, DOI 10.1016/j.aej.2018.10.001
   Erdem F, 2021, ADV SPACE RES, V67, P964, DOI 10.1016/j.asr.2020.10.043
   Feng M, 2016, INT J DIGIT EARTH, V9, P113, DOI 10.1080/17538947.2015.1026420
   Feng WQ, 2019, IEEE GEOSCI REMOTE S, V16, P618, DOI 10.1109/LGRS.2018.2879492
   Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
   Ganesan P, 2015, ADV INTELL SYST, V309, P319, DOI 10.1007/978-81-322-2009-1_37
   Ganesan P., 2015, Intelligent Computing, Communication and Devices, P685
   Gao H, 2012, WATER RESOUR RES, V48, DOI 10.1029/2012WR012063
   Gonzalez J, 2020, 2020 IEEE LATIN AMERICAN GRSS & ISPRS REMOTE SENSING CONFERENCE (LAGIRS), P483, DOI 10.1109/LAGIRS48042.2020.9165643
   Guo HX, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9040189
   Guo QD, 2017, INT J REMOTE SENS, V38, P5430, DOI 10.1080/01431161.2017.1341667
   Guo ZS, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14071752
   Hong S, 2015, SENSORS-BASEL, V15, P6652, DOI 10.3390/s150306652
   Isikdogan F, 2017, IEEE J-STARS, V10, P4909, DOI 10.1109/JSTARS.2017.2735443
   Kaplan G, 2017, EUR J REMOTE SENS, V50, P137, DOI 10.1080/22797254.2017.1297540
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kim JH, 2019, IEEE GEOSCI REMOTE S, V16, P115, DOI 10.1109/LGRS.2018.2868880
   Kundu N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165386
   Labed K, 2018, APPL ARTIF INTELL, V32, P96, DOI 10.1080/08839514.2018.1451214
   Li MY, 2021, IEEE J-STARS, V14, P3120, DOI 10.1109/JSTARS.2021.3060769
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Liu XY, 2019, IEEE ACCESS, V7, P180281, DOI 10.1109/ACCESS.2019.2959662
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Merchant MA, 2020, REMOTE SENS LETT, V11, P1127, DOI 10.1080/2150704X.2020.1825869
   Miao ZM, 2018, IEEE GEOSCI REMOTE S, V15, P602, DOI 10.1109/LGRS.2018.2794545
   Moses Sheela A., 2013, Lakes & Reservoirs Research and Management, V18, P145, DOI 10.1111/lre.12027
   Nandi D., 2018, Int J Sci Res Sci Eng Technol, V4, P498
   Pacheco AD, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13071345
   Pai MMM, 2019, 2019 IEEE SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P15, DOI 10.1109/AIKE.2019.00011
   Poliyapram V, 2019, INT GEOSCI REMOTE SE, P3884, DOI 10.1109/IGARSS.2019.8900323
   Priya RMS, 2016, AUTOM CONTROL COMPUT, V50, P151, DOI 10.3103/S014641161603007X
   Rishikeshan C. A., 2018, ISH Journal of Hydraulic Engineering, V24, P222, DOI 10.1080/09715010.2017.1408040
   Sharifzadeh S., 2020, CALIFORNIA GEOGR, V59, P1
   Singh K, 2016, IEEE J-STARS, V9, P363, DOI 10.1109/JSTARS.2015.2504338
   Song SR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020397
   Sun Y, 2018, ISPRS J PHOTOGRAMM, V143, P3, DOI 10.1016/j.isprsjprs.2018.06.005
   Talal M., 2018, INT C SIGN PESS INF, DOI [10.1109/cspis.2018.8642743, DOI 10.1109/CSPIS.2018.8642743]
   Verpoorter C, 2012, LIMNOL OCEANOGR-METH, V10, P1037, DOI 10.4319/lom.2012.10.1037
   Vignesh T, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Wang GJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050795
   Wang ZB, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244140
   Wurm M, 2019, ISPRS J PHOTOGRAMM, V150, P59, DOI 10.1016/j.isprsjprs.2019.02.006
   Yu L, 2018, AUTOM CONTROL COMPUT, V52, P517, DOI 10.3103/S0146411618060123
   Yu L, 2017, INT J COMPUT INTELL, V16, DOI 10.1142/S1469026817500018
   Yudie W., 2019, IEEE J-STARS, V13, P768
   Zeng LF, 2017, INT J REMOTE SENS, V38, P7041, DOI 10.1080/01431161.2017.1370151
   Zhou YA, 2014, IEEE J-STARS, V7, P4301, DOI 10.1109/JSTARS.2014.2360436
NR 67
TC 2
Z9 2
U1 17
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15764-5
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F8KZ4
UT WOS:000984795600001
DA 2024-07-18
ER

PT J
AU Hu, ZH
   Wang, CH
AF Hu, Zhenhua
   Wang, Chunhua
TI Hopfield neural network with multi-scroll attractors and application in
   image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hopfield neural network; Multi-scroll attractors; Electromagnetic
   radiation; Multi-level-logic pulse; Image encryption
ID ELECTRICAL-ACTIVITY; CHAOTIC ATTRACTORS; DYNAMICS; MODEL; HYPERCHAOS;
   ALGORITHM; SYSTEM; SYNCHRONIZATION; NEURONS
AB Hopfield neural networks are favored by academia and industrial fields due to their abundant dynamics. In this paper, the dynamical behavior of a small Hopfield neural network (HNN) simultaneously stimulated by electromagnetic radiation and multi-level-logic pulse is investigated. Firstly, a modified HNN with three neurons is presented by selecting appropriate synapse weight coefficients. And the system model of the HNN under electromagnetic radiation and an electrical pulse is constructed. Then its equilibrium stabilities and nonlinear dynamical phenomena are analyzed by using numerical analysis methods including phase portraits, Lyapunov exponents, and bifurcation diagrams. The research results show that the neural network affected by electromagnetic radiation and a multi-level-logic pulse signal can generate chaotic multi-scroll attractors, which has not been observed in the previous investigation for the Hopfield-type neural networks. In addition, the number of the scroll can be easily changed by adjusting the electrical pulse signal. Circuit simulations based on the designed neural network circuit are carried out to confirm the numerical simulations. Finally, an HNN-based image encryption scheme is designed from the perspective of engineering applications. Performance evaluations demonstrate that the proposed image cryptosystem has good security.
C1 [Hu, Zhenhua; Wang, Chunhua] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Hu, Zhenhua] Hunan City Univ, Coll Sci, Yiyang 413000, Peoples R China.
C3 Hunan University; Hunan City University
RP Wang, CH (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM wch1227164@hnu.edu.cn
RI Wang, Chunhua/HCH-5464-2022
OI Wang, Chunhua/0000-0001-6522-9795
FU National Natural Science Foundation of China [62271197, 61971185];
   Natural Science Foundation of Hunan Province [2020JJ4218]
FX This work is supported by the National Natural Science Foundation of
   China (62271197,61971185), the Natural Science Foundation of Hunan
   Province (2020JJ4218).~All authors certify that they have no
   affiliations with or involvement in any organization or entity with any
   financial interest or non-financial interest in the subject matter or
   materials discussed in this manuscript.
CR Bao BC, 2018, NONLINEAR DYNAM, V92, P1695, DOI 10.1007/s11071-018-4155-8
   Bao BC, 2017, NONLINEAR DYNAM, V90, P2359, DOI 10.1007/s11071-017-3808-3
   Bao BC, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00081
   Bao H, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420300293
   Bao H, 2020, IEEE T NEUR NET LEAR, V31, P502, DOI 10.1109/TNNLS.2019.2905137
   Bao ZY, 2020, MULTIMED TOOLS APPL, V79, P7401, DOI 10.1007/s11042-019-08569-y
   Chen CJ, 2021, NONLINEAR DYNAM, V106, P2559, DOI 10.1007/s11071-021-06910-5
   Chen CJ, 2019, NONLINEAR DYNAM, V95, P3385, DOI 10.1007/s11071-019-04762-8
   CHUA LO, 1988, IEEE T CIRCUITS SYST, V35, P1257, DOI 10.1109/31.7600
   Pano-Azucena AD, 2017, NONLINEAR DYNAM, V87, P2203, DOI 10.1007/s11071-016-3184-4
   Danca MF, 2017, CHAOS SOLITON FRACT, V103, P144, DOI 10.1016/j.chaos.2017.06.002
   de Haan W, 2012, NEUROIMAGE, V59, P3085, DOI 10.1016/j.neuroimage.2011.11.055
   Ding DW, 2020, INT J MOD PHYS B, V34, DOI 10.1142/S0217979220503026
   HINDMARSH JL, 1982, NATURE, V296, P162, DOI 10.1038/296162a0
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Hong QH, 2020, NEURAL COMPUT APPL, V32, P8175, DOI 10.1007/s00521-019-04305-7
   Hong QH, 2017, NONLINEAR DYNAM, V87, P1015, DOI 10.1007/s11071-016-3094-5
   HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088
   Hu XY, 2018, NONLINEAR DYNAM, V91, P1541, DOI 10.1007/s11071-017-3963-6
   Hu YC, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/2051653
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Lakshmi C, 2020, NEURAL COMPUT APPL, V32, P11477, DOI 10.1007/s00521-019-04637-4
   Li QD, 2014, NONLINEAR DYNAM, V78, P1087, DOI 10.1007/s11071-014-1498-7
   Li ZJ, 2021, NONLINEAR DYNAM, V104, P1455, DOI 10.1007/s11071-021-06315-4
   Lin HR, 2023, IEEE T CIRCUITS-II, V70, P311, DOI 10.1109/TCSII.2022.3212394
   Lin HR, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11061369
   Lin HR, 2022, NONLINEAR DYNAM, V110, P841, DOI 10.1007/s11071-022-07630-0
   Lin HR, 2021, IEEE T CIRCUITS-I, V68, P3397, DOI 10.1109/TCSI.2021.3081150
   Lin HR, 2020, COMMUN NONLINEAR SCI, V90, DOI 10.1016/j.cnsns.2020.105390
   Lin HR, 2020, NONLINEAR DYNAM, V99, P2369, DOI 10.1007/s11071-019-05408-5
   Liu LD, 2019, IEEE ACCESS, V7, P185796, DOI 10.1109/ACCESS.2019.2961164
   Ma J, 2019, NONLINEAR DYNAM, V95, P1585, DOI 10.1007/s11071-018-4646-7
   Ma J, 2017, NONLINEAR DYNAM, V89, P1569, DOI 10.1007/s11071-017-3565-3
   Ma J, 2017, APPL MATH COMPUT, V307, P321, DOI 10.1016/j.amc.2017.03.002
   Ma XJ, 2023, INT J BIFURCAT CHAOS, V33, DOI 10.1142/S021812742350061X
   Ma XJ, 2023, MULTIMED TOOLS APPL, V82, P38967, DOI 10.1007/s11042-023-15119-0
   Nasr S, 2019, CHAOS SOLITON FRACT, V118, P366, DOI 10.1016/j.chaos.2018.12.002
   Njitacke ZT, 2020, EUR PHYS J-SPEC TOP, V229, P1133, DOI 10.1140/epjst/e2020-900205-y
   Njitacke ZT, 2021, CHAOS SOLITON FRACT, V153, DOI 10.1016/j.chaos.2021.111577
   Njitacke ZT, 2021, NEURAL COMPUT APPL, V33, P6733, DOI 10.1007/s00521-020-05451-z
   Rajagopal K, 2021, CHAOS, V31, DOI 10.1063/5.0061406
   Rech PC, 2011, NEUROCOMPUTING, V74, P3361, DOI 10.1016/j.neucom.2011.05.016
   Ren GD, 2019, APPL MATH COMPUT, V342, P45, DOI 10.1016/j.amc.2018.09.017
   Takembo CN, 2019, NONLINEAR DYNAM, V95, P1067, DOI 10.1007/s11071-018-4616-0
   Tlelo-Cuautle E, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051326
   Villoslada P, 2009, ANN NEUROL, V65, P124, DOI 10.1002/ana.21634
   Volkow ND, 2016, NEW ENGL J MED, V374, P363, DOI 10.1056/NEJMra1511480
   Wang GW, 2020, AEU-INT J ELECTRON C, V120, DOI 10.1016/j.aeue.2020.153209
   Wang HT, 2016, NONLINEAR DYNAM, V85, P881, DOI 10.1007/s11071-016-2730-4
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wang Z, 2020, CHAOS SOLITON FRACT, V134, DOI 10.1016/j.chaos.2020.109702
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/NMAT4756, 10.1038/nmat4756]
   Wen ZH, 2022, NONLINEAR DYNAM, V110, P3823, DOI 10.1007/s11071-022-07813-9
   Wu FQ, 2019, EUR PHYS J-SPEC TOP, V228, P1527, DOI 10.1140/epjst/e2019-800233-6
   Xu Y, 2018, NEUROCOMPUTING, V283, P196, DOI 10.1016/j.neucom.2017.12.036
   Yang ZQ, 2020, NONLINEAR DYNAM, V100, P647, DOI 10.1007/s11071-020-05533-6
   Ye XL, 2020, OPT LASER ENG, V127, DOI 10.1016/j.optlaseng.2019.105905
   Yu F, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111350
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang S, 2021, CHAOS SOLITON FRACT, V145, DOI 10.1016/j.chaos.2021.110761
   Zheng PS, 2010, NEUROCOMPUTING, V73, P2280, DOI 10.1016/j.neucom.2010.02.015
   Zhu Y, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11030767
NR 62
TC 15
Z9 16
U1 12
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15670-w
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9HG1
UT WOS:000985378600005
DA 2024-07-18
ER

PT J
AU Choudhary, D
   Pahuja, R
AF Choudhary, Deepak
   Pahuja, Roop
TI AI-ciphering techniques for connected vehicular Adhoc networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence (AI); Connected ad-hoc network; Intrusion
   detection; Machine learning; WSN & VANET; Security
ID INTERNET; ATTACKS; THINGS
AB The major two issues in Wireless Sensor Networks (WSN) & Vehicular Networks (VANET) remain energy and security. As a result, safeguarding these Connected Adhoc Wireless networks against DoS and Dynamic Circulated DoS (DDoS) attacks is an important security task for the Connected Adhoc Wireless networks. Traditional parcel deep sweep methods rely on open field review in transport layer security bundles and the open field encryption pattern, making AI-based frameworks the only feasible alternative for these attacks. This article investigates the application of AI computations in Connected Adhoc Wireless hub traffic and their impact on the lifespan of Connected Adhoc Wireless networks. We investigated the performance metrics of various AI arrangement classes, including K-Closest Neighbor (KNN), Strategic Relapse (LR), Backing Vector Machine (SVM), Gboost, Decision/Choice Tree (DT), Gullible Bayes, LTSM, and Multi-Facet Perceptron, on a Connected Adhoc Wireless dataset of various sizes (MLP). The test results revealed that the correct and astute grouping classifications performed best on numerically measurable datasets. When all exhibition criteria were summed, the Gboost calculation revealed the best presentation. The presenting metrics for these approvals were accuracy, F1-score, bogus positive proportion (FPR), bogus negative proportion (FNR), and preparation execution time. Furthermore, the Gboost computation obtained 99.6%, 98.8%, 0.4%, and 0.13% accuracy, F1-score, FPR, and FNR, respectively, according to test findings. The average of all preparation time execution datasets at that time was 1.41 seconds. Furthermore, this study found that the best results for the numeric measurable information type occur when the dataset is between 3000 and 6000 records in size and the rate between classifications is greater than half for each classification with different classes. This study also looked at how Gboost affects the longevity of Connected Adhoc Wireless, which dropped by 32% when compared to comparable non-Gboost circumstances.
C1 [Choudhary, Deepak; Pahuja, Roop] Dr BR Ambedkar Natl Inst Technol, Dept Instrumentat & Control Engn, Jalandhar, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Choudhary, D (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Instrumentat & Control Engn, Jalandhar, India.
EM dream2132@gmail.com
RI Pahuja, Roop/X-8544-2019
OI Pahuja, Roop/0000-0002-1575-9349
CR Abidoye AP, 2018, IET WIREL SENS SYST, V8, P52, DOI 10.1049/iet-wss.2017.0029
   Abumarshoud H, 2019, IEEE VTS VEH TECHNOL, DOI 10.1109/vtcspring.2019.8746663
   Ahmad B., 2019, REMOTE INDIVIDUAL IN, V106, P1841
   Ahmad R, 2017, 2017 IEEE 13TH MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS (MICC), P253, DOI 10.1109/MICC.2017.8311768
   Al-Kashoash HAA., 2019, REMOTE SYST, V25, P4493
   Almomani I, 2016, DIARY SENS, DOI [10.1155/2016/4731953, DOI 10.1155/2016/4731953]
   [Anonymous], 2008, P 4 IEEE IFIP WORLDW
   Ballarini P, 2013, SECUR COMMUN NETW, V6, P420, DOI 10.1002/sec.630
   Bikmukhamedov RF., 2019, SYNCHROINFO 2019
   Bin Zikria Y, 2018, FUTURE GENER COMP SY, V82, P200, DOI 10.1016/j.future.2017.12.045
   Borkar GM., 2019, FEASIBLE REGISTER IN, V23, P120
   Bouaziz M., 2016, PC INTERCHANGES, V74, P3
   Cauteruccio F., 2021, GROUP PEOPLE YET COM, V114, P322
   Cheng J., 2018, PC DIARY, V61, P959
   Choudhary D., 2021, SPRINGER P ENERGY BO, P1
   Choudhary D, 2020, ADV INTELL SYST COMP, V1154, P1
   Choudhary D, 2022, WIRELESS PERS COMMUN, V125, P1, DOI 10.1007/s11277-022-09538-9
   Coppolino L, 2013, 8 WORLDW C P2P EQ FR, P247
   Darabkh KA, 2019, AD HOC NETW, V82, P155, DOI 10.1016/j.adhoc.2018.08.012
   Depart A, 2019, SAS 2019 2019 IEEE S
   Garofalo A, 2013, RELIABLE REGISTERING, P1
   Glissa G, 2017, P 13 GLOB REM INT VE, P264
   Hameed A, 2020, P WORLDW WORKSH PC H, V2020
   Ho J-W., 2012, IMPROMPTU SYST, V10, P512
   Ioannou C, 2018, MSWIM'18: PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON MODELING, ANALYSIS AND SIMULATION OF WIRELESS AND MOBILE SYSTEMS, P259, DOI 10.1145/3242102.3242145
   Islam MNU, 2020, REMOTE INDIVIDUAL IN
   Islam SKH, 2018, FUTURE GENER COMP SY, V84, P216, DOI 10.1016/j.future.2017.07.002
   jupyter org, Project Jupyter
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kaur T, 2016, P WORLDW C LAT ADV D, P23
   Khashan OA., 2021, IMPROMPTU SYST, V115, P102448
   Koroniotis N, 2019, FUTURE GENER COMP SY, V100, P779, DOI 10.1016/j.future.2019.05.041
   Kumar PM., 2020, DIARY SUPERCOMPUT, V76, P3963, DOI [10.1007/s11227-017-2169-5, DOI 10.1007/S11227-017-2169-5]
   Kumar V, 2012, DIRECTING IPV6 LOW P, V2012
   Li W., 2014, DIARY ELECT PC DESIG, V2014, P1
   Lu X., 2020, WORLDWIDE DIARY COMP, V22, P221
   Marcel K, 2018, P 2018 ACM SIGSAC C
   Osanaiye O, 2018, SENSOR, V18
   Otoum Safa, 2019, IEEE Networking Letters, V1, P68, DOI 10.1109/LNET.2019.2901792
   Praveen Kumar D., 2019, DATA COMBIN, V49, P1
   Premkumar M, 2020, MICROCHIPS MICROSYST, V79
   Qu HC, 2018, ADV FUZZY SYST, V2018, DOI 10.1155/2018/4071851
   Sharafaldin I, 2019, INT CARN CONF SECU
   Singh KJ., 2017, DIARY DATA SECUR APP, V36, P145
   Srinivasu PN, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121437
   Sujanthi S., 2020, REMOTE INDIVIDUAL IN, V114, P2135
   Thing Vrizlynn LL, 2018, 2018 IEEE 4 WORLD FO, P231, DOI [10.1109/WF-IoT.2018.8355132, DOI 10.1109/WF-IOT.2018.8355132]
   Vangipuram R., 2020, MASTER FRAMEWORKS, V37, P1
   Vishwakarma R, 2020, TELECOMMUN SYST, V73, P3, DOI 10.1007/s11235-019-00599-z
   Wu D, 2020, IEEE T IND INFORM, V16, P5244, DOI 10.1109/TII.2019.2952917
   Yang YC, 2017, IEEE INTERNET THINGS, V4, P1250, DOI 10.1109/JIOT.2017.2694844
   Yi LT, 2019, IEEE ACCESS, V7, P53079, DOI 10.1109/ACCESS.2019.2911395
   Zhang GY, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/3126010
   Zhang W., 2020, DELICATE PROCESS, V24, P12361
   Zhang XY, 2012, SECUR COMMUN NETW, V5, P789, DOI 10.1002/sec.375
NR 55
TC 2
Z9 2
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 9
PY 2023
DI 10.1007/s11042-023-15642-0
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9KB5
UT WOS:000985452800012
DA 2024-07-18
ER

PT J
AU Zhang, GF
   Chen, JX
   Lu, WP
   Liu, ZH
AF Zhang, Guifang
   Chen, Jiaxin
   Lu, Wenpeng
   Liu, Zhonghua
TI Weighted non-negative matrix factorization based on adaptive robust
   local sparse graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NMF; Local constraints; Sparse constraints; Weighting matrix; Adaptive
   robust local sparse graph
AB As an efficient and intuitive dimension reduction algorithm, non-negative matrix factorization (NMF) has been widely employed in various fields. However, the existing NMF based methods have two disadvantages. Firstly, it treats each sample equally without considering the noise problem. Secondly, it does not restrict the coefficient matrix. Therefore, this paper proposes a novel weighted NMF algorithm based on adaptive robust local sparse graph (WNMF-ARLS), which includes the following superiorities compared with the other NMF-based algorithms: 1) The proposed method introduces a weighting regularization term, which distributes smaller weights to outliers and noise, and allocates larger weights to clean data. 2) Our method constructs a sparse local constraint graph to discover the data's potential manifold structure. 3) Unlike most NMF algorithms based on graph regularization, in which the graphs remain unchanged and are pre-defined during the NMF process, the proposed method introduces sparse constraints and local constraints into the unified framework to adaptively construct the optimization graph. Lots of image clustering experiments are provided to illustrate the effectiveness and superiority of the proposed WNMF-ARLS algorithm. Experimental results also show that the clustering performance of the proposed method is significantly better than that of other comparison algorithms.
C1 [Zhang, Guifang; Chen, Jiaxin; Liu, Zhonghua] Henan Univ Sci & Technol, Sch Informat Engn, Luoyang, Peoples R China.
   [Lu, Wenpeng] Qilu Univ Technol, Shandong Acad Sci, Sch Comp Sci & Technol, Jinan, Peoples R China.
C3 Henan University of Science & Technology; Qilu University of Technology
RP Zhang, GF (corresponding author), Henan Univ Sci & Technol, Sch Informat Engn, Luoyang, Peoples R China.
EM zgf1563829811@163.com; lzhua_217@163.com
OI Zhang, Guifang/0000-0003-1120-8299
FU NSFC of China [U1504610, 61971339, 61471161]; Scientific and
   Technological Innovation Team of Colleges and Universities in Henan
   Province [20IRTSTHN018]; Natural Science Foundations of Henan Province
   [202300410148]; Key scientific research projects in Colleges and
   Universities [22A120006]
FX AcknowledgementsThis work was partly supported by NSFC of China
   (U1504610, 61971339, 61471161), the Scientific and Technological
   Innovation Team of Colleges and Universities in Henan Province
   (20IRTSTHN018), the Natural Science Foundations of Henan Province
   (202300410148), Key scientific research projects in Colleges and
   Universities (22A120006).
CR Bai Y, 2021, IEEE T IMAGE PROCESS, V30, P6715, DOI 10.1109/TIP.2021.3094140
   Ben Harnza A, 2006, IEEE T SIGNAL PROCES, V54, P3637, DOI 10.1109/TSP.2006.879282
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chandran SN, 2021, MULTIMED TOOLS APPL, V80, P35741, DOI 10.1007/s11042-021-11542-3
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Dai XG, 2022, COMPLEX INTELL SYST, V8, P753, DOI 10.1007/s40747-021-00285-1
   Ding C, 2012, INT CONF ACOUST SPEE, P2033, DOI 10.1109/ICASSP.2012.6288308
   Han C, 2013, 11 INT S OP RES ITS
   He X, 2019, IEEE ACCESS, V7, P83101, DOI 10.1109/ACCESS.2019.2924520
   Hu SZ, 2021, IEEE T KNOWL DATA EN, V33, P1113, DOI 10.1109/TKDE.2019.2937026
   Hu WB, 2021, INFORM SCIENCES, V568, P199, DOI 10.1016/j.ins.2021.03.066
   Huang D, 2018, IEEE T CYBERNETICS, V48, P1460, DOI 10.1109/TCYB.2017.2702343
   Huang J, 2014, ACM T KNOWL DISCOV D, V8, DOI 10.1145/2601434
   Huang SD, 2017, IEEE IJCNN, P486, DOI 10.1109/IJCNN.2017.7965893
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kong D., 2011, P 20 ACM INT C INF K, P673, DOI DOI 10.1145/2063576.2063676
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li XL, 2020, PATTERN ANAL APPL, V23, P967, DOI 10.1007/s10044-019-00832-0
   Li ZC, 2018, IEEE T NEUR NET LEAR, V29, P1947, DOI 10.1109/TNNLS.2017.2691725
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu ZH, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107907
   Lu WP, 2021, IEEE INTELL SYST, V36, P6, DOI 10.1109/MIS.2020.3021188
   Wen J, 2019, IEEE T CYBERNETICS, V49, P1279, DOI 10.1109/TCYB.2018.2799862
   Xie J, 2010, 2010 2 INT WORKSH ED
   Yang ZY, 2020, IEEE T SYST MAN CY-S, V50, P2524, DOI 10.1109/TSMC.2018.2820084
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Zhang L, 2020, APPL INTELL, V50, P438, DOI 10.1007/s10489-019-01539-9
   Zhang Q, 2017, 2017 4 IAPR AS C PAT
   Zhang Qilong, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P819, DOI 10.1109/CSSE.2008.1454
   Zhu F, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108422
   Zhu F, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2020.106941
NR 32
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46313
EP 46330
DI 10.1007/s11042-023-15629-x
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985452800006
DA 2024-07-18
ER

PT J
AU Feng, LY
   Zhang, XL
   Peng, XF
   Zhuang, MX
AF Feng, Liying
   Zhang, Xiaoli
   Peng, Xiafu
   Zhuang, Mingxi
TI Improved monocular visual-inertial odometry with point and line features
   using adaptive line feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual-inertial odometry; Point and line features; Nonlinear
   optimization; Image preprocessing; Extraction of line features;
   Initialization procedure
ID SEGMENT DETECTOR; EFFICIENT; ROBUST
AB With the development of intelligent era, the application of UAVs is more and more extensive, and positioning and navigation technology is the key. Among them, the monocular VIO algorithm, with its advantages of lightweight and low cost, is the research focus of scholars today. However, VIO algorithm based on point features is easy to fail to locate in environments with weak texture, because it cannot extract enough corner features. In this paper, we propose a visual-inertial odometry based on point and line features, which is a tightly-coupled monocular one optimized in real time. In order to improve the positioning accuracy in the low light environments, we propose an image preprocessing algorithm based on adaptive strategy to increase the number of features detected. In order to reduce the difficulty of line feature matching, the method of grouping first and then merging is used to merge the wrongly segmented long line segment features. This also reduces the chasm of line features. At the same time, in the initialization procedure, a least square problem is used to estimate the acceleration bias to improve accuracy in localization. Experiments in the benchmark EuRoc dataset show that under the same operating environments and experimental parameter settings, our algorithm has higher accuracy and better robustness in localization than several mainstream visual-inertial odometry algorithms that only use point features. At the same time, compared with PLF-VINS, IPL-VINS and PL-VINS, the error in localization of our algorithm is reduced by about 0.6%, 18.9% and 9.7%.
C1 [Feng, Liying; Zhang, Xiaoli; Peng, Xiafu; Zhuang, Mingxi] Xiamen Univ, Sch Aerosp Engn, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Zhang, XL (corresponding author), Xiamen Univ, Sch Aerosp Engn, Xiamen 361005, Peoples R China.
EM zhangxl_xmu@163.com
CR Abdat F, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P71, DOI 10.1109/ROMAN.2008.4600645
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321
   Forster C, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Fu Q., 2020, arXiv
   Geneva P, 2020, IEEE INT CONF ROBOT, P4666, DOI [10.1109/ICRA40945.2020.9196524, 10.1109/icra40945.2020.9196524]
   He YJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041159
   Kaehler A, 2013, LEARNING OPENCV COMP, DOI [10.5555/2523356, DOI 10.5555/2523356]
   Kaiser J, 2017, IEEE ROBOT AUTOM LET, V2, P18, DOI 10.1109/LRA.2016.2521413
   Lee J, 2021, IEEE ROBOT AUTOM LET, V6, P7033, DOI 10.1109/LRA.2021.3095518
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Li JY, 2019, IEEE INT C INT ROBOT, P6230, DOI [10.1109/iros40897.2019.8968456, 10.1109/IROS40897.2019.8968456]
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251
   Lu XH, 2015, IEEE IMAGE PROC, P507, DOI 10.1109/ICIP.2015.7350850
   Martinelli A, 2014, INT J COMPUT VISION, V106, P138, DOI 10.1007/s11263-013-0647-7
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Qin T, 2019, Arxiv, DOI arXiv:1901.03638
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Qin T, 2017, IEEE INT C INT ROBOT, P4225, DOI 10.1109/IROS.2017.8206284
   Shen SJ, 2015, IEEE INT CONF ROBOT, P5303, DOI 10.1109/ICRA.2015.7139939
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wolf H, 2011, J EXP BIOL, V214, P1629, DOI 10.1242/jeb.038570
   Xu B, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12182901
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Yang YL, 2019, IEEE INT C INT ROBOT, P2447, DOI [10.1109/iros40897.2019.8967905, 10.1109/IROS40897.2019.8967905]
   Yang YL, 2019, IEEE T ROBOT, V35, P1399, DOI 10.1109/TRO.2019.2927835
   Yang YL, 2019, IEEE INT CONF ROBOT, P6094, DOI [10.1109/icra.2019.8794078, 10.1109/ICRA.2019.8794078]
   Zhang LL, 2013, J VIS COMMUN IMAGE R, V24, P794, DOI 10.1016/j.jvcir.2013.05.006
   Zhang T, 2022, DRONES-BASEL, V6, DOI 10.3390/drones6010023
NR 35
TC 0
Z9 0
U1 14
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 6
PY 2023
DI 10.1007/s11042-023-15597-2
EA MAY 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F5KI3
UT WOS:000982729800002
DA 2024-07-18
ER

PT J
AU Huang, LK
   Tseng, HT
   Hsieh, CC
   Yang, CS
AF Huang, Li-Kun
   Tseng, Hsiao-Ting
   Hsieh, Chen-Chiung
   Yang, Chih-Sin
TI Deep learning based text detection using resnet for feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text segmentation; Deep learning models; Convolutional neural network;
   Feature extraction; Optical character recognition
ID CHARACTER-RECOGNITION
AB Popular deep learning models for text segmentation include CTPN, EAST, and PixelLink. However, they are not very well capable of dealing with the images containing densely distributed characters, and those characters may be connected. For these problems, the ResNet with excellent sensitivity for feature extraction is used to replace those embedded convolution neural networks in the main structures of CTPN and EAST. The experimental results showed that a better feature extraction network could significantly improve the precision of text localization. Noteworthy, the results indicate that the accuracy of modified EAST with ResNet101 would be the highest with a deeper depth and larger width of ResNet. The accuracy of text segmentation on ICDAR 2015 is 83.4% which is 7% higher than the original PVANET-EAST. The text detection accuracy is 83.9% on the untrained scanned document. Also, it achieved an accuracy of 86.3% when applied to self-collected Chinese calligraphy. Those results demonstrated that text detection using ResNet is a better improvement for OCR applications.
C1 [Huang, Li-Kun] Natl Tsing Hua Univ, Inst Bioinformat & Struct Biol, Coll Life Sci, Sec 2,Kuangfu Rd East Dist, Hsinchu 300, Taiwan.
   [Tseng, Hsiao-Ting] Natl Cent Univ, Dept Informat Management, 300 Zhongda Rd, Taoyuan City 320, Taiwan.
   [Hsieh, Chen-Chiung; Yang, Chih-Sin] Tatung Univ, Dept Comp Sci & Engn, 40 Sec 3,Jhongshan N Rd, Taipei City 104, Taiwan.
C3 National Tsing Hua University; National Central University
RP Hsieh, CC (corresponding author), Tatung Univ, Dept Comp Sci & Engn, 40 Sec 3,Jhongshan N Rd, Taipei City 104, Taiwan.
EM cchsieh@gm.ttu.edu.tw
RI Tseng, Hsiao-Ting/E-3346-2013
OI Tseng, Hsiao-Ting/0000-0002-8289-5236
CR AGAZZI OE, 1993, PATTERN RECOGN, V26, P1813, DOI 10.1016/0031-3203(93)90178-Y
   Bahlmann C, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P49, DOI 10.1109/IWFHR.2002.1030883
   Bora MB, 2020, PROCEDIA COMPUT SCI, V167, P2403, DOI 10.1016/j.procs.2020.03.293
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong C, 1999, WORLD SCI, P223, DOI [10.1142/9789812797643_0014, DOI 10.1142/9789812797643_0014]
   Jawahar CV, 2003, PROC INT CONF DOC, P408
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kim KH, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1608.08021
   Laroca R., 2018, P INT JOINT C NEUR N, P1
   Li CL, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/6406856
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17
   Liu FG, 2019, IEEE ACCESS, V7, P44219, DOI 10.1109/ACCESS.2019.2908933
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lixia Chen, 2021, 2021 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA), P405, DOI 10.1109/AEECA52519.2021.9574199
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu MH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135962
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Naiemi F, 2022, MULTIMED TOOLS APPL, V81, P20255, DOI 10.1007/s11042-022-12693-7
   Naiemi F, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114549
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Pang B, 2020, P ACMIEEE JOINT C DI, P253, DOI [10.1145/3383583.3398516, DOI 10.1145/3383583.3398516]
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santos CFG, 2018, OPTICAL CHARACTER RE
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shuyan Zhao, 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P179, DOI 10.1109/ICDAR.2001.953779
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Tong X, 1996, VLC COLING
   Wang C, 2015, I C VIRTUAL REALITY, P109, DOI 10.1109/ICVRV.2015.45
   Wang HB, 2019, IEEE INT CONF ELECTR, P147, DOI [10.1109/ICEIEC.2019.8784576, 10.1109/iceiec.2019.8784576]
   Wei XH, 2005, PROC INT CONF DOC, P645
   Zhang RY, 2017, PROC INT CONF DOC, P25, DOI 10.1109/ICDAR.2017.324
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 43
TC 0
Z9 0
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46871
EP 46903
DI 10.1007/s11042-023-15449-z
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000014
DA 2024-07-18
ER

PT J
AU Chow, TE
   Yip, PSF
   Wong, KP
AF Chow, T. Edwin
   Yip, Paul S. F.
   Wong, Kwan-Po
TI An integrated framework of mobile crowd estimation for the 2019, July
   1st rally in Hong Kong
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Crowd counting; Capture-recapture; Mobile
   crowd estimation; Big rally
ID PEOPLE
AB Traditional approach of mobile crowd estimation involves counting a group of individuals at a specific place, manually, in real-time. It is a laborious exercise that can be physically and mentally demanding. In Hong Kong, a large rally can last more than six hours, making the manual count method susceptible to human errors. While crowd counting using object detection and tracking has been well-established in computer vision, such application has remained relatively small scale within a controlled indoor setting (e.g. counting people at fixed gateways in a mall). No attempt to date has applied the automatic crowd counting method to count hundreds of thousands of people along an open stretch of rally route within the complex urban outdoor landscape. This research proposed an integrated approach that combines the capture-recapture method in statistics and a Convolutional Neural Network (CNN) method in computer vision to count the mobile crowd. The research teams implemented the integrative approach and counted 276,970 people with a 95% confidence interval of 263,663 to 290,276 in the 2019, July 1(st) Rally in Hong Kong. This work counted the attendance of a large-scale rally as a proof of concept to fill in a gap in the empirical studies. The intellectual merits and research findings shed useful insights to improve mobile population estimation and leverage alternative data sources to support related scientific applications.
C1 [Chow, T. Edwin] Texas State Univ, Dept Geog & Environm Studies, San Marcos, TX 78666 USA.
   [Yip, Paul S. F.] Univ Hong Kong, Dept Social Work & Social Adm, Hong Kong, Peoples R China.
   [Wong, Kwan-Po] C&R Wise AI Ltd, Cambridge, England.
C3 Texas State University System; Texas State University San Marcos;
   University of Hong Kong
RP Chow, TE (corresponding author), Texas State Univ, Dept Geog & Environm Studies, San Marcos, TX 78666 USA.
EM chow@txstate.edu
RI ; Yip, Paul Siu Fai/D-4954-2009
OI Chow, T. Edwin/0000-0002-0386-5902; Wong, Kwan-Po/0009-0001-5754-0505;
   Yip, Paul Siu Fai/0000-0003-1596-4120
CR Abirami B, 2020, MATER TODAY-PROC, V33, P4708, DOI 10.1016/j.matpr.2020.08.350
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   Barrera O, 2020, J PUBLIC ECON, V182, DOI 10.1016/j.jpubeco.2019.104123
   Beyerlein K, 2018, SOCIOL METHOD RES, V47, P384, DOI 10.1177/0049124116661574
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chan AB, 2009, WORKSH PERF EV TRACK
   Chow TE, 2019, CARTOGR GEOGR INF SC, V46, P2, DOI 10.1080/15230406.2018.1524314
   Conte R, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00668
   Fisher DR, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw5461
   Hashemzadeh M, 2014, MULTIMED TOOLS APPL, V72, P453, DOI 10.1007/s11042-013-1367-2
   HKPORI, 2019, HKPORI WILL PLATF CO
   Hong Kong University Public Opinion Programme, 2018, JUL 1 RALL CROWD EST
   Jacobs H., 1967, COLUMBIA JOURNAL REV, V5, P37
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Lemos C, 2014, P 5 WORLD C SOCIAL S
   Liu Yuting, 2020, UNSUPERVISED CROWD C
   McPhail Clark., 2004, Contexts, V3, P12, DOI [DOI 10.1525/CTX.2004.3.3.12, 10.1525/CTX.2004.3.3.12]
   Mekni M., 2014, INT J MATH COMPUT SI, V8, P46
   Miao YQ, 2019, PATTERN RECOGN LETT, V125, P113, DOI 10.1016/j.patrec.2019.04.012
   Phuc Thinh Do, 2021, 2021 8th NAFOSTED Conference on Information and Computer Science (NICS), P65, DOI 10.1109/NICS54270.2021.9701500
   Raybould M., 2000, EVENT MANAGEMENT, V6, P25
   Reddy MKK, 2022, IEEE T MULTIMEDIA, V24, P1008, DOI 10.1109/TMM.2021.3062481
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Sam DB, 2019, AAAI CONF ARTIF INTE, P8868
   Scarr S, 2019, MANY PROTESTERS TOOK
   Sun Z, 2022, INT C EL ENG BIG DAT
   Torrens PM, 2013, ANN ASSOC AM GEOGR, V103, P20, DOI 10.1080/00045608.2012.685047
   Watson Ray., 2011, SIGNIFICANCE, V8, P104, DOI DOI 10.1111/J.1740-9713.2011.00502.X
   Yip PSF, 2010, AUST NZ J STAT, V52, P17, DOI 10.1111/j.1467-842X.2009.00562.x
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43349
EP 43366
DI 10.1007/s11042-023-15417-7
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000982739000011
PM 37362686
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wang, WK
   Hu, HP
   Cao, SF
   Song, N
AF Wang, Wenke
   Hu, Hongping
   Cao, Shengfang
   Song, Na
TI Adaptive single image defogging based on sky segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dark channel prior; Sky segmentation; Information entropy; Color
   distortion; Transmittance
ID DEEP RETINEX NETWORK; ENHANCEMENT
AB Aimed at image distortion caused in process of defogging images and interfered by bright objects, a single adaptive image defogging method based on sky segmentation is proposed in this paper. Firstly, the combination of the dark channels and bright channels is used to estimate the atmospheric light. And then the sky region and the accurate atmospheric light are obtained by the information entropy and the dark channel prior. Next, the initial transmittance is estimated by the dark channel prior, and then the fast guiding filter is utilized to estimate the transmittance accurately. Further, an adaptive weight factor and an error amplification compensation factor of bright objects are introduced to optimize the transmittance mapping constraint and to correct the sky region and the non-sky region, respectively. Finally, bright adjustments are performed on the fog-free image obtained from the atmospheric scattering model by a nonlinear mapping method, which causes a clearer and more natural defogging image to be got. The experimental results show that adaptive single image defogging algorithms proposed in this paper has the higher value of peak signal-to-noise ratio, the higher value of structural similarity index measure, the higher value of naturalness image quality evaluator, the higher value of fog aware density evaluator, and the less time consumed, which illustrates that the adaptive single image defogging algorithm proposed in this paper has a better defogging effect on haze images with sky areas and bright objects.
C1 [Wang, Wenke; Hu, Hongping; Cao, Shengfang; Song, Na] North Univ China, Sch Math, Taiyuan 030051, Peoples R China.
C3 North University of China
RP Hu, HP (corresponding author), North Univ China, Sch Math, Taiyuan 030051, Peoples R China.
EM hhp92@163.com
FU basic research program of Shanxi Province [20210302123019,
   20210302123031]; Shanxi Scholarship Council of China [2020-104]
FX This work was supported in part by basic research program of Shanxi
   Province (Grant No.20210302123019, and 20210302123031), and Shanxi
   Scholarship Council of China (Grant No. 2020-104).
CR Baig N, 2016, IEEE SIGNAL PROC LET, V23, P853, DOI 10.1109/LSP.2016.2559805
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bo Zhao, 2021, Arabian Journal of Geosciences, V14, DOI 10.1007/s12517-020-06292-9
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Guo Q, 2022, IEEE T BROADCAST, V68, P876, DOI 10.1109/TBC.2022.3187816
   He K, 2015, ARXIV, DOI DOI 10.48550/ARXIV.1505.00996
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hu XW, 2019, IEEE T INTELL TRANSP, V20, P1010, DOI 10.1109/TITS.2018.2838132
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kang XD, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3101491
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Kumar Rahul, 2021, IEEE Transactions on Intelligent Transportation Systems, V22, P6536, DOI 10.1109/TITS.2020.2993906
   Li B, 2015, IEEE INT C COMPUTER, P4780
   Li H, 2021, IEEE MULTIMEDIA, V28, P97, DOI 10.1109/MMUL.2021.3052821
   Li PY, 2021, IEEE T IMAGE PROCESS, V30, P1100, DOI 10.1109/TIP.2020.3040075
   Li XM, 2022, EUR RADIOL, V32, P771, DOI 10.1007/s00330-021-08198-w
   Li Z, 2021, INT C PATT RECOG, P8267, DOI 10.1109/ICPR48806.2021.9412595
   Liu W, 2021, IEEE T IMAGE PROCESS, V30, P176, DOI 10.1109/TIP.2020.3033402
   Liu W, 2020, IEEE T IMAGE PROCESS, V29, P7819, DOI 10.1109/TIP.2020.3007844
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narasimhan SG, 2001, PROC CVPR IEEE, P186
   Narasimhan SG, 2002, LECT NOTES COMPUT SC, V2352, P148
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Raikwar SC, 2020, IEEE T IMAGE PROCESS, V29, P4832, DOI 10.1109/TIP.2020.2975909
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P1895, DOI 10.1109/TIP.2018.2876178
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Sahu G, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103008
   Sharma N, 2021, ARCH COMPUT METHOD E, V28, P4449, DOI 10.1007/s11831-021-09541-6
   Shin J, 2020, IEEE T MULTIMEDIA, V22, P30, DOI 10.1109/TMM.2019.2922127
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Sun H, 2023, NEURAL COMPUT APPL, V35, P3737, DOI 10.1007/s00521-021-06296-w
   Sun ZY, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103133
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850
   Zhang YM, 2019, J COMPUT NEUROSCI, V46, P33, DOI 10.1007/s10827-018-0687-7
   Zhou JC, 2020, FRONT INFORM TECH EL, V21, P1745, DOI 10.1631/FITEE.2000190
   Zhou SY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3164154
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 43
TC 0
Z9 0
U1 6
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46521
EP 46545
DI 10.1007/s11042-023-15381-2
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000984294600003
DA 2024-07-18
ER

PT J
AU Firdaus, M
   Singh, GV
   Ekbal, A
   Bhattacharyya, P
AF Firdaus, Mauajama
   Singh, Gopendra Vikram
   Ekbal, Asif
   Bhattacharyya, Pushpak
TI Affect-GCN: a multimodal graph convolutional network for multi-emotion
   with intensity recognition and sentiment analysis in dialogues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conversational AI; Emotion; Intensity; Sentiment; Classification; Graph
   convolutional network; Multi-modal Factorized Bilinear (MFB) pooling
AB Emotion classification along with sentimental analysis in dialogues is a complex task that has currently attained immense popularity. When communicating their thoughts and feelings, humans are prone to having many emotions of varying intensities. The task is complicated and fascinating since emotions in a dialogue utterance can be independent or based on the preceding utterances. Additional details such as audio and video, along with text facilitates in the identification of the right emotions with the corresponding intensity and appropriate sentiments in a dialogue. In this work, we focus on the task of predicting multiple emotions and their corresponding intensity along with sentiments in a given utterance of a dialogue. With the release of MEISD dataset, the task of simultaneously predicting the sentiments along with multiple emotions with intensity from a given utterance of a conversation utilizing the knowledge from textual, audio and visual cues has gained significance in conversational systems. We design an Affect-GCN framework that utilizes an RNN-GCN network as an utterance encoder followed by Multimodal Factorized Bilinear (MFB) pooling for enhance representation of different modalities. The proposed Affect-GCN framework shows an improvement of 0.7 in terms of Jaccard index for multi-label emotion classification while an increase of 0.3 for intensity prediction. Experimental analysis shows that our proposed Affect-GCN framework outperforms the existing approaches and several baselines for the task of multi-label emotion classification, intensity prediction and sentiment analysis in dialogues.
C1 [Firdaus, Mauajama; Singh, Gopendra Vikram; Ekbal, Asif] Indian Inst Technol Patna, Comp Sci & Engn, Patna 801103, Bihar, India.
   [Bhattacharyya, Pushpak] Indian Inst Technol, Comp Sci & Engn, Mumbai 400076, Maharashtra, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Bombay
RP Firdaus, M (corresponding author), Indian Inst Technol Patna, Comp Sci & Engn, Patna 801103, Bihar, India.
EM mauajama.pcs16@iitp.ac.in; gopendra.99@gmail.com; asif@iitp.ac.in;
   pb@cse.iitb.ac.in
RI Ekbal, Asif/JKI-7638-2023
OI Firdaus, Mauajama/0000-0001-7485-5974
CR Akhtar MS, 2020, ACM T KNOWL DISCOV D, V14, DOI 10.1145/3380744
   Akhtar MS, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P370
   Akhtar MS, 2022, IEEE T AFFECT COMPUT, V13, P285, DOI 10.1109/TAFFC.2019.2926724
   Asri LE, 2017, P 18 ANN SIGDIAL M D
   Chauhan DS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5647
   Chen S.Y., 2018, arXiv
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Colneric N, 2020, IEEE T AFFECT COMPUT, V11, P433, DOI 10.1109/TAFFC.2018.2807817
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   El Rahman SA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P336, DOI 10.1109/iccisci.2019.8716464
   Firdaus Mauajama, 2020, P 28 INT C COMP LING, P4441, DOI DOI 10.18653/V1/2020.COLING-MAIN.393
   [符杨 Fu Yang], 2022, [中国电机工程学报, Proceedings of the Chinese Society of Electrical Engineering], V42, P4292
   Gan Z, 2019, Arxiv, DOI arXiv:1902.00579
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Ghosal D, 2020, Arxiv, DOI arXiv:2010.02795
   Ghosal D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3454
   Ghosal Deepanway, 2019, arXiv
   Hazarika D, 2018, CONVERSATIONAL MEMOR
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2594
   He HH, 2018, LECT NOTES ARTIF INT, V11108, P250, DOI 10.1007/978-3-319-99495-6_21
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Huang C, 2019, Seq2emo for multi-label emotion classification based on latent variable chains transformation
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Kim J, 2020, P 3 WORKSH COMP MOD, P64
   Kim Y, 2018, 12 INT WORKSHOP SEMA, P141
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kumar A, 2019, 2019 INT JOINT C NEU, P1
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Li YH, 2017, IEEE I CONF COMP VIS, P2098, DOI 10.1109/ICCV.2017.229
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Lu X., 2020, ITERATIVE EMOTION IN, P4078, DOI DOI 10.18653/V1/2020.COLING-MAIN.360
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Majumder N, 2018, KNOWL-BASED SYST, V161, P124, DOI 10.1016/j.knosys.2018.07.041
   Majumder N, 2019, AAAI CONF ARTIF INTE, P6818
   Mohammad S., 2018, P 12 INT WORKSHOP SE, P1, DOI DOI 10.18653/V1/S18-1001
   Mohammad S.M., 2017, arXiv
   Munezero M, 2014, IEEE T AFFECT COMPUT, V5, P101, DOI 10.1109/TAFFC.2014.2317187
   Noroozi Fatemeh, 2021, IEEE Transactions on Affective Computing, V12, P505, DOI 10.1109/TAFFC.2018.2874986
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Plutchik R., 1980, PLUTCHIKS WHEEL EMOT
   Poria S, 2019, Arxiv, DOI arXiv:1810.02508
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Roccetti M., 2010, Comput Entertain (CIE), V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   ROGERS DJ, 1960, SCIENCE, V132, P1115, DOI 10.1126/science.132.3434.1115
   Rudinac S, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P245, DOI 10.1145/3126686.3126776
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Serban IV, 2017, AAAI CONF ARTIF INTE, P3295
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tripathi S, 2019, Arxiv, DOI arXiv:1804.05788
   Yang PC, 2018, Arxiv, DOI [arXiv:1806.04822, 10.48550/arXiv.1806.04822]
   Yeh SL, 2019, INT CONF ACOUST SPEE, P6685, DOI 10.1109/ICASSP.2019.8683293
   Yoshino K, 2019, Arxiv, DOI arXiv:1901.03461
   Youze Wang, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P540, DOI 10.1145/3372278.3390713
   Yu J, 2018, 2018 C EMPIRICAL MET
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5415
   Zhang YZ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5436
   Zhong PX, 2019, Arxiv, DOI arXiv:1909.10681
   Zhu WH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7588, DOI 10.1109/ICASSP39728.2021.9414148
NR 65
TC 5
Z9 5
U1 6
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43251
EP 43272
DI 10.1007/s11042-023-14885-1
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979936300005
DA 2024-07-18
ER

PT J
AU Tao, HJ
   Bao, WJ
   Duan, QY
   Hu, ZW
   An, JF
   Xie, C
AF Tao, Huanjie
   Bao, Wenjie
   Duan, Qianyue
   Hu, Zhenwu
   An, Jianfeng
   Xie, Chao
TI An improved interaction-and-aggregation network for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person Re-identification; Gating Mechanism; Context Information;
   Attention Mechanism
AB Person re-identification (ReID) aims to match a specific person across non-overlapping camera views and has wide application prospects. However, existing methods are still susceptible to occlusion and missing critical parts. Most methods fuse low-level detail features and high-level strong semantic features using feature concatenation or addition, leading to useful information being overwhelmed by a large amount of useless information. In addition, many methods extract spatial context features by designing different blocks but ignore the local channel context features. To relieve these issues, this paper presents an improved interaction-and-aggregation network (IIANet) to learn more representative feature representation. First, to improve model robustness to serious occlusion or missing crucial parts of the target person, we employ a global multi-scale module (MSM) to extract multi-scale features by multi-branch convolution and hierarchical residual connection. Second, to selectively fuse low-level detail features and high-level semantic features effectively, we design a gated fully fusion module (GFFM) to control information transmission and reduce feature interferences in fusing different-level features. Finally, we adopt a channel context module (CCM) to learn channel context information via multi-scale local fusion. Sufficient experiments demonstrate the better performances of our IIANet on dataset Market-1501. The mAP and Rank-1 accuracy of our model reach 84.9% and 94.2%, respectively. Our code is available at: https://gitee.com/bingsfan/iianet/tree/master/
C1 [Tao, Huanjie; Bao, Wenjie; Duan, Qianyue; Hu, Zhenwu; An, Jianfeng] Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Peoples R China.
   [Tao, Huanjie; An, Jianfeng] Northwestern Polytech Univ, Engn & Res Ctr Embedded Syst Integrat, Minist Educ, Xian 710129, Peoples R China.
   [Tao, Huanjie; An, Jianfeng] Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710129, Peoples R China.
   [Xie, Chao] Nanjing Forestry Univ, Coll Mech & Elect Engn, Nanjing 210037, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Nanjing Forestry University
RP Tao, HJ (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Peoples R China.; Tao, HJ (corresponding author), Northwestern Polytech Univ, Engn & Res Ctr Embedded Syst Integrat, Minist Educ, Xian 710129, Peoples R China.; Tao, HJ (corresponding author), Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710129, Peoples R China.
EM huanjie_tao@126.com
RI YI, J/JJE-7713-2023; zhu, yujie/KBC-4009-2024
FU National Natural Science Foundation of China [62102320]; Fundamental
   Research Funds for the Central Universities [D5000210737]
FX AcknowledgementsThis work was partly supported by the National Natural
   Science Foundation of China (No. 62102320), and the Fundamental Research
   Funds for the Central Universities (No. D5000210737)
CR Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Cao Y, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9014055
   Cho K, 2020, ARXIV
   FAN X, 2018, P AS C COMP VIS, P19, DOI DOI 10.1007/978-3-030-20890-5_2
   Gao S, 2020, P IEEE CVF C COMP VI, P11744
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Ge Y, 2018, IEEE C EVOL COMPUTAT, V31
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He T, 2022, INT J E-COLLAB, V18, DOI 10.4018/IJeC.304029
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jin X, 2020, PROC CVPR IEEE, P3140, DOI 10.1109/CVPR42600.2020.00321
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Ke TW, 2018, LECT NOTES COMPUT SC, V11205, P605, DOI 10.1007/978-3-030-01246-5_36
   Kim G, 2021, MULTIMED TOOLS APPL, V80, P29129, DOI 10.1007/s11042-021-11127-0
   Li XT, 2020, AAAI CONF ARTIF INTE, V34, P11418
   Li YF, 2021, MULTIMED TOOLS APPL, V80, P14961, DOI 10.1007/s11042-021-10545-4
   Li Z, 2021, IEEE T PATTERN ANAL, P265
   Liu Z, 2019, IEEE INT CON MULTI, P700, DOI 10.1109/ICME.2019.00126
   Luo H., 2019, P IEEE CVF C COMP VI
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Qi L, 2019, IEEE INT CON MULTI, P496, DOI 10.1109/ICME.2019.00092
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shen C, 2019, IEEE T CIRC SYST VID, V29, P3016, DOI 10.1109/TCSVT.2018.2872503
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun H, 2019, IEEE I CONF COMP VIS, P6736, DOI 10.1109/ICCV.2019.00684
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Tao HJ, 2022, IEEE T IND INFORM, V18, P7653, DOI 10.1109/TII.2022.3146142
   Tao HJ, 2022, IEEE INTERNET THINGS, V9, P18749, DOI 10.1109/JIOT.2022.3162016
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Zhang D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6933, DOI 10.1109/ICCV48922.2021.00687
   Zhang SJ, 2018, IEEE INT CONF MOB, P228, DOI 10.1109/MASS.2018.00044
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao ZQ, 2021, IEEE T IMAGE PROCESS, V30, P6544, DOI 10.1109/TIP.2021.3093397
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   ZHONG Z, 2018, PROC CVPR IEEE, P5157, DOI DOI 10.1109/CVPR.2018.00541
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhu FQ, 2018, MULTIMED TOOLS APPL, V77, P3049, DOI 10.1007/s11042-017-5009-y
   Zijie Zhuang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P140, DOI 10.1007/978-3-030-58610-2_9
NR 54
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44053
EP 44069
DI 10.1007/s11042-023-15531-6
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000977607300002
DA 2024-07-18
ER

PT J
AU Zhou, WL
   Ji, RJ
   Lai, JX
AF Zhou, Weili
   Ji, Ruijie
   Lai, Jinxiong
TI MetaRL-SE: a few-shot speech enhancement method based on
   meta-reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; meta-learning; reinforcement learning; few-shot
   learning
AB The goal of speech enhancement is to reduce and suppress the noise in noisy speech and improve the quality and intelligibility of damaged speech. With the development of deep learning, the performance of SE has been significantly improved. However, deep learning relies on massive training data, and the lack of data is an important reason for the failure and difficulty of many algorithms. Aiming at this problem, this paper proposed a novel meta-reinforcement learning framework, focusing on the few-shot learning for speech enhancement. Specifically, first, a reinforcement learning based meta-learner is proposed which initializes the actions by a finite number of T-F masks, and the related action-value function is developed. Second, to optimize the model, this paper develops the reward calculation for reinforcement learning by using the user perception. Third, the model-agnostic Meta learning (MAML) algorithm is applied to fully utilize the limited data to improve the generalization of the meta-learner and towards better generalization of learning new tasks. The experiment results show that in terms of subjective and objective measurements, this work achieves at least improvement of 1.3%similar to 12.5% for 1-shot case and 3.1% similar to 14.3% for 5-shot case in contrast to the state-of-the-arts DNN based SE methods in challenging conditions, where the environment noises are diverse, and the signals are non-stationary.
C1 [Zhou, Weili; Ji, Ruijie; Lai, Jinxiong] Foshan Univ, Sch Elect & Informat Engn, Foshan, Peoples R China.
C3 Foshan University
RP Zhou, WL (corresponding author), Foshan Univ, Sch Elect & Informat Engn, Foshan, Peoples R China.
EM willychow@fosu.edu.cn
FU Foshan University Research Foundation for Advanced Talents [GG07005];
   Natural Science Foundation of Guangdong Province [2018A0303130082,
   2019A1515111148]; Guangdong Province Colleges and Universities Young
   Innovative Talent Project [2019KQNCX168]
FX AcknowledgmentsThis work is supported by the Foshan University Research
   Foundation for Advanced Talents (GG07005), the Natural Science
   Foundation of Guangdong Province (2018A0303130082, 2019A1515111148),
   Guangdong Province Colleges and Universities Young Innovative Talent
   Project (2019KQNCX168).
CR Afouras T, 2018, INTERSPEECH, P3244
   Anand P., 2019, ARXIV
   [Anonymous], 2001, PERCEPTUAL EVALUATIO, P862
   [Anonymous], 2020, ARXIV
   auditory, NOISEX 92 DAT
   Baker B., 2017, arXiv
   catalog.ldc.upenn, TIMIT SPEECH CORP
   Chu W-H, 2018, IEEE INT C IM PROC I
   Das D, 2020, IEEE T IMAGE PROCESS, V29, P3336, DOI 10.1109/TIP.2019.2959254
   Deng F, 2020, INTERSPEECH, P2457, DOI 10.21437/Interspeech.2020-1133
   Erdogan H, 2019, IEEE INT C AC SPEECH, P125
   Erdogan H, 2015, INT CONF ACOUST SPEE, P708, DOI 10.1109/ICASSP.2015.7178061
   Fakoor R, 2019, P INT C LEARN REPR, P332
   Finn C, 2017, PR MACH LEARN RES, V70
   Fu S., 2019, ARXIV
   Jane X, 2018, ARXIV
   Kang BY, 2019, IEEE I CONF COMP VIS, P8419, DOI 10.1109/ICCV.2019.00851
   Lin SC, 2020, IEEE ACCESS, V8, P42261, DOI 10.1109/ACCESS.2020.2976851
   Loizou Philipos C, 2013, SPEECH ENHANCEMENT T, DOI 10.1201/b14529
   Masuyama, 2018, ARXIV
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moss H. B., 2020, ARXIV
   Pan CY, 2019, IEEE ACCESS, V7, P53296, DOI 10.1109/ACCESS.2019.2911850
   Pascual S, 2018, P INTERSPEECH, P77
   Rangachari S, 2006, SPEECH COMMUN, V48, P220, DOI 10.1016/j.specom.2005.08.005
   Rethage D, 2019, IEEE INT C AC SPEECH, P423
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santoro A, 2016, PR MACH LEARN RES, V48
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Snell J, 2017, ADV NEUR IN, P512
   Tadas B, 2019, ARXIV
   Thiemann J., 2013, J. Acoustical Soc. Amer., V133
   Wang DeLiang, 2017, IEEE Spectr, V54, P32, DOI 10.1109/MSPEC.2017.7864754
   Williamson DS, 2016, IEEE-ACM T AUDIO SPE, V24, P483, DOI 10.1109/TASLP.2015.2512042
   Winata GI, 2020, ARXIV
   Yang Chen, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Zhou WL, 2021, INT J MACH LEARN CYB, V12, P959, DOI 10.1007/s13042-020-01214-3
   Zhou WL, 2019, MULTIMED TOOLS APPL, V78, P15647, DOI 10.1007/s11042-018-6990-5
   Zhou WL, 2017, IET SIGNAL PROCESS, V11, P486, DOI 10.1049/iet-spr.2016.0555
   Zhou WL, 2015, IEEE SYS MAN CYBERN, P2761, DOI 10.1109/SMC.2015.482
   Zhou WL, 2021, IEEE ACCESS
   Zoph B., 2016, INT C LEARN REPR
NR 42
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43903
EP 43922
DI 10.1007/s11042-023-14945-6
EA APR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976820400002
DA 2024-07-18
ER

PT J
AU Du, S
   Zhu, H
   Lin, GF
   Wang, D
   Shi, J
   Wang, J
AF Du, Sen
   Zhu, Hong
   Lin, Guangfeng
   Wang, Dong
   Shi, Jing
   Wang, Jing
TI Object semantic analysis for image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Saliency analysis; Relation analysis; Diverse image
   captioning
AB Although existing image captioning models can produce sentences through attention mechanisms and recurrent neural networks, it is difficult to generate multiple sentences to describe different important objects. Most image captioning models lack description diversity, whereas the diversity models often describe unimportant objects, resulting in low accuracy. In this paper, we propose a novel approach to balancing accuracy and diversity. To achieve this, we designed a novel model which combines saliency information and objects' relative position information to assess the semantic importance of all detected objects. By maintaining the features of important objects and making the network able to describe important objects by operating on the features of unimportant objects, our model can generate sentences with more diversity or accuracy. Experiments demonstrate the characteristics of our model on the MSCOCO and Flickr 30K datasets. In this dataset, our model can provide a set of accurate or diverse descriptions. Compared with the state-of-art models by standard captioning metrics and human evaluation metrics, our model outperforms these works in being able to generate more diverse or accuracy sentences.
C1 [Du, Sen; Zhu, Hong; Wang, Dong; Shi, Jing] Xian Univ Technol, Sch Automat & Informat Engn, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
   [Lin, Guangfeng; Wang, Jing] Xian Univ Technol, Informat Sci Dept, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology; Xi'an University of Technology
RP Zhu, H (corresponding author), Xian Univ Technol, Sch Automat & Informat Engn, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
EM 1180310024@stu.xaut.edu.cn; zhuhong@xaut.edu.cn; lgf78103@xaut.edu.cn;
   wangdong1210@xaut.edu.cn; shijing@xaut.edu.cn; wangjing63@xaut.edu.cn
RI Lin, Guangfeng/E-4420-2013
OI Lin, Guangfeng/0000-0002-6191-1102
FU NSFC [61771386]; Key Research and Development Program of Shaanxi
   [2020SF-359]; Research and development of manufacturing information
   system platform supporting product lifecycle management [2018GY-030];
   Natural Science Foundation of Shaanxi Province [2021JQ-487]; Scientific
   Research Program Funded of Shaanxi Education Department [20JK0788]
FX This research was supported by the NSFC (No. 61771386) ,and by the Key
   Research and Development Program of Shaanxi (Program no. 2020SF-359)
   ,and by the Research and development of manufacturing information system
   platform supporting product lifecycle management(No. 2018GY-030), and by
   the Natural Science Foundation of Shaanxi Province (No. 2021JQ-487), and
   by the, and by the Scientific Research Program Funded of Shaanxi
   Education Department (NO. 20JK0788).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], 2012, P AAAI C ART INT
   [Anonymous], 2015, arXiv
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Chen, 2015, ARXIV
   Dai B, 2017, IEEE I CONF COMP VIS, P2989, DOI 10.1109/ICCV.2017.323
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deshpande A, 2019, PROC CVPR IEEE, P10687, DOI 10.1109/CVPR.2019.01095
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Feng QY, 2020, IEEE T CIRC SYST VID, V30, P3413, DOI 10.1109/TCSVT.2020.2965966
   Gan C, 2017, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2017.108
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Heidari M, 2020, ARXIV
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li D., 2018, ARXIV
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu XH, 2018, LECT NOTES COMPUT SC, V11219, P353, DOI 10.1007/978-3-030-01267-0_21
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Luo RT, 2018, PROC CVPR IEEE, P6964, DOI 10.1109/CVPR.2018.00728
   Mao YZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4258
   Mathews A, 2018, PROC CVPR IEEE, P8591, DOI 10.1109/CVPR.2018.00896
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Shuster K, 2018, ARXIV
   Siris A., 2021, ICCV, P4156
   Sun H, 2021, P PAC RIM INT C ART, P501, DOI DOI 10.1007/978-3-030-89363-7_38
   Tian P, 2021, CHIN CONTR CONF, P7938
   Ushiku Y., 2012, P 20 ACM INT C MULT, P549
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vijayakumar A. K., 2016, arXiv
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang LW, 2017, ADV NEUR IN, V30
   Wang QZ, 2022, IEEE T PATTERN ANAL, V44, P1035, DOI 10.1109/TPAMI.2020.3013834
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Yiwu Zhong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P211, DOI 10.1007/978-3-030-58568-6_13
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zheng Y, 2019, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2019.00859
NR 56
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43179
EP 43206
DI 10.1007/s11042-023-14596-7
EA APR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000974364100004
DA 2024-07-18
ER

PT J
AU Welekar, R
   Dubey, A
   Hablani, S
AF Welekar, Rashmi
   Dubey, Anuradha
   Hablani, Sheetal
TI Meditation accuracy detection system using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meditation accuracy; Pose detection; Blink detection
AB Meditation is an effective technique for reducing stress, enhancing mental health, and enhancing overall wellbeing. However, the efficacy of meditation can be diminished if practitioners do not achieve the necessary level of concentration and precision. To address this issue, a Deep Learning-based Meditation Accuracy Detection System is proposed. Using EEG (electroencephalogram) signals, the system detects the precision of meditation. Using a large dataset of EEG signals collected from experienced meditators, a deep learning model is trained. The model is able to recognize patterns and characteristics in the EEG signals that indicate the level of concentration and precision attained during meditation. Potential applications of the proposed system include enhancing the efficacy of meditation practices, assisting individuals in monitoring their progress, and enabling researchers to investigate the neural mechanisms underlying meditations. Preliminary findings indicate that the proposed system can detect the level of meditation precision with high precision. This system has the potential to revolutionize the field of meditation by providing practitioners with objective feedback, facilitating the creation of personalized meditation programme, and allowing researchers to study the neural mechanisms underlying meditations.
C1 [Welekar, Rashmi; Dubey, Anuradha; Hablani, Sheetal] Shri Ramdeobaba Coll Engn & Management, Dept Comp Sci & Engn, Nagpur, India.
C3 Rashtrasant Tukadoji Maharaj Nagpur University; Shri Ramdeobaba College
   of Engineering & Management
RP Welekar, R (corresponding author), Shri Ramdeobaba Coll Engn & Management, Dept Comp Sci & Engn, Nagpur, India.
EM welekarr@rknec.edu
RI Welekar, Rashmi/AAE-5490-2020
CR Anwar D, 2018, USE PORTABLE EEG SEN, DOI [10.1109/COMSNETS.2018.8328299, DOI 10.1109/COMSNETS.2018.8328299]
   Bhayee Sheffy, 2016, BMC Psychol, V4, P60
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He J, 2014, INT C MULT FUS INF I, P1
   Morris T, 2002, J NETW COMPUT APPL, V25, P129, DOI 10.1006/jnca.2002.0130
   Soukupova T, 2016, C COMP VIS PATT REC
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yadav SK, 2019, NEURAL COMPUT APPL, V31, P9349, DOI 10.1007/s00521-019-04232-7
   Yi Liu, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P462, DOI 10.1109/IMCEC.2018.8469573
NR 12
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43625
EP 43633
DI 10.1007/s11042-023-15273-5
EA APR 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000971519600003
DA 2024-07-18
ER

PT J
AU Altaf, A
   Anwar, MW
   Jamal, MH
   Bajwa, UI
AF Altaf, Amna
   Anwar, Muhammad Waqas
   Jamal, Muhammad Hasan
   Bajwa, Usama Ijaz
TI Exploiting Linguistic Features for Effective Sentence-Level Sentiment
   Analysis in Urdu Language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Supervised Machine Learning; Parts of Speech Tagging; Sentiment
   Analysis; Urdu Language
ID SELECTION
AB Rapid increase in the use of social media has led to the generation of gigabytes of information shared by billions of users worldwide. To analyze this information and determine the behavior of people towards different events, sentiment analysis is widely used by researchers. Existing studies in Urdu sentiment analysis mostly use traditional n-gram features, which unlike linguistic features, do not focus on the contextual information being discussed. Moreover, no existing study classifies sentiments of proverbs and idioms which is challenging as mostly they do not contain sentiment words but carry strong sentiments. This study exploits linguistic features of Urdu language for sentence-level sentiment analysis and classifies idioms and proverbs using classical machine learning techniques. We develop a dataset comprising of idioms, proverbs, and sentences from the news domain, and extract part-of-speech tag-based features, boolean features, and numeric features from the dataset after keen linguistic analysis of Urdu language. Experimental results show that J48 classifier performs best in sentiment classification with an accuracy of 90% and an F-measure of 88%.
C1 [Altaf, Amna; Anwar, Muhammad Waqas; Jamal, Muhammad Hasan; Bajwa, Usama Ijaz] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 Km Def Rd Raiwind Rd, Lahore, Punjab, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Altaf, A (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 Km Def Rd Raiwind Rd, Lahore, Punjab, Pakistan.
EM amnaaltaf22@yahoo.com; waqasanwar@cuilahore.edu.pk;
   mhjamal@cuilahore.edu.pk; usamabajwa@cuilahore.edu.pk
CR Abd-Elhamid L, 2016, PROCEEDINGS OF 2016 11TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P260, DOI 10.1109/ICCES.2016.7822011
   Ali S, 2006, APPL SOFT COMPUT, V6, P119, DOI 10.1016/j.asoc.2004.12.002
   Amjad K, 2017, 2017 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS & TECHNOLOGIES (ICOSST), P48, DOI 10.1109/ICOSST.2017.8279004
   Aziz S., 2020, Pak. J. Eng. Technol, DOI [10.51846/vol3iss2pp172-177, DOI 10.51846/VOL3ISS2PP172-177]
   Benamara F., 2007, ICWSM, V7, P203
   Daud A, 2017, ARTIF INTELL REV, V47, P279, DOI 10.1007/s10462-016-9482-x
   Feldman R, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2436256.2436274
   Fürnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794
   Ghulam H, 2019, PROCEDIA COMPUT SCI, V147, P131, DOI 10.1016/j.procs.2019.01.202
   Glasmachers T, 2006, J MACH LEARN RES, V7, P1437
   Han J, 2012, MOR KAUF D, P1
   Hashim M., 2016, P C LANG TECHN, V2016, P101
   Ibrahim HS., 2015, INT J COMPUT APPL, V118, P26, DOI DOI 10.5120/20790-3435
   Jawaid B, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2938
   Kaur G., 2014, INT J COMPUTER APPL, V98, P13, DOI [10.5120/17314-7433, DOI 10.5120/17314-7433]
   Khan L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09381-9
   Khan L, 2021, IEEE ACCESS, V9, P97803, DOI 10.1109/ACCESS.2021.3093078
   Khan Moin, 2019, Advances in Information and Communication Networks. Proceedings of the 2018 Future of Information and Communication Conference (FICC). Advances in Intelligent Systems and Computing (AISC 887), P630, DOI 10.1007/978-3-030-03405-4_44
   Kohavi R, 1995, LECT NOTES ARTIF INT, V912, P174
   Kolkur S., 2015, Int J Curr Eng Technol, V5, P768
   Mahmood Z, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102233
   Manuel F-D., 2014, J MACHINE LEARNING R, V15, P3133
   Masoumi M., 2022, 2 INT C DIG FUT TRAN, P1, DOI DOI 10.1109/ICODT255437.2022.9787451
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Mehmood F, 2020, IEEE ACCESS, V8, P192740, DOI 10.1109/ACCESS.2020.3030885
   Mehmood K, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102368
   Mehmood K, 2019, ADV INTELL SYST COMP, V858, P29, DOI 10.1007/978-3-030-01174-1_3
   Mehmood K, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3329709
   Mehmood K, 2019, IEEE ACCESS, V7, P47991, DOI 10.1109/ACCESS.2019.2908420
   Mukhtar N, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3510830
   Mukhtar N, 2020, MEHRAN UNIV RES J EN, V39, P759, DOI 10.22581/muet1982.2004.08
   Mukhtar N, 2020, ARTIF INTELL REV, V53, P2521, DOI 10.1007/s10462-019-09740-5
   Mukhtar N, 2018, TELEMAT INFORM, V35, P2173, DOI 10.1016/j.tele.2018.08.003
   Mukhtar N, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12317
   Mukhtar N, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418510011
   Mukhtar N, 2017, COGN COMPUT, V9, P446, DOI 10.1007/s12559-017-9481-5
   Rehman Z, 2011, 2 WORKSH S SE AS NAT, P40
   Riloff E, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P105
   Safder I, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12751
   Singh VK, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P712, DOI 10.1109/iMac4s.2013.6526500
   Syed AZ, 2014, ARTIF INTELL REV, V41, P535, DOI 10.1007/s10462-012-9322-6
   Syed AZ, 2011, LECT NOTES ARTIF INT, V7094
   Syed AZ, 2010, LECT NOTES ARTIF INT, V6437
   Syed AZ., 2011, J AM SCI, V7, P644
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tan SB, 2008, EXPERT SYST APPL, V34, P2622, DOI 10.1016/j.eswa.2007.05.028
   Toutanova K, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P63, DOI 10.3115/1117794.1117802
   Ul Rehman Z, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P497, DOI 10.1109/INTECH.2016.7845095
   Zhang, 2003, P 20 INT C INT C MAC
NR 49
TC 4
Z9 4
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41813
EP 41839
DI 10.1007/s11042-023-15216-0
EA APR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968990200003
DA 2024-07-18
ER

PT J
AU Brahim, AH
   Pacha, AA
   Said, NH
AF Brahim, A. Hadj
   Pacha, A. Ali
   Said, N. Hadj
TI A new image compression-encryption scheme based on compressive sensing &
   classical AES algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 6D hyperchaotic system; Permutation; Compressive sensing; AES; Image
   encryption
ID CHAOTIC SYSTEM; RECONSTRUCTION
AB In recent years, many compressive sensing methods have been suggested to encrypt and compress images. However, these algorithms have some flaws in terms of the quality of the reconstructed images, compression ratio value, security performance, and encryption speed. Therefore, in this paper, a new image compression-encryption scheme is proposed based on compressive sensing and the AES-128 algorithm. The sparse coefficients are permuted by a matrix produced each time by the initial variable of the 6D hyperchaotic system to enhance the compression performance of compressive sensing. Additionally, the 6D hyperchaotic system uses two variables to generate the measurement matrix for compressive sensing. Moreover, to increase the security level of the proposed algorithm, the AES algorithm (using ECB mode) is applied to the compressed image where the AES input key is generated by two variables the 6D hyperchaotic system, and each column has its own input key. Experimental and analysis results show that the proposed algorithm has good performance in terms of security, such as large key-space, high sensitivity, statistical attacks, and good compression performance compared to existing algorithms.
C1 [Brahim, A. Hadj; Pacha, A. Ali; Said, N. Hadj] Univ Sci & Technol Oran Mohamed Boudiaf, Lab Coding & Secur Informat, POB 1505, Oran 31000, Mnaouer, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf
RP Brahim, AH (corresponding author), Univ Sci & Technol Oran Mohamed Boudiaf, Lab Coding & Secur Informat, POB 1505, Oran 31000, Mnaouer, Algeria.
EM abderrahmene.hadjbrahim@univ-usto.dz; a.alipacha@gmail.com;
   naima.hadjsaid@univ-usto.dz
OI Hadj Brahim, Abderrahmene/0000-0003-2208-704X; ali pacha,
   adda/0000-0003-1828-9562
CR Abbasi AA, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106465
   Ajagbe SA., 2020, CPJ, V26, P98
   Ajagbe SA., 2020, J COMPUT SCI APPL, V26, P64, DOI [10.4314/jcsia.v26i2.7, DOI 10.4314/JCSIA.V26I2.7]
   Al Naimi M, 2022, INT J LOGIST-RES APP, V25, P1191, DOI 10.1080/13675567.2021.1893288
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bao YQ, 2020, STRUCT HEALTH MONIT, V19, P293, DOI 10.1177/1475921719844039
   Brahim AH, 2023, INF SECUR J, V32, P59, DOI 10.1080/19393555.2021.1943572
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Fang H, 2014, IEEE T SIGNAL PROCES, V62, P196, DOI 10.1109/TSP.2013.2284762
   Fei L, 2017, IEEE T GEOSCI REMOTE, V55, P6937, DOI 10.1109/TGRS.2017.2737033
   Gan ZH, 2020, NEURAL COMPUT APPL, V32, P14113, DOI 10.1007/s00521-020-04808-8
   Han CY, 2019, OPTIK, V181, P779, DOI 10.1016/j.ijleo.2018.12.178
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Khan JS, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102711
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lim WYB, 2021, IEEE T INTELL TRANSP, V22, P5140, DOI 10.1109/TITS.2021.3056341
   Liu JL, 2021, MULTIMED TOOLS APPL, V80, P25433, DOI 10.1007/s11042-021-10884-2
   Madouri ZB, 2022, OPTIK, V264, DOI 10.1016/j.ijleo.2022.169382
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Midoun MA, 2021, OPT LASER ENG, V139, DOI 10.1016/j.optlaseng.2020.106485
   Musanna F, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102560
   Naim M, 2021, ADV SPACE RES, V67, P2077, DOI 10.1016/j.asr.2021.01.018
   National Institute of Standards and Technology, 2001, 197 NIST FIPS
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P135
   Shi YD, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23101297
   Vanjari HB, 2022, WORLD J ENG, V19, P216, DOI 10.1108/WJE-06-2021-0324
   Wang XY, 2020, OPTIK, V217, DOI 10.1016/j.ijleo.2020.164884
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wei DY, 2021, OPTIK, V238, DOI 10.1016/j.ijleo.2021.166748
   Xie SR, 2020, COMP MATER SCI, V180, DOI 10.1016/j.commatsci.2020.109690
   Xie YQ, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21090819
   Xu J, 2022, VISUAL COMPUT, V38, P1509, DOI 10.1007/s00371-021-02085-7
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yang LB, 2020, COMMUN NONLINEAR SCI, V90, DOI 10.1016/j.cnsns.2020.105362
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhu ZL, 2020, MULTIMED TOOLS APPL, V79, P25497, DOI 10.1007/s11042-020-09193-x
NR 51
TC 4
Z9 4
U1 14
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42087
EP 42117
DI 10.1007/s11042-023-15171-w
EA APR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000983404900005
DA 2024-07-18
ER

PT J
AU Xu, YL
   Meng, F
   Yang, H
   Lu, S
   Wang, HH
   Hu, M
AF Xu, Yongli
   Meng, Fan
   Yang, Hao
   Lu, Shuai
   Wang, Haihui
   Hu, Man
TI E-Net: a novel deep learning framework integrating expert knowledge for
   glaucoma optic disc hemorrhage segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Deep learning; Glaucoma optic disc
   hemorrhage; Expert knowledge
ID IMAGES; SYSTEM
AB Glaucoma is a serious eye disease and glaucoma optic disc hemorrhage (GODH) is an important diagnostic indicator for glaucoma. Deep-learning-based medical image segmentation methods for automatic optic cup and disc segmentation have made tremendous progress. However, when it comes to the segmentation of GODH, classical deep learning technologies face two main challenges: the difficulties in distinguishing GODH from the end points or bending points of blood vessels, and the imbalance between the pixel classes of the target area and the background area. In this paper, we proposed a deep learning framework integrating expert knowledge (E-Net) for the segmentation of GODH in fundus images. This E-Net consisted of a primary network for GODH segmentation and two auxiliary networks for extraction of optic disc (OD) and blood vessels. The segmentation probability maps from the two auxiliary networks were used to improve the segmentation accuracy of GODH, via expert knowledge loss functions and attention mechanism. Moreover, we designed a weighted segmentation accuracy loss function to balance the segmentation accuracy of the target and background region, thus fully mining the substantial information in the fundus images. The proposed E-Net was verified on a GODH dataset from Beijing Tongren Hospital. The experiments showed that the proposed E-Net achieved state-of-the-art results on this dataset.
C1 [Xu, Yongli; Meng, Fan; Yang, Hao] Beijing Univ Chem Technol, Dept Math, Beijing 100029, Peoples R China.
   [Lu, Shuai] Beijing Inst Technol, Inst Engn Med, Beijing 100081, Peoples R China.
   [Wang, Haihui] Beihang Univ, Sch Math Sci, Beijing 100191, Peoples R China.
   [Hu, Man] Capital Med Univ, Beijing Childrens Hosp, Dept Ophthalmol, Beijing 100045, Peoples R China.
   [Hu, Man] Capital Med Univ, Beijing Tongren Hosp, Beijing Tongren Eye Ctr, Beijing 100045, Peoples R China.
C3 Beijing University of Chemical Technology; Beijing Institute of
   Technology; Beihang University; Capital Medical University; Capital
   Medical University
RP Wang, HH (corresponding author), Beihang Univ, Sch Math Sci, Beijing 100191, Peoples R China.; Hu, M (corresponding author), Capital Med Univ, Beijing Childrens Hosp, Dept Ophthalmol, Beijing 100045, Peoples R China.; Hu, M (corresponding author), Capital Med Univ, Beijing Tongren Hosp, Beijing Tongren Eye Ctr, Beijing 100045, Peoples R China.
EM whhmath@buaa.edu.cn; human1125@163.com
FU National Natural Science Foundation of China [U1830107]; Joint Project
   of Biomedical Translational Engineering Research Center of BUCT-CJFH
   [XK2022-02]; National Science and Technology Major Project
   [2019-I-0001-0001, 2019-I-0019-0018]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China (U1830107), the Joint Project of Biomedical
   Translational Engineering Research Center of BUCT-CJFH (XK2022-02) and
   the National Science and Technology Major Project (Nos. 2019-I-0001-0001
   and 2019-I-0019-0018).
CR Bengtsson B, 2008, OPHTHALMOLOGY, V115, P2044, DOI 10.1016/j.ophtha.2008.05.031
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chaudhari S., 2019, ARXIV
   Chen H, 2020, NEUROCOMPUTING, V392, P305, DOI 10.1016/j.neucom.2019.01.111
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Christopher M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-35044-9
   Feng ST, 2020, NEUROCOMPUTING, V392, P268, DOI 10.1016/j.neucom.2018.10.098
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P2493, DOI 10.1109/TMI.2018.2837012
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0
   Hood DC, 2018, OPHTHALMOLOGY, V125, P1207, DOI 10.1016/j.ophtha.2018.04.020
   Hssayeni MD, 2020, DATA, V5, DOI 10.3390/data5010014
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Jiang Y, 2019, IEEE ACCESS, V7, P76342, DOI 10.1109/ACCESS.2019.2922365
   Jonas JB, 1999, SURV OPHTHALMOL, V43, P293, DOI 10.1016/S0039-6257(98)00049-6
   Kamili A, 2020, J INTELL FUZZY SYST, V39, P8389, DOI 10.3233/JIFS-189157
   Keetha NV, 2020, ARXIV
   Kim KE, 2017, CURR OPIN OPHTHALMOL, V28, P105, DOI 10.1097/ICU.0000000000000345
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li L, 2020, IEEE T MED IMAGING, V39, P413, DOI 10.1109/TMI.2019.2927226
   Liu HR, 2019, JAMA OPHTHALMOL, V137, P1353, DOI 10.1001/jamaophthalmol.2019.3501
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu S, 2020, IEEE ACCESS, V8, P132348, DOI 10.1109/ACCESS.2020.3009442
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tham Yih-Chung, 2014, Ophthalmology, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Watanabe R., 2017, PROC SPIE, V10134, P826
   Xu H, 2019, LECT NOTES COMPUT SC, V11766, P420, DOI 10.1007/978-3-030-32248-9_47
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu YL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204401
   Yu Y, 2017, PROC CVPR IEEE, P6119, DOI 10.1109/CVPR.2017.648
   Zhang ZJ, 2019, LECT NOTES COMPUT SC, V11764, P442, DOI 10.1007/978-3-030-32239-7_49
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu HD, 2020, IEEE ACCESS, V8, P29729, DOI 10.1109/ACCESS.2020.2972562
   Zhu YS, 2019, IEEE T IMAGE PROCESS, V28, P113, DOI 10.1109/TIP.2018.2865280
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 42
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41207
EP 41224
DI 10.1007/s11042-023-15174-7
EA APR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983404900001
DA 2024-07-18
ER

PT J
AU Saghir, U
   Hasan, M
AF Saghir, Uzma
   Hasan, Moin
TI Skin cancer detection and classification based on differential analyzer
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Differential Analyser approach; Enhancement; Feature extraction;
   Segmentation; Support vector machine
ID DERMOSCOPY IMAGES; DIAGNOSIS; MELANOMA; SEGMENTATION; LESIONS; SYSTEM;
   SELECTION; NETWORK
AB Skin cancer is one of the world's scariest diseases, having taken the lives of thousands of people. It can be treated if diagnosed at the right time. According to WHO, every year, approximately 3 million non-melanoma and 130,000 malignant melanomas occur worldwide. Many existing technologies have demonstrated that computer-aided systems can be useful in the early identification of cancer. One of the major challenges in computer-aided diagnostic systems is accurate segmentation of the lesion and extraction of features for successful classification and detection. The study's main goal is to recognize and segment cancerous parts of skin from the collected samples and then categorize them into separate affected and non-affected regions. The proposed model first performs the identification and separation of infected regions from the sample. This is performed by converting the RGB cell image into a greyscale colour scale. The background subtraction approach is used to track only cell structures from the image by eliminating the background, and region props are applied for segmentation from skin images. In the second phase, features from the segmented images are extracted. These features include homogeneity, contrast, energy, correlation, and some hybrid features. In the third phase, the differential analyzer approach (DAA) algorithm is used to select the significant features. In the final phase, the efficiency of the suggested optimization method is validated using different classifiers. The suggested methodology is applied to an ISIC 2018 dataset available. This result outperforms all other published papers that used the same dataset. Classification accuracy is notably higher in comparison to other approaches not following the DAA optimization algorithm. Validation of results is further extended through feature reduction ratio and still remarkable results concerning classification accuracy of 96% are achieved. The validity of the approach is examined using different classifiers including KNN, SVM, Naive Bayes, decision tree, and random forest-based mechanism.
C1 [Saghir, Uzma; Hasan, Moin] Lovely Profess Univ, Dept Comp Sci & Engn, Phagwara, Punjab, India.
C3 Lovely Professional University
RP Saghir, U (corresponding author), Lovely Profess Univ, Dept Comp Sci & Engn, Phagwara, Punjab, India.
EM uzma.1172017@lpu.in; mmoinhhasan@gmail.com
OI Saghir, Uzma/0000-0001-9206-9213; Hasan, Moin/0000-0003-4863-9973; ,
   UZMA/0000-0002-7124-3902
CR Abbas Q, 2013, SKIN RES TECHNOL, V19, pE490, DOI 10.1111/j.1600-0846.2012.00670.x
   Abuzaghleh O, 2015, IEEE J TRANSL ENG HE, V3, DOI 10.1109/JTEHM.2015.2419612
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Albert BA, 2020, IEEE ACCESS, V8, P31254, DOI 10.1109/ACCESS.2020.2973188
   American Cancer Society, 2021, MEL SKIN CANC WHAT I, P1
   Apalla Zoe, 2017, Dermatol Pract Concept, V7, P1, DOI 10.5826/dpc.0702a01
   Aswin RB, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1304, DOI 10.1109/ICCICCT.2014.6993162
   Ballerini L., 2013, Color medical image analysis, P63
   Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540
   Barata C, 2012, IEEE T BIO-MED ENG, V59, P2744, DOI 10.1109/TBME.2012.2209423
   Blundo A, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.637069
   Britanak V., 2007, Discrete Cosine and Sine Transforms: General Properties, Fast Algorithms and Integer Approximations
   Buemi A, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/323180
   Caie PD., 2021, Artificial Intelligence and Deep Learning in Pathology, DOI DOI 10.1016/B978-0-323-67538-3.00008-7
   Carrera EV, 2019, COMM COM INF SC, V895, P553, DOI 10.1007/978-3-030-05532-5_42
   Celebi ME, 2009, COMPUT MED IMAG GRAP, V33, P148, DOI 10.1016/j.compmedimag.2008.11.002
   Choudhari Sarika, 2014, INT J EMERG TRENDS T, V3, P147
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Dhane DM, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0554-x
   Dhane DM, 2015, PROCEDIA COMPUT SCI, V58, P438, DOI 10.1016/j.procs.2015.08.059
   Flores-Vidal PA, 2019, SOFT COMPUT, V23, P1809, DOI 10.1007/s00500-018-3540-z
   Geller AC, 2013, J CLIN ONCOL, V31, P4172, DOI 10.1200/JCO.2012.47.3728
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Glazer AM, 2017, DERMATOL CLIN, V35, P409, DOI 10.1016/j.det.2017.06.001
   Gonzalez-Correa CA., 2020, IEEE ENG MED BIOL, V72, P113, DOI [10.1007/978-981-13-3498-6_17, DOI 10.1007/978-981-13-3498-6_17]
   Gulati S., 2019, DETECTION MALIGNANT
   Hasan Md Kamrul, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2021.100819
   Heibel HD, 2020, AM J CLIN DERMATOL, V21, P513, DOI 10.1007/s40257-020-00517-z
   Hekler A, 2019, EUR J CANCER, V120, P114, DOI 10.1016/j.ejca.2019.07.019
   Höhn J, 2021, EUR J CANCER, V149, P94, DOI 10.1016/j.ejca.2021.02.032
   Jaworek-Korjakowska J, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/4381972
   Jiang Angela, 2021, Int J Womens Dermatol, V7, P411, DOI 10.1016/j.ijwd.2021.05.005
   Kassem MA, 2020, IEEE ACCESS, V8, P114822, DOI 10.1109/ACCESS.2020.3003890
   Kato J, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00180
   Khan MU, 2012, IMPROVED LINE DRAWIN, P322, DOI [10.3850/978-981-07-1403-1_713, DOI 10.3850/978-981-07-1403-1_713]
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Khan NH, 2022, J ADV RES, V36, P223, DOI 10.1016/j.jare.2021.06.014
   Lee H, 2014, APPL INTELL, V40, P415, DOI 10.1007/s10489-013-0474-0
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   Linsangan NB, 2018, ICBRA 2018: PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS RESEARCH AND APPLICATIONS, P47, DOI 10.1145/3309129.3309141
   Mahbod A, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105475
   Maity M, 2018, LECT NOTES ELECTR EN, V475, P561, DOI 10.1007/978-981-10-8240-5_63
   Marin-Gomez FX, 2020, J PRIM CARE COMMUNIT, V11, DOI 10.1177/2150132720937831
   Masood A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/323268
   Masood A, 2014, LECT NOTES COMPUT SC, V8835, P101, DOI 10.1007/978-3-319-12640-1_13
   Menzies SW, 2009, BRIT J DERMATOL, V161, P1270, DOI 10.1111/j.1365-2133.2009.09374.x
   Monika MK, 2020, MATER TODAY-PROC, V33, P4266, DOI 10.1016/j.matpr.2020.07.366
   Murugan A, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103727
   Murugan A, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1400-8
   Narayanamurthy V, 2018, RSC ADV, V8, P28095, DOI 10.1039/c8ra04164d
   Panigrahi R, 2019, SOCIAL NETWORK ANALYTICS: COMPUTATIONAL RESEARCH METHODS AND TECHNIQUES, P1, DOI 10.1016/B978-0-12-815458-8.00001-3
   Pathan S, 2018, BIOMED SIGNAL PROCES, V39, P237, DOI 10.1016/j.bspc.2017.07.010
   Perez F, 2018, LECT NOTES COMPUT SC, V11041, P303, DOI 10.1007/978-3-030-01201-4_33
   Premaladha J, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0460-2
   Rajan Bindhu K., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0920, DOI 10.1109/ICCSP48568.2020.9182414
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Ruela M, 2017, COMP M BIO BIO E-IV, V5, P127, DOI 10.1080/21681163.2015.1029080
   Saghir Uzma, 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P1304, DOI 10.1109/ICACCS51430.2021.9441787
   Satheesha TY, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2648797
   Serte S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103423
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Singh D, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105524
   Singh N, 2019, SKIN RES TECHNOL, V25, P129, DOI 10.1111/srt.12622
   Smaoui N, 2018, INT MULTICONF SYST, P274, DOI 10.1109/SSD.2018.8570526
   Taunk K, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P1255, DOI [10.1109/iccs45141.2019.9065747, 10.1109/ICCS45141.2019.9065747]
   Thaajwer Ma Ahmed, 2020, 2020 2nd International Conference on Advancements in Computing (ICAC), P363, DOI 10.1109/ICAC51239.2020.9357309
   Urban K, 2021, JAAD INT, V2, P98, DOI 10.1016/j.jdin.2020.10.013
   Vestergaard ME, 2008, BRIT J DERMATOL, V159, P669, DOI 10.1111/j.1365-2133.2008.08713.x
   Wu SW, 2016, AM J EPIDEMIOL, V183, P824, DOI 10.1093/aje/kwv282
   Wu XF, 2014, CURR OPIN CELL BIOL, V29, P1, DOI 10.1016/j.ceb.2014.02.003
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TMI.2019.2893944, 10.1109/TKDE.2019.2891537]
   Zhang YL, 2012, COMM COM INF SC, V308, P179
   Zhou HY, 2011, COMPUT MED IMAG GRAP, V35, P121, DOI 10.1016/j.compmedimag.2010.08.002
   Zortea M, 2017, PATTERN RECOGN, V64, P92, DOI 10.1016/j.patcog.2016.10.031
NR 76
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41129
EP 41157
DI 10.1007/s11042-023-14409-x
EA APR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961747500001
DA 2024-07-18
ER

PT J
AU Mzoughi, H
   Njeh, I
   Slima, MB
   BenHamida, A
AF Mzoughi, Hiba
   Njeh, Ines
   Slima, Mohamed Ben
   BenHamida, Ahmed
TI Deep efficient-nets with transfer learning assisted detection of
   COVID-19 using chest X-ray radiology imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Deep leaning; Efficient-net; Transfer learning; Radiography
   imaging; Chest X-ray
AB Corona Virus (COVID-19) could be considered as one of the most devastating pandemics of the twenty-first century. The effective and the rapid screening of infected patients could reduce the mortality and even the contagion rate. Chest X-ray radiology could be designed as one of the effective screening techniques for COVID-19 exploration. In this paper, we propose an advanced approach based on deep learning architecture to automatic and effective screening techniques dedicated to the COVID-19 exploration through chest X-ray (CXR) imaging. Despite the success of state-of-the-art deep learning-based models for COVID-19 detection, they might suffer from several problems such as the huge memory and the computational requirement, the overfitting effect, and the high variance. To alleviate these issues, we investigate the Transfer Learning to the Efficient-Nets models. Next, we fine-tuned the whole network to select the optimal hyperparameters. Furthermore, in the preprocessing step, we consider an intensity-normalization method succeeded by some data augmentation techniques to solve the imbalanced dataset classes' issues. The proposed approach has presented a good performance in detecting patients attained by COVID-19 achieving an accuracy rate of 99.0% and 98% respectively using training and testing datasets. A comparative study over a publicly available dataset with the recently published deep-learning-based architectures could attest the proposed approach's performance.
C1 [Mzoughi, Hiba; Njeh, Ines; Slima, Mohamed Ben; BenHamida, Ahmed] Natl Engn Sch Sfax ENIS, Adv Technol Med & Signal ATMS, Route Soukra Km 4-3038 Sfax, Sfax, Tunisia.
   [Njeh, Ines] Gabes Univ, Higher Inst Comp Sci & Multimedia Gabes, Teboulbou, Tunisia.
   [Slima, Mohamed Ben] Univ Sfax, Natl Sch Elect & Telecommun Sfax, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Gabes; Universite de Sfax
RP Mzoughi, H (corresponding author), Natl Engn Sch Sfax ENIS, Adv Technol Med & Signal ATMS, Route Soukra Km 4-3038 Sfax, Sfax, Tunisia.
EM hiba.mzoughi@yahoo.fr
FU Authors have nothing to discolor.
FX Authors have nothing to discolor.
CR Ahmed Tashin, 2022, SN Computer Science, V3, P1, DOI DOI 10.1007/S42979-021-00981-2
   Akiba T, 2017, Arxiv, DOI arXiv:1711.04325
   Chen HT, 2021, J DIGIT IMAGING, V34, P231, DOI 10.1007/s10278-021-00431-8
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iandola F, 2014, Arxiv, DOI [arXiv:1404.1869, DOI 10.48550/ARXIV.1404.1869]
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Kaggle, 2020, COVID-19 X-ray image classification | Kaggle
   Luz Eduardo, 2022, Research on Biomedical Engineering, V38, P149, DOI 10.1007/s42600-021-00151-6
   Meng ZA, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P681, DOI 10.1145/3383313.3418479
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Semenzato L, 2021, LANCET REG HEALTH-EU, V8, DOI 10.1016/j.lanepe.2021.100158
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tahir Hassam, 2021, Proceedings of the 2021 First International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT), DOI [10.1109/ICECCME52200.2021.9591060, 10.1109/ICAECT49130.2021.9392487]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang SJ, 2021, IEEE T IND INFORM, V17, P6539, DOI 10.1109/TII.2021.3057683
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
NR 25
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39303
EP 39325
DI 10.1007/s11042-023-15097-3
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500001
PM 37362692
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Sandidzadeh, MA
   Havaei, P
AF Sandidzadeh, Mohammad Ali
   Havaei, Pedram
TI A comprehensive study on reinforcement learning application for train
   speed profile optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Train speed profile; Q-SARSA algorithm; Deep-Q network; Convergence
   measurement
ID ENERGY-CONSUMPTION; OPTIMAL STRATEGIES; SYSTEM; TIME
AB Optimizing energy consumption in public transportation systems is a severe issue as the cost of energy increases over time. Since a palpable part of energy in transportation systems is consumed by subways, this issue has increased concerns over time. In this paper, the problem of train speed profile determination is discussed under the framework of Reinforcement Learning. First, the train dynamics are modeled, and the basics of RL are explained for the problem. As the novelty of this work, a new RL algorithm named Q-SARSA is proposed by incorporating the Q-learning and SARSA update rules. This helps Q-SARSA be as fast as SARSA and as accurate as Q-learning. The algorithm is prevented from local optimums by defining a new parameter as convergence measurement (CM). Furthermore, another RL-based method is designed called Deep-Q network by combining a deep, fully connected neural network with Q-table using Q-SARSA updates. This Deep-Q net relieves the problem of iterative calculations by adapting gradient ascend in networks weight updates, and a new reward function is formed to accord with the network and the time-energy problem. The conventional Q-learning and SARSA algorithms, latest versions of Genetic algorithm, Bees algorithm, Dynamic programming and Deep neural network are developed as well for comparison purposes. Simulations are conducted using the route information of Tehran Metro Lines 3, 5, and Shiraz Metro Line 1. The consulting results show the proposed methods' huge advantage and efficiency compared with the mentioned methods.
C1 [Sandidzadeh, Mohammad Ali] Iran Univ Sci & Technol IUST, Sch Railway Engn, Dept Control Engn & Signaling, Tehran, Iran.
   [Havaei, Pedram] Iran Univ Sci & Technol IUST, Sch Railway Engn, Dept Control Engn & Signaling, Univ St,Hengam St,Resalat Sq, Tehran 1311416846, Iran.
C3 Iran University Science & Technology; Iran University Science &
   Technology
RP Sandidzadeh, MA (corresponding author), Iran Univ Sci & Technol IUST, Sch Railway Engn, Dept Control Engn & Signaling, Tehran, Iran.
EM sandidzadeh@iust.ac.ir; havaei_pedram@alumni.iust.ac.ir
CR Aljohani TM, 2021, ELECTR POW SYST RES, V192, DOI 10.1016/j.epsr.2020.106962
   Anh AT., 2021, INT J ELECT COMPUT E, V11, P4881, DOI [10.11591/ijece.v11i6.pp4881-4890, DOI 10.11591/IJECE.V11I6.PP4881-4890]
   Bertsekas DP, 1996, NEURO DYNAMIC PROGRA, P161, DOI [10.1007/978-0-387-74759-0_440, DOI 10.1007/978-0-387-74759-0_440]
   Busoniu L, 2010, STUD COMPUT INTELL, V310, P183
   Chen M, 2021, IEEE INT C INTELL TR, P460, DOI 10.1109/ITSC48978.2021.9564452
   Cheng Y, 2021, FRONT ENG MANAG, V8, P595, DOI 10.1007/s42524-021-0173-1
   Deng K, 2022, ENERG CONVERS MANAGE, V251, DOI 10.1016/j.enconman.2021.115030
   [丁勇 Ding Yong], 2011, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V11, P96
   Du YC, 2022, TRANSPORT RES C-EMER, V134, DOI 10.1016/j.trc.2021.103489
   Esveld C., 2001, MODERN RAILWAY TRACK, VSecond
   Gosavi A, 2009, INFORMS J COMPUT, V21, P178, DOI 10.1287/ijoc.1080.0305
   Havaei P., 2021, INT J RAILWAY RES, V8, P25, DOI [10.22068/ijrare.282, DOI 10.22068/IJRARE.282]
   Howlett P, 2000, ANN OPER RES, V98, P65, DOI 10.1023/A:1019235819716
   Howlett P, 1996, AUTOMATICA, V32, P519, DOI 10.1016/0005-1098(95)00184-0
   Howlett PG, 1997, J AUST MATH SOC B, V38, P388, DOI 10.1017/S0334270000000746
   Howlett PG, 2001, DYNAM CONT DIS SER B, V8, P41
   Huang K, 2019, J ADV TRANSPORT, DOI 10.1155/2019/7258986
   Huang YR, 2018, COMPUT IND ENG, V126, P149, DOI 10.1016/j.cie.2018.09.024
   Hui Hu, 2010, 2010 IEEE 17th International Conference on Industrial Engineering and Engineering Management (IE&EM2010), P1560, DOI 10.1109/ICIEEM.2010.5646113
   Hwang HS, 1998, IEEE T SYST MAN CY A, V28, P791, DOI 10.1109/3468.725350
   Jaakkola T., 1993, Advances in neural information processing systems, V6
   Kang M., 2011, Journal of International Council on Electrical Engineering, V1, P123, DOI [10.5370/JICEE.2011.1.2.123, DOI 10.5370/JICEE.2011.1.2.123]
   Khmelnitsky E, 2000, IEEE T AUTOMAT CONTR, V45, P1257, DOI 10.1109/9.867018
   Kim H, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111911
   Lai QY, 2020, TRANSPORT RES E-LOG, V141, DOI 10.1016/j.tre.2020.102007
   Li WH, 2021, J ENERGY STORAGE, V36, DOI 10.1016/j.est.2021.102355
   Liang F, 2020, IEEE T COMMUN, V68, P1760, DOI 10.1109/TCOMM.2019.2957482
   Liu J, 2021, IEEE C EVOL COMPUTAT, P1333, DOI 10.1109/CEC45853.2021.9504810
   Liu WT, 2021, TRANSPORT RES C-EMER, V129, DOI 10.1016/j.trc.2021.103249
   Liu WT, 2018, IEEE INT C INTELL TR, P1944, DOI 10.1109/ITSC.2018.8569399
   Lu QH, 2011, J MOD TRANSP, V19, P82, DOI 10.1007/BF03325744
   Mao Q, 2022, INT C INTELLIGENT TR, P351, DOI [10.1007/978-981-19-2259-6_31, DOI 10.1007/978-981-19-2259-6_31]
   Melo F.S., 2001, Tech. Rep
   Milroy I.P.:., 1980, ASPECTS AUTOMATIC TR
   Naldini F., 2022, 24 EUR WORK GROUP TR, V62, P35, DOI 10.1016/j.trpro.2022.02.005
   Ning LB, 2022, IEEE T INTELL TRANSP, V23, P11562, DOI 10.1109/TITS.2021.3105380
   Pan ZQ, 2020, IEEE T VEH TECHNOL, V69, P3641, DOI 10.1109/TVT.2020.2975603
   Peng HJ, 2019, IEEE VEHICLE POWER, DOI 10.1109/vppc46532.2019.8952323
   Rochard BP, 2000, P I MECH ENG F-J RAI, V214, P185, DOI 10.1243/0954409001531306
   Shang MY, 2021, INFORM SCIENCES, V570, P708, DOI 10.1016/j.ins.2021.04.088
   Tang HY, 2020, KNOWL-BASED SYST, V190, DOI 10.1016/j.knosys.2019.105173
   Too J, 2021, J SUPERCOMPUT, V77, P2844, DOI 10.1007/s11227-020-03378-9
   Wang YH, 2022, IEEE T CONTR SYST T, V30, P2344, DOI 10.1109/TCST.2022.3140805
   Xiao Z, 2021, IEEE T TRANSP ELECTR, V7, P3163, DOI 10.1109/TTE.2021.3071251
   Yang JB, 2022, ENERGY, V244, DOI 10.1016/j.energy.2022.123098
   Yang LX, 2012, OMEGA-INT J MANAGE S, V40, P619, DOI 10.1016/j.omega.2011.12.001
   Yao C, 2002, IEEJ NATL CONVENTION
   Zhang M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT RAIL TRANSPORTATION (ICIRT)
   Zhong WF, 2022, IEEE T INTELL TRANSP, V23, P4063, DOI 10.1109/TITS.2020.3040730
   Zhou KC, 2022, IEEE T SYST MAN CY-S, V52, P716, DOI 10.1109/TSMC.2020.3000073
NR 50
TC 3
Z9 3
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-15051-3
EA MAR 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F6PQ0
UT WOS:000983548500001
DA 2024-07-18
ER

PT J
AU Sharma, A
   Katlaa, R
   Kaur, G
   Jayagopi, DB
AF Sharma, Annapurna
   Katlaa, Rohit
   Kaur, Gurleen
   Jayagopi, Dinesh Babu
TI Full-page handwriting recognition and automated essay scoring for
   in-the-wild essays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document analysis; Full-page handwriting recognition; Automated essay
   scoring
AB Scoring of handwritten essays in school education settings is a time-consuming task. Normalized assessment and prompt feedback enable a student to improve the articulation, comprehension and overall presentation of ideas. In this work, we present a system that can take in input as the images of the essay sheets and outputs the grade/score of the essay. We show a pipelined approach by combining a handwriting recognition model and automated essay scoring. Current handwriting recognition systems show an excellent transcription performance on the existing public domain dataset. These datasets are primarily captured in a constrained manner. The performance and efficacy of these models on unconstrained data are crucial for text understanding. In our work, we adapt an existing full-page handwriting recognition model to the unconstrained handwritten essay dataset. The full page handwriting recognition model is a deep learning model based on CNN and LSTM layers with explicit modules to identify the start of line, line normalization and text line recognition. The unconstrained dataset is from a national essay competition where students upload the essay after scanning the essay. This dataset is wild in nature as the background, margins, text-fonts and the scanning device make it challenging both visually and algorithmically.We have curated a subset of this dataset for all the experiments in this work and intend to make this dataset publicly available. We further analyze the performance on the downstream task of essay scoring using a set of classical handcrafted features and transformer-based contextual embeddings.We have formulated the problem of essay scoring as a regression task. The pre-trained embeddings/handcrafted features, for each essay, are used as representative features for the essay scoring model. Our results show that there is only a slight performance degradation in the essay scoring task due to transcription errors from the handwriting recognition module. We also show analysis with rubric level scores and handcrafted features to develop a subset of features that directly impact the rubric level score on the essay.
C1 [Sharma, Annapurna; Katlaa, Rohit; Kaur, Gurleen; Jayagopi, Dinesh Babu] Int Inst Informat Technol IIITB, Multimodal Percept Lab, Bangalore 560100, Karnataka, India.
C3 International Institute of Information Technology Bangalore (IIIT
   Bangalore)
RP Sharma, A (corresponding author), Int Inst Informat Technol IIITB, Multimodal Percept Lab, Bangalore 560100, Karnataka, India.
EM annapurna.sharma@iiitb.ac.in; rohit.katlaa@iiitb.org;
   gurleen.kaur@iiitb.org; jdinesh@iiitb.ac.in
RI Jayagopi, Dinesh Babu/ABE-2546-2021
OI Jayagopi, Dinesh Babu/0000-0003-0080-452X; Sharma,
   Annapurna/0000-0002-4661-6826
FU Visvesvaraya PhD Scheme, Ministry of Electronics and Information
   Technology (MeitY), Government of India [MEITY-PHD-2541]
FX This work was supported by Visvesvaraya PhD Scheme, Ministry of
   Electronics and Information Technology (MeitY), Government of India
   under grant number MEITY-PHD-2541.
CR [Anonymous], 2008, Advances in Neural Information Processing Systems
   Attali Yigal, 2006, The Journal of Technology, Learning and Assessment, V3
   Bojanowski P., 2016, ARXIV
   Chen H., 2013, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, P1741
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chowdhury A, 2018, ARXIV
   Devlin J., 2018, BERT PRE TRAINING DE
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2012, STUD COMPUT INTELL, V385, P5
   Heylighen F., 2002, FOUND SCI, V7, P293, DOI [10.1023/A:1019661126744, DOI 10.1023/A:1019661126744]
   Jacobson N., 2001, SIGCSE Bulletin, V33, P35, DOI 10.1145/572139.572166
   Joulin A., 2016, ARXIV
   Kakkonen T., 2005, Proceedings of the 2nd Workshop on Building Educational Applications Using NLP, P29
   Liu J.Z, 2019, ARXIV
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Moysset B, 2017, PROC INT CONF DOC, P871, DOI 10.1109/ICDAR.2017.147
   Puigcerver J, 2017, PROC INT CONF DOC, P67, DOI 10.1109/ICDAR.2017.20
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rowtula Vijay, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P426, DOI 10.1109/ICDAR.2019.00075
   Shareef A, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351263
   Sharma Annapurna, 2021, Expert Systems with Applications, V164, DOI 10.1016/j.eswa.2020.114004
   Sharma A, 2018, AUTOMATED GRADING HA
   Souibgui Mohamed Ali, 2020, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Srihari S, 2006, LECT NOTES COMPUT SC, V3872, P71
   Srihari S, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2880
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.0052, 10.1109/ICFHR.2016.48]
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   Wigington C, 2018, EUR C COMPUT VISION, P367
   Wigington C, 2017, PROC INT CONF DOC, P639, DOI 10.1109/ICDAR.2017.110
   Yannakoudakis H., 2012, P 7 WORKSHOP BUILDIN, P33
   Yousef Mohamed, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14698, DOI 10.1109/CVPR42600.2020.01472
   Zesch T., 2015, Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications, P224, DOI DOI 10.3115/V1/W15-0626
   Zhang H., 2018, PROC 13 WORKSHOP INN, DOI DOI 10.18653/V1/W18-0549
NR 37
TC 2
Z9 2
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35253
EP 35276
DI 10.1007/s11042-023-14558-z
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000948950300010
DA 2024-07-18
ER

PT J
AU Alcover-Couso, R
   SanMiguel, JC
   Escudero-Viñolo, M
   Garcia-Martin, A
AF Alcover-Couso, Roberto
   SanMiguel, Juan C.
   Escudero-Vinolo, Marcos
   Garcia-Martin, Alvaro
TI On exploring weakly supervised domain adaptation strategies for semantic
   segmentation using synthetic data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic data; Semantic segmentation; Domain adaptation; Weakly
   supervised domain adaptation
AB Pixel-wise image segmentation is key for many Computer Vision applications. The training of deep neural networks for this task has expensive pixel-level annotation requirements, thus, motivating a growing interest on synthetic data to provide unlimited data and its annotations. In this paper, we focus on the generation and application of synthetic data as representative training corpuses for semantic segmentation of urban scenes. First, we propose a synthetic data generation protocol, which identifies key features affecting performance and provides datasets with variable complexity. Second, we adapt two popular weakly supervised domain adaptation approaches (combined training, fine-tuning) to employ synthetic and real data. Moreover, we analyze several backbone models, real/synthetic datasets and their proportions when combined. Third, we propose a new curriculum learning strategy to employ several synthetic and real datasets. Our major findings suggest the high performance impact of pace and order of synthetic and real data presentation, achieving state of the art results for well-known models. The results by training with the proposed dataset outperform popular alternatives, thus demonstrating the effectiveness of the proposed protocol. Our code and dataset are available at http://www-vpu.eps.uam.es/publications/WSDA semantic/
C1 [Alcover-Couso, Roberto; SanMiguel, Juan C.; Escudero-Vinolo, Marcos; Garcia-Martin, Alvaro] Univ Autonoma Madrid, Escuela Politecn Super, Madrid, Spain.
C3 Autonomous University of Madrid
RP Alcover-Couso, R (corresponding author), Univ Autonoma Madrid, Escuela Politecn Super, Madrid, Spain.
EM roberto.alcover@uam.es; juancarlos.sanmiguel@uam.es;
   marcos.escudero@uam.es; alvaro.garcia@uam.es
RI Alcover-Couso, Roberto/IUP-6540-2023; Escudero-Vinolo,
   Marcos/C-3601-2014
OI Alcover-Couso, Roberto/0000-0001-9609-4416; Escudero-Vinolo,
   Marcos/0000-0002-9156-3428
FU Ministerio de Ciencia e Innovacion of the Spanish Government
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work is part of the preliminary tasks related to
   the SEGA-CV (TED2021-131643A-I00) and the HVD (PID2021-125051OB-I00)
   projects funded by the Ministerio de Ciencia e Innovacion of the Spanish
   Government.
CR Balaji Y, 2019, IEEE I CONF COMP VIS, P6509, DOI 10.1109/ICCV.2019.00660
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Biasetton M, 2019, IEEE COMPUT SOC CONF, P1211, DOI 10.1109/CVPRW.2019.00160
   Bousmalis K, 2019, PROC IEEE C COMPUT V
   Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249
   Chellappa R., 2018, PROC IEEE C COMPUT V, P3
   Chen L-C., 2015, ARXIV
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen SJ, 2021, PROC CVPR IEEE, P11013, DOI 10.1109/CVPR46437.2021.01087
   Chen Y., 2021, ARXIV
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   Di Mauro D, 2020, PATTERN RECOGN LETT, V136, P175, DOI 10.1016/j.patrec.2020.06.002
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gatys L. A., 2015, arXiv
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Georgakis G., 2017, ARXIV
   Gong C, 2016, IEEE T IMAGE PROCESS, V25, P3249, DOI 10.1109/TIP.2016.2563981
   Gonzalez M, 2017, THESIS U AUTONOMA MA
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Haoran Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P642, DOI 10.1007/978-3-030-58568-6_38
   Hinterstoisser S, 2019, IEEE INT CONF COMP V, P2787, DOI 10.1109/ICCVW.2019.00340
   Hoffman Judy, 2016, arXiv
   Hung W. -C., 2018, P BRIT MACHINE VISIO
   Ionescu RT, 2016, PROC CVPR IEEE, P2157, DOI 10.1109/CVPR.2016.237
   Kellman M, 2019, IEEE INT CONF COMPUT, DOI 10.1109/iccphot.2019.8747339
   Kong S, 2017, ARXIV
   Kumar MP, 2011, IEEE I CONF COMP VIS, P1800, DOI 10.1109/ICCV.2011.6126446
   Li S, 2020, AAAI CONF ARTIF INTE, V34, P11386
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Li Y, 2019, AEROSP CONF PROC
   Lian Q, 2019, IEEE I CONF COMP VIS, P6757, DOI 10.1109/ICCV.2019.00686
   Lin G, 2016, ARXIV
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Luyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P608, DOI 10.1007/978-3-030-58568-6_36
   Michieli U, 2021, COMPUT VIS IMAGE UND, V205, DOI 10.1016/j.cviu.2021.103167
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Nowruzi F. E., 2019, ARXIV
   Pawan Kumar M., 2010, NIPS
   Pemasiri A, 2021, COMPUT VIS IMAGE UND, V202, DOI 10.1016/j.cviu.2020.103085
   Pentina A, 2015, PROC CVPR IEEE, P5492, DOI 10.1109/CVPR.2015.7299188
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Russo P, 2019, LECT NOTES COMPUT SC, V11751, P292, DOI 10.1007/978-3-030-30642-7_26
   Saito K, 2019, IEEE I CONF COMP VIS, P8049, DOI 10.1109/ICCV.2019.00814
   Saporta A, 2020, ESL ENTROPY GUIDED S
   Sato M, 2019, PROC IEEE COOL CHIPS, DOI 10.1109/coolchips.2019.8721331
   Seichter D, 2021, IEEE INT CONF ROBOT, P13525, DOI 10.1109/ICRA48506.2021.9561675
   Shoeibi A., 2020, ARXIV
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Soviany P, 2021, ARXIV
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun RQ, 2019, PROC CVPR IEEE, P4355, DOI 10.1109/CVPR.2019.00449
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Tobin Josh, 2017, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P23, DOI 10.1109/IROS.2017.8202133
   Toldo M, 2021, IEEE WINT CONF APPL, P1357, DOI 10.1109/WACV48630.2021.00140
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   Wang Q, 2019, IEEE T IMAGE PROCESS, V28, P4376, DOI 10.1109/TIP.2019.2910667
   Wang W., 2021, ARXIV
   Wang YD, 2020, PATTERN RECOGN LETT, V136, P257, DOI 10.1016/j.patrec.2020.06.011
   Wang Z., 2020, P IEEECVF C COMPUTER
   Wen SH, 2020, IEEE ACCESS, V8, P176480, DOI 10.1109/ACCESS.2020.3026684
   Wu YZ, 2019, IEEE INT CONF BIG DA, P1971, DOI [10.1109/BigData47090.2019.9006104, 10.1109/bigdata47090.2019.9006104]
   Yao R, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3391743
   Yuan Y, 2021, HRT HIGH RESOLUTION
   Zhang B, 2021, INT C PATT RECOG, P1912, DOI 10.1109/ICPR48806.2021.9411915
   Zhang Y, 2020, IEEE T PATTERN ANAL, V42, P1823, DOI 10.1109/TPAMI.2019.2903401
   Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223
   Zhao H., 2017, ARXIV
   Zhao S., 2019, Adv. Neural Inf. Process. Syst., V32
   Zhao S, 2020, arXiv
   Zhao SC, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P541, DOI 10.1145/3442381.3449981
   Zheng Q, 2019, CHINA COMMUN, V16, P212, DOI 10.23919/JCC.2019.11.017
   Zhou T., 2022, arXiv
NR 82
TC 2
Z9 2
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35879
EP 35911
DI 10.1007/s11042-023-14662-0
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000947594500008
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Zhang, YW
   Wang, XT
   Yamasaki, T
AF Zhang, Yiwei
   Wang, Xueting
   Yamasaki, Toshihiko
TI Which account will you follow? Recommending influential accounts on
   social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Recommendation; Hashtag; Graph embedding
ID INSTAGRAM; FACEBOOK; BRANDS; IMPACT; TRUST
AB In the age of social media, brands spend large part of their budget on social media marketing to promote their products. Finding potential followers for brands has become an immense business opportunity. On the other hand, recommending influential accounts (such as brands and influencers) to ordinary users (customers) can help users find content of their interest. Therefore, matching among influential accounts and ordinary users is a necessary task and could be a powerful marketing tool. In order to effectively calculate compatibility among influential accounts and ordinary users, we consider that hashtags posted by users somehow represent their preferences and could be useful resources. We collected two Instagram datasets: including a brand dataset consisting of 99 brands with 78,996 followers and an influencer dataset consisting of 80 influencers with 43,992 followers. We utilize these users and their posted hashtags to create an account-user-tag graph. We propose a novel framework that incorporates graph embedding and pairwise learning to rank for better recommendation. The random walk based graph embedding method can capture high-order proximity in the interaction data. But it ignores some parts in the graph due to its randomness. The pairwise learning to rank component is designed for the complementary purpose. Experimental results showed that the proposed method is effective at recommending influential accounts when compared with existing methods. In the top-10 recommendation task, our proposed method achieves hit ratio of 0.416 in the brand dataset and 0.524 in the influencer dataset.
C1 [Zhang, Yiwei; Wang, Xueting; Yamasaki, Toshihiko] Univ Tokyo, Dept Informat Commun & Engn, 7-3-1 Hongo,Bunkyo Ku, Tokyo 1138656, Japan.
   [Wang, Xueting] CyberAgent Inc, AI Lab, Shibuya Scramble Sq 2-24-12,Shibuya Ku, Tokyo, Japan.
C3 University of Tokyo
RP Zhang, YW (corresponding author), Univ Tokyo, Dept Informat Commun & Engn, 7-3-1 Hongo,Bunkyo Ku, Tokyo 1138656, Japan.
EM zhangyiwei@cvm.t.u-tokyo.ac.jp; wangxueting@cyberagent.co.jp;
   yamasaki@cvm.t.u-tokyo.ac.jp
RI zheng, Li/JVN-7465-2024; zhou, you/KBC-3567-2024; wang,
   xueting/JPY-2782-2023; zhang, xu/JXX-7692-2024; Zhang,
   Xiaoxi/KBP-8753-2024; zhang, jiahao/KEE-9357-2024; Liu,
   Jingyi/JWP-6326-2024
FU  [JP19J22939];  [JP19K20289];  [JP18H03339]
FX AcknowledgementsThis work was supported by the Grants-in-Aid for
   Scientific Research Number JP19J22939, JP19K20289, and JP18H03339.
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Bonomo M, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P1155, DOI 10.1145/3341161.3345621
   Cattuto C, 2008, LECT NOTES COMPUT SC, V5318, P615, DOI 10.1007/978-3-540-88564-1_39
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen JP, 2018, APPL SOFT COMPUT, V66, P512, DOI 10.1016/j.asoc.2017.07.029
   Chiu YP, 2021, J THEOR APPL EL COMM, V16, P71, DOI 10.4067/S0718-18762021000100106
   Christoffel F, 2015, P 9 ACM C RECOMMENDE, P163, DOI DOI 10.1145/2792838.2800180
   Cui P, 2019, IEEE T KNOWL DATA EN, V31, P833, DOI 10.1109/TKDE.2018.2849727
   De Salve A, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3441447
   De Veirman M, 2017, INT J ADVERT, V36, P798, DOI 10.1080/02650487.2017.1348035
   de Vries L, 2012, J INTERACT MARK, V26, P83, DOI 10.1016/j.intmar.2012.01.003
   Farseev A, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1234, DOI 10.1145/3240508.3241387
   Felix R, 2017, J BUS RES, V70, P118, DOI 10.1016/j.jbusres.2016.05.001
   Gan T, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1933, DOI 10.1145/3343031.3351080
   Gelli F, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P465, DOI 10.1145/3240508.3240689
   Gori M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2766
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hamilton WL, 2017, ADV NEUR IN, V30
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hou YF, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P65, DOI 10.1145/3292500.3330948
   Kipf TN, 2017, INT C LEARN REPR
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kuksov D, 2013, MARKET SCI, V32, P294, DOI 10.1287/mksc.1120.0753
   Laroche M, 2013, INT J INFORM MANAGE, V33, P76, DOI 10.1016/j.ijinfomgt.2012.07.003
   Laroche M, 2012, COMPUT HUM BEHAV, V28, P1755, DOI 10.1016/j.chb.2012.04.016
   Mazloom M., 2016, P ACM MULT, P197, DOI [10.1145/2964284.2967210, 10]
   Mikolov T, 2013, P WORKSHOP ICLR 2013
   Naylor RW, 2012, J MARKETING, V76, P105, DOI 10.1509/jm.11.0105
   Park H, 2017, IEEE INT CONF BIG DA, P756, DOI 10.1109/BigData.2017.8257991
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Phua J, 2017, TELEMAT INFORM, V34, P412, DOI 10.1016/j.tele.2016.06.004
   Qiu JZ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2110, DOI 10.1145/3219819.3220077
   Recht Benjamin, 2011, 25 ANN C NEUR INF PR, DOI 10.48550/arXiv.1106.5730
   Rendle S., 2009, P 25 C UNCERTAINTY A, P452
   Salman A, INSTAGRAM NUMBERS ST
   Segev N, 2018, ACM/SIGIR PROCEEDINGS 2018, P1009, DOI 10.1145/3209978.3210134
   Su X, 2009, SURVEY COLLABORATIVE, V2009
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang JZ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P839, DOI 10.1145/3219819.3219869
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wartena C, 2009, INT CONF INTELL SYST, P273, DOI 10.1109/ISDA.2009.130
   Woods Steven., 2016, #Sponsored: The Emergence of Influencer Marketing
   Wu B, 2018, UNLOCKING AUTHOR POW
   Yang JH, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P140, DOI 10.1145/3240323.3240381
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yun JT, 2019, INT J ADVERT, V38, P776, DOI 10.1080/02650487.2019.1575106
   Zhang Y, 2019, P ACM INT C MULTIMED, P1
   Zhang YW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3106, DOI 10.1145/3474085.3475453
   Zhang YW, 2021, ITE TRANS MEDIA TECH, V9, P262, DOI 10.3169/mta.9.262
NR 54
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34053
EP 34074
DI 10.1007/s11042-023-14538-3
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000947594500002
DA 2024-07-18
ER

PT J
AU He, JY
   Song, XN
   Feng, ZH
   Xu, TY
   Wu, XJ
   Kittler, J
AF He, Junyuan
   Song, Xiaoning
   Feng, Zhenhua
   Xu, Tianyang
   Wu, Xiaojun
   Kittler, Josef
TI ETM-face: effective training sample selection and multi-scale feature
   learning for face detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Scale variation; Sample selection; Multi-scale feature
   extraction
AB In recent years, deep-learning-based face detectors have achieved promising results and been successfully used in a wide range of practical applications. However, extreme appearance variations are still the major obstacles for robust and accurate face detection in the wild. To address this issue, we propose an Improved Training Sample Selection (ITSS) strategy for mining effective positive and negative samples during network training. The proposed ITSS procedure collaborates with face sampling during data augmentation and selects suitable positive sample centres and IoU overlap for face detection. Moreover, we propose a Residual Feature Pyramid Fusion (RFPF) module that collects semantically robust features to improve the scale-invariance of deep features and better represent faces at different feature pyramid levels. The experimental results obtained on the FDDB and WiderFace datasets demonstrate the superiority of the proposed method over the state-of-the-art approaches. Specially, the proposed method achieves 96.9% and 96.2% in terms of AP on the easy and medium test sets of WiderFace.
C1 [He, Junyuan; Song, Xiaoning; Xu, Tianyang; Wu, Xiaojun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Lihu Ave, Wuxi 214122, Peoples R China.
   [Feng, Zhenhua] Univ Surrey, Dept Comp Sci, Guildford GU2 7XH, England.
   [Feng, Zhenhua; Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, England.
C3 Jiangnan University; University of Surrey; University of Surrey
RP Song, XN (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Lihu Ave, Wuxi 214122, Peoples R China.; Feng, ZH (corresponding author), Univ Surrey, Dept Comp Sci, Guildford GU2 7XH, England.; Feng, ZH (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, England.
EM x.song@jiangnan.edu.cn; z.feng@surrey.ac.uk
RI Feng, Zhenhua/T-3139-2019; Xu, Tianyang/AAE-1982-2019
OI Feng, Zhenhua/0000-0002-4485-4249; Xu, Tianyang/0000-0002-9015-3128;
   Song, Xiaoning/0000-0002-5741-9318
FU Major Project of National Social Science Foundation of China [21ZD166];
   National Natural Science Foundation of China [61876072, 61902153];
   Natural Science Foundation of Jiangsu Province [BK20221535]
FX This work was supported by the Major Project of National Social Science
   Foundation of China (No. 21&ZD166), the National Natural Science
   Foundation of China (61876072, 61902153) and the Natural Science
   Foundation of Jiangsu Province (No. BK20221535).
CR Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chen KA, 2019, PROC CVPR IEEE, P5114, DOI 10.1109/CVPR.2019.00526
   Chen P., 2019, ARXIV
   Chi C, 2019, AAAI CONF ARTIF INTE, P8231
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Feng ZH, 2018, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2018.00238
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hendrycks D., 2016, ARXIV
   Huang L., 2015, Comput. Sci.
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jiashu Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P344, DOI 10.1007/978-3-030-58539-6_21
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y., 2020, P IEEE CVF C COMPUTE, P13568
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang CJ, 2021, MULTIMED TOOLS APPL, V80, P13761, DOI 10.1007/s11042-020-10401-x
   Wei Ke, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10203, DOI 10.1109/CVPR42600.2020.01022
   Xiao YH, 2020, MULTIMED TOOLS APPL, V79, P16531, DOI 10.1007/s11042-019-7661-x
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Yang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13043, DOI 10.1109/CVPR42600.2020.01306
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang WK, 2019, MULTIMED TOOLS APPL, V78, P24373, DOI 10.1007/s11042-018-6995-0
   Yashunin D, 2020, ARXIV
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Zhang B., 2020, ARXIV
   Zhang F, 2019, ARXIV
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang SF, 2021, IEEE T PATTERN ANAL, V43, P4008, DOI 10.1109/TPAMI.2020.2997456
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang XS, 2019, ADV NEUR IN, V32
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng Z., 2020, ARXIV
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhu Y, 2020, ARXIV
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zoph B., 2016, INT C LEARN REPR
NR 57
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26595
EP 26611
DI 10.1007/s11042-023-14859-3
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946494700004
DA 2024-07-18
ER

PT J
AU Singh, JP
   Kumar, M
AF Singh, Juginder Pal
   Kumar, Manoj
TI Chronological ant lion optimizer-based deep convolutional neural network
   for panic behavior detection in crowded scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Panic behavior detection; Video surveillance; Motion estimation; ALO;
   Deep CNN
ID HYBRID TRACKING MODEL; ABNORMAL EVENT DETECTION; ALGORITHM; FEATURES
AB Nowadays, crowd scene becomes the most active-oriented research and trendy topic in computer vision applications. However, panic behavior is the key suggestion of occurrence of the abnormal behavior in the human crowd such that detecting the panic behavior helps to prevent the disastrous situations. Various existing methods are adopted for detecting panic behavior in crowded scenes, but it results in performance degradation due to the varying density of objects in the crowded scenes. Hence, an effective method is developed using the proposed Chronological-Ant Lion Optimizer-based Deep Convolutional Neural Network (Chronological ALO-based Deep CNN) to detect the panic behaviors in crowd scenes. Nevertheless, the adopted Chronological ALO is modeled by incorporating the Chronological event with ALO and is mainly used for training the Deep CNN classifier in order to reveal better detection results. Based on the extracted feature, variations in the crowd dynamics are examined in the non-panic situation for characterizing the usual behavior of pedestrians. Finally, panic behavior is presumed as the deviation from disparities observed while non-panic situations. However, the proposed Chronological ALO-based Deep CNN obtained better performance with the metrics, like accuracy, sensitivity, and specificity with the values of 95.833%, 96.296%, and 96.329%, respectively.
C1 [Singh, Juginder Pal; Kumar, Manoj] GLA Univ, Dept Comp Engn & Applicat, Chaumuhan 281406, Uttar Pradesh, India.
C3 GLA University
RP Singh, JP (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Chaumuhan 281406, Uttar Pradesh, India.
EM juginder.singh@gla.ac.in; manoj.kumar@gla.ac.in
RI Kumar, Manoj/AFS-0700-2022
OI Kumar, Manoj/0000-0001-9598-0280
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ali ES, 2016, ENERGY, V116, P445, DOI 10.1016/j.energy.2016.09.104
   Ali S, 2007, PROC CVPR IEEE, P65
   [Anonymous], 2014, ADV INTELL SYST
   Arndt R, 2007, P 6 INT SEMANTIC WEB
   Biswas S, 2017, MACH VISION APPL, V28, P35, DOI 10.1007/s00138-016-0800-8
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Dongping Zhang, 2013, Information Technology Journal, V12, P1199, DOI 10.3923/itj.2013.1199.1205
   Faghih-Roohi S, 2016, IEEE IJCNN, P2584, DOI 10.1109/IJCNN.2016.7727522
   Geng Y, 2019, WORLD WIDE WEB, V22, P689, DOI 10.1007/s11280-018-0603-0
   github, MOTION ESTIMATION DA
   Gogoi P, 2011, COMPUT J, V54, P570, DOI 10.1093/comjnl/bxr026
   Hatirnaz E, 2020, MULTIMED TOOLS APPL, V79, P17579, DOI 10.1007/s11042-020-08659-2
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Kumar M, 2017, IMAGING SCI J, V65, P75, DOI 10.1080/13682199.2016.1265707
   Kumar M, 2017, J CENT SOUTH UNIV, V24, P2071, DOI 10.1007/s11771-017-3616-4
   Kumar M, 2017, INT J COMPUT INT SYS, V10, P234, DOI 10.2991/ijcis.2017.10.1.16
   Lazaridis L, 2018, EUR SIGNAL PR CONF, P2060, DOI 10.23919/EUSIPCO.2018.8553620
   Li A, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/406941
   Liu Y, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2902, DOI 10.1109/WCICA.2014.7053189
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mousavi H, 2016, INTEL SYST REF LIBR, V106, P185, DOI 10.1007/978-3-319-31053-4_11
   Pawar K, 2019, WORLD WIDE WEB, V22, P571, DOI 10.1007/s11280-018-0582-1
   Pennisi A, 2016, COMPUT VIS IMAGE UND, V144, P166, DOI 10.1016/j.cviu.2015.09.010
   Rabiee H, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2786-0
   Shehab D, 2019, MACH VISION APPL, V30, P919, DOI 10.1007/s00138-018-0974-3
   Singh J, 2023, J FOOD SCI TECH MYS, V60, P1695, DOI 10.1007/s13197-022-05442-z
   Sjarif N. A., 2012, Int. J. Adv. Software Comput. Appl, V4, P1
   Song B, ADV INTELLIGENT FUZZ, V2020
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   [吴新宇 Wu Xinyu], 2014, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V28, P575
   Xie SC, 2019, NEURAL COMPUT APPL, V31, P175, DOI 10.1007/s00521-018-3692-x
   Xu L, 2012, IEEE T PATTERN ANAL, V34, P1744, DOI 10.1109/TPAMI.2011.236
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
NR 37
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32373
EP 32396
DI 10.1007/s11042-023-14598-5
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943970200018
DA 2024-07-18
ER

PT J
AU Bozkurt, MH
   Karagol, S
AF Bozkurt, Mustafa Hakan
   Karagol, Serap
TI Statistical elimination based approach to jaw and tooth separation on
   panoramic radiographs for dental human identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Medical imaging; Dental biometrics; Dental x-ray
   analysis; dental; Human identification
ID X-RAY IMAGES; SYSTEM; SHAPE; SEGMENTATION; BIOMETRICS; TEETH
AB Dental biometrics is a type of biometrics that uses dental information to identify individuals. Well-known biometric features such as fingerprints and gait images have been successfully used to identify individuals. However, these features can be easily damaged. Teeth are more durable than other biometric features. Therefore, dental biometrics are used when other biometric features are not available. There are several types of dental radiographs. Panoramic radiographs are a type of x-ray that show the entire jaw. In these x-rays, all the teeth are viewed together. Panoramic x-rays contain more information about the tooth and jaw structures. However, they also contain unwanted elements such as the bite disc, mandible, nasal bone, etc. This makes them more difficult to process. All types of dental radiographs have difficulties in processing due to slight differences in brightness, overlapping or differently aligned teeth. Identifying individuals from dental radiographs often involves the following main steps: jaw separation, tooth segmentation, feature extraction, and feature matching. The accuracy of jaw and tooth segmentation influences the next steps. In this study, a new fully automatic method for separating mandible, maxilla, and teeth in panoramic radiographs is proposed. The proposed method achieved high accuracy in jaw separation. It also achieved better jaw separation performance than comparable studies. Although the proposed method is a fully automatic method, its performance in tooth separation is close to that of the compared semi-automatic method. In the proposed study, a jaw separation ratio of 0.99, based on the number of correctly aligned teeth, was achieved. The detection rate of the separators for the teeth in the mandibular jaw is 0.90 and the accuracy is 0.86. For maxillary teeth, these values are 0.92 and 0.90, respectively. The results are promising for the automatic segmentation of panoramic radiographs for human identification.
C1 [Bozkurt, Mustafa Hakan] Karadeniz Tech Univ, Technol Fac, Dept Software Engn, Trabzon, Turkiye.
   [Karagol, Serap] Ondokuz Mayis Univ, Fac Engn, Dept Elect & Elect Engn, Samsun, Turkiye.
C3 Karadeniz Technical University; Ondokuz Mayis University
RP Bozkurt, MH (corresponding author), Karadeniz Tech Univ, Technol Fac, Dept Software Engn, Trabzon, Turkiye.
EM mhakanbozkurt@ktu.edu.tr; serap.karagol@omu.edu.tr
OI BOZKURT, MUSTAFA HAKAN/0000-0002-7734-0295
CR Abdel-Mottaleb M, 2003, Proceedings of the 46th IEEE International Midwest Symposium on Circuits & Systems, Vols 1-3, P411
   Abdi AH, 2015, J MED IMAGING, V2, DOI 10.1117/1.JMI.2.4.044003
   Ajaz A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P717, DOI 10.1109/iccsp.2013.6577149
   Al-sherif N, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P145, DOI 10.1109/ISM.2012.35
   Avuçlu E, 2019, CHAOS SOLITON FRACT, V120, P127, DOI 10.1016/j.chaos.2019.01.023
   Banday M, 2018, INT J BIOMETRICS, V10, P291
   Bozkurt MH, 2020, J DIGIT IMAGING, V33, P1410, DOI 10.1007/s10278-020-00380-8
   Cai WW, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102076
   Dibeh G, 2018, 2018 IEEE INTERNATIONAL MULTIDISCIPLINARY CONFERENCE ON ENGINEERING TECHNOLOGY (IMCET)
   Frejlichowski D, 2011, LECT NOTES COMPUT SC, V6979, P294, DOI 10.1007/978-3-642-24088-1_31
   Ghodsi S. B., 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE 2012), P303, DOI 10.1109/CSAE.2012.6272960
   Hofer M, 2007, SIBGRAPI, P281, DOI 10.1109/SIBGRAPI.2007.9
   Jaffino G, 2017, J FORENSIC LEG MED, V47, P39, DOI 10.1016/j.jflm.2017.02.006
   Jain AK, 2004, PATTERN RECOGN, V37, P1519, DOI 10.1016/j.patcog.2003.12.016
   Jain AK, 2003, LECT NOTES COMPUT SC, V2688, P429
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Lira Pedro H.M., 2009, P WORKSHOP COMPUTING
   Maurya M., 2013, INT J SCI RES PUBL, V3, P1
   Nassar DEM, 2004, P 1 INT COMP ENG C I, P354
   Nomir O, 2005, PATTERN RECOGN, V38, P1295, DOI 10.1016/j.patcog.2004.12.010
   Nomir O, 2006, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2006.313061
   Oktay AB, 2018, IET BIOMETRICS, V7, P349, DOI 10.1049/iet-bmt.2017.0078
   Olberg JV, 2016, SCAND J FORENSIC SCI, V22, P44, DOI 10.1515/sjfs-2016-0008
   Permata NA, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), P281, DOI 10.1109/KCIC.2017.8228600
   Pushparaj V, 2013, J DIGIT IMAGING, V26, P259, DOI 10.1007/s10278-012-9492-4
   Rabbani GS, 2019, PROCEEDINGS OF 2019 THE 3RD INTERNATIONAL CONFERENCE ON CRYPTOGRAPHY, SECURITY AND PRIVACY (ICCSP 2019) WITH WORKSHOP 2019 THE 4TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2019), P196, DOI 10.1145/3309074.3309115
   Rad AE, 2018, MULTIMED TOOLS APPL, V77, P28843, DOI 10.1007/s11042-018-6035-0
   Raja Rohit, 2018, International Journal of Information and Computer Security, V10, P303
   Raja R., 2015, Assoc. Adv. Model. Simul. Tech. Enterp. Adv. B, V58, P14
   Rehman F, 2015, 2015 FIFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION AND COMMUNICATION TECHNOLOGY AND ITS APPLICATIONS (DICTAP), P96, DOI 10.1109/DICTAP.2015.7113178
   Román JCM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093110
   Said EH, 2006, IEEE T INF FOREN SEC, V1, P178, DOI 10.1109/TIFS.2006.873606
   Sanjay R., 2012, Int J Future Comput Commun, P366, DOI DOI 10.7763/IJFCC.2012.V1.97
   Shamsafar F, 2013, IRAN CONF MACH, P397, DOI 10.1109/IranianMVIP.2013.6780018
   Silva G, 2018, EXPERT SYST APPL, V107, P15, DOI 10.1016/j.eswa.2018.04.001
   Srivastava A., 2017, Int. J. Latest Technol. Eng. Manag. Appl. Sci. (IJLTEMAS) VI, VVI
   Srivastava A, 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P281, DOI 10.4018/978-1-5225-2848-7.ch011
   Tiwari L, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108882
   You HF, 2021, KNOWL-BASED SYST, V231, DOI 10.1016/j.knosys.2021.107456
   Zhou J, 2005, PATTERN RECOGN, V38, P2132, DOI 10.1016/j.patcog.2005.01.011
NR 40
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32117
EP 32150
DI 10.1007/s11042-023-14746-x
EA MAR 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100008
DA 2024-07-18
ER

PT J
AU Vasudeva, K
   Dubey, A
   Chandran, S
AF Vasudeva, Kshitiza
   Dubey, Akshat
   Chandran, Saravanan
TI SCL-FExR: supervised contrastive learning approach for facial expression
   Recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrastive training; Supervised learning; FER2013; AffectNet; Facial
   expression Recognition
ID DEEP
AB Facial Expression Recognition (FER) is a significant field of computer vision and has emerged as a crucial component of Human-computer interaction. Breakthroughs in self-supervised representation learning have resulted from a renaissance of work in contrastive learning, following the state-of-the-art performance in unsupervised training of deep image models. However, due to the random sampling of false negatives for contrastive loss calculation, the representation quality might degrade in FER. In this work, we extend the self-supervised contrastive learning technique to the fully supervised setting to effectively exploit label information in classifying facial expressions. Therefore, we propose a Supervised Contrastive Learning- Facial Expression Recognition (SCL-FExR) system to create a model which is robust for real-world emotion detection. Our goal is not to compete with the highly complex state-of-the-art CNN-based Deep Neural Network, but to establish a method that can be incorporated to achieve similar performance but with less-complex models and more robustness. We demonstrate the effectiveness of the suggested method using three FER datasets: FER2013, AffectNet, and CK+. On FER2013, we achieved a similar accuracy of 76%, establishing a method that can be incorporated into less complex CNN-based Deep Neural Networks to achieve robustness and be significantly more noise-resistant. The secondary aim is to show how a data-based strategy may be used to train very complicated deep learning models instead of a model-based approach, which solves the issue of computational expenditure.
C1 [Vasudeva, Kshitiza; Chandran, Saravanan] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
   [Dubey, Akshat] Birla Inst Technol, Dept Comp Sci & Engn, Ranchi, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; Birla Institute of Technology Mesra
RP Vasudeva, K (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
EM kshitizavasudeva@gmail.com; dubeyakshat07@gmail.com; cs@ieee.org
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354
   Bengio Y., 2013, Fer-2013 face database
   Bisogni C, 2022, IEEE T IND INFORM, V18, P5619, DOI 10.1109/TII.2022.3141400
   Breuer R., 2017, arXiv
   Chaitanya K., 2020, Advances in Neural Information Processing Systems, V33, P12546, DOI DOI 10.48550/ARXIV.2006.10511
   Chen L, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101539
   Chen T, 2020, PR MACH LEARN RES, V119
   DAN Z, 2022, P IEEECVF C COMPUTER, P20291
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Fu R., 2020, ARXIV
   Gan YJ, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING (ICVISP 2018), DOI 10.1145/3271553.3271584
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Gidaris S., 2018, P 6 INT C LEARNING R
   Gunel B., 2020, ARXIV
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hua WT, 2019, IEEE ACCESS, V7, P24321, DOI 10.1109/ACCESS.2019.2900231
   Huang YX, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101189
   Jeon J., 2016, P 10 INT C UB INF MA, P1, DOI DOI 10.1145/2857546.2857642
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Knyazev B, 2017, ARXIV
   Kolesnikov A, 2019, PROC CVPR IEEE, P1920, DOI 10.1109/CVPR.2019.00202
   Li S., 2012, Asian Conference on Computer Vision, P577
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li Y, 2018, INT C PATT RECOG, P2209, DOI 10.1109/ICPR.2018.8545853
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Naik AJ, 2021, MULTIMED TOOLS APPL, V80, P18365, DOI 10.1007/s11042-021-10682-w
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Ramachandran P., 2017, ARXIV
   Rifai S, 2012, LECT NOTES COMPUT SC, V7577, P808, DOI 10.1007/978-3-642-33783-3_58
   Roy Shuvendu, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P253, DOI 10.1145/3462244.3479955
   Roy S, 2021, 2021 9 INT C AFFECTI, P1
   Selvaraju R.R., 2016, arXiv
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, DOI DOI 10.48550/ARXIV.1206.2944
   Spurr Adrian, 2021, P IEEE CVF INT C COM, P11230
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taghanaki S.R., 2020, ARXIV
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Yonglong Tian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P776, DOI 10.1007/978-3-030-58621-8_45
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhao X., 2021, Proceedings ofthe IEEE/CVFInternational Conference on Computer Vision, P10623
   Zhuang CX, 2019, IEEE I CONF COMP VIS, P6001, DOI 10.1109/ICCV.2019.00610
NR 51
TC 1
Z9 1
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31351
EP 31371
DI 10.1007/s11042-023-14803-5
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000943009100002
DA 2024-07-18
ER

PT J
AU Paramesha, K
   Gururaj, HL
   Nayyar, A
   Ravishankar, KC
AF Paramesha, K.
   Gururaj, H. L.
   Nayyar, Anand
   Ravishankar, K. C.
TI Sentiment analysis on cross-domain textual data using classical and deep
   learning approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Contextual polarity; Cross-domain; Machine learning;
   Classifiers; Hybrid models; Latent mutual information; Feature
   engineering
AB Sentiment Analysis (SA) using machine learning approaches is a fascinating field of research to unravel the opinion expressed by online users. It deals with the classification problem of opinions expressed on a product or service in review texts as positive or negative or neutral. Classification beyond binary classes poses even greater challenges using machine learning. In this paper two sets of approaches, first set of approach on traditional machine learning and second one on deep learning technique was and evaluated and analyzed for multiclass polarity classification at fine-grain level on cross-domain review dataset. The analysis of performance of traditional machine learning approaches that comprise ensemble models and incorporate semantic and diverse statistical features, shows that ensemble models are better in their category. With the proposed sentiment-document model coupled with the robustness of the proposed ensemble models, we were able to investigate and establish that the document polarity could serve as the latent mutual information that could leverage the model performance of predicting sentiments at sentence and document levels. Furthermore, the evaluation of deep learning models infers that they are more viable option for multi-class polarity classification of cross-domain dataset. They outperformed the traditional approaches based on feature extraction and feature engineering and achieved better accuracy and F1 scores.
C1 [Paramesha, K.] Vidyavardhaka Coll Engn, Mysuru, India.
   [Gururaj, H. L.] Manipal Acad Higher Educ, Manipal Inst Technol Bengaluru, Dept Informat Technol, Manipal, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
   [Ravishankar, K. C.] Dept Comp Sci Engn, Hassan, India.
C3 Vidyavardhaka College of Engineering; Manipal Academy of Higher
   Education (MAHE); Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015; L, G/JOK-3625-2023
OI Nayyar, Anand/0000-0002-9821-6146; , K C Ravishankar/0000-0002-9830-5675
CR Aggarwal Charu C, 2012, A survey of text clustering algorithms, P163, DOI [10.1007/978-1-4614-3223-4, DOI 10.1007/978-1-4614-3223-46]
   Al-Moslmi T, 2017, IEEE ACCESS, V5, P16173, DOI 10.1109/ACCESS.2017.2690342
   [Anonymous], 2003, The Oxford handbook of computational linguistics
   [Anonymous], 2005, Proceedings of Recent Advances in Natural Language Processing (RANLP)
   [Anonymous], 2015, P 6 WORKSH COMP APPR
   Baccianella S., 2010, P 7 INT C LANG RES O, P2200
   Benamara F., 2011, P 5 INT JOINT C NATU, P1180
   Benamara F., 2012, Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics, ExProM'12, P10
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   CHURCH KW, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P76
   De Marneffe M.-C., 2006, LREC, V6, P449
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI [DOI 10.1145/1341531.1341561, 10.1145/1341531.1341561]
   Esuli A., 2006, P 11 M EUROPEAN CHAP, P193
   Hoang M., 2019, P 22 NORD C COMP LIN, P187
   Hung CL, 2016, KNOWL-BASED SYST, V110, P224, DOI 10.1016/j.knosys.2016.07.030
   Indurkhya N., 2010, Handbook of natural language processing, V2
   Ji-won Jang, 2017, [Journal of British & American Studies, 영미연구], V39, P179, DOI 10.25093/jbas.2017.39.179
   Kaji N, 2007, EMNLP CONLL, P1075
   Koppel M, 2006, COMPUT INTELL-US, V22, P100, DOI 10.1111/j.1467-8640.2006.00276.x
   Kotzias D, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P597, DOI 10.1145/2783258.2783380
   Ku LW, 2009, CHILD NERV SYST, V383
   Li T, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P716, DOI 10.1145/1571941.1572093
   Li X., 2019, ARXIV
   Liu B., 2007, Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu Y, 2014, LECT NOTES COMPUT SC, V8404, P1, DOI 10.1007/978-3-642-54903-8_1
   Martineau Justin, 2009, P INT AAAI C WEB SOC, V3, P258
   McDonald Ryan., 2007, Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, P432
   Mihalcea R, 2011, ENCY MACHINE LEARNIN, P1027
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Narayanan R, 2009, P 2009 C EMP METH NA, V1, P180
   Paltoglou G, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1386
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Paramesha K., 2016, MACH LEARN APPL INT, V3, P65
   Paramesha K., 2021, Machine Learning for Healthcare Applications, P151
   Polpinij Jantima, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P518, DOI 10.1109/WIIAT.2008.68
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380
   Täckström O, 2011, LECT NOTES COMPUT SC, V6611, P368, DOI 10.1007/978-3-642-20161-5_37
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Wang G, 2014, DECIS SUPPORT SYST, V57, P77, DOI 10.1016/j.dss.2013.08.002
   Wang Y, 2013, 2013 INTERNATIONAL WORKSHOP ON MICROWAVE AND MILLIMETER WAVE CIRCUITS AND SYSTEM TECHNOLOGY (MMWCST), P300, DOI 10.1109/MMWCST.2013.6814637
   Whitelaw C, 2005, P 14 ACM INT C INF K, P625, DOI 10.1145/1099554.1099714
   Wiebe J, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P1065
   Wiegand M., 2010, P WORKSHOP NEGATION, P60
   Wilson T, 2009, COMPUT LINGUIST, V35, P399, DOI 10.1162/coli.08-012-R1-06-90
   Xu H, 2019, ARXIV
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yarowsky D, 2010, CH CRC MACH LEARN PA, P315
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang W, 2011, EXPERT SYST APPL, V38, P2758, DOI 10.1016/j.eswa.2010.08.066
NR 53
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30759
EP 30782
DI 10.1007/s11042-023-14427-9
EA FEB 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940729500013
DA 2024-07-18
ER

PT J
AU Asif, S
   Zhao, M
   Tang, FX
   Zhu, YS
AF Asif, Sohaib
   Zhao, Ming
   Tang, Fengxiao
   Zhu, Yusen
TI An enhanced deep learning method for multi-class brain tumor
   classification using deep transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-class brain tumor classification; Transfer learning; Xception;
   Deep learning; Image processing
ID CONVOLUTIONAL NEURAL-NETWORK; FEATURES FUSION; CT IMAGES; MRI; MACHINE;
   EXTRACTION
AB Multi-class brain tumor classification is an important area of research in the field of medical imaging because of the different tumor characteristics. One such challenging problem is the multiclass classification of brain tumors using MR images. Since accuracy is critical in classification, computer vision researchers are introducing a number of techniques; However, achieving high accuracy remains challenging when classifying brain images. Early diagnosis of brain tumor types can activate timely treatment, thereby improving the patient's chances of survival. In recent years, deep learning models have achieved promising results, especially in classifying brain tumors to help neurologists. This work proposes a deep transfer learning model that accelerates brain tumor detection using MR imaging. In this paper, five popular deep learning architectures are utilized to develop a system for diagnosing brain tumors. The architectures used is this paper are Xception, DenseNet201, DenseNet121, ResNet152V2, and InceptionResNetV2. The final layer of these architectures has been modified with our deep dense block and softmax layer as the output layer to improve the classification accuracy. This article presents two main experiments to assess the effectiveness of the proposed model. First, three-class results using images from patients with glioma, meningioma, and pituitary are discussed. Second, the results of four classes are discussed using images of glioma, meningioma, pituitary and healthy patients. The results show that the proposed model based on Xception architecture is the most suitable deep learning model for detecting brain tumors. It achieves a classification accuracy of 99.67% on the 3-class dataset and 95.87% on the 4-class dataset, which is better than the state-of-the-art methods. In conclusion, the proposed model can provide radiologists with an automated medical diagnostic system to make fast and accurate decisions.
C1 [Asif, Sohaib; Zhao, Ming; Tang, Fengxiao] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Zhu, Yusen] Hunan Univ, Sch Math, Changsha, Peoples R China.
C3 Central South University; Hunan University
RP Zhao, M; Tang, FX (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
EM meanzhao@csu.edu.cn; tangfengxiao@csu.edu.cn
RI Asif, Sohaib/JFB-3402-2023; Ming, Zhao/AAD-2155-2019
OI Asif, Sohaib/0000-0003-0526-3910; Ming, Zhao/0000-0003-2317-5359; Asif,
   Sohaib/0000-0003-0707-470X
FU Natural Science Foundation of Hunan Province, China [2020JJ4757]
FX This work was supported by the Natural Science Foundation of Hunan
   Province, China (Grant No. 2020JJ4757).
CR Aderghal K, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05652
   Alanazi MF, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010372
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   [Anonymous], 2014, PLYMOUTH STUD SCI
   Ansari MA, 2020, J INTERDISCIP MATH, V23, P955, DOI 10.1080/09720502.2020.1723921
   Avsar E, 2019, TEH GLAS, V13, P337, DOI 10.31803/tg-20190712095507
   Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999
   Bangare SL, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bhuvaji S., Brain Tumor Classification (MRI) Kaggle Dataset
   Chauhan S, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P223, DOI 10.1109/RISE.2017.8378158
   Cheng J, 2017, BRAIN TUMOR DATASET, DOI [10.6084/m9.figshare.2017;1512427:v5, DOI 10.6084/M9.FIGSHARE.2017;1512427:V5]
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115339
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Citak-Er F, 2018, COMPUT BIOL MED, V99, P154, DOI 10.1016/j.compbiomed.2018.06.009
   Cortes C., 2012, arXiv
   Deepa S. N., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P1032, DOI 10.1109/WICT.2011.6141390
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Devi TM, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Díaz-Pernas FJ, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020153
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hemanth DJ, 2019, IEEE ACCESS, V7, P4275, DOI 10.1109/ACCESS.2018.2885639
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ismael MR, 2018, INT CONF ELECTRO INF, P252, DOI 10.1109/EIT.2018.8500308
   Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779
   Kalaiselvi T., 2021, MACH LEARN BASED APP, V27, P69
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2020, IEEE ACCESS, V8, P197969, DOI 10.1109/ACCESS.2020.3034217
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   Kingma D. P., 2014, arXiv
   Kleesiek J, 2016, NEUROIMAGE, V129, P460, DOI 10.1016/j.neuroimage.2016.01.024
   Kokkalla S, 2021, SOFT COMPUT, V25, P8721, DOI 10.1007/s00500-021-05748-8
   Kumar PMS, 2016, 2016 IEEE ANN INDIA, P1, DOI [10.1109/INDICON.2016.7838875, DOI 10.1109/INDICON.2016.7838875]
   Latif G, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC ENGINEERING (ICEEE 2017), P333, DOI 10.1109/ICEEE2.2017.7935845
   Lavanyadevi R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ELECTRICAL, INSTRUMENTATION AND COMMUNICATION ENGINEERING (ICEICE)
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Maharjan S, 2020, J NEUROSCI METH, V330, DOI 10.1016/j.jneumeth.2019.108520
   Mathew AR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P75, DOI 10.1109/CSPC.2017.8305810
   Mehrotra R, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100003
   Minz A, 2017, IEEE INT ADV COMPUT, P701, DOI [10.1109/IACC.2017.0146, 10.1109/IACC.2017.137]
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Naseer A, 2021, INT J BIOMED IMAGING, V2021, DOI 10.1155/2021/5513500
   Pashaei A, 2020, J REAL-TIME IMAGE PR, V17, P1051, DOI 10.1007/s11554-019-00852-3
   Polat Ö, 2021, J SUPERCOMPUT, V77, P7236, DOI 10.1007/s11227-020-03572-9
   Polly FP, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P813, DOI 10.1109/ICOIN.2018.8343231
   Qiu YC, 2017, J X-RAY SCI TECHNOL, V25, P751, DOI 10.3233/XST-16226
   Rajan PG, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1368-4
   Rehman A, 2021, MICROSC RES TECHNIQ, V84, P133, DOI 10.1002/jemt.23597
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Ruba T., 2020, BIOMED PHARMACOL J, V13, P1227, DOI DOI 10.13005/bpj/1991
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Sarhan AM., 2020, J Biomed Sci Eng, V13, P102, DOI DOI 10.4236/JBISE.2020.136010
   Saxena P., 2021, INNOVATIONS COMPUTAT, P275, DOI DOI 10.1007/978-981-15-6067-5_30
   Seetha J., 2018, BIOMED PHARMACOL J, V11, P1457, DOI [DOI 10.13005/bpj/1511, 10.13005/bpj/1511]
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Sornam M, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P166, DOI 10.1109/ICACA.2016.7887944
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Taheri S, 2011, MAGN RESON MED, V65, P1036, DOI 10.1002/mrm.22686
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Ullah Z, 2020, MED HYPOTHESES, V143, DOI 10.1016/j.mehy.2020.109922
   Yu HW, 2017, ETHICS BEHAV, V27, P401, DOI 10.1080/10508422.2016.1169535
   Zhan TM, 2017, TECHNOL HEALTH CARE, V25, pS377, DOI 10.3233/THC-171341
   Zhou M, 2018, AM J NEURORADIOL, V39, P208, DOI 10.3174/ajnr.A5391
NR 74
TC 19
Z9 19
U1 14
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31709
EP 31736
DI 10.1007/s11042-023-14828-w
EA FEB 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940065100008
DA 2024-07-18
ER

PT J
AU Sowmyayani, S
   Rani, PAJ
AF Sowmyayani, S.
   Rani, P. Arockia Jansi
TI Content based video retrieval system using two stream convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object; Shot boundary; Keyframes; Correlation; Convolutional
   neural network
ID EFFICIENT APPROACH
AB Nowadays capturing video through mobile phones, digital cameras and uploading it in social media is a trend. These videos do not have semantic tags. Searching these kinds of videos is difficult to web users. Content Based Video Retrieval (CBVR) helps to identify the most relevant videos for a given video query. The objective of the paper is retrieve most relevant videos for a given query video in reduced time. To meet the objective, this paper proposes an efficient video retrieval system using salient object detection and keyframe extraction methods to reduce the high dimensionality of video data. The spatio-temporal features are extracted using two-stream Convolutional Neural Network (CNN) and stored in a feature dataset. The salient objects are used to search the exact subject that is given as query. The relevant videos are identified through similarity matching of feature dataset that are created using the input dataset with the feature of query video. To reduce the complexity of similarity matching, the proposed method replaces feature dataset with classification score dataset. Experiments are conducted on TRECVID and CC_Web_Video datasets and evaluated using precision, recall, specificity, accuracy and f-score. The proposed method is compared with recent methods and proved its efficiency with approximately 99.68% precision rate on TRECVID dataset and 88.9% precision rate on CC_Web_Video dataset. The proposed outperforms most recent methods by 0.001 increase in mean Average Precision (mAP) on CC_Web_Video dataset and 4% increase in precision rate on TRECVID dataset. The computation time is reduced by 100 min on TRECVID and 200 min on CC_Web_Video datasets.
C1 [Sowmyayani, S.] St Marys Coll Autonomous, Dept Comp Sci SF, Thoothukudi, Tamilnadu, India.
   [Rani, P. Arockia Jansi] Manonmaniam Sundaranar Univ, Dept Comp Sci & Engn, Tirunelveli, Tamilnadu, India.
C3 Manonmaniam Sundaranar University
RP Sowmyayani, S (corresponding author), St Marys Coll Autonomous, Dept Comp Sci SF, Thoothukudi, Tamilnadu, India.
EM sowmyayani@gmail.com; jansi_msu@yahoo.co.in
RI s, Sowmyayani/AAM-5159-2021
CR Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   AlZu'bi S, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P172, DOI 10.1109/SNAMS.2018.8554487
   Asha S, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC 2013), P212, DOI 10.1109/ICACC.2013.49
   Bian X, 2021, ACTA BIOMATER, V2021
   Charrière K, 2017, MULTIMED TOOLS APPL, V76, P22473, DOI 10.1007/s11042-017-4793-8
   Charrière K, 2014, IEEE ENG MED BIO, P4647, DOI 10.1109/EMBC.2014.6944660
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cheng H.K., 2021, ARXIV
   Chittajallu DR, 2019, PROC SPIE, V10951, DOI 10.1117/12.2509985
   Ding ST, 2019, FUTURE GENER COMP SY, V93, P583, DOI 10.1016/j.future.2018.10.054
   Diwakar Manoj, 2020, International Journal of Information and Computer Security, V12, P234
   Diwakar Manoj, 2019, Soft Computing: Theories and Applications. Proceedings of SoCTA 2017. Advances in Intelligent Systems and Computing (AISC 742), P343, DOI 10.1007/978-981-13-0589-4_32
   Diwakar M, 2019, HDB MULTIMEDIA INFOR, P501, DOI DOI 10.1007/978-3-030-15887-3_24
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Diwakar M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P297, DOI 10.1145/2791405.2791430
   Diwakar M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P160, DOI 10.1109/ICIIP.2013.6707574
   Hawashin B, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P220, DOI 10.1109/SDS49854.2020.9143953
   Jiang B, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102104
   Khan MN, 2020, INT CONF BIG DATA, P36, DOI 10.1109/BigComp48618.2020.0-102
   Kordopatis-Zilos G, 2019, IEEE I CONF COMP VIS, P6360, DOI 10.1109/ICCV.2019.00645
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar GSN, 2019, INT J KNOWL-BASED IN, V23, P311, DOI 10.3233/KES-190420
   Kumar P., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P816, DOI 10.1109/WICT.2011.6141352
   Kumar V., 2019, INT J INNOV TECHNOL, V9, P2402
   Lafi M, 2021, CMES-COMP MODEL ENG, V127, P99, DOI 10.32604/cmes.2021.013026
   Mohamadzadeh S, 2016, IMAGE ANAL STEREOL, V35, P67, DOI 10.5566/ias.1346
   Mühling M, 2016, LECT NOTES COMPUT SC, V9819, P67, DOI 10.1007/978-3-319-43997-6_6
   Naveen Kumar G. S., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 898), P751, DOI 10.1007/978-981-13-3393-4_76
   Pereira RB, 2018, ARTIF INTELL REV, V49, P57, DOI 10.1007/s10462-016-9516-4
   Prathiba T, 2021, J AMB INTEL HUM COMP, V12, P6215, DOI 10.1007/s12652-020-02190-w
   Ram RS, 2020, MULTIMED TOOLS APPL, V79, P10199, DOI 10.1007/s11042-019-07805-9
   Ramezani M, 2018, MULTIMED TOOLS APPL, V77, P26009, DOI 10.1007/s11042-018-5835-6
   Rehman SU, 2018, IEEE ACCESS, V6, P67176, DOI 10.1109/ACCESS.2018.2878868
   Shao J, 2020, ARXIV
   Shao J, 2021, IEEE WINT CONF APPL, P3267, DOI 10.1109/WACV48630.2021.00331
   Sharma P, 2013, C ADV COMMUNICATION, P363
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Sowmyayani S., 2014, ICTACT Journal on Image and Video Processing, V5, P868
   Spolaôr N, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103557
   Tao JL, 2019, LECT NOTES COMPUT SC, V11296, P352, DOI 10.1007/978-3-030-05716-9_29
   TRECVID, TREC VID RETR EV
   Ullah A, 2020, IEEE ACCESS, V8, P196529, DOI 10.1109/ACCESS.2020.3029834
   Veltkamp RC., 2013, STATE ART CONTENT BA
   Wu X, 2009, IEEE T MULTIMEDIA, V11, P196, DOI 10.1109/TMM.2008.2009673
   Yu SI, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P419, DOI 10.1145/2671188.2749398
   Yumeng Liu, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P718, DOI 10.1109/ICIS.2018.8466379
   Zhang CY, 2019, PATTERN RECOGN LETT, V123, P82, DOI 10.1016/j.patrec.2019.03.015
   Zhang HW, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P781, DOI 10.1145/2964284.2964308
   Zhang JM, 2016, PROC CVPR IEEE, P5733, DOI 10.1109/CVPR.2016.618
   Zhao GP, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102488
   Zhu YY, 2016, NEUROCOMPUTING, V187, P83, DOI 10.1016/j.neucom.2015.09.114
NR 55
TC 2
Z9 2
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24465
EP 24483
DI 10.1007/s11042-023-14784-5
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000940065100012
DA 2024-07-18
ER

PT J
AU Jain, R
   Kumar, A
   Nayyar, A
   Dewan, K
   Garg, R
   Raman, S
   Ganguly, S
AF Jain, Rachna
   Kumar, Ashish
   Nayyar, Anand
   Dewan, Kritika
   Garg, Rishika
   Raman, Shatakshi
   Ganguly, Sahil
TI Explaining sentiment analysis results on social media texts through
   visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interpretability; VADER; LIME; Explainability; Visualization
ID ARTIFICIAL-INTELLIGENCE; BLACK-BOX; MACHINE; AI
AB Today, Artificial Intelligence is achieving prodigious real-time performance, thanks to growing computational data and power capacities. However, there is little knowledge about what system results convey; thus, they are at risk of being susceptible to bias, and with the roots of Artificial Intelligence ("AI") in almost every territory, even a minuscule bias can result in excessive damage. Efforts towards making AI interpretable have been made to address fairness, accountability, and transparency concerns. This paper proposes two unique methods to understand the system's decisions aided by visualizing the results. For this study, interpretability has been implemented on Natural Language Processing-based sentiment analysis using data from various social media sites like Twitter, Facebook, and Reddit. With Valence Aware Dictionary for Sentiment Reasoning ("VADER"), heatmaps are generated, which account for visual justification of the result, increasing comprehensibility. Furthermore, Locally Interpretable Model-Agnostic Explanations ("LIME") have been used to provide in-depth insight into the predictions. It has been found experimentally that the proposed system can surpass several contemporary systems designed to attempt interpretability.
C1 [Jain, Rachna] Bhagwan Parshuram Inst Technol, New Delhi 110089, India.
   [Jain, Rachna] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, Uttar Pradesh, India.
   [Kumar, Ashish; Dewan, Kritika; Garg, Rishika; Raman, Shatakshi; Ganguly, Sahil] Bharati Vidyapeeths Coll Engn, New Delhi 110063, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
C3 Bhagwan Parshuram Institute of Technology; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM rachnajain@bpitindia.com; Ashish.gupta14d@gmail.com;
   anandnayyar@duytan.edu.vn; kritika.dewan11@gmail.com;
   rishikagarg.csn@gmail.com; raman.shat1612@gmail.com;
   sahilshubhamganguly@gmail.com
RI Nayyar, Anand/F-3732-2015
OI Nayyar, Anand/0000-0002-9821-6146; Kumar, Ashish/0000-0003-3466-8845
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Al Shahhi E., 2018, 2018 2nd URSI Atlantic Radio Science Meeting (AT-RASC), DOI 10.23919/URSI-AT-RASC.2018.8471340
   Arendt M, 2018, FACEBOOK COMMENTS SE
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Behl S, 2021, INT J DISAST RISK RE, V55, DOI 10.1016/j.ijdrr.2021.102101
   Bhaumik Ujjayanta, 2021, Computational Intelligence and Machine Learning. Proceedings of the 7th International Conference on Advanced Computing, Networking, and Informatics (ICACNI 2019). Advances in Intelligent Systems and Computing (AISC 1276), P59, DOI 10.1007/978-981-15-8610-1_7
   Biecek P., 2021, Explanatory model analysis: explore, explain, and examine predictive models, DOI DOI 10.1201/9780429027192
   Bologna G., 2018, Big Data And Cognitive Computing, V2, P6, DOI [10.3390/bdcc2010006, DOI 10.3390/BDCC2010006]
   Borg A, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113746
   Budhi GS, 2021, ARCH COMPUT METHOD E, V28, P2543, DOI 10.1007/s11831-020-09464-8
   Burkart N, 2021, J ARTIF INTELL RES, V70, P245
   Carvalho DV, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080832
   Castelvecchi D, 2016, NATURE, V537, P20, DOI 10.1038/538020a
   Çeliktug MF, 2018, IEEE INT CONF BIG DA, P2098, DOI 10.1109/BigData.2018.8621970
   Chae B, 2015, INT J PROD ECON, V165, P247, DOI 10.1016/j.ijpe.2014.12.037
   Chaehan So, 2020, Artificial Intelligence in HCI. First International Conference, AI-HCI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12217), P412, DOI 10.1007/978-3-030-50334-5_28
   Chen HJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4236
   Cilgin Cihan, 2022, AJIT E ONLINE ACAD J, V13, P90
   Cirqueira D, 2020, EXPLAINABLE SENTIMEN
   Cortis K., 2017, P 11 INT WORKSHOP SE, P519
   Dass P, 2016, COMPUTERS THEIR APPL
   Demsar J, 2004, LECT NOTES ARTIF INT, V3202, P537
   Doshi-Velez F., 2017, arXiv
   Fails J. A., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P39, DOI 10.1145/604045.604056
   Fan Feng-Lei, 2021, IEEE Trans Radiat Plasma Med Sci, V5, P741, DOI [10.1109/trpms.2021.3066428, 10.1109/TRPMS.2021.3066428]
   Ferreira P, 2020, LECT NOTES BUS INF P, V377, P202, DOI 10.1007/978-3-030-38724-2_15
   Gilpin LH, 2018, PR INT CONF DATA SC, P80, DOI 10.1109/DSAA.2018.00018
   Go A, 2008, SENTIMENT140
   Graham J, 1997, J AHIMA, V68, P41
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Hoffman R.R., 2018, arXiv
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Kaur H, 2022, PROD PLAN CONTROL, V33, P576, DOI 10.1080/09537287.2020.1834124
   Kumar A, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113711
   Liao QH, 2021, COMPOS INTERFACE, V28, P637, DOI [10.1145/3334480.3375044, 10.1080/09276440.2020.1798681]
   Lipton ZC., 2018, QUEUE, V16, P31, DOI 10.1145/3236386.3241340
   Liu H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5570
   London AJ, 2019, HASTINGS CENT REP, V49, P15, DOI 10.1002/hast.973
   Lundberg SM, 2017, ADV NEUR IN, V30
   Luo L, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4244
   Manaman HS, 2016, COMPUT HUM BEHAV, V54, P94, DOI 10.1016/j.chb.2015.07.061
   Mohseni S, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387166
   Monner D, 2012, NEURAL NETWORKS, V25, P70, DOI 10.1016/j.neunet.2011.07.003
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Mozes M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P171
   Newman H, 2018, LECT NOTES ARTIF INT, V10948, P246, DOI 10.1007/978-3-319-93846-2_45
   Ngaffo AN, 2019, INT WIREL COMMUN, P680
   Pedreschi Dino, 2018, ARXIV
   Razavi S, 2021, ENVIRON MODELL SOFTW, V144, DOI 10.1016/j.envsoft.2021.105159
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Ribeiro MT, 2016, MODEL AGNOSTIC EXPLA
   Stieglitz S, 2013, SOC NETW ANAL MIN, V3, P1277, DOI 10.1007/s13278-012-0079-3
   Talpau A., 2014, Bulletin of the Transilvania University of Brasov. Series V: Economic Sciences, V7, P45
   Thomas DM, 2022, NUTR DIABETES, V12, DOI 10.1038/s41387-022-00226-y
   Tjoa E, 2021, IEEE T NEUR NET LEAR, V32, P4793, DOI 10.1109/TNNLS.2020.3027314
   Tymann K., 2019, LWDA, P178
   Venkataramaiah M. K. A., 2020, Int. J. Intell. Eng. Syst, V13, P97, DOI [10.22266/ijies2020.1031.10, DOI 10.22266/IJIES2020.1031.10]
   Yadav RK, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P402, DOI 10.5220/0010382104020409
   Zhang Y, 2021, IEEE T EM TOP COMP I, V5, P726, DOI 10.1109/TETCI.2021.3100641
   Zhu J., 2018, 2018 IEEE C COMP INT, P1, DOI DOI 10.1109/CIG.2018.8490433
   Zhu YQ, 2015, BUS HORIZONS, V58, P335, DOI 10.1016/j.bushor.2015.01.006
NR 61
TC 14
Z9 14
U1 12
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22613
EP 22629
DI 10.1007/s11042-023-14432-y
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000924482400003
PM 36747895
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wu, ZX
   Zhu, JQ
AF Wu, Zhixiong
   Zhu, Jianqing
TI Multi-receptive field attention for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention; Deep learning; Intelligent video surveillance;
   Multi-receptive field; Person re-identification
ID NETWORK
AB Person re-identification is a challenging yet meaningful task to match two pedestrian images captured from non-overlapping cameras for public security. Attention schemes have been widely applied to deep learning based person re-identification because they help deep networks dynamically focus on salient regions on person images containing large scale variations and unconstrained auto-detection errors. However, previous attention approaches typically are of a single receptive field, which are difficult to capture rich structural affinities from different scales, harming salient region inferring effect. In this paper, we propose a multi-receptive field attention (MRFA) for person re-identification. MRFA captures multi-scale structural affinities among spatial positions in feature maps via weighted summing over correlations among positions represented with convolutional features of different receptive fields. The multi-scale structural affinities are further applied to infer the importance of different spatial locations. The MRFA is embedded into popular deep architectures (e.g., ResNet and Res2Net) to enhance the feature learning effect for person re-identification. The main contribution of this paper is to extend single receptive field attention to multi-receptive field attention to improve person re-identification effectively. Experiments on three public datasets, i.e., Market-1501, DukeMTMC-reID, and MSMT17, demonstrate that our method is superior to state-of-the-art person re-identification approaches, e.g., on the largest MSMT17 dataset, our method's rank-1 identification rate is 83.9%.
C1 [Wu, Zhixiong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Zhu, Jianqing] Huaqiao Univ, Coll Engn, 269 Chenghua North Rd, Quanzhou, Peoples R China.
C3 Tsinghua University; Huaqiao University
RP Zhu, JQ (corresponding author), Huaqiao Univ, Coll Engn, 269 Chenghua North Rd, Quanzhou, Peoples R China.
EM jqzhu@hqu.edu.cn
FU National Natural Science Foundation of China [61976098]; Natural Science
   Foundation for Outstanding Young Scholars of Fujian Province
   [2022J06023]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China under the Grant 61976098, in part by the
   Natural Science Foundation for Outstanding Young Scholars of Fujian
   Province under the Grant 2022J06023.
CR Alharthi AS, 2019, IEEE SENS J, V19, P9575, DOI 10.1109/JSEN.2019.2928777
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Hatirnaz E, 2020, MULTIMED TOOLS APPL, V79, P17579, DOI 10.1007/s11042-020-08659-2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Lingxiao, 2020, ARXIV200602631, V6, P8
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu B, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-019-2943-6
   Huang YW, 2021, IEEE T CIRC SYST VID, V31, P1790, DOI 10.1109/TCSVT.2020.3014167
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lian SC, 2021, IEEE T CIRC SYST VID, V31, P3140, DOI 10.1109/TCSVT.2020.3037179
   Liu HM, 2021, NEUROCOMPUTING, V423, P57, DOI 10.1016/j.neucom.2020.10.019
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Luo H, 2019, STRONG BASELINE BATC, P2597, DOI [10.1109/tmm.2019.2958756, DOI 10.1109/TMM.2019.2958756]
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Paszke A, 2019, ADV NEUR IN, V32
   Qian XL, 2020, IEEE T PATTERN ANAL, V42, P371, DOI 10.1109/TPAMI.2019.2928294
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang X, 2019, PROC CVPR IEEE, P5017, DOI 10.1109/CVPR.2019.00516
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
   Zhou SP, 2019, IEEE I CONF COMP VIS, P8039, DOI 10.1109/ICCV.2019.00813
   Zhou SP, 2019, IEEE T IMAGE PROCESS, V28, P4671, DOI 10.1109/TIP.2019.2908065
   Zhu JQ, 2018, IEEE T CIRC SYST VID, V28, P3183, DOI 10.1109/TCSVT.2017.2734740
NR 45
TC 2
Z9 2
U1 6
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20621
EP 20639
DI 10.1007/s11042-022-14321-w
EA JAN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000949190900003
DA 2024-07-18
ER

PT J
AU Adeniyi, AE
   Abiodun, KM
   Awotunde, JB
   Olagunju, M
   Ojo, OS
   Edet, NP
AF Adeniyi, A. E.
   Abiodun, K. M.
   Awotunde, J. B.
   Olagunju, M.
   Ojo, O. S.
   Edet, N. P.
TI Implementation of a block cipher algorithm for medical information
   security on cloud environment: using modified advanced encryption
   standard approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption algorithm; AES; Medical information; Cloud; Security
ID CHALLENGES
AB The need of keeping medical information safe and secure stems from the fact that doctors rely on it to make accurate diagnoses. If this information is altered in any way, no matter how minor, there is a risk of an inaccurate diagnosis, which could result in severe medical issues and death. The transition from paper to electronic health records (EHRs) has considerably improved patient care quality and efficiency. However, for many healthcare service providers, it has extended the attack surface. Because of the value of a patient's medical information, this has posed a threat to both patients and healthcare providers. When security is not taken into account in healthcare systems, patients' privacy is jeopardized. The intended solution to this challenge is to create a modified AES algorithm to secure patient medical information. Although, the AES algorithm is secure, however, there is always a need for improvement on any cryptographic algorithms in terms of computational cost. This study implements AES and modified the last round of the AES and their performance has been measured by scrambling input datasets of various contents and volumes. The experimental results show that modified AES outperforms AES algorithms in terms of Encryption time while AES outperform modified AES in terms of decryption time. Also, the Avalanche effect results revealed that modified AES has a higher avalanche effect for small-size files while a smaller avalanche effect for larger file sizes. This signifies that modified AES security is stronger for a small size file while conventional AES has higher security for larger file sizes. The average encryption time of the AES algorithm for text files is 1513.3ms while the modified AES average encryption time gives 1293.837ms. The average decryption time for conventional AES is 1289.627ms while the average decryption time for modified AES give 1400.136ms. Modified AES uses lesser time complexity during the encryption of all categories of data files while conventional AES uses lesser time complexity during the decryption of all categories of data files.
C1 [Adeniyi, A. E.] Precious Cornerstone Univ, Dept Comp Sci, Ibadan, Oyo State, Nigeria.
   [Abiodun, K. M.; Edet, N. P.] Landmark Univ, SDG 4 Qual Educ Grp, Omu Aran, Nigeria.
   [Abiodun, K. M.; Edet, N. P.] Landmark Univ, SDG 9 Ind Innovat & Infrastruct Res Grp, Omu Aran, Nigeria.
   [Abiodun, K. M.; Edet, N. P.] Landmark Univ, Dept Comp Sci, Omu Aran, Kwara State, Nigeria.
   [Awotunde, J. B.] Univ Ilorin, Dept Comp Sci, Ilorin, Kwara State, Nigeria.
   [Olagunju, M.] Fed Univ Oye Ekiti, Dept Comp Sci, Oye, Ekiti State, Nigeria.
   [Ojo, O. S.] Ajayi Crowther Univ, Dept Comp Sci, Oyo, Nigeria.
C3 Landmark University; Landmark University; Landmark University;
   University of Ilorin
RP Adeniyi, AE (corresponding author), Precious Cornerstone Univ, Dept Comp Sci, Ibadan, Oyo State, Nigeria.
EM adeniyi.emmanuel@lmu.edu.ng
RI Adeniyi, Abidemi Emmanuel/AAT-7427-2021; AWOTUNDE, Joseph
   Bamidele/AAC-7971-2021
OI Adeniyi, Abidemi Emmanuel/0000-0002-2728-0116; AWOTUNDE, Joseph
   Bamidele/0000-0002-1020-4432
CR Adeniyi AE, 2022, ALGORITHMS, V15, DOI 10.3390/a15100373
   Adeniyi EA, 2022, INFORMATION, V13, DOI 10.3390/info13100442
   Akande NO, 2019, LECT NOTES COMPUT SC, V11623, P166, DOI 10.1007/978-3-030-24308-1_14
   Al-Zubaidie M, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3263902
   Algarni A, 2019, IEEE ACCESS
   Alzakholi O., 2020, J Appl Sci Technol Trends, V1, P40, DOI [DOI 10.38094/JASTT1219, 10.38094/jastt1219]
   Anshari Muhammad, 2019, International Journal on Informatics for Development, V8, P35, DOI DOI 10.14421/IJID.2019.08106
   Bessani A, 2013, ACM T STORAGE, V9, DOI 10.1145/2535929
   Braun T, 2018, SUSTAIN CITIES SOC, V39, P499, DOI 10.1016/j.scs.2018.02.039
   Cobb MD, 2020, EMERGING TECHNOLOGIE, P197
   Devi A., 2017, INT RES J ENG TECHNO, V4, P3033
   Emmanuel AA, 2021, INT J ADV COMPUT SC, V12
   Ilayaraja M., 2017, INT J PURE APPL MATH, V116, P301
   James M, 2016, PROC TECH, V25, P582, DOI 10.1016/j.protcy.2016.08.148
   Joel, 2020, INT J EMERG TRENDS E, V8, DOI 10.30534
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Le D. -N., 2018, J. Cyber Secur. Mobil, V7, P379, DOI DOI 10.13052/JCSM2245-1439.742
   Li H, 2005, IEEE INT SYMP CIRC S, P4637
   McGhin T, 2019, J NETW COMPUT APPL, V135, P62, DOI 10.1016/j.jnca.2019.02.027
   Mousavi SK, 2021, WIREL NETW, V27, P1515, DOI 10.1007/s11276-020-02535-5
   Pimpale P, 2011, INT J COMPUT SCI NET, V11, P183
   Purnama B, 2015, PROCEDIA COMPUT SCI, V59, P195, DOI 10.1016/j.procs.2015.07.552
   Quilala TFG., 2021, B ELECT ENG, V10, P2192
   Rothman Lily., 2017, Time
   Samonas S, 2014, J INFORM SYST SECUR, V10
   Schmidt M, 2019, CLIN EPIDEMIOL, V11, P563, DOI 10.2147/CLEP.S179083
   Smirnoff, 2019, SYMMETRIC KEY ENCRYP
   Taha MS, 2019, IOP CONF SER-MAT SCI, V518, DOI 10.1088/1757-899X/518/5/052003
   Usman Muhammad, 2020, Procedia Computer Science, V174, P321, DOI 10.1016/j.procs.2020.06.093
NR 29
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20537
EP 20551
DI 10.1007/s11042-023-14338-9
EA JAN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000926801100006
DA 2024-07-18
ER

PT J
AU Shirke, A
   Chandane, MM
AF Shirke, Archana
   Chandane, M. M.
TI Collaborative offloading decision policy framework in IoT using edge
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computation offloading; Distributed architecture; Internet of thing;
   Edge computing; Resource management
AB Internet of Things (IoT) gives rise to concerns regarding edge computing policies for intelligent data processing to optimize resources at edge devices. The resources like energy, computation power, available memory, execution time need saving on for constraint-based IoT devices. These resources optimize to proper utilization of Edge devices, which increases the lifetime. A resource optimization decision is the basis of offloading some tasks from edge devices to the next level gateway/ server devices. This decision of full, partial, or no offloading depends on the different parameters under consideration. The study proposes a computation Offloading Decision Policy (ODP) framework to save battery lifetime, execution time, and memory utilization of IoT devices. This ODP framework estimates the execution time, energy consumption, and memory required for locally executing the task to be completed as well as when offloaded. The comparison between the loss function of locally and the remotely executed task performed. The proposed policy is compared with the traditional framework with no offloading at all and always full uploading. The results show improvement over traditional and other offloading frameworks. This technique applies to existing applications such as Smart Home, Industrial IoT, Intelligent traffic, Video Analytics, and Smart Healthcare delivers the power of AI. The ODP framework makes predictions for both the locally executed and offloaded versions of a task's execution time, energy use, and memory requirements. The outcomes demonstrate advancements above conventional and alternative offloading systems.
C1 [Shirke, Archana; Chandane, M. M.] VJTI, Mumbai, India.
C3 Veermata Jijabai Technological Institute (VJTI)
RP Shirke, A (corresponding author), VJTI, Mumbai, India.
EM archanashirke25@gmail.com; mmchandane@it.vjti.ac.in
RI CHANDANE, Dr. MADHAV/KCY-1070-2024
CR Akherfi Khadija, 2018, Applied Computing and Informatics, V14, P1, DOI 10.1016/j.aci.2016.11.002
   Ali FA, 2016, J SYST SOFTWARE, V113, P173, DOI 10.1016/j.jss.2015.11.042
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   De Vito S, 2008, SENSOR ACTUAT B-CHEM, V129, P750, DOI 10.1016/j.snb.2007.09.060
   Guo HZ, 2019, IEEE INTERNET THINGS, V6, P4317, DOI 10.1109/JIOT.2018.2875535
   He C, 2020, IEEE ACCESS, V8, P24662, DOI 10.1109/ACCESS.2020.2969214
   Huang L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061446
   Jamal J, 2021, SENS BIO-SENS RES, V34, DOI 10.1016/j.sbsr.2021.100450
   Jiang CF, 2019, IEEE ACCESS, V7, P131543, DOI 10.1109/ACCESS.2019.2938660
   Jin XM, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/8049804
   Kumar K, 2013, MOBILE NETW APPL, V18, P129, DOI 10.1007/s11036-012-0368-0
   Liu LQ, 2018, IEEE INTERNET THINGS, V5, P283, DOI 10.1109/JIOT.2017.2780236
   Markkanen A., 2015, IOT ANAL TODAY 2020
   Samie F, 2019, ACM T INTERNET TECHN, V19, DOI 10.1145/3230642
   Samie F, 2018, ACM TRANS CYBER-PHYS, V2, DOI 10.1145/3134842
   Samie F, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P7, DOI 10.1109/WF-IoT.2016.7845499
   Samie F, 2016, 2016 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2968456.2974005
   Shan NL, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4124791
   Sheng JF, 2019, INFORMATION, V10, DOI 10.3390/info10060191
   Sheng ZG, 2018, IEEE T CLOUD COMPUT, V6, P114, DOI 10.1109/TCC.2015.2458272
   Son Y, 2017, MOB INF SYST
   Sonmez C, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3493
   Sufyan F, 2020, IEEE ACCESS, V8, P149915, DOI 10.1109/ACCESS.2020.3016046
   Tao XY, 2017, IEEE WIREL COMMUN LE, V6, P774, DOI 10.1109/LWC.2017.2740927
   Varghese B, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P20, DOI 10.1109/SmartCloud.2016.18
   Zhu QL, 2017, CHINA COMMUN, V14, P59, DOI 10.1109/CC.2017.8233651
NR 27
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 13
PY 2023
DI 10.1007/s11042-023-14383-4
EA JAN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8P8XM
UT WOS:000926801100004
DA 2024-07-18
ER

PT J
AU Falahat, S
   Karami, A
AF Falahat, Shahrzad
   Karami, Azam
TI Maize tassel detection and counting using a YOLOv5-based model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Maize tassels; Plant detection; UAV; YOLOv5
ID VISION
AB Automated detection and counting of maize tassels are important to enhance yield efficiency. This paper introduces a maize tassel detection and counting technique based on the modified YOLOv5n network. The modifications include using the GELU activation function instead of SiLU, applying attention block to the last C3 structure of the backbone, utilizing depth-wise convolution in the neck part, and employing a spatial-dropout layer in the head part. They make the model learn more complex features, detect tassels better, control overfitting, and reduce inference time. This model is trained and evaluated by Maize Tassel Detection and Counting (MTDC) dataset, and a 6.67% improvement in average precision (AP) as a result of modifications is observed. To investigate the performance of the model in terms of accuracy and inference time, the results of the proposed model are compared with the ones obtained by Faster R-CNN, SSD, RetinaNet, and TasselNetv2+ algorithms. These methods achieve 88.25%, 68.31%, 75.32%, and 78.68% of R-2. Also, 52.94%, 68.46%, and 70.99% of AP are obtained by Faster R-CNN, SSD, and RetinaNet algorithms, respectively. These values are reported as 95.72% and 86.69% for the modified YOLOv5n model. The results verify the advantage of the modified YOLOv5n model in detecting and counting the highest number of maize tassels in the least time.
C1 [Falahat, Shahrzad; Karami, Azam] Shahid Bahonar Univ Kerman, Fac Phys, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Falahat, S (corresponding author), Shahid Bahonar Univ Kerman, Fac Phys, Kerman, Iran.
EM falahatshahrzad@gmail.com
CR Aich S, 2017, IEEE INT CONF COMP V, P2080, DOI 10.1109/ICCVW.2017.244
   Bekele B, 2020, DEV TRAFFIC CONGESTI
   Bisong E., 2019, Building Machine Learning and Deep Learning Models on Google Cloud Platform
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Choinski M, 2021, ARXIV
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Cordonnier J.-B., 2020, ARXIV
   Dillon J. V., 2017, TensorFlow distributions
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Elfwing S, 2018, NEURAL NETWORKS, V107, P3, DOI 10.1016/j.neunet.2017.12.012
   Ghosal S, 2019, PLANT PHENOMICS, V2019, DOI 10.34133/2019/1525874
   Gómez-Flores W, 2019, COMPUT ELECTRON AGR, V162, P825, DOI 10.1016/j.compag.2019.05.032
   Guo YH, 2019, AAAI CONF ARTIF INTE, P8368
   Hasan MM, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0366-8
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hendrycks D., 2016, ARXIV
   Jeong DJ, 2020, IEEE INT CONF BIG DA, P5559, DOI 10.1109/BigData50022.2020.9377847
   Ji MQ, 2021, INFORM PROCESS AGR, V8, P87, DOI 10.1016/j.inpa.2020.03.002
   Jocher G., 2020, YOLOv5
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Ketkar N, 2017, DEEP LEARNING PYTHON, P195, DOI [10.1007/978-1-4842-2766-4_12, DOI 10.1007/978-1-4842-2766-4_12]
   Kingma D. P., 2014, arXiv
   Kumar A, 2019, COMPUT VIS PROBLEMS, V3
   Kumar J. P., 2019, Information Processing in Agriculture, V6, P233, DOI 10.1016/j.inpa.2018.09.005
   Kurtulmus F, 2014, EXPERT SYST APPL, V41, P7390, DOI 10.1016/j.eswa.2014.06.013
   Kuznetsova Anna, 2020, Advances in Neural Networks - ISNN 2020. 17th International Symposium on Neural Networks, ISNN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12557), P233, DOI 10.1007/978-3-030-64221-1_20
   Li QY, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0231-1
   Li SW, 2021, CONSTR BUILD MATER, V273, DOI 10.1016/j.conbuildmat.2020.121949
   Li Y., 2020, ARXIV
   Li Y, 2013, MIPPR 2013 REMOTE SE
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu XY, 2016, COMPUT ELECTRON AGR, V122, P118, DOI 10.1016/j.compag.2016.01.023
   Liu YL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020338
   Long X., 2020, ARXIV
   Lu H, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.541960
   Lu H, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0224-0
   Parihar C, 2011, Maize Production Technologies in India
   Pourreza A, 2015, BIOSYST ENG, V130, P13, DOI 10.1016/j.biosystemseng.2014.11.013
   Quan LZ, 2019, BIOSYST ENG, V184, P1, DOI 10.1016/j.biosystemseng.2019.05.002
   Rahnemoonfar M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040905
   Ramchoun H, 2016, INT J INTERACT MULTI, V4, P26, DOI 10.9781/ijimai.2016.415
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Rothe R, 2015, LECT NOTES COMPUT SC, V9003, P290, DOI 10.1007/978-3-319-16865-4_19
   Sharma V, 2020, FACE MASK DETECTION
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tagne A, 2008, ENDURE INT C 2008 DI, P12
   Tardieu F, 2017, CURR BIOL, V27, pR770, DOI 10.1016/j.cub.2017.05.055
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Torres-Sospedra J, 2014, 2 STAGE PROCEDURE BA
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Ubbens J, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0273-z
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang L., 2021, GEOMETRY VISION 1 IN, P26, DOI [10.1007/978-3-030-72073-5_3, DOI 10.1007/978-3-030-72073-5_3]
   Xiong HP, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0537-2
   Xu RH, 2021, FRONT PSYCHIATRY, V12, DOI [10.3390/f12020217, 10.3389/fpsyt.2021.657224]
   Yao Xue, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P274, DOI 10.1007/978-3-319-46604-0_20
   Yap MH, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104596
   Ye MN, 2013, PROC SPIE, V8921, DOI 10.1117/12.2031024
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhao JQ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163095
   Zhou K, 2016, DESTECH TRANS COMP
   Zou HW, 2020, PLANT METHODS, V16, DOI 10.1186/s13007-020-00651-z
NR 68
TC 9
Z9 9
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19521
EP 19538
DI 10.1007/s11042-022-14309-6
EA DEC 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000903319100001
DA 2024-07-18
ER

PT J
AU de Sousa, PM
   Carneiro, PC
   Pereira, GM
   Oliveira, MM
   da Costa, CA
   de Moura, LV
   Mattjie, C
   da Silva, AMM
   Macedo, TAA
   Patrocinio, AC
AF de Sousa, Pedro Moises
   Carneiro, Pedro Cunha
   Pereira, Gabrielle Macedo
   Oliveira, Mariane Modesto
   da Costa Junior, Carlos Alberto
   de Moura, Luis Vinicius
   Mattjie, Christian
   da Silva, Ana Maria Marques
   Macedo, Tulio Augusto Alves
   Patrocinio, Ana Claudia
TI A new model for classification of medical CT images using CNN: a
   COVID-19 case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chest CT images; Convolutional neural networks; COVID-19; Wavelet; WCNN
AB SARS-CoV-2 is the causative agent of COVID-19 and leaves characteristic impressions on chest Computed Tomography (CT) images in infected patients and this analysis is performed by radiologists through visual reading of lung images, and failures may occur. In this article, we propose a classification model, called Wavelet Convolutional Neural Network (WCNN) that aims to improve the differentiation of images of patients with COVID-19 from images of patients with other lung infections. The WCNN model was based on a Convolutional Neural Network (CNN) and wavelet transform. The model proposes a new input layer added to the neural network, which was called Wave layer. The hyperparameters values were defined by ablation tests. WCNN was applied to chest CT images to images from two internal and one external repositories. For all repositories, the average results of Accuracy (ACC), Sensitivity (Sen) and Specificity (Sp) were calculated. Subsequently, the average results of the repositories were consolidated, and the final values were ACC = 0.9819, Sen = 0.9783 and Sp = 0.98. The WCNN model uses a new Wave input layer, which standardizes the network input, without using data augmentation, resizing and segmentation techniques, maintaining the integrity of the tomographic image analysis. Thus, applications developed based on WCNN have the potential to assist radiologists with a second opinion in the analysis.1
C1 [de Sousa, Pedro Moises; Carneiro, Pedro Cunha; Pereira, Gabrielle Macedo; Oliveira, Mariane Modesto; da Costa Junior, Carlos Alberto; Patrocinio, Ana Claudia] Univ Fed Uberlandia, Fac Elect Engn, Biomed Lab, Campus Sta Monica,Ave Joao Naves de Avila 2121,Blo, BR-38400000 Uberlandia, MG, Brazil.
   [de Moura, Luis Vinicius; Mattjie, Christian; da Silva, Ana Maria Marques] Pontif Catholic Univ Rio Grande Do Sul, Med Image Comp Lab, Ave Ipiranga,6681 Partenon, BR-90619900 Porto Alegre, RS, Brazil.
   [Macedo, Tulio Augusto Alves] Fed Univ, Clin Hosp, Campus Umuarama,Bloco UMU2H,Sala 01 Ave Para 1720, BR-38405320 Uberlandia, MG, Brazil.
C3 Universidade Federal de Uberlandia; Pontificia Universidade Catolica Do
   Rio Grande Do Sul
RP de Sousa, PM (corresponding author), Univ Fed Uberlandia, Fac Elect Engn, Biomed Lab, Campus Sta Monica,Ave Joao Naves de Avila 2121,Blo, BR-38400000 Uberlandia, MG, Brazil.
EM pedrosousa@ufu.br; pedrocarneiro@ufu.br; gabriellemp@ufu.br;
   modestomariane@gmail.com; carlosjunior@ufu.br; luis.moura@edu.pucrs.br;
   christian.mattjie@gmail.com; ana.marques@pucrs.br; tuliomacedo@ufu.br;
   ana.patrocinio@ufu.br
RI Marques da Silva, Ana Maria/HRA-7799-2023; Patrocinio, Ana
   C/E-1541-2015; Marques da Silva, Ana Maria/HZJ-6610-2023
OI Marques da Silva, Ana Maria/0000-0002-5924-6852; Patrocinio, Ana
   C/0000-0001-9376-7689; sousa, Pedro Moises de Sousa/0000-0003-4563-0033
FU "Coordination for the Improvement of Higher Education Personnel -
   Brazil" (CAPES);  [001]
FX This research was financed, in part, by the "Coordination for the
   Improvement of Higher Education Personnel - Brazil" (CAPES) - Finance
   Code 001
CR Aggarwal C.C., 2018, NEURAL NETWORKS DEEP, DOI DOI 10.1007/978-3-319-94463-0
   Balas V.E., 2019, SIST, V136, DOI [10.1007/978-3-030-11479-4, DOI 10.1007/978-3-030-11479-4]
   Chen YF, 2021, BMC GENOMICS, V22, DOI [10.1186/s12864-020-07315-1, 10.1186/s12859-021-04083-x]
   Dai WC, 2020, CAN ASSOC RADIOL J, V71, P195, DOI 10.1177/0846537120913033
   Eindhoven University of Technology MRJE, 2005, WAVELET THEORY APPL, V53
   Fan XL, 2022, DISPLAYS, V72, DOI 10.1016/j.displa.2022.102150
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guo TT, 2017, IEEE COMPUT SOC CONF, P1100, DOI 10.1109/CVPRW.2017.148
   Huang Y, 2021, NEUROCOMPUTING, V443, P26, DOI 10.1016/j.neucom.2021.02.091
   Ishitaki T, 2016, IEEE 30TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA 2016), P7, DOI 10.1109/WAINA.2016.143
   Jansen M, 2012, NOISE REDUCTION WAVE, V161, DOI [10.1007/978-1-4613-0145-5, DOI 10.1007/978-1-4613-0145-5]
   JUNIOR CAD, 2019, 26 BRAZILIAN C BIOME, P369, DOI DOI 10.1007/978-981-13-2517-5_56
   Junior CADC, 2019, THESIS U FEDERAL UBE, DOI [10.14393/ufu.di.2019.2036, DOI 10.14393/UFU.DI.2019.2036]
   Kasongo SM, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101752
   Kassani SH, 2021, BIOCYBERN BIOMED ENG, V41, P867, DOI 10.1016/j.bbe.2021.05.013
   Khatami A, 2017, EXPERT SYST APPL, V86, P190, DOI 10.1016/j.eswa.2017.05.073
   Kingma D. P., 2014, arXiv
   Kogilavani SV, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/7672196
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li X, 2019, RELIAB ENG SYST SAFE, V182, P208, DOI 10.1016/j.ress.2018.11.011
   Long W, 2019, KNOWL-BASED SYST, V164, P163, DOI 10.1016/j.knosys.2018.10.034
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Martin DR, 2020, ARCH PATHOL LAB MED, V144, P370, DOI 10.5858/arpa.2019-0004-OA
   Meyes R, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1901.08644
   Mittal M, 2019, APPL SOFT COMPUT, V78, P346, DOI 10.1016/j.asoc.2019.02.036
   Ozkaya U., 2020, BIG DATA ANALYTICS A, P281, DOI DOI 10.1007/978-3-030-55258-9_17
   Ozturk S., 2020, MEDRXIV, DOI [10.1101/2020.04.03.20048868, DOI 10.1101/2020.04.03.20048868]
   Ponti MA, 2018, ARXIV
   Rakita A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56847-4
   Rangarajan AK, 2022, AUTOMATIKA-UK, V63, P171, DOI 10.1080/00051144.2021.2014037
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Ribeiro CD, 2018, SCIENCE, V362, P404, DOI 10.1126/science.aau5229
   Ribeiro CD, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195885
   Roberts M, 2021, NAT MACH INTELL, V3, P199, DOI 10.1038/s42256-021-00307-0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Ruuska S, 2018, BEHAV PROCESS, V148, P56, DOI 10.1016/j.beproc.2018.01.004
   Shafiq M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12188972
   Sherry ST, 2001, NUCLEIC ACIDS RES, V29, P308, DOI 10.1093/nar/29.1.308
   Shirazi AZ, 2018, MED BIOL ENG COMPUT, V56, P721, DOI 10.1007/s11517-017-1721-z
   Simon JHM, 2005, B WORLD HEALTH ORGAN, V83, P707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Skansi S., 2018, An introduction to deep learning: From logical calculus to artificial intelligence, DOI DOI 10.1007/978-3-319-73004-2
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Ter-Sarkisov A, 2022, APPL INTELL, V52, P9664, DOI 10.1007/s10489-021-02731-6
   Vaya MDLI, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.01174
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wani MA., 2020, ADV DEEP LEARNING, DOI [10.1007/978-981-13-6794-6, DOI 10.1007/978-981-13-6794-6]
   Weiss SR, 2011, ADV VIRUS RES, V81, P85, DOI 10.1016/B978-0-12-385885-6.00009-2
   Wu J, 2020, NCOV LANG EN
   Yang WJ, 2020, J INFECTION, V80, P388, DOI 10.1016/j.jinf.2020.02.016
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang J., 2020, ARXIV
   Zhu N, 2020, NEW ENGL J MED, V382, P727, DOI [10.1056/NEJMoa2001017, 10.1172/JCI89857]
   ZIMMERMAN DW, 1993, J EXP EDUC, V62, P75, DOI 10.1080/00220973.1993.9943832
NR 58
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25327
EP 25355
DI 10.1007/s11042-022-14316-7
EA DEC 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000900189300002
PM 36570730
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zeng, L
   Zhang, H
   Li, YY
   Li, MD
   Wang, SS
AF Zeng, Liang
   Zhang, Hao
   Li, Yanyan
   Li, Maodong
   Wang, Shanshan
TI Supervision dropout: guidance learning in deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Dropout; Genetic algorithm; Dropout rate
AB In deep neural networks, the generalization is a vital evaluation metric. As it contributes to avoid over-fitting, Dropout plays an important role in improving the generalization of deep neural networks. Without fully utilizing the training data and the real-time performance of the networks, traditional Dropout and its variants lack of specificity in the selection of inactivated neurons and the planning of dropout rates, resulting in a weaker performance in enhancing the generalization. Therefore, this paper offers an improved Dropout method. As both the training data and the real-time performance of networks can be quantified by the loss, the method uses the loss of the network prediction to guide the selection of inactivated neurons and the determination of dropout rates. The selection is performed by the genetic algorithm, while the results of the selection are used to plan the dropout rate. In essence, this approach encourages the subset of neurons with the higher loss to be trained so as to increase the robustness of neurons and thus improves the generalization of networks. The experimental results demonstrate that the proposed method achieves better generalization on MiniImageNet and Caltech-256 datasets. Compared with the backbone network, the accuracy improves from 66.56% to 72.95%.
C1 [Zeng, Liang; Zhang, Hao; Li, Yanyan; Li, Maodong; Wang, Shanshan] Hubei Univ Technol, Sch Elect & Elect Engn, Wuhan 430068, Hubei, Peoples R China.
   [Zeng, Liang; Wang, Shanshan] Hubei Univ Technol, Hubei Key Lab High efficiency Utilizat Solar Energ, Wuhan 430068, Hubei, Peoples R China.
   [Zeng, Liang; Wang, Shanshan] Hubei Univ Technol, Xiangyang Ind Inst, Xiangyang 441100, Hubei, Peoples R China.
C3 Hubei University of Technology; Hubei University of Technology; Hubei
   University of Technology
RP Zeng, L; Wang, SS (corresponding author), Hubei Univ Technol, Sch Elect & Elect Engn, Wuhan 430068, Hubei, Peoples R China.; Zeng, L; Wang, SS (corresponding author), Hubei Univ Technol, Hubei Key Lab High efficiency Utilizat Solar Energ, Wuhan 430068, Hubei, Peoples R China.; Zeng, L; Wang, SS (corresponding author), Hubei Univ Technol, Xiangyang Ind Inst, Xiangyang 441100, Hubei, Peoples R China.
EM zengliang@hbut.edu.cn; wangshanshan@hbut.edu.cn
RI Wang, Shan-Shan/Z-4331-2019
OI Zeng, Liang/0000-0003-0271-6398
FU Key Research and Development Project of Hubei Province [2020BAB114]; Key
   Project of Science and Technology Research Program of Hubei
   EducationalCommittee [D20211402]; Project of Xiangyang Industrial
   Institute of Hubei University of Technology [XYYJ2022C04]; Open
   Foundation of Hubei Key Laboratory for High-efficiency Utilizationof
   Solar Energy and Operation Control of Energy Storage System
   [HBSEES201903, HBSEES202106]
FX This work was in part supported by the Key Research and Development
   Project of Hubei Province(No. 2020BAB114), the Key Project of Science
   and Technology Research Program of Hubei EducationalCommittee (No.
   D20211402), the Project of Xiangyang Industrial Institute of Hubei
   University of Technology (No. XYYJ2022C04), and the Open Foundation of
   Hubei Key Laboratory for High-efficiency Utilizationof Solar Energy and
   Operation Control of Energy Storage System (No. HBSEES201903 &
   HBSEES202106).
CR Achille A, 2018, IEEE T PATTERN ANAL, V40, P2897, DOI 10.1109/TPAMI.2017.2784440
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Ba Lei Jimmy, 2013, Advances in Neural Information Processing Systems, P3084
   Baldi Pierre, 2013, Advances in Neural Information Processing Systems, P2814
   Chattopadhay Aditya, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P839, DOI 10.1109/WACV.2018.00097
   Chen YY, 2021, NEUROCOMPUTING, V450, P354, DOI 10.1016/j.neucom.2021.04.047
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Fan X., 2021, ARXIV210304181
   Feng XL, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13040706
   Gal Y., 2016, PMLR, V48, P1050, DOI DOI 10.5555/3045390.3045502
   Gao W, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-5470-z
   Griffin G., 2007, CALTECH 256 OBJECT C
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2020, IEEE T INSTRUM MEAS, V69, P1493, DOI 10.1109/TIM.2019.2915404
   Hinton G. E., 2012, 12070580 ARXIV
   Huang SQ, 2021, ANN IEEE INT CONF SE, DOI 10.1109/SECON52354.2021.9491588
   Inoue H, 2019, ARXIV190509788
   Kamili A, 2020, J INTELL FUZZY SYST, V39, P8389, DOI 10.3233/JIFS-189157
   Khan N, 2019, LECT NOTES ARTIF INT, V11489, P296, DOI 10.1007/978-3-030-18305-9_24
   Konovalenko I, 2020, METALS-BASEL, V10, DOI 10.3390/met10060846
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lambert J, 2018, PROC CVPR IEEE, P8886, DOI 10.1109/CVPR.2018.00926
   Li MD, 2022, MATH COMPUT SIMULAT, V193, P71, DOI 10.1016/j.matcom.2021.10.003
   Lian ZF, 2016, CHINESE J ELECTRON, V25, P152, DOI 10.1049/cje.2016.01.023
   Molchanov D, 2017, PR MACH LEARN RES, V70
   Morerio P, 2017, IEEE I CONF COMP VIS, P3564, DOI 10.1109/ICCV.2017.383
   Nagaraj B, 2020, CLUSTER COMPUT, V23, P2001, DOI 10.1007/s10586-019-02963-9
   Ng ST, 2008, BUILD ENVIRON, V43, P1171, DOI 10.1016/j.buildenv.2007.02.017
   Nguyen S, 2021, IMPROVING BAYESIAN I
   Ou Y, 2022, OPT LASER TECHNOL, V146, DOI [10.1016/j.optlastec.2021.10760, DOI 10.1016/J.0PTLASTEC.2021.10760]
   Rennie SJ, 2014, IEEE W SP LANG TECH, P159, DOI 10.1109/SLT.2014.7078567
   Roccetti M, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0235-y
   Sai Ambati L, 2020, INFLUENCE DIGITAL DI
   Santra B, 2020, PATTERN RECOGN LETT, V131, P205, DOI 10.1016/j.patrec.2019.12.023
   Shen X., 2017, IEEE T NEURAL NETWOR, V29, P3926
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun Y, 2016, SPARSIFYING NEURAL N
   Tang YH, 2020, AAAI CONF ARTIF INTE, V34, P5964
   Viloria A., 2020, Procedia Comput. Sci, V175, P108, DOI [DOI 10.1016/J.PROCS.2020.07.018, 10.1016/j.procs.2020.07, DOI 10.1016/J.PROCS.2020.07]
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wang G., 2021, Sci. Rep, V11, P1
   Yu F, 2014, APPL ENERG, V134, P102, DOI 10.1016/j.apenergy.2014.07.104
   Zeng L, 2022, AUTOMAT CONSTR, V134, DOI 10.1016/j.autcon.2021.104088
   Zhou R, 2020, IEEE T MED IMAGING, V39, P2844, DOI 10.1109/TMI.2020.2975231
   Zunino A, 2021, INT J COMPUT VISION, V129, P1139, DOI 10.1007/s11263-020-01422-y
NR 47
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18831
EP 18850
DI 10.1007/s11042-022-14274-0
EA DEC 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000893056100002
DA 2024-07-18
ER

PT J
AU Mo, JW
   Zhu, R
   Yuan, H
   Shou, ZY
   Chen, LP
AF Mo, Jianwen
   Zhu, Rui
   Yuan, Hua
   Shou, Zhaoyu
   Chen, Lingping
TI Student behavior recognition based on multitask learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Student behavior recognition; Multitask learning; Pose estimation;
   Object detection
AB The assessment of students' classroom behavior is an important part of classroom teaching evaluation. However, teachers cannot timely, objectively and accurately evaluate the listening status of each student in the class. We offer a multitask classroom behavior recognition method that combines human pose estimation and object detection. First, the target detector extracts the individual region from the keyframe as the network's input. Then, the multitask heatmap network (MTHN) module extracts the intermediate heatmap of multi-scale feature association. The attitude estimation and target detection tasks are constructed by mapping relations to obtain the keypoints and object position information. Finally, the keypoints behavior vector and the metric vector are used to model the behavior, and a classroom behavior detection algorithm based on the fully connected network is designed. Additionally, we created a classroom dataset with pose estimation, objects, and behavior labels. Meanwhile, transfer learning is used to solve the problem of insufficient sample size. After several experiments, we show that the detection accuracy of the proposed multitask learning-based student behavior recognition algorithm reaches more than 90%.
C1 [Mo, Jianwen; Zhu, Rui; Yuan, Hua; Shou, Zhaoyu] Guilin Univ Elect Technol, Sch Informat & Commun, Guilin 541001, Peoples R China.
   [Chen, Lingping] Guilin Inst Informat Technol, Educ Technol Stat, Guilin 541001, Peoples R China.
C3 Guilin University of Electronic Technology; Guilin Institute of
   Information Technology
RP Yuan, H (corresponding author), Guilin Univ Elect Technol, Sch Informat & Commun, Guilin 541001, Peoples R China.
EM mo_jianwen@126.com; 614824028@qq.com; 16020158@qq.com; 601998001@qq.com;
   chenlingping2022@163.com
RI mo, jian/KLC-9208-2024; zhaoyu, shou/KHV-7632-2024
FU National Natural Science Foundation of China [62177012, 62001133,
   61967005]; Innovation Project of GUET Graduate Education [2021YCXS027]
FX This work was supported by The National Natural Science Foundation of
   China (Grant Number 62177012, 62001133, and 61967005). Innovation
   Project of GUET Graduate Education (Grant Number 2021YCXS027).
CR [Anonymous], 2020, YOLOv5
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   COCO, COCO LEAD BOARD
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Fu R, 2019, 2019 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P206, DOI [10.1109/ICICIP47338.2019.9012177, 10.1109/icicip47338.2019.9012177]
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang W, 2020, TRAIT SIGNAL, V37, P503, DOI 10.18280/ts.370318
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li Y, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107341
   Mohammadi S, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), P315, DOI [10.1109/ICCKE48569.2019.8965014, 10.1109/iccke48569.2019.8965014]
   Pei JY, 2019, TRAIT SIGNAL, V36, P557, DOI 10.18280/ts.360611
   Pise A, 2022, MULTIMED TOOLS APPL, V81, P26633, DOI 10.1007/s11042-020-10133-y
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Su K, 2019, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2019.00582
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xuefei Lv, 2021, 2021 IEEE 3rd International Conference on Frontiers Technology of Information and Computer (ICFTIC), P154, DOI 10.1109/ICFTIC54370.2021.9647300
   Yan SY, 2018, IEEE T COGN DEV SYST, V10, P1116, DOI 10.1109/TCDS.2017.2783944
   YiWen Zhang, 2020, 2020 International Conference on Artificial Intelligence and Education (ICAIE), P93, DOI 10.1109/ICAIE50891.2020.00029
   Zhao J, 2021, SUSTAIN CITIES SOC, V67, DOI 10.1016/j.scs.2021.102749
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng YP, 2020, NEUROCOMPUTING, V413, P383, DOI 10.1016/j.neucom.2020.07.016
   Zhou X., 2019, arXiv
NR 34
TC 5
Z9 5
U1 12
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 19091
EP 19108
DI 10.1007/s11042-022-14100-7
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000888710500003
DA 2024-07-18
ER

PT J
AU Kuila, S
   Dhanda, N
   Joardar, S
AF Kuila, Sumanta
   Dhanda, Namrata
   Joardar, Subhankar
TI ECG signal classification to detect heart arrhythmia using ELM and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Classification; Feature selection; Genetic algorithm;
   Extreme learning machine (ELM); Convolutional neural networks(CNN); ECG
   segmentation strategy; Anti-noise performance
ID EXTREME LEARNING-MACHINE; SELECTION; SYSTEM
AB The cardiovascular disease is the one of the major cause of death in the today's world. The Holter recorder is used to monitor the Electrocardiogram (ECG) signal to record the heart activity which is a popular method to detect the disease. Unfortunately, finding professionals to examine a big volume of ECG data takes up far too much medical time and money. The machine learning-based methods for recognising ECG characteristics have important role for extraction of features and ECG signal classification for Arrhythmia detection. The traditional processed used for the cardiac treatment have certain disadvantages, such as the need to understand the exact cardiac problem to recognize the disease and long learning curve to study the arrhythmia process manually. In this study twelve different heartbeat micro-classes are used with MIT-BIH Arrhythmia database for the classification. An efficient and robust virtually 12-layer deep traditionally one-dimensional CNN (convolutional neural network) is used with ELM (Extreme learning Machine) is used to propose the classification procedure. In the experiment different heart beat characteristics are identified, and the wavelet self-adaptive threshold denoising approach is applied by a combined algorithm using ELM and CNN. The results reveal that the model described in this paper performing better than the random forest, BP neural network, and other GA networks in terms of accuracy, sensitivity, resilience, and anti-noise capabilities. In this work ELM based classification on Convolutional Neural Network is developed for arrhythmia detection from the ECG signal. Its precise classification effectively conserves medical resources, which benefits clinical practise. In this study the classification result produces 98.82% accuracy which is quite satisfactory with compared with other similar types of algorithms used classification results.
C1 [Kuila, Sumanta] Amity Univ Uttar Pradesh, Lucknow, Uttar Pradesh, India.
   [Dhanda, Namrata] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Lucknow, Uttar Pradesh, India.
   [Joardar, Subhankar] Haldia Inst Technol, Dept Comp Sci & Engn, Haldia, India.
C3 Haldia Institute of Technology
RP Kuila, S (corresponding author), Amity Univ Uttar Pradesh, Lucknow, Uttar Pradesh, India.
EM sumanta.kuila@gmail.com; ndhanda510@gmail.com;
   subhankarranchi@yahoo.co.in
RI Dhanda, Namrata/JZT-2012-2024; Joardar, subhankar/AAD-5396-2022
OI Joardar, subhankar/0000-0002-1542-3757; Kuila,
   Sumanta/0000-0002-6088-6806; Dhanda, Namrata/0000-0003-0395-0696
CR a A Shahbahrami MKS., 2012, International journal of Computer Science, Engineering and Application (IJCSEA), V12, P1, DOI [DOI 10.5121/IJCSEA.2012.2101, 10.5121/ijcsea.2012.2101]
   Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   Amrani M, 2018, NEURAL COMPUT APPL, V30, P2047, DOI 10.1007/s00521-018-3616-9
   Andersen RS, 2019, EXPERT SYST APPL, V115, P465, DOI 10.1016/j.eswa.2018.08.011
   [Anonymous], 2018, Int J Adv Soft Comput Appl
   [Anonymous], 2011, Int J Inf Technol Knowl Manag
   Atal DK, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105607
   Chen K, 2021, ARXIV
   Chen TH, 2013, IEEE J EM SEL TOP C, V3, P75, DOI 10.1109/JETCAS.2013.2242772
   COAST DA, 1990, IEEE T BIO-MED ENG, V37, P826, DOI 10.1109/10.58593
   Diker A, 2020, MED HYPOTHESES, V136, DOI 10.1016/j.mehy.2019.109515
   Ding XX, 2017, IEEE T INSTRUM MEAS, V66, P1926, DOI 10.1109/TIM.2017.2674738
   Ertam F, 2017, MEASUREMENT, V95, P135, DOI 10.1016/j.measurement.2016.10.001
   Fan XM, 2018, IEEE J BIOMED HEALTH, V22, P1744, DOI 10.1109/JBHI.2018.2858789
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo SL, 2016, J GERIATR CARDIOL, V13, P528, DOI 10.11909/j.issn.1671-5411.2016.06.015
   Huang GB, 2004, IEEE IJCNN, P985
   Jemilehin T., 2016, DESIGN SIMULATION EL, V1, P155
   Jiang W, 2007, IEEE T NEURAL NETWOR, V18, P1750, DOI 10.1109/TNN.2007.900239
   Kachuee M, 2018, IEEE INT CONF HEALT, P443, DOI 10.1109/ICHI.2018.00092
   Karimian N, 2017, IEEE T BIO-MED ENG, V64, P1400, DOI 10.1109/TBME.2016.2607020
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Knee P, 2011, IEEE RAD CONF, P294
   Kuila S., 2020, INT J EL COMP ENG SY, V10, P6598, DOI [10.11591/ijece.v10i6.pp6598-6605, DOI 10.11591/IJECE.V10I6.PP6598-6605]
   Kuila S., 2019, SPRINGER PROCEED LNE, V602, P417
   Kuila S., 2021, J THEOR APPL INF TEC, V99, P1817
   Li C, 2017, PROCEDIA COMPUT SCI, V112, P2328, DOI 10.1016/j.procs.2017.08.265
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Li W, 2019, IEEE ACCESS, V7, P25627, DOI 10.1109/ACCESS.2018.2877793
   Luo K, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4108720
   Martis RJ, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500147
   Meng HH, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P7, DOI 10.1109/CSE.2014.36
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Oh SL, 2019, COMPUT BIOL MED, V105, P92, DOI 10.1016/j.compbiomed.2018.12.012
   Osowski S, 2004, IEEE T BIO-MED ENG, V51, P582, DOI 10.1109/TBME.2004.824138
   Pandey SK, 2020, PROCEDIA COMPUT SCI, V167, P2181, DOI 10.1016/j.procs.2020.03.269
   Pasolli E, 2015, BIOMED SIGNAL PROCES, V19, P130, DOI 10.1016/j.bspc.2014.10.013
   Patro K.K., 2017, Journal of Engineering Science Technology Review, V10, P1, DOI [DOI 10.25103/JESTR.106.01, 10.25103/jestr.106, DOI 10.25103/JESTR.106]
   Plawiak P, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105740
   Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Singh BN, 2006, DIGIT SIGNAL PROCESS, V16, P275, DOI 10.1016/j.dsp.2005.12.003
   Song GJ., 2014, J HARBIN I TECHNOL, V1, P8
   Vishwanath B, 2021, J KING SAUD UNIV-COM, V33, P54, DOI 10.1016/j.jksuci.2018.02.005
   Wang SN, 2016, NEUROCOMPUTING, V196, P125, DOI 10.1016/j.neucom.2016.02.059
   Wong SY, 2016, NEUROCOMPUTING, V171, P1431, DOI 10.1016/j.neucom.2015.07.065
   Yang WA, 2016, INT J PROD RES, V54, P4703, DOI 10.1080/00207543.2015.1111534
   Zhao ZY, 2019, IEEE ACCESS, V7, P34060, DOI 10.1109/ACCESS.2019.2900719
   Zubair M, 2016, INT CONF IT CONVERGE, P335
NR 50
TC 3
Z9 3
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29857
EP 29881
DI 10.1007/s11042-022-14233-9
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000886864300002
DA 2024-07-18
ER

PT J
AU Yang, YH
   Han, J
AF Yang, Yonghao
   Han, Jin
TI Real-Time object detector based MobileNetV3 for UAV applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UAV; Object detection; Lightweight; ShufflenetV2; MobileNetV3
AB With the continuous progress of UAV (unmanned aerial vehicle) flight technology, more and more outdoor vision tasks begin to rely on UAV to complete, many of which require computer vision algorithms to analyze the information captured by the camera. However, it is difficult to deploy detectors on embedded devices due to the challenges among energy consumption, accuracy, and speed. In this paper, we propose an end-to-end object detection model running on a UAV platform that is suitable for real-time applications. Through the research of shufflenetv2 and mobilenetv3, a new feature extraction network structure is proposed. In order to improve the detection accuracy without losing the detection efficiency, a multi-scale fusion module based on deconvolution is added. Experiments show when deployed on our onboard Nvidia Jetson TX2 for testing and inference, our model combined with a modified focal loss function, produced a desirable performance of 21.7% mAP for object detection with an inference time of 17 fps.
C1 [Yang, Yonghao; Han, Jin] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266000, Peoples R China.
C3 Shandong University of Science & Technology
RP Han, J (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266000, Peoples R China.
EM goodlc_yyh@163.com; shnk123@163.com
RI LI, Xiang-Yang/JZE-0275-2024; Wang, YUJIE/JXY-8442-2024
OI Han, Jin/0000-0002-9330-5019
FU Natural Science Foundation of Shandong Province [ZR2020KE023]; China
   Scholarship Council
FX This work was supported by Natural Science Foundation of Shandong
   Province (ZR2021MD057) and Natural Science Foundation of Shandong
   Province (ZR2020KE023). Jin Han is thankful for the financial support
   from the China Scholarship Council.
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Energy-Efficient Real-Time UAV., 2020, IEEE T COMPUT AID D, V39, P3123, DOI [10.1109/TCAD.2019.2957724, DOI 10.1109/TCAD.2019.2957724]
   Feng XY, 2018, ACTA OPT SIN, V38, DOI 10.3788/AOS201838.0615004
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Kyrkou C, 2018, DES AUT TEST EUROPE, P967, DOI 10.23919/DATE.2018.8342149
   Li J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010014
   Li YZ, 2017, ADV NEUR IN, V30
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sermanet P., 2013, ARXIV
   Singh P, 2019, INT C COMP VIS IM PR, P373
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaddi, 2019, EFFICIENT OBJECT DET
   [王金传 Wang Jinchuan], 2018, [地球信息科学学报, Journal of Geo-Information Science], V20, P1500
   Wang RJ, 2018, 32 C NEURAL INFORM P
   Zhang PY, 2019, IEEE INT CONF COMP V, P37, DOI 10.1109/ICCVW.2019.00011
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhu P, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2001.06303
NR 29
TC 3
Z9 3
U1 7
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18709
EP 18725
DI 10.1007/s11042-022-14196-x
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000887890500002
DA 2024-07-18
ER

PT J
AU Bhuyan, HK
   Saikiran, M
   Tripathy, M
   Ravi, V
AF Bhuyan, Hemanta Kumar
   Saikiran, M.
   Tripathy, Murchhana
   Ravi, Vinayakumar
TI Wide-ranging approach-based feature selection for classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Mutual information; Linear correlation coefficient;
   Classification; Data mining; Confusion matrix; P-values
ID SUB-FEATURE SELECTION; MUTUAL INFORMATION
AB Feature selection methods have been issued in the context of data classification due to redundant and irrelevant features. The above features slow the overall system performance, and wrong decisions are more likely to be made with extensive data sets. Several methods have been used to solve the feature selection problem for classification, but most are specific to be used only for a particular data set. Thus, this paper proposes wide-ranging approaches to solve maximum feature selection problems for data sets. The proposed algorithm analytically chooses the optimal feature for classification by utilizing mutual information (MI) and linear correlation coefficients (LCC). It considers linearly and nonlinearly dependent data features for the same. The proposed feature selection algorithm suggests various features used to build a substantial feature subset for classification, effectively reducing irrelevant features. Three different datasets are used to evaluate the performance of the proposed algorithm with classifiers which requires a higher degree of features to have better accuracy and a lower computational cost. We considered probability value (p value <0.05) for feature selection in experiments on different data sets, then the number of features is selected (such as 7, 5, and 6 features from mobile, heart, and diabetes data set, respectively). Various accuracy is considered with different classifiers; for example, classifier Nearest_Neighbors made accuracy such as 0.92225, 0.88333, 0.86250 for mobile, heart, and diabetes data sets, respectively. The proposed model is adequate as per the evaluation of several real-world data sets.
C1 [Bhuyan, Hemanta Kumar; Saikiran, M.] Vignans Fdn Sci Technol & Res Deemed Be Univ, Dept Informat Technol, Guntur, Andhra Pradesh, India.
   [Tripathy, Murchhana] Manipal Acad Higher Educ, TA Pai Management Inst, Informat Syst & Technol, Manipal, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar 34754, Saudi Arabia.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Manipal
   Academy of Higher Education (MAHE); Prince Mohammad Bin Fahd University
RP Bhuyan, HK (corresponding author), Vignans Fdn Sci Technol & Res Deemed Be Univ, Dept Informat Technol, Guntur, Andhra Pradesh, India.
EM hmb.bhuyan@gmail.com; kiranmunagala2@gmail.com;
   murchhanatripathy@gmail.com; vravi@pmu.edu.sa
RI Ravi, Vinayakumar/L-4202-2018
CR Abeywickrama DB, 2020, INT J SOFTW TOOLS TE, V22, P399, DOI 10.1007/s10009-020-00554-3
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Amiri F, 2011, J NETW COMPUT APPL, V34, P1184, DOI 10.1016/j.jnca.2011.01.002
   [Anonymous], 2005, ADV NEURAL INF PROCE
   archive, 2020, ML DAT PHP
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Bhuyan Hemanta Kumar, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P1212, DOI 10.1109/ICSSIT46314.2019.8987780
   Bhuyan H. K., 2012, INT J COMPU SCI ISSU, V9, P434
   Bhuyan HK, 2022, HEALTH TECHNOL-GER, V12, P987, DOI 10.1007/s12553-022-00687-2
   Bhuyan HK, 2022, CLUSTER COMPUT, V25, P4275, DOI 10.1007/s10586-022-03667-3
   Bhuyan HK, 2024, IEEE T COMPUT SOC SY, V11, P3131, DOI 10.1109/TCSS.2022.3164993
   Bhuyan HK, 2023, IEEE T ENG MANAGE, V70, P2732, DOI 10.1109/TEM.2021.3098463
   Bhuyan HK, 2022, ENG OPTIMIZ, V54, P1305, DOI 10.1080/0305215X.2021.1922897
   Bhuyan HK, 2015, APPL SOFT COMPUT, V36, P552, DOI 10.1016/j.asoc.2015.06.060
   Bhuyan HK, 2014, CLUSTER COMPUT, V17, P1383, DOI 10.1007/s10586-014-0393-9
   Bhuyan HK, 2018, 2018 2 INT C TRENDS, P210, DOI [10.1109/ICOEI.2018.8553763, DOI 10.1109/ICOEI.2018.8553763]
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chitrakar R, 2014, COMPUT SECUR, V45, P231, DOI 10.1016/j.cose.2014.06.006
   Chow TWS, 2005, IEEE T NEURAL NETWOR, V16, P213, DOI 10.1109/TNN.2004.841414
   Croft W. B., 2010, SEARCH ENGINES INFOR
   Dahiru Tukur, 2008, Ann Ib Postgrad Med, V6, P21
   Flannery B. P., 1992, NUMERICAL RECIPES C, DOI DOI 10.2277/052143064X
   Gakii C, 2022, ALGORITHMS, V15, DOI 10.3390/a15010021
   Greenland S, 2016, EUR J EPIDEMIOL, V31, P337, DOI 10.1007/s10654-016-0149-3
   Hsu CN., 2004, IEEE T SYST MAN CY B, V32, P212
   kaggle, 2020, DAT
   Kamila NK, 2016, CLUSTER COMPUT, V19, P1723, DOI 10.1007/s10586-016-0643-0
   Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138
   Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291
   Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131
   Li Z., 2012, PROC C ASS ADV ARTIF, P1026, DOI DOI 10.1609/AAAI.V26I1.8289
   Ma GX, 2020, IEEE T VIS COMPUT GR, V26, P3535, DOI 10.1109/TVCG.2020.3023636
   Mao KZ, 2004, IEEE T SYST MAN CY B, V34, P60, DOI 10.1109/TSMCB.2002.805808
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Rifkin R, 2004, J MACH LEARN RES, V5, P101
   Rossi F, 2006, CHEMOMETR INTELL LAB, V80, P215, DOI 10.1016/j.chemolab.2005.06.010
   Song J., 2011, P 1 WORKSHOP BUILDIN, P29
   Tabakhi S, 2014, ENG APPL ARTIF INTEL, V32, P112, DOI 10.1016/j.engappai.2014.03.007
   Tavallaee M, 2009, 2009 IEEE S COMP INT, P1, DOI DOI 10.1109/CISDA.2009.5356528
   Wan Y, 2021, IEEE T KNOWL DATA EN, V33, P3338, DOI 10.1109/TKDE.2020.2969860
   Wang G, 2022, IEEE-ASME T MECH, V27, P3350, DOI 10.1109/TMECH.2021.3131309
   Wang R, 2022, IEEE T KNOWL DATA EN, V34, P942, DOI 10.1109/TKDE.2020.2983396
   Zaffar M, 2022, CMC-COMPUT MATER CON, V70, P1893, DOI 10.32604/cmc.2022.018295
   Zhang L, 2020, IEEE T IMAGE PROCESS, V29, P1016, DOI 10.1109/TIP.2019.2938307
   Zhang Y, 2019, IEEE T KNOWL DATA EN, V31, P2423, DOI 10.1109/TKDE.2018.2877746
   Zhu JJ, 2022, IEEE T KNOWL DATA EN, V34, P271, DOI 10.1109/TKDE.2020.2978055
NR 47
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23277
EP 23304
DI 10.1007/s11042-022-14132-z
EA NOV 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000884953400003
DA 2024-07-18
ER

PT J
AU Chen, QG
   Huang, JC
   Zhu, HH
   Lian, LY
   Wei, KH
   Lai, XM
AF Chen, Qingguang
   Huang, Junchao
   Zhu, Haihua
   Lian, Luya
   Wei, Kaihua
   Lai, Xiaomin
TI Automatic and visualized grading of dental caries using deep learning on
   panoramic radiographs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Caries grading; Panoramic radiographs; Anatomical segmentation;
   Visualized intersection judgment
ID CLASSIFICATION; IMAGES
AB Caries grading plays a significant role for oral health management and treatment planning. Grading caries on panoramic image is a challenging task due to complication and diversity of gray distribution. In this paper, we proposed an automatic and visualized caries grading method for panoramic image using deep learning-based tooth anatomical segmentation and regions intersection judgment to achieve a consistent grading process with dentist. To achieve accurate semantic segmentation, a modified U-Net model by adding ASPP module and boundary loss is applied to segment caries, enamel, dentin, and pulp tissue region. Then a visualized process is conducted to judge the intersection of carious region and decision-making line for grading of shallow, medium, deep caries. Experimental results demonstrate our method achieves promising grading performance. Moreover, we validated that our proposed two-stage caries grading method outperform deep learning classification models. Ablation analysis of anatomical segmentation performance was also investigated, and the compared results show that our proposed modified U-Net model can obtain more accurate region and boundary to improve grading results. Some mis-graded cases were finally detailed analyzed. Our proposed caries grading approach has great potential for clinical aided diagnosis and automatic chart filling on panoramic radiographs.
C1 [Chen, Qingguang; Huang, Junchao; Wei, Kaihua; Lai, Xiaomin] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
   [Zhu, Haihua; Lian, Luya] Zhejiang Univ, Affiliated Hosp Stomatol, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University
RP Chen, QG (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
EM optichen@hdu.edu.cn
FU Fundamental Research Funds for the Zhejiang Provincial Universities
   [2021XZZX033]; Natural Science Foundation of Zhejiang Province
   [LZY21F030002]; Department of Science and Technology of Zhejiang
   Province [Y202045833]
FX This work was supported by the Fundamental Research Funds for the
   Zhejiang Provincial Universities (2021XZZX033), Natural Science
   Foundation of Zhejiang Province (LZY21F030002), Department of Science
   and Technology of Zhejiang Province (Y202045833).
CR Black G., 1917, A work on operative dentistry: the technical procedures in filling teeth
   Caliva F, 2019, ARXIV
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen X, 2019, PROC CVPR IEEE, P11624, DOI 10.1109/CVPR.2019.01190
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   El Jurdi R, 2021, PR MACH LEARN RES, V143, P158
   Fang LY, 2019, IEEE T MED IMAGING, V38, P1959, DOI 10.1109/TMI.2019.2898414
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao XT, 2015, IEEE T BIO-MED ENG, V62, P2693, DOI 10.1109/TBME.2015.2444389
   Goldberg, 2020, JSM DENT, V8, P11
   Goldberg M., 2016, Understanding dental caries
   Haghanifar A, 2020, ARXIV
   Han YX, 2021, ALGORITHMS, V14, DOI 10.3390/a14050144
   Hwang JJ, 2019, IMAGNG SCI DENT, V49, P1, DOI 10.5624/isd.2019.49.1.1
   Ismail AI, 2007, COMMUNITY DENT ORAL, V35, P170, DOI 10.1111/j.1600-0528.2007.00347.x
   Ismail AI, 2015, BMC ORAL HEALTH, V15, DOI 10.1186/1472-6831-15-S1-S9
   Jader G, 2018, SIBGRAPI, P400, DOI 10.1109/SIBGRAPI.2018.00058
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P115, DOI 10.1109/cibcb48159.2020.9277638
   Karimi D, 2020, IEEE T MED IMAGING, V39, P499, DOI 10.1109/TMI.2019.2930068
   Kassebaum NJ, 2015, J DENT RES, V94, P650, DOI 10.1177/0022034515573272
   Kervadec H, 2019, PR MACH LEARN RES, V102, P285
   Koch TL, 2019, I S BIOMED IMAGING, P15, DOI [10.1109/isbi.2019.8759563, 10.1109/ISBI.2019.8759563]
   Lee JH, 2018, J DENT, V77, P106, DOI 10.1016/j.jdent.2018.07.015
   Leo LM, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103836
   Li YC, 2020, IEEE ACCESS, V8, P117714, DOI 10.1109/ACCESS.2020.3005180
   Lin D, 2018, LECT NOTES COMPUT SC, V11207, P622, DOI 10.1007/978-3-030-01219-9_37
   Martinez-Murcia FJ, 2021, NEUROCOMPUTING, V452, P424, DOI 10.1016/j.neucom.2020.04.148
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Mount GJ, 2006, INT DENT J, V56, P82
   Nagpal K, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0112-2
   Naser MA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103758
   Qiu MY, 2022, MED PHYS, V49, P1739, DOI 10.1002/mp.15386
   Qureshi I, 2021, MULTIMED TOOLS APPL, V80, P11691, DOI 10.1007/s11042-020-10238-4
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Silva G, 2018, EXPERT SYST APPL, V107, P15, DOI 10.1016/j.eswa.2018.04.001
   Singh P, 2021, MULTIMED TOOLS APPL, V80, P5255, DOI 10.1007/s11042-020-09891-6
   Sinha A, 2021, IEEE J BIOMED HEALTH, V25, P121, DOI 10.1109/JBHI.2020.2986926
   Stidham RW, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3963
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Tao A., 2020, Arxiv
   Tran ST, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9010054
   Tuzoff DV, 2019, DENTOMAXILLOFAC RAD, V48, DOI 10.1259/dmfr.20180051
   Vinayahalingam S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92121-2
   Wang X, 2022, NEUROCOMPUTING, V486, P135, DOI 10.1016/j.neucom.2021.11.017
   Wang YL, 2021, DIABETES-METAB RES, V37, DOI 10.1002/dmrr.3445
   Whaites E, 2013, Essentials of Dental Radiography and Radiology, V5th
   Xu X, 2020, IEEE J BIOMED HEALTH, V24, P556, DOI 10.1109/JBHI.2019.2914690
   Yang D, 2002, B SURVEYING MAPP, V3, P58
   Yang QQ, 2020, J BIOPHOTONICS, V13, DOI 10.1002/jbio.201900203
   Yang QR, 2021, IEEE ACCESS, V9, P18867, DOI 10.1109/ACCESS.2021.3053316
   Zeller G, 2019, DETECTION ASSESSMENT, P57
   Zhang J, 2018, ARXIV
   Zhang X, 2022, ORAL DIS, V28, P173, DOI 10.1111/odi.13735
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao S, 2019, ADV NEUR IN, V32
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu HH, 2023, NEURAL COMPUT APPL, V35, P16051, DOI 10.1007/s00521-021-06684-2
NR 60
TC 1
Z9 1
U1 6
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23709
EP 23734
DI 10.1007/s11042-022-14089-z
EA NOV 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000884646000002
DA 2024-07-18
ER

PT J
AU Mirzaei, S
   Jazani, IK
AF Mirzaei, Sayeh
   Jazani, Iman Khani
TI Acoustic scene classification with multi-temporal complex modulation
   spectrogram features and a convolutional LSTM network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic scene classification; Convolutional neural network (CNN); Long
   short term memory (LSTM); Conv-LSTM; Modulation spectrogram
ID NONNEGATIVE TENSOR FACTORIZATION
AB Acoustic scene classification (ASC) is a mapping from an environmental sound recording to predefined classes representing the auditory scene of the recording. This paper proposes an ASC solution based on the combination of convolutional neural networks, long short term memory cells, and multi-temporal input encoding. The major novelty of the work is applying complex modulation spectrogram for feature extraction. We evaluate the complex modulation spectrogram as discriminant features, resulting in a 4.7% improvement in comparison with the commonly used Mel spectrogram. These features are computed for individual temporal segments of the audio recording to acquire a representation containing both spectral and temporal structure. Also, we derive a de-noising method which has not been used for ASC before but was beneficial in other speech processing tasks. This method leads to 1.5% improvement in prediction accuracy in comparison with a model without de-noising. The proposed model outperforms the state of the art methods by 7.5% in terms of the prediction accuracy for evaluation data in ASC on the DCASE 2017 dataset.
C1 [Mirzaei, Sayeh] Univ Tehran, Coll Engn, Sch Engn Sci, Tehran, Iran.
   [Jazani, Iman Khani] Amirkabir Univ Technol, Fac Comp Engn, Tehran, Iran.
C3 University of Tehran; Amirkabir University of Technology
RP Mirzaei, S (corresponding author), Univ Tehran, Coll Engn, Sch Engn Sci, Tehran, Iran.
EM s.mirzaei@ut.ac.ir
OI Mirzaei, Sayeh/0000-0003-1174-2280
CR Ahmadi S, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0036-3
   Baby D, 2014, IEEE W SP LANG TECH, P519, DOI 10.1109/SLT.2014.7078628
   Barker T, 2016, IEEE-ACM T AUDIO SPE, V24, P2377, DOI 10.1109/TASLP.2016.2602546
   Barker T, 2013, INTERSPEECH, P827
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chung Y-A, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.00982
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Giannoulis D, 2013, 2013 PROCEEDINGS OF THE 21ST EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO)
   Greenberg S, 1997, INT CONF ACOUST SPEE, P1647, DOI 10.1109/ICASSP.1997.598826
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Phan H, 2017, INTERSPEECH, P3043, DOI 10.21437/Interspeech.2017-101
   Kingsbury BED, 1998, SPEECH COMMUN, V25, P117, DOI 10.1016/S0167-6393(98)00032-6
   Kirbiz S, 2014, SIGNAL PROCESS, V105, P56, DOI 10.1016/j.sigpro.2014.05.019
   Lu Lu, 2018, Wuhan University Journal of Natural Sciences, V23, P178, DOI 10.1007/s11859-018-1308-z
   Masaya S, 2018, SIGNAL PROCESS, V142, P137, DOI 10.1016/j.sigpro.2017.07.013
   Mesaros A, 2017, DCASE 2017 CHALLENGE
   Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424
   Moritz N, 2011, INT CONF ACOUST SPEE, P5492
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Valenti M, 2017, IEEE IJCNN, P1547, DOI 10.1109/IJCNN.2017.7966035
   Wang DZ, 2019, J PHYS CONF SER, V1169, DOI 10.1088/1742-6596/1169/1/012037
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Xie J, 2019, EXPERT SYST APPL, V126, P20, DOI 10.1016/j.eswa.2019.01.085
   Xu JX, 2018, IEEE INT SYM MULTIM, P267, DOI 10.1109/ISM.2018.00038
   Xu KL, 2018, LECT NOTES COMPUT SC, V11166, P14, DOI 10.1007/978-3-030-00764-5_2
   Yang YH, 2019, INT CONF ACOUST SPEE, P840, DOI 10.1109/ICASSP.2019.8683000
   Zeinali H., 2018, Proc. Detection and Classification of Acoustic Scenes and Events (DCASE) Workshop, P202
NR 29
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16395
EP 16408
DI 10.1007/s11042-022-14192-1
EA NOV 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881546800001
DA 2024-07-18
ER

PT J
AU Singh, M
   Shrimali, V
   Kumar, M
AF Singh, Manu
   Shrimali, Vibhakar
   Kumar, Manoj
TI Detection and classification of brain tumor using hybrid feature
   extraction technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto-Encoder Neural Network Classifier; Expectation maximization; MRI;
   Ranklet Transformation; Statistical features; SVMC
ID EXPECTATION-MAXIMIZATION ALGORITHM; STATISTICAL FEATURE-EXTRACTION;
   HISTOGRAM EQUALIZATION; K-MEANS; SEGMENTATION; RANKLET
AB Accurate manual detection of brain tumor by a team of radiologists may be a long and tedious process, and further rely on their skills in the subject. Nowadays various medical imaging modalities are extensively used to minimize the above complexities and enable the patients to live a long and healthy life. This paper mainly focuses on the suspected patients of the brain tumor. A new method for feature extraction has been introduced and the framework for it has been briefed in the following steps. To begin with, a dual segmentation i.e. Fuzzy K-mean and Expectation-Maximization method has been performed consequently. The Ranklet Transformation(+) along with Statistical Feature Analysis, named as hybrid feature extraction has been proposed. Further, two classification techniques have been presented by involving Auto-Encoder Neural Network in addition to Support Vector Machine classifier. Here, Auto-Encoder is trained by using extracted feature vectors, and the resultant is subsequently trained by Support vector machine. Further, testing is performed by Support vector machine classifier. The experiments have been performed by applying BraTS 2013 and BraTS 2015 MRI brain datasets. The performance has been evaluated using various statistical matrices such as Sensitivity, Accuracy, Specificity, F-measure and Matthews's correlation coefficient and found that the suggested model attained the accuracy.
C1 [Singh, Manu] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, New Delhi 110078, India.
   [Shrimali, Vibhakar] GB Pant Govt Engn Coll, Dept Elect & Commun Engn, New Delhi 110020, India.
   [Kumar, Manoj] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun 248007, Uttarakhand, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
C3 GGS Indraprastha University; University of Petroleum & Energy Studies
   (UPES); University of Wollongong
RP Singh, M (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, New Delhi 110078, India.
EM ersinghmanu06@gmail.com; vibhakar.shrimali@gmail.com;
   wss.manojlcurnar@gmail.com
RI Singh, Manu/HPF-7008-2023; Kumar, Manoj/AAL-6474-2021
OI Kumar, Manoj/0000-0003-3733-295X; Singh, Manu/0000-0001-5164-1797
CR Acharya T, 2005, IMAGE PROCESSING: PRINCIPLES AND APPLICATIONS, P1, DOI 10.1002/0471745790
   Alkawaz MH, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P102, DOI [10.1109/CSPA48992.2020.9068731, 10.1109/cspa48992.2020.9068731]
   Amin Javeria, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P983, DOI 10.1007/s12652-018-1092-9
   Amin J, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1483-2
   [Anonymous], 2015, P BRATS CHALLENGE 20
   Ayadi W, 2022, VISUAL COMPUT, V38, P107, DOI 10.1007/s00371-020-02005-1
   Azarmdel H, 2020, POSTHARVEST BIOL TEC, V166, DOI 10.1016/j.postharvbio.2020.111201
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bansal A, 2016, SADHANA-ACAD P ENG S, V41, P507, DOI 10.1007/s12046-016-0492-9
   Berlin L, 1997, AM J ROENTGENOL, V169, P943, DOI 10.2214/ajr.169.4.9308440
   Cai L, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.02.44
   DeAngelis LM, 2001, NEW ENGL J MED, V344, P114, DOI 10.1056/NEJM200101113440207
   Dehariya V. K., 2010, Proceedings of the 2010 International Conference on Computational Intelligence and Communication Networks (CICN 2010), P386, DOI 10.1109/CICN.2010.80
   Dhal KG, 2018, INT J BIOMED ENG TEC, V28, P160
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Dharejo FA, 2021, IET IMAGE PROCESS, V15, P47, DOI 10.1049/ipr2.12004
   Do CB, 2008, NAT BIOTECHNOL, V26, P897, DOI 10.1038/nbt1406
   Fekri-Ershad S, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105392
   Ghaffari M, 2020, IEEE REV BIOMED ENG, V13, P156, DOI 10.1109/RBME.2019.2946868
   Gupta B, 2019, CAAI T INTELL TECHNO, V4, P73, DOI 10.1049/trit.2018.1006
   Gupta T, 2017, Arxiv, DOI arXiv:1710.11309
   Huang X, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419500174
   Huo J, 2012, MACHINE LEARNING IN COMPUTER-AIDED DIAGNOSIS: MEDICAL IMAGING INTELLIGENCE AND ANALYSIS, P297
   Jeyaraj PR, 2019, J CANCER RES CLIN, V145, P829, DOI 10.1007/s00432-018-02834-7
   Joseph J, 2017, BIOCYBERN BIOMED ENG, V37, P489, DOI 10.1016/j.bbe.2016.11.006
   Kang WX, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL II, P703, DOI 10.1109/ETCS.2009.417
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Khelifi F, 2011, IEEE T IMAGE PROCESS, V20, P293, DOI 10.1109/TIP.2010.2052277
   Kleesiek J, 2016, NEUROIMAGE, V129, P460, DOI 10.1016/j.neuroimage.2016.01.024
   Kolb B., 2001, INTRO BRAIN BEHAV, P154
   Kumar N., 2020, Int. J. Adv. Sci. Technol, V29, P1495
   Laha M, 2018, 2018 4 INT C RECENT, P1
   Lahmiri S, 2017, OPT LASER TECHNOL, V90, P128, DOI 10.1016/j.optlastec.2016.11.015
   Lee JH., 2008, MENINGIOMAS DIAGNOSI
   Liu J, 2018, BIG DATA MIN ANAL, V1, P1, DOI 10.26599/BDMA.2018.9020001
   Manju B. R., 2020, Procedia Computer Science, V171, P273, DOI 10.1016/j.procs.2020.04.029
   Masotti M, 2006, MED PHYS, V33, P3951, DOI 10.1118/1.2351953
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nixon M., 2019, Feature extraction and image processing for computer vision
   Pepe MS, 2000, J AM STAT ASSOC, V95, P308, DOI 10.2307/2669554
   Pitas I., 2000, DIGITAL IMAGE PROCES
   Qi JP, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P242, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.46
   Qiao J, 2019, DATA BRIEF, V27, DOI 10.1016/j.dib.2019.104628
   Rahmani MKI, 2014, INT J ADV COMPUT SC, V5, P160
   Ramadhan A, 2017, Arxiv, DOI arXiv:1703.06499
   Raza K, 2018, ARXIV
   Roy S, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P109
   Sagheer SVM, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102036
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Sammaknejad N, 2019, J PROCESS CONTR, V73, P123, DOI 10.1016/j.jprocont.2018.12.010
   Sehgal A, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P104
   Sento Adna., 2016, MANAGEMENT INNOVATIO, pMIT
   Shafiei F, 2020, TRAIT SIGNAL, V37, P1029, DOI 10.18280/ts.370615
   Shah AW, 2022, J KING SAUD UNIV-COM, V34, P505, DOI 10.1016/j.jksuci.2020.03.007
   Shakya Subarna, 2020, J. Innov. Image Process., V2, P44
   Shanker R, 2018, L N COMPUT VIS BIOME, V27, P286, DOI 10.1007/978-3-319-68195-5_31
   Shreffler J., 2021, StatPearls
   Simsek AS, 2018, OPER RES, V66, P748, DOI 10.1287/opre.2017.1692
   Singh M, 2020, 2020 IEEE 17 INDIA C, P1
   Srinivasu PN, 2020, INT J INF SYST MODEL, V11, P74, DOI 10.4018/IJISMD.2020010105
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Suhas S., 2017, 2017 INT C ELECT ELE, P1, DOI DOI 10.1109/ICEECCOT.2017.8284595
   Thaha MM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1416-0
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Trevethan R, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00307
   Umbaugh S.E., 2017, Digital Image Processing and Analysis: Applications with MATLAB and CVIPtools
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Vijay V, 2016, PROCEDIA COMPUT SCI, V92, P475, DOI 10.1016/j.procs.2016.07.370
   Xi XM, 2017, NEUROCOMPUTING, V259, P210, DOI 10.1016/j.neucom.2016.06.082
   Zhang XB, 2016, OPTIK, V127, P6821, DOI 10.1016/j.ijleo.2016.05.002
   Zubair M., 2020, P INT C HYBR INT SYS, P422
NR 72
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21483
EP 21507
DI 10.1007/s11042-022-14088-0
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000880356300002
DA 2024-07-18
ER

PT J
AU Rakshit, P
   Chatterjee, S
   Halder, C
   Sen, S
   Obaidullah, SM
   Roy, K
AF Rakshit, Payel
   Chatterjee, Somnath
   Halder, Chayan
   Sen, Shibaprasad
   Obaidullah, Sk Md
   Roy, Kaushik
TI Comparative study on the performance of the state-of-the-art CNN models
   for handwritten Bangla character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Bangla handwriting recognition; CNN; Ekush dataset
AB In the realm of Optical Character Recognition, handwritten character recognition in Bangla is still an unresolved challenge. There have been many breakthroughs in object recognition technology; however, the present approaches may not necessarily give good results for such problems. In this paper, a set of recently developed popular Convolutional Neural Networks (CNNs) is discussed with their application on Bangla handwritten character recognition for the standard dataset 'Ekush' and the performance of each of the CNN networks is systematically evaluated. It is obvious that the CNN approaches are more effective than traditional approaches because of their ability to generate discriminative features from raw data. The current study shows the superior performance of CNN models with their recognition rate; which in turn implies that CNN networks are practically suitable to build an automatic Bangla handwritten character recognition system.
C1 [Rakshit, Payel] Maheshtala Coll, Kolkata 141, India.
   [Chatterjee, Somnath] Future Inst Engn & Management, Kolkata 154, India.
   [Halder, Chayan] Ramakrishna Mission Vivekananda Centenary Coll, Kolkata 118, India.
   [Sen, Shibaprasad] Techno Main Salt Lake, Kolkata 700091, India.
   [Obaidullah, Sk Md] Aliah Univ, Kolkata 156, India.
   [Roy, Kaushik] West Bengal State Univ, Kolkata 126, India.
C3 Aliah University; West Bengal State University
RP Roy, K (corresponding author), West Bengal State Univ, Kolkata 126, India.
EM prmylife20@gmail.com; somnathchatterjee796@gmail.com;
   chayan.halderz@gmail.com; shibubiet@gmail.com; sk.obaidullah@gmail.com;
   kaushik.mrg@gmail.com
RI Rakshit, Payel/AIE-7535-2022; Roy, Kaushik/O-7021-2019
OI Rakshit, Payel/0000-0002-9006-2437; Halder, Chayan/0000-0002-6113-7284;
   Roy, Kaushik/0000-0002-3360-7576
CR Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Alom MZ, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6747098
   [Anonymous], 2019, INT J COMPUT ACAD RE
   [Anonymous], 2016, ARXIV160603391
   [Anonymous], 2010, J COMPUT
   Basu S, 2009, PATTERN RECOGN, V42, P1467, DOI 10.1016/j.patcog.2009.01.008
   Bhagyasree P. V., 2022, Advances in Micro-Electronics, Embedded Systems and IoT: Proceedings of Sixth International Conference on Microelectronics, Electromagnetics and Telecommunications (ICMEET 2021). Lecture Notes in Electrical Engineering (838), P89, DOI 10.1007/978-981-16-8550-7_10
   Bhattacharya U, 2012, PATTERN ANAL APPL, V15, P445, DOI 10.1007/s10044-012-0278-6
   Bhattacharyya A., 2022, SN COMPUT SCI, V3, P1, DOI DOI 10.1007/S42979-022-01157-2
   Bhowmik TK, 2009, INT J DOC ANAL RECOG, V12, P97, DOI 10.1007/s10032-009-0084-x
   Bin Ahmed S, 2019, NEURAL COMPUT APPL, V31, P1143, DOI 10.1007/s00521-017-3146-x
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Ciresan D, 2015, IEEE IJCNN
   Das A, 2018, INT C PATT RECOG, P3180, DOI 10.1109/ICPR.2018.8545630
   Das N, 2009, PROC INT C SIGNAL IM, P01
   Dey R, 2022, MULTIMED TOOLS APPL, V81, P10469, DOI 10.1007/s11042-022-12148-z
   Phamtoan D, 2021, MULTIMED TOOLS APPL, V80, P35193, DOI 10.1007/s11042-020-09975-3
   Ghosh T, 2019, 2019 INT C BANGLA SP, P1
   Guha R, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420520096
   Gulli A., 2017, Deep learning with Keras
   Halder C, 2015, 2015 5 NATL C COMPUT, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, PREPRINT
   Hu M, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1159, DOI 10.1145/3132847.3132962
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Indian A., 2022, Cyber Security in Intelligent Computing and Communications, P129, DOI 10.1007/978-981-16-8012-0_11
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Islam MS, 2022, MULTIMED TOOLS APPL, V81, P10631, DOI 10.1007/s11042-022-12070-4
   KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901
   Kaur H, 2021, MULTIMED TOOLS APPL, V80, P11155, DOI 10.1007/s11042-020-10297-7
   Kaur H, 2021, SOFT COMPUT, V25, P4451, DOI 10.1007/s00500-020-05455-w
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, INT C DEEP LEARN ART, P153
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar KP, 2017, ADV BUS STRATEGY COM, P1, DOI 10.4018/978-1-5225-1008-6.ch001
   Kumar S, 2018, IEEE IND APPLIC SOC
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Lincy Babitha., 2020, MULTIMED TOOLS APPL, V10, P1
   Malarvizhi N, 2020, MULTIMED TOOLS APPL, V79, P9131, DOI 10.1007/s11042-019-7436-4
   Mushtaq F, 2021, NEURAL COMPUT APPL, V33, P15229, DOI 10.1007/s00521-021-06144-x
   Narang SR, 2021, MULTIMED TOOLS APPL, V80, P20671, DOI 10.1007/s11042-021-10775-6
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A., 2021, Computational Intelligence and Healthcare Informatics, P255
   Negi A., 2021, Data Science and Its Applications, P63
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Obaidullah SM, 2018, MULTIMED TOOLS APPL, V77, P1643, DOI 10.1007/s11042-017-4373-y
   Obaidullah SM, 2016, ADV INTELL SYST, V404, P233, DOI 10.1007/978-81-322-2695-6_21
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Rabby AKMSA, 2018, PROCEDIA COMPUT SCI, V143, P603, DOI 10.1016/j.procs.2018.10.437
   Rabby ASA, 2018, RECENT TRENDS IMAGE, P149
   Rakshit P, 2021, RECENT TRENDS IMAGE, P511
   Rakshit P, 2019, APPROACH CHARACTER R, P15, DOI [10.1201/9780429277573-2, DOI 10.1201/9780429277573-2]
   Ren HQ, 2019, PATTERN RECOGN, V93, P179, DOI 10.1016/j.patcog.2019.04.015
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Roy A, 2012, 2012 IEEE INT C ENG, P1
   Roy S, 2017, PATTERN RECOGN LETT, V90, P15, DOI 10.1016/j.patrec.2017.03.004
   Sachdeva Juhee, 2022, Proceedings of Data Analytics and Management: ICDAM 2021. Lecture Notes on Data Engineering and Communications Technologies (90), P211, DOI 10.1007/978-981-16-6289-8_18
   Saha Sourajit, 2018, Procedia Computer Science, V132, P1760, DOI 10.1016/j.procs.2018.05.151
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarkhel R, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P325, DOI 10.1109/ReTIS.2015.7232899
   Sen S, 2017, ADV INTELL SYST, V458, P485, DOI 10.1007/978-981-10-2035-3_50
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Shuvo Shifat Nayme, 2021, Soft Computing Techniques and Applications. Proceedings of the International Conference on Computing and Communication (IC3 2020). Advances in Intelligent Systems and Computing (AISC 1248), P515, DOI 10.1007/978-981-15-7394-1_47
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh H, 2021, SOFT COMPUT, V25, P6329, DOI 10.1007/s00500-021-05620-9
   Singh P, 2016, STUD FUZZ SOFT COMP, V330, P1, DOI 10.1155/2016/2796863
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Ukil S, 2020, NEURAL COMPUT APPL, V32, P2829, DOI 10.1007/s00521-019-04111-1
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 77
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16929
EP 16950
DI 10.1007/s11042-022-13909-6
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000877437000003
DA 2024-07-18
ER

PT J
AU Mandeel, AR
   Al-Radhi, MS
   Csapó, TG
AF Mandeel, Ali Raheem
   Al-Radhi, Mohammed Salah
   Csapo, Tamas Gabor
TI Investigations on speaker adaptation using a continuous vocoder within
   recurrent neural network based text-to-speech synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech synthesis; RNN; TTS; Continuous vocoder
AB This paper presents an investigation of speaker adaptation using a continuous vocoder for parametric text-to-speech (TTS) synthesis. In purposes that demand low computational complexity, conventional vocoder-based statistical parametric speech synthesis can be preferable. While capable of remarkable naturalness, recent neural vocoders nonetheless fall short of the criteria for real-time synthesis. We investigate our former continuous vocoder, in which the excitation is characterized employing two one-dimensional parameters: Maximum Voiced Frequency and continuous fundamental frequency (F0). We show that an average voice can be trained for deep neural network-based TTS utilizing data from nine English speakers. We did speaker adaptation experiments for each target speaker with 400 utterances (approximately 14 minutes). We showed an apparent enhancement in the quality and naturalness of synthesized speech compared to our previous work by utilizing the recurrent neural network topologies. According to the objective studies (Mel-Cepstral Distortion and F0 correlation), the quality of speaker adaptation using Continuous Vocoder-based DNN-TTS is slightly better than the WORLD Vocoder-based baseline. The subjective MUSHRA-like test results also showed that our speaker adaptation technique is almost as natural as the WORLD vocoder using Gated Recurrent Unit and Long Short Term Memory networks. The proposed vocoder, being capable of real-time synthesis, can be used for applications which need fast synthesis speed.
C1 [Mandeel, Ali Raheem; Al-Radhi, Mohammed Salah; Csapo, Tamas Gabor] Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Budapest, Hungary.
C3 Budapest University of Technology & Economics
RP Mandeel, AR (corresponding author), Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Budapest, Hungary.
EM aliraheem.mandeel@edu.bme.hu; malradhi@tmit.bme.hu; csapot@tmit.bme.hu
RI Al-Radhi, Mohammed Salah/C-9727-2018
OI Al-Radhi, Mohammed Salah/0000-0003-3094-6916; Mandeel, Ali
   Raheem/0000-0003-4188-2196; Csapo, Tamas Gabor/0000-0003-4375-7524
FU APH-ALARM project - European Commission [2019-2.1.2-NEMZ-2020-00012];
   National Research, Development and Innovation Office of Hungary;
   European Union [RRF-2.3.1-21-2022-00004]; Ministry of Innovation and
   Technology; National Research, Development and Innovation Office; Bolyai
   Janos Research Fellowship of the Hungarian Academy of Sciences; New
   National Excellence Program of the Ministry for Innovation and
   Technology [uNKP-21-5, uNKP-21-5-BME-352]
FX The research was partially sponsored by the APH-ALARM project (contract
   2019-2.1.2-NEMZ-2020-00012), funded by the European Commission and the
   National Research, Development and Innovation Office of Hungary and
   supported by the European Union project RRF-2.3.1-21-2022-00004 within
   the framework of the Artificial Intelligence National Laboratory. The
   research reported in this publication, carried out by the Department of
   Telecommunications and Media Informatics Budapest University of
   Technology and Economic and IdomSoft Ltd., was supported by the Ministry
   of Innovation and Technology and the National Research, Development and
   Innovation Office within the framework of the National Laboratory of
   Infocommunication and Information Technology. Tamas Gabor Csapo's
   research was supported by the Bolyai Janos Research Fellowship of the
   Hungarian Academy of Sciences and by the uNKP-21-5 (identifier:
   uNKP-21-5-BME-352) New National Excellence Program of the Ministry for
   Innovation and Technology from the source of the National, Research,
   Development and Innovation Fund. The Titan X GPU used was donated by
   NVIDIA Corporation. We would like to thank the subjects for
   participating in the listening test.
CR Al-Radhi MS, 2021, MULTIMED TOOLS APPL, V80, P1969, DOI 10.1007/s11042-020-09783-9
   Al-Radhi MS, 2019, MULTIMED TOOLS APPL, V78, P33549, DOI 10.1007/s11042-019-08198-5
   Al-Radhi MS, 2020, COMPUT SPEECH LANG, V60, DOI 10.1016/j.csl.2019.101025
   Al-Radhi MS, 2017, INTERSPEECH, P434, DOI 10.21437/Interspeech.2017-678
   [Anonymous], 2001, ITU-R Recommendations
   Atkar G, 2021, NEURAL COMPUT APPL, V33, P9353, DOI 10.1007/s00521-021-05695-3
   Babacan Onur, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2564, DOI 10.1109/ICASSP.2014.6854063
   Bollepalli B, 2019, SPEECH COMMUN, V110, P64, DOI 10.1016/j.specom.2019.04.008
   Casanova E, 2021, INTERSPEECH, P3645, DOI 10.21437/Interspeech.2021-1774
   Chen B, 2022, IEEE-ACM T AUDIO SPE, V30, P1993, DOI 10.1109/TASLP.2022.3171971
   Chen MJ, 2020, INTERSPEECH, P4024, DOI 10.21437/Interspeech.2020-3139
   Chen Y., 2019, INT C LEARNING REPRE
   Choi S, 2020, INTERSPEECH, P2007, DOI 10.21437/Interspeech.2020-2096
   Csapó TG, 2016, EUR SIGNAL PR CONF, P1338, DOI 10.1109/EUSIPCO.2016.7760466
   Dai DY, 2022, INT CONF ACOUST SPEE, P8322, DOI 10.1109/ICASSP43922.2022.9747319
   Degottex G, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0038-1
   Fan Y., 2014, INTERSPEECH
   Luong HT, 2018, IEEE W SP LANG TECH, P610, DOI 10.1109/SLT.2018.8639659
   Hinterleitner F, 2017, QUALITY SYNTHETIC SP, P5, DOI DOI 10.1007/978-981-10-3734-4
   Hu QT., 2013, The mechanical mechanism of coal and gas outburst
   Jia Y., 2018, ARXIV
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Latif S, 2021, IEEE REV BIOMED ENG, V14, P342, DOI 10.1109/RBME.2020.3006860
   Lee JH, 2022, INT CONF ACOUST SPEE, P6312, DOI 10.1109/ICASSP43922.2022.9747388
   Li XX, 2021, COMPUT ELECTRON AGR, V180, DOI 10.1016/j.compag.2020.105908
   Luong HT, 2020, IEEE-ACM T AUDIO SPE, V28, P2967, DOI 10.1109/TASLP.2020.3034994
   Mandeel AR., 2021, SPECOM LECT NOTES CO, V12997
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   Ning YS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194050
   Oord A., 2016, ARXIV160903499
   Ping Wei, 2018, ARXIV180707281
   Prenger R, 2019, INT CONF ACOUST SPEE, P3617, DOI [10.1109/ICASSP.2019.8683143, 10.1109/icassp.2019.8683143]
   Quatieri T.F., 2006, Discrete-Time Speech Signal Processing: Principles and Practice, V1st
   Rao MVA, 2020, IEEE SIGNAL PROC LET, V27, P1170, DOI 10.1109/LSP.2020.3005031
   Schnell B, 2022, SPEECH COMMUN, V138, P26, DOI 10.1016/j.specom.2021.12.002
   Senior Andrew, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P225, DOI 10.1109/ICASSP.2014.6853591
   Silvestri R, 2022, J SPEC EDUC TECHNOL, V37, P498, DOI 10.1177/01626434211033577
   Tachibana K., 2020, SPEECH TO SPEECH TRA, P39
   Takaki S., 2016, 9 ISCA SPEECH SYNTHE, P153, DOI [10.21437/SSW.2016-25, DOI 10.21437/SSW.2016-25]
   Tejedor-García C, 2020, IEEE T LEARN TECHNOL, V13, P269, DOI 10.1109/TLT.2020.2980261
   Veaux C., 2016, CSTR VCTK corpus: English multi-speaker corpus for CSTR voice cloning toolkit
   Wang X, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4804, DOI 10.1109/ICASSP.2018.8461452
   Wu Z., 2016, SSW, P202, DOI DOI 10.21437/SSW.2016-33
   Wu ZZ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P879
   Wu ZZ, 2015, INT CONF ACOUST SPEE, P4460, DOI 10.1109/ICASSP.2015.7178814
   Xie X, 2021, IEEE-ACM T AUDIO SPE
   Xue SF, 2014, IEEE-ACM T AUDIO SPE, V22, P1713, DOI 10.1109/TASLP.2014.2346313
   Yang S, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P685, DOI 10.1109/ASRU.2017.8269003
   Zhang HT, 2022, INT CONF ACOUST SPEE, P8317, DOI 10.1109/ICASSP43922.2022.9746233
NR 49
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15635
EP 15649
DI 10.1007/s11042-022-14005-5
EA OCT 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000871167100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Bhardwaj, R
AF Bhardwaj, Rupali
TI An improved reversible data hiding method in encrypted domain for
   E-healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Lattice formation; Electronic patient
   information (EPI); Privacy protection
ID HIGH-CAPACITY; IMAGES; DIFFERENCE
AB In current scenario, patient data privacy and security is one of the most significant challenge for telemedicine applications. A minute change to Electronic Patient Information (EPI) may result in wrong diagnosis to the patient. With the aim to ensure secure and safe communications for telemedicine applications, an enhanced reversible data hiding technique in encrypted domain to embed secret message in hexadecimal form by embedding four binary bits of EPI in each block of cover image has been presented in this paper. The proposed algorithm has not been suffering from underflow and overflow problem so that empowering it to embed and recover information precisely from low intensity pixels too. This property makes our proposed methodology truly reasonable for its utilization on medical images. For all test images, the proposed methodology beated all the compared methodologies in its embedding capability with maintaining the visual quality of stego images too.
C1 [Bhardwaj, Rupali] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bhardwaj, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rupali.bhardwaj@thapar.edu
CR Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Kumar A., 2021, Res. Biomed. Eng, V37, P79, DOI [10.1007/s42600-020-00108-1, DOI 10.1007/S42600-020-00108-1]
   Kumar A.A., 2020, IEEE SENS J
   Kumar A, 2019, INT J CIRC THEOR APP, V47, P1459, DOI 10.1002/cta.2667
   Kumar A, 2018, ISA T, V79, P239, DOI 10.1016/j.isatra.2018.05.003
   Kumar A, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0953-2
   Kumar A, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0886-1, 10.1515/joc-2018-0071]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Shiu HJ, 2017, COMPUT METH PROG BIO, V151, P159, DOI 10.1016/j.cmpb.2017.08.015
   Tai WL, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010023
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao B, 2010, IEEE ICC
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 32
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16151
EP 16171
DI 10.1007/s11042-022-13905-w
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000870100200001
DA 2024-07-18
ER

PT J
AU Qayyum, M
   Yu, YY
   Bhatti, UA
   Li, SJ
AF Qayyum, Muhammad
   Yu Yuyuan
   Bhatti, Uzair Aslam
   Li Shijie
TI Evaluation of the one belt and one road (OBOR) in economic development
   and suggestions analysis based on SWOT analysis with weighted AHP and
   entropy methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE One belt one road (OBOR); SWOT decision making; AHP; Entropy
ID CHINA ONE BELT; DECISION-MAKING; PROJECT; TRADE
AB The "One Belt, One Road" (OBOR) initiative has had a profound impact on promoting the building of a community with a shared future for mankind and plays a vital rule in achieving the sustainable development goals (SDG) of 2030. So far there is no evaluation model proposed to study the impact of OBOR current progress and identify the risk factors of this model. For this purpose, a hybrid evaluation model was developed using SWOT (strengths, weaknesses, opportunities, and threats) for decision-making, which used quality factor and risk factor weights from an analytic hierarchy process (AHP) and entropy method. The questionnaires were used to quantify the SWOT factors, which were filled by business owners in the OBOR initiative, faculty members and students who have major in trade, finance, and economics from different countries. Weights from AHP and entropy helped to rank different variables according to importance and risk, which helps decision-makers to consider these factors while becoming a part of the OBOR initiative. These factors also help current enterprises, experts, business owners and governments of different countries to decide on which factors they need to focus, and which factors they need to avoid. The SWOT matrix helps to find the strong zone area, which needs to be focused on by all stakeholders who are a part of the OBOR or are a part of the OBOR initiative.
C1 [Qayyum, Muhammad] Guangzhou Univ, Sch Econ & Stat, Guangzhou, Guangdong, Peoples R China.
   [Yu Yuyuan] City Univ Hong Kong, Dept Econ & Finance, Hong Kong, Peoples R China.
   [Bhatti, Uzair Aslam] Hainan Univ, Sch Informat & Commun Engn, Haikou, Hainan, Peoples R China.
   [Li Shijie] Hainan Univ, Sch Econ, Haikou 570228, Hainan, Peoples R China.
C3 Guangzhou University; City University of Hong Kong; Hainan University;
   Hainan University
RP Qayyum, M (corresponding author), Guangzhou Univ, Sch Econ & Stat, Guangzhou, Guangdong, Peoples R China.
EM qayyum2494@gmail.com; yuyuanyu2-c@my.cityu.edu.hk;
   uzairaslambhatti@hotmail.com; lshijie@foxmail.com
RI Yu, Yuyuan/CAA-2731-2022
OI Yu, Yuyuan/0000-0002-0912-4881
CR Abdulsalam A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041623
   Ahmad F, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103520
   AHMED S, 2020, REGIONAL MULTILATERA
   Ali Y, 2019, ADV ENG INFORM, V40, P36, DOI 10.1016/j.aei.2019.03.005
   [Anonymous], 2016, ECONOMIST 0702
   [Anonymous], 2017, CHINAS PRESENCE MIDD
   [Anonymous], 2018, GOVT ANN RES J POLIT
   Bartosiewicz A, 2019, INT J LOGIST-RES APP, V22, P47, DOI 10.1080/13675567.2018.1526261
   Benintendi R., 2020, Sustain. Futures, V2, P100009, DOI [10.1016/j.sftr.2020.100009, DOI 10.1016/J.SFTR.2020.100009]
   Binghui, 2017, LOGISTICS TECHNOLOGY, V02
   BRYSON JM, 1987, J AM PLANN ASSOC, V53, P9, DOI 10.1080/01944368708976631
   Chaisse J, 2018, J WORLD TRADE, V52, P163
   Chen HP, 2016, TRANSNATL CORP REV, V8, P178, DOI 10.1080/19186444.2016.1233722
   Chen M.W., 2019, The Global Economic Recovery 10 Years after the 2008 Financial Crisis
   Cunningham JA, 2019, PILOT FEASIBILITY ST, V5, DOI 10.1186/s40814-019-0411-z
   Dave B, 2018, ASIA EUR J, V16, P267, DOI 10.1007/s10308-018-0513-x
   Deng YL, 2019, J PHYS CONF SER, V1176, DOI 10.1088/1742-6596/1176/4/042093
   Dimitrijevic D, 2018, EDITIORS BOARD, V68
   Dimitrova T, 2017, EVALUATING STRATEGIC
   Dos Santos L. M., 2018, Silk Road to Belt Road, P175
   Dossou T.A.M., 2018, IMPACT CHINAS ONE BE
   Du JL, 2018, CHINA ECON REV, V47, P189, DOI 10.1016/j.chieco.2017.05.010
   El Bernoussi Z, 2021, MUSLIM MINOR, V37, P108, DOI 10.1163/9789004459236_006
   Elfil M, 2017, EMERGENCY, V5
   Enderwick P, 2018, STRATEG CHANG, V27, P447, DOI 10.1002/jsc.2229
   Fahim A, 2021, IEEE ACCESS, V9, P76991, DOI 10.1109/ACCESS.2021.3082144
   Ferdinand P, 2016, INT AFF, V92, P941, DOI 10.1111/1468-2346.12660
   Foo N, 2020, N AM J ECON FINANC, V54, DOI 10.1016/j.najef.2019.101089
   Gao XP, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9081439
   Giirel Emet, 2017, Journal of International Social Research, V10, P994, DOI DOI 10.17719/JISR.2017.1832
   Gong S. J., 2019, IMPACT BELT ROAD INI
   Gong X, 2019, PAC REV, V32, P635, DOI 10.1080/09512748.2018.1513950
   Gootiiz B, 2009, J WORLD TRADE, V43, P1013
   Horesh N, 2018, DURH MOD MID E ISLAM, P1
   Hu AG, 2017, CHINA WOR, V4, P164, DOI 10.1163/9789004330818_012
   Hu N, 2019, J CONT ED RES, V3
   Hu RW, 2017, CHINA REP, V53, P107, DOI 10.1177/0009445517696619
   Huang WZ, 2015, INT C ED MANAGEMENT
   Kazi, 2017, P CPEC C
   Khachatryan A., 2011, IMF Working Paper No. 11/16
   Lee CH, 2016, FINANC INNOV, V2, DOI 10.1186/s40854-016-0022-0
   Li K.K., 2018, MODERN EC, V9, P1213, DOI DOI 10.4236/ME.2018.97079
   Li LQ., 2018, J TRANSP ENG INF, V16, P69
   Li Wei, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P953, DOI 10.1109/PACIIA.2008.125
   Lin KP, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10010005
   Liu HQ, 2017, CROAT INT RELAT REV, V23, P129, DOI 10.1515/cirr-2017-0010
   Ma H, 2019, ONE BELT ONE ROAD IM
   Nikjow MA, 2021, J RISK FINANC MANAG, V14, DOI 10.3390/jrfm14030092
   Rahman SaifUr., 2017, ARTS SOCIAL SCI J, V08, DOI DOI 10.4172/2151-6200.1000284
   Rauf A, 2020, J CLEAN PROD, V262, DOI 10.1016/j.jclepro.2020.121344
   Rauf A, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10082743
   Saaty Thomas L., 2001, P 6 ISAHP
   Saaty TL, 2003, EUR J OPER RES, V145, P85, DOI 10.1016/S0377-2217(02)00227-8
   Saner R, 2019, SUSTAIN SCI, V14, P1685, DOI 10.1007/s11625-019-00655-2
   Sarker I.N., 2018, J SOCIAL SCI, V6, P119, DOI [10.4236/jss.2018, DOI 10.4236/JSS.2018]
   Saud S, 2020, J CLEAN PROD, V250, DOI 10.1016/j.jclepro.2019.119518
   Shah AR, 2018, ASIA PAC POLICY STU, V5, P378, DOI 10.1002/app5.224
   Sheng B., 2016, NANKAI J PHILOS LITE, V1, P52
   Sheng J, 2018, P 8 INT NASD C EC LE, V14
   Si Xu, 2017, CHINESE STUD HIST, V6, P108, DOI [10.4236/chnstd.2017.62010, DOI 10.4236/CHNSTD.2017.62010]
   Siddiqui K, 2019, INT CRIT THOUGHT, V9, P214, DOI 10.1080/21598282.2019.1613921
   Solmecke U., 2016, The Copenhagen Journal of Asian Studies, V34, P9, DOI [10.22439/cjas.v34i2.5304, DOI 10.22439/CJAS.V34I2.5304]
   Tsalis TA, 2020, CORP SOC RESP ENV MA, V27, P1617, DOI 10.1002/csr.1910
   Wang ED, 2017, ENERGY, V125, P197, DOI 10.1016/j.energy.2017.02.131
   Wang K., 2020, DEV STUDIES REGIONAL, P221, DOI [10.1007/978-981-15-1435-7_13, DOI 10.1007/978-981-15-1435-7_13]
   Wang Q, 2020, ENVIRON IMPACT ASSES, V81, DOI 10.1016/j.eiar.2019.106356
   Wu J, 2011, EXPERT SYST APPL, V38, P5162, DOI 10.1016/j.eswa.2010.10.046
   Xue M, 2019, SWOT ANAL HEILONGJIA
   Yang B, 2021, ENERGY, V215, DOI 10.1016/j.energy.2020.119130
   Yang GJ, 2020, CHINA ECON REV, V60, DOI 10.1016/j.chieco.2020.101418
   Yii KJ, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10114131
   Yu H, 2017, J CONTEMP CHINA, V26, P353, DOI 10.1080/10670564.2016.1245894
   Zhang W, 2020, EUROPEAN P SOCIAL BE, P624
   Zhang ZX, 2018, CHINA Q INT STRATEG, V4, P327, DOI 10.1142/S2377740018500240
   Zheng JL, 2019, ONE EARTH, V1, P240, DOI 10.1016/j.oneear.2019.10.007
   Zhou P, 2019, BELT ROAD STRATEGY I, P164
NR 76
TC 4
Z9 4
U1 4
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14985
EP 15006
DI 10.1007/s11042-022-13565-w
EA OCT 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000869613100002
DA 2024-07-18
ER

PT J
AU Siqueira, ES
   Fleury, MC
   Lamar, MV
   Drachen, A
   Castanho, CD
   Jacobi, RP
AF Siqueira, Elton Sarmanho
   Fleury, Marcos Cordeiro
   Lamar, Marcus Vinicius
   Drachen, Anders
   Castanho, Carla Denise
   Jacobi, Ricardo Pezzuol
TI An automated approach to estimate player experience in game events from
   psychophysiological data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Player experience; Psychophysiological data; Games; Biometric sensors;
   Machine learning; Emotion classification
ID EMOTION RECOGNITION; AROUSAL
AB Games User Research (GUR) is a relevant field of research that exploits knowledge on human-computer interaction, game design, and psychology, with a focus on improving the player experience (PX) and the quality of the game. Games form an environment of rich interactions which can lead to a variety of experiences for the player. Researchers employ new ways to assess PX over time with some degree of precision, while avoiding the interruption of gameplay. A possible way of attaining great PX evaluation can be using psychophysiological data. It is a source that can provide relevant details about the emotional states and a potential information in the context of GUR. This paper presents a process for classifying PX in games based on psychophysiological data acquired from the user during the gameplay. Biosensors and a webcam were employed to capture three signals: Galvanic Skin Response (GSR), Blood Volume Pulse (BVP) and Facial Expression. Our artificial neural network was trained with a dataset formed by psychophysiological data and human-annotated emotional expressions derived from assessment and judgment of players' face and behavior with the help of an emotion annotation tool. Four classes of emotions, derived from the most significant game events, are considered for classification: Anger, Calm, Happiness and Sadness. The experimental results indicate that the proposed method leads to good human emotion recognition, and an accuracy score of 64%. The automatic assessment of player experience was compared with a traditional evaluation based on self-report, corroborating the effectiveness of the method.
C1 [Siqueira, Elton Sarmanho; Drachen, Anders] Univ York, Dept Comp Sci, York, N Yorkshire, England.
   [Fleury, Marcos Cordeiro; Lamar, Marcus Vinicius; Castanho, Carla Denise; Jacobi, Ricardo Pezzuol] Univ Brasilia, Dept Comp Sci, Brasilia, DF, Brazil.
C3 University of York - UK; Universidade de Brasilia
RP Siqueira, ES (corresponding author), Univ York, Dept Comp Sci, York, N Yorkshire, England.
EM eltonsarmanho@gmail.com; marcoscfleury@outlook.com; lamar@unb.br;
   anders.drachen@york.ac.uk; carlacastanho@unb.br; jacobi@unb.br
RI Drachen, Anders/L-4690-2017
OI Drachen, Anders/0000-0002-1002-0414; Sarmanho, Elton/0000-0002-2199-1910
CR Alhassan S, 2017, LECT NOTES COMPUT SC, V10283, P32, DOI 10.1007/978-3-319-58562-8_3
   AlZoubi O, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03367-7
   [Anonymous], 2015, Data Mining and Predictive Analytics
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   Bernhard W, 2014, TORCS: The open racing car simulator
   Bizzego A, 2017, BIORXIV, DOI 10.1101/118943
   Bizzego A, 2019, SOFTWAREX, V10, DOI 10.1016/j.softx.2019.100287
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Brockmyer JH, 2009, J EXP SOC PSYCHOL, V45, P624, DOI 10.1016/j.jesp.2009.02.016
   Cacioppo J, 2016, HDB PSYCHOPHYSIOLOGY, DOI [10.1017/9781107415782https://doi.org/10.1017/9781107415782, DOI 10.1017/9781107415782HTTPS://DOI.ORG/10.1017/9781107415782]
   Cacioppo JT, 1999, ANNU REV PSYCHOL, V50, P191, DOI 10.1146/annurev.psych.50.1.191
   Cai J, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, VOL 1, PROCEEDINGS, P497, DOI 10.1109/ITCS.2009.108
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Cattell R. B., 1978, The scientific use of factor analysis in behavioral life sciences
   Chanel Guillaume, 2020, Augmented Cognition. Theoretical and Technological Approaches. 14th International Conference, AC 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12196), P3, DOI 10.1007/978-3-030-50353-6_1
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chang CY, 2009, CIBCB: 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P278
   Cheng B, 2012, ADV INTEL SOFT COMPU, V114, P49
   Cuthbert BN, 2000, BIOL PSYCHOL, V52, P95, DOI 10.1016/S0301-0511(99)00044-7
   Davidson RJ, 2003, BRAIN COGNITION, V52, P129, DOI 10.1016/S0278-2626(03)00015-0
   Dorner R, 2016, PLAYER EXPERIENCE
   Drachen A., 2018, GAMES USER RES, P333, DOI DOI 10.1093/OSO/9780198794844.003.0019
   Drachen A., 2010, Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games, P49, DOI DOI 10.1145/1836135.1836143
   Drachen A., 2013, GAMES ANAL MAXIMIZIN, P13
   Drenikow B, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102089
   Drioli C, 2015, SIMPLE VIDEO CODER F, P1563, DOI [10.3758/s13428-016-0787-0.The, DOI 10.3758/S13428-016-0787-0.THE]
   El-nasr MS., 2013, Game Analytics, DOI [DOI 10.1007/978-1-4471-4769-5, 10.1007/978-1-4471-4769-5]
   Empatica, 2019, REAL TIM PHYS SIGN E
   Fairclough SH, 2006, BIOL PSYCHOL, V71, P100, DOI 10.1016/j.biopsycho.2005.03.007
   Granato M, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P19, DOI 10.1145/3284869.3284895
   Guardini P, 2013, GAME ANAL, P325, DOI DOI 10.1007/978-1-4471-4769-5_16
   Guardini P., 2013, BETTER GAME EXPERIEN, P325, DOI [10.1007/978-1-4471-4769-5set minus_16, DOI 10.1007/978-1-4471-4769-5]
   Harmon-Jones C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159915
   Haykin S., 2009, NEURAL NETWORKS LEAR
   Huynh S, 2016, P 14 ANN INT C MOBIL, P104, DOI [10.1145/2938559.2938576, DOI 10.1145/2938559.2938576]
   Inc E, 2018, REAL TIM PHYS SIGN E
   Isbister K., 2008, Using biometric measurement to help develop emotionally compelling games, P187, DOI DOI 10.1016/B978-0-12-374447-0.00013-5
   Isbister K., 2008, Game usability: Advice from the experts for advancing the player experience, V1st, DOI [10.1201/b14580, DOI 10.1201/B14580]
   Jain L. C., 1995, Proceedings. Electronic Technology Directions to the Year 2000, P36, DOI 10.1109/ETD.1995.403491
   Keltner D, 2019, COGNITION EMOTION, V33, P14, DOI 10.1080/02699931.2019.1574397
   Kharat Govind U., 2008, 2008 Conference on Human System Interactions, P422, DOI 10.1109/HSI.2008.4581476
   Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719
   Kivikangas JM, 2011, J GAMING VIRTUAL WOR, V3, P181, DOI 10.1386/jgvw.3.3.181_1
   Kramer RSS, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202655
   Kuppens P, 2019, COGNITION EMOTION, V33, P20, DOI 10.1080/02699931.2018.1536037
   Kushki A, 2011, PHYSIOL MEAS, V32, P1529, DOI 10.1088/0967-3334/32/10/002
   Maier M, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P2108
   Mandryk R.L., 2016, Biometrics in a data driven world: trends, technologies, and challenges, P191, DOI DOI 10.1201/9781315317083-7
   Mandryk RL, 2007, INT J HUM-COMPUT ST, V65, P329, DOI 10.1016/j.ijhcs.2006.11.011
   Mandryk RL, 2006, BEHAV INFORM TECHNOL, V25, P141, DOI 10.1080/01449290500331156
   Marshall C., 2014, DESIGNING QUALITATIV, DOI DOI 10.1080/12460125.2022.2074650
   McAllister G, 2015, HUM-COMPUT INT-SPRIN, P11, DOI 10.1007/978-3-319-15985-0_2
   McGrath C, 2019, MED TEACH, V41, P1002, DOI 10.1080/0142159X.2018.1497149
   McMahan T, 2015, ENTERTAIN COMPUT, V7, P1, DOI 10.1016/j.entcom.2015.03.001
   Medler B., 2013, Game Analytics: Maximizing the Value of Player Data, P403, DOI [DOI 10.1007/978-1-4471-4769-5_18, 10.1007/978-1-4471-4769-5, DOI 10.1007/978-1-4471-4769-5]
   Mejía S, 2016, AV PSICOL LATINOAM, V34, P205, DOI 10.12804/apl34.2.2016.02
   Mirza-Babaei P, 2014, THESIS U SUSSEX
   Mirza-Babaei Pejman., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13, P1499
   Myers J. L., 2010, RES DESIGN STAT ANAL
   Nacke L., 2013, INTRO PHYSL PLAYER M
   Nacke L.E., 2018, Games User Research, P281, DOI DOI 10.1093/OSO/9780198794844.003.0016
   Nacke L. E., 2011, P 2 INT WORKSH EV PL
   Nacke LE, 2015, HUM-COMPUT INT-SPRIN, P63, DOI 10.1007/978-3-319-15985-0_4
   Orero J.O., 2010, Proceedings of the International Conference on Kansei Engineering and Emotion Research, P1684
   Park B.-J., 2011, 2011 2nd International Conference on Engineering and Industries (ICEI), P1
   Paul E, 2005, BASIC EMOTIONS, P45, DOI [10.1002/0470013494.ch3, DOI 10.1002/0470013494.CH3]
   Plux, 2016, BIT ED SENS DAT
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Quandt T., 2013, MULTIPLAYER OCIAL AS, DOI [10.4324/9780203627488, DOI 10.4324/9780203627488]
   Roohi S, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P301, DOI 10.1145/3311350.3347197
   Roohi S, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P429, DOI 10.1145/3242671.3242701
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   Santhosh S., 2013, TELEMETRY ANAL BEST
   Sarmanho E, 2018, SBGAMES 2018 COMPUTI
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Siegert I, 2014, J MULTIMODAL USER IN, V8, P17, DOI 10.1007/s12193-013-0129-9
   Soares R, 2017, BRAZIL SYMP GAME DIG, P56, DOI 10.1109/SBGames.2017.00015
   Tan C.T., 2014, P 2014 C INTERACTIVE, DOI DOI 10.1145/2677758.2677765
   Tognetti S., 2010, Proceedings of the 3rd international workshop on Affective interaction in natural environments - AFFINE'10 p, P3, DOI DOI 10.1145/1877826.1877830
   Unluturk MS, 2009, P 10 WSEAS INT C NEU
   Valenza G, 2012, IEEE T AFFECT COMPUT, V3, P237, DOI 10.1109/T-AFFC.2011.30
   Vieira L., 2017, THESIS U SAO PAULO, DOI [10.11606/T.45.2017.tde-05072017-212226, DOI 10.11606/T.45.2017.TDE-05072017-212226]
   Vieira LC, 2017, COGN SYST RES, V41, P130, DOI 10.1016/j.cogsys.2016.09.007
   Wallner G, 2013, ENTERTAIN COMPUT, V4, P143, DOI 10.1016/j.entcom.2013.02.002
   Wallner G, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300593
   Weedon B., 2013, GAME ANAL, P515, DOI [10.1007/978-1-4471-4769-5_23, DOI 10.1007/978-1-4471-4769-523]
   Witten IH, 2011, DATA MINING PRACTICA, V54, DOI [10.1002/1521-3773(20010316)40:6&LANGBRAC;9823::AID-ANIE98233.3.CO;2-C, DOI 10.1002/1521-3773(20010316)40:6&LANGBRAC;9823::AID-ANIE9823]
   Yang Y, 2018, INT POW ELEC APPLICA, P7
   Yannakakis GN, 2008, USER MODEL USER-ADAP, V18, P207, DOI 10.1007/s11257-007-9036-7
   Zalabarria U, 2017, ADV INTELL SYST, V527, P301, DOI 10.1007/978-3-319-47364-2_29
NR 91
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19189
EP 19220
DI 10.1007/s11042-022-13845-5
EA OCT 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000874060500005
DA 2024-07-18
ER

PT J
AU Patil, KT
   Bhavsar, RP
   Pawar, BV
AF Patil, Kavita T.
   Bhavsar, R. P.
   Pawar, B., V
TI Contrastive study of minimum edit distance and cosine similarity
   measures in the context of word suggestions for misspelled Marathi words
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Spelling checking; Error correction;
   Minimum edit distance; Cosine similarity
ID SEARCH
AB Spelling errors are fundamental errors in text writing. The digital era has added another dimension called keyboard layout to this problem. Memorization, language orthography, and keyboard layout are sources of spelling errors in electronic texts. English is being the linked language of the world, good quantum of work towards the spelling error detection and plausible suggestions has been done for English language. But it is not the case for digital resources scarce languages like Indian languages. Marathi which is the official language of Maharashtra State in India and the world's 10th highest spoken language is not exception to this. Various computational approaches for spelling error detection and correction have been advocated in the literature. Amongst these, similarity-based measures have proven to be the prominent ones. This paper discusses the detailed contrastive study of the two popular similarity measures viz. minimum edit distance and cosine similarity measures in the context of mis-spelled Marathi words. The philosophical and empirical aspects of these methods have also been presented. For experimentation purpose we have chosen a dataset of 9, 29, 663 unique Marathi words harvested from various sources. We have obtained an accuracy of 85.88% and 86.76% for minimum edit distance algorithm and the cosine similarity algorithm, respectively.
C1 [Patil, Kavita T.; Bhavsar, R. P.; Pawar, B., V] Kavayitri Bahinahai Chaudhari North Maharashtra U, Dept Sch Comp Sci, Jalgaon, Maharashtra, India.
RP Patil, KT (corresponding author), Kavayitri Bahinahai Chaudhari North Maharashtra U, Dept Sch Comp Sci, Jalgaon, Maharashtra, India.
EM meetpatilkavita@gmail.com; rpbhavsar@nmu.ac.in; bvpawar@nmu.ac.in
OI Patil, Kavita Tukaram/0000-0002-2893-3270
CR Al-Jefri MM, 2013, CONTEXT SENSITIVE AR
   Amorim RC, 2013, EFFECTIVE SPELL CHEC
   [Anonymous], 2016, MORPHOLOGICAL ANALYZ
   Arun P, 2001, MARATHI LEKHAN KOSH, V2001
   Asadullah, 2007, FINITE STATE RECOGNI
   Basri SB, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2012), P506, DOI 10.1109/ICCSCE.2012.6487198
   Bhattacharyya A, 1946, SANKHYA, V7, P401
   Bilenko M.Y., 2006, Learnable Similarity Functions and Their Application to Record Linkage and Clustering
   Broder AZ, 1997, COMPUT NETWORKS ISDN, V29, P1157, DOI 10.1016/S0169-7552(97)00031-7
   Comodi A, 2018, IEEE SYM PARA DISTR, P131, DOI 10.1109/IPDPSW.2018.00028
   DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994
   Das M, 2003, LANGUAGE ENGINEERING CONFERENCE, PROCEEDINGS, P156, DOI 10.1109/LEC.2002.1182303
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dixit V., 2005, Archives of Control Sciences, V15(LI), P301
   Etoori P, 2018, AUTOMATIC SPELLING C
   FlorM Futagi Y, 2012, BEA NAACL HLT
   Forum for Information Retrieval (FIRE), INF RETR SOC IND
   Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914
   Gravano L., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P491
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Hamza B, 2014, INDEPENDENT SPELLCHE, P5
   Hatem M., 2016, EGYPT COMPUT SCI J, V40, P6164
   Huang G., 2020, J PHYS C SERIES, V1693
   Jaccard P., 1901, B SOC VAUD SCI NAT, V37, P547, DOI DOI 10.5169/SEALS-266450
   JARO MA, 1989, J AM STAT ASSOC, V84, P414, DOI 10.2307/2289924
   Jayakodi K, 2016, INT J EMERG TECHNOL, V11, P142, DOI 10.3991/ijet.v11i04.5654
   Kaur H., 2007, INT J SCI ENG TECHNO, V4
   Kaur K, 2018, HYBRID APPROACH SPEL
   Kondrak G., 2005, SPIRE
   Krause E.F., 1987, Taxicab Geometry: Na adventure in Non-Euclidean Geometry
   Lawaye A., 2016, INT J SCI RES, V5
   Lee D-G, 2022, AUTOMATIC STRING GEN
   Levenshtein V., 1965, Problems Inf. Transm., V1, P8
   Lu CJ, 2019, J AM MED INFORM ASSN, V26, P211, DOI 10.1093/jamia/ocy171
   Mahdi A. M., 2014, P INT C ADV COMP SCI, P59
   Mandal P., 2017, CLUSTERING BASED BAN, DOI 10.1109/ICIVPR.2017.7890878
   Martins B, 2004, LECT NOTES ARTIF INT, V3230, P372
   Maulana Y, 2018, AUTOCOMPLETE SPELL C, V5, P6775
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Padhy H, 2013, DESIGNING HYBRID APP
   Paramjeet Singh D, 2015, SPELLCHECKING ERROR
   Patil Kavita T., 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P892, DOI 10.1109/ICACCS51430.2021.9441858
   Patil KT, 2021, SPELLING CHECKING ER
   PETERSON JL, 1980, COMMUN ACM, V23, P676, DOI 10.1145/359038.359041
   Prasetya DD., 2018, International Journal of Advances in Intelligent Informatics, V4, P63
   Querol Chan C., 2008, J RES SCI COMPUT ENG, V4
   Sayed A, 2017, EGYPT INFORM J, V18, P181, DOI 10.1016/j.eij.2017.01.001
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Soel TT, 2019, INT J RECENT DEV ENG, P1
   Soyusiawaty D, 2021, INT J ADV COMPUT SC, V12, P332
   Umar R., 2015, International Journal of Computer Trends and Technology (IJCTT), V27, P131, DOI [10.14445/22312803/IJCTT-V27P123, DOI 10.14445/22312803/IJCTT-V27P123]
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   Wang JN, 2011, PROC INT CONF DATA, P458, DOI 10.1109/ICDE.2011.5767865
   Watcharabutsarakham S, 2007, TENCON 2005 2005 IEE, P1
   Winkler William E, 1990, STRING COMP METRICS
   Yu MH, 2016, FRONT COMPUT SCI-CHI, V10, P399, DOI 10.1007/s11704-015-5900-5
   Yulianto M, 2018, SCI J INFORM, V5, P75, DOI [DOI 10.15294/SJI.V5I1.14148, 10.15294/sji.v5i1.14148]
   US
NR 58
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15573
EP 15591
DI 10.1007/s11042-022-13948-z
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000865713700003
DA 2024-07-18
ER

PT J
AU Verma, P
   Selwal, A
   Sharma, D
AF Verma, Palak
   Selwal, Arvind
   Sharma, Deepika
TI A survey on data-driven iris spoof detectors: state-of-the-art, open
   issues and future perspectives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Spoof attacks; Spoof detectors; Data augmentation;
   Handcrafted features; CNN; Transfer learning
ID RECOMMENDATION SYSTEM; LIVENESS DETECTION; TEMPLATE SECURITY;
   RECOGNITION; SCHEME; FINGERPRINT; ENSEMBLE; NETWORK; FACE
AB In the modern era of computing, the iris-based biometric systems are gaining significant attention for secured and automatic human authentication. However, past decades have witnessed numerous spoofing assaults on these iris-based recognition systems where an attacker impersonates an exact replica of biometrical information of the genuine user. Particularly, these direct attacks are targeted on the iris sensor module of the biometric system by presenting the fake artefacts of a bonafide iris trait. With the emergence of data-driven paradigm (i.e. handcrafted feature learners such as support vector machine (SVM), decision tree (DT), k-nearest neighbor (KNN), ensembles, etc. or automatic image features extraction-based classifiers such as convolutional neural networks (CNN), generative adversial networks (GAN)), mitigating these iris spoof attacks has become comparatively an easier and accurate task of computer vision. An iris spoof detector (ISD) is a mechanism through which the vitality of a presented iris trait is measured intelligently by classifying it as genuine or counterfeit. In this study, we explicate a taxonomy-based comparative analysis of state-of-the-art (SOTA) ISDs that employ machine learning or deep learning-based approaches. We expound a novel taxonomy for classifying ISDs based on underlying criterion such as feature type, learning algorithm, pre-trained models, data augmentation, hybrid, etc. Furthermore, we investigate and analyze various benchmark datasets employed in the various data-driven iris spoof detectors ((DISD)-I-2). We also illustrate prominent performance evaluation protocols that are widely adopted in the SOTA approaches. Though, pioneer contributions related to (DISD)-I-2 is reported in the literature, but several potential open research problems still exist, that requisite a futuristic attention of the investigators in this active field of research.
C1 [Verma, Palak; Selwal, Arvind; Sharma, Deepika] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, India.
C3 Central University of Jammu
RP Verma, P (corresponding author), Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, India.
EM pv07111998@gmail.com
RI Selwal, Arvind/HTR-1625-2023
OI Selwal, Arvind/0000-0002-1075-6966; Verma, Palak/0000-0002-3893-332X
CR Abdellatef E, 2020, VISUAL COMPUT, V36, P1097, DOI 10.1007/s00371-019-01715-5
   Agarwal R, 2021, MULTIMED TOOLS APPL, V80, P15193, DOI 10.1007/s11042-020-10378-7
   Agarwal R, 2020, WIRELESS PERS COMMUN, V115, P2627, DOI 10.1007/s11277-020-07700-9
   Agarwal R, 2021, VISUAL COMPUT, V37, P1357, DOI 10.1007/s00371-020-01870-0
   Ahmadi N, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105701
   Bakkouri I, 2022, BG 3DM2F BIDIRECTION, V81
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bhogal APS, 2017, I W BIOMETRIC FORENS
   Boulkenafet Z, 2018, IMAGE VISION COMPUT, V77, P1, DOI 10.1016/j.imavis.2018.04.007
   Busch C., 2017, ISO IEC STANDARDS TE
   Chatterjee P., 2019, LNCS
   Chen CJ, 2018, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW.2018.00011
   Choudhary M, 2019, FUTURE GENER COMP SY, V101, P1259, DOI 10.1016/j.future.2019.07.003
   Czajka A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232849
   Czajka A, 2017, IEEE T INF FOREN SEC, V12, P2184, DOI 10.1109/TIFS.2017.2701332
   Czajka A, 2015, IEEE T INF FOREN SEC, V10, P726, DOI 10.1109/TIFS.2015.2398815
   Das P, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304941
   Daugman J., 1994, Biometric personal identification system based on iris analysis
   Dronky MR, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115266
   Elrefaei L., 2019, Int J Artif Intell Appl, V10, P49, DOI [https://doi.org/ 10.5121/ijaia.2019.10505, DOI 10.5121/IJAIA.2019.10505]
   Fang ML, 2020, PROCEEDINGS OF 2020 23RD INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2020), P233
   Fang ML, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104057
   Fang ZY, 2021, IEEE T INF FOREN SEC, V16, P510, DOI 10.1109/TIFS.2020.3015547
   Farmanbar M, 2017, SIGNAL IMAGE VIDEO P, V11, P1253, DOI 10.1007/s11760-017-1082-y
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gautam G., 2018, 2018 INT JOINT C NEU, P1
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   Goshtasby A. A., 2012, ADV COMPUTER VISION
   Gragnaniello D, 2015, PATTERN RECOGN LETT, V57, P81, DOI 10.1016/j.patrec.2014.10.018
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Gupta P, 2014, INT C PATT RECOG, P1681, DOI 10.1109/ICPR.2014.296
   Gupta R, 2016, INT J BIOMETRICS, V8, P145, DOI 10.1504/IJBM.2016.077833
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu Y, 2016, PATTERN RECOGN LETT, V82, P242, DOI 10.1016/j.patrec.2015.10.010
   Huang XY, 2013, IEEE WORK APP COMP, P252, DOI 10.1109/WACV.2013.6475026
   Hughes K, 2013, P ANN HICSS, P1763, DOI 10.1109/HICSS.2013.172
   Hui Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4279, DOI 10.1109/ICPR.2010.1040
   Ishfaq DSR, 2021, FINGERPRINT SPOOFING, P22
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Jamdar SD., 2017, IEEE T INF FOREN SEC, V1, P125
   Kaur B, 2020, MULTIMED TOOLS APPL, V79, P6623, DOI 10.1007/s11042-019-08281-x
   Kaur B, 2019, COMPUT ELECTR ENG, V73, P279, DOI 10.1016/j.compeleceng.2018.12.002
   Klochkov, 2020, DECISION AN APPL IND
   Kohli N, 2013, INT CONF BIOMETR
   Kohli N, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P674, DOI 10.1109/BTAS.2017.8272756
   Komogortsev OV, 2013, INT CONF BIOMETR
   Kuehlkamp A, 2019, IEEE T INF FOREN SEC, V14, P1419, DOI 10.1109/TIFS.2018.2878542
   Liu M, 2020, IEEE T FUZZY SYST, V28, P92, DOI 10.1109/TFUZZ.2019.2912576
   Long M, 2019, CMC-COMPUT MATER CON, V58, P493, DOI 10.32604/cmc.2019.04378
   Mehmood R, 2020, INT ARAB J INF TECHN, V17, P926, DOI 10.34028/iajit/17/6/11
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Minaee S., 2019, ARXIV191200271
   Nianfeng Liu, 2016, 2016 International Conference on Biometrics (ICB), DOI 10.1109/ICB.2016.7550055
   Nion D., INT CONF ACOUST SPEE, P2077, DOI 10.1109/ICASSP.2015.7178838
   Pala F, 2017, IEEE COMPUT SOC CONF, P664, DOI 10.1109/CVPRW.2017.95
   Puhan N. B., 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P71, DOI 10.1109/ISCE.2011.5973786
   Qingqiao Hu, 2020, Procedia Computer Science, V174, P505, DOI 10.1016/j.procs.2020.06.118
   Raghavendra R, 2015, IEEE T INF FOREN SEC, V10, P703, DOI 10.1109/TIFS.2015.2400393
   Raghavendra R, 2014, EUR SIGNAL PR CONF, P1387
   RAGHAVENDRA R, 2014, IJCB 2014 2014 IEEEI, DOI DOI 10.1109/BTAS.2014.6996226
   RAJA KB, 2015, 2015 IEEE 7 INT C BI, DOI DOI 10.1109/BTAS.2015.7358790
   Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223
   Ribeiro E, 2017, 2017 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Rigas I, 2015, PATTERN RECOGN LETT, V68, P316, DOI 10.1016/j.patrec.2015.06.011
   Rui Z, 2019, IEEE ACCESS, V7, P5994, DOI 10.1109/ACCESS.2018.2889996
   Sardar M, 2020, IEEE ACCESS, V8, P219322, DOI 10.1109/ACCESS.2020.3041519
   Selwal A, 2017, J INTELL FUZZY SYST, V32, P3325, DOI 10.3233/JIFS-169274
   Selwal A, 2016, ADV SCI TECHNOL-RES, V10, P23, DOI 10.12913/22998624/64062
   Sequeira AF, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   SHARMA D, 2021, INTELLIGENT APPROACH
   Sharma D, 2021, PATTERN RECOGN LETT, V152, P225, DOI 10.1016/j.patrec.2021.10.013
   Sharma D, 2022, VISUAL COMPUT, V38, P2999, DOI 10.1007/s00371-021-02173-8
   Silva P, 2015, SIBGRAPI, P157, DOI 10.1109/SIBGRAPI.2015.16
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh M, 2019, INFORM FUSION, V52, P187, DOI 10.1016/j.inffus.2018.12.003
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tann H, 2020, ACM J EMERG TECH COM, V16, DOI 10.1145/3357796
   Tapia JE, 2022, IEEE T INF FOREN SEC, V17, P42, DOI 10.1109/TIFS.2021.3132582
   Therar Huda Moyasar, 2021, IOP Conference Series: Materials Science and Engineering, V1105, DOI 10.1088/1757-899X/1105/1/012032
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Tobji R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102042
   Varkarakis V, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P402, DOI 10.1109/GEM.2018.8516446
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
   Yambay D., 2015, LivDet-Iris 2015-Iris Liveness Detection Competition 2015
   Yambay D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P733, DOI 10.1109/BTAS.2017.8272763
   Yambay D, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Yang YT, 2018, IEEE INT SYM MULTIM, P9, DOI 10.1109/ISM.2018.00010
   Zhang H, 2011, LEARNING HIERARCHICA
   Zhao ZJ, 2019, PATTERN RECOGN, V93, P546, DOI 10.1016/j.patcog.2019.04.010
   Zhao Z, 2017, IEEE I CONF COMP VIS, P3829, DOI 10.1109/ICCV.2017.411
NR 97
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19745
EP 19792
DI 10.1007/s11042-022-14014-4
EA OCT 2022
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000865376900003
DA 2024-07-18
ER

PT J
AU Deepa, D
   Sivasangari, A
AF Deepa, D.
   Sivasangari, A.
TI An effective detection and classification of road damages using hybrid
   deep learning framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road damage detection; Feature extraction; Deep learning approach;
   Classification; Optimization
ID NEURAL-NETWORK
AB The monitoring of road surfaces is a critical thing in transport infrastructure management. The manual reporting process increases the processing delay and causes challenges in accuracy. Detecting road surface damages is important for improving the quality of transportation and avoiding several issues normal people face in daily life. Therefore, an automated monitoring system is needed to compute road surface conditions for effective road maintenance regularly. Accurately detecting and classifying road damage images become a challenging task for researchers. Thus, the proposed work introduced a hybrid deep learning framework for detecting and classifying road damage images. At first, the input images are acquired from the dataset and pre-processed with an adaptive intensity limited histogram equalization algorithm. This pre-processing method enhances the contrast of the given input images and eliminates the noise presented in the image. Then, the damage detection is performed in the segmentation stage using an adaptive density based fuzzy c-means clustering method. Features from the segmented images are extracted using Laplacian edge detection with Gaussian operator and hybrid wavelet-Walsh transform approaches. Subsequently, the dimensionality of the feature set is reduced by using the Adaptive Horse herd Optimization (AHO) algorithm. Finally, the road damages are detected and classified using the proposed Hybrid Deep Capsule autoencoder based Convolutional Neural network (Hybrid DCACN) with Improved Whale Optimization (IWO) model. The experimental validation is done using the RDD2020 dataset, and the performance metrics are evaluated to show the efficacy of the proposed model. The proposed work attains 98.815% accuracy, and the obtained results outperform the existing approaches.
C1 [Deepa, D.] Sathyabama Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Sivasangari, A.] Sathyabama Inst Sci & Technol, Sch Comp, Dept Informat Technol, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; Sathyabama Institute of
   Science & Technology
RP Deepa, D (corresponding author), Sathyabama Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM deepa.cse@sathyabama.ac.in; sivasanagri.it@sathyabama.ac.in
RI D, Deepa/AEV-9235-2022
OI D, Deepa/0000-0003-3516-8201
CR Anand A, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P532, DOI 10.1109/SPIN.2015.7095391
   Arman Md Shohel, 2020, Cyber Security and Computer Science. Second EAI International Conference, ICONCS 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 325), P730, DOI 10.1007/978-3-030-52856-0_58
   Arya D., 2020, COMPUT VIS PATTERN R, V16, DOI [10.48550/arXiv.2008.13101, DOI 10.48550/ARXIV.2008.13101]
   Arya D, 2021, AUTOMAT CONSTR, V132, DOI 10.1016/j.autcon.2021.103935
   Arya D, 2021, DATA BRIEF, V36, DOI 10.1016/j.dib.2021.107133
   Cao MT, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101182
   Dung CV, 2019, AUTOMAT CONSTR, V99, P52, DOI 10.1016/j.autcon.2018.11.028
   Chowdhary C.L., 2018, Nature inspired computing, P75
   Chowdhary CL, 2016, INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION COMMUNICATION TECHNOLOGY & COMPUTING, 2016, DOI 10.1145/2979779.2979800
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Chowdhary CL, 2016, ADV INTELL SYST, V411, P325, DOI 10.1007/978-81-322-2731-1_30
   Chun C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19245501
   Devi HS, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102424
   Fan R, 2020, IEEE T INTELL TRANSP, V21, P4906, DOI 10.1109/TITS.2019.2947206
   Gao YL, 2021, INT J FUZZY SYST, V23, P2218, DOI 10.1007/s40815-021-01090-1
   Griffiths D, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121499
   Guo L, 2021, IEEE T IND INFORM, V17, P2737, DOI 10.1109/TII.2020.3010799
   He Y, 2022, INT J CLIMATOL, V42, P5038, DOI 10.1002/joc.7518
   Hegde V, 2020, IEEE INT CONF BIG DA, P5553, DOI 10.1109/BigData50022.2020.9377833
   Hou Y, 2021, ENGINEERING-PRC, V7, P845, DOI 10.1016/j.eng.2020.07.030
   Ju HY, 2020, STRUCT CONTROL HLTH, V27, DOI 10.1002/stc.2551
   Kanwal S, 2020, TOURISM MANAGE, V77, DOI 10.1016/j.tourman.2019.104014
   Maeda H, 2021, COMPUT-AIDED CIV INF, V36, P47, DOI 10.1111/mice.12561
   Mei QP, 2020, CONSTR BUILD MATER, V256, DOI 10.1016/j.conbuildmat.2020.119397
   MiarNaeimi F, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106711
   Mohan A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3998
   Pandey AK, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107725
   Park S, 2019, J COMPUT CIVIL ENG, V33, DOI 10.1061/(ASCE)CP.1943-5487.0000831
   Pham V, 2020, IEEE INT CONF BIG DA, P5592, DOI 10.1109/BigData50022.2020.9378027
   Ping Ping, 2020, 2020 IEEE Sixth International Conference on Big Data Computing Service and Applications (BigDataService). Proceedings, P198, DOI 10.1109/BigDataService49289.2020.00039
   Shim S, 2022, AUTOMAT CONSTR, V135, DOI 10.1016/j.autcon.2022.104139
   Shim S, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103833
   Shtayat A, 2020, J TRAFFIC TRANSP ENG, V7, P629, DOI 10.1016/j.jtte.2020.03.004
   Wang Q., 2021, J. Phys. Conf. Ser, V1903, P012008, DOI [10.1088/1742-6596/1903/1/012008, DOI 10.1088/1742-6596/1903/1/012008]
   Wei C, 2021, AUTOMAT CONSTR, V131, DOI 10.1016/j.autcon.2021.103876
   Wu HB, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100936
   Xu HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142867
   Xu HQ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030689
   Yang F, 2020, IEEE T INTELL TRANSP, V21, P1525, DOI 10.1109/TITS.2019.2910595
   Yang JX, 2020, INFORM SCIENCES, V540, P117, DOI 10.1016/j.ins.2020.05.090
   Yeoh Keng Yik, 2021, Journal of Physics: Conference Series, V1828, DOI 10.1088/1742-6596/1828/1/012001
   Yuan YC, 2021, FUTURE GENER COMP SY, V125, P385, DOI 10.1016/j.future.2021.06.035
NR 44
TC 5
Z9 5
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18151
EP 18184
DI 10.1007/s11042-022-14001-9
EA OCT 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000863553600005
DA 2024-07-18
ER

PT J
AU Ghobaei-Arani, M
   Rezaei, M
   Souri, A
AF Ghobaei-Arani, Mostafa
   Rezaei, Maryam
   Souri, Alireza
TI An auto-scaling mechanism for cloud-based multimedia storage systems: a
   fuzzy-based elastic controller
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Multi-media storage system; OODA loop; Fuzzy logic;
   Elasticity
ID LOGIC
AB Cloud computing is a new technology that is increasing in popularity day-by-day. One of the reasons for its popularity can be its elasticity feature. In other words, cloud computing considers the consumer's resource capacity to be infinite, where the consumer can obtain the resources on-demand and increase or decrease the number of resources. Although various solutions for elasticity management have been developed so far, more work is needed to manage the elasticity of the cloud-based multimedia storage systems more effectively. Accordingly, this paper presents the Observe-Orient-Decide-Act (OODA) loop to improve the resource elasticity in cloud-based multimedia storage systems. In the proposed solution, elasticity management is performed using the OODA loop and fuzzy logic theory. Our simulation results demonstrate that the proposed solution reduces the read time, write time, response time by 7.2%, 6.9%, and 8.4%, respectively, compared with existing elastic cloud-based storage mechanisms.
C1 [Ghobaei-Arani, Mostafa] Islamic Azad Univ, Dept Comp Engn, Qom Branch, Qom, Iran.
   [Rezaei, Maryam] Islamic Azad Univ, Dept Comp Engn, Mahallat Branch, Markazi, Iran.
   [Souri, Alireza] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University
RP Ghobaei-Arani, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Qom Branch, Qom, Iran.
EM m.ghobaei@qom-iau.ac.ir
RI Ghobaei-Arani, Mostafa/K-5058-2015; Souri, Alireza/Y-4580-2018
OI Ghobaei-Arani, Mostafa/0000-0003-2639-0900; Souri,
   Alireza/0000-0001-8314-9051
CR Ai W, 2016, SCI PROGRAMMING-NETH, V2016, DOI 10.1155/2016/7519507
   Al-Dhuraibi Y., 2018, COORDINATING VERTICA
   [Anonymous], 2015, PROC USENIX ATC
   Arabnejad H, 2017, IEEE ACM INT SYMP, P64, DOI 10.1109/CCGRID.2017.15
   Aslanpour MS, 2021, SIMUL MODEL PRACT TH, V108, DOI 10.1016/j.simpat.2020.102245
   Aslanpour MS, 2020, INT CONF UTIL CLOUD, P186, DOI 10.1109/UCC48980.2020.00037
   Aslanpour MS, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P31, DOI 10.1109/ICWR.2016.7498443
   Beloglazov A, 2010, MGC@ Middleware, DOI 10.1145/1890799.1890803
   Beltrán M, 2016, FUTURE GENER COMP SY, V64, P39, DOI 10.1016/j.future.2016.05.014
   Bowers KD, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P187
   Cardellini V., 2018, Autonomous Control for a Reliable Internet of Services, P182
   Chen LB, 2018, J SUPERCOMPUT, V74, P1045, DOI 10.1007/s11227-016-1827-3
   Chiesa G, 2020, AUTOMAT CONSTR, V120, DOI 10.1016/j.autcon.2020.103397
   Chitra K, 2021, J AMB INTEL HUM COMP, V12, P6491, DOI 10.1007/s12652-020-02264-9
   Franco JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105389
   Galante G, 2012, INT CONF UTIL CLOUD, P263, DOI 10.1109/UCC.2012.30
   Ghobaei-Arani M, 2019, IEEE ACCESS, V7, P106911, DOI 10.1109/ACCESS.2019.2932462
   Gueye SMK, 2014, FUTURE GENER COMP SY, V35, P14, DOI 10.1016/j.future.2013.12.037
   Harter Tyler., 2014, 12 USENIX C FILE STO, P199
   Hosamani N., 2020, P INT C COMP COMM NE, P1
   Jamshidi P, 2014, 9TH INTERNATIONAL SYMPOSIUM ON SOFTWARE ENGINEERING FOR ADAPTIVE AND SELF-MANAGING SYSTEMS (SEAMS 2014), P95, DOI 10.1145/2593929.2593940
   Jannapureddy R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071417
   Kaur PD, 2014, FUTURE GENER COMP SY, V37, P14, DOI 10.1016/j.future.2014.02.018
   Lehrig S, 2018, FUTURE GENER COMP SY, V78, P115, DOI 10.1016/j.future.2017.04.018
   Li KQ, 2020, IEEE T CLOUD COMPUT, V8, P1135, DOI 10.1109/TCC.2017.2665549
   Liu Y, 2017, CLUSTER COMPUT, V20, P1977, DOI 10.1007/s10586-017-0899-z
   Lytvyn Vasyl, 2020, 2020 IEEE Third International Conference on Data Stream Mining & Processing (DSMP), P409, DOI 10.1109/DSMP47368.2020.9204107
   Maghsoudloo M, 2020, J SUPERCOMPUT, V76, P174, DOI 10.1007/s11227-019-03017-y
   Marcus LJ, 2020, IND MARKET MANAG, V88, P272, DOI 10.1016/j.indmarman.2020.05.019
   Meana-Llorián D, 2017, FUTURE GENER COMP SY, V76, P275, DOI 10.1016/j.future.2016.11.020
   Mirzakhanov VE, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113781
   Newcombe C, 2015, COMMUN ACM, V58, P66, DOI 10.1145/2699417
   Qureshi NMF, 2019, WIRELESS PERS COMMUN, V106, P2225, DOI 10.1007/s11277-018-5936-6
   Révay M, 2017, 2017 COMMUNICATION AND INFORMATION TECHNOLOGIES (KIT), P127
   Serrano D, 2013, IEEE ACM INT SYMP, P50, DOI 10.1109/CCGrid.2013.66
   Sharmila S, 2021, SOFT COMPUT, V25, P1431, DOI 10.1007/s00500-020-05229-4
   Shi YL, 2020, FUTURE GENER COMP SY, V105, P814, DOI 10.1016/j.future.2017.08.034
   Sivashakthi T., 2013, INT J EMERGING TECHN, V3, P125
   Szalay M., 2020, CSCM 2020, P1
   Wang H., 2014, P 12 USENIX C FIL ST, P229
   Wanke P, 2017, J TRANSP GEOGR, V60, P33, DOI 10.1016/j.jtrangeo.2017.02.006
   Wu CG, 2021, VLDB J, V30, P25, DOI 10.1007/s00778-020-00632-7
   Wu T, 2018, INFORM SCIENCES, V432, P392, DOI 10.1016/j.ins.2017.12.006
   Xu Lianghong., 2014, Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST 14), P243
NR 44
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34501
EP 34523
DI 10.1007/s11042-021-11021-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000859151000021
DA 2024-07-18
ER

PT J
AU Zou, QH
   Wang, C
   Yang, SH
   Chen, B
AF Zou, Qinhong
   Wang, Cong
   Yang, Shaohua
   Chen, Bin
TI A compact periocular recognition system based on deep learning framework
   AttenMidNet with the attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periocular recognition; Deep learning; Attention mechanism; Mid-level
   features
ID NETWORK; IRIS
AB In the context of the spread of the new crown epidemic, periocular recognition has become an effective alternative in less constrained environments where the face is inconvenient to obtain. Although the periocular recognition algorithms based on deep learning have made great progress, the network performance is expected to be further improved with fewer parameters in the practical applications. In this work, we proposed a lightweight CNN based on the combination of an attention mechanism and mid-level features, referred to as AttenMidNet. This attention module is directly inserted into the convolution blocks at all levels to adaptively assign weights to the feature channels to obtain the mid-level features with the most information. Then the mid-level features at all levels are contacted to form the final feature representation vector. This method not only expresses the features more comprehensively, but also drastically reduces the number of network parameters. The experimental results using within-dataset and cross-dataset evaluation on three publicly available datasets (UBIRIS.v2, CASIA_Iris_Distance, CASIA_Iris_Twins, and one self-collected periocular dataset) have proved the effectiveness of the proposed network. Moreover, a compact and efficient periocular recognition system including access control and mobile terminals was designed using the proposed network. In addition to the real-time detection and matching of periocular images, the access control terminal can also realize scanning and verification of QR code images. During the peak period of people flow, users can log in to the online periocular recognition system via the mobile terminal in advance for matching authentication. If successful, the corresponding QR code will be generated, through which to reduce crowd gathering time.
C1 [Zou, Qinhong; Wang, Cong; Yang, Shaohua; Chen, Bin] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Southwest University - China
RP Chen, B (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM zqhzqh123@email.swu.edu.cn; wc2039@email.swu.edu.cn;
   ysh971020@email.swu.edu.cn; chenbin121@swu.edu.cn
FU National Nature Science Foundation of China [61801400]; JSPS KAKENHI
   [JP18F18392]
FX This study was supported by the National Nature Science Foundation of
   China [grant number 61801400] and JSPS KAKENHI [grant number
   JP18F18392]. At the same time, we would like to thank the SOCIA Lab,
   University of Beira Interior, CovilhA, Portugal and the Institute of
   Automation, Chinese Academy of Sciences, Beijing, China, for their
   contributions of the datasets employed in this work.
CR Abate A, 2022, LECT NOTES COMPUT SC, V13231, P368, DOI 10.1007/978-3-031-06427-2_31
   Ai H, 2018, MEASUREMENT, V123, P309, DOI 10.1016/j.measurement.2018.04.005
   Almadan A, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9660033
   [Anonymous], CASIA Iris Image Database
   Behera SS, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104016
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Chen Q, 2019, CHIN CONTR CONF, P8772, DOI [10.23919/ChiCC.2019.8865153, 10.23919/chicc.2019.8865153]
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu CH, 2020, IEEE T INTELL TRANSP, V21, P4958, DOI 10.1109/TITS.2019.2945923
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hwang H, 2020, IEEE ACCESS, V8, P158612, DOI 10.1109/ACCESS.2020.3020142
   Im D, 2020, IEEE T CIRCUITS-I, V67, P3471, DOI 10.1109/TCSI.2020.2991189
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Khan S, 2020, WIRELESS PERS COMMUN, V113, P469, DOI 10.1007/s11277-020-07224-2
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumari P, 2021, J AMB INTEL HUM COMP, V12, P10321, DOI 10.1007/s12652-020-02814-1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee DH, 2021, MULTIMED TOOLS APPL, V80, P34237, DOI 10.1007/s11042-020-09924-0
   Li T, 2019, MULTIMED TOOLS APPL, V78, P3411, DOI 10.1007/s11042-018-5986-5
   Lin LK, 2018, J SYST ENG ELECTRON, V29, P947, DOI 10.21629/JSEE.2018.05.07
   Mahalingam G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-36
   Mishra NK., 2022, APPL INTELL, V2022, P1
   Molchanov P., 2016, arXiv
   Park U, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P153
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proença H, 2014, IEEE T IMAGE PROCESS, V23, P5082, DOI 10.1109/TIP.2014.2361285
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Qin JM, 2020, IEEE ACCESS, V8, P20991, DOI 10.1109/ACCESS.2019.2963053
   Qin R, 2020, IEEE J-STARS, V13, P4760, DOI 10.1109/JSTARS.2020.3015520
   Reddy N, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103996
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smereka JM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Smereka JM, 2015, IEEE T INF FOREN SEC, V10, P1875, DOI 10.1109/TIFS.2015.2434271
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan CW, 2013, IEEE T IMAGE PROCESS, V22, P3751, DOI 10.1109/TIP.2013.2260165
   Umer S, 2020, NEURAL NETWORKS, V122, P407, DOI 10.1016/j.neunet.2019.11.009
   van Dyk DA, 2001, J COMPUT GRAPH STAT, V10, P1, DOI 10.1198/10618600152418584
   Wang K, 2021, IEEE T INF FOREN SEC, V16, P866, DOI 10.1109/TIFS.2020.3023289
   Wang Z, 2018, IEEE ACCESS, V6, P17905, DOI 10.1109/ACCESS.2018.2812208
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Zhao ZJ, 2018, IEEE T INF FOREN SEC, V13, P2937, DOI 10.1109/TIFS.2018.2833018
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
NR 46
TC 4
Z9 4
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15837
EP 15857
DI 10.1007/s11042-022-14017-1
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000862219700006
DA 2024-07-18
ER

PT J
AU Mu, SS
   Zhang, YH
   Jiang, YB
AF Mu, Shaoshuo
   Zhang, Yanhua
   Jiang, Yanbing
TI DRN-VideoSR: a deep recursive network for video super-resolution based
   on a deformable convolution shared-assignment network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video super-resolution; Deformable convolution; Pyramid; Encoder-Decoder
AB Video super-resolution(videoSR) usually involves several steps: motion estimation, motion compensation, fusion, and upsampling. Here, we propose a novel architecture for video SR. First, in place of motion estimation and compensation, this architecture is based on a specially designed deformable convolution shared-assignment network. The model does not require warp operation and uses a three-layer pyramid deformable convolution network. Second, inspired by the idea of back-projection and Encoder-Decoder structure, we propose a deep recursive fusion network that fuses multi-frame information for the target frame. The fusion network adopts a Decoder-Encoder structure with shared weights to construct the back-projection network, and concatenates the output of each back-projection layer. This design not only reduces the network requirements, but also deepens the network structure so that it can extract deeper image features and achieve fusion. Extensive evaluations and comparisons with previous methods validate the strengths of this approach and demonstrate that the proposed framework is able to significantly outperform the current state of the art.
C1 [Mu, Shaoshuo; Zhang, Yanhua; Jiang, Yanbing] Commun Univ Zhejiang, Hangzhou, Peoples R China.
C3 Communication University of Zhejiang
RP Jiang, YB (corresponding author), Commun Univ Zhejiang, Hangzhou, Peoples R China.
EM hitshaoshuomu@163.com; 20170015@cuz.edu.cn; zjujyb@163.com
RI Zhang, Yanhua/GNM-8398-2022
OI Zhang, Yanhua/0000-0002-7927-4949
FU National Natural Science Foundation Youth Fund [61601404]; General
   Scientific Research Projects of Zhejiang Education Department
   [Y201840087]; Opening Foundation of State Key Laboratory of Cognitive
   Intelligence, iFLYTEK [CIOS-2022SC06]
FX This study was funded the National Natural Science Foundation Youth Fund
   (61601404), General Scientific Research Projects of Zhejiang Education
   Department (Y201840087), and the Opening Foundation of State Key
   Laboratory of Cognitive Intelligence, iFLYTEK (CIOS-2022SC06).
CR Abbass MY, 2021, MULTIMED TOOLS APPL, V80, P5403, DOI 10.1007/s11042-020-09824-3
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Arjovsky M, 2018, ARXIV
   Berthelot D, 2017, ARXIV
   Bin H, 2017, ARXIV
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Chu M, 2019, ARXIV
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fu LH, 2021, MULTIMED TOOLS APPL, V80, P11423, DOI 10.1007/s11042-020-10337-2
   Haris M, 2021, IEEE T PATTERN ANAL, V43, P4323, DOI 10.1109/TPAMI.2020.3002836
   Haris M, 2019, PROC CVPR IEEE, P3892, DOI 10.1109/CVPR.2019.00402
   Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167
   Isobe Takashi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8005, DOI 10.1109/CVPR42600.2020.00803
   Isobe T., 2020, ARXIV
   Jiang K, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107475
   Jiang K, 2019, IEEE T GEOSCI REMOTE, V57, P5799, DOI 10.1109/TGRS.2019.2902431
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li F, 2020, IEEE T IMAGE PROCESS, V29, P4474, DOI 10.1109/TIP.2020.2972118
   Li S, 2019, PROC CVPR IEEE, P10514, DOI 10.1109/CVPR.2019.01077
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Maalouf A, 2012, IET IMAGE PROCESS, V6, P168, DOI 10.1049/iet-ipr.2010.0275
   Min L, 2019, GUANGDIAN GONGCHENG
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   [孙超 Sun Chao], 2017, [光学学报, Acta Optica Sinica], V37, P1210004
   Sun W, 2020, NEUROCOMPUTING, V406, P24, DOI 10.1016/j.neucom.2020.03.068
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tian YP, 2020, PROC CVPR IEEE, P3357, DOI 10.1109/CVPR42600.2020.00342
   Wang LG, 2020, IEEE T IMAGE PROCESS, V29, P4323, DOI 10.1109/TIP.2020.2967596
   Wang SZ, 2022, AAAI CONF ARTIF INTE, P2522
   Wang SY, 2022, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, V60, DOI [10.1109/TGRS.2021.3057721, DOI 10.1109/TGRS.2021.3057721]
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Yi P, 2022, IEEE T PATTERN ANAL, V44, P2264, DOI 10.1109/TPAMI.2020.3042298
   Yi P, 2019, IEEE I CONF COMP VIS, P3106, DOI 10.1109/ICCV.2019.00320
   Yi P, 2020, IEEE T CIRC SYST VID, V30, P2503, DOI 10.1109/TCSVT.2019.2925844
   Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17
   Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhou TF, 2021, PROC CVPR IEEE, P6981, DOI 10.1109/CVPR46437.2021.00691
   Zhou TF, 2021, PROC CVPR IEEE, P1622, DOI 10.1109/CVPR46437.2021.00167
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
NR 48
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14019
EP 14035
DI 10.1007/s11042-022-13818-8
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416900006
DA 2024-07-18
ER

PT J
AU Das, S
   Chakravortty, S
AF Das, Srirupa
   Chakravortty, Somdatta
TI Spectral-spatial 3D dynamic trimmed median filter for removal of impulse
   noise in remotely sensed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral; Image restoration; Impulse noise; Noise suppression;
   Remote sensing; Spectral correlation
ID WEIGHTED MEAN FILTER; HIGH-DENSITY SALT; PEPPER NOISE; DIMENSIONALITY
   REDUCTION; HYPERSPECTRAL IMAGES; FUZZY FILTER; SPARSE; RESTORATION;
   ALGORITHM; SHRINKING
AB Multiband images get immense importance in the field of remote sensing image analysis and applications. The remote sensing images get affected by unwanted impulses because of the sensor and bit errors during acquisition and transmission, which hampers remote sensing image analysis and applications by altering the image scenes. The restoration of corrupt satellite images gain extensive consequences and is indeed a great challenge for remote sensing applications. Several spectral filters are proposed in the literature for the last few decades but they fail to preserve the valuable circumstances. In this study, a spectral-spatial 3D dynamic median filter with spatial-spectral property is proposed to deal with the impulse noise in the remotely sensed images without compromising the image quality. Our objective is to remove the impulse noise and restore the original details of the corrupted images with greater efficiency by constructing a 3D dynamic kernel, which can adaptively change the number of neighbours of the corrupted pixel, depending upon the degree of distortions in the neighbourhood. We have also concentrated on the high correlation among the consecutive spectral channels for restoring the information of the corrupted pixel. The proposed filtering method has been rigorously analyzed for varying features of satellite image datasets in the presence of different noise densities. The outcome of the proposed filter is compared with the existing state-of-the-art and recent non-linear filtering methods of image denoising and restoration. The performances and efficiency of the proposed filter have been shown through analysing its superiority over the considered and most accepted advanced filters.
C1 [Das, Srirupa] RCC Inst Informat Technol, Dept Comp Sci & Engn, Kolkata, India.
   [Chakravortty, Somdatta] Maulana Abul Kalam Azad Univ Technol West Bengal, Dept Informat Technol, Haringhata, India.
C3 RCC Institute of Information Technology (RCCIIT); Maulana Abul Kalam
   Azad University of Technology
RP Chakravortty, S (corresponding author), Maulana Abul Kalam Azad Univ Technol West Bengal, Dept Informat Technol, Haringhata, India.
EM srirupadas000@gmail.com; csomdatta@rediffmail.com
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   Aiswarya K, 2010, ICCMS 2010, V4, DOI [10.1109/ICCMS.2010.310, DOI 10.1109/ICCMS.2010.310]
   [Anonymous], IMAGEPROCESSINGPLACE
   [Anonymous], WEEBLYHYPERSPECTRAL
   [Anonymous], MULTISPECHYPERSPECTR
   [Anonymous], REMOTE SENSING LABOR
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Atkinson I, 2003, INT GEOSCI REMOTE SE, P743
   Balasubramanian S, 2009, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, COMMUNICATION AND ENERGY CONSERVATION INCACEC 2009 VOL 1, P99
   Baumgardner M. F., 2015, 220 Band AVIRIS Hyperspectral Image Data Set: June 12, 1992 Indian Pine Test Site 3, DOI [10.4231/R7RX991C, DOI 10.4231/R7RX991C]
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2011, COMMUN ACM, V54, P109, DOI 10.1145/1941487.1941513
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chang Y, 2015, IEEE T IMAGE PROCESS, V24, P1852, DOI 10.1109/TIP.2015.2404782
   Chen GY, 2011, INT J PATTERN RECOGN, V25, P403, DOI 10.1142/S0218001411008725
   Chen GY, 2011, IEEE T GEOSCI REMOTE, V49, P973, DOI 10.1109/TGRS.2010.2075937
   Chen GY, 2009, INT J REMOTE SENS, V30, P4889, DOI 10.1080/01431160802653724
   Chen GY, 2008, CAN J REMOTE SENS, V34, P447, DOI 10.5589/m08-058
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Das S, 2021, SOFT COMPUT, V25, P7379, DOI 10.1007/s00500-021-05697-2
   Dash A, 2015, INT C ADV COMPUT COM, P96, DOI 10.1109/ACCT.2015.100
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Fu B, 2015, NEUROCOMPUTING, V169, P119, DOI 10.1016/j.neucom.2014.11.094
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Guo X, 2013, ISPRS J PHOTOGRAMM, V83, P50, DOI 10.1016/j.isprsjprs.2013.06.001
   He W, 2018, IEEE J-STARS, V11, P713, DOI 10.1109/JSTARS.2018.2800701
   He W, 2017, IEEE T GEOSCI REMOTE, V55, P3909, DOI 10.1109/TGRS.2017.2683719
   He W, 2015, IEEE J-STARS, V8, P3050, DOI 10.1109/JSTARS.2015.2398433
   He W, 2014, INT GEOSCI REMOTE SE, P1536, DOI 10.1109/IGARSS.2014.6946731
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Jayaraj V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/690218
   Kamamjjaman, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P125, DOI 10.1109/ICACCI.2016.7732035
   Kamarujjaman, 2021, MULTIMED TOOLS APPL, V80, P299, DOI 10.1007/s11042-020-09473-6
   Kamarujjaman, 2019, PATTERN ANAL APPL, V22, P1561, DOI 10.1007/s10044-019-00806-2
   Kamarujjaman M, 2015, IEEE INT C RES COMPU, DOI [10.1109/ICRCICN.2015.7434247, DOI 10.1109/ICRCICN.2015.7434247]
   Kamarujjaman S, 2014, INT C DEVICE CIRCUIT, DOI [10.1109/ICDCCom.2014.7024689, DOI 10.1109/ICDCCOM.2014.7024689]
   Kandemir C, 2015, DIGIT SIGNAL PROCESS, V46, P164, DOI 10.1016/j.dsp.2015.08.012
   Kuiteing Simeon Kamdem, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7794, DOI 10.1109/ICASSP.2014.6855117
   Letexier D, 2008, IEEE T GEOSCI REMOTE, V46, P2061, DOI 10.1109/TGRS.2008.916641
   Li J, 2016, IEEE T GEOSCI REMOTE, V54, P5425, DOI 10.1109/TGRS.2016.2564639
   Liu XF, 2012, IEEE GEOSCI REMOTE S, V9, P368, DOI 10.1109/LGRS.2011.2169041
   Ma CB, 2019, MULTIMED TOOLS APPL, V78, P1131, DOI 10.1007/s11042-018-6442-2
   Mafi M, 2018, IEEE T IMAGE PROCESS, V27, P5475, DOI 10.1109/TIP.2018.2857448
   Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Othman H, 2006, IEEE T GEOSCI REMOTE, V44, P397, DOI 10.1109/TGRS.2005.860982
   Pok G, 2003, IEEE T IMAGE PROCESS, V12, P85, DOI 10.1109/TIP.2002.804278
   Raza MT, 2012, NIRMA UNIV INT CONF
   Robin A, 2015, IEEE J-STARS, V8, P2854, DOI 10.1109/JSTARS.2015.2432460
   Rodarmel C., 2002, Surveying and Land Information Science, V62, P115, DOI DOI 10.1109/IGARSS.2001.976068
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Sendur L, 2002, IEEE SIGNAL PROC LET, V9, P438, DOI 10.1109/LSP.2002.806054
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Varghese J, 2014, IET IMAGE PROCESS, V8, P199, DOI 10.1049/iet-ipr.2013.0297
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V54, P595, DOI 10.1016/j.procs.2015.06.069
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Yuan QQ, 2012, IEEE T GEOSCI REMOTE, V50, P3660, DOI 10.1109/TGRS.2012.2185054
   Zhang H., 2012, ISPRS ANN PHOTOGRAMM, V7, P95, DOI [DOI 10.5194/isprsannals-I-7-95-2012, DOI 10.5194/ISPRSANNALS-I-7-95-2012]
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
   Zhu F, 2017, arXiv
NR 68
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 15945
EP 15982
DI 10.1007/s11042-022-13965-y
EA SEP 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000859866600004
DA 2024-07-18
ER

PT J
AU Hosseini, F
   Gharehchopogh, FS
   Masdari, M
AF Hosseini, Fatemeh
   Gharehchopogh, Farhad Soleimanian
   Masdari, Mohammad
TI MOAEOSCA: an enhanced multi-objective hybrid artificial ecosystem-based
   optimization with sine cosine algorithm for feature selection in botnet
   detection in IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-objective; Artificial ecosystem-based optimization; Sine cosine
   algorithm; Feature selection; Botnet detection in IoT
ID PARTICLE SWARM OPTIMIZATION; SECURE
AB The number of Internet of Things (IoT) devices overgrows, and this technology dominates. The importance of IoT security and the growing need to devise intrusion detection systems (IDSs) to detect all types of attacks. The limited sources on the IoT. They have led researchers to explore and provide new and efficient solutions to create Botnet Detection in IoT systems. These systems use data features to detect network traffic status and thus detect malicious behavior. Also, data set features indicate the type of network traffic. Many features in the problem space and network behaviour unpredictability make IDSs the main challenge in establishing security in computer networks. Many unnecessary features have also made feature selection an essential aspect of attack detection systems. This paper developed a multi-objective MOAEOSCA algorithm hybridizing Artificial Ecosystem-based Optimization (AEO) algorithms and the Sine Cosine Algorithm (SCA) for botnet detection in IoT. By accurately identifying the weaknesses of the MOAEOSCA algorithm, it has been tried to cover the weaknesses to a large extent and to reach a robust algorithm. We promoted the proposed algorithm using Bitwise operations, Disruption operator, and Opposition-based learning (OBL) mechanisms. Ten standard datasets in the UCI repository were examined to evaluate the proposed algorithm's performance in solving the feature selection problem to detect a botnet. Simulation findings indicated that the proposed algorithm had an acceptable accuracy in Botnet Detection in the IoT, outperforming other methods. According to the experiments carried out in this paper, the MOAEOSCA algorithm has shown that nine data sets out of ten data sets in the feature selection problem performed better than other optimization algorithms. But in all seven botnet data sets, performance has shown better than different optimization algorithms.
C1 [Hosseini, Fatemeh; Gharehchopogh, Farhad Soleimanian; Masdari, Mohammad] Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
C3 Islamic Azad University
RP Gharehchopogh, FS (corresponding author), Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
EM bonab.farhad@gmail.com
RI Gharehchopogh, Farhad Soleimanian/AAX-9598-2020
OI Gharehchopogh, Farhad Soleimanian/0000-0003-1588-1659
CR Abdollahzadeh B, 2022, ENG COMPUT-GERMANY, V38, P1845, DOI 10.1007/s00366-021-01369-9
   Abdullah JM, 2019, IEEE ACCESS, V7, P43473, DOI 10.1109/ACCESS.2019.2907012
   Al Shorman A, 2020, J AMB INTEL HUM COMP, V11, P2809, DOI 10.1007/s12652-019-01387-y
   Al-Kasassbeh M, J INTELL FUZZY SYST, P1
   Al-Tashi Q, 2019, IEEE ACCESS, V7, P39496, DOI 10.1109/ACCESS.2019.2906757
   Aladeemy M, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105866
   AlKhatib AAA, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P240, DOI [10.1109/SDS49854.2020.9143874, 10.1109/sds49854.2020.9143874]
   AlZu'bi Shadi, 2021, 2021 International Conference on Information Technology (ICIT), P679, DOI 10.1109/ICIT52682.2021.9491125
   AlZu'bi S, 2020, 2020 FIFTH INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P306, DOI [10.1109/FMEC49853.2020.9144916, 10.1109/fmec49853.2020.9144916]
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   Armano G, 2016, EXPERT SYST APPL, V55, P184, DOI 10.1016/j.eswa.2016.02.009
   Asghari K, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12779
   Asghari K, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12734
   Azizi M, 2022, MULTIOBJECTIVE ATOMI
   Bagui Sikha, 2021, International Journal of Machine Learning and Computing, V11, P399, DOI 10.18178/ijmlc.2021.11.6.1068
   Bezerra V.H., 2018, ANAIS PRINCIPAIS 18
   Chen SC, 2018, IEEE TRUST, P372, DOI 10.1109/TrustCom/BigDataSE.2018.00062
   Cheraghchi F, 2018, INFORM SCIENCES, V448, P53, DOI 10.1016/j.ins.2018.03.013
   Chuang LY, 2011, COMPUT BIOL MED, V41, P228, DOI 10.1016/j.compbiomed.2011.02.004
   Ghafori S., 2022, Multi-Objective Combinatorial Optimization Problems and Solution Methods, P177
   Ghaith Iyad H., 2021, 2021 International Conference on Information Technology (ICIT), P714, DOI 10.1109/ICIT52682.2021.9491721
   Ghanem W., 2016, International Journal of Advance Soft Computing Applications, V8
   Gharehchopogh FS, 2022, J BIONIC ENG, V19, P1177, DOI 10.1007/s42235-022-00185-1
   Gharehchopogh FS, 2022, ARCH COMPUT METHOD E, V29, P3281, DOI 10.1007/s11831-021-09698-0
   Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007
   Goldanloo MJ, 2022, J SUPERCOMPUT, V78, P3998, DOI 10.1007/s11227-021-04015-9
   Habib M, 2020, ALGO INTELL SY, P203, DOI 10.1007/978-981-32-9990-0_10
   Habib M, 2020, ARAB J SCI ENG, V45, P6081, DOI 10.1007/s13369-020-04476-9
   Hamdani TM, 2007, LECT NOTES COMPUT SC, V4431, P240
   Han J, 2012, MOR KAUF D, P1
   Hancer E, 2018, INFORM SCIENCES, V422, P462, DOI 10.1016/j.ins.2017.09.028
   Hassan BA, 2021, NEURAL COMPUT APPL, V33, P10987, DOI 10.1007/s00521-020-05649-1
   Hattawi W, 2021, 2021 INT C INFORM TE
   Hosseini S, 2022, EVOL SYST-GER, V13, P101, DOI 10.1007/s12530-020-09362-1
   Huy-Trung Nguyen, 2018, 2018 IEEE International Conference on Information Communication and Signal Processing (ICICSP). Proceedings, P118, DOI 10.1109/ICICSP.2018.8549713
   Jagadeesan S, 2021, MEASUREMENT, V176, DOI 10.1016/j.measurement.2021.109140
   Kesavamoorthy R, 2019, CLUSTER COMPUT, V22, pS9469, DOI 10.1007/s10586-018-2365-y
   Khammassi C, 2020, COMPUT NETW, V172, DOI 10.1016/j.comnet.2020.107183
   Khan MA, 2018, FUTURE GENER COMP SY, V82, P395, DOI 10.1016/j.future.2017.11.022
   Khodadadi N, 2022, SOFT COMPUT, V26, P6659, DOI 10.1007/s00500-022-07050-7
   Khodadadi N, 2021, IEEE ACCESS, V9, P117795, DOI 10.1109/ACCESS.2021.3106487
   Knowles J, 2002, IEEE C EVOL COMPUTAT, P711, DOI 10.1109/CEC.2002.1007013
   Kuhn M., 2013, APPL PREDICTIVE MODE, V26, DOI [10.1007/978-1-4614-6849-3, DOI 10.1007/978-1-4614-6849-3]
   Li JQ, 2019, IEEE INTERNET THINGS, V6, P2093, DOI 10.1109/JIOT.2018.2883344
   Li SY, 2018, IEEE ACCESS, V6, P10311, DOI 10.1109/ACCESS.2018.2800664
   Lin QZ, 2016, INFORM SCIENCES, V339, P332, DOI 10.1016/j.ins.2015.12.022
   Ma XL, 2018, IEEE T EVOLUT COMPUT, V22, P226, DOI 10.1109/TEVC.2017.2704118
   McDermott CD, 2018, IEEE IJCNN
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mohammadi M, 2021, J NETW COMPUT APPL, V178, DOI 10.1016/j.jnca.2021.102983
   Mohemmed AW, 2008, IEEE C EVOL COMPUTAT, P2929, DOI 10.1109/CEC.2008.4631192
   Mohmmadzadeh H, 2021, J SUPERCOMPUT, V77, P9102, DOI 10.1007/s11227-021-03626-6
   Nadimi-Shahraki MH, 2022, J COMPUT SCI-NETH, V61, DOI 10.1016/j.jocs.2022.101636
   Nadimi-Shahraki MH, 2021, PROCESSES, V9, DOI 10.3390/pr9122276
   Nadimi-Shahraki MH, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23121637
   Naseri TS, 2022, J NETW SYST MANAG, V30, DOI 10.1007/s10922-022-09653-9
   Neggaz N, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113103
   Oliva D, 2020, SOFT COMPUT, V24, P14051, DOI 10.1007/s00500-020-04781-3
   Padmavathi B, 2022, J CONTROL DECISION, P1
   Pan AQ, 2018, INFORM SCIENCES, V436, P441, DOI 10.1016/j.ins.2018.01.038
   Qadir QM, 2018, IEEE ACCESS, V6, P77454, DOI 10.1109/ACCESS.2018.2883151
   Rahman CM, 2021, EGYPT INFORM J, V22, P213, DOI 10.1016/j.eij.2020.08.003
   Rana S, 2018, INT J ADV COMPUT SC, V9, P267
   Rezaee H., 2011, 2011 IEEE GCC Conference and Exhibition (GCC), P397, DOI 10.1109/IEEEGCC.2011.5752541
   Roopak M, 2020, IET NETW, V9, P120, DOI 10.1049/iet-net.2018.5206
   Bonab MS, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4434
   Sanchez-Pi N, 2018, LECT NOTES ARTIF INT, V10870, P363, DOI 10.1007/978-3-319-92639-1_30
   Selvarani P, 2019, CLUSTER COMPUT, V22, pS4007, DOI 10.1007/s10586-018-2609-x
   Shamsaldin AS, 2019, J COMPUT DES ENG, V6, P562, DOI 10.1016/j.jcde.2019.04.004
   Sreenivasamurthy S, 2018, I S MOD ANAL SIM COM, P319, DOI 10.1109/MASCOTS.2018.00038
   Suman C, 2019, ARXIV
   Tellez N., 2018, INT ARTIF INTELL, V16, P78
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Wang XH, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106041
   Xue B, 2013, IEEE T CYBERNETICS, V43, P1656, DOI 10.1109/TSMCB.2012.2227469
   Xue Y, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2492956
   Zavala GR, 2014, STRUCT MULTIDISCIP O, V49, P537, DOI 10.1007/s00158-013-0996-4
   Zhao WG, 2020, NEURAL COMPUT APPL, V32, P9383, DOI 10.1007/s00521-019-04452-x
   Zhu YY, 2017, KNOWL-BASED SYST, V116, P74, DOI 10.1016/j.knosys.2016.10.030
   Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969
NR 80
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13369
EP 13399
DI 10.1007/s11042-022-13836-6
EA SEP 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000858393000005
DA 2024-07-18
ER

PT J
AU Tessore, JP
   Esnaola, LM
   Ramón, HD
   Lanzarini, L
   Baldassarri, S
AF Tessore, Juan Pablo
   Esnaola, Leonardo Martin
   Ramon, Hugo Dionisio
   Lanzarini, Laura
   Baldassarri, Sandra
TI Contextual information usage for the enhancement of basic emotion
   classification in a weakly labelled social network dataset in Spanish
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distant supervision; Basic emotion classification; Contextual
   information; Social media
ID SENTIMENT ANALYSIS; STRENGTH DETECTION
AB Basic emotion classification is one of the main tasks of Sentiment Analysis usually performed by using several machine learning techniques. One of the main issues in Sentiment Analysis is the availability of tagged resources to properly train supervised classification algorithms. This is of particular concern in languages other than English, such as Spanish, where scarcity of these resources is the norm. In addition, most basic emotion datasets available in Spanish are rather small, containing a few hundred (or thousand) samples. Usually, the samples only contain a short text (frequently a comment) and a tag (the basic emotion), omitting crucial contextual information that may help to improve the classification task results. In this paper, the impact of using contextual information is measured on a recently published Spanish basic emotion dataset and the baseline architecture proposed in the Semantic Evaluation 2019 competition. This particular dataset has two main advantages for this paper. First, it was compiled using Distant Supervision and as a result it contains several hundred thousand samples. Secondly, the authors included valuable contextual information for each comment. The results show that contextual information, such as news headlines or summaries, helps improve the classification accuracy over a dataset of distantly supervised basic emotion labelled comments.
C1 [Tessore, Juan Pablo; Esnaola, Leonardo Martin; Ramon, Hugo Dionisio] Univ Nacl Noroeste Buenos Aires, Inst Invest & Transferencia Tecnol ITT, Ctr CICPBA, Junin, Argentina.
   [Tessore, Juan Pablo] Consejo Nacl Invest Cient & Tecn CONICET, Buenos Aires, Argentina.
   [Lanzarini, Laura] Univ Nacl La Plata, Inst Invest Informat LIDI Ctr CICPBA, Fac Informat, La Plata, Argentina.
   [Baldassarri, Sandra] Univ Zaragoza, Dept Informat & Ingn Sistemas, Zaragoza, Spain.
   [Baldassarri, Sandra] Univ Zaragoza, Inst Invest Ingn I3A, Zaragoza, Spain.
C3 Universidad Nacional del Noroeste de la Provincia de Buenos Aires;
   Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET);
   National University of La Plata; University of Zaragoza; University of
   Zaragoza
RP Tessore, JP (corresponding author), Univ Nacl Noroeste Buenos Aires, Inst Invest & Transferencia Tecnol ITT, Ctr CICPBA, Junin, Argentina.; Tessore, JP (corresponding author), Consejo Nacl Invest Cient & Tecn CONICET, Buenos Aires, Argentina.
EM juanpablo.tessore@ittunnoba.edu.ar; leonardo.esnaola@itt.unnoba.edu.ar;
   hugo.ramon@itt.unnoba.edu.ar; laural@lidi.info.edu.ar; sandra@unizar.es
RI ; Baldassarri, Sandra/L-6033-2014
OI Tessore, Juan Pablo/0000-0002-2111-0976; Ramon,
   Hugo/0000-0003-1577-3092; Baldassarri, Sandra/0000-0002-9315-6391;
   Esnaola, Leonardo/0000-0001-6298-9019
FU Consejo Nacional de Investigaciones Cientificas y Tecnicas, Argentina
   [RESOL-2020-131-APNDIR#CONICET]; Convocatoria para la Acreditacion de
   Proyectos y Solicitud de Subsidios de Investigacion Bianuales 2019;
   Secretaria de Investigacion Desarrollo y Transferencia, Universidad
   Nacional del Noroeste de la Provincia de Buenos Aires, Argentina [EXP
   536-2019]; Gobierno de Aragon, Espana [AffectiveLab-T60-20R]; Ministerio
   de Ciencia, Innovacion y Universidades, Espana [RTI2018-096986-B-C31]
FX This study was funded by: Consejo Nacional de Investigaciones
   Cientificas y Tecnicas, Argentina, (RESOL-2020-131-APNDIR#CONICET).
   Convocatoria para la Acreditacion de Proyectos y Solicitud de Subsidios
   de Investigacion Bianuales 2019, Secretaria de Investigacion Desarrollo
   y Transferencia, Universidad Nacional del Noroeste de la Provincia de
   Buenos Aires, Argentina, (EXP 536-2019). Gobierno de Aragon, Espana,
   (AffectiveLab-T60-20R). Ministerio de Ciencia, Innovacion y
   Universidades, Espana, (contrato RTI2018-096986-B-C31).
CR Agarwal B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/715730
   AGRAWAL P, 2019, P 13 INT WORKSH SEM, P266
   [Anonymous], TALLER ANALISIS SENT
   [Anonymous], 2017, FASTTEXT FASTTEXT TE
   [Anonymous], 2021, Keras
   [Anonymous], 1963, AFIPS Conference Proceedings
   Bae S, 2019, P 13 INT WORKSHOP SE, P312
   Bae Y, 2012, J AM SOC INF SCI TEC, V63, P2521, DOI 10.1002/asi.22768
   Basile A., 2019, P 13 INT WORKSHOP SE, P330
   Bi JW, 2019, INT J PROD RES, V57, P7068, DOI 10.1080/00207543.2019.1574989
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Cambria E, 2012, 25 INT FLAIRS C
   Cambria E, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.4531228
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Canete J, 2019, COMPILATION LARGE SP
   Cardellino C., 2019, Spanish billion words corpus and embeddings
   Chatterjee A., 2019, P 13 INT WORKSH SEM, P39, DOI DOI 10.18653/V1/S19-2005
   Chaturvedi I, 2016, IEEE IJCNN, P4474, DOI 10.1109/IJCNN.2016.7727785
   Chen L, 2011, SOC NETW ANAL MIN, V1, P301, DOI 10.1007/s13278-011-0023-y
   Chiruzzo L., 2021, CEUR WORKSHOP PROC, V2943, P72
   Diaz-Galiano M. C., 2019, P IBERIAN LANGUAGES, P550
   Duiaz S., 2018, 39 JORN AUT 2018 SEP, P644
   El Alaoui I, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0120-0
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Fu Y., 2021, CEUR WORKSHOP PROC, V2943, P27
   Garc?a-D?az JA., 2021, CEUR WORKSHOP PROC, V2943, P59
   Ghosal D., 2018, P 2018 C EMP METH NA, P3454, DOI [10.18653/v1/D18-1382, DOI 10.18653/V1/D18-1382]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Huang CK, 2019, PROCEEDINGS OF THE 2019 ACM MOBIHOCWORKSHOP ON PERVASIVE SYSTEMS IN THE IOT ERA (PERSIST-IOT '19), P49, DOI 10.1145/3331052.3332478
   Jain T.I., 2010, Int. J. Comput. Appl., V7, P12, DOI 10.5120/1160-1453
   Gambino OJ, 2019, COMPUT SPEECH LANG, V58, P280, DOI 10.1016/j.csl.2019.03.004
   Justo R, 2018, COGN COMPUT, V10, P1135, DOI 10.1007/s12559-018-9578-5
   Li K., 2021, CEUR WORKSHOP PROC, V2943, P49
   Liang X., 2019, P 13 INT WORKSHOP SE, P345
   Luo H., 2021, P IB LAND EV FOR IBE, P35
   Mahata D, 2018, ARXIV
   Majumder N, 2019, IEEE INTELL SYST, V34, P38, DOI 10.1109/MIS.2019.2904691
   Majumder N, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.23
   Mercado V, 2020, J COMPUT SCI TECHNOL, V20, P43, DOI 10.24215/16666038.20.e05
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Plaza-del-Arco FM, 2021, PROCES LENG NAT, P155, DOI 10.26342/2021-67-13
   Moctezuma, 2017, CEUR WORKSHOP PROC, V1896, P23
   Muhammad A, 2016, KNOWL-BASED SYST, V108, P92, DOI 10.1016/j.knosys.2016.05.032
   Mukherjee Indrajit, 2017, International Journal of Information Engineering and Electronic Business, V9, P31, DOI 10.5815/ijieeb.2017.04.05
   Nakov P., 2013, 2 JOINT C LEXICAL CO, P312
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Poria S, 2017, IEEE DATA MINING, P1033, DOI 10.1109/ICDM.2017.134
   Qu S, 2021, CEUR WORKSHOP PROC, P94
   Qu Y., 2021, CEUR WORKSHOP PROC, V2943, P101
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   S?nchez JAF., 2021, CEUR WORKSHOP PROC, V2943, P43
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Sebastiani F., 2006, P 5 INT C LANG RES E, P417, DOI DOI 10.1155/2015/715730
   Serra Ariadna de Arriba, 2021, CEUR WORKSHOP PROC, P86
   Tessore JP, 2022, COGN COMPUT, V14, P407, DOI 10.1007/s12559-020-09800-x
   Thakkar H, 2015, ARXIV
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Vanzo A., 2014, The 25th International Conference on Computational Linguistics: Technical Papers, P2345
   Vera D., 2021, CEUR WORKSH P, V2943, P16
   Vitiugin F, 2021, IBERLEF SEPLN, P78
   Voleti, 2018, INTUITION LSTM
   Vosoughi S., 2015, Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, P16
   Winata G.I., 2019, P 13 INT WORKSHOP SE, P142
   Xiao J., 2019, P 13 INT WORKSHOP SE, P220
   Yusof Nor Nadiah, 2018, International Journal of Machine Learning and Computing, V8, DOI 10.18178/ijmlc.2018.8.4.719
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
NR 68
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9871
EP 9890
DI 10.1007/s11042-022-13750-x
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854695000003
DA 2024-07-18
ER

PT J
AU Keyvanpour, MR
   Shirzad, MB
   Heydarian, F
AF Keyvanpour, Mohammad Reza
   Shirzad, Mehrnoush Barani
   Heydarian, Farideh
TI Android malware detection applying feature selection techniques and
   machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Android operating system; Malware detection; Machine learning; Random
   forest; Feature selection
AB Android operating system is known as one of the most popular mobile operating systems. The malware intrusion increases in the same pace as the production of applicable software. Propagation of new and transformed malware in seconds is a critical challenge in malware detection. Android software supplies thousands of features, providing assistance to identify malware applications. In this paper, a novel method based on a random forest algorithm, which applied three different feature selection techniques is proposed. This paper assesses the consequence of applying three different feature selection types including effective, high weight and effective group feature selection. Experiments conducted on Drebin dataset indicate applying the feature selection methods ameliorate the accuracy in terms of metrics and required time. In addition, comparison between the candidate feature selection model and a variety of algorithms as baselines proves the merit of applying feature selection on Random Forest, which outperforms other models based on several metrics.
C1 [Keyvanpour, Mohammad Reza; Heydarian, Farideh] Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
   [Shirzad, Mehrnoush Barani] Alzahra Univ, Fac Engn, Dept Comp Engn, Data Min Lab, Tehran, Iran.
C3 Alzahra University; Alzahra University
RP Keyvanpour, MR (corresponding author), Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
EM Keyvanpour@alzahra.ac.ir
RI Keyvanpour, Mohammad Reza/AAL-5574-2020
OI Keyvanpour, Mohammad Reza/0000-0003-2115-9099
CR Aafer Y, 2013, L N INST COMP SCI SO, V127, P86
   Alatwi HA, 2016, SIGITE'16: PROCEEDINGS OF THE 17TH ANNUAL CONFERENCE ON INFORMATION TECHNOLOGY EDUCATION, P54, DOI 10.1145/2978192.2978218
   Almin SB, 2015, PROCEDIA COMPUT SCI, V45, P407, DOI 10.1016/j.procs.2015.03.170
   Alzaylaee M.K., 2017, Proceedings of the 3rd ACM on International Workshop on Security And Privacy Analytics, P65, DOI DOI 10.1145/3041008.3041010
   [Anonymous], 2013, YEARS MOB MALW
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Baker S, 2016, INT DATA CORPORATION
   Bhattacharya A., 2018, Lecture Notes in Networks and Systems, P249, DOI DOI 10.1007/978-981-10-6916-1_23
   Bhattacharya A, 2018, J GLOB INF MANAG, V26, P54, DOI 10.4018/JGIM.2018070105
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Dash SK, 2016, 2016 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2016), P252, DOI 10.1109/SPW.2016.25
   Firdaus A, 2018, FRONT INFORM TECH EL, V19, P712, DOI 10.1631/FITEE.1601491
   de la Puerta JG, 2015, ADV INTELL SYST COMP, V369, P389, DOI 10.1007/978-3-319-19713-5_33
   Idrees F, 2017, COMPUT SECUR, V68, P36, DOI 10.1016/j.cose.2017.03.011
   Keyvanpour MR, 2013, INTELL DATA ANAL, V17, P367, DOI 10.3233/IDA-130584
   Kumar MV., 2019, INT J SCI RES REV, V7, P105
   Kumar R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9020277
   Li CL, 2019, IEEE ACCESS, V7, P184008, DOI 10.1109/ACCESS.2019.2958927
   Martín A, 2019, INFORM FUSION, V52, P128, DOI 10.1016/j.inffus.2018.12.006
   Martín I, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5749481
   Milosevic N, 2017, COMPUT ELECTR ENG, V61, P266, DOI 10.1016/j.compeleceng.2017.02.013
   Ozdemir M., 2014, Transactions on Machine Learning and Artificial Intelligence, V2, P90
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peiravian N., 2013, Data Mining Heuristic-Based Malware Detection for Android Applications
   Sanz B, 2013, ADV INTELL SYST COMP, V189, P289
   Sanz B, 2012, CONSUM COMM NETWORK, P149, DOI 10.1109/CCNC.2012.6181075
   Sharma K, 2018, COMPUT ELECTR ENG, V71, P416, DOI 10.1016/j.compeleceng.2018.08.003
   Shirzad MB, 2018, INT J INF RETR RES, V8, P46, DOI 10.4018/IJIRR.2018070104
   Shirzad MB, 2017, ADV INTELL SYST, V573, P273, DOI 10.1007/978-3-319-57261-1_27
   Shrivastava G, 2019, MULTIMED TOOLS APPL, V78, P35713, DOI 10.1007/s11042-019-07899-1
   Spreitzenbarth M., 2013, P 28 ANN ACM S APPL, DOI [DOI 10.1145/2480362.2480701, 10.1145/2480362.2480701]
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P5028, DOI 10.1109/TGRS.2020.3011002
   Wang Q, 2022, IEEE T CYBERNETICS, V52, P12966, DOI 10.1109/TCYB.2021.3094843
   Wen L, 2017, AIP CONF PROC, V1864, DOI 10.1063/1.4992953
   Xing Liu, 2014, 2014 2nd IEEE International Conference on Mobile Cloud Computing, Services and Engineering (MobileCloud), P142, DOI 10.1109/MobileCloud.2014.22
   Yerima SY, 2015, IET INFORM SECUR, V9, P313, DOI 10.1049/iet-ifs.2014.0099
   Yerima SY, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P1236, DOI 10.1109/SAI.2015.7237302
   Yerima SY, 2014, IET INFORM SECUR, V8, P25, DOI 10.1049/iet-ifs.2013.0095
   Yerima SY, 2013, INT CON ADV INFO NET, P121, DOI 10.1109/AINA.2013.88
   Yerima SY., 2014, ANDROID MALWARE DETE
   Yildiz O, 2019, INT J SOFTW ENG KNOW, V29, P245, DOI 10.1142/S0218194019500116
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   Zandian ZK, 2019, APPL ARTIF INTELL, V33, P669, DOI 10.1080/08839514.2019.1592347
   Zandian ZK, 2017, INT J KNOWL-BASED IN, V21, P123, DOI 10.3233/KES-170357
   Zenghui Liu, 2015, International Journal of Simulation and Process Modelling, V10, P315
NR 45
TC 6
Z9 6
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9517
EP 9531
DI 10.1007/s11042-022-13767-2
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000854682700003
DA 2024-07-18
ER

PT J
AU Cao, ZW
   Qin, Y
   Li, YL
   Xie, ZY
   Guo, JY
   Jia, LM
AF Cao, Zhiwei
   Qin, Yong
   Li, Yongling
   Xie, Zhengyu
   Guo, Jianyuan
   Jia, Limin
TI Face detection for rail transit passengers based on single shot detector
   and active learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Mask detection; Rail transit passengers; Single shot
   detector; Active learning
ID FASTER
AB COVID-19 spreads rapidly among people, so that more and more people are wearing masks in rail transit stations. However, the current face detection algorithms cannot distinguish between a face wearing a mask and a face not wearing a mask. This paper proposes a face detection algorithm based on single shot detector and active learning in rail transit surveillance, effectively detecting faces and faces wearing masks. Firstly, we propose a real-time face detection algorithm based on single shot detector, which improves the accuracy by optimizing backbone network, feature pyramid network, spatial attention module, and loss function. Subsequently, this paper proposes a semi-supervised active learning method to select valuable samples from video surveillance of rail transit to retrain the face detection algorithm, which improves the generalization of the algorithm in rail transit and reduces the time to label samples. Extensive experimental results demonstrate that the proposed method achieves significant performance over the state-of-the-art algorithms on rail transit dataset. The proposed algorithm has a wide range of applications in rail transit stations, including passenger flow statistics, epidemiological analysis, and reminders of passenger who do not wear masks. Simultaneously, our algorithm does not collect and store face information of passengers, which effectively protects the privacy of passengers.
C1 [Cao, Zhiwei; Qin, Yong; Li, Yongling; Jia, Limin] Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, 3 Shangyuancun, Beijing 100044, Peoples R China.
   [Cao, Zhiwei; Li, Yongling; Xie, Zhengyu; Guo, Jianyuan] Beijing Jiaotong Univ, Sch Traff & Transportat, Beijing 100044, Peoples R China.
   [Qin, Yong; Jia, Limin] Beijing Res Ctr Urban Traff Informat Sensing & Se, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Qin, Y (corresponding author), Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, 3 Shangyuancun, Beijing 100044, Peoples R China.; Qin, Y (corresponding author), Beijing Res Ctr Urban Traff Informat Sensing & Se, Beijing 100044, Peoples R China.
EM yqin@bjtu.edu.cn
RI cao, zhiwei/AAR-9207-2020
OI cao, zhiwei/0000-0003-1611-9703
FU Fundamental Research Funds for the Central Universities [2018JBZ006]
FX This work was supported by Fundamental Research Funds for the Central
   Universities [2018JBZ006].
CR [Anonymous], 2010, U WISCONSIN MADISON, V52, P11, DOI DOI 10.1016/J.MATLET.2010.11.072
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Brust C.-A., 2018, ARXIV
   Chiang D., 2020, Detect faces and determine whether people are wearing mask
   Desai SV, 2019, ARXIV
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   He Y., 2019, ARXIV
   Holub A, 2008, PROC CVPR IEEE, P885
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jeong J, 2017, ARXIV
   Jiang M., 2020, ARXIV
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Joshi Ajay J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2372, DOI 10.1109/CVPRW.2009.5206627
   Kao CC, 2019, LECT NOTES COMPUT SC, V11366, P506, DOI 10.1007/978-3-030-20876-9_32
   Konyushkova K, 2018, PROC CVPR IEEE, P9175, DOI 10.1109/CVPR.2018.00956
   Kovashka A, 2011, IEEE I CONF COMP VIS, P1403, DOI 10.1109/ICCV.2011.6126395
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li X, 2013, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2013.116
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Long CJ, 2015, IEEE I CONF COMP VIS, P2839, DOI 10.1109/ICCV.2015.325
   Misra D., 2019, ARXIV190808681
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Papadopoulos DP, 2017, IEEE I CONF COMP VIS, pCP38, DOI 10.1109/ICCV.2017.528
   Papadopoulos DP, 2017, PROC CVPR IEEE, P180, DOI 10.1109/CVPR.2017.27
   Papadopoulos DP, 2016, PROC CVPR IEEE, P854, DOI 10.1109/CVPR.2016.99
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy S., 2018, 29 BRIT MACH VIS C B, P91
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sethi S, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103848
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vijayanarasimhan S, 2011, INT J COMPUT VISION, V91, P24, DOI 10.1007/s11263-010-0372-4
   Wang ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1072
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang S., 2019, ARXIV
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
NR 48
TC 2
Z9 2
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42433
EP 42456
DI 10.1007/s11042-022-13491-x
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000847629600004
PM 36060225
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wang, Z
   Wang, Y
   Bai, XL
   Zhang, SS
   He, WP
   Zhang, XY
   Han, S
   Yan, YX
AF Wang, Zhuo
   Wang, Yang
   Bai, Xiaoliang
   Zhang, Shusheng
   He, Weiping
   Zhang, Xiangyu
   Han, Shu
   Yan, Yuxiang
TI Micro-information-level AR instruction: a new visual representation
   supporting manual classification of similar assembly parts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Manual classification; Assembly instruction; Visual
   representation
ID AUGMENTED REALITY; INDUSTRY 4.0; MAINTENANCE; SYSTEM
AB In AR operation guidance training, for assembly parts with similar geometric shapes, there are still two problems in the visual representation of AR instructions: (1) AR instructions cannot accurately represent the micro-geometric differences between similar parts. (2) The AR instruction design specification that reflects the micro-geometric differences of similar parts has not been formulated. Based on such a problem, our team has carried out the following research work: First, the geometric features of parts are defined at the micro-geometric level and micro-information level, thereby explaining the relationships and differences between similar part features. From the above two levels. Secondly, a mathematical model of the geometric features of the parts is established, and the control parameters in the model are given to characterize the feature differences between similar parts. To verify the accuracy of the control parameters, we designed three AR instructions based on the control parameters and verified them through five hypotheses. Our team then analyzed the data from a case study and focused our discussion on test results that did not meet expectations. We have a more in-depth discussion by comparing the differences and analyzing the results. Finally, three implications of AR instructions in representing feature differences between similar parts are given, and future research directions for such work are indicated. It is provided guidance for future research.
C1 [Wang, Zhuo] Univ Shanghai Sci & Technol, Sch Mech Engn, Shanghai 200093, Peoples R China.
   [Wang, Zhuo; Bai, Xiaoliang; Zhang, Shusheng; He, Weiping; Zhang, Xiangyu; Han, Shu; Yan, Yuxiang] Cyber Real Innovat Ctr China, Nanjing 211200, Peoples R China.
   [Wang, Yang] AVIC Xinxiang Aviat Ind Grp Co Ltd, Civil Aircraft R&D Ctr, Xinxiang 453049, Henan, Peoples R China.
C3 University of Shanghai for Science & Technology; Aviation Industry
   Corporation of China (AVIC)
RP Wang, Y (corresponding author), AVIC Xinxiang Aviat Ind Grp Co Ltd, Civil Aircraft R&D Ctr, Xinxiang 453049, Henan, Peoples R China.
EM wy102344@gmail.com
RI Zhang, Shusheng/GRO-2963-2022
OI Wang, Zhuo/0000-0002-4582-3401
FU Defense Industrial Technology Development Program [XXXX2018213A001];
   SASTIND China [JCKY2018205B021]
FX This work is partly supported by Defense Industrial Technology
   Development Program(No. XXXX2018213A001) and SASTIND China under Grant
   (JCKY2018205B021).
CR Almiyad MA, 2017, LECT NOTES ARTIF INT, V10331, P450, DOI 10.1007/978-3-319-61425-0_38
   Ceruti A, 2019, J COMPUT DES ENG, V6, P516
   Chu CH, 2021, J MANUF SYST, V61, P685, DOI 10.1016/j.jmsy.2021.04.003
   Feng S., 2022, IEEE T WIREL COMMUN, P1
   Fiorentino M, 2009, INT J INTERACT DES M, V3, P121, DOI 10.1007/s12008-009-0062-z
   Gattullo M, 2019, ROBOT CIM-INT MANUF, V56, P276, DOI 10.1016/j.rcim.2018.10.001
   HENDERSON S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI DOI 10.1109/TVCG.2010.245
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Huang JM, 2017, COMPUT AIDED DESIGN, V84, P1, DOI 10.1016/j.cad.2016.10.004
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Lai ZH, 2020, J MANUF SYST, V55, P69, DOI 10.1016/j.jmsy.2020.02.010
   Laviola E, 2022, INT J ADV MANUF TECH, V119, P1769, DOI 10.1007/s00170-021-08449-6
   Liu C, 2017, J MANUF SYST, V44, P280, DOI 10.1016/j.jmsy.2017.04.008
   Nurelmadina N, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010338
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Raji MF, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/3204695
   Shin J.-e., 2021, P 2021 CHI C HUMAN F, P1, DOI [10.1145/3411764.3445675, DOI 10.1145/3411764.3445675]
   Siew CY, 2019, ROBOT CIM-INT MANUF, V59, P115, DOI 10.1016/j.rcim.2019.03.010
   Urbas U, 2019, PROC CIRP, V81, P832, DOI 10.1016/j.procir.2019.03.208
   Vanneste P, 2020, INT J HUM-COMPUT ST, V143, DOI 10.1016/j.ijhcs.2020.102480
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P31059, DOI 10.1007/s11042-020-09731-7
   [王增磊 Wang Zenglei], 2019, [西北工业大学学报, Journal of Northwestern Polytechnical University], V37, P496
   Wang Z, 2021, IEEE T KNOWL DATA EN, V33, P3634, DOI 10.1109/TKDE.2020.2971490
   Wang Z, 2021, INT J ADV MANUF TECH, V115, P475, DOI 10.1007/s00170-021-07142-y
   Wang Z, 2021, INT J HUM-COMPUT INT, V37, P1799, DOI 10.1080/10447318.2021.1909278
   Wang Z, 2020, INT J ADV MANUF TECH, V106, P603, DOI 10.1007/s00170-019-04538-9
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
NR 27
TC 1
Z9 1
U1 7
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11589
EP 11618
DI 10.1007/s11042-022-13574-9
EA AUG 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000843355500001
DA 2024-07-18
ER

PT J
AU Bao, JN
   Zhang, YZ
   Zhu, SD
AF Bao, Jining
   Zhang, Yunzhou
   Zhu, Shangdong
TI Scale space tracker with multiple features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Correlation filter; Color space; Multiple features
ID OBJECT TRACKING
AB Object tracking in videos has been a hot research for decades. Many approaches have been applied to improve the visual tracking, a challenging task in computer vision. Compared with the state-of-the-art methods, correlation filters have achieved more significant performance in visual object tracking. However, their flexibilities in the robust scale estimation are not very well. In this paper, we improve the performance of tracking with high discrimination power and explore an energy-efficient approach to design a simple superior tracker. First, instead of one simple feature extraction, we utilize multi-feature channels from the color space and convolutional layers, respectively, and establish a corresponding weighted formulation to fuse multiple features. Through the optimization, it can effectively obtain the latest position estimation of target object. Furthermore, the scale space correlation filter is investigated by the tracking-by-detection structure to distinguish the scale variation of the target object according to the updating position estimation. Additionally, we employ fusion approach to merge the multi-channel response maps to obtain an optimal tracking result, which ensures that our model can supply sufficient tracking information. Compared with the existing tracking approaches, we reduce the computation complexity. On the OTB-dataset, our tracker significantly improves the baseline, with a gain of 3.4% in the experimental evaluation. Both quantitative and qualitative evaluations are implemented on multiple benchmark sequences to demonstrate that the effectiveness of our proposed algorithm outperforms the state-of-the-art approaches.
C1 [Bao, Jining; Zhang, Yunzhou] Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Liaoning, Peoples R China.
   [Zhu, Shangdong] Northeastern Univ, Fac Robot Sci & Engn, Shenyang, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Bao, JN (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Liaoning, Peoples R China.
EM yiyinbaobao@126.com; zhangyunzhou@mail.neu.cdu.cn
OI Zhu, Shangdong/0000-0003-4701-2028
FU National Natural Science Foundation of China [61973066, 61471110];
   Foundation Project of National Key Laboratory [6142002301, 61420030302];
   Distinguished Creative Talent Program of Shenyang [RC170490];
   Fundamental Research Funds for the Central Universities [N172608005,
   N182608004]; China Postdoctoral Science Foundation [2019 M661117];
   Scientific Research Fund Project of Liaoning Provincial Department of
   Education [JYT19040]; Natural Science Foundation of Liaoning Province
   Science and Technology Department [2019-ZD-0234]
FX Supported by National Natural Science Foundation of China (No. 61973066,
   61471110), Foundation Project of National Key Laboratory (6142002301,
   61420030302), the Distinguished Creative Talent Program of Shenyang
   (RC170490), the Fundamental Research Funds for the Central Universities
   (N172608005, N182608004), China Postdoctoral Science Foundation (No.2019
   M661117), the Scientific Research Fund Project of Liaoning Provincial
   Department of Education (No. JYT19040), the Natural Science Foundation
   of Liaoning Province Science and Technology Department (No.
   2019-ZD-0234).
CR Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   BERLIN BRENT., 1999, Basic color terms: Their universality and evolution
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bozic A, 2020, ADV NEURAL INFORM PR, V33, P18727
   Breve B, 2020, 26 INT C DISTRIBUTED, P49, DOI [10.18293/DMSVIVA20-011, DOI 10.18293/DMSVIVA20-011]
   Breve B, 2022, MULTIMED TOOLS APPL, V81, P73, DOI 10.1007/s11042-021-11077-7
   Cho K., 2014, ARXIV14061078
   Choi J., 2017, arXiv
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Feng YY, 2020, MULTIMED TOOLS APPL, V79, P16941, DOI 10.1007/s11042-019-7483-x
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hochreiter S, 1997, ADV NEUR IN, V9, P473
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kawakami K., 2008, THESIS
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee DH, 2021, MULTIMED TOOLS APPL, V80, P34237, DOI 10.1007/s11042-020-09924-0
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Pan ZB, 2020, MULTIMED TOOLS APPL, V79, P5477, DOI 10.1007/s11042-019-08205-9
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang N., 2015, ARXIV
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhou W, 2019, MED BIOL ENG COMPUT, V57, P2055, DOI 10.1007/s11517-019-02011-z
   Zhu JM, 2021, MULTIMED TOOLS APPL, V80, P15469, DOI 10.1007/s11042-021-10574-z
NR 51
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5663
EP 5684
DI 10.1007/s11042-022-13449-z
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000832844000006
DA 2024-07-18
ER

PT J
AU Xia, TE
   Zhang, JY
AF Xia, Tie-en
   Zhang, Jing-ya
TI Clothing classification using transfer learning with squeeze and
   excitation block
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; Dataset construction; Clothing classification;
   Squeeze and excitation block
ID CONVOLUTIONAL NEURAL-NETWORKS; RECOGNITION; NET
AB Automatic clothing classification with deep learning models becomes an inevitable trend in the era of artificial intelligence. Clothing classification methods using conventional convolution neural networks are computationally expensive due to the tremendous training load. To reduce the training time and to improve test accuracy, in this paper, we design a novel transfer learning model and a new training mode. Our proposed transfer learning model is constructed by a pre-trained neural network and novel classification layers with Squeeze-and-Excitation Blocks. The feature maps extracted by the pre-trained CNN are reweighted to enhance the feature selection ability in the blocks. Instead of fine-tuning the un-frozen convolution layers that require extra convolution computing, we separate the classification layers from convolution layers and train it using the adaptive learning rate optimization. Moreover, to facilitate training dataset construction with specific tasks, a novel dataset construction technique is proposed in this paper. Experiments validated that our method can reduce the training time from 25531s to 1419s and also reached classification accuracy of 97.205% that outperformed the existing state-of-art transfer learning methods. It demonstrated that our novel method has potentials in fast data collection, more efficient training for classification models using less training data and simpler computing hardware.
C1 [Xia, Tie-en; Zhang, Jing-ya] Changshu Inst Technol, Sch Elect & Informat Engn, Changshu, Jiangsu, Peoples R China.
C3 Changshu Institute of Technology
RP Zhang, JY (corresponding author), Changshu Inst Technol, Sch Elect & Informat Engn, Changshu, Jiangsu, Peoples R China.
EM zhangjy0611@163.com
OI , zhangjy0611/0000-0003-0583-8972
CR Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Basly H, 2022, VISUAL COMPUT, V38, P993, DOI 10.1007/s00371-021-02064-y
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bayoudh K, 2021, APPL INTELL, V51, P124, DOI 10.1007/s10489-020-01801-5
   Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212
   Carreira J, 1998, IEEE T SOFTWARE ENG, V24, P125, DOI 10.1109/32.666826
   Chen JC, 2017, SOFT COMPUT, V21, P2923, DOI 10.1007/s00500-017-2585-8
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dimou A, 2019, IEEE T CIRC SYST VID, V29, P2363, DOI 10.1109/TCSVT.2018.2869680
   Donati L, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071385
   Ganti Venkatesh., 2013, DATA CLEANING PRACTI
   Gu XL, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102276
   He GQ, 2020, IEEE ACCESS, V8, P15436, DOI 10.1109/ACCESS.2020.2966651
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hidayati SC, 2018, IEEE T CYBERNETICS, V48, P1647, DOI 10.1109/TCYB.2017.2712634
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu JF, 2019, WOOD SCI TECHNOL, V53, P505, DOI 10.1007/s00226-019-01086-z
   Khan ZY, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114528
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang ZZ, 2021, NEUROCOMPUTING, V425, P191, DOI 10.1016/j.neucom.2020.04.085
   Li DS, 2019, AUTOMAT CONSTR, V101, P199, DOI 10.1016/j.autcon.2019.01.017
   Li RF, 2018, IEEE ACCESS, V6, P36283, DOI 10.1109/ACCESS.2018.2848966
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Nguyen ND, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P33, DOI [10.1109/APCCAS47518.2019.8953123, 10.1109/apccas47518.2019.8953123]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ravindran P, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0292-9
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Seo Y, 2019, EXPERT SYST APPL, V116, P328, DOI 10.1016/j.eswa.2018.09.022
   Srivastava D, 2019, MULTIMED TOOLS APPL, V78, P14129, DOI 10.1007/s11042-018-6793-8
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Uzun E, 2020, IEEE ACCESS, V8, P208910, DOI 10.1109/ACCESS.2020.3039044
   Wazarkar S, 2018, MULTIMED TOOLS APPL, V77, P25941, DOI 10.1007/s11042-018-5829-4
   Weng YC, 2019, IEEE T COMPUT SOC SY, V6, P547, DOI 10.1109/TCSS.2019.2914499
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xiang J, 2020, IEEE ACCESS, V8, P48299, DOI 10.1109/ACCESS.2020.2979164
   Yamazaki K, 2017, AUTON ROBOT, V41, P865, DOI 10.1007/s10514-016-9559-z
   Zhu WB, 2021, CHEMOMETR INTELL LAB, V211, DOI 10.1016/j.chemolab.2021.104269
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zou MY, 2018, SENS IMAGING, V19, DOI 10.1007/s11220-018-0191-1
NR 43
TC 4
Z9 4
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2839
EP 2856
DI 10.1007/s11042-022-13395-w
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000823376700004
DA 2024-07-18
ER

PT J
AU El Raheb, K
   Buccoli, M
   Zanoni, M
   Katifori, A
   Kasomoulis, A
   Sarti, A
   Ioannidis, Y
AF El Raheb, Katerina
   Buccoli, Michele
   Zanoni, Massimiliano
   Katifori, Akrivi
   Kasomoulis, Aristotelis
   Sarti, Augusto
   Ioannidis, Yannis
TI Towards a general framework for the annotation of dance motion sequences
   A framework and toolkit for collecting movement descriptions as
   ground-truth datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movement annotation; Dance; Motion capture; Movement analysis; User
   interfaces; Tagging; Multimedia
ID TEMPORAL SEGMENTATION; SEMANTIC GAP; RECOGNITION
AB In this paper, we present a conceptual framework and toolkit for movement annotation. We explain how the design of the annotation systems, based on the framework, if combined with specific strategies for the process of annotation, can enhance the collection of ground-truth datasets for training algorithms. Computational algorithms, such as machine learning, show promising results for massive and scalable automatic movement annotation. Nevertheless, the need for reliable ground-truth datasets annotated by human experts, to train the machine learning algorithms and for bridging the gap between machine measurable and human perceived expressive aspects remains an open issue. This need constitutes a challenging task, due to the complexity of human movement and diversity of possible descriptors, as well as the high subjectivity that accompanies movement characterisation by both experts and non-expert users. We contribute to addressing this problem, by proposing a conceptual framework for dance movement manual annotation which we evaluate through the development and deployment of the toolkit. Finally, we discuss how the different design choices affect the process and the reliability of collecting data sets regarding qualitative aspects of movement.
C1 [El Raheb, Katerina; Katifori, Akrivi; Ioannidis, Yannis] Natl & Kapodistrian Univ Athens, Athens, Greece.
   [El Raheb, Katerina; Katifori, Akrivi; Kasomoulis, Aristotelis; Ioannidis, Yannis] Athena Res Ctr, Athens, Greece.
   [Buccoli, Michele; Zanoni, Massimiliano; Sarti, Augusto] Politecn Milan, Milan, Italy.
C3 National & Kapodistrian University of Athens; Polytechnic University of
   Milan
RP El Raheb, K (corresponding author), Natl & Kapodistrian Univ Athens, Athens, Greece.; El Raheb, K (corresponding author), Athena Res Ctr, Athens, Greece.
EM kelraheb@di.uoa.gr
OI El Raheb, Katerina/0000-0002-3005-8081
FU European Commission under the European Commission [688865]; H2020 -
   Industrial Leadership [688865] Funding Source: H2020 - Industrial
   Leadership
FX This work is part of the WhoLoDance project (wholodance.eu), which is
   funded by the European Commission within the H2020 Programme, under the
   European Commission Grant Agreement no 688865. Special thanks to the
   dance expert partners (in alphabetical order): Rosemary Cisneros, Ruth
   Gibson, Amalia Markatzi, Muriel Romero, Jean-Marc Matos, Sarah Whatley,
   Karen Wood, and all the other volunteers who have participated in the
   evaluation of the interfaces and the annotation process.
CR Alaoui S.F., 2014, Proc. of the 2014 International Workshop on Movement and Computing, P1, DOI DOI 10.1145/2617995.2617996
   Alaoui SF, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4009, DOI 10.1145/3025453.3025530
   Alaoui SF, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2738219
   Alborno Paolo, 2017, P 4 INT C MOV COMP M, P29
   [Anonymous], WHOLODANCE WHOLE BOD
   [Anonymous], INTRO MEMOREKALL SIM
   Aristidou A, 2019, ACM J COMPUT CULT HE, V12, DOI 10.1145/3344383
   Aristidou A, 2014, 2014 PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS (GRAPP 2014), P277
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Bermudez B, 2011, J ARTISTIC RES
   Blades H, 2015, PERFORM RES, V20, P26, DOI 10.1080/13528165.2015.1111048
   Buccoli M, 2017, IEEE INT WORKSH MULT
   Cabral D, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P572, DOI 10.1145/2254556.2254663
   Camurri A., 2016, Proceedings of the 3rd International Symposium on Movement and Computing, P43
   Camurri A, 2016, MOCO'16: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON MOVEMENT AND COMPUTING, DOI 10.1145/2948910.2948927
   Celma O, 2008, J WEB SEMANT, V6, P250, DOI 10.1016/j.websem.2008.09.004
   Chau MT, 2017, LECT NOTES ARTIF INT, V10351, P3, DOI 10.1007/978-3-319-60045-1_1
   Chaudhry H, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL ARTS, MEDIA AND TECHNOLOGY (ICDAMT): DIGITAL ECONOMY FOR SUSTAINABLE GROWTH, P254, DOI 10.1109/ICDAMT.2017.7904972
   Cisneros RE, 2019, RES DANC EDUC, V20, P54, DOI 10.1080/14647893.2019.1566305
   Cisneros R, 2021, INT J PERF ART DIGIT, V17, P138, DOI 10.1080/14794713.2021.1880141
   Dewan S, 2018, LECT NOTES COMPUT SC, V11279, P55, DOI 10.1007/978-3-030-04257-8_5
   dos Santos ADP, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P448, DOI 10.1145/3292147.3292194
   El Raheb K., 2016, P 3 INT S MOV COMP, P5
   El Raheb K., 2018, P 2018 INT C ADV VIS, P27
   El Raheb K, 2021, INT J PERF ART DIGIT, V17, P118, DOI 10.1080/14794713.2021.1884804
   El Raheb K, 2018, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON MOVEMENT AND COMPUTING (MOCO'18), DOI 10.1145/3212721.3212837
   El Raheb K, 2018, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON MOVEMENT AND COMPUTING (MOCO'18), DOI 10.1145/3212721.3212722
   El Raheb K, 2017, LECT NOTES COMPUT SC, V10250, P49, DOI 10.1007/978-3-319-58451-5_4
   El Raheb Katerina, 2016, WHOLODANCE DELIVERAB, DOI [10.5281/zenodo.1042544, DOI 10.5281/ZENODO.1042544]
   Even Zohar O, 2016, WHOLODANCE DELIVERAB, DOI [10.5281/zenodo.1042661, DOI 10.5281/ZENODO.1042661]
   Evola V, 2019, J NONVERBAL BEHAV, V43, P451, DOI 10.1007/s10919-019-00313-2
   Fdili AlaouiS., 2015, Proceedings of the 2Nd International Workshop on Movement and Computing, MOCO '15, P84, DOI DOI 10.1145/2790994.2791000
   Gong D, 2012, LECT NOTES COMPUT SC, V7574, P229, DOI 10.1007/978-3-642-33712-3_17
   Hutchinson A., 1970, LABANOTATION
   Ioannidis Yannis, 2011, GESTURE SIGN LANGUAG, P106
   Jenett F, 2015, PERFORM RES, V20, P24, DOI 10.1080/13528165.2015.1111046
   Kico I, 2019, INT CONF GAMES VIRTU, P226, DOI 10.1109/vs-games.2019.8864604
   Kipp M, 2007, LANG RESOUR EVAL, V41, P325, DOI 10.1007/s10579-007-9053-5
   Krüger B, 2017, IEEE T MULTIMEDIA, V19, P797, DOI 10.1109/TMM.2016.2635030
   Lagrue S, 2019, SUMAC'19: PROCEEDINGS OF THE 1ST WORKSHOP ON STRUCTURING AND UNDERSTANDING OF MULTIMEDIA HERITAGE CONTENTS, P75, DOI 10.1145/3347317.3357245
   Lan RY, 2015, VISUAL COMPUT, V31, P35, DOI 10.1007/s00371-013-0902-5
   Law Edith, 2007, ISMIR
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Ma H, 2010, IEEE T MULTIMEDIA, V12, P462, DOI 10.1109/TMM.2010.2051360
   Ma Thi C, 2019, ONTOLOGY WEB APPL BA
   Mallick T, 2019, ARXIV 190911023
   Maystre Lucas, 2015, Advances in Neural Information Processing Systems, P172
   Md Faridee A, 2018, GETMOBILE-MOB COMPU, V22, P10, DOI 10.1145/3308755.3308759
   Mentis Helena M., 2013, P SIGCHI C HUMAN FAC, P3375, DOI [DOI 10.1145/2470654.2466462, 10.1145/2470654.2466462]
   Niewiadomski R, 2019, J MULTIMODAL USER IN, V13, P191, DOI 10.1007/s12193-018-0284-0
   Piana S., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, CHI EA'16, page, P1629, DOI DOI 10.1145/2851581.2892478
   Piana S, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2818740
   Quiroga RQ, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.041904
   Ramadoss B, 2007, CYBERNET SYST, V38, P349, DOI 10.1080/01969720701291189
   Ribeiro C, 2016, MOCO'16: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON MOVEMENT AND COMPUTING, DOI 10.1145/2948910.2948961
   Rivire Jean-Philippe, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359188
   Rizzo A., 2018, WHOLODANCE WHOLE BOD
   Saad S, 2012, INT CONF MULTIMED, P77, DOI 10.1109/ICMCS.2012.6320129
   Sikos LF, 2017, MULTIMED TOOLS APPL, V76, P14437, DOI 10.1007/s11042-016-3705-7
   Singh V., 2011, Proceedings of the 8th ACM conference on Creativity and cognition, CC '11, P197
   Stancliffe R, 2019, THEATR DANCE PERFORM, V10, P273, DOI 10.1080/19443927.2019.1610039
   Sun D, 2020, INT C APPL TECHNIQUE, P355
   Wittenburg Peter, 2006, 5 INT C LANG RES EV, V2006
   Yang YH, 2011, MULTIMEDIA COMPUT CO, P1
   Yordanova K, 2018, 2018 IEEE INT C PERV
   Zohar Oshri Even, 2017, WHOLODANCE DELIVERAB, DOI [10.5281/zenodo.1068999, DOI 10.5281/ZENODO.1068999]
NR 66
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3363
EP 3395
DI 10.1007/s11042-022-12602-y
EA JUL 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000820564000002
DA 2024-07-18
ER

PT J
AU Majidi, M
   Toroghi, RM
AF Majidi, Maryam
   Toroghi, Rahil Mahdian
TI A combination of multi-objective genetic algorithm and deep learning for
   music harmony generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic Music generation; Polyphonic Music pieces; Harmony;
   Multi-objective genetic algorithm; Bi-LSTM
ID NEURAL-NETWORKS
AB Automatic Music Generation (AMG) has become an interesting research topic for many scientists in artificial intelligence, who are also interested in the music industry. One of the main challenges in Automatic Music Generation is that there is no clear objective evaluation criterion that can measure the music grammar, structural rules, and audience satisfaction. Also, original music contains different elements that should work together, such as melody, harmony, and rhythm; but in the most of previous works, Automatic Music Generation works only for one element (e.g., melody). Therefore, in this paper, we propose a Multi-Objective Genetic Algorithm (MO-GA) to generate polyphonic music pieces, considering grammar and listener satisfaction. In this method, we use three objective functions. The first objective function is the accuracy of the generated music piece, based on music theory; and the other two objective functions are modeled scores provided by music experts and ordinary listeners. The scoring of experts and listeners separately are modeled using Bi-directional Long Short-Term Memory (Bi-LSTM) neural networks. The proposed music generation system tries to maximize mentioned objective functions to generate a new piece of music, including melody and harmony. The results show that the proposed method can generate pleasant pieces with desired styles and lengths, along with harmonic sounds that follow the grammar.
C1 [Majidi, Maryam; Toroghi, Rahil Mahdian] Iran Broadcasting Univ, Fac Media Technol & Engn, Tehran, Iran.
RP Majidi, M (corresponding author), Iran Broadcasting Univ, Fac Media Technol & Engn, Tehran, Iran.
EM Mry20mj@gmail.com; Mahdian.t.r@gmail.com
CR Agarwal S, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P455, DOI 10.1109/SSCI.2018.8628712
   Agres K, 2017, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01999
   Agres KR, 2009, P ANN M COGN SCI SOC, V31
   [Anonymous], 2001, Journee d'Informatique Musicale
   [Anonymous], 2009, Proceedings of the Sound and Music Computing Conference
   [Anonymous], 2007, Evolutionary Computer Music
   [Anonymous], 2005, Proceedings of the International Computer Music Conference
   [Anonymous], 1957, IRE Transactions on Electronic Computers, EC, DOI DOI 10.1109/TEC.1957.5222016
   Boulanger-Lewandowski N, 2013, INT CONF ACOUST SPEE, P3178, DOI 10.1109/ICASSP.2013.6638244
   Browne TM., 2009, GLOBAL EXPECTATION V
   Chuan C.H., 2017, ARXIV PREPRINT ARXIV
   Davismoon S, 2010, LECT NOTES COMPUT SC, V6025, P361, DOI 10.1007/978-3-642-12242-2_37
   de Freitas ARR, 2011, THESIS U FEDERAL OUR
   Douglas Eck, 2002, Istituto Dalle Molle Di Studi Sull'Intelligenza Artificiale, V103, P48
   Farzaneh M., 2019, MUSIC GENERATION USI
   Franklin JA, 2006, INFORMS J COMPUT, V18, P321, DOI 10.1287/ijoc.1050.0131
   Herremans D, 2013, EXPERT SYST APPL, V40, P6427, DOI 10.1016/j.eswa.2013.05.071
   Herremans D., 2016, MORPHEUS AUTOMATIC M
   Herremans D, 2012, J MATH ARTS, V6, P169, DOI 10.1080/17513472.2012.738554
   Hiller L, 1993, MACHINE MODELS MUSIC, P9
   Horner A., 1991, URBANA, P437
   Keller RobertM., 2007, Sound and Music Computing Conference, P330
   Lewis J.P., 1991, Music and Connectionism, P212
   Makris D, 2017, COMM COM INF SC, V744, P570, DOI 10.1007/978-3-319-65172-9_48
   Manzelli R, 2018, P MUS MET WORKSH 9 I
   McIntyre R. A., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P852, DOI 10.1109/ICEC.1994.349943
   McVicar M, 2014, INT CONF SIGN PROCES, P599, DOI 10.1109/ICOSP.2014.7015074
   Mishra A., 2019, LONG SHORT TERM MEMO
   NAKAMURA JI, 1994, J VISUAL COMP ANIMAT, V5, P247, DOI 10.1002/vis.4340050405
   Pachet F, 2011, 22 INT JOINT C ART I
   Papadopoulos A, 2014, AAAI CONF ARTIF INTE, P2731
   PINKERTON RC, 1956, SCI AM, V194, P77, DOI 10.1038/scientificamerican0256-77
   Scirea M, 2017, GENET PROGRAM EVOL M, V18, P433, DOI 10.1007/s10710-017-9307-y
   TODD PM, 1989, COMPUT MUSIC J, V13, P27, DOI 10.2307/3679551
   Wu J, 2020, IEEE T CYBERNETICS, V50, P2749, DOI 10.1109/TCYB.2019.2953194
   Yang L.-C., 2017, ARXIV PREPRINT ARXIV, P324
NR 36
TC 6
Z9 6
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2419
EP 2435
DI 10.1007/s11042-022-13329-6
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000815565800001
DA 2024-07-18
ER

PT J
AU Dashkov, A
   Khaleiev, O
AF Dashkov, Andrii
   Khaleiev, Oleksii
TI Haar descriptors preliminary sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Objects detection; Haar descriptors; Face detection; Pedestrian
   detection; Cascade classifier; Binary classifier; Features mining
ID FEATURES; SELECTION
AB The selection of meaningful features for training computer vision solutions is the most important part of a robust framework construction. A huge amount of possible features with different parameters makes this task chalenging. We have developed a preliminary procedure of sampling of Haar descriptors for more effective learning of the binary classifier. A dataset and boosting weights are used to sample a data driven subset of descriptors from the vast space of all potential candidates, using the Kullback-Leibler divergence as a metric. Our aim was to create a simple technique which makes Haar features mining more reasonable and helps to reach higher learning rates, and further to investigate the practical usage of this data-driven approach. The proposed technique can be used for improvement of learning rates during the training process of cascade Haar classifiers with the usage of the AdaBoost framework. The developed data-driven sampling procedure can help to improve learning rates up to 34% depending on the dataset type. Additionally, the research clarifies the influence of the 'complexity' of dataset samples on learning effectiveness and provides practical recommendations for a reasonable choice of the initial size of descriptors' list.
C1 [Dashkov, Andrii; Khaleiev, Oleksii] P Prod Inc, Kharkiv, Ukraine.
RP Dashkov, A (corresponding author), P Prod Inc, Kharkiv, Ukraine.
EM avdkharkov@gmail.com; haleev25@gmail.com
OI Dashkov, Andrii/0000-0003-3186-957X
CR AbdelRaouf A, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P319, DOI 10.1109/ICCES.2018.8639437
   [Anonymous], 2016, Pattern Recognition and Machine Learning, Softcover Reprint of the Original 1st ed., Information Science and Statistics, DOI DOI 10.1117/1.2819119
   Besnassi M, 2020, PATTERN ANAL APPL, V23, P309, DOI 10.1007/s10044-019-00784-5
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Chen DQ, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P662, DOI 10.1109/IAEAC.2018.8577211
   Cheng RZ, 2017, INT J IMAGE GRAPH, V17, DOI 10.1142/S0219467817500231
   Cobos-May C, 2015, INT J COMPUT SCI, V2, P64
   Dandashy T, 2019, INT J ENG MANAG RES, V9, DOI [10.31033/ijemr.9.4.17, DOI 10.31033/IJEMR.9.4.17]
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Ess A, 2007, IEEE I CONF COMP VIS, P2065
   Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Harjoko A., 2020, INT J SMART SENS INT, V13, P1, DOI [10.21307/ijssis-2020-026, DOI 10.21307/ijssis-2020-026]
   Hoang VD, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P614
   Jabri S, 2018, 2018 IEEE THIRD INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, APPLICATIONS AND SYSTEMS (IPAS), P121, DOI 10.1109/IPAS.2018.8708898
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lisani JL, 2019, IMAGE PROCESS ON LIN, V9, P269, DOI 10.5201/ipol.2019.272
   Liu C, 2003, COMPUT VIS PATTERN R
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo AW, 2019, IEEE ACCESS, V7, P14472, DOI 10.1109/ACCESS.2019.2894169
   Maria Dominic Savio M., 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1964/6/062023
   Mita T, 2005, IEEE I CONF COMP VIS, P1619
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Naido S, 2020, 2020 IEEE 2 INT C AR, P1
   Oualla M., 2020, INT J-TORONTO, V9, P4055, DOI [10.30534/ijatcse/2020/232932020, DOI 10.30534/IJATCSE/2020/232932020]
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pavani SK, 2010, PATTERN RECOGN, V43, P160, DOI 10.1016/j.patcog.2009.05.011
   Pham MT, 2007, IEEE I CONF COMP VIS, P1634
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rezaei M, 2014, LECT NOTES COMPUT SC, V8333, P302, DOI 10.1007/978-3-642-53842-1_26
   Saha S, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P387, DOI 10.1109/dicta47822.2019.8946021
   Shishi Duan, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P483, DOI 10.1109/ICIG.2013.97
   Srithar S., 2021, Journal of Physics: Conference Series, V1916, DOI 10.1088/1742-6596/1916/1/012019
   Sun SJ, 2015, CHIN CONT DECIS CONF, P1888, DOI 10.1109/CCDC.2015.7162227
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Viola P, 2003, IEEE C COMPUTER VISI
   Wei Y, 2013, ADV MECH ENG, DOI 10.1155/2013/546206
   Zhang SS, 2014, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2014.126
   Zhou CJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P735, DOI 10.1145/3123266.3123303
NR 40
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 819
EP 837
DI 10.1007/s11042-022-13204-4
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809315600004
DA 2024-07-18
ER

PT J
AU Ahmed, MI
   Kannan, G
AF Ahmed, Mohammed Imtyaz
   Kannan, G.
TI Safeguards and weightless of electronic chain of command consolidated
   for virtual patient evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; Medicalcare; Biosensors; Security; Privacy; Remote victim
   observation
ID ATTRIBUTE-BASED-ENCRYPTION; OF-THE-ART; MONITORING-SYSTEM; KEY
   AGREEMENT; LIGHTWEIGHT; INTERNET; PRIVACY; SECURE; SCHEME; TRUST
AB The Internet of Things (IoT), 5G cellular technology, and Cyber-Physical Systems (CPS) are enabling a wide range of IoT-based application cases that are both intelligent. As one of the most impactful applications of the Internet of Things (IoT), healthcare makes use of AAL (Ambient Assisted Living), mobile health (mHealth), and electronic health (eHealth). Spending on health is a significant portion of people's income. Traditional medicine is prone to long delays, waste of money and effort, and even death. RVO (Remote Victim Observation) can be utilized to circumvent problems associated with traditional healthcare facilities because of IoT's intelligence and predictive power. With the help of IoT-based RVO and wearable devices, sensor networks, and other digital infrastructure, we can detect oncoming situations before they become life-threatening or even fatal. IoT integration with healthcare units was demonstrated in order to build a trustworthy, available, and secure RVO system. Secure end to end communication, encryption of RFID data, and privacy protection are all part of the proposed solution. An android wearable watch (Biosensor | Body sensor), a server using REST framework, and a smartphone app to monitor and detect falls, blood pressure, and heart rate are all part of the system. As a bonus, the peace and quiet of this secluded location contribute to the attraction. Using this RVO could improve health care and quality of life, according to an empirical investigation.
C1 [Ahmed, Mohammed Imtyaz; Kannan, G.] BS Abdur Rahman Crescent Inst Sci & Technol, ECE Dept, Chennai, Tamil Nadu, India.
C3 B. S. Abdur Rahman Crescent Institute of Science & Technology
RP Ahmed, MI (corresponding author), BS Abdur Rahman Crescent Inst Sci & Technol, ECE Dept, Chennai, Tamil Nadu, India.
EM mdimtyazahmed@gmail.com; kannann@crescent.education
RI Ahmed, Mohammed Imtyaz/AAU-8005-2021
OI Ahmed, Mohammed Imtyaz/0000-0003-4794-7683; , Dr G
   Kannan/0000-0001-9060-1317
CR Simplicio MA, 2017, COMPUT COMMUN, V98, P43, DOI 10.1016/j.comcom.2016.05.002
   Abawajy JH, 2017, IEEE COMMUN MAG, V55, P48, DOI 10.1109/MCOM.2017.1600374CM
   Abbas A, 2014, IEEE J BIOMED HEALTH, V18, P1431, DOI 10.1109/JBHI.2014.2300846
   Adat V, 2018, TELECOMMUN SYST, V67, P423, DOI 10.1007/s11235-017-0345-9
   Ahmed I, 2018, J ADV RES DYNAMICAL, P352
   Ahmed MI., 2020, INT J FUTUR GENER CO, V13, P1550
   Akkas MA, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100173
   Ali A, 2013, MULTIMED TOOLS APPL, V66, P201, DOI 10.1007/s11042-011-0791-4
   [Anonymous], 2017, ALEX ENG J, DOI 10.1109/icems.2017.8056507
   Avoine G., 2007, Proceedings of the IEEE International Symposium on a World of Wireless Mobile and Multimedia Networks, P1
   Bin Rais RN, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P462, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00092
   Chiuchisan I, 2015, 2015 INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE FOR MULTIMEDIA UNDERSTANDING (IWCIM)
   Esposito C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102468
   Fortino G, 2015, INFORM FUSION, V22, P50, DOI 10.1016/j.inffus.2014.03.005
   Fortino G, 2014, FUTURE GENER COMP SY, V35, P62, DOI 10.1016/j.future.2013.12.015
   Gómez J, 2016, PROCEDIA COMPUT SCI, V83, P90, DOI 10.1016/j.procs.2016.04.103
   Gope P, 2018, FUTURE GENER COMP SY, V83, P629, DOI 10.1016/j.future.2017.06.023
   Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005
   Han JG, 2015, IEEE T INF FOREN SEC, V10, P665, DOI 10.1109/TIFS.2014.2382297
   Hassanalieragh M, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2015), P285, DOI 10.1109/SCC.2015.47
   He DJ, 2013, IEEE J BIOMED HEALTH, V17, P664, DOI 10.1109/JBHI.2012.2235180
   He DJ, 2012, IEEE T INF TECHNOL B, V16, P1164, DOI 10.1109/TITB.2012.2199996
   He DJ, 2012, IEEE T INF TECHNOL B, V16, P623, DOI 10.1109/TITB.2012.2194788
   He DJ, 2012, IEEE T IND ELECTRON, V59, P4155, DOI 10.1109/TIE.2011.2178214
   Kannan G, 2015, INT J ENG RES, P469
   Khemissa H, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPLICATIONS, SERVICES AND TECHNOLOGIES (NGMAST 2015), P90, DOI 10.1109/NGMAST.2015.31
   Kim H, 2012, WIREL COMMUN MOB COM, V12, P145, DOI 10.1002/wcm.947
   Lee J, 2010, COMPUT NETW, V54, P2967, DOI 10.1016/j.comnet.2010.05.011
   Li YC, 2020, IEEE INT C COMPUT, P92, DOI 10.1109/CSE50738.2020.00020
   Liang KT, 2015, IEEE T INF FOREN SEC, V10, P1981, DOI 10.1109/TIFS.2015.2442215
   Möller S, 2012, SENSOR ACTUAT A-PHYS, V173, P55, DOI 10.1016/j.sna.2011.10.016
   Moosavi SR, 2016, FUTURE GENER COMP SY, V64, P108, DOI 10.1016/j.future.2016.02.020
   Nohl K, 2006, LECT NOTES COMPUT SC, V4307, P228
   Pu C, 2020, 2020 26TH IEEE INTERNATIONAL SYMPOSIUM ON LOCAL AND METROPOLITAN AREA NETWORKS (IEEE LANMAN), DOI 10.1109/lanman49260.2020.9153239
   Rahman F, 2017, FUTURE GENER COMP SY, V72, P339, DOI 10.1016/j.future.2016.06.001
   Ray BR, 2018, FUTURE GENER COMP SY, V78, P838, DOI 10.1016/j.future.2017.02.020
   Saha HN, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), P69, DOI 10.1109/IEMECON.2017.8079564
   Sedik A, 2022, NEURAL COMPUT APPL, V34, P11423, DOI 10.1007/s00521-020-05410-8
   Shanin F., 2018, 2018 INT CET C CONTR, P1
   Simplicio MA, 2011, C LOCAL COMPUT NETW, P450, DOI 10.1109/LCN.2011.6115506
   Stergiou CL, 2021, IEEE INTERNET THINGS, V8, P5164, DOI 10.1109/JIOT.2020.3033131
   Tewari A, 2020, FUTURE GENER COMP SY, V108, P909, DOI 10.1016/j.future.2018.04.027
   Wan J, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1308-x
   Whitmore A, 2015, INFORM SYST FRONT, V17, P261, DOI 10.1007/s10796-014-9489-2
   Wu F, 2018, J AMB INTEL HUM COMP, V9, P919, DOI 10.1007/s12652-017-0485-5
   Yang JJ, 2015, FUTURE GENER COMP SY, V43-44, P74, DOI 10.1016/j.future.2014.06.004
   Yang Y, 2017, J NETW COMPUT APPL, V89, P26, DOI 10.1016/j.jnca.2016.11.017
   Yang Y, 2016, IEEE T INF FOREN SEC, V11, P746, DOI 10.1109/TIFS.2015.2509912
   Yao XX, 2015, FUTURE GENER COMP SY, V49, P104, DOI 10.1016/j.future.2014.10.010
   Yew HT, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P176, DOI [10.1109/CSPA48992.2020.9068699, 10.1109/cspa48992.2020.9068699]
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhao SS, 2012, IEEE COMMUN SURV TUT, V14, P380, DOI 10.1109/SURV.2011.020211.00045
   Zhou ZB, 2015, IEEE T COMPUT, V64, P126, DOI 10.1109/TC.2013.200
NR 53
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 453
EP 478
DI 10.1007/s11042-022-13310-3
EA JUN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806683100002
PM 35694035
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Moad, MS
   Kafi, MR
   Khaldi, A
AF Moad, Med Sayah
   Kafi, Mohamed Redouane
   Khaldi, Amine
TI Medical image watermarking for secure e-healthcare applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Watermarking; Compression; Wavelet transform; Stream
   cipher encryption
ID ROBUST; SCHEME; HYBRID; BLIND; ENCRYPTION; DWT
AB In telemedicine, medical data are exchanged between hospitals and healthcare professionals to facilitate patient care. This transmission will expose the medical data to several security threats and most existing security mechanisms such as cryptographic techniques secure data from unauthorized access but this protection is only valid when the data are encrypted. In order to overcome these limitations, we propose in this paper a watermarking approach for patient identification and watermark integrity verification. In this approach, the watermark consists of two parts, the first part contains the patient's information fingerprint, and the second part contains the patient's encrypted photography. For the integration process, a discrete wavelet transform is applied to divide the medical image into four sub-bands. The watermark bits are then integrated by modulating the obtained mid-frequency coefficients. This approach's capacity allows the integration of the patient's photography and fingerprint, but will also be sufficient for a possible error-correcting code addition. The coefficient modulation performed by the integration process allowed hiding the watermark in an imperceptible way. From the experiments results, we can conclude the use of discrete wavelet transform allows generating a watermarked image almost similar to the host signal. The robustness results also confirm the watermark resistance to various attacks commonly used in watermarking.
C1 [Moad, Med Sayah; Kafi, Mohamed Redouane] Univ Kasdi Merbah, Fac Sci & Technol, Dept Elect, Elect Engn Lab, Ouargla 30000, Algeria.
   [Khaldi, Amine] Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
C3 Universite Kasdi Merbah Ouargla; Universite Kasdi Merbah Ouargla
RP Khaldi, A (corresponding author), Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
EM Kafi.Rcdouane@univ-ouargla.dz; Khaldi.Amine@univ-ounla.dz
RI Kafi, Mohamed Redouane/AAT-2301-2021; Moad, Mohamed
   Essayah/IST-2295-2023; Khaldi, Amine/AAV-1266-2020
OI Kafi, Mohamed Redouane/0000-0002-5500-0943; Khaldi,
   Amine/0000-0002-1637-9129
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Ahmadi SBB, 2020, MULTIMED TOOLS APPL, V79, P1075, DOI 10.1007/s11042-019-08197-6
   Amine K, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622500979
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Borra S, 2019, INT J DIGIT CRIME FO, V11, P13, DOI 10.4018/IJDCF.2019040102
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   Cedillo-Hernandez M, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101695
   Devi HS, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102424
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Geetha R, 2020, MULTIMED TOOLS APPL, V79, P12869, DOI 10.1007/s11042-019-08484-2
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Kahlessenane F, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02793-3
   Kahlessenane F, 2021, MULTIMED TOOLS APPL, V80, P19827, DOI 10.1007/s11042-021-10713-6
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Khaldi A., 2018, Law, State and Telecommunications Review, V10, P1, DOI [10.26512/lstr.v10i1.21504, DOI 10.26512/LSTR.V10I1.21504]
   Khaldi A, 2020, J TELECOMMUN ELECT C, V12, P65
   Khaldi A., 2020, INT J COMPUT VIS ROB, V10, P373, DOI [10.1504/IJCVR.2020.10029218, DOI 10.1504/IJCVR.2020.10029218, 10.1504/IJCVR.2020.109389]
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Kukreja S, 2020, MULTIMED TOOLS APPL, V79, P26155, DOI 10.1007/s11042-020-09130-y
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Luo YF, 2020, MULTIMED TOOLS APPL, V79, P32259, DOI 10.1007/s11042-020-09507-z
   Moad MS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103114
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Mothi R, 2019, MEASUREMENT, V136, P67, DOI 10.1016/j.measurement.2018.12.030
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Ocular Disease Recognition, Right and left eye fundus photographs of 5000 patients
   Saadi S, 2019, SIGNAL PROCESS, V154, P74, DOI 10.1016/j.sigpro.2018.08.011
   Salah E, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621502108
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Su GD, 2020, IEEE ACCESS, V8, P26984, DOI 10.1109/ACCESS.2020.2966234
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Thanki R, 2019, J INF SECUR APPL, V46, P231, DOI 10.1016/j.jisa.2019.03.017
   Thanki R, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0795-3
   Valandar MY, 2020, SOFT COMPUT, V24, P771, DOI 10.1007/s00500-019-04524-z
   Verma U., 2019, Int J Innov Technol Explor Eng, V9, P351, DOI [DOI 10.35940/IJITEE.A4126.119119, 10.35940/ijitee.A4126.119119]
   Yuan GH, 2020, CHINA COMMUN, V17, P88, DOI 10.23919/JCC.2020.04.009
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zermi N, 2022, CYBERNET SYST, V53, P282, DOI 10.1080/01969722.2021.1983700
   Zermi N, 2021, MICROPROCESS MICROSY, V84, DOI 10.1016/j.micpro.2021.104134
   Zermi N, 2021, MULTIMED TOOLS APPL, V80, P24823, DOI 10.1007/s11042-021-10712-7
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
NR 50
TC 17
Z9 17
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44087
EP 44107
DI 10.1007/s11042-022-12004-0
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000803780600003
DA 2024-07-18
ER

PT J
AU Fatima, B
   Ghafoor, A
   Ali, SS
   Riaz, MM
AF Fatima, Baheesa
   Ghafoor, Abdul
   Ali, Syed Sohaib
   Riaz, M. Mohsin
TI FAST, BRIEF and SIFT based image copy-move forgery detection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image copy-move forgery detection; Feature detection and matching; FAST;
   BRIEF; SIFT; Region duplication detection; Tampering detection
AB Easily accessible image-editing softwares have fueled the need for better forgery detection schemes that can overcome the limitedness of human vision to determine image authenticity. Most of the existing copy-move forgery techniques fail to detect forgery in smooth areas, forgery regions which are pasted multiple times or pasted after rotation and scaling. To solve these issues, the paper presents a two step keypoint based forgery detection technique. First, SIFT is used to detect keypoints in smooth regions. Second, BRIEF features with FAST descriptors are used to detect keypoints from missing regions (i.e. texture areas). Afterwards, keypoints are matched using generalized 2(nd) nearest neighbour. Then, morphological processing and structural similarity index are used to refine matches. Afterwards, linear spectral clustering is applied for better forgery localization. Simulations are performed on images taken from three datasets in which copy-move area was plain,compressed, rotated, scaled and pasted multiple times. Comparison of the simulation results with the state-of-the-art techniques shows improved precision, recall, and F-Measure values for the proposed technique. The technique also gives better visual results and reduces computational complexity.
C1 [Fatima, Baheesa; Ghafoor, Abdul] Natl Univ Sci & Technol, Islamabad, Pakistan.
   [Ali, Syed Sohaib; Riaz, M. Mohsin] COMSATS Univ, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Fatima, B (corresponding author), Natl Univ Sci & Technol, Islamabad, Pakistan.
EM bfatima.mscs25mcs@student.nust.edu.pk; abdulghafoor-mcs@nust.edu.pk;
   sohaib.ali@comsats.edu.pk; mohsin.riaz@comsats.edu.pk
RI Imran, Muhammad/AAS-9984-2021
OI Imran, Muhammad/0000-0002-7122-8454; Syed, Sohaib
   Ali/0000-0003-4795-7275; Ghafoor, Abdul/0000-0002-6117-3656
CR Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bilal M, 2021, AUST J FORENSIC SCI, V53, P459, DOI 10.1080/00450618.2020.1715479
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Dhanaraj R S., 2021, 2021 3 INT C INTELLI
   Emam M, 2018, J FORENSIC SCI, V63, P102, DOI 10.1111/1556-4029.13456
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hegazi Aya, 2020, International Journal of Sociotechnology and Knowledge Development, V12, P1, DOI 10.4018/IJSKD.2020010101
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P477, DOI 10.1007/s11042-019-08044-8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Rao Y, 2016, IEEE INT WORKS INFOR
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Roy, 2020, DIGITAL IMAGE FORENS, P6577
   Roy A., 2020, Digital image forensics: Theory and implementation, DOI [10.1007/978-981-10-7644-2, DOI 10.1007/978-981-10-7644-2]
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Soni B, 2019, J INF SECUR APPL, V45, P44, DOI 10.1016/j.jisa.2019.01.007
   Wang CY, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120706
   Zhengqin L., 2015, PROC CVPR IEEE, P1356, DOI DOI 10.1109/CVPR.2015.7298741
   Zhong JL, 2020, INFORM SCIENCES, V512, P675, DOI 10.1016/j.ins.2019.09.085
NR 26
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43805
EP 43819
DI 10.1007/s11042-022-12915-y
EA MAY 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805509400002
DA 2024-07-18
ER

PT J
AU Sheela, SJ
   Suresh, KV
   Tandur, D
   Sanjay, A
   Embar, S
   Rajani, TS
AF Sheela, S. J.
   Suresh, K., V
   Tandur, Deepaknath
   Sanjay, A.
   Embar, Surya
   Rajani, T. S.
TI Image cryptosystem based on modified Henon chaotic map and dynamic
   encoding mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; 2D-modified Henon map; DNA encoding
ID PERMUTATION
AB In this article, a novel cryptosystem for the protection of images is proposed. The proposed cryptosystem uses two dimensional modified Henon map (2D-MHM) and DNA technology to perform cryptographic operations. Initially, the chaotic sequences are generated from 2D-MHM by using secret key. Then, the chaotic sequences and the plain image are transformed into DNA matrices. The algorithm uses innovative method of random DNA encoding mechanism and DNA arithmetic operations to achieve diffusion operation. Experimental results and security analysis show that the proposed cryptosystem offers high security. Further, it can also resist brute force attack, differential attack and statistical attack.
C1 [Sheela, S. J.; Suresh, K., V; Sanjay, A.; Embar, Surya; Rajani, T. S.] Siddaganga Inst Technol, Tumakuru 572103, Karnataka, India.
   [Tandur, Deepaknath; Sanjay, A.; Embar, Surya] Hitachi ABB Power Grids, Bengaluru 560048, Karnataka, India.
C3 Siddaganga Institute of Technology; Hitachi Limited; ABB
RP Sheela, SJ (corresponding author), Siddaganga Inst Technol, Tumakuru 572103, Karnataka, India.
EM sheeladinu@sit.ac.in; sureshkvsit@sit.ac.in;
   deepaknath.tandur@hitachi-powergrids.com; rajanits@sit.ac.in
RI Sheela, S. J/GNH-2430-2022
OI Sheela, S. J./0000-0001-6793-1182; Arunachala,
   Sanjay/0000-0003-3882-8666
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   Zhou SH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22101091
   Zhu CJ, 2020, MULTIMED TOOLS APPL, V79, P7227, DOI 10.1007/s11042-019-08226-4
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 17
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40253
EP 40268
DI 10.1007/s11042-022-12924-x
EA MAY 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791638100009
DA 2024-07-18
ER

PT J
AU Cheng, R
   Wang, LK
   Wei, MR
   Tian, CP
AF Cheng, Ru
   Wang, Lukun
   Wei, Mingrun
   Tian, Chunpeng
TI Joint learning dynamic pruning and attention for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person Re-ID; Model pruning; Attention mechanism
AB In this paper, we investigate the problem of person re-identification by learning pedestrian distinguishing features and reducing model complexity. Traditional methods usually extract pedestrian features by designing better network structures and loss functions, which lack the consideration of the model size and ignore the impact of model efficiency on the accuracy of person re-identification. In this work, an end-to-end joint learning framework, namely PA-Net, with attention model and dynamic filter pruning algorithm is proposed. First, for a feature node, we mine patterns from a compact representation for attention learning, which points out the direction for dynamic filter pruning during training. The compact representation is obtained by stacking its pairwise relations with all feature nodes as a vector. Second, in an epoch training phase, the filters of small l(2)-norm are given high priority of being pruned to temporarily eliminate their contribution to the model output than those of higher l(2)-norm. Pruned filters can still be updated in the next epoch training phase until some filters no longer have any effect on the model and are completely pruned. Third, the weighted regularized triplet (WRT) loss and center loss are used to constrain the original features, and the softmax loss is used to constrain the batch normalized (BN) processed features to obtain the final score. Comprehensive experiments on the Market-1501, DukeMTMC-reID and MSMT17 datasets clearly show the superior performance of our proposed method in comparison with state-of-the-art methods.
C1 [Cheng, Ru; Wei, Mingrun] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Wang, Lukun; Tian, Chunpeng] Shandong Univ Sci & Technol, Coll Intelligent Equipment, Tai An 271000, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Wang, LK (corresponding author), Shandong Univ Sci & Technol, Coll Intelligent Equipment, Tai An 271000, Shandong, Peoples R China.
EM 33957790@qq.com
OI wang, lukun/0000-0001-6942-6681
CR Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Eom C., 2019, ADV NEURAL INFORM PR, P5297
   Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gherardi R, 2010, PROC CVPR IEEE, P1594, DOI 10.1109/CVPR.2010.5539782
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Han S, 2015, ADV NEUR IN, V28
   HAN SY, 2016, IEEE ICC
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Herzog F., 2021, ARXIV210110774
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Mnih V, 2014, ADV NEUR IN, V27
   Obeso AM, 2019, INT WORK CONTENT MUL
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xie Ben, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12307), P16, DOI 10.1007/978-3-030-60636-7_2
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zajdel W, 2005, IEEE INT CONF ROBOT, P2081
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng, 2020, ARXIV200604569
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
NR 38
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39409
EP 39429
DI 10.1007/s11042-022-12195-6
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000001
DA 2024-07-18
ER

PT J
AU Lahmyed, R
   El Ansari, M
   Kerkaou, Z
AF Lahmyed, Redouan
   El Ansari, Mohamed
   Kerkaou, Zakaria
TI A novel visible spectrum images-based pedestrian detection and tracking
   system for surveillance in non-controlled environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Pedestrian tracking; Artificial neural networks
   (ANN); Support Vector Machines (SVMs); Adaboost; Gradient local binary
   patterns (GLBP); Histograms of oriented optical flow (HOOF)
ID HOG; SEGMENTATION; RECOGNITION; HISTOGRAMS; PATTERNS; MOTION
AB For many vision applications, robust detection and tracking of pedestrians in image sequences are essential. In this paper, a hybrid system for pedestrian detection and tracking is presented. The proposed method is achieved in four major stages. First, the given image is segmented by exploiting the motion information to generate regions of interests where pedestrians are likely to exist. In the second stage, the ROIs are subjected to a selection process in order to keep only significant ones. Then, a hybrid feature is defined to classify the ROIs generated from the previous step. It entails combining the so-called GLBP-Color together with the histograms of oriented optical flow (HOOF). Artificial neural networks (ANN), Adaboost and support vector machine (SVM) classifiers have been tested together with the introduced hybrid feature and the first one is adopted as it outperforms the other two. The last step performs the tracking of the detected pedestrians using the so-called Color-BMA, which is an extension of the classical block matching (BMA) algorithm to the RGB color space. The proposed method has been tested in non-controlled environments with a collection of common databasets that are well known in the surveillance research community (CAVIAR, PETS 2006 and PETS 2009). The obtained results are satisfactory when compared to the recent state of the art approaches.
C1 [Lahmyed, Redouan; El Ansari, Mohamed; Kerkaou, Zakaria] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
   [El Ansari, Mohamed] My Ismail Univ, Fac Sci, Dept Comp Sci, Informat & Applicat Lab, Meknes, Morocco.
C3 Ibn Zohr University of Agadir; Moulay Ismail University of Meknes
RP Lahmyed, R (corresponding author), Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
EM lahmyed.redouan@yahoo.fr; m.elansari@uiz.ac.ma;
   kerkaou.zakaria@gmail.com
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066; Lahmyed,
   Redouan/0000-0003-1023-2502
FU National Center for Scientific and technical Research (CNRST)
   [20UIZ2015]
FX This research work was supported by the National Center for Scientific
   and technical Research (CNRST), research grant No: 20UIZ2015.
CR Akhloufi, 2013, P SPIE, V9076
   [Anonymous], 2010, Computer Vision Winter Workshop
   Arora M, 2018, NATL ACAD SCI LETT, V41, P365, DOI 10.1007/s40009-018-0694-2
   Bak S, 2012, LECT NOTES COMPUT SC, V7574, P806, DOI 10.1007/978-3-642-33712-3_58
   Baneiji S., 2012, Cross Disciplinary Biometric Systems, P205
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bertozzi M, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P584
   Bianco S, 2015, DIGIT SIGNAL PROCESS, V44, P1, DOI 10.1016/j.dsp.2015.06.001
   Broggi A, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P410, DOI 10.1109/IVS.2003.1212946
   Choudhury SK, 2018, MULTIMED TOOLS APPL, V77, P13075, DOI 10.1007/s11042-017-4933-1
   Conde C, 2013, NEUROCOMPUTING, V100, P19, DOI 10.1016/j.neucom.2011.12.037
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dash PP, 2019, J AMB INTEL HUM COMP, V10, P449, DOI 10.1007/s12652-017-0663-5
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   El Ansari M, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P325, DOI 10.5220/0006620803250334
   Ellahyani A, 2016, APPL SOFT COMPUT, V46, P805, DOI 10.1016/j.asoc.2015.12.041
   Espinace P, 2013, ROBOT AUTON SYST, V61, P932, DOI 10.1016/j.robot.2013.05.002
   Freire-Obregón D, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.102991
   Gavrila D., 2000, PROC EUROPEAN C COMP, P37, DOI [DOI 10.1007/3-540-45053-X, 10.1007/3-540-45053-X-3., DOI 10.1007/3-540-45053-X-3]
   Gupta S, 2020, SOFT COMPUT, V24, P5409, DOI 10.1007/s00500-019-04297-5
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Jiang N, 2013, IEEE INT SYMP CIRC S, P978, DOI 10.1109/ISCAS.2013.6572012
   Jiang N, 2012, IEICE T FUND ELECTR, VE95A, P1280, DOI 10.1587/transfun.E95.A.1280
   Jiang ZJ, 2017, MAR POLLUT BULL, V125, P513, DOI 10.1016/j.marpolbul.2017.07.066
   Kai Jungling, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P30, DOI 10.1109/CVPR.2009.5204085
   Kerkaou Z, 2021, IET IMAGE PROCESS, V15, P715, DOI 10.1049/ipr2.12056
   Kumar M., 2013, Smart Comput Rev, V3, P346, DOI [10.6029/smartcr.2013.05.005, DOI 10.6029/SMARTCR.2013.05.005]
   Kumar M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103052
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P9791, DOI 10.1007/s11042-018-6599-8
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lahmyed R., 2016, IEEE ACS INT C COMP, P1
   Lahmyed R, 2019, MULTIMED TOOLS APPL, V78, P15861, DOI 10.1007/s11042-018-6974-5
   Lahmyed R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063011
   Laptev I., 2006, BMVC 06 EDINBURGH UK, VIII, P949
   Lee MW, 2006, LECT NOTES COMPUT SC, V3953, P368
   Li JF, 2010, INFRARED PHYS TECHN, V53, P267, DOI 10.1016/j.infrared.2010.03.005
   Liao S., 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, P1301, DOI DOI 10.1109/CVPR.2010.5539817
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Liu YF, 2014, SIGNAL IMAGE VIDEO P, V8, pS125, DOI 10.1007/s11760-014-0649-0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Luo YH, 2018, MULTIMED TOOLS APPL, V77, P24041, DOI 10.1007/s11042-018-5728-8
   Madadlou A, 2009, COMPUT ELECTRON AGR, V68, P216, DOI 10.1016/j.compag.2009.06.005
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Olmeda D, 2013, INTEGR COMPUT-AID E, V20, P347, DOI 10.3233/ICA-130441
   Papageorgiou C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P35, DOI 10.1109/ICIP.1999.819462
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pers J, 2010, PATTERN RECOGN LETT, V31, P1369, DOI 10.1016/j.patrec.2010.03.024
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Rittscher J, 2005, PROC CVPR IEEE, P486
   Schapire RE, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1401
   Schmidt S., 2013, LECT NOTES ELECT ENG, V196, P1363
   Shahrokni, 2009, OVERALL EVALUATION P
   Shashua A, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P1
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Smith K, 2005, PROC CVPR IEEE, P962
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Thirde David., 2006, PROC 9 IEEE INT WORK, P47
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Varga D, 2015, 2015 INTERNATIONAL CONFERENCE ON MODELS AND TECHNOLOGIES FOR INTELLIGENT TRANSPORTATION SYSTEMS (MT-ITS), P413, DOI 10.1109/MTITS.2015.7223288
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Walk S., 2010, CVPR 2010, DOI DOI 10.1109/CVPR.2010.5540102
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wu HF, 2014, SIGNAL IMAGE VIDEO P, V8, P665, DOI 10.1007/s11760-013-0576-5
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao F, 2020, MULTIMED TOOLS APPL, V79, P14593, DOI 10.1007/s11042-018-7143-6
   Yang JL, 2012, INT C PATT RECOG, P2492
   Yang T, 2017, MULTIMED TOOLS APPL, V76, P11021, DOI 10.1007/s11042-016-3461-8
   Yao SH, 2015, NEUROCOMPUTING, V151, P1006, DOI 10.1016/j.neucom.2014.08.080
   Zhang SS, 2013, 2013 IEEE WORKSHOP ON ROBOT VISION (WORV), P102, DOI 10.1109/WORV.2013.6521921
NR 74
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39275
EP 39309
DI 10.1007/s11042-022-13026-4
EA APR 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000013
DA 2024-07-18
ER

PT J
AU Long, CK
   Hai, PV
   Tuan, TM
   Lan, LTH
   Chuan, PM
   Son, LH
AF Long, Cu Kim
   Pham Van Hai
   Tran Manh Tuan
   Luong Thi Hong Lan
   Pham Minh Chuan
   Le Hoang Son
TI A novel fuzzy knowledge graph pairs approach in decision making
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE M-CFIS-FKG; Knowledge graph; Fuzzy knowledge graph; FKG-pairs;
   Approximate reasoning; Decision making
ID INFERENCE SYSTEM; DESIGN
AB Fuzzy Knowledge Graph (FKG) has recently been emerging as one of the key techniques for supporting classification and decision-making problems. FKG is a novel concept that was firstly introduced in 2020 by integrating approximate reasoning with inference mechanism to find labels of new records, which are impossible for inference by the rule base. However, one of the key limitations of FKG is the use of a single pair to find new records' label that leads to low performance in approximation. This paper presents a novel approach of using FKG pairs instead of a single pair as in the classical model. A novel FKG-Pairs model including a new representing method and an approximation algorithm is presented. Theoretical analysis of the FKG-Pairs model such as identification of a threshold for the best value (k*) pairs is also investigated. Finally, to validate the proposed model, a numerical example and the experiments on the UCI datasets are presented. In addition, a two-way ANOVA method is also conducted to validate the model statistically. The novel concept about the FKG-Pairs given in this paper exposes new ideas in the effort to realize the much-anticipated decision-making and classification problems in fuzzy systems
C1 [Long, Cu Kim; Pham Van Hai] Hanoi Univ Sci & Technol SoICT HUST, Sch Informat Commun Technol, Hanoi, Vietnam.
   [Long, Cu Kim] Minist Sci & Technol MOST, Informat Technol Ctr, Hanoi, Vietnam.
   [Tran Manh Tuan; Luong Thi Hong Lan] Thuyloi Univ, Fac Comp Sci & Engn, 175 Tay Son, Hanoi, Vietnam.
   [Pham Minh Chuan] UTEHY, Dept Comp Sci, Fac Informat Technol, Khoai Chau, Hung Yen, Vietnam.
   [Le Hoang Son] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
   [Le Hoang Son] Vietnam Natl Univ, VNU Univ Sci, Hanoi, Vietnam.
C3 Hanoi University of Science & Technology (HUST); Thuyloi University;
   Vietnam National University Hanoi; Vietnam National University Hanoi
RP Tuan, TM (corresponding author), Thuyloi Univ, Fac Comp Sci & Engn, 175 Tay Son, Hanoi, Vietnam.
EM longck.2006@gmail.com; haipv@soict.hust.edu.vn; tmtuan@tlu.edu.vn;
   lanlhbk@tlu.edu.vn; chuanpm@gmail.com; sonlh@vnu.edu.vn
RI Tran, Tuan/AAV-4913-2021; V. Pham, A/ Prof. Hai/F-4106-2019
OI Tran, Tuan/0000-0002-1117-7253; Cu Kim, Long/0009-0000-6115-3869; V.
   Pham, A/ Prof. Hai/0000-0001-8325-1662; Hoang Son,
   Le/0000-0001-6356-0046
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.05-2019.316]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.05-2019.316.
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P9977, DOI 10.1007/s11042-019-07742-7
   Alves MA, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104335
   [Anonymous], 2021, DAT SOURC COD THIS P
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Bai W., 2020, Int. J. Cognitive Comput. Eng., V1, P18, DOI [10.1016/j.ijcce.2020.09.002, DOI 10.1016/J.IJCCE.2020.09.002]
   Bakhshipour A, 2020, J FOOD MEAS CHARACT, V14, P1402, DOI 10.1007/s11694-020-00390-8
   Banerjee S, 2021, MULTIMED TOOLS APPL, V80, P8377, DOI 10.1007/s11042-020-09794-6
   Cai Y., 2020, 2020 IEEE 9 JOINT IN, V9, DOI 10.1109/ITAIC49862.2020.9338752
   Chen J., 2021, INFORM SCIENCES, V563
   Cuong B.C., 2014, J. Compt. Sci. Cybern., V30, P409, DOI DOI 10.15625/1813-9663/30/4/5032
   de Azevedo Jacyntho MD, 2021, WEB SEMANTICS, P195
   Ehrlinger Lisa, 2016, SEMANTiCS, V48, P2, DOI DOI 10.1016/J.STR.2015.04.004
   FIGALIST I, 2020, INF SOFTW TECHNOL, V132
   Nguyen HL, 2020, INFORM FUSION, V61, P56, DOI 10.1016/j.inffus.2020.03.014
   Souza MLH, 2020, J MANUF SYST, V56, P133, DOI 10.1016/j.jmsy.2020.05.016
   Hogan A., 2019, DAGSTUHL REPORTS, V2019, P74
   Lan LTH, 2020, IEEE ACCESS, V8, P164899, DOI 10.1109/ACCESS.2020.3021097
   HORTA VAC, FUTURE GENER COMP SY, V20
   Phan HT, 2021, INFORM SCIENCES, V561, P243, DOI 10.1016/j.ins.2021.01.008
   Ismayil A. M., 2019, Am. Int. J. Res. Sci., Technol., Eng. Math., P205
   Jack H., 2022, ENG DESIGN PLANNING, P211, DOI [10.1016/B978-0-12-821055-0.00006-2, DOI 10.1016/B978-0-12-821055-0.00006-2]
   Johann G, 2021, SOFTW IMPACTS, V10, DOI 10.1016/j.simpa.2021.100145
   Kapadia B., 2020, STUD INDIAN PLACE NA, V40, P104
   Karaboga D, 2019, ARTIF INTELL REV, V52, P2263, DOI 10.1007/s10462-017-9610-2
   Ketipi MK, 2020, PROCEDIA MANUF, V51, P1305, DOI 10.1016/j.promfg.2020.10.182
   Khokhlov I, 2020, 2020 IEEE 6TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT)
   Klement EP, 2010, IEEE T FUZZY SYST, V18, P178, DOI 10.1109/TFUZZ.2009.2039367
   Komsiyah S, 2021, PROCEDIA COMPUT SCI, V179, P268, DOI 10.1016/j.procs.2021.01.006
   Krotzsch M., 2017, DESCRIPTION LOGICS
   Lampropoulos G, 2020, VIS INFORM, V4, P32, DOI 10.1016/j.visinf.2020.01.001
   Son LH, 2017, FUZZY OPTIM DECIS MA, V16, P359, DOI 10.1007/s10700-016-9249-5
   Son LH, 2017, APPL INTELL, V46, P652, DOI 10.1007/s10489-016-0856-1
   Son LH, 2017, APPL INTELL, V46, P1, DOI 10.1007/s10489-016-0811-1
   Son LH, 2016, APPL SOFT COMPUT, V46, P284, DOI 10.1016/j.asoc.2016.05.009
   Li LF, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101817
   Li XY, 2021, COMPUT IND, V129, DOI 10.1016/j.compind.2021.103449
   Liu JT, 2021, RELIAB ENG SYST SAFE, V207, DOI 10.1016/j.ress.2020.107352
   Long JW, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106205
   Lourdusamy R., 2021, WEB SEMANTICS CUTTIN, P69, DOI [10.1016/B978-0-12-822468-7.00012-2, DOI 10.1016/B978-0-12-822468-7.00012-2]
   Man JY, 2007, NAFIPS 2007 - 2007 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, P415, DOI 10.1109/NAFIPS.2007.383875
   Manzoor N, 2021, INT J PSYCHOPHYSIOL, V162, P1, DOI 10.1016/j.ijpsycho.2021.01.002
   Mosleh M, 2021, MULTIMED TOOLS APPL, V80, P20423, DOI 10.1007/s11042-021-10686-6
   Moussa S, 2017, PROCEDIA COMPUT SCI, V112, P800, DOI 10.1016/j.procs.2017.08.048
   MURUGANANTHAM A, 2019, MULTIMED TOOLS APPL
   Ortega LC, 2019, IEEE ACCESS, V7, P174368, DOI 10.1109/ACCESS.2019.2956918
   Pan ZL, 2021, AUTOMAT CONSTR, V125, DOI 10.1016/j.autcon.2021.103617
   Paulheim H, 2017, SEMANT WEB, V8, P489, DOI 10.3233/SW-160218
   Thong PH, 2016, ENG APPL ARTIF INTEL, V56, P121, DOI 10.1016/j.engappai.2016.08.009
   Thong PH, 2016, KNOWL-BASED SYST, V109, P48, DOI 10.1016/j.knosys.2016.06.023
   Pu B, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106688
   Qiao C, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102309
   Saini J, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115376
   Sharma A, 2021, MULTIMED TOOLS APPL, V80, P35081, DOI 10.1007/s11042-020-09366-8
   Singhal A., 2012, Introducing the knowledge graph: Things, not strings
   Son LH, 2015, EXPERT SYST APPL, V42, P51, DOI 10.1016/j.eswa.2014.07.026
   Son TT, 1999, TAP CHI TIN HOC VA D, V15, P6
   Song KH, 2021, KNOWL-BASED SYST, V221, DOI 10.1016/j.knosys.2021.106835
   Sun Y, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2020.106594
   Tang M, 2021, OMEGA-INT J MANAGE S, V100, DOI 10.1016/j.omega.2019.102141
   Tao SH, 2020, IEEE ACCESS, V8, P146027, DOI 10.1109/ACCESS.2020.3014670
   Tiwari Laxmikant, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P33, DOI 10.1007/978-981-13-8798-2_4
   Tran Thi Ngan, 2020, Frontiers in Intelligent Computing: Theory and Applications. Proceedings of the 7th International Conference on FICTA (2018). Advances in Intelligent Systems and Computing (AISC 1013), P11, DOI 10.1007/978-981-32-9186-7_2
   Ngan TT, 2018, ROM J INF SCI TECH, V21, P344
   Triantaphyllou E, 2020, OMEGA-INT J MANAGE S, V94, DOI 10.1016/j.omega.2020.102208
   Troussas C, 2019, EXPERT SYST APPL, V127, P85, DOI 10.1016/j.eswa.2019.03.003
   Tu CH, 2018, LECT NOTES ARTIF INT, V10751, P243, DOI 10.1007/978-3-319-75417-8_23
   Tuan TM, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8050707
   Verborgh R, 2016, J WEB SEMANT, V37-38, P184, DOI 10.1016/j.websem.2016.03.003
   Wang R, 2021, ADV ENG INFORM, V48, DOI 10.1016/j.aei.2021.101257
   Wu Q, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106757
   Yazdanbakhsh O, 2019, INT J APPROX REASON, V105, P417, DOI 10.1016/j.ijar.2018.10.018
   Yu T, 2017, ARTIF INTELL MED, V77, P48, DOI 10.1016/j.artmed.2017.04.001
   Zadeh L., 1979, MACHINE INTELLIGENCE, P149
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang Y, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102324
   Zheng X, 2021, NEUROCOMPUTING, V430, P104, DOI 10.1016/j.neucom.2020.10.095
   Zhou B, 2021, ROBOT CIM-INT MANUF, V71, DOI 10.1016/j.rcim.2021.102160
   Zhou YL, 2020, J CLEAN PROD, V263, DOI 10.1016/j.jclepro.2020.121528
   Zuo C, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7050470
   2019, IEEE T FUZZY SYST
NR 80
TC 7
Z9 7
U1 6
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26505
EP 26534
DI 10.1007/s11042-022-13067-9
EA APR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000788451300003
DA 2024-07-18
ER

PT J
AU El Balmany, C
   Asimi, A
   Bamarouf, M
   Tbatou, Z
AF El Balmany, Chawki
   Asimi, Ahmed
   Bamarouf, Mohamed
   Tbatou, Zakariae
TI Dynamic proof of retrievability based on public auditing for coded
   secure cloud storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Proof; Public auditing; Encoding; Dynamic data; Privacy preserving;
   Integrity
ID DATA INTEGRITY; CHALLENGES; TAXONOMY
AB Cloud storage represents a cloud delivered-service model which draws the attention of organizations and individuals due to its uncounted attractive advantages. Cloud Service Providers (CSPs) supply storage facilities while the cloud user has the ability to manage and migrate its own data towards remote cloud servers in ubiquitous and cost-effective manner. However, security and data integrity brake the evolution and scalability of such delivered-service because of data corruption and policy violation. Hence, data auditing and Proof-of-Retrievability (PoR) have been introduced to ensure the user data integrity verification in cloud storage nearby a Trusted Third Party (TTP) without downloading the entire file. Numerous related researches have been involved to enhance the computational cost of dynamic data integrity signature schemes based on PoR for corruption correctness and encoding outsourced data. However, the proposed schemes still foggy regarding computational cost complexity and data integrity issues. Thus, data corruption remains an inhibitor of the growth of cloud storage. The purpose of this paper is to establish an efficient public auditing scheme ensuring dynamic data privacy-preserving along with PoR. Thus, the proposed auditing scheme consists of ensuring the integrity of user outsourced data file by performing various functionalities such as: i) Encoding outsourced file based on Goppa codes generator matrix. ii) Generation of BLS-HVT signatures for data integrity. iii) data recovery where TTP (i.e. Verifier) has the capability to challenge the CSP (i.e. Prover) for detecting whether the stored data has been tampered or kept intact. iv) Dynamic data processing with low-computational cost.
C1 [El Balmany, Chawki; Asimi, Ahmed; Bamarouf, Mohamed] Lab Comp Syst & Vis LabS, Agadir, Morocco.
   [Tbatou, Zakariae] Tech Univ LIDRA, Lab Sustainable Innovat & Appl Res, Agadir, Morocco.
RP El Balmany, C (corresponding author), Lab Comp Syst & Vis LabS, Agadir, Morocco.
EM chawki.elbalmany@gmail.com; asimiahmed2008@gmail.com;
   bamaroufmohamed@gmail.com; tbatou.zakariae@gmail.com
CR Ahmed D., 2013, INT J ENG SCI TECHNO, V5, P359
   Alliance CS, 2016, TREACH 12 CLOUD COMP
   Anupa J, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1598, DOI 10.1109/ICACCI.2014.6968496
   Bian Jianchao, 2015, Journal of China Universities of Posts and Telecommunications, V22, P17, DOI 10.1016/S1005-8885(15)60663-X
   Bowers KD, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P187
   Cash D, 2017, J CRYPTOL, V30, P22, DOI 10.1007/s00145-015-9216-2
   Chawki E, 2018, PROCEDIA COMPUT SCI, V134, P328, DOI 10.1016/j.procs.2018.07.180
   Erway CC, 2015, ACM T INFORM SYST SE, V17, DOI 10.1145/2699909
   Fu AM, 2018, J NETW COMPUT APPL, V104, P97, DOI 10.1016/j.jnca.2017.12.007
   Garg N, 2020, FUTURE GENER COMP SY, V109, P306, DOI 10.1016/j.future.2020.03.032
   Goppa V., 1970, PROB PEREDACH INF, V6, P207
   Hu CY, 2020, INFORM SCIENCES, V520, P15, DOI 10.1016/j.ins.2020.02.010
   Juels A, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P584
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Madni SHH, 2016, J NETW COMPUT APPL, V68, P173, DOI 10.1016/j.jnca.2016.04.016
   Mell P, 2010, COMMUN ACM, V53, P50
   REED IS, 1960, J SOC IND APPL MATH, V8, P300, DOI 10.1137/0108018
   Shacham H, 2008, LECT NOTES COMPUT SC, V5350, P90, DOI 10.1007/978-3-540-89255-7_7
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen J, 2017, IEEE T INF FOREN SEC, V12, P2402, DOI 10.1109/TIFS.2017.2705620
   Sookhak M, 2018, IEEE T PARALL DISTR, V29, P999, DOI 10.1109/TPDS.2017.2784423
   Sookhak M, 2014, J NETW COMPUT APPL, V43, P121, DOI 10.1016/j.jnca.2014.04.011
   Tan CB, 2018, J NETW COMPUT APPL, V110, P75, DOI 10.1016/j.jnca.2018.03.017
   Tian H, 2017, IEEE T SERV COMPUT, V10, P701, DOI 10.1109/TSC.2015.2512589
   Zafar F, 2017, COMPUT SECUR, V65, P29, DOI 10.1016/j.cose.2016.10.006
   Zhang XJ, 2021, IEEE T CLOUD COMPUT, V9, P1362, DOI 10.1109/TCC.2019.2927219
   Zhu Y., 2011, Proceedings of the 2011 ACM Symposium on Applied Computing, P1550, DOI DOI 10.1145/1982185.1982514
   Zhu Y, 2013, IEEE T SERV COMPUT, V6, P227, DOI 10.1109/TSC.2011.51
NR 30
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39229
EP 39249
DI 10.1007/s11042-022-13089-3
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451400003
DA 2024-07-18
ER

PT J
AU Kör, H
   Erbay, H
   Yurttakal, AH
AF Kor, Hakan
   Erbay, Hasan
   Yurttakal, Ahmet Hasim
TI Diagnosing and differentiating viral pneumonia and COVID-19 using X-ray
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Transfer learning; Classification; Chest
   X-Rays; Pneumonia; COVID-19
ID ARCHITECTURES
AB Coronavirus-caused diseases are common worldwide and might worsen both human health and the world economy. Most people may instantly encounter coronavirus in their life and may result in pneumonia. Nowadays, the world is fighting against the new coronavirus: COVID-19. The rate of increase is high, and the world got caught the disease unprepared. In most regions of the world, COVID-19 test is not possible due to the absence of the diagnostic kit, even if the kit exists, its false-negative (giving a negative result for a person infected with COVID-19) rate is high. Also, early detection of COVID-19 is crucial to keep its morbidity and mortality rates low. The symptoms of pneumonia are alike, and COVID-19 is no exception. The chest X-ray is the main reference in diagnosing pneumonia. Thus, the need for radiologists has been increased considerably not only to detect COVID-19 but also to identify other abnormalities it caused. Herein, a transfer learning-based multi-class convolutional neural network model was proposed for the automatic detection of pneumonia and also for differentiating non-COVID-19 pneumonia and COVID-19. The model that inputs chest X-ray images is capable of extracting radiographic patterns on chest X-ray images to turn into valuable information and monitor structural differences in the lungs caused by the diseases. The model was developed by two public datasets: Cohen dataset and Kermany dataset. The model achieves an average training accuracy of 0.9886, an average training recall of 0.9829, and an average training precision of 0.9837. Moreover, the average training false-positive and false-negative rates are 0.0085 and 0.0171, respectively. Conversely, the model's test set metrics such as average accuracy, average recall, and average precision are 97.78%, 96.67%, and 96.67%, respectively. According to the simulation results, the proposed model is promising, can quickly and accurately classify chest images, and helps doctors as the second reader in their final decision.
C1 [Kor, Hakan] Hitit Univ, Engn Fac, Dept Comp Engn, Corum, Turkey.
   [Erbay, Hasan] Univ Turkish Aeronaut Assoc, Engn Fac, Comp Engn Dept, TR-06790 Etimesgut Ankara, Turkey.
   [Yurttakal, Ahmet Hasim] Afyon Kocatepe Univ, Engn Fac, Comp Engn Dept, TR-03204 Erenler Afyon, Turkey.
C3 Hitit University; Turk Hava Kurumu University; Turkish Aeronautical
   Association; Afyon Kocatepe University
RP Kör, H (corresponding author), Hitit Univ, Engn Fac, Dept Comp Engn, Corum, Turkey.
EM hakankor@hitit.edu.tr; herbay@thk.edu.tr; ahyurttakal@aku.edu.tr
RI YURTTAKAL, Ahmet Haşim/HPG-3175-2023
CR Akram T, 2021, PATTERN ANAL APPL, V24, P951, DOI 10.1007/s10044-020-00950-0
   Albelwi S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060242
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Andersen KG, 2020, NAT MED, V26, P450, DOI 10.1038/s41591-020-0820-9
   [Anonymous], 2020, CTR SYST SCI ENG CSS
   [Anonymous], 2016, ARXIV160207360
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Babu B., 2020, APPL INTELL, VApril, P1
   Bussani R, 2020, EBIOMEDICINE, V61, DOI 10.1016/j.ebiom.2020.103104
   Catak FO, 2021, HUMAN IN THE LOOP EN
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Cohen J. P., 2020, ARXIV 200611988
   Dansana D, 2023, SOFT COMPUT, V27, P2635, DOI 10.1007/s00500-020-05275-y
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Dreyer KJ, 2017, RADIOLOGY, V285, P713, DOI 10.1148/radiol.2017171183
   Gorbalenya AE, 2020, NAT MICROBIOL, V5, P536, DOI 10.1038/s41564-020-0695-z
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Hamey LGC, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P15
   Kermany Daniel, 2018, Mendeley Data, V2
   Khairat S, 2018, JMIR MED INF, V6, P25, DOI 10.2196/medinform.8912
   Khan MA, 2021, CMC-COMPUT MATER CON, V66, P2923, DOI 10.32604/cmc.2021.013191
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LAI CC, 2020, INT J ANTIMICROB AG, V55, DOI DOI 10.1016/J.IJANTIMICAG.2020.105924
   Li H, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.041304
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Mason RJ, 2020, EUR RESPIR J, V55, DOI 10.1183/13993003.00607-2020
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Padma T., 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P589, DOI 10.1109/ICOSEC49089.2020.9215257
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319
   Ruuskanen O, 2011, LANCET, V377, P1264, DOI 10.1016/S0140-6736(10)61459-6
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shan F, 2020, ARXIV 200304655
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Song YZ, 2022, IEEE T INTELL TRANSP, V23, P12287, DOI 10.1109/TITS.2021.3112458
   Üreten K, 2020, TURK J ELECTR ENG CO, V28, P2968, DOI 10.3906/elk-1912-23
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Zhang J, 2020, ARXIV 200312338 27
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 48
TC 5
Z9 5
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39041
EP 39057
DI 10.1007/s11042-022-13071-z
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000794850900002
PM 35493416
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Tamilmathi, AC
   Chithra, PL
AF Tamilmathi, A. Christoper
   Chithra, P. L.
TI Tensor block-wise singular value decomposition for 3D point cloud
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D point cloud; LiDAR; 3D image compression; Singular value
   decomposition; Tensor decomposition; Spatial information
AB A novel and efficient block-wise decomposition-based codec (BDC) for a three-dimensional (3D) light detection and ranging (LiDAR) point cloud (PCD) image (BDCPCD) has been introduced in this paper. The raw LiDAR data is cleansed and normalized by applying the axis outlier detection and circular differential cosine transformation methods, respectively. Then, the iterative dimensionality reduction approach is used to decompose and quantize the tensor structured signal data through block-wise singular value decomposition and signal block vectorization methods, respectively. The final single order tensor is considered as a compressed bitstream for efficient transformation. The proposed BDCPCD is applied on three different dense 3D LiDAR PCD data sets. The results demonstrate that it outperformed the four existing well-known compression techniques, such as WinRAR, 7-Zip, Tensor Tucker decomposition, and Random sample consensus (RANSAC) point cloud compression algorithm. This iterative compression algorithm constantly reduces the 66.66% of tensor blocks in each iteration. This research proves that the BDCPCD compresses different sizes of 3D LiDAR PCD spatial data to be reduced into six bytes and averagely increases the quality of the decompressed image by 1.6 decibels than the existing Tucker based algorithm.
C1 [Tamilmathi, A. Christoper; Chithra, P. L.] Univ Madras, Dept Comp Sci, Guindy Campus, Chennai 600025, Tamil Nadu, India.
C3 University of Madras
RP Chithra, PL (corresponding author), Univ Madras, Dept Comp Sci, Guindy Campus, Chennai 600025, Tamil Nadu, India.
EM chitrasp2001@yahoo.com; actamilmathi@gmail.com
RI Tamilmathi, A.Christoper/IAN-6690-2023
OI Tamilmathi, Dr.A.Christoper/0000-0002-3573-3314
CR Anh-Huy Phan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6766, DOI 10.1109/ICASSP.2014.6854910
   Ballester-Ripoll R, 2016, VISUAL COMPUT, V32, P1433, DOI 10.1007/s00371-015-1130-y
   Chithra PL, 2018, INT CONF ADV COMPU, P20
   Chithra P, 2020, IMAGING SCI J, V68, P1, DOI 10.1080/13682199.2020.1719747
   Chithra PL., 2020, IJITEE, V9, P1897, DOI [10.35940/ijitee.C8551.019320, DOI 10.35940/IJITEE.C8551.019320]
   Eftekhari A, 2015, APPL COMPUT HARMON A, V38, P1, DOI 10.1016/j.acha.2014.02.001
   Guo JF, 2019, IEEE GEOSCI REMOTE S, V16, P301, DOI 10.1109/LGRS.2018.2872111
   Jeyakumar S, 2019, COMPUTAT GEOSCI, V23, P969, DOI 10.1007/s10596-019-09855-2
   Koep N., 2019, ARXIV190106214V1
   Krivokuca M, 2020, IEEE T IMAGE PROCESS, V29, P2217, DOI 10.1109/TIP.2019.2957853
   Li J, 2017, OPEN PHYS, V15, P992, DOI 10.1515/phys-2017-0123
   Marani R., 2016, MODIFIED ITERATIVE C
   Mekuria R., 2016, EVALUATION CRITERIA
   Morell V, 2014, PATTERN RECOGN LETT, V50, P55, DOI 10.1016/j.patrec.2014.05.016
   Ning XJ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201280
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Shou ZY, 2017, J CENT SOUTH UNIV, V24, P1299, DOI 10.1007/s11771-017-3535-4
   Swathi H. R., 2017, IOP Conference Series: Materials Science and Engineering, V263, DOI 10.1088/1757-899X/263/4/042082
   Tian D, 2017, IEEE IMAGE PROC, P3460, DOI 10.1109/ICIP.2017.8296925
   Wang QZ, 2018, MULTIMED TOOLS APPL, V77, P1715, DOI 10.1007/s11042-017-4349-y
   Xu XD, 2018, INT J COMPUT INT SYS, V11, P652, DOI 10.2991/ijcis.11.1.50
   Wang YC, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P471
NR 22
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37917
EP 37938
DI 10.1007/s11042-021-11738-7
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000786824500002
DA 2024-07-18
ER

PT J
AU Ghaemi, A
   Danyali, H
   Kazemi, K
AF Ghaemi, Alireza
   Danyali, Habibollah
   Kazemi, Kamran
TI Reversible Data Hiding in Encryption Domain based on two dimensional
   histogram shifting and secure encryption system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Chaotic encryption; Histogram shifting;
   Watermarking
ID HIGH-CAPACITY; CHAOTIC MAP; IMAGE; SCHEME; TRANSFORM; DESIGN
AB Reversible Data Hiding in Encryption Domain (RDHED) can be used in different areas such as secure remote sensing or telemedicine. Since data structure is completely changed after a reliable encryption process, custom reversible data hiding methods are not efficient to perform RDHED. In this paper, a reversible method is proposed to embed extra information in the encryption domain by designing two dimensional (2-D) error histogram. According to the proposed method, target pixels are predicted in the encryption domain to design a 2-D error histogram. The obtained histogram is shifted according to a novel pattern for data insertion. 2-D histogram shifting makes it possible to shift bins of the error histogram in various directions. This property augments embedding capacity and improves quality of directly decrypted images. To perform a secure encryption process, an improved Closed-Loop Chaotic Encryption System (CLCES) has been designed. The proposed CLCES performs a sensitive encryption process in a closed-loop system. Extensive experiments have been conducted to evaluate the performance and security of the proposed method. Obtained embedding capacity has been 0.128 bit per pixel by taking average values over 1000 test images and using least square predictor. Results confirm superiority of the proposed method in comparison with other schemes.
C1 [Ghaemi, Alireza; Danyali, Habibollah; Kazemi, Kamran] Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz 7155713876, Iran.
C3 Shiraz University of Technology
RP Danyali, H (corresponding author), Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz 7155713876, Iran.
EM a.ghaemi@sutech.ac.ir; danyali@sutech.ac.ir; kazemi@sutech.ac.ir
RI ghaemi, alireza/GZA-5034-2022
CR Bas P., 2007, Break our Watermarking System, V2nd
   Borah S, 2020, MULTIMED TOOLS APPL, V79, P11437, DOI 10.1007/s11042-019-08411-5
   Bouslimi D, 2016, SIGNAL PROCESS-IMAGE, V47, P263, DOI 10.1016/j.image.2016.06.012
   Cao F, 2021, MULTIMEDIA SYST, V27, P317, DOI 10.1007/s00530-020-00700-6
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chen LST, 2010, INT J PATTERN RECOGN, V24, P433, DOI 10.1142/S0218001410007968
   Geetha R, 2020, MULTIMED TOOLS APPL, V79, P12869, DOI 10.1007/s11042-019-08484-2
   Ghaemi A, 2021, J REAL-TIME IMAGE PR, V18, P221, DOI 10.1007/s11554-020-00971-2
   Guan B, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102744
   Herbadji D, 2020, IET IMAGE PROCESS, V14, P40, DOI 10.1049/iet-ipr.2019.0123
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang DL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115632
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Ishtiaq Muhammad, 2017, J. appl. res. technol, V15, P524, DOI 10.1016/j.jart.2017.06.001
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Jiang LZ, 2020, IEEE T DEPEND SECURE, V17, P179, DOI 10.1109/TDSC.2017.2751476
   Jiang RQ, 2018, IEEE T MULTIMEDIA, V20, P55, DOI 10.1109/TMM.2017.2723244
   Khelifi F, 2018, SIGNAL PROCESS, V143, P336, DOI 10.1016/j.sigpro.2017.09.020
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Konyar MZ, 2020, SIGNAL IMAGE VIDEO P, V14, P897, DOI 10.1007/s11760-019-01621-2
   Kumar R, 2020, INFORM SCIENCES, V512, P96, DOI 10.1016/j.ins.2019.09.062
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Liu H, 2019, IEEE ACCESS, V7, P65450, DOI 10.1109/ACCESS.2019.2917498
   Liu JY, 2020, CIRC SYST SIGNAL PR, V39, P3532, DOI 10.1007/s00034-019-01321-9
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mansouri A, 2021, INFORM SCIENCES, V563, P91, DOI 10.1016/j.ins.2021.02.022
   Mhalla A, 2019, IEEE T INTELL TRANSP, V20, P4006, DOI 10.1109/TITS.2018.2876614
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Njitacke ZT, 2021, NEURAL COMPUT APPL, V33, P6733, DOI 10.1007/s00521-020-05451-z
   Peng F, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115715
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2018, INFORM SCIENCES, V465, P285, DOI 10.1016/j.ins.2018.07.021
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Sanivarapu PV, 2020, PHYS ENG SCI MED, V43, P213, DOI 10.1007/s13246-019-00838-2
   Sayood, 2018, LOSSLESS IMAGE COMPR, P187
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Unde AS, 2020, IEEE T CIRCUITS-II, V67, P167, DOI 10.1109/TCSII.2019.2897839
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wang YG, 2018, IEEE ACCESS, V6, P15816, DOI 10.1109/ACCESS.2018.2802928
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2018, SIGNAL PROCESS, V150, P171, DOI 10.1016/j.sigpro.2018.04.016
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 55
TC 0
Z9 0
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33731
EP 33757
DI 10.1007/s11042-022-12493-z
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300015
DA 2024-07-18
ER

PT J
AU Canário, JP
   Ferreira, MV
   Freire, J
   Carvalho, M
   Rios, R
AF Canario, Joao Paulo
   Ferreira, Marcos Vinicius
   Freire, Junot
   Carvalho, Matheus
   Rios, Ricardo
TI A face detection ensemble to monitor the adoption of face masks inside
   the public transportation during the COVID-19 pandemic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Mask detection; Ensemble models; Covid-19; Deep Learning
AB The designing of ensembles is widely adopted when single machine learning methods fail to obtain satisfactory performances by analyzing complex data characterized by being imbalanced, high-dimensional, and noisy. Such a failure is a well-known statistical challenge when the learning algorithm searches for a model in a large space of hypotheses and the data do not significantly represent the problem, thus not inducing it from a space of admissible functions towards the best global model. We have addressed this issue in a real-world application, whose main objective was to identify whether users were wearing masks inside public transportation during the COVID-19 pandemic. Several studies have already pointed that face masks are an important and efficient non-pharmacological strategy to reduce the virus spread. In this sense, we designed an approach using Convolutional Neural Networks (CNN) to track the adoption of masks in different transportation lines, regions, days, and time. Aiming at reaching this goal, we propose an ensemble of face detectors and a CNN architecture, called MaskNet, to analyze all public-transport passengers and provide valuable information to policymakers, which are able to dedicate efforts to more effective advertisements and awareness work. In practice, our approach is running in a real scenario in Salvador (Brazil).
C1 [Canario, Joao Paulo; Rios, Ricardo] Univ Fed Bahia, Dept Comp Sci, Salvador, BA, Brazil.
   [Ferreira, Marcos Vinicius; Freire, Junot] Smart Solut, Neodados, Salvador, BA, Brazil.
   [Carvalho, Matheus] Assoc Publ Transportat Co, Integra, Salvador, BA, Brazil.
C3 Universidade Federal da Bahia
RP Rios, R (corresponding author), Univ Fed Bahia, Dept Comp Sci, Salvador, BA, Brazil.
EM joao.canario@ufba.br; marcos.ferreira@neodados.com; junot@neodados.com;
   matheus.souza@gevan.com.br; ricardoar@ufba.br
RI Rios, Ricardo/H-2599-2013
OI Rios, Ricardo/0000-0003-1449-4745
FU CAPES (Coordination for the Improvement of Higher Education Personnel -
   Brazilian Federal Government Agency); NVIDIA Corporation
FX This work was partially supported by CAPES (Coordination for the
   Improvement of Higher Education Personnel - Brazilian Federal Government
   Agency). We gratefully acknowledge the support of NVIDIA Corporation
   with the donation of the Titan V GPU used for this research. Any
   opinions, findings, and conclusions or recommendations expressed in this
   material are those of the authors and do not necessarily reflect the
   views of CAPES, and NVIDIA.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Bradski G, 2000, DR DOBBS J, V25, P120
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Canário JP, 2020, J VOLCANOL GEOTH RES, V401, DOI 10.1016/j.jvolgeores.2020.106881
   Centers for Disease Control and Prevention (CDC), 2020, SYMPT COR DIS 2019 C
   Chu DK, 2020, LANCET, V395, P1973, DOI 10.1016/S0140-6736(20)31142-9
   Davies NG, 2020, LANCET PUBLIC HEALTH, V5, pE375, DOI 10.1016/S2468-2667(20)30133-X
   Din NU, 2020, IEEE ACCESS, V8, P44276, DOI 10.1109/ACCESS.2020.2977386
   Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Harsoyo Agung, 2013, 2013 IEEE 3rd International Conference on System Engineering and Technology (ICSET), P341, DOI 10.1109/ICSEngT.2013.6650196
   Haykin S., 1994, NEURAL NETWORKS COMP
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hendrawan A, 2018, 2018 1 INT C COMP AP, P1
   Hitam Muhammad Suzuri, 2013, 2013 INT C COMPUTER
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Kharel N, 2017, INT CONF INFORM COMM, P120, DOI 10.1109/IACS.2017.7921957
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D. P., 2014, arXiv
   Kolhar M, 2020, IEEE ACCESS, V8, P163608, DOI 10.1109/ACCESS.2020.3021983
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Luo DZ, 2018, MULTIMED TOOLS APPL, V77, P24663, DOI 10.1007/s11042-018-5658-5
   Markel H, 2007, JAMA-J AM MED ASSOC, V298, P644, DOI 10.1001/jama.298.6.644
   Merkel D., 2014, LINUX J, V2014, P2, DOI DOI 10.5555/2600239.2600241
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Nieto-Rodríguez A, 2015, LECT NOTES COMPUT SC, V9117, P138, DOI 10.1007/978-3-319-19390-8_16
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schünemann HJ, 2020, LANCET RESP MED, V8, P954, DOI 10.1016/S2213-2600(20)30352-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P19005, DOI 10.1007/s11042-016-4342-x
   Vapnik V., 2013, The nature of statistical learning theory
   Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747
   Wang XD, 2022, IEEE T CYBERNETICS, V52, P13293, DOI 10.1109/TCYB.2021.3130047
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xiang J, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P424, DOI 10.1109/ICISCE.2017.95
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang WK, 2019, MULTIMED TOOLS APPL, V78, P24373, DOI 10.1007/s11042-018-6995-0
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 51
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33689
EP 33714
DI 10.1007/s11042-022-12806-2
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784951200002
PM 35463219
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Yogeswararao, G
   Naresh, V
   Malmathanraj, R
   Palanisamy, P
AF Yogeswararao, G.
   Naresh, V
   Malmathanraj, R.
   Palanisamy, P.
TI An efficient densely connected convolutional neural network for
   identification of plant diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Skip connection; Dense connection; Plant
   leaf diseases
AB In this research work, novel densely connected convolutional neural network (DCCNN) based deep learning architectures are proposed to identify diseases in the apple, corn, cucumber, grape and potato plant leaves. The three concrete novel deep learning architectures, namely 6 block DCCNN, 7 block DCCNN and 8 block DCCNN are compared with state-of-the-art conventional machine learning and deep learning approaches. The performance is evaluated using training accuracy, validation accuracy, loss values, confusion matrices, sensitivity, specificity, precision and F-score measures. The 8 block DCCNN achieved greater identification accuracy of 99.78%, 98.85%, 98.23%, 99.78, % and 99.83% for apple, corn, cucumber, grape and potato plant leaf dataset respectively. The higher identification accuracy is achieved in the proposed 8 block DCCNN since the densely connected convolution neural network layers are incorporated with modified dense blocks.
C1 [Yogeswararao, G.; Naresh, V; Malmathanraj, R.; Palanisamy, P.] Natl Inst Technol Trichy, Dept Elect & Commun Engn, Tiruchirappalli, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Yogeswararao, G (corresponding author), Natl Inst Technol Trichy, Dept Elect & Commun Engn, Tiruchirappalli, India.
EM yogi.gurubelli@gmail.com
RI Yogeswararao, Gurubelli/ADN-0953-2022
OI , Naresh/0000-0003-0079-2661
CR Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Agrawal N, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P238, DOI 10.1109/RISE.2017.8378160
   Baranwal S, 2019, P INT C SUST COMP SC
   Bhatt P, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P894, DOI 10.5220/0007687608940899
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Gavhale KR, 2014, IOSR J COMPUT ENG IO, V16, P10, DOI DOI 10.9790/0661-16151016
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Gutte V. S., 2016, International Journal of Engineering Science, V7100
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam M, 2017, CAN CON EL COMP EN
   Kandel I, 2020, ICT EXPRESS, V6, P312
   Kingma D. P., 2014, arXiv
   Kusumo BS, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P93, DOI 10.1109/IC3INA.2018.8629507
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu ZX, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P661, DOI [10.1109/itnec48623.2020.9084689, 10.1109/ITNEC48623.2020.9084689]
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Miaomiao Ji, 2020, Information Processing in Agriculture, V7, P418, DOI 10.1016/j.inpa.2019.10.003
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Mishra S, 2020, PROCEDIA COMPUT SCI, V167, P2003, DOI 10.1016/j.procs.2020.03.236
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Padol PB, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P175
   Priyadharshini RA, 2019, NEURAL COMPUT APPL, V31, P8887, DOI 10.1007/s00521-019-04228-3
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Ray Susmita, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P35, DOI 10.1109/COMITCon.2019.8862451
   Sholihati Rizqi Amaliatus, 2020, 2020 International Electronics Symposium (IES), P392, DOI 10.1109/IES50839.2020.9231784
   Tiwari D, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P461, DOI [10.1109/iciccs48265.2020.9121067, 10.1109/ICICCS48265.2020.9121067]
   Waheed A, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105456
   Yang X., 2017, Eur. J. BioMed. Res., V3, P6, DOI DOI 10.18088/EJBMR.3.1.2017.PP6-9
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
NR 32
TC 9
Z9 9
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32791
EP 32816
DI 10.1007/s11042-022-13053-1
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782717900002
DA 2024-07-18
ER

PT J
AU Dim, CA
   Feitosa, RM
   Mota, MP
   de Morais, JM
AF Dim, Cleyton Aparecido
   Feitosa, Rafael Martins
   Mota, Marcelle Pereira
   de Morais, Jefferson Magalhaes
TI Alert systems to hearing-impaired people: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Assistive technologies; Alert systems; Devices; Hearing impairment
AB In recent years there has been a growing concern about the inclusion of people with disabilities in society. Many research in assistive technologies have been carried out, but with a significant disparity between support for the visually impaired and the hearing-impaired, with research referring to visual impairment accounting for more than 90% of them. Furthermore, an analysis of surveys related to the topic shows the low scientific production of assistive technologies for the hearing-impaired, and to our best knowledge, there is no survey specifically dedicated to alert systems for them. Considering this imbalance in scientific production and bearing in mind the positive impact that alert systems can have on the life of a hearing-impaired person, we present a survey in the scientific literature on alert systems specifically designed for people with hearing impairment. The survey aims to contribute to the scientific community in presenting the current scenario of these systems and directing future research, and contributing to people who can directly benefit from technological advances. A search in the Science Direct, IEEE Xplore, and ACM Digital Library databases for alert systems to hearing-impaired people in which mobile devices are involved returned 795 papers, 20 of which met the criteria defined at research protocol of the systematic literature review. These papers are described here, with notes and reflections on their usefulness, potentials, involved technologies, and possible improvements. We describe our findings of assistive systems for the hearing impaired, pointing out a gap in research in this field, as well as the possibilities for future work based on the data analyzed in this systematic literature review.
C1 [Dim, Cleyton Aparecido; Feitosa, Rafael Martins; Mota, Marcelle Pereira; de Morais, Jefferson Magalhaes] Fed Univ Para, Belem, Para, Brazil.
C3 Universidade Federal do Para
RP Dim, CA (corresponding author), Fed Univ Para, Belem, Para, Brazil.
EM cleytondim@ufpa.br; rafaelmf@ufpa.br; mpmota@ufpa.br; jmorais@ufpa.br
RI Mota, Marcelle Pereira/ABI-4261-2020
OI Mota, Marcelle Pereira/0000-0001-9226-9020
CR Abbas MK, 2018, 4 INT C COMP INF SCI, P1, DOI [10.1109/ICCOINS.2018.8510584, DOI 10.1109/ICCOINS.2018.8510584]
   Arunachalam R, 2019, MULTIMED TOOLS APPL, V78, P20787, DOI 10.1007/s11042-019-7329-6
   Bahbouh NM, 2019, INT C ADV EM COMP TE, P1, DOI [10.1109/AECT47998.2020.9194179, DOI 10.1109/AECT47998.2020.9194179]
   Bhat GS, 2020, IEEE ACCESS, V8, P106296, DOI [10.1109/access.2020.2999546, 10.1109/ACCESS.2020.2999546]
   Bourne RRA, 2020, INVEST OPHTH VIS SCI, V61
   Bragg D, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P3, DOI 10.1145/2982142.2982171
   Chadha S, 2021, B WORLD HEALTH ORGAN, V99, P242, DOI 10.2471/BLT.21.285643
   Chatterjee A, 2016, 2016 SECOND IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P22, DOI 10.1109/ICRCICN.2016.7813545
   Chen C. Y., 2019, 2019 IEEE 8 GLOB C C, P933, DOI [10.1109/GCCE46687.2019.9015516, DOI 10.1109/GCCE46687.2019.9015516]
   Dabran I, 2018, IEEE IFIP NETW OP MA, P1, DOI [10.1109/NOMS.2018.8406181, DOI 10.1109/NOMS.2018.8406181]
   Dhanjal Amandeep Singh, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P205, DOI 10.1109/COMITCon.2019.8862454
   Findlater L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300276
   Ito Atsushi, 2008, 2008 Third International Conference on Broadband Communications, Information Technology & Biomedical Applications, P486, DOI 10.1109/BROADCOM.2008.57
   Jain D, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3416991
   Jain D, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3416986
   Kim GY, 2018, PROCEEDINGS OF THE 2018 WORKSHOP ON MULTIMEDIA FOR ACCESSIBLE HUMAN COMPUTER INTERFACE (MAHCI'18), P1, DOI 10.1145/3264856.3264857
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Kumar MP, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9417928
   Kumari P, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS (ADCOM), P39, DOI 10.1109/ADCOM.2015.14
   Liu Sicong, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090082
   Marculescu C, 2020, INT SYM DES TECH ELE, P140, DOI [10.1109/SIITME50350.2020.9292234, 10.1109/siitme50350.2020.9292234]
   Mielke M, 2015, IEEE ENG MED BIO, P5008, DOI 10.1109/EMBC.2015.7319516
   Mielke M, 2013, MIXED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, MIXDES 2013, P512
   Mohanraj I, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P189, DOI 10.1109/ICICCT.2017.7975185
   Padhy S., 2019, 2019 Global Conference for Advancement in Technology (GCAT), P1, DOI 10.1109/CICT48419.2019.9066252
   Rastgoo R, 2022, J AMB INTEL HUM COMP, V13, P591, DOI 10.1007/s12652-021-02920-8
   Sen AAA, 2021, 2021 INT C COMP SUST, P380, DOI [10.1109/INDIACom51348.2021.00066, DOI 10.1109/INDIACOM51348.2021.00066]
   Sneha T, 2021, 5 INT C COMP COMM SI, P1, DOI [10.1109/ICCCSP52374.2021.9465502, DOI 10.1109/ICCCSP52374.2021.9465502]
   Sugang Li, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130938
   Suriyachai Petcharat, 2020, 2020 5th International Conference on Information Technology (InCIT), P222, DOI 10.1109/InCIT50588.2020.9310946
   Yaegashi JG., 2021, REV BRAS INICIACAO C, V8, P1
NR 31
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32351
EP 32370
DI 10.1007/s11042-022-13045-1
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941300002
DA 2024-07-18
ER

PT J
AU Goyal, N
   Kumar, N
   Kapil
AF Goyal, Neha
   Kumar, Nitin
   Kapil
TI Leaf Bagging: A novel meta heuristic optimization based framework for
   leaf identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf classification; Feature selection; Nature-based optimization;
   Ensemble approach; Bootstrap aggregating
ID SHAPE-FEATURES; PLANT; CLASSIFICATION; TEXTURE; MACHINE
AB Automated plant recognition based on leaf images is a challenging task among the researchers from several fields. This task requires distinguishing features derived from leaf images for assigning class label to a leaf image. There are several methods in literature for extracting such distinguishing features. In this paper, we propose a novel automated framework for leaf identification. The proposed framework works in multiple phases i.e. pre-processing, feature extraction, classification using bagging approach. Initially, leaf images are pre-processed using image processing operations such as boundary extraction and cropping. In the feature extraction phase, popular nature inspired optimization algorithms viz. Spider Monkey Optimization (SMO), Particle Swarm Optimization (PSO) and Gray Wolf Optimization (GWO) have been exploited for reducing the dimensionality of features. In the last phase, a leaf image is classified by multiple classifiers and then output of these classifiers is combined using majority voting. The effectiveness of the proposed framework is established based on the experimental results obtained on three datasets i.e. Flavia, Swedish and self-collected leaf images. On all the datasets, it has been observed that the classification accuracy of the proposed method is better than the individual classifiers. Furthermore, the classification accuracy for the proposed approach is comparable to deep learning based method on the Flavia dataset.
C1 [Goyal, Neha; Kumar, Nitin; Kapil] Natl Inst Technol, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Goyal, N (corresponding author), Natl Inst Technol, Kurukshetra, Haryana, India.
EM neha.goyal2309@gmail.com
RI Aggarwal, Kapil/ACA-2420-2022
OI Aggarwal, Kapil/0000-0001-7658-5058; Goyal, Neha/0000-0002-7016-4663
FU University Grant Commission, India
FX We acknowledge University Grant Commission, India for providing research
   fellowship to one of the author Ms. Neha Goyal
CR Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003
   [Anonymous], 1979, P IMAGE UNDERSTANDIN
   Bansal JC, 2014, MEMET COMPUT, V6, P31, DOI 10.1007/s12293-013-0128-0
   Barré P, 2017, ECOL INFORM, V40, P50, DOI 10.1016/j.ecoinf.2017.05.005
   Bodhwani Vinit, 2019, Procedia Computer Science, V152, P186, DOI 10.1016/j.procs.2019.05.042
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010
   Choudhary M. K., 2021, P INT C COMM COMP TE, P657
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Das Choudhury S, 2018, BIOSYST ENG, V170, P72, DOI 10.1016/j.biosystemseng.2018.04.001
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Gonzalez R.C., 2018, Digital Image Processing
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goyal N, 2021, SIVIP, P1
   Goyal N, 2021, MULTIMED TOOLS APPL, V80, P4533, DOI 10.1007/s11042-020-09899-y
   Goyal N, 2019, MULTIMED TOOLS APPL, V78, P27785, DOI 10.1007/s11042-019-7588-2
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hsiao JK, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P389, DOI 10.1109/SAI.2014.6918216
   Kalyoncu C, 2015, COMPUT VIS IMAGE UND, V133, P102, DOI 10.1016/j.cviu.2014.11.001
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kumar S, 2020, SUSTAIN COMPUT-INFOR, V28
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Lin CH, 2012, IET IMAGE PROCESS, V6, P822, DOI 10.1049/iet-ipr.2011.0445
   Löfstedt T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212110
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Pankaja K., 2020, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V101, P597, DOI 10.1007/s40031-020-00470-9
   Patel Bharati, 2020, 2020 First International Conference on Power, Control and Computing Technologies (ICPC2T), P267, DOI 10.1109/ICPC2T48082.2020.9071511
   Patel B, 2019, ADVANCES IN BIOMETRICS: MODERN METHODS AND IMPLEMENTATION STRATEGIES, P211, DOI 10.1007/978-3-030-30436-2_10
   Patil Sumedh, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P1138, DOI 10.1109/ICOEI51242.2021.9453003
   Pearline SA, 2019, J INTELL FUZZY SYST, V36, P1997, DOI 10.3233/JIFS-169911
   Saleem G, 2019, COMPUT ELECTRON AGR, V157, P270, DOI 10.1016/j.compag.2018.12.038
   Schapire RE, 2012, ADAPT COMPUT MACH LE, P1
   Sharaff A., 2021, P DAT DRIV APPR DISR, P49
   SHEARER SA, 1990, T ASAE, V33, P2037
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Soderkvist O., 2001, COMPUTER VISION CLAS
   Sulc M, 2016, VERY DEEP RESIDUAL N
   SUN Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI DOI 10.1155/2017/7361042
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Too JW, 2021, EVOL INTELL, V14, P1691, DOI 10.1007/s12065-020-00441-5
   Too J, 2018, COMPUTERS, V7, DOI 10.3390/computers7040058
   Wäldchen J, 2018, METHODS ECOL EVOL, V9, P2216, DOI 10.1111/2041-210X.13075
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Yang KL, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10111721
   Zhang CY, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P2147, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.318
   Zhao ZQ, 2015, NEUROCOMPUTING, V151, P1112, DOI 10.1016/j.neucom.2014.02.077
NR 51
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32243
EP 32264
DI 10.1007/s11042-022-12825-z
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941600005
DA 2024-07-18
ER

PT J
AU Iyer, A
   Das, SS
   Teotia, R
   Maheshwari, S
   Sharma, RR
AF Iyer, Abhishek
   Das, Srimit Sritik
   Teotia, Reva
   Maheshwari, Shishir
   Sharma, Rishi Raj
TI CNN and LSTM based ensemble learning for human emotion recognition using
   EEG recordings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; EEG; Hybrid model; Differential entropy; LSTM
ID CLASSIFICATION; MUSIC
AB Emotion is a significant parameter in daily life and is considered an important factor for human interactions. The human-machine interactions and their advanced stages like humanoid robots essentially require emotional investigation. This paper proposes a novel method for human emotion recognition using electroencephalogram (EEG) signals. We have considered three emotions namely neutral, positive, and negative. These EEG signals are separated into five frequency bands according to EEG rhythms and the differential entropy is computed over the different frequency band components. The convolution neural network (CNN) and long short-term memory (LSTM) based hybrid model is developed for accurate emotion detection. Further, the extracted features are fed to all three models for emotion recognition. Finally, an ensemble model combines the predictions of all three models. The proposed approach is validated on two datasets namely SEED and DEAP for EEG based emotion analysis. The developed method achieved 97.16% accuracy on SEED dataset for emotion classification. The experimental results indicate that the proposed approach is effective and yields better performance than the compared methods for EEG-based emotion analysis.
C1 [Iyer, Abhishek; Das, Srimit Sritik; Teotia, Reva] Birla Inst Technol & Sci, Dept Elect & Elect Engn, Pilani 333031, Rajasthan, India.
   [Maheshwari, Shishir] Vellore Inst Technol VIT, Sch Elect Engn Sense, Chennai 600127, Tamil Nadu, India.
   [Sharma, Rishi Raj] Def Inst Adv Technol, Dept Elect Engn, Pune 411025, Maharashtra, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); Vellore
   Institute of Technology (VIT); VIT Chennai; Defence Research &
   Development Organisation (DRDO); Defence Institute of Advanced
   Technology (DIAT)
RP Sharma, RR (corresponding author), Def Inst Adv Technol, Dept Elect Engn, Pune 411025, Maharashtra, India.
EM f20181105@pilani.bits-pilani.ac.in; f20180527@pilani.bits-pilani.ac.in;
   f20190268@pilani.bits-pilani.ac.in; shishir.maheshwari@vit.ac.in;
   dr.rrsrrs@gmail.com
RI Sharma, Rishi Raj/X-8015-2018
OI Sharma, Rishi Raj/0000-0001-6835-003X
CR Agarap A. F., 2018, ARXIV
   Anastassiou GA, 2011, COMPUT MATH APPL, V61, P809, DOI 10.1016/j.camwa.2010.12.029
   [Anonymous], 2017, L2 Regularization versus Batch and Weight Normalization
   Bos D. O., 2006, Influ Vis Audit Stimuli, V56, P1
   Chen ZX, 2015, APPL MATH COMPUT, V256, P565, DOI 10.1016/j.amc.2015.01.049
   Cheng Bo, 2008, Journal of Computer Applications, V28, P333, DOI 10.3724/SP.J.1087.2008.00333
   Cui H, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106243
   Dash M., 1997, Intelligent Data Analysis, V1
   Rodríguez JD, 2010, IEEE T PATTERN ANAL, V32, P569, DOI 10.1109/TPAMI.2009.187
   Duan RN, 2013, I IEEE EMBS C NEUR E, P81, DOI 10.1109/NER.2013.6695876
   Glowinski D, 2008, PROC CVPR IEEE, P1608
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Grozea C, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025008
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Huang YJ, 2015, IEEE T BIO-MED ENG, V62, P256, DOI 10.1109/TBME.2014.2347318
   Hwang S, 2020, PATTERN ANAL APPL, V23, P1323, DOI 10.1007/s10044-019-00860-w
   Kurbalija V, 2018, COGN SYST RES, V52, P103, DOI 10.1016/j.cogsys.2018.06.009
   Lan ZR, 2019, IEEE T COGN DEV SYST, V11, P85, DOI 10.1109/TCDS.2018.2826840
   Li H, 2018, LECT NOTES COMPUT SC, V11305, P403, DOI 10.1007/978-3-030-04221-9_36
   Li Mu, 2009, Annu Int Conf IEEE Eng Med Biol Soc, V2009, P1323, DOI 10.1109/IEMBS.2009.5334139
   Li PY, 2019, IEEE T BIO-MED ENG, V66, P2869, DOI 10.1109/TBME.2019.2897651
   Li X, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00162
   Li Y, 2021, IEEE T AFFECT COMPUT, V12, P494, DOI 10.1109/TAFFC.2018.2885474
   Liu JX, 2020, FRONT SYST NEUROSCI, V14, DOI 10.3389/fnsys.2020.00043
   Liu NH, 2013, SENSORS-BASEL, V13, P8199, DOI 10.3390/s130708199
   Liu W, 2016, LECT NOTES COMPUT SC, V9948, P521, DOI 10.1007/978-3-319-46672-9_58
   Liu WY, 2016, PR MACH LEARN RES, V48
   Mariooryad S, 2014, SPEECH COMMUN, V57, P1, DOI 10.1016/j.specom.2013.07.011
   Mathersul D, 2008, EMOTION, V8, P560, DOI 10.1037/a0012811
   Park S, 2017, LECT NOTES COMPUT SC, V10112, P189, DOI 10.1007/978-3-319-54184-6_12
   Piana S, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2818740
   Qiu JL, 2018, LECT NOTES COMPUT SC, V11305, P221, DOI 10.1007/978-3-030-04221-9_20
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   Sarkar P, 2022, IEEE T AFFECT COMPUT, V13, P1541, DOI 10.1109/TAFFC.2020.3014842
   Sauvet F, 2014, IEEE T BIO-MED ENG, V61, P2840, DOI 10.1109/TBME.2014.2331189
   Sharma R., 2021, Computer-Aided Design and Diagnosis Methods for Biomedical Applications, P35
   Sharma RR, 2018, IET SCI MEAS TECHNOL, V12, P72, DOI 10.1049/iet-smt.2017.0058
   Sharma S, 2022, ARTIF INTELL, P101
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Subasi A, 2010, EXPERT SYST APPL, V37, P8659, DOI 10.1016/j.eswa.2010.06.065
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Tabar YR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2560/14/1/016003
   Tahir MA, 2012, PATTERN RECOGN LETT, V33, P513, DOI 10.1016/j.patrec.2011.10.019
   Tang H, 2017, LECT NOTES COMPUT SC, V10637, P811, DOI 10.1007/978-3-319-70093-9_86
   Teuwen J., 2020, Handbook of Medical Image Computing and Computer-Assisted Intervention, P481, DOI DOI 10.1016/C2017-0-04608-6
   Tripathi S, 2017, AAAI CONF ARTIF INTE, P4746
   Wang YX, 2019, IEEE I CONF COMP VIS, P9924, DOI 10.1109/ICCV.2019.01002
   Wang ZM, 2019, IEEE ACCESS, V7, P93711, DOI 10.1109/ACCESS.2019.2927768
   Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29
   Wenming Zheng, 2018, IEEE Transactions on Affective Computing, V9, P21, DOI 10.1109/TAFFC.2016.2563432
   Wu ZZ, 2014, P IEEE INT FREQ CONT, P136, DOI 10.1007/s10766-014-0304-y
   Young AW, 1997, COGNITION, V63, P271, DOI 10.1016/S0010-0277(97)00003-6
   Zhang DL, 2018, AAAI CONF ARTIF INTE, P1703
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zhong PX, 2022, IEEE T AFFECT COMPUT, V13, P1290, DOI 10.1109/TAFFC.2020.2994159
NR 56
TC 41
Z9 41
U1 14
U2 112
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4883
EP 4896
DI 10.1007/s11042-022-12310-7
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000781124000011
DA 2024-07-18
ER

PT J
AU Zhang, XQ
   Gong, ZJ
AF Zhang, Xiaoqiang
   Gong, Zhengjun
TI Color image encryption algorithm based on 3D Zigzag transformation and
   view planes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Zigzag transformation; Chaotic system; SHA-256; View
   plane
ID SYSTEM
AB To prevent the information leak of image content, image encryption technology has received increasing attention. The proposed algorithm adopts a diffusion-permutation-diffusion structure. Inspired by the three-view drawing in the engineering field, the view planes of color image are defined in this paper and applied in both diffusion stages. At the permutation stage, a 3D Zigzag transformation is proposed to destroy the correlation among R, G, B components. Moreover, we combine two chaotic systems as a new pseudo-random number generator (PRNG). Experiments and algorithm analyses indicate that the proposed algorithm has strong security and desirable performance.
C1 [Zhang, Xiaoqiang; Gong, Zhengjun] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhang, Xiaoqiang; Gong, Zhengjun] Xuzhou Key Lab Artificial Intelligence & Big Data, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Zhang, XQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.; Zhang, XQ (corresponding author), Xuzhou Key Lab Artificial Intelligence & Big Data, Xuzhou 221116, Jiangsu, Peoples R China.
EM grayqiang@163.com
RI gong, zhengjun/V-7285-2019
OI gong, zhengjun/0000-0001-5710-3156
CR Abdallah E, 2007, GRAPH INT C MONTR CA
   Abdallah EE, 2006, INT C PATT RECOG, P673
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Albhrany E, 2017, INT J SCI ENG RES, V8, P2114
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Chen L, 2020, NONLINEAR DYNAM, V100, P3959, DOI 10.1007/s11071-020-05735-y
   Dawahdeh ZE, 2018, J KING SAUD UNIV-COM, V30, P349, DOI 10.1016/j.jksuci.2017.06.004
   Fan CL, 2019, NONLINEAR DYNAM, V97, P831, DOI 10.1007/s11071-019-05015-4
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Guo F, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/8474715
   Hanif M, 2020, IEEE ACCESS, V8, P146408, DOI 10.1109/ACCESS.2020.3015085
   He JB, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7080743
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2020, IEEE T SIGNAL PROCES, V68, P1937, DOI 10.1109/TSP.2020.2979596
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Huang LK, 2019, ADV ENERGY MATER, V9, DOI 10.1002/aenm.201900248
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Li J, 2020, J COMPUT APPL MATH, V380, DOI 10.1016/j.cam.2020.112952
   Liu XB, 2019, IEEE ACCESS, V7, P57188, DOI 10.1109/ACCESS.2019.2914184
   Liu Y, 2020, NONLINEAR DYNAM, V100, P2917, DOI 10.1007/s11071-020-05654-y
   Liu Y, 2019, IEEE ACCESS, V7, P74070, DOI 10.1109/ACCESS.2019.2916600
   Liu YJ, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106171
   Ma YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102566
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Man ZL, 2019, IEEE ACCESS, V7, P103047, DOI 10.1109/ACCESS.2019.2931732
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Ramasamy P, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070656
   Sun SL, 2019, IEEE ACCESS, V7, P28539, DOI 10.1109/ACCESS.2019.2901870
   Tresor LO, 2019, IEEE ACCESS, V7, P103463, DOI 10.1109/ACCESS.2019.2929244
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P34981, DOI 10.1007/s11042-019-08085-z
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhao TY, 2016, OPT COMMUN, V376, P47, DOI 10.1016/j.optcom.2016.05.016
   Zhu HG, 2019, IEEE ACCESS, V7, P14081, DOI 10.1109/ACCESS.2019.2893538
NR 45
TC 16
Z9 16
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31753
EP 31785
DI 10.1007/s11042-022-13003-x
EA APR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000012
DA 2024-07-18
ER

PT J
AU Kavitha, TS
   Prasad, KS
AF Kavitha, Tirugatla Surya
   Prasad, Kodati Satya
TI A novel method of compressive sensing MRI reconstruction based on
   sandpiper optimization algorithm (SPO) and mask region based convolution
   neural network (mask RCNN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging (MRI); Sandpiper optimization algorithm
   (SPO); Compressed sensing; Cartesian sampling; Radial sampling; Aliasing
AB A compressive sensing method is a current structure for signal sampling and reclamation. It allows signal acquisition with fewer sampling than the Nyquist-Shannon theorem needs and decreases Magnetic Resonance Imaging (MRI) data achievement time. In this manuscript, Mask Region Based Convolution Neural Network (Mask RCNN) optimized with Sand Piper Optimization (SPO) algorithm is proposed for eliminating aliasing artifacts while attaining enhanced reconstructing images. Initially, Mask Region Based Convolution Neural Network reduces the aliasing artifacts, and then Sand Piper Optimization is used to optimize the weight parameter of the Mask Region Based Convolutional Neural Network, which is used for enhancing the efficiency of image reconstruction. The advantage of Sandpiper Optimization Algorithm is to provide correct reconstruction from a small set of l-space. This algorithm prevents premature convergence and makes better solutions. The proposed algorithm is tested with compressive sensed l-space data at sampling rates 75%, 60% and 50%. Here, two different sampling methods are used, they are Cartesian and radial sampling. The simulation is carried out in MATLAB tool. Finally, the performance of the proposed method is analysed with Peak Signal to Noise Ratio (PSNR), Mean Square Error (MSE) and Structural Similarity Index Measure (SSIM) of brain and compared with five different existing methods.
C1 [Kavitha, Tirugatla Surya; Prasad, Kodati Satya] JNTUK, Dept Elect & Commun Engn, Kakinada, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Kavitha, TS (corresponding author), JNTUK, Dept Elect & Commun Engn, Kakinada, Andhra Pradesh, India.
EM kavitats24@gmail.com; prasad_kodati@yahoo.co.in
RI Tirugatla, Surya Kavitha/GZL-9428-2022
OI Tirugatla, Surya Kavitha/0000-0003-3462-2273
CR Bansal J.C., 2019, Evolutionary and Swarm Intelligence Algorithms, VVolume 779
   Chen Z, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.104969
   Dai YX, 2019, MAGN RESON IMAGING, V63, P93, DOI 10.1016/j.mri.2019.07.014
   Deka B, 2018, IEEE SIGNAL PROC LET, V25, P730, DOI 10.1109/LSP.2018.2824251
   Fan XY, 2017, IEEE ACCESS, V5, P19311, DOI 10.1109/ACCESS.2017.2749381
   Huijben IAM, 2020, INT CONF ACOUST SPEE, P8906, DOI [10.1109/icassp40776.2020.9053331, 10.1109/ICASSP40776.2020.9053331]
   Kaur A, 2020, APPL INTELL, V50, P582, DOI 10.1007/s10489-019-01507-3
   Krahmer F, 2017, APPL NUMER HARMON AN, P333, DOI 10.1007/978-3-319-69802-1_11
   Li YX, 2021, MAGN RESON IMAGING, V77, P124, DOI 10.1016/j.mri.2020.12.011
   Liu XJ, 2017, IEEE T INFORM THEORY, V63, P2922, DOI 10.1109/TIT.2017.2677965
   Liu YL, 2020, IEEE T COMPUT IMAG, V6, P434, DOI 10.1109/TCI.2019.2956877
   Manimala MVR, 2021, WIRELESS PERS COMMUN, V116, P491, DOI 10.1007/s11277-020-07725-0
   Mythili S., 2020, HKIE T, V27, P25, DOI DOI 10.33430/V27N1THIE-2018-0024
   Oh G, 2020, I S BIOMED IMAGING, P1087, DOI [10.1109/isbi45749.2020.9098579, 10.1109/ISBI45749.2020.9098579]
   Pawar K, 2019, IEEE ACCESS, V7, P177690, DOI 10.1109/ACCESS.2019.2959037
   Rajesh P., 2020, Eur J Electr Eng, V22, P224, DOI [10.18280/ejee.224-509, DOI 10.18280/EJEE.224-509]
   Schnass K, 2018, IEEE SIGNAL PROC LET, V25, P1865, DOI 10.1109/LSP.2018.2878061
   Shajin FH, 2022, INT J PERVASIVE COMP, V18, P603, DOI 10.1108/IJPCC-09-2020-0136
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Su YS, 2019, ANN IEEE SYM FIELD P, P254, DOI 10.1109/FCCM.2019.00041
   Sun LY, 2019, IEEE T IMAGE PROCESS, V28, P6141, DOI 10.1109/TIP.2019.2925288
   Thota M. K., 2020, Int. J. ApplSci Eng., V17, P331, DOI [DOI 10.6703/IJASE.20201217(4).331, DOI 10.6703/IJASE.202012_17(4).331]
   Wang Alan Q., 2020, Machine Learning for Medical Image Reconstruction. Third International Workshop, MLMIR 2020. Held in Conjunction with MICCAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12450), P27, DOI 10.1007/978-3-030-61598-7_3
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879
   Ye Jong Chul, 2019, BMC Biomed Eng, V1, P8, DOI 10.1186/s42490-019-0006-z
   Yu Y, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.06.001
   Zbontar J, 2018, FAST MRI OPEN DATASE
   Zeng K, 2019, IEEE ACCESS, V7, P85430, DOI 10.1109/ACCESS.2019.2924604
   Zhang XB, 2019, IEEE ACCESS, V7, P175554, DOI 10.1109/ACCESS.2019.2955759
   Zhu YG, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03680
NR 31
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31469
EP 31492
DI 10.1007/s11042-022-12940-x
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700001
DA 2024-07-18
ER

PT J
AU Prasad, DS
   Chanamallu, SR
   Prasad, KS
AF Prasad, Devulapalli Shyam
   Chanamallu, Srinivasa Rao
   Prasad, Kodati Satya
TI Optimized deformable convolution network for detection and mitigation of
   ocular artifacts from EEG signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalogram; Ocular artifacts; 5-level discrete wavelet
   transform; Pisarenko harmonic decomposition; Optimized deformable
   convolutional networks; Empirical mean curve decomposition; Distance
   sorted-electric fish optimization
ID REMOVAL; CLASSIFICATION; SVM; ICA
AB Electroencephalogram (EEG) is the key component in the field of analyzing brain activity and behavior. EEG signals are affected by artifacts in the recorded electrical activity; thereby it affects the analysis of EGG. To extract the clean data from EEG signals and to improve the efficiency of detection during encephalogram recordings, a developed model is required. Although various methods have been proposed for the artifacts removal process, sill the research on this process continues. Even if, several types of artifacts from both the subject and equipment interferences are highly contaminated the EEG signals, the most common and important type of interferences is known as Ocular artifacts. Many applications like Brain-Computer Interface (BCI) need online and real-time processing of EEG signals. Hence, it is best if the removal of artifacts is performed in an online fashion. The main intention of this proposal is to accomplish the new deep learning-based ocular artifacts detection and prevention model. In the detection phase, the 5-level Discrete Wavelet Transform (DWT), and Pisarenko harmonic decomposition are used for decomposing the signals. Then, the Principle Component Analysis (PCA) and Independent Component Analysis (ICA) are adopted as the techniques for extracting the features. With the collected features, the development of optimized Deformable Convolutional Networks (DCN) is used for the detection of ocular artifacts from the input EEG signal. Here, the optimized DCN is developed by optimizing or tuning some significant parameters by Distance Sorted-Electric Fish Optimization (DS-EFO). If the artifacts are detected, the mitigation process is performed by applying the Empirical Mean Curve Decomposition (EMCD), and then, the optimized DCN is used for denoising the signals. Finally, the clean signal is generated by applying inverse EMCD. Based on the EEG data collected from diverse subjects, the proposed method has achieved a higher performance than that of conventional methods, which demonstrates a better ocular-artifact reduction by the proposed method.
C1 [Prasad, Devulapalli Shyam] JNTU, Kakinada, Andhra Pradesh, India.
   [Prasad, Devulapalli Shyam] CVR Coll Engn, Hyderabad, Telangana, India.
   [Chanamallu, Srinivasa Rao] Univ Coll Engn, JNTUK, Dept ECE, Narasaraopet, Andhra Pradesh, India.
   [Prasad, Kodati Satya] Univ Coll Engn, JNTUK, Dept ECE, Kakinada, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Jawaharlal Nehru
   Technological University - Kakinada; Jawaharlal Nehru Technological
   University - Kakinada
RP Prasad, DS (corresponding author), JNTU, Kakinada, Andhra Pradesh, India.; Prasad, DS (corresponding author), CVR Coll Engn, Hyderabad, Telangana, India.
EM devula_shyam@yahoo.co.in
CR Betta M, 2013, IEEE ENG MED BIO, P5079, DOI 10.1109/EMBC.2013.6610690
   Fallani FD, 2009, ANAT REC, V292, P2023, DOI 10.1002/ar.20965
   Gajbhiye P, 2019, IEEE SENS J, V19, P10600, DOI 10.1109/JSEN.2019.2931727
   Jafarifarmand A, 2017, BIOMED SIGNAL PROCES, V31, P199, DOI 10.1016/j.bspc.2016.08.006
   Jaffino G, 2021, 2021 INT C ADV EL CO, P1, DOI [10.1109/ICAECT49130.2021.9392541, DOI 10.1109/ICAECT49130.2021.9392541]
   Kanoga S, 2019, NEUROCOMPUTING, V347, P240, DOI 10.1016/j.neucom.2019.02.060
   Li XY, 2017, IEEE T BIO-MED ENG, V64, P1906, DOI 10.1109/TBME.2016.2628958
   Li Z, 2023, IEEE T NEUR NET LEAR, V34, P2854, DOI 10.1109/TNNLS.2021.3109953
   Maddirala AK, 2016, IEEE SENS J, V16, P8279, DOI 10.1109/JSEN.2016.2560219
   Mahajan R, 2015, IEEE J BIOMED HEALTH, V19, P158, DOI 10.1109/JBHI.2014.2333010
   Mamun M, 2013, J APPL RES TECHNOL, V11, P156, DOI 10.1016/S1665-6423(13)71524-4
   Manne R., 2020, Int J Modern Trends Sci Technol, P2455, DOI [10.46501/IJMTST061118, DOI 10.46501/IJMTST061118]
   Mashhadi N, 2020, IEEE GLOB HUMANIT C, DOI 10.1109/GHTC46280.2020.9342884
   Metsomaa J, 2017, IEEE T BIO-MED ENG, V64, P2054, DOI 10.1109/TBME.2016.2616389
   Mishra Ayushi, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P793, DOI 10.1007/978-981-13-3600-3_76
   Mosquera GC, 2009, EUR SIGN PROC C
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Peng H, 2013, IEEE J BIOMED HEALTH, V17, P600, DOI 10.1109/JBHI.2013.2253614
   Prasad D, 2022, CATAL REV, V64, P356, DOI 10.1080/01614940.2020.1812212
   Quazi MH, 2017, BIOCYBERN BIOMED ENG, V37, P401, DOI 10.1016/j.bbe.2017.04.003
   Rambabu C, 2014, INT J COMPUTER APPL, V85
   Ravi V, 2021, COMPUTATIONAL BIOL, V31
   Ravi V, 2022, MULTIMEDIA SYST, V28, P1401, DOI 10.1007/s00530-021-00826-1
   Ravi V, 2023, IEEE T ENG MANAGE, V70, P249, DOI 10.1109/TEM.2021.3059664
   Sai CY, 2018, IEEE J BIOMED HEALTH, V22, P664, DOI 10.1109/JBHI.2017.2723420
   Sarin Mohit, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P1054, DOI 10.1109/SPIN48934.2020.9071360
   Selvan S, 1999, IEEE SIGNAL PROC LET, V6, P330, DOI 10.1109/97.803438
   Selvan S, 2015, IEEE SIGNAL PROC LET, V6
   Shaker M.M., 2007, EEG Waves Classifier using Wavelet Transform and Fourier Transform, V1, P169
   Shamshirband S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103627
   Shao SY, 2009, IEEE T BIO-MED ENG, V56, P336, DOI 10.1109/TBME.2008.2005969
   Shoker L, 2005, IEEE SIGNAL PROC LET, V12, P721, DOI 10.1109/LSP.2005.855539
   So HC, 2004, IEEE T SIGNAL PROCES, V52, P1128, DOI 10.1109/TSP.2004.823473
   Sreeja SR, 2018, IEEE J BIOMED HEALTH, V22, P1362, DOI 10.1109/JBHI.2017.2771783
   Subasi A, 2010, EXPERT SYST APPL, V37, P8659, DOI 10.1016/j.eswa.2010.06.065
   Sun LS, 2005, PROCEEDINGS OF 2005 IEEE INTERNATIONAL WORKSHOP ON VLSI DESIGN AND VIDEO TECHNOLOGY, P219, DOI 10.1109/IWVDVT.2005.1504590
   ter Braack EM, 2013, IEEE T NEUR SYS REH, V21, P376, DOI 10.1109/TNSRE.2012.2228674
   Wang G, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2450196
   Wang XM, 2021, BIOSENSORS-BASEL, V11, DOI 10.3390/bios11060198
   Yang BH, 2018, BIOMED SIGNAL PROCES, V43, P148, DOI 10.1016/j.bspc.2018.02.021
   Yang C, 2019, IEEE ACCESS, V7, P22301, DOI 10.1109/ACCESS.2019.2898711
   Yi P, 2021, EEGDNET FUSING NONLO
   Yilmaz S, 2020, NEURAL COMPUT APPL, V32, P11543, DOI 10.1007/s00521-019-04641-8
   Zeng H, 2013, SENSORS-BASEL, V13, P14839, DOI 10.3390/s131114839
   Zou Y, 2016, IEEE J BIOMED HEALTH, V20, P73, DOI 10.1109/JBHI.2014.2370646
NR 45
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30841
EP 30879
DI 10.1007/s11042-022-12874-4
EA APR 2022
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779229700001
PM 35431612
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Tasci, E
   Ugur, A
AF Tasci, Erdal
   Ugur, Aybars
TI A novel pattern recognition framework based on ensemble of handcrafted
   features on images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Image processing; Feature extraction; Feature
   selection; Machine learning
ID CLASSIFICATION; SHAPE; ALGORITHMS
AB Nowadays, with the advances and use of technological possibilities and devices, the number of digital images is increasing gradually. Computer-aided classification of image types is widely applied in many applications such as medicine, security, and automation. The feature extraction and selection stages have great importance in terms of improving the classification performance as sub-stages of the pattern recognition process. Researchers apply different feature extraction methods for their works due to the requirements. In this study, a novel pattern recognition framework combining diverse and large-scale handcrafted feature extraction methods (shape-based and texture-based) and the selection stage on images is developed. Genetic algorithms are also used for feature selection. In the experimental studies, Flavia leaf recognition, Caltech101 object classification image datasets, and five supervised classification models (random forest, ECOC-SVM, k-nearest neighbor, AdaBoost, classification tree) with different parameters' values are used. The experimental results show that the proposed method achieves 98.39% and 82.77% accuracy rates on Flavia and Caltech101 datasets with the ECOC-SVM model, respectively. The proposed framework is also competitive with the existing state-of-the-art methods in the related literature.
C1 [Tasci, Erdal; Ugur, Aybars] Ege Univ, Comp Engn Dept, Bornova, Turkey.
C3 Ege University
RP Tasci, E (corresponding author), Ege Univ, Comp Engn Dept, Bornova, Turkey.
EM arif.erdal.tasci@ege.edu.tr; aybars.ugur@ege.edu.tr
RI UGUR, Aybars/A-2962-2010; Taşcı, Erdal/AAB-7693-2020
OI Taşcı, Erdal/0000-0001-6754-2187
FU Scientific and Technological Research Council of Turkey (TUBITAK) 2211
   National Graduate Scholarship Program
FX The author Erdal TASCI has been supported by the Scientific and
   Technological Research Council of Turkey (TUBITAK) 2211 National
   Graduate Scholarship Program.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], 2013, ARXIV14014447
   [Anonymous], 2012, PROC 2012 INT S INNO, DOI DOI 10.1109/INISTA.2012.6247030
   Antipov G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1263, DOI 10.1145/2733373.2806332
   Bagheri Mohammad Ali, 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P508, DOI 10.1109/AISP.2012.6313800
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Barczak Andre LC, 2011, INT C IM VIS COMP NZ
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Busuttil Steven, 2004, Genome Inform, V15, P191
   Caltech, 2018, CALTECH101
   Chang C, 2001, PROC SPIE, V4315, P31, DOI 10.1117/12.410947
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dash M., 1997, Intelligent Data Analysis, V1
   Ehsanirad A., 2010, International Journal of Computer Science and Information Security, V8, P78
   Eid HF, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION TECHNOLOGY AND SENSOR APPLICATION (AITS), P76, DOI 10.1109/AITS.2015.28
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   Gupta S, 2020, PATTERN ANAL APPL, V23, P1569, DOI 10.1007/s10044-020-00879-4
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hossain J., 2010, Proceedings of the 13th International Conference on Computer and Information Technology (ICCIT 2010), P458, DOI 10.1109/ICCITECHN.2010.5723901
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hwang W, 2018, MULTIMED TOOLS APPL, V77, P23429, DOI 10.1007/s11042-017-5571-3
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jeong D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071936
   Jovic A, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1200, DOI 10.1109/MIPRO.2015.7160458
   KABBAI L, 2018, VISUAL COMPUT
   Khan R, 2015, COMPUT VIS IMAGE UND, V132, P102, DOI 10.1016/j.cviu.2014.09.005
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kim JH, 2018, DISPLAYS, V55, P38, DOI 10.1016/j.displa.2018.08.001
   Kumar PSVVSR, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P548, DOI 10.1109/IC3I.2016.7918024
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li XC, 2008, ENG APPL ARTIF INTEL, V21, P785, DOI 10.1016/j.engappai.2007.07.001
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Materka A, 1998, TEXTURE ANAL METHODS, P9
   Mathworks, 2018, MEAS PROP IM REG
   Mathworks, 2018, DCT2
   Mingqiang Y., 2008, SURVEY SHAPE FEATURE
   Mukherjee S., 2017, Jmis.Org, V4, P233, DOI 10.9717/JMIS.2017.4.4.233
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095
   Mutch J., 2006, 2006 IEEE COMP SOC C, V1, P11, DOI DOI 10.1109/CVPR.2006.200
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pankaja K., 2020, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V101, P597, DOI 10.1007/s40031-020-00470-9
   Prasad S, 2017, MULTIMED TOOLS APPL, V76, P6915, DOI 10.1007/s11042-016-3309-2
   Pyactlearn, 2018, MULTICL PERF METR
   Rahman MM, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0178-1
   Raji IK., 2016, INT J TELEMED CLIN P, V1, P265
   Ramesh B, 2017, PATTERN RECOGN, V67, P380, DOI 10.1016/j.patcog.2017.02.024
   Sargano AB, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7010110
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Satti V., 2013, International Journal of Engineering Science and Technology (IJEST), V4, P874
   Singh B.K., 2015, INT J COMPUTER APPL, V116
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   SRINIVAS M, 1994, COMPUTER, V27, P17, DOI 10.1109/2.294849
   Tahmasbi A, 2011, COMPUT BIOL MED, V41, P726, DOI 10.1016/j.compbiomed.2011.06.009
   Tang J., 2014, Data Classification, V37, DOI DOI 10.1201/B17320
   Tasci E, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0231-5
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wang XG, 2011, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2011.5995696
   Watanabe S., 1985, PATTERN RECOGN
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Yousefi E, 2017, COMPUT ELECTRON AGR, V140, P70, DOI 10.1016/j.compag.2017.05.031
   Zhou JX, 2019, MULTIMED TOOLS APPL, V78, P6163, DOI 10.1007/s11042-018-6192-1
NR 73
TC 5
Z9 5
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30195
EP 30218
DI 10.1007/s11042-022-12909-w
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500002
DA 2024-07-18
ER

PT J
AU Zhou, YG
   Ren, YB
   Xu, EY
   Liu, SL
   Zhou, LJ
AF Zhou, Yuguo
   Ren, Yanbo
   Xu, Erya
   Liu, Shiliang
   Zhou, Lijian
TI Supervised semantic segmentation based on deep learning: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Supervised learning; Computer vision;
   Convolutional neural networks
AB Recently, many semantic segmentation methods based on fully supervised learning are leading the way in the computer vision field. In particular, deep neural networks headed by convolutional neural networks can effectively solve many challenging semantic segmentation tasks. To realize more refined semantic image segmentation, this paper studies the semantic segmentation task with a novel perspective, in which three key issues affecting the segmentation effect are considered. Firstly, it is hard to predict the classification results accurately in the high-resolution map from the reduced feature map since the scales are different between them. Secondly, the multi-scale characteristics of the target and the complexity of the background make it difficult to extract semantic features. Thirdly, the problem of intra-class differences and inter-class similarities can lead to incorrect classification of the boundary. To find the solutions to the above issues based on existing methods, the inner connection between past research and ongoing research is explored in this paper. In addition, qualitative and quantitative analyses are made, which can help the researchers to establish an intuitive understanding of various methods. At last, some conclusions about the existing methods are drawn to enhance segmentation performance. Moreover, the deficiencies of existing methods are researched and criticized, and a guide for future directions is provided.
C1 [Zhou, Yuguo; Ren, Yanbo; Xu, Erya; Liu, Shiliang; Zhou, Lijian] Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266525, Shandong, Peoples R China.
C3 Qingdao University of Technology
RP Zhou, LJ (corresponding author), Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao 266525, Shandong, Peoples R China.
EM zhouyuguo@qut.edu.cn; christopher0527@163.com; 1030061939@qq.com;
   1156844855@qq.com; zhoulijian@qut.edu.cn
RI Zhou, Lijian/JAC-6504-2023; Zhou, Lijian/ABM-3689-2022
OI Zhou, Lijian/0000-0001-6975-1732; Zhou, Yuguo/0000-0002-0800-4853
FU National Natural Science Foundation [62171247]; Natural Science
   Foundation of Shandong Province [ZR2020MF001, ZR2020QF101]
FX This work was supported by a National Natural Science Foundation (Grant
   No. 62171247) and two Natural Science Foundation of Shandong Province
   (Grant No. ZR2020MF001 and Grant No. ZR2020QF101).
CR Acuna D, 2019, PROC CVPR IEEE, P11067, DOI 10.1109/CVPR.2019.01133
   ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Andrew T, 2020, ARXIV PREPRINT ARXIV
   [Anonymous], 2008, IEEE C COMPUTER VISI
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bertasius G, 2016, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2016.392
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen J., 2021, Transunet: transformers make strong encoders for medical image segmentation
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Galassi A, 2021, IEEE T NEUR NET LEAR, V32, P4291, DOI 10.1109/TNNLS.2020.3019893
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Ghosh S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329784
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kendall Alex, 2017, ADV NEURAL INFORM PR, V30, DOI DOI 10.5555/3295222.3295309
   Kirillov A., 2020, P IEEECVF C COMPUTER, P9799, DOI DOI 10.48550/ARXIV.1912.08193
   Kittler J., 1983, Image and Vision Computing, V1, P37, DOI [DOI 10.1016/0262-8856(83)90006-9, 10.1016/0262-8856(83)90006-9]
   Krahenbuhl P., 2011, NIPS
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lakshmi S., 2010, IJCA SPECIAL ISSUE C, P35, DOI DOI 10.5120/209-351
   Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu S., 2017, ADV NEURAL INFORM PR, P1521
   [刘松涛 Liu Songtao], 2012, [自动化学报, Acta Automatica Sinica], V38, P911
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maggiori E, 2017, INT GEOSCI REMOTE SE, P3226, DOI 10.1109/IGARSS.2017.8127684
   MARDIA KV, 1988, IEEE T PATTERN ANAL, V10, P919, DOI 10.1109/34.9113
   Mazzini, 2018, P BRIT MACH VIS C 20
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Minghao Yin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P191, DOI 10.1007/978-3-030-58555-6_12
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Paisitkriangkrai S, 2016, IEEE J-STARS, V9, P2868, DOI 10.1109/JSTARS.2016.2582921
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Poudel R.P.K., 2019, ARXIV190204502, P289
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shao, 2019, DIANZI KEJI DAXUE XU, V48, P644, DOI [10.3969/j.issn.1001-0548.2019.05.001, DOI 10.3969/J.ISSN.1001-0548.2019.05.001]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Suyash, 2016, ARXIV PREPRINT ARXIV
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vemulapalli R, 2016, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2016.351
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Z, 2019, PROC CVPR IEEE, P7492, DOI 10.1109/CVPR.2019.00768
   Wu HP, 2019, IEEE I CONF COMP VIS, P9216, DOI 10.1109/ICCV.2019.00931
   Xie Enze, 2021, ARXIV210515203, DOI DOI 10.48550/ARXIV.2105.15203
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yanwei Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8550, DOI 10.1109/CVPR42600.2020.00858
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu F., 2015, ARXIV
   Yuan Y., 2018, ARXIV PREPRINT ARXIV
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P489, DOI 10.1007/978-3-030-58610-2_29
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou Bolei, 2017, PROC CVPR IEEE, P633, DOI DOI 10.1109/CVPR.2017.544
NR 86
TC 2
Z9 2
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29283
EP 29304
DI 10.1007/s11042-022-12842-y
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777384900007
DA 2024-07-18
ER

PT J
AU Wang, DL
   Sun, H
   Lu, W
   Zhao, WB
   Liu, YT
   Chai, PP
   Han, Y
AF Wang, Daolei
   Sun, Hao
   Lu, Wu
   Zhao, Wenbin
   Liu, Yiteng
   Chai, Pingping
   Han, Yang
TI A novel binocular vision system for accurate 3-D reconstruction in
   large-scale scene based on improved calibration and stereo matching
   methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo vision; Camera calibration; Polar correction; 3-D reconstruction
AB The 3D reconstruction technology based on stereo vision directly acquires the 3D model of the object through two 2D images. The reconstruction is recovered highly automated. It does not require any prior information and special hardware support. However, for large outdoor scenes, the existing 3D reconstruction technology based on stereo vision often has detailed information loss and data scattering, which makes the reconstruction result less accurate. For this problem, a novel binocular vision system for 3D reconstruction in large-scale scene is proposed. This system uses the calibration rods to perform the calibration calculation based on the polar line correction, and then it utilizes the weighted least squares filter(WLSF) to denoise and smooth the depth map, finally, the point cloud is reconstructed. The results of experiment show that compared with the traditional stereo vision system, the calibration results of new system is more accurate and the calibration space is expanded. The depth map is smoother and less noisy. The system can reconstruct the 3D point cloud of large scene more stably and accurately, has high practical value.
C1 [Sun, Hao] Xi An Jiao Tong Univ, Sch Energy & Power Engn, Xian 710049, Shaanxi, Peoples R China.
   [Wang, Daolei; Lu, Wu; Zhao, Wenbin; Liu, Yiteng; Chai, Pingping; Han, Yang] Shanghai Univ Elect Power, Coll Energy & Mech Engn, Shanghai 200090, Peoples R China.
C3 Xi'an Jiaotong University; Shanghai University of Electric Power
RP Sun, H (corresponding author), Xi An Jiao Tong Univ, Sch Energy & Power Engn, Xian 710049, Shaanxi, Peoples R China.; Zhao, WB (corresponding author), Shanghai Univ Elect Power, Coll Energy & Mech Engn, Shanghai 200090, Peoples R China.
EM hallesun@stu.xjtu.edu.cn; zhaowenbin@shiep.edu.cn
RI Zhao, Wenbin/GLR-9468-2022; Han, Yang/JVN-5921-2024; sun,
   hao/HMD-2991-2023; wang, wenxin/JOZ-3291-2023; Li, Shuyao/JRY-8603-2023;
   zheng, xin/JNS-5523-2023; lu, yuting/IIS-2826-2023
OI Zhao, Wenbin/0000-0002-0613-2923; 
FU National Natural Science Foundation of China [61502297, 51707113]
FX This work was supported by National Natural Science Foundation of China
   under the grant number 61502297 and 51707113.
CR BURIE JC, 1995, MATH COMPUT MODEL, V22, P235, DOI 10.1016/0895-7177(95)00135-O
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gao S, 2019, PHOTOGRAMM REC, V34, P36, DOI 10.1111/phor.12268
   Golodetz S, 2018, IEEE T VIS COMPUT GR, V24, P2895, DOI 10.1109/TVCG.2018.2868533
   Ha H, 2012, IEEE T INSTRUM MEAS, V61, P267, DOI 10.1109/TIM.2011.2159322
   Hu Y, 2019, OPT LASER ENG, V113, P14, DOI 10.1016/j.optlaseng.2018.09.011
   Hu YF, 2011, MATH COMPUT MODEL, V54, P919, DOI 10.1016/j.mcm.2010.11.016
   Irijanti E., 2011, NAT POSTGR C IEEE
   Li Y., 2000, Actaautomat. Sin., V26, P43
   Liang X., 2019, 2019 34 YOUTH AC ANN
   Park JH, 2006, IEEE T IMAGE PROCESS, V15, P1751, DOI 10.1109/TIP.2006.877070
   Sch?ps T., 2016, COMPUT VIS IMAGE UND, P151
   Shenyue W., 2017, COMPUT MEAS CONTROL, V25, P137
   Vlaminck M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111923
   Wu PF, 2017, IEEE T MULTIMEDIA, V19, P266, DOI 10.1109/TMM.2016.2612761
   Yang F., 2019, HIGH VOLTAGE ENG, V45, P377
   Yang L, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2784958
   Zhang CS, 2018, INT WORKS EARTH OB, P62
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 19
TC 4
Z9 5
U1 13
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26265
EP 26281
DI 10.1007/s11042-022-12866-4
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900011
DA 2024-07-18
ER

PT J
AU Eltayeb, A
   Shanableh, T
AF Eltayeb, Afaf
   Shanableh, Tamer
TI Data embedding in scrambled video by rotating motion vectors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data embedding; Machine learning; Video coding
ID H.264/AVC
AB Data embedding in videos has several important applications including Digital Rights Management, preserving confidentiality of content, authentication and tampering detection. This paper proposes a novel data embedding solution in scrambled videos by rotating motion vectors of predicted macroblocks. The rotation of motion vectors and the propagation of motion compensation error serve another purpose, which is video scrambling. A compliant decoder uses machine learning to counter-rotate the motion vectors and extract embedded message bits. To achieve this, the decoder uses a sequence-dependent approach to train a classifier to distinguish between macroblocks reconstructed using rotated and un-rotated motion vectors. In the testing phase, motion vectors belonging to a classified macroblock are compared against the reviewed rotated motion vectors and the message bits are extracted. Furthermore, to guarantee accurate classification at the decoder, a constrained encoding approach is proposed in which data embedding is restricted to motion vectors that can be correctly counter-rotated at the decoder. The proposed solution is referred to as Classifying Rotated Vectors or CRVs for short. Experimental results revealed that scrambled videos can be reconstructed correctly without quality loss with a bitrate increase at the encoder of around 6% and an average data embedding rate of 1.68 bits per MB.
C1 [Eltayeb, Afaf; Shanableh, Tamer] Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
C3 American University of Sharjah
RP Shanableh, T (corresponding author), Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
EM g00082016@aus.edu; tshanableh@aus.edu
RI Shanableh, Tamer/AAC-7893-2021
OI Shanableh, Tamer/0000-0002-7651-3094
FU American University of Sharjah [FRG19-S-E102]
FX The work in this paper was supported by a faculty research Grant from
   the American University of Sharjah (FRG19-S-E102). This paper represents
   the opinions of the authors and does not mean to represent the position
   or opinions of the American University of Sharjah
CR Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   HASSAN M, 2018, MULTIMED TOOLS APPL
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Livingston Frederick., 2005, ECE591Q Machine Learning Journal Paper
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ma ZF, 2018, FUTURE GENER COMP SY, V89, P746, DOI 10.1016/j.future.2018.07.029
   Ong S, 2015, SIGNAL PROCESS, V109, P38, DOI 10.1016/j.sigpro.2014.10.028
   Patel R, 2021, MULTIMEDIA SYST, V27, P417, DOI 10.1007/s00530-020-00735-9
   Peixoto E, 2014, IEEE T CIRC SYST VID, V24, P99, DOI 10.1109/TCSVT.2013.2273651
   SHANABLEH T, 2017, MULTIMEDIA APPL
   Shanableh T, 2012, SIGNAL PROCESS-IMAGE, V27, P1025, DOI 10.1016/j.image.2012.06.003
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   Su PC, 2017, MULTIMED TOOLS APPL, V76, P7473, DOI 10.1007/s11042-016-3406-2
   Toh KA, 2004, IEEE T PATTERN ANAL, V26, P740, DOI 10.1109/TPAMI.2004.3
   Wang YS, 2015, SIGNAL PROCESS-IMAGE, V35, P71, DOI 10.1016/j.image.2015.04.013
   Xu, 2020, IEEE ACCESS EFFICIEN
   Xu DW, 2017, J VIS COMMUN IMAGE R, V45, P34, DOI 10.1016/j.jvcir.2017.02.008
   Xu DW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033028
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Yu XB, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2933328
NR 23
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25473
EP 25496
DI 10.1007/s11042-022-12945-6
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882200006
DA 2024-07-18
ER

PT J
AU Chen, S
   Liang, LM
   Ouyang, JQ
AF Chen, Shu
   Liang, Luming
   Ouyang, Jianquan
TI Accurate structure from motion using consistent cluster merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structure-from-Motion; 3D reconstruction; Cluster merging
AB The incremental Structure-from-Motion approach is widely used for scene reconstruction as it is robust to outliers. However, the method suffers from two major limitations: error accumulation and heavy time consumption. To alleviate these problems, we propose a redundant cluster merge approach which is effective and efficient. Different from the previous clustering methods, each cluster has only one overlapping adjacent cluster. each of the sub clusters divided by our approach has several adjacent cluster candidates with overlapping. In addition, these cluster candidates are verified whether they are suitable for merging. By selecting the correct estimated clusters, cluster merging achieves more accurate results. The cluster verification is implemented based on the fact that the correctly estimated clusters have consistent point cloud and extrinsic camera parameters in each image of the same scene will be formulated as two constraints. In addition, we introduce a feature matching consistency constraint to eliminate the falsely matched feature pairs. The gain in accuracy of feature matching leads to better estimated results in each cluster. Experiments were performed on three public datasets. The reconstruction results show that our method outperformed state-of-the-art SfM approaches in terms of both efficiency and accuracy.
C1 [Chen, Shu; Ouyang, Jianquan] Xiangtan Univ, Sch Comp Sci, Xiangtan 411105, Peoples R China.
   [Chen, Shu; Ouyang, Jianquan] Xiangtan Univ, Sch Cyberspace Secur, Xiangtan 411105, Peoples R China.
   [Chen, Shu; Ouyang, Jianquan] Minist Educ, Key Lab Intelligent Comp & Informat Proc, Xiangtan 411105, Peoples R China.
   [Liang, Luming] Microsoft, Appl Sci Grp, Buffalo, WA 98052 USA.
C3 Xiangtan University; Xiangtan University; Microsoft
RP Liang, LM (corresponding author), Microsoft, Appl Sci Grp, Buffalo, WA 98052 USA.
EM llmpass@gmail.com
RI Liang, Luming/E-3371-2016; ouyang, jianquan/HTN-9999-2023
OI Liang, Luming/0000-0002-1127-2568; ouyang, jianquan/0000-0002-7518-5156
FU Natural Science Foundation of Hunan Province [2017JJ2252]
FX This research is supported in part by the Natural Science Foundation of
   Hunan Province (No. 2017JJ2252).
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   [Anonymous], 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539801
   Bhowmick B, 2017, COMPUT VIS IMAGE UND, V157, P190, DOI 10.1016/j.cviu.2017.02.006
   Bian J, 2007, PROC IEEE C COMPUTER, P2828
   Chatterjee A, 2018, IEEE T PATTERN ANAL, V40, P958, DOI 10.1109/TPAMI.2017.2693984
   Crandall D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3001, DOI 10.1109/CVPR.2011.5995626
   Cui HN, 2017, INT CONF 3D VISION, P205, DOI 10.1109/3DV.2017.00032
   Cui HN, 2017, IEEE IMAGE PROC, P4517, DOI 10.1109/ICIP.2017.8297137
   Cui HN, 2017, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2017.257
   Dai YC, 2013, IEEE T PATTERN ANAL, V35, P2238, DOI 10.1109/TPAMI.2013.20
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Gherardi R, 2010, PROC CVPR IEEE, P1594, DOI 10.1109/CVPR.2010.5539782
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0
   Jiang NJ, 2012, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2012.6247834
   Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824
   Lin WY, 2016, LECT NOTES COMPUT SC, V9905, P562, DOI 10.1007/978-3-319-46448-0_34
   Lipman Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602142
   Lowe DG, 1999, P INT C COMP VIS, P1150
   Magerand L, 2017, IEEE I CONF COMP VIS, P39, DOI 10.1109/ICCV.2017.14
   Martinec D, 2007, PROC CVPR IEEE, P1107
   Moulon P, 2013, IEEE I CONF COMP VIS, P3248, DOI 10.1109/ICCV.2013.403
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Pedersini F, 2000, SIGNAL PROCESS, V80, P1, DOI 10.1016/S0165-1684(99)00108-5
   Roberts R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3137, DOI 10.1109/CVPR.2011.5995549
   ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Shen TW, 2016, LECT NOTES COMPUT SC, V9907, P139, DOI 10.1007/978-3-319-46487-9_9
   Snavely N, 2008, PROC CVPR IEEE, P2617
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Strecha C, 2008, PROC CVPR IEEE, P2838
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Toldo R, 2015, COMPUT VIS IMAGE UND, V140, P127, DOI 10.1016/j.cviu.2015.05.011
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Wilson K, 2013, IEEE I CONF COMP VIS, P513, DOI 10.1109/ICCV.2013.69
   Wu C, 2020, VISUALSFM VISUAL STR
   Wu C., 2007, Siftgpu: A gpu implementation of david lowe's scale invariant feature transform (sift)
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Zach C, 2020, SSBA 3 0
   Zhu QB, 2009, SIGNAL PROCESS, V89, P2152, DOI 10.1016/j.sigpro.2009.04.030
   Zhu SY, 2018, PROC CVPR IEEE, P4568, DOI 10.1109/CVPR.2018.00480
NR 45
TC 1
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24913
EP 24935
DI 10.1007/s11042-022-12202-w
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771882300014
DA 2024-07-18
ER

PT J
AU Mi, JX
   Huang, Q
   Zhou, LF
AF Mi, Jian-Xun
   Huang, Qiang
   Zhou, Li-Fang
TI Local spatial continuity steered sparse representation for occluded face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Face recognition; Robustness; Contiguous
   occlusion; Support map
ID MATRIX REGRESSION; CLASSIFICATION; OCCLUSION
AB Recently, sparse representation in face recognition has been widely studied in computer vision. For face identification under complex conditions, many robust variants of sparse methods are proposed and achieved good results. However, the occlusion problem is still a challenging problem. Most of the state-of-the-art methods merely use pixel-wise error coding or structural error coding, which ignore the structural correlations between pixels. One can observe that occlusion has local spatial continuity. To make use of this local spatial continuity, this paper proposes a novel method, namely local spatial continuity steered sparse representation (LSCSR) for face recognition. The LSCSR uses a two-step strategy to calculate the occlusion support map. In the first step, we make use of information on residual to construct a matching mark image, and in the second step, we utilize the prior knowledge of the local spatial continuity and obtain the occlusion support map based on the matching mark image. Then, the weighted sparse coding framework is used to execute the face representation and classification. Extensive experiments on several public face databases demonstrate the effectiveness and robustness of the LSCSR in the face recognition against occlusion and other variations. Especially in AR dataset, we achieve the 4.00% performance gain in accuracy(96.50% vs. 92.50%) in Scarf occlusion.
C1 [Mi, Jian-Xun; Huang, Qiang] Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.
   [Zhou, Li-Fang] Chongqing Univ Posts & Telecommun, Coll Software, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications
RP Mi, JX (corresponding author), Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.
EM mijianxun@gmail.com
RI Zhou, Lifang/AAA-6979-2021; Mi, Jianxun/U-3642-2019; Mi,
   Jianxun/J-9670-2014
OI Mi, Jianxun/0000-0002-7531-4341
FU Scientific and Technological Research Program of Chongqing Municipal
   Education Commission [KJQN202100638]; National Natural Science
   Foundation of China [61906024]
FX Funding This work was sponsored by Scientific and Technological Research
   Program of Chongqing Municipal Education Commission(Grant No.
   KJQN202100638), and partially by National Natural Science Foundation of
   China (Grant No.61906024).
CR Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A., 2010, COMPUTE ANIM VIRTUAL, V15, P352
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   BRUSH SG, 1967, REV MOD PHYS, V39, P883, DOI 10.1103/RevModPhys.39.883
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   FAN Z, 2015, NEUROCOMPUTING
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang S, 2015, SIGNAL PROCESS, V116, P38, DOI 10.1016/j.sigpro.2015.04.018
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Laaksonen J, 1997, LECT NOTES COMPUTER, V1327, P638, DOI [10.1007/bfb0020226, DOI 10.1007/BFB0020226]
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   Li SZ, 1998, PROC CVPR IEEE, P839, DOI 10.1109/CVPR.1998.698702
   Li XX, 2013, IEEE T IMAGE PROCESS, V22, P1889, DOI 10.1109/TIP.2013.2237920
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065
   Mi JX, 2019, NEUROCOMPUTING, V348, P107, DOI 10.1016/j.neucom.2018.05.123
   Mi JX, 2018, LECT NOTES COMPUT SC, V11004, P357, DOI 10.1007/978-3-319-97785-0_34
   Mi JX, 2016, COGN COMPUT, V8, P818, DOI 10.1007/s12559-016-9420-x
   Mi JX, 2013, OPTIK, V124, P6786, DOI 10.1016/j.ijleo.2013.05.099
   Mi JX, 2013, NEUROCOMPUTING, V113, P241, DOI 10.1016/j.neucom.2013.01.003
   Mi JX, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0059430
   Mi JX, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042461
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Peng CL, 2017, IEEE T PATTERN ANAL, V39, P301, DOI 10.1109/TPAMI.2016.2542816
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Wright J, 2010, IEEE T INFORM THEORY, V56, P3540, DOI 10.1109/TIT.2010.2048473
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892
   Xie JC, 2017, IEEE T IMAGE PROCESS, V26, P2286, DOI 10.1109/TIP.2017.2662213
   Xu Y, 2013, INFORM SCIENCES, V238, P138, DOI 10.1016/j.ins.2013.02.051
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zeng SN, 2020, MULTIMED TOOLS APPL, V79, P20617, DOI 10.1007/s11042-020-08918-2
   Zhan TM, 2019, IEEE ACCESS, V7, P11868, DOI 10.1109/ACCESS.2019.2891938
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zheng JW, 2019, IEEE T NEUR NET LEAR, V30, P3788, DOI 10.1109/TNNLS.2019.2899073
   Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383
NR 47
TC 1
Z9 1
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25147
EP 25170
DI 10.1007/s11042-022-12427-9
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300019
DA 2024-07-18
ER

PT J
AU Guzsvinecz, T
AF Guzsvinecz, Tibor
TI The correlation between positive reviews, playtime, design and game
   mechanics in souls-like role-playing video games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dark souls; Data analysis; Game design; Game mechanics; Souls-like;
   Video game feedback
AB The "Souls-like" role-playing video game genre was inadvertently created due to the influence of the "Souls franchise". However, each game has different twists which can be new gameplay mechanics, graphical style, etc. while maintaining the core elements of the "Souls franchise". The goal of this study is to understand which gameplay mechanics are more liked by comparing reviews of these games to each other. Thus, different game design elements and game mechanics are investigated in 21 "Souls-like" video games to see how the users reacted to them and whether they positively reviewed them. All (993,932) reviews were scraped from the Steam webpage regarding these games in the middle of April 2021 using the steam_reviews Python package. These reviews contain the playtime at review, whether a positive or negative rating is given, and a textual component among others. Overall, 11 various game design elements and game mechanics were set up for the investigation: the setting, graphical dimensions as well as style, level design, and whether there are difficulty settings, multiplayer features, upgradeable weapons/armor, equipment durability, in-game map, extra penalties upon death, and a classic level-up system. Based on data distributions, either the t-test or the Mann-Whitney-Wilcoxon test was used for the analysis. The syuzhet package, which uses Natural Language Processing methods, was used in the statistical program package R along with the NRC Emotion Lexicon to evaluate the textual parts. According to the results, a slight-to-moderate correlation exists between positive reviews and the users' playtimes: more playtimes mean a larger chance of having positive reviews. Significant differences also exist in the percentages of positive reviews among these games: Hollow Knight is the most liked game. Out of the investigated 11 factors, significant differences exist among all of them: drawn graphics (96.48%) and 2D style (95.61%) are the two most liked factors, while pixel graphics (87.11%) and a futuristic setting (86.74%) are the two least liked ones. Almost every factor can significantly affect all eight basic emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust). The exceptions are graphical dimensions, weapon/armor upgradability, in-game map, and extra penalties upon character death as no significant differences exist in case of trust (p = 0.85), anger (p = 0.24), sadness (p = 0.21) and disgust (p = 0.095), respectively when the average sentiments per review were examined. Future "Souls-like" game design and development can be influenced by the results as game developers can more easily choose from the factors they want to implement or whether they want them at all in their games.
C1 [Guzsvinecz, Tibor] Univ Pannonia, Dept Informat Technol & Its Applicat, Zalaegerszeg, Hungary.
RP Guzsvinecz, T (corresponding author), Univ Pannonia, Dept Informat Technol & Its Applicat, Zalaegerszeg, Hungary.
EM guzsvinecz.tibor@zek.uni-pannon.hu
RI Guzsvinecz, Tibor/AAK-5708-2021
OI Guzsvinecz, Tibor/0000-0003-3273-313X
FU University of Pannonia
FX Open access funding provided by University of Pannonia.
CR Adams E., 2012, Game Mechanics: Advanced Game Design
   Anderson CG, 2018, THINK SKILLS CREAT, V30, P135, DOI 10.1016/j.tsc.2018.03.002
   Ascher, 2014, NARRATION THINGS
   Bevilacqua F, 2018, ENTERTAIN COMPUT, V24, P10, DOI 10.1016/j.entcom.2017.10.004
   Bostan B, 2009, GAME-ON 2009: 10TH INTERNATIONAL CONFERENCE ON INTELLIGENT GAMES AND SIMULATION, P5
   Bravo-Marquez F, 2019, J MACH LEARN RES, V20
   Busurkina I, 2020, DIGITAL TRANSFORMATI, V1242, DOI 10.1007/978-3-030-65218-0_9
   Byl, 2019, HOLISTIC GAME DEV UN, DOI 10.1201/9781351053693
   Castellon, 2014, DARK SOULS DARKER HE
   Csikszentmihalyi M., 2014, The concept of flow. Flow and the foundations of positive psychology: The collected works of Mihaly Csikszentmihalyi, P239, DOI [DOI 10.1007/978-94-017-9088-8, 10.1007/978-94-017-9088-8_16, DOI 10.1007/978-94-017-9088-8_16]
   Daneels R, 2021, MEDIA COMMUN-LISBON, V9, P49, DOI 10.17645/mac.v9i1.3205
   Eberhard L, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P43, DOI 10.1109/SNAMS.2018.8554542
   Elverdam C., 2007, Games and Culture, V2, P3, DOI DOI 10.1177/1555412006286892
   Fabricatore C., 2007, ENLACES MINEDUC CHIL
   FIELLER EC, 1957, BIOMETRIKA, V44, P470, DOI 10.2307/2332878
   Ford D., 2020, ACM International Conference Proceeding Series, P1, DOI DOI 10.1145/3402942.3402966
   Fusdahl, 2019, THESIS NTNU
   Gandolfi E, 2018, INFORM VISUAL, V17, P218, DOI 10.1177/1473871617717075
   Godsey, 2020, REIGNITING FLAME PUR
   Hjaltason K., 2015, GAME MECH TELLING ST
   Horsfall M, 2011, 2011 16 INT C COMP G, DOI 10.1109/CGAMES.2011.6000361
   Jenkins GainesS., 2020, WHAT IS GAME ESSAYS, P131
   Jockers M., 2017, Package "syuzhet
   Kang H.-N., 2017, International Journal of Innovation, Management and Technology, V8, P90, DOI DOI 10.18178/IJIMT.2017.8.2.709
   Kao D, 2020, ENTERTAIN COMPUT, V34, DOI 10.1016/j.entcom.2020.100359
   Kim AmyJo., 2018, Game Thinking: Innovate smarter drive deep engagement with design techniques from hit games
   Kiritchenko S., 2014, P 8 INT WORKSH SEM E, P437, DOI DOI 10.3115/V1/S14-2076
   Kunzelman C, 2020, R ADV GAME STUD, P167
   Lin DY, 2018, EMPIR SOFTW ENG, V23, P771, DOI 10.1007/s10664-017-9531-3
   Madigan J, 2020, PALG STUD CYBERPSYCH, P65, DOI 10.1007/978-3-030-32770-5_5
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Martyn, 2017, DARK SOULS FLOW
   Melnic D., 2018, UNIV BUCH REV, V7, P29
   Mohammad S., 2010, P NAACL HLT 2010 WOR, DOI DOI 10.5555/1860631.1860635
   Neto A, 2021, SPRINGER SER DES INN, V12, P148, DOI 10.1007/978-3-030-61671-7_14
   OWEN DB, 1965, J AM STAT ASSOC, V60, P320, DOI 10.2307/2283156
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Roe, 2019, DIGRA C
   Rogers S., 2014, LEVEL UP GUIDE GREAT
   Salmon JP, 2017, ENTERTAIN COMPUT, V21, P45, DOI 10.1016/j.entcom.2017.04.006
   Skalski P, 2010, PSYCHNOLOGY J, V8, P67
   Smethurst T, 2016, THESIS GHENT U
   SMIRNOV N, 1948, ANN MATH STAT, V19, P279, DOI 10.1214/aoms/1177730256
   Theodorou, 2020, DEATH CULTURE LEISUR, DOI 10.1108/978-1-83909-037-020201013
   Werder K, 2018, 2018 IEEE/ACM 3RD INTERNATIONAL WORKSHOP ON EMOTION AWARENESS IN SOFTWARE ENGINEERING (SEMOTION), P20, DOI 10.1145/3194932.3194941
NR 45
TC 4
Z9 4
U1 10
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4641
EP 4670
DI 10.1007/s11042-022-12308-1
EA MAR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000770754000024
OA hybrid
DA 2024-07-18
ER

PT J
AU Sánchez-Caballero, A
   de López-Diz, S
   Fuentes-Jimenez, D
   Losada-Gutiérrez, C
   Marrón-Romera, M
   Casillas-Pérez, D
   Sarker, MI
AF Sanchez-Caballero, Adrian
   de Lopez-Diz, Sergio
   Fuentes-Jimenez, David
   Losada-Gutierrez, Cristina
   Marron-Romera, Marta
   Casillas-Perez, David
   Sarker, Mohammad Ibrahim
TI 3DFCNN: real-time action recognition using 3D deep neural networks with
   raw depth information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-CNN; Action Recognition; Depth Maps; Real-time; Video-surveillance
ID RGB-D
AB This work describes an end-to-end approach for real-time human action recognition from raw depth image-sequences. The proposal is based on a 3D fully convolutional neural network, named 3DFCNN, which automatically encodes spatio-temporal patterns from raw depth sequences. The described 3D-CNN allows actions classification from the spatial and temporal encoded information of depth sequences. The use of depth data ensures that action recognition is carried out protecting people's privacy, since their identities can not be recognized from these data. The proposed 3DFCNN has been optimized to reach a good performance in terms of accuracy while working in real-time. Then, it has been evaluated and compared with other state-of-the-art systems in three widely used public datasets with different characteristics, demonstrating that 3DFCNN outperforms all the non-DNN-based state-of-the-art methods with a maximum accuracy of 83.6% and obtains results that are comparable to the DNN-based approaches, while maintaining a much lower computational cost of 1.09 seconds, what significantly increases its applicability in real-world environments.
C1 [Sanchez-Caballero, Adrian; de Lopez-Diz, Sergio; Fuentes-Jimenez, David; Losada-Gutierrez, Cristina; Marron-Romera, Marta; Sarker, Mohammad Ibrahim] Univ Alcala, Dept Elect, Km 33600, Alcala De Henares 28805, Spain.
   [Casillas-Perez, David] Univ Rey Juan Carlos, Dept Signal Proc & Commun, Madrid, Spain.
C3 Universidad de Alcala; Universidad Rey Juan Carlos
RP Losada-Gutiérrez, C (corresponding author), Univ Alcala, Dept Elect, Km 33600, Alcala De Henares 28805, Spain.
EM adrian.sanchez@uah.es; s.lopezd@edu.uah.es; d.fuentes@edu.uah.es;
   cristina.losada@uah.es; marta.marron@uah.es; david.casillas@urjc.es;
   ibrahim.sarker@uah.es
RI Losada-Gutiérrez, Cristina/E-9306-2016; Marta,
   Marrón-Romera/T-5343-2017; Marta, Marrón Romera/AAD-9385-2021
OI Losada-Gutiérrez, Cristina/0000-0001-9545-327X; Marta,
   Marrón-Romera/0000-0001-7723-2262; Marta, Marrón
   Romera/0000-0001-7723-2262; de Lopez Diz, Sergio/0000-0002-2463-4396;
   Fuentes Jimenez, David/0000-0001-6424-4782; Casillas-Perez,
   David/0000-0002-5721-1242; Sanchez Caballero, Adrian/0000-0002-3395-7568
FU Spanish Ministry of Science and Innovation [PID2020-113118RB-C31/C33];
   Community of Madrid [CM/JIN/2021-015]; University of Alcal
   [PIUAH21/IA-016]
FX This work has been partially supported by the Spanish Ministry of
   Science and Innovation under projects EYEFUL (PID2020-113118RB-C31/C33),
   by the Community of Madrid under project CONCORDIA (CM/JIN/2021-015) and
   by the University of Alcal under project ARGOS+ (PIUAH21/IA-016)
CR Al-Akam R, 2018, COMPUT SCI RES NOTES, V2803, P18, DOI 10.24132/CSRN.2018.2803.3
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2016, 2016 INT C IND POS I, DOI DOI 10.1109/IPIN.2016.7743617
   [Anonymous], 2015, Deep convolutional neural networks for action recognition using depth map sequences
   Ashraf N, 2014, COMPUT VIS IMAGE UND, V123, P41, DOI 10.1016/j.cviu.2014.03.005
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6
   Chou KP, 2018, IEEE ACCESS, V6, P15283, DOI 10.1109/ACCESS.2018.2809552
   Das S, 2019, NEW HYBRID ARCHITECT
   Dawar N, 2017, PROC IEEE INT SYMP, P1342, DOI 10.1109/ISIE.2017.8001440
   Dipakkr, 2018, 3D CNN ACT REC
   Farooq Adnan, 2015, IEIE Trans. Smart Process. Comput., V4, P281, DOI DOI 10.5573/IEIESPC.2015.4.4.281
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   GEBERT P, 2019, IEEE INT VEH SYM, P969, DOI DOI 10.1109/ivs.2019.8814249
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou YH, 2018, IEEE ACCESS, V6, P2206, DOI 10.1109/ACCESS.2017.2782258
   Hsu YP, 2016, PATTERN RECOGN, V60, P215, DOI 10.1016/j.patcog.2016.05.010
   Hu JF, 2018, LECT NOTES COMPUT SC, V11211, P346, DOI 10.1007/978-3-030-01234-2_21
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Khurana R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P542, DOI 10.1109/ICSCCC.2018.8703295
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kingma D. P., 2014, arXiv
   Ko KE, 2018, ENG APPL ARTIF INTEL, V67, P226, DOI 10.1016/j.engappai.2017.10.001
   Kong J, 2019, J VIS COMMUN IMAGE R, V59, P537, DOI 10.1016/j.jvcir.2019.02.013
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448
   Laraba S, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1782
   Li J, 2022, IEEE T ENG MANAGE, V69, P1902, DOI 10.1109/TEM.2019.2940702
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li X, 2020, MULTIMED TOOLS APPL, V79, P35761, DOI 10.1007/s11042-020-09593-z
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu BL, 2019, PATTERN RECOGN, V94, P1, DOI 10.1016/j.patcog.2019.05.020
   Liu CC, 2017, DES AUT CON, DOI [10.1145/3061639.3062310, 10.1109/ICCSN.2017.8230067]
   Liu J, 2018, IEEE ACCESS, V6, P70061, DOI 10.1109/ACCESS.2018.2880231
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu K, 2018, AAAI CONF ARTIF INTE, P7138
   Liu ZM, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P583, DOI 10.1145/3343031.3350916
   Luo ZL, 2017, PROC CVPR IEEE, P7101, DOI 10.1109/CVPR.2017.751
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Martinez M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185202
   Ning X, 2020, IEEE ACCESS, V8, P65340, DOI 10.1109/ACCESS.2020.2985086
   Ning X, 2020, IEEE ACCESS, V8, P8834, DOI 10.1109/ACCESS.2020.2964838
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sarfraz M. S., 2021, ARXIV210311264
   Schindler K, 2008, PROC CVPR IEEE, P3025
   Sell J, 2014, IEEE MICRO, V34, P44, DOI 10.1109/MM.2014.9
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shahroudy A., 2016, NTU RGB D ACTION REC
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Tej, 2019, Advances in Signal Processing and Communication. Select Proceedings of ICSC 2018. Lecture Notes in Electrical Engineering (LNEE 526), P247, DOI 10.1007/978-981-13-2553-3_24
   Siyal Mohsin Raza, 2020, 2020 International Conference on Computational Intelligence (ICCI), P311, DOI 10.1109/ICCI51257.2020.9247670
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Wan J, 2016, IEEE T PATTERN ANAL, V38, P1626, DOI 10.1109/TPAMI.2015.2513479
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wang LC, 2019, IEEE I CONF COMP VIS, P6221, DOI 10.1109/ICCV.2019.00631
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2017, IEEE INT CONF COMP V, P1005, DOI 10.1109/ICCVW.2017.123
   Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52
   Wang PC, 2016, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2016.7899599
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Weng JW, 2017, PROC CVPR IEEE, P445, DOI 10.1109/CVPR.2017.55
   Wu HB, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881418825093
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351
   Xu Y, 2019, MULTIMED TOOLS APPL, V78, P25063, DOI 10.1007/s11042-019-7593-5
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang KL, 2021, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR46437.2021.00143
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang JG, 2017, IEEE T CYBERNETICS, V47, P960, DOI 10.1109/TCYB.2016.2535122
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao YX, 2012, ADV DIFFER EQU-NY, P1, DOI 10.1186/1687-1847-2012-15
NR 99
TC 22
Z9 22
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24119
EP 24143
DI 10.1007/s11042-022-12091-z
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000013
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, J
   Zhao, J
   Huang, HH
   Xu, GX
AF Liu, Jun
   Zhao, Juan
   Huang, Haihui
   Xu, Guangxia
TI A novel logistics data privacy protection method based on blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Attribute encryption; Privacy protection; Access control
ID ATTRIBUTE-BASED ENCRYPTION; TECHNOLOGY
AB This paper is dedicated to investigating the application of blockchain in e-commerce logistics. In the traditional logistics system, the protection mechanism of complete logistics information is not perfect and the privacy of users is leaked. Although access control can ensure the confidentiality of data to some extent, the traditional centralized access control is difficult to adapt to the access control needs of the e-commerce logistics environment. On this basis, a novel access control scheme for logistics data is proposed. It combines the membership in Hyperledger and ciphertext-policy attribute-based encryption and ensures the security of the user's private key with the membership in Hyperledger instead of the traditional key distribution center. Finally, an experimental test and verification results on Hyperledger Fabric show the feasibility of the scheme.
C1 [Liu, Jun; Zhao, Juan; Huang, Haihui; Xu, Guangxia] Chongqing Univ Posts & Telecommun, Sch Software Engn, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Liu, J (corresponding author), Chongqing Univ Posts & Telecommun, Sch Software Engn, Chongqing 400065, Peoples R China.
EM junliu@cqupt.edu.cn
RI Luo, Jun/JPX-3855-2023; Huang, Hai-Hui/J-7342-2015; Jun,
   LIU/HIK-1509-2022
OI Jun, LIU/0000-0001-8122-1443; Liu, Jun/0000-0001-7390-8958
FU National Natural Science Foundation [61772099, 61772098]; Chongqing
   Research Program of Basic Research and Frontier Technology
   [cstc2021jcyj-msxmX0530]; Science and Technology Innovation Leadership
   Support Program of Chongqing [CSTCCXLJRC201917]; University Outstanding
   Achievements Transformation Funding Project of Chongqing [KJZH17116];
   Innovation and Entrepreneurship Demonstration Team Cultivation Plan of
   Chongqing [CSTC2017KJRC-CXCYTD0063]; Technology Innovation and
   Application Development Project of Chongqing [CSTC2019JSCX-FXYDX0086,
   CSTC2019JSCX-FXYDX0089, CSTC2018JSCX-MSZD0132]
FX This work is supported by the National Natural Science Foundation (Grant
   No. 61772099, Grant No. 61772098); the Chongqing Research Program of
   Basic Research and Frontier Technology (Grant No.
   cstc2021jcyj-msxmX0530); the Science and Technology Innovation
   Leadership Support Program of Chongqing (Grant No. CSTCCXLJRC201917);
   the University Outstanding Achievements Transformation Funding Project
   of Chongqing (Grant No. KJZH17116); the Innovation and Entrepreneurship
   Demonstration Team Cultivation Plan of Chongqing (Grant No.
   CSTC2017KJRC-CXCYTD0063); the Technology Innovation and Application
   Development Project of Chongqing (CSTC2019JSCX-FXYDX0086,
   CSTC2019JSCX-FXYDX0089, CSTC2018JSCX-MSZD0132).
CR Anderson J.C., 2010, COUCHDB DEFINITIVE G
   Aobing, BIG DATA RES, V2
   Ausanka-Crues R., METHODS ACCESS CONTR
   Azaria A, 2016, PROCEEDINGS 2016 2ND INTERNATIONAL CONFERENCE ON OPEN AND BIG DATA - OBD 2016, P25, DOI 10.1109/OBD.2016.11
   Barreto L, 2017, PROCEDIA MANUF, V13, P1245, DOI 10.1016/j.promfg.2017.09.045
   Berghel H, 2000, COMMUN ACM, V43, P17, DOI 10.1145/328236.328114
   Cao Y, 2020, IEEE T IND INFORM, V16, P6004, DOI 10.1109/TII.2019.2942211
   Chen S., 2021, P 7 IEEE INT C BIG D, P32
   Cui RM, 2020, MANAGE SCI, V66, P3879, DOI 10.1287/mnsc.2019.3411
   Domingo Galindo L., 2016, The challenges of logistics 4.0 for the supply chain management and the information technology (Master's thesis
   Du MX, 2020, IEEE T ENG MANAGE, V67, P1045, DOI 10.1109/TEM.2020.2971858
   Gan CQ, 2021, MULTIMED TOOLS APPL, V80, P30605, DOI 10.1007/s11042-020-09322-6
   Gao S, 2020, IEEE T VEH TECHNOL, V69, P5784, DOI 10.1109/TVT.2020.2967099
   Jamil F., 2019, ELECTRONICS-SWITZ, V8
   Li M, 2019, IEEE INT CON AUTO SC, P751, DOI [10.1109/coase.2019.8843250, 10.1109/COASE.2019.8843250]
   Liang XP, 2017, IEEE ACM INT SYMP, P468, DOI 10.1109/CCGRID.2017.8
   Liang YQ, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100963
   Liu J, 2021, INFORM SCIENCES, V575, P528, DOI 10.1016/j.ins.2021.06.046
   Liu SH, 2020, IEEE INTERNET THINGS, V7, P7851, DOI 10.1109/JIOT.2020.2993231
   Müssigmann B, 2020, IEEE T ENG MANAGE, V67, P988, DOI 10.1109/TEM.2020.2980733
   Ouaddah A, 2016, SECUR COMMUN NETW, V9, P5943, DOI 10.1002/sec.1748
   Ouaddah A, 2017, ADV INTELL SYST COMP, V520, P523, DOI 10.1007/978-3-319-46568-5_53
   Pal S, 2020, IEEE INTERNET THINGS, V7, P2630, DOI 10.1109/JIOT.2019.2952141
   Rozman N, 2019, PROC CIRP, V81, P826, DOI 10.1016/j.procir.2019.03.207
   Schmidtke N, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON LOGISTICS OPERATIONS MANAGEMENT (GOL)
   Strandhagen JO, 2017, ADV MANUF, V5, P359, DOI 10.1007/s40436-017-0198-1
   Wu YQ, 2020, INT J COOP INF SYST, V29, DOI 10.1142/S0218843020400067
   Xu, PEER TO PEER NETW AP
   Xu GX, 2020, IEEE T IND INFORM, V16, P4252, DOI 10.1109/TII.2019.2955719
   Xu J, 2019, IEEE INTERNET THINGS, V6, P8770, DOI 10.1109/JIOT.2019.2923525
   Yaga D.J., 2018, NIST Pubs, V8202, P1, DOI [10.6028/NIST.IR.8202, DOI 10.6028/NIST.IR.8202]
   Yang YT, 2021, ENGINEERING-PRC, V7, P787, DOI 10.1016/j.eng.2021.03.011
   [祝烈煌 Zhu Liehuang], 2017, [计算机研究与发展, Journal of Computer Research and Development], V54, P2170
NR 33
TC 8
Z9 9
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23867
EP 23887
DI 10.1007/s11042-022-12836-w
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800013
DA 2024-07-18
ER

PT J
AU Khosravi, MH
   Hassanpour, H
AF Khosravi, Mohammad Hossein
   Hassanpour, Hamid
TI A new paradigm for image quality assessment based on human abstract
   layers of quality perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Full reference image quality assessment; Human abstract perception
   layers; Image region smoothness; Image content detectability
ID STRUCTURAL SIMILARITY; INFORMATION; CONTRAST
AB Image Quality Assessment (IQA) plays a central role in many visual processing algorithms and systems. Most of the existing IQA methods try to detect the image distortions' type and then evaluate its severity. But each image distortion type has its own characteristics, which can harden up the process of quality evaluation. Here, we propose a novel framework for image quality assessment, in which the image is evaluated based on the human judgment process, comprises the three abstract perception layers, namely, illumination sensation, whole content detectability, and details perception. What distinguishes the proposed framework from the existing ones is its independence from the image distortion type. Indeed, we try to assess the amount of success in visual perception, instead of measuring the amount of image distortions. The proposed method has been extensively tested on four benchmark datasets and shows highly competitive performance to state-of-the-art IQA methods.
C1 [Khosravi, Mohammad Hossein] Univ Birjand, Fac Elect & Comp Engn, Birjand, Iran.
   [Hassanpour, Hamid] Shahrood Univ Technol, Fac Comp Engn & Informat Technol, Shahrood, Iran.
C3 University of Birjand; Shahrood University of Technology
RP Khosravi, MH (corresponding author), Univ Birjand, Fac Elect & Comp Engn, Birjand, Iran.
EM mohokhosravi@birjand.ac.ir; h.hassanpour@shahroodut.ac.ir
RI Khosravi, Mohammad Hossein/AAQ-9988-2021; Hassanpour,
   Hamid/AAL-7271-2020
OI Khosravi, Mohammad Hossein/0000-0003-3595-1829; Hassanpour,
   Hamid/0000-0002-5513-9822
CR [Anonymous], 2008, VLFEAT OPEN PORTABLE
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], 1927, STUDIES OPTICS
   [Anonymous], 2017, INT J ENG T B APPL, DOI DOI 10.5829/IDOSI.IJE.2017.30.02B.00
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Cheng Guangquan, 2010, [Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications), Pattern Recognition and Image Analysis. (Advances in Mathematical Theory and Applications)], V20, P286
   Fischler MA., 2014, Readings in computer vision: issues, problem, principles, and paradigms
   Frazor RA, 2006, VISION RES, V46, P1585, DOI 10.1016/j.visres.2005.06.038
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Kamble V, 2015, OPTIK, V126, P1090, DOI 10.1016/j.ijleo.2015.02.093
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Khosravi MH, 2020, IEEE T CIRC SYST VID, V30, P48, DOI 10.1109/TCSVT.2018.2890457
   Khosravi MH, 2019, J VIS COMMUN IMAGE R, V60, P217, DOI 10.1016/j.jvcir.2018.11.019
   Khosravi MH, 2018, MULTIMED TOOLS APPL, V77, P7357, DOI 10.1007/s11042-017-4636-7
   Khosravi MH, 2017, MULTIMED TOOLS APPL, V76, P2733, DOI 10.1007/s11042-015-3149-5
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Manap RA, 2015, INFORM SCIENCES, V301, P141, DOI 10.1016/j.ins.2014.12.055
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang TH, 2016, SIGNAL PROCESS-IMAGE, V45, P1, DOI 10.1016/j.image.2016.04.005
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE SIGNAL PROC MAG, V28, P137, DOI 10.1109/MSP.2011.942295
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang JF, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0134-5
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
NR 43
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23193
EP 23215
DI 10.1007/s11042-022-12478-y
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770205800001
DA 2024-07-18
ER

PT J
AU Rafiq, S
   Selwal, A
AF Rafiq, Shehla
   Selwal, Arvind
TI Block-XOR based cancellable template protection scheme for
   multi-instance iris biometric system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris; Cancellable biometric; Feature level fusion; Template security;
   Irreversibility; Revocability
ID CRYPTO
AB An iris recognition framework within the secured authentication infrastructure is an outstanding, reliable and broadly accepted biometric. It has been broadly perceived as one of the grounded biometrics credited to its high precision execution. But, the templates in traditional iris recognition systems are extremely susceptible to various attacks. Although a number of cancellable biometric methods had been proposed there is usually a trade-off with numerous overall performance and security parameters like FAR, FRR, EER, revocability, diversity and security. In this paper, a novel cancellable technique has been introduced, named as "Block-XOR Based Iris Fusion (BXBIF) template protection scheme". The purpose of this non-invertible technique is to distort the biometric information so that an attacker may not be able to decrypt it. The experiments are performed on IITD database version 1.0 with an EER equal to 0.45 and GAR equal to 96.7%. The BXBIF technique shows a decent performance accuracy and also satisfies the requirements of cancellable biometrics namely revocability and irreversibility.
C1 [Rafiq, Shehla; Selwal, Arvind] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, J&K, India.
C3 Central University of Jammu
RP Rafiq, S (corresponding author), Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, J&K, India.
EM shehlarafiq5@gmail.com; arvind.cuj@gmail.com
RI rafiq, shehla/ITT-3962-2023; Selwal, Arvind/HTR-1625-2023
OI rafiq, shehla/0000-0002-8310-3405; Selwal, Arvind/0000-0002-1075-6966
CR Abe N, 2015, INT CONF BIOMETR THE
   Ali H, 2014, ELECTRON LETT, V50, P1098, DOI 10.1049/el.2014.1207
   Mariño RA, 2012, INFORM SCIENCES, V195, P91, DOI 10.1016/j.ins.2012.01.042
   Anuja JS., 2018, SURVEY IRIS TEMPLATE, V119, P1471
   Chaudhary Sheetal, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359306
   Choudhury B, 2018, INT J IMAGE GRAPH, V18, DOI 10.1142/S0219467818500067
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2006, P IEEE, V94, P1927, DOI 10.1109/JPROC.2006.884092
   Diaz DiazE., 2016, Church, Communication and Culture, V1, P206, DOI DOI 10.1080/23753234.2016.1240912
   Dwivedi R, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P785, DOI 10.1109/SPIN.2015.7095296
   Fathee HN, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/6575019
   Gomez-Barrero M, 2016, INFORM SCIENCES, V370, P18, DOI 10.1016/j.ins.2016.06.046
   Gomez-Barrero M, 2014, INT C PATT RECOG, P4483, DOI 10.1109/ICPR.2014.767
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jenisch S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3213, DOI 10.1109/ICIP.2011.6116352
   Khalaf E. T., 2016, P 2016 INT C COMM IN, P53, DOI [10.1145/3023924.3023938., DOI 10.1145/3023924.3023938]
   Kumar MM, 2018, P 2018 2 INT C BIOM, P43, DOI DOI 10.1145/3230820.3230828
   Lai YL, 2017, PATTERN RECOGN, V64, P105, DOI 10.1016/j.patcog.2016.10.035
   Manzoor SI, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P306, DOI 10.1109/PDGC.2018.8745722
   Manzoor SI, 2018, INT J COMPUT SCI ENG, V6
   Misztal K., 2012, BIOMETRICS KANSEI EN, P43, DOI [10.1007/978-1-4614-5608-7_3, DOI 10.1007/978-1-4614-5608-7_3]
   Ouda O., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P882, DOI 10.1109/ICPR.2010.222
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Prasad MVNK, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS (SITIS), P210, DOI 10.1109/SITIS.2017.44
   Rafiq S., 2019, LECT NOTES ELECT ENG, V2019, P771
   Rathgeb C, 2014, COMPUT SECUR, V42, P1, DOI 10.1016/j.cose.2013.12.005
   Rathgeb C, 2014, IET BIOMETRICS, V3, P207, DOI 10.1049/iet-bmt.2013.0049
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rathgeb C, 2010, LECT NOTES COMPUT SC, V6112, P266, DOI 10.1007/978-3-642-13775-4_27
   Selwal A, 2015, 2015 2 INT C REC ADV, P1, DOI 10.1109/RAECS.2015.7453302
   Selwal A, 2016, PROCEDIA COMPUT SCI, V85, P899, DOI 10.1016/j.procs.2016.05.280
   Umer S, 2017, INFORM SCIENCES, V406, P102, DOI 10.1016/j.ins.2017.04.026
   Yu, 2012, 2012 INT C COMP SCI
   Zhao DD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/4519548
   Zuo JY, 2008, INT C PATT RECOG, P2925
NR 36
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23217
EP 23235
DI 10.1007/s11042-022-12655-z
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770205800002
DA 2024-07-18
ER

PT J
AU Ahmed, K
   Gad, MA
   Aboutabl, AE
AF Ahmed, Kareem
   Gad, Mai A.
   Aboutabl, Amal Elsayed
TI Performance evaluation of salient object detection techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Saliency; Image Segmentation; Salient Object Detection (SOD);
   Machine learning; deep Learning; Medical Image; Remote Sensing image
ID SEGMENTATION; NETWORK; MODEL
AB Recently, the detection and segmentation of salient objects that attract the attention of human visual in images is determined by using salient object detection (SOD) techniques. As an essential computer vision problem, SOD has increasingly attracted the researchers' interest over the years. While a lot of SOD models and applications have been proposed, there is still a lack of deep understanding of the issues and achievements. A comprehensive study on the recent techniques of SOD is provided in this paper. Precisely, this paper presents a review of SOD techniques from various perspectives. Various image segmentation techniques are presented such as segmentation based on machine learning or deep learning, the second perspective concentrates on classifying them into supervised and unsupervised learning techniques and the last one based on manual approach, semi-automatic approach, and fully automatic approach and so on. Then, the paper presents a summarization of datasets used for SOD. Finally, analyses of SOD models and comparison results are presented.
C1 [Ahmed, Kareem; Gad, Mai A.] Beni Suef Univ, Fac Comp & Artificial Intelligence, Comp Sci Dept, Bani Suwayf, Egypt.
   [Aboutabl, Amal Elsayed] Helwan Univ, Fac Comp & Artificial Intelligence, Comp Sci Dept, Helwan, Egypt.
C3 Egyptian Knowledge Bank (EKB); Beni Suef University; Egyptian Knowledge
   Bank (EKB); Helwan University
RP Ahmed, K (corresponding author), Beni Suef Univ, Fac Comp & Artificial Intelligence, Comp Sci Dept, Bani Suwayf, Egypt.
EM kareem_ahmed@hotmail.co.uk; maialaa@fcis.bsu.edu.eg;
   amal.aboutab1@fci.helwan.edu.eg
RI ahmed, kareem/AFE-8267-2022; Aboutabl, Amal Elsayed/AGH-3806-2022
OI ahmed, kareem/0000-0002-1252-8625; Aboutabl, Amal/0000-0002-7189-9274
FU Science, Technology AMP; Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abbas Z, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P317, DOI [10.1109/aicai.2019.8701374, 10.1109/AICAI.2019.8701374]
   Abdusalomov A, 2020, APPL SCI
   Adhitya Y, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10111642
   Aganj I., 2018, SCI REP-UK
   Ahmed Abrar, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P203, DOI 10.1109/ICAEM.2019.8853834
   Ahmed KT, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P162, DOI 10.1109/iccisci.2019.8716437
   Al-khayyat A. T. A., 2020, 2020 4 INT S MULT ST
   Alalharith DM, 2020, ENV RES PUBLIC HLTH, P1
   Alzahrani AJ, 2019, SALIENT OBJECT DETEC
   [Anonymous], 2020, 2020 6 INT C ADV COM
   [Anonymous], 2020, 2020 5 INT C COMM EL
   Aruraj A., 2019, 2019 2 INT C SIGN PR
   Bayraktar E, 2017, TURK J ELECTR ENG CO, V25, P2444, DOI 10.3906/elk-1602-225
   Benjelloun F., 2019, 2019 INT C INT SYST
   Bi Y, 2020, IEEE COMPUT INTELL M, V15, P65, DOI 10.1109/MCI.2020.2976186
   Bingzhen Z, COMPUTER SCI ED IEEE
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cao CQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174696
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Castillo TJM, 2020, CANCERS, V12, DOI 10.3390/cancers12061606
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Chaganti SY, 2020, 2020 INT C COMP SCI, P1
   Chang Y.-T., 2019, 12 INT C UBI MED COM
   Chen HJ, 2019, SOFT COMPUT, V23, P11409, DOI [10.1007/978-3-030-34139-8_1, 10.1007/s00500-019-04088-y]
   Chen K, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102715
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Cheng H.-T., 2018, COMPUTER VISION PATT
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Dai ZZ, 2020, ADV RADIAT ONCOL, V5, P473, DOI 10.1016/j.adro.2020.01.005
   Das D, 2020, 2020 INT C COMM SIGN
   Demirovic D, 2019, IMAGE PROCESS ON LIN, V9, P251, DOI 10.5201/ipol.2019.255
   Difar KA, 2020, INT C ELECT COMPUT, DOI 10.1109/ecai50035.2020.9223180
   Dong C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131529
   Ehsani R, 2020, CANCER INFORM, V19, DOI 10.1177/1176935120965542
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2020, PROC CVPR IEEE, P2916, DOI 10.1109/CVPR42600.2020.00299
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Farooq J, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONIC AND ELECTRICAL ENGINEERING (ICE CUBE), P318, DOI 10.1109/ICECUBE.2016.7495245
   Fatemi N., 2019, 2019 4 INT C PATT RE
   Fatemi N., 2018, 8 INT C COMP KNOWL E
   Ferariu L., 2020, 2020 INT S ELMAR 202
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ghaffari S, 2019, IEEE PAC RIM CONF CO, DOI 10.1109/pacrim47961.2019.8985056
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Goswami A, 2020, 9 IEEE INT C COMM SY
   Gupta P., 2019, 2019 5 INT C COMP CO
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hidalgo F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154343
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang Y., 2020, IEEE CVF C COMP VIS
   Huangyue Chen Y.L., 2020, Mathematical Problems in Engineering, P1
   Ingole, 2019, INT J SCI DEV RES IJ, P261
   Jackins V, 2021, J SUPERCOMPUT, V77, P5198, DOI 10.1007/s11227-020-03481-x
   Jain I, 2020, INT J ADV SCI TECHNO, P8013
   Jaus A., PANORAMIC PANOPTIC S, P2021
   Jensen PM, 2020, P IEEE CVF C COMP VI, P976
   Jiang BT, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P606, DOI [10.1109/itnec.2019.8729392, 10.1109/ITNEC.2019.8729392]
   Jiang H., 2013, 2013 IEEE C COMP VIS
   Jiang Y, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/4152816
   Jin WD, 2021, IEEE T IMAGE PROCESS, V30, P3376, DOI 10.1109/TIP.2021.3060167
   Jing Li, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166928
   Jubair A. S., 2019, 2019 INT RUSS AUT C
   Ke-Chen S., 2013, ACTA AUTOMATICA SINI
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang HL, 2018, IEEE T INTELL TRANSP, V19, P814, DOI 10.1109/TITS.2017.2702665
   Kumar C., 2020, 2020 3 INT C SMART S
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030578
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li J, 2018, IEEE T IMAGE PROCESS, V27, P349, DOI 10.1109/TIP.2017.2762594
   Li J, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.86
   Li X., 2019, COMPUTER VISION PATT
   Li XX, 2018, LECT NOTES COMPUT SC, V11207, P93, DOI 10.1007/978-3-030-01219-9_6
   Li Y., 2020, 2020 IEEE 4 INF TECH
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Li ZJ, 2020, COLOR RES APPL, V45, P656, DOI 10.1002/col.22491
   Liu GH, 2020, SIGNAL IMAGE VIDEO P, V14, P1171, DOI 10.1007/s11760-020-01647-x
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu JE, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/7607612
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T., 2007, 2007 IEEE C COMP VIS, P1
   Liu YZ, 2020, IEEE T ENG MANAGE, V67, P483, DOI 10.1109/TEM.2018.2887118
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mandal V, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12219177
   Mansourian L, 2016, KSII T INTERNET INF, V10, P769, DOI 10.3837/tiis.2016.02.018
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Mishra Z, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66355-5
   Mohammed Mohammed G., 2020, International Journal of Machine Learning and Computing, V10, P654, DOI 10.18178/ijmlc.2020.10.5.987
   MOURAD A, 2020, 2020 21 INT ARAB C I
   Murthy AV, 2019, ANNU IEEE IND CONF, DOI 10.1109/indicon47234.2019.9030311
   Nuari R., 2019, 2019 4 INT C INF TEC
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Pancha P., 2019, 2019 4 INT C COMP SY
   Papandrianos N, 2020, DIAGNOSTICS, P1
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Prihandoko P., 2020, 2020 5 INT C INF COM
   Qi J, 2020, IEEE SIGNAL PROC LET, V27, P1485, DOI 10.1109/LSP.2020.3016837
   Qian Y., 2018, 2018 IEEE CIC INT C
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qing Tian, 2013, Journal of Software, V8, P2223, DOI 10.4304/jsw.8.9.2223-2230
   Rachapudi V, 2021, EVOL INTELL, V14, P1337, DOI 10.1007/s12065-020-00367-y
   Ramola A, 2020, ENG REP, V2, DOI 10.1002/eng2.12149
   Rani F. P., 2019, 2019 INT C REC ADV E
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romera E, 2019, IEEE INT VEH SYM, P1312, DOI [10.1109/IVS.2019.8813888, 10.1109/ivs.2019.8813888]
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sakinis Tomas, 2019, ARXIV PREPRINT ARXIV
   Sasirekha D., 2012, IJCSIS INT J COMPUTE
   Sha G., 2020, 2020 IEEE INT C ART
   Shang J, 2016, IET IMAGE PROCESS, V10, P662, DOI 10.1049/iet-ipr.2016.0058
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shen Y., 2020, INTERPRETABLE CLASSI
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Shivajirao S., 2019, 2019 18 IEEE INT C M
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh J, 2020, PROCEDIA COMPUT SCI, V167, P1970, DOI 10.1016/j.procs.2020.03.226
   Singh NK, 2020, IET IMAGE PROCESS, V14, P487, DOI 10.1049/iet-ipr.2019.0255
   Sohn K., 2020, COMPUTER VISION PATT
   Sommer L, 2018, IEEE IMAGE PROC, P3054, DOI 10.1109/ICIP.2018.8451189
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Srivastava G, 2019, J VIS COMMUN IMAGE R, V62, P330, DOI 10.1016/j.jvcir.2019.06.005
   Tan T., 2018, PAC RIM INT C ART IN
   Tiwari D, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P461, DOI [10.1109/iciccs48265.2020.9121067, 10.1109/ICICCS48265.2020.9121067]
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tourani A., 2019, 2019 4 INT C PATT RE
   Tsai CC, 2020, IEEE INT CONF MULTI, DOI 10.1109/icmew46912.2020.9106010
   Tulshan AS, 2019, INT CONF COMPUT
   Ucar F., 2020, INTELLIGENT SYSTEMS, P147
   Üreten K, 2020, CLIN RHEUMATOL, V39, P969, DOI 10.1007/s10067-019-04487-4
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinay A, 2015, PROCEDIA COMPUT SCI, V70, P174, DOI 10.1016/j.procs.2015.10.068
   Vincente TFY, 2016, LECT NOTES COMPUT SC, V9910, P816, DOI 10.1007/978-3-319-46466-4_49
   Voronin V., 2019, ANOMALY DETECTION IM
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang Q, 2013, IEEE T CIRC SYST VID, V23, P1150, DOI 10.1109/TCSVT.2012.2226528
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang Q, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107340
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184
   Waqas M., 2020, APSIPA ANN SUMM C
   Wei K., 2020, P 2020 IEEE INT C EL, P171
   Wigati EK., 2020, ADV SCI TECHNOLOGY E, V5, P584, DOI [10.25046/aj050273, DOI 10.25046/AJ050273]
   Wong T-T, 2020, IEEE T KNOWL DATA EN, P1
   Wu JW, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107766
   Wu Y, 2020, IEEE ACCESS, V8, P39389, DOI 10.1109/ACCESS.2020.2968339
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xia X., 2019, 2019 12 INT C INT CO
   Xiao W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111263
   Xiao Y, 2020, MULTIMED TOOLS APPL
   Xiao Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195490
   Yadhav S. Y., 2020, 2020 INT C ELECT SUS
   Yan PX, 2019, IEEE I CONF COMP VIS, P7283, DOI 10.1109/ICCV.2019.00738
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang KL, 2022, IEEE T INTELL TRANSP, V23, P1184, DOI 10.1109/TITS.2020.3023331
   Yang KL, 2021, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR46437.2021.00143
   Yang Z., 2019, 2019 CHIN CONTR C CC
   Yu Kong, 2020, Medical Imaging and Computer-Aided Diagnosis. Proceeding of 2020 International Conference on Medical Imaging and Computer-Aided Diagnosis (MICAD 2020). Lecture Notes in Electrical Engineering (LNEE 633), P107, DOI 10.1007/978-981-15-5199-4_11
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang J, 2022, IEEE T PATTERN ANAL, V44, P5761, DOI 10.1109/TPAMI.2021.3073564
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang Q, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107484
   Zhang YZ, 2020, IEEE ACCESS, V8, P90652, DOI 10.1109/ACCESS.2020.2994147
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao K, 2019, IOP CONF SER-MAT SCI, V533, DOI 10.1088/1757-899X/533/1/012056
   Zhou LQ, 2019, WORLD J GASTROENTERO, V25, P672, DOI 10.3748/wjg.v25.i6.672
   Zhu J, 2010, ASIA S PACIF DES AUT, P220
NR 189
TC 3
Z9 3
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21741
EP 21777
DI 10.1007/s11042-022-12567-y
EA MAR 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Singh, C
   Majeed, S
AF Singh, Chandan
   Majeed, Shahbaz
TI Novel and robust color texture descriptors for color face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Color texture descriptor; Local binary pattern; Local
   binary pattern for color images
ID KERNEL SPARSE REPRESENTATION; LOCAL BINARY PATTERNS; 2-DIMENSIONAL PCA;
   CLASSIFICATION; TRANSFORM; FEATURES; SPACES
AB We propose novel and robust color texture descriptors which are based on the relative dominance of the discriminative power of the color components in a multi-channel representation of a color model. LBP-like operators are derived by fitting linear regression models in 2D color subspaces RG, and GB of a 3D RGB color space keeping in view of the relative dominance of G component over the R, and B components. The linear regression models yield three operators LBPLRG, LBPLGB, and LBPLCGB, which are jointly referred to as local binary patterns using lines (LBPL). The features of the three operators are combined to form feature vectors. To further boost the performance, the LBPL features are combined with the existing local binary pattern of color images (LBPC). Experimental results demonstrate the superiority of the proposed operators, LBPL and LBPL + LBPC over the state-of-the-art LBP-, SRC- and under certain conditions over CNN-based approaches across various classifiers and they are found to be robust to many variations in the face images.
C1 [Singh, Chandan; Majeed, Shahbaz] Punjabi Univ, Dept Comp Sci, Patiala 147002, Punjab, India.
C3 Punjabi University
RP Singh, C (corresponding author), Punjabi Univ, Dept Comp Sci, Patiala 147002, Punjab, India.
EM chandan.csp@gmail.com; Shahbaz.nengroo858@gmail.com
CR Aghdam OA, 2019, IEEE COMPUT SOC CONF, P2363, DOI 10.1109/CVPRW.2019.00290
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P ICPR
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212
   Chen ZH, 2015, INFORM SCIENCES, V292, P15, DOI 10.1016/j.ins.2014.08.066
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Choi JY, 2009, IEEE T SYST MAN CY B, V39, P1217, DOI 10.1109/TSMCB.2009.2014245
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Fan ZZ, 2020, MULTIMED TOOLS APPL, V79, P7319, DOI 10.1007/s11042-019-08211-x
   Fan ZZ, 2018, PATTERN RECOGN, V76, P1, DOI 10.1016/j.patcog.2017.10.001
   Gao SH, 2014, IEEE T MULTIMEDIA, V16, P762, DOI 10.1109/TMM.2014.2299516
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Guo YM, 2008, INT C PATT RECOG, P3161
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang KK, 2017, IEEE T NEUR NET LEAR, V28, P1082, DOI 10.1109/TNNLS.2016.2522431
   Nguyen TT, 2015, IEEE T INF FOREN SEC, V10, P1739, DOI 10.1109/TIFS.2015.2426144
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Khan SA, 2015, J INTELL FUZZY SYST, V28, P1819, DOI 10.3233/IFS-141468
   Lee SH, 2012, IEEE T IMAGE PROCESS, V21, P2347, DOI 10.1109/TIP.2011.2181526
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li J, 2016, NEUROCOMPUTING, V182, P111, DOI 10.1016/j.neucom.2015.12.005
   Liao W.-H., 2010, 2010 20th International Conference on Pattern Recognition, P1003
   Liu CJ, 2008, IEEE T INF FOREN SEC, V3, P213, DOI 10.1109/TIFS.2008.923824
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu Z, 2018, PATTERN RECOGN, V83, P456, DOI 10.1016/j.patcog.2018.06.015
   Lu ZJ, 2018, IEEE ACCESS, V6, DOI [10.1109/ACCESS.2018.2864189, 10.1109/LSP.2018.2810121]
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   Mäenpää T, 2002, INT C PATT RECOG, P668, DOI 10.1109/ICPR.2002.1044840
   Munir A, 2018, OPTIK, V158, P1016, DOI 10.1016/j.ijleo.2018.01.003
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011
   Ramesha K, 2011, COMM COM INF SC, V147, P13
   Ranade SK, 2021, MULTIMED TOOLS APPL, V80, P10797, DOI 10.1007/s11042-020-10244-6
   Sao AK, 2010, SIGNAL IMAGE VIDEO P, V4, P353, DOI 10.1007/s11760-009-0125-4
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P21481, DOI 10.1007/s11042-017-5440-0
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Sotoodeh M, 2019, EXPERT SYST APPL, V127, P342, DOI 10.1016/j.eswa.2019.03.020
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Topi M, 2000, INT C PATT RECOG, P939, DOI 10.1109/ICPR.2000.903699
   Torres L., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P627, DOI 10.1109/ICIP.1999.817191
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Vishwanathan S., 2010, Proc. of Neural Information Processing Systems, P2361
   Wang HY, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P4522
   Wang ZF, 2014, VISUAL COMPUT, V30, P359, DOI 10.1007/s00371-013-0861-x
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu F, 2016, PATTERN RECOGN, V60, P630, DOI 10.1016/j.patcog.2016.06.010
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang JA, 2010, NEUROCOMPUTING, V73, P2140, DOI 10.1016/j.neucom.2010.02.005
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Yip Andrew., 2001, Role of color in face recognition
   Yong Xu, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.234
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang DS, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P928
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
NR 75
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21313
EP 21347
DI 10.1007/s11042-022-12625-5
EA MAR 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700008
DA 2024-07-18
ER

PT J
AU Hamza, S
   Ben Ayed, Y
AF Hamza, Sihem
   Ben Ayed, Yassine
TI Toward improving person identification using the ElectroCardioGram (ECG)
   signal based on non-fiducial features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Identification system; ECG signal; Cepstral coefficients; ZCR; Entropy;
   SVM
AB In the last years, the ElectroCardioGram (ECG) signal identification system presents an important technology due to the expanding domain of applications. The ECG signal of each person is composed of P-wave, T-wave, and QRS-complex. In fact, any state of the person (e.g. the stress, the physical activity) the shape of the heartbeat is not easy to change but can increase the heart rate. The paper presents an efficient person identification system based on ECG signal. Our identification system is realized in different steps such as preprocessing, detection of R peaks, segmentation, features extraction, and classification. After the processing step and the detection of R peaks step, we realized the segmentation step. In this work, we used two cases of the segmentation, namely, fragments with single R peak and fragments with two R peaks. Then, in the step of the features extraction, we interested in the non-fiducial features. We proposed to use an integration of non-fiducial parameters like cepstral coefficients, Zero Crossing Rate (ZCR), and entropy. In addition, the Support Vector Machines (SVM) is use for the classification system. The integration of the different characteristics are evaluated using two benchmarks databases namely Massachusetts Institute of Technology-Boston's Beth Israel Hospital (MIT-BIH) Arrhythmia and ECG-ID database obtained from the Physionet database. The Experimental results present that our characteristics can receive high person, an accuracy equal to 100%, 100%, 100%, and 99.01% that are from the MIT-BIH database (47 subjects), ECG-ID (12 subjects) (Five-recording), ECG-ID (90 subjects) (Two-recording), and ECG-ID (90 subjects) (All-recording), respectively.
C1 [Hamza, Sihem; Ben Ayed, Yassine] MIRACL Univ Sfax, Multimedia InfoRmat Syst & Adv Comp Lab, Sfax, Tunisia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax
RP Hamza, S (corresponding author), MIRACL Univ Sfax, Multimedia InfoRmat Syst & Adv Comp Lab, Sfax, Tunisia.
EM sihemhz401@gmail.com; yassine.benayed@gmail.com
OI hamza, sihem/0000-0001-9146-1379
CR Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Bouhabba EM., 2011, 2011 4th International Conference on Mechatronics (ICOM), P1
   Chantaf S, 2010, INT J BIOMETRICS, V2, P236, DOI 10.1504/IJBM.2010.033388
   Chauhan N, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P130, DOI [10.1109/ccoms.2019.8821751, 10.1109/CCOMS.2019.8821751]
   David, 2019, INTRO SECURITY, P433
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Hamza Sihem, 2020, Procedia Computer Science, V176, P430, DOI 10.1016/j.procs.2020.08.044
   Hanilu║i A., 2019, J INNOV SCI ENG, V3, P22
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Hong WC, 2011, ENERGIES, V4, P960, DOI 10.3390/en4060960
   Houalef, 2012, SYSTEME RECONNAISSAN, P1
   Ibrahim AE., 2020, INT J ADV COMPUT RES, V10, P89, DOI [10.19101/IJACR.2019.940129, DOI 10.19101/IJACR.2019.940129]
   Isik S, 2019, TURK J ELECTR ENG CO, V27, P3682, DOI 10.3906/elk-1901-168
   Islam MS, 2012, IEEE T INF TECHNOL B, V16, P445, DOI 10.1109/TITB.2012.2188535
   Kim J.S., 2017, J. Internet Serv. Inf. Secur, V7, P19
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Lee SC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072068
   Liu M, 2018, IEEE ENG MED BIO, P2707, DOI 10.1109/EMBC.2018.8512761
   Lugovaya, 2005, HUMAN IDENTIFICATION
   Nikolova D., 2018, ANNA'18; Advances in Neural Networks and Applications 2018, P1
   Nikolova D, 2019, L N INST COMP SCI SO, V283, P25, DOI 10.1007/978-3-030-23976-3_3
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Pan T, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093003
   Patro KK, 2020, J SUPERCOMPUT, V76, P858, DOI 10.1007/s11227-019-03022-1
   Pietro L, 2012, SPEECH RECOGNITION U
   Pinto JR, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102228
   Rinaldi A, 2016, EMBO REP, V17, P22, DOI 10.15252/embr.201541677
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sihem, 2020, INTELL SYST APPL, V72, P416
   Taelman J, 2009, IFMBE PROC, V22, P1366
   Tan R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020410
   Vafaie MH, 2014, BIOMED SIGNAL PROCES, V14, P291, DOI 10.1016/j.bspc.2014.08.010
   Wang D, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060667
   Wang D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9010201
   Wang HX, 2020, J COMP PHYSIOL A, V206, P289, DOI [10.1007/s00359-019-01396-4, 10.19818/j.cnki.1671-1637.2020.02.001]
   Zhang QX, 2017, IEEE ACCESS, V5, P11805, DOI 10.1109/ACCESS.2017.2707460
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
NR 38
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18543
EP 18561
DI 10.1007/s11042-022-12244-0
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300016
DA 2024-07-18
ER

PT J
AU Yu, LC
   He, SH
   Liu, XS
   Ma, M
   Xiang, SY
AF Yu, Licun
   He, Shuanhai
   Liu, Xiaosong
   Ma, Ming
   Xiang, Shuiying
TI Engineering-oriented bridge multiple-damage detection with damage
   integrity using modified faster region-based convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bridge inspection; Deep learning; Faster region-based convolutional
   neural network (faster R-CNN); Multiple-damage detection
ID CRACK DETECTION; DEFECT DETECTION; MACHINE VISION; DEEP; INSPECTION
AB A bridge damage detector with preserving integrity based on modified Faster region-based convolutional neural network (R-CNN) is proposed for multiple damage types. The methodologies of dataset collection, damage annotation, and anchors generation are modified. The performance for bridge multiple-damage detectors with ResNet50 or ResNet101 as feature extraction network are compared. The results show that, with the modified Faster R-CNN, the mean average precision reaches 84.56% (76.43%) at the intersection-over-union metrics of 0.5 (0.75). We further demonstrate that the localization offset for Faster R-CNN is lower than that of YOLOv3. The modified bridge damage detector enables better detecting performance, and can preserve the damage integrity.
C1 [Yu, Licun; He, Shuanhai] Changan Univ, Sch Highway, Xian 710064, Peoples R China.
   [Yu, Licun; Ma, Ming] CCCC First Highway Consultants Co Ltd, Xian 710075, Peoples R China.
   [Liu, Xiaosong; Xiang, Shuiying] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
C3 Chang'an University; Xidian University
RP Yu, LC (corresponding author), Changan Univ, Sch Highway, Xian 710064, Peoples R China.; Yu, LC (corresponding author), CCCC First Highway Consultants Co Ltd, Xian 710075, Peoples R China.
EM yulicun1026@163.com
FU National Key Research and Development Program of China [2021YFB2801900,
   2021YFB2801901, 2021YFB2801902, 2021YFB2801904]; National Natural
   Science Foundation of China [61674119, 61974177]; Key Science and
   Technology Project in Transportation Industry of China [2020-MS1-060]
FX This work was supported by the National Key Research and Development
   Program of China (2021YFB2801900, 2021YFB2801901, 2021YFB2801902,
   2021YFB2801904); by the National Natural Science Foundation of China
   (61674119, 61974177); by the Key Science and Technology Project in
   Transportation Industry of China (2020-MS1-060).
CR Adeli H, 2001, COMPUT-AIDED CIV INF, V16, P126, DOI 10.1111/0885-9507.00219
   Adhikari RS, 2014, AUTOMAT CONSTR, V39, P180, DOI 10.1016/j.autcon.2013.06.011
   Butcher JB, 2014, COMPUT-AIDED CIV INF, V29, P191, DOI 10.1111/mice.12039
   Cai WW, 2021, MULTIMED TOOLS APPL, V80, P11291, DOI 10.1007/s11042-020-10188-x
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   Dung CV, 2019, AUTOMAT CONSTR, V99, P52, DOI 10.1016/j.autcon.2018.11.028
   Cha YJ, 2018, COMPUT-AIDED CIV INF, V33, P731, DOI 10.1111/mice.12334
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Chen FC, 2018, IEEE T IND ELECTRON, V65, P4392, DOI 10.1109/TIE.2017.2764844
   Dawood T, 2017, AUTOMAT CONSTR, V81, P149, DOI 10.1016/j.autcon.2017.06.008
   Deng JH, 2020, COMPUT-AIDED CIV INF, V35, P373, DOI 10.1111/mice.12497
   Dorafshan S, 2018, DATA BRIEF, V21, P1664, DOI 10.1016/j.dib.2018.11.015
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan QF, 2016, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2016.7535375
   Gao YQ, 2018, COMPUT-AIDED CIV INF, V33, P748, DOI 10.1111/mice.12363
   German S, 2012, ADV ENG INFORM, V26, P846, DOI 10.1016/j.aei.2012.06.005
   Ghosh-Dastidar S, 2009, NEURAL NETWORKS, V22, P1419, DOI 10.1016/j.neunet.2009.04.003
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gou HY, 2019, INT J STRUCT STAB DY, V19, DOI 10.1142/S0219455419501116
   Huyan J, 2019, AUTOMAT CONSTR, V107, DOI 10.1016/j.autcon.2019.102946
   Isailovic D, 2020, AUTOMAT CONSTR, V112, DOI 10.1016/j.autcon.2020.103088
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kingma D. P., 2014, arXiv
   Koziarski M, 2017, INTEGR COMPUT-AID E, V24, P337, DOI 10.3233/ICA-170551
   Li G, 2014, AUTOMAT CONSTR, V41, P83, DOI 10.1016/j.autcon.2013.10.021
   Li H, 2015, SMART STRUCT SYST, V15, P555, DOI 10.12989/sss.2015.15.3.555
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Li RX, 2018, COMPUT-AIDED CIV INF, V33, P527, DOI 10.1111/mice.12351
   Li SY, 2019, COMPUT-AIDED CIV INF, V34, P616, DOI 10.1111/mice.12433
   Liang X, 2019, COMPUT-AIDED CIV INF, V34, P415, DOI 10.1111/mice.12425
   Liao KW, 2016, AUTOMAT CONSTR, V71, P294, DOI 10.1016/j.autcon.2016.08.008
   Lin YZ, 2017, COMPUT-AIDED CIV INF, V32, P1025, DOI 10.1111/mice.12313
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Hoang ND, 2018, AUTOMAT CONSTR, V94, P203, DOI 10.1016/j.autcon.2018.07.008
   Oksuz K, 2018, LOCALIZATION RECALL
   Provost F, 1998, MACH LEARN, V30, P127, DOI 10.1023/A:1007442505281
   Qin SQ, 2019, KSCE J CIV ENG, V23, P754, DOI 10.1007/s12205-018-0985-7
   Qin SQ, 2017, ENGINEERING-PRC, V3, P787, DOI 10.1016/j.eng.2017.11.001
   Rafiei MH, 2017, STRUCT DES TALL SPEC, V26, DOI 10.1002/tal.1400
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Tang MC, 2007, IABSE S REPORT, V93, P38
   Tang MC., 2016, STRUCT INFRASTRUCT E, V13, P1
   Huynh TC, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.102844
   Torres JF, 2018, INTEGR COMPUT-AID E, V25, P335, DOI 10.3233/ICA-180580
   Wang NN, 2019, AUTOMAT CONSTR, V103, P53, DOI 10.1016/j.autcon.2019.03.003
   Xiang HF, 2007, FRONT STRUCT CIV ENG, V1, P379, DOI 10.1007/s11709-007-0051-x
   Xiang SY, 2020, OPT LETT, V45, P1104, DOI 10.1364/OL.383942
   Xiang SY, 2019, IEEE J SEL TOP QUANT, V25, DOI 10.1109/JSTQE.2019.2911565
   Yang ZL, 2021, IEEE T INF FOREN SEC, V16, P880, DOI 10.1109/TIFS.2020.3023279
   Yeum CM, 2015, COMPUT-AIDED CIV INF, V30, P759, DOI 10.1111/mice.12141
   Zhang A, 2017, COMPUT-AIDED CIV INF, V32, P805, DOI 10.1111/mice.12297
   Zhang CB, 2020, COMPUT-AIDED CIV INF, V35, P389, DOI 10.1111/mice.12500
   Zhang JD, 2018, PROC INST CIV ENG-BR, V171, P237, DOI 10.1680/jbren.18.00007
   Zhang XX, 2019, COMPUT-AIDED CIV INF, V34, P951, DOI 10.1111/mice.12477
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zou Z., 2019, ARXIV COMPUTER VISIO
NR 61
TC 8
Z9 8
U1 3
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18279
EP 18304
DI 10.1007/s11042-022-12703-8
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766063900003
DA 2024-07-18
ER

PT J
AU Guo, JF
   Huang, LF
   Chien, WC
AF Guo, Jiefeng
   Huang, Lianfen
   Chien, Wei-Che
TI Multi-viewport based 3D convolutional neural network for 360-degree
   video quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Video quality assessment (VQA); 360-degree video;
   Convolutional neural network (CNN); Virtual reality (VR)
ID PREDICTION; ATTENTION; FEATURES; MOTION
AB 360-degree videos, also known as omnidirectional or panoramic videos, provide the user an immersive experience that 2D videos cannot provide. It is crucial to access the perceived quality of the 360-degree video. 2D video quality assessment (VQA) methods are unsuitable for 360-degree videos. There are few 360-degree video quality assessment (360VQA) methods. This paper proposes a multi-viewport based 3D convolutional neural network for 360VQA (3D-360VQA). First, it is easy to divide the 2D planar video into rectangular blocks as video patches in order to adapt to a deep neural network. The way to form the video patch in a 2D planar video is unsuitable for a 360-degree video. Thus, a multiple viewports based video patch forming method is proposed. Second, although the deep neural networks have achieved great success in image quality assessment (IQA), there are few deep neural networks for 360VQA. A 3D convolution based deep neural network is proposed to predict the perceived quality of 360-degree videos. The publicly available 360-degree videos datasets are used to evaluate the proposed method. The experimental results show that the proposed method is suitable for the 360-degree video and outperforms other existing methods, which verifies the effectiveness of our network architecture.
C1 [Guo, Jiefeng] Xiamen Univ, Sch Elect Sci & Engn, Xiamen 361005, Peoples R China.
   [Huang, Lianfen] Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
   [Chien, Wei-Che] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien 97401, Taiwan.
C3 Xiamen University; Xiamen University; National Dong Hwa University
RP Guo, JF (corresponding author), Xiamen Univ, Sch Elect Sci & Engn, Xiamen 361005, Peoples R China.
EM jfguo@xmu.edu.cn
FU Natural Science Foundation of Fujian Province of China [2019J01046]
FX This work was supported by the Natural Science Foundation of Fujian
   Province of China under Grant 2019J01046.
CR [Anonymous], 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Chen DQ, 2020, IEEE T IMAGE PROCESS, V29, P6496, DOI 10.1109/TIP.2020.2990342
   Chen SJ, 2018, IEEE INT CON MULTI
   Chen ZB, 2016, IEEE T CIRC SYST VID, V26, P1029, DOI 10.1109/TCSVT.2015.2441432
   DALY S, 1992, P SOC PHOTO-OPT INS, V1666, P2, DOI 10.1117/12.135952
   Dinh KQ, 2018, IEEE IMAGE PROC, P2496, DOI 10.1109/ICIP.2018.8451262
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gao F, 2018, PATTERN RECOGN, V81, P432, DOI 10.1016/j.patcog.2018.04.016
   Girod Bernd, 1993, P207
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Hu SD, 2017, IEEE T CIRC SYST VID, V27, P1844, DOI 10.1109/TCSVT.2016.2556499
   Jiang QP, 2019, IEEE T CIRC SYST VID, V29, P323, DOI 10.1109/TCSVT.2017.2783938
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   KELLY DH, 1979, J OPT SOC AM, V69, P1340, DOI 10.1364/JOSA.69.001340
   Kim H, 2017, IEEE T CIRC SYST VID, V27, P951, DOI 10.1109/TCSVT.2016.2515303
   Kim J, 2019, IEEE T NEUR NET LEAR, V30, P11, DOI 10.1109/TNNLS.2018.2829819
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Kim MC, 2016, J DISP TECHNOL, V12, P185, DOI 10.1109/JDT.2015.2478519
   Laparra V, 2010, J OPT SOC AM A, V27, P852, DOI 10.1364/JOSAA.27.000852
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee S, 2002, IEEE T MULTIMEDIA, V4, P129, DOI 10.1109/6046.985561
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li SN, 2012, IEEE T CIRC SYST VID, V22, P1100, DOI 10.1109/TCSVT.2012.2190473
   Li YM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P685, DOI 10.1109/ICDSP.2016.7868646
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Liu H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/263540
   Liu YT, 2017, J VIS COMMUN IMAGE R, V46, P70, DOI 10.1016/j.jvcir.2017.03.007
   Masry M, 2006, IEEE T CIRC SYST VID, V16, P260, DOI 10.1109/TCSVT.2005.861946
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Oh T, 2014, IEEE T IMAGE PROCESS, V23, P5428, DOI 10.1109/TIP.2014.2364925
   Po LM, 2019, IEEE T CIRC SYST VID, V29, P1223, DOI 10.1109/TCSVT.2019.2891159
   Roodaki H, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348823
   Saha A, 2015, IEEE T IMAGE PROCESS, V24, P1879, DOI 10.1109/TIP.2015.2411436
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Sinno Z, 2019, IEEE T IMAGE PROCESS, V28, P612, DOI 10.1109/TIP.2018.2869673
   Su YC, 2018, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2018.00816
   Sun Wei., 2019, Proceedings of the ACM on Human-Computer Interaction 3.CSCW, P1
   Sun Y, 2016, 4 JVET M CHENGD CN
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   Tang ZS, 2019, IEEE T BROADCAST, V65, P138, DOI 10.1109/TBC.2018.2871376
   Wang SZ, 2016, IEEE T MED IMAGING, V35, P1046, DOI 10.1109/TMI.2015.2506902
   Wang YF, 2019, NEUROCOMPUTING, V332, P298, DOI 10.1016/j.neucom.2018.12.029
   Wang Z, 2001, PROC SPIE, V4472, P42, DOI 10.1117/12.449797
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI [10.1109/TCSVT.2018.2886277, 10.1080/17445302.2018.1558727]
   Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351
   Yan QS, 2019, IEEE T IMAGE PROCESS, V28, P2200, DOI 10.1109/TIP.2018.2883741
   You JY, 2014, IEEE T IMAGE PROCESS, V23, P200, DOI 10.1109/TIP.2013.2287611
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zhang F, 2016, IEEE T CIRC SYST VID, V26, P1017, DOI 10.1109/TCSVT.2015.2428551
   Zhang F, 2013, IEEE T IMAGE PROCESS, V22, P1534, DOI 10.1109/TIP.2012.2233486
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang W, 2016, IEEE T NEUR NET LEAR, V27, P1266, DOI 10.1109/TNNLS.2015.2461603
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhou C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3209660
NR 62
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16813
EP 16831
DI 10.1007/s11042-022-12073-1
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100005
DA 2024-07-18
ER

PT J
AU Balasamy, K
   Krishnaraj, N
   Vijayalakshmi, K
AF Balasamy, K.
   Krishnaraj, N.
   Vijayalakshmi, K.
TI Improving the security of medical image through neuro-fuzzy based ROI
   selection for reliable transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet transform; Medical data; Authentication; Neuro-fuzzy ROI;
   Watermarking; Encryption
ID REVERSIBLE WATERMARKING SCHEME; HARMONIC FOURIER MOMENTS; LOSSLESS
   WATERMARKING; TAMPER DETECTION; ROBUST; AUTHENTICATION; INFORMATION;
   PROTECTION; ALGORITHM; INTEGRITY
AB Lately, medical service area has developed quickly with its own advantages and disadvantages. In this computerized time, giving exact determination in the carefully communicated clinical pictures is at more serious dangers. This paper presents the watermarking method for medical images that should resists for various kinds of attacks. Firstly, our method identifies the region of interest for extracting the high intensity energy levels in the medical image. Wavelet decomposition is done to the identified region in order to extract the sub-bands for embedding. Singular values obtained from SVD decomposition helps in identifies the matrix and singular values of the medical image. Finally, validation code is generated for authenticating the medical image from both sender and receiver side, in order to track any region of the image being tampered through intruders. Our proposed method shows better accuracy in testing the robustness of the image.
C1 [Balasamy, K.] Bannari Amman Inst Technol, Dept Artificial Intelligence & Data Sci, Sathyamangalam, India.
   [Krishnaraj, N.] Sri Krishna Coll Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Vijayalakshmi, K.] VSB Coll Engn Tech Campus, Dept ECE, Coimbatore, Tamil Nadu, India.
C3 Bannari Amman Institute of Technology
RP Balasamy, K (corresponding author), Bannari Amman Inst Technol, Dept Artificial Intelligence & Data Sci, Sathyamangalam, India.
EM balasamyk@gmail.com
RI Krishnasamy, Balasamy/ABE-1237-2021
OI Krishnasamy, Balasamy/0000-0003-0973-5698; natarajan,
   krishnaraj/0000-0003-0919-8335
CR Acharya R, 2004, COMPUT METH PROG BIO, V76, P13, DOI 10.1016/j.cmpb.2004.02.009
   Acharya R, 2003, COMPUT BIOL MED, V33, P303, DOI 10.1016/S0010-4825(02)00083-5
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Balasamy K, 2022, WIRELESS PERS COMMUN, V122, P2817, DOI 10.1007/s11277-021-09031-9
   Balasamy K, 2023, IETE J RES, V69, P83, DOI 10.1080/03772063.2021.1893231
   Balasamy K, 2019, CLUSTER COMPUT, V22, pS4431, DOI 10.1007/s10586-018-1991-8
   Balasamy K, 2021, SECURITY PRIVACY ASP, DOI 10.1002/9781119792253.ch9
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Das S, 2011, LECT NOTES COMPUT SC, V6744, P286
   Favorskaya M, 2019, PROCEDIA COMPUT SCI, V159, P1267, DOI 10.1016/j.procs.2019.09.296
   Feng ZJ, 2020, CHINA CDC WEEKLY, V2, P113, DOI [10.46234/ccdcw2020.032, 10.3760/cma.j.issn.0254-6450.2020.02.003]
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Gopalakrishnan T., 2011, 2011 WORLD C INF COM, P120
   Guo XT, 2009, J DIGIT IMAGING, V22, P620, DOI 10.1007/s10278-008-9120-5
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Keshavarzian R, 2016, AEU-INT J ELECTRON C, V70, P278, DOI 10.1016/j.aeue.2015.12.003
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Lavanya A, 2012, SADHANA-ACAD P ENG S, V37, P723, DOI 10.1007/s12046-012-0107-z
   Laws, 2011, TEXTURED IMAGE SEGME
   Lim, 2010, 2 DIMENSIONAL SIGNAL
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Liu YL, 2015, IEICE T INF SYST, VE98D, P769, DOI 10.1587/transinf.2014ICP0001
   Luo XW, 2003, P ANN INT IEEE EMBS, V25, P852, DOI 10.1109/IEMBS.2003.1279899
   Manikandan VM, 2021, ISA T, V108, P269, DOI 10.1016/j.isatra.2020.08.019
   Mothi R, 2019, MEASUREMENT, V136, P67, DOI 10.1016/j.measurement.2018.12.030
   Nambakhsh MS, 2011, COMPUT METH PROG BIO, V104, P418, DOI 10.1016/j.cmpb.2010.08.016
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Ramakrishnan S, 2011, CS IT, P155
   Ramakrishnan S., 2011, Signal & Image Processing, V2, P157, DOI [10.5121/sipij.2011.2313, DOI 10.5121/SIPIJ.2011.2313]
   Rayachoti E, 2020, CLUSTER COMPUT, V23, P3175, DOI 10.1007/s10586-020-03078-2
   SUGANYADEVI S, 2021, INT J MULTIMED INF R, P1
   Suganyadevi S, 2021, SMART HEALTHC SYST D, DOI 10.1002/9781119792253.ch8
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Woo C-S, 2005, P APRS WORKSH DIG CO
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Xia ZQ, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2020.106568
   Xia ZQ, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107864
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
   Zain JM, 2004, P ANN INT IEEE EMBS, V26, P3237
   Zhang XP, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P826, DOI 10.1109/ChinaSIP.2015.7230520
NR 53
TC 9
Z9 9
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14321
EP 14337
DI 10.1007/s11042-022-12367-4
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300014
DA 2024-07-18
ER

PT J
AU Lee, JY
   Van Le, T
   Choi, Y
   Choi, K
AF Lee, Jin Young
   Van Le, The
   Choi, Yongho
   Choi, Kiho
TI Low-complexity two-step lossless depth coding using coarse Lossy coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth image; Coarse lossy coding; Two-step lossless coding; Fast mode
   decision; Low complexity
ID COMPRESSION; IMAGES
AB Texture and depth images are generally used for 3D viewing with advanced displays. Because sthe characteristics of a depth image are very different from those of a texture image, an efficient compression method is required to transmit a depth image in a limited bandwidth. In this paper, a low-complexity two-step lossless depth coding (LTLDC) method using coarse lossy coding is proposed. The proposed method downsamples an original image and then coarsely compresses the downsampled image in the first step. This compressed image is upsampled, and then its residual is generated by subtracting the upsampled image from the original image. In the second step, each coding block within the residual and original images is adaptively compressed with a fast mode decision method in a lossless way, and the proposed method determines the best block based on their coding performance. Experimental results show that the proposed LTLDC method achieves a bitrate reduction of 4.35% with encoding complexity reduction of 20.38%.
C1 [Lee, Jin Young; Van Le, The; Choi, Yongho] Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
   [Choi, Kiho] Gachon Univ, Sch Comp, Seongnam, South Korea.
C3 Sejong University; Gachon University
RP Choi, K (corresponding author), Gachon Univ, Sch Comp, Seongnam, South Korea.
EM aikiho@gachon.ac.kr
RI Choi, Kiho/HPE-3499-2023
OI Choi, Kiho/0000-0002-2869-0440; Le, The/0000-0001-8568-4023; Choi,
   Yongho/0000-0002-5953-5312
FU Institute of Information & communications Technology Planning &
   Evaluation(IITP) - Korea government(MSIT) [IITP-2021-0-02067]; National
   Research Foundation of Korea(NRF) - Korea government(MSIT)
   [NRF-2020M3F6A1109603, NRF-2021R1C1C1006459, NRF-2021R1F1A1060816]
FX This work was supported by Institute of Information & communications
   Technology Planning & Evaluation(IITP) grant funded by the Korea
   government(MSIT) (IITP-2021-0-02067) and the National Research
   Foundation of Korea(NRF) grant funded by the Korea government(MSIT)
   (NRF-2020M3F6A1109603, NRF-2021R1C1C1006459, NRF-2021R1F1A1060816).
CR [Anonymous], 2011, ISO144951 JPEGLS
   [Anonymous], 2009, 1544422004 ISOIEC
   Bossen F., 2013, JCTVCL110
   Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   Chen F, 2020, IEEE ACCESS, V8, P21966, DOI 10.1109/ACCESS.2020.2969524
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Hertel DW, 2007, IEEE INT VEH S
   Kazui K., 2015, JTC1SC29WG11 ISOIEC
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim SH, 2011, IEEE T CIRC SYST VID, V21, P1005, DOI 10.1109/TCSVT.2011.2133170
   Lee J. Y., 2020, JVETT0096 ITUT SG
   Lee JY, 2020, MULTIMED TOOLS APPL, V79, P20929, DOI 10.1007/s11042-020-08938-y
   Lee JY, 2015, IEEE T CIRC SYST VID, V25, P1347, DOI 10.1109/TCSVT.2014.2380191
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Muller K., 2014, JCT3VG1100 ISOIEC
   Niu B., 2020, EUR C COMP VIS, P191, DOI [10.1007/978-3-030-58610-2_47, DOI 10.1007/978-3-030-58610-2_12]
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Pan ZT, 2013, IEEE T CIRC SYST VID, V23, P949, DOI 10.1109/TCSVT.2013.2243056
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   PATEL R, 2021, MULTIMEDIA SYST
   Patel R, 2021, MULTIMEDIA SYST, V27, P417, DOI 10.1007/s00530-020-00735-9
   Saxena A, 2013, IEEE T IMAGE PROCESS, V22, P3974, DOI 10.1109/TIP.2013.2265882
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan YH, 2013, INT CONF ACOUST SPEE, P2021, DOI 10.1109/ICASSP.2013.6638008
   Nguyen T, 2013, IEEE J-STSP, V7, P978, DOI 10.1109/JSTSP.2013.2278071
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Watanabe O., 2018, IEEE INT S CIRC SYST
   WIEGAND T, 2013, IEEE T CIRC SYSTVIDE, V13
   Wige E, 2013, IEEE IMAGE PROC, P1806, DOI 10.1109/ICIP.2013.6738372
   Yang K., 2020, APSIPA ANN SUMM C
   Yang SY, 2019, IEEE T CIRC SYST VID, V29, P881, DOI 10.1109/TCSVT.2018.2809690
   Yang Y, 2020, IEEE SIGNAL PROC LET, V27, P256, DOI 10.1109/LSP.2020.2965826
   Yoshida T, 2018, IEICE T FUND ELECTR, VE101A, P259, DOI 10.1587/transfun.E101.A.259
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhao H, 2020, COMPUTER VISION ECCV, P56, DOI DOI 10.1007/978-3-030-67070-23
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
   Zuo YF, 2020, IEEE T CIRC SYST VID, V30, P297, DOI 10.1109/TCSVT.2018.2890271
NR 40
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14065
EP 14079
DI 10.1007/s11042-022-12145-2
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300025
DA 2024-07-18
ER

PT J
AU Shaheed, K
   Qureshi, I
AF Shaheed, Kashif
   Qureshi, Imran
TI A hybrid proposed image quality assessment and enhancement framework for
   finger vein recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric; Finger vein recognition; Image classification; Image
   enhancement; Image processing
ID ROI LOCALIZATION; REPRESENTATION; CLASSIFICATION; NORMALIZATION; SYSTEM;
   SCALE
AB Finger vein recognition (FVR) is a biometric trait that can authenticate the person in real-time applications. However, finger vein (FV) images are generally poor due to various unfavorable factors. Therefore, these images are prone to low contrast, insufficient brightness, and noise problems, significantly impacting the FVR system performance. Hence, image quality assessment and enhancement play a vital role in finger vein recognition. To advance the FVR system performance, we propose two FVR algorithms based on FV image quality estimation and an enhancement algorithm. At first, good quality feature such as contrast, entropy and information capacity were extracted from finger vein images. Then, the image quality is evaluated by the KNN with the r-smote technique to classify the FV image into two classes, High Quality (HQ) and Low Quality (LQ) images. Second, a novel enhancement method called guided filter and bilateral filter (GFBF) are presented to enhance the low-quality FV images. Afterward, we estimate the enhancement algorithm by using SSIM and PSNR. Finally, we evaluate and test the proposed system strength using two parameters-namely accuracy and equal error rate (EER), for Classifier and recognition performance, respectively, on a dataset of 1052 FV images. The completed experiment determined that the proposed image assessment and enhancement method outperformed other enhancement and assessment schemes by achieving a low identification error rate of 0.0335. Further results conclude that the proposed art would be a perfect pre-processing tool for finger vein feature-based algorithms.
C1 [Shaheed, Kashif] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Qureshi, Imran] Natl Univ Sci & Technol MCS NUST, Mil Coll Signals, Dept Comp Software Engn, Islamabad 44000, Pakistan.
   [Qureshi, Imran] Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Key Lab Space Photoelect Detect & Percept, Minist Ind & Informat Technol, Nanjing 211106, Jiangsu, Peoples R China.
C3 South China University of Technology; National University of Sciences &
   Technology - Pakistan; Nanjing University of Aeronautics & Astronautics
RP Shaheed, K (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM kashifshaheed1@gmail.com; imarwat11@gmail.com
OI Shaheed, Kashif/0000-0002-7399-6211
FU NSF of Guangdong Province [2019A1515010833]; Fundamental Research Funds
   for Central Universities [2020ZYGXR089]
FX We would like to thank my supervisor, Professor Aihua Mao, and
   co-supervisor, Prof. Xingming Zhang, who supervises my Ph.D. project.
   And Thanks to all anonymous reviewers for their valuable comments. This
   work is financially supported by the NSF of Guangdong Province
   (No.2019A1515010833) and the Fundamental Research Funds for Central
   Universities (No.2020ZYGXR089). It is a part of a Ph.D. research project
   conducted in the School of Computer Science and Engineering, South China
   University of Technology, Guangzhou, China.
CR [Anonymous], 2015, Int J Sig Process Image Process Pattern Recognit, DOI DOI 10.14257/IJSIP.2015.8.8.23
   Banerjee A, 2018, MULTIMED TOOLS APPL, V77, P5857, DOI 10.1007/s11042-017-4501-8
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Du SS, 2021, MULTIMED TOOLS APPL, V80, P10705, DOI 10.1007/s11042-020-09270-1
   Ganesan T, 2020, ADV INTELL SYST, V1039, P690, DOI 10.1007/978-3-030-30465-2_76
   Gao YA, 2020, MULTIMED TOOLS APPL, V79, P20039, DOI 10.1007/s11042-020-08865-y
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hsia CH, 2018, IEEE SENS J, V18, P790, DOI 10.1109/JSEN.2017.2772799
   Hsia CH, 2017, MULTIMED TOOLS APPL, V76, P25179, DOI 10.1007/s11042-016-4296-z
   Huang ZX, 2016, LECT NOTES COMPUT SC, V9967, P244, DOI 10.1007/978-3-319-46654-5_27
   Hui Ma, 2013, Intelligent Science and Intelligent Data Engineering. Third Sino-foreign-interchange Workshop, IScIDE 2012. Revised Selected Papers, P498, DOI 10.1007/978-3-642-36669-7_61
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jumaa S. S., 2019, Period Eng Nat Sci Vol, V7, P514, DOI DOI 10.21533/PEN.V7I1.434
   장영균, 2008, [KIPS Transactions on Software and Data Engineering, 정보처리학회논문지. 소프트웨어 및 데이터 공학], V15, P275
   Kas M, 2020, MULTIMED TOOLS APPL, V79, P375, DOI 10.1007/s11042-019-08049-3
   Kim HG, 2012, LECT NOTES COMPUT SC, V7432, P21, DOI 10.1007/978-3-642-33191-6_3
   Lee EC, 2009, ELECTRON LETT, V45, P1074, DOI 10.1049/el.2009.1231
   Lee EC, 2011, SENSORS-BASEL, V11, P2319, DOI 10.3390/s110302319
   Lee EC, 2009, INT J IMAG SYST TECH, V19, P179, DOI 10.1002/ima.20193
   Lee HC, 2010, J ZHEJIANG U-SCI C, V11, P514, DOI 10.1631/jzus.C0910550
   Lei L, 2019, IEEE ACCESS, V7, P57226, DOI 10.1109/ACCESS.2019.2914229
   Naseriparsa M, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-020-00112-w
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan YY, 2019, CHIN CONT DECIS CONF, P5722, DOI [10.1109/ccdc.2019.8832770, 10.1109/CCDC.2019.8832770]
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Park YH, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/53474
   Peng JL, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P239, DOI 10.1109/IIH-MSP.2014.66
   Qin HF, 2018, IEEE T CIRC SYST VID, V28, P1677, DOI 10.1109/TCSVT.2017.2684826
   Qin HF, 2018, MULTIMED TOOLS APPL, V77, P2505, DOI 10.1007/s11042-016-4317-y
   Qin HF, 2015, LECT NOTES COMPUT SC, V9489, P421, DOI 10.1007/978-3-319-26532-2_46
   Qin HF, 2012, ASIAPAC SIGN INFO PR
   Qureshi Imran, 2020, International Journal of Intelligent Systems Technologies and Applications, V19, P1
   Qureshi I, 2019, ALGORITHMS, V12, DOI 10.3390/a12010014
   Shaheed Kashif, 2018, 2018 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC), P223, DOI 10.1109/SPAC46244.2018.8965537
   Shin KY, 2014, SENSORS-BASEL, V14, P3095, DOI 10.3390/s140203095
   Syarif MA, 2017, MULTIMED TOOLS APPL, V76, P6859, DOI 10.1007/s11042-016-3315-4
   Wei Pi, 2010, 2010 International Conference on Electronics and Information Engineering (ICEIE 2010), P424, DOI 10.1109/ICEIE.2010.5559667
   Xie S. J., 2013, Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics), P266
   Xie SJ, 2015, SENSORS-BASEL, V15, P17089, DOI 10.3390/s150717089
   Xie SJ, 2014, COGN COMPUT, V6, P446, DOI 10.1007/s12559-014-9254-3
   Xie S, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P206, DOI 10.1109/ICIVC.2017.7984547
   Xu YT, 2019, INT J MACH LEARN CYB, V10, P357, DOI 10.1007/s13042-017-0720-6
   Yang J., 2011, 2011 INT C HAND BAS, P188, DOI DOI 10.1109/ICHB.2011.6094320
   Yang JF, 2019, NEUROCOMPUTING, V328, P171, DOI 10.1016/j.neucom.2018.02.098
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P1569, DOI 10.1016/j.patrec.2012.04.018
   Yang JF, 2012, SENSORS-BASEL, V12, P3627, DOI 10.3390/s120303627
   Yang JF, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P87, DOI 10.1109/ICIG.2009.170
   Yang L, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.2.027003
   Yang MX, 2020, WATER RESOUR MANAG, V34, P849, DOI 10.1007/s11269-019-02479-2
   Yoza A., 2019, B NETWORKING COMPUT, V8, P4
   Zhang YK, 2019, 2019 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE BIG DATA AND INTELLIGENT SYSTEMS (HPBD&IS), P219, DOI [10.1109/hpbdis.2019.8735471, 10.1109/HPBDIS.2019.8735471]
   Zhu CP, 2019, INT CONF COMP SCI ED, P374, DOI [10.1109/ICCSE.2019.8845517, 10.1109/iccse.2019.8845517]
NR 53
TC 3
Z9 3
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15363
EP 15388
DI 10.1007/s11042-021-11877-x
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000761979300001
DA 2024-07-18
ER

PT J
AU Thakur, SS
   Poddar, P
   Roy, RB
AF Thakur, Saurabh Singh
   Poddar, Pradeep
   Roy, Ram Babu
TI Real-time prediction of smoking activity using machine learning based
   multi-class classification model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Preventive healthcare; mHealth; Smoking cessation; Wearable sensors;
   Predictive modeling; Personalized healthcare; Multimedia applications;
   IoT
ID HEALTH; TECHNOLOGIES; PREVENTION
AB Smoking cessation efforts can be greatly influenced by providing just-in-time intervention to individuals who are trying to quit smoking. Detecting smoking activity accurately among the confounding activities of daily living (ADLs) being monitored by the wearable device is a challenging and intriguing research problem. This study aims to develop a machine learning based modeling framework to identify the smoking activity among the confounding ADLs in real-time using the streaming data from the wrist-wearable IMU (6-axis inertial measurement unit) sensor. A low-cost wrist-wearable device has been designed and developed to collect raw sensor data from subjects for the activities. A sliding window mechanism has been used to process the streaming raw sensor data and extract several time-domain, frequency-domain, and descriptive features. Hyperparameter tuning and feature selection have been done to identify best hyperparameters and features respectively. Subsequently, multi-class classification models are developed and validated using in-sample and out-of-sample testing. The developed models obtained predictive accuracy (area under receiver operating curve) up to 98.7% for predicting the smoking activity. The findings of this study will lead to a novel application of wearable devices to accurately detect smoking activity in real-time. It will further help the healthcare professionals in monitoring their patients who are smokers by providing just-in-time intervention to help them quit smoking. The application of this framework can be extended to more preventive healthcare use-cases and detection of other activities of interest.
C1 [Thakur, Saurabh Singh; Roy, Ram Babu] Indian Inst Technol, Rajendra Mishra Sch Engn Entrepreneurship, Kharagpur, W Bengal, India.
   [Poddar, Pradeep] Indian Inst Technol Kharagpur, Dept Met & Mat Engn, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Thakur, SS (corresponding author), Indian Inst Technol, Rajendra Mishra Sch Engn Entrepreneurship, Kharagpur, W Bengal, India.
EM saurabhjan07@gmail.com; pradeeppoddar.iitkgp@gmail.com;
   rambabu@see.iitkgp.ac.in
CR Abroms LC, 2013, AM J PREV MED, V45, P732, DOI 10.1016/j.amepre.2013.07.008
   Adibi S, 2015, MOBILE HLTH TECHNOLO
   Akash K, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3132743
   Al-Ubaydli O, 2017, J ECON PERSPECT, V31, P125, DOI 10.1257/jep.31.4.125
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Aly M., 2005, NEURAL NETWORKS, V19, P9
   Anguita D, 2012, IEEE T NEUR NET LEAR, V23, P1390, DOI 10.1109/TNNLS.2012.2202401
   Atallah L, 2011, IEEE T BIOMED CIRC S, V5, P320, DOI 10.1109/TBCAS.2011.2160540
   Formagini TDB, 2017, CAD SAUDE PUBLICA, V33, DOI 10.1590/0102-311X00178215
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burba F, 2009, J NONPARAMETR STAT, V21, P453, DOI 10.1080/10485250802668909
   Chatterjee S, 2009, J AM MED INFORM ASSN, V16, P171, DOI 10.1197/jamia.M2859
   COX DR, 1958, J R STAT SOC B, V20, P215
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Erdas ÇB, 2016, PROCEDIA COMPUT SCI, V98, P522, DOI 10.1016/j.procs.2016.09.070
   Eyobu OS, 2018, IEEE I C CONS ELECT
   Fogg BJ, 1999, COMMUN ACM, V42, P26, DOI 10.1145/301353.301396
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Haskins BL, 2017, TRANSL BEHAV MED, V7, DOI 10.1007/s13142-017-0492-2
   Heydari, 2015, INT J PREV MED, V2015
   Heydari G, 2014, INT J PREVENTIVE MED, V5, P673
   Hoeppner BB, 2016, NICOTINE TOB RES, V18, P1025, DOI 10.1093/ntr/ntv117
   Huang WH, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061218
   Jain R, 2013, BIOMED RES INT-UK, V2013, DOI 10.1155/2013/278392
   Jha P, 2014, NEW ENGL J MED, V370, P60, DOI 10.1056/NEJMra1308383
   Jun Qi, 2015, 2015 IEEE International Conferences on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; and Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM). Proceedings, P2353, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.348
   Kim E, 2019, EXPERT SYST APPL, V128, P214, DOI 10.1016/j.eswa.2019.03.042
   Kosse NM, 2013, INT J MED INFORM, V82, P743, DOI 10.1016/j.ijmedinf.2013.06.001
   Luna-Perejon F, 2019, COMPUT METH PROG BIO, V182, DOI 10.1016/j.cmpb.2019.105042
   McClure JB, 2016, JMIR MHEALTH UHEALTH, V4, P199, DOI 10.2196/mhealth.5181
   Méndez D, 2017, NICOTINE TOB RES, V19, P1418, DOI 10.1093/ntr/ntw239
   Messer K, 2008, AM J PUBLIC HEALTH, V98, P317, DOI 10.2105/AJPH.2007.112060
   Miao F, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0026-4
   O'Donoghue G, 2014, PHYSIOTHERAPY, V100, P116, DOI 10.1016/j.physio.2013.10.004
   Pärkkä J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863
   Paulovich FV, 2018, ACS SENSORS, V3, P1433, DOI 10.1021/acssensors.8b00276
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Qi J, 2018, J BIOMED INFORM, V87, P138, DOI 10.1016/j.jbi.2018.09.002
   Raiff BR, 2014, ELECTRONICS-SWITZ, V3, P87, DOI 10.3390/electronics3010087
   Raschka Sebastian., 2018, MLxtend: Providing machine learning and data science utilities and extensions to Python's scientific computing stack
   Reeder B, 2016, J BIOMED INFORM, V63, P269, DOI 10.1016/j.jbi.2016.09.001
   Regmi K, 2017, TOB PREV CESS, V3, DOI 10.18332/tpc/70088
   Rose S, 2018, JAMA NETW OPEN, V1, DOI 10.1001/jamanetworkopen.2018.1404
   Rossel PO, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719888167
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Saleheen N, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P999, DOI 10.1145/2750858.2806897
   Schick Robert S, 2018, Pilot Feasibility Stud, V4, P19, DOI 10.1186/s40814-017-0165-4
   Scholl P. M., 2012, 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS 2012), P886, DOI 10.1109/IMIS.2012.96
   Schwartz RP, 2014, ADDICTION, V109, P1091, DOI 10.1111/add.12502
   Senyurek V, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030570
   Silva BMC, 2015, J BIOMED INFORM, V56, P265, DOI 10.1016/j.jbi.2015.06.003
   Tang Q., 2014, PROC PERVASIVEHEALTH, P80, DOI [10.4108/icst.pervasivehealth.2014.254978, DOI 10.4108/ICST.PERVASIVEHEALTH.2014.254978]
   Thakur SS, 2018, PROCEEDINGS OF THE ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MANAGEMENT OF DATA (CODS-COMAD'18), P352, DOI 10.1145/3152494.3167989
   Thakur SS., 2018, ADV INTELLIGENT SYST, P119
   Triantafyllidis A, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103984
   Ubhi HK, 2016, ADDICT BEHAV, V58, P175, DOI 10.1016/j.addbeh.2016.02.026
   Varkey JP, 2012, PERS UBIQUIT COMPUT, V16, P897, DOI 10.1007/s00779-011-0455-4
   Verbeek P.P., 2012, Encyclopedia of applied ethics, P431, DOI DOI 10.1016/B978-0-12-373932-2.00008-9
   Villalobos-Zúñiga G, 2020, INT J HUM-COMPUT ST, V140, DOI 10.1016/j.ijhcs.2020.102449
   WALKER SH, 1967, BIOMETRIKA, V54, P167, DOI 10.1093/biomet/54.1-2.167
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Whittaker Robyn., 2012, Mobile phone-based interventions for smoking cessation
   Zheng YL, 2014, IEEE T BIO-MED ENG, V61, P1538, DOI 10.1109/TBME.2014.2309951
NR 69
TC 4
Z9 4
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14529
EP 14551
DI 10.1007/s11042-022-12349-6
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300022
PM 35233178
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU AlhaiderynAff, MMA
   Taherinia, AH
AF AlhaiderynAff, Manaf Mohammed Ali
   Taherinia, Amir Hossein
TI A passive image forensic scheme based on an adaptive and hybrid
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy move forgery detection; Image forensic analysis; Image
   segmentation; Duplicated regions; Haar wavelet transform; Entropy;
   RANSAC
ID COPY-MOVE FORGERY; SPLICING DETECTION; FEATURES; DCT
AB The fast growth of using digital images in the virtual world and, The advance of image processing tools makes an image under the effect of attackers or intruders. Attackers tamper digital images and divert the content of the image from its true meaning. The manipulation in digital images makes tampering hard to detect with the naked eye. Therefore, image forensic analysis is developed to keep up and protect the authenticity and rights of the owner of digital images. The Copy-move forgery detection (CMFD) scheme is the popular type in image forensic analysis. This paper presents a merged CMFD scheme. This scheme contains a preparing process and three layers of processing. In the preparing process, Haar Discrete Wavelet Transform(HDWT) automates the number of segments before applying the segmentation process. The first layer, Simple Linear Iterative Clustering(SLIC)segmentation method is proposed to split images into irregular labels. Then, classification these segments into two main types called texture or smooth regions based on the Entropy metric. In the second layer, the keypoint-based technique is adopted. Speed Up Robust Feature(SURF) as detector and Histogram Of Oriented Gradient (HOG) as a descriptor is applied on each region. SURF-HOG to extract key points from regions with different Threshold values. In the third layer, an efficient probabilistic false positive removal filter(M-SAC) is employed. It aims to include the correct results and exclude false results from the output detected image. Subsequently, increase TPR and decrease FPR. The proposed scheme is evaluated by using(IMD and MICC-F220)data sets. The photometric attacks(brightness, blurring, JPEG compression) and geometric transformation attacks(scaling, rotation) are applied in these datasets. The experimental results indicate that the proposed scheme is fast, efficient, and high performance under simple and compound attacks. It has high TPR, Low FPR and, makes the scheme more dynamic and suitable in image forensic analysis.
C1 [AlhaiderynAff, Manaf Mohammed Ali; Taherinia, Amir Hossein] Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Taherinia, AH (corresponding author), Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
EM Manafma77@gmail.com; taherinia@um.ac.ir
RI Taherinia, Amir Hossein/HTP-1792-2023; Taherinia, Amir
   Hossein/AAC-9575-2020; Alhaidery, Manaf/KHD-1036-2024
OI Taherinia, Amir Hossein/0000-0002-5103-4812; 
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bhanu MPB, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P224, DOI 10.1109/ISCO.2017.7855986
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Emam M, 2018, J FORENSIC SCI, V63, P102, DOI 10.1111/1556-4029.13456
   Escolano, 2009, IMAGE
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Fridrich J., DETECTION COPY MOVE
   Gonzalez RC., Digital image processing third edition Pearson international edition prepared by Pearson Education
   Hassaballah M, IMAGE FEATURES DETEC
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Jothi JN, 2020, SOFT COMPUT, V24, P5427, DOI 10.1007/s00500-019-04298-4
   Kaspi O, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0224-0
   Khan S, ROBUST METHOD DETECT, P69
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P477, DOI 10.1007/s11042-019-08044-8
   MacDermott A, 2018, INT CONF NEW TECHNOL
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Mathematics, 2014, IJPAM, V91, P349
   Meena KB, 2019, MULTIMED TOOLS APPL, V78, P33505, DOI 10.1007/s11042-019-08082-2
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sadeghi S, 2017, PATTERN ANAL APPL
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Sridevi M, FREAK DESCRIPTOR
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Uliyan DM, 2016, EXPERT SYST APPL, V64, P1, DOI 10.1016/j.eswa.2016.07.026
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang WW, 2017, LECT NOTES COMPUT SC, V10082, P159, DOI 10.1007/978-3-319-53465-7_12
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6
NR 39
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12681
EP 12699
DI 10.1007/s11042-022-12374-5
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758973600003
DA 2024-07-18
ER

PT J
AU Kittawi, N
   Al-Haj, A
AF Kittawi, Nour
   Al-Haj, Ali
TI Reversible data hiding using bit flipping and histogram shifting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Watermarking; Encrypted domain; Histogram
   shifting; Bit flipping; Embedding capacity; Image visual quality;
   Standard images; Medical images
ID SCHEME
AB Medical, military, and cloud computing applications require high degrees of security and privacy, and thus they are potential candidates to benefit from hiding data in encrypted images. This paper introduces a new algorithm that combines cryptography and data hiding techniques to hide data into encrypted grayscale images in a reversible manner. Based on the proposed algorithm, the original cover image is encrypted before a data hiding procedure is applied to embed two watermarks in the encrypted image. One watermark is embedded by flipping the two middle bits of encrypted image pixels which are secretly selected using a pre-shared hiding key. The bits of the second watermark are embedded by applying the histogram shifting method on the watermarked image. At the receiving send, the bits of the second watermark are extracted using the inverse histogram shifting and the integrity and authenticity of the recovered image are verified. The experimental results obtained demonstrate that the proposed algorithm meets the requirements of effective reversible data hiding such as high visual image quality, high embedding capacity, and high entropy. The algorithm is also competitive with other recent algorithms with respect to these performance metrics.
C1 [Kittawi, Nour; Al-Haj, Ali] Princess Sumaya Univ Technol, King Abdullah II Sch Engn, Dept Comp Engn, POB 1438, Amman 11941, Jordan.
C3 Princess Sumaya University for Technology
RP Al-Haj, A (corresponding author), Princess Sumaya Univ Technol, King Abdullah II Sch Engn, Dept Comp Engn, POB 1438, Amman 11941, Jordan.
EM n.kanawi@psut.edu.jo; ali@psut.edu.jo
OI Al-Haj, Ali/0000-0002-4215-2286
CR Fujiyoshi M, 2013, IEEE INT CONF MULTI
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Jose R, 2013, 2013 ANNUAL INTERNATIONAL CONFERENCE ON EMERGING RESEARCH AREAS & 2013 INTERNATIONAL CONFERENCE ON MICROELECTRONICS, COMMUNICATIONS & RENEWABLE ENERGY (AICERA/ICMICR)
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Ke Y, 2020, IEEE T CIRC SYST VID, V30, P2353, DOI 10.1109/TCSVT.2019.2963393
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Lee C.-F., 2019, INT CONF AWARE SCI, P1
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mahasree M, 2021, P 5 INT C TRENDS EL
   Mahasree M, 2017, P 5 INT WORKSH BIOM
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Singh AK., 2020, Intelligent Data Security Solutions for e-Health Applications
   Stallings W., 2018, Effective Cybersecurity: A Guide to Using Best Practices and Standards, VFirst
   Subburam S, 2018, MULTIMED TOOLS APPL, V77, P7071, DOI 10.1007/s11042-017-4622-0
   Xiong LZ, 2018, MULTIDIM SYST SIGN P, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Yang P., 2020, IEEE ACCESS, V8, P3210
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Zhang S, 2014, J APPL MATH, DOI 10.1155/2014/861782
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 22
TC 4
Z9 4
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12441
EP 12458
DI 10.1007/s11042-022-12364-7
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400008
DA 2024-07-18
ER

PT J
AU Nagaraj, N
   Gururaj, HL
   Swathi, BH
   Hu, YC
AF Nagaraj, Nandini
   Gururaj, Harinahalli Lokesh
   Swathi, Beekanahalli Harish
   Hu, Yu-Chen
TI Passenger flow prediction in bus transportation system using deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Passenger prediction; Bus transportation system; Deep learning; Long
   short-term memory; Recurrent neural network
ID TIME PREDICTION; FUSION; MODEL
AB The forecasting of bus passenger flow is important to the bus transit system's operation. Because of the complicated structure of the bus operation system, it's difficult to explain how passengers travel along different routes. Due to the huge number of passengers at the bus stop, bus delays, and irregularity, people are experiencing difficulties of using buses nowadays. It is important to determine the passenger flow in each station, and the transportation department may utilize this information to schedule buses for each region. In Our proposed system we are using an approach called the deep learning method with long short-term memory, recurrent neural network, and greedy layer-wise algorithm are used to predict the Karnataka State Road Transport Corporation (KSRTC) passenger flow. In the dataset, some of the parameters are considered for prediction are bus id, bus type, source, destination, passenger count, slot number, and revenue These parameters are processed in a greedy layer-wise algorithm to make it has cluster data into regions after cluster data move to the long short-term memory model to remove redundant data in the obtained data and recurrent neural network it gives the prediction result based on the iteration factors of the data. These algorithms are more accurate in predicting bus passengers. This technique handles the problem of passenger flow forecasting in Karnataka State Road Transport Corporation Bus Rapid Transit (KSRTCBRT) transportation, and the framework provides resource planning and revenue estimation predictions for the KSRTCBRT.
C1 [Nagaraj, Nandini; Gururaj, Harinahalli Lokesh; Swathi, Beekanahalli Harish] Vidyavardhaka Coll Engn, Dept Comp Sci & Engn, Mysuru, Karnataka, India.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200 Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
C3 Vidyavardhaka College of Engineering; Providence University - Taiwan
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200 Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
EM ychu@pu.edu.tw
RI H, Swathi B/AAU-1909-2020; Hui, Yu/JOZ-3598-2023; Hu,
   Yu-Chen/AAT-5264-2020; L, G/JOK-3625-2023
OI H, Swathi B/0000-0001-6694-6075; Hu, Yu-Chen/0000-0002-5055-3645; 
CR Agafonov AA, 2019, OPT MEMORY NEURAL, V28, P222, DOI 10.3103/S1060992X19030081
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Bai Y, 2017, APPL SOFT COMPUT, V58, P669, DOI 10.1016/j.asoc.2017.05.011
   Crawford F, 2017, TRANSPORT RES B-METH, V95, P196, DOI 10.1016/j.trb.2016.11.004
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Du BW, 2020, IEEE T INTELL TRANSP, V21, P972, DOI 10.1109/TITS.2019.2900481
   Duan YJ, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1053, DOI 10.1109/ITSC.2016.7795686
   Fontes T, 2020, TRANSP TELECOMMUN J, V21, P255, DOI 10.2478/ttj-2020-0020
   Grossberg S., 2013, SCHOLARPEDIA, V8, P1888, DOI DOI 10.4249/SCHOLARPEDIA.1888
   Guo JY, 2019, IEEE ACCESS, V7, P42946, DOI 10.1109/ACCESS.2019.2907739
   Han Y, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8090366
   Nguyen H, 2018, IET INTELL TRANSP SY, V12, P998, DOI 10.1049/iet-its.2018.0064
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsu YW, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163675
   Hu N, 2022, CONNECT SCI, V34, P429, DOI 10.1080/09540091.2021.2006607
   Huang Z, 2019, IEEE ACCESS, V7, P106453, DOI 10.1109/ACCESS.2019.2932801
   Jung J, 2017, IET INTELL TRANSP SY, V11, P334, DOI 10.1049/iet-its.2016.0276
   Liu LJ, 2017, TRANSPORT RES C-EMER, V84, P74, DOI 10.1016/j.trc.2017.08.001
   Luo D, 2021, IEEE T INTELL TRANSP, V22, P7184, DOI 10.1109/TITS.2020.3002772
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Ma ZL, 2014, TRANSPORT RES C-EMER, V39, P148, DOI 10.1016/j.trc.2013.12.008
   Petersen NC, 2019, EXPERT SYST APPL, V120, P426, DOI 10.1016/j.eswa.2018.11.028
   Polson NG, 2017, TRANSPORT RES C-EMER, V79, P1, DOI 10.1016/j.trc.2017.02.024
   Shiralashetti AS., 2008, ICFAI J SERV MARKET, V6, P29
   Sun YJ, 2014, DISCRETE DYN NAT SOC, V2014, DOI 10.1155/2014/397154
   Sun YX, 2015, NEUROCOMPUTING, V166, P109, DOI 10.1016/j.neucom.2015.03.085
   Tsai CW, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2020.106068
   Wang HY, 2019, TRANSPORT RES C-EMER, V105, P580, DOI 10.1016/j.trc.2019.05.022
   Wang Y, 2019, TRANSPORT RES C-EMER, V99, P144, DOI 10.1016/j.trc.2018.12.004
   Xie ZY, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6636367
   Zhang J, 2017, IEEE T INTELL TRANSP, V18, P3168, DOI 10.1109/TITS.2017.2686877
   Zhang Y, 2020, MULTIMED TOOLS APPL, V79, P28785, DOI 10.1007/s11042-020-09487-0
   Zhao Z, 2017, IET INTELL TRANSP SY, V11, P68, DOI 10.1049/iet-its.2016.0208
   Zhou C, 2015, 2015 INT C GREEN COM, P8
NR 36
TC 18
Z9 19
U1 12
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12519
EP 12542
DI 10.1007/s11042-022-12306-3
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400012
PM 35221777
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Yu, KL
   Chen, LQ
   Wang, Y
   Lu, TY
AF Yu, Kunliang
   Chen, Liquan
   Wang, Yu
   Lu, Tianyu
TI A channel coding information hiding algorithm for images based on
   uniform cyclic shift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Channel encoding; Information hiding; Covert channels; Uniform cyclic
   shift
ID REVERSIBLE WATERMARKING; DIFFERENCE EXPANSION; INTEGER TRANSFORM
AB Robust reversible watermarking algorithms for images have good performance against traditional image processing methods such as compression, noise and filtering. However, when the sender transmits a carrier image over a noisy channel, the quality of the image is significantly affected and the receiver has difficulty recovering the secret information. To address this problem, we change the carrier of secret information from image to channel coding and propose a channel coding information hiding scheme based on uniform cyclic shift algorithm for images. The proposed algorithm, which is not based on a specific protocol, uses the error correction capability of the code to construct a covert channel. The secret information is embedded in the carrier bitstream approximately uniformly by the proposed algorithm, which makes the noise caused by the secret information similar to the random noise of the channel at low signal-to-noise ratio (SNR). We experimentally and analytically give the optimal values of some adjustable parameters and deduce the maximum embedding capacity of the proposed algorithm. Compared with the traditional robust reversible information hiding scheme, the carrier obtained by channel decoding at the receiving end can be the closest to the original carrier, and the secret information can be restored with the lowest bit error rate (BER).
C1 [Yu, Kunliang; Chen, Liquan; Wang, Yu; Lu, Tianyu] Southeast Univ, Sch Cyber Sci & Engn, Nanjing 210096, Peoples R China.
   [Chen, Liquan] Purple Mt Labs, Nanjing 211118, Peoples R China.
C3 Southeast University - China
RP Chen, LQ (corresponding author), Southeast Univ, Sch Cyber Sci & Engn, Nanjing 210096, Peoples R China.; Chen, LQ (corresponding author), Purple Mt Labs, Nanjing 211118, Peoples R China.
EM Lqchen@seu.edu.cn
RI lu, Tianyu/ACZ-1638-2022
OI lu, Tianyu/0000-0002-7958-1594; Yu, Kunliang/0000-0002-6718-8875
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Al-Qerem A, 2020, SOFT COMPUT, V24, P5695, DOI 10.1007/s00500-019-04220-y
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Esposito C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102468
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Grabska I, 2013, INT C ULTRA MOD TELE, P20, DOI 10.1109/ICUMT.2013.6798399
   Harley PMB, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P54, DOI 10.23919/elinfocom.2019.8706484
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Ishtiaq M, 2018, IEEE ACCESS, V6, P13213, DOI 10.1109/ACCESS.2018.2803301
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Ma HX, 2014, ADV INTEL SYS RES, V91, P1
   Mehta A., 2008, 2008 IEEE Antennas and Propagation Society International Symposium and USNC/URSI National Radio Science Meeting, DOI 10.1109/APS.2008.4619211
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Paul G, 2010, ARXIV10125573
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Petitcolas FAP, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P574, DOI 10.1109/MMCS.1999.779264
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin JQ, 2019, IEEE SIGNAL PROC LET, V26, P843, DOI 10.1109/LSP.2019.2909080
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang X, 2020, IEEE T CIRC SYST VID, V30, P2406, DOI 10.1109/TCSVT.2019.2915116
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2017, J VIS COMMUN IMAGE R, V48, P317, DOI 10.1016/j.jvcir.2017.05.005
   Weng SW, 2016, J VIS COMMUN IMAGE R, V35, P25, DOI 10.1016/j.jvcir.2015.11.005
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zeng XT, 2010, PATTERN RECOGN, V43, P1656, DOI 10.1016/j.patcog.2009.09.016
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zielinska E., 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P586, DOI 10.1109/MINES.2011.23
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 44
TC 3
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11279
EP 11300
DI 10.1007/s11042-022-12034-8
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200002
DA 2024-07-18
ER

PT J
AU Hsu, CC
   Lee, CY
   Lin, CJ
   Yeh, H
AF Hsu, Chih-Chung
   Lee, Chia-Yen
   Lin, Cheng-Jhong
   Yeh, Hung
TI A comprehensive study of age-related macular degeneration detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age-related macular degeneration (AMD); Segmentation; Deep learning;
   Annotation quality; Small-symptom dilation (SSD)
ID AUTOMATIC DETECTION; EXUDATE DETECTION; RETINAL IMAGES; SEGMENTATION
AB Age-related macular degeneration (AMD) is an illness involving the degeneration of the macula of the retina. Fundus photography is the most affordable and convenient way to monitor individuals, in which AMD symptoms segmentation is necessary to assist clinical diagnosis. This study conducted a large number of experimental discussions on the annotation quality and symptoms categories to find a reliable learning strategy, and then applied it to early detection of AMD. Specifically, we discuss the inference of the representational power of the deep neural network, loss function selection, the preprocessing scheme of annotation augmentation, and the annotation quality of the dataset on prediction performance. This paper verified that different learning strategies need to be selected for the AMD symptoms segmentation tasks with varying characteristics of database, which can be used as a reference for developing the related research in the future. On the other hand, we demonstrated that current medical datasets suffer from annotation quality uncertainty, leading to limited learning capabilities. In the future, it is necessary to develop methods to overcome the impact of datasets with poor annotation quality.
C1 [Hsu, Chih-Chung] Natl Cheng Kung Univ, Inst Data Sci, Tainan, Taiwan.
   [Lee, Chia-Yen; Lin, Cheng-Jhong; Yeh, Hung] Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
C3 National Cheng Kung University; National United University
RP Lee, CY (corresponding author), Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
EM leecyya@gmail.com
RI Hsu, Chih-Chung/Y-4835-2019
OI Hsu, Chih-Chung/0000-0002-2083-4438; Lee, Chia-Yen/0000-0002-7477-782X
CR Francia GA, 2020, IEEE ACCESS, V8, P38493, DOI 10.1109/ACCESS.2020.2975745
   Badar M, 2018, COMM COM INF SC, V894, P313, DOI 10.1007/978-3-319-95921-4_29
   Bertasius G, 2017, PROC CVPR IEEE, P6137, DOI 10.1109/CVPR.2017.650
   BRESSLER NM, 1988, SURV OPHTHALMOL, V32, P375, DOI 10.1016/0039-6257(88)90052-5
   Chen L-C, 2014, ARXIV PREPR ARXIV141
   CHEN LC, 2017, ARXIV PREPRINT ARXIV, V1706, P5587, DOI DOI 10.48550/ARXIV.1706.05587
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Fine SL, 2000, NEW ENGL J MED, V342, P483, DOI 10.1056/NEJM200002173420707
   Fleming AD, 2007, PHYS MED BIOL, V52, P7385, DOI 10.1088/0031-9155/52/24/012
   Grassmann F, 2018, OPHTHALMOLOGY, V125, P1410, DOI 10.1016/j.ophtha.2018.02.037
   Guo S, 2019, NEUROCOMPUTING, V349, P52, DOI 10.1016/j.neucom.2019.04.019
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heller N, 2018, LECT NOTES COMPUT SC, V11043, P112, DOI 10.1007/978-3-030-01364-6_13
   Hu K, 2018, NEUROCOMPUTING, V309, P179, DOI 10.1016/j.neucom.2018.05.011
   Jager RD, 2008, NEW ENGL J MED, V358, P2606, DOI 10.1056/NEJMra0801537
   Joshi S, 2020, EUR J OPHTHALMOL, V30, P1135, DOI 10.1177/1120672119843021
   Karimi D, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101759
   Kats E, 2019, I S BIOMED IMAGING, P1563, DOI [10.1109/ISBI.2019.8759518, 10.1109/isbi.2019.8759518]
   Kerfoot E., 2019, Statistical Atlases and Computational Models of the Heart. Atrial Segmentation and LV Quantification Challenges: 9th International Workshop, STACOM 2018, Held in with MICCAI 2018, Granada, Spain, V11395, P371
   Khanna A, 2020, BIOCYBERN BIOMED ENG, V40, P1314, DOI 10.1016/j.bbe.2020.07.007
   Kou CX, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.2.025008
   Li D, 2019, IEEE IMAGE PROC, P1425, DOI [10.1109/ICIP.2019.8803101, 10.1109/icip.2019.8803101]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marino C., 2008, WSEAS Transactions on Computers, V7, P207
   Cárdenas JM, 2013, ADV INTELL SYST, V184, P73
   Peng YF, 2019, OPHTHALMOLOGY, V126, P565, DOI 10.1016/j.ophtha.2018.11.015
   Pham QTM, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101617
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen WH, 2021, INVERSE PROBL IMAG, V15, P1333, DOI 10.3934/ipi.2020057
   Sopharak A, 2009, SENSORS-BASEL, V9, P2148, DOI 10.3390/s90302148
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Tajbakhsh N, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101693
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Walter T, 2007, MED IMAGE ANAL, V11, P555, DOI 10.1016/j.media.2007.05.001
   Yan F, 2018, LECT NOTES COMPUT SC, V11071, P48, DOI 10.1007/978-3-030-00934-2_6
   Yan ZZ, 2019, I S BIOMED IMAGING, P597, DOI 10.1109/isbi.2019.8759579
   Yazid H, 2012, J MED SYST, V36, P1997, DOI 10.1007/s10916-011-9659-4
   Yu W, 2019, IEEE IMAGE PROC, P250, DOI [10.1109/icip.2019.8802951, 10.1109/ICIP.2019.8802951]
   Zabihollahy F, 2019, PROC SPIE, V10953, DOI 10.1117/12.2513034
   Zhang JX, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050721
   Zhang XW, 2014, MED IMAGE ANAL, V18, P1026, DOI 10.1016/j.media.2014.05.004
   Zong YS, 2020, IEEE ACCESS, V8, P167225, DOI 10.1109/ACCESS.2020.3023273
NR 44
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11897
EP 11916
DI 10.1007/s11042-021-11896-8
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000756332700005
DA 2024-07-18
ER

PT J
AU Wang, Y
   Yu, XS
   Wu, CD
AF Wang, Ying
   Yu, Xiaosheng
   Wu, Chengdong
TI Optic disc detection based on fully convolutional neural network and
   structured matrix decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal fundus images; Optic disc detection; Structured matrix
   decomposition; Fully convolutional neural network
ID FUNDUS IMAGES; SEGMENTATION; CUP; DIAGNOSIS
AB Optic disc (OD) region provides a wealth of information for fundus images analysis. The accurate detection of OD contour is very important for the diagnosis and treatment of eye diseases. Considering that the OD region is generally a saliency area that distinguishes with the background in the fundus image, in this paper, we propose a unified OD detection approach by using the fully convolution neural network (FCNN) combined with the structured matrix decomposition (SMD) model, which can detect the OD region from original image directly excluding the localization step. First, the original fundus image is clustered into super pixels by Simple Linear Iterative Clustering (SLIC) algorithm, and its color, texture, and edge features are extracted to construct a feature matrix. Then, a hierarchical segmentation tree is established based on the spatial connectivity and feature similarity between super pixel patches. Finally, the SMD model and the high-level semantic prior knowledge provided by FCNN are used together to decompose the feature matrix into a sparse matrix representing the OD region and a low-rank matrix indicating the background. In this way, the OD region is derived from the sparse matrix obtained by decomposition. Our proposed method is evaluated on DRISHTI-GS dataset and IDRiD dataset and shows superior performance compared with the state-of-the-art methods.
C1 [Wang, Ying] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
   [Yu, Xiaosheng; Wu, Chengdong] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Wang, Y (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
EM wangying0337@163.com
RI Wu, Chengdong/IST-5302-2023
FU National Natural Science Foundation of China [U20A20197, 61973063];
   Liaoning Key Research and Development Project [2020JH2/10100040];
   Natural Science Foundation of Liaoning Province [2021-KF-12-01];
   Foundation of National Key Laboratory [OEIPO-202005]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant nos. U20A20197, 61973063, Liaoning Key
   Research and Development Project 2020JH2/10100040, Natural Science
   Foundation of Liaoning Province 2021-KF-12-01 and the Foundation of
   National Key Laboratory OEIPO-202005.
CR Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Almazroa A, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/180972
   [Anonymous], 2011, Eur J Sci Res
   [Anonymous], 1998, Gabor Analysis and Algorithms
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Besenczi R, 2016, COMPUT STRUCT BIOTEC, V14, P371, DOI 10.1016/j.csbj.2016.10.001
   Cheng J, 2013, IEEE T MED IMAGING, V32, P1019, DOI 10.1109/TMI.2013.2247770
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Gao Y, 2019, IEEE IMTC P, P177, DOI [10.1109/i2mtc.2019.8826970, 10.1145/3314399]
   Hagiwara Y, 2018, COMPUT METH PROG BIO, V165, P1, DOI 10.1016/j.cmpb.2018.07.012
   Haleem MS, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0859-4
   Haleem MS, 2013, COMPUT MED IMAG GRAP, V37, P581, DOI 10.1016/j.compmedimag.2013.09.005
   Ji PL, 2019, MULTIMED TOOLS APPL, V78, P35471, DOI 10.1007/s11042-019-08043-9
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Lalonde M, 2001, IEEE T MED IMAGING, V20, P1193, DOI 10.1109/42.963823
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Lee S., 1991, BMVC91
   Li HQ, 2003, PATTERN RECOGN, V36, P2093, DOI 10.1016/S0031-3203(03)00052-9
   Li T, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2021.101971
   Lim G, 2015, PROC INT C TOOLS ART, P162, DOI 10.1109/ICTAI.2015.36
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mithun Niluthpol Chowdhury, 2014, 2013 16th International Conference on Computer and Information Technology (ICCIT), P98, DOI 10.1109/ICCITechn.2014.6997365
   Mittapalli PS, 2016, BIOMED SIGNAL PROCES, V24, P34, DOI 10.1016/j.bspc.2015.09.003
   Mohamed NA, 2019, BIOMED SIGNAL PROCES, V53, DOI [10.1016/j.bspc.2019.01.003, 10.1080/09291016.2019.1629167]
   Niemeijer M, 2009, MED IMAGE ANAL, V13, P859, DOI 10.1016/j.media.2009.08.003
   Niu D, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P208, DOI 10.1109/SIPROCESS.2017.8124534
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perez CA, 2013, IEEE SYS MAN CYBERN, P4300, DOI 10.1109/SMC.2013.733
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi YX, 2021, IEEE T MULTIMEDIA, V23, P3264, DOI 10.1109/TMM.2020.3023272
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Tang YD, 2006, INT C PATT RECOG, P183
   Thakur N, 2018, BIOMED SIGNAL PROCES, V42, P162, DOI 10.1016/j.bspc.2018.01.014
   Wang L, 2019, BIOMED SIGNAL PROCES, V51, P82, DOI 10.1016/j.bspc.2019.01.022
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Welfer D, 2013, PATTERN RECOGN LETT, V34, P476, DOI 10.1016/j.patrec.2012.12.011
   Wong DWK, 2008, IEEE ENG MED BIO, P2266, DOI 10.1109/IEMBS.2008.4649648
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yin FS, 2011, IEEE ENG MED BIO, P2626, DOI 10.1109/IEMBS.2011.6090724
   Zhou HY, 2010, MULTIMED TOOLS APPL, V49, P447, DOI 10.1007/s11042-009-0443-0
   Zhu XL, 2010, J DIGIT IMAGING, V23, P332, DOI 10.1007/s10278-009-9189-5
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
   Zou BJ, 2019, CHINESE J ELECTRON, V28, P71, DOI 10.1049/cje.2017.12.007
NR 53
TC 5
Z9 5
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10797
EP 10817
DI 10.1007/s11042-022-12235-1
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700016
DA 2024-07-18
ER

PT J
AU Osman, FA
   Hashem, MYM
   Eltokhy, MAR
AF Osman, Fawzy A.
   Hashem, Mohamed Y. M.
   Eltokhy, Mostafa A. R.
TI Secured cloud SCADA system implementation for industrial applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote SCADA System; RSS; RSA and CBC encryption algorithms
ID CYBER-SECURITY
AB The proposed Remote SCADA System (RSS) is a smarter, faster and more reliable way to control high power machines and monitor their sensors, data, and failures. The proposed system focuses mainly on building our own complete SCADA software and not using open-source SCADA software. The proposed RSS can use unlimited number of added Remote Terminal Units (RTU) nodes and each of them can handling unlimited number of input/output and can be used under different operating systems like Windows and Android. Using RSS all machines can be monitored and controlled by a single click from anywhere at any time. By doing this a real-time response from RSS system can be achieved. It's mainly based on standard communication techniques between remote nodes and single server-side application that talk to each node with its own ID and modify its instant database. So that every time accessing this web application, a real-time access to these nodes data and a virtual control room controls each General Purpose Input/Output (GPIO) in the selected node can be gotten. When a new event is happened in server-side program, it will be broadcasted to all related. On RSS there are two main points to deal with, the request latency and security of the system. This paper studied how the system latency and security are improved to obtain the needed values. The proposed RSS is a very secure program which have 4 security levels; authentication, authorization, RSA and CBC encryption system. Also, the encryption algorithms used in RSS are RSA and CBC block cipher encryption system. It is mixed way to prevent any attacker from breaking the cipher. First of all, RSA generates the public and private keys, and then CBC generates its Initialization vector and a random encryption key. Then a special function sends all of these keys encrypted with a pre-stored token in the data base and node memory which varied from node to another. Finally, node generates its private key from loaded public key. With this combination the speed of symmetric encryption system and the security of asymmetric encryption system can be achieved. On the other hand, the level of security firewalls needed to be Brocken by the attacker to brock the cipher is increased. The proposed system achieved low cost comparing with reported work; it is lower than Arduino + WIFI method by five times and 13 times lower than Raspberry-PI method. The proposed system is applied in educational systems, where it is used for teaching unlimited number of students Online.
C1 [Osman, Fawzy A.] Benha Univ, Fac Engn, Elect Engn Dept, Cairo, Egypt.
   [Hashem, Mohamed Y. M.; Eltokhy, Mostafa A. R.] Helwan Univ, Fac Technol & Educ, Elect Technol Dept, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Benha University; Egyptian Knowledge Bank
   (EKB); Helwan University
RP Osman, FA (corresponding author), Benha Univ, Fac Engn, Elect Engn Dept, Cairo, Egypt.
EM fawzi.osman@bhit.bu.edu.eg; m_yusuf7@yahoo.com;
   mostafaeltokhy2717@yahoo.com
OI A. Osman, Fawzy/0000-0003-2411-5606
FU Science, Technology & Innovation Funding Authority (STDF); The Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Aghenta LO, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080822
   Aghenta LO., 2019, P 2019 IEEE CAN C EL, P1, DOI DOI 10.1109/CCECE.2019.8861827
   Aniruddha S, 2017, 2 IEEE INT C EL COMP
   [Anonymous], 2016, IEEE INT C COMPUTATI
   Carlsson O, 2015, ENABLING LARGE IOT P
   Chang V, 2016, IEEE T SERV COMPUT, V9, P138, DOI [10.1109/ISSNIP.2015.7106910, 10.1109/TSC.2015.2491281]
   Chen Y, 2015, ZTE COMMUNICATIONS, V13, P33
   Cherdantseva Y, 2016, COMPUT SECUR, V56, P1, DOI 10.1016/j.cose.2015.09.009
   Church P, 2017, J CLOUD COMPUT-ADV S, V6, DOI 10.1186/s13677-017-0080-5
   El Mrabet Z, 2018, COMPUT ELECTR ENG, V67, P469, DOI 10.1016/j.compeleceng.2018.01.015
   ELEZI M, 2015, PROCEDIA SOCIAL BEHA, V195, P1938
   Gupta S.C., 2020, Malaya J. Matematik, V8, P1138
   Hashem M.Y.M., 2020, J. Eng. Res, V166, pELE15, DOI [10.21608/erj.2020.135262, DOI 10.21608/ERJ.2020.135262]
   Howard P., 2015, A Security Checklist for SCADA Systems in the Cloud
   Jayasinghe LS, 2017, CAN CON EL COMP EN
   Krishna BH, 2016, PROCEDIA COMPUT SCI, V87, P246, DOI 10.1016/j.procs.2016.05.156
   Long M, 2020, CMC-COMPUT MATER CON, V65, P1425, DOI 10.32604/cmc.2020.011116
   Merchán DF, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER SCIENCE (INCISCOS), P160, DOI 10.1109/INCISCOS.2017.9
   Mononen T, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P502, DOI 10.1109/ICCIS.2017.8274827
   Moustapha Fall C, IEEE ENHANCING SCADA
   Nazir S, 2017, COMPUT SECUR, V70, P436, DOI 10.1016/j.cose.2017.06.010
   Obaid TAS, 2020, EJERS EUR J ENG RES, V5
   Phuyal S., 2020, INT J ENG MANUFACTUR, V10, P15, DOI 10.5815/ijem.2020.02.02
   Phuyal S, 2019, INT S CURR RES HYDR, V9
   Polese A, 2018, INT LIBR HISTOR STUD, V111, P1
   Poomagal CT, 2020, COMPUT SYST SCI ENG, V35, P51
   Prokhorov AS, 2018, PROCEEDINGS OF THE 2018 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN ELECTRICAL AND ELECTRONIC ENGINEERING (EICONRUS), P220, DOI 10.1109/EIConRus.2018.8317069
   Sail S, 2017, T MACH LEARN ARTIF I, V5, P291, DOI [10.14738/tmlai.54, DOI 10.14738/TMLAI.54]
   Sajid A, 2016, IEEE ACCESS, V4, P1375, DOI 10.1109/ACCESS.2016.2549047
   [Цочев Георги Руменов Tsochev Georgi], 2020, [Труды СПИИРАН, Trudy SPIIRAN], V19, P358, DOI 10.15622/sp.2020.19.2.5
   Wang CJ, 2020, CMC-COMPUT MATER CON, V63, P1031, DOI 10.32604/cmc.2020.06278
   Yadav G, 2001, ARXIV02925V1CSCR
   Yu H, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020246
NR 33
TC 7
Z9 7
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9989
EP 10005
DI 10.1007/s11042-022-12130-9
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800012
OA hybrid
DA 2024-07-18
ER

PT J
AU Juang, LH
AF Juang, Li-Hong
TI Multi-target objects and complex color recognition model based on
   humanoid robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NAO robot; Visual detection technology; Multi-target objects; Complex
   color; Choregraphe
ID IMAGE; SEGMENTATION
AB This research mainly focuses on the humanoid robot's recognition model for the multiple targets and complex color. The purpose of this research is to apply visual detection technology on a humanoid robot and propose a real time image extraction method to enhance the robot's visual application like a human. The multi-target objects and complex color experiments for various geometric shapes were conducted using humanoid robot NAO. The main procedure of the humanoid robot performing the operation of the multiple targets and complex color is as follows: firstly, the image is acquired by the vision system mounted on the camera of the humanoid robot; secondly, the pixel position of the object point is obtained through the image processing; furthermore, the outer shape position is set for the humanoid robot and then the improvement is performed to let it become more efficiencies. These experimental results demonstrate it can successfully identify the target objects and their outer contour, and also through the learning function in the Choregraphe platform, it can learn more complex definitions on the outer contour such as bottle and book and their recognition. The superiority of the proposed work is that it can be for various complex conditions. In the three-dimensional environment, the visual system of the NAO robot was firstly used to perceive its surrounding environment, and then the image processing technology was used to identify the chess position. The first general remark is that this work can be conceived as a good technological/engineering achievement.
C1 [Juang, Li-Hong] Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
RP Juang, LH (corresponding author), Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
EM lipuu@qq.com
CR An der Wal, 2012, OBJECT GRASPING NAO
   Azad P, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5339, DOI 10.1109/IROS.2006.282094
   Burget F, 2013, IEEE INT CONF ROBOT, P1656, DOI 10.1109/ICRA.2013.6630792
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   De Xu, 2011, ROBOT VISUAL MEASURE
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   Fulop AO, 2018, IEEE INT CONF AUTO, DOI 10.1109/AQTR.2018.8402778
   Haffner O, 2014, 23 INT C ROB ALP ADR, P1
   Jenkins M, 2017, IEEE INT C INT ROBOT, P5162, DOI 10.1109/IROS.2017.8206404
   Jie, 2006, 3 DIMENSIONAL RECONS
   Kim W, 2017, IEEE INT C INT ROBOT, P6498, DOI 10.1109/IROS.2017.8206558
   Koniar D, 2017, ELECTR ENG, V99, P1349, DOI 10.1007/s00202-017-0609-0
   Koniar D, 2016, COMPUT METH PROG BIO, V127, P258, DOI 10.1016/j.cmpb.2015.12.009
   Le PH, 2017, IEEE INT C INT ROBOT, P4944, DOI 10.1109/IROS.2017.8206375
   Li Guodong, 2010, Journal of Southeast University (Natural Science Edition), V40, P30
   Louloudi A., 2010, Proceedings of the Swedish AI Society Workshop (SAIS). Linkoping Electronic Conference Proceedings, V48, P35
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Mellmann H, 2011, FUND INFORM, V112, P89, DOI 10.3233/FI-2011-580
   Mohaimin SM, 2018, IET IMAGE PROCESS, V12, P919, DOI 10.1049/iet-ipr.2017.0685
   Moughlbay AA, 2012, CONTR AUT ROB VIS IC, P1311
   Müller J, 2012, IEEE-RAS INT C HUMAN, P349, DOI 10.1109/HUMANOIDS.2012.6651543
   Okada K, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3223
   Pengcheng Z., 2015, BASED NAO ROBOT VISU
   Porzi L, 2017, IEEE ROBOT AUTOM LET, V2, P468, DOI 10.1109/LRA.2016.2637444
   Qiang, 2012, THESIS SHANDONG U
   Rehman Y, 2018, IET IMAGE PROCESS, V12, P2229, DOI 10.1049/iet-ipr.2018.5424
   Song Y, 2014, BIOSYST ENG, V118, P203, DOI 10.1016/j.biosystemseng.2013.12.008
   Sonka M., 2014, Image processing, analysis, and machine vision
   Tölgyessy M, 2017, INT J SOC ROBOT, V9, P509, DOI 10.1007/s12369-017-0408-9
   Wong SC, 2017, IEEE T IMAGE PROCESS, V26, P4669, DOI 10.1109/TIP.2017.2696744
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Yu H., 2012, 3 DIMENSIONAL RECONS
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao YH, 2017, IEEE INT C INT ROBOT, P6625, DOI 10.1109/IROS.2017.8206576
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 44
TC 0
Z9 0
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9645
EP 9669
DI 10.1007/s11042-022-11962-9
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000754145600001
DA 2024-07-18
ER

PT J
AU Alhaidery, MMA
   Taherinia, AH
   Yazdi, HS
AF Alhaidery, Manaf Mohammed Ali
   Taherinia, Amir Hossein
   Yazdi, Hadi Sadoghi
TI Cloning detection scheme based on linear and curvature scale space with
   new false positive removal filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy Move Forgery Detection (CMFD); SURF; MSER; Non-uniform
   transformation; Multi cloning; Random Sample Consensus (RANSAC)
ID COPY-MOVE FORGERY; LOCALIZATION; SYMMETRY; FEATURES
AB Recently, tampering in digital images considered the main challenge in image forensic analyses. Hence, copying a part and pasting it in the same image became the most crucial action in image forgery. It threatens the integrity and authenticity of image ownership. The intruder utilizes the development tools of image processing programs to make the forged image the same as the authentic one and strict for detection. This work as copy-move forgery detection (CMFD) manipulates the problem of a few key points in small-size and homogenous digital images by adopting a merging scheme to detects sufficient key points by using a linear scale-space detector based on Speedup Robust Feature(SURF) and curvature scale space detector based on Maximally Stable Extremal Region (MSER). Afterward, these key points are described distinctively by extract unique vectors, and matching these vectors to find duplicated regions. In the post-processing stage, we propose new filters, the first is called Parallel Filter and the other called Distance Ratio Filter. These Filters aim to remove false-positive results and boost true positive results thus improving the accuracy of the detection scheme. The experimental results on standard data sets (MICC 220, F8 Multi) show that CMFD is efficient and insensitive against simple and combination post-processing attacks like photometric and geometric transformations. Also, it is invariant against non-uniform transformation like (skew, wrap), and detects multi cloning efficiently with a high true-positive ratio (TPR=98.5) and low false-positive ratio (FPR=4).
C1 [Alhaidery, Manaf Mohammed Ali; Taherinia, Amir Hossein; Yazdi, Hadi Sadoghi] Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Taherinia, AH (corresponding author), Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
EM Manafma77@gmail.com; taherinia@um.ac.ir; h-sadoghi@um.ac.ir
RI Taherinia, Amir Hossein/HTP-1792-2023; Alhaidery, Manaf/KHD-1036-2024;
   Taherinia, Amir Hossein/AAC-9575-2020
OI Taherinia, Amir Hossein/0000-0002-5103-4812
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Al-Hammadi MM, 2016, IEEE INT SYM MULTIM, P341, DOI [10.1109/ISM.2016.91, 10.1109/ISM.2016.0075]
   Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2016, IMAGE FEATURES DETEC
   [Anonymous], 2012, INT J ADV COMPUTING
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Dixit Anuja, 2016, International Journal of Image, Graphics and Signal Processing, V8, P29, DOI 10.5815/ijigsp.2016.06.04
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Fan XH, 2012, APPL MECH MATER, V127, P115, DOI 10.4028/www.scientific.net/AMM.127.115
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Kaspi O, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0224-0
   Kucherov AS, 2011, RAST 2011 P 5 INT C, V365, P369
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Muzaffer G, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P688, DOI 10.1109/UBMK.2017.8093499
   Niyishaka P, 2020, MULTIMED TOOLS APPL, V79, P26045, DOI 10.1007/s11042-020-09225-6
   Sadeghi S, 2018, PATTERN ANAL APPL, V21, P291, DOI 10.1007/s10044-017-0678-8
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Vaishnavi D, 2019, J INF SECUR APPL, V44, P23, DOI 10.1016/j.jisa.2018.11.001
   Walia S, 2019, AUST J FORENSIC SCI, V51, P488, DOI 10.1080/00450618.2018.1424241
   Wang CY, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120706
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Yang HY, 2019, MULTIMED TOOLS APPL, V78, P34585, DOI 10.1007/s11042-019-08169-w
   Zhang WW, 2017, LECT NOTES COMPUT SC, V10082, P159, DOI 10.1007/978-3-319-53465-7_12
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6
NR 31
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8745
EP 8766
DI 10.1007/s11042-022-12237-z
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751584600006
DA 2024-07-18
ER

PT J
AU Prajapati, A
   Parashar, A
   Sunita
   Chhabra, JK
   Jain, CK
AF Prajapati, Amarjeet
   Parashar, Anshu
   Sunita
   Chhabra, Jitender Kumar
   Jain, Chakresh Kumar
TI Multimedia in search-based software engineering: challenges and
   opportunities within a new research domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Software analysis; Search-based software engineering;
   visualization; Representations; Search-based optimization
ID VISUALIZATION; MODULARIZATION; COMPREHENSION
AB Search-based software engineering (SBSE) is an emerging research sub-area in the field of software engineering. The concept of SBSE is based on the idea of formulation of software engineering problem as a search-based optimization problem and effective exploitation of metaheuristic search optimizers to solve it. The complex nature of software engineering problems and complex computational behaviour of the metaheuristic search algorithms makes the SBSE approaches challenging to understand and analyze. A variety of multimedia technologies are generally used to make the problem formulation and their computational method more understandable and analyzable. Even after wide application of multimedia in science and engineering, the SBSE got little attention in this direction. To explore and exploit the potential of the multimedia in the SBSE, this work first conducted a research study on the current trends of multimedia in SBSE, then based on this study, the various challenges and opportunities are presented. More specifically, our work mainly focusses on current multimedia trends in various forms of SBSE approaches (e.g., single, multi, and many-objective SBSE). Apart from that, we also explore the various opportunities and challenges in SBSE from the perspective of visualization of software artefacts, software quality metrics, problem formulation, search trajectory, Pareto optimal set and front.
C1 [Prajapati, Amarjeet; Jain, Chakresh Kumar] JIIT, Noida, India.
   [Parashar, Anshu] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Sunita] CCET, Chandigarh, India.
   [Chhabra, Jitender Kumar] NIT, Kurukshetra, Haryana, India.
C3 Jaypee Institute of Information Technology (JIIT); Thapar Institute of
   Engineering & Technology; National Institute of Technology (NIT System);
   National Institute of Technology Kurukshetra
RP Parashar, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM amarjeetnitkkr@gmail.com; aparashar@thapar.edu; sunita@ccet.ac.in;
   jitenderchhabra@gmail.com; ckj522@yahoo.com
RI Chhabra, Jitender Kumar/A-1026-2016
OI Chhabra, Jitender Kumar/0000-0002-2257-0982
CR Amarjeet, 2018, J INTELL SYST, V27, P619, DOI 10.1515/jisys-2016-0253
   Amarjeet, 2018, COMPUT LANG SYST STR, V51, P1, DOI 10.1016/j.cl.2017.08.001
   Amarjeet, 2017, COMPUT LANG SYST STR, V47, P153, DOI 10.1016/j.cl.2016.09.003
   Amarjeet, 2014, INT CONF CONTEMP, P206, DOI 10.1109/IC3.2014.6897174
   Anslow C, 2006, P WORKSH X3D EARTH R
   Anslow C, 2006, P ACM SIGPLAN S OBJ, P655
   Barros MD, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1205, DOI 10.1145/2330163.2330330
   Dos Santos CR, 2000, IEEE INFOR VIS, P379, DOI 10.1109/IV.2000.859785
   Doval D., 1999, STEP '99. Proceedings Ninth International Workshop Software Technology and Engineering Practice, P73, DOI 10.1109/STEP.1999.798481
   Fittkau F, 2017, INFORM SOFTWARE TECH, V87, P259, DOI 10.1016/j.infsof.2016.07.004
   Halim S, 2005, P MET INT C AUG 22 2, P630
   Halim S, 2006, FRONT ARTIF INTEL AP, V141, P703
   Harman M, 2001, INFORM SOFTWARE TECH, V43, P833, DOI 10.1016/S0950-5849(01)00189-6
   Harman M, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P1029
   Harman M, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379787
   Hasselbring W, 2020, SOFTW IMPACTS, V6, DOI 10.1016/j.simpa.2020.100034
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Huang JH, 2016, INFORM SCIENCES, V342, P96, DOI 10.1016/j.ins.2016.01.030
   Ibrahim A, 2018, SWARM EVOL COMPUT, V39, P157, DOI 10.1016/j.swevo.2017.09.011
   Ibrahim A, 2016, IEEE C EVOL COMPUTAT, P736, DOI 10.1109/CEC.2016.7743865
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Jalali NS, 2019, SOFT COMPUT, V23, P11141, DOI 10.1007/s00500-018-3666-z
   Kadluczka M, 2004, PROC INT C TOOLS ART, P508
   Khaloo P, 2017, 2017 IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT 2017), P43, DOI 10.1109/VISSOFT.2017.10
   Knight C, 1999, PROG COMPREHEN, P4, DOI 10.1109/WPC.1999.777733
   Kohonen T. K., 2001, SELF ORG MAPS, V3rd ed.
   Kot B., 2005, 6 ACM SIGGHI NZ CHAP, P53, DOI [DOI 10.1145/1073943.1073954, 10.1145]
   Kumari AC, 2016, J SYST SOFTWARE, V117, P384, DOI 10.1016/j.jss.2016.04.007
   Mahdavi K, 2003, PROC IEEE INT CONF S, P315, DOI 10.1109/ICSM.2003.1235437
   Mancoridis S, 1998, PROG COMPREHEN, P45, DOI 10.1109/WPC.1998.693283
   Merino L, 2018, 2018 SIXTH IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P54, DOI 10.1109/VISSOFT.2018.00014
   Mitchell BS, 2006, IEEE T SOFTWARE ENG, V32, P193, DOI 10.1109/TSE.2006.31
   Mkaouer W, 2015, ACM T SOFTW ENG METH, V24, DOI 10.1145/2729974
   Murray P, 2014, IEEE CONF VIS ANAL, P261, DOI 10.1109/VAST.2014.7042520
   Panas T, 2003, IEEE INFOR VIS, P314, DOI 10.1109/IV.2003.1217996
   Parashar A, 2017, NATL ACAD SCI LETT, V40, P21, DOI 10.1007/s40009-016-0472-y
   Perez J., 2013, INT J EMERGING TECHN, V3, P32
   Pourasghar B, 2021, INFORM SOFTWARE TECH, V133, DOI 10.1016/j.infsof.2020.106469
   Praditwong K, 2011, IEEE T SOFTWARE ENG, V37, P264, DOI 10.1109/TSE.2010.26
   Prajapati A, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8111906
   Prajapati A, 2019, COMPUT INTELL-US, V35, P98, DOI 10.1111/coin.12193
   Prajapati A, 2016, LECT NOTES COMPUT SC, V9734, P296, DOI 10.1007/978-3-319-40349-6_28
   Ramirez A, 2019, J SYST SOFTWARE, V149, P382, DOI 10.1016/j.jss.2018.12.015
   Vincur J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P509, DOI 10.1109/QRS-C.2017.88
NR 44
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35671
EP 35691
DI 10.1007/s11042-021-11882-0
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000749966800009
DA 2024-07-18
ER

PT J
AU Li, HT
   Liu, YP
   Chang, YK
   Chiang, CK
AF Li, Hao-Ting
   Liu, Yung-Pin
   Chang, Yun-Kai
   Chiang, Chen-Kuo
TI Action recognition and tracking via deep representation extraction and
   motion bases learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Motion bases; Action tracking; Deep learning
ID BIDIRECTIONAL LSTM
AB Action recognition and positional tracking are critical issues in many applications in Virtual Reality (VR). In this paper, a novel feature representation method is proposed to recognize actions based on sensor signals. The feature extraction is achieved by jointly learning Convolutional Auto-Encoder (CAE) and the representation of motion bases via clustering, which is called the Sequence of Cluster Centroids (SoCC). Then, the learned features are used to train the action recognition classifier. We have collected new dataset of actions of limbs by sensor signals. In addition, a novel action tracking method is proposed for the VR environment. It extends the sensor signals from three Degrees of Freedom (DoF) of rotation to 6DoF of position plus rotation. Experimental results demonstrate that CAE-SoCC feature is effective for action recognition and accurate prediction of position displacement.
C1 [Li, Hao-Ting; Liu, Yung-Pin; Chang, Yun-Kai; Chiang, Chen-Kuo] Natl Chung Cheng Univ, Adv Inst Mfg High Tech Innovat, Dept Comp Sci & Informat Engn, 168,Sec 1,Univ Rd, Chiayi 621301, Taiwan.
   [Li, Hao-Ting; Liu, Yung-Pin; Chang, Yun-Kai; Chiang, Chen-Kuo] Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, 168,Sec 1,Univ Rd, Chiayi 621301, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University
RP Chiang, CK (corresponding author), Natl Chung Cheng Univ, Adv Inst Mfg High Tech Innovat, Dept Comp Sci & Informat Engn, 168,Sec 1,Univ Rd, Chiayi 621301, Taiwan.; Chiang, CK (corresponding author), Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, 168,Sec 1,Univ Rd, Chiayi 621301, Taiwan.
EM lht107p@cs.ccu.edu.tw; ping8tw@gmail.com; tony091520933@gmail.com;
   ckchiang@cs.ccu.edu.tw
FU Ministry of Science and Technology [109-2218-E-194-009]; Advanced
   Institute of Manufacturing with Hightech Innovations; Center for
   Innovative Research on Aging Society (CIRAS) from The Featured Areas
   Research Center Program within Ministry of Education (MOE) in Taiwan
FX This work was supported by the Advanced Institute of Manufacturing with
   Hightech Innovations and Center for Innovative Research on Aging Society
   (CIRAS) from The Featured Areas Research Center Program within the
   framework of the Higher Education Sprout Project by Ministry of
   Education (MOE) in Taiwan. It was also supported by Ministry of Science
   and Technology under the grant 109-2218-E-194-009.
CR Bai S., 2018, CoRR
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chavarriaga R, 2013, PATTERN RECOGN LETT, V34, P2033, DOI 10.1016/j.patrec.2012.12.014
   Chen CH, 2018, AAAI CONF ARTIF INTE, P6468
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Garcia FA, 2019, 2019 LATIN AMERICAN ROBOTICS SYMPOSIUM, 2019 BRAZILIAN SYMPOSIUM ON ROBOTICS (SBR) AND 2019 WORKSHOP ON ROBOTICS IN EDUCATION (LARS-SBR-WRE 2019), P121, DOI 10.1109/LARS-SBR-WRE48964.2019.00029
   Jaouedi N, 2020, J KING SAUD UNIV-COM, V32, P447, DOI 10.1016/j.jksuci.2019.09.004
   Jegham I, 2020, FORENS SCI INT-DIGIT, V32, DOI 10.1016/j.fsidi.2019.200901
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Kapoor J, 2017, 2017 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN COMPUTING AND COMMUNICATION TECHNOLOGIES (ICETCCT), P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020679
   Liu J, 2017, P IEEE C COMPUTER VI
   Ma SG, 2016, PROC CVPR IEEE, P1942, DOI 10.1109/CVPR.2016.214
   Nafea O, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062141
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qian HW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5614
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Saker M, 2019, NEW MEDIA SOC, V21, P214, DOI 10.1177/1461444818792407
   Simonyan K, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   van Hees VT, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061691
   Wang LK, 2020, CIRC SYST SIGNAL PR, V39, P837, DOI 10.1007/s00034-019-01116-y
   Yang J, 2015, IEEE IJCNN
   Zhang Y, 2017, IEEE I CONF COMP VIS, P2116, DOI 10.1109/ICCV.2017.231
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zhu AC, 2020, NEUROCOMPUTING, V414, P90, DOI 10.1016/j.neucom.2020.07.068
NR 34
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11845
EP 11864
DI 10.1007/s11042-021-11888-8
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000745425000001
DA 2024-07-18
ER

PT J
AU Othman, MK
   Ong, LW
   Aman, S
AF Othman, Mohd Kamal
   Ong, Lay Wan
   Aman, Shaziti
TI Expert vs novice collaborative heuristic evaluation (CHE) of a
   smartphone app for cultural heritage sites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative heuristic evaluation; Cultural heritage site; Expert;
   Heuristics; Novice; Smartphone app
ID USABILITY EVALUATION
AB This study was conducted to compare CHE between Human-Computer Interaction (HCI) experts and novices in evaluating the Smartphone app for the cultural heritage site. It uses the Smartphone Mobile Application heuRisTics (SMART), focusing on smartphone applications and traditional Nielsen heuristics, focusing on a wider range of interactive systems. Six experts and six novices used the severity rating scale to categorise the severity of the usability issues. These issues were mapped to both heuristics. The study found that experts and novice evaluators identified 19 and 14 usability issues, respectively, with ten as the same usability issues. However, these same usability issues have been rated differently. Although the t-test indicates no significant differences between experts and novices in their ratings for usability issues, these results nevertheless indicate the need for both evaluators in CHE to provide a more comprehensive perspective on the severity of the usability issues. Furthermore, the mapping of the usability issues for Nielsen and SMART heuristics concluded that more issues with the smartphone app could be addressed through smartphone-specific heuristics than general heuristics, indicating a better tool for heuristic evaluation of the smartphone app. This study also provides new insight into the required number of evaluators needed for CHE.
C1 [Othman, Mohd Kamal; Ong, Lay Wan; Aman, Shaziti] Univ Malaysia Sarawak, Fac Cognit Sci & Human Dev, Sarawak, Malaysia.
C3 University of Malaysia Sarawak
RP Othman, MK (corresponding author), Univ Malaysia Sarawak, Fac Cognit Sci & Human Dev, Sarawak, Malaysia.
EM omkamal@unimas.my
RI OTHMAN, MOHD KAMAL/R-1644-2018
OI OTHMAN, MOHD KAMAL/0000-0001-5401-2515
FU Universiti Malaysia Sarawak; Universiti Malaysia Sarawak under SpMYRA
FX This work was supported by Universiti Malaysia Sarawak under Short Grant
   Scheme and SpMYRA.
CR ADELSON B, 1984, J EXP PSYCHOL LEARN, V10, P483, DOI 10.1037/0278-7393.10.3.483
   Aljohani M., 2015, INT C DESIGN USER EX, P119
   Alsumait Asmaa, 2010, Journal of Software, V5, P654, DOI 10.4304/jsw.5.6.654-661
   ANDERSON J, 1982, AM QUART, V34, P290, DOI 10.2307/2712780
   Babajo, 2012, THESIS YORK U YORK
   Bertini E., 2006, Methodology, P119, DOI DOI 10.1145/1133265.1133291
   Broin, 2011, HEURISTIC EVALUATION
   Cejka J, 2020, PERS UBIQUIT COMPUT, V24, P815, DOI 10.1007/s00779-019-01354-6
   Chen WQ, 2014, PROCEDIA COMPUT SCI, V35, P979, DOI 10.1016/j.procs.2014.08.180
   Chung N, 2015, COMPUT HUM BEHAV, V50, P588, DOI 10.1016/j.chb.2015.02.068
   Dieck MCT, 2018, CURR ISSUES TOUR, V21, P154, DOI 10.1080/13683500.2015.1070801
   Economou M., 2011, Promising beginnings? Evaluating museum mobile phone apps, P26
   Galatis P., 2016, P MOBICASE16 P 8 EAI, P11
   Georgsson M, 2014, STUD HEALTH TECHNOL, V205, P930, DOI 10.3233/978-1-61499-432-9-930
   Hausmann A., 2015, Int. J. Cult. Digit. Tour, V2, P19
   Helyar V, 2001, USABILITY ISSUES USE
   Herr S, 2016, CHI EA 16 P 2016 CHI, P3069, DOI [10.1145/2851581.2892454, DOI 10.1145/2851581.2892454]
   Hiramatsu Y., 2017, International Journal of Social and Business Sciences, V11, P121
   Hvannberg ET, 2007, INTERACT COMPUT, V19, P225, DOI 10.1016/j.intcom.2006.10.001
   Hwang W, 2010, COMMUN ACM, V53, P130, DOI 10.1145/1735223.1735255
   Inostroza R., 2012, Proceedings of the 2012 Ninth International Conference on Information Technology: New Generations (ITNG), P662, DOI 10.1109/ITNG.2012.134
   Inostroza R, 2016, COMPUT STAND INTER, V43, P40, DOI 10.1016/j.csi.2015.08.007
   Jeffries R., 1992, SIGCHI Bulletin, V24, P39, DOI 10.1145/142167.142179
   Joyce Ger, 2015, Design, User Experience and Usability: Users and Interactions. 4th International Conference, DUXU 2015, held as part of HCI International 2015. Proceedings LNCS 9187, P541, DOI 10.1007/978-3-319-20898-5_52
   Joyce G., 2014, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), V8517, P465, DOI DOI 10.1007/978-3-319-07668-3_45
   Kessner Martin, 2001, C HUM FACT COMP SYST, P97
   Kjeldskov J, 2005, BEHAV INFORM TECHNOL, V24, P51, DOI 10.1080/01449290512331319030
   Kjeldskov J, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P43, DOI 10.1145/2628363.2628398
   Kuflik T., 2011, Proceedings of the 16th international conference on Intelligent user interfaces, P375, DOI DOI 10.1145/1943403.1943469
   Kuparinen L, 2013, P 26 INT CART C
   Law E., 2004, P 3 NORD C HUM COMP, P241, DOI DOI 10.1145/1028014.1028051
   Lockwood LA., 2003, PRO FORUSE, P253
   McGookin DK, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188504
   Molich R, 2008, BEHAV INFORM TECHNOL, V27, P263, DOI 10.1080/01449290600959062
   Moreno De Sousa J.C., 2020, PLEISTOCENE ARCHAEOL, DOI [10.5772/intechopen.89154, DOI 10.5772/INTECHOPEN.89154]
   Neil T., 2014, Mobile design pattern gallery: UI patterns for smartphone apps
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Nielsen J, 1990, Proceedings ACM CHI'90 Conf, DOI [DOI 10.1145/97243.97281, 10.1145/97243.97281]
   Nielsen J., 1992, Conference companion, DOI DOI 10.1145/142750.142834
   Nielsen J., 1992, Posters and short talks of the 1992 SIGCHI conference on Human factors in computing systems, P129, DOI DOI 10.1145/1125021.1125117
   Nielsen Jakob, 1994, USABILITY INSPECTION, P413, DOI [10.1145/259963.260531, DOI 10.1145/259963.260531]
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/502007
   Othman MK., 2012, THESIS YORK U YORK
   Othman MK, 2014, INT CONF USER SCI, P232, DOI 10.1109/IUSER.2014.7002708
   Othman MK, 2011, LECT NOTES COMPUT SC, V6949, P92, DOI 10.1007/978-3-642-23768-3_8
   Park H, 2018, LECT NOTES COMPUT SC, V10905, P167, DOI 10.1007/978-3-319-92046-7_15
   Petrie H., 2010, P UPA 2010 INT C
   Petrie H., 2012, P SIGCHI C HUMAN FAC, P2107, DOI DOI 10.1145/2207676.2208363
   Proctor, P MUS WEB 2010
   Reynaga G, 2015, BRITISH HCI 2015, P126, DOI 10.1145/2783446.2783583
   Sabra JB, 2015, 2015 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE COMPUTING), P167, DOI 10.1109/Culture.and.Computing.2015.16
   Salazar L. H. A., 2012, COMPANION P 11 BRAZI, P37
   Salgado AD, 2014, LECT NOTES COMPUT SC, V8512, P178, DOI 10.1007/978-3-319-07227-2_18
   Sauro J, 2012, VALUE MULTIPLE EVALU
   Smirnov A., 2013, LNCS, P94
   Spool J., 2001, CHI 01 EXTENDED ABST, P285, DOI 10.1145/634067.634236
   Sylaiou S., 2008, Computers in Entertainment, V6, P1, DOI DOI 10.1145/1371216.1371226
   Tallon Loic., 2008, Digital Technologies and the Museum Experience: Handheld Guides and Other Media, pxiii
   Tan, 2003, THESIS U NEBRASKA LI
   Tan JJY., 2014, P INT C ADV DES RES, DOI [10.3850/978-981-09-1348-9_041, DOI 10.3850/978-981-09-1348-9_041]
   Tan WS, 2009, INT J IND ERGONOM, V39, P621, DOI 10.1016/j.ergon.2008.02.012
   Tehrani SEM, 2014, INT CONF USER SCI, P227, DOI 10.1109/IUSER.2014.7002707
   Vithani Tejas, 2014, International MultiConference of Computer Scientists (IMEC 2014). Proceedings, P596
   Wecker Alan J., 2017, P 22 INT C INT US IN, P153, DOI DOI 10.1145/3030024.3040980
   Zhang WJ, 2020, ACM T HUM-ROBOT INTE, V9, DOI 10.1145/3368943
NR 65
TC 4
Z9 5
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6923
EP 6942
DI 10.1007/s11042-022-11991-4
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000744767900004
DA 2024-07-18
ER

PT J
AU Liu, ZB
   Yuan, L
   Sun, L
AF Liu, Zhenbing
   Yuan, Lu
   Sun, Long
TI Frequency separation-based multi-scale cascading residual block network
   for image super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Frequency separation; Multi-scale; Attention mechanism; Cascading
   residual; Image super-resolution
AB Deep Convolutional Neural Network (CNN) has recently obtained remarkable achievements in single image super-resolution (SISR). Whereas, these existing methods are usually associated with abundant parameters or computational complexity, which highly limits the real-time application. To solve this problem, we propose a lightweight network named FSCRNet. In general, the proposed network consists of three parts: division schema, feature extraction block, and reconstruction block. Specifically, we decouple the image into two parts: content features and detail features, and then perform different operations separately. Concretely, for detailed features, by combining multi-scale strategy and cascading residual block (MSCRB), the model can explore features and propagate messages efficiently. Also, we introduce channel attention to enhance high-frequency feature representation ability. We use a content feature module (CFM) for content features, consisting of asymmetric convolutions to fetch the tensor elements from the horizontal and vertical directions. We demonstrate that the proposed method with few parameters performs favorably on the benchmarks in quantitative and qualitative results.
EM zbliu@guet.edu.cn
RI yuan, luhao/GWM-4451-2022
FU Innovation Project of National Natural Science Foundation of China
   [61866009]; Guet Graduate Education [2020YCXS055]
FX This work was supported in part by the Innovation Project of National
   Natural Science Foundation of China under grants (61866009), Guet
   Graduate Education(2020YCXS055).
CR Alkanha L, 2020, INT J ADV COMPUTER E, V11
   [Anonymous], 2017, PROC IEEE C COMPUT V
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gao S, 2019, CORR
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Izonin Ivan, 2015, 2015 Xth International Scientific and Technical Conference - Computer Sciences and Information Technologies (CSIT). Proceedings, P25, DOI 10.1109/STC-CSIT.2015.7325423
   Kim J, 2015, CORR
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   Kingma D. P, 2015, International Conference on Learning Representations
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Peleshko Dmytro, 2016, International Journal of Intelligent Systems and Applications, V8, P1, DOI 10.5815/ijisa.2016.12.01
   Peleshko D, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P235, DOI 10.1109/DSMP.2016.7583548
   Rashkevych Y, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P944, DOI 10.1109/UKRCON.2017.8100390
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi Wuzhen, 2017, ABS170707128 CORR
   Song TA, 2020, NEURAL NETWORKS, V125, P83, DOI 10.1016/j.neunet.2020.01.029
   Song XB, 2020, PROC CVPR IEEE, P5630, DOI 10.1109/CVPR42600.2020.00567
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Ye C, 2019, ABS190511926 CORR
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang M, 2019, CRNET IMAGE SUPER RE
   Zhang Y, 2018, CORR
   Zhang Y, 2020, IEEE INT CONF SENS, DOI 10.1109/secon48991.2020.9158410
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 41
TC 4
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6827
EP 6848
DI 10.1007/s11042-021-11724-z
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000743863400001
DA 2024-07-18
ER

PT J
AU Rajesh, B
   Javed, M
   Nagabhushan, P
AF Rajesh, Bulla
   Javed, Mohammed
   Nagabhushan, P.
TI FastSS: Fast and smooth segmentation of JPEG compressed printed text
   documents using DC and AC signal analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document Image processing; JPEG compressed domain; Printed text-line
   segmentation; Printed word segmentation; DCT coefficients
ID IMAGE SEGMENTATION; LINE EXTRACTION; SCHEME
AB With the surge of COVID-19 pandemic, the world is moving towards digitization and automation more than it was presumed. The Internet is becoming one of the popular mediums for communication, and multimedia (image, audio, and video) combined with data compression techniques play a pivotal role in handling a huge volume of data that is being generated on a daily basis. Developing novel algorithms for automatic analysis of compressed data without decompression is the need of the present hour. JPEG is a popular compression algorithm supported in the digital electronics world that achieves compression by dividing the whole image into non-overlapping blocks of 8 x 8 pixels, and subsequently transforming each block using Discrete Cosine Transform (DCT). This research paper proposes to carry out Fast and Smooth Segmentation (FastSS) directly in JPEG compressed printed text document images at text-line and word-level using DC and AC signals. From each 8 x 8 block, DC and AC signals are analyzed for accomplishing Fast and Smooth segmentation, and subsequently, two Faster segmentation (MFastSS) algorithms are also devised using low resolution-images generated by mapping the DC signal (DC Reduced Image) and encoded DCT (ECM Image) coefficients separately. Proposed models are tested on various JPEG compressed printed text document images created with varied space and fonts. The experimental results have demonstrated that the direct analysis of compressed streams is computationally efficient, and has achieved speed gain more than 90% when compared to uncompressed domains.
C1 [Rajesh, Bulla; Javed, Mohammed; Nagabhushan, P.] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, UP, India.
C3 Indian Institute of Information Technology Allahabad
RP Javed, M (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, UP, India.
EM rajesh091106@gmail.com; javed@iiita.ac.in; pnagabhushan@iiita.ac.in
RI Javed, Mohammed/HKE-5354-2023
OI Javed, Mohammed/0000-0002-3019-7401
CR Alaei A, 2011, PATTERN RECOGN, V44, P917, DOI 10.1016/j.patcog.2010.10.014
   Amarnath R., 2018, IJISAE, V6, P251, DOI [10.18201/ijisae.2018448451, DOI 10.18201/IJISAE.2018448451]
   Arivazhagan M, 2007, PROC SPIE, V6500, DOI 10.1117/12.704538
   Bhowmik S, 2018, INT J DOC ANAL RECOG, V21, P1, DOI 10.1007/s10032-018-0296-z
   Boulid Y, 2015, INT CONF INTELL SYST, P80, DOI 10.1109/ISDA.2015.7489204
   Chebil F, 2005, IEEE T CONSUM ELECTR, V51, P710, DOI 10.1109/TCE.2005.1468023
   Das D, 2020, IET IMAGE PROCESS, V14, P1794, DOI 10.1049/iet-ipr.2019.1398
   de Queiroz RL, 1998, J ELECTRON IMAGING, V7, P367, DOI 10.1117/1.482607
   Fernández-Mota D, 2014, INT J DOC ANAL RECOG, V17, P293, DOI 10.1007/s10032-014-0220-0
   Florea C, 2013, ADV ENG FORUM, V8-9, P480, DOI 10.4028/www.scientific.net/AEF.8-9.480
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Giotis AP, 2017, PATTERN RECOGN, V68, P310, DOI 10.1016/j.patcog.2017.02.023
   Gueguen L, 2018, ADV NEUR IN, V31
   Hopkins M, 2018, IEEE DATA COMPR CONF, P412, DOI 10.1109/DCC.2018.00065
   Hsi-Chin Hsin, 2011, Proceedings of the 2011 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR 2011), P24, DOI 10.1109/ICWAPR.2011.6014466
   Javed M, 2019, J INTELL FUZZY SYST, V36, P541, DOI 10.3233/JIFS-18859
   Javed M, 2018, ARTIF INTELL REV, V50, P539, DOI 10.1007/s10462-017-9551-9
   Javed M, 2015, PROC INT CONF DOC, P216, DOI 10.1109/ICDAR.2015.7333755
   Javed M, 2013, NAT CONF COMPUT VIS
   Kasturi R, 2002, SADHANA-ACAD P ENG S, V27, P3, DOI 10.1007/BF02703309
   Kidwai NR, 2016, IEEE SENS J, V16, P2575, DOI 10.1109/JSEN.2016.2519600
   Kiumarsi E, 2018, INT CONF FRONT HAND, P241, DOI 10.1109/ICFHR-2018.2018.00050
   Kumar S, 2007, IEEE T IMAGE PROCESS, V16, P2117, DOI 10.1109/TIP.2007.900098
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Lu Y, 2003, PATTERN RECOGN, V36, P987, DOI 10.1016/S0031-3203(02)00127-9
   Mukhopadhyay J, 2011, IMAGE AND VIDEO PROCESSING IN THE COMPRESSED DOMAIN, P1, DOI 10.1201/b10797
   Papavassiliou V, 2010, PATTERN RECOGN, V43, P369, DOI 10.1016/j.patcog.2009.05.007
   Vo QN, 2016, IEEE IMAGE PROC, P3264, DOI 10.1109/ICIP.2016.7532963
   Rajesh Bulla, 2019, 2019 IEEE 8th Global Conference on Consumer Electronics (GCCE), P1067, DOI 10.1109/GCCE46687.2019.9015518
   Rajesh B, 2020, IET IMAGE PROCESS, V14, P1909, DOI 10.1049/iet-ipr.2019.1437
   Renton G, 2018, INT J DOC ANAL RECOG, V21, P177, DOI 10.1007/s10032-018-0304-3
   Retraint F, 2020, DIGIT SIGNAL PROCESS, V103, DOI 10.1016/j.dsp.2020.102759
   Ryu J, 2014, IEEE SIGNAL PROC LET, V21, P1115, DOI 10.1109/LSP.2014.2325940
   Shen B, 1996, P SOC PHOTO-OPT INS, V2670, P404, DOI 10.1117/12.234779
   Shen B, 1996, J VIS COMMUN IMAGE R, V7, P411, DOI 10.1006/jvci.1996.0035
   SMITH BC, 1993, IEEE COMPUT GRAPH, V13, P34, DOI 10.1109/38.232097
   Song Q, 2018, IEEE DATA COMPR CONF, P97, DOI 10.1109/DCC.2018.00018
   Tausif M, 2020, IEEE SENS J, V20, P6863, DOI 10.1109/JSEN.2019.2930006
   Tausif M, 2015, IEEE SENS J, V15, P6218, DOI 10.1109/JSEN.2015.2456332
   Tompkins D. A. D., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P224, DOI 10.1109/ICIP.1999.821602
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Yanikoglu B, 1998, PATTERN RECOGN, V31, P1825, DOI 10.1016/S0031-3203(98)00081-8
   Yousfi Y, 2020, IEEE SIGNAL PROC LET, V27, P830, DOI 10.1109/LSP.2020.2993959
   Zhang YH, 2018, IEEE DATA COMPR CONF, P207, DOI 10.1109/DCC.2018.00029
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
   Zhu N, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091119
NR 46
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8855
EP 8881
DI 10.1007/s11042-021-11858-0
EA JAN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000743891900003
PM 35068992
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Lu, T
   Wang, Y
   Xu, RB
   Liu, W
   Fang, WH
   Zhang, YD
AF Lu, Tao
   Wang, Yu
   Xu, Ruobo
   Liu, Wei
   Fang, Wenhua
   Zhang, Yanduo
TI Deep representation learning for face hallucination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep representation; Deep dictionary updating; Residual recursive
   learning; Local and nonlocal patches
ID SUPERRESOLUTION; NETWORK; LIMITS
AB Recently, deep learning, as a novel emerging algorithm, offers an end-to-end effective paradigm for super-resolution. Various successful practices with the deep learning model have confirmed the truth that deeper features always bring better performance. In this paper, we present a novel deep representation learning framework for face hallucination to verify the "coarse-to-fine" nature of deep features. The proposed framework includes the optimization of deep representation coefficients and the updating of deep dictionary learning. First, local and nonlocal patches are used to enrich the self-similarity prior to local to global optimization. Then a unified regularization term is added into the representation objective function to fully exploit accurate prior. Deeply coupled multi-layer dictionaries are developed to support the deep representation scheme as refining the high-resolution image from coarse to fine layer-by-layer. Finally, residual recursive learning is combined into a deep representation framework for boosting the reconstruction performances. Different from neural network's deep feature learning manner, the proposed method provides a novel explanation of how deep representation works. Extensive experiments are conducted on FEI, CAS-PEAL-R1, and LFW databases to testify its subjective and objective performance. Experimental results demonstrate that the proposed approach outperforms some state-of-the-art face hallucination methods, including the method based on convolution neural network and the method based on vanilla representation.
C1 [Lu, Tao; Wang, Yu; Liu, Wei; Fang, Wenhua; Zhang, Yanduo] Sch Comp Sci & Engn, Wuhan Inst Technol, Hubei Prov Key Lab Intelligent Robot, Wuhan 430205, Peoples R China.
   [Wang, Yu] Jingchu Univ Technol, Sch Gen Aviat, Jingmen 448000, Peoples R China.
   [Xu, Ruobo] Jiangsu Vocat Coll Informat Technol, Sch IoT Engn, Sch Informat Secur, Wuxi 214153, Jiangsu, Peoples R China.
C3 Wuhan Institute of Technology; Jingchu University of Technology; Jiangsu
   Vocational College of Information Technology
RP Lu, T (corresponding author), Sch Comp Sci & Engn, Wuhan Inst Technol, Hubei Prov Key Lab Intelligent Robot, Wuhan 430205, Peoples R China.
RI li, zhang/JHV-1750-2023; Liu, Song/KCX-6842-2024; Wang,
   Peilin/JWP-6008-2024; zheng, xin/JNS-5523-2023; xu,
   lingzhi/JVZ-8748-2024; Zhang, Yihao/JGM-3514-2023; Cheng,
   Yuan/JKJ-0794-2023
FU National Natural Science Foundation of China [62072350, 62171328]; Hubei
   Technology Innovation Project [2019AAA045]; Central Government Guides
   Local Science and Technology Development Special Projects [2018ZYYD059];
   High value Intellectual Property Cultivation Project of Hubei Province;
   Enterprise Technology Innovation Project of Wuhan [202001602011971];
   Opening Fund of Hubei key Laboratory of Intelligent Robot [HBIR202103]
FX This work is supported by the National Natural Science Foundation of
   China (62072350, 62171328), Hubei Technology Innovation Project
   (2019AAA045), the Central Government Guides Local Science and Technology
   Development Special Projects (2018ZYYD059), the High value Intellectual
   Property Cultivation Project of Hubei Province, the Enterprise
   Technology Innovation Project of Wuhan(202001602011971), the Opening
   Fund of Hubei key Laboratory of Intelligent Robot (HBIR202103).
CR Aberdam A, 2018, ABS180409788 CORR
   [Anonymous], 2008, WORKSH FACES REAL LI
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Brahma PP, 2016, IEEE T NEUR NET LEAR, V27, P1997, DOI 10.1109/TNNLS.2015.2496947
   Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019
   Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Choi JS, 2017, IEEE T IMAGE PROCESS, V26, P1300, DOI 10.1109/TIP.2017.2651411
   Doicu, 2010, TIKHONOV REGULARIZAT
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Farrugia RA, 2017, IEEE T IMAGE PROCESS, V26, P4562, DOI 10.1109/TIP.2017.2717181
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Gao GW, 2016, IEEE ACCESS, V4, P8775, DOI 10.1109/ACCESS.2016.2633281
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Hu YT, 2016, IEEE T IMAGE PROCESS, V25, P4091, DOI 10.1109/TIP.2016.2580942
   Huang JJ, 2017, IEEE T CIRC SYST VID, V27, P937, DOI 10.1109/TCSVT.2015.2513661
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Jiang JJ, 2016, INFORM SCIENCES, V367, P354, DOI 10.1016/j.ins.2016.05.032
   Jiang JJ, 2014, IEEE T IMAGE PROCESS, V23, P4220, DOI 10.1109/TIP.2014.2347201
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jung CK, 2011, IEEE SIGNAL PROC LET, V18, P367, DOI 10.1109/LSP.2011.2140370
   Junjun Jiang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P212, DOI 10.1109/ICME.2012.152
   Kim J, 2016, THE IEEE C COMPUTER
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim J, 2021, NEUROCOMPUTING, V446, P11, DOI 10.1016/j.neucom.2021.03.048
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P48, DOI 10.1109/LGRS.2014.2325978
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643
   Lu Tiantao., 2013, 3D SYSTEMS INTEGRATI, P1, DOI DOI 10.1109/VCIP.2013.6706354
   Ma X, 2015, IEEE T HUM-MACH SYST, V45, P238, DOI 10.1109/THMS.2014.2375329
   Ma X, 2012, SIGNAL PROCESS, V92, P2066, DOI 10.1016/j.sigpro.2012.01.018
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shao ZF, 2019, IEEE J-STARS, V12, P2663, DOI 10.1109/JSTARS.2019.2925456
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Song YB, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4537
   Sulam J, 2018, IEEE T SIGNAL PROCES, V66, P4090, DOI 10.1109/TSP.2018.2846226
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang ZY, 2014, IEEE T CIRC SYST VID, V24, P802, DOI 10.1109/TCSVT.2013.2290574
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang X, 2018, LECT NOTES COMPUT SC, V11165, P441, DOI 10.1007/978-3-030-00767-6_41
   Yu JF, 2014, IEEE T NEUR NET LEAR, V25, P780, DOI 10.1109/TNNLS.2013.2281313
   Yu XY, 2020, ASIA PAC J MANAG, V37, P1141, DOI 10.1007/s10490-019-09657-1
   Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang YB, 2016, IEEE T MULTIMEDIA, V18, P405, DOI 10.1109/TMM.2015.2512046
   Zhou EJ, 2015, AAAI CONF ARTIF INTE, P3871
   Zhou HL, 2015, ASIAPAC SIGN INFO PR, P537, DOI 10.1109/APSIPA.2015.7415328
NR 57
TC 1
Z9 1
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6305
EP 6330
DI 10.1007/s11042-021-11648-8
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000740429700016
DA 2024-07-18
ER

PT J
AU Zhang, QQ
   Feng, GR
   Wu, HZ
AF Zhang, Qianqian
   Feng, Guorui
   Wu, Hanzhou
TI Surveillance video anomaly detection via non-local U-Net frame
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Frame prediction; GAN; Non-local U-Net
ID LOCALIZATION; NETWORK
AB Anomaly detection of surveillance video has become a critical concern in computer vision. It can be used for real-time monitoring and the timely generation of alarms and is widely applied in transportation systems and security systems. An unsupervised anomaly detection method for surveillance video based on frame prediction is implemented in this paper. Generative Adversarial Network (GAN) is used to generate the high-quality frame. Two generators are designed to predict the next future frame. Non-local U-Net is proposed as Generator 1 for frame prediction to predict the global information. Generator 2 obtains more related past frame features and large contour information. The predicted frame and the ground truth are compared to determine anomalies. We take spatial constraints during generative adversarial training, including gradient loss and intensity loss, and time constraints, such as optical flow loss, into account. We experimentally verify that the proposed method has better accuracy in surveillance videos than some other state-of-the-art anomaly detection algorithms.
C1 [Zhang, Qianqian; Feng, Guorui; Wu, Hanzhou] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Feng, Guorui] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Shanghai University; Guangxi Normal University
RP Feng, GR (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.; Feng, GR (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM fgr2082@aliyun.com
RI Wu, Hanzhou/AAL-3361-2021
OI Wu, Hanzhou/0000-0002-1599-7232
FU Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS19-03]; National Natural Science Foundation of China
   [62072295]; Natural Science Foundation of Shanghai [19ZR1419000]
FX This work was supported by Research Fund of Guangxi Key Lab of
   Multi-source Information Mining & Security (MIMS19-03), the National
   Natural Science Foundation of China under Grants (62072295) and the
   Natural Science Foundation of Shanghai under Grant 19ZR1419000.
CR Anala MR, 2019, 2019 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING, DATA AND ANALYTICS WORKSHOP (HIPCW 2019), P93, DOI 10.1109/HiPCW.2019.00031
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Dhole H, 2019, INT CONF COMPUT
   Dong F, 2020, IEEE ACCESS, V8, P88170, DOI 10.1109/ACCESS.2020.2993373
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fan SN, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA 2020), P123, DOI 10.1109/ICCIA49625.2020.00031
   Fu JP, 2018, 9TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC 2018), P179, DOI 10.1109/ISIVC.2018.8709229
   Ganokratanaa T, 2020, IEEE ACCESS, V8, P50312, DOI 10.1109/ACCESS.2020.2979869
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu XX, 2014, OPTIK, V125, P3428, DOI 10.1016/j.ijleo.2014.01.041
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hu J., 2019, 2019 12 INT C IM SIG, P1, DOI [10.1109/CISP-BMEI48845.2019.8966045, DOI 10.1109/CISP-BMEI48845.2019.8966045]
   Ismail Y., 2018, 2018 INT C INN INT I, P1
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kim H, 2016, EXPERT SYST APPL, V45, P131, DOI 10.1016/j.eswa.2015.09.035
   Koshti D, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), P729, DOI 10.1109/icict48043.2020.9112552
   Kwon YH, 2019, PROC CVPR IEEE, P1811, DOI 10.1109/CVPR.2019.00191
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Li S, 2021, IEEE T CIRC SYST VID, V31, P1283, DOI 10.1109/TCSVT.2020.2984783
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Li YY, 2019, IEEE ACCESS, V7, P172425, DOI 10.1109/ACCESS.2019.2954540
   Liang XD, 2017, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2017.194
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu YW, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909850
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mathieu M., 2015, PROC INT C LEARN REP
   Medel J. R., 2016, Anomaly detection in video using predictive convolutional long short-term memory networks
   Morais R, 2019, PROC CVPR IEEE, P11988, DOI 10.1109/CVPR.2019.01227
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Nayak Rashmiranjan, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P175, DOI 10.1109/IC3A48958.2020.233292
   Persia F, 2020, IEEE INT C SEMANT CO, P287, DOI 10.1109/ICSC.2020.00058
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabzalian Behnam, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P173, DOI 10.1109/PRIA.2019.8786007
   Singh Prateek Kumar, 2021, ISH Journal of Hydraulic Engineering, V27, P23, DOI 10.1080/09715010.2018.1505562
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Wang JZ, 2019, IEEE T CIRC SYST VID, V29, P3531, DOI 10.1109/TCSVT.2018.2882061
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Yang Y, 2019, 2019 INTERNATIONAL RADAR CONFERENCE (RADAR2019), P161, DOI [10.1109/RADAR41533.2019.171361, 10.1145/3300061.3300130]
   Zhang CX, 2019, IEEE IMAGE PROC, P1975, DOI [10.1109/ICIP.2019.8803151, 10.1109/icip.2019.8803151]
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
   Zong XL, 2019, INT WORKSH INT DATA, P368, DOI [10.1109/IDAACS.2019.8924464, 10.1109/idaacs.2019.8924464]
NR 49
TC 7
Z9 8
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27073
EP 27088
DI 10.1007/s11042-021-11550-3
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000740429700035
DA 2024-07-18
ER

PT J
AU Leibetseder, A
   Schoeffmann, K
   Keckstein, J
   Keckstein, S
AF Leibetseder, Andreas
   Schoeffmann, Klaus
   Keckstein, Joerg
   Keckstein, Simon
TI Endometriosis detection and localization in laparoscopic gynecology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Endometriosis segmentation; Lesion detection; Deep learning
ID DEEP; TRACKING; SURGERY
AB Endometriosis is a common gynecologic condition typically treated via laparoscopic surgery. Its visual versatility makes it hard to identify for non-specialized physicians and challenging to classify or localize via computer-aided analysis. In this work, we take a first step in the direction of localized endometriosis recognition in laparoscopic gynecology videos using region-based deep neural networks Faster R-CNN and Mask R-CNN. We in particular use and further develop publicly available data for transfer learning deep detection models according to distinctive visual lesion characteristics. Subsequently, we evaluate the performance impact of different data augmentation techniques, including selected geometrical and visual transformations, specular reflection removal as well as region tracking across video frames. Finally, particular attention is given to creating reasonable data segmentation for training, validation and testing. The best performing result surprisingly is achieved by randomly applying simple cropping combined with rotation, resulting in a mean average segmentation precision of 32.4% at 50-95% intersection over union overlap (64.2% for 50% overlap).
C1 [Leibetseder, Andreas; Schoeffmann, Klaus] Klagenfurt Univ, Inst Informat Technol, Klagenfurt, Austria.
   [Keckstein, Joerg] Ulm Univ, Fac Med, Ulm, Germany.
   [Keckstein, Simon] Ludwig Maximilians Univ Munchen, Univ Hosp, Munich, Germany.
C3 University of Klagenfurt; Ulm University; University of Munich
RP Leibetseder, A (corresponding author), Klagenfurt Univ, Inst Informat Technol, Klagenfurt, Austria.
EM aleibets@itec.aau.at; ks@itec.aau.at; joerg@keckstein.at;
   simon.keckstein@med.uni-muenchen.de
RI Leibetseder, Andreas/AAI-2725-2020; Keckstein, Joerg/K-1747-2019
OI Leibetseder, Andreas/0000-0002-9535-966X; Keckstein,
   Joerg/0000-0002-3943-3300
FU FWF Austrian Science Fund [P 32010-N38]
FX This work was funded by the FWF Austrian Science Fund under grant P
   32010-N38.
CR Canis M, 1997, FERTIL STERIL, V67, P817
   Du WJ, 2019, IEEE ACCESS, V7, P142053, DOI 10.1109/ACCESS.2019.2944676
   Fox M, 2020, COMP MED SY, P565, DOI 10.1109/CBMS49503.2020.00112
   Fu YG, 2019, LECT NOTES COMPUT SC, V11795, P173, DOI 10.1007/978-3-030-33391-1_20
   Gibson E, 2017, PROC SPIE, V10135, DOI 10.1117/12.2255975
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Grammatikopoulou Maria, 2019, ARXIV190611586
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Jha D, 2020, ARXIV201107631
   Jin A, 2018, IEEE WINT CONF APPL, P691, DOI 10.1109/WACV.2018.00081
   Jung A. B., 2020, imgaug
   Keckstein J, 2020, BEST PRACT RES CLIN
   Keckstein J, 2003, Zentralbl Gynakol, V125, P291
   Kletz S, 2019, INT WORK CONTENT MUL
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leibetseder A, 2020, LECT NOTES COMPUT SC, V11962, P439, DOI 10.1007/978-3-030-37734-2_36
   Leibetseder A, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P357, DOI 10.1145/3204949.3208127
   Leibetseder A, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P296, DOI 10.1145/3126686.3126690
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Minaee S., 2020, ARXIV200105566
   MUNZER B, 2017, MULTIMED TOOLS APPL
   Münzer B, 2019, LECT NOTES COMPUT SC, V11296, P571, DOI 10.1007/978-3-030-05716-9_48
   Nwoye CI, 2019, INT J COMPUT ASS RAD, V14, P1059, DOI 10.1007/s11548-019-01958-6
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Petscharnig S, 2018, MULTIMED TOOLS APPL, V77, P8061, DOI 10.1007/s11042-017-4699-5
   Piccialli F, 2021, INFORM FUSION, V66, P111, DOI 10.1016/j.inffus.2020.09.006
   Rai Hari Mohan, 2020, 2020 IEEE 1st International Conference for Convergence in Engineering (ICCE), P134, DOI 10.1109/ICCE50343.2020.9290740
   Rai HM, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102477
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saraswat L, 2018, BJOG-INT J OBSTET GY, V125, P64, DOI 10.1111/1471-0528.14793
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957
   Visalaxi S, 2021, INT J NONLINEAR ANAL, V12, P2403, DOI 10.22075/ijnaa.2021.5383
   Visalaxi S., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P747, DOI 10.1109/ICAIS50930.2021.9395822
   Visalaxi S., 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P739, DOI 10.1109/ICICV50876.2021.9388403
   Yang CM, 2020, COMPUT ASSIST SURG, V25, P15, DOI 10.1080/24699322.2020.1801842
   Yengera G., 2018, arXiv 1805.08569
   Zadeh SM, 2020, SURG ENDOSC, V34, P5377, DOI 10.1007/s00464-019-07330-8
NR 43
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6191
EP 6215
DI 10.1007/s11042-021-11730-1
EA JAN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000740155400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, KS
   Gao, TG
   You, DT
   Wu, XJ
   Kan, HB
AF Wang, Kunshu
   Gao, Tiegang
   You, Daotao
   Wu, Xiangjun
   Kan, Haibin
TI A secure dual-color image watermarking scheme based 2D DWT, SVD and
   Chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image watermarking; Two-dimensional discrete wavelet transform (2D
   DWT); Singular value decomposition (SVD); Chaotic encryption; Color
   space
ID WAVELET TRANSFORM; OPTIMIZED COMPENSATION; ROBUST WATERMARKING;
   FOURIER-TRANSFORM; DCT; ALGORITHM; DECOMPOSITION; DOMAIN
AB In this paper, by using multi-level two-dimensional (2D) discrete wavelet transform (DWT), singular value decomposition (SVD) and chaotic encryption, a new secure watermarking scheme is proposed for embedding the color watermark into the color host image. In order to improve the security of the proposed algorithm, coupled map lattice (CML) is employed to modify the pixel values of the watermark image. For watermark embedding, both the host image and the encrypted watermark are converted into the NTSC color space, and then the multi-level 2D DWT is performed on the host image. The ciphered watermark is embedded by modifying the singular values of the low frequency sub-bands of the host image. Also a reliable extraction algorithm is devised to extract the watermark from the possibly attacked watermarked images without resorting to the original image. Experimental and analysis results demonstrate that the proposed watermarking scheme has not only an excellent imperceptibility but a strong robustness against the common image processing attacks, geometric attacks and some composite attacks. The results also show that our proposed method outperforms the related dual-images watermarking algorithms in most cases.
C1 [Wang, Kunshu; Gao, Tiegang] Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
   [You, Daotao; Wu, Xiangjun] Henan Univ, Coll Software, Kaifeng 475004, Peoples R China.
   [Kan, Haibin] Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Shanghai 200433, Peoples R China.
C3 Nankai University; Henan University; Fudan University
RP Gao, TG (corresponding author), Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.; Wu, XJ (corresponding author), Henan Univ, Coll Software, Kaifeng 475004, Peoples R China.
EM gaotiegang@nankai.edu.cn; wuhsiang@yeah.net
OI Wu, Xiangjun/0000-0003-0371-8707
FU National Natural Science Foundation of China [61872125]; National
   Science and Technology Major Project of China [2018YFB0204304]; Science
   and Technology Foundation of Henan Province of China [182102410051,
   182102210027]; Tianjin Graduate Scientific Research Innovation Project
   [2021YJSB012]
FX This research was jointly supported by the National Natural Science
   Foundation of China (Grant No. 61872125), the National Science and
   Technology Major Project of China (Grant No. 2018YFB0204304), the
   Science and Technology Foundation of Henan Province of China (Grant Nos.
   182102410051 and 182102210027) , Tianjin Graduate Scientific Research
   Innovation Project (Grant No. 2021YJSB012).
CR Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Asikuzzaman M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P277, DOI 10.1109/PCS.2015.7170090
   Barni M, 2003, IEEE T SIGNAL PROCES, V51, P1118, DOI 10.1109/TSP.2003.809371
   Bhatnagar G, 2013, MATH COMPUT MODEL, V58, P204, DOI 10.1016/j.mcm.2012.06.002
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chappelier V, 2006, IEEE T IMAGE PROCESS, V15, P2892, DOI 10.1109/TIP.2006.877526
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Chou CH, 2003, EURASIP J APPL SIG P, V2003, P32, DOI 10.1155/S1110865703211227
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Darwish M.M., 2020, Multimedia security using chaotic maps: principles and methodologies, P137
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Ghouti L, 2006, IEEE T SIGNAL PROCES, V54, P1519, DOI 10.1109/TSP.2006.870624
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hwang MS, 1999, IEEE T CONSUM ELECTR, V45, P286, DOI 10.1109/30.793411
   Kaneko K, 1992, CHAOS, V2, P279, DOI 10.1063/1.165869
   Keyvanpour M, 2013, MATH COMPUT MODEL, V58, P56, DOI 10.1016/j.mcm.2012.07.008
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Lee IS, 2009, PATTERN RECOGN, V42, P1604, DOI 10.1016/j.patcog.2009.01.014
   Lee SH, 2014, INFORM SCIENCES, V273, P263, DOI 10.1016/j.ins.2014.03.039
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Megías D, 2010, SIGNAL PROCESS, V90, P3078, DOI 10.1016/j.sigpro.2010.05.012
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Nan H, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/526174
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, OPTIK, V124, P3254, DOI 10.1016/j.ijleo.2012.10.005
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Su QT, 2012, OPT COMMUN, V285, P1717, DOI 10.1016/j.optcom.2011.11.117
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Tang LL, 2015, MULTIMED TOOLS APPL, V74, P4397, DOI 10.1007/s11042-013-1531-8
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Tsai HH, 2011, PATTERN RECOGN, V44, P751, DOI 10.1016/j.patcog.2010.10.004
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Weber A., 1997, The usc-sipi image database
   Yen E, 2010, EXPERT SYST APPL, V37, P4033, DOI 10.1016/j.eswa.2009.09.032
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
   Zheng PP, 2014, NEUROCOMPUTING, V142, P520, DOI 10.1016/j.neucom.2014.04.005
NR 60
TC 11
Z9 12
U1 5
U2 69
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6159
EP 6190
DI 10.1007/s11042-021-11725-y
EA JAN 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000740155400002
DA 2024-07-18
ER

PT J
AU Viji, D
   Revathy, S
AF Viji, D.
   Revathy, S.
TI A hybrid approach of Weighted Fine-Tuned BERT extraction with deep
   Siamese Bi - LSTM model for semantic text similarity identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BERT; Bi-LSTM; CNN; NLP; Semantic text-similarity; Embedded vectors;
   Siamese networks
AB The conventional semantic text-similarity methods requires high amount of trained labeled data and also human interventions. Generally, it neglects the contextual-information and word-orders information resulted in data sparseness problem and latitudinal-explosion issue. Recently, deep-learning methods are used for determining text-similarity. Hence, this study investigates NLP application tasks usage in detecting text-similarity of question pairs or documents and explores the similarity score predictions. A new hybridized approach using Weighted Fine-Tuned BERT Feature extraction with Siamese Bi-LSTM model is implemented. The technique is employed for determining question pair sets using Semantic-text-similarity from Quora dataset. The text features are extracted using BERT process, followed by words embedding with weights. The features along with weight values, are represented as embedded vectors, are subjected to various layers of Siamese Networks. The embedded vectors of input text features were trained by using Deep Siamese Bi-LSTM model, in various layers. Finally, similarity scores are determined for each sentence, and the semantic text-similarity is learned. The performance evaluation of proposed-framework is established with respect to accuracy rate, precision value, F1 score data and Recall values parameters compared with other existing text-similarity detection methods. The proposed-framework exhibited higher efficiency rate with 91% in accuracy level in determining semantic-text-similarity compared with other existing algorithms.
C1 [Viji, D.] Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Revathy, S.] Sathyabama Inst Sci & Technol, Dept Informat Technol, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; Sathyabama Institute of
   Science & Technology
RP Viji, D (corresponding author), Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM dviji2k@gmail.com
RI Revathy, S/ABE-6744-2020
OI Revathy, S/0000-0001-9294-0304
CR Abishek K, 2019, ADV INTELL SYST COMP, V758, P769, DOI 10.1007/978-981-13-0514-6_73
   Al-Smadi M, 2017, INFORM PROCESS MANAG, V53, P640, DOI 10.1016/j.ipm.2017.01.002
   [Anonymous], 2018, 2018 INT JOINT C NEU
   Buscaldi D, 2013, 2 JOINT C LEX COMP S, P63
   Croce D., 2012, SEM 2012, p[2012, 597]
   Deguang Peng, 2020, CCRIS 2020: 2020 International Conference on Control, Robotics and Intelligent System, P19, DOI 10.1145/3437802.3437806
   Deudon Michel, 2018, Advances in Neural Information Processing Systems, P986
   Devlin J., 2018, BERT PRE TRAINING DE
   Gomaa WH., 2013, international journal of Computer Applications, V68, P13, DOI 10.5120/11638-7118
   Guo X, 2007, ARXIV PREPRINT ARXIV, P2020
   Habibi M, 2008, ARXIV PREPRINT ARXIV, P2020
   He H., 2016, P 2016 C N AM CHAPT, P937, DOI [10.18653/v1/N16-1108, DOI 10.18653/V1/N16-1108]
   He H., 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, P1576, DOI 10.18653/v1/D15-1181
   Jang B, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175841
   Kashefi O., 2010, J CONVERGENCE INFORM, V5, P101, DOI [10.4156/jcit.vol5.issue2.11, DOI 10.4156/JCIT.VOL5.ISSUE2.11]
   Kumar M, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P257, DOI 10.1109/Confluence51648.2021.9377050
   Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006
   Kumar M, 2018, SUSTAIN COMPUT-INFOR, V19, P147, DOI 10.1016/j.suscom.2018.06.002
   Kumar M, 2018, COMPUT ELECTR ENG, V69, P395, DOI 10.1016/j.compeleceng.2017.11.018
   Kumar S, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2046
   Laskar MTR, 2019, INT C APPL MATH MOD, P693
   Li JY, MASSIVE PRETRAINED M
   Li YL, 2020, IEEE ACCESS, V8, P75437, DOI 10.1109/ACCESS.2020.2988918
   Lo Chi-kiu, 2019, P 23 C COMP NAT LANG, P206
   Mahmoud A., 2017, 31 PAC AS C LANG INF, P274
   Mihalcea R., 2006, P 21 NAT C ART INT, V6, P775
   Nguyen HT, 2019, KNOWL-BASED SYST, V182, DOI 10.1016/j.knosys.2019.07.013
   Peinelt N, 2010, ARXIV PREPRINT ARXIV
   Peinelt N., 2020, P 58 ANN M ASS COMP, P7047
   Peng S, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2500, DOI 10.1145/3366423.3379998
   Rao JF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5370
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567
   Saedi C, 2021, COMPUT SPEECH LANG, V70, DOI 10.1016/j.csl.2021.101241
   Shi HX, 2020, AACL-IJCNLP 2020: THE 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P24
   Shih CH, 2017, ASIAPAC SIGN INFO PR, P641, DOI 10.1109/APSIPA.2017.8282104
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Vani K, 2018, INFORM PROCESS MANAG, V54, P408, DOI 10.1016/j.ipm.2018.01.008
   Viswanathan Sujith, 2019, Advances in Big Data and Cloud Computing. Proceedings of ICBDCC18. Advances in Intelligent Systems and Computing (AISC 750), P519, DOI 10.1007/978-981-13-1882-5_45
   Wang YS, 2020, LANG RESOUR EVAL, V54, P57, DOI 10.1007/s10579-018-9431-1
   Xiao H, 2020, NEURAL NETWORKS, V131, P172, DOI 10.1016/j.neunet.2020.07.024
   Xiong Y, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-1045-z
   Yoo Y, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13081442
   Zhang T, 2019, PR MACH LEARN RES, V97
   Zhang X, 2017, IEEE IJCNN, P2158, DOI 10.1109/IJCNN.2017.7966116
   Zhang ZS, 2020, AAAI CONF ARTIF INTE, V34, P9628
   Zhu Z., 2018, CCKS TASKS, V2242, P44
NR 46
TC 18
Z9 18
U1 14
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6131
EP 6157
DI 10.1007/s11042-021-11771-6
EA JAN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000739790800010
PM 35018132
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Behera, AP
   Singh, J
   Verma, S
   Kumar, M
AF Behera, Adarsh Prasad
   Singh, Jagriti
   Verma, Shekhar
   Kumar, Manish
TI Data visualization through non linear dimensionality reduction using
   feature based Ricci flow embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data visualization; Ambient space; Intrinsic dimension; Dimensionality
   reduction; Manifold; Ricci flow; Conformal mapping; Mean correlation
ID PARAMETERIZATION
AB Data visualization in high-dimensional space is a significant problem in machine learning. In many data sets, the data apparently lie on a high dimensional ambient space due to redundant features, while the intrinsic dimension is very low. This work proposes an analytical approach to use Feature Based Ricci Flow Embedding (FBRFE) as a nonlinear dimensionality reduction technique. For visualization purposes, we have considered nonlinear data with an intrinsic dimension of 2D but lie on an ambient space 3D and reduced the dimensionality accordingly. FBRFE uses conformal mapping that preserves the angle between the points in the higher dimensional manifold. At first, a surface triangulation mesh is formed using all the data points, and then circle packing is done in order to compute the respective angles between the data points. Then, conformal mapping is performed through the surface Ricci flow algorithm. After that, the 3D surface triangulation mesh is flattened into 2D using a seed face flattening algorithm to reduce the dimensionality of the data. Comparison results show that FBRFE visualizes the data in a lower dimension with a much better mean correlation up to 120.17% and less overlapping than the existing conventional algorithms.
C1 [Behera, Adarsh Prasad; Singh, Jagriti; Verma, Shekhar; Kumar, Manish] Indian Inst Informat Technol, Dept Informat Technol, Allahabad 211012, UP, India.
C3 Indian Institute of Information Technology Allahabad
RP Behera, AP (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Allahabad 211012, UP, India.
EM pwc2015004@iiita.ac.in
RI Behera, Adarsh Prasad/HJB-2376-2022
OI Behera, Adarsh Prasad/0000-0001-7220-5353
CR [Anonymous], ARXIVMATH0211159
   Buja A, 2008, J COMPUT GRAPH STAT, V17, P444, DOI 10.1198/106186008X318440
   Chen J, 2011, ARTIF INTELL REV, V36, P29, DOI 10.1007/s10462-010-9200-z
   Chen X, 2013, COMPUT VIS IMAGE UND, V117, P1107, DOI 10.1016/j.cviu.2013.02.010
   Chow B, 2003, J DIFFER GEOM, V63, P97
   Coifman RR, 2014, APPL COMPUT HARMON A, V36, P79, DOI 10.1016/j.acha.2013.03.001
   Cox T.F., 2001, Multidimensional Scalin, V46, P1050
   Crane Keenan, 2020, ARXIV200710430
   De la Porte J., 2008, P 19 S PATT REC ASS, P15
   Engel D., 2011, VISUALIZATION LARGE, V27, P135, DOI [DOI 10.4230/OASICS.VLUDS.2011.135, 10.4230/OASIcs.VLUDS.2011.1352, DOI 10.4230/OASICS.VLUDS.2011.1352]
   Fernández A, 2015, NEUROCOMPUTING, V163, P25, DOI 10.1016/j.neucom.2014.08.090
   Gu XF, 2008, COMPUT AIDED DESIGN, V40, P676, DOI 10.1016/j.cad.2008.01.008
   HAMILTON RS, 1982, J DIFFER GEOM, V17, P255
   Hamilton RS., 1988, CONT MATH, V71, P237, DOI DOI 10.1090/CONM/071/954419
   Jin M, 2008, IEEE T VIS COMPUT GR, V14, P1030, DOI 10.1109/TVCG.2008.57
   Jin Miao, 2006, SPM '06: Proceedings of the 2006 ACM Symposium on Solid and Physical Modeling, P105
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Lee J.M., 2007, Riemannian Manifolds: An Introduction to Curvature
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Liu ZX, 2016, CAAI T INTELL TECHNO, V1, P285, DOI 10.1016/j.trit.2016.10.002
   MAUR P., 2002, DELAUNAY TRIANGULATI
   Narra N, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-23248-y
   Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443
   Borges VRP, 2014, IEEE SYS MAN CYBERN, P1654, DOI 10.1109/SMC.2014.6974153
   Perelman G., 2003, ARXIVMATHDG0307245
   Perelman G., 2003, ARXIV
   Peters J, 2017, ADAPT COMPUT MACH LE
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Schinzinger R, 2012, Conformal mapping: methods and applications
   Shao C, 2005, LECT NOTES ARTIF INT, V3789, P534
   Shi J, 2015, NEUROIMAGE, V104, P1, DOI 10.1016/j.neuroimage.2014.09.062
   Thurston W.P., 1979, The Geometry and Topology of Three-Manifolds
   Tsai F.S., 2010, J ARTIF INTEL, V3, P119, DOI DOI 10.3923/JAI.2010.119.134
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Verleysen M, 2005, LECT NOTES COMPUT SC, V3512, P758
   Wang YL, 2012, IEEE T MED IMAGING, V31, P251, DOI 10.1109/TMI.2011.2168233
   Yang YL, 2009, COMPUT GRAPH FORUM, V28, P2005, DOI 10.1111/j.1467-8659.2009.01579.x
   Zeng W., 2013, Ricci Flow for Shape Analysis and Surface Registration: Theories, Algorithms and Applications
   Zhang M, 2014, GRAPH MODELS, V76, P321, DOI 10.1016/j.gmod.2014.04.008
   Zhang ZY, 2003, LECT NOTES COMPUT SC, V2690, P477
NR 40
TC 2
Z9 2
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14831
EP 14850
DI 10.1007/s11042-021-11479-7
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000737741900004
DA 2024-07-18
ER

PT J
AU Deng, TP
   Li, X
   Xiong, JB
   Wu, Y
AF Deng, Tianpeng
   Li, Xuan
   Xiong, Jinbo
   Wu, Ying
TI POISIDD: privacy-preserving outsourced image sharing scheme with illegal
   distributor detection in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image sharing; Illegal distribution detection; Data hiding; Discrete
   cosine transform; Homomorphic encryption
AB Privacy-preserving outsourced image sharing schemes can help relieve the local storage of image owners and protect images' privacy by sending encrypted images to receivers, but they cannot prevent the decrypted image from being illegally distributed by illegal distributors. To cope with this issue, we propose a privacy-preserving image sharing scheme with illegal distributor detection (POISIDD). POISIDD embeds the authentication information of image receiver in the encrypted form based on discrete cosine transform (DCT) and privacy-preserving outsourced calculation on floating point numbers (POCF) . Moreover, in order to prevent all operations from being carried out by the single cloud which may lead to privacy disclosure, we adopt two platforms (Storage Center and Authentication Center) to achieve the embedding of authentication information(AI) by the communications between them. Furthermore, in order to better defend against attackers, we generate random vectors based on the original AI and use them instead of the AI as the embedded data. The aim of identifying illegal distributor will be achieved with the help of Authentication Center. The scheme is secure under the defined attack model, and its robustness under different attacks has been shown by experiments.
C1 [Deng, Tianpeng; Li, Xuan; Xiong, Jinbo; Wu, Ying] Fujian Normal Univ, Coll Comp & Cyber Secur, Fuzhou 350117, Peoples R China.
   [Li, Xuan; Xiong, Jinbo] Fujian Prov Key Lab, Network Secur & Cryptol, Fuzhou 350117, Peoples R China.
   [Li, Xuan] Digital Fujian Big Data Secur Technol Inst, Fuzhou 350117, Peoples R China.
C3 Fujian Normal University
RP Deng, TP (corresponding author), Fujian Normal Univ, Coll Comp & Cyber Secur, Fuzhou 350117, Peoples R China.
RI Deng, Tianpeng/JDW-4767-2023
FU National Natural Science Foundation of China [61872090, 61872086]
FX This work is supported by the National Natural Science Foundation of
   China (No.61872090, No.61872086).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Amato Flora, 2019, Future Generation Computer Systems, V93, P914, DOI 10.1016/j.future.2017.04.028
   Cheng B, 2014, 2014 IEEE FOURTH INTERNATIONAL CONFERENCE ON BIG DATA AND CLOUD COMPUTING (BDCLOUD), P116, DOI 10.1109/BDCloud.2014.36
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Ilia P, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P781, DOI 10.1145/2810103.2813603
   Jianping He, 2016, 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). Proceedings, P359, DOI 10.1109/DSN.2016.40
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Liu XM, 2016, IEEE T INF FOREN SEC, V11, P2513, DOI 10.1109/TIFS.2016.2585121
   Meng SM, 2021, IEEE T IND INFORM, V17, P4219, DOI 10.1109/TII.2020.2995348
   Mondal M, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P991, DOI 10.1145/3319535.3354202
   Mukherjee Dhritiman, 2019, Procedia Computer Science, V152, P274, DOI 10.1016/j.procs.2019.05.016
   Narasimman A, 2019, IFIP ADV INF COMM TE, V562, P271, DOI 10.1007/978-3-030-22312-0_19
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Tierney M., 2013, Proceedings of the first ACM conference on Online social networks, P75
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xie SN, 2019, IEEE I CONF COMP VIS, P1284, DOI 10.1109/ICCV.2019.00137
   Xu XL, 2021, IEEE T IND INFORM, V17, P5819, DOI 10.1109/TII.2020.3031440
   Yang Y, 2019, INFORM SCIENCES, V479, P567, DOI 10.1016/j.ins.2018.02.005
   Yuan L, 2015, IEEE CONF COMPUT, P185, DOI 10.1109/INFCOMW.2015.7179382
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 30
TC 5
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3693
EP 3714
DI 10.1007/s11042-021-11737-8
EA NOV 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000720587800001
DA 2024-07-18
ER

PT J
AU Zhong, Z
AF Zhong, Zhen
TI A novel visible and infrared image fusion method based on convolutional
   neural network for pig-body feature detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VI and IR image fusion; Convolutional neural network; Pig-body shape
   feature; Pig-body temperature feature
ID EXTRACTION
AB The visible (VI) and infrared (IR) image fusion has been an active research task because of its higher segmentation accuracy rate during recent years. However, traditional VI and IR image fusion algorithms could not extract more texture and edge features of fused image. In order to more effectively extract pig-body shape and temperature feature, a new multisource fusion algorithm for shape segmentation and temperature extraction is presented based on convolutional neural network (CNN), named as MCNNFuse. Firstly, visible and infrared images are fused by modified CNN fusion model. Then, shape feature is extracted by Otsu threshold and morphological operation in view of fusion results. Finally, pig-body temperature feature is extracted based on shape segmentation. Experimental results show that segmentation model based on presented fusion method is capable of achieving 1.883-7.170% higher average segmentation accuracy rate than prevalent traditional and previously published methods. Furthermore, it establishes the groundwork for accurate measurement of pig-body temperature.
C1 [Zhong, Zhen] Tianjin Univ Technol & Educ, Coll Informat Technol Engn, Tianjin 300222, Peoples R China.
C3 Tianjin University of Technology & Education
RP Zhong, Z (corresponding author), Tianjin Univ Technol & Educ, Coll Informat Technol Engn, Tianjin 300222, Peoples R China.
EM 18322141247@163.com
OI Zhong, Zhen/0000-0002-7349-1256
FU Fundamental Research Funds for Tianjin University of Technology and
   Education [KRKC012105]
FX The author would like to thank her colleagues for their support of this
   work. The detailed comments from the anonymous reviewers were gratefully
   acknowledged. This work is jointly supported by the Fundamental Research
   Funds for Tianjin University of Technology and Education (No.
   KRKC012105).
CR Alsaaod M, 2014, VET J, V199, P281, DOI 10.1016/j.tvjl.2013.11.028
   Bai XZ, 2015, INFRARED PHYS TECHN, V71, P77, DOI 10.1016/j.infrared.2015.03.001
   Bai XZ, 2011, OPT EXPRESS, V19, P8444, DOI 10.1364/OE.19.008444
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Caldara FR, 2014, ASIAN AUSTRAL J ANIM, V27, P431, DOI 10.5713/ajas.2013.13505
   Cheng BY, 2018, INFRARED PHYS TECHN, V91, P153, DOI 10.1016/j.infrared.2018.04.004
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Font-i-Furnols M, 2015, ANIMAL, V9, P166, DOI 10.1017/S1751731114002237
   Jia Y, 2016, 2016 8 INT C INT HUM
   Jin X, 2018, SIGNAL PROCESS, V153, P379, DOI 10.1016/j.sigpro.2018.08.002
   Jin X, 2018, INFRARED PHYS TECHN, V88, P1, DOI 10.1016/j.infrared.2017.10.004
   Kashiha MA, 2013, LECT NOTES COMPUT SC, V8192, P555, DOI 10.1007/978-3-319-02895-8_50
   Kawasue K, 2017, ARTIF LIFE ROBOT, V22, P464, DOI 10.1007/s10015-017-0373-2
   Kong WW, 2016, NEUROCOMPUTING, V212, P12, DOI 10.1016/j.neucom.2016.01.120
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   Kong WW, 2014, INFRARED PHYS TECHN, V63, P110, DOI 10.1016/j.infrared.2013.12.016
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Liu W., 2018, 2018 11 INT C IM, P1, DOI 10.1109/CISP-BMEI.2018.8633236
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Ma Y, 2016, NEUROCOMPUTING, V202, P12, DOI 10.1016/j.neucom.2016.03.009
   Mohammed A, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2147, DOI 10.1109/TENCON.2016.7848406
   Nemalidinne SM, 2018, FIRE SAFETY J, V101, P84, DOI 10.1016/j.firesaf.2018.08.012
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Shen G, 2011, INT C DIG MAN AUT
   Stajnko D, 2008, COMPUT ELECTRON AGR, V61, P233, DOI 10.1016/j.compag.2007.12.002
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Wan W, 2018, SIGNAL IMAGE VIDEO P, V12, P959, DOI 10.1007/s11760-018-1240-x
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   Ye W, 2000, T ASAE, V43, P1843, DOI 10.13031/2013.3089
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao JF, 2017, INFRARED PHYS TECHN, V81, P201, DOI 10.1016/j.infrared.2017.01.012
   Zhong Z, 2020, KSII T INTERNET INF, V14, P4395, DOI 10.3837/tiis.2020.11.008
   Zhong Z, 2021, MULTIDIM SYST SIGN P, V32, P381, DOI 10.1007/s11045-020-00744-x
   Zhong Z, 2020, MULTIMED TOOLS APPL, V79, P26225, DOI 10.1007/s11042-020-09044-9
NR 36
TC 5
Z9 6
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2757
EP 2775
DI 10.1007/s11042-021-11675-5
EA NOV 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714500100004
DA 2024-07-18
ER

PT J
AU Francese, R
   Risi, M
   Tortora, G
   Di Salle, F
AF Francese, Rita
   Risi, Michele
   Tortora, Genoveffa
   Di Salle, Francesco
TI Thea: empowering the therapeutic alliance of children with ASD by
   multimedia interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autism Spectrum Disorder; Empowerment; Chatbot; Multimedia Interaction;
   Therapeutic Alliance
ID PATIENT EMPOWERMENT; SELF-MANAGEMENT; TECHNOLOGY; INTERVENTION
AB The Therapeutic Alliance (TA) between patient and health provider (therapist or clinician) is one of the most relevant factors for the success of a therapy. In the case of people suffering from Autism Spectrum Disorder (ASD), the alliance is extended to all the people involved in their care (i.e., teachers, therapists, clinicians, relatives). In this paper, we propose a multimedia application named Thea for empowering the TA of children with ASD by improving the communication among the TA members, sharing guidelines, multimedia contents, and strategies to comply with challenging behaviors and progress with particular attention towards end-users who are occasional smart-users. A detailed process for empowering the TA members by enhancing the informed interaction among all of them is proposed and implemented. A vocal assistant also supports patients/caregivers and therapists in documenting their activity with the person with ASD by recording videos in a free-hand modality. After a contextual analysis based on Thematic Analysis Template, Thea has been implemented using a user-centered development approach. We performed three iterations involving the end-users. A user study is performed at the third iteration. Results of the user study revealed a positive attitude towards the application. In particular, the perception of empowerment of participants increased after the tool had been used. We also highlighted the guidelines and tools that may be adopted for empowering different kinds of patients. The first results seem to suggest that the use of Thea may increase the belief of the caregivers of a person with ASD to be able to better take care of her, in a more controlled and informed way.
C1 [Francese, Rita; Risi, Michele; Tortora, Genoveffa; Di Salle, Francesco] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
C3 University of Salerno
RP Francese, R (corresponding author), Univ Salerno, Dept Comp Sci, Fisciano, Italy.
EM francese@unisa.it; mrisi@unisa.it; tortora@unisa.it; fdisalle@unisa.it
RI Di Salle, Francesco/ABX-8875-2022; Tortora, Genoveffa/M-8155-2019
OI FRANCESE, Rita/0000-0002-6929-0056; Di Salle,
   Francesco/0000-0002-0226-8460
FU Universita degli Studi di Salerno within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Salerno within
   the CRUI-CARE Agreement.
CR Abrahamyan S, 2017, LECT NOTES COMPUT SC, V10408, P448, DOI 10.1007/978-3-319-62404-4_33
   Aguilera Adrian, 2012, Behav Ther (N Y N Y), V35, P65
   ANDERSON RM, 1995, DIABETES CARE, V18, P943, DOI 10.2337/diacare.18.7.943
   [Anonymous], QUALITATIVE DATA ANA
   [Anonymous], 2011, THERAPEUTIC ALLIANCE
   Bandura A., 1996, SOCIAL FDN THOUGHT A, DOI DOI 10.5465/AMR.1987.4306538
   Bravo P, 2015, BMC HEALTH SERV RES, V15, DOI 10.1186/s12913-015-0907-z
   Castonguay LG, 1996, J CONSULT CLIN PSYCH, V64, P497, DOI 10.1037/0022-006X.64.3.497
   Cipolletta S, 2018, PSYCHOTHER RES, V28, P909, DOI 10.1080/10503307.2016.1259533
   de Bell S, 2017, LANDSCAPE URBAN PLAN, V167, P118, DOI 10.1016/j.landurbplan.2017.06.003
   Eldevik S, 2009, J CLIN CHILD ADOLESC, V38, P439, DOI 10.1080/15374410902851739
   Espinosa FD, 2020, BEHAV ANAL PRACT, V13, P550, DOI 10.1007/s40617-020-00438-7
   Feinstein Noah R, 2009, Am J Psychother, V63, P319
   Ferreira JM, 2020, INFORM SOFTWARE TECH, V117, DOI 10.1016/j.infsof.2019.106195
   Francese R, 2022, COMPLEX INTELL SYST, V8, P3659, DOI 10.1007/s40747-021-00447-1
   Freeman RL, 2020, FUNCTIONAL ASSESMENT
   FreireP, 2018, PEDAGOGY OPPRESSED
   Freund P., 1993, Psychosocial Rehabilitation Journal, V16, P65, DOI DOI 10.1037/H0095674
   Green J, 2006, J CHILD PSYCHOL PSYC, V47, P425, DOI 10.1111/j.1469-7610.2005.01516.x
   Hess JD, 1996, ADV NURS SCI, V19, P18
   Hill J.H., 2016, The Impact of Emojis and Emoticons on Online Consumer Reviews, Perceived Company Response Quality, Brand Relationship, and Purchase Intent, V4, P85
   HORVATH AO, 1993, J CONSULT CLIN PSYCH, V61, P561, DOI 10.1037/0022-006X.61.4.561
   HOUGAARD E, 1994, SCAND J PSYCHOL, V35, P67, DOI 10.1111/j.1467-9450.1994.tb00934.x
   Kim S C, 2001, Clin Nurs Res, V10, P314
   Lamprinos I, 2016, INT J MED INFORM, V91, P31, DOI 10.1016/j.ijmedinf.2016.04.006
   Law GC, 2019, RES AUTISM SPECT DIS, V67, DOI 10.1016/j.rasd.2019.101411
   Lindgreen P, 2018, INT J EAT DISORDER, V51, P314, DOI 10.1002/eat.22833
   Macbeth G, 2011, UNIV PSYCHOL, V10, P545, DOI 10.11144/Javeriana.upsy10-2.cdcp
   McAllister M, 2012, BMC HEALTH SERV RES, V12, DOI 10.1186/1472-6963-12-157
   McDougall T., 1997, MENTAL HLTH NURSING, V17, P4
   Nunnally J. C., 1975, Educ. Res, V4, P7, DOI [10.3102/0013189X004010007, DOI 10.3102/0013189X004010007]
   Pekonen A, 2020, PATIENT EDUC COUNS, V103, P777, DOI 10.1016/j.pec.2019.10.019
   Pfleeger SL, 2000, IEEE SOFTWARE, V17, P27, DOI 10.1109/52.819965
   Rahman MS, 2016, COMPUT HUM BEHAV, V58, P12, DOI 10.1016/j.chb.2015.12.016
   Rauschenberger M, 2013, INT J INTERACT MULTI, V2, P39, DOI 10.9781/ijimai.2013.215
   Richards P, 2018, CLIN PSYCHOL-UK, V22, P171, DOI 10.1111/cp.12102
   Schnall R, 2016, J BIOMED INFORM, V60, P243, DOI 10.1016/j.jbi.2016.02.002
   Sun V, 2017, CLIN LUNG CANCER, V18, pE151, DOI 10.1016/j.cllc.2017.01.010
   Tarasewich P, 2007, AMCIS 2007 P, P352
   Vitiello G, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206551
   Vitiello G, 2017, 2017 IEEE 25TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW), P139, DOI 10.1109/REW.2017.67
NR 41
TC 0
Z9 1
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34875
EP 34907
DI 10.1007/s11042-021-11520-9
EA OCT 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000712943000002
PM 34744483
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Rai, HM
   Chatterjee, K
AF Rai, Hari Mohan
   Chatterjee, Kalyan
TI 2D MRI image analysis and brain tumor detection using deep learning CNN
   model LeU-Net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LeU-Net; Biomedical image analysis; Deep neural network; Convolutional
   neural network; Magnetic resonance imaging; Artificial neural network
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION; SEGMENTATION
AB MRI image analysis and its segmentation for the accurate and automatic detection of brain tumors at an early stage is very much crucial for diagnosis the disorders and save human lives. Since most deep learning models have a large number of layers, they also take longer processing time, making them unsuitable for smaller image datasets. Hence, we have proposed, the detection of abnormality from brain MR images using a Less Layered and less complex U-Net model (LeU-Net) architecture. The principle of LeU-Net is inspired by the Le-Net and U-Net models, but completely different from both the design and architectural perspectives. The abnormality detection indicates the classification of the tumorous cell from overall Magnetic Resonance images. The Proposed deep learning model (LeU-Net) performance was compared with the existing basic CNN models Le-Net, U-Net, and VGG-16. The model performance was evaluated using evaluation metrics accuracy, precision, F-score, recall, and specificity. The experiment is performed on MR Dataset with uncropped images and cropped images (removed unwanted area) and compared the result with all three models. The LeU-Net model registers overall 98% accuracy on cropped images and 94% of accuracy on uncropped images. The LeU-Net model has much faster processing (simulation) time, it only takes 244.42 s and 252.36 s, respectively, to train the model with 100 epochs on the uncropped and cropped images. We have compared the performance of our proposed model with various state-of-the-art techniques, and it provides the best classification accuracy among all.
C1 [Rai, Hari Mohan; Chatterjee, Kalyan] Indian Inst Technol ISM Dhanbad, Dept Elect Engn, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Rai, HM (corresponding author), Indian Inst Technol ISM Dhanbad, Dept Elect Engn, Dhanbad, Bihar, India.
EM harimohanrai@gmail.com; kalyanchatterjee@iitism.ac.in
RI CHATTERJEE, KALYAN/B-8587-2018; Rai, Dr. Hari Mohan/L-8104-2015
OI CHATTERJEE, KALYAN/0000-0003-0069-2302; Rai, Dr. Hari
   Mohan/0000-0003-2557-3510
CR Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Akkus Z, 2017, J DIGIT IMAGING, V30, P469, DOI 10.1007/s10278-017-9984-3
   Alfonse M., 2016, Egyptian Computer Science Journal, V40, P11
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   [Anonymous], 2019, The Indian Express
   Bakr Siddiaue MA., 2020, P 4 INT C IOT SOC MO, DOI 10.1109/I-SMAC49090.2020.9243461
   Chakrabarty N, 2019, Brain MRI Images for Brain Tumor Detection
   Çinar A, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109684
   Das D, 2020, APPL NANOSCI, V10, P2383, DOI 10.1007/s13204-020-01416-9
   Ding Y, 2019, IEEE ACCESS, V7, P104011, DOI 10.1109/ACCESS.2019.2926448
   Fu J, 2019, MED PHYS, V46, P3788, DOI 10.1002/mp.13672
   Guari Q, 2019, J CANCER, V10, P4876, DOI 10.7150/jca.28769
   Gupta V, 2018, PROCEDIA COMPUT SCI, V125, P18, DOI 10.1016/j.procs.2017.12.005
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Heravi EJ, 2018, PATTERN RECOGN LETT, V105, P50, DOI 10.1016/j.patrec.2017.12.007
   Kumar RL, 2021, MULTIMED TOOLS APPL, V80, P13429, DOI 10.1007/s11042-020-10335-4
   Kumar S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45605-1
   Lachinov D, 2019, LECT NOTES COMPUT SC, V11384, P189, DOI 10.1007/978-3-030-11726-9_17
   Leonel J, 2019, MEDIUM
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   narayanahealth, 2020, BRAIN TUM SYMPT CAUS
   Narmadha, 2019, INT J INNOV TECHNOL, V8, P977, DOI [10.35940/ijitee, DOI 10.35940/IJITEE]
   Pashaei A, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P314, DOI 10.1109/ICCKE.2018.8566571
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Preethi S, 2021, MULTIMED TOOLS APPL, V80, P14789, DOI 10.1007/s11042-021-10538-3
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosebrock, 2016, FIND EXTR POINTS CON
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Saxena P., 2019, Predictive modeling of brain tumor: A deep learning approach
   Selvaraj D., 2013, International Journal of Computer Science & Engineering Technology, V4, P1313
   Shahzadi I, 2018, IEEE EMBS CONF BIO, P633, DOI 10.1109/IECBES.2018.8626704
   Sharif M I, 2021, Complex & Intelligent Systems
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Swapna M., 2020, International Journal of Recent Technology and Engineering, V8, P953
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Trivizakis E, 2019, IEEE J BIOMED HEALTH, V23, P923, DOI 10.1109/JBHI.2018.2886276
   Varuna Shree N, 2018, BRAIN INFORM, V5, P23, DOI DOI 10.1007/S40708-017-0075-5
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
NR 41
TC 21
Z9 22
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 36111
EP 36141
DI 10.1007/s11042-021-11504-9
EA OCT 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000712943000003
DA 2024-07-18
ER

PT J
AU Shenassa, ME
   Minaei-Bidgoli, B
AF Shenassa, Mohammad E.
   Minaei-Bidgoli, Behrouz
TI ElmNet: a benchmark dataset for generating headlines from Persian papers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dataset; Text summarization; Headline generation; Machine learning; Deep
   learning
AB Headline generation is a challenging subtask of abstractive text summarization, which its output should be a summary, shorter than one sentence. It would be precious to develop a dataset for the evaluation of abstractive summarization methods on this task in the Persian language. There are several datasets for headline generation in Persian, most of which are not large enough to be used by more sophisticated methods of text summarization, such as deep learning models. Moreover, all of these datasets are focused on daily news and there is no dataset for summarizing scientific Persian papers. In this article, we present "ElmNet," a headline generation dataset of about 400,000 abstract/headline pairs of scientific papers, gathered from six major publishers for scientific articles in Persian. We, moreover, evaluate the performance of the most important deep learning-based headline generation methods, on the proposed dataset. The results prove the comparability of the performance of the state-of-the-art methods on this task, to their results on the existing English datasets.
C1 [Shenassa, Mohammad E.] Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
   [Minaei-Bidgoli, Behrouz] Iran Univ Sci & Technol, Tehran, Iran.
C3 Islamic Azad University; Iran University Science & Technology
RP Minaei-Bidgoli, B (corresponding author), Iran Univ Sci & Technol, Tehran, Iran.
EM b_minaei@iust.ac.ir
RI Minaei-Bidgoli, Behrouz/L-2779-2018
OI Minaei-Bidgoli, Behrouz/0000-0002-9327-7345
CR Al Saied H, 2018, INT J DIGIT LIBRARIE, V19, P203, DOI 10.1007/s00799-017-0214-x
   AleAhmad A, 2009, KNOWL-BASED SYST, V22, P382, DOI 10.1016/j.knosys.2009.05.002
   [Anonymous], 2013, P ACL
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Banko N, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P318
   Chandrasekaran MK., 2019, P 4 JOINT WORKSH BIB, P153
   Chopra Sumit, 2016, P 2016 C N AM CHAPT, P93, DOI DOI 10.18653/V1/N16-1012
   Cohan Arman, 2015, P 2015 C EMP METH NA
   Cohn T, 2009, J ARTIF INTELL RES, V34, P637, DOI 10.1613/jair.2655
   Conroy JohnM., 2006, Proceedings of DUC, V6, P150
   Farzi S, 2019, DIGIT SCHOLARSH HUM, V34, P277, DOI 10.1093/llc/fqy034
   Filippova K., 2008, P 5 INT NAT LANG GEN, P25
   Filippova Katja, 2015, P 2015 C EMP METH NA, P360
   Fisas B, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3081
   Galley Michel, 2007, HUMAN LANGUAGE TECHN, P180
   Ganesan K, 2018, ARXIV
   Gehrmann S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4098
   Grusky Max, 2018, P 2018 C N AM CHAPTE, V1, P708, DOI [DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]
   Habash N, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P96
   Kestemont M, 2017, DIGIT SCHOLARSH HUM, V32, P797, DOI 10.1093/llc/fqw034
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   Kouris P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5082
   Li S, 2007, DOC UND C
   Lin C-Y., 2004, JPN CIRC J, V34, P8, DOI 10.1253/jcj.34.1213
   Lin H, 2019, AAAI CONF ARTIF INTE, P9815
   Mahajani Abhishek, 2019, Ambient Communications and Computer Systems. RACCCS-2018. Advances in Intelligent Systems and Computing (AISC 904), P339, DOI 10.1007/978-981-13-5934-7_31
   Nallapati R., 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Santosh Kumar P, 2021, ADV INTELLIGENT SYST, V1165, P525, DOI [10.1007/978-981-15-5113-0_41, DOI 10.1007/978-981-15-5113-0_41]
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shen XY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3762
   Sun R, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P462
   Systems S, 2004, P DOC UND C 2003
   Turner J., 2005, Proc. Assoc. for Computational Linguistics (ACL), V43, P290
   Vanderwende L., 2006, Proceedings of th e Workshop on Automatic Summarization (DUC 2006), P70, DOI 10.1.1.114.2486&rep=rep1&type=pdf
   Vaswani A, 2017, ADV NEUR IN, V30
   Wei Z, 2017, SOCIAL MEDIA CONTENT, P309, DOI [10.1142/9789813223615_0021, DOI 10.1142/9789813223615_0021]
   Woodsend K., 2010, EMNLP, P513
NR 39
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1853
EP 1866
DI 10.1007/s11042-021-11641-1
EA OCT 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000707292900001
DA 2024-07-18
ER

PT J
AU Kashyap, GS
   Malik, K
   Wazir, S
   Khan, R
AF Kashyap, Gautam Siddharth
   Malik, Karan
   Wazir, Samar
   Khan, Rijwan
TI Using Machine Learning to Quantify the Multimedia Risk Due to Fuzzing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cybersecurity; Fuzzing; Gradient boosting; Multimedia; Machine learning;
   Vulnerability; Random forest algorithm; XGBoost
AB There have been considerable advancements in multimedia technologies over the past 5 years. It has been observed that state-of-the-art multimedia systems face three broad categories of challenges: (1) Dependency on continuous network connections, (2) Data-sharing applications & collaboration, and (3) Security issues. Among these, security vulnerability poses a major threat to modern multimedia systems. Therefore, it is imperative to carefully investigate the security issues that can endanger wireless and mobile communications. At present, multimedia security research mainly focuses on wireless traffic monitoring, wireless system attacks, and wireless and mobile security. In this paper, we have used the network attack-type, "Reconnaissance", which contains two types of malicious activities: (1) OS scanning, and (2) Fuzzing. The goal of this paper is to quantify multimedia security risks due to Fuzzing by using various types of machine learning models. The highest accuracy i.e., 96.8%, is obtained using the XGBoost classifier, which is good compared to the existing models present in the literature. This is the first paper, to the best of our knowledge, that uses machine learning methods to differentiate between benign and malignant Fuzzing attacks.
C1 [Kashyap, Gautam Siddharth; Wazir, Samar] Jamia Hamdard, Dept Comp Sci & Engn, SEST, New Delhi, India.
   [Malik, Karan] USICT Guru Gobind Singh Indraprastha Univ, New Delhi, India.
   [Khan, Rijwan] ABES Inst Technol, Dept Comp Sci & Engn, Ghaziabad, India.
C3 Jamia Hamdard University; GGS Indraprastha University
RP Kashyap, GS (corresponding author), Jamia Hamdard, Dept Comp Sci & Engn, SEST, New Delhi, India.
EM officialgautamgsk.gsk@gmail.com; karanmalik2000@gmail.com;
   samar.wazir786@gmail.com; rijwankhan786@gmail.com
RI Wazir, Samar/AAT-9154-2020; Kashyap, Gautam Siddharth/HTQ-6293-2023;
   Khan, Rijwan/AAW-8355-2021
OI Kashyap, Gautam Siddharth/0000-0003-2140-9617; Khan,
   Rijwan/0000-0003-3354-3047; wazir, samar/0000-0002-7824-1766
CR Abubakar A, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P138, DOI 10.1109/EST.2017.8090413
   Anthi Eirini, 2018, Living in the Internet of Things: Cybersecurity of the IoT - 2018
   Attia Amr, 2020, 2020 International Conference on Computational Science and Computational Intelligence (CSCI), P138, DOI 10.1109/CSCI51800.2020.00031
   Aubet F.X, 2018, ALL EYES YOU DISTRIB
   Conole A, SFUZZ PENETRATION TE
   D'angelo G, 2015, APPL SOFT COMPUT, V36, P408, DOI 10.1016/j.asoc.2015.07.029
   Diro AA, 2018, FUTURE GENER COMP SY, V82, P761, DOI 10.1016/j.future.2017.08.043
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   Kulkarni P, 2018, P 1 INT WORKSH MAC L, DOI [10.1145/3243127.3243130, DOI 10.1145/3243127.3243130]
   Lippmann RP, 2000, Em: Proceedings-DARPA Information Survivability Conference and Exposition, DISCEX 2000, V2, P12, DOI DOI 10.1109/DISCEX.2000.821506
   Liu X, 2018, IEEE T IND INFORM, V14, P3801, DOI 10.1109/TII.2018.2836150
   Marteau PF, 2021, IEEE T INF FOREN SEC, V16, P2157, DOI 10.1109/TIFS.2021.3050605
   Mirsky Y, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23204
   Pajouh NH, 2019, IEEE T EMERG TOP COM, V7, P314, DOI 10.1109/TETC.2016.2633228
NR 14
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36685
EP 36698
DI 10.1007/s11042-021-11558-9
EA OCT 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000704216300001
DA 2024-07-18
ER

PT J
AU Agarwal, M
   Singhal, A
AF Agarwal, Megha
   Singhal, Amit
TI Directional local co-occurrence patterns based on Haar-like filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color histogram; Corel 10k; Haar-like filters; Image retrieval; Local
   ternary co-occurrence pattern
ID FEATURE DESCRIPTOR; IMAGE RETRIEVAL; TEXTURE FEATURE; EXTREMA PATTERNS;
   COLOR; CLASSIFICATION; SPACE
AB Content based image retrieval (CBIR) systems enable a quick retrieval of similar images from a large digital repository. However, the performance of the system is heavily reliant on the feature definition of images. The challenge lies in extracting suitable features that can work across a variety of datasets. In this paper, Haar-like local ternary co-occurrence pattern (HLTCoP) is designed as a feature for image retrieval applications. In HLTCoP, four different Haar-like filters are deployed to capture directional information of the image and two different local neighborhoods are considered to obtain the local patterns around every pixel. Thereafter, co-occurrence between two filtered images is computed to construct the HLTCoP feature. Additionally, color information is extracted using histograms of hue and saturation planes. Image retrieval performance is verified on diversified benchmark datasets, Corel 10k, CMU-PIE and MIT VisTex. Significant improvement is achieved in comparison to the existing techniques.
C1 [Agarwal, Megha] Jaypee Inst Informat Technol, Dept Elect & Commun Engn, Noida 201304, India.
   [Singhal, Amit] Netaji Subhas Univ Technol, Dept Elect & Commun Engn, Delhi 110078, India.
C3 Jaypee Institute of Information Technology (JIIT); Netaji Subhas
   University of Technology
RP Singhal, A (corresponding author), Netaji Subhas Univ Technol, Dept Elect & Commun Engn, Delhi 110078, India.
EM drmegha.iit@gmail.com; singhalamit.iitd@gmail.com
RI Singhal, Amit/GQI-4592-2022
OI Singhal, Amit/0000-0002-4010-6614; Agarwal, Megha/0000-0003-3434-6555
CR Agarwal Megha, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P242
   Agarwal M, 2019, PATTERN ANAL APPL, V22, P1585, DOI 10.1007/s10044-019-00787-2
   Banerjee P, 2018, EXPERT SYST APPL, V113, P100, DOI 10.1016/j.eswa.2018.06.044
   Bella MIT, 2019, COMPUT ELECTR ENG, V75, P46, DOI 10.1016/j.compeleceng.2019.01.022
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Das P, 2021, IRBM, V42, P245, DOI 10.1016/j.irbm.2020.06.007
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Dey M, 2016, PATTERN ANAL APPL, V19, P1159, DOI 10.1007/s10044-015-0522-y
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P16411, DOI 10.1007/s11042-018-7028-8
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Ghose S, 2020, MULTIMED TOOLS APPL, V79, P18527, DOI 10.1007/s11042-020-08752-6
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   MIT Vision and Modeling Group Cambridge., 2002, VISION TEXTURE
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2013, SPIE, V8663, P230
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng SH, 2010, COMPUT BIOL MED, V40, P931, DOI 10.1016/j.compbiomed.2010.10.005
   Rao LK, 2019, MULTIDIM SYST SIGN P, V30, P1413, DOI 10.1007/s11045-018-0609-x
   Raza A, 2019, MULTIMED TOOLS APPL, V78, P2719, DOI 10.1007/s11042-018-5795-x
   Reddy AH, 2015, AEU-INT J ELECTRON C, V69, P290, DOI 10.1016/j.aeue.2014.09.015
   Roy SK, 2020, MULTIMED TOOLS APPL, V79, P4783, DOI 10.1007/s11042-018-6559-3
   Schmid, 2014, PATTERN RECOGN
   Shyu CR, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P30, DOI 10.1109/IVL.1998.694482
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Sucharitha G, 2020, MULTIMED TOOLS APPL, V79, P1847, DOI 10.1007/s11042-019-08215-7
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Yang WK, 2020, NEUROCOMPUTING, V373, P109, DOI 10.1016/j.neucom.2019.09.102
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
NR 44
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1109
EP 1123
DI 10.1007/s11042-021-11361-6
EA SEP 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698308700003
DA 2024-07-18
ER

PT J
AU Bajpai, S
   Kidwai, NR
   Singh, HV
   Singh, AK
AF Bajpai, Shrish
   Kidwai, Naimur Rahman
   Singh, Harsh Vikram
   Singh, Amit Kumar
TI A low complexity hyperspectral image compression through 3D set
   partitioned embedded zero block coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral imagery; Lossy compression; Memory efficient image sensor;
   Zero block cube; Wavelet transform coding
ID AVIRIS-NG; CHALLENGES; ALGORITHM
AB Memory management of the hyperspectral image sensor is a challenging issue. The existing hyperspectral image compression schemes play a dominant role in minimizing the cost of storage equipment and bandwidth for data transmission for resource constraints onboard hyperspectral image sensors. Traditionally many transform-based set partition hyperspectral image compression algorithms are proposed, but these compression schemes use the data-dependent link list to keep track of the significant or insignificant coefficients or block cube sets, and the size of the lists increases swiftly with the encoding rate. The data-dependent list management and multiple memory read or write operations slow down the compression scheme. Many attempts had been made to address the memory issue through the replacement of the dynamic lists by the static fixed size state tables. The memory required for the state table depends upon the dimension of the hyperspectral image and at the low bit rates, it requires a lot of memory. This paper presents the novel hyperspectral image compression scheme for the hyperspectral image sensor that eliminates the linked list and state table. The obtained experimental results show that the proposed compression scheme outperforms state of the art transform hyperspectral image compression schemes in terms of coding memory and computation complexity while maintaining the coding efficiency. Due to the low complex nature, the proposed scheme saves the operation time and energy for the coding operation. The proposed compression scheme is a suitable candidate for the lossy data transmission and for the low memory hyperspectral sensors.
C1 [Bajpai, Shrish] Dr APJ Abdul Kalam Tech Univ, Elect Engn Dept, Lucknow, Uttar Pradesh, India.
   [Kidwai, Naimur Rahman] Integral Univ, Fac Engn, Dept ECE, Lucknow, Uttar Pradesh, India.
   [Singh, Harsh Vikram] KNIT, Elect Engn Dept, Sultanpur, Uttar Pradesh, India.
   [Singh, Amit Kumar] NIT Patna, Dept CSE, Patna, Bihar, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Integral University;
   Kamla Nehru Institute of Technology Sultanpur; National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Bajpai, S (corresponding author), Dr APJ Abdul Kalam Tech Univ, Elect Engn Dept, Lucknow, Uttar Pradesh, India.
EM shrishbajpai@gmail.com
RI Kidwai, Naimur Rahman/C-1721-2018; Singh, Harsh Vikram/Q-9457-2019;
   Bajpai, Shrish/GPC-4732-2022; Singh, Amit Kumar/D-1300-2015
OI Singh, Harsh Vikram/0000-0002-8904-862X; Bajpai,
   Shrish/0000-0001-5598-1940; Singh, Amit Kumar/0000-0001-7359-2068
CR Alvarez-Cortés S, 2018, INT J REMOTE SENS, V39, P1971, DOI 10.1080/01431161.2017.1375617
   Anand R, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1808, DOI 10.1109/ICACCI.2017.8126107
   Arrigoni S, 2017, COMPUT BIOL MED, V88, P60, DOI 10.1016/j.compbiomed.2017.06.018
   Bajpai S., 2019, INT J INNOVATIVE TEC, V8, P64
   Bajpai S, 2019, MULTIMED TOOLS APPL, V78, P27193, DOI 10.1007/s11042-019-07797-6
   Bajpai S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P97, DOI 10.1109/MSPCT.2017.8363982
   Bhardwaj R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023017
   Chaudhuri S, 2018, P 2018 IEEE EUR C CO, P1
   Cheng KJ, 2013, PROC SPIE, V8743, DOI 10.1117/12.2016200
   Choi I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130810
   Choi Y, 2019, IEEE I CONF COMP VIS, P3146, DOI 10.1109/ICCV.2019.00324
   Christophe E, 2008, IEEE T IMAGE PROCESS, V17, P2334, DOI 10.1109/TIP.2008.2005824
   Chutia D, 2016, T GIS, V20, P463, DOI 10.1111/tgis.12164
   Datta A, 2019, CLOUD COMPUTING GEOS, V49, P265, DOI [10.1007/978-3-030-03359-0_13, DOI 10.1007/978-3-030-03359-0_13]
   Datta A, 2017, IEEE GEOSCI REMOTE S, V14, P82, DOI 10.1109/LGRS.2016.2628078
   Dua Y, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.9.090902
   Dumke I, 2018, REMOTE SENS ENVIRON, V209, P19, DOI 10.1016/j.rse.2018.02.024
   Dusselaar R, 2017, J OPT SOC AM A, V34, P2170, DOI 10.1364/JOSAA.34.002170
   ElMasry G, 2021, J FOOD ENG, V289, DOI 10.1016/j.jfoodeng.2020.110148
   Foster DH, 2019, J OPT SOC AM A, V36, P606, DOI 10.1364/JOSAA.36.000606
   Fowler J.E., 2007, Hyperspectral Data Exploitation: Theory and Applications, P379
   Goetz AFH, 2009, REMOTE SENS ENVIRON, V113, pS5, DOI 10.1016/j.rse.2007.12.014
   Govil H, 2020, ADV INTELL SYST, V1016, P95, DOI 10.1007/978-981-13-9364-8_7
   Guilloteau C, 2020, ASTRON J, V160, DOI 10.3847/1538-3881/ab9301
   Gunasheela KS., 2019, INF COMMUN TECHNOL I, DOI [10.1007/978-981-13-1742-2_49, DOI 10.1007/978-981-13-1742-2_49]
   Hou Y, 2007, PROC SPIE, V6790, DOI 10.1117/12.750975
   Huang B, 2004, PROC SPIE, V5238, P255, DOI 10.1117/12.511437
   Jiang ZC, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060038
   Kidwai NR, 2016, IEEE SENS J, V16, P2575, DOI 10.1109/JSEN.2016.2519600
   Kranjcic N, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060655
   Kumar V, 2019, J INDIAN SOC REMOTE, V47, P447, DOI 10.1007/s12524-018-0889-5
   Kumaresan PR, 2020, PLANET SPACE SCI, V182, DOI 10.1016/j.pss.2019.104817
   Langevin Y, 2000, P SOC PHOTO-OPT INS, V4115, P364, DOI 10.1117/12.411561
   Lee HS, 2002, INT GEOSCI REMOTE SE, P3317, DOI 10.1109/IGARSS.2002.1027168
   Li R, 2019, MULTIMED TOOLS APPL, V78, P11701, DOI 10.1007/s11042-018-6724-8
   Lim S, 2001, INT GEOSCI REMOTE SE, P109, DOI 10.1109/IGARSS.2001.976072
   Liu HH, 2020, IEEE T IMAGE PROCESS, V29, P641, DOI 10.1109/TIP.2019.2933743
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Lyons P, 2018, PROC SPIE, V10628, DOI 10.1117/12.2305175
   Malegori C, 2020, TALANTA, V215, DOI 10.1016/j.talanta.2020.120911
   Mei SH, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111139
   Mishra MK, 2019, CURR SCI INDIA, V116, P1089, DOI 10.18520/cs/v116/i7/1089-1100
   Miyoshi GT, 2018, INT J REMOTE SENS, V39, P4910, DOI 10.1080/01431161.2018.1425570
   Mohan BK, 2015, CURR SCI INDIA, V108, P833
   Nagendran R, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S021969131941008X
   Nageswaran K, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1403-5
   Ngadiran R., 2010, IEEE INT C COMP COMM, P1, DOI [10.1109/ICCCE.2010.5556843, DOI 10.1109/ICCCE.2010.5556843]
   Nguyen HV, 2021, IEEE T GEOSCI REMOTE, V59, P3369, DOI 10.1109/TGRS.2020.3008844
   Pal MD, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P168, DOI 10.1109/IAI.2002.999912
   Penna B, 2007, IEEE T GEOSCI REMOTE, V45, P1408, DOI 10.1109/TGRS.2007.894565
   Picollo M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102843
   Quesada-Barriuso P., 2014, Recent Advances in Knowledge-Based Paradigms and Applications, P19, DOI [DOI 10.1007/978-3-319-01649-8_2, 10.1007/978-3-319-01649-8_2]
   Qureshi R, 2019, PATTERN RECOGN, V90, P12, DOI 10.1016/j.patcog.2019.01.026
   Ramakrishnan D, 2015, CURR SCI INDIA, V108, P879
   Rangnekar A, 2020, IEEE T GEOSCI REMOTE, V58, P8116, DOI 10.1109/TGRS.2020.2987199
   Rao AK, 1996, IEEE T GEOSCI REMOTE, V34, P385, DOI 10.1109/36.485116
   Reshef Edith R, 2020, Int Ophthalmol Clin, V60, P85, DOI 10.1097/IIO.0000000000000293
   Senapati RK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3784-y
   Shahriyar S, 2016, PROC INT C DIGIT IMA, P1, DOI 10.1109/DICTA.2016.7797060
   Sharma D, 2020, IETE TECH REV, V37, P36, DOI 10.1080/02564602.2018.1557569
   Sharma D, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.7.076102
   Shimoni M, 2019, IEEE GEOSC REM SEN M, V7, P101, DOI 10.1109/MGRS.2019.2902525
   Shukla UP, 2018, EXPERT SYST APPL, V97, P336, DOI 10.1016/j.eswa.2017.12.034
   Signoroni A, 2019, J IMAGING, V5, DOI 10.3390/jimaging5050052
   Singh P., 2020, Hyperspectral Remote Sensing :121-146, DOI DOI 10.1016/B978-0-08-102894-0.00009-7
   Singh S, 2018, MULTIMED TOOLS APPL, V77, P27061, DOI 10.1007/s11042-018-5904-x
   Song SW, 2019, ANAL CHEM, V91, P5810, DOI 10.1021/acs.analchem.9b00047
   Srivastava V, 2020, MULTIDIM SYST SIGN P, V31, P221, DOI 10.1007/s11045-019-00658-3
   Subrahmanyam KV, 2020, IETE TECH REV, V37, P211, DOI 10.1080/02564602.2019.1593890
   Sudha VK, 2013, J SCI IND RES INDIA, V72, P735
   Sujitha B, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3976
   Tan YL, 2020, IEEE J-STARS, V13, P471, DOI 10.1109/JSTARS.2020.2964000
   Tang X, 2006, HYPERSPECTRAL DATA COMPRESSION, P273, DOI 10.1007/0-387-28600-4_10
   Tang XL, 2004, IEEE IMAGE PROC, P3283
   Tang XL, 2004, PROC SPIE, V5308, P310, DOI 10.1117/12.526004
   Tang XL, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P239
   Tausif M, 2020, IEEE SENS J, V20, P6863, DOI 10.1109/JSEN.2019.2930006
   Tausif M, 2015, IEEE SENS J, V15, P6218, DOI 10.1109/JSEN.2015.2456332
   Teodoro AM, 2021, IEEE T GEOSCI REMOTE, V59, P2478, DOI 10.1109/TGRS.2020.3006757
   Wang LZ, 2019, IEEE T IMAGE PROCESS, V28, P2257, DOI 10.1109/TIP.2018.2884076
   Wang XH, 2018, J INDIAN SOC REMOTE, V46, P667, DOI 10.1007/s12524-017-0735-1
   Wu JJ, 2006, OPT ENG, V45, DOI 10.1117/1.2173996
   Yang J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010053
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Zhao F, 2010, SIGNAL PROCESS-IMAGE, V25, P697, DOI 10.1016/j.image.2010.07.003
   Zikiou N, 2020, VISUAL COMPUT, V36, P1473, DOI 10.1007/s00371-019-01753-z
NR 86
TC 9
Z9 9
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 841
EP 872
DI 10.1007/s11042-021-11456-0
EA SEP 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696768700002
DA 2024-07-18
ER

PT J
AU Patel, H
   Upla, KP
AF Patel, Heena
   Upla, Kishor P.
TI A shallow network for hyperspectral image classification using an
   autoencoder with convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autoencoder; CNN; ERDAS Imagine; Feature extraction; Hyperspectral
   images; Classification
ID FEATURES; FUSION
AB This paper addresses an approach for the classification of hyperspectral imagery (HSI). In remote sensing, the HSI sensor acquires hundreds of images with narrow and continuous spectral width in visible and near-infrared regions of the electromagnetic (EM) spectrum. Such nature of data acquisition is very useful in the classification and/or the identification of different objects present in the HSI data. However, the low-spatial resolution and large volume of HS images make it more challenging. In the proposed approach, we use an autoencoder with convolutional neural network (AECNN) for the classification of HS images. Pre-processing with autoencoder enhances the features in the HS images which helps to obtain optimized weights in the initial layers of the CNN model. Hence, shallow CNN architecture can be utilized to extract features from the pre-processed HSI data which are used further for the classification of the same. The potential of the proposed approach has been verified by conducting many experiments on various datasets. The classification results obtained using the proposed method are compared with many state-of-the-art deep learning based methods including the winner of the geoscience and remote sensing society (GRSS) Image Fusion Contest-2018 on HSI classification held at IEEE International Geoscience and Remote Sensing Symposium (IGARSS)-2018 and it shows superiority over those methods.
C1 [Patel, Heena; Upla, Kishor P.] Sardar Vallabhbhai Natl Inst Technol, Surat 395007, India.
C3 National Institute of Technology (NIT System); Sardar Vallabhbhai
   National Institute of Technology
RP Upla, KP (corresponding author), Sardar Vallabhbhai Natl Inst Technol, Surat 395007, India.
EM hpatel1323@gmail.com; kishorupla@gmail.com
CR Aptoula E, 2016, IEEE GEOSCI REMOTE S, V13, P1970, DOI 10.1109/LGRS.2016.2619354
   Baumgardner M. F., 2015, 220 Band AVIRIS Hyperspectral Image Data Set: June 12, 1992 Indian Pine Test Site 3, DOI [10.4231/R7RX991C, DOI 10.4231/R7RX991C]
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Camps-Valls G, 2014, IEEE SIGNAL PROC MAG, V31, P45, DOI 10.1109/MSP.2013.2279179
   Cao XY, 2020, IEEE T GEOSCI REMOTE, V58, P4604, DOI 10.1109/TGRS.2020.2964627
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Congalton R.G., 2008, ASSESSING ACCURACY R
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Duan PH, 2019, IEEE T GEOSCI REMOTE, V57, P10336, DOI 10.1109/TGRS.2019.2933588
   Fang S, 2018, INT GEOSCI REMOTE SE, P3860, DOI 10.1109/IGARSS.2018.8517816
   Gao LR, 2015, IEEE GEOSCI REMOTE S, V12, P349, DOI 10.1109/LGRS.2014.2341044
   Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481
   Hao QB, 2020, IEEE T GEOSCI REMOTE, V58, P4263, DOI 10.1109/TGRS.2019.2962014
   Hong DF, 2020, IEEE T GEOSCI REMOTE, V58, P3791, DOI 10.1109/TGRS.2019.2957251
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kingma D. P., 2014, arXiv
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Le Saux B, 2018, IEEE GEOSC REM SEN M, V6, P52, DOI 10.1109/MGRS.2018.2798161
   Li J, 2013, IEEE GEOSCI REMOTE S, V10, P318, DOI 10.1109/LGRS.2012.2205216
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Haut JM, 2018, IEEE T GEOSCI REMOTE, V56, P6440, DOI 10.1109/TGRS.2018.2838665
   Mei T., 2015, PROC CVPR IEEE, P3707
   Mei XG, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080963
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pal M, 2010, IEEE T GEOSCI REMOTE, V48, P2297, DOI 10.1109/TGRS.2009.2039484
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Patel H, 2018, WORKSH COMP VIS APPL
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Spinoulas L, 2015, IEEE COMPUT SOC CONF
   Windrim L, 2018, IEEE T GEOSCI REMOTE, V56, P2798, DOI 10.1109/TGRS.2017.2783886
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Yan DQ, 2018, MULTIMED TOOLS APPL, V77, P5803, DOI 10.1007/s11042-017-4494-3
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhao WZ, 2015, INT J REMOTE SENS, V36, P3368, DOI 10.1080/2150704X.2015.1062157
   Zhu C, 2015, IEEE T IMAGE PROCESS, V24, P5619, DOI 10.1109/TIP.2015.2483376
NR 50
TC 36
Z9 38
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 695
EP 714
DI 10.1007/s11042-021-11422-w
EA SEP 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696143500002
DA 2024-07-18
ER

PT J
AU You, HF
   Yu, L
   Tian, SW
   Ma, X
   Xing, Y
AF You, Hongfeng
   Yu, Long
   Tian, Shengwei
   Ma, Xiang
   Xing, Yan
TI Medical image segmentation based on dual-channel integrated cross-layer
   residual algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-channel network; Deep learning; Integrated module; Medical image
   segmentation
ID EMPIRICAL MODE DECOMPOSITION; REGRESSION
AB Segmentation tasks in medical images have always been a hot topic in the medical imaging field. Compared with traditional images, medical images have richer semantics, which increases the difficulty of feature learning. This paper proposes a new end-to-end dual-channel integrated cross-layer residual algorithm (TIC-Net) based on deep learning to fully mine the semantic information between features for medical image segmentation. First, in the encoder, we built a dual-channel network of traditional convolution and dilated convolution using multiple structures to learn different semantic information from the image and from feature fusion and residual calculation to achieve feature joint mining. Second, we added two sets of new integrated modules between the decoder and encoder to fully fuse the global and local features of each layer of the image in the encoder. Finally, in the decoder, we use a cross-layer feature residual fusion strategy to obtain more semantic information. Compared with the existing partial segmentation model, the proposed deep learning algorithm model achieves the best results with the Kaggle and MICCAI datasets.
C1 [Yu, Long] XinJiang Univ, Network Ctr, Urumqi, Peoples R China.
C3 Xinjiang University
RP Yu, L (corresponding author), XinJiang Univ, Network Ctr, Urumqi, Peoples R China.
EM yul@xju.edu.cn
RI Wang, Zhi/GZB-2713-2022
OI Wang, Zhi/0000-0001-6952-8848; Yu, Long/0000-0002-9038-4129
FU Science and Technology Department of Xinjiang Uyghur Autonomous Region
   [2020E0234]; Xinjiang Autonomous Region key research and development
   project [2021B03001-4]
FX This research is partially supported by Science and Technology
   Department of Xinjiang Uyghur Autonomous Region (2020E0234). Xinjiang
   Autonomous Region key research and development project (2021B03001-4).
   We would also like to thank our tutor for the careful guidance and all
   the participants for their insightful comments.
CR Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   An FP, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101589
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2019, IEEE T MED IMAGING, DOI DOI 10.1109/TMI.2018.2867261
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bonta LR, 2019, L N COMPUT VIS BIOME, V31, P39, DOI 10.1007/978-3-030-04061-1_5
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   Chen, 2020, DEEP LEARNING HEALTH, P79, DOI [10.1007/978-3-030-32606-7_5, DOI 10.1007/978-3-030-32606-7_5]
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen ZJ, 2020, SAFETY SCI, V130, DOI 10.1016/j.ssci.2020.104812
   Chen ZJ, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.06.041
   Chen ZJ, 2019, IEEE INTEL TRANSP SY, V11, P41, DOI 10.1109/MITS.2019.2903525
   Cheng ZP, 2019, CHIN AUTOM CONGR, P3647, DOI [10.1109/cac48633.2019.8996569, 10.1109/CAC48633.2019.8996569]
   Estienne T, 2019, LECT NOTES COMPUT SC, V11766, P310, DOI 10.1007/978-3-030-32248-9_35
   Fan GF, 2020, J FORECASTING, V39, P737, DOI 10.1002/for.2655
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Geng L, 2019, COMPUT ASSIST SURG, V24, P27, DOI 10.1080/24699322.2019.1649071
   Guo HJ, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108661
   HENRY H, 2020, IEEE 17 INT S BIOMED, P1508
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hu C, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P2098, DOI 10.1109/ITNEC48623.2020.9084750
   Huang T, 2020, J NETW COMPUT APPL, V162, DOI 10.1016/j.jnca.2020.102632
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Karimi D, 2020, IEEE T MED IMAGING, V39, P499, DOI 10.1109/TMI.2019.2930068
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Qiang ZW, 2019, LECT NOTES COMPUT SC, V11935, P552, DOI 10.1007/978-3-030-36189-1_46
   Rodríguez-Esparza E, 2020, EXPERT SYST APPL, V155, DOI 10.1016/j.eswa.2020.113428
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shankar K, 2020, IEEE ACCESS, V8, P118164, DOI 10.1109/ACCESS.2020.3005152
   Shin YG, 2021, IEEE T NEUR NET LEAR, V32, P252, DOI 10.1109/TNNLS.2020.2978501
   Wan Y, 2019, PROC SPIE, V11179, DOI 10.1117/12.2540315
   Wang B, 2019, MED PHYS, V46, P1707, DOI 10.1002/mp.13416
   Wang EK, 2020, FUTURE GENER COMP SY, V108, P135, DOI 10.1016/j.future.2020.02.054
   Wang GT, 2019, NEUROCOMPUTING, V338, P34, DOI 10.1016/j.neucom.2019.01.103
   Wang W, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8893419
   Wang W, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8859172
   Xia HY, 2020, NEURAL PROCESS LETT, V51, P2915, DOI 10.1007/s11063-020-10230-x
   Xiao J, 2020, ARXIV200910608
   Xinpeng Xie, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P341, DOI 10.1007/978-3-030-59722-1_33
   Yakopcic, 2018, ARXIV180206955
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   You HF, 2021, KNOWL-BASED SYST, V231, DOI 10.1016/j.knosys.2021.107456
   Zhang Z, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105395
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhu ZT, 2019, INT CONF 3D VISION, P240, DOI 10.1109/3DV.2019.00035
NR 49
TC 3
Z9 3
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5587
EP 5603
DI 10.1007/s11042-021-11326-9
EA SEP 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000695537100002
DA 2024-07-18
ER

PT J
AU Wang, LF
   Dou, JL
   Qin, PL
   Lin, SZ
   Gao, Y
   Wang, RF
   Zhang, J
AF Wang, Lifang
   Dou, Jieliang
   Qin, Pinle
   Lin, Suzhen
   Gao, Yuan
   Wang, Ruifang
   Zhang, Jin
TI Multimodal medical image fusion based on nonsubsampled shearlet
   transform and convolutional sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal medical image fusion; Convolutional sparse representation;
   Nonsubsampled shearlet transform; Regional energy; Improved space
   frequency
AB Multimodal medical image fusion technology can assist doctors diagnose diseases accurately and efficiently. However the multi-scale decomposition based image fusion methods exhibit low contrast and energy loss. And the sparse representation based fusion methods exist weak expression ability caused by the single dictionary and the spatial inconsistency. To solve these problems, this paper proposes a novel multimodal medical image fusion method based on nonsubsampled shearlet transform (NSST) and convolutional sparse representation (CSR). First, the registered source images are decomposed into multi-scale and multi-direction sub-images, and then these sub-images are trained respectively to obtain different sub-dictionaries by the alternating direction product method. Second, different scale sub-images are encoded by the convolutional sparse representation to get the sparse coefficients of the low frequency and the high frequency, respectively. Third, the coefficients of the low frequency are fused by the regional energy and the average L-1 norm. Meanwhile the coefficients of the high frequency are fused by the improved spatial frequency and the average l(1) norm. Finally, the final fused image is reconstructed by inverse NSST. Experimental results on serials of multimodal brain images including CT,MRT2,PET and SPECT demonstrate that the proposed method has the state-of-the-art performance compared with other current popular medical fusion methods whatever in objective and subjective assessment.
C1 [Wang, Lifang; Dou, Jieliang; Qin, Pinle; Lin, Suzhen; Gao, Yuan; Wang, Ruifang; Zhang, Jin] North Univ China, Sch Data Sci & Technol, Shanxi Key Lab Biomed Imaging & Imaging Big Data, Taiyuan, Shanxi, Peoples R China.
C3 North University of China
RP Wang, LF (corresponding author), North Univ China, Sch Data Sci & Technol, Shanxi Key Lab Biomed Imaging & Imaging Big Data, Taiyuan, Shanxi, Peoples R China.
EM 727690392@qq.com
RI Gao, Yuan/JPY-3603-2023
FU Natural Science Foundation of Shanxi Province: Research on texture and
   edge information in medical image fusion of cancer and brain tumor,
   China [201901D111152]
FX Natural Science Foundation of Shanxi Province: Research on texture and
   edge information in medical image fusion of cancer and brain tumor,
   China(201901D111152).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2017, CONVOLUTIONAL SPARSE
   Bengueddoudj A, 2019, LECT NOTE NETW SYST, V50, P225, DOI 10.1007/978-3-319-98352-3_24
   Bristow H, 2013, PROC CVPR IEEE, P391, DOI 10.1109/CVPR.2013.57
   Chavan SS, 2017, COMPUT BIOL MED, V81, P64, DOI 10.1016/j.compbiomed.2016.12.006
   Das S, 2013, IEEE T BIO-MED ENG, V60, P3347, DOI 10.1109/TBME.2013.2282461
   Ganasala P, 2014, BIOMED ENG LETT, V4, P414, DOI 10.1007/s13534-014-0161-z
   Heide F, 2015, PROC CVPR IEEE, P5135, DOI 10.1109/CVPR.2015.7299149
   Izonin Ivan, 2015, 2015 Xth International Scientific and Technical Conference - Computer Sciences and Information Technologies (CSIT). Proceedings, P25, DOI 10.1109/STC-CSIT.2015.7325423
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Kong WW, 2014, INFRARED PHYS TECHN, V67, P161, DOI 10.1016/j.infrared.2014.07.019
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Li XX, 2020, IEEE T INSTRUM MEAS, V69, P6880, DOI 10.1109/TIM.2020.2975405
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Martinez J, 2019, INFORM FUSION, V50, P197, DOI 10.1016/j.inffus.2019.01.003
   Muzammil SR, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10110904
   Rashkevych Y, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P944, DOI 10.1109/UKRCON.2017.8100390
   Singh S, 2015, BIOMED SIGNAL PROCES, V18, P91, DOI 10.1016/j.bspc.2014.11.009
   Tawfik N, 2021, MULTIMED TOOLS APPL, V80, P6369, DOI 10.1007/s11042-020-08834-5
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Vidoni Eric D, 2016, WHOLE BRAIN ATLAS
   Wan W, 2018, STUD SECUR INT AFF, P1
   Wang KP, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19070306
   Wang QX, 2020, J APPL CLIN MED PHYS, V21, P139, DOI 10.1002/acm2.12882
   Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Zhang ZC, 2021, MULTIMED TOOLS APPL, V80, P2847, DOI 10.1007/s11042-020-09647-2
   Zhu ZQ, 2018, INFORM SCIENCES, V432, P516, DOI 10.1016/j.ins.2017.09.010
NR 32
TC 15
Z9 16
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36401
EP 36421
DI 10.1007/s11042-021-11379-w
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692967600002
DA 2024-07-18
ER

PT J
AU Coccoli, M
   De Francesco, V
   Fusco, A
   Maresca, P
AF Coccoli, Mauro
   De Francesco, Vincenzo
   Fusco, Antonio
   Maresca, Paolo
TI A cloud-based cognitive computing solution with interoperable
   applications to counteract illegal dumping in smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart city; Cloud; Cognitive computing; Image recognition; Waste
   management; Environment
AB The study presented in this paper is the outcome of the activity carried on within the program "Party Cloud Challenge per Genova", promoted by IBM in collaboration with the city municipality of Genoa, Italy. This challenge aimed to show how using cognitive computing solutions in an integrated cloud-based development environment enables the rapid deployment of advanced services with interoperable applications. Specifically, we investigated a solution to cope with the problem of illegal dumping prevention in a smart city. In this respect, we will describe the study of the prototype of an automated visual recognition and alerting system. The presented solution relies on the use of cognitive computing technologies to analyze videos provided by cameras installed in urban areas, to identify trash, especially bulky waste, where it should not be, and trigger an alarm to the municipality. In particular, we want to take advantage of the pictures, frames and videos continuously recorded by cameras installed for traffic monitoring, for surveillance, etc. in smart cities where the waste management system is supposed to be integrated with other municipality services for environment control and management. Besides, an organization plan is also proposed for intelligent waste collection as well as some organizational ideas for scalability.
C1 [Coccoli, Mauro] Univ Genoa, DIBRIS, Genoa, Italy.
   [De Francesco, Vincenzo; Maresca, Paolo] Federico II Naples Univ, DIETI, Naples, Italy.
   [Fusco, Antonio] Asia Napoli Spa, Naples, Italy.
C3 University of Genoa; University of Naples Federico II
RP Coccoli, M (corresponding author), Univ Genoa, DIBRIS, Genoa, Italy.
EM mauro.coccoli@unige.it
RI Coccoli, Mauro/P-3795-2019
OI Coccoli, Mauro/0000-0001-5802-138X
FU Universita degli Studi di Genova within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Genova within
   the CRUI-CARE Agreement.
CR Al-Far A, 2018, INT ARAB CONF INF TE, P121
   Anagnostopoulos T, 2017, IEEE T SUST COMPUT, V2, P275, DOI 10.1109/TSUSC.2017.2691049
   Angelino CV, 2018, PROC SPIE, V10790, DOI 10.1117/12.2325557
   Anjum Mohd, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P1108, DOI 10.1109/ICACCCN.2018.8748568
   Aral RA, 2018, IEEE INT CONF BIG DA, P2058, DOI 10.1109/BigData.2018.8622212
   Bai JQ, 2018, IEEE T CONSUM ELECTR, V64, P382, DOI 10.1109/TCE.2018.2859629
   Begur H, 2017, 2017 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTED, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI)
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Coccoli M, 2017, J VISUAL LANG COMPUT, V38, P97, DOI 10.1016/j.jvlc.2016.03.002
   Coccoli M, 2016, J E-LEARN KNOWL SOC, V12, P55
   Coccoli M, 2015, J VISUAL LANG COMPUT, V31, P275, DOI 10.1016/j.jvlc.2015.10.014
   Conseil S., 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1960
   D'Amato A, 2018, SOCIO-ECON PLAN SCI, V64, P56, DOI 10.1016/j.seps.2017.12.006
   Dabholkar A, 2017, 2017 THIRD IEEE INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2017), P255, DOI 10.1109/BigDataService.2017.51
   Del Borghi A., 2014, IMPRESA PROGETTO ELE, V4, P1
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Imtihan A., 2019, CASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering, P376
   Istat, 2020, CONT SAT TUR IT
   Jain Shubhi, 2020, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2019. Advances in Intelligent Systems and Computing (AISC 1087), P699, DOI 10.1007/978-981-15-1286-5_62
   Kambam LR., 2019, P 2019 3 IEEE INT C, P1
   Kedia, 2016, INT J RES ENG TECHNO, V5, P208, DOI [10.15623/ijret.2016.0510034, DOI 10.15623/IJRET.2016.0510034]
   Kochut A, 2011, IBM J RES DEV, V55, DOI 10.1147/JRD.2011.2170920
   Kong S, 2021, IEEE T SYST MAN CY-S, V51, P6358, DOI 10.1109/TSMC.2019.2961687
   Lee S-H., 2019, P 2019 3 HIGH PERF C, P274, DOI [DOI 10.1145/3341069.3341087, 10.1145/3341069.3341087]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo Y., 2008, IEEE COMPUTER SOC C, P1, DOI [DOI 10.1109/CVPRW.2008.4563088, 10.1109/CVPRW.2008.4563088]
   Mahankali S, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2403, DOI 10.1109/ICACCI.2018.8554678
   Manocha S, 2007, PATTERN RECOGN LETT, V28, P1818, DOI 10.1016/j.patrec.2007.05.018
   Mittal G, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P940, DOI 10.1145/2971648.2971731
   Nam T., 2011, P 12 ANN INT DIG GOV, P282, DOI DOI 10.1145/2037556.2037602
   Ng, 2019, INT J COMPUT VISION, V9, P310, DOI [10.1504/IJCVR.2019.099441, DOI 10.1504/IJCVR.2019.099441]
   Nogueira Elias, 2016, Journal of Software Engineering Research and Development, V4, DOI 10.1186/s40411-016-0033-6
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Renjith R, 2019, PROCEEDINGS OF THE 2019 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2019), P73, DOI 10.1109/ised48680.2019.9096246
   Salmador A, 2008, INT J INTERACT MULTI, V1, P31
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Soo S., 2014, OBJECT DETECTION USI, P1
   Torres-García A, 2015, COMPUT SIST, V19, P487, DOI 10.13053/CyS-19-3-2254
   Vambol S, 2019, ECOL QUEST, V30, P43, DOI 10.12775/EQ.2019.018
   Yun K, 2019, ETRI J, V41, P494, DOI 10.4218/etrij.2018-0520
   Zygiaris S, 2013, J KNOWL ECON, V4, P217, DOI 10.1007/s13132-012-0089-4
NR 42
TC 8
Z9 8
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 95
EP 113
DI 10.1007/s11042-021-11238-8
EA SEP 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000692452100001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Spolaôr, N
   Lee, HD
   Takaki, WSR
   Ensina, LA
   Parmezan, ARS
   Oliva, JT
   Coy, CSR
   Wu, FC
AF Spolaor, Newton
   Lee, Huei Diana
   Takaki, Weber Shoity Resende
   Ensina, Leandro Augusto
   Parmezan, Antonio Rafael Sabino
   Oliva, Jefferson Tales
   Coy, Claudio Saddy Rodrigues
   Wu, Feng Chung
TI A video indexing and retrieval computational prototype based on
   transcribed speech
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational web system; Google web speech; Speech to text; TF-IDF;
   Video retrieval; Vitrivr
ID INFORMATION-RETRIEVAL; MEDICAL REPORTS; RECOGNITION; SYSTEM; SEARCH;
   AUDIO
AB Using the voice to interact with systems is attractive in medicine and other areas due to its friendliness and flexibility. Video indexing and retrieval have benefited from this resource. However, few initiatives use speech recognition to support both tasks. This work aims to develop and evaluate a prototype system to index and retrieve videos from speech transcription. In particular, the user can narrate each video's content, generating the utterance that is captured, transformed into text and timestamped by the computational system. Simple text processing techniques are then applied to the obtained transcript before indexing. Afterward, the user can also query by speech or text to find relevant videos previously indexed. We conducted an experimental evaluation of the prototype in sets of 50 and 10 public videos. As part of this process, one collaborator manually narrated the 50 videos, while four others narrated a subset of 13 videos. An automatic narration scheme was also applied to this subset and the set of 10 videos. The evaluation showed promising results regarding Brazilian Portuguese speech recognition and retrieval performance. For example, the average word error rate reached down to 0.03 and the mean average precision achieved up to 1.00. Besides performing well, the computational tool is flexible since few changes are required to support other languages.
C1 [Spolaor, Newton; Lee, Huei Diana; Takaki, Weber Shoity Resende; Ensina, Leandro Augusto; Parmezan, Antonio Rafael Sabino; Oliva, Jefferson Tales; Wu, Feng Chung] Western Parana State Univ UNIOESTE, Lab Bioinformat, Presidente Tancredo Neves Ave 6731, BR-85867900 Foz Do Iguacu, PR, Brazil.
   [Parmezan, Antonio Rafael Sabino] Univ Sao Paulo, Inst Math & Comp Sci, Lab Computat Intelligence, Sao Paulo, SP, Brazil.
   [Oliva, Jefferson Tales] Fed Univ Technol UTFPR, Pato Branco, PR, Brazil.
   [Coy, Claudio Saddy Rodrigues; Wu, Feng Chung] Univ Campinas UNICAMP, Fac Med Sci, Serv Coloproctol, Campinas, SP, Brazil.
C3 Universidade Estadual do Oeste do Parana; Universidade de Sao Paulo;
   Universidade Estadual de Campinas
RP Spolaôr, N (corresponding author), Western Parana State Univ UNIOESTE, Lab Bioinformat, Presidente Tancredo Neves Ave 6731, BR-85867900 Foz Do Iguacu, PR, Brazil.
EM newton.spolaor@unioeste.br; huei.lee@unioeste.br
RI Coy, Claudio/AAD-7599-2019; Spolaôr, Newton/JGC-8342-2023; Lee, Huei
   Diana/D-8219-2015
OI Spolaôr, Newton/0000-0003-0748-3693; Parmezan,
   Antonio/0000-0002-1725-132X; Ensina, Leandro Augusto/0000-0002-4412-7316
FU Araucaria Foundation for the Support of the Scientific and Technological
   Development of Parana [028/2019]; PGEEC/UNIOESTE; Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior -Brasil (CAPES) [001];
   Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq)
   [142050/2019-9]
FX We would like to thank Araucaria Foundation for the Support of the
   Scientific and Technological Development of Parana through a Research
   and Technological Productivity Scholarship for H. D. Lee (grant
   028/2019). We also would like to thank PGEEC/UNIOESTE through a
   postdoctoral scholarship for N. Spolaor, the Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior -Brasil (CAPES) -Finance
   Code 001 through a MSc. scholarship for L. A. Ensina and the Conselho
   Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq) through the
   grant number 142050/2019-9 for A. R. S. Parmezan. These agencies did not
   have any further involvement in this paper.
CR Akosu N, 2014, RECENT DEV COMPUTATI, V513, P157, DOI [10.1007/978-3-31901787-7_15, DOI 10.1007/978-3-31901787-7_15]
   Al Kabary I, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1227, DOI 10.1145/2600428.2609551
   Ambekar T, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), P212, DOI 10.1109/ICISIM.2017.8122175
   Amir A, 2003, EURASIP J APPL SIG P, V2003, P209, DOI 10.1155/S111086570321012X
   Amorim MN, 2017, BRAZ S MULT SYST WEB, P194
   [Anonymous], 2016, PROC IEEE WINTER C A
   Atkins A., 2018, The Journal of Finance and Data Science, V4, P120, DOI [10.1016/j.jfds.2018.02.002, DOI 10.1016/J.JFDS.2018.02.002]
   Bastianelli E, 2017, INT J ROBOT RES, V36, P660, DOI 10.1177/0278364917691112
   Bernard G, 2017, I C ENG TECHNOL
   Besacier L, 2014, SPEECH COMMUN, V56, P85, DOI 10.1016/j.specom.2013.07.008
   Bird S., 2009, NATURAL LANGUAGE PRO
   Cardona DAB, 2017, NEUROCOMPUTING, V265, P78, DOI 10.1016/j.neucom.2016.09.140
   Cao Y, 2004, LECT NOTES COMPUT SC, V3115, P160
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Charrière K, 2014, IEEE ENG MED BIO, P4647, DOI 10.1109/EMBC.2014.6944660
   Choi J, 2013, COMPUT VIS IMAGE UND, V117, P660, DOI 10.1016/j.cviu.2013.02.003
   Christel MG, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1032
   Coulouris G F, 2011, Distributed Systems: Concepts and Design, V5th
   DAGOSTINO RB, 1990, AM STAT, V44, P316, DOI 10.2307/2684359
   Das Dipanjan, 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V6820, p68200B, DOI 10.1117/12.766931
   Barra GD, 2016, INT WORK CONTENT MUL
   De Rooij O, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379793
   de Toledo TF, 2019, INT J MED INFORM, V121, P39, DOI 10.1016/j.ijmedinf.2018.10.010
   Doan A, 2011, COMMUN ACM, V54, P86, DOI 10.1145/1924421.1924442
   Ghoulam A, 2018, INT J INTELL INF TEC, V14, P1, DOI 10.4018/IJIIT.2018070101
   Giannakopoulos T, 2008, INT C PATT RECOG, P1846
   Girish KVV, 2019, BEGINNERS GUIDE SPEE
   Goel P, 2017, LECT NOTES COMPUT SC, V10193, P749, DOI 10.1007/978-3-319-56608-5_75
   Gomez-Duran J, 2017, ESPACIOS, V38, P4
   Granell E, 2018, COMPUT INTELL-US, V34, P398, DOI 10.1111/coin.12169
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Huurnink B, 2012, IEEE T MULTIMEDIA, V14, P1166, DOI 10.1109/TMM.2012.2193561
   Ianeva TI, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1607, DOI 10.1109/ICME.2004.1394557
   Inoue N., 2016, ITE TRANS MEDIA TECH, V4, P209, DOI DOI 10.3169/MTA.4.209
   Iwata S, 2016, INT C PATT RECOG, P4005, DOI 10.1109/ICPR.2016.7900260
   Jiang L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P49, DOI 10.1145/2733373.2806237
   Johnson M, 2014, BMC MED INFORM DECIS, V14, DOI 10.1186/1472-6947-14-94
   Johnston AB., 2014, WEBRTC APIS RTCWEB P
   Johnston AB, 2001, PROFESSIONAL JAVA SE
   Kamabathula V. K., 2011, Proceedings of the 2011 Third International Conference on Technology for Education (T4E 2011), P96, DOI 10.1109/T4E.2011.23
   Kayama A, 2007, OPUS, V13, P16
   Kemp T., 2001, International Journal of Speech Technology, V4, P177, DOI 10.1023/A:1011348306007
   Larson M, 2010, LECT NOTES COMPUT SC, V6242, P354, DOI 10.1007/978-3-642-15751-6_46
   Li H, 2010, INFORMEDIA TRECVID 2
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Luong Thi H., 2016, Worldwide Language Service Infrastructure. Second International Workshop, WLSI 2015. Revised Selected Papers: LNAI 9442, P147, DOI 10.1007/978-3-319-31468-6_11
   Machado Renato Bobsin, 2012, J. Coloproctol. (Rio J.), V32, P50
   Mitrovic D, 2011, INT WORKSH IM AN MUL, P1
   Mühling M, 2016, LECT NOTES COMPUT SC, V9819, P67, DOI 10.1007/978-3-319-43997-6_6
   Neto N., 2011, J BRAZILIAN COMPUTER, V17, P53
   Ojala, 2004, ACM SIGMM INT WORKSH, P197, DOI [10.1145/1026711.1026744, DOI 10.1145/1026711.1026744]
   Oliva JT, 2019, EXPERT SYST APPL, V115, P37, DOI 10.1016/j.eswa.2018.08.004
   Pala M, 2019, INT J SPEECH TECHNOL, V22, P433, DOI 10.1007/s10772-019-09598-6
   Pereira MHR, 2015, MULTIMED TOOLS APPL, V74, P10923, DOI 10.1007/s11042-014-2311-9
   Pham NM, 2013, PROC INT CONF ADV, P549, DOI 10.1109/ATC.2013.6698176
   Pham NM, 2013, PROC INT CONF ADV, P652, DOI 10.1109/ATC.2013.6698195
   Pranali B, 2015, INT CONF COMPUT INTE, P382, DOI 10.1109/CICN.2015.315
   Pressman R. S., 2010, Software Engineering: A Practitioner's Approach
   Priya R, 2013, FRONT COMPUT SCI-CHI, V7, P782, DOI 10.1007/s11704-013-1276-6
   Quilici AF., 2000, COLONOSCOPY
   Radha N, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 2, P115
   Rahman MM, 2012, INT J ADV COMPUT SC, V3, P131
   Ravinder M., 2016, INT J ENG TECHNOL, V7, P2156
   Repp S, 2008, ITICSE '08: PROCEEDINGS OF THE 13TH ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P17
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Rossetto L, 2018, ACM SIGMULTIMEDIA RE, V9
   Rudinac S, 2010, LECT NOTES COMPUT SC, V5993, P645, DOI 10.1007/978-3-642-12275-0_67
   Saita J, 2018, OK GOOGLE SPEECH REC
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Schoeffmann K, 2016, PROC SPIE, V9786, DOI 10.1117/12.2216864
   Shao L, 2014, IEEE T CIRC SYST VID, V24, P504, DOI 10.1109/TCSVT.2013.2276700
   Sharma R, 2013, Patent US, Patent No. 8380558
   Sheikh I, 2017, IEEE-ACM T AUDIO SPE, V25, P598, DOI 10.1109/TASLP.2017.2651361
   Silva CPA, 2010, THESIS PARA FEDERAL
   Singh A., 2013, WORKSH SPEECH AUD MU, P90
   Singhal A., 2001, IEEE DATA ENG B, V24, P35
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Spolaôr N, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103557
   Sprugnoli R, 2017, LANG RESOUR EVAL, V51, P283, DOI 10.1007/s10579-016-9372-5
   Tahayna Bashar, 2010, Proceedings of 2010 International Symposium on Information Technology (ITSim 2010), P783, DOI 10.1109/ITSIM.2010.5561553
   Vigneshwari G, 2015, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON SOFT-COMPUTING AND NETWORKS SECURITY (ICSNS 2015)
   Vogel M, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.5072
   Waheed K, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P328
   Wang X, 2018, INT J MACH LEARN CYB, V9, P373, DOI 10.1007/s13042-015-0426-6
   Wei XY, 2011, IEEE T CIRC SYST VID, V21, P62, DOI 10.1109/TCSVT.2011.2105597
   Witbrock MJ, 1998, J AM SOC INFORM SCI, V49, P619, DOI 10.1002/(SICI)1097-4571(19980515)49:7<619::AID-ASI4>3.0.CO;2-A
   Wu FC, 2010, Patent BR INPI, Patent No. 01810036941
   Xiang Ji, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3633, DOI 10.1109/ICIP.2011.6116505
   Yang HJ, 2014, IEEE T LEARN TECHNOL, V7, P142, DOI 10.1109/TLT.2014.2307305
   Yin YF, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700287
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Zhai Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P965, DOI 10.1109/ICME.2006.262693
   Zhao BQ, 2016, J AM MED INFORM ASSN, V23, pE34, DOI 10.1093/jamia/ocv123
NR 93
TC 4
Z9 4
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33971
EP 34017
DI 10.1007/s11042-021-11401-1
EA AUG 2021
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000690817900001
DA 2024-07-18
ER

PT J
AU Wang, CY
   Ren, Y
   Zhang, N
   Cui, FW
   Luo, SY
AF Wang, Chunyi
   Ren, Ying
   Zhang, Na
   Cui, Fuwei
   Luo, Shiying
TI Speech emotion recognition based on multi-feature and multi-lingual
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Feature extraction; Multi-feature fusion;
   Multi-lingual fusion; Deep neural networks (DNN)
AB A speech emotion recognition algorithm based on multi-feature and Multi-lingual fusion is proposed in order to resolve low recognition accuracy caused bylack of large speech dataset and low robustness of acoustic features in the recognition of speech emotion. First, handcrafted and deep automatic features are extractedfrom existing data in Chinese and English speech emotions. Then, the various features are fused respectively. Finally, the fused features of different languages are fused again and trained in a classification model. Distinguishing the fused features with the unfused ones, the results manifest that the fused features significantly enhance the accuracy of speech emotion recognition algorithm. The proposedsolution is evaluated on the two Chinese corpus and two English corpus, and isshown to provide more accurate predictions compared to original solution. As a result of this study, the multi-feature and Multi-lingual fusion algorithm can significantly improve the speech emotion recognition accuracy when the dataset is small.
C1 [Wang, Chunyi] Vanderbilt Univ, Dept Comp Sci, Nashville, TN 37235 USA.
   [Ren, Ying; Zhang, Na] Beijing Jiaotong Univ, Sch Econ & Management, Beijing 100044, Peoples R China.
   [Cui, Fuwei] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
   [Luo, Shiying] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 101408, Peoples R China.
C3 Vanderbilt University; Beijing Jiaotong University; Beijing Jiaotong
   University; Chinese Academy of Sciences; University of Chinese Academy
   of Sciences, CAS
RP Ren, Y; Zhang, N (corresponding author), Beijing Jiaotong Univ, Sch Econ & Management, Beijing 100044, Peoples R China.
EM chunyi.wang@vanderbilt.edu; renying@bjtu.edu.cn; zhangna@bjtu.edu.cn
CR Bertero D, 2017, INT CONF ACOUST SPEE, P5115, DOI 10.1109/ICASSP.2017.7953131
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Fu L., 2018, J LOGISTICS INFORMAT, V5, P55
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Huang JT, 2013, INT CONF ACOUST SPEE, P7304, DOI 10.1109/ICASSP.2013.6639081
   Jackson Philip, 2011, Surrey audio-visual expressed emotion (SAVEE) database.
   Kandali AB, 2008, TENCON IEEE REGION, P1543
   Kim JW, 2018, INTERSPEECH, P937, DOI 10.21437/Interspeech.2018-1132
   Lapkova D., 2018, J SYST MANAG SCI, V8, P23
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lee CM, 2001, ASRU 2001: IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, CONFERENCE PROCEEDINGS, P240, DOI 10.1109/ASRU.2001.1034632
   Li Y, 2017, J AMB INTEL HUM COMP, V8, P913, DOI 10.1007/s12652-016-0406-z
   Mao X, 2007, ELE COM ENG, P369
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Ousidhoum N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4675
   Pao TL, 2004, 2004 INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, P301
   Petrushin V.A., 2000, 6 INT C SPOK LANG PR
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688
   Voican O, 2020, ECON COMPUT ECON CYB, V54, P159, DOI 10.24818/18423264/54.1.20.11
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   Zhang BQ, 2019, IEEE T AFFECT COMPUT, V10, P85, DOI 10.1109/TAFFC.2017.2684799
NR 24
TC 18
Z9 19
U1 6
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4897
EP 4907
DI 10.1007/s11042-021-10553-4
EA AUG 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000690714100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, SS
   Chang, CC
   Lin, CC
AF Chen, Sisheng
   Chang, Chin-Chen
   Lin, Chia-Chen
TI Reversible data hiding in encrypted images based on homomorphism and
   block-based congruence transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Encrypted images; Homomorphism; Multi-secret
   sharing; Congruence relation
ID SCHEME
AB Reversible data hiding in encrypted images (RDHEI) is a technique that allows for secret data to be embedded in images while preserving the privacy of the image content when the image owner and the data hider are different entities. This paper proposes a new reversible data hiding scheme in encrypted images, in which the data hider does not need a data hiding key in the data embedding process. We first reserve embedding room before image encryption based on the congruence relations of pixel values within image blocks. Then, the pre-processed original image is encrypted using a multi-secret sharing based image encryption algorithm that satisfies additive homomorphism. Using the homomorphism of the image encryption, we embed the secret data into the reserved embedding room directly in the encrypted images without a data hiding key. The receiver can extract the secret data by checking the congruence relation between pixel values in a decrypted image block and then recover the original image. We analyze the security of the proposed scheme and embedding capacity with different block sizes and different parameters of transformation. The experimental results and analysis show that the proposed scheme achieves a high embedding capacity with a suitable block size especially in smooth images.
C1 [Chen, Sisheng] Fujian Polytech Normal Univ, Sch Big Data & Artificial Intelligence, Fuzhou 350300, Peoples R China.
   [Chen, Sisheng; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chen, Sisheng] Fujian Prov Univ, Fujian Polytech Normal Univ, Engn Res Ctr ICH Digitalizat & Multisource Inform, Fuzhou 350300, Peoples R China.
   [Lin, Chia-Chen] Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
C3 Fujian Polytechnic Normal University; Feng Chia University; Fujian
   Polytechnic Normal University; Fuzhou University; National Chin-Yi
   University of Technology
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
OI Lin, Chia-Chen/0000-0003-4480-7351
FU Education-Scientific Project for Youth Teacher of Fujian province
   [JT180618]; Natural Science Foundation of Fujian Province of China
   [2020J01300]; Engineering Research Center for ICH Digitalization and
   Multi-Source Information Fusion of Fujian Province University [FJ-ICH
   201901]
FX This work was supported in part by for Education-Scientific Project for
   Youth Teacher of Fujian province under grant: JT180618, in part by
   Natural Science Foundation of Fujian Province of China under Grant:
   2020J01300, and in part by Engineering Research Center for ICH
   Digitalization and Multi-Source Information Fusion of Fujian Province
   University under grant: FJ-ICH 201901.
CR Abdul MS., 2014, SIGNAL PROCESS, V94, P74, DOI [10.1016/j.sigpro.2013.05.007, DOI 10.1016/J.SIGPRO.2013.05.007]
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chang CC, 2018, IEEE ACCESS, V6, P70720, DOI 10.1109/ACCESS.2018.2880904
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chen YC, 2019, IEEE T INF FOREN SEC, V14, P3332, DOI 10.1109/TIFS.2019.2914557
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Franklin M., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P699, DOI 10.1145/129712.129780
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Li M, 2019, IEEE ACCESS, V7, P69808, DOI 10.1109/ACCESS.2019.2919376
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P11591, DOI 10.1007/s11042-019-08460-w
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   PUTEAUX P, 2020, IEEE T MULTIMEDIA BE
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P18815, DOI 10.1007/s11042-020-08745-5
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Xu Y, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102804
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Ying QC, 2019, IEEE ACCESS, V7, P46506, DOI 10.1109/ACCESS.2019.2909560
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 38
TC 1
Z9 1
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 33115
EP 33138
DI 10.1007/s11042-021-11324-x
EA AUG 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000684916500002
DA 2024-07-18
ER

PT J
AU Pradeepa, S
   Sasikaladevi, N
   Manjula, KR
AF Pradeepa, S.
   Sasikaladevi, N.
   Manjula, K. R.
TI Emotion aware feature based opining mining on large scale data by
   exploring hypergraph with helly property
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature based opining mining; Hypergraph; Helly property; Feature
   selection; Large scale data set
ID TERM WEIGHTING SCHEME; SENTIMENT ANALYSIS; REVIEWS
AB Customers making product purchases and businesses looking for feedback on their items have grown to rely on feature-based online comments provided by users on e-commerce platforms. As a result, it's critical to create aspect-based opinion mining frameworks that focus on obtaining consumers' feature-based judgments about products. Nowadays people convey their opinions and provide their experiences that significantly affect new purchasers in buying products, thus it leads to maintenance of large data sets. This massive amount of data is extremely beneficial for studying user preferences, desires, and behavior in relation to a product. E-commerce service providers face the difficult task of evaluating such vast amounts of data in order to derive client feedback. In order to resolve this issue, we explored Hypergraph with Helly property to perform emotion aware aspect-based opinion mining on real-world customer review data. In this paper, we are proposing a new distributed Hypergraph with Helly property algorithm for opinion mining to work on distributed Hadoop environment. Because of the large size data set, the suggested feature-based opinion mining system surpasses the alternative approaches in terms of greater accuracy and less time complexity, according to the performance evaluation using state-of-the-art methods. The proposed methodology is more efficient for extracting aspect-sentiment, categorizing, and summarizing online product reviews, according to the experimental results.
C1 [Pradeepa, S.; Sasikaladevi, N.; Manjula, K. R.] SASTRA Deemed Univ, Sch Comp, Thanjavur, TN, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Manjula, KR (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, TN, India.
EM manjula@cse.sastra.edu
RI R, Manjula K/AAI-5805-2020
OI Varma, Manjula/0000-0001-5639-2566
CR Ali F, 2016, APPL SOFT COMPUT, V47, P235, DOI 10.1016/j.asoc.2016.06.003
   Archak N, 2011, MANAGE SCI, V57, P1485, DOI 10.1287/mnsc.1110.1370
   Asghar MZ, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2809-x
   Bai X, 2011, DECIS SUPPORT SYST, V50, P732, DOI 10.1016/j.dss.2010.08.024
   Barbosa L., 2010, Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING '10, P36, DOI DOI 10.1145/3167132.3167324
   Bouazizi M, 2017, IEEE ACCESS, V5, P20617, DOI 10.1109/ACCESS.2017.2740982
   Bretto A., 2013, Hypergraph Theory: An Introduction, P111
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Chaturvedi I, 2018, INFORM FUSION, V44, P65, DOI 10.1016/j.inffus.2017.12.006
   Deng ZH, 2014, EXPERT SYST APPL, V41, P3506, DOI 10.1016/j.eswa.2013.10.056
   Deshmukh Jyoti S., 2018, Applied Computing and Informatics, V14, P55, DOI 10.1016/j.aci.2017.03.001
   El Rahman SA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P336, DOI 10.1109/iccisci.2019.8716464
   Ghani NA, 2019, COMPUT HUM BEHAV, V101, P417, DOI 10.1016/j.chb.2018.08.039
   Hou TJ, 2019, EXPERT SYST APPL, V132, P141, DOI 10.1016/j.eswa.2019.04.069
   Huang JX, 2018, INFORM SYST, V78, P199, DOI 10.1016/j.is.2018.02.002
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Indurkhya N, 2010, CH CRC MACH LEARN PA, pXXI
   Jagdale Rajkumar S., 2019, Cognitive Informatics and Soft Computing. Proceeding of CISC 2017. Advances in Intelligent Systems and Computing (AISC 768), P639, DOI 10.1007/978-981-13-0617-4_61
   Kim K, 2018, EXPERT SYST APPL, V109, P49, DOI 10.1016/j.eswa.2018.05.023
   Kouloumpis E., 2011, Icwsm, P538
   Lu Y, 2010, LECT NOTES COMPUT SC, V6184, P471, DOI 10.1007/978-3-642-14246-8_46
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Molnar B., 2014, Annales Universitatis Scientiarum Budapestinensis de Rolando Eotvos Nominatae, Sectio Geologica, V42, P261
   MULDER HM, 1979, DISCRETE MATH, V25, P41, DOI 10.1016/0012-365X(79)90151-1
   Nielsen F. A., 2011, ARXIV
   Pennebaker JW, 2003, ANNU REV PSYCHOL, V54, P547, DOI 10.1146/annurev.psych.54.101601.145041
   Rathan M, 2018, APPL SOFT COMPUT, V68, P765, DOI 10.1016/j.asoc.2017.07.056
   Riaz S, 2019, CLUSTER COMPUT, V22, pS7149, DOI 10.1007/s10586-017-1077-z
   Saif Hassan, 2012, The Semantic Web. 11th International Semantic Web Conference (ISWC 2012). Proceedings, P508, DOI 10.1007/978-3-642-35176-1_32
   Saini M, 2019, ADV INTELL SYST, V759, P3, DOI 10.1007/978-981-13-0341-8_1
   Sivarajah U, 2020, IND MARKET MANAG, V86, DOI 10.1016/j.indmarman.2019.04.005
   Tewari Anand S., 2019, Proceedings of International Ethical Hacking Conference 2018 (eHaCON 2018). Advances in Intelligent Systems and Computing (AISC 811), P443, DOI 10.1007/978-981-13-1544-2_36
   Wang H., 2012, P ACL 2012 SYST DEM, P115, DOI DOI 10.1145/1935826.1935854
   Wang WM, 2018, ENG APPL ARTIF INTEL, V73, P149, DOI 10.1016/j.engappai.2018.05.005
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Wu CH, 2018, KNOWL-BASED SYST, V148, P66, DOI 10.1016/j.knosys.2018.01.019
   Yang B, 2019, INT J INFORM MANAGE, V46, P173, DOI 10.1016/j.ijinfomgt.2018.12.006
   Zin HM, 2018, ADV SCI LETT, V24, P933, DOI 10.1166/asl.2018.10661
NR 38
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30919
EP 30938
DI 10.1007/s11042-021-11311-2
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000684489400002
DA 2024-07-18
ER

PT J
AU Aydinlilar, M
   Akyuz, AO
   Tari, S
AF Aydinlilar, Merve
   Akyuz, Ahmet Oguz
   Tari, Sibel
TI An experimental evaluation of visual similarity for HDR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HDR imaging; Visual similarity; Tone mapping
ID TONE REPRODUCTION; OPERATOR; DISPLAY
AB In this paper, we investigate visual similarity for high dynamic range (HDR) images. We collect crowdsourcing data through a web-based experimental interface, in which the participants are asked to choose one of the two candidate images as being more similar to the query image. Triplets forming the query-and-candidates sets are obtained by random sampling from existing HDR data sets. Experimental control factors include choice of tone mapping operator (TMO), choice of distance metric, and choice of image feature. The image features that we experiment with are chosen from the features that are commonly used in the usual low dynamic range setting including features learned via Convolutional Neural Networks. The set of image features also includes combined features where the combination coefficients are estimated using logistic regression. We compute correlations between human judgments and quantitative features to understand how much each feature contributes to visual similarity. Combined features yield nearly 84% agreement with human judgments when applied on tone mapped images. Though we observed that using common features directly on raw or linearly scaled HDR images yield subpar correlation estimates compared to using them on tone mapped HDR images, we did not observe significant effect due to the choice of TMO on the estimates. As an application, we propose an improvement to style-based tone mapping for more correctly imparting desired styles to HDR images with different characteristics.
C1 [Aydinlilar, Merve; Akyuz, Ahmet Oguz; Tari, Sibel] Middle East Tech Univ, Dept Comp Engn, Ankara, Turkey.
C3 Middle East Technical University
RP Akyuz, AO (corresponding author), Middle East Tech Univ, Dept Comp Engn, Ankara, Turkey.
EM merve@ceng.metu.edu.tr; akyuz@ceng.metu.edu.tr; sibel@ceng.metu.edu.tr
RI Akyuz, Ahmet O/A-7956-2018; Tari, Sibel/B-4905-2011
OI Akyuz, Ahmet/0000-0001-7685-5572; Tari, Sibel/0000-0003-4485-2806
CR Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   [Anonymous], EMPA HDR IMAGE DATAB
   Banterle F, 2011, ADVANCED HIGH DYNAMIC RANGE IMAGING: THEORY AND PRACTICE, P1
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhattacharyya A, 1946, SANKHYA, V7, P401
   Brown KC., 2010, J FORENSIC IDENTIFIC, V60, P449
   Cai H, 2013, LIGHTING RES TECHNOL, V45, P230, DOI 10.1177/1477153512453273
   Cerda-Company X, 2018, J OPT SOC AM A, V35, P626, DOI 10.1364/JOSAA.35.000626
   Chalmers A., 2016, High Dynamic Range Video, Concepts, Technologies, and Applications
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Debevec Paul E, 2008, ACM SIGGRAPH 2008 CL, P1, DOI DOI 10.1145/1401132.1401174
   Donahue J, 2014, PR MACH LEARN RES, V32
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fairchild MD, 2007, FIFTEENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, FINAL PROGRAM AND PROCEEDINGS, P233
   Fattal R., 2002, ACM Transactions on Graphics, V21, P249, DOI 10.1145/566570.566573
   Ferradans S, 2011, IEEE T PATTERN ANAL, V33, P2002, DOI 10.1109/TPAMI.2011.46
   Ferwerda J. A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P249, DOI 10.1145/237170.237262
   Frese T, 1997, P SOC PHOTO-OPT INS, V3016, P472, DOI 10.1117/12.274545
   Froehlich J, 2014, PROC SPIE, V9023, DOI 10.1117/12.2040003
   Glassner A.S., 1995, PRINCIPLES DIGITAL I, V1
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Grimaldi A, 2019, J VISION, V19, DOI 10.1167/19.2.13
   Grinzato E, 2009, SPIE DEFENSE SECURIT
   Hanhart P, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0091-4
   Happa J, 2010, P 11 INT C VIRT REAL, P17
   Harifi S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGY AND INFORMATION MANAGEMENT (ICCTIM), P115, DOI 10.1109/ICCTIM.2015.7224603
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   ISO EN, 2011, 116644 ISO EN
   Kalantari N. K., 2017, ACM Trans. Graph., V36, DOI DOI 10.1145/3072959.3073609
   Kleiman Y, 2016, VISUAL COMPUT, V32, P1045, DOI 10.1007/s00371-016-1266-4
   Klíma M, 2011, RADIOENGINEERING, V20, P1016
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundu D., 2017, ESPL LIVE HDR IMAGE
   Kundu D., 2017, IEEE T IMAGE PROCESS, V26, P4725, DOI DOI 10.1109/TIP.2017.2713945
   Larson G.W., 1998, MKS COMP GRAPH GEOME
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lun ZL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766929
   Mai ZC, 2011, IEEE T IMAGE PROCESS, V20, P1558, DOI 10.1109/TIP.2010.2095866
   Mantiuk Ratal, 2009, Journal of Graphics Tools, V14, P43
   Mantiuk R., 2007, Forsch. Wiss. Rechnen, V72, P11
   Mantiuk R., 2006, ACM Transactions on Applied Perception, V3, P286, DOI DOI 10.1145/1166087.1166095
   Mantiuk R, 2008, COMPUT GRAPH FORUM, V27, P699, DOI 10.1111/j.1467-8659.2008.01168.x
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Nemoto H., 2015, 9 INT WORKSHOP VIDEO
   Neumann D., 2006, ACM Trans. Appl. Percept, V3, P31, DOI DOI 10.1145/1119766.1119769
   Oguz Akyuz A, 2013, SIGGRAPH ASIA 2013 T
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   Rawat S, 2018, LECT NOTES COMPUT SC, V10704, P216, DOI 10.1007/978-3-319-73603-7_18
   Reinhard E, 2005, IEEE T VIS COMPUT GR, V11, P13, DOI 10.1109/TVCG.2005.9
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Reinhard E., 2010, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting
   Rizzi A, 2018, IET COMPUT VIS, V12, P976, DOI 10.1049/iet-cvi.2018.5252
   Rogowitz BE, 1998, P SOC PHOTO-OPT INS, V3299, P576, DOI 10.1117/12.320148
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Sharma M, 2015, IEEE IMAGE PROC, P4614, DOI 10.1109/ICIP.2015.7351681
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   STANDARD SMPTE, 2016, DYN MET COL VOL TRAN
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Theodor JM, 2009, PALAEONTOL ELECTRON, V12
   Tocci MD, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964936
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554
   UPTON GJG, 1992, J ROY STAT SOC A STA, V155, P395, DOI 10.2307/2982890
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wu HHP, 2012, APPL OPTICS, V51, P6870, DOI 10.1364/AO.51.006870
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang B, 2003, P JCIS INT C COMP VI
   Zhou Bolei, 2017, PROC CVPR IEEE, P633, DOI DOI 10.1109/CVPR.2017.544
NR 78
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32449
EP 32472
DI 10.1007/s11042-021-11182-7
EA JUL 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679762700002
DA 2024-07-18
ER

PT J
AU Kushwaha, A
   Khare, A
   Srivastava, P
AF Kushwaha, Arati
   Khare, Ashish
   Srivastava, Prashant
TI On integration of multiple features for human activity recognition in
   video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Discrete wavelet transform; Multiscale local
   binary pattern; Histogram of oriented gradients; Support vector machine
ID LOCAL BINARY PATTERN; WAVELET TRANSFORM; CLASSIFICATION; FRAMEWORK;
   HISTOGRAM; SHAPE
AB Human activity recognition has become one of the most active areas of research in computer vision, due to its increasing demand in many automated monitoring applications such as visual surveillance, human-computer interaction, health care, security systems, and many more. This work aims to introduce an integrated feature descriptor which combines texture feature and shape feature, at multiple orientations, to construct the efficient and robust feature vector for activity recognition in realistic scenarios. This feature descriptor is an integration of Discrete Wavelet Transform (DWT), multiscale Local Binary Pattern, and Histogram of Oriented Gradients (HOG). HOG descriptor extracts local-oriented histograms of the frame sequences, multiscale LBP gives the complex structural information of the frames and DWT gives the directional information at multiple scales. By exploiting these properties, we have constructed an integrated feature descriptor to construct the feature vector and achieves promising results of activity recognition in realistic videos. Multiclass Support Vector Machine (SVM) classifier with one-vs-one architecture has been used for activity recognition. The experiments are performed on five benchmark publicly available video datasets, namely Weizmann, IXMAS, UT Interaction, HMDB51, and UCF101. The experimental results are compared with the results of other state-of-art methods based on conventional machine learning and deep learning-based methods to show the effectiveness and usefulness of the proposed work. The experimental results have demonstrated that the proposed method performs better than the other state-of-art methods.
C1 [Kushwaha, Arati; Khare, Ashish] Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
   [Srivastava, Prashant] NIIT Univ, Neemrana, Rajasthan, India.
C3 University of Allahabad; NIIT University, Rajasthan
RP Kushwaha, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
EM aratikushwaha.jk@gmail.com; ashishkhare@hotmail.com;
   prashant.jk087@gmail.com
RI Khare, Ashish/D-4566-2012; Kushwaha, Arati/ABG-4933-2020
OI Kushwaha, Arati/0000-0002-4425-8615; Srivastava,
   Prashant/0000-0002-5812-2022
CR Ahad MAR, 2016, J MULTIMODAL USER IN, V10, P335, DOI 10.1007/s12193-016-0229-4
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   Akula A, 2018, COGN SYST RES, V50, P146, DOI 10.1016/j.cogsys.2018.04.002
   Almaadeed N., 2019, ARXIV PREPRINT ARXIV
   Althloothi S, 2014, PATTERN RECOGN, V47, P1800, DOI 10.1016/j.patcog.2013.11.032
   Aly S, 2019, MULTIMED TOOLS APPL, V78, P24923, DOI 10.1007/s11042-019-7674-5
   [Anonymous], 2012, UCF101 DATASET 101 H
   [Anonymous], ACM INT C IM VID RET
   Avola D, 2019, MULTIMED TOOLS APPL, V78, P5919, DOI 10.1007/s11042-018-6875-7
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P69, DOI 10.1007/s11042-009-0351-3
   Ben-Arie J, 2002, IEEE T PATTERN ANAL, V24, P1091, DOI 10.1109/TPAMI.2002.1023805
   Bhatti N, 2018, MULTIMED TOOLS APPL, V77, P9111, DOI 10.1007/s11042-017-4808-5
   Bi FM, 2020, CMC-COMPUT MATER CON, V62, P199, DOI 10.32604/cmc.2020.06258
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Carlsson S, 2001, WORKSH MOD VERS EX C, V1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cohen I, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P74
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Nguyen DT, 2013, PATTERN RECOGN, V46, P1485, DOI 10.1016/j.patcog.2012.10.024
   Fernández A, 2011, MACH VISION APPL, V22, P913, DOI 10.1007/s00138-010-0253-4
   Gadekallu TR, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020274
   Gonzalez R.C., 2002, DIGITAL IMAGE PROCES, P793
   Gumaei A, 2020, CMC-COMPUT MATER CON, V65, P1033, DOI 10.32604/cmc.2020.011740
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jamel AAM, 2020, COMPUT SYST SCI ENG, V35, P441
   Kabir MH, 2019, INTELL AUTOM SOFT CO, V25, P673, DOI 10.31209/2018.100000035
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kellokumpu V, 2011, MACH VISION APPL, V22, P767, DOI 10.1007/s00138-009-0233-8
   Khare M, 2017, MULTIMED TOOLS APPL, V76, P1247, DOI 10.1007/s11042-015-3068-5
   Kim SJ, 2014, PATTERN RECOGN LETT, V49, P40, DOI 10.1016/j.patrec.2014.05.018
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumaran N, 2018, MULTIMED TOOLS APPL, V77, P23115, DOI 10.1007/s11042-017-5591-z
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Liu CW, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/3508350
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Moussa MM, 2015, J ADV RES, V6, P163, DOI 10.1016/j.jare.2013.11.007
   Murtaza F, 2016, IET COMPUT VIS, V10, P758, DOI 10.1049/iet-cvi.2015.0416
   Nigam S, 2016, MULTIMED TOOLS APPL, V75, P17303, DOI 10.1007/s11042-015-3000-z
   Nigam S, 2015, MULTIMED TOOLS APPL, V74, P7037, DOI 10.1007/s11042-014-1951-0
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2011, COMPUT IMAGING VIS, V40, P13, DOI 10.1007/978-0-85729-748-8_2
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Seemanthini K., 2018, Procedia Computer Science, V132, P1317, DOI 10.1016/j.procs.2018.05.048
   Sharif A, 2019, CONTROL ENG APPL INF, V21, P3
   Sharif M, 2020, PATTERN ANAL APPL, V23, P281, DOI 10.1007/s10044-019-00789-0
   Sharma C.M., 2011, P INT C ADV COMPUTIN, P97
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Shen JF, 2013, NEURAL COMPUT APPL, V23, P1937, DOI 10.1007/s00521-012-1153-5
   Singh D, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105524
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P30599, DOI 10.1007/s11042-018-6425-3
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Srivastava P, 2018, MULTIMED TOOLS APPL, V77, P12377, DOI 10.1007/s11042-017-4894-4
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Uddin MA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071599
   Veeraraghavan A., 2006, CVPR 06, P959, DOI [DOI 10.1109/CVPR.2006.304, 10.1109/CVPR.2006.304]
   Vili K, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P206
   Vishwakarma DK, 2020, COGN SYST RES, V61, P1, DOI 10.1016/j.cogsys.2019.12.004
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Zare A, 2020, PATTERN ANAL APPL, V23, P265, DOI 10.1007/s10044-019-00788-1
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 70
TC 8
Z9 8
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32511
EP 32538
DI 10.1007/s11042-021-11207-1
EA JUL 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679762700001
DA 2024-07-18
ER

PT J
AU Zhang, H
   Tian, CW
   You, L
   Li, ZM
   Zong, M
   Huang, K
AF Zhang, Hong
   Tian, Chunwei
   You, Lei
   Li, Zhengming
   Zong, Ming
   Huang, Kan
TI Design and implementation on matching between music and color
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color music; Audio signal; Music note; FFT analysis; RGB-LED
AB Color music has attracted great interest in real applications. However, the mismatching problem between music and color has not been resolved. This paper proposes a novel mechanism to map the corresponding relation between music and color, which is embedded into a device with a micro-processor to play music color flashing. The proposed mechanism deduces perfect fifth relation among the wavelengths of lights and determines 12 colors corresponding to musical notes of Twelve-tone equal temperament is determined. Specifically, when a piece of music is playing, the audio signal is sampled and transformed by Fast Fourier Transform (FFT). The method can judge color corresponding to a note and research the mixed light effect of RGB LED driven by PWM outputs. Extended experiments show that the effect of music playing with matching colors flashing in real time is reached, and the color of the mixed lights can automatically match with arbitrary music being played. The paper can reveal relationships between music and color from the perspective of frequency spectrum, and promote the development of the color music, which has broad applications.
C1 [Zhang, Hong] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
   [Tian, Chunwei] Northwestern Polytech Univ, Sch Software, Xian 710072, Shaanxi, Peoples R China.
   [You, Lei] Univ Texas Houston Sci Ctr Houston, Sch Biomed Informat, Houston, TX 77030 USA.
   [Li, Zhengming] Guangdong Polytech Normal Univ, Ind Training Ctr, Guangzhou 510665, Guangdong, Peoples R China.
   [Zong, Ming] Massey Univ, Sch Nat & Computat Sci, Auckland, New Zealand.
   [Huang, Kan] Peking Univ, Sch Elect & Comp Engn, Shenzhen Grad Sch, Shenzhen 518055, Guangdong, Peoples R China.
C3 Harbin University of Science & Technology; Northwestern Polytechnical
   University; Guangdong Polytechnic Normal University; Massey University;
   Peking University
RP Tian, CW (corresponding author), Northwestern Polytech Univ, Sch Software, Xian 710072, Shaanxi, Peoples R China.
EM zhangh@hrbust.edu.cn; chunweitian@163.com; Lei.You@uth.tmc.edu;
   gslzm@gpnu.edu.cn; m.zong@messey.ac.nz; huangkan@pku.edu.cn
FU National Nature Science Foundation of China [61702117]
FX This work is supported in part by the National Nature Science Foundation
   of China Gant No. 61702117.
CR Abood S.I., 2020, DIGIT SIGNAL PROCESS, V1, P129
   Collopy, 2017, US Patent, Patent No. [9,786,067, 9786067]
   Deng XM, 2013, ADV MATER RES-SWITZ, V671-674, P2847, DOI 10.4028/www.scientific.net/AMR.671-674.2847
   Du, 2014, INT J CONTROL AUTOM, V7, P177, DOI [10.14257/ijca.2014.7.6.18, DOI 10.14257/IJCA.2014.7.6.18]
   Du L., 2014, ADV MAT RES, V945, P1764
   Gaskill N, 2017, CONFIGURATIONS, V25, P475, DOI 10.1353/con.2017.0029
   Gunther L., 2012, The Physics of Music and Color
   Guo L, 2013, HEBEI J IND SCI TECH, V2
   Hong Zhang, 2014, ICIC Express Letters, Part B: Applications, V5, P1027
   Hong Zhang, 2013, 2013 8th International Forum on Strategic Technology (IFOST), P64, DOI 10.1109/IFOST.2013.6616861
   Hongbin Z, 2013, INT J MULTIMEDIA UBI, V8, P151, DOI [10.14257/ijmue.2013.8.6.15, DOI 10.14257/IJMUE.2013.8.6.15]
   Ingale R., 2014, Int J Signal Process Image Process Pattern Recognit, V7, P345
   Jiang RA, 2007, IEEE T CONSUM ELECTR, V53, P1322, DOI 10.1109/TCE.2007.4429219
   Lima E.S.C., 2020, THESIS ANDREWS U
   Mateski S, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P1741, DOI 10.1109/TELFOR.2012.6419564
   Mirri S, 2017, INT J HUM-COMPUT INT, V33, P1010, DOI 10.1080/10447318.2017.1321218
   Nakamura Mieko, 2012, Computer Software, V29, P118
   Oikawa M, 2011, OPT EXPRESS, V19, P12008, DOI 10.1364/OE.19.012008
   Palmer SE, 2016, MULTISENS RES, V29, P157, DOI 10.1163/22134808-00002486
   Palmer SE, 2013, P NATL ACAD SCI USA, V110, P8836, DOI 10.1073/pnas.1212562110
   Poast M, 2000, LEONARDO, V33, P215, DOI 10.1162/002409400552531
   Rashid M, 2013, VISUAL COMPUT, V29, P1269, DOI 10.1007/s00371-012-0768-y
   Rui-mi F., 2014, J HARBIN U SCI TECHN, V19
   Schloss KB, 2010, YALE REV UNDERGRADUA, V82
   Schubert E., 2007, PSYCHOL MUSIC, V35, P499, DOI [DOI 10.1177/0305735607072657, 10.1177/0305735607072657]
   Simner J, 2006, PERCEPTION, V35, P1024, DOI 10.1068/p5469
   Son CG, 2011, J OPT SOC KOREA, V15, P272, DOI 10.3807/JOSK.2011.15.3.272
   Sun DZ, 2014, APPL MECH MATER, V443, P746, DOI 10.4028/www.scientific.net/AMM.443.746
   Tempelaars S., 2014, SIGNAL PROCESSING SP
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tian CW, 2018, ARAB J SCI ENG, V43, P741, DOI 10.1007/s13369-017-2696-7
   Vitez T, 2018, THESIS SVEUCILISTE S
   Wang ZQ., 2015, J HARBIN U SCI TECHN, P21
   Whiteford KL, 2018, I-PERCEPTION, V9, DOI 10.1177/2041669518808535
   Yang H, 2020, VISUAL COMPUT, V36, P559, DOI 10.1007/s00371-019-01641-6
   Yun, 2013, INT J MULTIMED UBIQU, V8, P201, DOI [10.14257/ijmue.2013.8.6.20, DOI 10.14257/IJMUE.2013.8.6.20]
   Zeng W., 2016, IND ENG J, V19, P102
   Zhang H, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION AND NETWORKING (ACN), P40, DOI 10.1109/ACN.2015.19
   Zhang H, 2016, INT J GRID DISTRIB, V9, P111, DOI 10.14257/ijgdc.2016.9.4.11
   Zhou WL, 2016, INT J GRID DISTRIB, V9, P231, DOI 10.14257/ijgdc.2016.9.8.20
   Zoranovic AL, 2010, INT J ELEC ENG EDUC, V47, P329, DOI 10.7227/IJEEE.47.3.8
NR 42
TC 0
Z9 0
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32091
EP 32109
DI 10.1007/s11042-021-11162-x
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000676079100001
DA 2024-07-18
ER

PT J
AU Karolin, M
   Meyyappan, T
AF Karolin, M.
   Meyyappan, T.
TI Authentic secret share creation techniques using visual cryptography
   with public key encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; VSS scheme; PSNR; MSE; Encryption; Decryption; RSA
   algorithm; Matlab
AB In the digital transparent world, share the secret messages are challenged one. Visual cryptography (VC) is safer method for information transfer without any distraction by hackers. It is giving more security to the information sharing through digital form. This method hides the messages into images. So intruder cannot understand the distorted image and the data communication become secured. Through VC method number of shares has been generated from the original images. So here each RGB pixel shares are separately created by Visual Secret Share (VSS) scheme. The created multiple shares of the secret images are encrypted and decrypted with RSA algorithm. In the encryption process the multiplication technique is used for key generation process and public key is used for encryption process and private key is used for decryption process. Secret image's quality has been compared through the Peak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE) values. The experimental result of decrypted image PSNR value is 156.32 and MSE value is 0.5031. The Number of Changing Pixel Rate (NPCR) and Unified Averaged Changed Intensity (UACI) values are compared for the secure level of the secret image. The result of decrypted image NPCR value is 69.44 and UACI value is 13.88. Finally, the experiment result shows that the proposed method is giving more security and quality of secret image sharing and also execution time is faster than existing method.
C1 [Karolin, M.; Meyyappan, T.] Alagappa Univ, Dept Comp Sci, Karaikkudi, Tamil Nadu, India.
C3 Alagappa University
RP Karolin, M (corresponding author), Alagappa Univ, Dept Comp Sci, Karaikkudi, Tamil Nadu, India.
EM karolinmsc@gmail.com
RI Karolin, M/AAV-7808-2020
OI Karolin, M/0000-0003-1439-9967
CR Asha Bhadran, 2015, INT RES J ENG TECHNO, V02
   Gupta N, 2017, INT J INNOVATION ADV, V6
   Hegde SS, 2011, IJCSET, V1
   JoshiJesalkumari A., 2013, INT J COMPUT APPL TE, V2, P350
   Karolin M., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0058, DOI 10.1109/ICCSP.2019.8698013
   Karolin M., 2015, Int. J. Adv. Res. Comput. Commun. Eng, V4, P151
   Karolin M., 2019, INT J ENG ADV TECHNO, V9, P2797, DOI DOI 10.35940/IJEAT.B4021.129219
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Mahto D member Iaeng Danish Ali Khan member Iaeng and Dilip Kumar yadav member Iaeng, 2016, P WORLD C ENG, V1
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Pandey LN, 2013, J ADV RES COMPUT SCI, V1, P62
   Patel, 2017, 2016 INT C INV COMP, DOI 10.1109/INVENTIVE.2016.7824848
   Patel N., 2016, 10 INT C EM SEC INF
   Rijmen V, 1996, EUR 96 RUMP SESS BER
   Sanaboina C.S., 2019, INT J INNOV TECHNOL, V8, P3474, DOI [10.35940/ijitee.K2562.0981119, DOI 10.35940/IJITEE.K2562.0981119]
   Saturwar J, 2017, PROCEEDINGS OF THE 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION TECHNOLOGIES (ICECCT)
   Shankar K, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501383
   Sharma M, 2013, INT J ENGI INNOV TEC, V2
   Singh SR, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P13, DOI 10.1109/ICACDOT.2016.7877543
   Vandana Sreela, 2017, 2016 ONL INT C GRE E, DOI 10.1109/GET.2016.7916633
NR 20
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32023
EP 32040
DI 10.1007/s11042-021-11202-6
EA JUL 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678031600003
DA 2024-07-18
ER

PT J
AU Lu, XH
   Liu, PH
   Ke, YR
   Zhang, H
AF Lu, Xinghua
   Liu, Peihao
   Ke, Yiran
   Zhang, Hao
TI Network data security sharing system based on blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Network data; Secure sharing; Smart contract; Storage;
   Transmission management thread
ID SCHEME
AB Traditional network data security sharing system ignores that many people share data simultaneously, which leads to poor real-time performance. Therefore, the authors designed a network data security sharing system based on blockchain technology. In the hardware design, the PCI encryption card is used to encode the data. The microprocessor is used to access the system's external equipment, and DDR-SDRAM dynamic storage area and NAND flash static memory are used as network data. In the software section of the system, a secure transmission mechanism is established. The cp-abe method is used to encrypt the network shared data, and the multi-person digital envelope technology is used to share the data. These two methods contribute to the design of the network data security sharing system. In the experiment, eight users share the data. The system login response time, key distribution time, data encryption time, and key update time are taken as the experimental objects. Experimental results show that the system response time, key distribution time, data encryption time, and key update time of the system are shorter than those of the comparison method.
C1 [Lu, Xinghua; Liu, Peihao; Ke, Yiran; Zhang, Hao] Huali Coll Guangdong Univ Technol, Guangzhou 511325, Peoples R China.
RP Lu, XH (corresponding author), Huali Coll Guangdong Univ Technol, Guangzhou 511325, Peoples R China.
EM xhlu@gdtu.edu.cn
RI Liu, Joyce/KEI-8953-2024; wu, yunhui/JGD-6838-2023; CUI,
   XU/JYO-8134-2024; lei, xh/KFR-2496-2024; lin, qing/JED-5250-2023
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Al-Saleem SM, 2018, CLUSTER COMPUT, V21, P469, DOI 10.1007/s10586-017-0903-7
   Herrera-Quintero LF, 2018, IEEE INTEL TRANSP SY, V10, P4, DOI 10.1109/MITS.2018.2811449
   Geng DF, 2020, J COASTAL RES, P718, DOI 10.2112/SI103-147.1
   Hassija V, 2020, IEEE T VEH TECHNOL, V69, P5799, DOI 10.1109/TVT.2020.2967052
   Lei K, 2019, IEEE COMMUN MAG, V57, P26, DOI 10.1109/MCOM.2019.1800722
   Li CT, 2018, J INTERNET TECHNOL, V19, P147, DOI 10.3966/160792642018011901014
   Li XY, 2018, IEEE T SERV COMPUT, V11, P671, DOI 10.1109/TSC.2015.2475743
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Nowlin BT, 2018, J LEUKOCYTE BIOL, V103, P141, DOI 10.1002/JLB.4A0217-047R
   Pattipati Dileep Kumar, 2016, International Journal of Network Security, V18, P874
   Shen J, 2017, J INTERNET TECHNOL, V18, P833, DOI 10.6138/JIT.2017.18.4.20160415
   Singh M, 2022, IMMUNOL INVEST, V51, P120, DOI 10.1080/08820139.2020.1813756
   Tang FL, 2018, IEEE T CLOUD COMPUT, V6, P915, DOI 10.1109/TCC.2016.2543722
   van Leeuwen G, 2020, APPL ENERG, V263, DOI 10.1016/j.apenergy.2020.114613
   [王军 Wang Jun], 2019, [电子科技大学学报, Journal of University of Electronic Science and Technology of China], V48, P307
   Wen FH, 2019, INT J FINANC ECON, V24, P812, DOI 10.1002/ijfe.1692
   Yang JC, 2020, IEEE NETWORK, V34, P62, DOI 10.1109/MNET.011.1900374
   Yin H, 2018, IEEE NETWORK, V32, P112, DOI 10.1109/MNET.2018.1700172
NR 20
TC 5
Z9 5
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31887
EP 31906
DI 10.1007/s11042-021-11183-6
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000675334700001
DA 2024-07-18
ER

PT J
AU Baghban, H
   Huang, CY
   Hsu, CH
AF Baghban, Hojjat
   Huang, Ching-Yao
   Hsu, Ching-Hsien
TI Latency minimization model towards high efficiency edge-IoT service
   provisioning in horizontal edge federation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Latency; Service provisioning; Horizontal edge federation; Resource
   sharing; Edge-IoT
ID CLOUD; PLACEMENT
AB Edge computing plays a critical role in IoT as it potentially minimized the computation tasks response latency demanded by time-critical IoT applications. The growth of IoT users with high demanded computation power as well as ultra-low latency tasks may cause the performance degradation. One way to minimize the end-to-end (E2E) latency is to form horizontal edge federation (HEF) so that the computation resources can be shared with each participating edge node. Achieving ultra-low latency in HEF-IoT ecosystem involves setting two factor: resource allocation and task dispatching. This two factor interact with each other yet feasible solutions must provide satisfactory service level to meet latency constraints demanded by target applications. In this paper, we formulate it as E2E latency minimization problem and proposed a two-phase iterative (TPI) approach. The TPI method alternately determines optimal task dispatching and computation resource allocation. We exploit bin packing problem and, genetic algorithm (GA) to determine the edge nodes, and the required computation resources. The simulation results show that by using TPI approach, we can achieve more throughput, minimum E2E latency and optimum number of required edge nodes.
C1 [Baghban, Hojjat; Huang, Ching-Yao] Natl Yang Ming Chiao Tung Univ, Inst Elect, Dept Elect Engn, Hsinchu, Taiwan.
   [Baghban, Hojjat] Natl Yang Ming Chiao Tung Univ, Dept Elect Engn & Comp Sci, Hsinchu, Taiwan.
   [Baghban, Hojjat; Hsu, Ching-Hsien] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Hsu, Ching-Hsien] Foshan Univ, Sch Math & Big Data, Guangdong Hong Kong Macao Joint Lab Intelligent M, Foshan 528000, Peoples R China.
   [Hsu, Ching-Hsien] China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University; Asia University Taiwan; Foshan University; China Medical
   University Taiwan; China Medical University Hospital - Taiwan
RP Hsu, CH (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Hsu, CH (corresponding author), Foshan Univ, Sch Math & Big Data, Guangdong Hong Kong Macao Joint Lab Intelligent M, Foshan 528000, Peoples R China.; Hsu, CH (corresponding author), China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung, Taiwan.
EM hojjatbaghban.eed06g@nctu.edu.tw; cyhuang@mail.nctu.edu.tw;
   chh@cs.ccu.edu.tw
RI Hsu, Ching-Hsien/AAE-6917-2020
FU Ministry of Education, Taiwan, under the project: Trusted Intelligent
   Edge/Fog computing Technology RSC [107RSA0021]; National Natural Science
   Foundation of China [61872084]; Guangdong-Hong Kong-Macao Joint
   Laboratory for Intelligent Micro-Nano Optoelectronic Technology
   [2020B1212030010]
FX This work was partially supported by Ministry of Education, Taiwan,
   under the project: Trusted Intelligent Edge/Fog computing Technology RSC
   (Grant No. 107RSA0021), the National Natural Science Foundation of China
   (Grant No. 61872084), and Guangdong-Hong Kong-Macao Joint Laboratory for
   Intelligent Micro-Nano Optoelectronic Technology (No. 2020B1212030010).
CR Aburukba RO, 2020, FUTURE GENER COMP SY, V111, P539, DOI 10.1016/j.future.2019.09.039
   [Anonymous], ALGORITHM DESIGN COM
   Aryal RG, 2018, 2018 THIRD INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P147, DOI 10.1109/FMEC.2018.8364057
   Ashwini K, 2018, MULTIMED TOOLS APPL, V77, P31581, DOI 10.1007/s11042-018-6112-4
   Atapattu S, 2020, LATENCY MINIMIZATION
   Baecker O., 2010, MULTIKONFERENZ WIRTS
   Baghban H, 2020, COMPUT COMMUN, V158, P39, DOI 10.1016/j.comcom.2020.04.009
   Baktir AC, 2019, WILEY SER PARA DIST, P25
   Campolo C, 2018, 2018 4TH IEEE CONFERENCE ON NETWORK SOFTWARIZATION AND WORKSHOPS (NETSOFT), P400, DOI 10.1109/NETSOFT.2018.8459911
   Cao XY, 2021, IEEE GEOSCI REMOTE S, V18, P1104, DOI 10.1109/LGRS.2020.2990407
   Choi J, 2019, J INF PROCESS SYST, V15, P440, DOI 10.3745/JIPS.03.0113
   Dinh HT, 2013, WIREL COMMUN MOB COM, V13, P1587, DOI 10.1002/wcm.1203
   Gonçalves M, 2015, 2015 IEEE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, P813, DOI 10.1109/CLOUD.2015.112
   Gurobi Optimization LLC, 2021, Gurobi optimization reference manual 2020
   Jiang YX, 2013, IEEE T NETW SERV MAN, V10, P312, DOI 10.1109/TNSM.2013.051913.120278
   Jo JH, 2019, J INF PROCESS SYST, V15, P765, DOI 10.3745/JIPS.03.0124
   Kharel J, 2019, MULTIMED TOOLS APPL, V78, P9405, DOI 10.1007/s11042-018-6530-3
   Liu JQ, 2017, IEEE COMMUN MAG, V55, P34, DOI 10.1109/MCOM.2017.1600371CM
   Liu L, 2016, J SUPERCOMPUT, V72, P3169, DOI 10.1007/s11227-015-1590-x
   Liu MN, 2020, HUM-CENTRIC COMPUT I, V10, DOI 10.1186/s13673-019-0207-4
   Liu YJ, 2020, IEEE INTERNET THINGS, V7, P4961, DOI 10.1109/JIOT.2020.2972041
   Ma X, 2017, 2017 IEEE/ACM 25TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS)
   Mitchell M., 1998, INTRO GENETIC ALGORI
   Morrison DR, 2016, DISCRETE OPTIM, V19, P79, DOI 10.1016/j.disopt.2016.01.005
   Mu SQ, 2019, IEEE INTERNET THINGS, V6, P1046, DOI 10.1109/JIOT.2018.2866945
   Nimkar AV, 2013, J CLOUD COMPUT-ADV S, V2, DOI 10.1186/2192-113X-2-19
   Park S.-H., 2016, PROC IEEE 17 INT WOR, P1
   Pinsky MA, 2019, INTRO PROBABILITY MO, V12th, P507
   Rahman GMS, 2018, IEEE ACCESS, V6, P17442, DOI 10.1109/ACCESS.2018.2805303
   Rathore S, 2018, APPL SOFT COMPUT, V72, P79, DOI 10.1016/j.asoc.2018.05.049
   Stavrinides GL, 2019, MULTIMED TOOLS APPL, V78, P24639, DOI 10.1007/s11042-018-7051-9
   Tai LJ, 2019, MULTIMED TOOLS APPL, V78, P4579, DOI 10.1007/s11042-018-6391-9
   Yang BX, 2018, IEEE T NETW SERV MAN, V15, P475, DOI 10.1109/TNSM.2018.2790081
   Yin CY, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0195-4
   Zhu CY, 2018, 2018 INTERNATIONAL SYMPOSIUM ON ANTENNAS AND PROPAGATION (ISAP)
NR 35
TC 4
Z9 4
U1 6
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26803
EP 26820
DI 10.1007/s11042-021-11009-5
EA JUN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000668401600001
DA 2024-07-18
ER

PT J
AU Singh, VK
   Kolekar, MH
AF Singh, Vipul Kumar
   Kolekar, Maheshkumar H.
TI Deep learning empowered COVID-19 diagnosis using chest CT scan images
   for collaborative edge-cloud computing platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chest CT scan; COVID-19; Deep Learning; Diagnosis; Edge Computing;
   MobileNet V2
ID NEURAL-NETWORK; HEALTH-CARE; DISEASE; CLASSIFICATION; SEGMENTATION
AB The novel coronavirus outbreak has spread worldwide, causing respiratory infections in humans, leading to a huge global pandemic COVID-19. According to World Health Organization, the only way to curb this spread is by increasing the testing and isolating the infected. Meanwhile, the clinical testing currently being followed is not easily accessible and requires much time to give the results. In this scenario, remote diagnostic systems could become a handy solution. Some existing studies leverage the deep learning approach to provide an effective alternative to clinical diagnostic techniques. However, it is difficult to use such complex networks in resource constraint environments. To address this problem, we developed a fine-tuned deep learning model inspired by the architecture of the MobileNet V2 model. Moreover, the developed model is further optimized in terms of its size and complexity to make it compatible with mobile and edge devices. The results of extensive experimentation performed on a real-world dataset consisting of 2482 chest Computerized Tomography scan images strongly suggest the superiority of the developed fine-tuned deep learning model in terms of high accuracy and faster diagnosis time. The proposed model achieved a classification accuracy of 96.40%, with approximately ten times shorter response time than prevailing deep learning models. Further, McNemar's statistical test results also prove the efficacy of the proposed model.
C1 [Singh, Vipul Kumar; Kolekar, Maheshkumar H.] Indian Inst Technol, Dept Elect Engn, Patna, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna
RP Singh, VK (corresponding author), Indian Inst Technol, Dept Elect Engn, Patna, Bihar, India.
EM vipul_1911ee13@iitp.ac.in; mahesh@iitp.ac.in
OI KUMAR SINGH, VIPUL/0000-0002-6897-6830
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Abdel-Basset M, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106647
   Al Mamun KA, 2017, FUTURE GENER COMP SY, V66, P36, DOI 10.1016/j.future.2015.11.010
   Al-Qurishi M, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/985629
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alsharif MH, 2020, EUR REV MED PHARMACO, V24, P11455, DOI 10.26355/eurrev_202011_23640
   ALzubi JA, 2019, APPL SOFT COMPUT, V80, P579, DOI 10.1016/j.asoc.2019.04.031
   [Anonymous], SARS COV 2 CT SCAN D
   [Anonymous], Q A CORONAVIRUS DIS
   [Anonymous], CORONAVIRUS DIS COVI
   [Anonymous], BATTLE SHIFTING COVI
   Ardakani AA, 2021, EUR RADIOL, V31, P121, DOI 10.1007/s00330-020-07087-y
   Azemin MZC, 2020, INT J BIOMED IMAGING, V2020, DOI 10.1155/2020/8828855
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   C H, Diagnostic testing at the speed of life | Cue
   Chen XF, 2020, EUR RADIOL, V30, P4893, DOI 10.1007/s00330-020-06829-2
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Das AK, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110713
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Everitt BS., 1992, The Analysis of Contingency Tables, V2, P46, DOI [10.1201/b15072, DOI 10.1201/B15072]
   Gaura EI, 2013, IEEE SENS J, V13, P3816, DOI 10.1109/JSEN.2013.2266895
   Ghosal D, 2018, INTERSPEECH, P2087
   Gianchandani N, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02669-6
   Gifani P, 2021, INT J COMPUT ASS RAD, V16, P115, DOI 10.1007/s11548-020-02286-w
   Goldstein E, 2020, ARXIV201001362
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X. etal, 2020, medRxiv
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam MR, 2018, J SYST SOFTWARE, V145, P125, DOI 10.1016/j.jss.2018.08.030
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Jiang YF, 2021, IEEE J BIOMED HEALTH, V25, P441, DOI 10.1109/JBHI.2020.3042523
   Karakanis S, 2021, COMPUT BIOL MED, V130, DOI 10.1016/j.compbiomed.2020.104181
   Kaur T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01069-2
   Kong XJ, 2021, IEEE INTERNET THINGS, V8, P15929, DOI 10.1109/JIOT.2021.3051844
   Li XY, 2019, IEEE ACCESS, V7, P36433, DOI 10.1109/ACCESS.2019.2904245
   Liang GB, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.06.023
   Loey M, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05437-x
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Mishra AK, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8843664
   Muhammad G, 2018, IEEE COMMUN MAG, V56, P60, DOI 10.1109/MCOM.2018.1700790
   Pathak Y, 2022, IRBM, V43, P87, DOI 10.1016/j.irbm.2020.05.003
   Rahman MA, 2021, IEEE INTERNET THINGS, V8, P15847, DOI 10.1109/JIOT.2021.3051080
   Rahman MA, 2020, IEEE NETWORK, V34, P98, DOI 10.1109/MNET.011.2000353
   Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sacco A, 2020, IEEE J BIOMED HEALTH, V24, P2523, DOI 10.1109/JBHI.2020.3007661
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma S, 2020, ENVIRON SCI POLLUT R, V27, P37155, DOI 10.1007/s11356-020-10133-3
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Y, 2021, IEEE ACM T COMPUT BI, V18, P2775, DOI 10.1109/TCBB.2021.3065361
   Vardhana M, 2018, COGN SYST RES, V50, P10, DOI 10.1016/j.cogsys.2018.03.005
   Wang SG, 2019, J PARALLEL DISTR COM, V127, P160, DOI 10.1016/j.jpdc.2018.06.008
   Yang G, 2018, IEEE J BIOMED HEALTH, V22, P1711, DOI 10.1109/JBHI.2017.2776351
   Zhang J., 2019, Why Adam beats SGD for attention models
   Zhang JP, 2021, IEEE T MED IMAGING, V40, P879, DOI 10.1109/TMI.2020.3040950
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
NR 61
TC 30
Z9 30
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 3
EP 30
DI 10.1007/s11042-021-11158-7
EA JUN 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000667613100001
PM 34220289
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Haouam, MY
   Meraoumia, A
   Laimeche, L
   Bendib, I
AF Haouam, Mohamed Yassine
   Meraoumia, Abdallah
   Laimeche, Lakhdar
   Bendib, Issam
TI S-DCTNet: Security-oriented biometric feature extraction technique An
   effective pathway to secure and reliable biometric systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometric; Deep feature; DCTNet; Chaotic maps; Palmprint;
   Palm-vein
ID GENERATION; PRIVACY
AB The proliferation of information technology has prompted researchers to create a multitude of new security solutions for secure electronic applications, especially on the Internet. Among them, security officials prefer authentication systems for user's identity identification. Indeed, biometric authentication has proved to be superior in many respects compared to the traditional authentication means. Unfortunately, these systems are vulnerable to a variety of attacks, the most serious of which is perhaps the attack on the stored or transmitted template, which makes the safety of this template more important in the design of the biometric systems. This research, therefore, suggests an effective feature extraction method that can provide a deep and cancelable biometric feature. In this study, DCTNet deep learning is combined with chaotic systems to extract revocable palmprint/palm-vein features.
C1 [Haouam, Mohamed Yassine; Meraoumia, Abdallah; Laimeche, Lakhdar; Bendib, Issam] Univ Larbi Tebessi, Lab Math Informat & Syst LAMIS, Tebessa, Algeria.
RP Haouam, MY (corresponding author), Univ Larbi Tebessi, Lab Math Informat & Syst LAMIS, Tebessa, Algeria.
EM mohamed-yassine.haouam@univ-tebessa.dz; ameraoumia@univ-tebessa.dz;
   lakhdar.laimeche@univ-tebessa.dz; issam.bendib@univ-tebessa.dz
RI HAOUAM, Mohamed Yassine/KFT-1015-2024
OI BENDIB, Issam/0000-0001-9153-8161; lakhdar,
   laimeche/0000-0002-9473-2637; Haouam, Mohamed
   Yassine/0000-0001-8989-6656
FU Directorate General for Scientific Research and Technological
   Development (DGRSDT)
FX This work would not have been possible without the financial support of
   the Directorate General for Scientific Research and Technological
   Development (DGRSDT). The authors also appreciate the unknown referee's
   valuable and profound comments.
CR Abdellatef E, 2019, VISUAL COMPUTER INT
   AZZOUZ A, 1984, IEEE T CIRCUITS SYST, V31, P587, DOI 10.1109/TCS.1984.1085540
   Bendjenna H, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033008
   Bhatnagar G, 2014, MULTIMEDIA SYST, V20, P203, DOI 10.1007/s00530-013-0323-3
   Bhatnagar G, 2012, IEEE T INSTRUM MEAS, V61, P876, DOI 10.1109/TIM.2011.2179330
   Blasco J, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2968215
   Chai TY, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020164
   Coelho DFG, 2018, J SIGNAL PROCESS SYS, V90, P505, DOI 10.1007/s11265-017-1270-6
   Dwivedi R, 2017, COMPUT SECUR, V65, P373, DOI 10.1016/j.cose.2016.10.004
   Fu C, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P724, DOI 10.1109/CIS.2013.158
   Hamad N, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATICS, HEALTH & TECHNOLOGY (ICIHT), DOI 10.1109/CEIDP.2017.8257451
   Hong Kong Polytechnic University (PolyU), 2013, MULT PALMPR DAT
   Hsiao HI, 2013, I SYMP CONSUM ELECTR, P95
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jang Y.K., 2019, 2019 16 IEEE INT C A, P1
   Jeong JY, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/7473591
   Jindal AK, 2018, IEEE COMPUT SOC CONF, P575, DOI 10.1109/CVPRW.2018.00087
   Kurban OC, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA), P361, DOI 10.1109/INISTA.2017.8001186
   Li HJ, 2020, MULTIMED TOOLS APPL, V79, P11947, DOI 10.1007/s11042-019-08446-8
   Li XL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0358-7
   Liu Y, 2018, SOFT COMPUT, V22, P2257, DOI 10.1007/s00500-017-2487-9
   Menezes A., 1996, Cryptography
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Ng CJ, 2015, ASIAPAC SIGN INFO PR, P761, DOI 10.1109/APSIPA.2015.7415375
   Phartchayanusit V, 2018, INT JOINT CONF COMP, P361
   Ponce-Hernandez W, 2020, IEEE ACCESS, V8, P11152, DOI 10.1109/ACCESS.2020.2965165
   Rajab H, 2018, INT SYM NETWO COMP
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2015, I W BIOMETRIC FORENS
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Salami Momoh J. E., 2011, Biometric Systems, Design and Applications, P235
   Sallehuddin AFH, 2016, INT CONF ELECTRON D, P464, DOI 10.1109/ICED.2016.7804689
   SARKAR A, 2018, 4 INT C RECENT ADV I, P1, DOI DOI 10.1109/RAIT.2018.8389007
   Shah Krishna, 2018, IEEE INT C EM TRENDS, P1, DOI 10.1109/ICINPRO43533.2018.9096789
   Sujitha V, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1220-x
   Talreja V, 2017, IEEE GLOB CONF SIG, P298, DOI 10.1109/GlobalSIP.2017.8308652
   Dang TK, 2016, IET BIOMETRICS, V5, P229, DOI 10.1049/iet-bmt.2015.0029
   Dang TK, 2018, INT ARAB J INF TECHN, V15, P331
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Walia GS, 2019, IET BIOMETRICS, V8, P231, DOI 10.1049/iet-bmt.2018.5018
   Wang, 2010, INT C COMP APPL SYST
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
NR 44
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 36059
EP 36091
DI 10.1007/s11042-021-10936-7
EA JUN 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000667012400005
DA 2024-07-18
ER

PT J
AU Ghosh, M
   Mukherjee, H
   Obaidullah, SKM
   Santosh, KC
   Das, N
   Roy, K
AF Ghosh, Mridul
   Mukherjee, Himadri
   Obaidullah, Sk Md
   Santosh, K. C.
   Das, Nibaran
   Roy, Kaushik
TI LWSINet: A deep learning-based approach towards video script
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video script; Handcrafted feature; Convolutional neural networks; Noise
ID ALGORITHM; CLASSIFIER; NOISE; IMAGE
AB Videos - a high volume of texts - broadcast via different media, such as television and the internet. Since Optical Character Recognition (OCR) engines are script-dependent, script identification is a precursor. Other than that, video script identification is not trivial as we have difficult issues, such as low resolution, complex background, noise, and blur effects. In this work, a deep learning-based system, which we call LWSINet: LightWeight Script Identification Network (6-layered CNN) is proposed to identify video scripts. For validation, we used a publicly available dataset named CVSI-15. Besides, the effects of three common noises namely, Salt & pepper, Gaussian and Poisson were considered on the scripts along with their hybridized metamorphosis. In our test results, we observed that the proposed CNN is coherent and robust enough to identify scripts in both scenarios, with and without noise. Further, we also employed other well-known handcrafted feature-based and deep learning approaches for a comparison.
C1 [Ghosh, Mridul] Shyampur Siddheswari Mahavidyalaya, Dept Comp Sci, Howrah, India.
   [Ghosh, Mridul; Obaidullah, Sk Md] Aliah Univ, Dept Comp Sci, Engn, Kolkata, India.
   [Mukherjee, Himadri; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Santosh, K. C.] Univ South Dakota, KCs PAMI Res Lab Comp Sci, Vermillion, SD USA.
   [Das, Nibaran] Jadavpur Univ, Dept Comp Sci, Kolkata, India.
C3 Aliah University; West Bengal State University; University of South
   Dakota; Jadavpur University
RP Roy, K (corresponding author), West Bengal State Univ, Dept Comp Sci, Kolkata, India.
EM mridulxyz@gmail.com; himadrim027@gmail.com; sk.obaidullah@gmail.com;
   santosh.kc@usd.edu; nibaranju@gmail.com; kaushik.mrg@gmail.com
RI GHOSH, MRIDUL/ABA-8687-2021; GHOSH, DR. MRIDUL/AEY-8327-2022; Santosh,
   KC/H-1363-2012; Roy, Kaushik/O-7021-2019
OI GHOSH, MRIDUL/0000-0002-4777-2492; GHOSH, DR.
   MRIDUL/0000-0002-4777-2492; Sk, Md Obaidullah/0000-0002-5207-3709;
   Santosh, KC/0000-0003-4176-0236; Roy, Kaushik/0000-0002-3360-7576
CR Acharjya D, 2017, INT J AMBIENT COMPUT, V8, P32, DOI 10.4018/IJACI.2017040103
   [Anonymous], 2012, 2012 INT C DIG IM CO
   [Anonymous], 2018, ARXIV180101627
   Awad A, 2019, ENG SCI TECHNOL, V22, P746, DOI 10.1016/j.jestch.2019.01.012
   Baljozovic D, 2013, IET IMAGE PROCESS, V7, P310, DOI 10.1049/iet-ipr.2012.0105
   Basu S, 2005, LECT NOTES COMPUT SC, V3776, P236
   Bhunia AK, 2019, PATTERN RECOGN, V85, P172, DOI 10.1016/j.patcog.2018.07.034
   Castellano G, 2019, CIRC SYST SIGNAL PR, V38, P3269, DOI 10.1007/s00034-018-01020-x
   CHERIET M, 1993, PATTERN RECOGN LETT, V14, P1009, DOI 10.1016/0167-8655(93)90009-3
   Ghosh D, 2010, IEEE T PATTERN ANAL, V32, P2142, DOI 10.1109/TPAMI.2010.30
   Gomez L, 2017, PATTERN RECOGN, V67, P85, DOI 10.1016/j.patcog.2017.01.032
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Khaliq A, 2020, IEEE T ROBOT, V36, P561, DOI 10.1109/TRO.2019.2956352
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Kingma D. P., 2014, arXiv
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu Y, 2015, INT CONF ACOUST SPEE, P1563, DOI 10.1109/ICASSP.2015.7178233
   Lu LQ, 2019, IEEE ACCESS, V7, P52669, DOI 10.1109/ACCESS.2019.2911964
   Luisier F, 2011, IEEE T IMAGE PROCESS, V20, P696, DOI 10.1109/TIP.2010.2073477
   Mei JR, 2016, INT C PATT RECOG, P4053, DOI 10.1109/ICPR.2016.7900268
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Naz S, 2016, NEUROCOMPUTING, V177, P228, DOI 10.1016/j.neucom.2015.11.030
   Obaidullah SM, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418560128
   Obaidullah SM, 2019, INT J MACH LEARN CYB, V10, P87, DOI 10.1007/s13042-017-0702-8
   Obaidullah SM, 2018, MULTIMED TOOLS APPL, V77, P1643, DOI 10.1007/s11042-017-4373-y
   Obaidullah SM, 2014, APPL COMPUT INTELL S, V2014, DOI 10.1155/2014/896128
   Pal U, 2003, PROC INT CONF DOC, P880
   Pal U, 2010, PATTERN RECOGN, V43, P4124, DOI 10.1016/j.patcog.2010.06.017
   Petrovska B, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175792
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Roy S, 2015, EXPERT SYST APPL, V42, P5554, DOI 10.1016/j.eswa.2015.02.030
   Sharma N, 2014, IEEE IJCNN, P1827, DOI 10.1109/IJCNN.2014.6889906
   Sharma N, 2015, PROC INT CONF DOC, P1196, DOI 10.1109/ICDAR.2015.7333950
   Shi BG, 2016, PATTERN RECOGN, V52, P448, DOI 10.1016/j.patcog.2015.11.005
   Shi BG, 2015, PROC INT CONF DOC, P531, DOI 10.1109/ICDAR.2015.7333818
   SHIJIAN L, 2007, IEEE T PATTERN ANAL, V30, P14
   Shivakumara P, 2014, INT C PATT RECOG, P3098, DOI 10.1109/ICPR.2014.534
   Shivakumara P, 2015, COMPUT VIS IMAGE UND, V130, P35, DOI 10.1016/j.cviu.2014.09.003
   Singh PK, 2018, MULTIMED TOOLS APPL, V77, P8441, DOI 10.1007/s11042-017-4745-3
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thanh D. N. H., 2016, Pattern Recognition and Image Analysis, V26, P285, DOI 10.1134/S1054661816020231
   Ul-Hasan A, 2015, PROC INT CONF DOC, P1046, DOI 10.1109/ICDAR.2015.7333921
   Wojna Z, 2017, PROC INT CONF DOC, P844, DOI 10.1109/ICDAR.2017.143
   Wong EK, 2003, PATTERN RECOGN, V36, P1397, DOI 10.1016/S0031-3203(02)00230-3
   Yeung S., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P5154
   Zhang P., 2018, P 2 INT C ADV ARTIFI, P1
   ZHOU L, 2006, LECT NOTES COMPUT SC, P243
NR 50
TC 8
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29095
EP 29128
DI 10.1007/s11042-021-11103-8
EA JUN 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000662846600005
DA 2024-07-18
ER

PT J
AU Slivova, M
   Voznak, M
   Tovarek, J
   Partila, P
AF Slivova, Martina
   Voznak, Miroslav
   Tovarek, Jaromir
   Partila, Pavol
TI Detection of speaker liveness with CNN isolated word ASR for
   verification systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; CNN; i-Vector; MFCC; Liveness detection; IWASR
AB The article proposes a new speaker liveness test for speech verification systems. Biometric authentication systems based on speaker verification are often subject to presentation attacks which use the target speaker's recorded speech. We propose a liveness test which uses CNN isolated word ASR as a countermeasure to repel attacks during the verification process. The liveness test incorporates the extraction of MFCC coefficients and the CNN classifier. Reliability of the recognition of isolated words is verified against a validation dataset of various sizes. The achieved results verified the system's reliability, which decreased slightly as the size of the keyword dataset increased. The proposed method represents a simple and effective security component against presentation attacks for existing SV systems.
C1 [Slivova, Martina; Voznak, Miroslav; Tovarek, Jaromir; Partila, Pavol] VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci, 17 Listopadu 2172-15, Ostrava 70800, Czech Republic.
C3 Technical University of Ostrava
RP Slivova, M (corresponding author), VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci, 17 Listopadu 2172-15, Ostrava 70800, Czech Republic.
EM martina.slivova@vsb.cz
RI Partila, Pavol/AAW-4821-2021; Voznak, Miroslav/E-6448-2016
OI Voznak, Miroslav/0000-0001-5135-7980; Partila,
   Pavol/0000-0001-5348-8722; Slivova, Martina/0000-0001-8238-317X
FU Czech Ministry of Education, Youth and Sports [SP2021/25]; Large
   Infrastructures for Research,Experimental Development and Innovations
   project "e-Infrastructure CZ" [LM2018140]
FX The research leading to this results was supported by Czech Ministry of
   Education, Youth and Sports within project reg. no. SP2021/25 and also
   partially within the Large Infrastructures for Research, Experimental
   Development and Innovations project "e-Infrastructure CZ" reg. no.
   LM2018140, both projects were conducted by VSB-Technical university of
   Ostrava.
CR Abu Shariah MAM, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P1173
   Chen GG, 2014, ICASSP, V2014, P4087, DOI DOI 10.1109/ICASSP.2014.6854370
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dhanashri D, 2017, ADV INTELL SYST, V468, P9, DOI 10.1007/978-981-10-1675-2_2
   Dörfler M, 2017, 2017 INTERNATIONAL CONFERENCE ON SAMPLING THEORY AND APPLICATIONS (SAMPTA), P152, DOI 10.1109/SAMPTA.2017.8024472
   Fang F, 2018, ARXIV180904274
   FRANGOULIS E, 1991, INT CONF ACOUST SPEE, P413, DOI 10.1109/ICASSP.1991.150364
   Fu SW, 2017, IEEE INT WORKS MACH
   Garcia-Romero D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P256
   Gouda SK, 2018, SPEECH RECOGNITION K
   Imtiaz MA, 2016, 2016 ASIA PACIFIC CONFERENCE ON MULTIMEDIA AND BROADCASTING (APMEDIACAST), P106, DOI 10.1109/APMediaCast.2016.7878163
   Jia Y, 2018, ADV NEUR IN, V31
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1435, DOI 10.1109/TASL.2006.881693
   Li, 2017, SPEECH COMMAND RECOG
   Partila P, 2020, IEEE COMMUN MAG, V58, P100, DOI 10.1109/MCOM.001.1900396
   Ping Wei, 2017, Deep Voice 3: 2000-Speaker Neural Text-to-Speech
   Poddar A, 2017, INT J SPEECH TECHNOL, V11
   Potrino G., 2019, 2019 16 IEEE ANN CON, P1, DOI DOI 10.1109/CCNC.2019.8651744
   Ranjan Rajeev, 2016, 2016 International Conference on Signal Processing and Communication (ICSC), P323, DOI 10.1109/ICSPCom.2016.7980600
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Singhal S, 2015, 2015 COMMUNICATION, CONTROL AND INTELLIGENT SYSTEMS (CCIS), P199, DOI 10.1109/CCIntelS.2015.7437908
   Slivova M, 2020, MULTIMEDIA COMMUNICA, P252
   Tang R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5484, DOI 10.1109/ICASSP.2018.8462688
   Warden P, 2018, ArXiv e-prints: 1804.03209
   Zhang Y, 2018, HELLO EDGE KEYWORD S
   Zhao Lishuang, 2010, Proceedings of the 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P449, DOI 10.1109/ICMTMA.2010.298
NR 26
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9445
EP 9457
DI 10.1007/s11042-021-11150-1
EA JUN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000662846600006
DA 2024-07-18
ER

PT J
AU Liu, XX
   An, P
   Chen, YL
   Huang, XP
AF Liu, Xiaoxiao
   An, Ping
   Chen, Yilei
   Huang, Xinpeng
TI An improved lossless image compression algorithm based on Huffman coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossless compression; Linear prediction; Integer wavelet transform;
   Huffman coding
ID INTEGER WAVELET TRANSFORM
AB There is an increasing number of image data produced in our life nowadays, which creates a big challenge to store and transmit them. For some fields requiring high fidelity, the lossless image compression becomes significant, because it can reduce the size of image data without quality loss. To solve the difficulty in improving the lossless image compression ratio, we propose an improved lossless image compression algorithm that theoretically provides an approximately quadruple compression combining the linear prediction, integer wavelet transform (IWT) with output coefficients processing and Huffman coding. A new hybrid transform exploiting a new prediction template and a coefficient processing of IWT is the main contribution of this algorithm. The experimental results on three different image sets show that the proposed algorithm outperforms state-of-the-art algorithms. The compression ratios are improved by at least 6.22% up to 72.36%. Our algorithm is more suitable to compress images with complex texture and higher resolution at an acceptable compression speed.
C1 [Liu, Xiaoxiao; An, Ping; Chen, Yilei; Huang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP An, P (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM anping@shu.edu.cn
RI Huang, xp/JRX-2837-2023; Liu, Xiaoxiao/HNI-6180-2023
FU National Natural Science Foundation of China [62020106011, 62071287,
   62001279]
FX This work was supported in part by the National Natural Science
   Foundation of China, under Grants 62020106011, 62071287, and 62001279.
CR [Anonymous], 2021, NEW TEST IMAGES IMAG
   [Anonymous], 2021, IMAGE REPOSITORY U W
   Avramovic A., 2011, Serbian Journal of Electrical Engineering, V8, P27, DOI DOI 10.2298/SJEE1101027A
   Ayyoubzadeh SM, 2020, ABS200110484
   Azman NAN, 2019, B ELECT ENG INFORM, V8, P1289, DOI [10.11591/eei.v8i4.1612, DOI 10.11591/EEI.V8I4.1612]
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Dorobantiu A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132681
   Fawcett R, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P434, DOI 10.1109/DCC.1996.488366
   Fleet, 2019, DISCRETE WAVELET TRA, P525, DOI [10.1002/9781119555414.ch12, DOI 10.1002/9781119555414.CH12]
   Giudice O, 2018, IEEE IMAGE PROC, P1138, DOI 10.1109/ICIP.2018.8451221
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Hassen W, 2013, 2013 7TH IEEE INTERNATIONAL CONFERENCE ON E-LEARNING IN INDUSTRIAL ELECTRONICS (ICELIE), P150, DOI 10.1109/ICELIE.2013.6701290
   Hussain AJ, 2018, NEUROCOMPUTING, V300, P44, DOI 10.1016/j.neucom.2018.02.094
   Jain C., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P244, DOI 10.1109/ICECTECH.2011.5941746
   Jain P, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   Jian-Jiun Ding, 2016, 2016 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P1, DOI 10.1109/ICCE-TW.2016.7521049
   Khandwani FI., 2018, Int. J. Electr. Electron. Comput. Sci. Eng, V5, P39
   Kitanovski V, 2008, INT CONF SYST SIGNAL, P105, DOI 10.1109/IWSSIP.2008.4604378
   Kumar, 2017, INT J SOFT COMPUTING, P10
   Kumar RN, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0276-z
   Mentzer, 2020, PRACTICAL FULL RESOL
   Oswal S., 2016, Int. J. Eng. Res. Gen. Sci., V4, P430
   Pinho AJ, 2004, IEEE T IMAGE PROCESS, V13, P1411, DOI 10.1109/TIP.2004.836168
   Rahman MA, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101274
   Rahman MA, 2018, INT CONF ELECTR ENG, P279, DOI 10.1109/CEEICT.2018.8628092
   Reed S, 2017, PR MACH LEARN RES, V70
   Salimans T, 2017, ICLR 2017 19 JAN
   Savakis AE, 2000, IEEE IMAGE PROC, P136, DOI 10.1109/ICIP.2000.900913
   Schiopu I, 2018, PICT COD SYMP, P16, DOI 10.1109/PCS.2018.8456311
   Sharma K, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P256, DOI 10.1109/CCAA.2017.8229810
   Sheikh Shahrukh, 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P1671, DOI 10.1109/ICICICT46008.2019.8993282
   Shrikhande RN, 2014, 2014 INT C ADV COMM, P1, DOI [10.1109/EIC.2015.7230725, DOI 10.1109/EIC.2015.7230725]
   Sun YK, 2004, IEEE IMAGE PROC, P497
   Sweldens W., 1998, P SPIE THE INT SOC O, V2569 1 68, P79
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Zhou YL, 2010, INT CONF COMP SCI, P523, DOI 10.1109/ICCSIT.2010.5563620
NR 38
TC 16
Z9 16
U1 8
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4781
EP 4795
DI 10.1007/s11042-021-11017-5
EA JUN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000659016500002
DA 2024-07-18
ER

PT J
AU Sah, M
   Direkoglu, C
AF Sah, Melike
   Direkoglu, Cem
TI Review and evaluation of player detection methods in field sports
   Comparing conventional and deep learning based methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Convolutional neural networks; Deep learning; Player detection methods;
   Polar transformed shape information image; Shape information image;
   Faster R-CNN; Single shot detector; Yolo
ID TRACKING
AB In order to analyse field sport videos, accurate player detection is essential. If players' positions are identified correctly in video frames, the higher level analysis such as event detection, activity and performance analysis will be more accurate. For player detection, many methods have been presented until now with varying performances and under different evaluation settings. Convolutional Neural Networks (CNN) became very popular for object recognition and detection. Generally, CNN approaches use Gray or RGB image representations for detection. However, other image representations such as shape information image (SIM) and polar transformed shape information image (PSIM) can also be utilized for player detection. Furthermore, recent deep neural networks such as Faster R-CNN, Single Shot Detector (SSD) and Yolo can be applied for player detection using transfer learning. The aim of this study is to investigate and compare the performances of conventional methods, CNNs with different image representations and complex deep learning methods under the same evaluation settings, and on two field hockey datasets. We compare performances for different overlap ratios and for different occlusion cases. This is the first time an extensive evaluation, review and comparison have been conducted for player detection in field sports.
C1 [Sah, Melike] Near East Univ, Dept Comp Engn, Mersin 10, Nicosia, North Cyprus, Turkey.
   [Direkoglu, Cem] Middle East Tech Univ, Dept Elect & Elect Engn, Northern Cyprus Campus,Mersin 10, Guzelyurt, North Cyprus, Turkey.
C3 Near East University; Middle East Technical University
RP Sah, M (corresponding author), Near East Univ, Dept Comp Engn, Mersin 10, Nicosia, North Cyprus, Turkey.
EM melike.sah@neu.edu.tr; cemdir@metu.edu.tr
RI Sah, Melike/AAD-8897-2020; Direkoglu, Cem/H-2893-2013
OI Sah, Melike/0000-0003-3869-7205; Direkoglu, Cem/0000-0001-7709-4082
CR Acuna D., 2017, PROC C NEURAL INF PR, P4
   [Anonymous], 2018, RECENT ADV OBJECT DE
   Beetz M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2066
   Buric M, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1034, DOI 10.23919/MIPRO.2018.8400189
   Buric M, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P845, DOI 10.5220/0007582008450851
   Carr P, 2012, LECT NOTES COMPUT SC, V7572, P864, DOI 10.1007/978-3-642-33718-5_62
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Direkoglu C, 2007, LECT NOTES COMPUT SC, V4678, P553
   Direkoglu C, 2018, MACH VISION APPL, V29, P187, DOI 10.1007/s00138-017-0893-8
   Direkoglu C, 2011, PATTERN RECOGN LETT, V32, P270, DOI 10.1016/j.patrec.2010.08.012
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Figueroa PJ, 2006, COMPUT VIS IMAGE UND, V101, P122, DOI 10.1016/j.cviu.2005.07.006
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   HAMID R, 2010, PROC CVPR IEEE
   Han B, 2012, IEEE T PATTERN ANAL, V34, P1017, DOI 10.1109/TPAMI.2011.243
   Haro, 2020, INT WORKSH MULT CONT, DOI 10.1145/3422844.3423054
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Khatoonabadi SH, 2009, IMAGE VISION COMPUT, V27, P469, DOI 10.1016/j.imavis.2008.06.015
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lehuger A, 2007, COMPRESSION REPRESEN
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu K, 2017, BMVC, V173, P1, DOI DOI 10.5244/C.31.173
   Lu WL, 2013, IEEE T PATTERN ANAL, V35, P1704, DOI 10.1109/TPAMI.2012.242
   Matlab, 2013, OBJECT DETECTION DIS
   NIXON MS, 2009, COMPUT J, V54, P11
   Pham P, 2017, LECT NOTES COMPUT SC, V10636, P516, DOI 10.1007/978-3-319-70090-8_53
   Pobar M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051475
   Rahmad N.A., 2019, Indonesian Journal of Electrical Engineering and Computer Science, V14, P1330, DOI 10.11591/ijeecs.v14.i3.pp1330-1335
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sah M, 2019, ADV INTELL SYST, V896, P107, DOI 10.1007/978-3-030-04164-9_17
   Sarwas, 2019, FOOTANDBALL INTEGRAT, DOI 10.5220/0008916000470056
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Zhang LJ, 2018, LECT NOTES ARTIF INT, V11013, P438, DOI 10.1007/978-3-319-97310-4_50
   ZHANG Y, 2020, SENSORS-BASEL, V20
NR 39
TC 5
Z9 5
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13141
EP 13165
DI 10.1007/s11042-021-11071-z
EA JUN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000657588300004
DA 2024-07-18
ER

PT J
AU Chen, L
AF Chen, Lei
TI Analysis of synchronized storage method for multimedia key areas based
   on machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Multimedia key area; Synchronous storage; Energy
   consumption; Data volume
AB Aiming at the problems of high energy consumption, small amount of stored data, large standard deviation of storage space, high failure rate of storage nodes and poor quality of data storage in existing multimedia key area synchronous storage methods, a machine learning based multimedia key area synchronous storage method is proposed. Using genetic algorithm to calculate the distance between data in multimedia critical area and cluster center, and redistribute cluster set, K-Mean is realized by M-R parallel computing model. Different amounts of data are allocated to the clustered sample data storage nodes to complete the synchronous storage of multimedia key area data. The experimental results show that compared with other methods, under the network regulation of 2800 m x 800 m, the storage energy consumption of the proposed method is in the range of 10 x 10(3)NJ-1250 x 10(3)NJ, and the storage energy consumption is low; The maximum number of data storage is 570, and the amount of stored data is large; the standard deviation of data storage space in the key area of multimedia changes within the range of 1.3-4, and the standard deviation of storage space is small. The proposed method lays a foundation for the further development of data storage technology.
C1 [Chen, Lei] Beijing Normal Univ, Int Business Fac, Zhuhai 519000, Peoples R China.
   [Chen, Lei] Haerbin Inst Technol, Management Fac, Haerbin 155923, Peoples R China.
C3 Beijing Normal University; Beijing Normal University Zhuhai; Harbin
   Institute of Technology
RP Chen, L (corresponding author), Beijing Normal Univ, Int Business Fac, Zhuhai 519000, Peoples R China.; Chen, L (corresponding author), Haerbin Inst Technol, Management Fac, Haerbin 155923, Peoples R China.
EM klheichen@sina.com
CR El-Rabiaey MA, 2016, J LIGHTWAVE TECHNOL, V34, P3726, DOI 10.1109/JLT.2016.2582838
   [韩敬峰 Han Jingfeng], 2016, [计算机仿真, Computer Simulation], V33, P390
   Hu JW., 2017, J INN MONG NORM UNIV, V3, P456, DOI DOI 10.3969/j.issn.1001.-8735.2017.03.033
   Huang Baohua, 2016, Computer Engineering, V42, P123, DOI 10.3969/j.issn.1000-3428.2016.07.021
   Li YB, 2017, INFORM SCIENCES, V387, P103, DOI 10.1016/j.ins.2016.09.005
   Nobukawa T, 2017, OPT EXPRESS, V25, P1326, DOI 10.1364/OE.25.001326
   Varan B, 2016, IEEE J SEL AREA COMM, V34, P1550, DOI 10.1109/JSAC.2016.2545418
   Wang Jian, 2016, Computer Engineering and Applications, V52, P248, DOI 10.3778/j.issn.1002-8331.1407-0245
   Wu CW, 2018, IEEE T NEUR NET LEAR, V29, P3022, DOI 10.1109/TNNLS.2017.2712619
   [徐英辉 Xu Yinghui], 2017, [电力系统及其自动化学报, Proceedings of the CSU-EPSA], V29, P93
   Yang CT, 2016, COMPUTING, V98, P93, DOI 10.1007/s00607-014-0399-4
   Yang DR, 2017, J CHINA ACAD ELECT I, V12, P546
   Yang XY, 2016, AUTOM INSTRUM, V10, P166
   Yazdi SMHT, 2017, IEEE T INF THEORY, V99, P1
   Zhao D, 2016, APPL PHYS LETT, V23, P1040
NR 15
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22685
EP 22700
DI 10.1007/s11042-019-07752-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000669314100017
DA 2024-07-18
ER

PT J
AU Galiyawala, H
   Raval, MS
AF Galiyawala, Hiren
   Raval, Mehul S.
TI Person retrieval in surveillance using textual query: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Attribute recognition; Natural language description; Person retrieval;
   Soft biometric attributes; Video surveillance
ID GENDER RECOGNITION; SEX DETERMINATION; GAIT; METACARPALS; BIOMETRICS;
   ATTRIBUTE; NETWORK; SPEECH
AB Recent advancement of research in biometrics, computer vision, and natural language processing has discovered opportunities for person retrieval from surveillance videos using textual query. The prime objective of a surveillance system is to locate a person using a description, e.g., a short woman with a pink t-shirt and white skirt carrying a black purse. She has brown hair. Such a description contains attributes like gender, height, type of clothing, colour of clothing, hair colour, and accessories. Such attributes are formally known as soft biometrics. They help bridge the semantic gap between a human description and a machine as a textual query contains the person's soft biometric attributes. It is also not feasible to manually search through huge volumes of surveillance footage to retrieve a specific person. Hence, automatic person retrieval using vision and language-based algorithms is becoming popular. In comparison to other state-of-the-art reviews, the contribution of the paper is as follows: 1. Recommends most discriminative soft biometrics for specific challenging conditions. 2. Integrates benchmark datasets and retrieval methods for objective performance evaluation. 3. A complete snapshot of techniques based on features, classifiers, number of soft biometric attributes, type of the deep neural networks, and performance measures. 4. The comprehensive coverage of person retrieval from handcrafted features based methods to end-to-end approaches based on natural language description.
C1 [Galiyawala, Hiren; Raval, Mehul S.] Ahmedabad Univ, Sch Engn & Appl Sci, Ahmadabad, Gujarat, India.
C3 Ahmedabad University
RP Galiyawala, H (corresponding author), Ahmedabad Univ, Sch Engn & Appl Sci, Ahmadabad, Gujarat, India.
EM hirenkumar.g@ahduni.edu.in; mehul.raval@ahduni.edu.in
OI Galiyawala, Hiren/0000-0002-2973-3844
FU Board of Research in Nuclear Sciences (BRNS), Government of India
   [36(3)/14/20/2016-BRNS/36020]
FX The Board of Research in Nuclear Sciences (BRNS), Government of India
   (36(3)/14/20/2016-BRNS/36020) supports this work. The authors
   acknowledge the support of NVIDIA Corporation for a donation of the
   Quadro K5200 GPU used for this research. The authors are thankful to
   Ahmedabad University, India, for access to resources like GPUs. We would
   also like to thank the vision and language domain's active researchers
   for creating publicly available challenging datasets.
CR Aggarwal S, 2020, IEEE WINT CONF APPL, P2606, DOI [10.1109/WACV45572.2020.9093640, 10.1109/wacv45572.2020.9093640]
   Amayeh G., 2008, 2008 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Work. CVPR Work, DOI [10.1109/CVPRW.2008.4563122, DOI 10.1109/CVPRW.2008.4563122]
   Anguelov D., 2007, Computer Vision and Pattern Recognition, P1
   [Anonymous], 2008, Biometrics: Theory, Applications and Systems
   [Anonymous], 2008, P 16 ACM INT C MULT, DOI [DOI 10.1145/1459359.1459470, DOI 10.1145/1459359.1459470.11.P]
   [Anonymous], 2006, INT WORKSH PERF EV T
   [Anonymous], 1976, Color: Universal Language and Dictionary of Names
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 2013, International Journal of Engineering Trends and Technology
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   Badawi A., 2006, IPCV, V1, P41
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Baltieri D, 2011, LECT NOTES COMPUT SC, V6978, P197, DOI 10.1007/978-3-642-24085-0_21
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   BenAbdelkader C, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P499
   BenAkdelkader C., 2002, Motion-based recognition of people in EigenGait space, P155
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Bertillon, 1889, INSTRUCTIONS TAKING
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Cao YT, 2020, ARXIV 200709609
   Chang TH, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P19, DOI 10.1109/MOT.2001.937977
   Chen DP, 2018, LECT NOTES COMPUT SC, V11220, P56, DOI 10.1007/978-3-030-01270-0_4
   [陈丽琼 CHEN Li-qiong], 2009, [高分子通报, Polymer Bulletin], P1
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   CHILDERS DG, 1991, J ACOUST SOC AM, V90, P1841, DOI 10.1121/1.401664
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Chung Junyoung, 2014, ARXIV14123555
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Denman S, 2012, IEEE INT C DIG IM CO, P1
   Denman S, 2015, PATTERN RECOGN LETT, V68, P306, DOI 10.1016/j.patrec.2015.06.015
   Denman S, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P196, DOI 10.1109/DICTA.2009.38
   Devlin J., 2018, BERT PRE TRAINING DE
   Ding LY, 2008, PROC CVPR IEEE, P3653
   Dong Q, 2019, IEEE I CONF COMP VIS, P3651, DOI 10.1109/ICCV.2019.00375
   Doretto G, 2011, J AMB INTEL HUM COMP, V2, P127, DOI 10.1007/s12652-010-0034-y
   El Kissi Ghalleb Asma, 2013, 2013 10th International Multi-Conference on Systems, Signals and Devices (SSD 2013), P1
   FALSETTI AB, 1995, J FORENSIC SCI, V40, P774
   Galiyawala H. J., 2020, Deep Biometrics, P191
   Galiyawala H, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.002
   Galiyawala H, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P471
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Golomb B.A., 1990, Advances in Neural Information Processing Systems (NIPS), P572
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Gupta S., 2014, INT J COMPUT SCI MOB, V3, P1289
   Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948
   Halstead M, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P477
   Halstead M, 2014, INT C PATT RECOG, P4501, DOI 10.1109/ICPR.2014.770
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu P, 2019, KNOWL-BASED SYST, V180, P38, DOI 10.1016/j.knosys.2019.05.017
   Huang CH, 2009, LECT NOTES COMPUT SC, V5414, P771, DOI 10.1007/978-3-540-92957-4_67
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jain A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P159, DOI 10.1109/AFGR.2004.1301524
   Jain AK, 2004, PROC SPIE, V5404, P561, DOI 10.1117/12.542890
   Jain AK, 2004, LECT NOTES COMPUT SC, V3087, P259
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Jain AK, 2009, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2009.5413921
   Jia S, 2015, PATTERN RECOGN LETT, V58, P35, DOI 10.1016/j.patrec.2015.02.006
   Kanchan T, 2011, J FORENSIC LEG MED, V18, P14, DOI 10.1016/j.jflm.2010.11.013
   Khatun A, 2020, ARXIV 200503222
   Kim HC, 2006, PATTERN RECOGN LETT, V27, P618, DOI 10.1016/j.patrec.2005.09.027
   Krishan K, 2011, J FORENSIC SCI, V56, P453, DOI 10.1111/j.1556-4029.2010.01652.x
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar SV, 2020, ARXIV 200402782
   Lagree S., 2011, 2011 IEEE International Conference on Technologies for Homeland Security (HST 2011), P440, DOI 10.1109/THS.2011.6107909
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5
   LAZENBY RA, 1994, J FORENSIC SCI, V39, P1188
   Lee JE, 2008, PROC CVPR IEEE, P373
   Li DW, 2019, IEEE T IMAGE PROCESS, V28, P1575, DOI 10.1109/TIP.2018.2878349
   Li DW, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P111, DOI 10.1109/ACPR.2015.7486476
   Li S, 2017, IEEE I CONF COMP VIS, P1908, DOI 10.1109/ICCV.2017.209
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Li SZ, 2009, ADV PATTERN RECOGNIT, P3, DOI 10.1007/978-1-84882-385-3_1
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Madden CS, 2005, IM VIS COMP C WICKL
   Marasco E, 2014, PROC SPIE, V9075, DOI 10.1117/12.2048125
   Martinho-Corbishley D, 2016, IEEE T CONTROL NETW, P1
   Martinho-Corbishley D, 2016, INT C PATT RECOG, P3067, DOI 10.1109/ICPR.2016.7900105
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883
   Nixon M., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V575, P279
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   Nixon MS, 2018, 15 IEEE INT C ADV VI, P1
   Omidiora E O, 2012, INT J ADV RES ARTIFI, V1, P2, DOI [DOI 10.14569/IJARAI.2012.010210, 10.14569/IJARAI.2012.010210]
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Pronobis M, 2009, IDIAP TECHNICAL REPO
   Ramanathan V, 2010, PATTERN RECOGN LETT, V31, P2425, DOI 10.1016/j.patrec.2010.07.011
   Rattani A, 2015, LECT NOTES COMPUT SC, V8926, P764, DOI 10.1007/978-3-319-16181-5_58
   Raval, 2016, CSI COMMUNICATIONS, V39, P9
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Reid DA, 2013, HANDB STAT, V31, P327, DOI 10.1016/B978-0-444-53859-8.00013-8
   Reid D.A., 2010, Proceedings of the 2nd ACM workshop on Multimedia in forensics, security and intelligence, MiFor '10, P25, DOI DOI 10.1145/1877972.1877982
   Reid DA, 2014, IEEE T PATTERN ANAL, V36, P1216, DOI 10.1109/TPAMI.2013.219
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rhodes Henry., 1968, FATHER SCI DETECTION
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   SCHEUER JL, 1993, J FORENSIC SCI, V38, P769
   Schumann A, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P465
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shah P, 2017, NAT C COMP VIS PATT, P457
   Shan CF, 2008, NEUROCOMPUTING, V71, P1931, DOI 10.1016/j.neucom.2007.09.023
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sorokin VN, 2008, ACOUST PHYS+, V54, P571, DOI 10.1134/S1063771008040192
   Sridharan S, 2017, P INT ASS PATT REC I, P496
   Sudowe P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P329, DOI 10.1109/ICCVW.2015.51
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Sun N, 2006, LECT NOTES COMPUT SC, V3972, P194
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P165, DOI 10.1109/ACV.2002.1182176
   Tan, 2019, 18 IEEE INT C ADV VI, P1
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Thomas VM, 2007, IEEE INT SYMP ELECTR, P180, DOI 10.1109/ISEE.2007.369390
   Tome P, 2014, IEEE T INF FOREN SEC, V9, P464, DOI 10.1109/TIFS.2014.2299975
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Walawalkar L, 2002, LECT NOTES COMPUT SC, V2388, P144
   Wang K., 2016, ABS160706215 CORR
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang YY, 2019, INT CONF ACOUST SPEE, P2057, DOI 10.1109/ICASSP.2019.8682456
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Woodward JD., 2003, BIOMETRICS
   WU K, 1991, J ACOUST SOC AM, V90, P1828, DOI 10.1121/1.401663
   Wu Q., 2019, SIGNAL IMAGE VIDEO P, V5, P1
   Yamaguchi M, 2017, IEEE I CONF COMP VIS, P1462, DOI 10.1109/ICCV.2017.162
   Yin Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1100
   Yoo JH, 2005, LECT NOTES COMPUT SC, V3708, P138
   Yu SQ, 2009, IEEE T IMAGE PROCESS, V18, P1905, DOI 10.1109/TIP.2009.2020535
   Zha ZJ, 2020, IEEE T MULTIMEDIA, V22, P1836, DOI 10.1109/TMM.2020.2972168
   Zhang Y, 2018, LECT NOTES COMPUT SC, V11205, P707, DOI 10.1007/978-3-030-01246-5_42
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zheng Zhedong, 2017, ARXIV171105535
   Zhou T, 2017, IEEE COMPUT SOC CONF, P27, DOI 10.1109/CVPRW.2017.10
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
   Zhu JQ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P331, DOI 10.1109/ICCVW.2013.51
NR 156
TC 8
Z9 8
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27343
EP 27383
DI 10.1007/s11042-021-10983-0
EA MAY 2021
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000651689300001
DA 2024-07-18
ER

PT J
AU Banerjee, T
   Jain, A
   Sethuraman, SC
   Satapathy, SC
   Karthikeyan, S
   Jubilson, A
AF Banerjee, Tathagat
   Jain, Aditya
   Sethuraman, Sibi Chakkaravarthy
   Satapathy, Suresh Chandra
   Karthikeyan, S.
   Jubilson, Ajith
TI Deep Convolutional Neural Network (Falcon) and transfer learning-based
   approach to detect malarial parasite
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malaria; Medical science; Deep learning; Data science; Deep&#8208;
   Convolutional Neural Networks; Microscopists; Artificial intelligence;
   Transfer learning; Computational power
AB Deep learning models have already benchmarked its demonstration in the applications of Medical Sciences. Present day medical industries suffer due to deadly disease such as malaria etc. As per the report from World Health Organization (WHO), it is noted that the amount of caution and care taken per patient by a human doctor to cure malaria is decreasing. To address this issue, this paper proposes an automated solution for the detection of malaria from the real-time image. The key idea of the proposed solution is to use a Deep Convolutional Neural Network (DCNN) called "Falcon" to detect the parasitic cells from blood smeared slide images of Malaria Screener. Furthermore, the class accuracy of the given dataset samples is maintained in order to model not only the normal case but to accurately predict the presence of malaria as well. Experimental results confirms that the model does not possess overfitting, class imbalance, and provides a reasonable classification report and trustworthy accuracy with 95.2 % when compared to the state-of-the-art Convolutional Neural Network (CNN) models.
C1 [Banerjee, Tathagat; Jain, Aditya; Sethuraman, Sibi Chakkaravarthy; Karthikeyan, S.; Jubilson, Ajith] VIT AP Univ, Sch Comp Sci & Engn, Amaravati, India.
   [Banerjee, Tathagat; Jain, Aditya; Sethuraman, Sibi Chakkaravarthy] VIT AP Univ, Artificial Intelligence & Robot AIR Res Ctr, Amaravati, India.
   [Banerjee, Tathagat; Jain, Aditya; Sethuraman, Sibi Chakkaravarthy; Karthikeyan, S.; Jubilson, Ajith] Vellore Inst Technol Andhra Pradesh VIT AP, Amaravati, India.
   [Satapathy, Suresh Chandra] KIIT Deemed Univ, Bhubaneswar, India.
C3 VIT-AP University; VIT-AP University; VIT-AP University; Kalinga
   Institute of Industrial Technology (KIIT)
RP Satapathy, SC (corresponding author), KIIT Deemed Univ, Bhubaneswar, India.
EM sureshsatapathy@gmail.com
RI Banerjee, Tathagat/GSM-9549-2022; Saminathan, Karthikeyan/KAO-3101-2024
OI Saminathan, Karthikeyan/0000-0003-2540-5752; satapathy, suresh
   chandra/0000-0001-8236-4104
FU Artificial Intelligence and Robotics (AIR) center, Vellore Institute of
   Technology - Andhra Pradesh, Amaravati, India
FX We would like to thank Dr. S. V. Kota Reddy, Vice Chancellor, VIT-AP
   University for motivating and helping us to build this project. This
   research is supported and carried out in Artificial Intelligence and
   Robotics (AIR) center, Vellore Institute of Technology - Andhra Pradesh,
   Amaravati, India.
CR Bashir A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, CONTROL, COMPUTING AND ELECTRONICS ENGINEERING (ICCCCEE)
   Chen KR, 2016, IEEE J SEL TOP QUANT, V22, DOI 10.1109/JSTQE.2016.2518959
   Delas Peñas K, 2018, LECT NOTES ARTIF INT, V10752, P472, DOI 10.1007/978-3-319-75420-8_45
   Delas Peñas KE, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P1, DOI 10.1109/CHASE.2017.51
   Hirimutugoda, 2009, 2009 2 INT C IMAGE S, DOI [10.1109/cisp.2009.5301750, DOI 10.1109/CISP.2009.5301750]
   Horne G, 2011, 2011 7 INT C NAT COM, DOI [10.1109/icnc.2011.6022163, DOI 10.1109/ICNC.2011.6022163]
   Khan A, 2018, 2018 IEEE 6TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD WORKSHOPS (W-FICLOUD 2018), P146, DOI 10.1109/W-FiCloud.2018.00029
   Kido S, 2018, PROC INT WORKSH ADV
   Ogunleye A, 2018 IEEE 14 INT C C, DOI [10.1109/icca.2018.8444167, DOI 10.1109/ICCA.2018.8444167]
   Sethi K, 2018, BIOMED CIRC SYST C, P639
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Shu GS, 2018, IEEE ACCESS, V6, P68621, DOI 10.1109/ACCESS.2018.2880196
   Stemple CC, 2012, IEEE SENS J, V12, P2735, DOI 10.1109/JSEN.2012.2205072
NR 13
TC 4
Z9 4
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13237
EP 13251
DI 10.1007/s11042-021-10946-5
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000647349000001
DA 2024-07-18
ER

PT J
AU Raghavaiah, P
   Varadarajan, S
AF Raghavaiah, Pemmu
   Varadarajan, S.
TI A CAD system design to diagnosize alzheimers disease from MRI brain
   images using optimal deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer disease; Mild cognitive impairment; Gabor filter; Deep neural
   network; Enhanced squirrel search algorithm
AB Memory related issues in brain are mainly caused by Alzheimer disease (AD) which is the most common form of dementia. This disease must be diagnosed in its prodromal stage known as Mild Cognitive Impairment (MCI) also it needs an accurate detection and classification technique. In this paper, a computer-aided diagnosis (CAD) system is implemented on Magnetic resonance imaging (MRI) data from ADNI database. This disease highly affects the Hippocampus and cerebrum regions which are normally found in the grey matter region of brain. At first, MNI/ICBM atlas space of every three dimensional MRI images are constructed using normalization procedure, then grey matter region of brain is extracted. Subsequently, feature extraction is done by two dimensional Gabor filter in three scales and eight orientations. Then, the proposed optimal Deep Neural Network (DNN) classifier is used to classify the images as Cognitive normal (CN), Alzheimer disease (AD), and Mild Cognitive Impairment (MCI). Here, DNN classifier is optimized by selecting optimal weight parameter using Enhanced Squirrel Search Algorithm. The experimental results prove an efficiency of the proposed method using MR images. The proposed algorithm beats existing techniques in terms of accuracy, sensitivity, and specificity.
C1 [Raghavaiah, Pemmu] JNTUK, Univ Coll Engn, Dept Elect & Commun Engn, Kakinada, India.
   [Varadarajan, S.] Sri Venkateswara Univ, Dept Elect & Commun Engn, SVU Coll Engn, Tirupati, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Sri Venkateswara
   University
RP Raghavaiah, P (corresponding author), JNTUK, Univ Coll Engn, Dept Elect & Commun Engn, Kakinada, India.
EM raghavaiahpemmu@gmail.com
RI RAGHAVAREDDY, PEMMU/AAE-1938-2022; Sourirajan, Varadarajan/HDN-3210-2022
OI RAGHAVAREDDY, PEMMU/0000-0003-4757-7280; 
CR Altaf T, 2018, BIOMED SIGNAL PROCES, V43, P64, DOI 10.1016/j.bspc.2018.02.019
   Babulal GM, 2019, ALZHEIMERS DEMENT, V15, P292, DOI 10.1016/j.jalz.2018.09.009
   Bartos A, 2019, PSYCHIAT RES-NEUROIM, V287, P70, DOI 10.1016/j.pscychresns.2019.01.014
   Ben Ahmed O, 2015, MULTIMED TOOLS APPL, V74, P1249, DOI 10.1007/s11042-014-2123-y
   Bilderbeck AC, 2019, NEUROSCI BIOBEHAV R, V97, P87, DOI 10.1016/j.neubiorev.2018.06.019
   Çevik A, 2017, ANN OPER RES, V258, P31, DOI 10.1007/s10479-017-2405-7
   Cui RX, 2019, COMPUT MED IMAG GRAP, V73, P1, DOI 10.1016/j.compmedimag.2019.01.005
   Jain M, 2019, SWARM EVOL COMPUT, V44, P148, DOI 10.1016/j.swevo.2018.02.013
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Ju RH, 2019, IEEE ACM T COMPUT BI, V16, P244, DOI 10.1109/TCBB.2017.2776910
   Karami V, 2019, INT J IMAG SYST TECH, V29, P83, DOI 10.1002/ima.22300
   Keserwani P, 2016, INT J IMAGE GRAPH SI, V8
   Li F, 2018, COMPUT MED IMAG GRAP, V70, P101, DOI 10.1016/j.compmedimag.2018.09.009
   Li HC, 2019, IEEE T BIO-MED ENG, V66, P3393, DOI 10.1109/TBME.2019.2904702
   Lin SY, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101680
   Liu J, 2018, IEEE ACM T COMPUT BI, V15, P624, DOI 10.1109/TCBB.2016.2635144
   Liu J, 2017, IEEE T NANOBIOSCI, V16, P428, DOI 10.1109/TNB.2017.2707139
   Liu M, 2019, IEEE T CYBERN, P1
   Liu MX, 2019, IEEE T BIO-MED ENG, V66, P1195, DOI 10.1109/TBME.2018.2869989
   Meyer SRA, 2019, AGING NEUROPSYCHOL C, V26, P447, DOI 10.1080/13825585.2018.1475002
   Pandya M. D., 2019, ADV UBIQUITOUS SENSI, P37, DOI 10.1016/B978-0-12-815370-3.00003-7
   Peng JL, 2019, PATTERN RECOGN, V88, P370, DOI 10.1016/j.patcog.2018.11.027
   Platero C, 2019, HUM BRAIN MAPP, V40, P1666, DOI 10.1002/hbm.24478
   Razavi F, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0190-7
   Saravanakumar S, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1147-7
   Shi Y, 2019, IEEE T NEURAL NETW L
   Wang HF, 2019, NEUROCOMPUTING, V333, P145, DOI 10.1016/j.neucom.2018.12.018
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P10393, DOI 10.1007/s11042-016-4222-4
   Xu LN, 2019, IEEE ACCESS, V7, P26157, DOI 10.1109/ACCESS.2019.2894530
   Zhang Y, 2016, ENG APPL ARTIF INTEL, V50, P245, DOI 10.1016/j.engappai.2016.01.032
   Zhang YD, 2018, J ALZHEIMERS DIS, V65, P855, DOI 10.3233/JAD-170069
NR 31
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26411
EP 26428
DI 10.1007/s11042-021-10928-7
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000646557900001
DA 2024-07-18
ER

PT J
AU Rao, PCS
   Lalwani, P
   Banka, H
   Rao, GSN
AF Rao, P. C. Srinivasa
   Lalwani, Praveen
   Banka, Haider
   Rao, G. Siva Nageswara
TI Competitive swarm optimization based unequal clustering and routing
   algorithms (CSO-UCRA) for wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks; Hotspot problem; Unequal clustering; Routing;
   Energy consumption; Competitive swarm optimization (CSO)
ID ENERGY-EFFICIENT; MAXIMIZING LIFETIME; PARTIAL COVERAGE; HYBRID;
   PROTOCOL
AB Cluster based routing approaches have been researched extensively for saving energy of wireless sensor networks (WSNs). In a cluster based routing mechanism, cluster heads (CHs) cooperate mutually to forward their data to the base station (BS) through multi-hop fashion. Due to this process, CHs near to the BS loaded with huge relay traffic and tend to die quickly, which causes partition of the network is popularly known as a hot-spot problem. To tackle the hot-spot problem, in this paper, competitive swarm optimization (CSO) based algorithms have been proposed, jointly call these algorithms as CSO-UCRA (CSO based Unequal Clustering and Routing Algorithms). First, the CH selection algorithm has been presented which is based on CSO based technique, next assign the non-CH sensors to CHs based on the derived CHproficiency function. Finally, a CSO based routing algorithm has been presented. Efficient particle encoding schemes and novel fitness functions have been developed for these algorithms. The CSO-UCRA is simulated extensively with varying number of sensor nodes and CHs for various WSN scenarios, and the obtained results are compared with some recent devised algorithms and standard meta-heuristic based algorithm called PSO-UCRA to show the efficiancy in terms of various performance metrics. CSO-UCRA shows decreased energy consumption of 28.48%, 22.55%, 12.92%, and 3.81%, increased network lifetime of 56.92%, 46.02%, 26.2%, and 8.04% and increased data packets received 73%, 52.5%, 20.8%, and 6.18% over EBUC, EAUCF, EPUC and PSO-UCRA respectively.
C1 [Rao, P. C. Srinivasa; Rao, G. Siva Nageswara] Koneru Lakshmaiah Educ Fdn, Comp Sci & Engn, Vaddeswaram, AP, India.
   [Lalwani, Praveen] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
   [Banka, Haider] IIT ISM Dhanbad, Comp Sci & Engn, Dhanbad, Bihar, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   VIT Bhopal University; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Lalwani, P (corresponding author), VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
EM p.csrao@kluniversity.in; praveen.lalwani@vitbhopal.ac.in;
   hbanka2002@yahoo.com; sivanags@kluniversity.in
RI G, Siva Nageswara Rao/GMW-7483-2022
OI G, Siva Nageswara Rao/0000-0001-6422-4968
CR Abbasi AA, 2007, COMPUT COMMUN, V30, P2826, DOI 10.1016/j.comcom.2007.05.024
   Afsar MM, 2014, C LOCAL COMPUT NETW, P262, DOI 10.1109/LCN.2014.6925780
   Afsar MM, 2014, J NETW COMPUT APPL, V46, P198, DOI 10.1016/j.jnca.2014.09.005
   Akkaya K., 2005, Ad Hoc Networks, V3, P325, DOI 10.1016/j.adhoc.2003.09.010
   Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   Attea BA, 2012, APPL SOFT COMPUT, V12, P1950, DOI 10.1016/j.asoc.2011.04.007
   Bagci H, 2013, APPL SOFT COMPUT, V13, P1741, DOI 10.1016/j.asoc.2012.12.029
   Carrabs F, 2017, LECT NOTES COMPUT SC, V10232, P285, DOI 10.1007/978-3-319-57186-7_22
   Carrabs F, 2016, IFAC PAPERSONLINE, V49, P973, DOI 10.1016/j.ifacol.2016.07.902
   Carrabs F, 2015, J NETW COMPUT APPL, V58, P12, DOI 10.1016/j.jnca.2015.08.018
   Carrabs F, 2015, COMPUT OPER RES, V60, P121, DOI 10.1016/j.cor.2015.02.013
   Cheng R, 2015, IEEE T CYBERNETICS, V45, P191, DOI 10.1109/TCYB.2014.2322602
   Dietrich I, 2009, ACM T SENSOR NETWORK, V5, DOI 10.1145/1464420.1464425
   Guru SM, 2005, PROCEEDINGS OF THE 2005 INTELLIGENT SENSORS, SENSOR NETWORKS & INFORMATION PROCESSING CONFERENCE, P319
   Heiniger R. W., 2000, Proceedings of the 5th International Conference on Precision Agriculture, Bloomington, Minnesota, USA, 16-19 July, 2000, P1
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Jana PK, 2015, INT C SWARM EV MEM C, P247
   Jiang Chang-jiang, 2010, Journal of China Universities of Posts and Telecommunications, V17, P94, DOI 10.1016/S1005-8885(09)60494-5
   Jiuqiang Xu, 2010, Wireless Sensor Network, V2, P606, DOI 10.4236/wsn.2010.28072
   Khalil EA, 2011, SWARM EVOL COMPUT, V1, P195, DOI 10.1016/j.swevo.2011.06.004
   Lee S, 2011, WIRELESS PERS COMMUN, V56, P715, DOI 10.1007/s11277-009-9842-9
   Lindsey S, 2002, AEROSP CONF PROC, P1125, DOI 10.1109/aero.2002.1035242
   Liu T, 2012, COMPUT COMMUN, V35, P2150, DOI 10.1016/j.comcom.2012.06.013
   Malathi L, 2015, COMPUT ELECTR ENG, V48, P358, DOI 10.1016/j.compeleceng.2015.06.019
   Mao Song, 2011, Journal of China Universities of Posts and Telecommunications, V18, P89, DOI 10.1016/S1005-8885(10)60126-4
   Nayyar, 2014, INT J COMPUT SCI MOB, V3, P112
   Nayyar, 2014, COMBATING CONGESTION
   Nayyar A., 2015, J WIRELESS NETWORKIN, V5, P19
   Nayyar Anand., 2018, Advances in swarm intelligence for optimizing problems in computer science, P53
   Rao PCS, 2016, ADV INTELL SYST COMP, V379, P605, DOI 10.1007/978-81-322-2517-1_58
   Rao PCS, 2017, WIREL NETW, V23, P759, DOI 10.1007/s11276-015-1148-0
   Rao PCS, 2017, WIREL NETW, V23, P2005, DOI 10.1007/s11276-016-1270-7
   Rao PCS, 2017, WIREL NETW, V23, P433, DOI 10.1007/s11276-015-1156-0
   Rao PCS, 2016, LECT NOTES COMPUT SC, V9873, P222, DOI 10.1007/978-3-319-48959-9_20
   Sabor N, 2016, APPL SOFT COMPUT, V43, P372, DOI 10.1016/j.asoc.2016.02.016
   Sharma N., 2014, INT J APPL INNOVATIO, V3, P441
   Singh S, 2020, PEER PEER NETW APPL, V13, P1357, DOI 10.1007/s12083-020-00890-w
   Singh S, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.100354
   Soro S., 2005, 19 IEEE INT PARALLEL, P8
   Verma S, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105788
   Younis O, 2004, IEEE T MOBILE COMPUT, V3, P366, DOI 10.1109/TMC.2004.41
   Yu JG, 2011, INT J DISTRIB SENS N, DOI 10.1155/2011/202145
   Zeng B, 2016, APPL SOFT COMPUT, V41, P135, DOI 10.1016/j.asoc.2015.12.028
NR 43
TC 27
Z9 27
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26093
EP 26119
DI 10.1007/s11042-021-10901-4
EA APR 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000644761700002
DA 2024-07-18
ER

PT J
AU Abbes, W
   Sellami, D
   Marc-Zwecker, S
   Zanni-Merk, C
AF Abbes, Wiem
   Sellami, Dorra
   Marc-Zwecker, Stella
   Zanni-Merk, Cecilia
TI Fuzzy decision ontology for melanoma diagnosis using KNN classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma; ABCD rule; Computer-aided diagnosis system; Ontology; Feature
   extraction; Conceptual modeling; Bag-of-Words; KNN classifier
ID DERMOSCOPY USE; DERMATOLOGISTS
AB Melanoma is the most dangerous type of skin cancer when discovered in an advanced stage. Early detection of melanoma improves survival. Several Computer -Aided Diagnosis (CAD) systems are currently developed to speed up early diagnosis. Recently, ontology is widely adapted for describing and diagnosing a disease. For melanoma detection, the ontology reasoning of dermatologists is based on expert rules, such as ABCD rule. Accordingly, dermatologists classify skin lesions in three classes: melanoma, benign, and recommended follow-up class. In this paper, we propose a CAD system based on an ontology for melanoma diagnosis by giving the probability of being melanoma. We first present our ontology focusing on its main concepts involved in ABCD rule: Asymmetry, Border, Color and Differential structures. Accordingly, the Bag-of-Words, modeling these concepts, are generated from extracted features of skin lesion images. An important step in ontology is to define rules relating the different concepts. In our case, these rules allow the fuzzy decision to classify lesion in melanoma, benign or recommended follow-up class with a malignancy probability. Considering the similarity of melanoma cases, the K-Nearest Neighbors approach is applied to make the final decision in case of a recommended follow-up class. Experimental validation on two public datasets of 206 lesion images shows that our approach presents an efficient method of analysis and can be more appropriate for lesion severity classification. It yields a sensitivity of (96%) and an accuracy of (92%), surpassing existing recent approaches on melanoma diagnosis.
C1 [Abbes, Wiem; Sellami, Dorra] Sfax Univ, Natl Engn Sch Sfax, CEM Lab, Soukra St, Sfax 3038, Tunisia.
   [Marc-Zwecker, Stella] Univ Strasbourg, CNRS, ICUBE SDC Team, Strasbourg, France.
   [Zanni-Merk, Cecilia] Normandy Univ, INSA Rouen, LITIS MIND, F-76000 St Etienne Du Rouvray, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Centre
   National de la Recherche Scientifique (CNRS); Universites de Strasbourg
   Etablissements Associes; Universite de Strasbourg; Universite de Rouen
   Normandie
RP Abbes, W (corresponding author), Sfax Univ, Natl Engn Sch Sfax, CEM Lab, Soukra St, Sfax 3038, Tunisia.
EM wiem.abbes@enis.tn
RI Sellami, Dorra/KSL-6903-2024
OI Abbes, Wiem/0000-0001-6414-7931
CR Abbes W., 2016, C IM PROC APPL SYST, P1
   Abbes W, 2017, PROCEDIA COMPUT SCI, V112, P2096, DOI 10.1016/j.procs.2017.08.226
   Amelard R, 2015, IEEE T BIO-MED ENG, V62, P820, DOI 10.1109/TBME.2014.2365518
   Argenziano G., 2002, DERMOSCOPY TUTORIAL
   Braun RP, 2005, J AM ACAD DERMATOL, V52, P109, DOI 10.1016/j.jaad.2001.11.001
   Celebi ME, 2014, IEEE SYST J, V8, P980, DOI 10.1109/JSYST.2014.2313671
   Chang CC, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL II, PROCEEDINGS, P346, DOI 10.1109/IITA.2008.259
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Cokkinides V., 2005, American Cancer Society: Cancer Facts and Figures
   Dean M., 2004, SWRL: a semantic web Rule Language combining OWL and RuleML
   Engasser HC, 2010, J AM ACAD DERMATOL, V63, P412, DOI 10.1016/j.jaad.2009.09.050
   Fan JP, 2015, IEEE T IMAGE PROCESS, V24, P4172, DOI 10.1109/TIP.2015.2457337
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Gupta S., 2012, LNCS, V7540, P430, DOI [DOI 10.1007/978-3-662-46641-4_40, 10.1007/978-3-662-46641-4\_40, 10.1007/, DOI 10.1007/978-3-662-46641-4]
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang CL., 2005, CANC SKIN, P265
   Kaliyadan F, 2018, INDIAN J DERMATOL VE, V84, DOI 10.4103/ijdvl.IJDVL_122_17
   Kuo YW, 2015, DERMATOL SIN, V33, P215, DOI 10.1016/j.dsi.2015.06.002
   Thao LT, 2017, 2017 21ST ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS (IES), P106, DOI 10.1109/IESYS.2017.8233570
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Maglogiannis I, 2009, IEEE T INF TECHNOL B, V13, P721, DOI 10.1109/TITB.2009.2017529
   Maragoudakis M, 2008, IEEE INT C BIOINF BI, P346
   Marchetti MA, 2018, J AM ACAD DERMATOL, V78, P270, DOI 10.1016/j.jaad.2017.08.016
   MUIR BM, 1987, INT J MAN MACH STUD, V27, P527, DOI 10.1016/S0020-7373(87)80013-5
   Murugan A, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1400-8
   Rijsbergen C. J. V., 1979, Information Retrieval
   Sheha MA., 2012, Int J Comput Appl, V42, P22
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Sherimon PC, 2016, ARAB J SCI ENG, V41, P1145, DOI 10.1007/s13369-015-1959-4
   STEINER A, 1993, J AM ACAD DERMATOL, V29, P581, DOI 10.1016/0190-9622(93)70225-I
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhao TY, 2018, IEEE T IMAGE PROCESS, V27, P4740, DOI 10.1109/TIP.2018.2845118
NR 34
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25517
EP 25538
DI 10.1007/s11042-021-10858-4
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640944400001
DA 2024-07-18
ER

PT J
AU Rinosha, SMJ
   Augasta, MG
AF Rinosha, Jainul S. M.
   Augasta, Gethsiyal M.
TI Review of recent advances in visual tracking techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Discriminative trackers; Generative trackers;
   Correlation filter based trackers; Combined trackers; Visual trackers
   review; Deep learning
ID OBJECT TRACKING; ROBUST
AB Visual tracking is the widely emerging research in computer vision applications. Nowadays, researchers have proposed various novel tracking methodologies to attain the excellence in terms of performance. In this review, several recent visual tracking methodologies have been clearly examined and categorised into four different categories such as Discriminative Trackers, Generative Trackers, Correlation Filter Based Trackers and Combined Trackers. Moreover, this study analyses and tabulates the methodologies applied in every recently proposed visual tracking method. The main objective of this review is to provide a detailed insight to the reader with the different aspects of tracking methodologies and future direction of tracking researches. The experimental evaluations on recent trackers have been documented for the better understanding of the performance of existing visual trackers on different benchmark datasets such as OTB 2015, VOT 2016 and MOT 2020.
C1 [Rinosha, Jainul S. M.; Augasta, Gethsiyal M.] Manonmaniam Sundaranar Univ, Kamaraj Coll, Thoothuhudi 628003, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Augasta, MG (corresponding author), Manonmaniam Sundaranar Univ, Kamaraj Coll, Thoothuhudi 628003, Tamil Nadu, India.
EM sm.jainulrinosha@gmail.com; augastaglady@gmail.com
RI M, Gethsiyal Augasta/AAS-2164-2020
OI M, Gethsiyal Augasta/0000-0002-1975-7623
CR [Anonymous], 2008, CSE200807
   [Anonymous], 2015, ICCV WORKSH
   [Anonymous], 2009, CVPR
   [Anonymous], 2018, IEEE T PATTERN ANAL
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Blanco-Filgueira B, 2019, IEEE INTERNET THINGS, V6, P5423, DOI 10.1109/JIOT.2019.2902141
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257
   Galoogahi Hamed Kiani, 2014, CVPR
   Gan Q, 2015, ABS151106425 CORR
   Gao Y, 2019, IEEE T CIRCUITS SYST
   Grabner H., 2006, BMVC, P47
   Guo X, 2019, MULTIMED TOOLS APPL, P1
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Huang D, 2015, P BMVC
   Huang Y, 2019, MULTIMED TOOLS APPL, V78, P34725, DOI 10.1007/s11042-019-07901-w
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kahou SE, 2015, ABS151008660 CORR
   Khalaf AA, 2020, VISUAL COMPUT, P1
   Kitani K., 2018, ARXIV PREPRINT ARXIV
   Kristan M, 2016, LECT NOTES COMPUT SC, V9914, P777, DOI 10.1007/978-3-319-48881-3_54
   Kuai YL, 2018, J VIS COMMUN IMAGE R, V51, P104, DOI 10.1016/j.jvcir.2018.01.008
   Kumar A., 2020, MICR END FUNCT BIOL, P1, DOI DOI 10.1016/B978-0-12-819654-0.00001-6
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Li C, 2019, ADAPTIVE WEIGHTED CN, DOI [10.1109/ACCESS.2019.2922494, DOI 10.1109/ACCESS.2019.2922494]
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li H., 2014, P BMVC
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lv Y-Q, 2018, VISUAL TRACKING TREE, DOI [10.1049/iet-ipr.2018.6517, DOI 10.1049/IET-IPR.2018.6517]
   Ma C., 2018, INT J COMPUTER VISIO
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Montero AS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P587, DOI 10.1109/ICCVW.2015.80
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Nam H., 2016, ABS160807242 CORR
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shi J., 2020, ARXIV200309003CS
   Song K, 2019, VISUAL OBJECT TRACKI, DOI [10.1109/TCSVT.2019.2948600, DOI 10.1109/TCSVT.2019.2948600]
   Sun J, 2019, INFORM SCIENCES, V486, P133, DOI 10.1016/j.ins.2019.02.043
   Tang FH, 2019, MULTIMED TOOLS APPL, V78, P21065, DOI 10.1007/s11042-019-7416-8
   Tian SJ, 2020, VISUAL COMPUT, V36, P1219, DOI 10.1007/s00371-019-01730-6
   Tokola R, 2015, IEEE WINT CONF APPL, P935, DOI 10.1109/WACV.2015.129
   Unlu HU, 2019, IEEE IND ELEC, P638, DOI 10.1109/IECON.2019.8927731
   Viola P, 2001, P 2001 IEEE COMP SOC, V1
   Wang F, 2018, ROBUST LONG TERM COR, DOI [10.1049/iet-ipr.2018.6209, DOI 10.1049/IET-IPR.2018.6209]
   WANG Q., 2017, ABS170404057 CORR
   Wang X., 2020, ARXIV PREPRINT ARXIV
   Wang Y, 2019, MULTIMED TOOLS APPL, V78, P31633, DOI 10.1007/s11042-019-07851-3
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Xue XZ, 2019, MULTIMED TOOLS APPL, V78, P21187, DOI 10.1007/s11042-019-7246-8
   Yang A., 2019, MULTIMED TOOLS APPL, V78, P27933, DOI [10.1007/s11042-019-07864-y, DOI 10.1007/s11042-019-07864-y]
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Yi Y, 2018, MULTIMED TOOLS APPL
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P14277, DOI 10.1007/s11042-018-6800-0
   Zeng X, 2019, VISUAL TRACKING BASE, DOI [10.1109/ACCESS.2019.2924746, DOI 10.1109/ACCESS.2019.2924746]
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang R, 2019, ACTA ASTRONAUT, V162, P121, DOI 10.1016/j.actaastro.2019.06.003
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zolfaghari M., 2019, VISUAL COMPUT
NR 75
TC 3
Z9 3
U1 7
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24185
EP 24203
DI 10.1007/s11042-021-10848-6
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000635488700002
DA 2024-07-18
ER

PT J
AU Dagher, I
   Barbara, D
AF Dagher, Issam
   Barbara, Dany
TI Facial age estimation using pre-trained CNN and transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial age estimation; Pretrained CNN; Transfer learning
ID CLASSIFICATION; ROBUST; FACE
AB This paper tackled the problem of human facial age estimation using transfer learning of some pre-trained CNNs, namely VGG, Res-Net, Google-Net, and Alex-Net. Those networks have been fine-tuned with transfer learning and undergone many experiments to get the optimum number of outputs and the optimum age gap. Based on those experiments, a novel hierarchical network that generates high age estimation accuracy was developed. This new network consists of a set of pre-trained 2-classes CNNs (Google-Net) with an optimum age gap which can better organize the face images in the age group they belong to. To show its effectiveness, it was compared with other states of the art techniques on the FGNET and the MORPH databases.
C1 [Dagher, Issam; Barbara, Dany] Univ Balamand, Comp Engn Dept, Tripoli, Lebanon.
C3 University Balamand
RP Dagher, I (corresponding author), Univ Balamand, Comp Engn Dept, Tripoli, Lebanon.
EM dagheri@balamand.edu.lb
CR Abousaleh FS, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0151-4
   [Anonymous], 2021, FG NET AGING DATABAS
   [Anonymous], 2010, SCHOLARPEDIA, DOI DOI 10.4249/SCHOLARPEDIA.9701
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.532
   [Anonymous], 2018, P IEEE WORKSH APPL C
   [Anonymous], 2006, P 14 ANN ACM INT C M
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Chen SX, 2017, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2017.86
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Günay A, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P378
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   He YT, 2017, IEEE IMAGE PROC, P1092, DOI 10.1109/ICIP.2017.8296450
   Huerta I, 2015, PATTERN RECOGN LETT, V68, P239, DOI 10.1016/j.patrec.2015.06.006
   Iorga C, 2019, INT C ELECT COMPUT, DOI 10.1109/ecai46879.2019.9042173
   Kang JS, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040108
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang-Yu Chang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3396, DOI 10.1109/ICPR.2010.829
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Mohan MC, 2010, INT J COMPUT SCI NET, V10, P61
   Murty Gorti S, 2013, INT J COMPUTER SCI E, V5, P885
   Ni B., 2009, Proceedings of the 17th ACM international conference on Multimedia, P85
   Punyani P, 2020, ARTIF INTELL REV, V53, P3299, DOI 10.1007/s10462-019-09765-w
   Punyani P, 2018, INT J IMAGE DATA FUS, V9, P222, DOI 10.1080/19479832.2018.1423644
   Ramanathan N., 2006, IEEE COMP SOC C COMP, P387, DOI [DOI 10.1109/CVPR.2006.187, 10.1109/CVPR.2006.187]
   Rattani A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P756, DOI 10.1109/BTAS.2017.8272766
   Rhodes MG, 2009, APPL COGNITIVE PSYCH, V23, P1, DOI 10.1002/acp.1442
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Ruder S, 2017, arXiv preprint arXiv:1706.05098
   Sabharwal, 2018, ARTIF INTELL REV
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tian, 2016, ABS160903815 CORR
   Vijaya Kumar V., 2013, International Journal of Image, Graphics and Signal Processing, V6, P9, DOI 10.5815/ijigsp.2014.01.02
   Yan SC, 2007, IEEE I CONF COMP VIS, P1735
   Yan SC, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P96
   YI D, 2015, COMPUTER VISION ACCV
   Yu TT, 2019, CAAI T INTELL TECHNO, V4, P122, DOI 10.1049/trit.2019.0017
   Zhang K, 2020, IEEE T CIRC SYST VID, V30, P3140, DOI 10.1109/TCSVT.2019.2936410
NR 48
TC 17
Z9 17
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20369
EP 20380
DI 10.1007/s11042-021-10739-w
EA MAR 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625713700001
DA 2024-07-18
ER

PT J
AU Keyvanpour, MR
   Khanbani, N
   Boreiry, M
AF Keyvanpour, Mohammad Reza
   Khanbani, Neda
   Boreiry, Mahsa
TI A secure method in digital video watermarking with transform domain
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Discrete cosine transform; Watermark; Digital video
   Watermarking; Collusion attacks
ID ROBUST; SCHEME; IMAGE; COLLUSION; ROTATION
AB One of the problems in the digital world is the secure transmission of information through insecure communication channels which has been selected as the main concept discussed in this research. This article, by thoroughly analyzing the types of attacks in video watermarking, learns the basics used in the proposed method and offers a solution to deal with the most important categories. Therefore, it presents a secure solution against collusion attacks by introducing a three-dimensional discrete cosine transform algorithm. According to the evaluations, it can be claimed that the proposed solution is resistant to collusion attacks, which is the most important attack in the field of digital watermarking. Another strength of the proposed algorithm compared to other methods is its higher capacity in watermarking. The proposed algorithm, using its special blocking method, has the ability to cover all types of video, both dynamic and static. Various tests have been applied to the selected dataset to analyze the security and the performance of the proposed algorithm. The results show that if the proposed algorithm is used in watermarking, in addition to high accuracy, it can have an acceptable resistance to attacks.
C1 [Keyvanpour, Mohammad Reza] Alzahra Univ, Dept Comp Engn, Tehran, Iran.
   [Khanbani, Neda; Boreiry, Mahsa] Alzahra Univ, Dept Comp Engn, Data Min Lab, Tehran, Iran.
C3 Alzahra University; Alzahra University
RP Keyvanpour, MR (corresponding author), Alzahra Univ, Dept Comp Engn, Tehran, Iran.
EM keyvanpour@alzahra.ac.ir; neda.khanbani@yahoo.com;
   mahsa.boreiri@yahoo.com
RI Keyvanpour, Mohammad Reza/AAL-5574-2020
OI Keyvanpour, Mohammad Reza/0000-0003-2115-9099
CR Abdelwahab KM, 2020, MULTIMED TOOLS APPL, V79, P5617, DOI 10.1007/s11042-019-08023-z
   Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Ahmadi SBB, 2020, MULTIMED TOOLS APPL, V79, P1075, DOI 10.1007/s11042-019-08197-6
   Al-Maweri NAAS, 2017, MULTIMED TOOLS APPL, V76, P16239, DOI 10.1007/s11042-016-3906-0
   Bahrami Z, 2018, MULTIMED TOOLS APPL, V77, P327, DOI 10.1007/s11042-016-4226-0
   Bakshi, 2019, PROGR ADV COMPUTING
   Bayoudh I, 2018, MULTIMED TOOLS APPL, V77, P14361, DOI 10.1007/s11042-017-5033-y
   Bhardwaj A, 2018, MULTIMED TOOLS APPL, V77, P19659, DOI 10.1007/s11042-017-5340-3
   Cao ZL, 2019, MULTIMED TOOLS APPL, V78, P26089, DOI 10.1007/s11042-019-07809-5
   Chopra A, 2020, MULTIMED TOOLS APPL, V79, P501, DOI 10.1007/s11042-019-08087-x
   Das Soumik, 2018, International Journal of Information Technology, V10, P21, DOI 10.1007/s41870-017-0054-3
   Dhaou D, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0223-1
   Gupta G, 2018, MICROSYST TECHNOL, V24, P2539, DOI 10.1007/s00542-017-3689-x
   He JH, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00500-y
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P8603, DOI 10.1007/s11042-017-4754-2
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Jain L., 2020, COMPUTER VISION CONT, V6
   Kadu S, 2018, MULTIMEDIA SYST, V24, P583, DOI 10.1007/s00530-017-0584-3
   Kanócz T, 2009, PROCEEDINGS OF 19TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA 2009, P99
   Karmakar A, 2016, J KING SAUD UNIV-COM, V28, P199, DOI 10.1016/j.jksuci.2014.06.019
   Kumar S., 2020, MULTIMED TOOLS APPL, P1
   Li Z, 2015, MULTIMED TOOLS APPL, V74, P2781, DOI 10.1007/s11042-013-1678-3
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Maloo S, 2018, SMART INNOV SYST TEC, V83, P509, DOI 10.1007/978-3-319-63673-3_61
   Mohammed AA, 2018, MULTIMED TOOLS APPL, V77, P2791, DOI 10.1007/s11042-017-4427-1
   Shoitan R, 2020, MULTIMED TOOLS APPL, V79, P26837, DOI 10.1007/s11042-020-09258-x
   Singh KM, 2018, MULTIMED TOOLS APPL, V77, P16419, DOI 10.1007/s11042-017-5213-9
   Singh OP, 2021, MULTIMED TOOLS APPL, V80, P30367, DOI 10.1007/s11042-020-09606-x
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Singh V., 2018, ADV INTELLIGENT SYST, DOI [10.1007/978-981-10-3773-3_42, DOI 10.1007/978-981-10-3773-3_42]
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Tian LH, 2020, MULTIMED TOOLS APPL, V79, P1759, DOI 10.1007/s11042-019-08256-y
   Wang XY, 2015, COMPUT ELECTR ENG, V46, P403, DOI 10.1016/j.compeleceng.2015.04.001
   Wu JY, 2020, MULTIMED TOOLS APPL, V79, P22727, DOI 10.1007/s11042-020-08987-3
   Yang RP, 2019, LECT NOTES COMPUT SC, V11921, P371, DOI 10.1007/978-3-030-34578-5_14
   Yoo G, 2017, J REAL-TIME IMAGE PR, V13, P467, DOI 10.1007/s11554-015-0557-8
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 39
TC 7
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20449
EP 20476
DI 10.1007/s11042-021-10730-5
EA MAR 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625713700006
DA 2024-07-18
ER

PT J
AU Li, T
   Cao, WQ
AF Li, Teng
   Cao, Weiqun
TI Research on a method of creating digital shadow puppets based on
   parameterized templates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parameterized template; Digital shadow puppet; Gesture recognition;
   Gesture control
AB Shadow play is an ancient traditional folk art in China and a precious Chinese artistic treasure. However, with the continuous diversification of entertainment forms, traditional shadow play art is gradually fading out of sight and even facing the possibility of having no successor. A fast method of creating digital shadow puppets based on parameterized templates is proposed in this paper. Adopting this method can transform the materials of a shadow character designed by an artist into a digital shadow puppet that can be interactively controlled by hand gestures. This paper classifies digital shadow puppets based on an analysis and summary of traditional shadow play art and designs the corresponding parameterized template for each type. In addition, a control method for shadow puppets based on the Leap Motion device is designed and implemented in this paper in accordance with common human hand gestures and the requirements for controlling shadow puppets. Based on the above work, we design and implement a platform for digital shadow story creation and performance and test the proposed method on this platform. The experimental results show that the method proposed in this paper can quickly create digital shadow puppets that can be interactively controlled and allow shadow plays to be performed based on gesture control. The research ideas and achievements of this paper help promote the development of digital shadow play technology and have great significance to the inheritance and development of traditional shadow play art.
C1 [Li, Teng; Cao, Weiqun] Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing 100083, Peoples R China.
   [Li, Teng; Cao, Weiqun] Natl Forestry & Grassland Adm, Engn Res Ctr Forestry Oriented Intelligent Inform, Beijing 100083, Peoples R China.
C3 Beijing Forestry University
RP Cao, WQ (corresponding author), Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing 100083, Peoples R China.; Cao, WQ (corresponding author), Natl Forestry & Grassland Adm, Engn Res Ctr Forestry Oriented Intelligent Inform, Beijing 100083, Peoples R China.
EM weiqun.cao@126.com
CR Chen K, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1747
   Costa C., 2012, LECT NOTES I COMPUTE, DOI [10.1007/978-3-642-30214-5_13, DOI 10.1007/978-3-642-30214-5_13]
   ElKoura G., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P110
   Hsu Shu-Wei, 2005, ACM SIGGRAPH 2005, DOI [10.1145/1187112.1187195, DOI 10.1145/1187112.1187195]
   Li Q., 2011, COMMUNICATION SYSTEM, DOI [10.1007/978-3-642-21762-3_24, DOI 10.1007/978-3-642-21762-3_24]
   Liang H, 2018, VIRTUAL REAL-LONDON, V22, P149, DOI 10.1007/s10055-018-0333-8
   Liang H, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1727
   Lu F, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1919
   Oshita M, 2016, COMPUT ANIMAT VIRT W, V27, P532, DOI 10.1002/cav.1673
   Rhodin H, 2014, COMPUT GRAPH FORUM, V33, P273, DOI 10.1111/cgf.12325
   Shi Y, 2014, COMPUT ANIMAT VIRT W, V25, P33, DOI 10.1002/cav.1530
   Yan ZF, 2016, I C VIRTUAL REALITY, P341, DOI 10.1109/ICVRV.2016.63
   Yao C, 2010, INT J COMPUT APPL T, V38, P86
   Zhang Mingmin, 2014, SIGGRAPH AS 2014 SHE, V17, DOI [10.1145/2668975.2669006, DOI 10.1145/2668975.2669006]
   Zhu YB., 2003, Proceeding of ACM SIGGRAPH 2003 Sketches Applications, P1
NR 15
TC 3
Z9 3
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20403
EP 20422
DI 10.1007/s11042-021-10726-1
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625713700004
DA 2024-07-18
ER

PT J
AU Shrestha, U
   Alsadoon, A
   Prasad, PWC
   Al Aloussi, S
   Alsadoon, OH
AF Shrestha, Ujjwol
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al Aloussi, Sarmad
   Alsadoon, Omar Hisham
TI Supervised machine learning for early predicting the sepsis patient:
   modified mean imputation and modified chi-square feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sepsis; Prediction; Machine learning; Supervised learning; Specificity;
   Sensitivity; Electronic health records
AB Sepsis is a typical and significant emergency in medical clinics comprehensively. A creative and possible instrument for identifying sepsis stays elusive. Supervised models can identify potential clinical factors and give a more accurate prediction than the existing benchmark rule-based tools. This research aims to increase the sensitivity to accurately predict the sepsis patient. The proposed system consists of the mean imputation and chi-square technique to replace the missing features and feature selection, respectively. All datasets are fed into the chi-square technique for feature selection by measuring how expectations compare to actual observed data. The essential missing data are then replaced using the mean-imputation method by calculating the mean value of the available data. Finally, the selected features are used as an input to the supervised machine learning model for the classification of sepsis patient. The results of accuracy and processing time are obtained by using different datasets. The results show that the proposed solution achieves better classification performance in different data scenarios and different review types. The proposed solution provides a classification accuracy of 97.67% against the current accuracy of 91.12% on average. It also provides a processing time of 29.1 milliseconds against the current processing time of 32.8 milliseconds on average. The proposed system is focused on the feature selection process that is involved in the machine learning model. Finally, this study solves the issue of model overfitting with supervised machine learning.
C1 [Shrestha, Ujjwol; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Al Aloussi, Sarmad] Massasoit Community Coll, Comp Technol & Informat Management Dept, Brockton, MA USA.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Alsadoon, Omar
   Hisham/0000-0001-7797-6392; withana, chandana/0000-0002-3007-687X
CR Alhaj TA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166017
   Barton C, 2019, COMPUT BIOL MED, V109, P79, DOI 10.1016/j.compbiomed.2019.04.027
   Chiew CJ, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000014197
   Delahanty RJ, 2019, ANN EMERG MED, V73, P334, DOI 10.1016/j.annemergmed.2018.11.036
   Horng S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174708
   Islam MM, 2019, COMPUT METH PROG BIO, V170, P1, DOI 10.1016/j.cmpb.2018.12.027
   Mao QQ, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-017833
   Masino AJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212665
   McCoy Andrea, 2017, BMJ Open Qual, V6, pe000158, DOI 10.1136/bmjoq-2017-000158
   Nemati S, 2018, CRIT CARE MED, V46, P547, DOI [10.1097/CCM.0000000000002936, 10.1097/ccm.0000000000002936]
   Sherwin R, 2018, ANN EMERG MED, V72, pS6, DOI 10.1016/j.annemergmed.2018.08.019
   Shimabukuro DW, 2017, BMJ OPEN RESPIR RES, V4, DOI 10.1136/bmjresp-2017-000234
   Topiwala R., 2019, CRIT CARE MED, V47, P806, DOI [10.1097/01.ccm.0000552404.00270.60, DOI 10.1097/01.CCM.0000552404.00270.60]
NR 13
TC 8
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20477
EP 20500
DI 10.1007/s11042-021-10725-2
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625713700005
DA 2024-07-18
ER

PT J
AU Ludovico, LA
   Presti, G
   Rizzi, A
AF Ludovico, Luca A.
   Presti, Giorgio
   Rizzi, Alessandro
TI Audio dynamics automatic equalization inspired by visual perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio processing; Dynamics processors; Automatic equalization
AB This paper explores the behavior of an algorithm called Audio Dynamics Automatic Equalization (ADAE). This algorithm has been inspired by research carried out in the context of image restoration: it is the adaptation of a contrast and color unsupervised equalizer for images, called Automatic Color Equalization (ACE), into the audio domain. Beside testing if the domain shift from image to audio processing can bring some interesting result, this work also investigates if ADAE behaves like already-known technologies for audio manipulation and restoration. To this end, after a description of the original and the derived algorithms, quantitative test are carried out using typical analyses from the Sound and Music Computing literature, such as frequency response, transfer function, and harmonic distortion. Finally, the paper discusses how the algorithm introduces dynamic range adjustments and non-linear distortions, thus behaving like a dynamics processor, a harmonic exciter, and a waveshaper.
C1 [Ludovico, Luca A.; Presti, Giorgio; Rizzi, Alessandro] Univ Milan, Dept Comp Sci, Via G Celoria 18, I-20133 Milan, Italy.
C3 University of Milan
RP Ludovico, LA (corresponding author), Univ Milan, Dept Comp Sci, Via G Celoria 18, I-20133 Milan, Italy.
EM ludovico@di.unimi.it
RI Ludovico, Luca Andrea/H-1913-2015
OI Ludovico, Luca Andrea/0000-0002-8251-2231; PRESTI,
   GIORGIO/0000-0001-7643-9915
FU Universit degli Studi di Milano within the CRUI-CARE Agreement
FX Open access funding provided by Universit degli Studi di Milano within
   the CRUI-CARE Agreement.
CR BEDROSIAN E, 1971, PR INST ELECTR ELECT, V59, P1688, DOI 10.1109/PROC.1971.8525
   Bertalmío M, 2007, IEEE T IMAGE PROCESS, V16, P1058, DOI 10.1109/TIP.2007.891777
   CREUTZFELDT O, 1990, J OPT SOC AM A, V7, P1644, DOI 10.1364/JOSAA.7.001644
   CREUTZFELDT O, 1987, EXP BRAIN RES, V67, P270
   Farina Angelo, 2000, 108 AES CONVENTION
   Giannoulis D, 2012, J AUDIO ENG SOC, V60, P399
   JAMESON D, 1964, VISION RES, V4, P135, DOI 10.1016/0042-6989(64)90037-9
   Jeffs R., 2005, RANENOTES, V155, P1
   Katz R. A., 2003, MASTERING AUDIO ART
   Kibangou AY, 2006, IEEE SIGNAL PROC LET, V13, P381, DOI 10.1109/LSP.2006.871705
   McCann J.J., 2011, The art and science of HDR imaging, V26
   Rizzi A, 2007, PROC SPIE, V6493, DOI 10.1117/12.708905
   Rizzi A, 2004, J ELECTRON IMAGING, V13, P75, DOI 10.1117/1.1635366
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Shekar P, 2013, AUD ENG SOC CONV, P135
   Tronchin L, 2017, AUDIO ENG SOC CONVEN, P142
   Tronchin L, 2012, J AUDIO ENG SOC, V60, P984
   Zaidi Q., 1999, COLOR VISION GENES P, P317
NR 18
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11903
EP 11915
DI 10.1007/s11042-020-10197-w
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200008
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Suwanwiwat, H
   Das, A
   Saqib, M
   Pal, U
AF Suwanwiwat, Hemmaphan
   Das, Abhijit
   Saqib, Muhammad
   Pal, Umapada
TI Benchmarked multi-script Thai scene text dataset and its multi-class
   detection solution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Script scene text detection; Multi-script; Text detection; Single Shot
   Multi-Box detector; Convolutional Neural Networks (CNN); Text image
ID RECOGNITION; COMPETITION
AB Detecting text portion from scene images can be found to be one of the prevalent research topics. Text detection is considered challenging and non-interoperable since there could be multiple scripts in a scene image. Each of these scripts can have different properties, therefore, it is crucial to research the scene text detection based on the geographical location owing to different scripts. As no work on large-scale multi-script Thai scene text detection is found in the literature, the work conducted in this study focuses on multi-script text that includes Thai, English (Roman), Chinese or Chinese-like script, and Arabic. These scripts can generally be seen around Thailand. Thai script contains more consonants, vowels, and has numerals when compared to the Roman/ English script. Furthermore, the placement of letters, intonation marks, as well as vowels, are different from English or Chinese-like script. Hence, it could be considered challenging to detect and recognise the Thai text. This study proposed a multi-script dataset which includes the aforementioned scripts and numerals, along with a benchmarking employing Single Shot Multi-Box Detector (SSD) and Faster Regions with Convolutional Neural Networks (F-RCNN). The proposed dataset contains scene images which were recorded in Thailand. The dataset consists of 600 images, together with their manual detection annotation. This study also proposed a detection technique hypothesising a multiscript scene text detection problem as a multi-class detection problem which found to work more effective than legacy approaches. The experimental results from employing the proposed technique with the dataset achieved encouraging precision and recall rates when compared with such methods. The proposed dataset is available upon email request to the corresponding authors.
C1 [Suwanwiwat, Hemmaphan] James Cook Univ, Cairns, Australia.
   [Das, Abhijit] Inria Sophia Antipolish, Nice, France.
   [Das, Abhijit; Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata, India.
   [Saqib, Muhammad] Univ Technol Sydney, Sydney, NSW, Australia.
C3 James Cook University; Indian Statistical Institute; Indian Statistical
   Institute Kolkata; University of Technology Sydney
RP Suwanwiwat, H (corresponding author), James Cook Univ, Cairns, Australia.; Das, A (corresponding author), Inria Sophia Antipolish, Nice, France.; Das, A (corresponding author), Indian Stat Inst, CVPR Unit, Kolkata, India.
EM art.suwanwiwat@jcu.edu.au; abhijitdas2048@gmail.com;
   muhammad.saqib@uts.edu.au; umapada@isical.ac.in
RI Pal, Umapada/AAC-4930-2022
OI Suwanwiwat, Hemmaphan/0000-0001-6371-4084; Saqib,
   Muhammad/0000-0003-4374-0888
CR [Anonymous], 2007, INT J COMPUT INF SYS
   [Anonymous], 2015, Tzutalin LabelImg: Git Code
   Bahlmann C, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P255
   Blumenstein M, 2018, P INT C PATT REC ART
   Blumenstein M, 2017, 2017 INT C DIG IM CO, P1
   Chowdhury MA, 2013, INT J COMPUT APPL, V74, P18
   Chumuang N, 2014, TENCON IEEE REGION
   Das A, 2018, IET BIOMETRICS, V7, P615, DOI 10.1049/iet-bmt.2017.0218
   Das A, 2016, IET BIOMETRICS, V5, P305, DOI 10.1049/iet-bmt.2016.0010
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fahn CS, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P37, DOI 10.1109/RAM.2013.6758556
   Fung CC, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P236, DOI 10.1109/WKDD.2010.110
   He ZW, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 & 2, P1688
   Jirattitichareon W, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1000
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Kobchaisawat T, 2014, ASIAPAC SIGN INFO PR
   Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93
   Li GF, 2019, IEEE ACCESS, V7, P11533, DOI 10.1109/ACCESS.2019.2891749
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long SB, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01369-0
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Nayef Nibal, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1582, DOI 10.1109/ICDAR.2019.00254
   Parkinson C., 2016, U.S. Patent, Patent No. [9507772B2, 9507772]
   Phokharatkul P, 2002, COMPUT INTELL-US, V18, P270, DOI 10.1111/0824-7935.00191
   Phokharatkul P, 1998, APCCAS '98 - IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P149, DOI 10.1109/APCCAS.1998.743689
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sanguansat P, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P492
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shi CZ, 2014, PATTERN RECOGN, V47, P2853, DOI 10.1016/j.patcog.2014.03.023
   Suwanwiwat H, 2018, INT CONF FRONT HAND, P500, DOI 10.1109/ICFHR-2018.2018.00093
   Theeramunkong T, 2002, LECT NOTES COMPUT SC, V2555, P340
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wong EK, 2003, PATTERN RECOGN, V36, P1397, DOI 10.1016/S0031-3203(02)00230-3
   Wongsirichot T, 2011, ADV INTEL SOFT COMPU, V95, P747
   Woraratpanya Kuntpong, 2013, 2013 International Conference on Information Technology and Electrical Engineering (ICITEE), P137, DOI 10.1109/ICITEED.2013.6676227
   Woraratpanya K, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRICAL ENGINEERING (ICITEE), P138
   Yang J, 2002, INT CONF ACOUST SPEE, P2101
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yuan TL, 2019, J COMPUT SCI TECH-CH, V34, P509, DOI 10.1007/s11390-019-1923-y
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 42
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11843
EP 11863
DI 10.1007/s11042-020-10143-w
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200005
DA 2024-07-18
ER

PT J
AU Almutiry, O
   Iqbal, K
   Hussain, S
   Mahmood, A
   Dhahri, H
AF Almutiry, Omar
   Iqbal, Khalid
   Hussain, Shariq
   Mahmood, Awais
   Dhahri, Habib
TI Underwater images contrast enhancement and its challenges: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image contrast enhancement; Spatial domain; Frequency domain;
   Image pre-processing
ID QUALITY ENHANCEMENT; COLOR; VISIBILITY; ALGORITHMS
AB Exploration of the deep sea and ocean in the marine industry has continued to gain interest in recent years. To get the detailed imaging of deep sea layers, marine vessels and robots are fitted with advanced imaging technologies. There are certain factors like water properties and impurities that affect the quality of the photographs captured by the underwater imaging devices. As sea water absorbs colors, so processing of sea imaging data becomes more challenging. Water light attenuation is a phenomenon that is caused by the absorbance and scattering factors. Certain studies showed that the existence of certain intrinsic shortcomings are attributed to the appearance of objects and ambient noise in underwater images. As a result, it is difficult in a real-time system to distinguish objects from their surroundings in these images. We measures the algorithms performance with respect to various aspects, effect of the hardware and software parts for underwater images and critical review of different underwater image enhancement algorithms. First, we describe some well-known techniques of spatial and frequency domains. Then, we list the existing quantitative measurements which are required to measure the quality of the enhanced image. Finally, the performance of various up-to-date existing methods is compared based on the outcomes of standard quantitative measurements, and factors such as requirements/suitability, and technical aspects, are included. Furthermore, a variety of image databases used for image contrast enhancement is discussed in detail. This study expands the scope for other researchers to understand the important characteristics of different underwater image contrast enhancement methods, and also provides future research directions.
C1 [Almutiry, Omar; Mahmood, Awais; Dhahri, Habib] King Saud Univ, Coll Appl Comp Sci, Almuzahmiyah Campus, Riyadh, Saudi Arabia.
   [Iqbal, Khalid] COMSATS Univ Islamabad, Dept Comp Sci, Attock Campus, Attock, Pakistan.
   [Hussain, Shariq] Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
C3 King Saud University; COMSATS University Islamabad (CUI); Quaid I Azam
   University
RP Hussain, S (corresponding author), Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
EM oalmutiry@ksu.edu.sa; khalidiqbal@cuiatk.edu.pk; shariq@fui.edu.pk;
   mawais@ksu.edu.sa; hdhahri@ksu.edu.sa
RI Iqbal, Khalid/AAF-4040-2021; Dhahri, Habib/L-7833-2018; Hussain,
   Shariq/K-5047-2013
OI Hussain, Shariq/0000-0003-2093-7274
FU Deanship of Scientific Research at King Saud University [RG-1441-379]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University for funding this work through the
   research group under project RG-1441-379.
CR Agaian SS, 2001, IEEE T IMAGE PROCESS, V10, P367, DOI 10.1109/83.908502
   Akila C, 2018, MULTIMED TOOLS APPL, V77, P4309, DOI 10.1007/s11042-017-5187-7
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Avidan S, 2017, P BRIT MACH VIS C
   Banerjee J, 2016, SADHANA-ACAD P ENG S, V41, P225, DOI 10.1007/s12046-015-0446-7
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Eustice R, 2002, PROCEEDINGS OF THE 2002 INTERNATIONAL SYMPOSIUM ON UNDERWATER TECHNOLOGY, P141, DOI 10.1109/UT.2002.1002415
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Ge M, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2018), P123, DOI 10.1145/3301506.3301539
   Ghani ASA, 2018, OCEAN ENG, V162, P224, DOI 10.1016/j.oceaneng.2018.05.027
   Ghani ASA, 2017, COMPUT ELECTRON AGR, V141, P181, DOI 10.1016/j.compag.2017.07.021
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Ghani ASA, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-757
   Ghani ASA, 2014, INT J NAV ARCH OCEAN, V6, P840, DOI 10.2478/IJNAOE-2013-0217
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   Gupta ES, 2014, INT J ADV RES COMPUT, V3
   Guraksin GE, 2019, INTEL SYST REF LIBR, V150, P255, DOI 10.1007/978-3-319-96002-9_11
   Hariadi M, 2013, P 7 ICTS
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Hitam Muhammad Suzuri, 2013, 2013 INT C COMPUTER
   Hou GJ, 2018, IET IMAGE PROCESS, V12, P292, DOI 10.1049/iet-ipr.2017.0359
   Hou W, 2007, INT GEOSCI REMOTE SE, P1889, DOI 10.1109/IGARSS.2007.4423193
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P23371, DOI 10.1007/s11042-018-5650-0
   Kaur Ramandeep., 2016, Communications on Applied Electronics, V4, P22, DOI DOI 10.5120/CAE2016652166
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   LIDONG H, 2015, IET IMAGE PROCESS, V9, P908, DOI DOI 10.1049/IET-IPR.2015.0150
   Lu HM, 2017, MOBILE NETW APPL, V22, P1204, DOI 10.1007/s11036-017-0863-4
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Ma JX, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418540186
   Naim MJNM, 2012, APPL SOFT COMPUT, V12, P2948, DOI 10.1016/j.asoc.2012.04.028
   Nnolim UA, 2018, J IMAGING, V4, DOI 10.3390/jimaging4090108
   Nnolim UA, 2017, IET IMAGE PROCESS, V11, P1059, DOI 10.1049/iet-ipr.2017.0259
   Porikli F., 2018, ARXIV PREPRINT ARXIV
   Priyadharsini R, 2018, MULTIDIM SYST SIGN P, V29, P1845, DOI 10.1007/s11045-017-0533-5
   Rajkumar S., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2016/v9i47/105556, DOI 10.17485/IJST/2016/V9I47/105556]
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Trucco E, 2006, IEEE J OCEANIC ENG, V31, P511, DOI 10.1109/JOE.2004.836395
   Unar S, 2016, ARXIV PREPRINT ARXIV
   Vasamsetti S, 2017, OCEAN ENG, V141, P88, DOI 10.1016/j.oceaneng.2017.06.012
   Vijayalakshmi D, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00305-3
   Wang YF, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1013, DOI 10.1109/ICIT.2017.7915500
   Wong SL, 2018, ADV ELECTR COMPUT EN, V18, P109, DOI 10.4316/AECE.2018.02014
   Xi Qiao, 2017, Information Processing in Agriculture, V4, P206, DOI 10.1016/j.inpa.2017.06.001
   Xie K, 2018, ROBOTICS, V7, DOI 10.3390/robotics7010014
   Zhang CJ, 2008, FUZZY OPTIM DECIS MA, V7, P331, DOI 10.1007/s10700-008-9042-1
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zheng LT, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P585, DOI 10.1109/ICInfA.2016.7831889
NR 57
TC 6
Z9 6
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15125
EP 15150
DI 10.1007/s11042-021-10626-4
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000622247800002
DA 2024-07-18
ER

PT J
AU Aggarwal, U
   Popescu, A
   Belouadah, E
   Hudelot, C
AF Aggarwal, Umang
   Popescu, Adrian
   Belouadah, Eden
   Hudelot, Celine
TI A comparative study of calibration methods for imbalanced class
   incremental learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Incremental learning; Calibration; Class imbalance; Image classification
AB Deep learning approaches are successful in a wide range of AI problems and in particular for visual recognition tasks. However, there are still open problems among which is the capacity to handle streams of visual information and the management of class imbalance in datasets. Existing research approaches these two problems separately while they co-occur in real world applications. Here, we study the problem of learning incrementally from imbalanced datasets. We focus on algorithms which have a constant deep model complexity and use a bounded memory to store exemplars of old classes across incremental states. Since memory is bounded, old classes are learned with fewer images than new classes and an imbalance due to incremental learning is added to the initial dataset imbalance. A score prediction bias in favor of new classes appears and we evaluate a comprehensive set of score calibration methods to reduce it. Evaluation is carried with three datasets, using two dataset imbalance configurations and three bounded memory sizes. Results show that most calibration methods have beneficial effect and that they are most useful for lower bounded memory sizes, which are most interesting in practice. As a secondary contribution, we remove the usual distillation component from the loss function of incremental learning algorithms. We show that simpler vanilla fine tuning is a stronger backbone for imbalanced incremental learning algorithms.
C1 [Aggarwal, Umang; Popescu, Adrian; Belouadah, Eden] Univ Paris Saclay, CEA List, F-91120 Palaiseau, France.
   [Aggarwal, Umang; Hudelot, Celine] Univ Paris Saclay, Cent Supelec, Math & Informat Complexite & Syst, F-91191 Gif Sur Yvette, France.
C3 CEA; Universite Paris Cite; Universite Paris Saclay; Universite Paris
   Cite; Universite Paris Saclay
RP Aggarwal, U (corresponding author), Univ Paris Saclay, CEA List, F-91120 Palaiseau, France.; Aggarwal, U (corresponding author), Univ Paris Saclay, Cent Supelec, Math & Informat Complexite & Syst, F-91191 Gif Sur Yvette, France.
EM umang.aggarwal@cea.fr; adrian.popescu@cea.fr; eden.belouadah@cea.fr;
   celine.hudelot@centralesupelec.fr
RI HUDELOT, CELINE/IRZ-2920-2023
OI HUDELOT, CELINE/0000-0003-3849-4133
FU CEA List, France; Ilede-France Regional Council; European Unions Horizon
   2020 research and innovation programme [951911 - AI4Media]
FX The research is funded by CEA List, France. This publication was made
   possible by the use of FactoryIA supercomputer, financially supported by
   the Ilede-France Regional Council. This paper was supported by European
   Unions Horizon 2020 research and innovation programme under grant number
   951911 - AI4Media.
CR Aljundi R, 2017, PROC CVPR IEEE, P7120, DOI 10.1109/CVPR.2017.753
   Bengio Y., 2013, An empirical investigation of catastrophic forgeting in gradient-based neural networks
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Castro FM, 2018, LECT NOTES COMPUT SC, V11216, P241, DOI 10.1007/978-3-030-01258-8_15
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Dean J., 2015, NIPS DEEP LEARNING R
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Guo CA, 2017, PR MACH LEARN RES, V70
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou SH, 2019, PROC CVPR IEEE, P831, DOI 10.1109/CVPR.2019.00092
   Japkowicz, 2016, MACH LEARN KNOW EXTR, P248
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Javed K., 2018, AS C COMP VIS
   Jenks GF, 1977, OPTIMAL DATA CLASSIF, V2
   Krasin I., 2017, Openimages: A public dataset for large-scale multi-label and multi-class image classification
   Kubat M., 1997, ICML, P179
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Maciejewski T., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM 2011), P104, DOI 10.1109/CIDM.2011.5949434
   Martinetz, 2014, ESANN
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]
   Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83
   Niculescu-Mizil A., 2005, P 22 INT C MACHINE L, P625, DOI [10.1145/1102351.1102430, DOI 10.1145/1102351.1102430]
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Paszke A., 2017, NIPS W
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Rebuffi SA, 2017, PROC CVPR IEEE, P5533, DOI 10.1109/CVPR.2017.587
   Richard MD, 1991, NEURAL COMPUT, V3, P461, DOI 10.1162/neco.1991.3.4.461
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A.A., 2016, ARXIV
   Syed N.A., 1999, P WORKSH SUPP VECT M, P317, DOI 10.1145/312129.312267
   Venkatesan Ragav, 2017, ARXIV170500744
   Wu Y, 2019, PROC CVPR IEEE, P374, DOI 10.1109/CVPR.2019.00046
   Zadrozny B., 2002, P 8 ACM SIGKDD INT C, P694, DOI [10.1145/775047.775151, DOI 10.1145/775047.775151]
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 41
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19237
EP 19256
DI 10.1007/s11042-020-10485-5
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000618600400001
DA 2024-07-18
ER

PT J
AU Aayesha
   Qureshi, MB
   Afzaal, M
   Qureshi, MS
   Fayaz, M
AF Aayesha
   Qureshi, Muhammad Bilal
   Afzaal, Muhammad
   Qureshi, Muhammad Shuaib
   Fayaz, Muhammad
TI Machine learning-based EEG signals classification model for epileptic
   seizure detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Epilepsy; Seizure detection; Signal processing; EEG;
   Classification
ID NEAREST-NEIGHBOR ALGORITHMS; FEATURES
AB The detection of epileptic seizures by classifying electroencephalography (EEG) signals into ictal and interictal classes is a demanding challenge, because it identifies the seizure and seizure-free states of an epileptic patient. In previous works, several machine learning-based strategies were introduced to investigate and interpret EEG signals for the purpose of their accurate classification. However, non-linear and non-stationary characteristics of EEG signals make it complicated to get complete information about these dynamic biomedical signals. In order to address this issue, this paper focuses on extracting the most discriminating and distinguishing features of seizure EEG recordings to develop an approach that employs both fuzzy-based and traditional machine learning algorithms for epileptic seizure detection. The proposed framework classifies unknown EEG signal segments into ictal and interictal classes. The model is validated using empirical evaluation on two benchmark datasets, namely the Bonn and Children's Hospital of Boston-Massachusetts Institute of Technology (CHB-MIT) datasets. The obtained results show that in both cases, K-Nearest Neighbor (KNN) and Fuzzy Rough Nearest Neighbor (FRNN) give the highest classification accuracy scores, with improved sensitivity and specificity percentages.
C1 [Aayesha; Qureshi, Muhammad Bilal] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Dept Comp Sci, Islamabad 44000, Pakistan.
   [Afzaal, Muhammad] Stockholm Univ, Dept Comp & Syst Sci, Stockholm, Sweden.
   [Qureshi, Muhammad Shuaib; Fayaz, Muhammad] Univ Cent Asia, Sch Arts & Sci, Dept Comp Sci, Bishkek, Kyrgyzstan.
C3 Shaheed Zulfikar Ali Bhutto Institute of Science & Technology; Stockholm
   University; University of Central Asia
RP Qureshi, MB (corresponding author), Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Dept Comp Sci, Islamabad 44000, Pakistan.
EM a2z.aayesha@gmail.com; muhdbilal.qureshi@gmail.com;
   muhammad.afzaal@dsv.su.se; qureshi.shuaib@gmail.com;
   muhammad.fayaz@ucentralasia.org
RI Fayaz, Muhammad/CAF-2058-2022; Qureshi, Muhammad Shuaib/C-4877-2012;
   Qureshi, Muhammad Shuaib/K-8901-2012
OI Fayaz, Muhammad/0000-0001-6383-2988; 
CR Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Anugraha A., 2017, 2017 INT C COMPUTATI, P1, DOI [DOI 10.1109/ICCIDS.2017.8272636, 10.1109/ICCIDS.2017.8272636, 10.1109/iccids.2017.8272636]
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Bhattacharyya A, 2017, IEEE T BIO-MED ENG, V64, P2003, DOI 10.1109/TBME.2017.2650259
   Bongiorni L., 2020, ARRAY, V8
   Boughorbel S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177678
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Derrac J, 2014, INFORM SCIENCES, V260, P98, DOI 10.1016/j.ins.2013.10.038
   Feng YF, 2019, AAAI CONF ARTIF INTE, P3558
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gu Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010029
   Gupta V, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101569
   Han J, 2012, MOR KAUF D, P1
   Hühn J, 2009, DATA MIN KNOWL DISC, V19, P293, DOI 10.1007/s10618-009-0131-8
   Jana GC, 2020, PROCEDIA COMPUT SCI, V167, P403, DOI 10.1016/j.procs.2020.03.248
   Jensen R, 2011, THEOR COMPUT SCI, V412, P5871, DOI 10.1016/j.tcs.2011.05.040
   Kaburlasos VG, 2007, INT J APPROX REASON, V45, P152, DOI 10.1016/j.ijar.2006.08.001
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Li MY, 2017, BIOMED SIGNAL PROCES, V34, P114, DOI 10.1016/j.bspc.2017.01.010
   Li MY, 2017, BIOMED SIGNAL PROCES, V31, P357, DOI 10.1016/j.bspc.2016.09.008
   Mahjoub C, 2020, BIOMED ENG-BIOMED TE, V65, P33, DOI 10.1515/bmt-2019-0001
   Mursalin M, 2017, NEUROCOMPUTING, V241, P204, DOI 10.1016/j.neucom.2017.02.053
   Naz I, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419500556
   Olokodana IL, 2020, IEEE COMP SOC ANN, P264, DOI 10.1109/ISVLSI49217.2020.00055
   Orhan U, 2011, EXPERT SYST APPL, V38, P13475, DOI 10.1016/j.eswa.2011.04.149
   Orosco L, 2016, COMPUT BIOL MED, V71, P128, DOI 10.1016/j.compbiomed.2016.02.016
   Park C., 2018, P INT C EL INF COMM, P1, DOI DOI 10.23919/ELINFOCOM.2018.8330671
   Patidar S, 2017, BIOMED SIGNAL PROCES, V34, P74, DOI 10.1016/j.bspc.2017.01.001
   Riaz F, 2016, IEEE T NEUR SYS REH, V24, P28, DOI 10.1109/TNSRE.2015.2441835
   Sarkar M, 2007, FUZZY SET SYST, V158, P2134, DOI 10.1016/j.fss.2007.04.023
   Sharif M, 2020, COGN SYST RES, V59, P273, DOI 10.1016/j.cogsys.2019.10.001
   Shukla K., 2013, Efficient Algorithms for Discrete Wavelet Transform: With Applications to Denoising and Fuzzy Inference Systems
   Singh M, 2019, MULTIDIM SYST SIGN P, P1
   Subasi A, 2019, NEURAL COMPUT APPL, V31, P317, DOI 10.1007/s00521-017-3003-y
   Subramanian R, 2018, IEEE T AFFECT COMPUT, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Tiwari AK, 2017, IEEE J BIOMED HEALTH, V21, P888, DOI 10.1109/JBHI.2016.2589971
   Ullah I, 2018, EXPERT SYST APPL, V107, P61, DOI 10.1016/j.eswa.2018.04.021
   Vapnik V., 2013, The nature of statistical learning theory
   Vidyaratne LS, 2017, IEEE T NEUR SYS REH, V25, P2146, DOI 10.1109/TNSRE.2017.2697920
   Wang XS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020219
   Wang YF, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/6849360
   Yadati N., 2019, Advances in Neural Information Processing Systems, P1509
   Yuan Q, 2017, SEIZURE-EUR J EPILEP, V50, P99, DOI 10.1016/j.seizure.2017.05.018
   Zhang T, 2017, IEEE T NEUR SYS REH, V25, P1100, DOI 10.1109/TNSRE.2016.2611601
   Zhang YD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051372
   Zhao SC, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3233184
NR 46
TC 57
Z9 59
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17849
EP 17877
DI 10.1007/s11042-021-10597-6
EA FEB 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617415000006
DA 2024-07-18
ER

PT J
AU Maji, G
   Mandal, S
   Sen, S
AF Maji, Giridhar
   Mandal, Sharmistha
   Sen, Soumya
TI Cover independent image steganography in spatial domain using higher
   order pixel bits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exclusive-OR; LSB substitution; Image steganography; Spatial domain;
   Information hiding; RS analysis; Pixel difference histogram
ID SECRET; ROBUST
AB In spatial domain image steganography, Least Significant Bits (LSB) of cover image pixels are used to embed a secret message due to minimal distortion and higher payload capacity. In this paper, we have introduced an exclusive-OR (XOR) based encoding of encrypted secret message bits using varying higher-order pixel intensity bits. Encoding and LSB embedding is done block-wise by dividing the cover image into a number of blocks. The secret message is first encrypted using symmetric key cryptography and then encoded those encrypted bits by XORing them with randomly selected higher-order pixel bis of the cover image to obscure the secret bits further. Next, an inversion technique is applied to the encoded bits block-wise to keep the LSB bit changes to a minimum. The stego-key consists of the symmetric encryption key and the encode-key containing parameter settings such as the number_of_blocks, starting_block, start_pixel_offset, block_selection_rule, etc. This stego-key is shared prior to the actual communication using public-key cryptography to ensure the key's authenticity and integrity. The extraction process does not require the cover image; the stego-image and the stego-key are sufficient. Experimental results show the visual imperceptibility along with improved image quality metrics such as Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR), Normalized Cross-Correlation (NCC), and Structural Similarity (SSIM) index in comparison to other well-known techniques. The average PSNR value remains above 51dB, even with 90% of the capacity utilized. The proposed scheme successfully eludes many standard steganalysis attacks such as histogram-based analysis (PDH), chi-square based embed probability test, Regular and Singular groups (RS) analysis, sample pair test, etc. on the tested stego-images.
C1 [Maji, Giridhar] Asansol Polytech, Dept Elect Engn, Asansol, W Bengal, India.
   [Mandal, Sharmistha] Kanyapur Polytech, Dept Comp Sci & Technol, Asansol, W Bengal, India.
   [Sen, Soumya] Univ Calcutta, AK Choudhury Sch Informat Technol, Kolkata, India.
C3 University of Calcutta
RP Maji, G (corresponding author), Asansol Polytech, Dept Elect Engn, Asansol, W Bengal, India.
EM Giridhar.Maji@gmail.com; sharmistha.cse@gmail.com;
   iamsoumyasen@gmail.com
RI Maji, Giridhar/R-4457-2019
OI Maji, Giridhar/0000-0003-4751-3471; MANDAL,
   SHARMISTHA/0000-0002-8653-565X
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Al-Nofaie SMA, 2020, MULTIMED TOOLS APPL, V79, P19, DOI 10.1007/s11042-019-08025-x
   Bharti SS, 2019, MULTIMED TOOLS APPL, V78, P23179, DOI 10.1007/s11042-019-7630-4
   Bhuiyan Touhid, 2019, 2019 International Conference on Information and Communications Technology (ICOIACT), P44
   Biswas R, 2020, MULTIMED TOOLS APPL, V79, P7101, DOI 10.1007/s11042-019-08497-x
   Boehm B, 2014, ARXIV14091556
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P360, DOI 10.1109/MUE.2009.68
   Dalal M, 2019, MULTIMED TOOLS APPL, V78, P5769, DOI 10.1007/s11042-018-6093-3
   Datta B, 2016, PROCEDIA COMPUT SCI, V85, P425, DOI 10.1016/j.procs.2016.05.188
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Farwa S, 2020, MULTIMED TOOLS APPL, V79, P28225, DOI 10.1007/s11042-020-09324-4
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Mukherjee N, 2020, MULTIMED TOOLS APPL, V79, P13449, DOI 10.1007/s11042-019-08178-9
   Kahn D., 1996, Information Hiding. First International Workshop Proceedings, P1
   Kang S, 2020, MULTIMED TOOLS APPL, V79, P21155, DOI 10.1007/s11042-020-08925-3
   Kharrazi M, 2006, LECT NOTES COMPUT SC, V4300, P123
   Kuznetsov A, 2020, 2020 IEEE 11TH INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS, SERVICES AND TECHNOLOGIES (DESSERT): IOT, BIG DATA AND AI FOR A SAFE & SECURE WORLD AND INDUSTRY 4.0, P161, DOI [10.1109/dessert50317.2020.9125032, 10.1109/DESSERT50317.2020.9125032]
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Mahato S, 2020, J KING SAUD UNIV-COM, V32, P197, DOI 10.1016/j.jksuci.2017.08.003
   Maji G., 2019, INT J INNOV TECHNOL, V8, P2828
   Maji G, 2020, MULTIMED TOOLS APPL, V79, P26549, DOI 10.1007/s11042-020-09329-z
   Maji G, 2019, IEEE INTL CONF IND I, P1358, DOI [10.1109/indin41052.2019.8972175, 10.1109/INDIN41052.2019.8972175]
   Maji G, 2020, INT J INF SECUR PRIV, V14, P83, DOI 10.4018/IJISP.2020040105
   Maji G, 2018, PROCEEDINGS OF 2018 2ND INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SIGNAL PROCESSING, TELECOMMUNICATIONS & COMPUTING (SIGTELCOM 2018), P61, DOI 10.1109/SIGTELCOM.2018.8325806
   Mandal PC, 2021, MULTIMED TOOLS APPL, V80, P3623, DOI 10.1007/s11042-020-09341-3
   Maniriho P, 2019, J KING SAUD UNIV-COM, V31, P335, DOI 10.1016/j.jksuci.2018.01.011
   Muhammad N, 2018, PATTERN ANAL APPL, V21, P997, DOI 10.1007/s10044-017-0613-z
   Muhammad N, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176979
   Mukherjee S, 2020, MULTIMED TOOLS APPL, V79, P29951, DOI 10.1007/s11042-020-09522-0
   Sahu AK, 2022, J KING SAUD UNIV-COM, V34, P1395, DOI 10.1016/j.jksuci.2019.07.004
   Setiadi DIM, 2019, INT J ELECTRON TELEC, V65, P287, DOI 10.24425/ijet.2019.126312
   Setyono A, 2019, SECURING HIDING SECR, V1196
   Shen SY, 2018, MULTIMED TOOLS APPL, V77, P12563, DOI 10.1007/s11042-017-4905-5
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Singh S, 2018, Comput Vis, P170, DOI [10.4018/978-1-5225-5204-8.ch007, DOI 10.4018/978-1-5225-5204-8.CH007]
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P18815, DOI 10.1007/s11042-020-08745-5
   Stanley C.A., 2005, Pairs of values and the chi-squared attack
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Trithemius Johannes., 1982, STEGANOGRAPHIA JOHAN
   Wang Jiaxin, 2019, JIHPP, V2019, DOI 10.32604/jihpp.2019.07189
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Younus ZS, 2022, J KING SAUD UNIV-COM, V34, P2951, DOI 10.1016/j.jksuci.2019.04.008
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 49
TC 3
Z9 3
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15977
EP 16006
DI 10.1007/s11042-020-10298-6
EA FEB 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615771800001
DA 2024-07-18
ER

PT J
AU Wang, F
   Peng, GH
AF Wang, Fan
   Peng, Guohua
TI Salient object detection via cross diffusion-based compactness on
   multiple graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Cross diffusion-based compactness; Multi-view
   image informations; Multiple k-regular graphs; Multi-view SCA model
ID REGION DETECTION; MODEL
AB The diffusion-based graph has been widely used in saliency detection. Most of the existing methods treat the image boundary patches as background seeds, which may result in the imprecise saliency map if the salient region touches the image boundaries. In this paper, we propose a salient object detection approach via cross diffusion-based compactness on multiple graphs. Firstly, we extract multi-view image features including low-level image features, mid-level image cues (low-level saliency priors), and background-based saliency map. Then, we compute the respective similarity matrix to construct the corresponding graph, and a cross-diffusion algorithm is presented that diffuses each similarity matrix on other's graphs rather than at itself graph, helping to the compactness-based saliency maps. Additionally, for well propagating the saliency values, we model a propagation mechanism based on cellular automata, by linearly incorporating low-level image features and mid-level image cues together to generate a superior impact factor matrix. Extensive experiment results demonstrate that the proposed method achieves better saliency detection performance against the unsupervised state-of-the-art methods on three public datasets.
C1 [Wang, Fan; Peng, Guohua] Northwestern Polytecn Univ, Sch Nat & Appl Sci, Xian, Shaanxi, Peoples R China.
RP Wang, F (corresponding author), Northwestern Polytecn Univ, Sch Nat & Appl Sci, Xian, Shaanxi, Peoples R China.
EM wf03126666@mail.nwpu.edu.cn; penggh@mail.edu.cn
FU Natural Science Basic Research Plan of Shaanxi Province of China
   [2015JM6296]
FX This work was supported by the Natural Science Basic Research Plan of
   Shaanxi Province of China (Grant number 2015JM6296).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, IEEE T PATTERN ANAL, V33, P200, DOI 10.1109/TPAMI.2010.138
   Cheng ZY, 2016, MULTIMEDIA SYST, V22, P509, DOI 10.1007/s00530-014-0432-7
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Deng C, 2020, IEEE T MULTIMEDIA, V22, P885, DOI 10.1109/TMM.2019.2934833
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Lan RS, 2017, IEEE T CIRC SYST VID, V27, P261, DOI 10.1109/TCSVT.2015.2492839
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li R, 2018, MULTIMED TOOLS APPL, V77, P12139, DOI 10.1007/s11042-017-4862-z
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P1023, DOI 10.1109/TCSVT.2018.2823769
   Liu ZY, 2020, NEUROCOMPUTING, V387, P210, DOI 10.1016/j.neucom.2020.01.045
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Pang Y, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013011
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Piao YR, 2020, AAAI CONF ARTIF INTE, V34, P11865
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Qiu WL, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107266
   Qiu Y, 2020, NEUROCOMPUTING, V388, P124, DOI 10.1016/j.neucom.2019.12.123
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang W., 2019, ARXIV190409146
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xia CX, 2020, NEUROCOMPUTING, V383, P194, DOI 10.1016/j.neucom.2019.09.096
   Xiao Y, 2019, NEUROCOMPUTING, V351, P156, DOI 10.1016/j.neucom.2019.03.066
   Xiao Y, 2018, NEUROCOMPUTING, V315, P234, DOI 10.1016/j.neucom.2018.06.072
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Zhang DW, 2017, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2017.436
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P4421, DOI 10.1109/TIP.2020.2970529
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang YY, 2020, IEEE T IMAGE PROCESS, V29, P1536, DOI 10.1109/TIP.2019.2942796
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zheng Q, 2020, NEUROCOMPUTING, V376, P232, DOI 10.1016/j.neucom.2019.08.091
   Zhou L, 2017, IEEE T IMAGE PROCESS, V26, P5882, DOI 10.1109/TIP.2017.2738839
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 62
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15959
EP 15976
DI 10.1007/s11042-021-10568-x
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564700001
DA 2024-07-18
ER

PT J
AU Lei, L
   Xi, F
   Chen, SY
   Liu, Z
AF Lei, Lei
   Xi, Feng
   Chen, Shengyao
   Liu, Zhong
TI A sparse representation denoising algorithm for finger-vein image based
   on dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Finger-vein recognition; Dictionary learning;
   Image denoising
ID FACE RECOGNITION; GABOR; CLASSIFICATION
AB As an important method of biometric authentication, finger-vein recognition utilizes the unique finger-vein patterns to identify individuals at a high level of accuracy and safety. However, noise components, inherent in finger-vein images, pose a formidable challenge for extracting reliable finger-vein features for recognition. To tackle this challenge, intensive efforts have been directed at sparse representation (SR) methods, which can find the best representative of a test sample by a sparse linear combination of training samples (atoms) from a dictionary. Previous SR approaches treat training atoms equally for image representations, even if these atoms may vary in their effectiveness as feature descriptors, thus jeopardizing the denoising and recognition performances. To overcome this limitation, the present study proposed an adaptive SR with distance-based dictionary learning (DDL), enabling the ability to target more informative training samples. Specifically, based on the Euclidean distance, atoms in the dictionary are classified into two groups: the high-information and the low-information. Their weights for feature representations are assigned based on the distance entropy. Experimental results indicate that the developed SR-DDL denoising method, can suppress image noises and subsequently enhance the image recognition performance.
C1 [Lei, Lei; Xi, Feng; Chen, Shengyao; Liu, Zhong] Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Lei, L (corresponding author), Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Nanjing 210094, Peoples R China.
EM leilei4428@126.com; xifeng@njust.edu.cn; chenshengyao@njust.edu.cn;
   eezliu@njust.edu.cn
RI Xi, Feng/AAB-4544-2019; Chen, Shengyao/AAT-4361-2020
OI Xi, Feng/0000-0002-4170-3023; Lei, Lei/0000-0001-7703-8603
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Cevher V, 2011, IEEE J-STSP, V5, P979, DOI 10.1109/JSTSP.2011.2161862
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chen PY, 2014, SIGNAL PROCESS, V94, P476, DOI 10.1016/j.sigpro.2013.06.011
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   De P, 2018, IEEE SENS J, V18, P2434, DOI 10.1109/JSEN.2017.2787616
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Foroughi H, 2018, IEEE T IMAGE PROCESS, V27, P806, DOI 10.1109/TIP.2017.2766446
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Ilhan HO, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103845
   Ito K, 2004, IEICE T FUND ELECTR, VE87A, P682
   Keinert F, 2019, IEEE T IMAGE PROCESS, V28, P2785, DOI 10.1109/TIP.2018.2890312
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   Lei Lei, 2019, Computer Engineering, V45, P187, DOI 10.19678/j.issn.1000-3428.0050817
   Lei Z., 2020, PATTERN RECOGN, V43
   Li N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121216
   Li Q, 2012, EXPERT SYST APPL, V39, P7600, DOI 10.1016/j.eswa.2011.12.046
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Saito, 2018, IMPROVING SPARSE REP
   Shin KY, 2014, SENSORS-BASEL, V14, P3095, DOI 10.3390/s140203095
   THIAGARAJAN JJ, 2011, DIG SIGN PROC WORKSH, P271
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   Venna SR, 2018, SPRINGERBR APPL SCI, P55, DOI 10.1007/978-981-10-6698-6_6
   Vesnicer, 2013, IEEE INT C AC SPEECH
   Wright JL, 2009, IEEE INT C EMERG
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang AF, 2013, J CENT SOUTH UNIV, V20, P2720, DOI 10.1007/s11771-013-1789-z
   Yang J., 2009, IEEE INT C INT COMP
   Yang M, 2013, PATTERN RECOGN, V46, P1865, DOI 10.1016/j.patcog.2012.06.022
   Zhang FC, 2010, INT CONF BIOMED, P531, DOI 10.1109/BMEI.2010.5639983
   Zhu CP, 2019, INT CONF COMP SCI ED, P374, DOI [10.1109/ICCSE.2019.8845517, 10.1109/iccse.2019.8845517]
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 38
TC 6
Z9 7
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15135
EP 15159
DI 10.1007/s11042-021-10516-9
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613628000007
DA 2024-07-18
ER

PT J
AU An, XW
   Liang, QQ
   Sun, NL
AF An, Xiaowei
   Liang, Quanquan
   Sun, Nongliang
TI Multi-kernel support correlation filters with temporal filtering
   constraint for object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-kernel support correlation filters; Hedge parameter strategy;
   Temporal filtering constraint; Alternating fixed-point algorithm; Object
   tracking
ID TIME VISUAL TRACKING
AB This paper proposes the adaptive multi-kernel support correlation filters with hedge parameter strategy and temporal filtering constraint for real-time tracking. In order to fuse the excellent properties of various views that characterize the object robust appearance accurately, support correlation filtering responses from multiple kernels can be adaptively integrated into one strong and accurate filtering response map by hedge parameter strategy in a parallel way. It absorbs the strongly discriminative ability from different feature-based support correlation filters, which tolerate sampling outliers of circulant structures with the help of SVM learning way. Also, it exploits the intense information of multi-view appearance representations which guarantee the fusion of reliable correlation filtering maps with reasonable parameters. Meanwhile, with the temporal filtering constraint to maintain historical appearance characteristics, alternating fixed-point algorithm improves complementary memory-updated model that keeps the stability of tracking process continuously and alleviates the target drifting situation for each support correlation filter. Experimental results demonstrate that the proposed approach achieves favorable performance on multiple dynamic scenes.
C1 [An, Xiaowei] Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Shandong, Peoples R China.
   [Liang, Quanquan; Sun, Nongliang] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Liang, QQ; Sun, NL (corresponding author), Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Shandong, Peoples R China.
EM anxiaowei2017@aliyun.com; quanquan406@gmail.com; nl_jackson@aliyun.com
OI liang, quanquan/0000-0002-6374-2402
FU Leading Talents of Shandong University of Science and Technology; 863
   project Physical Model Based Dynamic Evolution Technology of Complex
   Scene [2015AA016404]; Shandong Province Higher Educational Science and
   Technology Program [J17KA075]; National Nature Science Foundation of
   China [61801270]
FX This work was supported by 'Leading Talents of Shandong University of
   Science and Technology', '863 project Physical Model Based Dynamic
   Evolution Technology of Complex Scene' (2015AA016404), 'Shandong
   Province Higher Educational Science and Technology Program' (J17KA075)
   and 'National Nature Science Foundation of China' (61801270).
CR [Anonymous], 2014, ARXIV14046031
   [Anonymous], 2015, PIOTRS COMPUTER VISI
   [Anonymous], 2009, Advances in neural information processing systems
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Bai YC, 2011, IEEE IMAGE PROC, P517, DOI 10.1109/ICIP.2011.6116395
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bibi A, 2016, LECT NOTES COMPUT SC, V9910, P419, DOI 10.1007/978-3-319-46466-4_25
   Bibi A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P613, DOI 10.1109/ICCVW.2015.83
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P1327, DOI 10.1109/TIP.2016.2520358
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Ding GG, 2018, IEEE T INTELL TRANSP, V19, P140, DOI 10.1109/TITS.2017.2774778
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gan Quan, 2015, ARXIV151106425
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2013, IEEE I CONF COMP VIS, P2760, DOI 10.1109/ICCV.2013.343
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu HW, 2019, IEEE T MULTIMEDIA, V21, P510, DOI 10.1109/TMM.2018.2859831
   Ij ZJ, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102602
   Jung I, 2018, LECT NOTES COMPUT SC, V11208, P89, DOI 10.1007/978-3-030-01225-0_6
   Kahou SE, 2017, IEEE COMPUT SOC CONF, P1613, DOI 10.1109/CVPRW.2017.206
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lin YT, 2019, IEEE ACCESS, V7, P99441, DOI 10.1109/ACCESS.2019.2930550
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mei X, 2015, IEEE T NEUR NET LEAR, V26, P2874, DOI 10.1109/TNNLS.2015.2399233
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Nam H., 2016, CORR
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Qi YK, 2019, IEEE T PATTERN ANAL, V41, P1116, DOI 10.1109/TPAMI.2018.2828817
   Radford A., 2015, ARXIV
   Rao C, 2012, INT C PATT RECOG, P1447
   Roffo G., 2016, BMVC
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Su ZY, 2020, FRONT COMPUT SCI-CHI, V14, P417, DOI 10.1007/s11704-018-8116-1
   Sui Y, 2018, IEEE T CYBERNETICS, V48, P1290, DOI 10.1109/TCYB.2017.2690860
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang C, 2018, AAAI CONF ARTIF INTE, P4179
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wang D, 2012, IEEE SIGNAL PROC LET, V19, P711, DOI 10.1109/LSP.2012.2215320
   Wang GF, 2015, IEEE T IMAGE PROCESS, V24, P3796, DOI 10.1109/TIP.2015.2445291
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Zhang BC, 2017, IEEE T SYST MAN CY-S, V47, P693, DOI 10.1109/TSMC.2016.2629509
   Zhang J, 2014, SIGNAL PROCESS-IMAGE, V29, P987, DOI 10.1016/j.image.2014.06.009
   Zhang K, 2013, COMPUT SCI, DOI DOI 10.48550/ARXIV.1311.1939
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang L, 2017, PROC CVPR IEEE, P5825, DOI 10.1109/CVPR.2017.617
   Zhang L, 2017, PATTERN RECOGN, V69, P82, DOI 10.1016/j.patcog.2017.04.004
   Zhang SL, 2017, IEEE T CIRC SYST VID, V27, P1249, DOI 10.1109/TCSVT.2015.2513659
   Zhang SL, 2015, IEEE T IMAGE PROCESS, V24, P5723, DOI 10.1109/TIP.2015.2484068
   Zhang SL, 2015, PATTERN RECOGN, V48, P2474, DOI 10.1016/j.patcog.2015.02.008
   Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P265, DOI 10.1109/TMM.2015.2390044
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhu SG, 2018, MACH VISION APPL, V29, P955, DOI 10.1007/s00138-018-0947-6
   Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180
NR 83
TC 2
Z9 3
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14041
EP 14073
DI 10.1007/s11042-020-10345-2
EA JAN 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000609388200002
DA 2024-07-18
ER

PT J
AU Keyvanpour, MR
   Khanbani, N
   Aliniya, Z
AF Keyvanpour, Mohammad Reza
   Khanbani, Neda
   Aliniya, Zahra
TI Detection of individual activities in video sequences based on fast
   interference discovery and semi-supervised method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity detection; Semi-supervised learning; Co-training; Active
   learning; External clues
ID HUMAN ACTION RECOGNITION; VISUAL TRACKING; DESCRIPTOR; MACHINE; SYSTEM
AB Auto understanding of human activities in video is an increasing necessity in some application realms. The existing methods for human's activity identification are divided into two methods: activity recognition and activity detection. The most important challenge in activity detection realm is activity boundary false detection which decreases system accuracy. In this research, an activity detection system was suggested denoting rapid interference and sewing it. Although it has improved accuracy it has also accuracy time, activities in suggested system were replayed more usefully and influenced by creating a descriptor denoting movable and apparent form. The suggested system was tested on Weizmann dataset and reached an accuracy of 93.34%. Furthermore, the proposed system in activity recognition was tested on KTH dataset and reached an accuracy of 93.63%. When activity recognition is stated as a learning case, sufficient labeled educational examples must be used. But labeling the video data is expensive, so the useful method uses unlabeled and labeled examples, during the learning process, this idea is the basic foundation of the semi-supervised method. In this research, a semi-supervised method with co-training algorithm appearance and active learning was suggested which improved the efficiency of semi-supervised learning that was tested.
C1 [Keyvanpour, Mohammad Reza] Alzahra Univ, Dept Comp Engn, Tehran, Iran.
   [Khanbani, Neda; Aliniya, Zahra] Alzahra Univ, Dept Comp Engn, Data Min Lab, Tehran, Iran.
C3 Alzahra University; Alzahra University
RP Keyvanpour, MR (corresponding author), Alzahra Univ, Dept Comp Engn, Tehran, Iran.
EM keyvanpour@alzahra.ac.ir; neda.khanbani@yahoo.com; z_aliniya_m@yahoo.eom
RI Keyvanpour, Mohammad Reza/AAL-5574-2020
OI Keyvanpour, Mohammad Reza/0000-0003-2115-9099
CR Al-Berry MN., 2016, IET COMPUT VIS IEEE, V10
   [Anonymous], 2019, PATTERN ANAL APPL, DOI DOI 10.1007/s10044-018-0697-0
   [Anonymous], 2012, P 25 IEEE CAN C EL C
   [Anonymous], 2013, CROWD MONITORING USI
   [Anonymous], 2012, ARTIF INTELL REV
   [Anonymous], 2016, 18th International Conference on Transparent Optical Networks
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bautista-Gomez L, 2016, J PARALLEL DISTR COM, V98, P8, DOI 10.1016/j.jpdc.2016.07.007
   Benderbal HH, 2018, INT J ADV MANUF TECH, V94, P729, DOI 10.1007/s00170-017-0803-2
   Cai LQ, 2020, NONLINEAR DYNAM, V99, P3253, DOI 10.1007/s11071-020-05468-y
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P27309, DOI 10.1007/s11042-019-07827-3
   Chen L, 2021, MULTIMED TOOLS APPL, V80, P22685, DOI 10.1007/s11042-019-07752-5
   Cuentas S, 2017, INT J ADV MANUF TECH, V91, P485, DOI 10.1007/s00170-016-9693-y
   Dianting Liu, 2013, 2013 IEEE 14th International Conference on Information Reuse & Integration (IRI), P626, DOI 10.1109/IRI.2013.6642527
   Fang QC, 2020, NAT RESOUR RES, V29, P791, DOI 10.1007/s11053-019-09577-3
   Feng Shi, 2011, 2011 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2011), P35, DOI 10.1109/HAVE.2011.6088408
   Mollinetti MAF, 2013, 2013 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P349, DOI 10.1109/SOCPAR.2013.7054157
   Galvao Diana F., 2016, Artificial Evolution. 12th International Conference, Evolution Artificielle, EA 2015. Revised Selected Papers: LNCS 9554, P177, DOI 10.1007/978-3-319-31471-6_14
   Guo P., 2020, 2010 7 IEEE INT C AD, P248
   Guo P, 2014, MULTIMED TOOLS APPL, V68, P827, DOI 10.1007/s11042-012-1084-2
   Guo XY, 2019, FRONT COMPUT SCI-CHI, V13, P99, DOI 10.1007/s11704-018-7138-5
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Holte MB, 2012, IEEE J-STSP, V6, P553, DOI 10.1109/JSTSP.2012.2193556
   Ko T, 2008, IEEE APP IMG PAT, P84
   Koohzadi M, 2015, SIGNAL IMAGE VIDEO P, V9, P1235, DOI 10.1007/s11760-013-0557-8
   Koohzadi M, 2014, ARTIF INTELL REV, V41, P401, DOI 10.1007/s10462-012-9315-5
   Kulkarni K, 2015, INT J COMPUT VISION, V112, P90, DOI 10.1007/s11263-014-0758-9
   Ladjailia A, 2019, NEURAL COMPUTING APP
   Lamberto B, ADV TOP COMPUT VIS, DOI [10.3389/frobt.2015.00028, DOI 10.3389/FROBT.2015.00028]
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Lin JL, 2012, ALGORITHMS, V5, P433, DOI 10.3390/a5040433
   Liu X, 2021, IEEE T IND INFORM, V17, P3391, DOI 10.1109/TII.2020.2987421
   Liu X, 2020, IEEE T IND INFORM, V16, P5379, DOI 10.1109/TII.2019.2947435
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mahbub U., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P646, DOI 10.1109/ICCITechn.2011.6164868
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   Modarres AFA, 2013, IET COMPUT VIS, V7, P488, DOI 10.1049/iet-cvi.2012.0121
   Mota VF, 2020, MULTIMED TOOLS APPL, V79, P13919, DOI 10.1007/s11042-020-08642-x
   Pan H., 2016, 2016 11th International Conference on Reliability, Maintainability and Safety (ICRMS), P1, DOI [10.1109/ICRMS.2016.8050042, DOI 10.1109/ICRMS.2016.8050042]
   Pfister T, 2014, LECT NOTES COMPUT SC, V8694, P814, DOI 10.1007/978-3-319-10599-4_52
   Savargiv M, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01882-7
   Selmi M., 2016, IET COMPUT VIS IEEE, V10
   Shen HQ, 2015, MULTIMED TOOLS APPL, V74, P523, DOI 10.1007/s11042-014-1936-z
   Singh T, 2019, ARTIF INTELL REV, V52, P1107, DOI 10.1007/s10462-018-9651-1
   Su YT, 2019, MULTIMED TOOLS APPL, V78, P767, DOI 10.1007/s11042-018-5657-6
   Su ZY, 2020, FRONT COMPUT SCI-CHI, V14, P417, DOI 10.1007/s11704-018-8116-1
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Uijlings JRR., 2014, INT J MULTIMEDIA INF, V2014
   Uijlings JRR, 2010, ICMR GLASG UK APR 01, P145
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang S, 2014, COMMUN COMPUT INFORM, V462, P78, DOI [10.1007/978-3-662-43908-1_10, DOI 10.1007/978-3-662-43908-1_10]
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin B, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P99
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P14277, DOI 10.1007/s11042-018-6800-0
   Zhang TZ, 2011, PATTERN RECOGN, V44, P2334, DOI 10.1016/j.patcog.2010.06.018
   Zhang YH, 2014, EXPERT SYST APPL, V41, P2372, DOI 10.1016/j.eswa.2013.09.035
   Zhao Y, 2019, J MED BIOL ENG, V39, P569, DOI 10.1007/s40846-018-0437-3
   Zhou Z, 2015, IEEE T MULTIMEDIA, V17, P512, DOI 10.1109/TMM.2015.2404779
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
NR 67
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13879
EP 13910
DI 10.1007/s11042-020-10418-2
EA JAN 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608968500005
DA 2024-07-18
ER

PT J
AU Jazi, SY
   Kaedi, M
   Fatemi, A
AF Jazi, Saba Yousefian
   Kaedi, Marjan
   Fatemi, Afsaneh
TI An emotion-aware music recommender system: bridging the user's
   interaction and music recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion-aware music recommender; Keystroke pattern; Mouse click pattern;
   Collaborative filtering
ID NEURAL-NETWORKS; KEYBOARD
AB In emotion-aware music recommender systems, the user's current emotion is identified and considered in recommending music to him. We have two motivations to extend the existing systems: (1) to the best of our knowledge, the current systems first estimate the user's emotions and then suggest music based on it. Therefore, the emotion estimation error affects the recommendation accuracy. (2) Studies show that the pattern of users' interactions with input devices can reflect their emotions. However, these patterns have not been used yet in emotion-aware music recommender systems. In this study, a music recommender system is proposed to suggest music based on users' keystrokes and mouse clicks patterns. Unlike the previous ones, the proposed system maps these patterns directly to the user's favorite music, without labeling its current emotion. The results show that even though this system does not use any additional device, it is highly accurate compared to previous methods.
C1 [Jazi, Saba Yousefian; Kaedi, Marjan; Fatemi, Afsaneh] Univ Isfahan, Fac Comp Engn, Hezar Jerib St, Esfahan 8174673441, Iran.
C3 University of Isfahan
RP Kaedi, M (corresponding author), Univ Isfahan, Fac Comp Engn, Hezar Jerib St, Esfahan 8174673441, Iran.
EM saba.yousefian@mehr.ui.ac.ir; kaedi@eng.uiac.ir; a_fatemi@eng.ui.ac.ir
RI Kaedi, Marjan/ABG-5384-2021
CR Abdul A, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071103
   Aljanaki A, 2016, INFORM PROCESS MANAG, V52, P115, DOI 10.1016/j.ipm.2015.03.004
   Aracena C, 2015, IEEE SYS MAN CYBERN, P2632, DOI 10.1109/SMC.2015.460
   Ayata D, 2018, IEEE T CONSUM ELECTR, V64, P196, DOI 10.1109/TCE.2018.2844736
   Burns H, 2015, MOVING AVERAGES 101
   Burns S, 2017, 5 MOVING AVERAGE SIG
   Da Cunha, 2018, EXPERT SYST APPL
   Deng SG, 2015, EXPERT SYST APPL, V42, P9284, DOI 10.1016/j.eswa.2015.08.029
   Forcado MR, 2017, INT C BIG DAT TECHN
   Friedrich G, 2010, HARDBACK NOV
   Gavrilescu M, 2015, 2015 23RD TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P720, DOI 10.1109/TELFOR.2015.7377568
   Geng BR, 2015, PHYSICA A, V424, P383, DOI 10.1016/j.physa.2015.01.007
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   Guo Y, 2017, P 26 INT C WORLD WID
   Hafshejani ZY, 2018, ELECTRON COMMER RES, V18, P813, DOI 10.1007/s10660-018-9287-x
   Hamedani EM, 2019, KNOWL-BASED SYST, V164, P348, DOI 10.1016/j.knosys.2018.11.004
   Kabani H., 2015, INT J ENG RES GEN SC, V3, P2091
   Kawakami A, 2013, MUSIC PERCEPT, V30, P407, DOI 10.1525/MP.2013.30.4.407
   Kawakami A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00311
   Khan IA, 2013, FRONT COMPUT SCI-CHI, V7, P943, DOI 10.1007/s11704-013-2331-z
   Khanna Preeti., 2010, International_journal_of_computer_applications, V11, P1, DOI DOI 10.5120/1614-2170
   KM A, 2015, PROCEDIA COMPUT SCI, V70, P296
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Lukose S, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P1751, DOI 10.1109/ICICICT1.2017.8342835
   Nahin AFMNH, 2014, BEHAV INFORM TECHNOL, V33, P987, DOI 10.1080/0144929X.2014.907343
   Pentel A, 2017, INT CONF INFORM INTE, P420
   Pichl, 2018, MULTICONTEXT AWARE R
   PICHL M, MULTIMED TOOLS APPL
   Robinson J, 2012, MUSIC THEOR SPECTRUM, V34, P71, DOI 10.1525/mts.2012.34.2.71
   Roy S, 2020, MULTIMED TOOLS APPL, V79, P24119, DOI 10.1007/s11042-020-09126-8
   Salmeron-Majadas S, 2014, PROCEDIA COMPUT SCI, V35, P691, DOI 10.1016/j.procs.2014.08.151
   Schedl M, 2018, INT J MULTIMED INF R, V7, P95, DOI 10.1007/s13735-018-0154-2
   Shakirova E, 2017, IEEE NW RUSS YOUNG, P548, DOI 10.1109/EIConRus.2017.7910613
   Shikder R, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON NETWORKING, SYSTEMS AND SECURITY (NSYSS), P96, DOI 10.1109/NSysS.2017.7885808
   Song K.-t., 2017, Google Patents
   Sulikowski P, 2018, PROCEDIA COMPUT SCI, V126, P1587, DOI 10.1016/j.procs.2018.08.132
   Sunitha M, 2018, LECT NOTE DATA ENG, V3, P267, DOI 10.1007/978-981-10-4585-1_22
   Tso K, 2006, STUD CLASS DATA ANAL, P614, DOI 10.1007/3-540-31314-1_75
   Wang, 2018, INT C DAT SYST ADV A
   Xing BX, 2015, NEUROCOMPUTING, V148, P619, DOI 10.1016/j.neucom.2014.08.007
   Yin H, 2016, 6 INT C EM DAT TECHN
   Zakamulin V., 2017, MARKET TIMING MOVING
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zhang, 2014, COLLABORATIVE FILTER, DOI 10.1109/CBD.2014.47
NR 44
TC 15
Z9 16
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13559
EP 13574
DI 10.1007/s11042-020-10386-7
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607985000003
DA 2024-07-18
ER

PT J
AU Zhang, GF
   Chen, JX
AF Zhang, Guifang
   Chen, Jiaxin
TI Non-negative matrix factorization via adaptive sparse graph
   regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonnegative matrix factorization; Manifold learning; l(1) graph; Sparse
   representation
ID LOW-RANK; ALGORITHM
AB Non-negative matrix factorization (NMF), as an efficient and intuitive dimension reduction algorithm, has been successfully applied to clustering tasks. However, there are still two dominating limitations. First, the original NMF only pays attention to the global data structure, ignoring the intrinsic geometry of the original higher-dimensional data. Second, the traditional pairwise distance-based graph construction is sensitive to noise and outliers, and the nearest neighbor graph obtained is not optimal. As a result, the clustering performance will be reduced. To solve the aforementioned problems and increase the cluster accuracy, a non-negative matrix factorization via adaptive sparse graph (NMF_ASGR) is proposed in this paper. More precisely, this paper assembles the sparse representation and manifold learning into a framework to get the l(1) sparse robust graph. The l(1) sparse robust graph not only can adaptively discover the potential manifold structure of the data, but also has strong robustness to noise and outliers, which makes the structure of the graph can be learned automatically in the process of matrix decomposition. Moreover, an adaptive sparse graph is learned to batter regularize the NMF. Finally, the effectiveness and superiority of the proposed algorithm are illustrated by lots of image clustering experiments.
C1 [Zhang, Guifang; Chen, Jiaxin] Henan Univ Sci & Technol, Sch Informat Engn, Luoyang 471000, Peoples R China.
C3 Henan University of Science & Technology
RP Zhang, GF (corresponding author), Henan Univ Sci & Technol, Sch Informat Engn, Luoyang 471000, Peoples R China.
EM zgf1563829811@163.com
OI Zhang, Guifang/0000-0003-1120-8299
FU National Natural Science Foundation of China [U1504610]; Key Science and
   Technology Program of Henan Province [182102210283]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1504610, and in party by the Key
   Science and Technology Program of Henan Province under Grant
   182102210283.
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   [Anonymous], 2010, 100920105055 ARXIV
   Azzopardi G, 2013, IEEE T PATTERN ANAL, V35, P490, DOI 10.1109/TPAMI.2012.106
   Bampis CG, 2016, IEEE IMAGE PROC, P1254
   Barik Debalina, 2010, 2010 2nd International Conference on Education Technology and Computer (ICETC 2010), P170, DOI 10.1109/ICETC.2010.5529412
   Bernstein A, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P64, DOI 10.1109/ICMLA.2015.26
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Cai D, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1010
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chen ZG, 2018, NEUROCOMPUTING, V311, P344, DOI 10.1016/j.neucom.2018.05.067
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Chin TJ, 2007, IEEE T IMAGE PROCESS, V16, P1662, DOI 10.1109/TIP.2007.896668
   Chu WW, 2000, IEEE T INF TECHNOL B, V4, P97, DOI 10.1109/4233.845202
   Cui HZ, 2019, IEEE ACCESS, V7, P18284, DOI 10.1109/ACCESS.2019.2896286
   Dandil E., 2019 3 INT S MULTIDI, DOI [DOI 10.1109/ISMSIT.2019.8932817, 10.1109/ismsit.2019.8932817]
   Ding C, 2012, INT CONF ACOUST SPEE, P2033, DOI 10.1109/ICASSP.2012.6288308
   Du HS, 2015, NEUROCOMPUTING, V164, P220, DOI 10.1016/j.neucom.2015.02.067
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   He R, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995487
   He X, 2019, IEEE ACCESS, V7, P83101, DOI 10.1109/ACCESS.2019.2924520
   Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46
   Huang DS, 2007, IEEE T NEURAL NETWOR, V18, P1532, DOI 10.1109/TNN.2007.895910
   Kong D., 2011, P 20 ACM INT C INF K, P673, DOI DOI 10.1145/2063576.2063676
   Lee DD, 2001, ADV NEUR IN, V13, P556
   [李乐 LI Le], 2008, [电子学报, Acta Electronica Sinica], V36, P737
   Li ZC, 2018, IEEE T NEUR NET LEAR, V29, P1947, DOI 10.1109/TNNLS.2017.2691725
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   LIU G, 2010, IEEE T CYBERNETICS, V44, P1432
   Liu ZH, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103758
   Liu ZH, 2019, NEUROCOMPUTING, V362, P129, DOI 10.1016/j.neucom.2019.06.073
   Pedreira CE, 2006, IEEE T PATTERN ANAL, V28, P157, DOI 10.1109/TPAMI.2006.14
   Peng C, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3003730
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Wang LJ, 2019, IEEE ACCESS, V7, P133996, DOI 10.1109/ACCESS.2019.2941219
   Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51
   Yan Shuicheng., 2009, SOC IND APPL MATH P, P792, DOI [10.1137/1.9781611972795.68, DOI 10.1137/1.9781611972795.68]
   Yang YZ, 2014, AAAI CONF ARTIF INTE, P3148
   Yi YG, 2020, IEEE T CIRC SYST VID, V30, P427, DOI 10.1109/TCSVT.2019.2892971
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhang HW, 2012, PROC CVPR IEEE, P2464, DOI 10.1109/CVPR.2012.6247961
   Zhang L, 2020, APPL INTELL, V50, P438, DOI 10.1007/s10489-019-01539-9
   Zhang YW, 2019, IEEE T INFORM THEORY, V65, P5565, DOI 10.1109/TIT.2019.2920635
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhong N, 2016, INT CONF SIGN PROCES, P213, DOI 10.1109/ICSP.2016.7877826
   Zhu WJ, 2019, NEURAL COMPUT APPL, V31, P7381, DOI 10.1007/s00521-018-3572-4
   Zhuang LS, 2015, IEEE T IMAGE PROCESS, V24, P3717, DOI 10.1109/TIP.2015.2441632
NR 47
TC 5
Z9 6
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12507
EP 12524
DI 10.1007/s11042-020-10247-3
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100003
DA 2024-07-18
ER

PT J
AU Takacs, B
   Vincze, Z
AF Takacs, Barnabas
   Vincze, Zsuzsanna
TI Deep authoring-an AI Tool set for creating immersive MultiMedia
   experiences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural nets; Artificial intelligence; Volumetric video (6DoF); 360
   degrees depth estimation; Multi-camera systems; Free viewpoint video;
   Virtual humans; Spatial audio; Authoring Tools
AB We introduce a fully automated 360 degrees video processing pipeline using a hierarchical combination of Artificial Intelligence (AI) modules to create immersive volumetric XR experiences. Two critical productions tasks (person segmentation and depth estimation) are addressed with a parallel Deep Neural Network (DNN) pipeline that combines instance segmentation, person detection, pose estimation, camera stabilization, neural tracking, 3D face detection, hair masking, and monocular 360 degrees depth computation in a single and robust tool set. To facilitate the rapid uptake of these techniques we provide a detailed review of AI-based methods to address these problems (complete with links to recommended open source implementations) as well as references to existing authoring tools in the market. Our key contributions include a method to create semi-synthetic data sets for data auto-augmentation and using this technique to generate over 3.8 m images as part of a concise evaluation and subsequent retraining of DNNs for person detection tasks. Furthermore, we apply the same techniques to develop a spherical DNN for monocular depth estimation with a Free Viewpoint Video (FVV) capture system and a novel method to generate 3D human shapes and pose mannequins for training. To evaluate the performance of our AI authoring tool set we address four challenging production tasks and demonstrate the practical use of our solution with videos showing processed output.
C1 [Takacs, Barnabas] PanoCAST Drukka, Budapest, Hungary.
   [Vincze, Zsuzsanna] Drukka Moholy Nagy Univ, Budapest, Hungary.
RP Takacs, B (corresponding author), PanoCAST Drukka, Budapest, Hungary.
EM btakacs@panocast.com; vincze@mome.hu
FU European Union's Horizon 2020 research and innovation programme
   [761934]; H2020 - Industrial Leadership [761934] Funding Source: H2020 -
   Industrial Leadership
FX This work has received funding from the European Union's Horizon 2020
   research and innovation programme, grant n degrees 761934, Hyper360
   ("Enriching 360 media with 3D storytelling and personalisation
   elements").
CR Andersson Technologies, 2020, SYNTHEYES 3D CAM TRA
   [Anonymous], 2020, PIXEL ANNOTATION TOO
   [Anonymous], 2020, SGO MISTIKA VR OPTIC
   [Anonymous], 2020, ADOBE CREATIVE SUITE
   [Anonymous], 2020, CVATCOMPUTER VISION
   Bodini M, 2019, BIG DATA COGN COMPUT, V3, DOI 10.3390/bdcc3010014
   Bolya D, 2022, IEEE T PATTERN ANAL, V44, P1108, DOI 10.1109/TPAMI.2020.3014297
   Bulat A., 2017, SUPER FAN INTEGRATED
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen LJ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS), P1, DOI [10.1109/ICSRS.2018.8688869, 10.1109/ICSRS.2018.00009]
   Cohen T.S., 2018, P 6 INT C LEARN REPR, P1
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   de La Garanderie GP, 2018, LECT NOTES COMPUT SC, V11217, P812, DOI 10.1007/978-3-030-01261-8_48
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Duan ZH, 2020, IEEE COMPUT SOC CONF, P2700, DOI 10.1109/CVPRW50498.2020.00326
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang Hao-Shu., 2018, Rmpe: Regional multi-person pose estimation
   Fassold H., 2019, J SOFTWARE ENG APPL, V12, P127, DOI [10.4236/jsea.2019.125009, DOI 10.4236/JSEA.2019.125009]
   Gao KK, 2019, LECT NOTES COMPUT SC, V11935, P299, DOI 10.1007/978-3-030-36189-1_25
   Ghiasi G., 2017, Exploring the structure of a real-time, arbitrary neural artistic stylization network
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Han Z, 2020, P ASIANHCI 19 P AS C, P60, DOI 10.1145/3309700.3338440
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hohman F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376177
   Huang JW, 2017, P IEEE VIRT REAL ANN, P37, DOI 10.1109/VR.2017.7892229
   Karakottas A, 2018, 1 WORKSH 360 PERC IN
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Kopf J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982405
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   LINDLBAUE D, 2019, UIST 19
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu SJ, 2019, P 32 ANN ACM S US IN
   Lyu W, 2019, VIRTUAL REALITY INTE, V1, P55, DOI [10.3724/SP.J.2096-5796.2018.0008, DOI 10.3724/SP.J.2096-5796.2018.0008]
   Maninis KK, 2018, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2018.00071
   Matos T, 2018, WEB3D 2018: THE 23RD INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3208806.3208818
   Nakatani A, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P23, DOI 10.1145/3355355.3361880
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Paulsen RR, 2019, LECT NOTES COMPUT SC, V11361, P706, DOI 10.1007/978-3-030-20887-5_44
   Pseudoscience, 2020, VOLUMETRIC 360 6DOF
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Su YC, 2017, NEURAL INFORM PROCES
   Svanera M, 2016, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.2016.7532494
   Szczuko P, 2019, MULTIMED TOOLS APPL, V78, P29357, DOI 10.1007/s11042-019-7433-7
   Takacs B, 2020, P SIGGRAPH2020, DOI 10.1145/3388770.3407410
   Takács B, 2011, VIRTUAL REAL-LONDON, V15, P267, DOI 10.1007/s10055-010-0157-7
   Tripathi Shashank, 2020, POSENET3D UNSUPERVIS, P2
   Wang Fu-En., 2018, CoRR, P53
   Wang QZ, 2019, PROC CVPR IEEE, P4190, DOI 10.1109/CVPR.2019.00432
   Wikipedia, 2020, LIST MAP PROJECTIONS
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Xiu Y., 2018, BMVC
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Yan Y., 2019, IEEE CVF INT C COMP
   Yu K, 2019, IMAGE QUALITY ASSESS
   Zhang ZH, 2018, LECT NOTES COMPUT SC, V11211, P504, DOI 10.1007/978-3-030-01234-2_30
   Zhao Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1198
   Zioulis N, 2019, INT CONF 3D VISION, P690, DOI 10.1109/3DV.2019.00081
NR 60
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31105
EP 31134
DI 10.1007/s11042-020-10275-z
EA JAN 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000607038100007
DA 2024-07-18
ER

PT J
AU Chen, X
   Zhou, GX
   Chen, AB
   Pu, L
   Chen, WJ
AF Chen, Xiao
   Zhou, Guoxiong
   Chen, Aibin
   Pu, Ling
   Chen, Wenjie
TI The fruit classification algorithm based on the multi-optimization
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutionnal neural network; Deep learning; Image classification;
   Linear integration optimization; Weight initialization
AB To solve the problems of the traditional convolutional neural network's needs of long training time and poor accuracy in the process of fruit image classification, the present study proposes a fruit image classification method based on the multi-optimization convolutional neural network with the background of fruit classification. Firstly, in order to avoid the interference of external noise and influence the accuracy of classification, the wavelet threshold is used to denoise the fruit image, which can reduce image noise while preserving the details of the image. Secondly, to correct the over-bright fruit image or the over-dark fruit image, the gamma transform is adopted to correct the image. Finally, in the process of constructing the convolutional neural network, the SOM network is introduced for pre-learning the samples. Besides, the weights of the trained optimal SOM network are applied to the full connection layer, and an integrated optimization model of convolution and full connection is established for feature extraction and regression classification. The optimized convolutional neural network was adopted to classify fruits. According to the application results, the accuracy of the optimized convolutional neural network for fruit classification reaches 99%. Therefore, the improved convolutional neural network depth learning algorithm makes better performance to achieve fruit classification.
C1 [Chen, Xiao; Zhou, Guoxiong; Chen, Aibin; Pu, Ling; Chen, Wenjie] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
   [Zhou, Guoxiong] Cent South Univ Forest Technol, Changsha 410000, Hunan, Peoples R China.
C3 Central South University of Forestry & Technology; Central South
   University of Forestry & Technology
RP Zhou, GX (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.; Zhou, GX (corresponding author), Cent South Univ Forest Technol, Changsha 410000, Hunan, Peoples R China.
EM zhougx01@163.com
OI Zhou, Guoxiong/0000-0002-5142-4845
FU State Bureau of Forestry "948" project in China [2014-4-09]; National
   Natural Science Foundation of China [61703441]
FX This work was supported by The State Bureau of Forestry "948" project in
   China (Grant No. 2014-4-09), the National Natural Science Foundation of
   China (Grant No. 61703441).
CR Adeel A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12569
   Akmal Farah, 2020, 2020 6th Conference on Data Science and Machine Learning Applications (CDMA), P146, DOI 10.1109/CDMA47397.2020.00031
   Alishba A, 2019, SUSTAIN COMPUT-INFOR, P24, DOI [10.1016/j.suscom.2019.08.002, DOI 10.1016/J.SUSC0M.2019.08.002]
   [Anonymous], 2014, J SHANDONG U SCI TEC
   Chaitali G, 2015, INT J RECENT INNOVAT
   Chun W, 2005, J ASTRONAUTIC METROL
   Reza AE, 2007, INT CONF ON CYBERNETICS AND INFORMATION TECHNOLOGIES, SYSTEMS AND APPLICATIONS/INT CONF ON COMPUTING, COMMUNICATIONS AND CONTROL TECHNOLOGIES, VOL II, P72
   Ghaseminezhad M. H., 2011, Applied Soft Computing, V11, P3771, DOI 10.1016/j.asoc.2011.02.009
   Haidar A, 2012, IV INTERNATIONAL CONGRESS ON ULTRA MODERN TELECOMMUNICATIONS AND CONTROL SYSTEMS 2012 (ICUMT), P357, DOI 10.1109/ICUMT.2012.6459693
   He W, 2015, ELECT DESIGN ENG, P101, DOI [10.3969/j.issn.1674-6236.2015.12.031, DOI 10.3969/J.ISSN.1674-6236.2015.12.031]
   Hossain MS, 2019, IEEE T IND INFORM, V15, P1027, DOI 10.1109/TII.2018.2875149
   Hu J, 2014, J SHANGHAI DIANJI U, DOI [10.3969/j.issn.2095-0020.2014.06.007, DOI 10.3969/J.ISSN.2095-0020.2014.06.007]
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Kang HW, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105108
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P25763, DOI 10.1007/s11042-020-09244-3
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Li Y, 2014, COMPUT ENG DESIGN, DOI [10.2495/ciie140371, DOI 10.2495/CIIE140371]
   [李岳云 Li Yueyun], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P53
   Liu JF, 2014, SCI TECHNOL ENG, DOI [10.3969/j.issn.1671-1815.2014.33.045, DOI 10.3969/J.ISSN.1671-1815.2014.33.045]
   Lu Hongtao, 2016, Journal of Data Acquisition and Processing, V31, P1, DOI 10.16337/j.1004-9037.2016.01.001
   Osako Y, 2020, SCI HORTIC-AMSTERDAM, V269, DOI 10.1016/j.scienta.2020.109360
   Safdar A, 2019, MICROSC RES TECHNIQ, V82, P1542, DOI 10.1002/jemt.23320
   Srivastava M, 2016, IEEE ACCESS, V4, P3862, DOI 10.1109/ACCESS.2016.2587581
   Tao HuaWei Tao HuaWei, 2014, Transactions of the Chinese Society of Agricultural Engineering, V30, P305
   Wang XH, 2016, FIRM STRATEG DECIS, P162
   [吴光文 Wu Guangwen], 2014, [电子与信息学报, Journal of Electronics & Information Technology], V36, P1340
   [吴明光 Wu Mingguang], 2015, [电子学报, Acta Electronica Sinica], V43, P1108
   Xu LJ, 2012, B SCI TECHNOL, V28, P160, DOI [10.13774/j.cnki.kjtb.2012.10.052, DOI 10.13774/J.CNKI.KJTB.2012.10.052]
   Zhong JJ, 2015, J TSINGHUA U SCI TEC, V54, P259
   Zhou FX, 2019, MODERN ELECT TECHNIQ, V042, P68
NR 31
TC 21
Z9 21
U1 7
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11313
EP 11330
DI 10.1007/s11042-020-10406-6
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000605548700021
DA 2024-07-18
ER

PT J
AU Hu, G
   Qin, Y
   Shao, J
AF Hu, Gang
   Qin, Yi
   Shao, Jie
TI Personalized travel route recommendation from multi-source social media
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Topical package; LSTM; Route mining
AB Personalized travel route recommendation aims to recommend tourist attractions based on user's interest and generate routes which can be viewed as a recommendation and sequence task. How to build interest model for users to find personalized attractions and generate the location sequence brings great challenges. In this work, multi-source social media (e.g., travelogues and check-in records) are leveraged to find user interests and model route attributes. In order to fuse multi-source data in a unify metric space, a topical package is built as the measurement space. Then, a long short-term memory (LSTM) based method is used to generate some candidate positions based on sparse user-specified inputs. Finally, top ranked routes are recommended as final results. The proposed approach combining multi-source social based topical package and LSTM is evaluated on a real travel dataset and compared with three state-of-the-art methods. The experimental result shows that our method performs better for providing personalized travel routes.
C1 [Hu, Gang; Qin, Yi; Shao, Jie] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Peoples R China.
   [Hu, Gang; Qin, Yi; Shao, Jie] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Shao, J (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Peoples R China.; Shao, J (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China.
EM hugang@std.uestc.edu.cn; qinyi@std.uestc.edu.cn; shaojie@uestc.edu.cn
RI Hu, Gang/ABT-0320-2022
OI Hu, Gang/0000-0002-7134-3380
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   [Anonymous], 2013, PREPRINT ARXIV 1308
   [Anonymous], 2010, P 17 INT C WORLD WID, DOI DOI 10.1145/1772690.1772732
   [Anonymous], 2011, CORRABS11065213
   Brilhante Igo, 2014, Advances in Information Retrieval. 36th European Conference on IR Research, ECIR 2014. Proceedings: LNCS 8416, P771, DOI 10.1007/978-3-319-06028-6_93
   Castillo L, 2008, EXPERT SYST APPL, V34, P1318, DOI 10.1016/j.eswa.2006.12.029
   Chen G, 2014, IEEE T KNOWL DATA EN, V26, P514, DOI 10.1109/TKDE.2013.46
   Chen XH, 2015, P INT COMP SOFTW APP, P692, DOI 10.1109/COMPSAC.2015.28
   Chen YY, 2013, IEEE T MULTIMEDIA, V15, P1283, DOI 10.1109/TMM.2013.2265077
   De Choudhury M., 2010, Proceedings of the 21st ACM Conference on Hypertext and Hypermedia-HT'10, P35, DOI DOI 10.1145/1810617.1810626
   Gao Y., 2010, Proceedings of Descriptional Complexity of Formal Systems 12th Workshop (DCFS 2010), P123
   Hsieh H.P., 2012, P 12 INT C URBAN COM, P55
   Hsueh YL, 2018, INFORM SCIENCES, V433, P55, DOI 10.1016/j.ins.2017.12.031
   Hu G, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P893, DOI 10.1145/3077136.3080672
   Hu G, 2018, WORLD WIDE WEB, V21, P1689, DOI 10.1007/s11280-017-0511-8
   Hu G, 2017, IEEE T KNOWL DATA EN, V29, P114, DOI 10.1109/TKDE.2016.2617326
   Kesorn K, 2017, IEEE ACCESS, V5, P26703, DOI 10.1109/ACCESS.2017.2778293
   Kurashima T, 2006, LECT NOTES COMPUT SC, V4080, P213
   Liu XL, 2019, WORLD WIDE WEB, V22, P423, DOI 10.1007/s11280-018-0600-3
   Luo CZ, 2016, IEEE T MULTIMEDIA, V18, P40, DOI 10.1109/TMM.2015.2495248
   Shang S., 2012, Proceedings of the 15th International Conference on Extending Database Technology, P156, DOI 10.1145/2247596.2247616
   Shang S, 2017, WORLD WIDE WEB, V20, P1135, DOI 10.1007/s11280-016-0425-x
   Shang S, 2016, NEUROCOMPUTING, V213, P147, DOI 10.1016/j.neucom.2016.02.085
   Shang S, 2016, J COMPUT SCI TECH-CH, V31, P637, DOI 10.1007/s11390-016-1653-3
   Shang S, 2016, NEUROCOMPUTING, V173, P118, DOI 10.1016/j.neucom.2015.06.086
   Shang S, 2015, GEOINFORMATICA, V19, P723, DOI 10.1007/s10707-015-0227-9
   Shang S, 2014, VLDB J, V23, P449, DOI 10.1007/s00778-013-0331-0
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   Song Xuan., 2016, P INT JOINT C ART IN, P2618
   Taylor K, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1198, DOI 10.1145/3184558.3191558
   Vansteenwegen P., 2007, OR Insight, V20, P21, DOI DOI 10.1057/0RI.2007.17
   Wang M, 2017, IEEE T KNOWL DATA EN, V29, P1101, DOI 10.1109/TKDE.2017.2654445
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wu F, 2017, ALGORITHMS, V10, DOI 10.3390/a10020037
   Yin HG, 2012, IEEE INT CONF MULTI, P540, DOI 10.1109/ICMEW.2012.100
   Yu ZW, 2016, IEEE T HUM-MACH SYST, V46, P151, DOI 10.1109/THMS.2015.2446953
   Zheng BL, 2018, WORLD WIDE WEB, V21, P455, DOI 10.1007/s11280-017-0466-9
   Zheng PW, 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND SCIENTIFIC MANAGEMENT, VOLS 1-2, P1029
   Zheng Y., 2009, WWW, P791, DOI [10.1145/1526709.1526816, DOI 10.1145/1526709.1526816]
   Zheng Y, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921596
   Zhu J, 2017, WORLD WIDE WEB, V20, P111, DOI 10.1007/s11280-016-0400-6
NR 42
TC 15
Z9 15
U1 3
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33365
EP 33380
DI 10.1007/s11042-018-6776-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000003
DA 2024-07-18
ER

PT J
AU Xie, DY
   Nie, FP
   Gao, QX
AF Xie, Deyan
   Nie, Feiping
   Gao, Quanxue
TI On the optimal solution to maximum margin projection pursuit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maximum margin projections; Support vector machines; Dimensionality
   reduction; Face recognition
ID DIMENSIONALITY REDUCTION; PRESERVING PROJECTIONS; SUBSPACE
AB Most existing dimensionality reduction methods have been applied as a separable data preprocessing step before classification algorithms. This reduces the flexibility of classification algorithms. To handle this limitation, recently, a novel method, namely maximum margin projection pursuit (MMPP), was developed by simultaneously taking into account dimensionality reduction and classification in the criterion function. MMPP alternatively updates the projection matrix and normal vector of classifications hyperplane by optimizing the min-max problem. This results in the following two problems: (1) It does not guarantee both the convergence of the proposed iterative algorithm in real applications and minimization of the objective function; (2) It heavily depends on learning rate and does not get the global optimal solution. In this paper, we simultaneously solve both the projection matrix and norm vector of classification hyperplane by non-iterative method which not only optimizes the criterion function but also is faster than traditional MMPP algorithm. Furthermore, we extend our method to solve multiclass classification problems. Experiments on the Yale, ORL, AR and COIL20 databases have been conducted to evaluate our method. The results illustrate that, compared with the iterative algorithm, our no-iteration algorithm achieves higher efficiency, more stable recognition, and smaller objective value.
C1 [Xie, Deyan; Gao, Quanxue] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
   [Nie, Feiping] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Nie, Feiping] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Peoples R China.
   [Gao, Quanxue] Xidian Ningbo Informat Technol Inst, Ningbo 315000, Peoples R China.
C3 Xidian University; Northwestern Polytechnical University; Northwestern
   Polytechnical University
RP Gao, QX (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.; Nie, FP (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.; Nie, FP (corresponding author), Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Peoples R China.; Gao, QX (corresponding author), Xidian Ningbo Informat Technol Inst, Ningbo 315000, Peoples R China.
EM 17836573@qq.com; qxgao@xidian.edu.cn
RI Nie, Feiping/B-3039-2012
OI Xie, Deyan/0000-0003-3517-9007; Nie, Feiping/0000-0002-0871-6519
CR Anton B, 1996, J COMP NEUROL, V368, P229
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D., 2007, AAAI, P528
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cai D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P714
   Chen HT, 2005, PROC CVPR IEEE, P846
   Cortes C., 1995, Machine learning, P1303, DOI [DOI 10.1007/978-0-387-73003-5_299, 10.1007/978-0-387-73003-5_299]
   Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fletcher R., 1987, Practical Methods of Optimization, DOI [DOI 10.1002/9781118723203, 10.1002/9781118723203]
   Gao QX, 2014, NEURAL NETWORKS, V54, P49, DOI 10.1016/j.neunet.2014.02.009
   Gao QX, 2013, IEEE T IMAGE PROCESS, V22, P2521, DOI 10.1109/TIP.2013.2249077
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Ji SW, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1077
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131
   Liu Y, 2018, IEEE ACCESS, V6, P40723, DOI 10.1109/ACCESS.2018.2859299
   Liu Y, 2017, IEEE T IMAGE PROCESS, V26, P684, DOI 10.1109/TIP.2016.2621667
   Majumdar A, 2010, IEEE T SYST MAN CY B, V40, P1359, DOI 10.1109/TSMCB.2009.2038493
   Nene S. A., 1996, COLUMBIA OBJECT IMAG
   Nie FP, 2009, OPT ENG, V48, DOI 10.1117/1.3067869
   Nikitidis S, 2014, IEEE T IMAGE PROCESS, V23, P4413, DOI 10.1109/TIP.2014.2348868
   Paul S., 2013, Proc. 16th Int. Conf. Artificial Intell. and Statist, P498
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shi Q, 2012, ARXIV PREPRINT ARXIV
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P10195, DOI 10.1007/s11042-017-5318-1
   Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188
   Xu Y, 2004, PATTERN RECOGN, V37, P381, DOI 10.1016/S0031-3203(03)00232-2
   Xu Y, 2003, PATTERN RECOGN, V36, P3031, DOI 10.1016/S0031-3203(03)00157-2
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang B, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL IV, PROCEEDINGS, P275, DOI 10.1109/ICICTA.2009.782
   Yang X., 2017, MULTIMED TOOLS APPL, V77, P3071
NR 41
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35441
EP 35461
DI 10.1007/s11042-019-07749-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900040
DA 2024-07-18
ER

PT J
AU Kwon, H
   Kim, Y
   Yoon, H
   Choi, D
AF Kwon, Hyun
   Kim, Yongchul
   Yoon, Hyunsoo
   Choi, Daeseon
TI Classification score approach for detecting adversarial example in deep
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Evasion attack; Adversarial example; Machine
   learning; Detection method; Classification score
AB Deep neural networks (DNNs) provide superior performance on machine learning tasks such as image recognition, speech recognition, pattern analysis, and intrusion detection. However, an adversarial example, created by adding a little noise to an original sample, can cause misclassification by a DNN. This is a serious threat to the DNN because the added noise is not detected by the human eye. For example, if an attacker modifies a right-turn sign so that it misleads to the left, autonomous vehicles with the DNN will incorrectly classify the modified sign as pointing to the left, but a person will correctly classify the modified sign as pointing to the right. Studies are under way to defend against such adversarial examples. The existing method of defense against adversarial examples requires an additional process such as changing the classifier or modifying input data. In this paper, we propose a new method for detecting adversarial examples that does not invoke any additional process. The proposed scheme can detect adversarial examples by using a pattern feature of the classification scores of adversarial examples. We used MNIST and CIFAR10 as experimental datasets and Tensorflow as a machine learning library. The experimental results show that the proposed method can detect adversarial examples with success rates: 99.05% and 99.9% for the untargeted and targeted cases in MNIST, respectively, and 94.7% and 95.8% for the untargeted and targeted cases in CIFAR10, respectively.
C1 [Kwon, Hyun; Kim, Yongchul] Korea Mil Acad, Dept Elect Engn, 574 Hwarang Ro, Seoul 01819, South Korea.
   [Yoon, Hyunsoo] Korea Adv Inst Sci & Technol KAIST, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
   [Choi, Daeseon] Soongsil Univ, Dept Software, 369 Sangdo Ro, Seoul, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Soongsil
   University
RP Choi, D (corresponding author), Soongsil Univ, Dept Software, 369 Sangdo Ro, Seoul, South Korea.
EM hkwon.cs@gmail.com; sunchoi@ssu.ac.kr
RI Choi, Daeseon/HZI-2916-2023; Kwon, Hyun/M-1140-2018
OI Kwon, Hyun/0000-0003-1169-9892
FU Hwarang-Dae Research Institute of Korea Military Academy; National
   Research Foundation of Korea (NRF) - Korea government (MEST)
   [2020R1A2C1014813]
FX This work was supported by the Hwarang-Dae Research Institute of Korea
   Military Academy and the National Research Foundation of Korea (NRF)
   grant funded by the Korea government (MEST) (No.2020R1A2C1014813).
CR Abadi M., 2016, TENSORFLOW SYSTEM LA, V16
   [Anonymous], 2017, PATTERN RECOGNITION
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Carlini Nicholas, 2017, ACM WORKSH ART INT S, P3
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fawzi A., 2015, MACH LEARN, V107, P1
   Goodfellow I., 2017, The space of transferable adversarial examples
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Kereliuk C, 2015, IEEE T MULTIMEDIA, V17, P2059, DOI 10.1109/TMM.2015.2478068
   Krizhevsky A., 2014, The cifar-10 dataset
   Kurakin Alexey, 2017, INT C LEARN REPR
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li K, 2015, IEEE T CYBERNETICS, V45, P2076, DOI 10.1109/TCYB.2014.2365354
   Liu Y., 2017, DELVING TRANSFERABLE
   Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Narodytska N, 2017, IEEE COMPUT SOC CONF, P1310, DOI 10.1109/CVPRW.2017.172
   Oliveira GL, 2016, IEEE INT CONF ROBOT, P1634, DOI 10.1109/ICRA.2016.7487304
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Potluri S., 2016, Emerging Technologies and Factory Automation (ETFA), 2016 IEEE 21st International Conference on, P1, DOI 10.1109/ETFA.2016.7733515
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shen Shiwei., 2017, Ape-gan: Adversarial perturbation elimination with gan
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tramer Florian, 2018, P 7 INT C LEARN REPR
   Xu W, 2018, FEATURE SQUEEZING DE
NR 33
TC 20
Z9 20
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10339
EP 10360
DI 10.1007/s11042-020-09167-z
EA NOV 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000591261400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Alipour, N
   Hasanzadeh, RPR
AF Alipour, Niloufar
   Hasanzadeh, Reza P. R.
TI Superpixel-based brain tumor segmentation in MR images using an extended
   local fuzzy active contour model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Fuzzy logic; Magnetic resonance imaging;
   Region-based active contour; Superpixel
ID WAVELETS
AB In this paper, to deal with poor boundaries in the presence of noise and heterogeneity of magnetic resonance (MR) images, a new region-based fuzzy active contour model based on techniques of curve evolution is introduced for the brain tumor segmentation. On the other hand, since brain MR images intrinsically contain significant amounts of dark areas such as cerebrospinal fluid, therefore for properly declining the heterogeneity of classes and better segmentation results, the proposed fuzzy energy-based function has been extended to consider three distinct regions; target, dark tissues with a dark background and the rest of the foreground. Moreover, due to the inevitable dependency of pixel-based models on the initial contour, artifact, and inhomogeneity of MR images, we have used superpixels as basic atomic units not only to reduce the sensitivity to the mentioned factors but also to reduce the computational cost of the algorithm. Results show that the proposed method outperforms the accuracy of the state-of-the-art models in both real and synthetic brain MR images.
C1 [Alipour, Niloufar; Hasanzadeh, Reza P. R.] Univ Guilan, Dept Elect Engn, Rasht, Iran.
C3 University of Guilan
RP Hasanzadeh, RPR (corresponding author), Univ Guilan, Dept Elect Engn, Rasht, Iran.
EM hasanzadehpak@guilan.ac.ir
RI Hasanzadeh, Reza PR/E-8509-2013; Alipour Talemi, Niloufar/HGD-1546-2022
OI Hasanzadeh, Reza PR/0000-0002-6431-758X; 
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Abood LK, 2015, INT J SCI RES, V6, P1592
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amirmoezzi Y, 2019, AUSTRALAS PHYS ENG S, V42, P529, DOI 10.1007/s13246-019-00754-5
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   [Anonymous], 2013, P NCI MICCAI BRATS
   Bakas S., 2018, arXiv
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen-Ping Yu, 2012, Proceedings of the International Conference on Bio-inspired Systems and Signal Processing (BIOSIGNALS 2012), P527
   Chithra PL, 2020, INT J IMAG SYST TECH, V30, P674, DOI 10.1002/ima.22407
   Cordier N, 2013, P MICCAI BRATS
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P1451, DOI 10.1109/JBHI.2014.2360515
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dong JW, 2013, INT CONF INFO SCI, P59
   Fang JX, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/1064692
   Festa J., 2013, Proceedings of NCIMICCAI Brats, V1, P23
   Ibrahim RW, 2018, COMPUT METH PROG BIO, V163, P21, DOI 10.1016/j.cmpb.2018.05.031
   Ilhan U, 2017, PROCEDIA COMPUT SCI, V120, P580, DOI 10.1016/j.procs.2017.11.282
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Iscan Z, 2010, EXPERT SYST APPL, V37, P2540, DOI 10.1016/j.eswa.2009.08.003
   Jaccard P., 1908, B SOCIETE VAUDOISE S, V44, P223, DOI DOI 10.5169/SEALS-268384
   Jiang J, 2013, COMPUT MED IMAG GRAP, V37, P512, DOI 10.1016/j.compmedimag.2013.05.007
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kermi A, 2018, IET IMAGE PROCESS, V12, P1964, DOI 10.1049/iet-ipr.2017.1124
   Khotanlou H, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P198
   Kistler M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2930
   Krinidis S, 2009, IEEE T IMAGE PROCESS, V18, P2747, DOI 10.1109/TIP.2009.2030468
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Lok KH, 2017, J X-RAY SCI TECHNOL, V25, P301, DOI 10.3233/XST-17261
   Lv HL, 2017, IEEE ACCESS, V5, P7753, DOI 10.1109/ACCESS.2017.2697975
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Saehdeva J, 2012, MAGN RESON IMAGING, V30, P694, DOI 10.1016/j.mri.2012.01.006
   Saha BN, 2012, COMPUT MED IMAG GRAP, V36, P95, DOI 10.1016/j.compmedimag.2011.06.001
   Sethian J. A., 1996, Acta Numerica, V5, P309, DOI 10.1017/S0962492900002671
   Sheela CJJ, 2020, MULTIMED TOOLS APPL, V79, P17483, DOI 10.1007/s11042-020-08636-9
   Shivhare SN, 2019, MULTIMED TOOLS APPL, V78, P34207, DOI 10.1007/s11042-019-08048-4
   Shyu KK, 2012, NONLINEAR DYNAM, V67, P1559, DOI 10.1007/s11071-011-0088-1
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   SONG B, 2002, 0268 CAM U CAL
   Sun L, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00810
   Tarkhaneh O, 2019, EXPERT SYST APPL, P138
   Thaha MM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1416-0
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Wadhwa A, 2019, MAGN RESON IMAGING, V61, P247, DOI 10.1016/j.mri.2019.05.043
   Wang T, 2009, IEEE T BIO-MED ENG, V56, P781, DOI 10.1109/TBME.2009.2012423
   Wu Y, 2015, APPL SOFT COMPUT, V34, P301, DOI 10.1016/j.asoc.2015.04.058
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500
   Zeineldin RA, 2020, INT J COMPUT ASS RAD, V15, P909, DOI 10.1007/s11548-020-02186-z
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 56
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8835
EP 8859
DI 10.1007/s11042-020-10122-1
EA NOV 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000586377600002
DA 2024-07-18
ER

PT J
AU Baziyad, M
   Rabie, T
   Kamel, I
AF Baziyad, Mohammed
   Rabie, Tamer
   Kamel, Ibrahim
TI Toward stronger energy compaction for high capacity dct-based
   steganography: a region-growing approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Data hiding; Quad-tree; Segmentation; DCT; Region-growing
AB It has been proven that the strong energy compaction property of the Discrete Cosine Transform (DCT) has a relation with the inter-pixel correlation level in the spatial domain of the cover image. Recent studies have proven that the higher the correlation between pixels in the spatial domain, the stronger the energy compaction property of the DCT. Therefore, several state-of-the-art image hiding schemes aim to increase the homogeneity by segmenting the cover image into homogeneous segments to exploit the strong compaction property of the DCT. Early attempts had adopted the idea of segmenting the cover image with fixed-sized blocks to increase the homogeneity. In other attempts, the homogeneity was increased by utilizing the quad-tree segmentation technique, which showed improved results in hiding capacity and stego quality compared to the fixed-block based hiding scheme. This paper proposes the Adaptive Region-Growing (ARG) image hiding scheme, which aims to maximize the inter-pixel correlation level using the region-growing segmentation method. This segmentation technique has the ability to precisely segment the cover image into free-shaped homogeneous regions. Since objects in an image are usually free-shaped regions, it is expected that segmenting into free-shaped regions will maximize the homogeneity level within a region more than block-based segmentation techniques. Therefore, experimental results have shown superior performance of the proposed ARG scheme over competitive steganography techniques in both the hiding capacity and the quality of the stego image that reached up to 40.36 dB at 22.34 bpp.
C1 [Baziyad, Mohammed] Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
   [Rabie, Tamer; Kamel, Ibrahim] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah
RP Baziyad, M (corresponding author), Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
EM mbaziyad@sharjah.ac.ae; trabie@sharjah.ac.ae; kamel@sharjah.ac.ae
OI Baziyad, Mohammed/0000-0003-0272-2659
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Baziyad M, 2018, IEEE INT CONF INNOV, P1, DOI 10.1109/INNOVATIONS.2018.8606008
   Boroumand M, 2018, Electron. Imag., V30, DOI 10.2352/
   Datta B, 2019, MULTIMED TOOLS APPL, V78, P1511, DOI 10.1007/s11042-018-6195-y
   Dhivya R, 2018, ELECTRON LETT, V54, P1332, DOI 10.1049/el.2018.6426
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Grajeda-Marín IR, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418600108
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kalita M, 2016, 2016 INT C SYST SIGN, P1, DOI DOI 10.1109/IWS-SIP.2016.7502756
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Liao X., 2020, IEEE T DEPENDABLE SE
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Munoz A, 2015, STEGSECRET SIMPLE ST
   NYEEM H, 2017, 2017 20 INT C COMP I, P1
   Rabie T, 2020, J CIRCUIT SYST COMP, V29, P2050042
   Rabie T, 2019, IEEE ACCESS, V7, P21948, DOI 10.1109/ACCESS.2019.2898838
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063001
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rabie T, 2016, MULTIMED TOOLS APPL, V75, P5939, DOI 10.1007/s11042-015-2557-x
   Rajendran Sujarani, 2017, International Journal of Network Security, V19, P593, DOI 10.6633/IJNS.201707.19(4).12
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Weber A. G., 1997, USC-SIPI Report, V315
   Xiang LY, 2017, IEICE T INF SYST, VE100D, P313, DOI 10.1587/transinf.2016EDP7358
   Xiang LY, 2014, MULTIMED TOOLS APPL, V71, P1893, DOI 10.1007/s11042-012-1313-8
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 33
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8611
EP 8637
DI 10.1007/s11042-020-10008-2
EA NOV 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000585774700001
DA 2024-07-18
ER

PT J
AU Zhang, H
   Pan, M
AF Zhang, Hong
   Pan, Min
TI Semantics-preserving hashing based on multi-scale fusion for cross-modal
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Multi-scale fusion; Hash learning; Semantics
   preserving; Deep learning
AB Research on hash-based cross-modal retrieval has been a hotspot in the field of content-based multimedia retrieval research. Most deep cross-modal hashing methods only consider inter-modal loss that can remain local information of training data, and ignore the loss within data samples of the same modality that can remain the global information of dataset. In addition, they also ignore the factor that different scales of single modal data contain different semantic information, which affects the representation of data features. In this paper, we propose a semantics-preserving hashing method based on multi-scale fusion. More concretely, a multi-scale fusion pooling model is proposed for both image feature training network and text feature training network. Therefore, we can extract the multi-scale features of image dataset and solve the sparsity problem of text BOW vectors. When constructing the loss function, we consider intra-modal loss while considering inter-modal loss. Therefore, the output hash code retains both global and local underlying semantic correlation when image and text feature training network are trained. Experiment results on NUS-WIDE and MIRFlickr-25 K prove that against other existing methods, our algorithm improves cross-modal retrieval accuracy.
C1 [Zhang, Hong; Pan, Min] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.
   [Zhang, Hong; Pan, Min] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
C3 Wuhan University of Science & Technology
RP Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.; Zhang, H (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
EM zhanghong_wust@163.com
RI Pan, Min/HDM-7621-2022; Pan, Min/JXX-6220-2024
OI Pan, Min/0000-0002-8419-9357; 
CR Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Han YH, 2012, PROC CVPR IEEE, P2981, DOI 10.1109/CVPR.2012.6248027
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He XT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1740, DOI 10.1145/3343031.3350974
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Lin Y, 2018, PATTERN RECOGNITION
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Long MS, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P579, DOI 10.1145/2911451.2911493
   Lu XQ, 2018, IEEE T IMAGE PROCESS, V27, P106, DOI 10.1109/TIP.2017.2755766
   Mu N, 2018, NEURAL COMPUT APPL, V29, P181, DOI 10.1007/s00521-017-2870-6
   Peng YX, 2020, IEEE T MULTIMEDIA, V22, P2061, DOI 10.1109/TMM.2019.2951462
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wu F, 2012, INT J MULTIMED INF R, V1, P3, DOI 10.1007/s13735-012-0001-9
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   YANG E, 2017, 31 AAAI C ART INT
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Ye ZD, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3356338
   Ye ZD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P852, DOI 10.1145/3240508.3240560
   Yuan MK, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1407, DOI 10.1145/3240508.3240559
   Yuwono B., 1997, Database Systems for Advanced Applications '97. Proceedings of the Fifth International Conference, P41, DOI 10.1142/9789812819536_0005
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang H, 2020, PATTERN RECOGN LETT, V130, P335, DOI 10.1016/j.patrec.2019.01.002
   Zhang J, 2019, IEEE T CIRC SYST VID, V29, P212, DOI 10.1109/TCSVT.2017.2771332
   Zhang J, 2020, IEEE T MULTIMEDIA, V22, P174, DOI 10.1109/TMM.2019.2922128
   Zhang J, 2018, IEEE T MULTIMEDIA, V20, P2400, DOI 10.1109/TMM.2018.2804763
   Zhang JG, 2017, MULTIMEDIA SYST, V23, P63, DOI 10.1007/s00530-014-0416-7
   Zhuang YT, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P901, DOI 10.1145/2647868.2655059
NR 35
TC 3
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17299
EP 17314
DI 10.1007/s11042-020-09869-4
EA NOV 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000584348700002
DA 2024-07-18
ER

PT J
AU Forouzandeh, S
   Berahmand, K
   Rostami, M
AF Forouzandeh, Saman
   Berahmand, Kamal
   Rostami, Mehrdad
TI Presentation of a recommender system with ensemble learning and graph
   embedding: a case on MovieLens
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Ensemble learning; Fuzzy rules; Decision tree;
   Graph embedding; Heterogeneous knowledge graph
ID MACHINE; INFORMATION; NETWORKS; INTERNET; USERS
AB Information technology has spread widely, and extraordinarily large amounts of data have been made accessible to users, which has made it challenging to select data that are in accordance with user needs. For the resolution of the above issue, recommender systems have emerged, which much help users go through the process of decision-making and selecting relevant data. A recommender system predicts users' behavior to be capable of detecting their interests and needs, and it often uses the classification technique for this purpose. It may not be sufficiently accurate to employ single classification, where not all cases can be examined, which makes the method inappropriate to specific problems. In this research, group classification and the ensemble learning technique were used for increasing prediction accuracy in recommender systems. Another issue that is raised here concerns user analysis. Given the large size of the data and a large number of users, the process of user needs analysis and prediction (using a graph in most cases, representing the relations between users and their selected items) is complicated and cumbersome in recommender systems. Graph embedding was also proposed for resolution of this issue, where all or part of user behavior can be simulated through the generation of several vectors, resolving the problem of user behavior analysis to a large extent while maintaining high efficiency. In this research, individuals most similar to the target user were classified using ensemble learning, fuzzy rules, and the decision tree, and relevant recommendations were then made to each user with a heterogeneous knowledge graph and embedding vectors. This study was performed on the MovieLens datasets, and the obtained results indicated the high efficiency of the presented method.
C1 [Forouzandeh, Saman] Univ Appl Sci & Technol, Ctr Tehran Municipal ICT Org, Dept Comp Engn, Tehran, Iran.
   [Berahmand, Kamal] Queensland Univ Technol, Dept Sci & Engn, Brisbane, Qld, Australia.
   [Rostami, Mehrdad] Univ Kurdistan, Dept Comp Engn, Sanandaj, Iran.
C3 Queensland University of Technology (QUT); University of Kurdistan
RP Forouzandeh, S (corresponding author), Univ Appl Sci & Technol, Ctr Tehran Municipal ICT Org, Dept Comp Engn, Tehran, Iran.
EM saman.forouzandeh@gmail.com; kamal.berahmand@hdr.qut.edu.au;
   m.rostami@eng.uok.ac.ir
RI berahmand, kamal/ABH-1804-2020; Rostami, Mehrdad/W-5970-2019; Rostami,
   Mehrdad/AFU-5740-2022
OI berahmand, kamal/0000-0003-4459-0703; Rostami,
   Mehrdad/0000-0001-5710-217X; Rostami, Mehrdad/0000-0001-5710-217X
CR [Anonymous], 2015, P RECSYS
   Bai J, 2019, INFORM SYST, V81, P82, DOI 10.1016/j.is.2018.11.008
   Barkan Oren, 2016, IEEE INT WORKSHOP MA
   Basile P, 2019, INFORM SYST, V86, P1, DOI 10.1016/j.is.2019.07.001
   Ben-Lhachemi N, 2018, PROCEDIA COMPUT SCI, V127, P7, DOI 10.1016/j.procs.2018.01.092
   Berahmand K, 2019, COMPUTING, V101, P1711, DOI 10.1007/s00607-018-0684-8
   Berahmand K, 2018, CHAOS SOLITON FRACT, V110, P41, DOI 10.1016/j.chaos.2018.03.014
   Boongoen T, 2018, COMPUT SCI REV, V28, P1, DOI 10.1016/j.cosrev.2018.01.003
   Borràs J, 2014, EXPERT SYST APPL, V41, P7370, DOI 10.1016/j.eswa.2014.06.007
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Chang SY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P119, DOI 10.1145/2783258.2783296
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   da Costa Fortes A, 2014, P 20 BRAZ S MULT WEB, P47, DOI DOI 10.1145/2664551.2664556
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Forouzandeh S., 2019, Webology, V16
   Forouzandeh S., 2015, INT J COMPUT APPL, V124
   Forouzandeh S., 2014, Webology, V11, P1
   Forouzandeh S, 2020, COMPUT SCI ENG, V22, P62, DOI 10.1109/MCSE.2018.2875321
   Forouzandeh S, 2018, INT J WEB INF SYST, V14, P158, DOI 10.1108/IJWIS-07-2017-0053
   Forouzandeh S, 2017, INT J COMPUT SCI NET, V17, P46
   Golzardi E, 2019, PHYSICA A, V527, DOI 10.1016/j.physa.2019.121269
   Grbovic M, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1809, DOI 10.1145/2783258.2788627
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hamilton William L, 2017, ARXIV170905584
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Islam MZ, 2019, LECT NOTES ARTIF INT, V11439, P29, DOI 10.1007/978-3-030-16148-4_3
   Jahrer M., 2010, P 16 ACM SIGKDD INT, P693, DOI [DOI 10.1145/1835804.1835893, 10.1145/1835804.1835893]
   Jendoubi S, 2017, KNOWL-BASED SYST, V121, P58, DOI 10.1016/j.knosys.2017.01.014
   Khan Z, 2020, NEUROCOMPUTING, V380, P246, DOI 10.1016/j.neucom.2019.09.080
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Krawczyk B, 2017, INFORM FUSION, V37, P132, DOI 10.1016/j.inffus.2017.02.004
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   Lerato M, 2015, 2015 International Conference on Computing, Communication and Security (ICCCS)
   Liang B, 2015, INT CONF SOFTW ENG, P894, DOI 10.1109/ICSESS.2015.7339198
   Lin YK, 2015, AAAI CONF ARTIF INTE, P2181
   Mohammadpour T, 2019, GENOMICS, V111, P1902, DOI 10.1016/j.ygeno.2019.01.001
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2422
   Nilashi M, 2018, EXPERT SYST APPL, V92, P507, DOI 10.1016/j.eswa.2017.09.058
   Nilashi M, 2017, COMPUT IND ENG, V109, P357, DOI 10.1016/j.cie.2017.05.016
   Nilashi M, 2014, EXPERT SYST APPL, V41, P3879, DOI 10.1016/j.eswa.2013.12.023
   Palumbo E, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113235
   Barbin JP, 2020, J AMB INTEL HUM COMP, V11, P1339, DOI 10.1007/s12652-019-01451-7
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Porta A, 2001, IEEE T BIO-MED ENG, V48, P1282, DOI 10.1109/10.959324
   Pujahari A, 2019, INFORM SCIENCES, V490, P126, DOI 10.1016/j.ins.2019.03.064
   Qiu L, 2018, NEUROCOMPUTING, V278, P144, DOI 10.1016/j.neucom.2017.05.100
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ren JT, 2019, DECIS SUPPORT SYST, V125, DOI 10.1016/j.dss.2019.113115
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Ristoski P, 2014, COMM COM INF SC, V475, P150, DOI 10.1007/978-3-319-12024-9_19
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Sadeghian A, 2019, ARXIV191003943
   Seo YD, 2017, EXPERT SYST APPL, V69, P135, DOI 10.1016/j.eswa.2016.10.024
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Valcarce D, 2019, ENG APPL ARTIF INTEL, V85, P347, DOI 10.1016/j.engappai.2019.06.020
   Vasile F, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P225, DOI 10.1145/2959100.2959160
   Wang HW, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P417, DOI 10.1145/3269206.3271739
   Wang X, 2017, AAAI CONF ARTIF INTE, P203
   Wang Z, 2014, AAAI CONF ARTIF INTE, P1112
   Wei XK, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1611, DOI 10.1145/3038912.3052575
   Wolpert DH, 2002, SOFT COMPUTING AND INDUSTRY, P25
   Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006
   Xie Y, 2019, INFORM SCIENCES, V495, P37, DOI 10.1016/j.ins.2019.05.001
   Yu LY, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1295, DOI 10.1145/3097983.3098189
   Yue X, 2020, BIOINFORMATICS, V36, P1241, DOI 10.1093/bioinformatics/btz718
   Zareie A, 2019, INFORM SCIENCES, V493, P217, DOI 10.1016/j.ins.2019.04.033
   Zenobi G., 2001, Lecture Notes in Computer Science, P576, DOI DOI 10.1007/3-540-44795-4_
   Zhang F, 2016, KNOWL-BASED SYST, V96, P96, DOI 10.1016/j.knosys.2015.12.025
   Zhang MX, 2018, INFORM SCIENCES, V453, P389, DOI 10.1016/j.ins.2018.04.022
   Zhang WN, 2019, NEUROCOMPUTING, V334, P206, DOI 10.1016/j.neucom.2019.01.028
   Zhang W, 2016, NEUROCOMPUTING, V173, P979, DOI 10.1016/j.neucom.2015.08.054
   Zhou C, 2017, AAAI CONF ARTIF INTE, P2942
   Zhou H, 2019, EXPERT SYST APPL, V136, P276, DOI 10.1016/j.eswa.2019.06.045
NR 74
TC 51
Z9 53
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7805
EP 7832
DI 10.1007/s11042-020-09949-5
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Garg, S
   Jindal, B
AF Garg, Shelly
   Jindal, Balkrishan
TI Skin lesion segmentation using k-mean and optimized fire fly algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic detection; FFA; K-mean; Pre-processing; Segmentation
ID DERMOSCOPY IMAGES; BORDER DETECTION; AUTOMATIC SEGMENTATION; DIAGNOSIS;
   ACCURACY
AB Digital image processing is turning out to be increasingly more significant in the health care field used to diagnose skin cancer. The death rate is increasing by 1% every year due to skin cancer. One of the major causes of casualties due to this cancer is the non-predictability at the early stages. This paper will help in future research work when it comes to early detection of a tumor. In this work, the proposed model comprises of two important steps which are preprocessing and segmentation. In a pre-processing case, unwanted artifacts like hair, illumination, or many other artifacts are reduced by an enhanced technique using threshold and morphological operations and In the second step, segmentation of skin lesion using k-mean segmentation algorithm with optimized firefly algorithm (FFA) technique is used to achieve high accuracy. Input sample images are taken from the International skin imaging collaboration (ISIC) archive dataset and dermatology service of Hospital Pedro Hispano (PH2) dataset which are available online. The results of the proposed method are measured in terms of different parameters. It provides an accuracy of 99.1% and 98.9% using ISIC and PH2 datasets and shows better performance than existing techniques such as K-Mean and K-Mean with Particle Swarm Optimization (PSO). The performance of this research work is, in fact, quite promising.
C1 [Garg, Shelly] Punjabi Univ, Dept Elect & Commun, Patiala, Punjab, India.
   [Jindal, Balkrishan] Punjabi Univ, Dept Comp Engn, YCoE, Guru Kashi Campus, Talwandi Sabo, India.
C3 Punjabi University; Punjabi University
RP Garg, S (corresponding author), Punjabi Univ, Dept Elect & Commun, Patiala, Punjab, India.
EM shellygarg96@gmail.com; balkrishan_76@rediffmail.com
RI Garg, Shelly/AAJ-5191-2021
OI , Shelly Garg/0000-0002-5139-472X
CR Abbas Q, 2011, COMPUT METH PROG BIO, V104, pE1, DOI 10.1016/j.cmpb.2010.06.016
   Abbas Q, 2011, BIOMED SIGNAL PROCES, V6, P395, DOI 10.1016/j.bspc.2011.01.003
   Abbas Q, 2011, SKIN RES TECHNOL, V17, P91, DOI 10.1111/j.1600-0846.2010.00472.x
   Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Bi L, 2016, I S BIOMED IMAGING, P1059, DOI 10.1109/ISBI.2016.7493448
   Bozorgtabar B, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708283
   Celebi ME, 2008, SKIN RES TECHNOL, V14, P347, DOI 10.1111/j.1600-0846.2008.00301.x
   Celebi ME, 2014, IEEE SYST J, V8, P980, DOI 10.1109/JSYST.2014.2313671
   Celebi ME, 2013, SKIN RES TECHNOL, V19, pE252, DOI 10.1111/j.1600-0846.2012.00636.x
   Celebi ME, 2009, COMPUT MED IMAG GRAP, V33, P148, DOI 10.1016/j.compmedimag.2008.11.002
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Eltayef K, 2017, COMP MED SY, P739, DOI 10.1109/CBMS.2017.26
   Fan HD, 2017, COMPUT BIOL MED, V85, P75, DOI 10.1016/j.compbiomed.2017.03.025
   Fleming MG, 1998, COMPUT MED IMAG GRAP, V22, P375, DOI 10.1016/S0895-6111(98)00048-2
   Francisco RB, 2014, LECT NOTES COMPUT SC, V8580, P227, DOI 10.1007/978-3-319-09129-7_17
   Garnavi R, 2011, COMPUT MED IMAG GRAP, V35, P105, DOI 10.1016/j.compmedimag.2010.08.001
   George Y, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P692
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Gómez DD, 2008, IEEE T BIO-MED ENG, V55, P157, DOI 10.1109/TBME.2007.910651
   GRIN CM, 1990, ARCH DERMATOL, V126, P763, DOI 10.1001/archderm.126.6.763
   Iyatomi H, 2006, MELANOMA RES, V16, P183, DOI 10.1097/01.cmr.0000215041.76553.58
   Jafari MH, 2016, INT C PATT RECOG, P337, DOI 10.1109/ICPR.2016.7899656
   Jaisakthi SM, 2018, IET COMPUT VIS, V12, P1088, DOI 10.1049/iet-cvi.2018.5289
   Kéchichian R, 2014, IEEE IMAGE PROC, P892, DOI 10.1109/ICIP.2014.7025179
   Ma Z, 2016, IEEE J BIOMED HEALTH, V20, P615, DOI 10.1109/JBHI.2015.2390032
   MAGLOGIANNIS I, 2015, 37 ANN INT C IEEE EN
   Morton CA, 1998, BRIT J DERMATOL, V138, P283
   Nayak J, 2017, ADV INTELL SYST COMP, V556, P55, DOI 10.1007/978-981-10-3874-7_6
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Pennisi A, 2016, COMPUT MED IMAG GRAP, V52, P89, DOI 10.1016/j.compmedimag.2016.05.002
   Sadri AR, 2013, IEEE T BIO-MED ENG, V60, P1134, DOI 10.1109/TBME.2012.2227478
   Silveira M, 2009, IEEE J-STSP, V3, P35, DOI 10.1109/JSTSP.2008.2011119
   Suer S, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-S10-S12
   Toossi MTB, 2013, SKIN RES TECHNOL, V19, P230, DOI 10.1111/srt.12015
   Xie FY, 2013, PATTERN RECOGN, V46, P1012, DOI 10.1016/j.patcog.2012.08.012
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yüksel ME, 2009, IEEE T FUZZY SYST, V17, P976, DOI 10.1109/TFUZZ.2009.2018300
   Zhou HY, 2009, IEEE J-STSP, V3, P26, DOI 10.1109/JSTSP.2008.2010631
NR 39
TC 21
Z9 23
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7397
EP 7410
DI 10.1007/s11042-020-10064-8
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858400005
DA 2024-07-18
ER

PT J
AU Castellano, G
   Lella, E
   Vessio, G
AF Castellano, Giovanna
   Lella, Eufemia
   Vessio, Gennaro
TI Visual link retrieval and knowledge discovery in painting datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cultural heritage; Visual arts; Visual link retrieval; Knowledge
   discovery; Deep learning; Computer vision
ID CENTRALITY; NETWORKS
AB Visual arts are of inestimable importance for the cultural, historic and economic growth of our society. One of the building blocks of most analysis in visual arts is to find similarity relationships among paintings of different artists and painting schools. To help art historians better understand visual arts, this paper presents a framework forvisual link retrievalandknowledge discoveryin digital painting datasets. Visual link retrieval is accomplished by using a deep convolutional neural network to perform feature extraction and a fully unsupervised nearest neighbor mechanism to retrieve links among digitized paintings.Historicalknowledge discovery is achieved by performing a graph analysis that makes it possible to study influences among artists. An experimental evaluation on a database collecting paintings by very popular artists shows the effectiveness of the method. The unsupervised strategy makes the method interesting especially in cases where metadata are scarce, unavailable or difficult to collect.
C1 [Castellano, Giovanna; Vessio, Gennaro] Univ Bari Aldo Moro, Dept Comp Sci, Bari, Italy.
   [Lella, Eufemia] Exprivia SpA, Innovat Lab, Molfetta, Italy.
C3 Universita degli Studi di Bari Aldo Moro
RP Vessio, G (corresponding author), Univ Bari Aldo Moro, Dept Comp Sci, Bari, Italy.
EM gennaro.vessio@uniba.it
RI Vessio, Gennaro/AAG-9890-2019
OI Vessio, Gennaro/0000-0002-0883-2691
FU Universita degli Studi di Bari Aldo Moro within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Bari Aldo Moro
   within the CRUI-CARE Agreement.
CR Acharya UR, 2019, APPL INTELL, V49, P16, DOI 10.1007/s10489-018-1179-1
   Athiwaratkun B., 2015, ARXIV150702313
   Bharti M, 2020, COMPUT ELECTR ENG, V86, DOI 10.1016/j.compeleceng.2020.106693
   Bharti M, 2021, J SUPERCOMPUT, V77, P1739, DOI 10.1007/s11227-020-03315-w
   Brandes U, 2008, SOC NETWORKS, V30, P136, DOI 10.1016/j.socnet.2007.11.001
   Cai HP, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P74, DOI 10.1109/ICCVW.2015.19
   Cai Hongping, 2015, ARXIV150500110
   Carneiro G, 2012, LECT NOTES COMPUT SC, V7575, P143, DOI 10.1007/978-3-642-33765-9_11
   Castellano G, 2020, COMM COM INF SC, V1177, P105, DOI 10.1007/978-3-030-39905-4_11
   Castellano G, 2020, LECT NOTES COMPUT SC, V12011, P301, DOI 10.1007/978-3-030-38919-2_25
   Cetinic E, 2018, EXPERT SYST APPL, V114, P107, DOI 10.1016/j.eswa.2018.07.026
   Crowley Elliot J., 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P721, DOI 10.1007/978-3-319-46604-0_50
   Crowley EJ, 2015, LECT NOTES COMPUT SC, V8925, P54, DOI 10.1007/978-3-319-16178-5_4
   Deo N., 2017, Graph theory with applications to engineering and computer science
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Gonthier N, 2019, LECT NOTES COMPUT SC, V11130, P692, DOI 10.1007/978-3-030-11012-3_53
   Grobe EM, 1994, STUDENT SOLUTIONS MA
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Kalaiarsasi G, 2013, 2013 INTERNATIONAL CONFERENCE ON GREEN COMPUTING, COMMUNICATION AND CONSERVATION OF ENERGY (ICGCE), P767, DOI 10.1109/ICGCE.2013.6823537
   Khan FS, 2014, MACH VISION APPL, V25, P1385, DOI 10.1007/s00138-014-0621-6
   Leavy P., 2017, RES DESIGN QUANTITAT, DOI DOI 10.1111/FCSR.12276
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Mao H, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1183, DOI 10.1145/3123266.3123405
   Minu RI, 2014, INT J AUTOM COMPUT, V11, P489, DOI 10.1007/s11633-014-0832-3
   Nagarajan G, 2012, PROCEDIA ENGINEER, V38, P2164, DOI 10.1016/j.proeng.2012.06.260
   Ren JSJ, 2012, IEEE INT C INTELL TR, P172, DOI 10.1109/ITSC.2012.6338621
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saleh B, 2016, MULTIMED TOOLS APPL, V75, P3565, DOI 10.1007/s11042-014-2193-x
   Sandoval C, 2019, IEEE ACCESS, V7, P41770, DOI 10.1109/ACCESS.2019.2907986
   Seguin Benoit, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P753, DOI 10.1007/978-3-319-46604-0_52
   Shamir L, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670672
   Shen X, 2019, PROC CVPR IEEE, P9270, DOI 10.1109/CVPR.2019.00950
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strezoski G., 2017, ARXIV PREPRINT ARXIV
   Tan WR, 2016, IEEE IMAGE PROC, P3703, DOI 10.1109/ICIP.2016.7533051
   Thyagharajan KK, 2021, ARCH COMPUT METHOD E, V28, P897, DOI 10.1007/s11831-020-09400-w
   Thyagharajan KK, 2018, ADV ELECTR COMPUT EN, V18, P87, DOI 10.4316/AECE.2018.03012
   van de Kamp MT, 2015, BRIT J EDUC PSYCHOL, V85, P47, DOI 10.1111/bjep.12061
   van Noord N, 2015, IEEE SIGNAL PROC MAG, V32, P46, DOI 10.1109/MSP.2015.2406955
   Wilber MJ, 2017, IEEE I CONF COMP VIS, P1211, DOI 10.1109/ICCV.2017.136
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
NR 42
TC 17
Z9 17
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6599
EP 6616
DI 10.1007/s11042-020-09995-z
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000578977800002
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Zhan, MM
   Gan, JZ
   Lu, GQ
   Wan, YY
AF Zhan, Mengmeng
   Gan, Jiangzhang
   Lu, Guangquan
   Wan, Yingying
TI Graph convolutional networks of reconstructed graph structure with
   constrained Laplacian rank
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph convolutional networks; Adaptive graph; Hypergraph;
   Semi-supervised classification; Graph structure
AB Convolutional neural networks (CNNs) have achieved unprecedented competitiveness in text and two-dimensional image data processing because of its good accuracy performance and high detection speed. Graph convolutional networks (GCNs), as an extension of classical CNNs in graph data processing, have attracted wide attention. At present, GCNs often use domain knowledge (such as citation recommendation system, biological cell networks) or artificial created fixed graph to achieve various semi-supervised classication tasks. Poor quality graph will lead to suboptimal results of semi-supervised classification tasks. We propose a more general GCN of reconstructed graph structure with constrained Laplacian rank. First, we use hypergraph to establish multivariate relationships between data. On the basis of the hypergraph, In virtue of Laplacian rank constraint to the graph matrix, we learn a new graph structure which hascconnected components (wherecis the number of classification), and then we construct an ideal graph matrix which is more suitable for the task of semi-supervised classification on GCNs. Finally, the data and the new graph are input GCNs model to get the results of classification. Experiments on 10 different datasets demonstrate that this method is more competitive than the comparison method.
C1 [Zhan, Mengmeng; Lu, Guangquan; Wan, Yingying] Guangxi Normal Univ, Coll Comp Sci & Informat Technol, Guilin 541004, Guangxi, Peoples R China.
   [Gan, Jiangzhang] Massey Univ, Sch Nat & Computat Sci, Auckland Campus, Auckland 0745, New Zealand.
C3 Guangxi Normal University; Massey University
RP Lu, GQ (corresponding author), Guangxi Normal Univ, Coll Comp Sci & Informat Technol, Guilin 541004, Guangxi, Peoples R China.
EM lugq@mailbox.gxnu.edu.cn
RI Lu, Guangquan/JXL-7832-2024; zhang, hanyun/ABH-7128-2020
OI Lu, Guangquan/0000-0001-6908-6269; 
FU Key Program of the National Natural Science Foundation of China
   [61836016]; Natural Science Foundation of China [61876046, 81701780,
   61672177, 61972177]; Project of Guangxi Science and Technology
   [GuiKeAD17195062]; Guangxi Natural Science Foundation
   [2017GXNSFBA198221]; Guangxi Collaborative Innovation Center of
   Multi-Source Information Integration and Intelligent Processing;
   Research Fund of Guangxi Key Lab of Multisource Information Mining
   Security [18-A-01-01]; 2019 basic scientific research capability
   enhancement project for middle-aged teachers in guangxi university
   [2019KY0062]; Innovation Project of Guangxi Graduate Education
   [YCSW20201008, JXXYYJSCXXM-008]
FX This work is partially supported by the Key Program of the National
   Natural Science Foundation of China (Grant No: 61836016); the Natural
   Science Foundation of China (Grants No: 61876046, 81701780, 61672177 and
   61972177); the Project of Guangxi Science and Technology
   (GuiKeAD17195062); the Guangxi Natural Science Foundation (Grant No:
   2017GXNSFBA198221); the Guangxi Collaborative Innovation Center of
   Multi-Source Information Integration and Intelligent Processing; the
   Research Fund of Guangxi Key Lab of Multisource Information Mining &
   Security (18-A-01-01); 2019 basic scientific research capability
   enhancement project for middle-aged teachers in guangxi university
   (2019KY0062); and Innovation Project of Guangxi Graduate Education
   (Grants No:YCSW20201008, JXXYYJSCXXM-008).
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Agarwal S., 2005, PROC CVPR IEEE, V2, P838
   [Anonymous], 2009, NIPS
   Atwood J, 2016, ADV NEUR IN, V29
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Coley CW, 2019, CHEM SCI, V10, P370, DOI 10.1039/c8sc04228d
   Defferrard M, 2016, ADV NEUR IN, V29
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Franceschi L, 2019, ARXIV 190311960
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hamilton WL, 2017, ADV NEUR IN, V30
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hu RY, 2020, WORLD WIDE WEB, V23, P1945, DOI 10.1007/s11280-019-00766-x
   Jiang JW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2635
   Kingma D.P., 2014, ARXIV14126980
   Kipf TN, 2017, INT C LEARN REPR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Mirza BJ, 2003, J INTELL INF SYST, V20, P131, DOI 10.1023/A:1021819901281
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shi HY, 2019, IEEE T NEUR NET LEAR, V30, P2963, DOI 10.1109/TNNLS.2018.2869747
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Yao D, 2015, IEEE IJCNN
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhou D, 2007, 2007 IEEE NORTH-EAST WORKSHOP ON CIRCUITS AND SYSTEMS, P167, DOI 10.1109/CADCG.2007.4407875
   Zhu XF, 2020, WORLD WIDE WEB, V23, P1969, DOI 10.1007/s11280-019-00731-8
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 33
TC 5
Z9 6
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34183
EP 34194
DI 10.1007/s11042-020-09984-2
EA OCT 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000577066700006
DA 2024-07-18
ER

PT J
AU Bourouis, S
   Channoufi, I
   Alroobaea, R
   Rubaiee, S
   Andejany, M
   Bouguila, N
AF Bourouis, Sami
   Channoufi, Ines
   Alroobaea, Roobaea
   Rubaiee, Saeed
   Andejany, Murad
   Bouguila, Nizar
TI Color object segmentation and tracking using flexible statistical model
   and level-set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image segmentation; Object tracking; Mixture bounded model;
   Feature selection; Minimum message length; Level-set
ID IMAGE SEGMENTATION; FEATURE-SELECTION; ACTIVE CONTOURS; MIXTURE-MODELS;
   REGION
AB This study presents an unsupervised novel algorithm for color image segmentation, object detection and tracking based on unsupervised learning step followed with a post processing step implemented with a variational active contour. Flexible learning method of a finite mixture of bounded generalized Gaussian distributions using the Minimum Message Length (MML) principle is developed to cope with the complexity of color images modeling. We deal here simultaneously with the issues of data-model fitting, determining automatically the optimal number of classes and selecting relevant features. Indeed, a feature selection step based on MML is implemented to eliminate uninformative features and therefore improving the algorithm's performance. For model's parameters estimation, the maximum likelihood (ML) was investigated and conducted via expectation maximization (EM) algorithm. The obtained object boundaries in the first step are tracked on each frame of a given sequence using a geometric level-set approach. The implementation has the advantage to help in improving the computational efficiency in high-dimensional spaces. We demonstrate the effectiveness of the developed segmentation method through several experiments. Obtained results reveal that our approach is able to achieve higher precision as compared to several other methods for color image segmentation and object tracking.
C1 [Bourouis, Sami; Alroobaea, Roobaea] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, At Taif 21944, Saudi Arabia.
   [Bourouis, Sami; Channoufi, Ines] Univ Tunis El Manar, LR SITI Lab Signal Image & Technol Informat, Tunis 1002, Tunisia.
   [Rubaiee, Saeed; Andejany, Murad] Univ Jeddah, Fac Engn, Dept Ind & Syst Engn, Jeddah, Saudi Arabia.
   [Bouguila, Nizar] Concordia Univ, Concordia Inst Informat Syst Engn CIISE, Montreal, PQ H3G 1T7, Canada.
C3 Taif University; Universite de Tunis-El-Manar; University of Jeddah;
   Concordia University - Canada
RP Bourouis, S (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, At Taif 21944, Saudi Arabia.; Bourouis, S (corresponding author), Univ Tunis El Manar, LR SITI Lab Signal Image & Technol Informat, Tunis 1002, Tunisia.
EM s.bourouis@tu.edu.sa; ines.channoufi@esprit.tn; r.robai@tu.edu.sa;
   salrubaiee@uj.edu.sa; mbazzar@uj.edu.sa; nizar.bouguila@concordia.ca
RI Rubaiee, Saeed/T-8560-2019; Alroobaea, Roobaea/M-3894-2019; Bourouis,
   Sami/N-4995-2019
OI Rubaiee, Saeed/0000-0002-4433-5529; Alroobaea,
   Roobaea/0000-0003-1585-2962; Bourouis, Sami/0000-0002-6638-7039
FU Taif University Researchers Supporting Project, Taif University, Taif,
   Saudi Arabia [TURSP-2020/26]
FX Taif University Researchers Supporting Project number (TURSP-2020/26),
   Taif University, Taif, Saudi Arabia.
CR Alhakami W, 2019, IEEE ACCESS, V7, P52181, DOI 10.1109/ACCESS.2019.2912115
   Allili Mohand Said, 2010, Proceedings of the 2010 Seventh Canadian Conference on Computer and Robot Vision (CRV 2010), P285, DOI 10.1109/CRV.2010.44
   Alroobaea R., 2018, INT J APPL ENG RES, V13, P6795
   Alroobaea R, 2020, INT J IMAG SYST TECH, V30, P18, DOI 10.1002/ima.22391
   [Anonymous], 2005, Statistical and Inductive Inference by Minimum Message Length
   [Anonymous], 2006, Conference on Computer Vision Pattern Recognition Workshop, DOI [DOI 10.1109/CVPRW.2006.48, 10.1109/CVPRW.2006.48]
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Babu Giltta, 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P414, DOI 10.1109/ICCS1.2017.8326033
   Ben Ayed I, 2005, IEEE T PATTERN ANAL, V27, P793, DOI 10.1109/TPAMI.2005.106
   Bouguila N, 2006, STAT COMPUT, V16, P215, DOI 10.1007/s11222-006-8451-7
   Bouguila N, 2005, LECT NOTES COMPUT SC, V3686, P172
   Bourouis S, 2008, LECT NOTES COMPUT SC, V5112, P770, DOI 10.1007/978-3-540-69812-8_76
   Bourouis S, 2019, IEEE ACCESS, V7, P1107, DOI 10.1109/ACCESS.2018.2886315
   Bourouis S, 2014, EXPERT SYST APPL, V41, P2329, DOI 10.1016/j.eswa.2013.09.030
   Bourouis S, 2010, INT J IMAGE GRAPH, V10, P135, DOI 10.1142/S0219467810003706
   Boutemedjet S., 2007, Proc. of 17-th IEEE workshop on Machine Learning for Signal Processing (MLSP), P69
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Channoufi I, 2020, FLEXIBLE STAT LEARNI, P325
   Channoufi I, 2018, MULTIMED TOOLS APPL, V77, P25591, DOI 10.1007/s11042-018-5808-9
   Channoufi I, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Cuevas C, 2016, COMPUT VIS IMAGE UND, V152, P103, DOI 10.1016/j.cviu.2016.08.005
   Darolti C, 2008, IEEE T IMAGE PROCESS, V17, P2275, DOI 10.1109/TIP.2008.2006443
   Dzyubachyk O, 2010, IEEE T MED IMAGING, V29, P852, DOI 10.1109/TMI.2009.2038693
   Falco ID, 2018, HEALTHINF 2018, P633
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Gao Z, 2020, NEURAL NETWORKS, V125, P290, DOI 10.1016/j.neunet.2020.02.017
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hastie T., 2009, The Elements of Statistical Learning
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Ilyasova N, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), P138, DOI 10.1109/INTECH.2017.8102433
   Jackowski K, 2017, PATTERN ANAL APPL, V20, P401, DOI 10.1007/s10044-015-0502-2
   Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71
   Li Y, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P2103
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lindblom J, 2003, IEEE T SPEECH AUDI P, V11, P88, DOI 10.1109/TSA.2002.805639
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo JF, 2016, INT CONF SIGN PROCES, P794, DOI 10.1109/ICSP.2016.7877940
   Maire M, 2008, 2008 IEEE COMP SOC C
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Maska M, 2010, LECT NOTES COMPUT SC, V6455, P387
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Meignen S, 2006, IEEE T IMAGE PROCESS, V15, P1647, DOI 10.1109/TIP.2006.873455
   Mignotte M, 2010, IEEE T IMAGE PROCESS, V19, P1610, DOI 10.1109/TIP.2010.2044965
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Najar F, 2020, SOFT COMPUT, V24, P10611, DOI 10.1007/s00500-019-04567-2
   Najar F, 2019, MULTIMED TOOLS APPL, V78, P18669, DOI 10.1007/s11042-018-7116-9
   Najar F, 2018, LECT NOTES COMPUT SC, V10882, P408, DOI 10.1007/978-3-319-93000-8_46
   Najar F, 2017, I C COMP SYST APPLIC, P704, DOI 10.1109/AICCSA.2017.108
   Oussalah M, 2012, INT CONF IMAG PROC, P105, DOI 10.1109/IPTA.2012.6469575
   Pi MH, 2006, PATTERN RECOGN LETT, V27, P1710, DOI 10.1016/j.patrec.2006.04.019
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sethian J., 1999, LEVEL SET METHODS FA
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.7017.09.004, 10.1016/j.cmpb.2012.09.004]
   Tychsen-Smith L, 2017, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2017.54
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Zhang KH, 2013, IEEE T CIRC SYST VID, V23, P1957, DOI 10.1109/TCSVT.2013.2269772
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
NR 66
TC 12
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5809
EP 5831
DI 10.1007/s11042-020-09809-2
EA OCT 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577990600006
DA 2024-07-18
ER

PT J
AU Wu, YL
   Chen, MH
   Wo, Y
   Han, GQ
AF Wu, Yuanlu
   Chen, Minghao
   Wo, Yan
   Han, Guoqiang
TI Video smoke detection base on dense optical flow and convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smoke detection; Convolutional neural networks; Dense optical flow
ID ANOMALY DETECTION
AB Fire is one of the disasters with the highest probability among natural disasters and social disasters. It poses a serious threat to human life and life safety. In order to reduce fire losses, a reliable fire warning method is particularly important. But due to huge variations of smoke in color, shapes, and texture and complex application environments, the existing methods still do not meet the application requirements well. To solve these problems, in this paper, we propose a two-stage real-time video smoke detection method base on dense optical flow and convolutional neural network. In the first stage, we propose a fast pre-positioning module to obtain suspicious smoke areas through the dynamic characteristics of smoke which can greatly reduce the subsequent computational complexity, and only extract the moving optical flow of suspicious smoke areas as the dynamic features of the smoke which reduce the subsequent processing time cost. Instead of simply using moving optical flow as the dynamic characteristics of smoke, we found that the optical flow of the blue channel (OFBC) can effectively reflect the motion characteristics of smoke, so we combine the OFBC of suspicious smoke areas with its three RGB color channels to form a quaternion matrix for subsequent classification. In the second stage, we choose ResNet as our pre-classifier, and a temporal enhanced adjustment algorithm was proposed as the pre-classified follow-up fine optimization module, which can fully utilize the characteristics of the smoke movement in the video to improve detection rate. The experimental results show that compared with the existing smoke detection methods, our proposed method achieves high detection rate and low false alarm rate.
C1 [Wu, Yuanlu; Chen, Minghao; Wo, Yan; Han, Guoqiang] South China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510641, Peoples R China.
C3 South China University of Technology
RP Wo, Y (corresponding author), South China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510641, Peoples R China.
EM woyan@scut.edu.cn
FU National Natural Science Foundation of Guangdong [2018A030313994];
   Guangzhou science and technology plan project [202002030298]
FX This work was supported by the National Natural Science Foundation of
   Guangdong [Grant No.2018A030313994], and Guangzhou science and
   technology plan project [Grant No.202002030298].
CR [Anonymous], 2015, P 32 INT C INT C MAC
   Chen Jun-zhou, 2016, Journal of University of Electronic Science and Technology of China, V45, P992, DOI 10.3969/j.issn.1001-0548.2016.06.020
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Filonenko A, 2017, C HUM SYST INTERACT, P64, DOI 10.1109/HSI.2017.8004998
   Garg S, 2019, IEEE T NETW SERV MAN, V16, P924, DOI 10.1109/TNSM.2019.2927886
   Garg S, 2019, IEEE T MULTIMEDIA, V21, P566, DOI 10.1109/TMM.2019.2893549
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YC, 2018, MULTIMED TOOLS APPL, V77, P29283, DOI 10.1007/s11042-018-5978-5
   Kaiser T, 2000, SEC TECHN 2000 P IEE
   Khan S, 2019, IEEE INTERNET THINGS, V6, P9237, DOI 10.1109/JIOT.2019.2896120
   Kingma D. P, 2015, International Conference on Learning Representations
   Lin GH, 2017, KSII T INTERNET INF, V11, P5522
   Lu X, 2019, IEEE C COMP VIS PATT
   Manutchehr-Danai M, 2009, DICT GEMS GEMOLOGY
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryser P, 1991, INT C SOL STAT SENS
   Tao CY, 2016, 2016 INT C IND INF C
   Tung TX, 2011, FIRE SAFETY J, V46, P276, DOI 10.1016/j.firesaf.2011.03.003
   Verstockt S, 2013, FIRE SAFETY J, V57, P44, DOI 10.1016/j.firesaf.2012.07.005
   Wang W, 2019, IEEE INT C COMP VIS
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   Zhang F, 2020, MULTIMEDIA TOOLS APP
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 26
TC 9
Z9 11
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35887
EP 35901
DI 10.1007/s11042-020-09870-x
EA OCT 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000575795600010
DA 2024-07-18
ER

PT J
AU Karim, S
   He, H
   Laghari, AA
   Magsi, AH
   Laghari, RA
AF Karim, Sajida
   He, Hui
   Laghari, Asif Ali
   Magsi, Arif Hussain
   Laghari, Rashid Ali
TI Quality of service (QoS): measurements of image formats in social cloud
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network (CNN); Deep learning (DL); Quality of service
   (QoS); Social cloud (SC) computing; Etc
AB With the development of multimedia and the popularity of social cloud (SC), Quality of Service (QoS) is used to measure the technical parameters of service delivery. QoS is mostly used for measuring various kinds of multimedia data. Sharing (uploading) on SC has become the daily activity of end-users. As a result of this activity, it provides an open challenge for service providers. As a service provider, the host delivers productive infrastructure, allowing end-users to upload and share their high-quality images. To evaluate the QoS of image compression, we conduct objective QoS techniques to measure the efficiency of image quality and QoS performance of service delivery via uploading /downloading of images on three popular SC, (Facebook, Twitter, and Instagram). These social clouds and image services are compared by the mean, standard deviation (STDEV),mean square error (MSE), and signal-to-noise ratio (SNR). So we can achieve better results about the SC image quality. The results show that Instagram and Facebook compressed images more as compared to Twitter. However, Twitter less supports image formats and provides an acceptable quality of compressed images as compared to others. Therefore, Facebook supports all image file formats and enhanced (QoE) levels of end-users, but Twitter provided the best QoS of compressed images as compared to Instagram. Further, we found that the decrease of MSE and increase of SNR both have a high impact on image resolutions as compared to original image parameters, which has a higher effect on quality. For the specific quality assurance of image tasks acquired for robust automated image analysis research, we are also using deep learning techniques (DLT) to classify the quality of images. We also have identified the opportunity to simplify the Convolutional Neural network (CNN) with smaller resampling grids and making this process more suitable for at least five thousand (5000) of the enormous datasets available in the future.
C1 [Karim, Sajida; He, Hui; Laghari, Asif Ali; Laghari, Rashid Ali] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [Magsi, Arif Hussain] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing, Peoples R China.
C3 Harbin Institute of Technology; Beijing University of Posts &
   Telecommunications
RP He, H (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
EM hehui@hit.edu.cn
RI laghari, Rashid Ali/AGY-4067-2022; Laghari, Rashid Ali/GRF-5084-2022;
   Laghari, Asif Ali/AAF-5893-2020; HE, HUI/KUK-4080-2024; Hussain,
   Arif/KHZ-0081-2024
OI Laghari, Asif Ali/0000-0001-5831-5943; Magsi, ARIF
   HUSSAIN/0000-0002-5801-8268; Laghari, Dr. Rashid Ali/0000-0002-9710-7538
FU National Key R&D Program of China [2017YFB803304]; National Science
   Foundation of China (NSFC) [61672186, 61872110]
FX The work is supported by the National Key R&D Program of China under
   grant No.2017YFB803304, the National Science Foundation of China (NSFC)
   under grant No. 61672186 and 61872110.
CR Ahammad P, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P797, DOI 10.1145/2647868.2654982
   Amerini I, 2017, SIGNAL PROCESS-IMAGE, V57, P1, DOI 10.1016/j.image.2017.04.009
   [Anonymous], 2008, J247 ITUT
   Ansari Mohammadi, 2019, International Journal of Computer Network and Information Security, V11, P11, DOI DOI 10.5815/IJCNIS.2019.01.02
   Batini C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541883
   Boutaba R, 2018, J INTERNET SERV APPL, V9, DOI 10.1186/s13174-018-0087-2
   Brunnstrom K, 2013, FFHAL00977812F EUR N
   Carnec M, 2005, IEEE IMAGE PROC, P753
   Chang WY, 2010, TRANSFORMING ENTERPRISE CLOUD SERVICES, P1, DOI 10.1007/978-90-481-9846-7
   Dargie W., 2010, FUNDAMENTALS WIRELES, DOI [10.1002/9780470666388, DOI 10.1002/9780470666388]
   Eckert M, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1082
   Engelke U, 2007, 2007 NEXT GENERATION INTERNET NETWORKS, P190, DOI 10.1109/NGI.2007.371215
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiau MK, 2015, IEEE INTEL TRANSP SY, V7, P62, DOI 10.1109/MITS.2015.2417974
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   Karim S, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/5028132
   Kovarik Bill., 2015, REVOLUTIONS COMMUNIC
   Lee JS, 2013, MULTIMED TOOLS APPL, V67, P31, DOI 10.1007/s11042-012-1011-6
   Liu C, 2017, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2017.241
   Mikolajczyk J, 2018, P I C NEW T SIG PROC, P118
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Muhammad N, 2006, QOS QOE MANAGEMENT U, P1
   Pereira F, 2005, P INT WORKSH VID PRO, P910
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Ramesh B., 2013, INT J COMPUT TECHNOL, V4, P97
   Rosenthal A, 2010, J BIOMED INFORM, V43, P342, DOI 10.1016/j.jbi.2009.08.014
   Shi ZB, 2014, IEEE J EM SEL TOP C, V4, P17, DOI 10.1109/JETCAS.2014.2298291
   Smith TL, 2011, VISUAL STUD, V26, P270, DOI 10.1080/1472586X.2011.610953
   Staehle B, 2010, NEW DIMENSIONS ASSES, P6
   Tsaur LF, 2003, CCW 2003: IEEE 18TH ANNUAL WORKSHOP ON COMPUTER COMMUNICATIONS, PROCEEDINGS, P40, DOI 10.1109/CCW.2003.1240788
   Usman MA, 2017, IETE TECH REV, V34, P309, DOI 10.1080/02564602.2016.1185975
   Wang Z, 2005, PROC SPIE, V5666, P149, DOI 10.1117/12.597306
   Xu YD, 2014, IEEE T MOBILE COMPUT, V13, P2734, DOI 10.1109/TMC.2014.2307323
   Yalman Y, 2012, PRZ ELEKTROTECHNICZN, V88, P126
   Yang G, 2011, IEEE INT SYMP CIRC S, P1239
NR 37
TC 11
Z9 12
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4507
EP 4532
DI 10.1007/s11042-020-09959-3
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100009
DA 2024-07-18
ER

PT J
AU Giannakeris, P
   Petrantonakis, PC
   Avgerinakis, K
   Vrochidis, S
   Kompatsiaris, I
AF Giannakeris, Panagiotis
   Petrantonakis, Panagiotis C.
   Avgerinakis, Konstantinos
   Vrochidis, Stefanos
   Kompatsiaris, Ioannis
TI First-person activity recognition from micro-action representations
   using convolutional neural networks and object flow histograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Object detection; Egocentric vision; Ambient
   assisted living
ID EGOCENTRIC VISION
AB A novel first-person human activity recognition framework is proposed in this work. Our proposed methodology is inspired by the central role moving objects have in egocentric activity videos. Using a Deep Convolutional Neural Network we detect objects and develop discriminant object flow histograms in order to represent fine-grained micro-actions during short temporal windows. Our framework is based on the assumption that large scale activities are synthesized by fine-grained micro-actions. We gather all the micro-actions and perform Gaussian Mixture Model clusterization, so as to build a micro-action vocabulary that is later used in a Fisher encoding schema. Results show that our method can reach 60%recognition rate on the benchmark ADL dataset. The capabilities of the proposed framework are also showcased by profoundly evaluating for a great deal of hyper-parameters and comparing to other State-of-the-Art works.
C1 [Giannakeris, Panagiotis; Petrantonakis, Panagiotis C.; Avgerinakis, Konstantinos; Vrochidis, Stefanos; Kompatsiaris, Ioannis] ITI CERTH, Thermi, Greece.
RP Giannakeris, P (corresponding author), ITI CERTH, Thermi, Greece.
EM giannakeris@iti.gr; ppetrant@iti.gr; koafgeri@iti.gr; stefanos@iti.gr;
   ikom@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015; Petrantonakis, Panagiotis/L-2286-2018
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Giannakeris,
   Panagiotis/0000-0002-3774-3161; Vrochidis, Stefanos/0000-0002-2505-9178
FU project SUITCEYES - European Union's Horizon 2020 research and
   innovation program [780814]; H2020 - Industrial Leadership [780814]
   Funding Source: H2020 - Industrial Leadership
FX This work is supported by the project SUITCEYES that has received
   funding from the European Union's Horizon 2020 research and innovation
   program under grant agreement No 780814.
CR [Anonymous], 2015, CORR
   [Anonymous], 2018, ARXIV180703284
   Avgerinakis K, 2016, COMPUT VIS IMAGE UND, V144, P46, DOI 10.1016/j.cviu.2015.10.013
   Bambach S, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P351, DOI 10.1145/2818346.2820771
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Chen M, 2011, INT CONF CLOUD COMPU, P316, DOI 10.1109/CCIS.2011.6045082
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Crispim CF Jr, 2016, IEEE T PATTERN ANAL, V38, P1598, DOI 10.1109/TPAMI.2016.2537323
   Crispim-Junior CF, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071528
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du WB, 2017, IEEE I CONF COMP VIS, P3745, DOI 10.1109/ICCV.2017.402
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269
   Feichtenhofer C, 2016, ADV NEUR IN, V29
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   FRANKL P, 1988, J COMB THEORY B, V44, P355, DOI 10.1016/0095-8956(88)90043-3
   Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646
   Giangrande P., 2018, P IEEE INT C EL SYST, DOI DOI 10.1109/ESARS-ITEC.2018.8607467
   González-Díaz I, 2019, PATTERN RECOGN, V88, P223, DOI 10.1016/j.patcog.2018.11.013
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Johnson W.B., 1984, CONTEMP MATH-SINGAP, V26, P189, DOI DOI 10.1090/CONM/026/737400
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kroeger T, 2016, LECT NOTES COMPUT SC, V9908, P471, DOI 10.1007/978-3-319-46493-0_29
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Li Y, 2018, LECT NOTES COMPUT SC, V11209, P639, DOI 10.1007/978-3-030-01228-1_38
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   McCandless T, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.30
   Meditskos G, 2018, J VIS COMMUN IMAGE R, V51, P169, DOI 10.1016/j.jvcir.2018.01.009
   Ohnishi K, 2016, PROC CVPR IEEE, P3103, DOI 10.1109/CVPR.2016.338
   Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P159, DOI 10.1145/275487.275505
   Pirsiavash H, 2014, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2014.85
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salakhutdinov, 2015, ARXIV151104119
   Singh B, 2018, 32 C NEURAL INFORM P
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Tran A, 2017, IEEE INT CONF COMP V, P3110, DOI 10.1109/ICCVW.2017.368
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaca-Castano G, 2017, COMPUT VIS IMAGE UND, V156, P92, DOI 10.1016/j.cviu.2016.10.016
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang L, 2018, IEEE IPCCC
   Wang XH, 2018, NEUROCOMPUTING, V275, P438, DOI 10.1016/j.neucom.2017.08.063
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhao Q, 2018, ARXIV181104533
   Zhou Y, 2016, PROC CVPR IEEE, P1904, DOI 10.1109/CVPR.2016.210
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 57
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22487
EP 22507
DI 10.1007/s11042-020-09902-6
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000573766700002
DA 2024-07-18
ER

PT J
AU Jha, S
   Seo, C
   Yang, E
   Joshi, GP
AF Jha, Sudan
   Seo, Changho
   Yang, Eunmok
   Joshi, Gyanendra Prasad
TI Real time object detection and trackingsystem for video surveillance
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Object tracking; Video surveillance; Edge computing;
   Artificial intelligence
AB This paper introduces a system capable of real-time video surveillance in low-end edge computing environment by combining object detection tracking algorithm. Recently, the accuracy of object detection has been improved due to the performance of approaches based on deep learning algorithm such as region-based convolutional network, which has two stages for inferencing. One-stage detection algorithms such as single shot detector and you only look once (YOLO) have been developed at the expense of some accuracy and can be used for real-time systems. However, high-performance hardware such as general-purpose graphics processing unit is required to achieve excellent object detection performance and speed. In this study, we propose an approach called N-YOLO which is instead of resizing image step in YOLO algorithm, it divides into fixed size images used in YOLO and merges detection results of each divided sub-image with inference results at different times using correlation-based tracking algorithm the amount of computation for object detection and tracking can be significantly reduced. In addition, we propose a system that can guarantee real-time performance in various edge computing environments by adaptively controlling the cycle of object detection and tracking.
C1 [Jha, Sudan] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara 144411, Punjab, India.
   [Seo, Changho] Kongju Natl Univ, Dept Convergence Sci, Gongju 32588, South Korea.
   [Yang, Eunmok] Kookmin Univ, Dept Financial Informat Secur, Seoul 02707, South Korea.
   [Joshi, Gyanendra Prasad] Sejong Univ, Dept Comp Sci & Engn, Seoul 05006, South Korea.
C3 Lovely Professional University; Kongju National University; Kookmin
   University; Sejong University
RP Joshi, GP (corresponding author), Sejong Univ, Dept Comp Sci & Engn, Seoul 05006, South Korea.
EM joshi@sejong.ac.kr
RI Jha, Sudan/P-9823-2018; Joshi, Gyanendra Prasad/I-3767-2019
OI Jha, Sudan/0000-0003-0074-2584; Joshi, Gyanendra
   Prasad/0000-0002-5446-288X; Yang, Eunmok/0000-0002-6508-7034
CR Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   Cao XY, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107233
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Ding Z, 2019, ARXIV190200615, V1902, P1
   Durand T, TRACKING THINGS OBJE
   Fu H, 2019, LECT NOTES COMPUT SC, V11901, P157, DOI 10.1007/978-3-030-34120-6_13
   Geng Y, 2017, LEARNING CONVOLUTION, P589
   GOUVEIA M, 1995, REV INCOME WEALTH, P1
   Huang CH, 2015, PROC CVPR IEEE, P4027, DOI 10.1109/CVPR.2015.7299029
   Le N, 2016, LECT NOTES COMPUT SC, V9914, P43, DOI 10.1007/978-3-319-48881-3_4
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Nikouei SY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE), P125, DOI 10.1109/EDGE.2018.00025
   Pinho C, 2005, INT J FOOD ENG, V1, DOI 10.2202/1556-3758.1010
   Pinho R. R., 2007, WSEAS Transactions on Information Science and Applications, V4, P196
   Pinho RR, 2009, CMES-COMP MODEL ENG, V46, P51
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Wang SH, 2018, INTL CONF POWER SYST, P3871, DOI 10.1109/POWERCON.2018.8602149
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P1918, DOI 10.1109/TITS.2016.2614548
   Zhang BB, 2019, MATEC WEB CONF, V277, DOI 10.1051/matecconf/201927701003
   Zhang G., 2017, MEDIAT INFLAMM, V2017, P1, DOI [DOI 10.1155/2017/3578702, 10.1155/2017/3578702, DOI 10.1155/2017/3126010]
   Zhang GH, 2018, LECT NOTES ARTIF INT, V10956, P134, DOI 10.1007/978-3-319-95957-3_15
   Zhu J, 2019, LECT NOTES COMPUT SC, V11903, P555, DOI 10.1007/978-3-030-34113-8_46
NR 24
TC 51
Z9 53
U1 5
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3981
EP 3996
DI 10.1007/s11042-020-09749-x
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572719800003
DA 2024-07-18
ER

PT J
AU Xiao, RY
   Cui, XC
   Qiao, H
   Zheng, XW
   Zhang, YQ
AF Xiao, Ruyi
   Cui, Xinchun
   Qiao, Hong
   Zheng, Xiangwei
   Zhang, Yiquan
TI Early diagnosis model of Alzheimer's Disease based on sparse logistic
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse logistic regression; Mild cognitive impairment; Alzheimer's
   disease; MR image
ID MILD COGNITIVE IMPAIRMENT; MULTITASK FEATURE-SELECTION; CLASSIFICATION;
   MRI; PREDICTION; REPRESENTATIONS; LASSO
AB Accurate classification of Alzheimer's Disease (AD) and its prodromal stage, i.e., mild cognitive impairment (MCI) are critical for the effective treatment of AD. However, compared with AD classification tasks, predicting the conversion of MCI to AD is relatively difficult. as there are only minor differences among MCI groups. What's more, in brain imaging analysis, the high dimensionality and relatively small number of subjects brings challenges to computer-aided diagnosis of AD and MCI. Many previous researches focused on the identification of imaging biomarkers for AD diagnosis. In this paper, we introduce sparse logistic regression for the early diagnosis of AD. Sparse logistic regression (SLR) uses L(1/2)regularization to impose a sparsity constraint on logistic regression. The L(1/2)regularization is considered a representative of Lq regularization, where fewer but informative key brain regions are applied for the classification of AD/MCI. We evaluated the SLR on 197 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results showed that the SLR improves the classification performance of AD/MCI compared other classical methods.
C1 [Xiao, Ruyi; Cui, Xinchun; Zhang, Yiquan] Qufu Normal Univ, Sch Informat Sci & Engn, Rizhao 276800, Peoples R China.
   [Qiao, Hong] Shandong Normal Univ, Sch Business, Jinan 250014, Peoples R China.
   [Zheng, Xiangwei] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
C3 Qufu Normal University; Shandong Normal University; Shandong Normal
   University
RP Cui, XC (corresponding author), Qufu Normal Univ, Sch Informat Sci & Engn, Rizhao 276800, Peoples R China.
EM cuixinchun@qfnu.edu.cn
FU National Nature Science Foundation of China [71971190]; Ministry of
   Education Humanities and Social Science Project [11YJCZH021,
   15YJCZH111]; Shandong Social Science Planning Research Project
   [17CHLJ41, 16CTQJ02, 18CHLJ34]
FX This work is partially supported by National Nature Science Foundation
   of China (71971190); Ministry of Education Humanities and Social Science
   Project (11YJCZH021, 15YJCZH111). Shandong Social Science Planning
   Research Project (17CHLJ41, 16CTQJ02, 18CHLJ34).
CR Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Algamal ZY, 2015, COMPUT BIOL MED, V67, P136, DOI 10.1016/j.compbiomed.2015.10.008
   Algamal ZY, 2015, EXPERT SYST APPL, V42, P9326, DOI 10.1016/j.eswa.2015.08.016
   Ben Ahmed O, 2017, NEUROCOMPUTING, V220, P98, DOI 10.1016/j.neucom.2016.08.041
   Breheny P, 2011, ANN APPL STAT, V5, P232, DOI 10.1214/10-AOAS388
   Cai J, 2020, J MED IMAG HEALTH IN, V10, P370, DOI 10.1166/jmihi.2020.2888
   Cheng B, 2017, NEUROINFORMATICS, V15, P115, DOI 10.1007/s12021-016-9318-5
   Chowdhary C.L., 2018, Nature inspired computing, P75
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Chowdhary CL, 2016, ADV INTELL SYST, V411, P325, DOI 10.1007/978-81-322-2731-1_30
   Cui RX, 2019, COMPUT MED IMAG GRAP, V73, P1, DOI 10.1016/j.compmedimag.2019.01.005
   Dai WY, 2009, RADIOLOGY, V250, P856, DOI 10.1148/radiol.2503080751
   Del Sole A, 2008, EUR J NUCL MED MOL I, V35, P1357, DOI 10.1007/s00259-008-0773-6
   Eshkoor SA, 2015, CLIN INTERV AGING, V10, P687, DOI 10.2147/CIA.S73922
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gómez-Sancho M, 2018, MAGN RESON IMAGING, V50, P84, DOI 10.1016/j.mri.2018.03.003
   Karas G, 2007, NEURORADIOLOGY, V49, P967, DOI 10.1007/s00234-007-0269-2
   Koh KM, 2007, J MACH LEARN RES, V8, P1519
   Li F, 2015, IEEE J BIOMED HEALTH, V19, P1610, DOI 10.1109/JBHI.2015.2429556
   Liang Y, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-198
   Liu FH, 2019, IEEE T NEUR NET LEAR, V30, P765, DOI 10.1109/TNNLS.2018.2851305
   Liu F, 2014, NEUROIMAGE, V84, P466, DOI 10.1016/j.neuroimage.2013.09.015
   Liu MH, 2020, NEUROIMAGE, V208, DOI 10.1016/j.neuroimage.2019.116459
   Matsuda H, 2013, AGING DIS, V4, P29
   Meinshausen N, 2009, ANN STAT, V37, P246, DOI 10.1214/07-AOS582
   Min R, 2014, HUM BRAIN MAPP, V35, P5052, DOI 10.1002/hbm.22531
   Moradi E, 2015, NEUROIMAGE, V104, P398, DOI 10.1016/j.neuroimage.2014.10.002
   Papakostas GA, 2015, NEUROCOMPUTING, V150, P37, DOI 10.1016/j.neucom.2014.02.076
   Patterson C, 2018, The state of the art of dementia research: New frontiers World Alzheimer Report 2018
   Petersen Ronald C, 2016, Continuum (Minneap Minn), V22, P404, DOI 10.1212/CON.0000000000000313
   Qiu Z., 2016, IEEE T NEURAL NETWOR, V28, P917
   Ruiz E, 2018, J ALZHEIMERS DIS, V65, P819, DOI 10.3233/JAD-170514
   Sun LN, 2017, COMP BIOCHEM PHYS D, V22, P1, DOI 10.1016/j.cbd.2017.01.001
   Tripathy B, 2013, FRAMEWORK INTELLIGEN
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vandewater L, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/1471-2105-16-S18-S1
   Wang R, 2020, IEEE T NEUR NET LEAR, V31, P527, DOI 10.1109/TNNLS.2019.2905261
   Wang YJ, 2015, OPER RES LETT, V43, P423, DOI 10.1016/j.orl.2015.06.005
   Wee CY, 2013, HUM BRAIN MAPP, V34, P3411, DOI 10.1002/hbm.22156
   Wee CY, 2012, NEUROIMAGE, V59, P2045, DOI 10.1016/j.neuroimage.2011.10.015
   Xu ZB, 2010, SCI CHINA INFORM SCI, V53, P1159, DOI 10.1007/s11432-010-0090-0
   Ye TT, 2016, BRAIN IMAGING BEHAV, V10, P739, DOI 10.1007/s11682-015-9437-x
   Yu G, 2016, BRAIN STRUCT FUNCT, V221, P3787, DOI 10.1007/s00429-015-1132-6
   Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008
   Zhang XW, 2015, IEEE T NANOBIOSCI, V14, P237, DOI 10.1109/TNB.2015.2403274
NR 47
TC 14
Z9 15
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3969
EP 3980
DI 10.1007/s11042-020-09738-0
EA SEP 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572719800002
DA 2024-07-18
ER

PT J
AU Zhang, H
   Rong, JX
AF Zhang, Hong
   Rong, Jiexiong
TI Enhanced 3D residual network for video event recognition in shipping
   monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three-dimensional convolutional neural network; Residual network;
   Residual blocks; Video recognition
AB The three-dimensional convolutional neural network is widely used in video recognition, action recognition and other tasks because it can directly extract temporal and spatial features. Due to the large number of parameters, many computing resources, and difficulty in training, the structure of three-dimensional convolutional neural network is generally shallow. For example, the traditional C3D [17] method uses only the 11-layer VGGNet structure, and the traditional Res3D [18] method adopts a residual network of 18 and 34 layers. Some experience of two-dimensional convolutional neural network shows that the deeper the network structure is, the higher the recognition accuracy will be. Therefore, this paper proposes a new method 3D ResNet-66, which combines a 50-layer 3D residual network and four-layer residual blocks, effectively reducing the number of parameters while increasing the depth of the network, and we finally obtain a better video recognition model through experiments. We evaluate our method on shipping event datasets. Compared to the traditional C3D and Res3D method, our method has improved the accuracy from 91.48% to 96.33%, the model size has been reduced from 561 MB to 135 MB, and the average processing time has become half of the original.
C1 [Zhang, Hong; Rong, Jiexiong] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.
   [Zhang, Hong; Rong, Jiexiong] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
C3 Wuhan University of Science & Technology
RP Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.; Zhang, H (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
EM zhanghong_wust@163.com
CR Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GL, 2017, IEEE ICC
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kay W., 2017, ARXIV170506950
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Simonyan K., 2014, CORR
   Simonyan K, 2014, ADV NEUR IN, V27
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tran Du, 2017, ARXIV170805038
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P2413, DOI 10.1109/TPAMI.2020.2966453
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
NR 20
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3337
EP 3348
DI 10.1007/s11042-020-09564-4
EA SEP 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571363200001
DA 2024-07-18
ER

PT J
AU Jothiaruna, N
   Sundar, KJA
   Ahmed, MI
AF Jothiaruna, N.
   Joseph Abraham Sundar, K.
   Ifjaz Ahmed, M.
TI A disease spot segmentation method using comprehensive color feature
   with multi-resolution channel and region growing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Color spaces; Grayscale conversion; Region growing method;
   Disease spots
ID IMAGES; RECOGNITION; INFORMATION
AB The paper proposes a novel method to segment disease spots in leaves using image processing techniques. In the process of disease spot segmentation many challenges are faced such as uneven illumination and clutter background. To solve uneven illumination, color spaces and gray scale conversions are summed. Color spaces like H (hue) component of HSV, L*a*b* color spaces and Excess Red index (ExR) are used. Color to gray scale conversion is done by using weighted mulitresolution channel. Region growing method is used to solve the clutter background issues by interactively selecting growing seeds under real field conditions. Using precision, performance measure is calculated and an average segmentation accuracy of 94% is achieved.
C1 [Jothiaruna, N.; Joseph Abraham Sundar, K.; Ifjaz Ahmed, M.] SASTRA, Comp Vis & Soft Comp Lab, Sch Comp, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sundar, KJA (corresponding author), SASTRA, Comp Vis & Soft Comp Lab, Sch Comp, Thanjavur, Tamil Nadu, India.
EM kjoseph_88@yahoo.com
RI K, Joseph Abraham Sundar/E-2133-2016
OI K, Joseph Abraham Sundar/0000-0003-0342-8048
CR Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Grundland M, 2007, PATTERN RECOGN, V40, P2891, DOI 10.1016/j.patcog.2006.11.003
   Jothiaruna N, 2020, ADV INTELL SYST, V1045, P303, DOI 10.1007/978-981-15-0029-9_24
   Jothiaruna N, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P225, DOI 10.1109/iss1.2019.8908017
   Jothiaruna N, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104934
   Kim Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618507
   Lu CW, 2014, INT J COMPUT VISION, V110, P222, DOI 10.1007/s11263-014-0732-6
   Ma JC, 2017, COMPUT ELECTRON AGR, V142, P110, DOI 10.1016/j.compag.2017.08.023
   Martin M, 2019, MULTIMED TOOLS APPL, V78, P20987, DOI 10.1007/s11042-019-7445-3
   Minervini M, 2014, ECOL INFORM, V23, P35, DOI 10.1016/j.ecoinf.2013.07.004
   Olszewska JI, 2015, NEUROCOMPUTING, V161, P65, DOI 10.1016/j.neucom.2014.12.089
   Quinn M, 2019, FED CONF COMPUT SCI, P81, DOI 10.15439/2019F274
   [任守纲 Ren Shougang], 2016, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V47, P11
   Sowmya V, 2017, SIGNAL IMAGE VIDEO P, V11, P129, DOI 10.1007/s11760-016-0911-8
   Sundar KJA, 2015, DEFENCE SCI J, V65, P459, DOI 10.14429/dsj.65.8336
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034
   Wu TR, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.4.043004
   Yuan Yuan Yuan Yuan, 2013, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V44, P233
   Zhou R, 2014, COMPUT ELECTRON AGR, V108, P58, DOI 10.1016/j.compag.2014.07.004
   Zhu W, 2014, VISUAL COMPUT, V30, P299, DOI 10.1007/s00371-013-0854-9
NR 22
TC 9
Z9 9
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3327
EP 3335
DI 10.1007/s11042-020-09882-7
EA SEP 2020
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571253200011
DA 2024-07-18
ER

PT J
AU Kollem, S
   Reddy, KR
   Rao, DS
AF Kollem, Sreedhar
   Reddy, Katta Ramalinga
   Rao, Duggirala Srinivasa
TI Improved partial differential equation-based total variation approach to
   non-subsampled contourlet transform for medical image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonsubsampled contourlet transform; Power-law transform method; Adaptive
   threshold method; Partial differential equations; Directional filter
   bank; Total variation model
ID TOTAL VARIATION REGULARIZATION
AB This article proposes an improved partial differential equation (PDE)-based total variation (TV) model that enhances grey and coloured brain tumour images obtained by magnetic resonance imaging. A nonsubsampled contourlet transform was applied to images from standard databases that converted into lowpass and highpass (or bandpass) contourlet coefficients. An improved version of the power-law transform method was used on the lowpass contourlet coefficients, and an adaptive threshold method was applied to the highpass (or bandpass) contourlet coefficients. The inverse contourlet transform was performed on all the enhanced contourlet coefficients to generate a complete brain tumour image. Finally, the PDE-based TV model was applied to this image to produce the denoised image. The performance of the suggested method was calculated in terms of the peak signal-to-noise ratio, mean square error, and structural similarity index. This method achieved the best peak signal-to-noise ratio, mean square error, and structural similarity index of 77.9846 dB, 0.00012612, and 97.895%, respectively, compared to the conventional PDE+modified transform-based gamma correction, adaptive PDE+generalized cross-validation, parallel magnetic resonance imaging, and Berkeley wavelet transform+support vector machine methods.
C1 [Kollem, Sreedhar] SR Univ, Sch Engn, Dept ECE, Warangal 506371, Telangana, India.
   [Reddy, Katta Ramalinga] G Narayanamma Inst Technol & Sci, Dept ETM, Hyderabad 500104, Telangana, India.
   [Rao, Duggirala Srinivasa] JNTUH Coll Engn, Dept ECE, Hyderabad 500085, Telangana, India.
   [Kollem, Sreedhar] JNTUH Univ, Dept ECE, Hyderabad 500085, Telangana, India.
C3 Jawaharlal Nehru Technological University - Hyderabad; Jawaharlal Nehru
   Technological University - Hyderabad
RP Kollem, S (corresponding author), SR Univ, Sch Engn, Dept ECE, Warangal 506371, Telangana, India.; Kollem, S (corresponding author), JNTUH Univ, Dept ECE, Hyderabad 500085, Telangana, India.
EM ksreedhar446@gmail.com
RI Kollem, S/GQQ-3144-2022; Katta, Ramalinga Reddy/AAD-8597-2021; Kollem,
   Sreedhar/AAT-3764-2020; Kollem, S/GPT-4725-2022
OI Kollem, S/0000-0002-9203-0404; Katta, Ramalinga
   Reddy/0000-0002-4649-4187; Kollem, S/0000-0002-9203-0404
CR Asmare MH, 2015, SIGNAL IMAGE VIDEO P, V9, P1679, DOI 10.1007/s11760-014-0626-7
   Bahari A., 2017, Int. J. Polym. Sci, V2017, P1, DOI [10.1155/2017/2717848, DOI 10.1155/2017/2717848]
   Brito-Loeza C, 2016, NUMER METH PART D E, V32, P1066, DOI 10.1002/num.22042
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chen Y, 2008, J MATH IMAGING VIS, V30, P133, DOI 10.1007/s10851-007-0042-5
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kollem Sreedhar, 2019, International Journal of Machine Learning and Computing, V9, P288, DOI 10.18178/ijmlc.2019.9.3.800
   Kollem S, 2018, INT J ELECT COMP ENG, V8, P971
   Kollem S, 2020, INT J IMAG SYST TECH, V30, P1271, DOI 10.1002/ima.22429
   Kollem S, 2019, INT J IMAG SYST TECH, V29, P195, DOI 10.1002/ima.22302
   Korti A, 2018, INT J IMAG SYST TECH, V28, P92, DOI 10.1002/ima.22260
   Lahmiri S, 2017, OPT LASER TECHNOL, V90, P128, DOI 10.1016/j.optlastec.2016.11.015
   Liu J, 2018, IEEE T CIRC SYST VID, V28, P1232, DOI 10.1109/TCSVT.2016.2643009
   Liu J, 2017, IEEE T MED IMAGING, V36, P2499, DOI 10.1109/TMI.2017.2739841
   Liu XW, 2014, MATH COMPUT SIMULAT, V97, P224, DOI 10.1016/j.matcom.2013.10.001
   Meng XY, 2017, MULTIMED TOOLS APPL, V76, P17651, DOI 10.1007/s11042-015-2881-1
   Nnolim UA, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023009
   Nnolim UA, 2017, INT J IMAGE GRAPH, V17, DOI 10.1142/S0219467817500048
   Tian CS, 2019, INT J DISAST RISK RE, V39, DOI 10.1016/j.ijdrr.2019.101144
   Wang DH, 2016, INT J COMPUT MATH, V93, P942, DOI 10.1080/00207160.2015.1011144
   Wang XY, 2013, INFORM SCIENCES, V246, P155, DOI 10.1016/j.ins.2013.05.028
   Wu LN, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.053003
   Yan J, 2015, MULTIDIM SYST SIGN P, V26, P243, DOI 10.1007/s11045-013-0255-2
   Yin XR, 2019, IEEE T MED IMAGING, V38, P2903, DOI 10.1109/TMI.2019.2917258
   Zhang CJ, 2016, ENG APPL ARTIF INTEL, V48, P204, DOI 10.1016/j.engappai.2015.10.008
NR 29
TC 22
Z9 22
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2663
EP 2689
DI 10.1007/s11042-020-09745-1
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570041100003
DA 2024-07-18
ER

PT J
AU Niyishaka, P
   Bhagvati, C
AF Niyishaka, Patrick
   Bhagvati, Chakravarthy
TI Image splicing detection technique based on Illumination-Reflectance
   model and LBP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Splicing; Illumination; Reflectance; LBP; Luminance; Chrominance
AB A Copy-create digital image forgery is image tampering that merges two or more areas of images from different sources into one composite image; it is also known as image splicing. Excellent forgeries are so tricky that they are not noticeable to the naked eye and don't reveal traces of tampering to traditional image tamper detection techniques. To tackle this image splicing detection problem, machines learning-based techniques are used to instantly discriminate between the authentic and forged image. Numerous image forgery detection methods to detect and localize spliced areas in the composite image have been proposed. However, the existing methods with high detection accuracy are computationally expensive since most of them are based on hybrid feature set or rely on the complex deep learning models, which are very expensive to train, run on expensive GPUs, and require a very large amount of data to perform better. In this paper, we propose a simple and computationally efficient image splicing forgery detection that considers a trade-off between performance and the cost to the users. Our method involves the following steps: first, luminance and chrominance are found from the input image; second, illumination is estimated from Luminance using Illumination-Reflectance model; third, Local Binary Patterns normalized histogram for illumination and Chrominance is computed and used as the feature vector for classification using the following machine learning algorithms: Support Vector Machine, Linear Discriminant Analysis, Logistic Regression, K-Nearest Neighbors, Decision Tree, and Naive Bayes. Extensive experiments on the public dataset CASIA v2.0 show that the new algorithm is computationally efficient and effective for image splicing tampering detection.
C1 [Niyishaka, Patrick; Bhagvati, Chakravarthy] Univ Hyderabad, Hyderabad, Telangana, India.
C3 University of Hyderabad
RP Niyishaka, P (corresponding author), Univ Hyderabad, Hyderabad, Telangana, India.
EM niyishakapatrick@gmail.com
OI Patrick, Niyishaka/0000-0003-4200-335X
CR Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bharati A, 2016, IEEE T INF FOREN SEC, V11, P1903, DOI 10.1109/TIFS.2016.2561898
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Chen DL, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P207, DOI 10.1109/CISP-BMEI.2016.7852709
   Drira F, 2004, PROC SPIE, V5607, P165, DOI 10.1117/12.578741
   El-Latif E.I.A., 2019, Int. J. Comput. Netw. Inform. Secur, V11, P28, DOI 10.5815/ijcnis.2019.05.04
   Evgeniou T., 2001, Machine learning and its applications. Advanced lectures, P249
   Gupta B., 2017, INT J COMPUT APPL, V163, P15, DOI DOI 10.5120/IJCA2017913660
   Hakimi F, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P1074, DOI 10.1109/KBEI.2015.7436195
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Isaac MM, 2018, J INTELL FUZZY SYST, V34, P1679, DOI 10.3233/JIFS-169461
   Laaksonen J, 1996, IEEE IJCNN, P1480, DOI 10.1109/ICNN.1996.549118
   Mandeep K, 2016, P INT S SEC COMP COM
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Pham NT, 2019, MULTIMED TOOLS APPL, V78, P12405, DOI 10.1007/s11042-018-6792-9
   NIYISHAKA P, 2018, LECT NOTES COMPUTER
   NIYISHAKA P, 2020, MULTIMED TOOLS 0709
   Parihar AS, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P619, DOI 10.1109/ICISC.2018.8398874
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peng CYJ, 2002, J EDUC RES, V96, P3, DOI 10.1080/00220670209598786
   Peng Z, 2018, ARXIV180504953
   Rachna, 2019, J ENVIRON CHEM ENG, V7, DOI 10.1016/j.jece.2019.103153
   Rao Y, 2016, IEEE INT WORKS INFOR
   Rao Y, 2020, IEEE ACCESS, V8, P25611, DOI 10.1109/ACCESS.2020.2970735
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Steve E, 2013, HOMOMORPHIC FILTERIN
   Steven B, 2014, WHY LUMINANCE IS KEY
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   Thing VLL, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P290, DOI 10.1109/ISM.2012.61
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Willy W, 2020, HUMAN VISION COLOR
   Xu XK, 2013, IEEE IMAGE PROC, P4422, DOI 10.1109/ICIP.2013.6738911
   Zhang ZP, 2018, INT C PATT RECOG, P2658, DOI 10.1109/ICPR.2018.8545074
NR 37
TC 20
Z9 20
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2161
EP 2175
DI 10.1007/s11042-020-09707-7
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568478700003
DA 2024-07-18
ER

PT J
AU Hassan, N
   Ullah, S
   Bhatti, N
   Mahmood, H
   Zia, M
AF Hassan, Najmul
   Ullah, Sami
   Bhatti, Naeem
   Mahmood, Hasan
   Zia, Muhammad
TI The Retinex based improved underwater image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinex; CLAHE; Bilateral filter; Underwater images
AB The underwater images suffer from low contrast and color distortion due to variable attenuation of light and nonuniform absorption of red, green and blue components. In this paper, we propose a Retinex-based underwater image enhancement approach. First, we perform underwater image enhancement using the contrast limited adaptive histogram equalization (CLAHE), which limits the noise and enhances the contrast of the dark components of the underwater image at the cost of blurring the visual information. Then, in order to restore the distorted colors, we perform the Retinex-based enhancement of the CLAHE processed image. Next, in order to restore the distorted edges and achieve smoothing of the blurred parts of image, we perform bilateral filtering on the Retinex processed image. In order to utilize the individual strengths of CLAHE, Retinex and bilateral filtering algorithms in a single framework, we determine the suitable parameter values. The qualitative and quantitative performance comparison with some of the existing approaches shows that the proposed approach achieves better enhancement of the underwater images.
C1 [Hassan, Najmul; Ullah, Sami; Bhatti, Naeem; Mahmood, Hasan; Zia, Muhammad] Quaid I Azam Univ, Dept Elect, Islamabad 45320, Pakistan.
C3 Quaid I Azam University
RP Bhatti, N (corresponding author), Quaid I Azam Univ, Dept Elect, Islamabad 45320, Pakistan.
EM nbhatti@qau.edu.pk
RI Ullah, Sami/IAM-8005-2023
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], 2006, P CMM 06
   [Anonymous], 2017, P BRIT MACH VIS C BM
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Du WH, 2011, IEEE INT SOC CONF, P19, DOI 10.1109/SOCC.2011.6085069
   Emberton S., 2015, PROC BRIT MACH VIS C, V125, DOI 10.5244/C.29.125
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Fang S, 2013, J COMPUT, V8, P904, DOI 10.4304/jcp.8.4.904-911
   Farhadifard F, 2015, INT SYMP IMAGE SIG, P48, DOI 10.1109/ISPA.2015.7306031
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Garg D, 2018, MULTIMED TOOLS APPL, P1
   Hassan N, 2020, SIGNAL IMAGE VIDEO P, P1
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Levedahl BA, 2009, IEEE J OCEANIC ENG, V34, P656, DOI 10.1109/JOE.2009.2027798
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Liu R, IEEE T CIRC SYST VID
   Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704
   Ludvigsen M, 2007, OCEANOGRAPHY, V20, P140, DOI 10.5670/oceanog.2007.14
   Naim MJNM, 2012, APPL SOFT COMPUT, V12, P2948, DOI 10.1016/j.asoc.2012.04.028
   Ng MK, 2011, SIAM J IMAGING SCI, V4, P345, DOI 10.1137/100806588
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Paris S, 2007, SIGGRAPH ACM
   Pizer S M., 1990, VISUALIZATION BIOMED
   Schechner YY, IEEE T PATTERN ANAL, V29
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang W, 2017, VISUAL COMMUNICATION, P1
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 35
TC 30
Z9 32
U1 7
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1839
EP 1857
DI 10.1007/s11042-020-09752-2
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100012
DA 2024-07-18
ER

PT J
AU Zhang, F
   Chen, XP
   Zhang, XH
AF Zhang, Fan
   Chen, Xiaopan
   Zhang, Xinhong
TI Parallel thinning and skeletonization algorithm based on cellular
   automaton
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thinning algorithm; Skeletonization algorithm; Cellular automation;
   Parallel computation
ID SHAPE; EXTRACTION; APPEARANCE; PATTERNS
AB This paper proposes a parallel image thinning algorithm and a skeletonization algorithm based on cellular automaton (CA). Cellular automaton is a parallel computation model and a non-linear dynamical system. In this paper, each image pixel is identified as a cell of CA and the change of cell depends on the current state of itself and the state of its neighbors. In a binary image, this paper assumes that the objects (white pixel) are preys which are surrounded by many ants (every black pixels). The movement of ants is controlled by cellular automation. The ants gnaw preys until the preys (objects) become skeleton. The proposed parallel skeletonization algorithm can produce a traditional skeleton with a thin line located in the center of object, and the proposed thinning algorithm can produce a new kind of skeleton which is named as the ants-gnawing skeleton. The computation of ants-gnawing skeleton is faster than the traditional skeleton while it contains more the structural features of image. Benefiting from the properties of cellular automation, the proposed thinning algorithm does not change the basic geometry structure of image, and it is invariant for image rotation.
C1 [Zhang, Fan; Chen, Xiaopan] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Zhang, Fan] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
   [Zhang, Xinhong] Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
C3 Henan University; Henan University; Henan University
RP Chen, XP (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.; Zhang, XH (corresponding author), Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
EM zhangfan@henu.edu.cn; 10120039@vip.henu.edu.cn; zxh@henu.edu.cn
OI Zhang, Fan/0000-0003-2176-3835
FU National Key Technology Research and Development Program of China
   [2015BAK01B06]; Natural Science Foundation of Henan Province
   [162300410032]
FX This research was supported by the National Key Technology Research and
   Development Program of China (Grant No. 2015BAK01B06) and the Natural
   Science Foundation of Henan Province (Grant No. 162300410032).
CR Aslan C, 2008, IEEE T PATTERN ANAL, V30, P2188, DOI 10.1109/TPAMI.2007.70842
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Bidlo M, 2016, IEEE T EVOLUT COMPUT, V20, P742, DOI 10.1109/TEVC.2016.2516242
   BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0
   Bouaynaya N, 2006, IEEE T IMAGE PROCESS, V15, P3579, DOI 10.1109/TIP.2006.877475
   BRANDT JW, 1992, CVGIP-IMAG UNDERSTAN, V55, P329, DOI 10.1016/1049-9660(92)90030-7
   By O, 2010, PATTERN RECOGN, V28, P343
   Chang HH, 1996, OPT ENG, V35, P1003, DOI 10.1117/1.600716
   Chen PW, 2013, SIAM J IMAGING SCI, V6, P730, DOI 10.1137/12086443X
   Choi WP, 2003, PATTERN RECOGN, V36, P721, DOI 10.1016/S0031-3203(02)00098-5
   Delgado-Friedrichs O, 2015, IEEE T PATTERN ANAL, V37, P654, DOI 10.1109/TPAMI.2014.2346172
   Du HS, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.031
   Jin D, 2016, PATTERN RECOGN LETT, V76, P32, DOI 10.1016/j.patrec.2015.04.002
   Kaur I, 2016, COMMUN NONLINEAR SCI, V39, P300, DOI 10.1016/j.cnsns.2016.03.003
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013
   Lu P, 2017, OPTIK, V143, P26, DOI 10.1016/j.ijleo.2017.06.009
   Nayak D. R., 2014, IJCA P INT C EM TREN, P78
   Rosin PL, 2006, IEEE T IMAGE PROCESS, V15, P2076, DOI 10.1109/TIP.2006.877040
   Saha PK, 2016, PATTERN RECOGN LETT, V76, P3, DOI 10.1016/j.patrec.2015.04.006
   Shamir A, 2006, GRAPH MODELS, V68, P307, DOI 10.1016/j.gmod.2005.10.001
   Shen W, 2013, PATTERN RECOGN, V46, P539, DOI 10.1016/j.patcog.2012.07.023
   Suarez AJF, 2018, COMPUT AIDED DESIGN, V62, P45
   Tabedzki M, 2016, INT J AP MAT COM-POL, V26, P439, DOI 10.1515/amcs-2016-0031
   Tang C, 2008, OPT LETT, V33, P183, DOI 10.1364/OL.33.000183
   Tari ZSG, 1997, COMPUT VIS IMAGE UND, V66, P133, DOI 10.1006/cviu.1997.0612
   Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849
   Wang S, 2012, GRAPH MODELS, V74, P109, DOI 10.1016/j.gmod.2012.03.008
   Wei F, 2013, CHINESE J GEOPHYS-CH, V56, P1, DOI 10.6038/cjg20130101
   Wei R, 2017, OPTIK, V145, P407, DOI 10.1016/j.ijleo.2017.07.046
   Wieser E, 2017, MULTIMED TOOLS APPL, V76, P8285, DOI 10.1007/s11042-016-3395-1
   Wink O, 2004, IEEE T MED IMAGING, V23, P130, DOI 10.1109/TMI.2003.819920
   Wong WT, 2006, INFORM SCIENCES, V176, P1379, DOI 10.1016/j.ins.2005.04.001
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Xie WJ, 2003, PATTERN RECOGN, V36, P1529, DOI 10.1016/S0031-3203(02)00348-5
   Yasseen Z, 2016, PATTERN RECOGN, V57, P115, DOI 10.1016/j.patcog.2016.03.022
   Youssef R, 2016, PATTERN RECOGN, V57, P97, DOI 10.1016/j.patcog.2016.03.033
   Zhang F, 2015, OPTIK, V126, P3692, DOI 10.1016/j.ijleo.2015.08.189
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
   Zhu XK, 2019, NEURAL COMPUT APPL, V31, P7303, DOI 10.1007/s00521-018-3529-7
NR 42
TC 4
Z9 6
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33215
EP 33232
DI 10.1007/s11042-020-09660-5
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000006
DA 2024-07-18
ER

PT J
AU Javeed, A
   Shah, TR
   Ullah, A
AF Javeed, Adnan
   Shah, Tariq
   Ullah, Atta
TI A color image privacy scheme established on nonlinear system of coupled
   differential equations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Differential equations; Chaotic system; Image privacy; Encryption
   analysis
ID ENCRYPTION SCHEME; DYNAMICAL-SYSTEM; ALGORITHM; CHAOS; DESIGN
AB In this manuscript, an encryption technique is developed using a coupled chaotic system of differential equations. The lengthy process of recurring rounds of encryption consumes more space and time on the computing systems demands simple but yet applicable scheme of image encryption, which opens the gateway of the utilization of complex and nonlinear chaotic systems. The proposed image encryption procedure is fast as implementation is concerned because of containing only one round, furthermore, it is found resistant against any type of differential and linear attacks due to the large keyspace and involvement of complex mathematical systems. The third order nonlinearity of Rabinovich-Fabrikant (RF) system of differential equations generates rich and complex chaotic dynamics. Initially, this system is used to generate three chaotic sequences of pseudorandom numbers from the numerical solution of RF system. Then, a color image being converted into three layers is passed from three mathematical operations i.e. XOR, permutation and substitution to create confusion and diffusion in them to generate enciphered image. Moreover, encrypted images successfully passed the NIST SP-800 test and encryption analyses like correlation, histogram and information entropy etc.
C1 [Javeed, Adnan; Shah, Tariq; Ullah, Atta] Natl Univ Technol, Dept Math, Islamabad, Pakistan.
RP Ullah, A (corresponding author), Natl Univ Technol, Dept Math, Islamabad, Pakistan.
EM attaqau@gmail.com
CR Ahmad M, 2021, J KING SAUD UNIV-COM, V33, P77, DOI 10.1016/j.jksuci.2018.02.002
   Alligood K. A., 1996, Chaos: An Introduction to Dynamical Systems
   Anees A, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0059-2
   [Anonymous], 2010, Understanding Cryptography
   [Anonymous], 1985, IEEE STAND BIN FLOAT
   Asif M, 2019, J INTELL FUZZY SYST, V37, P3925, DOI 10.3233/JIFS-190137
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2015, SIGNAL PROCESS, V111, P294, DOI 10.1016/j.sigpro.2015.01.003
   Danca MF, 2017, NONLINEAR DYNAM, V88, P791, DOI 10.1007/s11071-016-3276-1
   Hussain I, 2014, OPT LASER TECHNOL, V61, P50, DOI 10.1016/j.optlastec.2014.01.018
   Hussain I, 2012, OPT COMMUN, V285, P4887, DOI 10.1016/j.optcom.2012.06.011
   Javeed A, 2020, CHINESE J PHYS, V66, P645, DOI 10.1016/j.cjph.2020.04.008
   Javeed A, 2020, WIRELESS PERS COMMUN, V112, P467, DOI 10.1007/s11277-020-07052-4
   Javeed A, 2020, MULTIMED TOOLS APPL, V79, P6649, DOI 10.1007/s11042-019-08393-4
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Moysis L, 2017, INT J SYST DYN APPL, V6, P77, DOI 10.4018/IJSDA.2017010105
   Naseer Y, 2020, MATH COMPUT SIMULAT, V178, P207, DOI 10.1016/j.matcom.2020.06.007
   Naseer Y, 2019, MICROPROCESS MICROSY, V65, P1, DOI 10.1016/j.micpro.2018.12.003
   Pareschi F, 2012, IEEE T INF FOREN SEC, V7, P491, DOI 10.1109/TIFS.2012.2185227
   RABINOVICH MI, 1979, ZH EKSP TEOR FIZ+, V77, P617
   Shah T, 2020, WIRELESS PERS COMMUN, V113, P1201, DOI 10.1007/s11277-020-07274-6
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Wang XY, 2020, MULTIMED TOOLS APPL, V79, P19005, DOI 10.1007/s11042-020-08810-z
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Waseem HM, 2020, IEEE ACCESS, V8, P71821, DOI 10.1109/ACCESS.2020.2987097
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Xie YQ, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21090819
   Yildiz MZ, 2019, IEEE ACCESS, V7, P60850, DOI 10.1109/ACCESS.2019.2914721
   You L, 2020, SOFT COMPUT, V24, P12413, DOI 10.1007/s00500-020-04683-4
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   ZENG XB, 1993, B AM METEOROL SOC, V74, P631, DOI 10.1175/1520-0477(1993)074<0631:CTAIAT>2.0.CO;2
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
NR 42
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32487
EP 32501
DI 10.1007/s11042-020-09582-2
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564978000003
DA 2024-07-18
ER

PT J
AU Tsai, CY
   Liu, TY
   Lu, YH
   Nisar, H
AF Tsai, Chi-Yi
   Liu, Ting-Yuan
   Lu, Yun-Han
   Nisar, Humaira
TI A novel interactive assembly teaching aid using multi-template augmented
   reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive teaching-aids; Multi-template tracking; 6-DoF pose tracking;
   Augmented reality
ID DESIGN
AB Augmented Reality (AR) technology is a fast growing field in the academics and industry. This paper presents a novel design of an interactive assembly teaching aid based on a multi-template AR system, which consists of three units: a multi-template AR unit, an online three-dimension (3D) model assembly unit, a hand-gesture interaction unit. The design of the multi-template AR unit employs an efficient multi-template pose tracking method to detect and track multiple template images simultaneously. The online 3D model assembly unit is enabled, when the pose of each target template is tracked and computed by the multi-template pose tracking method. This method measures the distance between the two templates to determine the 3D rendering mode of the virtual object. The third unit aims to realize a vision-based human-computer interactive system, which combines the AR rendering system with the real-time hand-gesture recognition method to decide the status of AR rendering of a 3D dynamic animation according to the user's hand gesture. Based on the feedback of twenty-one users of the AR-based interactive teaching-aid, it can be concluded that the system creates an interactive experiences that engages the users and facilitates them to increase their learning interest significantly. In future, we plan to port the proposed AR system to Android and iOS mobile devices while improving the functionality, interactivity, and entertaining qualities of the teaching aid system.
C1 [Tsai, Chi-Yi; Liu, Ting-Yuan; Lu, Yun-Han] TamKang Univ, Dept Elect & Comp Engn, 151 Yingzhuan Rd, New Taipei 251, Taiwan.
   [Nisar, Humaira] Univ Tunku Abdul Rahman, Dept Elect Engn, Jalan Univ, Kampar 31900, Perak, Malaysia.
C3 Tamkang University; Universiti Tunku Abdul Rahman (UTAR)
RP Tsai, CY (corresponding author), TamKang Univ, Dept Elect & Comp Engn, 151 Yingzhuan Rd, New Taipei 251, Taiwan.
EM chiyi_tsai@mail.tku.edu.tw; humaira@utar.edu.my
RI Nisar, Humaira/A-5188-2009; Tsai, Chi-Yi/AAT-2837-2021; Tsai,
   Chi-Yi/AFJ-8560-2022
OI Nisar, Humaira/0000-0003-2026-5666; Tsai, Chi-Yi/0000-0001-9872-4338;
   Tsai, Chi-Yi/0000-0001-9872-4338
FU Ministry of Science and Technology of Taiwan, ROC [MOST
   108-2221-E-032-046, MOST 109-2221-E-032-039]; NUWA Robotics Co., Ltd.,
   Nanjing East Road, Zhongshan District, Taipei City, Taiwan
FX This work was supported by the Ministry of Science and Technology of
   Taiwan, ROC under grant MOST 108-2221-E-032-046 and MOST
   109-2221-E-032-039 and was supported in part by NUWA Robotics Co., Ltd.,
   Nanjing East Road, Zhongshan District, Taipei City 104, Taiwan.
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2005, SPATIAL AUGMENTED RE
   Argyros AA, 2006, LECT NOTES COMPUT SC, V3979, P40
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bin Abdul Rahman NA, 2006, P MMU INT S INF COMM, P1
   Bocevska Andrijana, 2017, International Journal of Computer Science & Information Technology, V9, P141, DOI 10.5121/ijcsit.2017.9213
   Buenaposada M, 2002, INT C PATT RECOG, P697, DOI 10.1109/ICPR.2002.1048397
   do Carmo RMC, 2007, IEEE INT CONF INF VI, P156
   Chiu CD., 2010, THESIS
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Freeman W.T., 1995, International Workshop on Automatic Face- and Gesture- Recognition," in, P179
   Ghoneim A, 2018, IEEE COMMUN MAG, V56, P33, DOI 10.1109/MCOM.2018.1700817
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Ha H, 2016, LECT NOTES COMPUT SC, V9431, P447, DOI 10.1007/978-3-319-29451-3_36
   Hartley R. I., 2004, Multiple View Geometry in Computer Vision, Vsecond, P2
   Heen Chen, 2011, Proceedings of the 2011 International Symposium on Information Technology in Medicine and Education (ITME 2011), P362, DOI 10.1109/ITiME.2011.6132125
   Holzer S, 2015, INT J COMPUT VISION, V111, P12, DOI 10.1007/s11263-014-0729-1
   Ibáñez MB, 2016, IEEE T LEARN TECHNOL, V9, P46, DOI 10.1109/TLT.2015.2445761
   Ibáñez MB, 2015, IEEE T EDUC, V58, P208, DOI 10.1109/TE.2014.2379712
   Imbert N, 2013, PROCEDIA COMPUT SCI, V25, P364, DOI 10.1016/j.procs.2013.11.044
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Lei T, 2019, INT J AEROSPACE ENG, V2019, DOI 10.1155/2019/9086891
   Li Y, 2019, INT J ORAL SCI, V11, DOI 10.1038/s41368-019-0045-2
   Liu H, 2018, ADV ENERGY MATER, V8, DOI 10.1002/aenm.201701616
   Liu WL, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.7.073101]
   Andújar JM, 2011, IEEE T EDUC, V54, P492, DOI 10.1109/TE.2010.2085047
   Meena S, 2011, STUDY HAND GESTURE R
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Nugraha IE, 2017, PROCEEDINGS OF 2017 4TH INTERNATIONAL CONFERENCE ON NEW MEDIA STUDIES (CONMEDIA 2017), P32, DOI 10.1109/CONMEDIA.2017.8266027
   Rekimoto J., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P113, DOI 10.1145/503376.503397
   Rentzos L., 2013, IFAC Proc., V46, P98, DOI [DOI 10.3182/20130811-5-US-2037.00053, 10.3182/20130811-5-US-2037.00053]
   Alvarado LAR, 2018, IEEE ACCESS, V6, P57897, DOI 10.1109/ACCESS.2018.2873976
   Salman FH, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P1353, DOI 10.1109/FTC.2016.7821781
   Santos MEC, 2014, IEEE T LEARN TECHNOL, V7, P38, DOI 10.1109/TLT.2013.37
   SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P1355, DOI 10.1109/T-C.1972.223507
   Sun C, 2019, INT J SOFTW SCI COMP, V11, P38, DOI 10.4018/IJSSCI.2019040103
   Tian K, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173508
   Tsai CY, 2018, ALGORITHMS, V11, DOI 10.3390/a11080122
   Tsai CY, 2016, IET COMPUT VIS, V10, P212, DOI 10.1049/iet-cvi.2015.0137
   Urbano D, 2015, IEEE GLOB ENG EDUC C, P852, DOI 10.1109/EDUCON.2015.7096072
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 43
TC 12
Z9 14
U1 4
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31981
EP 32009
DI 10.1007/s11042-020-09584-0
EA AUG 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360100002
DA 2024-07-18
ER

PT J
AU Gokulkumari, G
AF Gokulkumari, G.
TI Analytical outlook on customer awareness towards biometrics mechanism of
   unimodal and multimodal in online transactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online transaction; Biometric system; Customer awareness; Unimodal vs;
   multimodal; Data privacy
ID SCORE LEVEL FUSION; AUTHENTICATION; FEATURES; SYSTEMS
AB The awareness of the Biometric mechanism to the customer is an essential one during online transactions. Till now, the single biometric mechanism is used in various fields like banking, forensic, etc. However, the security issues are still lagging under many aspects, which show the need for stronger security levels; thus moving to multimodal biometrics. This paper aims to investigate customer awareness of the biometric mechanism (both unimodal and multimodal) during online transactions. Initially, questionnaire preparation is done based on certain core perspectives and is distributed among customers. Once the data collection is over (responses), this work makes an analytical study based on all the four core perspectives called customer awareness, perception/feedback, unimodal vs. multimodal, and data privacy. The initial one defines how much awareness the customers have about the biometrics usage in the online transaction. The second phase defines the thought on the usage of biometrics by the customer and third is the awareness about the unimodal or multimodal biometric facility and the final one is about the privacy preservation of data using multimodal biometric. The analysis is made concerning the overall model assessment, measurement model, and structural model. The experiment is conducted on 108 samples with measurement variables 45 and latent constructs 4. The analysis shows that 93.4% of the customers have ensured the use of multimodal biometrics in the future, as well as 68.87% of customers, assured the interested in buying the online product if the multimodal biometrics facility is available. From this analysis, the statistics show that it is worth investigation on the interestingness and awareness of the consumers in implementing multimodal biometrics.
C1 [Gokulkumari, G.] Saudi Elect Univ, Coll Adm & Financial Sci, Dept E Commerce, Riyadh, Saudi Arabia.
C3 Saudi Electronic University
RP Gokulkumari, G (corresponding author), Saudi Elect Univ, Coll Adm & Financial Sci, Dept E Commerce, Riyadh, Saudi Arabia.
EM g.govindasamy@seu.edu.sa
CR Arutyunov VV, 2010, SCI TECH INF PROCESS, V37, P87, DOI 10.3103/S0147688210020012
   Chaudhry SA, 2016, MULTIMED TOOLS APPL, V75, P12705, DOI 10.1007/s11042-015-3194-0
   Chaudhry SA, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0335-y
   Chen YR, 2016, EXPERT SYST APPL, V64, P93, DOI 10.1016/j.eswa.2016.07.009
   Cui J, 2008, 2008 INTERNATIONAL CONFERENCE ON APPERCEIVING COMPUTING AND INTELLIGENCE ANALYSIS (ICACIA 2008), P66, DOI 10.1109/ICACIA.2008.4769972
   Das AK, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0027-z
   Dass SC, 2006, IEEE T PATTERN ANAL, V28, P1902, DOI 10.1109/TPAMI.2006.255
   Friedman L, 2019, IEEE T INF FOREN SEC, V14, P2528, DOI 10.1109/TIFS.2019.2904844
   Goswami G, 2016, INFORM FUSION, V32, P3, DOI 10.1016/j.inffus.2015.06.007
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   Hammad M, 2019, IEEE ACCESS, V7, P26527, DOI 10.1109/ACCESS.2018.2886573
   Höller Y, 2019, IEEE T INF FOREN SEC, V14, P459, DOI 10.1109/TIFS.2018.2854728
   Kaur H, 2019, IEEE T INF FOREN SEC, V14, P709, DOI 10.1109/TIFS.2018.2855669
   Kumar A, 2016, INFORM FUSION, V32, P49, DOI 10.1016/j.inffus.2015.09.002
   Ma Xin, 2017, Journal of China Universities of Posts and Telecommunications, V24, P34, DOI 10.1016/S1005-8885(17)60221-8
   Monwar MM, 2009, IEEE T SYST MAN CY B, V39, P867, DOI 10.1109/TSMCB.2008.2009071
   Nappi M, 2018, IMAGE VISION COMPUT, V76, P27, DOI 10.1016/j.imavis.2018.05.001
   Oloyede MO, 2016, IEEE ACCESS, V4, P7532, DOI 10.1109/ACCESS.2016.2614720
   Peng JL, 2014, OPTIK, V125, P6891, DOI 10.1016/j.ijleo.2014.07.027
   Ribaric S, 2003, IEE P-VIS IMAGE SIGN, V150, P409, DOI 10.1049/ip-vis:20031038
   Sitová Z, 2016, IEEE T INF FOREN SEC, V11, P877, DOI 10.1109/TIFS.2015.2506542
   Walia GS, 2019, EXPERT SYST APPL, V116, P364, DOI 10.1016/j.eswa.2018.08.036
   Winston JJ, 2019, SOFT COMPUT, V23, P9361, DOI 10.1007/s00500-018-3497-y
   Xin Y, 2018, IEEE ACCESS, V6, P21418, DOI 10.1109/ACCESS.2018.2815540
   Yang WC, 2015, ELECTRON LETT, V51, P234, DOI 10.1049/el.2014.4182
NR 25
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31691
EP 31714
DI 10.1007/s11042-020-09526-w
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561717800001
DA 2024-07-18
ER

PT J
AU Hamdani, M
   Belbachir, MF
AF Hamdani, Mansour
   Belbachir, Mohamed Faouzi
TI IMPROVED-SDROM filtering for scratches removal from images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection; Scratches; Restoration of old movies; Interpolation
AB This article is dedicated to the detection and correction of scratches found in old movies. The method we propose is based on the SDROM method (Signal Dependent Rank Ordered Mean) which corrects only the pixels of the detected scratches. A statistical study of the noised images by scratches shows that the amplitude difference of the neighboring pixels in an image outside the scratch is small (less than 10 Gy levels). We find that the scratch can be characterized by a high difference of amplitude of its edges pixels, we propose an approach called IMPROVED SDROM, is constituted by three stages. First for the detection of the scratches we use two neighboring sliding windows (3 x 3 pixels) sweeping the entire image. We show that Delta = m(2)-m(1)(with m(1)and m(2)the averages of the two windows), is a relevant parameter for the detection of pixels that can belong to a stripe. The average of each window is calculated after a pre-treatment. Then we locate the stripes and their widths and finally we make the correction by a simple interpolation. Unlike the SDROM method, our approach allows to locate scratches of any width, with simplicity of treatment certainly allows a gain in processing time compared to other methods that will be mentioned in what follows. A study of a set of examples of scratches obtained by simulation and also on real scratches illustrates the validity of our approach.
C1 [Hamdani, Mansour; Belbachir, Mohamed Faouzi] Univ Sci & Technol Oran Mohamed Boudiaf, Inst Elect, Lab Signals Syst & Data, Oran, Usto, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf
RP Hamdani, M (corresponding author), Univ Sci & Technol Oran Mohamed Boudiaf, Inst Elect, Lab Signals Syst & Data, Oran, Usto, Algeria.
EM Mansour_hamdani@yahoo.com; mf_belbachir@yahoo.fr
OI HAMDANI, MANSOUR/0000-0003-1544-0984
CR Abreu E, 1996, ISCAS 96: 1996 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - CIRCUITS AND SYSTEMS CONNECTING THE WORLD, VOL 2, P730, DOI 10.1109/ISCAS.1996.541829
   ABREU E, 1995, INT CONF ACOUST SPEE, P2371, DOI 10.1109/ICASSP.1995.479969
   [Anonymous], 2018, MATWORKS
   [Anonymous], 2000, GENIE MODERATION
   Archa AB, 2015, INT J ENG ADV TECHNO
   Bankar A, 2015, INT J ADV RES COMPUT, V3, P456
   Bashir I, 2017, IJCSMC, V6, P90
   Bretschneider T, 2000, P IM VIS COMP NZ, P38
   Bretshneider T, 2001, DIGITAL RESTORATION, P31
   Bruni V, 2004, INT C PATT RECOG, P827, DOI 10.1109/ICPR.2004.1333900
   CHITTARANJAN B, 2014, INT J ADV RES COMPUT, V4
   Diaz ME, 1999, MODEL BASED METHOD L
   Ferrandiere ED, 1997, THESIS
   Harathi B, 2017, ASIAN J APPL SCI TEC, V1, P61
   Hu Kun, 2017, ICAMMT IOP C SER MAT, V242
   Joyeux L, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P8, DOI 10.1109/WACV.2000.895396
   Joyeux L., 1999, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), P548, DOI DOI 10.1109/CVPR.1999.786991
   Kokaram A, 1999, SIGNAL PROCESSING CO, V1, P1548
   Kokaram A. C, 1993, THESIS
   Kokaram AC, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P245, DOI 10.1109/MMCS.1999.778303
   Ma XM, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/3610482
   Mo YW, 2020, J VASC ACCESS, V21, P602, DOI 10.1177/1129729819894090
   Moore MS, 1999, P SOC PHOTO-OPT INS, V3646, P56, DOI 10.1117/12.341102
   Moore MS, 2000, IEEE IMAGE PROC, P904, DOI 10.1109/ICIP.2000.901106
   Morris RD, 1995, THESIS
   Morris RD, 1996, P INT C 1996 IEEEXPL
   Newson A, 2014, 00927007 HAL
   PUETTER RC, 1993, P SOC PHOTO-OPT INS, V1946, P405, DOI 10.1117/12.158693
   Qingyue Z, 2009, ASIA PAC C INFORM PR
   Rosenthaler L, 1996, IMAGE COM 96 BORD FR, P1
   Sheu RK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041206
   Shih TK, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P477, DOI 10.1109/ICME.2006.262576
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Sumitra P., 2016, INT J ADV INFORM TEC, V6, P35
   Tao X., 2018, Automatic Metallic Surface Defect Detection and Recognition with Convolutional Neural Networks
   Vinayak M, 2018, P ICCASP, P927
   Vitulano D, 2002, INT C CENTR EUR COMP
   You B, DETECTION RESTORATIO
   Zhang HY, 2019, OPT EXPRESS, V27, P20910, DOI 10.1364/OE.27.020910
NR 39
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31429
EP 31449
DI 10.1007/s11042-020-09224-7
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561518100006
DA 2024-07-18
ER

PT J
AU Binsawad, M
AF Binsawad, Muhammad
TI Social media efficiency towards restaurant business: a comparison
   between social media profiles (case study in Saudi Arabia)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Correlation; Social media profiles; Social media marketing; Saudi
   Arabia; Restaurant
ID WORD-OF-MOUTH; SCALE DEVELOPMENT; PERFORMANCE; ENGAGEMENT; BEHAVIOR;
   QUALITY; TRUST; EWOM; HOSPITALITY; EXPERIENCES
AB This study mainly focuses on how social media influences the Saudi restaurant business. Undoubtedly, the modern generation is primarily influenced by social media. Several human activities are associated with and influenced by social media. Internet, specifically social media greatly influences the behavioral patterns of millions of registered Facebook, Instagram, and Twitter users. However, there is inadequate information related to the social media's impact on the restaurant business. Fashion, entertainment, and eating patterns are some of the forms that are highly vulnerable to social media. This research specifically analyzed the success of restaurant businesses in Saudi Arabia due to social media. The data was collected through an online search where social media profiles for five restaurants in Saudi Arabia were analyzed. The findings from these social media profiles were associated to the evidence in the literature review. Relevant recommendations and limitations of the study project are provided. It concluded that when used correctly, social media positively impacts the performance and profitability of the restaurant business in Saudi Arabia.
C1 [Binsawad, Muhammad] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Informat Syst, Jeddah, Saudi Arabia.
C3 King Abdulaziz University
RP Binsawad, M (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Informat Syst, Jeddah, Saudi Arabia.
EM Mbinsawad@kau.edu.sa
RI Binsawad, Muhammad/AAT-4028-2021
CR Ainin S, 2015, IND MANAGE DATA SYST, V115, P570, DOI 10.1108/IMDS-07-2014-0205
   Alnsour M, 2019, J INT FOOD AGRIBUSIN, V17, P1
   Ashley C, 2015, PSYCHOL MARKET, V32, P15, DOI 10.1002/mar.20761
   Baxter S, 2014, AM J HEALTH PROMOT, V28, P347, DOI 10.4278/ajhp.130731-LIT-395
   BILAL G., 2014, International Journal of Multidisciplinary Sciences and Engineering, V5, P1
   Bilgihan A, 2016, TOURISM MANAGE, V52, P287, DOI 10.1016/j.tourman.2015.07.002
   Boulianne S, 2015, INFORM COMMUN SOC, V18, P524, DOI 10.1080/1369118X.2015.1008542
   Büschken J, 2016, MARKET SCI, V35, P953, DOI 10.1287/mksc.2016.0993
   Chang SE, 2016, J BUS RES, V69, P4890, DOI 10.1016/j.jbusres.2016.04.048
   Comi A, 2014, QUAL RES ORGAN MANAG, V9, P110, DOI 10.1108/QROM-05-2012-1074
   Dijkmans C, 2015, TOURISM MANAGE, V47, P58, DOI 10.1016/j.tourman.2014.09.005
   Durkin M, 2013, J SMALL BUS ENTERP D, V20, P716, DOI 10.1108/JSBED-08-2012-0094
   Effing R, 2016, INT J INFORM MANAGE, V36, P1, DOI 10.1016/j.ijinfomgt.2015.07.009
   Engler TH, 2015, J RETAIL CONSUM SERV, V27, P113, DOI 10.1016/j.jretconser.2015.07.010
   Farook F., 2016, International Journal of Business and Management Invention, V5, P115
   Floreddu PB, 2014, BUS HORIZONS, V57, P737, DOI 10.1016/j.bushor.2014.07.007
   Guesalaga R, 2016, IND MARKET MANAG, V54, P71, DOI 10.1016/j.indmarman.2015.12.002
   Habibi MR, 2014, COMPUT HUM BEHAV, V37, P152, DOI 10.1016/j.chb.2014.04.016
   Holland P, 2016, INT J HUM RESOUR MAN, V27, P2621, DOI 10.1080/09585192.2016.1227867
   Hollebeek LD, 2014, J INTERACT MARK, V28, P149, DOI 10.1016/j.intmar.2013.12.002
   Hudson S, 2015, TOURISM MANAGE, V47, P68, DOI 10.1016/j.tourman.2014.09.001
   Jussila JJ, 2014, COMPUT HUM BEHAV, V30, P606, DOI 10.1016/j.chb.2013.07.047
   Karapanos E, 2016, COMPUT HUM BEHAV, V55, P888, DOI 10.1016/j.chb.2015.10.015
   Karnowski V, 2014, TELEMAT INFORM, V31, P184, DOI 10.1016/j.tele.2013.11.001
   Kim AJ, 2016, COMPUT HUM BEHAV, V58, P98, DOI 10.1016/j.chb.2015.12.047
   Kim D, 2019, SERV BUS, V13, P25, DOI 10.1007/s11628-018-0367-8
   Kim D, 2015, INT J CONTEMP HOSP M, V27, P261, DOI 10.1108/IJCHM-06-2013-0269
   Kohli C, 2015, BUS HORIZONS, V58, P35, DOI 10.1016/j.bushor.2014.08.004
   Kwahk KY, 2017, SERV BUS, V11, P803, DOI 10.1007/s11628-016-0331-4
   Kwok L, 2013, CORNELL HOSP Q, V54, P84, DOI 10.1177/1938965512458360
   Lau KN, TEXT MINING HOTEL IN
   Leung XY, 2015, J HOSP TOUR RES, V39, P147, DOI 10.1177/1096348012471381
   Litvin SW, 2008, TOURISM MANAGE, V29, P458, DOI 10.1016/j.tourman.2007.05.011
   Litvin SW, 2018, INT J CONTEMP HOSP M, V30, P313, DOI 10.1108/IJCHM-08-2016-0461
   Munar AM, 2014, TOURISM MANAGE, V43, P46, DOI 10.1016/j.tourman.2014.01.012
   Nisar TM, 2016, COMPUT HUM BEHAV, V62, P743, DOI 10.1016/j.chb.2016.04.042
   Parveen F, 2015, TELEMAT INFORM, V32, P67, DOI 10.1016/j.tele.2014.03.001
   Pookulangara S, 2011, J RETAIL CONSUM SERV, V11, P348, DOI 10.1016/j.jretconser.2011.03.003
   Rapp A, 2013, J ACAD MARKET SCI, V41, P547, DOI 10.1007/s11747-013-0326-9
   Ryschka AM, 2016, INT J HOSP TOUR ADM, V17, P198, DOI 10.1080/15256480.2015.1130671
   Schivinsky B., 2014, Journal of Marketing Communications, DOI [10.1080/13527266.2013.871323, DOI 10.1080/13527266.2013.871323]
   Schniederjans D, 2013, DECIS SUPPORT SYST, V55, P911, DOI 10.1016/j.dss.2012.12.027
   Cantallops AS, 2014, INT J HOSP MANAG, V36, P41, DOI 10.1016/j.ijhm.2013.08.007
   Shan Y, 2016, COMPUT HUM BEHAV, V55, P633, DOI 10.1016/j.chb.2015.10.013
   Siamagka NT, 2015, IND MARKET MANAG, V51, P89, DOI 10.1016/j.indmarman.2015.05.005
   Sparks BA, 2016, TOURISM MANAGE, V53, P74, DOI 10.1016/j.tourman.2015.09.011
   Subakti A.G., 2013, BINUS BUSINESS REV, V4, P290
   Szwajca D, 2017, FOUND MANAGE, V9, P161, DOI 10.1515/fman-2017-0013
   Trainor KJ, 2014, J BUS RES, V67, P1201, DOI 10.1016/j.jbusres.2013.05.002
   Walden J, 2018, CORP COMMUN, V23, P423, DOI 10.1108/CCIJ-06-2017-0057
   Walsh G, 2017, J PRODUCT BRAND MANA
   Walsh G, 2016, J INTERACT MARK, V36, P46, DOI 10.1016/j.intmar.2016.05.001
   Xie KL, 2014, INT J HOSP MANAG, V43, P1, DOI 10.1016/j.ijhm.2014.07.007
   Zhang TT, 2017, INT J CONTEMP HOSP M, V29, P732, DOI [10.1108/IJCHM-10-2015-0611, 10.1108/ijchm-10-2015-0611]
NR 54
TC 5
Z9 5
U1 10
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31389
EP 31399
DI 10.1007/s11042-020-09620-z
EA AUG 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561259400006
DA 2024-07-18
ER

PT J
AU Lai, XS
   Zhou, YR
AF Lai, Xinsheng
   Zhou, Yuren
TI Analysis of multiobjective evolutionary algorithms on the biobjective
   traveling salesman problem (1,2)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiobjective evolutionary algorithm; Multiobjective traveling salesman
   problem; Approximation algorithm; Population diversity; Combinatorial
   optimization problem
ID EXPECTED RUNTIMES; CROSSOVER
AB Multiobjective evolutionary algorithms have been successfully used to deal with multiobjective combinatorial optimization problems for more than two decades. However, we know little about the performance of multiobjective evolutionary algorithms on multiobjective combinatorial optimization problems in theory so far, especially on NP-hard ones from real-world, since Pareto curves are often of exponential size, meanwhile, evolutionary algorithms rely heavily on the use of randomness and are hard to understand from a theoretical point of view. In this paper, we theoretically investigate the performance of two simple multiobjective evolutionary algorithms with different population diversity mechanisms on the biobjective traveling salesman problem (1,2). It is found that one of them can efficiently find a 3/2-approximation Pareto curve for the problem, the best result so far. At the same time, these two multiobjective evolutionary algorithms are proved to be superior to a multiobjective local search algorithm, and the multiobjective local search algorithm is also proven to outperform these two multiobjective evolutionary algorithms as well. Finally, the population diversity is proved to be helpful in reducing the expected runtime of multiobjective evolutionary algorithm.
C1 [Lai, Xinsheng] Shaoxing Univ, Sch Comp Sci & Engn, Shaoxing 312000, Zhejiang, Peoples R China.
   [Zhou, Yuren] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.
C3 Shaoxing University; Sun Yat Sen University
RP Lai, XS (corresponding author), Shaoxing Univ, Sch Comp Sci & Engn, Shaoxing 312000, Zhejiang, Peoples R China.
EM xsl2001_jx@163.com
FU National Natural Science Foundation of China [61562071, 61773410]
FX The authors are very grateful to the anonymous referees and editors for
   their valuable suggestions and comments, which have helped to improve
   the paper greatly. The authors also thank Qing Yan, Xiaoyun Xia and
   Langping Tang for their help in revising this manuscript. This work was
   supported by National Natural Science Foundation of China (Nos.
   61562071, 61773410).
CR Angel E, 2005, LECT NOTES COMPUT SC, V3623, P329, DOI 10.1007/11537311_29
   Angel E, 2004, THEOR COMPUT SCI, V310, P135, DOI 10.1016/S0304-3975(03)00376-1
   Nguyen AQ, 2015, THEOR COMPUT SCI, V561, P24, DOI 10.1016/j.tcs.2014.06.023
   Chen TS, 2012, THEOR COMPUT SCI, V436, P54, DOI 10.1016/j.tcs.2011.02.016
   Diakonikolas I., 2011, THESIS
   Doerr B, 2016, GECCO'16: PROCEEDINGS OF THE 2016 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P557, DOI 10.1145/2908812.2908827
   Doerr B, 2011, EVOL COMPUT, V19, P673, DOI 10.1162/EVCO_a_00047
   Droste S, 2002, THEOR COMPUT SCI, V276, P51, DOI 10.1016/S0304-3975(01)00182-7
   Friedrich T, 2010, EVOL COMPUT, V18, P617, DOI 10.1162/EVCO_a_00003
   Gao W, 2014, GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P777, DOI 10.1145/2576768.2598251
   Giel O, 2003, IEEE C EVOL COMPUTAT, P1918
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P544, DOI 10.1109/TGRS.2015.2461653
   He J, 2001, ARTIF INTELL, V127, P57, DOI 10.1016/S0004-3702(01)00058-3
   He J, 2013, IEEE T EVOLUTION COM, V21, P426
   Horoba C, 2009, FOGA'09: PROCEEDINGS OF THE 10TH ACM SIGRVO CONFERENCE ON FOUNDATIONS OF GENETIC ALGORITHMS, P113
   Huang ZX, 2019, AAAI CONF ARTIF INTE, P2296
   Jansen T, 2002, ALGORITHMICA, V34, P47, DOI 10.1007/s00453-002-0940-2
   Jun He, 2004, Natural Computing, V3, P21, DOI 10.1023/B:NACO.0000023417.31393.c7
   Karp R. M, 1972, COMPLEXITY COMPUTER
   Kötzing T, 2012, SWARM INTELL-US, V6, P1, DOI 10.1007/s11721-011-0059-7
   Kumar R, 2005, LECT NOTES COMPUT SC, V3469, P112
   Laumanns M, 2004, IEEE T EVOLUT COMPUT, V8, P170, DOI 10.1109/TEVC.2004.823470
   Laumanns M., 2002, Parallel Problem Solving from Nature - PPSN VII. 7th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2439), P44
   Laumanns Marco, 2004, Natural Computing, V3, P37, DOI 10.1023/B:NACO.0000023415.22052.55
   Li L, 2014, IEEE T EVOLUT COMPUT, V18, P827, DOI 10.1109/TEVC.2013.2287153
   Li YL, 2016, IEEE T EVOLUT COMPUT, V20, P563, DOI 10.1109/TEVC.2015.2501315
   Manthey B., 2009, Proceedings of 26th Annual Symposium on Theoretical Aspects of Computer Science, volume 09001 of Dagstuhl Seminar Proceedings, V09001, P637
   Meer K, 2007, INFORM PROCESS LETT, V104, P216, DOI 10.1016/j.ipl.2007.06.016
   Neumann F, 2007, EUR J OPER RES, V181, P1620, DOI 10.1016/j.ejor.2006.08.005
   Neumann F, 2010, LECT NOTES COMPUT SC, V6238, P667, DOI 10.1007/978-3-642-15844-5_67
   Oliveto PS, 2014, LECT NOTES COMPUT SC, V8672, P932
   Osuna EC, 2019, EVOL COMPUT, V27, P403, DOI 10.1162/evco_a_00225
   Qian C, 2013, ARTIF INTELL, V204, P99, DOI 10.1016/j.artint.2013.09.002
   Scharnow J., 2005, J MATH MODELLING ALG, V3, P349, DOI [10 . 1007 / s10852 - 005 - 2584 - 0, DOI 10.1007/S10852-005-2584-0, DOI 10.1023/B:JMMA.0000049379.14872.F5]
   Shi JC, 2017, IEEE C EVOL COMPUTAT, P2488, DOI 10.1109/CEC.2017.7969607
   Witt C, 2005, LECT NOTES COMPUT SC, V3404, P44
   Yu Y, 2012, ARTIF INTELL, V180, P20, DOI 10.1016/j.artint.2012.01.001
   Zhou YR, 2009, ARTIF INTELL, V173, P240, DOI 10.1016/j.artint.2008.11.002
NR 38
TC 39
Z9 39
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30839
EP 30860
DI 10.1007/s11042-020-09399-z
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300009
DA 2024-07-18
ER

PT J
AU Nogueira, TDC
   Vinhal, CDN
   da Cruz, G
   Ullmann, MRD
AF Nogueira, Tiago do Carmo
   Vinhal, Cassio Dener Noronha
   da Cruz Junior, Gelson
   Ullmann, Matheus Rudolfo Diedrich
TI Reference-based model using multimodal gated recurrent units for image
   captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gated recurrent units; Caption generation references; Convolutional
   neural network
ID ATTENTION; LSTM; NETWORK
AB Describing images through natural language is a challenging task in the field of computer vision. Image captioning consists of creating image descriptions that can be accomplished via deep learning architectures that use convolutional neural networks (CNNs) and recurrent neural networks (RNNs). However, traditional RNNs encounter problems such as exploding and vanishing gradients, and they exhibit poor performance when generating non-descriptive sentences. To solve these issues, we proposed a model based on the encoder-decoder structure using CNNs to extract the image features and multimodal gated recurrent units (GRU) for descriptions. This model implements the part-of-speech (PoS) and likelihood function for weight generation in the GRU. The method performs knowledge transfer during a validation phase that uses the k-nearest neighbors technique (kNN). Experimental results using the Flickr30k and MSCOCO datasets demonstrated that the proposed PoS-based model presents competitive scores in comparison to state-of-the-art models. The system predicts more descriptive captions and closely approximates the expected captions both in the predicted andkNN selected captions.
C1 [Nogueira, Tiago do Carmo; Vinhal, Cassio Dener Noronha; da Cruz Junior, Gelson; Ullmann, Matheus Rudolfo Diedrich] Fed Univ Goias UFG, Sch Elect Mech & Comp Engn EMC, Goiania, Go, Brazil.
C3 Universidade Federal de Goias
RP Nogueira, TDC (corresponding author), Fed Univ Goias UFG, Sch Elect Mech & Comp Engn EMC, Goiania, Go, Brazil.
EM tiago.nogueira@ifbaiano.edu.br; vinhal@ufg.br; gcruzjr@ufg.br;
   matheusullmann@gmail.com
RI Nogueira, Tiago TCN/R-9573-2018
OI Cruz Jr., Gelson/0000-0002-8130-8087
CR Al-Muzaini HA, 2018, AUTOMATIC ARABIC IMA, V9
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   [Anonymous], 2017, CSCW17 P 2017 ACM C, DOI DOI 10.1145/2998181.2998295
   [Anonymous], 2019, KYBERNETES 1202, DOI DOI 10.1108/K-07-2019-0508
   [Anonymous], 2019, 2019 IEEE INT C IND
   [Anonymous], 2005, I CONF VLSI DESIGN
   Barratt S, 2018, ARXIV180101973
   Chang YS, 2018, MULTIMED TOOLS APPL, V77, P2959, DOI 10.1007/s11042-017-4593-1
   Chen X, 2015, CORR, V1504, P325
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Chung JY, 2015, PR MACH LEARN RES, V37, P2067
   Chung Junyoung, 2014, ARXIV14123555
   Deshpande A, 2019, PROC CVPR IEEE, P10687, DOI 10.1109/CVPR.2019.01095
   Devlin J, 2015, ARXIV150504467
   Ding G, 2018, COGNITIVE COMPUTATIO, P1
   Dognin P, 2019, ICLR 2019 WORKSH DEE
   Fakoor R, 2016, ARXIV161102261
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gao LZ, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P225, DOI 10.1145/3195106.3195114
   He C, 2019, NEURAL PROCESS LETT, V49, P177, DOI 10.1007/s11063-018-9807-7
   He X, 2017, FORCE SAVING FORMING
   He XW, 2019, NEUROCOMPUTING, V328, P48, DOI 10.1016/j.neucom.2018.02.106
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Lavie A., 2007, P 2 WORKSH STAT MACH, P228
   Li L, 2017, 31 AAAI C ART INT
   Li SH, 2017, IET COMPUT VIS, V11, P104, DOI 10.1049/iet-cvi.2015.0473
   Li XL, 2018, MULTIMED TOOLS APPL, V77, P29847, DOI 10.1007/s11042-018-5856-1
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Nakashima K, 2018, IEEE SYS MAN CYBERN, P2122, DOI 10.1109/SMC.2018.00365
   Nezami OM, 2019, PAC RIM INT C ART IN, P270
   Peng YQ, 2019, IMAGE VISION COMPUT, V86, P38, DOI 10.1016/j.imavis.2019.03.003
   Qu ZW, 2019, CMC-COMPUT MATER CON, V59, P575, DOI 10.32604/cmc.2019.05569
   Rashtchian C, 2010, P NAACL HLT 2010 WOR, P139
   Ravanelli M, 2018, IEEE T EM TOP COMP I, V2, P92, DOI 10.1109/TETCI.2017.2762739
   Sharma G, 2019, 2 INT C ADV SCI TECH
   Shi Y, 2020, NEUROCOMPUTING, P22071
   Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI DOI 10.1162/TACL_A_00177
   Song JK, 2018, AAAI CONF ARTIF INTE, P394
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan YH, 2019, NEUROCOMPUTING, V333, P86, DOI 10.1016/j.neucom.2018.12.026
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wei W, 2019, ARXIV190902489
   Wu C, 2020, MULTIMEDIA TOOLS APP, P1
   Wu L, 2009, P 18 INT C WORLD WID, P361
   Yuan AH, 2019, NEUROCOMPUTING, V330, P17, DOI 10.1016/j.neucom.2018.10.059
   Zheng J, 2019, ARXIV190606632
   Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P305, DOI 10.1145/3126686.3126717
   Zhu WH, 2019, IEEE ACCESS, V7, P51810, DOI 10.1109/ACCESS.2019.2911983
   Zou FY, 2019, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2019.01138
NR 54
TC 16
Z9 16
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30615
EP 30635
DI 10.1007/s11042-020-09539-5
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900004
DA 2024-07-18
ER

PT J
AU Li, JY
   Zhang, CZ
AF Li, Jing-You
   Zhang, Chao-Zhu
TI Blind watermarking scheme based on Schur decomposition and
   non-subsampled contourlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking scheme; Schur decomposition; Non-subsampled
   contourlet transform; Logistic map; Arnold transform
ID DISCRETE WAVELET TRANSFORM; IMAGE WATERMARKING; DWT-SVD; ROBUST;
   ALGORITHM; SECURE; DCT; DOMAIN; HYBRID
AB An invisibility and blind watermarking algorithm based on Schur decomposition and non-subsampled contourlet transform is designed to protect copyright. The cover image is decomposed by the non-subsampled contourlet transform. And the low pass sub-band of the non-subsampled contourlet transform is divided into 8 x 8 non-overlapping blocks. Then each block is performed by the Schur decomposition and the watermark information is embedded by modifying the largest energy element in the Schur domain. Before embedding into the cover image, the original watermark is scrambled with logistic map and Arnold transform to ensure the security. Besides, a synchronization mechanism based on scale invariant feature transform is designed for resisting geometrical attacks. The proposed watermarking algorithm is evaluated with structural similarity index, peak signal to noise ratio and bit error rate. Experimental results demonstrate that the proposed watermarking scheme performs better in terms of invisibility, robustness and payload than other similar schemes.
C1 [Li, Jing-You; Zhang, Chao-Zhu] Harbin Engn Univ, Sch Informat & Commun Engn, Harbin 150001, Peoples R China.
   [Li, Jing-You] Qiqihar Univ, Sch Commun & Elect Engn, Qiqihar 161006, Peoples R China.
C3 Harbin Engineering University; Qiqihar University
RP Li, JY (corresponding author), Harbin Engn Univ, Sch Informat & Commun Engn, Harbin 150001, Peoples R China.; Li, JY (corresponding author), Qiqihar Univ, Sch Commun & Elect Engn, Qiqihar 161006, Peoples R China.
EM lijingyou99@163.com; zhangchaozhu@hrbeu.edu.cn
FU National Natural Science Foundation of China [61172159]; Research
   Foundation of the Education Department of Heilongjiang Province
   [12531767, 12541872]
FX This work is supported by the National Natural Science Foundation of
   China (grant no. 61172159), and the Research Foundation of the Education
   Department of Heilongjiang Province (grant nos. 12531767 and 12541872).
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Chang TJ, 2019, MULTIMED TOOLS APPL, V78, P9169, DOI 10.1007/s11042-018-6505-4
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Fan D, 2019, MULTIMED TOOLS APPL, V78, P8981, DOI 10.1007/s11042-018-7140-9
   Guo Y, 2016, IET IMAGE PROCESS, V10, P773, DOI 10.1049/iet-ipr.2015.0818
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P2469, DOI 10.1007/s11042-013-1561-2
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Khalifa mal, 2012, INT J COMPUTER APPL, V37, P33, DOI DOI 10.5120/4631-6666
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu F, 2018, MULTIMED TOOLS APPL, V77, P23483, DOI 10.1007/s11042-018-5652-y
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Parah SA, 2018, NONLINEAR DYNAM, V93, P1933, DOI 10.1007/s11071-018-4299-6
   Rosin DP, 2015, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-319-13578-6
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Sun S., 2015, Journal of Information Hiding and Multimedia Signal Processing, V6, P889
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   WEI SR, 2017, J INFORM HIDING MULT, V8, P1029, DOI DOI 10.1109/TSTE.2016.2646061
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
   Zhou Y, 2012, IET IMAGE PROCESS, V6, P1136, DOI 10.1049/iet-ipr.2012.0148
NR 43
TC 12
Z9 12
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 30007
EP 30021
DI 10.1007/s11042-020-09389-1
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559430400008
DA 2024-07-18
ER

PT J
AU Singh, VK
   Kumar, N
   Singh, N
AF Singh, Vivek Kumar
   Kumar, Nitin
   Singh, Navjot
TI A hybrid approach using color spatial variance and novel object position
   prior for salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixel; K-means; Gaussian mixture model (GMM); Color spatial
   variance; Saliency map
ID VISUAL-ATTENTION; MODEL
AB Salient object detection in a real-time environment demands high accuracy with less computation time. It is a changeling task to investigate a saliency model which improves saliency detection accuracy as well as reduces computation time. In this paper, we propose a hybrid model that improves detection accuracy with low computational time. The input image is simplified and clustered at multiple scales using SLIC and K-means clustering algorithms respectively. Gaussian Mixture Model (GMM) is developed on various color components of the digital image at multiple scales. The parameters of GMM are learnt using Expectation Maximization (EM) algorithm. The spatial variance of each color component is determined using GMM parameters and hence object position is estimated. Further, spatial variance of color components and object position is exploited to compute saliency map at a scale level. Afterwards, all the saliency maps generated across various scales are linearly combined to produce the final saliency map. The performance of the proposed model is compared in terms of Precision, Recall, F-Measure, Area under the Curve (AUC), Receiver Operating Characteristics (ROC) and Mean Absolute Error (MAE). Extensive experiments on six publicly available datasets viz. MSRA10K, DUT-OMRON, ECSSD, PASCAL-S, SED2, and THUR15K show that the proposed model outperforms or comparable against 11 state-of-the-art methods of the last decade. The key features of the proposed method are object completeness and efficiency in terms of computational time.
C1 [Singh, Vivek Kumar; Kumar, Nitin] Natl Inst Technol Uttarakhand, Srinagar, Uttarakhand, India.
   [Singh, Navjot] Motilal Nehru Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand; National Institute of Technology (NIT System);
   Motilal Nehru National Institute of Technology
RP Singh, VK (corresponding author), Natl Inst Technol Uttarakhand, Srinagar, Uttarakhand, India.
EM vivek.kumarsingh@nituk.ac.in; nitin@nituk.ac.in;
   navjot.singh.09@gmail.com
RI Singh, Navjot/I-5444-2017
OI Singh, Navjot/0000-0003-0409-8482
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007, PROC CVPR IEEE, P359
   [Anonymous], 2010, 149300 EPFL
   [Anonymous], 2007, P C NEUR INF PROC SY
   [Anonymous], 2012, Technical Report
   [Anonymous], 2013, CHRON INFL MOL PATH
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cho YS, 2011, ACTA HORTIC, P249
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang H., 2013, SALIENT OBJECT DETEC
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Kumar N, 2018, MULTIMED TOOLS APPL, V77, P19139, DOI 10.1007/s11042-017-5329-y
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu GH, 2019, IEEE T IMAGE PROCESS, V28, P6, DOI 10.1109/TIP.2018.2847422
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P33, DOI 10.1007/978-3-642-14267-3_2
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Marat Sophie, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1784
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ren Z., 2010, Proceedings of the 18th ACM international conference on Multimedia, P1099
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Singh N, 2017, MULTIMED TOOLS APPL, V76, P10521, DOI 10.1007/s11042-016-3676-8
   Singh N, 2016, DIGIT SIGNAL PROCESS, V55, P22, DOI 10.1016/j.dsp.2016.05.003
   Singh Nirbhay N, 2020, Mindfulness (N Y), V11, P99, DOI 10.1007/s12671-018-0895-2
   Snowden RJ, 2002, PSYCHOL SCI, V13, P180, DOI 10.1111/1467-9280.00433
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zeng Y, 2018, IEEE T IMAGE PROCESS, V27, P4545, DOI 10.1109/TIP.2018.2838761
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang W, 2010, IEEE T MULTIMEDIA, V12, P300, DOI 10.1109/TMM.2010.2047607
NR 56
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 30045
EP 30067
DI 10.1007/s11042-020-09467-4
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559430400011
DA 2024-07-18
ER

PT J
AU García-Lucas, D
   Cebrián-Márquez, G
   Cuenca, P
AF Garcia-Lucas, D.
   Cebrian-Marquez, G.
   Cuenca, P.
TI Rate-distortion/complexity analysis of HEVC, VVC and AV1 video codecs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; VVC; AV1; Computational time; Coding efficiency
AB With the advent of smartphones and tablets, the amount of online video traffic has increased enormously. This, together with the growing popularity of high-definition video, motivated the development of the High Efficiency Video Coding (HEVC) standard, released in 2013, with the aim of achieving a 50% bitrate reduction with respect to its predecessor, namely H.264/MPEG-4 Advanced Video Coding (AVC). However, new contents with greater resolutions and requirements arise every day, making it necessary to reduce the bitrate to a further extent. In this regard, the efforts to become the leading video codec in the market resulted in two main contenders: the Joint Video Experts Team (JVET), which leads the development of the Versatile Video Coding (VVC) standard, and the Alliance for Open Media (AOMedia), which spearheads the AOMedia Video 1 (AV1) project. In this context, this paper presents a rate-distortion/complexity analysis of HEVC, VVC and AV1 main video codecs using objective measures of assessment in order to analyze their real capabilities. The analysis, which was done using well-defined test conditions, reveals that VVC considerably outperforms both HEVC and AV1 in terms of coding efficiency.
C1 [Garcia-Lucas, D.; Cuenca, P.] Univ Castilla La Mancha, High Performance Networks & Architectures Grp, Albacete, Spain.
   [Cebrian-Marquez, G.] Univ Politecn Madrid, Escuela Tecn Super Ingenieros Informat, Madrid, Spain.
C3 Universidad de Castilla-La Mancha; Universidad Politecnica de Madrid
RP García-Lucas, D (corresponding author), Univ Castilla La Mancha, High Performance Networks & Architectures Grp, Albacete, Spain.
EM David.GarciaLucas@uclm.es; gabriel.cebrian@upm.es; Pedro.Cuenca@uclm.es
RI Márquez, Gabriel Cebrián/Q-6541-2017; Cuenca, Pedro/P-7960-2019
OI Márquez, Gabriel Cebrián/0000-0002-6510-7517; Cuenca,
   Pedro/0000-0002-2791-0165; Garcia Lucas, David/0000-0001-6934-1901
FU Spanish Ministry of Science, Innovation and Universities; European
   Commission (FEDER funds) [RTI2018-098156-B-C52]; Regional Government of
   Castilla-La Mancha [SBPLY/17/180501/000353]; Spanish Ministry of
   Education, Culture and Sports [FPU16/05692]
FX This work was supported by the Spanish Ministry of Science, Innovation
   and Universities, and the European Commission (FEDER funds) under
   project RTI2018-098156-B-C52, by the Regional Government of Castilla-La
   Mancha under project SBPLY/17/180501/000353, and by the Spanish Ministry
   of Education, Culture and Sports under grant FPU16/05692.
CR [Anonymous], 2016, 2016 PICTURE CODING
   [Anonymous], 2008, VCEGAI11 ITUT
   [Anonymous], 2017, JVETH1002
   [Anonymous], 2001, ITU T VCEG M AUST TE
   [Anonymous], 2008, Subjective video quality assessment methods for multimedia applications. Recommendation P.910
   AOMedia, 2019, AV1 BITSTR DEC PROC
   Bjontegaard G, 2016, IEEE DATA COMPR CONF, P476, DOI 10.1109/DCC.2016.74
   Chen J., 2018, JVETK1002
   Chen Y, 2018, INT SYM COMPUT INTEL, P41, DOI 10.1109/ISCID.2018.00016
   García-Lucas D, 2017, J SUPERCOMPUT, V73, P495, DOI 10.1007/s11227-016-1895-4
   Google, 2013, VP9 BITSTR DEC PROC
   Grois D., 2018, SPIE P APPL DIGITAL, V10396
   Grois D, 2014, PROC SPIE, V9217, DOI 10.1117/12.2073323
   ISO/IEC ITU-T, 2013, 230082 ISOIEC ITUT
   ISO/IEC ITU-T, 2003, 1449610 ISOIEC ITUT
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Rerábek M, 2014, PROC SPIE, V9217, DOI 10.1117/12.2065561
   Suehring K, 2017, JVETH1010
   Sullivan GJ, 2012, JVETH0012
   Topiwala P, 2018, PROC SPIE, V10752, DOI 10.1117/12.2322024
   Nguyen T, 2018, PICT COD SYMP, P31, DOI 10.1109/PCS.2018.8456289
   Valin JM, 2016, IEEE IMAGE PROC, P76, DOI 10.1109/ICIP.2016.7532322
NR 22
TC 13
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29621
EP 29638
DI 10.1007/s11042-020-09453-w
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300009
DA 2024-07-18
ER

PT J
AU Zuo, JH
   Jia, ZH
   Yang, J
   Kasabov, N
AF Zuo, Junhui
   Jia, Zhenhong
   Yang, Jie
   Kasabov, Nikola
TI Moving object detection in video sequence images based on an improved
   visual background extraction algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; Visual background extraction; Ghost removal;
   Dynamic background; Edge detection
AB Visual background extraction is a method for detecting moving objects in video sequence images. In the traditional visual background extraction algorithm, ghost phenomena and dynamic background interference exist in the detection results. In order to speed up ghost removal and suppress the interference of dynamic background, an improved visual background extraction algorithm is proposed. In this method, secondary judgment is added to eliminate ghost pixel interference in the process of spatial transmission of pixels, and the flicker degree of pixels is analyzed to suppress the interference of dynamic background pixels. In order to improve the detection effect, the edge of moving object is obtained by edge detection method, then filled and fused with the detected object. Finally, the detection of moving object is optimized by means of median filtering and mathematical morphology. The simulation results show that the improved algorithm accelerate ghost removal, effectively suppresses the noise interference caused by dynamic background, and improves the accuracy of moving object detection.
C1 [Zuo, Junhui; Jia, Zhenhong] Xinjiang Univ, Coll Informat Sci & Engn, 666 Shengli Rd, Tianshan Dist, Urumqi, Peoples R China.
   [Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 2-427 SEIEE Bldg,800 Dong Chun Rd, Shanghai, Peoples R China.
   [Kasabov, Nikola] Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, Private Bag 92006, Auckland, New Zealand.
C3 Xinjiang University; Shanghai Jiao Tong University; Auckland University
   of Technology
RP Jia, ZH (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, 666 Shengli Rd, Tianshan Dist, Urumqi, Peoples R China.
EM jzhh9009@sohu.com
RI Kasabov, Nikola Kirilov/JQJ-5530-2023; Yang, Jie/JCD-9867-2023
OI Kasabov, Nikola/0000-0003-4433-7521
FU National Science Foundation of China [61665012]; International Science
   and Technology Cooperation Project of the Ministry of Education of the
   People's Republic of China [2016-2196]
FX This work was supported by the National Science Foundation of China
   (nos.U1803261 and 61665012) and the International Science and Technology
   Cooperation Project of the Ministry of Education of the People's
   Republic of China (nos. 2016-2196).(Corresponding author: Zhenhong Jia).
CR Aranda LA, 2017, IEEE T NUCL SCI, V64, P2219, DOI 10.1109/TNS.2017.2666843
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Cao JL, 2016, IEEE T IMAGE PROCESS, V25, P5538, DOI 10.1109/TIP.2016.2609807
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Choi J, 2016, IEEE T INTELL TRANSP, V17, P2440, DOI 10.1109/TITS.2016.2519536
   Devanne M, 2017, PATTERN RECOGN, V61, P222, DOI 10.1016/j.patcog.2016.07.041
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gennarelli G, 2016, IEEE GEOSCI REMOTE S, V13, P1226, DOI 10.1109/LGRS.2016.2577715
   Haixiang Su, 2014, 2014 7th International Symposium on Computational Intelligence and Design (ISCID), P104, DOI 10.1109/ISCID.2014.75
   Han G, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.063005
   Hu J, 2017, IEEE T VEH TECHNOL, V66, P6645, DOI 10.1109/TVT.2017.2660497
   Hu WR, 2017, IEEE T IMAGE PROCESS, V26, P724, DOI 10.1109/TIP.2016.2627803
   Huang SC, 2014, IEEE T CYBERNETICS, V44, P114, DOI 10.1109/TCYB.2013.2248057
   Huang W, 2015, INFRARED PHYS TECHN, V71, P518, DOI 10.1016/j.infrared.2015.06.011
   Ju JG, 2019, MULTIMED TOOLS APPL, V78, P29937, DOI 10.1007/s11042-018-6710-1
   Kaushal M, 2017, APPL INTELL, V47, P1008, DOI 10.1007/s10489-017-0912-5
   Khadidos A, 2017, IEEE T IMAGE PROCESS, V26, P1979, DOI 10.1109/TIP.2017.2666042
   Koniar D, 2017, ELECTR ENG, V99, P1349, DOI 10.1007/s00202-017-0609-0
   Lu XF, 2018, IEEJ T ELECTR ELECTR, V13, P1540, DOI 10.1002/tee.22718
   Lv PY, 2018, INFRARED PHYS TECHN, V91, P107, DOI 10.1016/j.infrared.2018.03.007
   Ou XF, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419500046
   Pang YW, 2016, IEEE T CYBERNETICS, V46, P2220, DOI 10.1109/TCYB.2015.2472478
   Pang YW, 2016, IEEE T IND ELECTRON, V63, P5592, DOI 10.1109/TIE.2016.2564938
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Wan MJ, 2016, INFRARED PHYS TECHN, V76, P455, DOI 10.1016/j.infrared.2016.04.003
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wu SZ, 2017, OXID MED CELL LONGEV, V2017, DOI 10.1155/2017/4130824
   Xin YH, 2014, OPTIK, V125, P5690, DOI 10.1016/j.ijleo.2014.06.092
   Yang Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), P26
NR 34
TC 9
Z9 11
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29663
EP 29684
DI 10.1007/s11042-020-09530-0
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300008
DA 2024-07-18
ER

PT J
AU Jia, HM
   Peng, XX
   Kang, LF
   Li, Y
   Jiang, ZC
   Sun, KJ
AF Jia, Heming
   Peng, Xiaoxu
   Kang, Lifei
   Li, Yao
   Jiang, Zichao
   Sun, Kangjian
TI Pulse coupled neural network based on Harris hawks optimization
   algorithm for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Pulse coupled neural network; Harris hawks
   optimization; Mutual information entropy; Image entropy
ID MEAN-SHIFT; PCNN; LINKING
AB Medical image segmentation is a hotspot in the field of image segmentation, and there are many segmentation methods. As a method of image segmentation, pulse coupled neural network (PCNN) has excellent segmentation effect. Of course, it also reduces the efficiency and effect of segmentation because of the complexity of parameter setting and the need for manual setting. This paper presents a method of searching simplified PCNN parameters by using Harris Hawks optimization (HHO) algorithm. For one thing the number of parameters of PCNN is reduced without affecting the segmentation effect, for another the corresponding parameters of PCNN are searched quickly and accurately by intelligent optimization algorithm. Then, image entropy (H) and mutual information entropy (MI) are introduced as fitness functions. The performance of HHO-PCNN is compared with WOA-PCNN, SCA-PCNN, SSA-PCNN, PSO-PCNN, GWO-PCNN, MVO-PCNN, Otsu and K-means by performance indicators (UM, CM, Precision, Recall, and Dice). The experimental results verify the superiority of this method in image segmentation.
C1 [Jia, Heming; Peng, Xiaoxu; Kang, Lifei; Li, Yao; Jiang, Zichao; Sun, Kangjian] Northeast Forestry Univ, Coll Mech & Elect Engn, Harbin 150040, Peoples R China.
C3 Northeast Forestry University - China
RP Jia, HM (corresponding author), Northeast Forestry Univ, Coll Mech & Elect Engn, Harbin 150040, Peoples R China.
EM jiaheming@nefu.edu.cn
OI Sun, Kangjian/0000-0002-9205-4078
FU Fundamental Research Funds for the Central Universities [2572019BF04];
   Northeast Forestry University Horizontal Project [43217002, 43217005,
   43219002]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities(2572019BF04), the Northeast Forestry University
   Horizontal Project (43217002, 43217005, 43219002).
CR Alsmadi MK, 2018, AIN SHAMS ENG J, V9, P697, DOI 10.1016/j.asej.2016.03.016
   Bai XF, 2013, IEICE T INF SYST, VE96D, P387, DOI 10.1587/transinf.E96.D.387
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   Deng XY, 2016, PATTERN RECOGN LETT, V79, P8, DOI 10.1016/j.patrec.2016.04.019
   Dong ZK, 2018, NEUROCOMPUTING, V308, P172, DOI 10.1016/j.neucom.2018.04.066
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Guo WY, 2014, OPTIK, V125, P5234, DOI 10.1016/j.ijleo.2014.05.003
   Hage IS, 2013, COMPUT MED IMAG GRAP, V37, P466, DOI 10.1016/j.compmedimag.2013.08.003
   Hall O, 2004, LANDSCAPE ECOL, V19, P59, DOI 10.1023/B:LAND.0000018371.43447.1f
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He FL, 2019, OPT LASER TECHNOL, V110, P114, DOI 10.1016/j.optlastec.2018.05.042
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Helmy AK, 2016, APPL SOFT COMPUT, V40, P405, DOI 10.1016/j.asoc.2015.11.042
   Hu J, 2012, SENSOR LETT, V10, P190, DOI 10.1166/sl.2012.1840
   Ji HW, 2013, IEEE J BIOMED HEALTH, V17, P690, DOI 10.1109/JBHI.2013.2242480
   Jing HY, 2014, NEUROCOMPUTING, V129, P114, DOI 10.1016/j.neucom.2013.02.048
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P461, DOI 10.1109/TNN.1999.761704
   JOHNSON JL, 1993, OPT LETT, V18, P1253, DOI 10.1364/OL.18.001253
   JOHNSON JL, 1994, APPL OPTICS, V33, P6239, DOI 10.1364/AO.33.006239
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   JOHNSON JL, 1993, WCNN'93 - PORTLAND, WORLD CONGRESS ON NEURAL NETWORKS, VOL IV, P299
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   Kuntimad G, 1999, IEEE T NEURAL NETWOR, V10, P591, DOI 10.1109/72.761716
   LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lindblad T, 1997, NUCL INSTRUM METH A, V389, P245, DOI 10.1016/S0168-9002(97)00143-5
   Liu C, 2014, IET IMAGE PROCESS, V8, P327, DOI 10.1049/iet-ipr.2013.0195
   Madhukumar S, 2015, EGYPT J RADIOL NUC M, V46, P475, DOI 10.1016/j.ejrnm.2015.02.008
   Mandavi S, 2018, SWARM EVOL COMPUT, V39, P1, DOI 10.1016/j.swevo.2017.09.010
   Martini MN, 2014, J GEOPHYS RES-ATMOS, V119, P12674, DOI 10.1002/2014JD021962
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammed MM, 2015, EXPERT SYST APPL, V42, P4927, DOI 10.1016/j.eswa.2015.02.019
   Montazer GA, 2015, NEUROCOMPUTING, V168, P221, DOI 10.1016/j.neucom.2015.05.104
   Ranganath HS, 1999, IEEE T NEURAL NETWOR, V10, P615, DOI 10.1109/72.761720
   REITBOECK HJ, 1990, SPRINGER SERIES SYNE, V45, P112
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Shi C, 2013, NEUROCOMPUTING, V117, P47, DOI 10.1016/j.neucom.2012.10.025
   Shi ZF, 2012, IEICE T INF SYST, VE95D, P2585, DOI 10.1587/transinf.E95.D.2585
   Subashini MM, 2014, EXPERT SYST APPL, V41, P3965, DOI 10.1016/j.eswa.2013.12.027
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   Vania M, 2019, J COMPUT DES ENG, V6, P224, DOI 10.1016/j.jcde.2018.05.002
   Wang ZB, 2010, IMAGE VISION COMPUT, V28, P5, DOI 10.1016/j.imavis.2009.06.007
   Wu CD, 2016, OPT, V157, P914
   Xu XM, 2017, INT J DIGIT EARTH, V10, P522, DOI 10.1080/17538947.2016.1237571
   [杨娜 Yang Na], 2012, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V12, P48
   Yi-De MA, 2012, J CHINA I COMMUN, V23, P46
   Zhan K, 2017, ARCH COMPUT METHOD E, V24, P573, DOI 10.1007/s11831-016-9182-3
   Zhang H, 2019, MEASUREMENT, V138, P182, DOI 10.1016/j.measurement.2019.02.005
   Zhang T, 2012, ICDIP, V8334, P1
   ZHANG T, 2013, INF TECHNOL J, V12, P2342, DOI DOI 10.3923/itj.2013.2342.2349
   Zhao CH, 2014, OPTIK, V125, P6247, DOI 10.1016/j.ijleo.2014.08.024
   Zou BJ, 2012, APPL MECH MATER, V155-156, P861, DOI 10.4028/www.scientific.net/AMM.155-156.861
NR 60
TC 20
Z9 25
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28369
EP 28392
DI 10.1007/s11042-020-09228-3
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554845600002
DA 2024-07-18
ER

PT J
AU Bakkouri, I
   Afdel, K
AF Bakkouri, Ibtissam
   Afdel, Karim
TI Computer-aided diagnosis (CAD) system based on multi-layer feature
   fusion network for skin lesion recognition in dermoscopy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin diseases; Dermoscopic pattern recognition; Transfer learning;
   Multi-layer feature fusion; Multi-class classification
ID CONVOLUTIONAL NEURAL-NETWORKS; DEEP; CLASSIFICATION; CANCER; MELANOMA;
   SEGMENTATION; EXTRACTION; CNN
AB Skin lesion recognition is one of the most important tasks in dermoscopic image analysis. Current Convolutional Neural Network (CNN) algorithms based recognition methods tend to become a standard methodology to fix a large array of Computer-Aided Diagnosis (CAD) and interpretation problems. Besides significant practical and theoretical improvements in their architecture, their effectiveness is built on the existence of the flexible pre-trained models which generalize well to novel tasks and handle the problem of having small set of dermoscopic data. However, existing works pay little attention to exploring the benefits of hierarchical multi-feature fusion for classifying the skin lesions in digital dermoscopic images. Practically, it has been found that integrating multi-layer features has significant potential for improving performance of any pattern recognition task. In this paper, we developed a robust CAD system based on transfer learning and multi-layer feature fusion network to diagnose complex skin diseases. It is a convenient approach in terms of overfitting prevention, convergence speed and high morphological feature similarity processing. Our research focuses exclusively on obtaining optimal performance with addressing the various gaps in the skin pattern recognition area. For validation and comparison purposes, the proposed approach was evaluated on publicly dermoscopic dataset, and achieved the high recognition precision compared with fully trained CNN models, fine-tuning process, single CNN model and other related works. Therefore, the study demonstrates that our proposed approach can dramatically improve the performance of CAD systems which are based on the conventional recognition and classification algorithms for skin lesion recognition in dermoscopic data.
C1 [Bakkouri, Ibtissam; Afdel, Karim] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Bakkouri, I (corresponding author), Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
EM ibtissam.bakkouri@gmail.com
RI Karim, AFDEL/AAC-7992-2019; Bakkouri, Ibtissam/Z-1275-2018
OI Karim, AFDEL/0000-0002-0828-2116; Bakkouri, Ibtissam/0000-0003-4827-9007
CR Abd-Ellah MK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0332-4
   Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22
   Akçay S, 2016, IEEE IMAGE PROC, P1057, DOI 10.1109/ICIP.2016.7532519
   Anic GM, 2013, CANCER EPIDEMIOL, V37, P434, DOI 10.1016/j.canep.2013.02.010
   [Anonymous], 2017, 2017 IEEE INT C BIOI, DOI DOI 10.1109/BIBM.2017.8217751
   [Anonymous], 2017, ARXIV171204415
   [Anonymous], 2011, ARTIFI INTELLIG REV
   [Anonymous], 2016, NEUROCOMPUTING, DOI [DOI 10.1016/J.NEUC0M.2015.09.116, DOI 10.1016/J.NEUCOM.2015.09.116, 10. 1016/j.neucom.2015.09.116]
   [Anonymous], 2016, arXiv
   Antropova N, 2017, MED PHYS, V44, P5162, DOI 10.1002/mp.12453
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Aubreville M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12320-8
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Bakkouri I, 2017, 2017 INT C ADV TECHN, P1, DOI 10.1109/ATSIP.2017.8075562
   Bakkouri I, 2019, MULTIMED TOOLS APPL, V78, P12939, DOI 10.1007/s11042-018-6267-z
   Bakkouri I, 2018, LECT NOTES COMPUT SC, V10884, P453, DOI 10.1007/978-3-319-94211-7_49
   Baldi P, 2014, ARTIF INTELL, V210, P78, DOI 10.1016/j.artint.2014.02.004
   Banerjee I, 2018, COMPUT MED IMAG GRAP, V65, P167, DOI 10.1016/j.compmedimag.2017.05.002
   Byra M, 2018, INT J COMPUT ASS RAD, V13, P1895, DOI 10.1007/s11548-018-1843-2
   Castrejon L, 2016, PROC CVPR IEEE, P2940, DOI 10.1109/CVPR.2016.321
   Chen W, 2014, BRIT J RADIOL, V87, P1
   Chen Y, 2018, IET COMPUT VIS, V12, P1179, DOI 10.1049/iet-cvi.2018.5315
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Chu B, 2016, LECT NOTES COMPUT SC, V9915, P435, DOI 10.1007/978-3-319-49409-8_34
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Coates A, 2013, PROC INT C MACH LEAR, P1337
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Dai XY, 2017, PROC CVPR IEEE, P6100, DOI 10.1109/CVPR.2017.646
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ge Y, 2018, MULTIMED TOOLS APPL, V77, P17489, DOI 10.1007/s11042-017-5314-5
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Gogate M, 2017, 2017 IEEE S SERIES C, P1, DOI [DOI 10.1109/SSCI.2017.8285382, 10.1109/SSCI.2017.8285382]
   Golrizkhatami Z, 2018, EXPERT SYST APPL, V114, P54, DOI 10.1016/j.eswa.2018.07.030
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Han L, 2013, LECT NOTES COMPUT SC, V8033, P171, DOI 10.1007/978-3-642-41914-0_18
   Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huo L, 2019, MULTIMED TOOLS APPL, V78, P1635, DOI 10.1007/s11042-018-6249-1
   Ide H, 2016, 2016 INT JOINT C NEU, DOI [10.1109/ijcnn.2016.7727665, DOI 10.1109/IJCNN.2016.7727665]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kingma D. P., 2014, arXiv
   Kleinberg R, 2018, PR MACH LEARN RES, V80
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuai YL, 2019, SIGNAL IMAGE VIDEO P, V13, P35, DOI 10.1007/s11760-018-1325-6
   Lacy K, 2013, Medicine, V41, P402, DOI DOI 10.1016/J.MPMED.2013.04.008
   Thao LT, 2017, 2017 21ST ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS (IES), P106, DOI 10.1109/IESYS.2017.8233570
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee HD, 2018, KNOWL-BASED SYST, V158, P9, DOI 10.1016/j.knosys.2018.05.016
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Li F, 2017, IEEE ACCESS, V5, P10979, DOI 10.1109/ACCESS.2017.2713389
   Li HR, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24309-y
   Li YC, 2018, INT J COMPUT ASS RAD, V13, P1187, DOI 10.1007/s11548-018-1806-7
   Li YC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010311
   Liu B, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2287
   Liu MH, 2018, NEUROINFORMATICS, V16, P295, DOI 10.1007/s12021-018-9370-4
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Maas A, 2013, 2013 INT C MACH LEAR
   Majumder N, 2018, KNOWL-BASED SYST, V161, P124, DOI 10.1016/j.knosys.2018.07.041
   Mash Robert, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P113, DOI 10.1007/978-3-319-50835-1_11
   Matsugu M, 2004, LECT NOTES COMPUT SC, V3173, P864
   Menegola A, 2017, I S BIOMED IMAGING, P297, DOI 10.1109/ISBI.2017.7950523
   Mukkamala M, 2017, 2017 INT C MACH LEAR
   Nay Chi Lynn, 2017, 2017 18th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT). Proceedings, P117, DOI 10.1109/PDCAT.2017.00028
   Nickerson P, 2016, IEEE ENG MED BIO, P2966, DOI 10.1109/EMBC.2016.7591352
   Popescu D, 2015, LECT NOTES COMPUT SC, V9386, P693, DOI 10.1007/978-3-319-25903-1_60
   Shie CK, 2015, IEEE ENG MED BIO, P711, DOI 10.1109/EMBC.2015.7318461
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun J, 2017, LECT NOTES COMPUT SC, V10554, P126, DOI 10.1007/978-3-319-67561-9_14
   Suns A., 2001, P 2001 IEEE INT C DA, P521, DOI DOI 10.1109/ICDM.2001.989560
   Tang JR, 2014, COMPUT ELECTR ENG, V40, P86, DOI 10.1016/j.compeleceng.2014.05.017
   Taqi AM, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P140, DOI 10.1109/MIPR.2018.00032
   Vu TD, 2018, SOFT COMPUT, V22, P6825, DOI 10.1007/s00500-018-3421-5
   Toader MP, 2017, E-HEALTH BIOENG CONF, P583, DOI 10.1109/EHB.2017.7995491
   Tripathi G, 2019, VISUAL COMPUT, V35, P753, DOI 10.1007/s00371-018-1499-5
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Tschandl P, 2019, COMPUT BIOL MED, V104, P111, DOI 10.1016/j.compbiomed.2018.11.010
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wang XJ, 2018, J AM HEART ASSOC, V7, DOI 10.1161/JAHA.118.008701
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wen J, 2015, MEDICINE, V94, P1
   Xu J, 2018, P MACH LEARN RES PML
   Yang X, 2018, LECT NOTES COMPUT SC, V10663, P152, DOI 10.1007/978-3-319-75541-0_16
   Yang Y, 2014, 2014 IEEE INT C IM P, DOI [10.1109/icip.2014.7025311, DOI 10.1109/ICIP.2014.7025311]
   Yosinski J, 1792, INT C NEUR INF PROC
   Yu C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193321
   Yu D, 2018, NEUROCOMPUTING, V296, P23, DOI 10.1016/j.neucom.2018.03.031
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
   Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166
   Zhang K, 2018, INT CONF BIG DATA, P321, DOI 10.1109/BigComp.2018.00054
   Zhang XM, 2018, EARTH PLANET PHYS, V2, P84, DOI 10.26464/epp2018009
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zheng Liang, 2016, arXiv preprint arXiv
NR 105
TC 76
Z9 76
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20483
EP 20518
DI 10.1007/s11042-019-07988-1
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000558921600001
DA 2024-07-18
ER

PT J
AU Choi, DY
   Song, BC
AF Choi, Dong Yoon
   Song, Byung Cheol
TI Semi-supervised learning for facial expression-based emotion recognition
   in the continuous domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Semi-supervised learning; Convolutional neural
   network; Long shot-term memory
AB Emotion recognition is a very important technique for effective interaction between human and artificial intelligence (AI) system. For a long time, facial expression-based methods have been actively studied, and they are showing high recognition performance thanks to powerful deep learning recently. On the other hand, the images of the datasets used in the conventional emotion recognition studies are usually short in length and often generated through intentional expression. Also, continuous domain annotation of emotional labels in dataset configuration requires high cost. In order to overcome such problems, this paper proposes an emotion recognition method based on semi-supervised learning that utilizes an appropriate amount of unlabeled dataset in parallel while minimizing the use of labeled dataset requiring high training cost. The proposed emotion recognition method is based on CNN-LSTM-based regressor for regressing arousal and valence in continuous domain. In addition, we present scenarios and design criteria in which semi-supervised learning can be effectively applied to emotion recognition tasks through experiments using well-known MAHNOB-HCI and AFEW-VA datasets.
C1 [Choi, Dong Yoon; Song, Byung Cheol] Inha Univ, Dept Elect Engn, Inha Ro 100, Incheon 22212, South Korea.
C3 Inha University
RP Song, BC (corresponding author), Inha Univ, Dept Elect Engn, Inha Ro 100, Incheon 22212, South Korea.
EM bcsong@inha.ac.kr
OI Song, Byung Cheol/0000-0001-8742-3433
FU Institute of Information & communications Technology Planning &
   Evaluation(IITP) grant - Korea government(MSIT) [2020-0-01389];
   Industrial Technology Innovation Program through the Ministry of Trade,
   Industry, and Energy (MI, Korea) [Development of Human-Friendly
   Human-Robot Interaction Technologies Using Human Internal Emotional
   States] [10073154]
FX This work was supported by Institute of Information & communications
   Technology Planning & Evaluation(IITP) grant funded by the Korea
   government(MSIT) [2020-0-01389, Artificial Intelligence Convergence
   Research Center(Inha University)] and Industrial Technology Innovation
   Program through the Ministry of Trade, Industry, and Energy (MI, Korea)
   [Development of Human-Friendly Human-Robot Interaction Technologies
   Using Human Internal Emotional States] under Grant 10073154.
CR [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2018, P EUR C COMP VIS ECC
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhall A., 2017, P 19 ACM INT C MULT, P524, DOI [10.1145/3136755.3143004, DOI 10.1145/3136755.3143004]
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Ketkar N, 2017, DEEP LEARNING PYTHON, P195, DOI [10.1007/978-1-4842-2766-4_12, DOI 10.1007/978-1-4842-2766-4_12]
   Kim D.H., 2017, P ICMI 2017 19 ACM I, P529, DOI [10.1145/3136755.3143005, DOI 10.1145/3136755.3143005]
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kollias D, 2019, INT J COMPUT VISION, V127, P907, DOI 10.1007/s11263-019-01158-4
   Kossaifi J, 2017, IMAGE VISION COMPUT, V65, P23, DOI 10.1016/j.imavis.2017.02.001
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Laine Samuli, 2016, PROC INT C LEARN REP
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Mehrkanoon S, 2015, NEURAL NETWORKS, V71, P88, DOI 10.1016/j.neunet.2015.08.001
   Mehrkanoon S, 2015, IEEE T NEUR NET LEAR, V26, P720, DOI 10.1109/TNNLS.2014.2322377
   Netzer Y, 2011, WORKSH DEEP LEARN UN
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Rezagholizadeh M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2806, DOI 10.1109/ICASSP.2018.8462534
   Salimans T., 2016, P 30 C NEUR INF PROC, P2234
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Tarvainen Antti, 2017, ADV NEURAL INFORM PR, P2, DOI DOI 10.1137/0330046
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
NR 32
TC 11
Z9 11
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28169
EP 28187
DI 10.1007/s11042-020-09412-5
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436800009
DA 2024-07-18
ER

PT J
AU Cai, SH
   Wang, XN
AF Cai, Shaohao
   Wang, Xiaonan
TI Efficient vehicular content delivery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicular networks; Content delivery; Receiver; Provider; Mobility
   support
ID INFORMATION-CENTRIC NETWORKING; SCHEME
AB Nowadays, most of the traffic in vehicular networks is relevant to content, so the content-to-requester method could be an ideal solution for vehicular content delivery. However, due to the features of vehicular networks such as high mobility, the content-to-requester paradigm might cause the frequent content delivery failures and increase the content delivery cost. Inspired by the idea that the address-based mechanism can support mobility and reduce content delivery costs, we are motivated to take advantage of the address-based mechanism to achieve the content-to-requester paradigm. Based on this motivation, we propose a vehicular content delivery scheme with mobility support (VCDM). In VCDM, the receiver and provider handovers are achieved so that a receiver can correctly receive the requested content from a provider via one successful content delivery process. Moreover, a location-based address is proposed so that a requester can acquire the content from the nearest provider in a unicast way. Finally, VCDM is analyzed and evaluated, and the data show that VCDM effectively improves the content delivery success rate and reduces the content delivery cost and latency.
C1 [Cai, Shaohao; Wang, Xiaonan] Changshu Inst Technol, Changshu 215500, Jiangsu, Peoples R China.
C3 Changshu Institute of Technology
RP Wang, XN (corresponding author), Changshu Inst Technol, Changshu 215500, Jiangsu, Peoples R China.
EM wxn_2001@163.com
FU National Natural Science Foundation of China [61202440]
FX This work is supported by National Natural Science Foundation of China
   (61202440).
CR Ahmed SH, 2015, IEEE COMMUN LETT, V19, P1616, DOI 10.1109/LCOMM.2015.2451647
   Amadeo M, 2016, IEEE NETWORK, V30, P92, DOI 10.1109/MNET.2016.7437030
   Arshad S, 2019, IEEE INTERNET THINGS, V6, P2128, DOI 10.1109/JIOT.2018.2873343
   Bastos IV, 2019, COMPUT NETW, V157, P11, DOI 10.1016/j.comnet.2019.04.003
   Bouk SH, 2019, IEEE ACCESS, V7, P51799, DOI 10.1109/ACCESS.2019.2910281
   Fang C, 2015, IEEE COMMUN SURV TUT, V17, P1455, DOI 10.1109/COMST.2015.2394307
   Gao DM, 2019, IEEE ACCESS, V7, P40663, DOI 10.1109/ACCESS.2019.2902902
   Garcia-Luna-Aceves JJ, 2015, ELEVENTH 2015 ACM/IEEE SYMPOSIUM ON ARCHITECTURES FOR NETWORKING AND COMMUNICATIONS SYSTEMS, P135, DOI 10.1109/ANCS.2015.7110127
   Grassi G., 2013, ACM SIGMOBILE Mobile Computing and Communications Review, V17, P23, DOI [10.1145/2542095.2542108, DOI 10.1145/2542095.2542108]
   Grassi G, 2014, IEEE CONF COMPUT, P410, DOI 10.1109/INFCOMW.2014.6849267
   Gupta A, 2015, CONSUM COMM NETWORK, P802, DOI 10.1109/CCNC.2015.7158080
   Jacobson V, 2012, COMMUN ACM, V55, P117, DOI 10.1145/2063176.2063204
   Khelifi H., 2019, IEEE COMMUNICATIONS, P1
   Lee E, 2014, IEEE COMMUN MAG, V52, P148, DOI 10.1109/MCOM.2014.6736756
   Ortega V, 2018, IEEE VEH TECHNOL MAG, V13, P121, DOI 10.1109/MVT.2018.2813422
   Rezaeifar Z, 2019, FUTURE GENER COMP SY, V96, P538, DOI 10.1016/j.future.2018.12.049
   Wang L, 2013, IEEE GLOB COMM CONF, P2069, DOI 10.1109/GLOCOM.2013.6831380
   Wang X, 2019, IEEE T GEOSCI REMOTE, V57, P8827, DOI 10.1109/TGRS.2019.2923247
   Wang XN, 2020, IEEE INTERNET THINGS, V7, P3453, DOI 10.1109/JIOT.2020.2971009
   Wang XN, 2020, IEEE T VEH TECHNOL, V69, P2105, DOI 10.1109/TVT.2019.2959799
   Wang XN, 2019, IEEE SYST J, V13, P519, DOI 10.1109/JSYST.2018.2875918
   Wang XN, 2018, IEEE T COMPUT SOC SY, V5, P918, DOI 10.1109/TCSS.2018.2872531
   Wang XN, 2018, IEEE INTEL TRANSP SY, V10, P135, DOI 10.1109/MITS.2018.2842036
   Wang XN, 2018, COMMUN ACM, V61, P83, DOI 10.1145/3197544
   Wang XN, 2015, T EMERG TELECOMMUN T, V26, P836, DOI 10.1002/ett.2743
NR 25
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28043
EP 28063
DI 10.1007/s11042-020-09349-9
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554334600003
DA 2024-07-18
ER

PT J
AU Bao, H
   Lu, YX
   Wang, QJ
AF Bao, Hua
   Lu, Yixiang
   Wang, Qijun
TI Single target tracking via correlation filter and context adaptively
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Correlation filter; Contextual information
ID OBJECT TRACKING
AB Recently, tracking methods based on correlation filter show impressive performance in a variety of complex environments for their excellent classification performance. However, most of the existing methods only focus on the information in the bounding box regions of the target, and do not fully utilized the contextual information and the internal structure information of the target. Thus, when the target scenes experience dramatic change, the learned filter could not accurately adapt to the appearance change, which will lead to model degradation of the target. To address this issue, a novel approach via correlation filter and context jointly is proposed in this paper. First, we decompose the target into multiple independent parts, and each part learns the filtering response separately. Through the joint learning of multiple independent filters, the target model can effectively maintain the structural information of the object and is not sensitive to partial occlusion, and etc. Second, we introduce multi-channel features in the representation based on the parts of the target and the contextual information to migrate the background influences. With the introduction of collaborative representation strategy, the impact of background noise can be effectively suppressed. To evaluate the proposed approach, we conduct extensive experiments on several challenging benchmark datasets including OTB-2013 and OTB-2015 datasets. The results show our method demonstrates comparable performance against several state-of-the-art methods.
C1 [Bao, Hua; Lu, Yixiang; Wang, Qijun] Anhui Univ, Sch Elect Engn & Automat, Hefei 230601, Peoples R China.
C3 Anhui University
RP Wang, QJ (corresponding author), Anhui Univ, Sch Elect Engn & Automat, Hefei 230601, Peoples R China.
EM wangqijun308@163.com
RI wang, qi/HTN-8786-2023; wang, qi/IAN-4150-2023
OI wang, qi/0000-0002-2794-6897
FU National Natural Science Foundation of China [61201429]; Nature Science
   Research Project of Anhui province [1908085MF217]
FX This work was partially supported by the National Natural Science
   Foundation of China (61201429) and Nature Science Research Project of
   Anhui province (1908085MF217).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bibi A, 2016, LECT NOTES COMPUT SC, V9910, P419, DOI 10.1007/978-3-319-46466-4_25
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Chen DP, 2013, IEEE I CONF COMP VIS, P1113, DOI 10.1109/ICCV.2013.142
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Chou KP, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P259
   Chou KP, 2018, IEEE ACCESS, V6, P15283, DOI 10.1109/ACCESS.2018.2809552
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kong J, 2016, NEUROCOMPUTING, V213, P155, DOI 10.1016/j.neucom.2016.03.100
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Lee DY, 2014, PROC CVPR IEEE, P3486, DOI 10.1109/CVPR.2014.446
   Li DS, 2012, ELECTRON J QUAL THEO, P1
   Li F, 2017, IEEE INT CONF COMP V, P2001, DOI 10.1109/ICCVW.2017.234
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Prasad M, 2018, IEEE WCCI, P1
   Prasad M, 2018, PROCEDIA COMPUT SCI, V144, P13, DOI 10.1016/j.procs.2018.10.500
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tang YX, 2016, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2016.233
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao JJ, 2016, LECT NOTES COMPUT SC, V9908, P121, DOI 10.1007/978-3-319-46493-0_8
   Yang LK, 2019, AAAI CONF ARTIF INTE, P10071
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhu Z, 2017, IEEE INT CONF COMP V, P1973, DOI 10.1109/ICCVW.2017.231
NR 46
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27465
EP 27482
DI 10.1007/s11042-020-09309-3
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552512800003
DA 2024-07-18
ER

PT J
AU Zhang, YL
   Wen, L
   Zhang, YJ
   Wang, CF
AF Zhang, Yu-lei
   Wen, Long
   Zhang, Yong-jie
   Wang, Cai-fen
TI Deniably authenticated searchable encryption scheme based on Blockchain
   for medical image data sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Deniably authenticated encryption; Identity privacy;
   Searchable encryption; Medical image
ID PUBLIC-KEY ENCRYPTION; KEYWORD SEARCH; DESIGNATED TESTER; INTERNET
AB In the cloud applications of medical data based on blockchain, doctors and managers usually want to obtain image data shared by other healthcare institutions. To ensure the privacy and workability of the image data, it is necessary to encrypt plain image data, retrieve cypher data and verify the authenticity of the data. Public key authenticated searchable encryption (PAEKS) is an effective mechanism to realize the privacy and workability properties of data. However, the existing PAEKS schemes are unable to realize the identity privacy protection of the data owner, and the traditional blockchain system (such as the Bitcoin) cannot achieve these goals directly. To overcome the above drawback, we first present a deniably authenticated searchable encryption scheme for medical image data sharing (DASES) that is based on blockchain and deniably authenticated encryption technology. The DASES takes advantage of blockchain technology to ensure the non-tampered, unforgettable and traceability of the image data, and it also avoids the limitation of the blockchain's own storage and computing power. The DASES can not only withstand inside keyword guessing attack (IKGA) but also provide effective privacy protection and verify the authenticity of medical image data. Hence, it can better protect the privacy of data senders and provide stronger security. Next, we prove that the DASES satisfies the indistinguishability of the ciphertext and trapdoor. It is regrettable that the DASES is less efficient than related schemes in the literature, but its greatest strength is its ability to provide better identity privacy protection and stronger security.
C1 [Zhang, Yu-lei; Wen, Long] Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Yong-jie] Gansu Hlth Vocat Coll, Lanzhou 730000, Peoples R China.
   [Wang, Cai-fen] Shenzhen Technol Univ, Coll Big Data & Internet, Shenzhen 518000, Peoples R China.
C3 Northwest Normal University - China; Shenzhen Technology University
RP Zhang, YL (corresponding author), Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Peoples R China.
EM zhangyl@nwnu.edu.cn; 770293027@qq.com
FU National Natural Science Foundation of China [61662069]; Higher
   Educational Scientific Research Foundation of Gansu Province
   [No.2017A-003, 2018A-207]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant No.61662069, Higher Educational
   Scientific Research Foundation of Gansu Province under Grant
   No.2017A-003, and 2018A-207.
CR Ahene E, 2019, TELECOMMUN SYST, V70, P417, DOI 10.1007/s11235-018-0496-3
   [Anonymous], 2010, PAIRING BASED CRYPTO
   [Anonymous], 2017, SEARCHABLE SYMMETRIC
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Byun JW, 2006, LECT NOTES COMPUT SC, V4165, P75
   Castro M, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE THIRD SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '99), P173, DOI 10.1145/571637.571640
   Dimitrov DV, 2016, HEALTHC INFORM RES, V22, P156
   Emura K, 2015, SECUR COMMUN NETW, V8, P1547, DOI 10.1002/sec.1103
   He DB, 2018, IEEE T IND INFORM, V14, P3618, DOI 10.1109/TII.2017.2771382
   Huang Dong-Mei, 2016, Journal of Software, V27, P1729, DOI 10.13328/j.cnki.jos.005039
   Huang DM, 2019, LASER OPTOELECTRON P, V56, DOI 10.3788/LOP56.031001
   Huang Q, 2017, INFORM SCIENCES, V403, P1, DOI 10.1016/j.ins.2017.03.038
   Li FG, 2016, IEEE T INF FOREN SEC, V11, P2477, DOI 10.1109/TIFS.2016.2585086
   Li HB, 2019, INFORM SCIENCES, V481, P330, DOI 10.1016/j.ins.2019.01.004
   Lu Y, 2019, IEEE T SERV COMPUT, V99, P1
   Ma MM, 2018, COMPUT ELECTR ENG, V65, P413, DOI 10.1016/j.compeleceng.2017.05.014
   Ma WY, 1998, CONF REC ASILOMAR C, P253, DOI 10.1109/ACSSC.1998.750865
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Peng YG, 2014, CHINA COMMUN, V11, P100, DOI 10.1109/CC.2014.7004528
   Rhee HS, 2012, INFORM SCIENCES, V205, P93, DOI 10.1016/j.ins.2012.03.020
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   Wu LB, 2019, ANN TELECOMMUN, V74, P423, DOI 10.1007/s12243-018-00701-7
   Wu TY, 2017, ADV INTELL SYST, V536, P113, DOI 10.1007/978-3-319-48490-7_14
   Wu WF, 2015, KSII T INTERNET INF, V9, P1904, DOI 10.3837/tiis.2015.05.020
   Yunlong Sun, 2018, Journal of Electrical and Computer Engineering, V2018, DOI 10.1155/2018/1092718
   Zhang J, 2016, IEEE ACCESS, V4, P9239, DOI 10.1109/ACCESS.2016.2645904
   Zhang YL, 2019, IEEE ACCESS, V7, P146542, DOI 10.1109/ACCESS.2019.2945813
   Zhu Xudong, 2014, Journal of Xidian University, V41, P151, DOI 10.3969/j.issn.1001-2400.2014.02.025
NR 28
TC 8
Z9 9
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27075
EP 27090
DI 10.1007/s11042-020-09213-w
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551375500003
DA 2024-07-18
ER

PT J
AU Nizami, IF
   Rehman, MU
   Majid, M
   Anwar, SM
AF Nizami, Imran Fareed
   Rehman, Mobeen ur
   Majid, Muhammad
   Anwar, Syed Muhammad
TI Natural scene statistics model independent no-reference image quality
   assessment using patch based discrete cosine transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No-reference image quality assessment; Discrete cosine transform;
   Natural scene statistics; Curve fitting; Support vector regression
ID FEATURE-SELECTION ALGORITHMS; FREE-ENERGY PRINCIPLE; GRADIENT MAGNITUDE;
   SIMILARITY INDEX; JOINT STATISTICS; VISUAL QUALITY; DEGRADATION; IMPACT
AB Most of no-reference image quality assessment (NR-IQA) techniques reported in literature have utilized transform coefficients, which are modeled using curve fitting to extract features based on natural scene statistics (NSS). The performance of NR-IQA techniques that utilize curve-fitting suffers from degradation in performance because the distribution of curve fitted NSS features deviate from the statistical distribution of a distorted image. Although deep convolutional neural networks (DCNNs) have been used for NR-IQA that are NSS model-independent but their performance is dependent upon the size of training data. The available datasets for NR-IQA are small, therefore data augmentation is used that affects the performance of DCNN based NR-IQA techniques and is also computationally expensive. This work proposes a new patch-based NR-IQA technique, which utilizes features extracted from discrete cosine transform coefficients. The proposed technique is curve fitting independent and helps in avoiding errors in the statistical distribution of NSS features. It relies on global statistics to estimate image quality based on local patches, which allow us to decompose the statistics of images. The proposed technique divides the image into patches and extracts nine handcrafted features i.e., entropy, mean, variance, skewness, kurtosis, mobility, band power, energy, complexity, and peak to peak value. The extracted features are used with a support vector regression model to predict the image quality score. The experimental results have shown that the proposed technique is database and image content-independent. It shows better performance over a majority of distortion types and on images taken in real-time.
C1 [Nizami, Imran Fareed] Bahria Univ, Dept Elect Engn, Islamabad 44000, Pakistan.
   [Rehman, Mobeen ur] Air Univ, Dept Avion Engn, Islamabad 44000, Pakistan.
   [Majid, Muhammad] Univ Engn & Technol Taxila, Dept Comp Engn, Taxila 47050, Pakistan.
   [Anwar, Syed Muhammad] Univ Engn & Technol Taxila, Dept Software Engn, Taxila 47050, Pakistan.
C3 Air University Islamabad; University of Engineering & Technology Taxila;
   University of Engineering & Technology Taxila
RP Nizami, IF (corresponding author), Bahria Univ, Dept Elect Engn, Islamabad 44000, Pakistan.
EM imnizami.buic@bahria.edu.pk; cmobeenrahman@gmail.com;
   m.majid@uettaxila.edu.pk; s.anwar@uettaxila.edu.pk
RI anwar, syed/AGY-3965-2022; Majid, Muhammad/Z-5667-2019; Rehman, Mobeen
   Ur/AAR-2944-2021
OI anwar, syed/0000-0002-8179-3959; Majid, Muhammad/0000-0003-3662-2525;
   Rehman, Mobeen Ur/0000-0003-0914-7132
CR [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   Bai XF, 2013, IEICE T INF SYST, VE96D, P387, DOI 10.1587/transinf.E96.D.387
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Gao F, 2017, NEUROCOMPUTING, V257, P104, DOI 10.1016/j.neucom.2017.01.054
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   He LH, 2019, IEEE ACCESS, V7, P176087, DOI 10.1109/ACCESS.2019.2957292
   Heydari M, 2019, SIGNAL PROCESS-IMAGE, V74, P280, DOI 10.1016/j.image.2018.12.016
   Huang Y, 2016, MULTIMED TOOLS APPL, V75, P2769, DOI 10.1007/s11042-015-2620-7
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jiang QP, 2018, IEEE T MULTIMEDIA, V20, P2035, DOI 10.1109/TMM.2017.2763321
   Jing HY, 2014, NEUROCOMPUTING, V129, P114, DOI 10.1016/j.neucom.2013.02.048
   Kalatehjari E, 2018, MULTIMED TOOLS APPL, V77, P25053, DOI 10.1007/s11042-018-5757-3
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P14485, DOI 10.1007/s11042-018-6797-4
   Khosravi MH, 2018, MULTIMED TOOLS APPL, V77, P7357, DOI 10.1007/s11042-017-4636-7
   Kim JT, 2016, INT J STROKE, V11, P87
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li YM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P685, DOI 10.1109/ICDSP.2016.7868646
   Li YM, 2015, NEUROCOMPUTING, V154, P94, DOI 10.1016/j.neucom.2014.12.015
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin HH, 2019, INT WORK QUAL MULTIM
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu A, 2019, MULTIMED TOOLS APPL, V78, P24205, DOI 10.1007/s11042-018-6985-2
   Liu YT, 2018, IEEE T MULTIMEDIA, V20, P379, DOI 10.1109/TMM.2017.2729020
   Lu W, 2016, MULTIMED TOOLS APPL, V75, P14417, DOI 10.1007/s11042-016-3519-7
   Lv YQ, 2015, IEEE IMAGE PROC, P2344, DOI 10.1109/ICIP.2015.7351221
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   NILL NB, 1985, IEEE T COMMUN, V33, P551, DOI 10.1109/TCOM.1985.1096337
   Nizami IF, 2020, MULTIMED TOOLS APPL, V79, P7811, DOI 10.1007/s11042-019-08465-5
   Nizami IF, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0392-5
   Nizami IF, 2018, APPL INTELL, V48, P3482, DOI 10.1007/s10489-018-1151-0
   Nizami IF, 2018, ARAB J SCI ENG, V43, P4057, DOI 10.1007/s13369-017-2803-9
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Reisenhofer R, 2018, SIGNAL PROCESS-IMAGE, V61, P33, DOI 10.1016/j.image.2017.11.001
   Rezaie F, 2018, MULTIMED TOOLS APPL, V77, P2529, DOI 10.1007/s11042-017-4432-4
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sadiq A, 2020, OPTIK, V49, P205
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Siahaan E, 2018, SIGNAL PROCESS-IMAGE, V60, P237, DOI 10.1016/j.image.2017.10.009
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Temel D, 2019, SIGNAL PROCESS-IMAGE, V70, P37, DOI 10.1016/j.image.2018.09.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2019, J VIS COMMUN IMAGE R, V58, P353, DOI 10.1016/j.jvcir.2018.12.005
   Wu QB, 2017, IEEE T MULTIMEDIA, V19, P2490, DOI 10.1109/TMM.2017.2700206
   Xu HP, 2018, 2018 13TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P365, DOI 10.1109/WCICA.2018.8630551
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yan X., 2013, Journal of Information Hiding Multimedia and Signal Process (JIHMSP), V4, P118
   Yan X, 2014, LNCS, V9, P68, DOI DOI 10.1007/978-3-642-55046-1
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P9279, DOI 10.1007/s11042-014-2080-5
   Yang XC, 2018, MULTIMED TOOLS APPL, V77, P24185, DOI 10.1007/s11042-018-5740-z
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang M, 2015, IEEE SIGNAL PROC LET, V22, P207, DOI 10.1109/LSP.2014.2326399
   Zhang W, 2019, SIGNAL PROCESS-IMAGE, V75, P168, DOI 10.1016/j.image.2019.04.007
   Zhang YZ, 2016, DIGIT SIGNAL PROCESS, V57, P56, DOI 10.1016/j.dsp.2016.05.012
NR 65
TC 14
Z9 14
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26285
EP 26304
DI 10.1007/s11042-020-09229-2
EA JUL 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548128400001
DA 2024-07-18
ER

PT J
AU Rehman, HU
   Ghani, A
   Chaudhry, SA
   Alsharif, MH
   Nabipour, N
AF Rehman, Hafeez Ur
   Ghani, Anwar
   Chaudhry, Shehzad Ashraf
   Alsharif, Mohammed H.
   Nabipour, Narjes
TI A secure and improved multi server authentication protocol using fuzzy
   commitment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-server; Authentication; Fuzzy commitment; Security; BAN logic;
   AVISPA
ID KEY AGREEMENT SCHEME; ANONYMITY
AB The advancement in communication and computation technologies has paved a way for connecting large number of heterogeneous devices to offer specified services. Still, the advantages of this advancement are not realized completely due to inherent security issues. Most of the existing authentication mechanisms ensure the legitimacy of requesting user thorough single server leading towards multiple registrations and corresponding credentials storage on user side. Intelligent multimedia networks (IMN) may encompass wide range of networks and applications. However, the privacy and security of IMN cannot be apprehended through traditional multi sign on/single server authentication systems. The multi-server authentication systems can enable a user to acquire services from multiple servers using single registration and with single set of credentials (i.e.Password/smart card etc.) and can be accomplish IMN security and privacy needs. In 2018, Barman et al. proposed a multi-server authentication protocol using fuzzy commitment. The authors claimed that their protocol provides anonymity while resisting all known attacks. In this paper, we analyze that Barman et al.'s protocol is still vulnerable to anonymity violation attack and impersonation based on stolen smart card attack; moreover, it has incomplete login request and is prone to scalability issues. We then propose an enhanced protocol to overcome the security weaknesses of Barman et al.'s scheme. The security of the proposed protocol is verified using BAN logic and widely accepted automated AVISPA tool. The BAN logic and automated AVISPA along with the informal analysis ensure the robustness of the scheme against all known attacks.
C1 [Rehman, Hafeez Ur; Ghani, Anwar] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Chaudhry, Shehzad Ashraf] Istanbul Gelisim Univ, Fac Engn & Architecture, Dept Comp Engn, TR-34310 Istanbul, Turkey.
   [Alsharif, Mohammed H.] Sejong Univ, Coll Elect & Informat Engn, Dept Elect Engn, 209 Neungdong Ro, Seoul 05006, South Korea.
   [Nabipour, Narjes] Duy Tan Univ, Inst Res & Dev, Da Nang 550000, Vietnam.
C3 International Islamic University, Pakistan; Istanbul Gelisim University;
   Sejong University; Duy Tan University
RP Ghani, A (corresponding author), Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
EM hafeezkami@gmail.com; anwar.ghani@iiu.edu.pk;
   ashraf.shehzad.ch@gmail.com; malsharif@sejong.ac.kr;
   narjesnabipour@duytan.edu.vn
RI Alsharif, Mohammed H./X-7516-2018; Ghani, Anwar/Q-1973-2019; Chaudhry,
   Shehzad/Y-3430-2019
OI Alsharif, Mohammed H./0000-0001-8579-5444; Ghani,
   Anwar/0000-0001-7474-0405; Chaudhry, Shehzad/0000-0002-9321-6956
CR Ali R, 2017, ARAB J SCI ENG, V42, P3655, DOI 10.1007/s13369-017-2665-1
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0217-3
   [Anonymous], 2006, ERCIM NEWS
   [Anonymous], 2016, NIST Special Publication 800-57, DOI DOI 10.6028/NIST.SP.800-57PT1R4
   [Anonymous], 2019, IEEE ACCESS
   [Anonymous], 2015, FIPS PUB
   [Anonymous], 2018, J AMBIENT INTELLIGEN
   [Anonymous], 2016, PLOS ONE
   [Anonymous], 2005, TECHNICAL REPORT
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P181, DOI 10.1007/s11042-014-2282-x
   Barman S, 2018, IEEE ACCESS, V6, P38578, DOI 10.1109/ACCESS.2018.2854798
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Canetti R, 2001, LECT NOTES COMPUT SC, V2045, P453
   Chaudhry SA, 2018, MULTIMED TOOLS APPL, V77, P5503, DOI 10.1007/s11042-017-4464-9
   Chen CM, 2019, J AMB INTEL HUM COMP, V10, P3133, DOI 10.1007/s12652-018-1029-3
   Chuang MC, 2014, EXPERT SYST APPL, V41, P1411, DOI 10.1016/j.eswa.2013.08.040
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Ghani A, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.4139
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   Hussain S, 2019, IEEE INTERNET THINGS, V6, P10936, DOI 10.1109/JIOT.2019.2934947
   Irshad A, 2018, MULTIMED TOOLS APPL, V77, P1167, DOI 10.1007/s11042-016-4236-y
   Irshad A, 2017, MULTIMED TOOLS APPL, V76, P16463, DOI 10.1007/s11042-016-3921-1
   Juang WS, 2008, IEEE T IND ELECTRON, V55, P2551, DOI 10.1109/TIE.2008.921677
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kumar V, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4103
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Lee JK, 2002, ELECTRON LETT, V38, P554, DOI 10.1049/el:20020380
   Lin CH, 2004, COMPUT STAND INTER, V27, P19, DOI 10.1016/j.csi.2004.03.003
   Lin H, 2017, MULTIMED TOOLS APPL, V76, P2315, DOI 10.1007/s11042-015-3220-2
   Lu YR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126323
   Lwamo NMR, 2019, INFORM SCIENCES, V477, P369, DOI 10.1016/j.ins.2018.10.037
   Mansoor K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214752
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mir O, 2015, WIRELESS PERS COMMUN, V83, P2439, DOI 10.1007/s11277-015-2538-4
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Nguyen NT, 2018, MULTIMED TOOLS APPL, V77, P23909, DOI 10.1007/s11042-018-5708-z
   Qi MP, 2018, MULTIMED TOOLS APPL, V77, P23335, DOI 10.1007/s11042-018-5683-4
   Qi MP, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3341
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ravanbakhsh N, 2018, MULTIMED TOOLS APPL, V77, P55, DOI 10.1007/s11042-016-4208-2
   Reddy AG, 2017, IEEE ACCESS, V5, P3622, DOI 10.1109/ACCESS.2017.2666258
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Sood SK, 2011, J NETW COMPUT APPL, V34, P609, DOI 10.1016/j.jnca.2010.11.011
   Wu ZY, 2012, J MED SYST, V36, P1529, DOI 10.1007/s10916-010-9614-9
   Zhu ZA, 2012, J MED SYST, V36, P3833, DOI 10.1007/s10916-012-9856-9
NR 49
TC 14
Z9 14
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16907
EP 16931
DI 10.1007/s11042-020-09078-z
EA JUL 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000544843700003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chang, CC
   Lin, CC
   Su, GD
AF Chang, Chin-Chen
   Lin, Chia-Chen
   Su, Guo-Dong
TI An effective image self-recovery based fragile watermarking using
   self-adaptive weight-based compressed AMBTC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Self-recovery; Bit-reduction based AMBTC
   technology; Self-adaptive weight
ID TAMPER DETECTION; SCHEME; AUTHENTICATION; RESTORATION; SIGNATURE; SECURE
AB The quality of the watermarked image is degraded by introducing a large amount of the watermark, which also draws more attention of malicious attackers. Therefore, it is important to improve the quality of a watermarked image and improve the restoration capability of a tampered image. For this, a novel self-recovery based fragile watermarking scheme is proposed in this paper. To improve the watermarked image quality, a bit-reduction based AMBTC technology is employed to generate a watermark with fewer bits. The watermark is then embedded into the original image using turtle shell based data hiding technique. In the tampering detection phase, the high accuracy for tampering localization is achieved employing a two-level tampering detection strategy. Additionally, an effective self-adaptive weight-based recovery algorithm and an image inpainting algorithm are sequentially employed to provide improved recovered image quality. The experimental results show that the watermarked images appear to demonstrate higher quality (up to 49.76 dB), and the averagePSNRof recovered images can be up to 34.65 dB, which is higher than that of the state-of-the-art methods.
C1 [Chang, Chin-Chen] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Chang, Chin-Chen; Su, Guo-Dong] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
   [Su, Guo-Dong] Fujian Prov Univ, Fujian Normal Univ, Fuqing Branch, Engn Res Ctr ICH Digitalizat & Multisource Inform, Fuzhou 350500, Peoples R China.
C3 Hangzhou Dianzi University; Feng Chia University; Providence University
   - Taiwan; Fuzhou University; Fujian Normal University
RP Chang, CC (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.; Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM alan3c@gmail.com; mhlin3@pu.edu.tw; gdsu0206@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
OI Lin, Chia-Chen/0000-0003-4480-7351
FU Open Fund of Engineering Research Center for ICH Digitalization and
   Multi-Source Information Fusion of Fujian Province [FJ-ICH201901];
   Education-Scientific Research Project for Middle-Aged and Young of
   Fujian Province [JAT160574, JT180621, JAT190488]; Natural Science
   Foundation of Fujian Province
FX This work was supported by the Open Fund of Engineering Research Center
   for ICH Digitalization and Multi-Source Information Fusion of Fujian
   Province (FJ-ICH201901), the Education-Scientific Research Project for
   Middle-Aged and Young of Fujian Province (JAT160574, JT180621 and
   JAT190488), and the Natural Science Foundation of Fujian Province.
CR [Anonymous], 2013, P 3 INT C TRENDS INF, DOI DOI 10.1007/978-1-4614-3363-7_74
   [Anonymous], 2019, INT J ADV INTELL PAR
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Criminisi A., 2003, P 2003 IEEE COMP SOC, P1
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Guzman AM, 2013, IEEE J BIOMED HEALTH, V17, P214, DOI 10.1109/TITB.2012.2207729
   Hariyanto E., 2016, Int J Sci Res (IJSR), V5, P1363
   Hemida O, 2020, MULTIMED TOOLS APPL, P1
   Hemida O, 2019, MULTIMED TOOLS APPL, V78, P12373, DOI 10.1007/s11042-018-6664-3
   Hesabi Somayeh, 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P119, DOI 10.1109/ICSIP.2010.5697453
   Jiao SM, 2019, OPT LASER TECHNOL, V109, P370, DOI 10.1016/j.optlastec.2018.08.011
   Kim C, 2018, PERS UBIQUIT COMPUT, V22, P11, DOI 10.1007/s00779-017-1061-x
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lu HT, 2003, ELECTRON LETT, V39, P898, DOI 10.1049/el:20030589
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Sathya SPA, 2020, IET IMAGE PROCESS, V14, P366, DOI 10.1049/iet-ipr.2019.0341
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Sharma K, 2017, PRACTICE EXPERIENCE, V18, piii
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shrivastava G, 2018, IGI GLOBAL
   Shrivastava G., 2018, ADV RES MODEL DRIVEN
   Su GD., 2018, COMPUTER SYSTEMS APP, V27, P265
   Su GD, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102618
   WALTON S, 1995, DR DOBBS J, V20, P18
   Wong PW, 1998, IMAGE PROCESSING IMAGE QUALITY IMAGE CAPTURE SYSTEMS CONFERENCE, P374
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Xu LJ, 2004, IEEE T INSTRUM MEAS, V53, P1539, DOI 10.1109/TIM.2004.834066
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Zhang XP, 2009, LECT NOTES COMPUT SC, V5703, P268, DOI 10.1007/978-3-642-03688-0_24
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
NR 40
TC 12
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24795
EP 24824
DI 10.1007/s11042-020-09132-w
EA JUN 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543615200001
DA 2024-07-18
ER

PT J
AU Guo, JL
   Xue, YB
   Cai, J
   Gao, Z
   Xu, GP
   Zhang, H
AF Guo, Junliang
   Xue, Yanbing
   Cai, Jing
   Gao, Zan
   Xu, Guangping
   Zhang, Hua
TI A bus passenger re-identification dataset and a deep learning baseline
   using triplet embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Benchmark; Bus passenger re-identification dataset; Triplet loss; ResNet
AB Bus passenger re-identification is a special case of person re-identification, which aims to establish identity correspondence between the front door camera and the back door camera. In bus environment,it is hard to capture the full body of the passengers. So this paper proposes a bus passenger re-identification dataset,which contains 97,136 head images of 1,720 passengers obtained from hundreds of thousands of video frames with different lighting and perspectives. We also provide a evaluation applied to the dataset based on deep learning and triplet loss. After data augmentation,using ResNet with trihard loss as benchmark network and pre-training on pedestrian re-identification dataset Market-1501, we achieve mAP accuracy of 55.79% and Rank-1 accuracy of 67.91% on passenger re-identification dataset.
C1 [Guo, Junliang; Xue, Yanbing; Cai, Jing; Gao, Zan; Xu, Guangping; Zhang, Hua] Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin, Peoples R China.
   [Guo, Junliang; Xue, Yanbing; Cai, Jing; Gao, Zan; Xu, Guangping] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin, Peoples R China.
   [Zhang, Hua] Tianjin Sino German Univ Appl Sci, Tianjin, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology
RP Xue, YB (corresponding author), Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin, Peoples R China.; Xue, YB (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin, Peoples R China.
EM yanbingxue@163.com
FU National Natural Science Foundation of China [U1509207, 61572357and
   61872270]; Natural Science Foundation of Tianjin [18JCYBJC85500];
   Tianjin Science and Technology Project [18ZXZNGX00150]
FX This research has been supported by National Natural Science Foundation
   of China (U1509207, 61572357and 61872270). Natural Science Foundation of
   Tianjin (18JCYBJC85500), Tianjin Science and Technology
   Project(18ZXZNGX00150).
CR [Anonymous], 2016, arXiv preprint arXiv:1611.05244
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   DONG H, 2018, NEUROCOMPUTING
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hermans Alexander, 2017, ARXIV170307737
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xu HC, 2017, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aa7a3e
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
NR 16
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16425
EP 16440
DI 10.1007/s11042-020-08944-0
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000539939200005
DA 2024-07-18
ER

PT J
AU Sheela, CJJ
   Suganthi, G
AF Sheela, C. Jaspin Jeba
   Suganthi, G.
TI Brain tumor segmentation with radius contraction and expansion based
   initial contour detection for active contour model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active contour model; Brain tumor; Dilation; Erosion; Thresholding; MRI
   images; Fuzzy-C-means algorithm; Specificity; Sensitivity; Dice score;
   Probabilistic Rand index; Hausdorff distance
ID FEATURE-SELECTION; GAIT; CLASSIFICATION
AB This paper proposes a novel brain tumor segmentation algorithm that uses Active Contour Model and Fuzzy-C-Means optimization. In Active Contour model, the initial Contour selection is a challenging task for MRI brain tumor segmentation because the accuracy of active contour segmentation depends on initial contour. This method uses the two level morphological reconstruction processes such as Dilation and Erosion along with thresholding process for minimizing the non-tumor region. The segmented region thus obtained is not accurate that also contains non-tumor region. Also there is a chance of missing the tumor region along with background while performing two level morphological reconstructions. In order to overcome these issues, active contour model is used to segment the complete tumor part. The initial Contour for Active Contour model is detected by forming a circular region around the tumor region. The radius of the circular region is contracted or expanded based on the shape of the tumor. This proposed Radius Contraction and Expansion (RCE) technique is used to select the initial contour of active Contour model. Further Fuzzy-C-Means algorithm is used to optimize the edge pixels because the boundary of active contour model output also contains the non tumor pixels. The performance of the proposed segmentation algorithm was evaluated using the metrics such as specificity, sensitivity, dice score, Probabilistic Rand Index (PRI) and Hausdorff Distance (HD) onT(1)- weighted contrast enhanced image dataset. The experimental result shows that the proposed segmentation algorithm provides a good performance when compared to the state-of-the-art segmentation methods.
C1 [Sheela, C. Jaspin Jeba] Manonmaniam Sundaranar Univ, St Xaviers Autonomous Coll, Tirunelveli 627012, Tamil Nadu, India.
   [Suganthi, G.] Manonmaniam Sundaranar Univ, Womens Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Sheela, CJJ (corresponding author), Manonmaniam Sundaranar Univ, St Xaviers Autonomous Coll, Tirunelveli 627012, Tamil Nadu, India.
EM jaspinjebasheela@gmail.com; dr_suganthi_wcc@yahoo.co.in
CR Ain Q, 2014, APPL SOFT COMPUT, V21, P330, DOI 10.1016/j.asoc.2014.03.019
   Angulakshmi M, 2017, INT J IMAG SYST TECH, V27, P66, DOI 10.1002/ima.22211
   Aparajeeta J, 2016, APPL SOFT COMPUT, V41, P104, DOI 10.1016/j.asoc.2015.12.003
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cabria I, 2017, INFORM FUSION, V36, P1, DOI 10.1016/j.inffus.2016.10.003
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843
   Clark MC, 1998, IEEE T MED IMAGING, V17, P187, DOI 10.1109/42.700731
   Dass R., 2012, IJECT, V3, P2230
   Elyasi A, 2011, J AM SCI, V7
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Ilhan U, 2017, PROCEDIA COMPUT SCI, V120, P580, DOI 10.1016/j.procs.2017.11.282
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Li JC, 2019, NEUROCOMPUTING, V358, P10, DOI 10.1016/j.neucom.2019.05.025
   Liang Z, 2012, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON INNOVATION AND MANAGEMENT, P248
   Morales S, 2017, COMPUT METH PROG BIO, V145, P167, DOI 10.1016/j.cmpb.2017.04.006
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Patil Prithvi., 2019, IEEE, P1, DOI DOI 10.1109/ICASERT.2019.8934463
   Selvaraj D., 2013, Indian Journal of Computer Science and Engineering (IJCSE), P0976
   Semwal VB, 2019, ADV INTELLIGENT SYST
   Semwal VB, 2018, IEEE T AUTOM SCI ENG, V15, P104, DOI 10.1109/TASE.2016.2594191
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Sheela CJ, 2019, J KING SAUD UNIV-COM
   Sujji G. Evelin, 2013, INT J ADV COMPUTER R, V3, P2249
   Tarkhaneh O, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.037
   Thaha MM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1416-0
   Tuhin UP, 2012, INT J ENG RES APPL, V2, P226
   Vijay V, 2016, PROCEDIA COMPUT SCI, V92, P475, DOI 10.1016/j.procs.2016.07.370
   Viji KSA, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P691
   Wang Guotai, 2018, IEEE T MED IMAGING I
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 39
TC 9
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23793
EP 23819
DI 10.1007/s11042-020-09006-1
EA JUN 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539939200003
DA 2024-07-18
ER

PT J
AU Tran, SN
   Ngo, TS
   Zhang, Q
   Karunanithi, M
AF Tran, Son N.
   Ngo, Tung-Son
   Zhang, Qing
   Karunanithi, Mohan
TI Mixed-dependency models for multi-resident activity recognition in smart
   homes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart homes; Multi-resident activity recognition; Hidden Markov Models
ID HIDDEN MARKOV-MODELS
AB Recent growing interest in ambient intelligent environments has driven a desire for effective models to reason about activities of multiple residents. Such models are the keystone for the future of smart homes where occupants can be assisted with non-intrusive technologies. Much attention has been put on this research, however current works tend to focus on developing statistical algorithms for prediction, whilst there still lacks a study to fully understand the relations of residents' behaviours and how they are reflected through the sensors' states. In this paper we investigate the dependencies of the activities from residents and their interaction with the environments. We represent such dependencies in Bayesian networks that leads to construction of six variants of Hidden Markov Models (HMMs). Furthermore, we argue that a complete model should embody more than one type of dependency. Therefore, we propose an ensemble of HMMs, and then generalize it to a novel mixed-dependency model. In the experiments we perform intensive evaluation of our study on multi-resident activity recognition task. The results show that the proposed models outperform other models in three smart home environments, thus asserting our hypothesis.
C1 [Tran, Son N.] Univ Tasmania, Discipline ICT, Newnham Campus, Launceston, Tas, Australia.
   [Ngo, Tung-Son] FPT Univ, Dept Comp Sci, Hanoi, Vietnam.
   [Zhang, Qing; Karunanithi, Mohan] Royal Brisbane & Womens Hosp, CSIRO, Australian E Hlth Res Ctr, Level 5,UQ Hlth Sci Bldg, Brisbane, Qld, Australia.
C3 University of Tasmania; FPT University; Royal Brisbane & Women's
   Hospital; University of Queensland; Commonwealth Scientific & Industrial
   Research Organisation (CSIRO)
RP Tran, SN (corresponding author), Univ Tasmania, Discipline ICT, Newnham Campus, Launceston, Tas, Australia.
EM sn.tran@utas.edu.au
RI Karunanithi, Mohanraj/A-9643-2011
OI Karunanithi, Mohanraj/0000-0002-9141-932X; Ngo, Tung
   Son/0000-0003-4098-3147; Tran, Son/0000-0002-5912-293X
CR Alemdar H, 2013, INT CONF PER COMP, P232, DOI 10.4108/icst.pervasivehealth.2013.252120
   Aminikhanghahi S, 2019, PERVASIVE MOB COMPUT, V53, P75, DOI 10.1016/j.pmcj.2019.01.004
   Benmansour A, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2835372
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Chen R, 2014, ENTROPY-SWITZ, V16, P2184, DOI 10.3390/e16042184
   Chiang YT, 2010, IEEE INT C INT ROBOT, P3753, DOI 10.1109/IROS.2010.5650340
   Chung Junyoung, 2014, ARXIV14123555
   Cook Diane J, 2010, IEEE Intell Syst, V2010, P1
   Cook DJ, 2010, CYBERNET SYST, V41, P90, DOI 10.1080/01969720903584183
   CRANDALL AS, 2008, P AAAI FALL S AI ELD
   Dahmen J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051181
   Dahmen J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040737
   Davis RIA, 2003, PATTERN ANAL APPL, V6, P327, DOI 10.1007/s10044-003-0198-6
   Feuz KD, 2017, KNOWL INF SYST, V53, P337, DOI 10.1007/s10115-017-1043-3
   Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087
   Ghods A., 2019, ARXIV190705597
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsu KC, 2010, INT C COMPUT ENG APP, P417, DOI 10.1109/ICCEA.2010.231
   Mehr HD, 2016, 2016 4TH INTERNATIONAL ISTANBUL SMART GRID CONGRESS AND FAIR (ICSG), P75
   Minor B, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P805, DOI 10.1145/2783258.2783408
   Minor BD, 2017, IEEE T KNOWL DATA EN, V29, P2744, DOI 10.1109/TKDE.2017.2750669
   Natani Anubhav, 2019, 2019 IEEE 8th Global Conference on Consumer Electronics (GCCE), P340, DOI 10.1109/GCCE46687.2019.9015212
   Prossegger M, 2014, LECT NOTES ARTIF INT, V8779, P182, DOI 10.1007/978-3-319-11298-5_19
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Singla G, 2010, J AMB INTEL HUM COMP, V1, P57, DOI 10.1007/s12652-009-0007-1
   Sutskever I, 2014, ADV NEUR IN, V27
   Tan TH, 2018, IEEE SENS J, V18, P9718, DOI 10.1109/JSEN.2018.2866806
   TRAN SN, 2004, SMART ASSISTED LIVIN, P249
   Tunca C, 2014, SENSORS-BASEL, V14, P9692, DOI 10.3390/s140609692
   WANG A, 2016, WAIM WORKSH
   Wang L, 2011, PERVASIVE MOB COMPUT, V7, P287, DOI 10.1016/j.pmcj.2010.11.008
NR 31
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23445
EP 23460
DI 10.1007/s11042-020-09093-0
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538977500002
DA 2024-07-18
ER

PT J
AU Sidaty, N
   Heulot, J
   Hamidouche, W
   Pelcat, M
   Menard, D
AF Sidaty, Naty
   Heulot, Julien
   Hamidouche, Wassim
   Pelcat, Maxime
   Menard, Daniel
TI Software HEVC video decoder: towards an energy saving for mobile
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Quality assessment; Mobile energy saving; Filter complexity
   reduction; MOS; Statistical analysis; ARM
AB With the explosive growth of mobile video consumption over the Internet, delivering video at high quality while controlling the energy consumption of embedded decoding devices is becoming a primary concern. In this context, this paper demonstrates that tailored energy savings strategies, coupled with a video quality assessment protocol, have the potential to reduce the energy consumption of video decoding. We investigate on a real-time, optimized HEVC decoder, the relationship between the perceived mobile video quality and the energy consumption of the decoder. In addition to low level optimizations for ARM Neon platforms, two energy reduction methods named Approximate and Skipping have been investigated. Results show that energy savings of up to 20% can be achieved by using these methods with the same subjective perceived video quality. These subjective results confirm objective measurements, using PSNR and SSIM metrics, that depict a limited video quality degradation.
C1 [Sidaty, Naty] INSA Rennes, ViQuaM Labs, 20 Ave Buttes Coesmes, F-35000 Rennes, France.
   [Heulot, Julien; Hamidouche, Wassim; Pelcat, Maxime; Menard, Daniel] INSA Rennes, IETR, 20 Ave Buttes Coesmes, F-35000 Rennes, France.
C3 Institut National des Sciences Appliquees de Rennes; Universite de
   Rennes; Universite de Rennes; Institut National des Sciences Appliquees
   de Rennes
RP Sidaty, N (corresponding author), INSA Rennes, ViQuaM Labs, 20 Ave Buttes Coesmes, F-35000 Rennes, France.
EM Naty.Sidaty@insa-rennes.fr; Julien.Heulot@insa-rennes.fr;
   Wassim.Hamidouche@insa-rennes.fr; Maxime.Pelcat@insa-rennes.fr;
   Daniel.Menard@insa-rennes.fr
RI Menard, Daniel/AAL-7821-2021; Pelcat, Maxime/F-6443-2014
OI Sidaty, Naty/0000-0002-1953-3574
FU French FUI project EFIGI; European Celtic-Plus project 4KREPROSYS -
   French Industry Ministry
FX This work is partially supported by the French FUI project EFIGI and by
   the European Celtic-Plus project 4KREPROSYS funded by French Industry
   Ministry.
CR Abeydeera M, 2016, IEEE T CIRC SYST VID, V26, P236, DOI 10.1109/TCSVT.2015.2469113
   [Anonymous], INA231 HIGH LOW SID
   Assembly IR, 2003, METH SUBJ ASS QUAL T
   Bahran NA, 2019, MULTIMED TOOLS APPL, V78, P22351, DOI 10.1007/s11042-019-7562-z
   Bariani M., 2014, 2014 IEEE 11 CONS CO, P77, DOI [10.1109/CCNC.2014.7056307, DOI 10.1109/CCNC.2014.7056307]
   Benmoussa Y, 2015, THESIS
   Benmoussa Y, 2013, 16TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2013), P890, DOI 10.1109/DSD.2013.100
   Bossen F, 2012, IEEE T CIRC SYS VIDE, V22
   Bossen F, 2020, JCTVCH1100, P16
   Chi CC, 2015, IEEE T CIRC SYS VIDE, V25
   Chi CC, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2685551
   Chi CC, 2013, J SIGNAL PROCESS SYS, V71, P247, DOI 10.1007/s11265-012-0714-2
   Chiang P-T, 2016, IEEE T CIRC SYS VIDE, V26
   Cordeiro PJ, 2008, I SYMP CONSUM ELECTR, P114
   De Micheli G., 1997, DESIGN TECHNIQUES CA
   Engelhardt D, 2014, IEEE T CONSUMER ELEC, V60
   Holmbacka S., 2014, DES ARCH SIGN IM PRO, P1
   Jerbi K, 2017, J SIGNAL PROCESS SYS, V87, P127, DOI 10.1007/s11265-016-1113-x
   Jose J, 2014, IEEE INT C CL COMP, P10, DOI 10.1109/CLUSTER.2014.6968754
   Jridi M, 2017, IEEE T CIRC SYST VID, V27, P1815, DOI 10.1109/TCSVT.2016.2556578
   Ju CC, 2014, PROC EUR SOLID-STATE, P195
   Lappalainen V, 2012, IEEE T CIRC SYS VIDE, V12
   Lee SW, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P119, DOI 10.1109/MMSP.2007.4412832
   Lv H., 2012, P VIS COMM IM PROC N, P1
   Mercat A, 2017, INT CONF ACOUST SPEE, P1158, DOI 10.1109/ICASSP.2017.7952338
   Mohammadi P., 2014, SUBJECTIVE OBJECTIVE
   Monteiro E, 2015, IEEE INT SYMP CIRC S, P1278, DOI 10.1109/ISCAS.2015.7168874
   Nogues E., 2015, 2015 IEEE INT C MULT, P1
   Nogues E., 2014, P IEEE WORKSH SIGN P, P1, DOI 10.1109/SiPS.2014.6986059
   Puschel Markus, 2008, IEEE T SIGNAL PROCES, V56
   Raffin E., 2015, P 12 ACM INT C COMP, DOI [10.1145/2742854.2747286, DOI 10.1145/2742854.2747286]
   Raffin E, 2016, J REAL-TIME IMAGE PR, V12, P495, DOI 10.1007/s11554-015-0512-8
   Semsarzadeh M., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P925, DOI 10.1109/ICME.2012.91
   Sidaty N, 2017, EUR SIGNAL PR CONF, P1026, DOI 10.23919/EUSIPCO.2017.8081363
   Silveira D, 2017, EUR SIGNAL PR CONF, P1519, DOI 10.23919/EUSIPCO.2017.8081463
   Sullivan GJ, 2012, IEEE T CIRC SYS VIDE, V22
   Tan TK, 2016, IEEE T CIRC SYST VID, V26, P76, DOI 10.1109/TCSVT.2015.2477916
   Tikekar M, 2014, IEEE J SOLID STATE C, V49
   Tseng C-C, 2008, 2008 IEEE AS PAC C C
   Ugur K, 2013, IEEE J SELECTED TOPI, V7
   Wiegand T, 2003, IEEE T CIRC SYS VIDE, V13
   Zhou D, 2017, IEEE J SOLID STATE C, V52
NR 42
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 26861
EP 26884
DI 10.1007/s11042-020-09025-y
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000538508600001
DA 2024-07-18
ER

PT J
AU Alice, K
   Ramaraj, N
   Rajagopalan, SP
AF Alice, K.
   Ramaraj, N.
   Rajagopalan, S. P.
TI Rotation invariant image authentication using Haralick features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rotation invariant; Image authentication; Circular blocks; Haralick
   features; Content preserving modification; Tamper detection;
   Localization; Robustness; Sensitivity; Correlation coefficient
ID ROBUST; SECURE
AB The image authentication plays a vital role in modern multimedia technology. The existing technique for preserving authentication abided the content only by preserving transformations like scaling, additive noise, gamma correction, brightness adjustments, water marking etc., but it fails to authenticate larger angles rotations. Very few systems had authenticated rotations to a smaller angle which was less than 5(o). In existing system, the failure occurred in authenticating large angle rotation is due to the finite divisions of equal sized square block for calculating the local features. In this paper concept of dividing circular blocks with equal area is analyzed for better competency. The Haralick features are mostly calculated for square block. In the proposed system 14 features of Haralick has been grouped to hash code for each circular blocks in sender side. In receiver side, the same procedure is followed to generate hash code and the comparison is carried out to verify the authentication. In addition to scaling, brightness, contrast adjustment, gamma correction etc., the proposed system tolerates rotation even to greater angles up to 360(o) with better efficiency.
C1 [Alice, K.; Rajagopalan, S. P.] Anna Univ, GKM Coll Engn & Technol, Dept CSE, Chennai 600063, Tamil Nadu, India.
   [Ramaraj, N.] Vignans Univ, Dept EEE, Guntur, Andhra Pradesh, India.
C3 Anna University; Anna University Chennai; Vignan's Foundation for
   Science, Technology & Research (VFSTR)
RP Alice, K (corresponding author), Anna Univ, GKM Coll Engn & Technol, Dept CSE, Chennai 600063, Tamil Nadu, India.
EM k_alice_suresh@yahoo.com; ramaraj_gm@yahoo.com; sasirekaraj@yahoo.co.in
OI K, Alice/0000-0002-9920-549X
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], P ICIP
   [Anonymous], 4869719 CUCTR
   [Anonymous], IEEE EURASIP WORKSH
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Gharde ND, 2018, MULTIMED TOOLS APPL, V77, P30815, DOI 10.1007/s11042-018-6115-1
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hashmi MF, 2014, ENG LETT, V22, P4
   Khelifi F, 2010, IEEE T IMAGE PROCESS, V19, P981, DOI 10.1109/TIP.2009.2038637
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Nguyen TH, 2015, IEEE RIVF INT C COMP
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Sebastian LS, 2015, PROCEDIA COMPUT SCI, V46, P1554, DOI 10.1016/j.procs.2015.02.081
   Storck D., 1996, Mobile Communications. Technology, Tools, Applications, Authentication and Security. IFIP World Conference on Mobile Communications, P309
   Tabatabaei SAH, 2015, IEEE T MULTIMEDIA, V17, P945, DOI 10.1109/TMM.2015.2432672
   Tang ZJ, 2013, SIGNAL PROCESS, V93, P2061, DOI 10.1016/j.sigpro.2013.01.008
   Ur-Rehman O, 2015, SCC 2015 10 INT ITG
   Wu CW, 2002, IEEE T MULTIMEDIA, V4, P385, DOI 10.1109/TMM.2002.802018
   Wu CW, 2001, P SOC PHOTO-OPT INS, V4314, P241, DOI 10.1117/12.435404
   Yang GY, 2014, EFFICIENT LEGENDRE M
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 22
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17211
EP 17225
DI 10.1007/s11042-019-07750-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600078
DA 2024-07-18
ER

PT J
AU Ding, Z
   Yang, CF
   Ma, JT
   Wei, JG
   Jiang, F
AF Ding, Zhen
   Yang, Chifu
   Ma, Jiantao
   Wei, JianGuo
   Jiang, Feng
TI The online estimation of the joint angle based on the gravity
   acceleration using the accelerometer and gyroscope in the wireless
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IMU; Wireless networks; Gravity acceleration; Joint angle
ID PERFORMANCE; ORIENTATION; KINEMATICS; SENSORS
AB This study aims at the online estimation of the hip and knee angle in the sagittal plane for the motion surveillance only using the tri-axis accelerometers and gyroscopes of IMU, without considering the magnetic disturbance. The proposed method utilizes the projection of gravity acceleration on each sensor coordinate system to estimate the joint angle which rotating around the horizontal axis and approximately horizontal axis. With the third row of the rotation matrix independent of the yaw angle, the proposed method first calculates the projection of the gravity acceleration on each IMU sensor coordinate system only using accelerometer and gyroscope. And then, the rotation matrix between two adjacent coordinate systems is directly calculated. After evaluating the body to sensor rotation matrix, the rotation matrix between two adjacent body segments can be calculated, ultimately. Two types of experiments are adopted in the paper. The results show that the proposed method obtains the outstanding performance with the RMSE lower than 0.8 deg in the horizontal rotation experiment. In the limb joint experiment, the RMSE of the hip joint is lower than 3.12 deg, while the RMSE of the knee joint is lower than 3.83 deg for all predefined locomotion modes. The characteristic of our approach is that it can be run online without any parameter adjustment and additional time latency while ensuring estimation accuracy.
C1 [Ding, Zhen; Yang, Chifu; Ma, Jiantao] Harbin Inst Technol, Sch Mechatron Engn, Harbin, Peoples R China.
   [Wei, JianGuo] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Jiang, Feng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [Jiang, Feng] Pengcheng Lab, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; Tianjin University; Harbin Institute of
   Technology
RP Jiang, F (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.; Jiang, F (corresponding author), Pengcheng Lab, Shenzhen, Peoples R China.
EM 1130429336@qq.com; cfyang@hit.edu.cn; 1057357627@qq.com;
   Jianguo@tju.edu.cn; fjiang@hit.edu.cn
RI JIANG, Feng/HTP-2862-2023; Wei, Jianguo/KBA-3200-2024
OI Wei, Jianguo/0000-0002-8964-9759; Jiang, Feng/0000-0001-8342-1211
CR Bell-Jenje T, 2016, MANUAL THER, V21, P256, DOI 10.1016/j.math.2015.09.010
   Cutti AG, 2010, MED BIOL ENG COMPUT, V48, P17, DOI 10.1007/s11517-009-0545-x
   Dejnabadi H, 2005, IEEE T BIO-MED ENG, V52, P1478, DOI 10.1109/TBME.2005.851475
   Din S, 2018, J PARALLEL DISTR COM, V118, P34, DOI 10.1016/j.jpdc.2017.12.012
   Fong DTP, 2010, SENSORS-BASEL, V10, P11556, DOI 10.3390/s101211556
   Goslinski J, 2015, IEEE SENS J, V15, P3781, DOI 10.1109/JSEN.2015.2397397
   Hassan EA, 2007, J BIOMECH, V40, P930, DOI 10.1016/j.jbiomech.2006.03.019
   Kim Y, 2019, MULTIMED TOOLS APPL, V78, P3009, DOI 10.1007/s11042-018-5610-8
   Laidig D, 2017, INT C REHAB ROBOT, P971, DOI 10.1109/ICORR.2017.8009375
   Liu K, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P3065
   Madgwick S, 2010, EFFICIENT ORIENTATIO, V25, P113
   Mahony R, 2008, IEEE T AUTOMAT CONTR, V53, P1203, DOI 10.1109/TAC.2008.923738
   Millor N, 2014, IEEE T NEUR SYS REH, V22, P926, DOI 10.1109/TNSRE.2014.2331895
   Mohanraj V, 2018, INT J PARALLEL PROG, V46, P904, DOI 10.1007/s10766-017-0545-7
   Palermo E, 2014, MEASUREMENT, V52, P145, DOI 10.1016/j.measurement.2014.03.004
   Picerno P, 2008, GAIT POSTURE, V28, P588, DOI 10.1016/j.gaitpost.2008.04.003
   Picerno P, 2017, GAIT POSTURE, V51, P239, DOI 10.1016/j.gaitpost.2016.11.008
   Roetenberg D, 2005, IEEE T NEUR SYS REH, V13, P395, DOI 10.1109/TNSRE.2005.847353
   Roetenberg D, 2007, IEEE T NEUR SYS REH, V15, P469, DOI 10.1109/TNSRE.2007.903946
   Seel T, 2014, SENSORS-BASEL, V14, P6891, DOI 10.3390/s140406891
   SHUSTER MD, 1981, J GUID CONTROL, V4, P70, DOI 10.2514/3.19717
   Takeda R, 2009, J BIOMECH, V42, P2486, DOI 10.1016/j.jbiomech.2009.07.016
   Vitali RV, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17091970
   Yadav N, 2014, SENSORS-BASEL, V14, P20008, DOI 10.3390/s141120008
   Yuri XP, 2008, IEEE T INSTRUM MEAS, V57, P638, DOI 10.1109/TIM.2007.911646
NR 25
TC 1
Z9 1
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16265
EP 16279
DI 10.1007/s11042-019-07911-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600025
DA 2024-07-18
ER

PT J
AU Zhang, FQ
   Wei, QM
   Xu, LQ
AF Zhang, Fengquan
   Wei, Qiuming
   Xu, Liuqing
TI An fast simulation tool for fluid animation in VR application based on
   GPUs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Fluid animation; Multimedia tool; Real-time; GPUs
ID SPH; IMPLEMENTATION
AB Realistic and real-time simulation of fluid animation is widely used to the application of virtual reality(VR) such as VR game, special effect in film, augmented reality (AR) and so on. However, fast simulation of complex fluid animation problem such as free interaction surface and high impact requires a large number of both physical computations and time steps. It in turn leads to high computational cost. In order to improve the problem, we design a fast tool to accelerate and simulate fluid animation using multi-node graphics processing units clusters. In this paper, we present a fluid animation model tool for VR application based on multi-GPU cluster. The model method of position-based fluid (PBF) is implemented on our tool, and some strategies for GPUs optimizations are applied to parallel system based on the character of hardware. We first present an efficient data structure for speeding up memory access. Then, an optimized parallel framework is designed to get higher performance. We adjust the size of grid sptial index, reducing the access and thread synchronization during the neighborhood search, which greatly improve the efficiency on GPU. The key work of extending the PBF method from single GPU to GPU clusters, a spatial decomposition strategy is presented based on Orthogonal Recursive Bisection(ORB) model. Finally, an effective VR tool for real-time fluid animation modeling on the GPUs cluster is designed which can create various vivid animation. The performance and efficiency of our method are demonstrated using multiple VR scenes.
C1 [Zhang, Fengquan; Wei, Qiuming] North China Univ Technol, Sch Informat Sci, Beijing 100144, Peoples R China.
   [Xu, Liuqing] Chinese Acad Sci, Airborne Remote Sensing Ctr, Inst Remote Sensing & Digital Earth, Beijing 100094, Peoples R China.
C3 North China University of Technology; Chinese Academy of Sciences; The
   Institute of Remote Sensing & Digital Earth, CAS
RP Zhang, FQ (corresponding author), North China Univ Technol, Sch Informat Sci, Beijing 100144, Peoples R China.
EM zhangfengquan112@163.com; 18210527917@163.com; xulq@radi.ac.cn
CR Anderson JA, 2008, J COMPUT PHYS, V227, P5342, DOI 10.1016/j.jcp.2008.01.047
   Band S, 2018, WORKSH VIRT REAL INT
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J, 2014, COMPUT GRAPH-UK, V44, P1, DOI 10.1016/j.cag.2014.07.004
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   Cornelis J, 2019, VISUAL COMPUT, V35, P579, DOI 10.1007/s00371-018-1488-8
   Deng W, 2019, IEEE ACCESS, V7, P20281, DOI 10.1109/ACCESS.2019.2897580
   Diziol R, 2011, P 2011 ACM SIGGRAPH, P1
   Ferrari A, 2009, COMPUT FLUIDS, V38, P1203, DOI 10.1016/j.compfluid.2008.11.012
   Frezzotti A, 2011, COMPUT PHYS COMMUN, V182, P2445, DOI 10.1016/j.cpc.2011.07.002
   Hérault A, 2010, J HYDRAUL RES, V48, P74, DOI 10.1080/00221686.2010.9641247
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Kalojanov J., 2009, Proceedings of the 1st ACM conference on High Performance Graphics - HPG '09 (New York, New York, USA, 2009), P23
   Liu JX, 2004, INT J PARALLEL PROG, V32, P167, DOI 10.1023/B:IJPP.0000029272.69895.c1
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Moulinec C, 2008, CMES-COMP MODEL ENG, V25, P133
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Potluri S, 2012, IEEE SYM PARA DISTR, P1848, DOI 10.1109/IPDPSW.2012.228
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Wang H, 2011, IEEE INT C CL COMP, P308, DOI 10.1109/CLUSTER.2011.42
   Zhang FQ, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0227-9
   Zhang FQ, 2013, INT J NUMER MODEL EL, V26, P397, DOI 10.1002/jnm.1890
NR 23
TC 10
Z9 10
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16683
EP 16706
DI 10.1007/s11042-019-08002-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600049
DA 2024-07-18
ER

PT J
AU Zhou, PB
   Li, KY
   Wei, W
   Wang, Z
   Zhou, MQ
AF Zhou, Pengbo
   Li, Kaiyue
   Wei, Wei
   Wang, Zhe
   Zhou, Mingquan
TI Fast generation method of 3D scene in Chinese landscape painting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE The three-dimensional modeling; Height map; Flow chart
ID NAVIGATION
AB The three-dimensional (3D) modeling of Chinese landscape painting is of great significance for the digital protection of cultural heritage and the production of virtual reality content. A fast modeling method to create 3D landscape scenes for traditional Chinese painting is proposed in this paper, based on integrated terrain modeling and the water flow rendering algorithm. A height map generation algorithm based on auxiliary lines is first proposed to carry out fast modeling from a simple two-dimensional contour to create a 3D mountain model. A realistic flow simulation that fits the topography is then undertaken, based on a flow chart which is calculated using the particle force in the normal grid of topography, and the theory of smoothing particle hydrodynamics. Finally, a stylistic scene that conforms to the artistic concept of traditional Chinese painting is acquired by optimizing the parameters. The interactive modeling platform of the integrated algorithm is tested in this study, and compared with existing research. Results show the method can achieve real-time rendering and realistic rendering to rapidly generate a 3D scene model consistent with a traditional painting scene, and provide support for the follow up development of virtual reality applications.
C1 [Zhou, Pengbo; Li, Kaiyue; Wang, Zhe; Zhou, Mingquan] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
   [Wei, Wei] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
C3 Beijing Normal University; Xi'an University of Technology
RP Zhou, PB (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.; Wei, W (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
EM mqzhou@bnu.edu.cn; weiwei@xaut.edu.cn
RI Wei, Wei/ABB-8665-2021; wei, wei/HHR-8613-2022; zhou,
   pengbo/AAU-8811-2021; wei, wei/IQW-1347-2023; ZHOU, MING/JVP-2920-2024
OI Wei, Wei/0000-0002-8751-9205; zhou, pengbo/0000-0002-8926-2124; 
CR Chen PF, 2018, IEEE T DEPEND SECURE, V15, P675, DOI 10.1109/TDSC.2016.2604381
   Da-Jin Li, 2015, WSEAS Transactions on Computers, V14, P347
   Fan X., 2017, ADV MATER SCI ENG, V2017, P1, DOI DOI 10.1007/511042-017-5083-1
   Forkuo EK, 2008, INT ARCH PHOTOGRAMME, P151
   Hoesel FV, 2011, P INT C COMP GRAPH I, P11
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Jaworski M, 2018, IEEE T NEUR NET LEAR, V29, P2516, DOI 10.1109/TNNLS.2017.2698204
   Ke Q, 2018, NEUROCOMPUTING, V288, P3, DOI 10.1016/j.neucom.2017.07.072
   Levet Florian, 2007, Proceedings Graphics Interface 2007, P27, DOI 10.1145/1268517.1268524
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Reinhardt S, 2017, INT SOC STUD FORUM, P25
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Schmidt Ryan., 2006, ACM SIGGRAPH 2006 CO, P14, DOI [10.1145/1185657.1185775, DOI 10.1145/1185657.1185775]
   Schwarzkopf O.., 2000, Computational Geometry: Algorithms and Applications, V2nd
   [石永鑫 Shi Yongxin], 2003, [计算机辅助设计与图形学学报, Journal of Compute-Aided Design and Graphics], V15, P667
   Su  J., 2018, TELECOMMUN SYST, V67, P1
   Vlachos Alex., 2010, WATER FLOW PORTAL 2
   Wei W, 2014, INT J COMMUN SYST, V27, P3013, DOI 10.1002/dac.2522
   Wei W, 2018, IEEE T COMPUT SOC SY, V5, P736, DOI 10.1109/TCSS.2018.2855047
   Wei W, 2018, IEEE ACCESS, V6, P33766, DOI 10.1109/ACCESS.2017.2682845
   Wei W, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/908623
   Wei W, 2018, INF TECHNOL CONTROL, V47, P140, DOI 10.5755/j01.itc.47.1.19982
   Wei W, 2017, IEEE ACCESS, V5, P27810, DOI 10.1109/ACCESS.2017.2681684
   Wei W, 2017, INFORM SCIENCES, V408, P100, DOI 10.1016/j.ins.2017.04.042
   Wei W, 2012, INT J DISTRIB SENS N, DOI 10.1155/2012/135054
   Wei W, 2018, IEEE T SERV COMPUT, V11, P78, DOI 10.1109/TSC.2016.2528246
   Wei W, 2014, ABSTR APPL ANAL, DOI 10.1155/2014/797561
   Wei W, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/154630
   Wei W, 2011, SENSORS-BASEL, V11, P4794, DOI 10.3390/s110504794
   Xunxiang Li, 2011, Proceedings of the 2011 Workshop on Digital Media and Digital Content Management (DMDCM 2011), P13, DOI 10.1109/DMDCM.2011.13
   Yan H, 2009, COMPUT ANIMAT VIRT W, V20, P417, DOI 10.1002/cav.300
   Yang L, 2015, IEEE T PARALL DISTR, V26, P3149, DOI 10.1109/TPDS.2013.276
   Zhang Haisong, 2004, Journal of Computer Aided Design & Computer Graphics, V16, P1485
NR 35
TC 5
Z9 5
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16441
EP 16457
DI 10.1007/s11042-019-7476-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600035
DA 2024-07-18
ER

PT J
AU Picos, K
   Orozco-Rosas, U
AF Picos, Kenia
   Orozco-Rosas, Ulises
TI Evolutionary correlation filtering based on pseudo-bacterial genetic
   algorithm for pose estimation of highly occluded targets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Evolutionary correlation filtering; Template match
   filters; Three-dimensional pose; Pseudo-bacterial genetic algorithm
ID PATTERN-RECOGNITION; NOISY TARGET; TRACKING; ILLUMINATION
AB An accurate method based on evolutionary correlation filtering to solve pose estimation of highly occluded targets is presented. The proposed method performs multiple correlation operations between an input scene and a bank of filters designed in frequency-domain. Each filter is computed with statistical parameters of a real-world scene and a template that contains information of the target in a single pose parameter configuration. A vast set of templates is generated from multiple views of a three-dimensional model of the target, which are created synthetically with computer graphics. An evolutionary approach in the bank of filter construction for optimizing the pose estimation parameters is implemented. The evolutionary computation technique based on a pseudo-bacterial genetic algorithm yields high estimation accuracy finding the best filter that produces the highest matching score. The proposed evolutionary correlation filtering yields good convergence of the bank of filter optimization, which produces a reduction of the number of computational operations. Experimental results demonstrate the robustness of the proposed method in terms of detection performance and pose estimation of highly occluded targets compared with state-of-the-art methods.
C1 [Picos, Kenia; Orozco-Rosas, Ulises] CETYS Univ, Ctr Innovac & Diseno CEID, Ave CETYS Univ 4, Tijuana 22210, BC, Mexico.
RP Picos, K (corresponding author), CETYS Univ, Ctr Innovac & Diseno CEID, Ave CETYS Univ 4, Tijuana 22210, BC, Mexico.
EM kenia.picos@cetys.mx; ulises.orozco@cetys.mx
RI Orozco-Rosas, Ulises/X-8063-2018
OI Orozco-Rosas, Ulises/0000-0002-9627-0093; Picos,
   Kenia/0000-0001-6203-5389
FU Coordinacion Institucional de Investigacion of CETYS Universidad;
   Consejo Nacional de Ciencia y Tecnologia (CONACYT)
FX This work was supported by the Coordinacion Institucional de
   Investigacion of CETYS Universidad, and by Consejo Nacional de Ciencia y
   Tecnologia (CONACYT).
CR Aguilar-González PM, 2008, LECT NOTES COMPUT SC, V5197, P38, DOI 10.1007/978-3-540-85920-8_5
   Al-Obaydy WNI, 2020, MULTIMED TOOLS APPL, V79, P2897, DOI 10.1007/s11042-019-08414-2
   Altenberg L., 2016, ENCY EVOLUTIONARY BI, P40, DOI DOI 10.1016/B978-0-12-800049-6.00307-3
   [Anonymous], 2005, CORRELATION PATTERN
   [Anonymous], 1998, EVOLUTIONARY COMPUTA
   [Anonymous], 2011, TEXTS COMPUT SCI
   [Anonymous], 2015, BIOMED RES INT, DOI [DOI 10.1371/J0URNAL.PGEN.1005164, DOI 10.1155/2015/238971]
   Soulami KB, 2020, MULTIMED TOOLS APPL, V79, P18941, DOI 10.1007/s11042-019-08449-5
   Blum L., 2004, Notices Amer. Math. Soc., V51, P1024
   Botzheim J, 2012, MEMET COMPUT, V4, P73, DOI 10.1007/s12293-012-0076-0
   Botzheim J, 2009, STUD COMPUT INTELL, V222, P21
   Castro Oskardie, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7442, DOI 10.1117/12.826639
   Diaz-Ramirez V. H., 2012, ADV ADAPTIVE COMPOSI, P91, DOI DOI 10.5772/35708
   Diaz-Ramirez VH, 2015, OPT COMMUN, V338, P77, DOI 10.1016/j.optcom.2014.10.038
   Diaz-Ramirez VH, 2014, OPT COMMUN, V323, P32, DOI 10.1016/j.optcom.2014.02.063
   Furuhashi T., 1995, Advances in Fuzzy Logic, Neural Networks and Genetic Algorithms. IEEE/Nagoya-University World Wisepersons Workshop. Selected Papers, P173
   Garey M.R., 1979, COMPUTERS INTRACTABI
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang Y, 2019, MULTIMED TOOLS APPL, V78, P34725, DOI 10.1007/s11042-019-07901-w
   Javidi B, 1997, J OPT SOC AM A, V14, P836, DOI 10.1364/JOSAA.14.000836
   JAVIDI B, 1994, J OPT SOC AM A, V11, P2604, DOI 10.1364/JOSAA.11.002604
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kober V, 1996, J OPT SOC AM A, V13, P1653, DOI 10.1364/JOSAA.13.001653
   Kramer O, 2017, STUDIES COMPUTATIONA, V679, DOI [10.1007/978-3-319-52156-5_2, DOI 10.1007/978-3-319-52156-5_2]
   KUMAR BVKV, 1992, APPL OPTICS, V31, P4773, DOI 10.1364/AO.31.004773
   Liu WL, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.7.073101]
   Montiel O, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/713043
   Nawa NE, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P589, DOI 10.1109/ICEC.1997.592379
   Nawa NE, 1999, IEEE T IND ELECTRON, V46, P1080, DOI 10.1109/41.807990
   Newell M, 2019, UTAH TEAPOT 3D DIGIT
   Orozco-Rosas U, 2019, IEEE ACCESS, V7, P156787, DOI 10.1109/ACCESS.2019.2949835
   Orozco-Rosas U, 2017, STUD COMPUT INTELL, V667, P477, DOI 10.1007/978-3-319-47054-2_31
   Orozco-Rosas U, 2017, PROC SPIE, V10395, DOI 10.1117/12.2273596
   Orozco-Rosas U, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/60715
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Picos K, 2019, PROC SPIE, V11136, DOI 10.1117/12.2528944
   Picos K, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/5798696
   Picos K, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.7.073108
   Picos K, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.6.063102
   Qian C, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.3.033024
   Ruchay Alexey, 2018, Mathematical Problems in Engineering, V2018, DOI 10.1155/2018/8284123
   Ruchay A, 2016, PROC SPIE, V9971, DOI 10.1117/12.2237335
   Sang GL, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.8.083104
   Seong YK, 2000, OPT ENG, V39, P472, DOI 10.1117/1.602385
   Turk G, 2020, STANFORD BUNNY 3D DI
   Wang ZM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053018
   Wu X, 2013, J ROBOT, V2013, DOI 10.1155/2013/692838
   Wu Y, 2020, VISUAL TRACKER BENCH
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yu JL, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.1.013107
   Zhang DY, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/715808
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhu G., 2015, ONCOGENE, V1, P12, DOI [10.1038/onc.2015.4525746002, DOI 10.1038/ONC.2015.4525746002]
NR 54
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23051
EP 23072
DI 10.1007/s11042-020-08991-7
EA MAY 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000531339200003
DA 2024-07-18
ER

PT J
AU Hu, Q
   Zhou, J
   Zhang, XY
   Shi, ZR
   Gao, ZY
AF Hu, Qiang
   Zhou, Jun
   Zhang, Xiaoyun
   Shi, Zhiru
   Gao, Zhiyong
TI Viewport-adaptive 360-degree video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 360-degree video; Viewport prediction; Rate-distortion optimization
   (RDO); Lagrange multiplier; Video coding
ID RATE CONTROL ALGORITHM; NETWORK
AB 360-degree videos contain an omnidirectional view with ultra-high resolution, which will lead to the bandwidth-hungry issue in virtual reality (VR) applications. However, only a part of a 360-degree video is displayed on the head-mounted displays (HMDs). Thus, we propose a viewport-adaptive 360-degree video coding approach based on a novel viewport prediction strategy. Specifically, we firstly introduce a novel viewport prediction model based on deep 3-dimensional convolutional neural networks. In this model, a video saliency encoder and a trajectory encoder are trained to extract the features of video content and the history view path. With the outputs of the two encoders, a video prior analysis network is trained to adaptively determine the best fusion weight to generate the final feature. Moreover, benefiting from the viewport prediction model, a viewport-adaptive rate-distortion optimization (RDO) method is presented to decrease the bitrate and ensure an immersive experience. In addition, we also consider the scaling factor of the area from rectangular plane to spherical surface. Therefore, the Lagrange multiplier and quantization parameter are adaptively adjusted based on the weight of each coding tree unit. The experiments have demonstrated that the proposed RDO method gains considerably better RD performance than the traditional RDO method.
C1 [Hu, Qiang; Shi, Zhiru] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
   [Zhou, Jun; Zhang, Xiaoyun; Gao, Zhiyong] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Dept Elect Engn, Shanghai, Peoples R China.
C3 ShanghaiTech University; Shanghai Jiao Tong University
RP Hu, Q (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
EM huqiang@shanghaitech.edu.cn; zhoujun@sjtu.edu.cn;
   xiaoyun.zhang@sjtu.edu.cn; shizhr@shanghaitech.edu.cn;
   zhiyong.gao@sjtu.edu.cn
RI wang, xiao/HZI-9156-2023; sun, yuan/KBD-3926-2024
OI Hu, Qiang/0000-0003-4645-9776
CR Adeel A, 2016, JVETC0021
   [Anonymous], JVETC0050
   [Anonymous], ARXIV160408010
   [Anonymous], 2011, LOW BIT RATE ROI BAS
   [Anonymous], 2017, ARXIV170501759
   [Anonymous], 2016, 116M39532 MPEG ISOIE
   [Anonymous], 2016, ARXIV161204335
   [Anonymous], 2020, INT TELECOMMUNICATIO
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Boyce J., 2016, Document JVET-D1030
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Corbillon X, 2017, IEEE ICC, DOI 10.1109/ICC.2017.7996611
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan C, 2017, SIXTEENTH WUHAN INTERNATIONAL CONFERENCE ON E-BUSINESS, P67
   Gitman Y, 2014, IEEE IMAGE PROC, P1105, DOI 10.1109/ICIP.2014.7025220
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   HACISALIHZADE SS, 1992, IEEE T SYST MAN CYB, V22, P474, DOI 10.1109/21.155948
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hu Q, 2018, J REAL TIME IMAGE PR
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 2005, PROC CVPR IEEE, P631
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kammachi-Sreedhar K, 2016, IEEE INT SYM MULTIM, P583, DOI [10.1109/ISM.2016.0126, 10.1109/ISM.2016.143]
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li F, 2016, MULTIMED TOOLS APPL, V75, P4163, DOI 10.1007/s11042-015-2465-0
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li Y., 2018, IEEE T NEURAL NETWOR, V29, P1, DOI DOI 10.1109/TCSVT.2018.2860797
   Li YM, 2017, IEEE INT CON MULTI, P709, DOI 10.1109/ICME.2017.8019492
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Majid M, 2018, MULTIMED TOOLS APPL, V77, P20955, DOI 10.1007/s11042-017-5499-7
   Ogasawara K, 2017, IEEE T EMERG TOP COM, VPP, P1
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Quan F, 2016, ACM SIGCOMM ALLTHING, P583
   Rai Y, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P205, DOI 10.1145/3083187.3083218
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sullivan G, 2013, JCTVCL1003
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Sun C, 2008, DCC: 2008 DATA COMPRESSION CONFERENCE, PROCEEDINGS, P546, DOI 10.1109/DCC.2008.75
   Sun W, 2016, JVETD0179
   Sun Y., 2016, JVETD0040
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Tang LZ, 2018, IEEE ACCESS, V6, P913, DOI 10.1109/ACCESS.2017.2776344
   Wandell B. A, 1995, Foundations of vision
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Wei HL, 2016, IEEE INT SYMP CIRC S, P2547, DOI 10.1109/ISCAS.2016.7539112
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu YY, 2018, PROC CVPR IEEE, P5333, DOI 10.1109/CVPR.2018.00559
   Zare A, 2016, P ACM MULT, P583
   ZENG H, 2016, MULTIMED TOOLS APPL, V75, p10,38, DOI DOI 10.1007/s11042-015-2997-3
   Zhang F, 2016, IEEE IMAGE PROC, P4215, DOI 10.1109/ICIP.2016.7533154
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang MM, 2017, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2017.377
NR 67
TC 2
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12205
EP 12226
DI 10.1007/s11042-019-08390-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400042
DA 2024-07-18
ER

PT J
AU Nawaratne, R
   Adikari, A
   Alahakoon, D
   De Silva, D
   Chilamkurti, N
AF Nawaratne, Rashmika
   Adikari, Achini
   Alahakoon, Damminda
   De Silva, Daswin
   Chilamkurti, Naveen
TI Recurrent Self-Structuring Machine Learning for Video Processing using
   Multi-Stream Hierarchical Growing Self-Organizing Maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-structuring; Unsupervised machine learning; Human activity
   recognition; Self-organizing maps; Artificial intelligence
ID NETWORK; HISTOGRAMS
AB The emergence of IoT and advanced multimedia information systems have undoubtedly created a proliferation of video sensor data. Although diverse machine learning approaches are utilized to extract useful insights from these data, limitations occur when processing and accommodating the large volumes of video data, which are unlabeled and have previously unseen data structures. This brings out the importance of using self-structuring intelligence that can adapt to the nature of the data and with the ability to learn from multi-modal, spatiotemporal and unstructured data. Encompassing these advances, we propose a recurrent self-structuring machine learning approach for video processing using multi-stream hierarchical recurrent growing self-organizing maps (RGSOM) architecture. We have designed, implemented and evaluated the said approach using a human activity recognition video dataset (Weizmann dataset), achieving state-of-the-art accuracy of 93.5% in the unsupervised domain. We used both spatial and temporal data from the video as separate input feature streams, where RGSOMs were used to self-structure the video data in multi-streams for visual exploratory analysis and video classification. As potential implications, this study can contribute to the existing literature in advancing self-adaptation techniques for video sensor data processing.
C1 [Nawaratne, Rashmika; Adikari, Achini; Alahakoon, Damminda; De Silva, Daswin] La Trobe Univ, Res Ctr Data Analyt & Cognit, Melbourne, Vic, Australia.
   [Chilamkurti, Naveen] La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic, Australia.
C3 La Trobe University; La Trobe University
RP Chilamkurti, N (corresponding author), La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic, Australia.
EM B.Nawaratne@latrobe.edu.au; A.Adikari@latrobe.edu.au;
   D.Alahakoon@latrobe.edu.au; D.desilva@latrobe.edu.au;
   n.chilamkurti@latrobe.edu.au
RI des, d/GVU-7765-2022; Nawaratne, Rashmika/N-8893-2018; Chilamkurti,
   Naveen/S-9636-2019
OI Chilamkurti, Naveen/0000-0002-5396-8897
FU La Trobe University Postgraduate Research Scholarship
FX This work was supported by a La Trobe University Postgraduate Research
   Scholarship.
CR Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732
   Amarasiri R, 2005, 2005 IEEE/WIC/ACM International Conference on Web Intelligence, Proceedings, P215, DOI 10.1109/WI.2005.70
   Cardullo F., 2011, P AIAA MOD SIM TECHN, P6422
   CHAPPELL GJ, 1993, NEURAL NETWORKS, V6, P441, DOI 10.1016/0893-6080(93)90011-K
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Elloumi S, 2015, IET COMPUT VIS, V9, P522, DOI 10.1049/iet-cvi.2014.0311
   FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4
   Goldbeck J., 1999, Proceedings 199 IEEE/IEEJ/JSAI International Conference on Intelligent Transportation Systems (Cat. No.99TH8383), P74, DOI 10.1109/ITSC.1999.821030
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011
   He ZH, 2006, IEEE T CIRC SYST VID, V16, P590, DOI 10.1109/TCSVT.2006.873154
   Kohonen T, 1998, NEUROCOMPUTING, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Liu HH, 2013, IEEE T IND INFORM, V9, P1222, DOI 10.1109/TII.2013.2255616
   López-Rubio E, 2011, INT J NEURAL SYST, V21, P225, DOI 10.1142/S012906571100281X
   Lungarella M, 2005, INT C DEVEL LEARN, P25
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Marrow P, 2000, BT TECHNOL J, V18, P13, DOI 10.1023/A:1026746406754
   Marsland S, 2002, NEURAL NETWORKS, V15, P1041, DOI 10.1016/S0893-6080(02)00078-3
   Nallaperuma D, 2019, IEEE T INTELL TRANSP, P1
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Nawaratne R, 2017, IEEE IND ELEC, P4790, DOI 10.1109/IECON.2017.8216826
   Parisi GI, 2017, NEURAL NETWORKS, V96, P137, DOI 10.1016/j.neunet.2017.09.001
   Parisi GI, 2016, IEEE ROMAN, P71, DOI 10.1109/ROMAN.2016.7745093
   Peng B, 2020, IEEE T CIRC SYST VID, V30, P131, DOI 10.1109/TCSVT.2018.2889514
   Petrushin V. A., 2005, PROCEEDINGS OF THE E, P794
   Poggio T, NOT AMS, V50, P537
   Sargano AB, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7010110
   Strickert M, 2005, NEUROCOMPUTING, V64, P39, DOI 10.1016/j.neucom.2004.11.014
   Voegtlin T, 2002, NEURAL NETWORKS, V15, P979, DOI 10.1016/S0893-6080(02)00072-2
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P1635, DOI 10.1109/TPAMI.2012.253
NR 35
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16299
EP 16317
DI 10.1007/s11042-020-08886-7
EA APR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000529585600005
DA 2024-07-18
ER

PT J
AU Prasad, S
   Pal, AK
AF Prasad, Shiv
   Pal, Arup Kumar
TI Hamming code and logistic-map based pixel-level active forgery detection
   scheme using fragile watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active forgery detection; Authentication code; Fragile watermarking;
   Hamming codes; Logistic-map; Tamper detection
ID IMAGE AUTHENTICATION; TAMPERING DETECTION; LOCALIZATION
AB In this work, an active forgery detection scheme is proposed to locate the tampered region from a forged digital image. In this regard, an authentication code is formed and subsequently, the same is concealed into each pixel for the realization of a fragile watermarked image. In an active forgery detection procedure, the extracted authentication code from the fragile watermarked image is considered to detect the tampered region properly. The main goal of this work is to generate a secure authentication code for preventing the attackers from purposely altering the embedded code to match the tampered image contents as well as to cause less visual distortion after the construction of the fragile watermarked image. Initially, the authentication code for each pixel is computed using Hamming code from the first four most significant bits (MSBs) and subsequently, the same is considered to conceal into some least significant bits (LSBs) of that particular pixel. Generally, the LSB components are found visually insignificant so, the suggested pixel-level authentication code embedding procedure retains the high visual quality of the watermarked image. The proposed fragile watermarking is secured since the authentication code embedding procedure is realized using the logistic-map based generated secret parameters. The proposed scheme has been implemented and the results based on the input of several grayscale images are found satisfactory. In addition, several tampered images are considered to validate the proficiency of tampering detection of the proposed work. The obtained results demonstrate that the presented work is effectively capable to detect the tampered region even in pixel-level from the forged digital image content and also the results are found comparable to some related works.
C1 [Prasad, Shiv; Pal, Arup Kumar] Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Prasad, S (corresponding author), Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad, Jharkhand, India.
EM psad.shiv@gmail.com; arupkrpal@gmasil.com
RI PRASAD, SHIV/AAK-1104-2021
OI PRASAD, SHIV/0000-0002-9439-5765
CR Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   BAKER T, 2019, SOFTWARE PRACT EXPER, V2688, P1
   Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Chang YF, 2013, OPTO-ELECTRON REV, V21, P182, DOI 10.2478/s11772-013-0088-4
   Di Martino F, 2012, INFORM SCIENCES, V195, P62, DOI 10.1016/j.ins.2012.01.014
   Hamdi D, 2016, I C DEV ESYST ENG, P130, DOI 10.1109/DeSE.2016.22
   HE H, 2007, 2 INT C BIOINSP COMP
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Lee YK, 2012, INT CONF GENET EVOL, P149, DOI 10.1109/ICGEC.2012.45
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Peng YY, 2018, J INF SECUR APPL, V40, P236, DOI 10.1016/j.jisa.2018.04.007
   PRASAD S, 2019, MULTIMED TOOLS APPL, V78, P1
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Sharma A, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P1, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.18
   Sreenivas K, 2017, J VIS COMMUN IMAGE R, V49, P164, DOI 10.1016/j.jvcir.2017.09.001
   Suthaharan S, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/829516
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
   Xiao D, 2012, OPT COMMUN, V285, P2596, DOI 10.1016/j.optcom.2012.02.002
   Zhang XP, 2009, SIGNAL PROCESS, V89, P675, DOI 10.1016/j.sigpro.2008.10.001
NR 24
TC 14
Z9 15
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20897
EP 20928
DI 10.1007/s11042-020-08715-x
EA APR 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529074000002
DA 2024-07-18
ER

PT J
AU Huang, DL
   Wang, JJ
AF Huang, Delu
   Wang, Jianjun
TI Efficient reversible data hiding based on the histogram modification of
   differences of pixel differences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram modification; Reversible data hiding (RDH); Pixel differences;
   Differences of pixel differences (DPD)
ID EXPANSION
AB Histogram modification is one of the most successful reversible data hiding methods. Among many histogram-modification techniques, difference-histogram-based methods perform well, but the efficiency of difference-histogram-based methods is still unsatisfactory. In this paper, we propose a novel reversible data hiding method based on the differences of pixel differences (DPD). Our method consists of two parts. In the first part, the DPD of cover image is computed to generate the DPD histogram. DPDs that are greater than the position of the peak point of DPD histogram are shifted to the right. Then the secret data is embedded into the pixels associated with the peak point. In the second part, we compute the DPD of the pixel sequence generated by the first part to generate a DPD histogram and shift DPDs that are less than the position of the peak point to the left. As the secret data is embedded into the pixels related to the peak point, the higher the peak point is, the more messages can be embedded. Compared with difference histogram, DPD histogram has a higher peak point, so the embedding capacity is increased. What's more, we extend the proposed method to a high-embedding-capacity method. Experimental results demonstrate the superior performance of our method and the extended form.
C1 [Huang, Delu; Wang, Jianjun] Fudan Univ, Sch Informat Sci & Technol, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Wang, JJ (corresponding author), Fudan Univ, Sch Informat Sci & Technol, Shanghai 200433, Peoples R China.
EM 17210720032@fudan.edu.cn; wangjj@fudan.edu.cn
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Amirtharajan, 2017, J ARTIF INTEL, V10, P22, DOI [10.3923/jai.2017.22.31, DOI 10.3923/JAI.2017.22.31]
   Arham A, 2016, MULTIPLE LAYER DATA, V137, P52
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chang CC, 2008, EUC 2008: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING, VOL 1, MAIN CONFERENCE, P506, DOI 10.1109/EUC.2008.20
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hung KM, 2016, J APPL SCI ENG, V19, P489, DOI 10.6180/jase.2016.19.4.12
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kumar R, 2017, MULTIMED TOOLS APPL, V76, P979, DOI 10.1007/s11042-015-3069-4
   Lee CF, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS), P56, DOI 10.1109/CCOMS.2018.8463244
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li F, 2018, MULTIMED TOOLS APPL, V77, P5149, DOI 10.1007/s11042-017-4388-4
   Li XB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION PROBLEM-SOLVING (ICCP), P395, DOI 10.1109/ICCPS.2015.7454184
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Liu L, 2016, MULTIMED TOOLS APPL, V75, P11311, DOI 10.1007/s11042-015-2855-3
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Mathews LR, 2014, INT C CONTR INSTR CO, P927
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qin JQ, 2019, IEEE SIGNAL PROC LET, V26, P843, DOI 10.1109/LSP.2019.2909080
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 33
TC 1
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20881
EP 20896
DI 10.1007/s11042-020-08623-0
EA APR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528990000001
DA 2024-07-18
ER

PT J
AU Ullah, I
   Jian, MW
   Hussain, S
   Guo, J
   Yu, H
   Wang, X
   Yin, YL
AF Ullah, Inam
   Jian, Muwei
   Hussain, Sumaira
   Guo, Jie
   Yu, Hui
   Wang, Xing
   Yin, Yilong
TI A brief survey of visual saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Visual cues; Salient object; Saliency model
ID OBJECT DETECTION; REGION DETECTION; DETECTION MODEL; LEVEL SALIENCY;
   NEURAL-NETWORK; ATTENTION; SEGMENTATION; CONTRAST; FUSION; SCENE
AB Salient object detection models mimic the behavior of human beings and capture the most salient region/object from the images or scenes, this field contains many important applications in both computer vision and pattern recognition tasks. Despite hundreds of models that have been proposed in this field, but still, it requires a large room for research. This paper demonstrates a detailed overview of the recent progress of saliency detection models in terms of heuristic-based techniques and deep learning-based techniques. we have discussed and reviewed its co-related fields, such as Eye-fixation-prediction, RGBD salient-object-detection, co-saliency object detection, and video-saliency-detection models. We have reviewed the key issues of the current saliency models and discussed future trends and recommendations. The broadly utilized datasets and assessment strategies are additionally investigated in this paper.
C1 [Ullah, Inam; Hussain, Sumaira; Guo, Jie; Yin, Yilong] Shandong Univ, Sch Software Engn, Jinan, Shandong, Peoples R China.
   [Jian, Muwei] Linyi Univ, Sch Informat Sci & Engn, Linyi, Shandong, Peoples R China.
   [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Jian, Muwei; Hussain, Sumaira] Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi 74000, Pakistan.
   [Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
   [Wang, Xing] Liaoning Tech Univ, Sch Elect & Informat Engn, Huludao, Peoples R China.
C3 Shandong University; Linyi University; Shandong University of Finance &
   Economics; University of Portsmouth; Liaoning Technical University
RP Yin, YL (corresponding author), Shandong Univ, Sch Software Engn, Jinan, Shandong, Peoples R China.; Jian, MW (corresponding author), Linyi Univ, Sch Informat Sci & Engn, Linyi, Shandong, Peoples R China.; Jian, MW (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.; Jian, MW (corresponding author), Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi 74000, Pakistan.
EM jianmuweihk@163.com; ylyin@sdu.edu.cn
RI Yu, Hui/G-1115-2018; Ullah, INAM/GMX-1573-2022; Hussain,
   S/IQU-0327-2023; Jian, Muwei/Q-8319-2018
OI Yu, Hui/0000-0002-7655-9228; Ullah, INAM/0000-0002-2624-8093; Jian,
   Muwei/0000-0002-4249-2264
FU National Natural Science Foundation of China [61876098, 61976123,
   61601427]; National Key RAMP;D Program of China [2018YFC0830100,
   2018YFC0830102]; Royal Society-K; C. Wong International Fellowship
   [NIF\R1\180909]; Taishan Young Scholars Program of Shandong Province
FX This work was supported in part by the National Natural Science
   Foundation of China (61876098, 61976123, 61601427); National Key R&D
   Program of China (2018YFC0830100, 2018YFC0830102); Royal Society-K. C.
   Wong International Fellowship (NIF\R1\180909); Taishan Young Scholars
   Program of Shandong Province.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2008, BRIT MACHINE VISION
   [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   [Anonymous], 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, DOI DOI 10.1109/CVPR.2016.257
   [Anonymous], 2002, P 10 ACM INT C MULT
   [Anonymous], 2014, CVPR
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Borji A, 2014, SALIENT OBJECT DETEC, V2
   Borji A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247706
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Borji A, 2013, VISION RES, V91, P62, DOI 10.1016/j.visres.2013.07.016
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2011, IEEE INT CONF ROBOT, P1902
   Borji A, 2011, MACH VISION APPL, V22, P61, DOI 10.1007/s00138-009-0192-0
   Chang K.Y, 2011, FUSING GENERIC OBJEC
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cheng Y, 2014, IEEE INT CON MULTI
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Cong R, 2018, ARXIV PREPRINT ARXIV
   Cong RM, 2019, IEEE T MULTIMEDIA, V21, P1660, DOI 10.1109/TMM.2018.2884481
   Cong RM, 2019, IEEE T IMAGE PROCESS, V28, P4819, DOI 10.1109/TIP.2019.2910377
   Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fairclough G, 2018, ROUTL HANDBK, P1
   Fan Q, 2016, NEUROCOMPUTING, V175, P81, DOI 10.1016/j.neucom.2015.10.030
   Fang YM, 2019, IEEE T IMAGE PROCESS, V28, P2305, DOI 10.1109/TIP.2018.2885229
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Feng SH, 2010, SIGNAL PROCESS, V90, P1, DOI 10.1016/j.sigpro.2009.05.017
   Frintrop S, 2014, INT C PATT RECOG, P2329, DOI 10.1109/ICPR.2014.404
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   FU HZ, 2015, PROC CVPR IEEE, P4428, DOI DOI 10.1109/CVPR.2015
   Fu K, 2018, IEEE T MULTIMEDIA
   Ge CJ, 2016, SIGNAL PROCESS-IMAGE, V44, P69, DOI 10.1016/j.image.2016.03.005
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Gokturk S. B., 2004, 2004 C COMPUTER VISI, V2004, P35
   Goldberg C, 2012, COMPUTER GRAPHICS 1, V2pt1, P265
   Griffin G., 2007, CALTECH 256 OBJECT C
   Guo F, 2017, DESTECH TRANS ENG, P1
   Guo F, 2017, VIDEO SALIENCY DETEC
   Han J, 2017, CNNS BASED RGB D SAL
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang H, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024189
   Huang R, 2017, IEEE SIGNAL PROC LET, V24, P569, DOI 10.1109/LSP.2017.2681687
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 1999, P SOC PHOTO-OPT INS, V3644, P473, DOI 10.1117/12.348467
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jia YQ, 2013, IEEE I CONF COMP VIS, P1761, DOI 10.1109/ICCV.2013.221
   Jian Guo, 2017, Microsystem Technologies, V23, P1999, DOI 10.1007/s00542-016-2961-9
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2019, APPL SOFT COMPUT, V80, P425, DOI 10.1016/j.asoc.2019.04.025
   Jian MW, 2019, PATTERN RECOGN LETT, V127, P37, DOI 10.1016/j.patrec.2018.08.022
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P202, DOI 10.1016/j.jvcir.2018.11.007
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Kim J, 2016, INT C PATT RECOG, P609, DOI 10.1109/ICPR.2016.7899701
   Kim J, 2016, LECT NOTES COMPUT SC, V9908, P455, DOI 10.1007/978-3-319-46493-0_28
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Koehler K, 2014, J VISION, V14, DOI 10.1167/14.3.14
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li HY, 2017, NEUROCOMPUTING, V226, P212, DOI 10.1016/j.neucom.2016.11.056
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li J, 2018, IEEE T IMAGE PROCESS, V27, P349, DOI 10.1109/TIP.2017.2762594
   Li KQ, 2016, IEEE T IMAGE PROCESS, V25, P1898, DOI 10.1109/TIP.2016.2526900
   Li L., 2014, POLYM COMPOSITE, V2014, P1, DOI DOI 10.1093/MP/SSU068
   Li L., 2013, IEEE T EVOLUT COMPUT, V99, P1
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li TP, 2019, MULTIMED TOOLS APPL, V78, P21309, DOI 10.1007/s11042-019-7403-0
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li X, 2018, IEEE INT VAC ELECT C, P335, DOI 10.1109/IVEC.2018.8391513
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li YJ, 2015, IEEE SIGNAL PROC LET, V22, P588, DOI 10.1109/LSP.2014.2364896
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Liu D, 2019, IEEE IMAGE PROC, P3925, DOI [10.1109/icip.2019.8803653, 10.1109/ICIP.2019.8803653]
   Liu J.J, 2019, ARXIV09569
   Liu LJ, 2018, IEEE T VIS COMPUT GR, V24, P1956, DOI 10.1109/TVCG.2017.2703853
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Y, 2018, IEEE T CIRCUITS SYST
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo Z, 2017, CVPR, V6, P7
   Ma Y.F, 2002, IM PROC 2002 P 2002, pI
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Meger D, 2008, ROBOT AUTON SYST, V56, P503, DOI 10.1016/j.robot.2008.03.008
   Min K, 2019, IEEE I CONF COMP VIS, P2394, DOI 10.1109/ICCV.2019.00248
   Moosmann F., 2006, INT WORKSH REPR US P
   Mukherjee Lopamudra, 2011, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, P1881, DOI 10.1109/CVPR.2011.5995420
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan P, 2016, PROCEEDINGS OF 2016 IEEE 9TH UK-EUROPE-CHINA WORKSHOP ON MILLIMETRE WAVES AND TERAHERTZ TECHNOLOGIES (UCMMT), P39, DOI 10.1109/UCMMT.2016.7873954
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Peng H., 2013, PROC AAAI C ARTIF IN, P796
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qi W., 2015, Comput. Vis. Media, V1, P309, DOI DOI 10.1007/s41095-015-0028-y
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sang Nong, 2004, Infrared Laser Engineering, V33, P38
   Scharfenberger C, 2015, IEEE T IMAGE PROCESS, V24, P457, DOI 10.1109/TIP.2014.2380351
   Shen H, 2013, CHINESE J AERONAUT, V26, P1211, DOI 10.1016/j.cja.2013.07.038
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Song HK, 2016, IEEE SIGNAL PROC LET, V23, P1722, DOI 10.1109/LSP.2016.2615293
   Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984
   Sugimoto A, 2017, SUGIMOTO DEEPLY SUPE
   Tan ZY, 2013, INT CONF ACOUST SPEE, P2114, DOI 10.1109/ICASSP.2013.6638027
   Tang YB, 2016, LECT NOTES COMPUT SC, V9912, P809, DOI 10.1007/978-3-319-46484-8_49
   Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   TORRALBA A, 2011, PROC CVPR IEEE, P1521, DOI DOI 10.1109/CVPR.2011.5995347
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Trung-Nghia Le, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P465, DOI 10.1109/ICMEW.2017.8026300
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vikram TN, 2012, PATTERN RECOGN, V45, P3114, DOI 10.1016/j.patcog.2012.02.009
   Wang AZ, 2017, IEEE SIGNAL PROC LET, V24, P663, DOI 10.1109/LSP.2017.2688136
   Wang L, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P590, DOI [10.1109/ISAI.2016.127, 10.1109/ISAI.2016.0130]
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wang X, 2018, IEEE T IMAGE PROCESS, V27, P121, DOI 10.1109/TIP.2017.2756825
   Wang X, 2016, IEEE IMAGE PROC, P1042
   Wei L, 2017, ARXIV07381
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   WOLFE JM, 1989, J EXP PSYCHOL HUMAN, V15, P419, DOI 10.1037/0096-1523.15.3.419
   Xi T, 2017, IEEE T IMAGE PROCESS, V26, P3425, DOI 10.1109/TIP.2016.2631900
   Xia CQ, 2017, PROC CVPR IEEE, P4399, DOI 10.1109/CVPR.2017.468
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Xue YW, 2012, INT CONF ACOUST SPEE, P1485, DOI 10.1109/ICASSP.2012.6288171
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Ye LW, 2015, IEEE SIGNAL PROC LET, V22, P2073, DOI 10.1109/LSP.2015.2458434
   Yuan YC, 2018, IEEE T CIRC SYST VID, V28, P1130, DOI 10.1109/TCSVT.2016.2646720
   Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2015, IEEE I CONF COMP VIS, P594, DOI 10.1109/ICCV.2015.75
   Zhang DW, 2015, PROC CVPR IEEE, P2994, DOI 10.1109/CVPR.2015.7298918
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang JP, 2019, IEEE ACM T COMPUT BI, V16, P396, DOI 10.1109/TCBB.2017.2701379
   Zhang K, 2019, SMART POLYMER CATALYSTS AND TUNABLE CATALYSIS, P95, DOI 10.1016/B978-0-12-811840-5.00005-8
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhang XC, 2011, ACM T STORAGE, V7, DOI 10.1145/2027066.2027069
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhixiang Ren, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P158, DOI 10.1109/ICME.2012.173
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhu JY, 2015, IEEE T PATTERN ANAL, V37, P862, DOI 10.1109/TPAMI.2014.2353617
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou WB, 2015, IEEE I CONF COMP VIS, P406, DOI 10.1109/ICCV.2015.54
NR 230
TC 41
Z9 43
U1 7
U2 84
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34605
EP 34645
DI 10.1007/s11042-020-08849-y
EA APR 2020
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000526354300003
DA 2024-07-18
ER

PT J
AU Chan, DY
   Wu, JR
AF Chan, Din-Yuen
   Wu, Ji-Rong
TI Manifold-defect depth-map restoration for very low-cost S3D videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect-v1 depth repairing; Depth restoration; Low-cost S3D videos
ID ENHANCEMENT; COLOR
AB In this paper, the proposed algorithm provides a fluent and efficient method for repairing very-low quality depth maps of considerable manifold defects for low-cost stereoscopic 3D (S3D) photographing that such a depth map can be easily yielded by 1st-generation Kinect (Kinect-v1). The corresponding framework cascades two repairing portions named discriminative non-segmentation hole filling and edge rectification-by-deforming. The former can discriminatively fill a variety of depth-invalid holes with no need of practically making attribute-discrimination and target segmentation for depth holes. The main portions of the latter contain edge-shifting-rectification and texture-edge guided dual processing for tailoring possible twisted depth edges. Since the ingredients of proposed algorithm are compactly concatenated according to intimate context, most troublesome defects in Kinect-v1 depths can be tackled. Particularly, the proposed algorithm can obtain the restoring coherency for successive depth maps. A series of experimental results under various photographing scenarios can demonstrate that a single Kinect-v1 device can fast tell on the development of very low-cost S3D imaging tool by the proposed algorithm.
C1 [Chan, Din-Yuen; Wu, Ji-Rong] Natl Chia Yi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chiayi University
RP Chan, DY (corresponding author), Natl Chia Yi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM dychan@mail.ncyu.edu.tw; jirongwu81@gmail.com
CR [Anonymous], P BRIT MACH VIS C BM
   Bhavsar AV, 2012, COMPUT VIS IMAGE UND, V116, P572, DOI 10.1016/j.cviu.2011.12.005
   Blais F, 2004, J ELECTRON IMAGING, V13, P231, DOI 10.1117/1.1631921
   Chang NYC, 2010, IEEE T CIRC SYST VID, V20, P792, DOI 10.1109/TCSVT.2010.2045814
   Chen L, 2012, INT C PATT RECOG, P3070
   Chiu WC, 2010, 22 BRI MACH VIS C BM
   Ferstl D, 2013, IEEE INT CONF COMPUT
   Fu JJ, 2012, IEEE INT SYMP CIRC S, P512, DOI 10.1109/ISCAS.2012.6272078
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jiao JB, 2017, IEEE T CIRC SYST VID, V27, P1155, DOI 10.1109/TCSVT.2015.2513618
   Lee EK, 2010, IEEE T CONSUM ELECTR, V56, P2797, DOI 10.1109/TCE.2010.5681171
   Lee PJ, 2011, IEEE T MULTIMEDIA, V13, P246, DOI 10.1109/TMM.2010.2100372
   Liu W, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2612826
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Matyunin S., 2011, 3DTV Conference: The True Vision-Capture, Transmission and Display of 3D Video, P1
   Miao D, 2012, IEEE INT SYMP CIRC S, P604, DOI 10.1109/ISCAS.2012.6272103
   PoLin Lai, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P9, DOI 10.1109/PCS.2010.5702589
   Sheng L, 2015, IEEE T IMAGE PROCESS, V24, P2197, DOI 10.1109/TIP.2015.2416658
   Sheng L, 2013, IEEE IMAGE PROC, P2173, DOI 10.1109/ICIP.2013.6738448
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Suzumura T., 2012, Proceedings of the ACM SIGPLAN 2012 X10 Workshop on - X10'12, P1, DOI [10.1145/2246056.2246059, DOI 10.1145/2246056.2246059]
   Wang C, 2018, VISUAL COMPUT, V34, P67, DOI 10.1007/s00371-016-1312-2
   Wang YK, 2014, VISUAL COMPUT, V30, P1157, DOI 10.1007/s00371-013-0896-z
   XibinSong, 2016, INT C PATT RECOG, P2758, DOI 10.1109/ICPR.2016.7900053
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172
NR 28
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8863
EP 8886
DI 10.1007/s11042-018-6804-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600026
DA 2024-07-18
ER

PT J
AU Padmanabhan, SA
   Kanchikere, J
AF Padmanabhan, S. Anantha
   Kanchikere, Jayanna
TI An efficient face recognition system based on hybrid optimized KELM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kernel extreme learning machine (KELM); Modified principal component
   analysis (MPCA); Hybrid particle swarm optimization-genetic algorithm
   (PSO-GA); Adaptive neuro-fuzzy inference system (ANFIS); Modified wiener
   filter (MWF)
AB Face recognition (FR) from video offers a challenging issue in the area of image exploration along with computer visualization, furthermore, as such recognized heaps of deem over the previous years on account of its numerous applications in the scope of domains. The chief challenges in the video centered FR are the restraint of the camera hardware, the random poses captured by means of the camera as the subject is noncooperative, and changes in the resolutions owing to disparate lighting conditions, noise along with blurriness. Numerous FR algorithms were generated in the previous decennium, although these approaches are much better, the image's accuracy is less only. To trounce such difficulties, an efficient FR system centered on hybrid optimized Kernel ELM is proposed. The proposed work encompasses five phases, explicitly (i) preprocessing, (ii) Face detection, (iii) Feature Extraction, (iv) Feature Reduction, and (v) Classification. In the preliminary phase, the data-base video clips are converted in to the frames in which pre-processing are performed utilizing a Modified wiener filter to eliminate the noise. The succeeding phase is employed for detecting the pre-processed image via the viola-jones (V-J). With this technique, the face is identified. After that, the features are extorted. The extracted ones then will be provided as the input to the Modified PCA approach. Then, perform classification operation using hybrid (PSO-GA) optimized Kernel ELM approach. The similar process is replicated for query images (QI). At last, the recognized image is found. Experimental results contrasted with the previous ANFIS classifier and existing methods concerning precision, accuracy, recall, F-measure, sensitivity along with specificity. The proposed FR system indicates better accuracy when compared with the prevailing methods.
C1 [Padmanabhan, S. Anantha] Gopalan Coll Engn & Management, Dept ECE, Bangalore, Karnataka, India.
   [Kanchikere, Jayanna] St Peters Engn Coll, Dept EEE, Hyderabad, India.
C3 Gopalan College of Engineering & Management; St. Peter's Institute of
   Higher Education & Research
RP Padmanabhan, SA (corresponding author), Gopalan Coll Engn & Management, Dept ECE, Bangalore, Karnataka, India.
EM ananthu.padmanabhan@gmail.com; jayannak69@gmail.com
CR Agrawal S., 2018, MOL ASPECTS PLANTPAT, P1
   [Anonymous], 2015, INT J MULTIMED UBIQU
   [Anonymous], ANN DATA SCI
   [Anonymous], INT J SCI RES PUBLIC
   [Anonymous], INT J COMPUT TRENDS
   [Anonymous], INT J TECHNOLOGY ENG
   [Anonymous], INT J SCI ENG TECHNO
   [Anonymous], IOSR J ENG
   [Anonymous], 2018, INT C SOFT COMP NETW
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], NEURAL COMPUTING APP
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   BalaAnand M, 2018, PROC IEEE INT SOFT, P92
   Cheng Y, 2016, NEUROCOMPUTING, V215, P250, DOI 10.1016/j.neucom.2015.06.117
   Elliott WH, 2015, CELL MOL BIOENG, V8, P285, DOI 10.1007/s12195-015-0386-7
   Hermosilla G, 2018, IEEE ACCESS, V6, P42800, DOI 10.1109/ACCESS.2018.2850281
   Kasar MM, 2016, INT J SECUR APPL, V10, P81, DOI 10.14257/ijsia.2016.10.3.08
   Liu J, 2018, MITOCHONDRIAL DNA A, V29, P1165, DOI 10.1080/24701394.2018.1424843
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Nasution AL, 2014, 2014 INTERNATIONAL CONFERENCE OF ADVANCED INFORMATICS: CONCEPT, THEORY AND APPLICATION (ICAICTA), P171, DOI 10.1109/ICAICTA.2014.7005935
   Ni JJ, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/2186574
   Parmar D.N., 2014, Face Recognition Methods Applications
   Shermina J, 2010, INT J COMPUT SCI NET, V10, P106
   Sukhija P, 2016, PROCEDIA COMPUT SCI, V85, P410, DOI 10.1016/j.procs.2016.05.183
NR 24
TC 2
Z9 2
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10677
EP 10697
DI 10.1007/s11042-019-7243-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600052
DA 2024-07-18
ER

PT J
AU Rathee, G
   Sharma, A
   Saini, H
   Kumar, R
   Iqbal, R
AF Rathee, Geetanjali
   Sharma, Ashutosh
   Saini, Hemraj
   Kumar, Rajiv
   Iqbal, Razi
TI A hybrid framework for multimedia data processing in IoT-healthcare
   using blockchain technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data security; IoT-healthcare; Block chain; Security;
   Healthcare systems; IoT devices
ID WIRELESS SENSOR NETWORKS; PRIVACY ISSUES; SECURITY; INTERNET
AB Through the propagation of technology in recent years, people communicate in a range of ways via multimedia. The use of multimedia technique in healthcare system also makes it possible to store, process and transfer the patient's data presented in variety of forms such as images, text and audio through online using various smart objects. Healthcare organizations around the world are transforming themselves into more efficient, coordinated and user-centered systems through various multimedia techniques. However, the management of huge amount data such as reports and images of every person leads to increase the human efforts and security risks. In order to overcome these issues, IoT in healthcare enhances the quality of patients care and reduce the cost by allocating the medical resources in an efficient way. However, a number of threats can occur in IoT devices initiated by various intruders. Sometimes, in order to make their personal profit, even though the medical shop or pathology labs are not of good reputation, the doctors forced the patients to do the lab tests, or buy the medicines from those organizations only. Therefore, security should be at the staple of outlook in IoT elucidations. In order to prevent these issues, Blockchain technology has been encountered as the best technique that provides the secrecy and protection of control system in real time conditions. In this manuscript, we will provide a security framework of healthcare multimedia data through blockchain technique by generating the hash of each data so that any change or alteration in data or breaching of medicines may be reflected in entire blockchain network users. The results have been analyzed against conventional approach and validated with improved simulated results that offer 86% success rate over product drop ratio, falsification attack, worm hole attack and probabilistic authentication scenarios because of Blockchain technique.
C1 [Rathee, Geetanjali; Saini, Hemraj] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, HP, India.
   [Sharma, Ashutosh; Kumar, Rajiv] Jaypee Univ Informat Technol, Dept Elect & Commun, Solan, HP, India.
   [Iqbal, Razi] AUE, Coll Comp Informat Technol, Dubai, U Arab Emirates.
C3 Jaypee University of Information Technology; Jaypee University of
   Information Technology
RP Sharma, A (corresponding author), Jaypee Univ Informat Technol, Dept Elect & Commun, Solan, HP, India.
EM geetanjali.rathee123@gmail.com; sharmaashutosh1326@gmail.com;
   hemraj1977@yahoo.co.in; rjv.ece@gmail.com; razi.iqbal@ieee.org
RI Sharma, Ashutosh/AAA-4601-2021; Saini, Hemraj/K-9849-2015; Rathee,
   Geetanjali/C-8186-2018
OI Sharma, Ashutosh/0000-0002-4990-5252; Rathee,
   Geetanjali/0000-0002-4761-1912; Kumar, Dr. Rajiv/0000-0002-9329-4794
CR Ackerman MJ, 2007, MULTIMED TOOLS APPL, V33, P5, DOI 10.1007/s11042-006-0093-4
   Al Ameen M, 2012, J MED SYST, V36, P93, DOI 10.1007/s10916-010-9449-4
   Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Alemdar H, 2010, COMPUT NETW, V54, P2688, DOI 10.1016/j.comnet.2010.05.003
   Anderson LM, 2003, AM J PREV MED, V24, P68, DOI 10.1016/S0749-3797(02)00657-8
   [Anonymous], IEEE ACCESS
   [Anonymous], **NON-TRADITIONAL**
   Cerin E, 2017, INT J BEHAV NUTR PHY, V14, DOI 10.1186/s12966-017-0471-5
   Chen XC, 2015, CHINA COMMUN, V12, P42, DOI 10.1109/CC.2015.7112043
   Cheung SCS, 2015, IEEE MULTIMEDIA, V22, P4, DOI 10.1109/MMUL.2015.86
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Dey T, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P486, DOI 10.1109/ISS1.2017.8389459
   Esposito C, 2018, IEEE CLOUD COMPUT, V5, P31
   Gelogo YE, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON BIO-SCIENCE AND BIO-TECHNOLOGY (BSBT), P24, DOI 10.1109/BSBT.2015.17
   Greer N, 2018, U.S. Patent Application, Patent No. [16/119,915, 16119915]
   Karafiloski E, 2017, 17TH IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES - IEEE EUROCON 2017 CONFERENCE PROCEEDINGS, P763, DOI 10.1109/EUROCON.2017.8011213
   Kaur P, 2019, MULTIMED TOOLS APPL, P2019
   Krishna I, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P14, DOI 10.1109/ISCO.2017.7855973
   Lee Jay, 2015, Manufacturing Letters, V3, P18, DOI 10.1016/j.mfglet.2014.12.001
   Li SC, 2015, INFORM SYST FRONT, V17, P243, DOI 10.1007/s10796-014-9492-7
   Liu WS, 2017, INT J FUZZY SYST, V19, P1, DOI 10.1007/s40815-016-0272-z
   Mayron LM, 2010, IEEE SECUR PRIV, V8, P76, DOI 10.1109/MSP.2010.185
   Ngamsuriyaroj S, 2018, 7 IEEE ICT INT STUD, P2018
   Özyilmaz KR, 2019, IEEE CONSUM ELECTR M, V8, P28, DOI 10.1109/MCE.2018.2880806
   Praveena D, 2018, MULTIMED TOOLS APPL, P2018
   Puthal D, 2019, IEEE POTENTIALS, V38, P26, DOI 10.1109/MPOT.2018.2850541
   Scheuerman WE, 2014, PHILOS SOC CRIT, V40, P609, DOI 10.1177/0191453714537263
   Thuraisingham B, 2007, MULTIMED TOOLS APPL, V33, P13, DOI 10.1007/s11042-006-0096-1
   Ugrenovic D, 2015, 2015 23RD TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P79, DOI 10.1109/TELFOR.2015.7377418
   Wu LF, 2014, IEEE COMMUN MAG, V52, P80, DOI 10.1109/MCOM.2014.6766089
   Yang HK, 2019, IEEE ACCESS, V7, P6262, DOI 10.1109/ACCESS.2018.2885037
   Yu ST, 2018, PROCEEDINGS OF 2018 1ST IEEE INTERNATIONAL CONFERENCE ON HOT INFORMATION-CENTRIC NETWORKING (HOTICN 2018), P260, DOI 10.1109/HOTICN.2018.8606017
   Yu Y, 2018, IEEE WIREL COMMUN, V25, P12, DOI 10.1109/MWC.2017.1800116
   Zhang J, 2016, IEEE ACCESS, V4, P9239, DOI 10.1109/ACCESS.2016.2645904
   Zhao HW, 2018, CAAI T INTELL TECHNO, V3, P114, DOI 10.1049/trit.2018.0014
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
   Zhou L, 2011, IEEE NETWORK, V25, P35, DOI 10.1109/MNET.2011.5772059
NR 38
TC 108
Z9 112
U1 3
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9711
EP 9733
DI 10.1007/s11042-019-07835-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600001
DA 2024-07-18
ER

PT J
AU Sekaran, K
   Chandana, P
   Krishna, NM
   Kadry, S
AF Sekaran, Kaushik
   Chandana, P.
   Krishna, N. Murali
   Kadry, Seifedine
TI Deep learning convolutional neural network (CNN) With Gaussian mixture
   model for predicting pancreatic cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Gaussian mixture model (GMM);
   Expectation-Maximization algorithm (EM); TCIA
AB The tremendous research towards medical health systems are giving ample scope for the computing systems to emerge with the latest innovations. These innovations are leading to the efficient implementations of the medical systems which involve in automatic diagnosis of the health related problems. The most important health research is going on towards cancer prediction, which has different forms and can be affected on different portions of the body parts. One of the most affected cancer that predicted to be incurable are Pancreatic Cancer, which cannot be treated efficiently once identified, in most of the cases it found to be unpredictable as it lies in the abdomen region below the stomach. Therefore the advancements in the medical research is trending towards the implementations of an automated systems which identifies the stages of cancer if affected and provide the better diagnosis and treatment if identified. Deep learning is one such area which extended its research towards medical imaging, which automates the process of diagnosing the problems of the patients when appended with the set of machines like CT/PET Scan systems. In this paper, the deep learning strategy named Convolutional Neural network (CNN) model is used to predict the cancer images of the pancreas, which is embedded with the model of Gaussian Mixture model with EM algorithm to predict the essential features from the CT Scan and predicts the percentage of cancer spread in the pancreas with the threshold parameters taken as a markers. The experimentation is carried out on the CT Scan images dataset of pancreas collected from the Cancer Imaging Archive (TCIA) consists of approximately 19,000 images supported by the National Institutes of Health Clinical Center to analyze the performance of the model.
C1 [Sekaran, Kaushik] Vignan Inst Technol & Sci, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
   [Chandana, P.; Krishna, N. Murali] Vignan Inst Technol & Sci, Comp Sci & Engn Dept, Hyderabad, Telangana, India.
   [Kadry, Seifedine] Beirut Arab Univ, Dept Math & Comp Sci, Fac Sci, Beirut, Lebanon.
C3 Beirut Arab University
RP Kadry, S (corresponding author), Beirut Arab Univ, Dept Math & Comp Sci, Fac Sci, Beirut, Lebanon.
EM s.kadry@bau.edu.lb
RI Kadry, Seifedine/C-7437-2011; krishna, murali/AAD-2521-2019; P, Dr
   Chandana/AAZ-3580-2021
OI Kadry, Seifedine/0000-0002-1939-4842; P, Dr Chandana/0000-0003-3145-8148
CR [Anonymous], 2019, IEEE Trans Med Imaging
   [Anonymous], 2016, ARXIV161107004V1
   Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014
   Asri H, 2016, PROCEDIA COMPUT SCI, V83, P1064, DOI 10.1016/j.procs.2016.04.224
   Bridge CP, 2018, LECT NOTES COMPUTER, V11041
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Corredor G, 2018, PROC SPIE, V10581, DOI 10.1117/12.2293147
   Gerasa KJ, 2017, ARXIV170307047V1
   Glicksberg B. S., 2018, PAC S BIOCOMPUT
   Li H, 2017, INT J RAD ONCOLOGY, P99
   Miotto R, 2016, EUR C INF RETR
   Paeng K, 2016, ARXIV161207180V1
   Pearce C, 2018, CONVOLUTIONAL NEURAL
   Radford A., 2017, LEARNING GENERATE RE
   Rubadue C, 2016, ARXIV161003467
   Shelhamer E., 2016, ARXIV160506211V1
   Veta M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161286
   Zhen X, 2017, I PHYS ENG MED PHYS, P62
NR 18
TC 61
Z9 62
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10233
EP 10247
DI 10.1007/s11042-019-7419-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600027
DA 2024-07-18
ER

PT J
AU Wang, J
   Wang, L
AF Wang, Jian
   Wang, Lu
TI Multimedia animation filtering simulation based on image extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image edge detection operator; Multimedia animation filtering;
   Algorithmic simulation
ID ALGORITHM; SEGMENTATION
AB With the rapid development of computer technology and network technology, a large number of audio, video, text and other multimedia information are pouring in, but only part of the information is of practical value to Internet users. Therefore, in the information explosion society, timely screening and reasonable pushing of a large number of information has become an urgent technical problem. This paper will study and analyse the research point of multimedia animation filtering in Internet environment. Based on the basic principles of image sequential edge detection algorithm and watershed image detection algorithm, and combined with mathematical morphology theory, this paper creatively proposes an improved character class edge detection and filtering algorithm. Based on the image filtering algorithm proposed in this paper, the coordination and optimization of edge detection accuracy and anti-noise ability can be achieved. Finally, simulation experiments are carried out for the above algorithms. The experimental results show that the proposed optimization algorithm has excellent edge detection effect.
C1 [Wang, Jian; Wang, Lu] Jingdezhen Ceram Inst, Sch Design & Art, Jingdezhen 333403, Jiangxi, Peoples R China.
C3 Jingdezhen Ceramic Institute
RP Wang, J (corresponding author), Jingdezhen Ceram Inst, Sch Design & Art, Jingdezhen 333403, Jiangxi, Peoples R China.
EM xxjszx04@jci.edu.cn
CR [Anonymous], 2018, MALAYSIAN PAEDIAT PR
   Jiang YZ, 2017, IEEE T FUZZY SYST, V25, P3, DOI 10.1109/TFUZZ.2016.2637405
   Jiang YZ, 2015, IEEE T CYBERNETICS, V45, P688, DOI 10.1109/TCYB.2014.2334595
   Jiang YZ, 2015, IEEE T CYBERNETICS, V45, P548, DOI 10.1109/TCYB.2014.2330844
   Kuang HL, 2016, IEEE INTELL SYST, V31, P57, DOI 10.1109/MIS.2016.17
   Lin YB, 2017, PATTERN RECOGN, V63, P334, DOI 10.1016/j.patcog.2016.10.012
   Martin-Borregon D, 2014, EPJ DATA SCI, V3, DOI 10.1140/epjds/s13688-014-0008-y
   Neto Armando Alves, 2009, Journal of the Brazilian Computer Society, V15, P19, DOI 10.1007/BF03194503
   Pak JM, 2016, NEUROCOMPUTING, V173, P645, DOI 10.1016/j.neucom.2015.08.011
   Papaefthymiou M, 2016, VISUAL COMPUT, V32, P751, DOI 10.1007/s00371-016-1270-8
   Qian PJ, 2017, KNOWL-BASED SYST, V130, P33, DOI 10.1016/j.knosys.2017.05.018
   Qian PJ, 2017, IEEE T NEUR NET LEAR, V28, P1123, DOI 10.1109/TNNLS.2015.2511179
   Qian PJ, 2016, IEEE T CYBERNETICS, V46, P181, DOI 10.1109/TCYB.2015.2399351
   Sorlin S, 2008, CONSTRAINTS, V13, P518, DOI 10.1007/s10601-008-9044-1
   Tareef A., 2018, IEEE T MED IMAGING, P1
   Vasuki Y, 2017, COMPUT GEOSCI-UK, V100, P27, DOI 10.1016/j.cageo.2016.12.001
   Wu ML, 2017, APPL INTELL, V47, P347, DOI 10.1007/s10489-017-0893-4
   Yu J, 2016, MULTIMED TOOLS APPL, V75, P1
   Zhang J, 2016, APPL INTELL, V45, P230, DOI 10.1007/s10489-015-0756-9
   Zhang WC, 2017, PATTERN RECOGN, V63, P193, DOI 10.1016/j.patcog.2016.10.008
NR 20
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9579
EP 9597
DI 10.1007/s11042-019-07977-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600069
DA 2024-07-18
ER

PT J
AU Xu, XL
   Chen, Y
   Yuan, Y
   Huang, T
   Zhang, XY
   Qi, LY
AF Xu, Xiaolong
   Chen, Yi
   Yuan, Yuan
   Huang, Tao
   Zhang, Xuyun
   Qi, Lianyong
TI Blockchain-based cloudlet management for multimedia workflow in mobile
   cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; QoS; Multimedia workflow; Mobile cloud computing; Cloudlet
   management
ID EDGE; ALLOCATION; NETWORK; LATENCY; DESIGN
AB For the issue of users' sensibility to the QoS (Quality of Service) of multimedia applications, cloudlet has emerged as a novel paradigm which provides closer computing resources to users to improve the performance of multimedia applications and meet the QoS demands of users. However, the increasing users' requirements of migrating tasks pose a challenge to preserve the security and integrity of offloaded data which are processed by cloudlets. In view of this challenge, a blockchain-based cloudlet management method for multimedia workflow, named MWSM, is proposed in this paper. Technically, we first model each multimedia application as a multimedia workflow and formulate the multimedia workflow scheduling problem. Then, blockchain is adopted to secure the data integrity during the offloading procedure. Besides, NSGA-III (Non-dominated Sorting Genetic Algorithm III) is employed to realize the QoS enhancement and ELECTRE (Elimination Et Choix Tradulsant la REaltite) is utilized to solve the decision-making problems of the most optimal scheduling strategies. Finally, experimental evaluations are conducted to demonstrate the efficiency and potential of our proposed scheduling method.
C1 [Xu, Xiaolong; Chen, Yi] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Peoples R China.
   [Xu, Xiaolong] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Peoples R China.
   [Xu, Xiaolong] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Peoples R China.
   [Yuan, Yuan] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
   [Huang, Tao] Silicon Lake Coll, Sch Comp Sci & Technol, Suzhou, Peoples R China.
   [Zhang, Xuyun] Univ Auckland, Dept Elect & Comp Engn, Auckland, New Zealand.
   [Qi, Lianyong] Qufu Normal Univ, Sch Informat Sci & Engn, Rizhao, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology; Michigan State University; University
   of Auckland; Qufu Normal University
RP Qi, LY (corresponding author), Qufu Normal Univ, Sch Informat Sci & Engn, Rizhao, Peoples R China.
EM njuxlxu@gmail.com; yzyzchenyi@gmail.com; yyuan@msu.edu;
   nuisthuangtao@163.com; xuyun.zhang@auckland.ac.nz; lianyongqi@gmail.com
RI yuan, yubo/HSG-3147-2023; Huang, Tao/IQU-9175-2023; zhang,
   xu/GYE-3558-2022; Xu, Xiaolong/U-2547-2019; Qi, Lianyong/AAO-2681-2020;
   ZHANG, XUCHEN/KBB-7989-2024
OI Huang, Tao/0000-0002-7290-440X; Xu, Xiaolong/0000-0003-4879-9803; Zhang,
   Xuyun/0000-0001-7353-4159
CR Belcastro L, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3154411
   Ceselli A, 2017, IEEE ACM T NETWORK, V25, P1818, DOI 10.1109/TNET.2017.2652850
   Chen LX, 2018, IEEE ACM T NETWORK, V26, P1619, DOI 10.1109/TNET.2018.2841758
   Gao HH, 2018, INT J SOFTW ENG KNOW, V28, P1369, DOI 10.1142/S0218194018500390
   Gao HH, 2018, FUTURE GENER COMP SY, V87, P298, DOI 10.1016/j.future.2018.04.064
   Gao HH, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718761583
   Trinh H, 2018, IEEE T MULTIMEDIA, V20, P2562, DOI 10.1109/TMM.2018.2865661
   Lentisco CM, 2017, IEEE T MULTIMEDIA, V19, P173, DOI 10.1109/TMM.2016.2620605
   Liu H, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700344
   Liu YC, 2016, IEEE T MOBILE COMPUT, V15, P2398, DOI 10.1109/TMC.2015.2504091
   Pandey P, 2018, J PARALLEL DISTR COM, V120, P101, DOI 10.1016/j.jpdc.2018.05.004
   Qi LY, 2019, INFORM SCIENCES, V480, P354, DOI 10.1016/j.ins.2018.11.030
   Qi L, 2020, INT J PHYTOREMEDIAT, V22, P227, DOI 10.1080/15226514.2019.1658704
   Rahman A, 2018, IEEE ACCESS, V6, P72469, DOI 10.1109/ACCESS.2018.2881246
   Rimal BP, 2017, IEEE T WIREL COMMUN, V16, P3601, DOI 10.1109/TWC.2017.2685578
   ROY B, 1968, REV FR INFORM RECH O, V2, P57
   Shao L, 2018, J ELECTR COMPUT ENG, V2018, DOI 10.1155/2018/6079617
   Sun Q., 2016, ENG BLASTING, V22, P1
   Sun QD, 2018, J BIOMED INFORM, V83, P54, DOI 10.1016/j.jbi.2018.03.010
   Suo K, 2018, IEEE CONF COMPUT
   Wang S, 2016, IEEE T CLOUD COMPUT, DOI DOI 10.1109/TCC.2016.2603504
   Wang SG, 2019, J PARALLEL DISTR COM, V127, P160, DOI 10.1016/j.jpdc.2018.06.008
   Wang SG, 2021, IEEE T SERV COMPUT, V14, P1238, DOI 10.1109/TSC.2018.2868356
   Wang X, 2018, IEEE NETWORK
   Wang XK, 2017, IEEE COMMUN MAG, V55, P80, DOI 10.1109/MCOM.2017.1700360
   Whaiduzzaman M, 2018, IEEE T SERV COMPUT, V11, P144, DOI 10.1109/TSC.2016.2564407
   Wu FG, 2018, CMC-COMPUT MATER CON, V56, P19, DOI 10.3970/cmc.2018.02664
   Wu Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103472
   Xiong L, 2018, COMPUTERS MAT CONTIN
   Xu ZC, 2016, IEEE T PARALL DISTR, V27, P2866, DOI 10.1109/TPDS.2015.2510638
   Xu ZM, 2018, INT J ADV ROBOT SYST, V15, DOI [10.1109/INFOCOM.2018.8485853, 10.1177/1729881418763458]
   Yan C, 2017, IEEE ACCESS, V9
   Yin YY, 2020, MOBILE NETW APPL, V25, P391, DOI 10.1007/s11036-019-01241-7
   Yin YY, 2019, IEEE ACCESS, V7, P62312, DOI 10.1109/ACCESS.2019.2914737
   Yin YY, 2018, IEEE ACCESS, V6, P62815, DOI 10.1109/ACCESS.2018.2877137
   Yuan Y, 2020, IEEE T SOFTWARE ENG, V46, P1040, DOI 10.1109/TSE.2018.2874648
   Zhang J, 2017, PERSONAL UBIQUITOUS
   Zhang JX, 2018, CMC-COMPUT MATER CON, V56, P123, DOI 10.3970/cmc.2018.03728
   Zhao L, 2018, IEEE T VEH TECHNOL, V67, P6533, DOI 10.1109/TVT.2018.2808171
   Zhao Y, 2015, IEEE T SERV COMPUT, V8, P930, DOI 10.1109/TSC.2014.2341235
   Zhou XK, 2018, IEEE T HUM-MACH SYST, V48, P559, DOI 10.1109/THMS.2017.2725341
NR 41
TC 28
Z9 30
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9819
EP 9844
DI 10.1007/s11042-019-07900-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600006
DA 2024-07-18
ER

PT J
AU Yang, S
   Liu, WB
AF Yang, Shuai
   Liu, Wenbai
TI Application of image-pro plus in the shear strength and micro-structure
   of solidified soil mixed with fly ash
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Curing agent; Fly ash; Shear strength; Micro-structure; Scanning
   Electron Microscope; Image-pro plus
AB The connection between shear strength and micro-structure of solidified soil is to be done. However, most of the literature is only qualitative analysis between macro and micro. The purpose of this paper is to get the macro-micro relationship. The dredger fill is solidified by the different curing agent mixed with fly ash, and the shear strength index is measured by the direct shear test. The microscopic images are obtained by using Scanning Electron Microscope (SEM). The image is dealt with by using Image-Pro Plus (IPP), and the micro-structure parameters are deduced that include mean equivalent particle diameter D-p, mean equivalent pore diameter D-b and plane void ratio e. The research shows that there is no linear relation between the internal friction angle and the micro-structure parameters; The cohesion has a good linear relation with three micro-structure parameters; Compared with the other two microstructural parameters, the function of the plane void ratio on the cohesion is greater.
C1 [Yang, Shuai; Liu, Wenbai] Shanghai Maritime Univ, Sch Ocean Sci & Engn, Shanghai, Peoples R China.
C3 Shanghai Maritime University
RP Liu, WB (corresponding author), Shanghai Maritime Univ, Sch Ocean Sci & Engn, Shanghai, Peoples R China.
EM 2310746081@qq.com
CR Ding Jianwen, 2011, Journal of Southeast University (Natural Science Edition), V41, P1070, DOI 10.3969/j.issn.1001-0505.2011.05.033
   Fang Q.J., 2014, Sci. Technol. Eng, V14, P143
   Guozhu L, 2013, FLY ASH COMPREHENSIV, P44
   Liu X, 2011, ROCK SOIL MECH, V32, P1676
   [卢佩霞 Lu Peixia], 2015, [地下空间与工程学报, Chinese Journal of Underground Space and Engineering], V11, P375
   Riqing X., 2015, J EARTH SCI ENV, V3, P104
   Shao Yu-fang, 2006, Journal of Zhejiang University, V40, P1196
   Shi B., 2001, CHINESE J ROCK MECH, V20, P864
   Tang YX., 2000, Chinese Journal of Geotechnical Engineering, V5, P549, DOI DOI 10.3321/J.ISSN:1000-4548.2000.05.008
   Wang DX, 2012, ROCK SOIL MECH, V33, P3659
   Xu Ri-qing, 2015, Journal of Zhejiang University. Engineering Science, V49, P1417, DOI 10.3785/j.issn.1008-973X.2015.08.003
   Yongtao C, 2016, SCI TECHNOLOGY ENG, V16, P260
   Yuanfeng W.u., 2013, CLEAN COAL TECHNOL, V19, P100, DOI 10.13226/j.issn.1006-6772.2013.06.008
   Yumin J, 2014, B SCI TECHNOL, V30, P66
   [张季如 Zhang Jiru], 2015, [水利学报, Journal of Hydraulic Engineering], V46, P650
   [张志红 Zhang Zhihong], 2014, [土木工程学报, China Civil Engineering Journal], V47, P122
   Zhao Ming-hua, 2015, Journal of Hunan University (Natural Science), V42, P75
   Zhiheng Z, 2015, TRANSPORTATION SCI T, V08, P124
NR 18
TC 10
Z9 10
U1 9
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10065
EP 10075
DI 10.1007/s11042-019-07804-w
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600018
DA 2024-07-18
ER

PT J
AU Becerra, A
   de la Rosa, JI
   Gonzalez, E
   Pedroza, AD
   Escalante, NI
   Santos, E
AF Becerra, Aldonso
   Ismael de la Rosa, J.
   Gonzalez, Efren
   David Pedroza, A.
   Iracemi Escalante, N.
   Santos, Eduardo
TI A comparative case study of neural network training by using frame-level
   cost functions for automatic speech recognition purposes in Spanish
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Neural networks; Deep learning; Machine learning;
   Cross-entropy; Frame-level loss function
ID HIDDEN MARKOV-MODELS; MIXTURE OBSERVATIONS; CROSS-ENTROPY;
   CLASSIFICATION; ALGORITHM
AB Training procedures of a deep neural network are still an area with ample research possibilities and constant improvement either to increase its efficiency or its time performance. One of the lesser-addressed components is its objective function, which is an underlying aspect to consider when there is the necessity to achieve better error rates in the area of automatic speech recognition. The aim of this paper is to present two new variations of the frame-level cost function for training a deep neural network with the purpose of obtaining superior word error rates in speech recognition applied to a case study in Spanish. The first proposed function is a fusion between the boosted cross-entropy and the so called cross-entropy/log-posterior-ratio. The main idea is to jointly emphasize the prediction of difficult/crucial frames provided by a boosting factor and at the same time enlarge the distance between the target senone and its closest competitor. The second proposal is a fusion between the non-uniform mapped cross-entropy and the cross-entropy/log-posterior-ratio. This function utilizes both the mapped function to enhance the frames that have ambiguity in their belonging to specific senones and the log-posterior-ratio with the purpose of separating the target senone against the most competing tied tri-phone state. The proposed approaches are compared against those frame-level cost functions discussed in the state of the art. This comparative has been made by using a personalized mid-vocabulary speaker-independent voice corpus. This dataset is employed for the recognition of digit strings and personal name lists in Spanish from the northern central part of Mexico on a connected-words phone dialing task. A relative word error rate improvement of 15.14% and 12.30% is obtained with the two proposed approaches, respectively, against the plain well-established cross-entropy loss function.
C1 [Becerra, Aldonso; Ismael de la Rosa, J.; Gonzalez, Efren; David Pedroza, A.; Santos, Eduardo] Univ Autonoma Zacatecas, Unidad Acad Ingn Elect, Av Lopez Velarde 801, Zacatecas 98068, Zacatecas, Mexico.
   [Iracemi Escalante, N.] Inst Tecnol Pabellon Arteaga, Dept Basic Sci, Carretera Estn Rincon KM 1, Pabellon De Arteaga 20670, Ags, Mexico.
C3 Universidad Autonoma de Zacatecas
RP Becerra, A (corresponding author), Univ Autonoma Zacatecas, Unidad Acad Ingn Elect, Av Lopez Velarde 801, Zacatecas 98068, Zacatecas, Mexico.
EM a7donso@uaz.edu.mx; ismaelrv@ieee.org; gonzalez_efren@hotmail.com;
   P.A.D_16@hotmail.com; aivinsg_2682@hotmail.com; 3dmena@gmail.com
RI De la Rosa, José Ismael/N-7394-2019
OI De la Rosa, José Ismael/0000-0002-7337-8974; Becerra,
   Aldonso/0000-0002-4274-4396; GONZALEZ-RAMIREZ,
   EFREN/0000-0002-8060-6170; Pedroza, Angel/0000-0003-3568-2745;
   Escalante, Nivia/0000-0003-2688-6519
CR Ali A, 2014, IEEE W SP LANG TECH, P525, DOI 10.1109/SLT.2014.7078629
   Allauzen Cyril., 2007, P 9 INT C IMPLEMENTA, V4783, P11
   Almási AD, 2016, NEUROCOMPUTING, V174, P31, DOI 10.1016/j.neucom.2015.02.092
   Alpaydin E., 2010, Introduction to Machine Learning
   [Anonymous], 2006, The HTK book (for HTK version 3.4) [Computer software manual]
   [Anonymous], 2009, International Journal of Computer Science and Information Security, DOI DOI 10.1109/PROC.1976.10158
   [Anonymous], 1994, Connectionist Speech Recognition: A Hybrid Approach
   Astudillo RF, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3576
   Bacchiani M, 2014, P INTERSPEECH, P1900
   Becerra A, 2016, PROCEEDINGS OF THE 2016 IEEE ANDESCON
   Becerra A, 2018, MULTIMED TOOLS APPL, V77, P27231, DOI 10.1007/s11042-018-5917-5
   Becerra A, 2018, MULTIMED TOOLS APPL, V77, P15875, DOI 10.1007/s11042-017-5160-5
   Becerra A, 2017, IEEE INT AUT MEET
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bilmes JA, 2006, IEICE T INF SYST, VE89D, P869, DOI 10.1093/ietisy/e89-d.3.869
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Bourlard Herve A., 1993, Connectionist speech recognition: a hybrid approach, DOI 10.1007/978-1-4615-3210-1
   BURBEA J, 1982, IEEE T INFORM THEORY, V28, P489, DOI 10.1109/TIT.1982.1056497
   Cao WP, 2018, NEUROCOMPUTING, V275, P278, DOI 10.1016/j.neucom.2017.08.040
   Chen X, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P26
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   DENG L, 1991, IEEE T SIGNAL PROCES, V39, P1677, DOI 10.1109/78.134406
   Deng L, 2013, IEEE T AUDIO SPEECH, V21, P1060, DOI 10.1109/TASL.2013.2244083
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   Ge ZH, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P1089, DOI 10.1109/IntelliSys.2017.8324265
   Golik P, 2013, INTERSPEECH, P1755
   Hagan M. T., 2014, NEURAL NETWORK DESIG
   Han K, 2014, IEEE INT CONF SENS, P555, DOI 10.1109/SAHCN.2014.6990395
   Haykin S., 2009, NEURAL NETWORKS LEAR
   Heigold G, 2013, IEEE T AUDIO SPEECH, V21, P2616, DOI 10.1109/TASL.2013.2280234
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang JT, 2015, INT CONF ACOUST SPEE, P4989, DOI 10.1109/ICASSP.2015.7178920
   Huang Y, 2014, INTERSPEECH, P845
   Huang Z, 2014, INTERSPEECH, P1214
   Hwang MY, 1993, IEEE T SPEECH AUDI P, V1, P414, DOI 10.1109/89.242487
   Jaitly N, 2014, THESIS
   JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307, DOI 10.1109/TIT.1986.1057145
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Kingsbury B, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P10
   Lad F, 2015, STAT SCI, V30, P40, DOI 10.1214/14-STS430
   Li GQ, 2018, NEUROCOMPUTING, V272, P154, DOI 10.1016/j.neucom.2017.06.058
   Li XG, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P10, DOI 10.1109/ISCSLP.2014.6936622
   Li XG, 2015, NEUROCOMPUTING, V170, P251, DOI 10.1016/j.neucom.2014.07.087
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   McLachlan G., 1988, MIXTURE MODELS
   Miao YJ, 2013, INTERSPEECH, P2236
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Morgan N., 1995, IEEE Signal Processing Magazine, V12, P24, DOI 10.1109/79.382443
   Noguchi H, 2011, IEICE T ELECTRON, VE94C, P458, DOI 10.1587/transele.E94.C.458
   Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301, DOI 10.1109/ISCSLP.2012.6423452
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Prieto A, 2016, NEUROCOMPUTING, V214, P242, DOI 10.1016/j.neucom.2016.06.014
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rabiner LR, 2007, FOUND TRENDS SIGNAL, V1, P1, DOI 10.1561/2000000001
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RAO R, 1984, MULTIVARIATE STAT ME, P49
   Rath SP, 2013, INTERSPEECH, P109
   Ray J, 2014, 2014 FIRST WORKSHOP FOR HIGH PERFORMANCE TECHNICAL COMPUTING IN DYNAMIC LANGUAGES HPTCDL 2014, P41, DOI 10.1109/HPTCDL.2014.12
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Richard MD, 1991, NEURAL COMPUT, V3, P461, DOI 10.1162/neco.1991.3.4.461
   ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   SAINATH T, 2013, P IEEE C AUT SPEECH
   Sainath T. N., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P30, DOI 10.1109/ASRU.2011.6163900
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sainath TN, 2013, IEEE T AUDIO SPEECH, V21, P2267, DOI 10.1109/TASL.2013.2284378
   Sainath TN, 2012, P NEUR INF PROC SYST
   Scowen R. S., 1993, Proceedings 1993 Software Engineering Standards Symposium (Cat. No.93TH0568-6), P25, DOI 10.1109/SESS.1993.263968
   Seide F., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P24, DOI 10.1109/ASRU.2011.6163899
   Seide F, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P444
   Seki H, 2014, 2014 INTERNATIONAL CONFERENCE OF ADVANCED INFORMATICS: CONCEPT, THEORY AND APPLICATION (ICAICTA), P249, DOI 10.1109/ICAICTA.2014.7005949
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100
   Senior A, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6854675
   Siniscalchi SM, 2014, NEUROCOMPUTING, V140, P326, DOI 10.1016/j.neucom.2014.03.005
   Song LW, 2015, IEEE INT CONF COMMUN
   Su H, 2013, INT CONF ACOUST SPEE, P6664, DOI 10.1109/ICASSP.2013.6638951
   Trentin E, 2001, NEUROCOMPUTING, V37, P91, DOI 10.1016/S0925-2312(00)00308-8
   Vesely K, 2013, INTERSPEECH, P2344
   Vesely K, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P267, DOI 10.1109/ASRU.2013.6707741
   Vesely K, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2934
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang GS, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P448
   Wang XF, 2016, AAAI CONF ARTIF INTE, P2173
   WEI W, 1998, P IEEE INT C AC SPEE, P1520, DOI DOI 10.1109/ICASSP.1998.674476
   Wiesler S, 2015, INT CONF ACOUST SPEE, P4565, DOI 10.1109/ICASSP.2015.7178835
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Xue SF, 2014, IEEE-ACM T AUDIO SPE, V22, P1713, DOI 10.1109/TASLP.2014.2346313
   Yang Z, 2014, LECT NOTES COMPUT SC, V8679, P68, DOI 10.1007/978-3-319-10581-9_9
   Yao KS, 2012, IEEE W SP LANG TECH, P366, DOI 10.1109/SLT.2012.6424251
   Young S, 1996, IEEE SIGNAL PROC MAG, V13, P45, DOI 10.1109/79.536824
   Young S., 2008, Springer Handbook of Speech Processing, P539, DOI DOI 10.1007/978-3-540-49127-9_27
   Young S, 2007, ROUTL STUD SMALL BUS, V11, P3
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Yu D., 2010, P NIPS WORKSH DEEP L
   Yu D, 2012, INT CONF ACOUST SPEE, P4409, DOI 10.1109/ICASSP.2012.6288897
   Zeng Z, 2018, NEUROCOMPUTING, V273, P634, DOI 10.1016/j.neucom.2017.08.044
   Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072
   Zhang Tong, 2004, P 21 INT C MACH LEAR, P116, DOI DOI 10.1145/1015330.1015332
   ZHAO R, 2014, P INTERSPEECH
   Zhou P, 2015, IEEE-ACM T AUDIO SPE, V23, P631, DOI 10.1109/TASLP.2015.2392944
NR 102
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19669
EP 19715
DI 10.1007/s11042-020-08782-0
EA MAR 2020
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521930200005
DA 2024-07-18
ER

PT J
AU Abbasi, AA
   Javed, S
   Shamshirband, S
AF Abbasi, Aaqif Afzaal
   Javed, Sameen
   Shamshirband, Shahaboddin
TI An intelligent memory caching architecture for data-intensive multimedia
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cache; High-performance computing; Intelligent; Memory; Multimedia;
   Multi-threading; Networks; Threads
ID PERFORMANCE; CLOUD; SYSTEMS
AB With the rapid developments in cloud computing and mobile networks, multimedia content can be accessed conveniently. Recently, some novel intelligent caching-based approaches have been proposed to improve the memory architectures for multimedia applications. These applications often face bottleneck related challenges which result in performance degradation and service delay issues. Intelligent multimedia network applications access the shared data by using a specific network file system. This results in answering the processing related constraints on hard-drive storage and might result in bringing bottleneck issues. Therefore, to improve the performance of these multimedia network applications, we present an intelligent distributed memory caching system. We integrate the multimedia application message passing interface in a multi-threaded environment and propose an algorithm which can handle concurrent response behavior for different multimedia applications. Results demonstrate that our proposed scheme outperforms traditional approaches in terms of throughput and file read access features.
C1 [Abbasi, Aaqif Afzaal] Fdn Univ, Dept Software Engn, Islamabad 44000, Pakistan.
   [Javed, Sameen] Keeptruckin Inc, Qual Assurance Dept, Islamabad 44000, Pakistan.
   [Shamshirband, Shahaboddin] Ton Duc Thang Univ, Dept Management Sci & Technol Dev, Ho Chi Minh City, Vietnam.
   [Shamshirband, Shahaboddin] Ton Duc Thang Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
C3 Ton Duc Thang University; Ton Duc Thang University
RP Shamshirband, S (corresponding author), Ton Duc Thang Univ, Dept Management Sci & Technol Dev, Ho Chi Minh City, Vietnam.; Shamshirband, S (corresponding author), Ton Duc Thang Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
EM aaqif.afzaal@fui.edu.pk; sameen.javed@keeptruckin.com;
   shahaboddin.shamshirband@tdtu.edu.vn
RI S.Band, Shahab/ABI-7388-2020; Abbasi, Aaqif Afzaal/AFG-9482-2022;
   S.Band, Shahab/AAD-3311-2021
OI S.Band, Shahab/0000-0002-8963-731X; Abbasi, Aaqif
   Afzaal/0000-0002-9982-1321; 
CR Abdi Mania, 2019, 11 USENIX WORKSH HOT
   Adya Atul., 2010, Proceedings of the 7th USENIX conference on Networked Systems Design and Implementation (NSDI), P1
   Al Hubail M, 2019, PROC VLDB ENDOW, V12, P2275, DOI 10.14778/3352063.3352143
   Alowayyed S, 2019, FUTURE GENER COMP SY, V91, P335, DOI 10.1016/j.future.2018.08.045
   ANDERSEN DG, 2009, SOSP09 P 22 ACM SIG, P1
   Balaji P, 2004, INT SYM PERFORM ANAL, P28, DOI 10.1109/ISPASS.2004.1291353
   Catal F, 2019, PROCEDIA COMPUT SCI, V151, P279, DOI 10.1016/j.procs.2019.04.040
   Chakrabarti Somnath, 2019, P 8 INT WORKSH HARDW, P6
   Chen Chien-Hung, 2019, IEEE T PARAL DISTRI
   Choi W, 2021, J WOMEN AGING, V33, P30, DOI 10.1080/08952841.2019.1618129
   Coffman Jerrie, 2010, U.S. Patent, Patent No. [7,817,634, 7817634]
   Daglis A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P35, DOI 10.1145/3297858.3304070
   Eran H, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P345
   Fang J, 2019, IEEE CONSUM ELECTR M, V8, P46, DOI 10.1109/MCE.2019.2923928
   Felemban M, 2013, IEEE NETWORK, V27, P20, DOI 10.1109/MNET.2013.6616111
   Fujita H, 2019, PARALLEL COMPUT, V87, P1, DOI 10.1016/j.parco.2019.04.008
   Gimenez-Alventosa V, 2019, FUTURE GENER COMP SY, V97, P259, DOI 10.1016/j.future.2019.02.057
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Ha K, 2013, PROCEEDINGS OF THE 2013 IEEE INTERNATIONAL CONFERENCE ON CLOUD ENGINEERING (IC2E 2013), P166, DOI 10.1109/IC2E.2013.17
   Haghighi MA, 2019, WIRELESS PERS COMMUN, V104, P1367, DOI 10.1007/s11277-018-6089-3
   Han GJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020246
   Huang B, 2014, PEER PEER NETW APPL, V7, P485, DOI 10.1007/s12083-012-0165-3
   Jung K., 2019, 2 USENIX WORKSH HOT
   Kim J, 2019, CLUSTER COMPUT, V22, P347, DOI 10.1007/s10586-018-2833-4
   Lim H, 2011, SOSP 11: PROCEEDINGS OF THE TWENTY-THIRD ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P1
   Lim K., 2013, P 40 ANN INT S COMP, V41, P36, DOI DOI 10.1145/2485922.2485926
   Lu JH, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3323214
   Mahgoub A, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P223
   Nadeem MS, 2019, IEEE ACCESS, V7, P84003, DOI 10.1109/ACCESS.2019.2924733
   Nakao Masahiro, 2019, INT J HIGH PERFORM C
   Nan XM, 2012, IEEE INT SYMP CIRC S, P1111
   Novakovic S, 2019, ACM T COMPUT SYST, V36, DOI 10.1145/3309986
   Park JW, 2020, CURR EYE RES, V45, P955, DOI 10.1080/02713683.2019.1705493
   Pazos Nuria, 2004, GLOB SIGN PROC C GSP
   Prakash PB, 2019, WIRELESS PERS COMMUN, V104, P617, DOI 10.1007/s11277-018-6037-2
   Ruan ZY, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P379
   Tai LJ, 2019, MULTIMED TOOLS APPL, V78, P4579, DOI 10.1007/s11042-018-6391-9
   Venkataramani V, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3301308
   Wang LF, 2011, INT C PAR DISTRIB SY, P40, DOI 10.1109/ICPADS.2011.67
   Xu J, 2016, 14TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '16), P323
   Xu YH, 2014, PERFORM EVALUATION, V79, P24, DOI 10.1016/j.peva.2014.07.002
   Xu YH, 2014, IEEE INTERNET COMPUT, V18, P41, DOI 10.1109/MIC.2013.80
   Yang J, 2019, PROCEEDINGS OF THE 17TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P221
   Yang S.W., 2019, J SUPERCOMPUT, P1, DOI DOI 10.1080/15440478.2019.1685425
   Yassine A., 2016, IEEE T CLOUD COMPUT, P1
   Yoshimura Takeshi, 2019, 11 USENIX WORKSH HOT
NR 46
TC 1
Z9 1
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16743
EP 16761
DI 10.1007/s11042-020-08805-w
EA MAR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000521917400002
DA 2024-07-18
ER

PT J
AU Shokrollahi, A
   Maybodi, BMN
   Mahmoudi-Aznaveh, A
AF Shokrollahi, Ayub
   Maybodi, Babak Mazloom-Nezhad
   Mahmoudi-Aznaveh, Ahmad
TI Histogram modification based enhancement along with contrast-changed
   image quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Histogram modification; Image quality assessment
   (IQA); Particle swarm optimization (PSO)
ID EQUALIZATION; GRAY; PRESERVATION
AB Contrast is the difference in visual characteristics which make an object more recognizable. Despite the significance of contrast enhancement (CE) in image processing applications, few attempts have been made on assessment of the contrast change. In this paper, a visual information fidelity-based contrast change metric (VIF-CCM) is presented which includes visual information fidelity (VIF), local entropy, correlation coefficient, and mean intensity measures. The validation results of the presented VIF-CCM show its efficiency and superiority over the state-of-the-arts image quality assessment metrics. A histogram modification based contrast enhancement (HMCE) method is also proposed in this paper. The proposed HMCE comprises of four steps: segmentation of the input image, employing a set of weighting constraints, applying the combination of adaptive gamma correction and equalization on modified histogram, and optimization the value of the constraint weights by PSO algorithm. Experimental results demonstrate that the proposed HMCE outperforms other existing CE methods subjectively and objectively.
C1 [Shokrollahi, Ayub; Maybodi, Babak Mazloom-Nezhad] Shahid Beheshti Univ, Fac Elect Engn, Tehran, Iran.
   [Mahmoudi-Aznaveh, Ahmad] Shahid Beheshti Univ, Cyberspace Res Inst, Tehran, Iran.
C3 Shahid Beheshti University; Shahid Beheshti University
RP Mahmoudi-Aznaveh, A (corresponding author), Shahid Beheshti Univ, Cyberspace Res Inst, Tehran, Iran.
EM a_mahmoudi@sbu.ac.ir
RI Mahmoudi-Aznaveh, Ahmad/AAC-1996-2022
CR [Anonymous], 2010, ARXIV10034053
   Chen Gao, 2012, 2012 IEEE Conference on Technologies for Practical Robot Applications (TePRA), P42, DOI 10.1109/TePRA.2012.6215652
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen ZY, 2014, PROC CVPR IEEE, P3003, DOI 10.1109/CVPR.2014.384
   Cherifi D, 2010, SIGNAL IMAGE VIDEO P, V4, P247, DOI 10.1007/s11760-009-0115-6
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Ghufran RS, 2018, MULTIMED TOOLS APPL, V77, P2543, DOI 10.1007/s11042-017-4397-3
   Gu K, 2013, IEEE IMAGE PROC, P383, DOI 10.1109/ICIP.2013.6738079
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kwok NM, 2009, IEEE T AUTOM SCI ENG, V6, P145, DOI 10.1109/TASE.2008.917053
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Makhlouf Y, 2019, EXPERT SYST APPL, V119, P342, DOI 10.1016/j.eswa.2018.10.049
   Menotti D, 2007, IEEE T CONSUM ELECTR, V53, P1186, DOI 10.1109/TCE.2007.4341603
   Munteanu C, 2004, IEEE T SYST MAN CY B, V34, P1292, DOI 10.1109/TSMCB.2003.818533
   Padmanabhan S. A., 2019, MULTIMED TOOLS APPL, P1
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Pratt WK, 2001, DIGITAL IMAGE PROCES, P758
   Rohaly AM, 2000, INT SOC OPT PHOTONIC, P742
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shih FY, 2018, MULTIMED TOOLS APPL, V77, P1623, DOI 10.1007/s11042-017-4367-9
   Shokrollahi A, 2017, AEU-INT J ELECTRON C, V77, P61, DOI 10.1016/j.aeue.2017.04.026
   Simone G, 2012, J VIS COMMUN IMAGE R, V23, P491, DOI 10.1016/j.jvcir.2012.01.008
   Sivaranjani R, 2019, APPL SOFT COMPUT
   Sporring J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P900, DOI 10.1109/ICPR.1996.546154
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Tobias OJ, 2002, IEEE T IMAGE PROCESS, V11, P1457, DOI 10.1109/TIP.2002.806231
   Velde K. V., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P584, DOI 10.1109/ICIP.1999.817182
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu XL, 2011, IEEE T IMAGE PROCESS, V20, P1262, DOI 10.1109/TIP.2010.2092438
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu HJ, 2017, MULTIMED TOOLS APPL, V76, P8951, DOI 10.1007/s11042-016-3486-z
NR 45
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19193
EP 19214
DI 10.1007/s11042-020-08830-9
EA MAR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520811300005
DA 2024-07-18
ER

PT J
AU Borges, MS
   Vieira, ANW
   Carvalho, AB
   D'Angelo, MFSV
AF Borges, Matheus Silveira
   Vieira, Antonio Wilson
   Carvalho Jr, Alvaro B.
   D'Angelo, Marcos F. S. V.
TI Local range image descriptor for general point cloud registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud; Depth image; Registration
ID ROBUST; HISTOGRAMS
AB The general point cloud registration problem is addressed in this paper. Different from classical descriptors for alignment of RGB-D image, the present work proposes a descriptor for general point clouds, where no lattice structure is defined. The paper considers a point cloud as a set of 3D points without connectivity or normal vectors. In order to construct the descriptor a local reference frame is defined using PCA in the neighborhood of a keypoint and this basis is used to define a local range image upon which the descriptor is constructed. A histogram based approach is used to achieve invariance to rotation. In order to filter out ambiguity and reduce false correspondences a subset of corresponding points was constructed as an instance of the maximum clique problem. The reliability of the proposed descriptor is validated using ROC curve in comparison with other works from literature. Experiments show that the proposed descriptor have high matching precision and that the precision is improved by using the false correspondence filtering process. Furthermore, the false correspondence filtering process proposed in this paper is successfully applied to improve the precision of other descriptors from literature.
C1 [Borges, Matheus Silveira] Inst Fed Norte Minas Gerais, BR-39480000 Januaria, MG, Brazil.
   [Vieira, Antonio Wilson; Carvalho Jr, Alvaro B.; D'Angelo, Marcos F. S. V.] Univ Estadual Montes Claros, CCET, BR-39401089 Montes Claros, MG, Brazil.
C3 Instituto Federal do Norte de Minas Gerais (IFNMG); Universidade
   Estadual de Montes Claros
RP Vieira, ANW (corresponding author), Univ Estadual Montes Claros, CCET, BR-39401089 Montes Claros, MG, Brazil.
EM matheus.borges@ifnmg.edu.br; antonio.vieira@unimontes.br;
   alvarobcjr@yahoo.com.br; marcos.dangelo@unimontes.br
RI VIEIRA, ANTONIO W/B-5935-2012; D'Angelo, Marcos F. S. V./C-1322-2015
CR [Anonymous], ADV INTELL ANAL MED
   [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], ADV DEPTH IMAGE ANAL
   [Anonymous], STANFORD 3D SCANNING
   Avola D, 2019, MULTIMED TOOLS APPL, V78, P5919, DOI 10.1007/s11042-018-6875-7
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Campbell T., 2017, P IEEE C COMP VIS PA, P2941
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   do Nascimento ER, 2013, NEUROCOMPUTING, V120, P141, DOI 10.1016/j.neucom.2012.08.064
   Filipe S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P476
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Flint A., 2007, 9 BIENN C AUSTR PATT, P182, DOI [DOI 10.1109/DICTA.2007.4426794, 10.1109/DICTA.2007.4426794]
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   He YQ, 2015, NEUROCOMPUTING, V151, P354, DOI 10.1016/j.neucom.2014.09.029
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Howard A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3946, DOI 10.1109/IROS.2008.4651147
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/CVPRW.2009.5206587
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Jurado F, 2017, P I CONF MEC EL AUT, P114, DOI 10.1109/ICMEAE.2017.32
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lei H, 2017, IEEE T IMAGE PROCESS, V26, P3614, DOI 10.1109/TIP.2017.2700727
   Ligon J, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P731, DOI 10.1109/CCWC.2018.8301688
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahesh, 2012, INT CONF COMPUT
   Pankaj DS, 2016, IMAGE ANAL STEREOL, V35, P15, DOI 10.5566/ias.1378
   Prakhya SM, 2017, AUTON ROBOT, V41, P1501, DOI 10.1007/s10514-016-9612-y
   Ramalingam S, 2010, LECT NOTES COMPUT SC, V6315, P436, DOI 10.1007/978-3-642-15555-0_32
   Tareen S.A.K., 2018, 2018 INT C COMPUTING, P1, DOI DOI 10.1109/ICOMET.2018.8346440
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Wang Tao, 2011, Proceedings of the 2011 IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services (ICSDM 2011), P389, DOI 10.1109/ICSDM.2011.5969071
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
NR 34
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6247
EP 6263
DI 10.1007/s11042-019-08485-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900036
DA 2024-07-18
ER

PT J
AU Yao, X
   Song, YQ
   Liu, Z
AF Yao, Xu
   Song, Yuqing
   Liu, Zhe
TI Advances on pancreas segmentation: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Segmentation; Region; Edge; Pancreas; Atlas; Neural networks
ID ATLAS-BASED SEGMENTATION; BOTTOM-UP APPROACH; IMAGE SEGMENTATION;
   NEURAL-NETWORKS; LEVEL SET; SELECTION; ULTRASOUND; MRI; LOCALIZATION;
   SIMILARITY
AB Accurate pancreas segmentation from medical images is an important yet challenging problem for medical image analysis and medical surgery. Challenges relating to the pancreas image acquisition, the limited availability of image data and segmentation methodology hinder this segmentation task. This paper aims to present a systematic review of the different methodologies. Recently, a variety of segmentation methods have been proposed for automatic delineation of pancreas images. We intended to survey the methods proposed for image segmentation, outline those that have already been adopted for pancreas segmentation, perform a comparison between them using various indices and experimental data, and discuss their major contributions. Looking at the theoretical approach, different segmentation methods have been applied for delineating the pancreas and can be classified into those based on region, edge, atlas, neural network and other categories. Each segmentation method has its own advantages and disadvantages. Based on the previously performed analysis and discussion, and compared to other abdominal organs, improving the results of pancreas segmentation in the near future will require addressing several challenging issues. These issues include: (1) establishing publically available standardized datasets; (2) define clear metrics to evaluate the segmentation performance and (3) design new segmentation methods.
C1 [Yao, Xu; Song, Yuqing; Liu, Zhe] Jiangsu Univ, Sch Comp Sci & Telecommun, Zhenjiang, Jiangsu, Peoples R China.
   [Yao, Xu] Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang, Jiangsu, Peoples R China.
C3 Jiangsu University; Jiangsu University of Science & Technology
RP Yao, X (corresponding author), Jiangsu Univ, Sch Comp Sci & Telecommun, Zhenjiang, Jiangsu, Peoples R China.; Yao, X (corresponding author), Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang, Jiangsu, Peoples R China.
EM friendxiaoyao@163.com; yqsong@ujs.edu.cn; 1000004088@ujs.edu.cn
RI Yao, Xu/H-5009-2017
CR Aljabar P, 2009, NEUROIMAGE, V46, P726, DOI 10.1016/j.neuroimage.2009.02.018
   [Anonymous], MICCAI QUEB CIT SEP
   [Anonymous], INT C INF PROC MED I
   [Anonymous], MICCAI ATH OCT 17 21
   [Anonymous], MICCAI ATH
   [Anonymous], MICCAI BEIJ SEP 20 2
   [Anonymous], MICCAI BOST SEP 14 1
   [Anonymous], MICCAI QUEB CIT SEP
   [Anonymous], INT SYST TECHN APPL
   [Anonymous], MICCAI GRAN SEP 16 2
   [Anonymous], MED IM 2016 IM PROC
   [Anonymous], INT C IM AN REC POV
   [Anonymous], MICCAI MUN OCT 5 9
   [Anonymous], DEEP LEARNING MED IM
   [Anonymous], MICCAI BUS OCT 17 21
   [Anonymous], ARXIV562570
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2018 INT C 3D VIS VE
   [Anonymous], 2018, COMPUT MATH METHOD M, DOI DOI 10.1155/2018/2183847
   [Anonymous], INF PROC MED IM 2017
   [Anonymous], 2017, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2644615
   [Anonymous], INT J COMP APPL FLOR
   [Anonymous], EUR J ENG RES SCI
   [Anonymous], MICCAI NAG SEP 22 26
   Borges VRP, 2018, IEEE ACM T COMPUT BI, V15, P257, DOI 10.1109/TCBB.2016.2615606
   Cai Jinzheng, 2016, Med Image Comput Comput Assist Interv, V9901, P442, DOI 10.1007/978-3-319-46723-8_51
   Cardoso MJ, 2013, MED IMAGE ANAL, V17, P671, DOI 10.1016/j.media.2013.02.006
   Chen Hao, 2018, Neuroimage, V170, P446, DOI 10.1016/j.neuroimage.2017.04.041
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Chen Xinjian, 2018, IEEE Rev Biomed Eng, V11, P112, DOI 10.1109/RBME.2018.2798701
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Doshi J, 2013, ACAD RADIOL, V20, P1566, DOI 10.1016/j.acra.2013.09.010
   Erdt M, 2011, I S BIOMED IMAGING, P2076, DOI 10.1109/ISBI.2011.5872821
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Farag A, 2017, ADV COMPUT VIS PATT, P279, DOI 10.1007/978-3-319-42999-1_16
   Farag A, 2017, IEEE T IMAGE PROCESS, V26, P386, DOI 10.1109/TIP.2016.2624198
   Farag A, 2014, LECT NOTES COMPUT SC, V8676, P103, DOI 10.1007/978-3-319-13692-9_10
   Fritscher KD, 2014, MED PHYS, V41, DOI 10.1118/1.4871623
   Fu M, 2018, BMC SYST BIOL, V12, DOI 10.1186/s12918-018-0572-z
   Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309
   Gui LY, 2018, MED PHYS, V45, P223, DOI 10.1002/mp.12661
   Harrison Adam P., 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P621, DOI 10.1007/978-3-319-66179-7_71
   Howard M, 2018, SIAM J SCI COMPUT, V40, pB1161, DOI 10.1137/17M1155363
   Huang Q, 2018, COMPUT BIOL MED, V95, P198, DOI 10.1016/j.compbiomed.2018.02.012
   Ibachir IA, 2017, LECT NOTES ELECTR EN, V397, P545, DOI 10.1007/978-981-10-1627-1_43
   Iglesias JE, 2009, IEEE T MED IMAGING, V28, P1815, DOI 10.1109/TMI.2009.2025036
   Isgum I, 2009, IEEE T MED IMAGING, V28, P1000, DOI 10.1109/TMI.2008.2011480
   Janes AC, 2015, NEUROPSYCHOPHARMACOL, V40, P406, DOI 10.1038/npp.2014.185
   Jia HJ, 2012, NEUROIMAGE, V59, P422, DOI 10.1016/j.neuroimage.2011.07.036
   Karasawa K, 2017, MED IMAGE ANAL, V39, P18, DOI 10.1016/j.media.2017.03.006
   Karasawa K, 2016, LECT NOTES COMPUT SC, V9601, P47, DOI 10.1007/978-3-319-42016-5_5
   Karasawa K, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081756
   Kotrotsou A, 2014, MAGN RESON MED, V71, P364, DOI 10.1002/mrm.24661
   Kozegar E, 2018, IEEE T MED IMAGING, V37, P918, DOI 10.1109/TMI.2017.2787685
   Langerak TR, 2013, MED PHYS, V40, DOI 10.1118/1.4816654
   Latha M, 2018, MAGN RESON MATER PHY, V31, P483, DOI 10.1007/s10334-018-0674-z
   Li XM, 2018, MED IMAGE ANAL, V45, P41, DOI 10.1016/j.media.2018.01.004
   Li ZC, 2018, IEEE T NEUR NET LEAR, V29, P1947, DOI 10.1109/TNNLS.2017.2691725
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu F, 2018, MAGN RESON MED, V79, P2379, DOI 10.1002/mrm.26841
   Makropoulos A, 2018, NEUROIMAGE, V170, P231, DOI 10.1016/j.neuroimage.2017.06.074
   Nouranian S, 2015, IEEE T MED IMAGING, V34, P950, DOI 10.1109/TMI.2014.2371823
   Okada T, 2015, MED IMAGE ANAL, V26, P1, DOI 10.1016/j.media.2015.06.009
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth H, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293499
   Roth HR, 2018, MED IMAGE ANAL, V45, P94, DOI 10.1016/j.media.2018.01.006
   Roth HR, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081420
   Sabuncu MR, 2010, IEEE T MED IMAGING, V29, P1714, DOI 10.1109/TMI.2010.2050897
   Saiviroonporn P, 2018, J COMPUT ASSIST TOMO, V42, P387, DOI 10.1097/RCT.0000000000000713
   Shi Yonggang, 2013, Inf Process Med Imaging, V23, P244, DOI 10.1007/978-3-642-38868-2_21
   Shimizu A, 2010, INT J COMPUT ASS RAD, V5, P85, DOI 10.1007/s11548-009-0384-0
   Shimizu A, 2007, INT J COMPUT ASS RAD, V2, P135, DOI 10.1007/s11548-007-0135-z
   Shintani M, 2017, APPL POWER ELECT CO, P1001, DOI 10.1109/APEC.2017.7930818
   Siegel R, 2014, CA-CANCER J CLIN, V64, P9, DOI 10.3322/caac.21208
   Sjberg C, 2014, RADIAT ONCOL, V9, DOI 10.1186/s13014-014-0251-1
   Summers Ronald M, 2016, AJR Am J Roentgenol, V207, P67, DOI 10.2214/AJR.15.15996
   Suzuki T, 2016, SMART INNOV SYST TEC, V45, P575, DOI 10.1007/978-3-319-23024-5_52
   Takizawa H, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/5094592
   Tor-Díez C, 2018, COMPUT MED IMAG GRAP, V70, P73, DOI 10.1016/j.compmedimag.2018.09.003
   Torres HR, 2018, COMPUT METH PROG BIO, V157, P49, DOI 10.1016/j.cmpb.2018.01.014
   Tam TD, 2015, L N INST COMP SCI SO, V144, P332, DOI 10.1007/978-3-319-15392-6_31
   Vorontsov E, 2017, MED BIOL ENG COMPUT, V55, P127, DOI 10.1007/s11517-016-1495-8
   Wang XF, 2019, J VIS COMMUN IMAGE R, V61, P260, DOI 10.1016/j.jvcir.2019.03.024
   Wu ZW, 2018, MED IMAGE ANAL, V43, P198, DOI 10.1016/j.media.2017.11.001
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu ZB, 2014, PROC SPIE, V9034, DOI 10.1117/12.2043079
   Yan M, 2018, IET IMAGE PROCESS, V12, P1345, DOI 10.1049/iet-ipr.2017.1108
   Yan M, 2017, INT J IMAG SYST TECH, V27, P23, DOI 10.1002/ima.22207
   Yang J, 2018, MED PHYS, V45, P1758, DOI 10.1002/mp.12819
   Yang JZ, 2017, PHYS MED BIOL, V62, P9140, DOI 10.1088/1361-6560/aa94ba
   Zaffino P, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aac712
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhu JH, 2019, ACTA ONCOL, V58, P257, DOI 10.1080/0284186X.2018.1529421
   Zikic D, 2014, MED IMAGE ANAL, V18, P1262, DOI 10.1016/j.media.2014.06.010
NR 99
TC 10
Z9 11
U1 6
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6799
EP 6821
DI 10.1007/s11042-019-08320-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900061
DA 2024-07-18
ER

PT J
AU Wang, WQ
   Wang, WH
AF Wang, Weiqing
   Wang, Weihua
TI HS-based reversible data hiding scheme using median prediction error
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Side information; Median; Histogram shifting;
   Embedding payload
ID DIFFERENCE EXPANSION; WATERMARKING
AB Recently, reversible-data-hiding (RDH) scheme has been developed rapidly. In this paper, based on the local distribution of pixels in a block, (30) a histogram shifting (HS) based RDH scheme using median prediction error is proposed to increase the embedding capacity (EC) and decrease the distortion of stego image. First, we scan an original image to form the non-overlapping blocks. Then each block is sorted for locating its median. So, the median is used as the center to embed data into the pixels distributing on both sides of the median pixel in the block. Finally, the receiver can seek the same median of the block for data extraction and the recovery of the original image. Besides, we use the decomposed location message to modify the original pixels with overflow/underflow. (12) As the median is close to the mean value of block, the generated prediction error histogram is sharper than other schemes, which can provide a high capacity and lower distortion. Thus, the EC of the proposed algorithm outperforms that of the other algorithms. Experiments show the proposed scheme can provide a higher embedding rate and lower distortion as it takes advantage of the local correlation in a block.
C1 [Wang, Weiqing] Southwest Univ, Business Coll, Chongqing, Peoples R China.
   [Wang, Weihua] Chongqing Univ Arts & Sci, Sch Software Engn, Chongqing, Peoples R China.
C3 Southwest University - China; Chongqing University of Arts & Sciences
RP Wang, WQ (corresponding author), Southwest Univ, Business Coll, Chongqing, Peoples R China.
EM wwqlhy@163.com
RI liao, xingyu/KHE-4272-2024; yin, yue/JQV-9753-2023; zhu,
   zhu/JDN-0159-2023; Zhang, Yuting/JRW-3937-2023
FU National Natural Science Foundation of China [61304255]; Southwest
   University [SWU1909766, SWU1909785]
FX In this paper, we would like to thank the anonymous reviewers and
   associate editor for their comments that greatly improved the paper.
   This work is partially supported by the National Natural Science
   Foundation of China under Grant No. 61304255,
   theNaturalScienceFoundationof Chongqing under grand
   no.cstc2019jcyj-msxm2486, and Southwest University (No. SWU1909766, No.
   SWU1909785).
CR Al-Qershi Osamah M., 2010, Proceedings Second International Conference on Computer Research and Development (ICCRD 2010), P228, DOI 10.1109/ICCRD.2010.76
   Alattar AM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P377
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Andalibi M, 2015, IEEE T IMAGE PROCESS, V24, P5060, DOI 10.1109/TIP.2015.2476961
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Chen HS, 2016, SIGNAL PROCESS-IMAGE, V46, P1, DOI 10.1016/j.image.2016.04.006
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Hu Y, 2009, NAS: 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE, AND STORAGE, P315, DOI 10.1109/NAS.2009.60
   Jafar IF, 2016, J VIS COMMUN IMAGE R, V39, P239, DOI 10.1016/j.jvcir.2016.06.002
   Jiang RQ, 2018, IEEE T MULTIMEDIA, V20, P55, DOI 10.1109/TMM.2017.2723244
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lee CF, 2019, SOFT COMPUT, V23, P9719, DOI 10.1007/s00500-018-3537-7
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P1482, DOI 10.1109/TIP.2018.2878290
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liao XY, 2019, DIABETES TECHNOL THE, V21, P245, DOI 10.1089/dia.2018.0390
   Lin S. L., 2013, J INF HIDING MULTIME, V1, P19
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2017, NEUROCOMPUTING, V226, P23, DOI 10.1016/j.neucom.2016.11.017
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Shen SY, 2015, MULTIMED TOOLS APPL, V74, P707, DOI 10.1007/s11042-014-2016-0
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian HW, 2013, IEEE T CYBERNETICS, V43, P2190, DOI 10.1109/TCYB.2013.2245415
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Uyyala R, 2019, IET IMAGE PROCESS, V13, P1986, DOI 10.1049/iet-ipr.2019.0038
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   WENG S, 2016, MULTIMED TOOLS APPL, P1
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 46
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18143
EP 18165
DI 10.1007/s11042-020-08682-3
EA FEB 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000517055900001
DA 2024-07-18
ER

PT J
AU Hjouji, A
   EL-Mekkaoui, J
   Jourhmane, M
AF Hjouji, Amal
   EL-Mekkaoui, Jaouad
   Jourhmane, Mostafa
TI Rotation scaling and translation invariants by a remediation of Hu's
   invariant moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orthogonal moments; Rotation scaling and translation invariants; Pattern
   recognition; Image retrieval; Image classification; Radial basis
   functions neural networks
ID IMAGE RECOGNITION; FAST COMPUTATION
AB Due to the invariance to translation, rotation and scaling, the seven invariant moments presented by Hu (Visual pattern recognition by moment invariants, IRE Transactions on Information Theory, vol. 8, February 1962, pp. 179-187) are widely used in the field of pattern recognition. The set of these moments is finite; therefore, they do not comprise a complete set of image descriptors. To solve this problem, we introduce in this paper a new set of invariant moments of infinite order. The non-orthogonal property causes the redundancy of information. For this reason, we propose a new set of orthogonal polynomials in two variables, and we present a set of orthogonal moments, which are invariant to rotation, scale and translation. The presented approaches are tested by the invariability of the moments, the image retrieval and the classification of the objects. In this framework, using the proposed orthogonal moments, we present two classification systems. The first based on the Fuzzy C-Means Clustering algorithm (FCM) and the second based on the Radial Basis Functions Neural Network (RBF). The performance of our invariant moments is compared with Legendre invariant moments, Tchebichef-Krawtchouk (TKIM), Tchebichef-Hahn (THIM), Krawtchouk-Hahn (KHIM), Hu invariant moments, the descriptor of histogram of oriented gradients (HOG), the adaptive hierarchical density histogram features (AHDH) and with descriptors of color and texture Hist, HSV, FOS and SGLD. The experimental tests are performed on seven image databases: Columbia Object Image Library (COIL-20) database, MPEG7-CE shape database, , MNIST fashion image database, ImageNet database, COIL-100 database and ORL database. The obtained results show the efficiency and superiority of our orthogonal invariant moments.
C1 [Hjouji, Amal; Jourhmane, Mostafa] Sultan Moulay Slimane Univ, TIAD Lab, Beni Mellal, Morocco.
   [EL-Mekkaoui, Jaouad] Sultan Moulay Slimane Univ, LIRST Lab, Beni Mellal, Morocco.
C3 Sultan Moulay Slimane University of Beni Mellal; Sultan Moulay Slimane
   University of Beni Mellal
RP Hjouji, A (corresponding author), Sultan Moulay Slimane Univ, TIAD Lab, Beni Mellal, Morocco.
EM hjouji.amal@gmail.com
OI Jaouad, EL-MEKKAOUI/0000-0002-9209-7086; Hjouji,
   Amal/0000-0001-8932-9061
CR Broomhead DS, 1988, TECHNICAL REPORT RSR, V2, P41
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu X, 2016, INFORMATION, V7
   Jahid T, 2019, MULTIMED TOOLS APPL, V78, P12183, DOI 10.1007/s11042-018-6757-z
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Press W, 2020, IEEE T PATTERN ANAL
   Sidiropoulos P, 2011, PATTERN RECOGN, V44, P739, DOI 10.1016/j.patcog.2010.09.014
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Zhang H, 2010, IEEE T IMAGE PROCESS, V19, P596, DOI 10.1109/TIP.2009.2036702
   Zhu HQ, 2012, PATTERN RECOGN, V45, P1540, DOI 10.1016/j.patcog.2011.10.002
NR 19
TC 5
Z9 6
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14225
EP 14263
DI 10.1007/s11042-020-08648-5
EA FEB 2020
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000516247600002
DA 2024-07-18
ER

EF