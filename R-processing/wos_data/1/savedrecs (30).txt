FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Kumar, A
   Dua, M
AF Kumar, Atul
   Dua, Mohit
TI Novel pseudo random key & cosine transformed chaotic maps based
   satellite image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos theory; LM; CC; Pseudo-random; CTLM; CTLSM
ID SELF-ADAPTIVE PERMUTATION; STREAM-CIPHER; BIT MATRIX; ALGORITHM; SCHEME;
   SYSTEM; DIFFUSION; CRYPTANALYSIS; DECRYPTION
AB Image encryption converts the images into unrecognizable forms that seems like a white noise. Digital Chaos has also emerged as one of the important technique to design secure and efficient image encryption schemes. The chaos theory possesses various desirable properties required for the encrypting images like initial state sensitivity, unpredictability and behavioural complexity. However, image encryption schemes suffer from vulnerabilities like differential attack, statistical, known/chosen plaintext attack, and brute force attack. This paper proposes a novel approach to generate a pseudorandom key. This pseudo random key is combined with Logistic map (LM), cosine transformed Logistic map (CTLM) and cosine transformed Logistic-Sine Map (CTLSM), one by one, to implement three secure and efficient methods for satellite image encryption. The scheme uses the 384-bit of share key to perform encryption during the process. The proposed approaches are tested for parameters such as Entropy, Correlation Coefficient (CC), Number of Changing Pixel Rate (NPCR), Unified Averaged Changed Intensity (UACI), Avalanche effect, Bit Correct Ratio (BCR) and Peak Signal to Noise Ratio (PSNR). The work also analyses the various cryptanalytic attacks on the proposed chaos and novel Pseudo random key combinations. The results show that the proposed pseudo random key and CTLSM combination outperforms the other two combinations, and is more efficient in resisting all type of attacks as well.
C1 [Kumar, Atul; Dua, Mohit] Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Dua, M (corresponding author), Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
EM atul.kumar1995@gmail.com; er.mohitdua@nitkkr.ac.in
RI ; DUA, MOHIT/A-1409-2016
OI Kumar, Atul/0000-0002-6895-0104; DUA, MOHIT/0000-0001-7071-8323
CR Alawida M, 2019, IEEE ACCESS, V7, P150609, DOI 10.1109/ACCESS.2019.2947561
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Amirtharajan R, 2014, IMAGE ZONING ENCRYPT, V6
   Bahrami S, 2012, ADV MULTIMED, V2012, DOI 10.1155/2012/767364
   Bentoutou Y, 2020, ADV SPACE RES, V66, P176, DOI 10.1016/j.asr.2019.09.027
   Bisht Ankita, 2018, 2018 International Conference on Inventive Research in Computing Applications (ICIRCA). Proceedings, P676, DOI 10.1109/ICIRCA.2018.8597245
   Bisht A, 2020, J INTELL SYST, V29, P1246, DOI 10.1515/jisys-2018-0365
   Bisht A, 2019, J AMB INTEL HUM COMP, V10, P3519, DOI 10.1007/s12652-018-1072-0
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Chen JX, 2013, OPT EXPRESS, V21, P27873, DOI 10.1364/OE.21.027873
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   DHALL S, 2018, J KING SAUD U COMPUT
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   DUA M, 2020, COMPLEX INTELL SYST, V7, P1
   Dua M, 2020, J AMB INTEL HUM COMP, V11, P3771, DOI 10.1007/s12652-019-01580-z
   Farajallah M, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416500218
   Faraoun K, 2010, INT ARAB J INF TECHN, V7, P231
   Fu C, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2708532
   Ge M, 2019, EGYPT INFORM J, V20, P45, DOI 10.1016/j.eij.2018.10.001
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Hua ZY, 2018, IEEE T IND ELECTRON, V65, P2557, DOI 10.1109/TIE.2017.2736515
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Jallouli O, 2018, MULTIMED TOOLS APPL, V77, P13391, DOI 10.1007/s11042-017-4953-x
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V155, P630, DOI 10.1016/j.procs.2019.08.089
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P584, DOI 10.1016/j.procs.2019.11.043
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P491, DOI 10.1016/j.procs.2019.11.059
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P503, DOI 10.1016/j.procs.2019.11.057
   Li HJ, 2019, OPT LASER ENG, V115, P197, DOI 10.1016/j.optlaseng.2018.12.002
   Li XW, 2018, OPT LASER ENG, V100, P200, DOI 10.1016/j.optlaseng.2017.08.018
   Liu DD, 2018, SIGNAL PROCESS, V151, P130, DOI 10.1016/j.sigpro.2018.05.008
   Liu JZ, 2019, MULTIDIM SYST SIGN P, V30, P1637, DOI 10.1007/s11045-018-0622-0
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Liu YS, 2016, NONLINEAR DYNAM, V84, P2241, DOI 10.1007/s11071-016-2642-3
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Nancharla BK, 2020, 2020 5 INT C COMM EL, P1309, DOI DOI 10.1109/ICCES48766.2020.09138102
   Panwar K, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P236, DOI 10.1109/SPIN.2018.8474240
   PHATAK SC, 1995, PHYS REV E, V51, P3670, DOI 10.1103/PhysRevE.51.3670
   Saljoughi AS, 2019, PATTERN ANAL APPL, V22, P243, DOI 10.1007/s10044-018-0765-5
   Shen Q, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417502042
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Sreelaja NK, 2012, APPL SOFT COMPUT, V12, P2879, DOI 10.1016/j.asoc.2012.04.002
   Suneja K, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P693, DOI [10.1109/ICCMC.2019.8819860, 10.1109/iccmc.2019.8819860]
   Tong XJ, 2010, SCI CHINA INFORM SCI, V53, P191, DOI 10.1007/s11432-010-0010-3
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang B, 2011, OPT EXPRESS, V19, P2634, DOI 10.1364/OE.19.002634
   Zanella A, 2014, IEEE INTERNET THINGS, V1, P22, DOI 10.1109/JIOT.2014.2306328
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
   ZHU C, 2018, ENTROPY-SWITZ, V20, P2399
   2011, CHAOS BASED CRYPTOGR, V354, P1
NR 62
TC 14
Z9 14
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27785
EP 27805
DI 10.1007/s11042-021-10970-5
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000654112900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Gill, HS
   Khehra, BS
AF Gill, Harmandeep Singh
   Khehra, Baljit Singh
TI Hybrid classifier model for fruit classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid-Type II; Fuzzy; TLBO-MCET; Fruit image; Classification; CNN; RNN;
   LSTM
AB With an advancement in artificial intelligence (AI) applications, the use of smart imaging devices has been increased at a rapid rate. Recently, many researchers have utilized deep learning models such as convolutional neural networks (CNN) for image classification models. Compared to the traditional machine learning models, CNN does not require any kind of handcrafted features. It utilizes various filters to extract the potential features of images automatically. Inspired from this, in this paper, we have proposed a novel fruit classification model which utilizes the features of CNN, Long short Term Memory (LSTM) and Recurrent Neural Network (RNN) architectures. Type-II fuzzy enhancement is also used as pre-processing tool to enhance the images. Additionally, to tune the hyper-parameters of the proposed model, TLBO-MCET is also utilized. Extensive experiments are drawn by considering the existing and the proposed fruit classification models. Comparative analysis reveals that the proposed model outperforms the competitive fruit classification models.
C1 [Gill, Harmandeep Singh] Guru Arjan Dev Khalsa Coll, Comp Sci, Tarn Taran, Punjab, India.
   [Khehra, Baljit Singh] BBSBEC, CSE, Fatehgarh Sahib, India.
RP Gill, HS (corresponding author), Guru Arjan Dev Khalsa Coll, Comp Sci, Tarn Taran, Punjab, India.
EM profhdsgill@gmail.com; baljit.singh@bbsbec.ac.in
RI Gill, Harmandeep singh/AAY-9120-2020; Khehra, Baljit/W-7562-2019
OI Gill, Harmandeep singh/0000-0001-8699-2087; Khehra,
   Baljit/0000-0001-6789-7068
CR Al-Naji A, 2017, IET IMAGE PROCESS, V11, P292, DOI 10.1049/iet-ipr.2016.0569
   Andrecut M, 1999, MOD PHYS LETT B, V13, P33, DOI 10.1142/S0217984999000063
   Dang CY, 2015, IET IMAGE PROCESS, V9, P943, DOI 10.1049/iet-ipr.2014.0716
   Deng H, 2016, IET IMAGE PROCESS, V10, P701, DOI 10.1049/iet-ipr.2016.0035
   Fang CJ, 2017, MOD PHYS LETT B, V31, DOI 10.1142/S0217984917502499
   Gill HS, 2019, EGYPT INFORM J, V20, P11, DOI 10.1016/j.eij.2018.03.006
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Horng MH, 2010, EXPERT SYST APPL, V37, P4580, DOI 10.1016/j.eswa.2009.12.050
   Kalyani R, 2020, ENG SCI TECHNOL, V23, P1327, DOI 10.1016/j.jestch.2020.07.007
   Li C, 2016, NEUROCOMPUTING, V215, P196, DOI 10.1016/j.neucom.2015.07.156
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Liu W, 2016, IET IMAGE PROCESS, V10, P996, DOI 10.1049/iet-ipr.2016.0308
   Mohanty Banaja, 2016, Journal of Electrical Systems and Information Technology, V3, P33, DOI 10.1016/j.jesit.2015.11.007
   Nagadurga T, 2020, INT J AMBIENT ENERGY, DOI 10.1080/01430750.2020.1721327
   Nie FY, 2011, COMPUT ELECTR ENG, V37, P757, DOI 10.1016/j.compeleceng.2011.06.006
   Rao RV, 2012, INFORM SCIENCES, V183, P1, DOI 10.1016/j.ins.2011.08.006
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rao RV, 2013, SCI IRAN, V20, P710, DOI 10.1016/j.scient.2012.12.005
   Rasti P, 2017, IET COMPUT VIS, V11, P567, DOI 10.1049/iet-cvi.2016.0463
   Russon J, 2016, INFINITE PHENOMENOLOGY: THE LESSONS OF HEGEL'S SCIENCE OF EXPERIENCE, P1
   Shi JP, 2017, MOD PHYS LETT B, V31, DOI 10.1142/S0217984917400838
   Singh D, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918500513
   Singh D, 2017, IMAGING SCI J, V65, P282, DOI 10.1080/13682199.2017.1329792
   Singh D, 2017, J MOD OPTIC, V64, P2165, DOI 10.1080/09500340.2017.1344736
   Gill HS, 2020, IET IMAGE PROCESS, V14, P3463, DOI 10.1049/iet-ipr.2018.5310
   Singh H, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918501300
   Tang KZ, 2011, KNOWL-BASED SYST, V24, P1131, DOI 10.1016/j.knosys.2011.02.013
   Tian Z, 2015, MOD PHYS LETT B, V29, DOI 10.1142/S0217984915500748
   Tripathi AK, 2012, IETE TECH REV, V29, P148, DOI 10.4103/0256-4602.95386
   Xue YS, 2013, APPL MECH MAT, V380, P1342, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.380-384.1342
   Yoo WJ, 2010, MOD PHYS LETT B, V24, P979, DOI 10.1142/S0217984910023037
   Zheng LT, 2017, MOD PHYS LETT B, V31, DOI 10.1142/S0217984917400449
NR 34
TC 7
Z9 7
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27495
EP 27530
DI 10.1007/s11042-021-10772-9
EA MAY 2021
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652939000002
DA 2024-07-18
ER

PT J
AU Sharma, S
   Kumar, K
AF Sharma, Shikhar
   Kumar, Krishan
TI ASL-3DCNN: American sign language recognition technique using 3-D
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D CNN; Speech; ASL; Deep Learning
AB The communication between a person from the impaired community with a person who does not understand sign language could be a tedious task. Sign language is the art of conveying messages using hand gestures. Recognition of dynamic hand gestures in American Sign Language (ASL) became a very important challenge that is still unresolved. In order to resolve the challenges of dynamic ASL recognition, a more advanced successor of the Convolutional Neural Networks (CNNs) called 3-D CNNs is employed, which can recognize the patterns in volumetric data like videos. The CNN is trained for classification of 100 words on Boston ASL (Lexicon Video Dataset) LVD dataset with more than 3300 English words signed by 6 different signers. 70% of the dataset is used for Training while the remaining 30% dataset is used for testing the model. The proposed work outperforms the existing state-of-art models in terms of precision (3.7%), recall (4.3%), and f-measure (3.9%). The computing time (0.19 seconds per frame) of the proposed work shows that the proposal may be used in real-time applications.
C1 [Sharma, Shikhar; Kumar, Krishan] Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Srinagar, Garhwal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, K (corresponding author), Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Srinagar, Garhwal, India.
EM shikhar01.cse14@nituk.ac.in; kkberwal@nituk.ac.in
RI Berwal, Krishan/AAC-3473-2020
OI Berwal, Krishan/0000-0002-7068-6541
CR Ameen S, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12197
   [Anonymous], 2014, WORKSH EUR C COMP VI
   Athitsos Vassilis, 2008, COMP VIS PATT REC WO
   Cheng WT, 2019, NEURAL COMPUT APPL, V31, P309, DOI 10.1007/s00521-018-3775-8
   Cui Y, 2000, COMPUT VIS IMAGE UND, V78, P157, DOI 10.1006/cviu.2000.0837
   Gao W, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P553
   He Y, 2019, CLUSTER COMPUT, V22, P10935, DOI 10.1007/s10586-017-1237-1
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Isaacs J, 2004, SE SYM SYS THRY, P132
   Jiyong Ma, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P428, DOI 10.1109/AFGR.2000.840670
   Kang B, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P136, DOI 10.1109/ACPR.2015.7486481
   King DB, 2015, ACS SYM SER, V1214, P1
   Koller O, 2020, IEEE T PATTERN ANAL, V42, P2306, DOI 10.1109/TPAMI.2019.2911077
   Koller Oscar., 2016, P BMVC, P1, DOI 10.5244/C.30.136
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Le Cun Y., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop, P303
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lecun Y, 1988, NIPS, P141
   Li GF, 2019, IEEE ACCESS, V7, P11533, DOI 10.1109/ACCESS.2019.2891749
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Li YG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3378026
   Liang ZJ, 2018, COMPUT J, V61, P1724, DOI 10.1093/comjnl/bxy049
   Liwicki Stephan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P50, DOI 10.1109/CVPR.2009.5204291
   Negin F, 2018, EXPERT SYST APPL, V106, P21, DOI 10.1016/j.eswa.2018.03.063
   Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sagawa H., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P434, DOI 10.1109/AFGR.2000.840671
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Uebersax, 2011, COMP VIS WORKSH IEEE
   Vogler C, 2003, LECT NOTES ARTIF INT, V2915, P247
   Wang CL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/AFGR.2002.1004188
   Yao GL, 2006, INT C PATT RECOG, P312
   Yongsen Ma, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191755
   Yosinski J, 2014, ADV NEUR IN, V27
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
NR 40
TC 59
Z9 59
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26319
EP 26331
DI 10.1007/s11042-021-10768-5
EA MAY 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000656312100001
DA 2024-07-18
ER

PT J
AU Yang, B
   Cheng, J
   Yang, YX
   Zhang, B
   Li, JX
AF Yang, Bing
   Cheng, Jing
   Yang, Yunxiang
   Zhang, Bo
   Li, Jianxin
TI MERTA: micro-expression recognition with ternary attentions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expressions recognition; Attention mechanism; Convolutional neural
   network
ID DECEPTION
AB Micro-expression is a spontaneous and uncontrollable way to convey emotions. It contains abundant psychological information, whose recognition has significant importance in various fields. In recent years, with the rapid development of computer vision, the research of facial expression tends to be more mature while the research of micro-expression remains a hot yet challenging topic. The main difficulties of recognizing micro-expression lay on the discriminative feature extraction process due to the extremely short-term and subtlety of micro-expression. To deal with this problem, this paper proposes a deep learning model to efficiently extract discriminative features. Our model is based on three VGGNets and one Long Short-Term Memory (LSTM). Three VGGNets are used to extract static and motive information where three types of attention mechanism are jointly integrated for more discriminative visual representations. Then, the spatial features of a micro-expression sequence are sequentially fed into an LSTM to extract spatio-temporal features and predict the micro-expression category. Our algorithm is carried out on the benchmark micro-expression dataset CASME II. Its efficiency is demonstrated by extensive ablation analysis and state-of-the-art algorithms.
C1 [Yang, Bing; Cheng, Jing; Yang, Yunxiang; Zhang, Bo] China Acad Elect & Informat Technol, Beijing 100041, Peoples R China.
   [Li, Jianxin] Beihang Univ, Dept Comp Sci & Engn, Beijing 100041, Peoples R China.
C3 Beihang University
RP Yang, B (corresponding author), China Acad Elect & Informat Technol, Beijing 100041, Peoples R China.
EM yangbing7485370@126.com; chengjingwyw@sina.com; yyxsdu@126.com;
   edchang@126.com; lijx@act.buaa.edu.cn
CR [Anonymous], 2013, 2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG), DOI [DOI 10.1109/FG.2013.6553799, DOI 10.1109/FG.2013.6553799.IEEE]
   Bao W, 2019, CORR190400830
   Borza D, 2017, INT C INTELL COMP CO, P357, DOI 10.1109/ICCP.2017.8117030
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Davison Adrian K., 2018, IEEE Transactions on Affective Computing, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Ekman P, 1999, PSYCHOL SCI, V10, P263, DOI 10.1111/1467-9280.00147
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   Frank MG, 1997, J PERS SOC PSYCHOL, V72, P1429, DOI 10.1037/0022-3514.72.6.1429
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jing P, 2019, IEEE T IMAGE PROCESS, P1
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Li XH, 2016, INT CONF SIGN PROCES, P1130, DOI 10.1109/ICSP.2016.7878004
   Liu J, 2019, IEEE T MULTIMEDIA, V21, P2397, DOI 10.1109/TMM.2019.2897909
   Liu J, 2016, IEEE INT SYMP CIRC S, P990, DOI 10.1109/ISCAS.2016.7527409
   Lu G, 2018, LECT NOTES COMPUT SC, V11218, P591, DOI 10.1007/978-3-030-01264-9_35
   Ma S, 2017, PROC CVPR IEEE, P722, DOI 10.1109/CVPR.2017.84
   Matsumoto D, 2011, MOTIV EMOTION, V35, P181, DOI 10.1007/s11031-011-9212-2
   Mayya V, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P699, DOI 10.1109/ICACCI.2016.7732128
   Mnih V, 2014, ADV NEUR IN, V27
   PARK SY, 2015, ACM INT C MULT, P911
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Peng M, 2018, IEEE INT CONF AUTOMA, P657, DOI 10.1109/FG.2018.00103
   Perez J., 2013, Image Processing On Line, V3, P137, DOI DOI 10.5201/IPOL.2013.26
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Qu FB, 2018, IEEE T AFFECT COMPUT, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Warren G, 2009, J NONVERBAL BEHAV, V33, P59, DOI 10.1007/s10919-008-0057-7
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu N, 2019, J VIS COMMUN IMAGE R, V58, P477, DOI 10.1016/j.jvcir.2018.12.027
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   Yang B, 2016, INT CONF ACOUST SPEE, P1936, DOI 10.1109/ICASSP.2016.7472014
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
NR 45
TC 24
Z9 26
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16125
EP 16140
DI 10.1007/s11042-019-07896-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000652283400001
DA 2024-07-18
ER

PT J
AU Shalaby, AS
   Gad, R
   Hemdan, EE
   El-Fishawy, N
AF Shalaby, Ahmed Sabry
   Gad, Ramadan
   Hemdan, Ezz El-Din
   El-Fishawy, Nawal
TI An efficient CNN based encrypted Iris recognition approach in
   cognitive-IoT system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Iris recognition; Deep learning; Convolutional neural
   networks; Chaotic encryption; Cognitive IoT
AB Recently, biometric-based security plays a vital role in the success of the Cognitive Internet of Things (C-IoT) based security framework. The iris trait solves a lot of security issues, especially in smart IoT-based applications. It increases the resistance of these systems against severe authentication attacks. In this paper, an efficient iris recognition model based on chaotic encryption and deep Convolutional Neural Networks (CNNs) is proposed for C-IoT applications. CNN is used to extract the deep iris features from the left and right eyes, which will be used as input features to a fully connected neural network with a Softmax classifier. CASIA V4 Interval dataset and Phoenix dataset are used to train the CNN model; to get the best tuning of network parameters. In this paper, the effect of adding different kinds of noise to iris images, due to noise interference related to sensing IoT devices, bad acquisition of iris images by system users, or other system assaults, is discussed. This strategy of noisy encrypted iris images is evaluated over the internet environment. Chaotic encryption is utilized to secure the transmission of iris templates in the proposed model. The results showed that the proposed approach attains supreme accuracy compared to the existing approaches, it is obtained up to 99.24% and 100% with CASIA V4 and Phoenix datasets, respectively. The proposed model achieves satisfied and competitive results regard accuracy, and robustness among existing methods. Regards to recognition accuracy rate, this methodology shows low degradation of recognition accuracy rates in the case of using noised iris images. Likewise, the proposed method has a relatively low training time, which is a useful parameter in critical IoT based uses such as Tele-Medicine application.
C1 [Shalaby, Ahmed Sabry; Gad, Ramadan; Hemdan, Ezz El-Din; El-Fishawy, Nawal] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menof, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Hemdan, EE (corresponding author), Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menof, Egypt.
EM ahmed.sabry@el-eng.menofia.edu.eg; ramadangad@el-eng.menofia.edu.eg;
   ezzvip@yahoo.com; nelfishawy@hotmail.com
OI El-Fishawy, Nawal/0000-0001-9098-5541
CR Al-Waisy AS, 2018, PATTERN ANAL APPL, V21, P783, DOI 10.1007/s10044-017-0656-1
   Alaslani Maram G., 2018, International Journal of Computer Science & Information Technology, V10, P65, DOI 10.5121/ijcsit.2018.10206
   [Anonymous], 2004, SPR PRO COM, DOI 10.1007/978-1-4757-4036-3
   [Anonymous], 2020, RESNET ARCHITECTURE
   [Anonymous], 2020, INCEPTION V3 ARCHITE
   [Anonymous], 2013, HDB IRIS RECOGNITION
   [Anonymous], 2021, CASIA IRIS DATASET
   [Anonymous], 2020, VGG16 ARCHITECTURE
   [Anonymous], 2020, RASPBERRY PI 2
   [Anonymous], 2019, PHOENIX IRIS DATASET
   [Anonymous], 2020, ALEXNET ARCHITECTURE
   Atlam HF, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100220
   Baqar M., 2011, 2011 7th International Conference on Information Assurance and Security (IAS), P326, DOI 10.1109/ISIAS.2011.6122841
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Dhage SS, 2015, PROCEDIA COMPUT SCI, V45, P256, DOI 10.1016/j.procs.2015.03.135
   Dobes M, 2006, OPTIK, V117, P468, DOI 10.1016/j.ijleo.2005.11.008
   Dobes M, 2004, OPTIK, V115, P399, DOI 10.1078/0030-4026-00388
   El-Din HE, 2017, STUD BIG DATA, V25, P109, DOI 10.1007/978-3-319-53472-5_5
   El-Din HE, 2017, STUD BIG DATA, V25, P299, DOI 10.1007/978-3-319-53472-5_15
   Gad R., 2016, MENOUFIA J ELECT ENG, V25, P213, DOI [10.21608/mjeer.2016.64100, DOI 10.21608/MJEER.2016.64100]
   Gad R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTER APPLICATIONS & INFORMATION SECURITY (ICCAIS)
   Gad R, 2018, FUTURE GENER COMP SY, V89, P178, DOI 10.1016/j.future.2018.06.020
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Haykin S. S., 2008, NEURAL NETWORKS LEAR
   Jain A K, 2011, Introduction to Biometrics
   Khanam Ruqaiya, 2019, Data and Communication Networks. Proceedings of GUCON 2018. Advances in Intelligent Systems and Computing (AISC 847), P159, DOI 10.1007/978-981-13-2254-9_14
   Lozej J, 2019, I W BIOMETRIC FORENS, DOI 10.1109/iwbf.2019.8739225
   Mitchell T. M., 1997, MACH LEARN
   Nalla PR, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-0971-1
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Ramachandran, 2014, 9 INT C IND INF SYST
   Rana HK, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.184
   Saminathan K., 2015, ICTACT Journal on Soft Computing, V5, P889
   Sharma AN, INT C ADV EL COMP CO, P10
   Singh Ghanapriya, 2020, Procedia Computer Science, V171, P1868, DOI 10.1016/j.procs.2020.04.200
   Stallings W., 2016, Cryptography and Network Security: Principles and Practice, V7th
   Stevens W.R., 2003, UNIX Network Programming - The Sockets Networking API
   Thomas Parker S., 1989, Practical numerical algorithms for chaotic systems, DOI 10.1007/978-1-4612-3486-9
   Umer S, 2016, PATTERN ANAL APPL, V19, P283, DOI 10.1007/s10044-015-0482-2
   Wang, 2016, IEEE SIGN PROC MED B, P37
NR 40
TC 5
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26273
EP 26296
DI 10.1007/s11042-021-10932-x
EA APR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645496900002
DA 2024-07-18
ER

PT J
AU Wang, HY
   Gao, C
   Feng, J
   Pan, XY
   Yang, D
   Chen, BY
AF Wang, Hongyu
   Gao, Cong
   Feng, Jun
   Pan, Xiaoying
   Yang, Di
   Chen, Baoying
TI DCE-MRI interpolation using learned transformations for breast lesions
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast lesions classification; Interpolation; Contrast transformation;
   Convolutional neural network; DCE-MRI
ID CANCER DIAGNOSIS
AB Automatic differentiation of benign and malignant breast lesions on multiple DCE-MRI series is a challenging task. The performance of the Convolutional Neural Networks (CNNs) based methods is severely affected when the number of DCE-MRI series is inadequate or inconsistent. This paper is motivated by the need of capturing spatial-temporal features from consistent DCE-MRI series for most CNN-based classification methods, and aims at designing an interpolation network that can enlarge the DCE-MRI series. Therefore, our method achieves the objective of breast lesion classification for inconsistent DCE-MRI series with a two-stage method, i.e., DCE-MRI interpolation and classification. Inspired by the learning-based data augmentation, we propose a variable-length multiple DCE-MRI series interpolation method using learned transformations to enlarge DCE-MRI series. Specifically, the forward and backward contrast transformations are learned to estimate the kinetic and spatial variation between different DCE-MRI series. Then, an adaptive warping method is proposed to generate multiple interpolated DCE-MRI series. Finally, the spatial-temporal features are extracted by a new two-stream network from the interpolated DCE-MRI and they are further used to classify breast lesions. We justify the proposed method through extensive experiments using 1223 DCE-MRI slices. Comparing to other methods, it achieves better results on both single series interpolation and multiple series interpolation. The interpolated DCE-MRI greatly improves the classification accuracy nearly by 5% and the best accuracy is 81.9%.
C1 [Wang, Hongyu; Gao, Cong; Pan, Xiaoying] Xian Univ Posts & Telecommun, Sch Comp Sci & Technol, Xian 710121, Shaanxi, Peoples R China.
   [Wang, Hongyu; Gao, Cong; Pan, Xiaoying] Xian Univ Posts & Telecommun, Shaanxi Key Lab Network Data Anal & Intelligent P, Xian 710121, Shaanxi, Peoples R China.
   [Feng, Jun] Northwest Univ, Dept Informat Sci & Technol, Xian 7101127, Shaanxi, Peoples R China.
   [Yang, Di] Fourth Mil Med Univ, Tangdu Hosp, Dept Radiol, Funct & Mol Imaging Key Lab Shaanxi Prov, Xian 710038, Shaanxi, Peoples R China.
   [Chen, Baoying] Xian Int Med Ctr Hosp, Imaging Diag & Treatment Ctr, Xian 710110, Shaanxi, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of
   Posts & Telecommunications; Northwest University Xi'an; Air Force
   Military Medical University
RP Wang, HY (corresponding author), Xian Univ Posts & Telecommun, Sch Comp Sci & Technol, Xian 710121, Shaanxi, Peoples R China.; Wang, HY (corresponding author), Xian Univ Posts & Telecommun, Shaanxi Key Lab Network Data Anal & Intelligent P, Xian 710121, Shaanxi, Peoples R China.
EM hywang@xupt.edu.cn; cgao@xupt.edu.cn; fengjun@nwu.edu.cn;
   panxiaoying@xupt.edu.cn; yangdimed@163.com; chenby128@163.com
OI Wang, Hongyu/0000-0002-4556-9546
FU Youth Program of National Natural Science Foundation of China
   [62001380]; Key Research and Development Program of Shaanxi Province
   (the General Project of Social Development) [2020SF-049]; Scientific
   Research Project of Education Department of Shaanxi Provincial
   Government [19JK0808]; Xi'an Science and Technology Plan Project
   [20YXYJ0010(5)]
FX This research was supported by the Youth Program of National Natural
   Science Foundation of China (No. 62001380); the Key Research and
   Development Program of Shaanxi Province (the General Project of Social
   Development) (2020SF-049); Scientific Research Project of Education
   Department of Shaanxi Provincial Government (19JK0808); Xi'an Science
   and Technology Plan Project(20YXYJ0010(5)).
CR Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774
   Allarakha Atiya, 2019, Discov Med, V27, P139
   Alyafi B, 2020, PROC SPIE, V11314, DOI 10.1117/12.2543506
   Antropova N, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293265
   Banaie M, 2018, COMPUT METH PROG BIO, V155, P153, DOI 10.1016/j.cmpb.2017.12.015
   Bao WB, 2019, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2019.00382
   Chitalia RD, 2020, CLIN CANCER RES, V26, P862, DOI 10.1158/1078-0432.CCR-18-4067
   Feng HW, 2020, MAGN RESON IMAGING, V69, P40, DOI 10.1016/j.mri.2020.03.001
   Feng YX, 2018, GENES DIS, V5, P77, DOI 10.1016/j.gendis.2018.05.001
   Gravina M, 2019, LECT NOTES COMPUT SC, V11752, P661, DOI 10.1007/978-3-030-30645-8_60
   Guan SY, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031411
   Haarburger C, 2019, LECT NOTES COMPUT SC, V11767, P495, DOI 10.1007/978-3-030-32251-9_54
   Hauberg S, 2016, JMLR WORKSH CONF PRO, V51, P342
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Long GC, 2016, LECT NOTES COMPUT SC, V9910, P434, DOI 10.1007/978-3-319-46466-4_26
   Marrone S, 2017, LECT NOTES COMPUT SC, V10485, P479, DOI 10.1007/978-3-319-68548-9_44
   Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747
   Mihalco SP, 2020, CLIN RADIOL, V75, P194, DOI 10.1016/j.crad.2019.09.145
   Mishkin D, 2017, COMPUT VIS IMAGE UND, V161, P11, DOI 10.1016/j.cviu.2017.05.007
   Rasti R, 2017, PATTERN RECOGN, V72, P381, DOI 10.1016/j.patcog.2017.08.004
   Ravichandran K, 2018, PROC SPIE, V10575, DOI 10.1117/12.2294056
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saini Manisha, 2019, Pattern Recognition and Image Analysis. 9th Iberian Conference, IbPRIA 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11867), P409, DOI 10.1007/978-3-030-31332-6_36
   Shokouhi SB, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0476-x
   Surendiran B., 2012, International Journal of Medical Engineering and Informatics, V4, P36, DOI 10.1504/IJMEI.2012.045302
   Surendiran B., 2015, Int. J. Med. Eng. Inform., V7, P65, DOI DOI 10.1504/ijmei.2015.066244
   Vadivel A, 2013, COMPUT BIOL MED, V43, P259, DOI 10.1016/j.compbiomed.2013.01.004
   Valdora F, 2018, BREAST CANCER RES TR, V169, P217, DOI 10.1007/s10549-018-4675-4
   Yamada R, 2018, INT DEV EDUC, P1, DOI 10.1007/978-3-319-98666-1_1
   Yu QJ, 2019, BREAST CANCER RES TR, V177, P419, DOI 10.1007/s10549-019-05297-7
   Yutong Xie, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P656, DOI 10.1007/978-3-319-66179-7_75
   Zhang HR, 2019, THIRD INTERNATIONAL SYMPOSIUM ON IMAGE COMPUTING AND DIGITAL MEDICINE (ISICDM 2019), P118, DOI 10.1145/3364836.3364860
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
   Zheng H, 2018, LECT NOTES COMPUT SC, V11071, P876, DOI 10.1007/978-3-030-00934-2_97
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 38
TC 1
Z9 1
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26237
EP 26254
DI 10.1007/s11042-021-10919-8
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645497000002
DA 2024-07-18
ER

PT J
AU Sukumaran, A
   Brindha, T
AF Sukumaran, Asha
   Brindha, Thomas
TI Optimal feature selection with hybrid classification for automatic face
   shape classification using fitness sorted Grey wolf update
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face shapes; Face shape classification; Face detection; Optimal feature
   Selecetion; Grey wolf optimization
ID IDENTIFICATION; ALGORITHMS
AB Depending on the prevailing researches, the classification of face shapes could be deployed for numerous applications. This paper intends to develop a new method for face shape classification using intelligent approaches. The presented method includes three stages namely, (i) Face Detection (ii) Pre-processing (iii) Feature extraction (iv) Classification. The face detection process is used for identifying the most significant objects in the face, probably eyes, nose, etc. which is done using the Viola-Jones algorithm. Moreover, the pre-processing stage includes the Histogram Equalization (HE) model for enhancing the contrast of the image. The classification of face shapes is performed by a hybrid classifier that links Convolutional Neural Network (CNN) and Neural Network (NN). For performing the CNN-based classification, the images are directly given as input. On the other hand, NN-based classification requires features as input. Hence, the pre-processed image is again subjected to the feature extraction process, where the features are extracted using the Active Appearance Model (AAM) and the Active Shape Model (ASM). For reducing the length of extracted features, the optimal feature selection process is adopted, which is done by improved Grey Wolf Optimization (GWO) algorithm. As the main contribution, the features, number of hidden neurons in the convolutional layer of CNN, and training of NN (weight update) is optimally chosen by improved GWO so-called as Fitness Sorted Grey Wolf Update (FS-GU) model. Finally, the average of two outcomes from both CNN, and NN provides the classified five categories of face shapes like heart, oblong, oval, round, and square. The performance of the proposed classification model is finally validated by comparing over the conventional models by analyzing the relevant performance metrics.
C1 [Sukumaran, Asha] Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Kanyakumari, Tamil Nadu, India.
   [Brindha, Thomas] Noorul Islam Ctr Higher Educ, Dept Informat Technol, Kanyakumari, Tamil Nadu, India.
RP Sukumaran, A (corresponding author), Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Kanyakumari, Tamil Nadu, India.
EM ashaasasi1@gmail.com
OI Sukumaran, Asha/0000-0001-7200-1369
CR Benini S, 2019, SIGNAL PROCESS-IMAGE, V74, P21, DOI 10.1016/j.image.2019.01.005
   Bicego M, 2016, COMPUT VIS IMAGE UND, V145, P59, DOI 10.1016/j.cviu.2015.11.011
   Bouchaffra D, 2012, IEEE T NEUR NET LEAR, V23, P1229, DOI 10.1109/TNNLS.2012.2200261
   Carlos GD, 2015, J VIS COMMUN IMAGE R, V32, P170, DOI 10.1016/j.jvcir.2015.08.005
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Sa JJD, 2018, NEUROCOMPUTING, V312, P201, DOI 10.1016/j.neucom.2018.05.099
   De Winter FL, 2016, NEUROIMAGE-CLIN, V11, P368, DOI 10.1016/j.nicl.2016.03.001
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Heisel S, 2019, POWDER TECHNOL, V345, P425, DOI 10.1016/j.powtec.2019.01.018
   Huang B, 2010, INFORM SCIENCES, V180, P312, DOI 10.1016/j.ins.2009.09.016
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Juneja K, 2020, J KING SAUD UNIV-COM, V32, P618, DOI 10.1016/j.jksuci.2017.10.006
   Kashiwaya K, 2012, POWDER TECHNOL, V226, P147, DOI 10.1016/j.powtec.2012.04.036
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee S, 2017, MED IMAGE ANAL, V35, P570, DOI 10.1016/j.media.2016.08.012
   Lv CL, 2019, PATTERN RECOGN, V88, P458, DOI 10.1016/j.patcog.2018.12.006
   McCall J, 2005, J COMPUT APPL MATH, V184, P205, DOI 10.1016/j.cam.2004.07.034
   Mi Jian-Xun, 2018, NEUROCOMPUTING
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nemrodov D, 2019, NEUROIMAGE, V184, P813, DOI 10.1016/j.neuroimage.2018.09.083
   Pasupa K, 2019, EXPERT SYST APPL, V120, P14, DOI 10.1016/j.eswa.2018.11.011
   Petpairote C, 2018, IET COMPUT VIS, V12, P252, DOI 10.1049/iet-cvi.2017.0352
   Rong Z, 2015, OPTIK, V126, P5665, DOI 10.1016/j.ijleo.2015.08.169
   Roshini TV, 2020, INT J IMAG SYST TECH, V30, P1173, DOI 10.1002/ima.22419
   Sánchez-Escobedo D, 2016, COMPUT VIS IMAGE UND, V142, P111, DOI 10.1016/j.cviu.2015.08.012
   Sohn I, 2019, PHYSICA A, V523, P593, DOI 10.1016/j.physa.2019.02.046
   Song MF, 2017, GRAPH MODELS, V89, P14, DOI 10.1016/j.gmod.2017.01.001
   Song MF, 2015, COMPUT AIDED GEOM D, V35-36, P192, DOI 10.1016/j.cagd.2015.03.009
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Subramaniam K, 2020, J AMBIENT INTELL HUM, P1
   Takahashi H, 2010, INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2010), P2074
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Vinolin V, 2019, BREAST CANC DETECTIO, V2
   Wagh MB, 2018, INT J MODEL SIMUL SC, V9, DOI 10.1142/S1793962318500472
   Wang H, 2012, PATTERN RECOGN, V45, P2780, DOI 10.1016/j.patcog.2011.12.020
   Wilamowska K, 2012, J DIGIT IMAGING, V25, P400, DOI 10.1007/s10278-011-9430-x
   Xia BG, 2015, PATTERN RECOGN, V48, P746, DOI 10.1016/j.patcog.2014.09.021
   Zhang JH, 2017, J SOUND VIB, V389, P153, DOI 10.1016/j.jsv.2016.11.006
   Zhao L, 2011, VISION RES, V51, P2462, DOI 10.1016/j.visres.2011.10.001
NR 40
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25689
EP 25710
DI 10.1007/s11042-021-10710-9
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642836400002
DA 2024-07-18
ER

PT J
AU Ilyas, Z
   Aziz, Z
   Qasim, T
   Bhatti, N
   Hayat, MF
AF Ilyas, Zirgham
   Aziz, Zafar
   Qasim, Tehreem
   Bhatti, Naeem
   Hayat, Muhammad Faisal
TI A hybrid deep network based approach for crowd anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Video surveillance; Abnormal event detection; Crowd
   motion features; Crowd video analysis
AB In this paper, we present a hybrid deep network based approach for crowd anomaly detection in videos. For improved performance, the proposed approach exploits deep and handcrafted features. The proposed approach extracts spatial and temporal deep features from video frames using two resnet101 models. In order to enhance the deep features discrimination between normal and anomalous events, we perform smoothing of their Euclidean distance values for consecutive frames. For a handcrafted feature that describes the high level motion at the frame level, we compute gradient sum of the frame difference of consecutive video frames. Two deep features and one handcrafted feature of the training frames are used to train three one class support vector machines (OCSVMs). A frame is classified as anomalous performing decision combination of three OCSVMs. Experiments reveal that the proposed approach achieves high accuracy on UMN crowd anomaly dataset. On a more challenging PETS 2009 dataset the proposed approach achieves comparable performance to existing approaches.
C1 [Ilyas, Zirgham; Aziz, Zafar; Qasim, Tehreem; Bhatti, Naeem] Quaid I Azam Univ, Dept Elect, COMSIP LAB, Islamabad, Pakistan.
   [Hayat, Muhammad Faisal] Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
C3 Quaid I Azam University; University of Engineering & Technology Lahore
RP Qasim, T (corresponding author), Quaid I Azam Univ, Dept Elect, COMSIP LAB, Islamabad, Pakistan.
EM tehreemqasim@ele.qau.edu.pk
RI Hayat, Muhammad/HDN-8672-2022
OI Aziz, Zafar/0009-0005-7367-9565
CR [Anonymous], 2012, ASIAN C COMPUTER VIS
   Bhatti N, 2019, MATH COMPUT SIMULAT
   Biswas S, 2013, NAT CONF COMPUT VIS
   Chen TY, 2018, MULTIMED TOOLS APPL, V77, P14137, DOI 10.1007/s11042-017-5020-3
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Ding N, 2019, COMPUT ELECTR ENG, V79, DOI 10.1016/j.compeleceng.2019.106458
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Gnouma M, 2018, MULTIMED TOOLS APPL, V77, P24843, DOI 10.1007/s11042-018-5701-6
   Gu XX, 2014, OPTIK, V125, P3428, DOI 10.1016/j.ijleo.2014.01.041
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu X, 2016, IET COMPUT VIS, V10, P258, DOI 10.1049/iet-cvi.2015.0271
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Murugan BS, 2019, COMPUT ELECTR ENG, V75, P146, DOI 10.1016/j.compeleceng.2019.02.017
   Ravanbakhsh M, 2019, IEEE WINT CONF APPL, P1896, DOI 10.1109/WACV.2019.00206
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Susan S, 2015, SIGNAL IMAGE VIDEO P, V9, P511, DOI 10.1007/s11760-013-0464-z
   Wang T, 2018, OPTIK, V157, P1143, DOI 10.1016/j.ijleo.2017.11.176
   Wang T, 2018, OPTIK, V152, P50, DOI 10.1016/j.ijleo.2017.07.064
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu JX, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P48, DOI 10.1109/AVSS.2012.80
   Zhang XF, 2016, MULTIMED TOOLS APPL, V75, P8799, DOI 10.1007/s11042-015-3101-8
NR 26
TC 15
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24053
EP 24067
DI 10.1007/s11042-021-10785-4
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000635061900004
DA 2024-07-18
ER

PT J
AU Orio, N
   De Carolis, B
   Liotard, F
AF Orio, Nicola
   De Carolis, Berardina
   Liotard, Francesco
TI Locate your soundscape: interacting with the acoustic environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soundscape; Mobile app; Intangible heritage; Crowdsourcing
AB Although overshadowed by visual information, sound plays a central role in how people perceive an environment. The effect of a landscape is enriched by its soundscape, that is, the stratification of all the acoustic sources that, often unconsciously, are heard. This paper presents a framework for archiving, browsing, and accessing soundscapes, either remotely or on-site. The framework is based on two main components: a web-based interface to upload and search the recordings of an acoustic environment, enriched by in- formation about geolocation, timing, and context of the recording; and a mobile app to browse and listen to the recordings, using an interactive map or GPS information. To populate the archive, we launched two crowdsourcing initiatives. An initial experiment examined the city of Padua's soundscape through the participation of a group of undergraduate students. A broader experiment, which was proposed to all people in Italy, aimed at tracking how the nationwide COVID-19 lockdown was dramatically changing the soundscape of the entire country.
C1 [Orio, Nicola] Univ Padua, Dept Cultural Heritage, Piazza Capitaniato 7, Padua, Italy.
   [De Carolis, Berardina] Univ Bari Aldo Moro, Dept Informat Technol, Via E Orabona 4, Bari, Italy.
   [Liotard, Francesco] Moovioole Srl, Via Don Giuseppe Rizzi 26, Bassano Del Grappa, VI, Italy.
C3 University of Padua; Universita degli Studi di Bari Aldo Moro
RP Orio, N (corresponding author), Univ Padua, Dept Cultural Heritage, Piazza Capitaniato 7, Padua, Italy.
EM nicola.orio@unipd.it; berardina.decarolis@uniba.it;
   info@francescoliotard.com
RI DE CAROLIS, BERARDINA/ABD-4045-2021
OI DE CAROLIS, BERARDINA/0000-0002-2689-137X
FU Universita degli Studi di Padova within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Padova within
   the CRUI-CARE Agreement.
CR Adhitya S, 2018, 2018 CONFERENCE ON INTERACTION WITH SOUND (AUDIO MOSTLY): SOUND IN IMMERSION AND EMOTION (AM'18), DOI 10.1145/3243274.3243302
   [Anonymous], 2017, P 18 ISMIR C SUZH CH, DOI DOI 10.5281/ZENODO.1417159
   Ardito C, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2395131.2395136
   Barchiesi D, 2015, IEEE SIGNAL PROC MAG, V32, P16, DOI 10.1109/MSP.2014.2326181
   Boren MT, 2000, IEEE T PROF COMMUN, V43, P261, DOI 10.1109/47.867942
   Botteldooren D, 2006, J SOUND VIB, V292, P105, DOI 10.1016/j.jsv.2005.07.026
   Botteldooren D., 2011, FORUM ACUSTICUM 2011, P2047
   Bredies Katharina., 2008, AVI '08: Proceedings of the Working Conference on Advanced Visual Interfaces, P466, DOI DOI 10.1145/1385569.1385660
   Brown AL, 2012, INT J ACOUST VIB, V17, P73
   Cliffe L, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL AUDIO MOSTLY CONFERENCE, AM 2019, P176, DOI 10.1145/3356590.3356617
   Cox Trevor., 2014, SOUND BOOK SCI SONIC
   Falconer L, 2017, PERS UBIQUIT COMPUT, V21, P977, DOI 10.1007/s00779-017-1064-7
   Giannakopoulos T, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769501
   Gorko, 2018, 51 HAW INT C SYST SC, P1
   Hürst W, 2008, IEEE MULTIMEDIA, V15, P76, DOI 10.1109/MMUL.2008.66
   Kang, 1999, P 7 INT S ACM GIS 99, P116, DOI 10.1145/320134.320163
   Kang J, 2016, BUILD ENVIRON, V108, P284, DOI 10.1016/j.buildenv.2016.08.011
   Krause BernardL., 2012, GREAT ANIMAL ORCHEST
   Li CM, 2018, LANDSCAPE URBAN PLAN, V173, P64, DOI 10.1016/j.landurbplan.2018.02.002
   Luo J, 2011, P 1 INT ACM WORKSH M, P27
   Magas M, 2013, J NEW MUSIC RES, V42, P151, DOI 10.1080/09298215.2013.821999
   McGookin D, 2009, LECT NOTES COMPUT SC, V5763, P41, DOI 10.1007/978-3-642-04076-4_5
   McGregor I., 2011, SOUNDSCAPE MAPPING C
   Nunnari F, 2016, CEUR WORKSHOP PROC, V1621, P48
   Pampalk E., 2002, Proceedings of the tenth ACM international conference on Multimedia, P570, DOI DOI 10.1145/641007.641121
   Petrelli D, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1033, DOI 10.1145/2858036.2858287
   Radicchi A., 2017, P INV PLAC INT C SOU, P7
   Salo K., 2017, SAC 20117 P ACM S AP, P220, DOI [10.1145/3019612.3019691, DOI 10.1145/3019612.3019691]
   Schafer Murray., 1977, The Tuning of the World
   Sikora M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3230652
   Sinha P., 2012, Em: Proceedings of the 13th Annual International Conference on Digital Government Research. dg.o'12, P298, DOI [DOI 10.1145/2307729.2307793, https://doi.org/10.1145/2307729.2307793]
   Smiley SL, 2014, J GEOGR, V113, P238, DOI 10.1080/00221341.2013.877061
   Truax Barry., 1996, CONTEMP MUSIC REV, V15, P49, DOI [DOI 10.1080/07494469600640351, https://doi.org/10.1080/07494469600640351]
   Vazquez-Alvarez Y, 2012, PERS UBIQUIT COMPUT, V16, P987, DOI 10.1007/s00779-011-0459-0
   Vongkunkij S, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P1069, DOI 10.1145/3267305.3274162
   Yelmi P, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971492
NR 36
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34791
EP 34811
DI 10.1007/s11042-021-10683-9
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000632798100002
PM 33786010
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Costagliola, G
   De Rosa, M
   Fuccella, V
   Minas, M
AF Costagliola, Gennaro
   De Rosa, Mattia
   Fuccella, Vittorio
   Minas, Mark
TI Visual exploration of visual parser execution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parser visualization; Visual parsing; Graph parsing; Visualization;
   Program visualization; Human-computer interaction
ID COMPILER; TOOL
AB In this paper, we present ParVis, an interactive visual system for the animated visualization of logged parser trace executions. The system allows a parser implementer to create a visualizer for generated parsers by simply defining a JavaScript module that maps each logged parser instruction into a set of events driving the visual system interface. The result is a set of interacting graphical/text windows that allows users to explore logged parser executions and helps them to have a complete understanding of how the parser behaves during its execution on a given input. We used our system to visualize the behavior of textual as well as visual parsers and describe here two of these uses. Moreover, in order to validate the efficacy of our system, we ran a user experiment where students analyzed a CUP-generated parser both with ParVis, instantiated to LALR parsers, and the standard CUP debug facilities. The results show that students can indeed analyze parser behavior and find mistakes in parser specifications more easily and quickly using ParVis. In particular, in some parser design tasks, using ParVis participants achieved a higher success rate of 50% in 42% less time with respect to the baseline system.
C1 [Costagliola, Gennaro; De Rosa, Mattia; Fuccella, Vittorio] Univ Salerno, Dept Informat, Via Giovanni Paolo II, Fisciano, SA, Italy.
   [Minas, Mark] Univ Bundeswehr Munchen, Dept Comp Sci, Neubiberg, Germany.
C3 University of Salerno; Bundeswehr University Munich
RP De Rosa, M (corresponding author), Univ Salerno, Dept Informat, Via Giovanni Paolo II, Fisciano, SA, Italy.
EM gencos@unisa.it; matderosa@unisa.it; vfuccella@unisa.it;
   mark.minas@unibw.de
RI De Rosa, Mattia/V-7792-2019; Costagliola, Gennaro/GLV-1530-2022
OI De Rosa, Mattia/0000-0002-6922-5529; Costagliola,
   Gennaro/0000-0003-3816-7765; Fuccella, Vittorio/0000-0003-3244-3650;
   Minas, Mark/0000-0002-8968-9013
FU Universita degli Studi di Salerno within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Salerno within
   the CRUI-CARE Agreement.
CR ANDREWS K, 1988, SIGPLAN NOTICES, V23, P105, DOI 10.1145/960116.54001
   Blythe S. A., 1994, SIGCSE Bulletin, V26, P208, DOI 10.1145/191033.191121
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   BROWN MH, 1985, IEEE SOFTWARE, V2, P28, DOI 10.1109/MS.1985.229778
   Costagliola G, 2004, ACM T SOFTW ENG METH, V13, P431, DOI 10.1145/1040291.1040293
   COSTAGLIOLA G, 2020, P 2020 INT C ADV VIS
   Costagliola G, 2019, S VIS LANG HUM CEN C, P243, DOI [10.1109/VLHCC.2019.8818802, 10.1109/vlhcc.2019.8818802]
   Costagliola G, 2018, INFORM VISUAL, V17, P335, DOI 10.1177/1473871617714520
   Drewes F, 2019, J LOG ALGEBR METHODS, V104, P303, DOI 10.1016/j.jlamp.2018.12.006
   Drewes F, 2017, LECT NOTES COMPUT SC, V10373, P106, DOI 10.1007/978-3-319-61470-0_7
   Drewes F, 2015, LECT NOTES COMPUT SC, V9151, P19, DOI 10.1007/978-3-319-21145-9_2
   Economopoulos Giorgios Robert, 2006, THESIS U LONDON
   Fischer B, 2011, LANGUAGE DESCRIPTION, P12, DOI [10.1145/1988783.1988795, DOI 10.1145/1988783.1988795]
   Habel A., 1992, Hyperedge replacement: grammars and languages
   Hoffmann Berthold, 2019, Language and Automata Theory and Applications. 13th International Conference, LATA 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11417), P233, DOI 10.1007/978-3-030-13435-8_17
   Jain A., 2017, ACM INROADS, V8, P43, DOI [10.1145/3002136, DOI 10.1145/3002136]
   Johnstone Adrian., 2004, 4 WORKSHOP LANGUAGE, P97
   Kaplan A, 2000, SIGCSE BULL, V32, P11, DOI 10.1145/331795.331801
   Karavirta Ville., 2013, Proceedings of the 18th ACM conference on Innovation and technology in computer science education, P159, DOI DOI 10.1145/2462476.2462487
   Khuri S., 1998, SIGCSE Bulletin, V30, P232, DOI 10.1145/274790.274303
   Krebs N, 2014, SCI COMPUT PROGRAM, V79, P101, DOI 10.1016/j.scico.2012.03.001
   Lovato M. E., 1995, SIGCSE Bulletin, V27, P345, DOI 10.1145/199691.199855
   Mernik M, 2003, IEEE T EDUC, V46, P61, DOI 10.1109/TE.2002.808277
   Minas M, 2020, P 26 INT DMS C VIS V, P57, DOI [10.18293/DMSVIVA20-013, DOI 10.18293/DMSVIVA20-013]
   Minas M, 2019, ELECTRON P THEOR COM, P71, DOI 10.4204/EPTCS.309.4
   Mukherjea S., 1994, ACM Transaction on Computer Human Interaction, Vl, P215, DOI DOI 10.1145/196699.196702
   RESLER D, 1990, SIGPLAN NOTICES, V25, P120, DOI 10.1145/87416.87483
   Resler R. D., 1998, SIGCSE Bulletin, V30, P199, DOI 10.1145/290320.283123
   Rodger S.H., 2006, JFLAP: An Interactive Formal Languages and Automata Package
   Sangal S, 2018, EDUC INF TECHNOL, V23, P2737, DOI 10.1007/s10639-018-9739-x
   Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P185, DOI 10.1016/B978-0-12-384968-7.00008-4
   Shaffer, 2010, ACM T COMPUT EDUC, V10
   Stasko J. T., 1990, Proceedings of the 1990 IEEE Workshop on Visual Languages (Cat. No.90TH0330-1), P1, DOI 10.1109/WVL.1990.128374
   Tomita M., 1985, P 9 INT JOINT C ART, P756
   White EL, 1999, SOFTWARE PRACT EXPER, V29, P1, DOI 10.1002/(SICI)1097-024X(199901)29:1<1::AID-SPE216>3.0.CO;2-N
   Wilhelm R., 2013, Compiler design: syntactic and semantic analysis
NR 36
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 299
EP 317
DI 10.1007/s11042-021-10624-6
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000630281200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Saboo, S
   Singha, J
AF Saboo, Shweta
   Singha, Joyeeta
TI Vision based two-level hand tracking system for dynamic hand gestures in
   indoor environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand tracking; Hand detection; KLT algorithm; Dynamic hand gestures;
   Camshift algorithm
AB Object detection and tracking is one of the most challenging phases in any image processing application. The challenges that arise during hand gesture recognition are: hand shape variation, presence of multiple persons, illumination variation or occlusion with background. In this paper, a robust hand detector and tracker algorithm has been proposed which overcomes the above difficulties to a great extent. The proposed system first detects hand using a combination of color and motion information. Then, the hand is tracked using combination of feature based tracker modified KLT algorithm and a color-based tracker Camshift algorithm. New feature points have been added to our modified combination of feature and color based tracker. This prevents the loss of tracking as seen in traditional KLT algorithm. The experiments carried out using the proposed system shows that the system provides better results in comparison to the existing literatures on various challenging hand sequences.
C1 [Saboo, Shweta; Singha, Joyeeta] Dept Elect & Commun, Jaipur, Rajasthan, India.
   [Saboo, Shweta; Singha, Joyeeta] LNM Inst Informat Technol, Jaipur 302031, Rajasthan, India.
C3 LNM Institute of Information Technology
RP Singha, J (corresponding author), Dept Elect & Commun, Jaipur, Rajasthan, India.; Singha, J (corresponding author), LNM Inst Informat Technol, Jaipur 302031, Rajasthan, India.
EM shweta.saboo.y18pg@lnmiit.ac.in; joyeeta.singha@lnmiit.ac.in
RI Singha, Joyeeta/C-3650-2017
OI Singha, Joyeeta/0000-0001-9077-1842
FU DST; SEED Division [SP/YO/407/2018]
FX This work is supported by DST (Govt. of India) under the SEED Division
   [SP/YO/407/2018].
CR [Anonymous], 2004, Proceedings of the Pan-Sydney area workshop on Visual information processing
   Asaari MSM, 2014, MULTIMED TOOLS APPL, V70, P1869, DOI 10.1007/s11042-012-1212-z
   Badwaik SC, 2015, 2015 INT C PERV COMP, P1
   Chibelushi CC, 2003, CVONLINE ON LINE COM
   Guo JM, 2012, IEEE T CIRC SYST VID, V22, P693, DOI 10.1109/TCSVT.2011.2177192
   Heenaye-Mamode Khan Maleika, 2019, Information Systems Design and Intelligent Applications. Proceedings of Fifth International Conference INDIA 2018. Advances in Intelligent Systems and Computing (AISC 863), P295, DOI 10.1007/978-981-13-3338-5_27
   Khetarpal Poras, 2019, Applications of Computing, Automation and Wireless Systems in Electrical Engineering. Proceedings of MARC 2018. Lecture Notes in Electrical Engineering (LNEE 553), P1149, DOI 10.1007/978-981-13-6772-4_100
   Kolsch M., 2004, Computer Vision and Pattern Recognition Workshop, P158
   Lee HK, 2013, IEEE ICCE, P33, DOI 10.1109/ICCE.2013.6486783
   Nouar O.-D., 2006, 2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, IEEE, V2, pII
   Rahman MA, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS AGENTS, NETWORKS AND SYSTEMS (INAGENTSYS), P58, DOI 10.1109/INAGENTSYS.2014.7005726
   Sharmila Kumari, 2019, J COMPUT THEOR NANOS, V16, P1485, DOI [10.1166/jctn.2019.8062, DOI 10.1166/JCTN.2019.8062]
   Singha J, 2018, NEURAL COMPUT APPL, V29, P1129, DOI 10.1007/s00521-016-2525-z
   Singha J, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P3644, DOI 10.1109/TENCON.2016.7848737
   Sinha Keshav., 2019, INNOVATIONS SOFT COM, P55
   Suhr J. K., 2009, Computer Vision (EEE6503), P9
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xiu CB, 2018, CHIN CONT DECIS CONF, P4449, DOI 10.1109/CCDC.2018.8407900
   Yuan Y, 2014, IEEE T CIRC SYST VID, V24, P15, DOI 10.1109/TCSVT.2013.2273631
NR 19
TC 14
Z9 14
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20579
EP 20598
DI 10.1007/s11042-021-10669-7
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625906400002
DA 2024-07-18
ER

PT J
AU Razaq, A
   Iqra
   Ahmad, M
   Yousaf, MA
   Masood, S
AF Razaq, Abdul
   Iqra
   Ahmad, Musheer
   Yousaf, Muhammad Awais
   Masood, Sarfaraz
TI A novel finite rings based algebraic scheme of evolving secure S-boxes
   for images encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Substitution-box; Algebraic structure; Symmetric group; Image encryption
ID SUBSTITUTION-BOX; CHAOTIC MAP; DESIGN; DECOMPOSITION; CONSTRUCTION
AB Substitution-boxes have significant role in block ciphers as they are the only component which offers nonlinearity in the anticipated symmetric encryption systems. This paper proposed to present a novel algebraic scheme to generate secure 8 x 8 substitution-boxes. We find the finite rings of integers with exactly 256 unit elements which are utilized to construct S-boxes. Firstly, the unit elements of the selected rings are used to create the initial random sequence of 256 elements. Secondly, the newly defined bijective polynomial maps are applied to create two initial seed S-boxes of decent cryptographic strength. Lastly, appropriate permutations of a symmetric group of degree 16 are employed to evolve two more S-boxes. The performances of the generated S-boxes are tested through the standard analyses consisting of criterions such as nonlinearity test, probability tests (linear and differential approximation), strictly avalanche criteria, and output bits independence criteria. Moreover, we examine the strength of generated S-boxes for symmetric image encryption applications through various performance measures. The simulation outcomes confirm the effectiveness of proposed scheme for secure communication.
C1 [Razaq, Abdul] Univ Educ Lahore, Div Sci & Technol, Dept Math, Lahore, Pakistan.
   [Iqra] Muslim Cambridge High Sch Khushab, Dept Math, Khushab, Pakistan.
   [Ahmad, Musheer; Masood, Sarfaraz] Jamia Millia Islamia, Dept Comp Engn, New Delhi 110025, India.
   [Yousaf, Muhammad Awais] Islamia Univ Bahawalpur, Dept Math, Bahawalpur, Pakistan.
C3 Jamia Millia Islamia; Islamia University of Bahawalpur
RP Razaq, A (corresponding author), Univ Educ Lahore, Div Sci & Technol, Dept Math, Lahore, Pakistan.
EM abdul.razaq@ue.edu.pk; iqrarajpoot203@gmail.com; mahmad9@jmi.ac.in;
   awais.yousaf@iub.edu.pk; smasood@jmi.ac.in
RI Razaq, Abdul/Q-6545-2019; Ahmad, Musheer/H-9587-2018; Yousaf,
   Awais/ABA-5292-2020; Masood, Sarfaraz/AAR-6023-2021
OI Ahmad, Musheer/0000-0002-4915-9325; Yousaf, Awais/0000-0002-3507-9367;
   Masood, Sarfaraz/0000-0003-2675-3484; , Abdul Razaq/0000-0002-1898-4082
CR Abd-El-Atty B, 2019, I C SOFTWARE KNOWL I, DOI 10.1109/skima47702.2019.8982535
   Ahmad M., 2016, Perspectives in Science, V8, P465
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Anees A, 2015, WIRELESS PERS COMMUN, V82, P1497, DOI 10.1007/s11277-015-2295-4
   [Anonymous], 2017, WIRELESS PERS COMMUN
   Artuger F, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040571
   Cassal-Quiroga BB, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2702653
   Daemen J., 2002, The Design of Rijndael, P255, DOI DOI 10.1007/978-3-662-04722-4
   Dawson MH, 1992, UNIFIED FRAMEWORK SU
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Guesmi R, 2014, I C COMP SYST APPLIC, P678, DOI 10.1109/AICCSA.2014.7073265
   Hussain I, 2012, Z NATURFORSCH A, V67, P282, DOI 10.5560/ZNA.2012-0022
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Javeed A, 2020, WIRELESS PERS COMMUN, V112, P467, DOI 10.1007/s11277-020-07052-4
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2015, J INTELL FUZZY SYST, V28, P1509, DOI 10.3233/IFS-141434
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Khan MF, 2019, IEEE ACCESS, V7, P15999, DOI 10.1109/ACCESS.2019.2893176
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Muhammad N, 2018, PATTERN ANAL APPL, V21, P997, DOI 10.1007/s10044-017-0613-z
   Muhammad N, 2015, IET IMAGE PROCESS, V9, P795, DOI 10.1049/iet-ipr.2014.0395
   Muhammad ZMZ, 2020, IEEE ACCESS, V8, P56581, DOI 10.1109/ACCESS.2020.2982827
   Nedjah Nadia, 2007, International Journal of Innovative Computing and Applications, V1, P86, DOI 10.1504/IJICA.2007.013404
   Özkaynak F, 2019, NEURAL COMPUT APPL, V31, P3317, DOI 10.1007/s00521-017-3287-y
   PIEPRZYK J, 1988, IEE PROC-E, V135, P325, DOI 10.1049/ip-e.1988.0044
   Razaq A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5101934
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Siddiqui N, 2021, WIRELESS PERS COMMUN, V116, P3015, DOI 10.1007/s11277-020-07832-y
   Silva-García VM, 2018, APPL MATH COMPUT, V332, P123, DOI 10.1016/j.amc.2018.03.019
   Tian Y, 2018, NONLINEAR DYNAM, V94, P2115, DOI 10.1007/s11071-018-4478-5
   Tian Y, 2016, J SYST ENG ELECTRON, V27, P232, DOI 10.1109/JSEE.2016.00023
   Tran MT, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P253, DOI 10.1109/CIS.2008.205
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yi LT, 2019, IEEE ACCESS, V7, P53079, DOI 10.1109/ACCESS.2019.2911395
   Yousaf MA, 2020, IEEE ACCESS, V8, P39781, DOI 10.1109/ACCESS.2020.2975880
   Zahid AH, 2020, IEEE ACCESS, V8, P150326, DOI 10.1109/ACCESS.2020.3016401
   Zhang YQ, 2020, IEEE ACCESS, V8, P54175, DOI 10.1109/ACCESS.2020.2979827
   Zhu HH, 2020, MULTIMED TOOLS APPL, V79, P12329, DOI 10.1007/s11042-019-08478-0
NR 50
TC 15
Z9 15
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20191
EP 20215
DI 10.1007/s11042-021-10587-8
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612900008
DA 2024-07-18
ER

PT J
AU Cifuentes, J
   Orozco, ALS
   Villalba, LJG
AF Cifuentes, Jenny
   Sandoval Orozco, Ana Lucila
   Garcia Villalba, Luis Javier
TI A survey of artificial intelligence strategies for automatic detection
   of sexually explicit videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sexually explicit content detection; Video classification; Digital
   forensics; Deep learning; Motion features; Visual information analysis
ID CHILD PORNOGRAPHY; RECOGNITION; REPRESENTATION; SYSTEM
AB Digital forensics and analysis have emerged as a discipline to fight against cyber and computer-assisted crime. In particular, taking into account the increasing of unconstrained pornographic content over Internet and the spreading cases of Child Sex Abuse material distribution, there is a growing need of efficient computational tools to automatically detect or/and block pornographic videos. The primary objective of this study is to review the different strategies available in the literature for pornography detection in videos and identify research gaps. This survey shows that deep learning based techniques detect videos with sexually explicit content more accurately compared with other conventional detection strategies. The accuracy of the strategies reported in this work, is found to be dependent on features extraction techniques, architecture, and learning algorithms. Finally, further research areas in pornographic video detection are outlined.
C1 [Cifuentes, Jenny] Univ Carlos III Madrid, Santander Big Data Inst, Getafe, Spain.
   [Sandoval Orozco, Ana Lucila; Garcia Villalba, Luis Javier] Univ Complutense Madrid UCM, Grp Anal Secur & Syst GASS, Dept Software Engn & Artificial Intelligence DISI, Fac Comp Sci & Engn, Off 431,Calle Prof Jose Garcia Santesmases,9, Madrid 28040, Spain.
C3 Universidad Carlos III de Madrid; Complutense University of Madrid
RP Cifuentes, J (corresponding author), Univ Carlos III Madrid, Santander Big Data Inst, Getafe, Spain.
EM jacifuentesq@gmail.com
RI Villalba, Luis Javier Garcí­a/N-4631-2014
OI Cifuentes Quintero, Jenny/0000-0001-7421-291X
FU European Union [700326]
FX This project has received funding from the European Unionas Horizon 2020
   research and innovation programme under grant agreement No 700326.
   Website: http://ramses2020.eu
CR [Anonymous], 2006, The 3rd European Conference on Visual Media Production (CVMP 2006)-Part of the 2nd Multimedia Conference 2006, IET, DOI DOI 10.1049/CP:20061978
   [Anonymous], 2012, IEEE SIBGRAPI
   [Anonymous], 2019, TAPTAP SOFTWARE
   Apid R.A., 2005, International Conference on Philippine Computing Science Congress, P201
   Avila S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2909, DOI 10.1109/ICIP.2011.6116268
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Behrad A, 2012, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2012-23
   Caetano C, 2016, NEUROCOMPUTING, V213, P102, DOI 10.1016/j.neucom.2016.03.099
   Caetano C, 2014, EUR SIGNAL PR CONF, P1681
   Carlsson, 2008, AUTOMATIC DETECTION
   Da Silva Eleuterio PM, 2012, P 7 INT C FOR COMP S, P12, DOI DOI 10.5769/C2012002
   da Silva MV, 2018, IB C PATT REC, P547
   de Castro Polastro Mateus, 2010, 2010 21st International Conference on Database and Expert Systems Applications, P349, DOI 10.1109/DEXA.2010.74
   Deselaers T, 2008, PROC CVPR IEEE, P3017
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Endeshaw T, 2008, IEEE APP IMG PAT, P13
   Fleck M M, 1996, P EUR C COMP VIS, P593, DOI DOI 10.1007/3-540-61123-1_173
   Gangwar Abhishek, 2017, 8th International Conference on Imaging for Crime Detection and Prevention (ICDP 2017), P37
   Garcia Manuel B., 2018, 2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM), DOI 10.1109/HNICEM.2018.8666227
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hyperdyne software, 2019, SNITCH PLUS
   Jansohn C., 2009, PROC 17 ACM INT C MU, P601, DOI [DOI 10.1145/1631272.1631366, 10.1145/1631272.1631366]
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Jung S, 2014, IEEE T CONSUM ELECTR, V60, P696, DOI 10.1109/TCE.2014.7027345
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kim CY, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1435
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lee H, 2006, 8TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1-3, pU959
   Lillie O., 2017, PHP VIDEO
   Liu YZ, 2020, MULTIMED TOOLS APPL, V79, P4729, DOI 10.1007/s11042-019-7576-6
   Lopes Ana P. B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1552
   Lopes APB, 2009, SIBGRAPI, P224, DOI 10.1109/SIBGRAPI.2009.32
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   MOUSTAFA M, 2015, P PAC RIM S IM VID T
   Nian FD, 2016, NEUROCOMPUTING, V210, P283, DOI 10.1016/j.neucom.2015.09.135
   Ost S, 2002, J LAW SOC, V29, P436, DOI 10.1111/1467-6478.00227
   Papadamou K., 2020, P INT AAAI C WEB SOC, V14, P522, DOI [https://doi.org/10.1609/icwsm.v14i1.7320, DOI 10.1609/ICWSM.V14I1.7320]
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Platzer C, 2014, SFCS'14: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON SECURITY AND FORENSICS IN COMMUNICATION SYSTEMS, P45, DOI 10.1145/2598918.2598920
   Polastro MD, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES), P604, DOI 10.1109/ARES.2012.71
   Qu ZY, 2009, PROCEEDINGS OF 2009 2ND IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY, P183, DOI 10.1109/ICBNMT.2009.5348475
   Singh S, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P2104, DOI 10.1145/3297280.3297487
   Song KH, 2018, J ENG APPL SCI, V13, P1174, DOI DOI 10.3923/JEASCI.2018.1174.1182
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Ulges A., 2012, P 2012 ACM INT WORKS, P21, DOI [10.1145/2390214.2390222, DOI 10.1145/2390214.2390222]
   Ulges A, 2011, IEEE INT CON MULTI
   Valle, 2011, ARXIV11012427
   Vitorino P, 2018, J VIS COMMUN IMAGE R, V50, P303, DOI 10.1016/j.jvcir.2017.12.005
   Wang DH, 2005, PROC SPIE, V5637, P88, DOI 10.1117/12.577235
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang JZ, 1998, COMPUT COMMUN, V21, P1355, DOI 10.1016/S0140-3664(98)00203-5
   Wang YH, 2016, IEEE IMAGE PROC, P4418, DOI 10.1109/ICIP.2016.7533195
   Warner K, 2010, AUST LAW J, V84
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Zhang J, 2013, NEUROCOMPUTING, V110, P145, DOI 10.1016/j.neucom.2012.11.029
   Zhu Miao-Liang, 2000, Journal of Computer Aided Design & Computer Graphics, V12, P585
   Zuo HQ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P37, DOI 10.1109/ICME.2008.4607365
NR 59
TC 3
Z9 3
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3205
EP 3222
DI 10.1007/s11042-021-10628-2
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000625037300004
DA 2024-07-18
ER

PT J
AU Garg, K
   Lobiyal, DK
AF Garg, Kanika
   Lobiyal, D. K.
TI KL-NF technique for sentiment classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Neuro-fuzzy; KL divergence; Hindi; Low-resource
   language
AB This work proposes sentiment analysis for low-resource languages like Hindi using Neuro-Fuzzy Technique. Low-resource languages suffer from the scarcity of resources; consequently, we propose a method that can be implemented for any language. We use information theory for establishing a relation between terms that exists in a sentence. This work proposes a novel approach for calculating feature values using Kullback-Leibler (KL) divergence method. The feature values are employed to calculate the membership values associated with the Fuzzy logic in Neuro-Fuzzy Technique. The novelty of this method lies in its predictive nature that can mitigate the impact generated from un-labeled, unknown data or multi-domain data. We have seen the results for multi-domain data in our experiments. We evaluate our results using Accuracy, Precision, Recall and F1-Score. Our experiments show the efficacy of the proposed approach. It achieved 93.01% accuracy for English dataset and 91.18% accuracy for Hindi dataset which is more than the other state-of-art techniques like Naive Bayes and SVM. Additionally, we found that our approach provides satisfactory results with multi-domain data as both the datasets were of different domains.
C1 [Garg, Kanika; Lobiyal, D. K.] Jawaharlal Nehru Univ, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Garg, K (corresponding author), Jawaharlal Nehru Univ, New Delhi, India.
EM k.garg4579@gmail.com; lobiyal@gmail.com
RI Garg, Kanika/AAT-9586-2020
OI Garg, Kanika/0000-0001-7658-1305
CR Akhtar M. S., 2016, P COLING 2016 26 INT, P482
   Akhtar MS, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2703
   Aleem A., 2017, APPL MATH INFORM SCI, V11, P289, DOI [10.18576/amis/110135, DOI 10.18576/AMIS/110135]
   Ali F, 2016, APPL SOFT COMPUT, V47, P235, DOI 10.1016/j.asoc.2016.06.003
   Alm CO, 2005, P C HUM LANG TECHN E, P579, DOI DOI 10.3115/1220575.1220648
   [Anonymous], 2018, ARXIV180306745
   [Anonymous], 2012, Int. J. Comput. Linguist. Appl
   Bakliwal A, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1189
   Balamurali AR., 2011, P 2 WORKSH COMP APPR, P132
   Baziotis C., 2017, P 11 INT WORKSHOP SE, P747, DOI [DOI 10.18653/V1/S17-2126, 10.18653/v1/S17-2126]
   Benedetto F, 2016, STUD COMPUT INTELL, V639, P341, DOI 10.1007/978-3-319-30319-2_14
   Bhattacharyya P, 2010, P 8 INT C NAT LANG P
   Biswas SK., 2018, INT J PURE APPL MATH, V118, P85
   Blitzer John., 2007, Annual Meeting-Association For Computational Linguistics, V45, P440
   Bohra A., 2018, P 2 WORKSH COMP MOD, P36, DOI DOI 10.18653/V1/W18-1105
   Bravo-Marquez F, 2017, P EMNLP 2017 WORKSH
   Carvalho J, 2021, ARTIF INTELL REV, V54, P1887, DOI 10.1007/s10462-020-09895-6
   Ceron A, 2016, INFORM SCIENCES, V367, P105, DOI 10.1016/j.ins.2016.05.052
   Cerra D, 2011, ENTROPY-SWITZ, V13, P902, DOI 10.3390/e13040902
   Cheng XY, 2017, ACM T ASIAN LOW-RESO, V17, DOI 10.1145/3132684
   Cliche M, 2017, ABS170402017 CORR
   Dahiya A, 2019, ARXIV190607382
   Das A, 2009, P ICON 2009
   Das A., 2010, Proceedings of the Eighth Workshop on Asian Language Resouces, P56
   Das S, 2016, 2016 19TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1003
   Dave K., 2003, P 12 INT C WORLD WID, P519, DOI [10.1145/775152.775226, DOI 10.1145/775152.775226]
   Garain A, 2020, ARXIV200712561
   Garg, 2018, EXTENSIBLE ADAPTABLE, P251
   Garg Kanika, 2020, International Journal of Information Technology, V12, P37, DOI 10.1007/s41870-019-00324-8
   Garg K, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3383330
   GASKI JF, 1986, J MARKETING, V50, P71, DOI 10.2307/1251586
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   Hong S, 2012, GOV INFORM Q, V29, P455, DOI 10.1016/j.giq.2012.06.004
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Jain A., 2012, INT J INFORM SCI TEC, V2, P103, DOI [10.5121/ijist.2012.2410, DOI 10.5121/IJIST.2012.2410]
   Jain VK, 2017, J COMPUT SCI-NETH, V21, P316, DOI 10.1016/j.jocs.2017.01.010
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Jang JSR., 1997, NEUROFUZZY SOFT COMP, V42, P1482
   Jha V, 2018, COMPUT ELECTR ENG, V69, P585, DOI 10.1016/j.compeleceng.2017.10.015
   Joshi A, 2011, P 49 ANN M ASS COMP, P127
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   KULLBACK S, 1987, AM STAT, V41, P340
   Kummer Ol, 2012, 1 INT WORKSH SENT DI, P48
   Lei JS, 2014, FUTURE GENER COMP SY, V37, P438, DOI 10.1016/j.future.2013.09.024
   Leitch D, 2017, J COMPUT SCI-NETH, V21, P1, DOI 10.1016/j.jocs.2017.04.002
   Liu B, 2010, CH CRC MACH LEARN PA, P627
   Luyckx K, 2012, BIOMED INFORM INSIGH, V5, P61, DOI 10.4137/BII.S8966
   Matsumoto S, 2005, LECT NOTES ARTIF INT, V3518, P301
   McCart JA, 2012, BIOMED INFORM INSIGH, V5, P77, DOI 10.4137/BII.S8931
   Moudy Christopher, 2016, U.S. Patent, Patent No. [9,336,268, 9336268]
   Mukherjee Subhabrata, 2012, Computational Linguistics and Intelligent Text Processing. Proceedings 13th International Conference (CICLing 2012), P475, DOI 10.1007/978-3-642-28604-9_39
   Nakov P., ARXIV PREPRINT ARXIV
   Narr S., 2012, LANGUAGE INDEPENDENT, P12
   NAUCK D, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P1022, DOI 10.1109/ICNN.1993.298698
   Pak A, 2010, P 7 C INT LANG RES E, DOI DOI 10.17148/IJARCCE.2016.51274
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Paul Sanjoy Kumar, 2015, International Journal of Business Information Systems, V18, P268, DOI 10.1504/IJBIS.2015.068164
   Pundlik S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P512, DOI 10.1109/ICACCI.2016.7732097
   Raichelgauz I, 2015, U.S. Patent, Patent No. [9,218,606, 9218606]
   Raj S, 2015, INT J BUSINESS ANALY, V3, P38
   Rajat GL, 2019, 2019 INT C DAT SCI C, P1
   Ramrakhiyani N, 2015, P 7 FOR INF RETR EV, P39
   Rodrigues RG, 2016, INT J MED INFORM, V85, P80, DOI 10.1016/j.ijmedinf.2015.09.007
   Rosenthal Sara, 2017, P 11 INT WORKSH SEM, P502
   Rustamov S, 2013, 2013 P IEEE SE IEEE, P1
   Samir R, 2013, P 4 WORKSH COMP APPR, P108
   Schneider K-M., 2004, P 42 ANN M ASS COMP, P186
   Shi W, 2015, J EXP THEOR ARTIF IN, V27, P423, DOI 10.1080/0952813X.2014.971443
   Singh VK, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P712, DOI 10.1109/iMac4s.2013.6526500
   Song YW, 2017, INT CONF ADV CLOUD B, P188, DOI 10.1109/CBD.2017.40
   Srivastava A.K., 2020, ARXIV200310642
   Tetlock PC, 2007, J FINANC, V62, P1139, DOI 10.1111/j.1540-6261.2007.01232.x
   Tian Y., 2017, P 5 INT WORKSH NAT L, P11, DOI 10.18653/v1/W17-1102
   Tishby N., 2000, ARXIVPHYSICS0004057
   Tishby Naftali, 2015, 2015 IEEE INFORM THE, P1, DOI DOI 10.1109/ITW.2015.7133169
   Tripathy A, 2016, EXPERT SYST APPL, V57, P117, DOI 10.1016/j.eswa.2016.03.028
   Uhl MW., 2011, ACM TRANS MANAG INF, V2, P1, DOI [10.1145/1985347.1985350, DOI 10.1145/1985347.1985350]
   Varma V, 2012, P 26 PAC AS C LANG I, P171
   Whitelaw C, 2005, P 14 ACM INT C INF K, P625, DOI 10.1145/1099554.1099714
   Wilson T., 2005, RECOGNIZING CONTEXTU, P347
   Yadav M, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P309, DOI [10.1109/confluence.2019.8776943, 10.1109/CONFLUENCE.2019.8776943]
   Zhang CL, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 2, PROCEEDINGS, P909, DOI 10.1109/ICCIT.2008.51
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
   Zhang YH, 2015, PATTERN RECOGN LETT, V65, P44, DOI 10.1016/j.patrec.2015.07.006
   Zubiaga A, 2016, LANG RESOUR EVAL, V50, P729, DOI 10.1007/s10579-015-9317-4
NR 85
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19885
EP 19907
DI 10.1007/s11042-021-10559-y
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000624399400001
DA 2024-07-18
ER

PT J
AU Khoubani, S
   Moradi, MH
AF Khoubani, Sahar
   Moradi, Mohammad Hassan
TI A fast quaternion wavelet-based motion compensated frame rate
   up-conversion with fuzzy smoothing: application to echocardiography
   temporal enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion wavelet; Frame rate up-conversion; Frame interpolation;
   Motion compensation; Echocardiography frame rate up-conversion
ID HIGH-DEFINITION VIDEO; SUPER RESOLUTION; INTERPOLATION; MODEL
AB In this paper, we propose a fast Frame Rate Up-Conversion (FRUC) method based on Quaternion Wavelet Transform (QWT) motion estimation to improve the motion estimation accuracy and reduce the computational complexity. The proposed method contains three key elements: motion estimation, motion post-processing, and motion compensated frame interpolation. This paper considers the QWT motion estimation using the phase of image sequences, which leads to more accurate motion estimation, less post-processing procedures, and low complexity as well. Moreover, we proposed a modified fuzzy vector mean filtering to cope with motion outliers and made use of bilateral motion vector modification in the post-processing part. We have assessed our proposed method performance using six widely available benchmark test sequences and three echocardiography image sequences. The evaluations confirm that while our proposed method keeps the PSNR and SSIM performance suitable, it is at least twice faster in comparison with reference methods on the benchmark dataset. The echocardiography evaluations reveal our proposed method superiority in terms of PSNR, SSIM, and computation time, which make the proposed method suitable as an echocardiographic-specific method.
C1 [Khoubani, Sahar; Moradi, Mohammad Hassan] Amirkabir Univ Technol, Dept Biomed Engn, 424 Hafez Ave, Tehran, Iran.
C3 Amirkabir University of Technology
RP Moradi, MH (corresponding author), Amirkabir Univ Technol, Dept Biomed Engn, 424 Hafez Ave, Tehran, Iran.
EM sahar.khoubani@aut.ac.ir; mhmoradi@aut.ac.ir
RI Moradi, Mohammad Hassan/N-6073-2018
OI Moradi, Mohammad Hassan/0000-0002-3386-4003
CR Alessandrini M, 2015, IEEE T MED IMAGING, V34, P1436, DOI 10.1109/TMI.2015.2396632
   Alessandrini M, 2018, IEEE T ULTRASON FERR, V65, P411, DOI 10.1109/TUFFC.2017.2786300
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Baraniuk RG, 2008, THESIS RICE U
   Bayro-Corrochano E, 2006, J MATH IMAGING VIS, V24, P19, DOI 10.1007/s10851-005-3605-3
   Cetin M, 2011, IEEE T CONSUM ELECTR, V57, P923, DOI 10.1109/TCE.2011.5955241
   Chan WL, 2008, IEEE T IMAGE PROCESS, V17, P1069, DOI 10.1109/TIP.2008.924282
   Chan WL, 2006, IEEE IMAGE PROC, P1229, DOI 10.1109/ICIP.2006.312547
   Chen GR, 2020, J AMB INTEL HUM COMP, V11, P511, DOI 10.1007/s12652-018-0974-1
   Chen T, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P313
   Choi BT, 2000, IEEE T CONSUM ELECTR, V46, P603, DOI 10.1109/30.883418
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Choi G, 2019, IEEE T CIRC SYST VID, V29, P1251, DOI 10.1109/TCSVT.2018.2840842
   de Haan G, 1993, IEEE T CIRC SYST VID, V3, P368, DOI 10.1109/76.246088
   Gao H, 2009, IEEE T ULTRASON FERR, V56, P404, DOI 10.1109/TUFFC.2009.1051
   Gifani P, 2016, IEEE T ULTRASON FERR, V63, P6, DOI 10.1109/TUFFC.2015.2493881
   Gifani Parisa, 2011, J Med Signals Sens, V1, P107
   Ha T, 2004, IEEE T CONSUM ELECTR, V50, P752, DOI 10.1109/TCE.2004.1309458
   Han R, 2013, IEEE T CONSUM ELECTR, V59, P229, DOI 10.1109/TCE.2013.6490264
   Hill L, 2001, ELECTRON LETT, V37, P1512, DOI 10.1049/el:20011011
   Hosseinpour M, 2019, BIOMED SIGNAL PROCES, V52, P53, DOI 10.1016/j.bspc.2019.03.003
   Jalali M, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101868
   Kang SJ, 2007, IEEE T CONSUM ELECTR, V53, P1759, DOI 10.1109/TCE.2007.4429281
   Kang SJ, 2010, IEEE T CIRC SYST VID, V20, P1909, DOI 10.1109/TCSVT.2010.2087832
   Kaviani HR, 2016, IEEE T CIRC SYST VID, V26, P1581, DOI 10.1109/TCSVT.2015.2469120
   Khoubani S, 2018, 2017 24 IR C BIOM EN, DOI [10.1109/ICBME.2017.8430226, DOI 10.1109/ICBME.2017.8430226]
   Kim US, 2014, IEEE T CIRC SYST VID, V24, P384, DOI 10.1109/TCSVT.2013.2278142
   Konofagou EE, 2002, ULTRASOUND MED BIOL, V28, P475, DOI 10.1016/S0301-5629(02)00488-X
   Leclerc S, 2019, IEEE T MED IMAGING, V38, P2198, DOI 10.1109/TMI.2019.2900516
   Lee SH, 2003, IEEE T CONSUM ELECTR, V49, P485, DOI 10.1109/TCE.2003.1233759
   Leonard S, 2017, IEEE INT C CYBERNET, P189
   Li R, 2019, MULTIMED TOOLS APPL, V78, P19603, DOI 10.1007/s11042-019-7337-6
   Li R, 2017, SIGNAL PROCESS-IMAGE, V54, P36, DOI 10.1016/j.image.2017.02.010
   Li R, 2016, IEICE T INF SYST, VE99D, P208, DOI 10.1587/transinf.2015EDP7027
   Li R, 2014, J DISP TECHNOL, V10, P1010, DOI 10.1109/JDT.2014.2334598
   Liu HB, 2012, IEEE T CIRC SYST VID, V22, P1188, DOI 10.1109/TCSVT.2012.2197081
   Liu Z, 2017, IEEE ACCESS, P1905
   Marchesseau S, 2013, BIOMECH MODEL MECHAN, V12, P815, DOI 10.1007/s10237-012-0446-z
   Mirarkolaei HN, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101863
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   SHATTUCK DP, 1984, J ACOUST SOC AM, V75, P1273, DOI 10.1121/1.390734
   Tai SC, 2008, J DISP TECHNOL, V4, P188, DOI 10.1109/JDT.2007.916014
   Tong L, 2013, IEEE T ULTRASON FERR, V60, P1719, DOI 10.1109/TUFFC.2013.2753
   Van Thang N, 2018, IEEE ACCESS, V6, P60353, DOI 10.1109/ACCESS.2018.2875688
   VONRAMM OT, 1991, IEEE T ULTRASON FERR, V38, P109, DOI 10.1109/58.68467
   Wadhwa N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461966
   Wai Lam Chan, 2005, Proceedings of the SPIE - The International Society for Optical Engineering, V5914, p59140Z, DOI 10.1117/12.615393
   Wang DM, 2010, IEEE T BROADCAST, V56, P142, DOI 10.1109/TBC.2010.2043895
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yoo DG, 2013, J DISP TECHNOL, V9, P840, DOI 10.1109/JDT.2013.2263374
   Yoon SJ, 2018, IEEE T IMAGE PROCESS, V27, P5918, DOI 10.1109/TIP.2018.2861567
   Zhai JF, 2005, IEEE INT SYMP CIRC S, P4927
   Zhang JJ, 1998, ELECTRON LETT, V34, P52, DOI 10.1049/el:19980040
   Zhang YB, 2020, IEEE T CIRC SYST VID, V30, P11, DOI 10.1109/TCSVT.2018.2885564
   Zhang YB, 2009, IEEE T CIRC SYST VID, V19, P1289, DOI 10.1109/TCSVT.2009.2022798
   Zhou LN, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043036
NR 57
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8999
EP 9025
DI 10.1007/s11042-020-09834-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QZ7ZL
UT WOS:000630940800003
DA 2024-07-18
ER

PT J
AU Nahar, MN
   Alsadoon, A
   Prasad, PWC
   Giweli, N
   Alsadoon, OH
AF Nahar, Most Nuzman
   Alsadoon, Abeer
   Prasad, P. W. C.
   Giweli, Nabil
   Alsadoon, Omar Hisham
TI An enhanced one-time password with biometric authentication for mixed
   reality surgical Tele-presence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blowfish-128; Eavesdropping; PAKE; SMiShing; SMS-based OTSP; Phishing;
   Replay attack; Authentication; MITM attack
ID SECURITY; SYSTEMS; SCHEME; ECG
AB Mixed Reality (MR) surgery for telepresence has not been successfully implemented yet due to the lack of security and the high processing time required. In particular, the need for authentication during and after the real-time video transmission is not addressed adequately. This paper aims to increase the security and privacy by preventing unauthorized access into the telepresence system before and after the surgery by proposing real-time authentication with low processing time. The proposed system consists of an enhanced Multi-factor SMS-based one-time session password (OTSP) and an IRIS biometric authentication technique. The results of this work demonstrate a successful overcoming of several limitations of the previous state of the art solution. For instance, the average processing time is reduced from 81 ms to only 57 ms. The proposed solution also increases the protection from hacking to the system, i.e., the accuracy, to 80% compared to the accuracy of 53% for the previous solution. Besides, the proposed system is more resistance against several attacks by an attack-proof of 84.36% compared to 45.2% of the state of the art solution. Moreover, our solution reduced the required storage capacity and cost to the half. As a result, our proposed system is more robust against various kinds of attacks. The proposed system could be used effectively in surgical telepresence authentication with less time, cost overhead and higher security.
C1 [Nahar, Most Nuzman; Alsadoon, Abeer; Prasad, P. W. C.; Giweli, Nabil] Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
   [Nahar, Most Nuzman; Alsadoon, Abeer; Prasad, P. W. C.; Giweli, Nabil] Study Grp Australia, Dept Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Study Grp Australia, Dept Informat Technol, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Alsadoon, Omar Hisham/0000-0001-7797-6392
CR Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Ali R, 2018, ARAB J SCI ENG, V43, P7837, DOI 10.1007/s13369-018-3220-4
   Camara C, 2018, APPL SOFT COMPUT, V68, P784, DOI 10.1016/j.asoc.2017.07.032
   Ganeshan B, 2006, OPT LASER ENG, V44, P1, DOI 10.1016/j.optlaseng.2005.03.010
   Gomez-Barrero M, 2017, PATTERN RECOGN, V67, P149, DOI 10.1016/j.patcog.2017.01.024
   Hammad M, 2019, FUTURE GENER COMP SY, V101, P180, DOI 10.1016/j.future.2019.06.008
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   Khan SH, 2015, PATTERN RECOGN, V48, P458, DOI 10.1016/j.patcog.2014.08.024
   Laka P, 2018, TELECOMMUN SYST, V69, P365, DOI 10.1007/s11235-018-0437-1
   Liu X, 2018, SUSTAIN, V10
   Madhusudhan R, 2019, MULTIMED TOOLS APPL, V78, P15255, DOI 10.1007/s11042-018-6884-6
   Malarvizhi N, 2020, MULTIMED TOOLS APPL, V79, P9131, DOI 10.1007/s11042-019-7436-4
   Mohsin AH, 2019, COMPUT STAND INTER, V66, DOI 10.1016/j.csi.2019.04.002
   Mohsin AH, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1264-y
   Neha,, 2019, MULTIMED TOOLS APPL, V78, P6679, DOI 10.1007/s11042-018-6448-9
   Odinokikh G. A., 2018, Pattern Recognition and Image Analysis, V28, P516
   Ogundepo O., 2019, NIGER J TECHNOL, V38, P956
   Oiwa Y., 2019, MULTIMED TOOLS APPL, V2, P233
   Punithavathi P, 2019, MULTIMED TOOLS APPL, V78, P25487, DOI 10.1007/s11042-019-7617-1
   Punithavathi P, 2019, INFORM SCIENCES, V484, P255, DOI 10.1016/j.ins.2019.01.073
   Ramasamy P, 2019, MULTIMED TOOLS APPL, P568
   Regouid M, 2019, MULTIMED TOOLS APPL, V78, P22509, DOI 10.1007/s11042-019-7467-x
   Renuka K, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1251-3
   Rezaeibaghe F, 2018, J BIOMED INFORM, V78, P24, DOI 10.1016/j.jbi.2017.12.011
   Salehifar H, 2019, MULTIMED TOOLS APPL, V78, P16861, DOI 10.1007/s11042-018-7043-9
   Soni A., 2019, INT J ADV RES COMPUT, V2, P201
   Sujatha E, 2018, WIRELESS PERS COMMUN, V99, P23, DOI 10.1007/s11277-017-5034-1
   Trabelsi Randa Boukhris, 2018, Pattern Recognition and Image Analysis, V28, P430, DOI 10.1134/S1054661818030173
   Verma G, 2019, OPT LASER ENG, V123, P28, DOI 10.1016/j.optlaseng.2019.06.028
   Vidhyapriya R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1332-3
NR 30
TC 1
Z9 2
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10075
EP 10100
DI 10.1007/s11042-020-10013-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO7NF
UT WOS:000641228000001
DA 2024-07-18
ER

PT J
AU Bhople, AR
   Prakash, S
AF Bhople, Anagha R.
   Prakash, Surya
TI Learning similarity and dissimilarity in 3D faces with triplet network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face recognition; Point cloud; Deep learning; PointNet; Biometrics
ID RECOGNITION; FEATURES
AB Face is the most preferred biometric trait used to recognize a person. The 2D face can be considered as a promising biometric trait; however, it may be affected by changes in the age, skin color, texture, or any other environmental factors like illumination variations, occlusion, and low image resolution. The 3D face is an emerging biometric trait, which is being used recently for human recognition. The discriminating power of the 3D face is highly motivating for many tasks such as security, surveillance, and many other technological application in day to day life. Although there are many techniques available for 3D face recognition, most of these techniques are based on volumetric or depth/range images. The conversion of 3D face data, which is originally in point cloud format to volumetric representation makes the data bulkier. Further, some of the geometric properties may be lost when 3D data is converted to a representation of lower dimensions such as depth/range images. The driving objective behind this research is to perform 3D face recognition by directly using faces represented in the form of 3D point cloud. We propose a novel approach for 3D face recognition by learning the similarity and dissimilarity in 3D faces, and for this purpose, introduce a triplet network. The network is an ensemble of our proposed Convolutional PointNet (CPN) network, used for feature extraction and triplet loss. The proposed network maps a 3D face data to Euclidean space where distance based scores represent the similarity among the 3D faces. We also introduce a new evaluation approach for computing the dissimilarity between highly similar 3D face biometric data. Experimentation has been carried out on two databases, namely IIT Indore 3D face database (our in-house database) and Bosphorus 3D face database. To handle the training issues due to the limited availability of samples for each subject in both the databases, we propose a technique for 3D data augmentation. We perform various experiments using the proposed network and show the performance in terms of verification rate and ROC curve. Our point cloud based triplet network shows encouraging performance as compared to other state-of-the-art techniques.
C1 [Bhople, Anagha R.; Prakash, Surya] Indian Inst Technol Indore, Indore 453552, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore
RP Bhople, AR (corresponding author), Indian Inst Technol Indore, Indore 453552, India.
EM ms1804101008@iiti.ac.in; surya@iiti.ac.in
RI Prakash, Surya/S-6308-2019
OI Prakash, Surya/0000-0001-8039-1280
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Ahmed E., 2018, ARXIV180801462
   Akaike K, 2015, ADV MATER INTERFACES, V2, DOI 10.1002/admi.201500232
   [Anonymous], 2016, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2016.7727386
   Bagchi P, 2016, MULTIMED TOOLS APPL, V75, P11059, DOI 10.1007/s11042-015-2835-7
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Bhople AR, 2021, MULTIMED TOOLS APPL, V80, P30237, DOI 10.1007/s11042-020-09008-z
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Borisenko GV, 2004, PROGRAM COMPUT SOFT+, V30, P273, DOI 10.1023/B:PACS.0000043053.85314.58
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Cheflali FZ, 2009, INT CONF MULTIMED, P1, DOI 10.1109/MMCS.2009.5256630
   Chouchane A, 2018, MULTIMED TOOLS APPL, V77, P20697, DOI 10.1007/s11042-017-5478-z
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dorofeev K, 2019, PROC SPIE, V11137, DOI 10.1117/12.2527541
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Feng JY, 2019, ADV INTELL SYST COMP, V670, P123, DOI 10.1007/978-981-10-8971-8_12
   Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203
   Gilani SZ, 2018, IEEE T PATTERN ANAL, V40, P1584, DOI 10.1109/TPAMI.2017.2725279
   Gupta S, 2010, INT J COMPUT VISION, V90, P331, DOI 10.1007/s11263-010-0360-8
   He Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081862
   Jayaraman U, 2020, NEUROCOMPUTING, V408, P231, DOI 10.1016/j.neucom.2019.08.110
   Kang BN, 2017, IEEE COMPUT SOC CONF, P611, DOI 10.1109/CVPRW.2017.89
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   KINGKAN C, 2018, P BRIT MACH VIS C, P118
   Koziol Q, 2011, ENCY PARALLEL COMPUT, P827, DOI [DOI 10.1007/978, DOI 10.1007/978-0-387-09766-4_44]
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Leng BA, 2016, NEUROCOMPUTING, V215, P232, DOI 10.1016/j.neucom.2015.08.134
   Leo MJ, 2018, PROCEDIA COMPUT SCI, V143, P619, DOI 10.1016/j.procs.2018.10.441
   Li HB, 2015, INT J COMPUT VISION, V113, P128, DOI 10.1007/s11263-014-0785-6
   Li Y, 2018, NEUROCOMPUTING, V275, P1295, DOI 10.1016/j.neucom.2017.09.070
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Qi CR, 2017, ADV NEUR IN, V30
   Rahim R, 2018, P IOP C SERIES MAT S, P12
   Reji R, 2017, IEEE I C COMP INT CO, P144
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharma Preeti B., 2012, INT J ENG RES APPL I, V2, P787
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P17303, DOI 10.1007/s11042-020-08688-x
   Singh RD, 2019, MULTIMED TOOLS APPL, V78, P15951, DOI 10.1007/s11042-018-6912-6
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Soltanpour S, 2017, IET BIOMETRICS, V6, P27, DOI 10.1049/iet-bmt.2015.0120
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Yu Y, 2019, IEEE T INF FOREN SEC, V14, P1917, DOI 10.1109/TIFS.2018.2889255
   Zhang Z., 2019, ARXIV191104731
   Zhang ZY, 2019, PROC SPIE, V11205, DOI 10.1117/12.2541704
   Zhou HL, 2014, IEEE T HUM-MACH SYST, V44, P701, DOI 10.1109/THMS.2014.2340578
NR 52
TC 8
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35973
EP 35991
DI 10.1007/s11042-020-10160-9
EA FEB 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000621015900004
DA 2024-07-18
ER

PT J
AU Karri, C
AF Karri, Chiranjeevi
TI Secure robot face recognition in cloud environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud robotics; Image face recognition; Security
AB In robotic applications, recognition of human faces at high speed is important to improve human-machine interaction. Recognition speed can be limited by the on-board computation capabilities of the robots. These limitations are overcome by introducing cloud technology in face recognition. The cloud supplies the required memory and processor speed dynamically, when needed. However, public clouds are shared with many users, hence chance of image database insecurity. To address this problem, we explore several possibilities to achieve robot secure face recognition where face recognition is performed on the encrypted data. The performance of eight encryption algorithms in terms of security and recognition accuracy is measured. A face recognition test is conducted in a robot and cloud environments and the average time to recognize a face through simple Principal Component Analysis (PCA) over encrypted data is measured.
C1 [Karri, Chiranjeevi] Univ Beira Interior, Cloud Comp Competence Ctr C4, Covilha, Portugal.
C3 Universidade da Beira Interior
RP Karri, C (corresponding author), Univ Beira Interior, Cloud Comp Competence Ctr C4, Covilha, Portugal.
EM chiru404@gmail.com
RI Al-obaidi, Abdullah Thair/P-8487-2017
OI Al-obaidi, Abdullah Thair/0000-0002-9971-5895; chiranjeevi,
   karri/0000-0003-4102-4108
FU Operacao Centro - Cloud Computing Competence Center [01 - 0145 - FEDER -
   000019 - C4]; Programa Operacional Regional do Centro (CENTRO 2020),
   through the Sistema de Apoio a Investigacao Cientifica e Tecnologica -
   Programas Integrados de ICDT
FX This work was supported by Operacao Centro - 01 - 0145 - FEDER - 000019
   - C4 - Cloud Computing Competence Center, co-financed by the Programa
   Operacional Regional do Centro (CENTRO 2020), through the Sistema de
   Apoio a Investigacao Cientifica e Tecnologica - Programas Integrados de
   IC&DT. The author would like to express his special thanks of gratitude
   to principal and Vice-principal, GMR Institute of Technology, Rajam,
   Srikakulam, Andhrapradesh, India who gave him the golden opportunity to
   do this wonderful project.
CR Acharya Bibhudendra, 2009, International Journal of Recent Trends in Engineering, V1, P663
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Beigi NK, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292655
   Chepuri, 2017, INT J COURR TRENDS E, V3, P2455
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Dinesh A, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS, COMPUTING AND IT APPLICATIONS (CSCITA), P164, DOI 10.1109/CSCITA.2017.8066546
   Duin S.V., 2010, P ISR 2010 41 INT S, P1
   Ergun OO, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P643, DOI 10.1109/APCCAS.2014.7032863
   Goldwasser S, 2014, LECT NOTES COMPUT SC, V8441, P578, DOI 10.1007/978-3-642-55220-5_32
   Gomes L, 2016, IEEE SPECTRUM, V53, P13, DOI 10.1109/MSPEC.2016.7459105
   Guo SW, 2019, SIGNAL PROCESS, V164, P320, DOI 10.1016/j.sigpro.2019.06.024
   Hirano T, 2000, 6TH INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, PROCEEDINGS, P606, DOI 10.1109/AMC.2000.862950
   Hu GQ, 2012, IEEE NETWORK, V26, P21, DOI 10.1109/MNET.2012.6201212
   Jolfaei Alireza, 2010, 2010 Proceedings of International Conference on Artificial Intelligence and Computational Intelligence (AICI 2010), P369, DOI 10.1109/AICI.2010.198
   Karri C, 2016, ENG SCI TECHNOL, V19, P769, DOI 10.1016/j.jestch.2015.11.003
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492
   Korshunov P, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P208, DOI 10.1109/AVSS.2013.6636641
   Koubaa Anis, 2017, Robot Operating System (ROS)
   Liu CC, 2017, DES AUT CON, DOI [10.1145/3061639.3062310, 10.1109/ICCSN.2017.8230067]
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mataric MJ, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1973
   Mazloom S., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence for Multimedia, Signal and Vision Processing (CIMSIVP 2011), P142, DOI 10.1109/CIMSIVP.2011.5949254
   Mell P, 2010, COMMUN ACM, V53, P50
   Mohanarajah G, 2015, IEEE T AUTOM SCI ENG, V12, P481, DOI 10.1109/TASE.2014.2329556
   Mukaka MM, 2012, MALAWI MED J, V24, P69
   Olver, 2008, ORTHOGONAL BASES QR
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rohith S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Shen J, 2010, P 2010 ACM MULT WORK, P31, DOI DOI 10.1145/1877953.1877963
   Shen JL, 2010, LECT NOTES COMPUT SC, V5916, P500, DOI 10.1007/978-3-642-11301-7_50
   Shen J, 2018, IEEE T INF FOREN SEC, V13, P912, DOI 10.1109/TIFS.2017.2774439
   Shen J, 2017, IEEE T INF FOREN SEC, V12, P2402, DOI 10.1109/TIFS.2017.2705620
   Suli Wu, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P841, DOI 10.1109/CSSE.2008.987
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P1397, DOI 10.1109/TCSVT.2008.2002825
   Thien HT, 2016, EXPERT SYST APPL, V62, P177, DOI 10.1016/j.eswa.2016.06.015
   VIJAYARAGHAVAN R, 2014, INDIAN J SCI TECHN S, V7, P1
   Waibel M, 2011, IEEE ROBOT AUTOM MAG, V18, P69, DOI 10.1109/MRA.2011.941632
   Wang L., 2019, IEEE Transactions on Cybernetics
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yahya Abdelfatah A., 2009, Proceedings of the 2009 International Conference on Security & Management. SAM 2009, P113
   Yang TF, 2019, INFORM SCIENCES, V505, P198, DOI 10.1016/j.ins.2019.07.078
   Zeghid M, 2007, PROC WRLD ACAD SCI E, V21, P206
NR 48
TC 8
Z9 8
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18611
EP 18626
DI 10.1007/s11042-020-10253-5
EA FEB 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300012
DA 2024-07-18
ER

PT J
AU Bhuvaneshwari, P
   Rao, AN
   Robinson, YH
AF Bhuvaneshwari, P.
   Rao, A. Nagaraja
   Robinson, Y. Harold
TI Spam review detection using self attention based CNN and bi-directional
   LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE E-commerce; Opinion spam reviews; Machine learning; Deep learning; Self
   attention-based CNN Bi-LSTM (ACB) model; Convolution neural network;
   Self-attention mechanism; Bidirectional long short term memory
AB Opinion reviews are a valuable source of information in e-commerce. Indeed, it benefits users in buying decisions and businesses to enhance their quality. However, various greedy organizations employ spammers to post biased spam reviews to gain an advantage or to degrade the reputation of a competitor. This results in the explosive growth of opinion spamming. Due to its nature and their increasing volume, spam reviews are a fast-growing serious issue on the internet. Until now, researchers have developed many Machine Learning (ML) based methods to identify opinion spam reviews. However, the traditional ML methods cannot effectively detect spam messages due to the limited feature representations and the data manipulations done by spammers to escape from the detection mechanism. As an alternative to ML-based detection, in this paper, we proposed a Deep Learning (DL) based novel framework called Self Attention-based CNN Bi-LSTM (ACB) model to learn document level representation for identifying the spam reviews. Our approach computes the weightage of each word present in the sentence and identifies the spamming clues exists in the document with an attention mechanism. Then the model learns sentence representation by using Convolution Neural Network (CNN) and extracts the higher-level n-gram features. Then finally, sentence vectors are combined using Bi-directional LSTM (Bi-LSTM) as document feature vectors and identify the spam reviews with contextual information. The evaluated experiment results are compared with its variants and the result shows that ACB outperforms other variants in terms of classification accuracy.
C1 [Bhuvaneshwari, P.; Rao, A. Nagaraja] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Robinson, Y. Harold] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Robinson, YH (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM thenameisbhuvanapatt@gmail.com; nagarajaraoa@vit.ac.in;
   yhrobinphd@gmail.com
RI ; ROBINSON, HAROLD/A-1545-2016
OI P, Dr Bhuvaneshwari/0000-0003-2938-9059; ROBINSON,
   HAROLD/0000-0002-4881-7103
CR Crawford Michael, 2016, 20 9 INT FLAIRS C
   Dong LY, 2018, EXPERT SYST APPL, V114, P210, DOI 10.1016/j.eswa.2018.07.005
   Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645
   Enríquez F, 2016, EXPERT SYST APPL, V66, P1, DOI 10.1016/j.eswa.2016.09.005
   Fang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222713
   Feng S., 2012, P 50 ANN M ASS COMP, V2, P171
   Guanghai Liu, 2013, 2013 International Conference on Information Science and Cloud Computing Companion (ISCC-C), P728, DOI 10.1109/ISCC-C.2013.21
   Harris C.G., 2012, Workshops at AAAI on Artificial Intelligence, VWS-12-08, P87
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Horrigan J., 2008, Online Shopping
   Jindal N., 2008, P WSDM, P219, DOI [DOI 10.1145/1341531.1341560, 10.1145/1341531.1341560]
   Kim SM, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P376, DOI 10.1109/ITNG.2009.119
   Kumar N, 2018, J MANAGE INFORM SYST, V35, P350, DOI 10.1080/07421222.2018.1440758
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Liu, 2015, LEARNING DOCUMENT RE, DOI [10.1007/978-3-319-25816-4_32, DOI 10.1007/978-3-319-25816-4_32]
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Ott M., 2011, ACL HLT 2011 P 49 AN, V1, P309, DOI DOI 10.1145/2567948.2577293
   Pandey AC, 2019, EVOL INTELL, V12, P147, DOI 10.1007/s12065-019-00204-x
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Ren Y., 2016, Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, P140
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Sedighi Z., 2019, 32 INT FLAIRS C
   Wang CC., 2018, P 2 INT C E COMM E B, P16, DOI [10.1145/3234781.3234794, DOI 10.1145/3234781.3234794]
   Wang X, 2017, NATURAL LANGUAGE PRO, P866
   Ye JT, 2015, LECT NOTES ARTIF INT, V9284, P267, DOI 10.1007/978-3-319-23528-8_17
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang W, 2018, INFORM PROCESS MANAG, V54, P576, DOI 10.1016/j.ipm.2018.03.007
   Zhang Z., 2020, Bilateral Attention Network for RGB-D Salient Object Detection
   Zhao SY, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/2410206
NR 32
TC 25
Z9 25
U1 3
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18107
EP 18124
DI 10.1007/s11042-021-10602-y
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618132200001
OA Bronze
DA 2024-07-18
ER

PT J
AU Dhall, S
   Gupta, S
AF Dhall, Sangeeta
   Gupta, Shailender
TI Multilayered highly secure authentic watermarking mechanism for medical
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; LWT; Multilevel protection mechanism; Quantum encryption;
   Scrambling; Steganography; Telemedicine; Visually meaningful encryption;
   Watermarking
AB Telemedicine is a technology-based substitute for conventional health care facilities. It symbolizes the practice of medication via indirect means. The foremost requirement for such remote healthcare practices is the communication of highly sensitive data over insecure networks, which demands very high protection of different types of health-related information such as Electronic Patient Record (EPR) and Related Medical images. Consequently, there is a stern need to develop algorithms to secure all confidential information for overall well being. This paper is an effort to propose one multilayer protection mechanism, which not only secures the patient's transcript but also protects associated medical Images. EPR is embedded in the original medical image resulting in a watermarked medical image, which is further hidden in the reference image. But these two relevant records are given multiple strata of security before concealing and exposed to the insecure channel. Compression and Quantum Encryption of EPR are done, which is then embed into LWT transformed Medical Image, followed by scrambling and compression of all the planes of a watermarked medical image before embedding in different bands of LWT (Lifting Wavelet Transform), transformed reference image. This stride of hiding image is mandatory because original and watermarked medical images are very similar, thus prone to attacks. In order to avoid this, an image steganography technique is used to change the watermarked medical image's visual structure, which is also referred to as visually meaningful encryption, as popular encryption algorithms give noise-like textures that can attract attackers. For authentication on the accession of records, biometric-based detection along with hash algorithm is also incorporated. Overall results (implemented using MATLAB) show that the proposed mechanism provides a highly secure and authentic medical healthcare system.
C1 [Dhall, Sangeeta; Gupta, Shailender] JC Bose Univ Sci & Technol, Elect Engn Dept, Ymca, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Dhall, S (corresponding author), JC Bose Univ Sci & Technol, Elect Engn Dept, Ymca, Faridabad, India.
EM sangeeta_dhall@yahoo.co.in
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   [Anonymous], 2011, INT J COMPUT APPL
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Chopra A, 2020, MULTIMED TOOLS APPL, V79, P501, DOI 10.1007/s11042-019-08087-x
   Dhall Sangeeta, 2016, International Journal of Computer Network and Information Security, V8, P67, DOI 10.5815/ijcnis.2016.06.08
   Dhall S, 2015, INT J SECUR APPL, V9, P67, DOI 10.14257/ijsia.2015.9.8.07
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Gao T-G, 2007, INT C WAV AN PATT RE, P5
   Gholipour M, 2011, COMM COM INF SC, V166, P161
   Gupta S., 2015, INT J COMPUT NETW AP, V2, P6
   He D., 2009, 2009 1 INT C INF SCI, P1164, DOI [10.1109/ICISE.2009.347, DOI 10.1109/ICISE.2009.347]
   Kalita M, 2019, COMPUT J, V62, P1639, DOI 10.1093/comjnl/bxz014
   Kannammal A, 2014, INT J IMAG SYST TECH, V24, P111, DOI 10.1002/ima.22086
   Ko LT, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/839161
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Loan NA, 2017, J BIOMED INFORM, V73, P125, DOI 10.1016/j.jbi.2017.08.002
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P27941, DOI 10.1007/s11042-020-09279-6
   Moizuddin M, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ANTI-CYBER CRIMES (ICACC), P98, DOI 10.1109/Anti-Cybercrime.2017.7905271
   Mousavi SM, 2017, MULTIMED TOOLS APPL, V76, P10313, DOI 10.1007/s11042-016-3622-9
   National Institute of Standards and Technology, 2015, FED INF PROC STAND P, DOI [10.6028/NIST.FIPS.180-4, DOI 10.6028/NIST.FIPS.180-4]
   Ng RYF, 2008, INTERNATIONAL SYMPOSIUM OF INFORMATION TECHNOLOGY 2008, VOLS 1-4, PROCEEDINGS, P835
   Priya S, 2021, MOBILE NETW APPL, V26, P2501, DOI 10.1007/s11036-019-01213-x
   Rana, 2014, COMP VARIOUS BIOMETR, V2, P7
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Sharma G, 2018, MULTIMED TOOLS APPL, V77, P31737, DOI 10.1007/s11042-018-6226-8
   Sharma Rinku, 2018, International Journal of Computer Network and Information Security, V10, P37, DOI 10.5815/ijcnis.2018.09.04
   Shelke R, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Solanki Neha, 2014, International Journal of Modern Education and Computer Science, V6, P40, DOI 10.5815/ijmecs.2014.10.06
   Tayal N, 2017, MULTIMED TOOLS APPL, V76, P24063, DOI 10.1007/s11042-016-4111-x
   Wu Yue, 2011, NPCR UACI RANDOMNESS
   Yang Yan, 2000, Wuhan University Journal of Natural Sciences, V5, P204, DOI 10.1007/BF02827928
NR 36
TC 5
Z9 5
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18069
EP 18105
DI 10.1007/s11042-021-10531-w
EA FEB 2021
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617861200002
DA 2024-07-18
ER

PT J
AU Wang, HC
   Syu, SW
   Wongchaisuwat, P
AF Wang, Hei-Chia
   Syu, Sheng-Wei
   Wongchaisuwat, Papis
TI A method of music autotagging based on audio and lyrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music autotagging; Deep learning; Multitask learning; Multitag
   classification
ID CONVOLUTIONAL NEURAL-NETWORKS; SPEECH
AB With the development of the Internet and technology, online music platforms and music streaming services are flourishing. Information overload due to an abundance of digital music has become a common problem for many users. Social tags that are helpful for music recommendations have been discussed. However, label sparsity and a cold start problem, commonly observed with social tags, limit the effectiveness in supporting the recommendation system. A music autotagging system then becomes an alternative solution for supplementing a shortage of tags. Most prior studies on automatic labeling used only audio data for their analysis. However, some studies have suggested that lyrics enhance the music classification system to obtain more information and improve the overall accuracy. In addition to lyrics, audio data are also an important resource for finding music features. In summary, this paper proposes a music autotagging system that relies on both audio and lyrics to solve the above problems. Due to the development of deep learning algorithms in recent years, many scholars have effectively used neural networks to extract audio and textual features. Some of them also considered a structure of lyrics to extract features that consequentially improves the classification task. For lyric feature extraction, this study employs two types of deep learning models: convolutional neural networks (CNNs) and recurrent neural networks (RNNs). The feature extraction architecture is mainly motivated and characterized by the lyric architecture. In addition, a multitask learning method is adopted to learn correlations between tags. The experiments support that a multitask learning classifier that combines audio and lyric information has a better performance than a single-task learning classification method using only audio data than previous studies.
C1 [Wang, Hei-Chia; Syu, Sheng-Wei] Natl Cheng Kung Univ, Inst Informat Management, Tainan, Taiwan.
   [Wang, Hei-Chia] Natl Cheng Kung Univ, Ctr Innovat FinTech Business Models, Tainan, Taiwan.
   [Wongchaisuwat, Papis] Kasetsart Univ, Dept Ind Engn, Bangkok, Thailand.
C3 National Cheng Kung University; National Cheng Kung University;
   Kasetsart University
RP Wang, HC (corresponding author), Natl Cheng Kung Univ, Inst Informat Management, Tainan, Taiwan.; Wang, HC (corresponding author), Natl Cheng Kung Univ, Ctr Innovat FinTech Business Models, Tainan, Taiwan.
EM hcwang@mail.ncku.edu.tw; R76064027@mail.ncku.edu.tw; papis.w@ku.th
FU Taiwan Ministry of Science and Technology; MOST [107-2410-H-006 040-MY3,
   108-2511-H-006-009]; Center of Innovative Fintech Business Models for a
   research grant
FX The research is based on work supported by Taiwan Ministry of Science
   and Technology under Grant No. MOST 107-2410-H-006 040-MY3 and
   108-2511-H-006-009. We would like to thank the Center of Innovative
   Fintech Business Models for a research grant to support this research.
CR Alías F, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050143
   [Anonymous], 2017, Perspectives from the Global Entertainment and Media Outlook 2017-2021: Curtain up! User Experience takes Center Stage
   [Anonymous], 2017, P SMC 2017 14 SOUND
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cho K., 2014, ARXIV14061078
   Choi K, 2018, DEEP NEURAL NETWORKS
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Choi Keunwoo, 2016, ARXIV160600298, DOI 10.5281/zenodo.1416254
   Chordia P., 2011, ISMIR
   Coviello, 2014, AUTOMATIC MUSIC TAGG
   Datta AK, 2017, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-981-10-3959-1_1
   de Leon F, 2012, EUR SIGNAL PR CONF, P2005
   Delbouys Remi., 2018, P 19 INT SOC MUS INF, P370
   Dieleman S, 2014, INT CONF ACOUST SPEE
   Duan SF, 2014, ARTIF INTELL REV, V42, P637, DOI 10.1007/s10462-012-9362-y
   Gossi D, 2016, STUD COMPUT INTELL, V644, P301, DOI 10.1007/978-3-319-30569-1_23
   Gouyon, 2011, P 12 INT SOC MUS INF
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Horsburgh B, 2015, ARTIF INTELL, V219, P25, DOI 10.1016/j.artint.2014.11.004
   Hu X, 2017, J ASSOC INF SCI TECH, V68, P273, DOI 10.1002/asi.23649
   Huang Y, 2015, IEEE T MULTIMEDIA, V17, P1923, DOI 10.1109/TMM.2015.2476658
   Huang Y, 2013, IEEE IMAGE PROC, P2897, DOI 10.1109/ICIP.2013.6738596
   Kim T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P366, DOI 10.1109/ICASSP.2018.8462046
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kirmaci, 2016, INT C ART INT APPL I
   Knees P, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542206
   Kotropoulos, 2012, 2012 IEEE INT C AC 2
   Labrosa, 2011, LAST FM DAT
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Langlois, 2014, ARXIV PREPRINT ARXIV
   Lee J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010150
   Lee J, 2017, IEEE SIGNAL PROC LET, V24, P1208, DOI 10.1109/LSP.2017.2713830
   Lee K., 2015, ARXIV PREPRINT ARXIV
   Lim H., 2018, DCASE, P197
   Liu K, 2018, ARXIV PREPRINT ARXIV
   Malheiro R, 2018, IEEE T AFFECT COMPUT, V9, P240, DOI 10.1109/TAFFC.2016.2598569
   Mandel, 2011, AUTOMATIC TAGGING AU
   Nayyar RK, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P30, DOI 10.1109/BID.2017.8336569
   Ruder S., 2016, ARXIV
   Schedl M., 2013, 7 ACM C REC SYST HON
   Serra, 2019, 20 INT SOC MUS INF R
   Serra X, 2019, ARXIV PREPRINT ARXIV
   Shao X, 2019, MULTIMED TOOLS APPL, V78, P161, DOI 10.1007/s11042-018-5632-2
   Sharma G, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107020
   Shen JL, 2019, MULTIMEDIA SYST, V25, P639, DOI 10.1007/s00530-019-00613-z
   Shen JL, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P635
   Song GX, 2018, NEUROCOMPUTING, V292, P104, DOI 10.1016/j.neucom.2018.02.076
   Sporleder C., 2014, INT C COMP LING IR D
   Sturm BL, 2014, J NEW MUSIC RES, V43, P147, DOI 10.1080/09298215.2014.894533
   Sung B., 2008, INT J PRINC APPL INF, V2, P13
   Thiruvengatanadhan, 2018, INT RES J ENG TECHNO, V5, P922
   Tsaptsinos A, 2017, ARXIV PREPRINT ARXIV
   Turnbull D, 2008, P 9 INT C MUS INF RE
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Wang, 2019, P 2019 INT C MULT RE
   Wei, 2018, ARXIV PREPRINT ARXIV
   Xu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P121, DOI 10.1109/ICASSP.2018.8461975
   Zhuang N, 2018, PATTERN RECOGN, V80, P225, DOI 10.1016/j.patcog.2018.03.018
   Zuo Y, 2016, NEUROCOMPUTING, V204, P51, DOI 10.1016/j.neucom.2015.10.134
NR 59
TC 7
Z9 8
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15511
EP 15539
DI 10.1007/s11042-020-10381-y
EA FEB 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614681600004
DA 2024-07-18
ER

PT J
AU Agarwal, R
   Jalal, AS
AF Agarwal, Rohit
   Jalal, Anand Singh
TI Presentation attack detection system for fake Iris: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Biometric recognition; Iris detection; Presentation attack detection;
   Anti-spoofing
ID TEXTURED CONTACT-LENSES; LIVENESS DETECTION; VISIBLE SPECTRUM;
   RECOGNITION; CLASSIFICATION
AB The real-time solicitations of biometric systems have been extensively used for several things with the growing necessities of higher security level. There are numerous biometric traits used for person identification. In recent years, iris biometric trait become very popular and efficient in many security applications. However, biometric systems are prone to presentation attack. This attack is carried out by using spoofing of any biometric modality and present as a real trait. The objective of this paper is to present a broad and well thought-out overview of the effort that has been conceded out over the preceding years in the field of iris anti-spoofing. Spoofing of an iris image can be done by paper print and contact lens etc. So, it is essential to discover fake iris up to its core level. In this survey, we have discussed various research work done in the past on the topic of different classes of presentation attack and summarized the state-of-the-art methods in a structural way. We have also discussed the future direction in the field of iris liveness detection.
C1 [Agarwal, Rohit; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
C3 GLA University
RP Jalal, AS (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
EM rohit.agrwal@gla.ac.in; anandsinghjalal@gmail.com
OI Jalal, Anand/0000-0002-7469-6608; , Rohit/0000-0003-4192-726X
CR Agarwal R, 2020, WIRELESS PERS COMMUN, V115, P2627, DOI 10.1007/s11277-020-07700-9
   Agarwal R, 2021, VISUAL COMPUT, V37, P1357, DOI 10.1007/s00371-020-01870-0
   Agarwal R, 2020, MOD PHYS LETT B, V34, DOI 10.1142/S021798492030001X
   Agrawal R, 2019, INT J BIOMETRICS, V11, P177, DOI 10.1504/IJBM.2019.099065
   Anjos A, 2017, 34 INT C MACH LEARN
   Bhogal APS, 2017, 2017 5 INT WORKSH BI, P1
   Bodade, 2009, ICUMT, P1, DOI [10.1049/ic.2009.0123, DOI 10.1049/IC.2009.0123]
   Bodade R., 2011, INT J COMPUT APPL, V19, P1
   Chatterjee, 2019, P SPRING C SEC PRIV, V11637, DOI [10.1007/978-3-030-24900-7_7, DOI 10.1007/978-3-030-24900-7_7]
   Chen CJ, 2018, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW.2018.00011
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen R, 2012, PATTERN RECOGN LETT, V33, P1513, DOI 10.1016/j.patrec.2012.04.002
   Chingovska I, 2019, HDB BIOMETRIC ANTISP, P457, DOI [DOI 10.1007/978-3-319-92627-8_20, 10.1007/978-3-319-92627-8, DOI 10.1007/978--3-319-92627-8_20]
   Choudhary M, 2019, FUTURE GENER COMP SY, V101, P1259, DOI 10.1016/j.future.2019.07.003
   Connell J, 2013, INT CONF ACOUST SPEE, P8692, DOI 10.1109/ICASSP.2013.6639363
   Czajka A, 2015, IEEE T INF FOREN SEC, V10, P726, DOI 10.1109/TIFS.2015.2398815
   Das A, 2016, PATTERN RECOGN LETT, V82, P232, DOI 10.1016/j.patrec.2015.11.016
   Das P, 2020, ARXIV PREPRINT ARXIV
   Nguyen DT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082601
   Doyle JS, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Doyle JS, 2015, IEEE ACCESS, V3, P1672, DOI 10.1109/ACCESS.2015.2477470
   Fathy WSA, 2018, WIRELESS PERS COMMUN, V102, P2331, DOI 10.1007/s11277-017-5089-z
   Galbally J., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P271, DOI 10.1109/ICB.2012.6199819
   Galbally J., 2016, Biometrics and Forensics (IWBF), 2016 4th International Workshop on, P1, DOI DOI 10.1109/IWBF.2016.7449676
   Galbally J, 2016, ADV COMPUT VIS PATT, P469, DOI 10.1007/978-1-4471-6784-6_20
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gragnaniello D, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P560, DOI 10.1109/SITIS.2014.35
   Gragnaniello D, 2015, PATTERN RECOGN LETT, V57, P81, DOI 10.1016/j.patrec.2014.10.018
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Gupta P, 2014, INT C PATT RECOG, P1681, DOI 10.1109/ICPR.2014.296
   He L, 2016, INT CONF BIOMETR THE
   He X, 2008 CHIN C PATT REC
   He XF, 2009, LECT NOTES COMPUT SC, V5558, P1132
   Hoffman S, 2018, IEEE COMPUT SOC CONF, P1701, DOI 10.1109/CVPRW.2018.00213
   Hsieh SH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030795
   Hu Y, 2016, PATTERN RECOGN LETT, V82, P242, DOI 10.1016/j.patrec.2015.10.010
   Huang XY, 2013, IEEE WORK APP COMP, P252, DOI 10.1109/WACV.2013.6475026
   Hughes K, 2013, P ANN HICSS, P1763, DOI 10.1109/HICSS.2013.172
   Hui Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4279, DOI 10.1109/ICPR.2010.1040
   Kannala J, 2012, INT C PATT RECOG, P1363
   Karunya R., 2015, 2015 International Conference on Advanced Computing and Communication Systems (ICACCS). Proceedings, P1, DOI 10.1109/ICACCS.2015.7324134
   Kaur B, 2020, MULTIMED TOOLS APPL, V79, P6623, DOI 10.1007/s11042-019-08281-x
   Kaur B, 2019, COMPUT ELECTR ENG, V73, P279, DOI 10.1016/j.compeleceng.2018.12.002
   Kohli N., 2016, IEEE Int. Conf. on Biometrics: Theory Applications and Systems (BTAS), P1, DOI DOI 10.1109/BTAS.2016.7791168
   Kohli N, 2013, INT CONF BIOMETR
   Komogortsev OV, 2013, INT CONF BIOMETR
   Krupinski R, 2012, LECT NOTES COMPUTER, V7594, DOI [10.1007/978-3-642-33564-8_19, DOI 10.1007/978-3-642-33564-8_19]
   Lee EC, 2006, LECT NOTES COMPUT SC, V3832, P397
   Lee EC, 2010, INT J IMAG SYST TECH, V20, P162, DOI 10.1002/ima.20227
   Lee EC, 2008, OPT ENG, V47, DOI 10.1117/1.2947582
   Lee SJ, 2007, OPT ENG, V46, DOI 10.1117/1.2815719
   Li, 2010, SPIE, V7838
   Liu M, 2020, IEEE T FUZZY SYST, V28, P92, DOI 10.1109/TFUZZ.2019.2912576
   Long M, 2019, CMC-COMPUT MATER CON, V58, P493, DOI 10.32604/cmc.2019.04378
   Manjani I, 2017, IEEE T INF FOREN SEC, V12, P1713, DOI 10.1109/TIFS.2017.2676720
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, INT C PATT RECOG, P3596
   Pala F, 2017, IEEE COMPUT SOC CONF, P664, DOI 10.1109/CVPRW.2017.95
   Park JH, 2005, LECT NOTES COMPUT SC, V3781, P150, DOI 10.1007/11569947_19
   Pinto A. M. F. R., 2018, DEEP LEARNING BIOMET, P245, DOI [10.1016/B978-0-12-811849-8.00007-3, DOI 10.1016/B978-0-12-811849-8.00007-3]
   Puhan N. B., 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P71, DOI 10.1109/ISCE.2011.5973786
   Raghavendra R, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014), DOI 10.1109/BTAS.2014.6996225
   Raghavendra R, 2015, IEEE T INF FOREN SEC, V10, P703, DOI 10.1109/TIFS.2015.2400393
   Raghavendra R, 2014, EUR SIGNAL PR CONF, P1387
   Raghavendra R, 2014, P 2014 IND C COMP VI, P1
   Raja K.B., 2015, 2015 IEEE 7 INT C BI, DOI [DOI 10.1109/BTAS.2015.7358790, 10.1109/BTAS.2015.7358790]
   Raja KB, 2015, IEEE T INF FOREN SEC, V10, P2048, DOI 10.1109/TIFS.2015.2440188
   Rigas I, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Rigas I, 2015, PATTERN RECOGN LETT, V68, P316, DOI 10.1016/j.patrec.2015.06.011
   Ruiz-Albacete V, 2008, LECT NOTES COMPUT SC, V5372, P181, DOI 10.1007/978-3-540-89991-4_19
   Sequeira AF, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P660, DOI 10.1109/TSP.2016.7760965
   Sequeira AnaF., 2014, IEEE International Joint Conference on Biometrics (IJCB), P1
   Silva P, 2015, SIBGRAPI, P157, DOI 10.1109/SIBGRAPI.2015.16
   Singh Y. N., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P106, DOI 10.1109/WICT.2011.6141226
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Wei ZhongFen Wei ZhongFen, 2008, Guizhou Agricultural Sciences, P1
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
   Yambay D., 2017, IEEE International Conference on Identity, Security and Behavior Analysis (ISBA), P1
   Yambay D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P733, DOI 10.1109/BTAS.2017.8272763
   Yambay D, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Zhang H, 2011, INT JOINT C BIOM, V1
NR 83
TC 10
Z9 11
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15193
EP 15214
DI 10.1007/s11042-020-10378-7
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613628000006
DA 2024-07-18
ER

PT J
AU Bhatti, UA
   Yuan, LW
   Yu, ZY
   Li, JB
   Nawaz, SA
   Mehmood, A
   Zhang, K
AF Bhatti, Uzair Aslam
   Yuan, Linwang
   Yu, Zhaoyuan
   Li, JingBing
   Nawaz, Saqib Ali
   Mehmood, Anum
   Zhang, Kun
TI New watermarking algorithm utilizing quaternion Fourier transform with
   advanced scrambling and secure encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clifford algebra; Secure watermarking; Color watermarking
ID COLOR; SCHEME; PROTECTION; DETECTOR; ROBUST
AB Digital watermarking technology, as a powerful tool for copyright protection and content authentication of multimedia works, has received increasing attention, and the current image watermarking technology has developed significantly. Generally, embedding a watermark is done in grayscale images, mainly due to the fact that grayscale images are easier to process than color images, and grayscale images only contain brightness information and color-free information, in which an embedded watermark will not produce new color components. In real life, however, color images are more common than grayscale image information. To improve the security of the watermark information and the ability to embed the location and improve the security of the algorithm against a variety of attacks, this paper proposes an algorithm based on quaternion Fourier transform (QFT) with chaotic encryption and Arnold scrambling. Geometric Algebra (GA) can process color images in the form of vectors, and each component of Red,Green and Blue (RGB) should be processed separately. We utilized quaternion (which is a subalgebra of GA) and effectively completed color image processing by utilizing Fourier transform. After utilizing QFT, each component was made more secure by scrambling the pixels of the watermark and performing encryption utilizing chaotic sequencing. Different types of results utilizing Mean Square Error (MSE),Peak Signal to Noise Ratio (PSNR),Structure Similiarity Index Metric (SSIM), etc. were computed to verify the performance of our proposed algorithm and show that the robustness and security are high by utilizing our method.
C1 [Bhatti, Uzair Aslam; Yuan, Linwang; Yu, Zhaoyuan; Zhang, Kun] Nanjing Normal Univ, Sch Geog Remote Sensing & GIS, Nanjing, Peoples R China.
   [Yuan, Linwang] Nanjing Normal Univ, Minist Educ, Key Lab Virtual Geog Environm, 1 Wenyuan Rd, Nanjing, Peoples R China.
   [Yuan, Linwang] Nanjing Normal Univ, Jiangsu Prov Key Lab NSLSCS, 1 Wenyuan Rd, Nanjing, Peoples R China.
   [Li, JingBing; Nawaz, Saqib Ali] Hainan Univ, Coll Informat & Commun Engn, Nanjing, Peoples R China.
   [Mehmood, Anum] Southeast Univ, Sch Med, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing Normal University; Nanjing Normal University; Nanjing Normal
   University; Hainan University; Southeast University - China
RP Yuan, LW (corresponding author), Nanjing Normal Univ, Sch Geog Remote Sensing & GIS, Nanjing, Peoples R China.; Yuan, LW (corresponding author), Nanjing Normal Univ, Minist Educ, Key Lab Virtual Geog Environm, 1 Wenyuan Rd, Nanjing, Peoples R China.; Yuan, LW (corresponding author), Nanjing Normal Univ, Jiangsu Prov Key Lab NSLSCS, 1 Wenyuan Rd, Nanjing, Peoples R China.
EM yuanlinwang@njnu.edu.cn
OI Nawaz, Saqib Ali/0000-0002-3342-7874
FU National Natural Science Foundation of China [41625004, 41976186]; Six
   talent peaks project in Jiangsu Province [RJFW-019]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 41625004, 41976186, and Six talent peaks
   project in Jiangsu Province under Grant RJFW-019.
CR [Anonymous], 2007, Information Systems Security, V16, P93, DOI 10.1080/10658980701322528
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Chen BJ, 2019, MULTIMED TOOLS APPL, V78, P8057, DOI 10.1007/s11042-018-6595-z
   Chen BJ, 2018, MULTIMED TOOLS APPL, V77, P20809, DOI 10.1007/s11042-017-5511-2
   Chen Y, 2020, IEEE ACCESS, V8, P30628, DOI 10.1109/ACCESS.2020.2973044
   Chen YY, 2020, IEEE T IMAGE PROCESS, V29, P1426, DOI 10.1109/TIP.2019.2941319
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   Darwish M.M., 2020, Multimedia security using chaotic maps: principles and methodologies, P137
   Deng Y, 2016, CHAOS SOLITON FRACT, V91, P549, DOI 10.1016/j.chaos.2016.07.014
   Ell TA, 2014, FOCUS SER, P1, DOI 10.1002/9781118930908
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Haldar, 2018, USC SIPI REPORT 443
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hosny KM, 2019, PATTERN ANAL APPL, V22, P1105, DOI 10.1007/s10044-018-0740-1
   Jiang FF, 2020, MULTIMED TOOLS APPL, V79, P7599, DOI 10.1007/s11042-019-08459-3
   Jiang S., 2008, THESIS FUDAN U SHANG
   Jin LH, 2007, IEEE SIGNAL PROC LET, V14, P397, DOI 10.1109/LSP.2006.887840
   Kaur A., 2020, HDB RES MULTIMEDIA C, P73
   Labunets V, 2004, NATO SCI SER II-MATH, V136, P197
   Li B, 2005, J CENT SOUTH UNIV T, V12, P278, DOI 10.1007/s11771-005-0414-1
   Li MJ, 2020, IEEE ACCESS, V8, P72308, DOI 10.1109/ACCESS.2020.2987914
   Li SJ, 2001, PHYS LETT A, V290, P127, DOI 10.1016/S0375-9601(01)00612-0
   Madhavan S, 2017, INT J COMPUT SCI ENG, V15, P236, DOI 10.1504/IJCSE.2017.10008091
   Nawaz SA, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232902
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P2783, DOI 10.1109/78.960426
   Sangwine SJ, 1998, ELECTRON LETT, V34, P969, DOI 10.1049/el:19980697
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh N, 2019, INT C SUST COMP SCI
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Voyatzis G, 1999, P IEEE, V87, P1197, DOI 10.1109/5.771072
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P678, DOI 10.1016/j.jvcir.2016.04.011
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xia ZQ, 2019, IEEE ACCESS, V7, P122544, DOI 10.1109/ACCESS.2019.2935174
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Yang Y, 2018, 2018 11 INT C IM SIG
   Yu-jie H, 2013, 3 INT C MULT TECHN I
NR 42
TC 18
Z9 18
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13367
EP 13387
DI 10.1007/s11042-020-10257-1
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776300004
DA 2024-07-18
ER

PT J
AU AbdelRaouf, A
AF AbdelRaouf, Ashraf
TI A new data hiding approach for image steganography based on visual color
   sensitivity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; information hiding; Cover image; secret message; Stego
   image; Least Significant Bit (LSB)
AB The increase of data communication globally requires secure exchange of private information. Steganography is a common form of information hiding from an unauthorized access. Secret messages can be in different ways and file formats such as: images, texts, audios, and videos. Transmitting secret messages is important for trading private information between different countries without hacking. Adaptive Steganography enables hiding data with variable numbers of bits based on the size of the secret message and the cover image. This paper proposes a new data hiding approach for image steganography based on the human visual properties using adaptive Least Significant Bits (LSB). Two different methodologies are applied; firstly, the human eye has different sensitivity to RGB color channels which permits different number of bits for every color channel. Secondly, photos focus normally on their middle zone which permits hiding the secret message using a spiral way starting from the images' edges towards its center. Both methods are used to enhance the visual appearance of the stego image using the simple LSB replacement approach. This approach enables hiding bigger secret message with less real visual effect/distortion. Experiments are implemented using the common image processing photos dataset. We applied the traditional LSB Steganography with our approach using different performance metrics criteria. Our approach presented better results when compared to traditional LSB approach and when compared with similar recent researches.
C1 [AbdelRaouf, Ashraf] Misr Int Univ, Fac Comp Sci, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Misr University for Science & Technology;
   Misr International University
RP AbdelRaouf, A (corresponding author), Misr Int Univ, Fac Comp Sci, Cairo, Egypt.
EM ashraf.raouf@miuegypt.edu.eg
RI Abdelraouf, Ashraf/I-2058-2018
OI Abdelraouf, Ashraf/0000-0002-5337-7835
CR Abd-El-Atty B, 2016, INT C ADV INT SYST I, P342
   Akyüz AO, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2238891
   [Anonymous], 2019, IEEE ACCESS
   [Anonymous], 2010, 2010 2 INT C COMPUTI
   Attaby Abdelhamid Awad., 2017, Ain Shams Engineering Journal
   Bandyopadhyay SK, 2008, INT C CONT COMPUTING, V101, P105
   Cattrell P, 2005, PHOTOGRAPHIC SEEING
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Gallea R, 2013, LECT NOTES COMPUT SC, V8157, P21, DOI 10.1007/978-3-642-41184-7_3
   Gonzalez R., 2017, DIGITAL IMAGE PROCES
   Haar A, 1909, Zur theorie der orthogonalen funktionensysteme
   Hamming RW, 1982, ERROR DETECTING ERRO
   Heidari S, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1694-8
   Houser K, 2016, LEUKOS, V12, P7, DOI 10.1080/15502724.2014.989802
   Hussain M., 2013, International Journal of advanced Science and Technology, V54, P113
   Itseez, 2014, OPENCV REF MAN 2 4 9
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Lu JC, 2019, IEEE ACCESS, V7, P21702, DOI 10.1109/ACCESS.2019.2896781
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Maleki N, 2014, EGYPT INFORM J, V15, P115, DOI 10.1016/j.eij.2014.06.001
   MAZURCZYK W, 2014, IEEE COMMUNICATIONS, V17, P334
   Mohamed M. H., 2016, Appl. Math. Inf. Sci., V10, P259, DOI [10.18576/amis/100126, DOI 10.18576/AMIS/100126]
   Molaei AM, 2019, PATTERN ANAL APPL, V22, P205, DOI 10.1007/s10044-018-00773-0
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Murugan GVK, 2019, MULTIMED TOOLS APPL, P1
   Nilizadeh A, 2017, IEEE COMPUT SOC CONF, P1407, DOI 10.1109/CVPRW.2017.183
   Qin Jiaohua, 2019, IEEE ACCESS
   Qu ZG, 2019, IEEE ACCESS, V7, P35684, DOI 10.1109/ACCESS.2019.2894295
   Rabie T, 2019, IEEE ACCESS, V7, P21948, DOI 10.1109/ACCESS.2019.2898838
   RAJENDRAN R, 2017, INT J ENG SCI, V7, P11457
   Rajkumar P., 2012, INT J COMPUTER APPL, V53, P1, DOI DOI 10.5120/8382-1981
   Rawat D., 2013, International Journal of Computer Applications, V64, P15, DOI DOI 10.5120/10749-5625
   Saini S., 2014, INT J EMERGING RES M, V3, P83
   Salama MA, 2018, AIN SHAMS ENG J, V9, P3001, DOI 10.1016/j.asej.2018.03.002
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Shanthakumari R, 2019, MULTIMED TOOLS APPL, P1
   Shukla AK, 2018, IEEE ACCESS, V6, P51130, DOI 10.1109/ACCESS.2018.2868192
   Singh Amritpal, 2014, INT J ENG COMPUTER S, V3, P7341
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZC, 2019, IEEE ACCESS, V7, P57857, DOI 10.1109/ACCESS.2019.2914226
   Weber A. G., 1997, USC-SIPI Report, V315
   Xiang LY, 2018, IEEE ACCESS, V6, P64131, DOI 10.1109/ACCESS.2018.2878273
   Xu KQ, 2011, INT J INTELL INF TEC, V7, P1, DOI 10.4018/jiit.2011010101
   Yang CF, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9328-2
   Yang HF, 2009, RADIOENGINEERING, V18, P509
   Zhang Y, 2019, IEEE ACCESS, V7, P24282, DOI 10.1109/ACCESS.2019.2900286
   Zielinska E., 2012, DEV TRENDS STEGANOGR
NR 53
TC 26
Z9 27
U1 3
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23393
EP 23417
DI 10.1007/s11042-020-10224-w
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000605548700015
DA 2024-07-18
ER

PT J
AU Lu, YW
   Wang, YX
   Chen, ZJ
   Khan, A
   Salvaggio, C
   Lu, GY
AF Lu, Yawen
   Wang, Yuxing
   Chen, Zhanjie
   Khan, Awais
   Salvaggio, Carl
   Lu, Guoyu
TI 3D plant root system reconstruction based on fusion of deep
   structure-from-motion and IMU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structure-from-motion; Convolutional neural network; IMU; Fusion
ID KALMAN FILTER
AB Roots play a critical role in the functioning of plants. However, it is still challenging to generate detailed 3D models of thin and complicated plant roots, due to the complexity of the structure and the limited textures. Limited by the difficulty of realization and inaccessibility of labeled data for training, few works have been put in exploring this problem using deep neural networks. To overcome this limitation, this paper presents a structure-from-motion based deep neural network structure for plant root reconstruction in a self-supervised manner, which can be applied by mobile phone platforms. In the training process of deep structure-from-motion, each depth is constrained from the depth map and predicted relative poses from their adjacent frames captured by the mobile phone cameras, and the LSTM-based network after CNN for pose estimation is learnt from the ego-motion constraints by further exploiting the temporal relationship between consecutive frames. IMU unit in the mobile phone is further utilized to improve the pose estimation network by continuously updating the correct scales from the gyroscope and accelerometer moment. Our proposed approach is able to solve the scale ambiguity in recovering the absolute scale of the real plant roots so that the approach can promote the performance of camera pose estimation and scene reconstruction jointly. The experimental results on both real plant root dataset and the rendered synthetic root dataset demonstrate the superior performance of our method compared with the classical and state-of-the-art learning-based structure-from-motion methods.
C1 [Lu, Yawen; Wang, Yuxing; Chen, Zhanjie; Salvaggio, Carl; Lu, Guoyu] Rochester Inst Technol, Chester F Carlson Ctr Imaging Sci, Rochester, NY 14623 USA.
   [Khan, Awais] Cornell Univ, Plant Pathol & Plant Microbe Biol Sect, Ithaca, NY USA.
C3 Rochester Institute of Technology; Cornell University
RP Lu, GY (corresponding author), Rochester Inst Technol, Chester F Carlson Ctr Imaging Sci, Rochester, NY 14623 USA.
EM awais.khan@cornell.edu; luguoyu@cis.rit.edu
RI Salvaggio, Carl/GZH-0043-2022; Khan, Awais/JHT-9826-2023; lu,
   yawen/IAN-2329-2023
OI Salvaggio, Carl/0000-0001-9293-9696; Khan, Muhammad
   Awais/0000-0002-0424-7727; Lu, Guoyu/0000-0002-2685-5563
CR Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Almalioglu Y, 2019, IEEE INT CONF ROBOT, P5474, DOI [10.1109/icra.2019.8793512, 10.1109/ICRA.2019.8793512]
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   [Anonymous], 2019, ARXIV190810553
   Beardsley P., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P683
   Bloesch M, 2017, INT J ROBOT RES, V36, P1053, DOI 10.1177/0278364917728574
   Bloesch M, 2015, IEEE INT C INT ROBOT, P298, DOI 10.1109/IROS.2015.7353389
   Chen JJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1771, DOI 10.1145/3123266.3123428
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Cui HN, 2017, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2017.257
   Dellaert F, 2000, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2000.854916
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Farenzena Michela, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1489, DOI 10.1109/ICCVW.2009.5457435
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   Feng T, 2019, IEEE ROBOT AUTOM LET, V4, P4431, DOI 10.1109/LRA.2019.2925555
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Gherardi R, 2010, PROC CVPR IEEE, P1594, DOI 10.1109/CVPR.2010.5539782
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Haas J. K., 2014, A history of the unity game engine
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Huang W, 2020, ARXIV200405534
   Jiang NJ, 2013, IEEE I CONF COMP VIS, P481, DOI 10.1109/ICCV.2013.66
   Khan MKR, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.00436
   Kingma D. P., 2014, arXiv
   Kundu JN, 2018, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2018.00281
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li K, 2019, IEEE T IND INFORM
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251
   Li XS, 2019, COMPLEXITY, DOI 10.1155/2019/7485621
   Lu Q, 2011, PR ELECTROMAGN RES S, P576
   Ma J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1857, DOI 10.1109/ICASSP.2018.8461776
   Moulon Pierre, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P257, DOI 10.1007/978-3-642-37447-0_20
   Moulon P, 2013, IEEE I CONF COMP VIS, P3248, DOI 10.1109/ICCV.2013.403
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Poggi M, 2018, INT CONF 3D VISION, P324, DOI 10.1109/3DV.2018.00045
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Rogers ED, 2015, CURR OPIN BIOTECH, V32, P93, DOI 10.1016/j.copbio.2014.11.015
   Snavely Noah, 2011, IPSJ Transactions on Computer Vision and Applications, V3, P44, DOI 10.2197/ipsjtcva.3.44
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sweeney C, 2015, IEEE I CONF COMP VIS, P801, DOI 10.1109/ICCV.2015.98
   Tanskanen P, 2015, IEEE INT C INT ROBOT, P6073, DOI 10.1109/IROS.2015.7354242
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596
   Wang D, 2016, INT CONF UNMAN AIRCR, P615, DOI 10.1109/ICUAS.2016.7502643
   Wang KX, 2018, INT CONF 3D VISION, P248, DOI 10.1109/3DV.2018.00037
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang S, 2017, INT CONF ACOUST SPEE, P436, DOI 10.1109/ICASSP.2017.7952193
   Weiss S.M., 2012, THESIS
   Wilson K, 2014, LECT NOTES COMPUT SC, V8691, P61, DOI 10.1007/978-3-319-10578-9_5
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Wu C., 2011, VisualSFM: A visual structure from motion system
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Yang B, 2017, IEEE INT CONF COMP V, P679, DOI 10.1109/ICCVW.2017.86
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   You Y., 2019, PROC BRIT MACH VIS C
   Zebedin L, 2008, LECT NOTES COMPUT SC, V5305, P873, DOI 10.1007/978-3-540-88693-8_64
   Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhu SY, 2018, PROC CVPR IEEE, P4568, DOI 10.1109/CVPR.2018.00480
   Zhu Siyu, 2017, ARXIV170208601
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 72
TC 6
Z9 6
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17315
EP 17331
DI 10.1007/s11042-020-10069-3
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000604203000001
DA 2024-07-18
ER

PT J
AU Xing, LQ
AF Lanqin, Xing
TI Intelligent multimedia urban planning Construction based on spectral
   clustering algorithms of large data mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Knowledge mining; Smart city; Planning and construction;
   Spectral clustering
AB This paper presents a spatio-temporal analysis method of intelligent urban road planning congestion based on spectral clustering algorithm of large data mining. Firstly, a time-space model of intelligent urban road planning congestion based on four-dimensional spatial temporal data of GIS is established, it uses the solution of additional virtual data to improve the sampling density of time dimension smart urban road planning congestion data. Secondly, the training planning data are clustered according to time in time and space so that the planning data with the same or similar time are in the same class. Then, each time class is clustered according to regional characteristics, and similar regions are clustered into the same block. Then it uses the Dobernoulli model to find the joint probability distribution between each block and time in the time class; finally, the joint probability distribution model is used to mine knowledge from unlabeled planning data, the effectiveness of the proposed method is verified by simulation experiments.
C1 [Lanqin, Xing] Shaanxi Xueqian Normal Univ, Sch Econ & Management, Xian, Shaanxi, Peoples R China.
C3 Shaanxi Xueqian Normal University
RP Xing, LQ (corresponding author), Shaanxi Xueqian Normal Univ, Sch Econ & Management, Xian, Shaanxi, Peoples R China.
EM shaagaq@163.com
CR Abdulhay E, 2020, NEURAL COMPUT APPL, V32, P10947, DOI 10.1007/s00521-018-3738-0
   Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Bagyalakshmi G, 2018, IEEE ACCESS, V6, P57144, DOI 10.1109/ACCESS.2018.2872775
   Castro PF, 2012, INT C COMP SCI ITS A
   Elamaran V, 2018, IEEE ACCESS, V6, P62874, DOI 10.1109/ACCESS.2018.2876119
   Elamaran V, 2018, IEEE ACCESS, V6, P59672, DOI 10.1109/ACCESS.2018.2870557
   Elhoseny M, 2020, NEURAL COMPUT APPL, V32, P10979, DOI 10.1007/s00521-018-3801-x
   Han YF, 2016, INT J INTELL TRANSP, V14, P36, DOI 10.1007/s13177-014-0099-7
   Hussein A., IEEE ACCESS, V6, P49306
   Jiao DD, 2019, FUTURE GENER COMP SY, V92, P324, DOI 10.1016/j.future.2018.10.019
   Khamparia A, 2020, NEURAL COMPUT APPL, V32, P11083, DOI 10.1007/s00521-018-3896-0
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Liu JJ, 2018, IEEE ACCESS, V6, P61457, DOI 10.1109/ACCESS.2018.2876135
   Mohammed MA, 2020, J SUPERCOMPUT, V76, P1086, DOI 10.1007/s11227-018-2587-z
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Ouillon S, 2008, SENSORS-BASEL, V8, P4165, DOI 10.3390/s8074165
   Peixoto SA, 2020, NEURAL COMPUT APPL, V32, P10935, DOI 10.1007/s00521-018-3736-2
   Petropoulos GP, 2013, GEOCARTO INT, V28, P323, DOI 10.1080/10106049.2012.706648
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Sathishkumar BR, 2020, NEURAL COMPUT APPL, V32, P11097, DOI 10.1007/s00521-018-3919-x
   Small C, 2006, REMOTE SENS ENVIRON, V100, P441, DOI 10.1016/j.rse.2005.10.023
   Tarantino C, 2004, GEOSC REM SENS S 200, P1975
   Tasdemir K, 2009, IEEE T NEURAL NETWOR, V20, P549, DOI 10.1109/TNN.2008.2005409
   Venkatraman V, 2018, INT J HEAVY VEH SYST, V25, P344, DOI 10.1504/IJHVS.2018.094829
   Wu ZC, 2019, FUTURE GENER COMP SY, V93, P170, DOI 10.1016/j.future.2018.10.018
   Xin L, 2011, INT IEEE C INT TRANS
   Zhao B, 2003, J ENVIRON SCI-CHINA, V15, P205
   Zhao J, 2015, INT C SERV SYST SERV
NR 30
TC 2
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35183
EP 35194
DI 10.1007/s11042-019-7572-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900026
DA 2024-07-18
ER

PT J
AU Wang, SX
AF Wang, Shuxia
TI Multimedia data compression storage of sensor network based on improved
   Huffman coding algorithm in cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data compression storage; Sensor network; Cloud storage environment;
   Huffman coding algorithm; Network node
AB Based on the application of wireless sensor networks, this thesis studies the sensing data compression algorithm on sensor nodes and the compressed storage processing method of massive sensor data in wireless sensor networks. Considering the spatio-temporal correlation between sensor data of a single node, an improved adaptive Huffman coding algorithm is proposed, which aims to compress the capacity of transmitted data. The algorithm is applicable to wireless sensor network nodes with limited memory and computing resources. The time-space-related sensor data is compressed in the case where the error is adjustable. And carry out the corresponding experiments and analysis. Several lossless compression algorithms for sensing data characteristics were analyzed and related comparison experiments were conducted. The results show that the algorithm can significantly reduce redundant data, have a higher compression ratio and can guarantee data reconstruction accuracy.
C1 [Wang, Shuxia] Tonghua Normal Univ, Sch Comp, Tonghua 134001, Jilin, Peoples R China.
C3 Tonghua Normal University
RP Wang, SX (corresponding author), Tonghua Normal Univ, Sch Comp, Tonghua 134001, Jilin, Peoples R China.
EM wangwangsx631@163.com
CR Aboelela E, 2014, SENSORS-BASEL, V14, P14567, DOI 10.3390/s140814567
   Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Arunkumar N, 2018, J COMPUT SCI-NETH, V27, P440, DOI 10.1016/j.jocs.2018.02.002
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Cao X., 2017, 2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI), P1, DOI DOI 10.1109/CISPBMEI.2017.8302244
   Chen SL, 2013, ELECTRON LETT, V49, P1058, DOI 10.1049/el.2013.1692
   Ganjewar P, 2016, INT S INT SYST TECHN, P287
   Hsu CH, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P548, DOI 10.1109/WF-IoT.2014.6803227
   HYunge D, 2017, IEEE EMBED SYST LETT, P1
   Imran M, 2014, IEEE T CIRC SYST VID, V24, P2132, DOI 10.1109/TCSVT.2014.2330660
   Kavitha K., 2013, INT J COMPUT APPL, V62, P16, DOI [10.5120/10164-4928, DOI 10.5120/10164-4928]
   Li Y., 2014, CRISPR Reveals a Distal Super-Enhancer Required for Sox2 Expression in Mouse Embryonic Stem Cells, P1, DOI [10.1371/journal.pone.0114485, DOI 10.1371/JOURNAL.PONE.0114485]
   Liao YZ, 2014, IEEE SENS J, V14, DOI 10.1109/JSEN.2014.2358253
   Luo GQ., 2013, INT J ANTENN PROPAG, V2013, P1, DOI DOI 10.1155/2013/746920
   Medeiros HP., 2015, INT J DISTRIB SENSOR, V2014, P1
   Mehfuz S, 2015, HUFFMAN BASED LOSSLE, P48
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Renugadevi S., 2013, Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering (PRIME), P461, DOI 10.1109/ICPRIME.2013.6496521
   Song YZ, 2019, IEEE T INTELL TRANSP, V20, P232, DOI 10.1109/TITS.2018.2805817
   Szalapski T, 2013, DISTRIB PARALLEL DAT, V31, P151, DOI 10.1007/s10619-012-7111-5
   Tao Ziyi, 2017, Journal of Jilin University (Science Edition), V55, P947, DOI 10.13413/j.cnki.jdxblxb.2017.04.29
   Yong B, 2012, J GEOPHYS RES-ATMOS, V117, DOI 10.1029/2011JD017069
   Zordan D, 2014, ACM T SENSOR NETWORK, V11, DOI 10.1145/2629660
NR 23
TC 12
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35369
EP 35382
DI 10.1007/s11042-019-07765-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900036
DA 2024-07-18
ER

PT J
AU Afsharirad, H
AF Afsharirad, Hooman
TI Salient object detection using task simulation as a new input
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Object detection; Task simulation; Top-down;
   Task driven; Edge detection
ID REGION DETECTION
AB Saliency or the salient region changes in the human vision system depending on the type of its behavior and task. That is, the salient region in human vision system is not independent, but dependent on other parameters. If a saliency detection algorithm intends to work like the human vision system, it must have an input as its vision in order to detect that salient region or salient object according to that input. The proposed algorithm of this article (Salient Object Detection using Task Simulation based on Angle) is indeed the updated version of SOD-TS algorithm. In this method we have tried to simulate the task as an angle parameter in order to be able to detect the object independent of its size and rotation. In our proposed method, the algorithm detects the most salient object with regard to the applied task. This method can be used in detecting salient objects, detecting different types of ships, and different types of airplanes, and in edge detection. One of the most important advantages of this approach is its very high speed.
C1 [Afsharirad, Hooman] Ferdowsi Univ Mashhad, Fac Engn, Azadi Sq, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Afsharirad, H (corresponding author), Ferdowsi Univ Mashhad, Fac Engn, Azadi Sq, Mashhad, Razavi Khorasan, Iran.
EM afsharirad.hooman@mail.um.ac.ir
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Afsharirad Hooman, 2019, MULTIMED TOOLS APPL, P1
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Aytekin Ç, 2014, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2014.29
   Bernstein, 2010, ESSENTIALS PSYCHOL, P123
   Borji A, 2013, VISION RES, V91, P62, DOI 10.1016/j.visres.2013.07.016
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Duan L, 2011, CVPR 2011
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Harel J., 2006, ADV NEURAL INF PROCE
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang R, 2017, IEEE SIGNAL PROC LET, V24, P569, DOI 10.1109/LSP.2017.2681687
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian MW, 2019, PATTERN RECOGN LETT, V127, P37, DOI 10.1016/j.patrec.2018.08.022
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P202, DOI 10.1016/j.jvcir.2018.11.007
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Lu Y, 2019, VISUAL COMPUT, V35, P1, DOI [10.1007/s00371-018-01620-3, DOI 10.1007/S00371-018-01620-3]
   Lu Y, 2019, VISUAL COMPUT, V35, P1683, DOI 10.1007/s00371-019-01637-2
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Margolin R, 2013, VISUAL COMPUT, V29, P381, DOI 10.1007/s00371-012-0740-x
   Ming-Ming C., 2014, IEEE T PATTERN ANAL, V37, P582
   Movahedi Vida, 2010, IEEE COMPUTER SOC C
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Peng H, 2013, TWENTY SEVENTH AAAI
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qi W., 2015, Comput. Vis. Media, V1, P309, DOI DOI 10.1007/s41095-015-0028-y
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Sun J., 2017, US Patent, Patent No. [9,697,612, 9697612]
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   Tavakoli HR, 2011, SCANDINAVIAN C IMAGE
   Wang X, 2018, IEEE T IMAGE PROCESS, V27, P121, DOI 10.1109/TIP.2017.2756825
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Yin H, 2020, MULTIMED TOOLS APPL, P1
   Zhai Yun, 2006, P 14TH ACM INT C MUL
   Zhang HY, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277958
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou WB, 2015, IEEE I CONF COMP VIS, P406, DOI 10.1109/ICCV.2015.54
NR 67
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8689
EP 8719
DI 10.1007/s11042-020-09933-z
EA NOV 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000586377600001
DA 2024-07-18
ER

PT J
AU Shi, XY
   Lv, FS
   Seng, DW
   Zhang, JM
   Chen, J
   Xing, BX
AF Shi, Xiaoying
   Lv, Fanshun
   Seng, Dewen
   Zhang, Jiaming
   Chen, Jing
   Xing, Baixi
TI Visualizing and understanding graph convolutional network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph convolutional network; Visual analytics; Graph visualization;
   Interactive exploration
AB The graph convolutional network (GCN), which can handle graph-structured data, is enjoying great interest in recent years. However, while GCN achieved remarkable results for different kinds of tasks, the source of its performance and the underlying decision process remain poorly understood. In this paper, we propose a visual analytics system that supports progressive analysis of GCN executing process and the effect of graph convolution operation. Multiple coordinated views are designed to show the influence of hidden layer parameters, the change of loss/accuracy and activation distributions, and the diffusion process of correctly predicted nodes. In particular, since the traditional t-SNE and force-directed layout methods are unable to show the graph-structured data well, we propose to utilize 'graphTSNE', a novel visualization technique for graph-structured data, to present the node layout in a clearer way. The real-world graph dataset is used to demonstrate the usability and effectiveness of our system through case studies. The results manifest that our system can provide sufficient guidance for understanding the working principle of graph convolutional network.
C1 [Shi, Xiaoying; Lv, Fanshun; Seng, Dewen; Zhang, Jiaming; Chen, Jing; Xing, Baixi] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou, Peoples R China.
C3 Hangzhou Dianzi University
RP Seng, DW (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou, Peoples R China.
EM shixiaoying@hdu.edu.cn; 172050041@hdu.edu.cn; sengdw@hdu.edu.cn;
   z1198647915@gmail.com; cj@hdu.edu.cn; xingbx@hdu.edu.cn
RI Chen, Jing/ACN-9965-2022
OI Chen, Jing/0000-0003-3127-8462
FU National Natural Science Foundation of China [61903109, 61703127];
   Zhejiang Provincial Natural Science Foundation of China [LY19F020047]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61903109 and 61703127, and in part by
   the Zhejiang Provincial Natural Science Foundation of China under Grant
   LY19F020047.
CR Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Defferrard M, 2016, ADV NEUR IN, V29
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Greydanus S, 2018, PR MACH LEARN RES, V80
   Henaff M., 2015, ARXIV150605163
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Karpathy A., 2015, ARXIV150602078
   Kingma D. P., 2014, arXiv
   Kipf TN, 2017, INT C LEARN REPR
   Leow YY, 2019, ARXIV190406915
   Li Yaguang, 2018, INT C LEARN REPR
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Monti F, 2017, ADV NEUR IN, V30
   Pu Z., 2018, ARXIV180207007
   Seo Y, 2018, LECT NOTES COMPUT SC, V11301, P362, DOI 10.1007/978-3-030-04167-0_33
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Velickovic Petar, 2018, INT C LEARN REPR
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3634
   Zahavy T, 2016, PR MACH LEARN RES, V48
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang QS, 2018, FRONT INFORM TECH EL, V19, P27, DOI 10.1631/FITEE.1700808
NR 28
TC 8
Z9 12
U1 8
U2 88
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8355
EP 8375
DI 10.1007/s11042-020-09885-4
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000584348600001
DA 2024-07-18
ER

PT J
AU Chiang, JC
   Yang, CY
   Dedhia, B
   Char, YF
AF Chiang, Jui-Chiu
   Yang, Cheng-Yu
   Dedhia, Bhishma
   Char, Yi-Fan
TI Saliency-driven rate-distortion optimization for 360-degree image coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 360-degree image; ERP; Saliency prediction; Rate-distortion optimization
ID PREDICTION; MODELS; VR
AB 360-degree images allow an immersive experience. They offer multiple views of a scene and the viewpoint can be selected by the user. However, the huge amount of data that is necessary for real-time transmission of 360-degree image and video requires efficient coding techniques, particularly for virtual reality (VR) and augmented reality (AR) applications. The viewer is only interested in a part of the scene so compressing the entire scene with equal quality is inefficient. This study initially constructs a saliency model of the 360-degree image and then a visual attention guided coding scheme is developed using a predicted saliency map. For saliency prediction, two methods of saliency prediction are used and the results are fused, to address the problem of geometry distortion in the ERP (Equirectangular Projection) format. A smoothing-based optimization is then realized in the spherical domain to improve the saliency map. Using the saliency map of the 360-degree image, the distortion of the rate-distortion optimization is modified to ensure a better visual experience. The experimental results show that the viewports of greatest interest are rendered with the highest quality and there is a maximum of 14.33% reduction in the bitrate when the quality measurement is performed in these regions.
C1 [Chiang, Jui-Chiu; Yang, Cheng-Yu; Char, Yi-Fan] Natl Chung Cheng Univ, Dept Elect Engn, Adv Inst Mfg High Tech Innovat, Chiayi, Taiwan.
   [Dedhia, Bhishma] Indian Inst Technol, Dept Elect Engn, Bombay, Maharashtra, India.
C3 National Chung Cheng University; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Bombay
RP Chiang, JC (corresponding author), Natl Chung Cheng Univ, Dept Elect Engn, Adv Inst Mfg High Tech Innovat, Chiayi, Taiwan.
EM rachel@ccu.edu.tw
CR [Anonymous], 2017, JVETF0038
   [Anonymous], 2016, JVETD0027
   [Anonymous], MIT Saliency Benchmark
   [Anonymous], 2017, P IEEE INT C MULT EX
   Bauman B, 2019, MULTIMED TOOLS APPL, V78, P18113, DOI 10.1007/s11042-019-7171-x
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Bylinskii Z., 2016, What do different evaluation metrics tell us about saliency models
   Carlson C., How I Made Wine Glasses from Sunflowers
   Chao FY, 2018, IEEE INT CONF MULTI
   Char Y-F, 2019, P IEEE INT C AC SPEE
   Corbillon X, 2017, IEEE ICC, DOI 10.1109/ICC.2017.7996611
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   De Abreu A., 2017, PROC IEEE 9 INT C QU, P1, DOI 10.1109/QoMEX.2017.7965634
   Graf M, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P261, DOI 10.1145/3083187.3084016
   Gutiérrez J, 2018, SIGNAL PROCESS-IMAGE, V69, P35, DOI 10.1016/j.image.2018.05.003
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hendry M Coban, 2017, JVETF0049
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kammachi-Sreedhar K, 2017, IEEE IMAGE PROC, P2169, DOI 10.1109/ICIP.2017.8296666
   Kapoor J, 2017, 2017 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN COMPUTING AND COMMUNICATION TECHNOLOGIES (ICETCCT), P1
   Lebreton P, 2018, SIGNAL PROCESS-IMAGE, V69, P69, DOI 10.1016/j.image.2018.03.006
   Li JS, 2016, IEEE IMAGE PROC, P370, DOI 10.1109/ICIP.2016.7532381
   Li L, 2019, IEEE T IMAGE PROCESS, V28, P2342, DOI 10.1109/TIP.2018.2885482
   Li YM, 2017, IEEE INT CON MULTI, P709, DOI 10.1109/ICME.2017.8019492
   Ling J, 2018, SIGNAL PROCESS-IMAGE, V69, P60, DOI 10.1016/j.image.2018.03.007
   Luz G., 2017, 2017 IEEE 19 INT WOR, P1
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   OZCINAR C, 2018, 2018 IEEE INT C VIS, pNI158
   Pan J., 2017, SalGAN: Visual Saliency Prediction with Generative Adversarial Networks
   Rai Y, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P205, DOI 10.1145/3083187.3083218
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Skupin R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Sreedhar K. Kammachi, 2016, P IEEE INT S MULT IS
   Startsev M, 2018, SIGNAL PROCESS-IMAGE, V69, P43, DOI 10.1016/j.image.2018.03.013
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Sun Y., 2017, P IEEE C VIS COMM IM, P1, DOI [10.1109/VCIP.2017.8305087, DOI 10.1109/VCIP.2017.8305087]
   Sun Y, 2017, JVETF0072
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   Tang MH, 2017, IEEE INT CON MULTI, P799, DOI 10.1109/ICME.2017.8019460
   Nguyen TC, 2018, IEEE COMMUN LETT, V22, P1858, DOI 10.1109/LCOMM.2018.2848915
   Van den Broeck M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P762, DOI 10.1145/3123266.3123347
   Vishwanath B, 2017, IEEE INT WORKSH MULT
   Wang YZ, 2018, MULTIMED TOOLS APPL, V77, P11883, DOI 10.1007/s11042-017-4839-y
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Ye Y., 2018, JVETK1004
   Youvalari RG, 2016, PICT COD SYMP
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Yu MC, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0279-x
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang MM, 2019, MULTIMED TOOLS APPL, V78, P1081, DOI 10.1007/s11042-018-6283-z
   Zhu YC, 2018, SIGNAL PROCESS-IMAGE, V69, P15, DOI 10.1016/j.image.2018.05.010
NR 51
TC 2
Z9 3
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8309
EP 8329
DI 10.1007/s11042-020-10050-0
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000584348700003
DA 2024-07-18
ER

PT J
AU Matsumura, H
   Taketomi, T
   Kato, H
AF Matsumura, Haruka
   Taketomi, Takafumi
   Kato, Hirokazu
TI Impact of facial contour compensation on self-recognition in
   face-swapping technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face-swapping; Self-recognizability; Facial contour compensation
ID MENTAL PRACTICE
AB Experts in sports science anticipate substantial training gains that can result from elevated cerebral activity when face-swapping technology is used in videos of athletes to facilitate their motor imagery (Matsumura et al. 2017). In Matsumura et al. (2017), we confirmed that self-recognizability in face-swapping positively influences an individual's cerebral activity. However, to the best of our knowledge, self-recognizability in face-swapping is yet to be investigated. In this study, we evaluate self-recognizability in face-swapping from the following perspectives: the impact of facial contour compensation on face-swapped videos, the impact of face orientation, and the difference in the face-swapped targets. In our experiment, we use the visual analog scale for subjective evaluation. The experimental results confirm that facial contour compensation helps improve self-recognizability in face-swapping.
C1 [Matsumura, Haruka; Taketomi, Takafumi; Kato, Hirokazu] Nara Inst Sci & Technol, 8916-5 Takayama, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Taketomi, T (corresponding author), Nara Inst Sci & Technol, 8916-5 Takayama, Nara 6300192, Japan.
EM matsumura.haruka.md7@is.naist.jp; takafumi-t@is.naist.jp;
   kato@is.naist.jp
RI Taketomi, Takafumi/AAE-7546-2021; Taketomi, Takafumi/T-4236-2017
OI Kato, Hirokazu/0000-0003-3921-2871; Taketomi,
   Takafumi/0000-0002-5353-0895
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI [DOI 10.1109/WIFS.2018.8630761, 10.1109/WIFS.2018.8630761]
   [Anonymous], 2020, DEEPFACELAB
   [Anonymous], 2019, DLIB C LIB
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x
   Blefari ML, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00018
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   DECETY J, 1990, ACTA PSYCHOL, V73, P13, DOI 10.1016/0001-6918(90)90056-L
   DRISKELL JE, 1994, J APPL PSYCHOL, V79, P481, DOI 10.1037/0021-9010.79.4.481
   FELTZ DL, 1983, J SPORT PSYCHOL, V5, P25, DOI 10.1123/jsp.5.1.25
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Keyes H, 2010, BRAIN COGNITION, V72, P244, DOI 10.1016/j.bandc.2009.09.006
   Matsumura H, 2017, P INT C ART REAL TEX, P7
   Microsoft garage, 2019, FAC SWAP
   Morishima S, 2008, IEICE T INF SYST, VE91D, P1594, DOI 10.1093/ietisy/e91-d.6.1594
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Platek SM, 2004, COGNITIVE BRAIN RES, V19, P114, DOI 10.1016/j.cogbrainres.2003.11.014
   Sugase-Miyamoto Y, 2014, J NEUROSCI, V34, P12457, DOI 10.1523/JNEUROSCI.0485-14.2014
   Sugiura M, 2005, NEUROIMAGE, V24, P143, DOI 10.1016/j.neuroimage.2004.07.063
   Uddin LQ, 2005, NEUROIMAGE, V25, P926, DOI 10.1016/j.neuroimage.2004.12.018
   YIN RK, 1969, J EXP PSYCHOL, V81, P141, DOI 10.1037/h0027474
   YUE G, 1992, J NEUROPHYSIOL, V67, P1114, DOI 10.1152/jn.1992.67.5.1114
NR 23
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7727
EP 7748
DI 10.1007/s11042-020-09866-7
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ding, C
   Tang, LW
   Cao, LJ
   Shao, XJ
   Wang, W
   Deng, SJ
AF Ding, Chao
   Tang, Liwei
   Cao, Lijun
   Shao, Xinjie
   Wang, Wei
   Deng, Shijie
TI Preprocessing of multi-line structured light image based on Radon
   transformation and gray-scale transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-line structured light image; Radon transformation; Gray-scale
   transformation; Reliability evaluation
AB In the process of the structured light detection, it is affected by many factors such as the light source, object to it-self and environmental noise, which result in poor imaging quality. For this reason, the Radon transformation of multi angle is adopted to get the transform domain image, after obtaining the information of the oblique angle of the structured light stripes. After that the singular points unrelated to the target stripes are eliminated in the transform domain image. Then the processed transform domain image is restored and the noise is eliminated. At the same time, the above-mentioned structured light images are pre-processed by several existing means to eliminate noise. Then compared with the traditional methods, the superiority of the Radon transformation in eliminating noise interference is highlighted by using the reliability evaluation scheme to evaluate the quality of the processed images. Finally, aiming at the other shortcomings in the Radon transformed image and further improving the image quality, the restored images are handled by the gray-scale transformation enhancement to enhance the overall gray level of the image. The experimental results show that the imaging quality of the image processed by the above methods is significantly improved.
C1 [Ding, Chao; Tang, Liwei; Cao, Lijun; Shao, Xinjie; Wang, Wei; Deng, Shijie] Shijiazhuang Mech Engn Coll, 97 Heping West Rd, Shijiazhuang, Hebei, Peoples R China.
RP Ding, C (corresponding author), Shijiazhuang Mech Engn Coll, 97 Heping West Rd, Shijiazhuang, Hebei, Peoples R China.
EM duncan1119@163.com; tom5157@163.com
FU National Natural Science Foundation Program of China [51575523]
FX This study was funded by the National Natural Science Foundation Program
   of China (grant number No. 51575523).
CR [陈凯 Chen Kai], 2016, [振动、测试与诊断, Journal of Vibration, Measurement and Diagnosis], V36, P647
   Correa-Tome FE, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013007
   Ding C, 2018, INFRARED LASER ENG
   [丁超 Ding Chao], 2017, [光学精密工程, Optics and Precision Engineering], V25, P1077
   Dobes M, 2010, DIGIT SIGNAL PROCESS, V20, P1677, DOI 10.1016/j.dsp.2010.03.012
   [高正龙 Gao Zhenglong], 2013, [计算机工程与应用, Computer Engineering and Application], V49, P182
   He YS, 2016, J INTELL ROBOT SYST, V81, P395, DOI 10.1007/s10846-015-0226-y
   [刘习文 Liu Xiwen], 2017, [焊接学报, Transactions of the China Welding Institution], V38, P19
   Mohan Shelda, 2013, ACEEE International Journal on Information Technology, V3, P66
   Qin Xujia, 2013, Journal of Computer Aided Design & Computer Graphics, V25, P488
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shi YH, 2013, J CAP NORM U NATURAL, V34, P15
   [孙韶杰 SUN Shaojie], 2011, [计算机科学与探索, Journal of Frontiers of Computer Science & Technology], V5, P324
   Tan TL, 2012, INT J IMAG SYST TECH, V22, P153, DOI 10.1002/ima.22016
   Wang Fang, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P457
   [王海超 Wang Haichao], 2017, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V33, P229
   [王社教 Wang Shejiao], 2011, [天然气工业, Natural Gas Industry], V31, P40
   Wijenayake U, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.4.043109
   Yuan Xiaocui, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P800
   Zang Y, 2014, VISUAL COMPUT, V30, P969, DOI 10.1007/s00371-013-0881-6
   Zhang JM, 2015, MEASUREMENT SYSTEM O
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   [赵杰 Zhao Jie], 2018, [计算机科学, Computer Science], V45, P312
   Zhu JP, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.5.054108
   [朱齐丹 Zhu Qidan], 2013, [光电子·激光, Journal of Optoelectronics·Laser], V24, P2233
NR 25
TC 3
Z9 5
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7529
EP 7546
DI 10.1007/s11042-019-08031-z
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858400004
DA 2024-07-18
ER

PT J
AU Mohammed, ZF
   Abdulla, AA
AF Mohammed, Zhana Fidakar
   Abdulla, Alan Anwer
TI An efficient CAD system for ALL cell identification from microscopic
   blood images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAD; Medical image; Leukemia; ALL; DCT; Classifier technique
AB Computer-aided diagnosis (CAD) becomes a common tool for identifying diseases, especially various cancers, from medical images. Thus, digital image processing plays a significant role in this research area. This paper concerns with developing an efficient automatic system for the identification of acute lymphoblastic leukemia (ALL) cells. The proposed approach involves two steps. The first step focuses on segmenting the white blood cells (WBCs). In the second step, significant features such as shape, geometrical, statistical, and discrete cosine transform (DCT) are extracted from the segmented cells. Various classification techniques are applied to the extracted features to classify the segmented cells into normal and abnormal cells. The performance of the proposed approach has been evaluated via extensive experiments conducted on the well-known ALL-IDB dataset of microscopic images of blood. The experimental results demonstrate that the proposed approach realizes an accuracy rate 97.45% and outperforms other existing approaches.
C1 [Mohammed, Zhana Fidakar] Sulaimani Polytech Univ, Coll Informat, Dept Informat Technol, Sulaymaniyah, Iraq.
   [Abdulla, Alan Anwer] Univ Sulimani, Coll Commerce, Dept Informat Technol, Sulaymaniyah, Iraq.
C3 Sulaimani Polytechnic University
RP Abdulla, AA (corresponding author), Univ Sulimani, Coll Commerce, Dept Informat Technol, Sulaymaniyah, Iraq.
EM zhana.mohammed@spu.edu.iq; alan.abdulla@univsul.edu.iq
RI Mohammed, Zhana/KBC-0045-2024
OI Mohammed, Zhana/0000-0003-1594-8067
CR Anto Bennet M, 2019, Int J Recent Technol Eng (IJRTE), V7, P152
   Bhabatosh, 2011, DIGITAL IMAGE PROCES
   Bhargavi K., 2014, INT J INNOV RES DEV, V3, P234
   Bodzas A, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.01005
   ElDahshan KA., 2015, Adv Image Vid Process, V3, P8
   Hariprasath S, 2019, SSRG INT J ELECT COM, P7
   Janaki R., 2020, J Critic Rev, V7, P173, DOI [10.31838/jcr.07.03.32, DOI 10.31838/JCR.07.03.32]
   Kekre H.B., 2013, INT J COMPUT APPL, V27, P20
   Kumar S., 2018, Advances in Computer and Computational Sciences, P655
   Labati RD, 2011, IEEE IMAGE PROC
   Madhloom HT, 2015, J VIBROENG, V17, P4517
   Mishra S, 2017, P INT C COMP VIS IM
   Mohammad ZF, 2020, UHD J SCI TECHNOL, P4
   Neoh SC, 2015, SCI REP-UK, V5, DOI 10.1038/srep14938
   Nikitaev Valentin, 2020, Procedia Computer Science, V169, P353, DOI 10.1016/j.procs.2020.02.229
   Patel N, 2015, PROCEDIA COMPUT SCI, V58, P635, DOI 10.1016/j.procs.2015.08.082
   Piuri V, 2004, 2004 IEEE INT C COMP
   Purwanti E, 2017, J PHYS CONF SER, V853, DOI 10.1088/1742-6596/853/1/012011
   Rawat J, 2015, PROCEDIA COMPUT SCI, V70, P748, DOI 10.1016/j.procs.2015.10.113
   SCOTTI F, 2005, CIMSA 2005 IEEE INT
   Scotti F, 2006, INSTR MEAS TECHN C
   Srisukkham W, 2017, APPL SOFT COMPUT, V56, P405, DOI 10.1016/j.asoc.2017.03.024
   Sukhia KN, 2017, RADIOENGINEERING, V26, P1177, DOI 10.13164/re.2017.1177
   Venmathi V, 2017, INT J SCI RES DEV, V5, P804
NR 24
TC 35
Z9 35
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6355
EP 6368
DI 10.1007/s11042-020-10066-6
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577869200005
DA 2024-07-18
ER

PT J
AU Wu, HT
   Jia, RY
   Dugelay, JL
   He, JH
AF Wu, Hao-Tian
   Jia, Ruoyan
   Dugelay, Jean-Luc
   He, Junhui
TI Reversible image visual transformation for privacy and content
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual encryption; Histogram; Bit plane; Privacy protection; Reversible
   data hiding
ID WATERMARKING; HISTOGRAMS; PARTITION; STRATEGY; SCHEME
AB In this paper, a novel image transformation scheme is proposed to protect the visual information. By mimicking an arbitrarily chosen reference image, a secret image is visually changed and can be exactly recovered from the transformed image when needed. Unlike the block-wise visual encryption methods, the proposed transformation scheme modifies the secret image by bit plane replacement and reordering so that no block effect is introduced. In particular, one or more bit planes are hidden into the other bit planes so that the most significant one(s) can be vacated. Besides replacing the vacated bit plane(s) and reordering the others according to the reference image, histogram modification may be performed to conceal the secret content if needed. To exactly recover the secret image, the required information is recorded and reversibly hidden into the transformed image by adopting a reversible data hiding algorithm. The experimental results on three image sets show that their content can be semantically changed to prevent leakage of visual information. Moreover, the applicability and efficiency of the proposed scheme have been validated by comparing the existing visual encryption schemes.
C1 [Wu, Hao-Tian; Jia, Ruoyan; He, Junhui] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Dugelay, Jean-Luc] EURECOM, Digital Secur Dept, F-06410 Biot, France.
C3 South China University of Technology; IMT - Institut Mines-Telecom;
   EURECOM
RP Wu, HT (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM wuht@scut.edu.cn; 201820133058@mail.scut.edu.cn; jld@eurecom.fr;
   hejh@scut.edu.cn
RI DUGELAY, Jean-Luc/ABE-7096-2021; Wu, Hao-Tian/S-5360-2019
OI Wu, Hao-Tian/0000-0001-6462-7193
FU National Natural Science Foundation of China [61772208]; Key-Area
   Research and Development Program of Guangdong Province of China
   [2019B010137004]; Fundamental Research Funds for the Central
   Universities of China [x2js-D2190700]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61772208), the Key-Area Research and Development Program of
   Guangdong Province (No. 2019B010137004) of China and Fundamental
   Research Funds for the Central Universities of China (x2js-D2190700).
CR Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Cheung YM, 2007, IEEE T CIRC SYST VID, V17, P1007, DOI 10.1109/TCSVT.2007.903553
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Hou DD, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P427, DOI 10.1109/ICDSP.2016.7868593
   Hou DD, 2016, J VIS COMMUN IMAGE R, V40, P225, DOI 10.1016/j.jvcir.2016.06.018
   Kang YH, 2019, CMC-COMPUT MATER CON, V59, P315, DOI 10.32604/cmc.2019.05242
   Lai IJ, 2011, IEEE T INF FOREN SEC, V6, P936, DOI 10.1109/TIFS.2011.2135853
   Lee YL, 2014, IEEE T CIRC SYST VID, V24, P695, DOI 10.1109/TCSVT.2013.2283431
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2019, IEEE T INF FOREN SEC, V14, P2400, DOI 10.1109/TIFS.2019.2899520
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Su WG, 2019, MULTIMED TOOLS APPL, V78, P7927, DOI 10.1007/s11042-018-6410-x
   Subburam S, 2018, MULTIMED TOOLS APPL, V77, P7071, DOI 10.1007/s11042-017-4622-0
   Wang BW, 2019, CMC-COMPUT MATER CON, V58, P679, DOI 10.32604/cmc.2019.06106
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang YG, 2018, IEEE T CYBERNETICS, V48, P2307, DOI 10.1109/TCYB.2017.2735989
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2019, IEEE ACCESS, V7, P62361, DOI 10.1109/ACCESS.2019.2916355
   Wu HT, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P813, DOI 10.1109/ICACI.2018.8377566
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu HT, 2008, LECT NOTES COMPUT SC, V5284, P236
   Xia ZH, 2019, CMC-COMPUT MATER CON, V58, P27, DOI 10.32604/cmc.2019.02688
   Xiao D, 2019, CMC-COMPUT MATER CON, V58, P1, DOI 10.32604/cmc.2019.02171
   Yang JQ, 2021, IEEE T CIRC SYST VID, V31, P1661, DOI 10.1109/TCSVT.2020.3003653
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
NR 36
TC 3
Z9 3
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30863
EP 30877
DI 10.1007/s11042-020-09985-1
EA OCT 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000578275200001
DA 2024-07-18
ER

PT J
AU Ullah, I
   Khusro, S
   Ahmad, I
AF Ullah, Irfan
   Khusro, Shah
   Ahmad, Ibrar
TI Improving social book search using structure semantics, bibliographic
   descriptions and social metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Information science; Social web; Social book
   search; Ranking; re-ranking
ID INFORMATION-RETRIEVAL; QUERY EXPANSION; CURRENT STATE
AB Social Book Search is an Information Retrieval (IR) approach that studies the impact of the Social Web on book retrieval. To understand this impact, it is necessary to develop a stronger classical baseline run by considering the contribution of query formulation, document representation, and retrieval model. Such a stronger baseline run can be re-ranked using metadata features from the Social Web to see if it improves the relevance of book search results over the classical IR approaches. However, existing studies neither considered collectively the contribution of the three mentioned factors in the baseline retrieval nor devised a re-ranking formula to exploit the collective impact of the metadata features in re-ranking. To fill these gaps in the literature, this research work first performs baseline retrieval by considering all three factors. For query formulation, it uses topic sets obtained from the discussion threads of LibraryThing. For book representation in indexing, it uses metadata from social websites including Amazon and LibraryThing. For the role of the retrieval model, it experiments with traditional, probabilistic, and fielded models. Second, it devises a re-ranking solution that exploits ratings, tags, reviews, and votes in reordering the baseline search results. Our best-performing retrieval methods outperform existing approaches on several topic sets and relevance judgments. The findings suggest that using all topic fields formulates the best search queries. The user-generated content gives better book representation if made part of the search index. Re-ranking the classical/baseline results improves relevance. The findings have implications for information science, IR, and Interactive IR.
C1 [Ullah, Irfan; Khusro, Shah; Ahmad, Ibrar] Univ Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
C3 University of Peshawar
RP Khusro, S (corresponding author), Univ Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
EM cs.irfan@uop.edu.pk; khusro@uop.edu.pk; cs.ibrar@uop.edu.pk
RI Ullah, Irfan/C-9213-2014; Ullah, Irfan/CAA-4310-2022; Khusro,
   Shah/C-1661-2014; Ullah, Irfan/AGE-7574-2022
OI Ullah, Irfan/0000-0003-0693-5467; Ullah, Irfan/0000-0003-0693-5467;
   Khusro, Shah/0000-0002-7734-7243; Ullah, Irfan/0000-0003-0693-5467;
   Ullah, Irfan/0000-0003-3961-888X
CR Abualigah L. M. Q., 2019, STUDIES COMPUTATIONA, V816, DOI DOI 10.1007/978-3-030-10674-4
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Adriaans F, 2012, 10 INT WORKSH IN EV, P30, DOI 10.1007/978-3-642-35734-3_2
   Alharthi H, 2018, J INTELL INF SYST, V51, P139, DOI 10.1007/s10844-017-0489-9
   Amudha S, 2020, ADV INTELL SYST, V1016, P281, DOI 10.1007/978-981-13-9364-8_21
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 2014, CEUR WORKSHOP P
   [Anonymous], 4 INT C CLEF IN CLEF
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 3 INT C CLEF IN CLEF
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 3 INT C CLEF IN CLEF
   [Anonymous], LIB SCI INFORM SCI
   [Anonymous], 5 INT C CLEF IN CLEF
   [Anonymous], 4 INT C CLEF IN CLEF
   Azad HK, 2019, INFORM PROCESS MANAG, V56, P1698, DOI 10.1016/j.ipm.2019.05.009
   Badache I, 2020, WEB INTELL, V18, P15, DOI 10.3233/WEB-200426
   Badache I, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P155, DOI 10.1145/3020165.3020177
   Bellot P, 2014, CHAM INFORM ACCESS E, P212
   Bellot P, 2013, LECT NOTES COMPUT SC, V8138, P269, DOI 10.1007/978-3-642-40802-1_27
   Benkoussas Chahinez, 2015, ScientificWorldJournal, V2015, P926418, DOI 10.1155/2015/926418
   Benkoussas C, 2015, 2015 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT), VOL 1, P385, DOI 10.1109/WI-IAT.2015.200
   Benkoussasy C, 2013, CEUR WORKSHOP P
   Besbes Ghada, 2016, International Journal of Metadata, Semantics and Ontologies, V11, P221
   Bogers T, 2018, CEUR WORKSHOPT P, P35
   Bogers T, 2012, 10 INT WORKSH IN EV, P45, DOI 10.1007/978-3-642-35734-3_3
   Bogers Toine., 2017, Data and Information Management, V1, P17, DOI 10.1515/dim-2017-0004
   Buttcher S, 2010, INFORM RETRIEVAL IMP, P33
   Chaa M, 2018, LECT NOTES COMPUT SC, V11018, P64, DOI 10.1007/978-3-319-98932-7_6
   Chaa M, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), P799, DOI 10.1145/3106426.3106481
   Ettaleb M, 2018, PROCEDIA COMPUT SCI, V126, P768, DOI 10.1016/j.procs.2018.08.011
   Feng S.-H, 2016, WORKING NOTES CLEF 2, V1609, P1089
   Ferro N, 2019, LECT NOTES COMPUT SC, V11696, P3, DOI 10.1007/978-3-030-28577-7_1
   Fugleberg J, 2015, WORKING NOTES CLEF 2, V1391, P1
   Htait A, 2019, 20 INT C COMP LING I
   Htait A, 2020, 6 ACM SIGIR 10 INT C, P4
   Huang H, 2019, 8 INT C COMP ENG NET, P477, DOI [10.1007/978-3-030-14680-1_52, DOI 10.1007/978-3-030-14680-1_52]
   Huurdeman H., 2012, INEX 2012 Workshop pre-proceedings, P125
   Imhof M, 2018, INFORM RETRIEVAL J, V21, P81, DOI 10.1007/s10791-017-9322-x
   Kamps J., 2019, INFORM RETRIEVAL EVA, P415
   Kazai G, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P1554, DOI 10.1109/ITNG.2009.281
   Khalid S, 2019, ENG TECHNOL APPL SCI, V9, P3862
   Khan MS, 2014, ENVIRON SCI ENG, P521, DOI 10.1007/978-3-319-03002-9_130
   Khusro S, 2016, 2016 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P106, DOI 10.1109/ICOSST.2016.7838586
   Kim TK, 2015, KOREAN J ANESTHESIOL, V68, P540, DOI 10.4097/kjae.2015.68.6.540
   Koolen Marijn, 2014, Advances in Information Retrieval. 36th European Conference on IR Research, ECIR 2014. Proceedings: LNCS 8416, P323, DOI 10.1007/978-3-319-06028-6_27
   Koolen M., 2012, ACM Conference on Information and Knowledge Management (CIKM), P185, DOI DOI 10.1145/2396761.2396788
   Koolen M, 2016, LECT NOTES COMPUT SC, V9822, P351, DOI 10.1007/978-3-319-44564-9_29
   Koolen M, 2015, LECT NOTES COMPUT SC, V9283, P545, DOI 10.1007/978-3-319-24027-5_51
   Kumar R, 2020, ARTIF INTELL REV, V53, P95, DOI 10.1007/s10462-018-9647-x
   Kumar R, 2019, APPL INTELL, V49, P2178, DOI 10.1007/s10489-018-1383-z
   Li QZ, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P139, DOI 10.1145/3366424.3383527
   Li X, 2015, 20TH INTERNATIONAL CONFERENCE ON COMPOSITE MATERIALS
   Liu T-T, 2015, CEUR WORKSHOP P
   Macdonald Craig, 2012, P OSIR SIGIR, P60
   Mounika A, 2020, P INT C EV COMP MOB, P95, DOI 10.1007/978-981-15-5258-8_11
   Ounis I, 2005, LECT NOTES COMPUT SC, V3408, P517
   Ounis I., 2006, P 29 ACM C RES DEV I, P18
   Ounis I, 2007, CEPIS UPGRADE J
   Preminger M, 2012, WORKING NOTES CLEF 2, P1
   Preminger M, 2011, 10 INT WORKSH IN EV, P109, DOI 10.1007/978-3-642-35734-3_9
   Ramírez D, 2012, IEEE INT WORKS MACH
   Robertson S., 2004, P 13 ACM INT C INF K, P42
   Sanderson M, 2012, P IEEE, V100, P1444, DOI 10.1109/JPROC.2012.2189916
   Tekli J, 2019, KNOWL-BASED SYST, V164, P378, DOI 10.1016/j.knosys.2018.11.010
   Tekli J, 2018, DATA KNOWL ENG, V117, P133, DOI 10.1016/j.datak.2018.07.007
   Torbati GH, 2020, CHIIR'20: PROCEEDINGS OF THE 2020 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P427, DOI 10.1145/3343413.3378011
   Ullah I, 2020, THESIS
   Ullah I, 2020, BEHAV INFORM TECHNOL, V39, P443, DOI 10.1080/0144929X.2019.1599069
   Ullah I, 2020, MULTIMED TOOLS APPL, V79, P8011, DOI 10.1007/s11042-019-08591-0
   Ullah I, 2018, INFORM TECHNOL LIBR, V37, P47, DOI 10.6017/ital.v37i4.10432
   Ullah I, 2016, ADV INTELL SYST, V464, P347, DOI 10.1007/978-3-319-33625-1_31
   Xiao W.-L, 2013, WORKING NOTES CLEF 2, V1179, P1
   Yada S, 2020, INT J DIGIT LIBRARIE, V21, P265, DOI [10.1080/09715010.2019.1594417, 10.1007/s00799-019-00273-4]
   Yin XC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148479
   Zhang B-W, 2014, WORKING NOTES CLEF 2, V1180, P536
   Zhang BW, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1109, DOI 10.1145/3077136.3080734
   Zhang BW, 2016, INFORM SCIENCES, V367, P909, DOI 10.1016/j.ins.2016.07.004
   Zhang Bo-Wen., 2014, Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, P361, DOI [DOI 10.1145/2661829.2661940, 10.1145/2661829.2661940]
   Zhang JP, 2019, IEEE ACM T COMPUT BI, V16, P396, DOI 10.1109/TCBB.2017.2701379
NR 81
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5131
EP 5172
DI 10.1007/s11042-020-09811-8
EA OCT 2020
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574800200007
DA 2024-07-18
ER

PT J
AU Roy, S
   Shrivastava, M
   Pandey, CV
   Nayak, SK
   Rawat, U
AF Roy, Satyabrata
   Shrivastava, Manu
   Pandey, Chirag Vinodkumar
   Nayak, Sanjeet Kumar
   Rawat, Umashankar
TI IEVCA: An efficient image encryption technique for IoT applications
   using 2-D Von-Neumann cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lightweight; IoT; Image encryption; 2-D Cellular automata; Block cipher
ID SEMI-TENSOR PRODUCT; ONE-TIME KEYS; ALGORITHM; SCHEME; SECURITY;
   ARCHITECTURE; PERMUTATION; LIGHTWEIGHT; MANAGEMENT; INTERNET
AB Present era is marked by exponential growth in transfer of multimedia data through internet. Most of the Internet-of-Things(IoT) applications send images to cloud storages through internet. However, in sensitive applications such as healthcare, defense, etc., these images should be encrypted before transmission through insecure public channels to gateway fog nodes. Conventional encryption algorithms cannot be used there due to the resource constraint characters of IoT devices. Here, Cellular Automata (CA) based encryption algorithms can be used because of their inherent simplicity in implementation in hardware, without affecting the capability of generating highly random sequences. In this paper, a lightweight, robust and secure image encryption technique has been proposed using 2-D Von-Neumann Cellular Automata (VCA), called IEVCA, which is lossless, correlation immune and has all the essential properties of a good image cipher. Additionally, the proposed technique passes all the randomness tests of DIEHARD and NIST statistical test suites. Moreover, several security and performance analyses of the IEVCA proved its efficiency and resistance against security attacks. Experimental results of the IEVCA show its better performance when compared to the existing encryption techniques.
C1 [Roy, Satyabrata; Shrivastava, Manu; Pandey, Chirag Vinodkumar; Rawat, Umashankar] Manipal Univ Jaipur, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Nayak, Sanjeet Kumar] Bennett Univ, Dept Comp Sci Engn, Greater Noida, India.
C3 Manipal University Jaipur
RP Shrivastava, M (corresponding author), Manipal Univ Jaipur, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
EM satyabrata.roy@jaipur.manipal.edu; manu.shrivastava@jaipur.manipal.edu;
   chiragpandey15@gmail.com; sanjeet.nayak@bennett.edu.in;
   umashankar.rawat@jaipur.manipal.edu
RI Rawat, Umashankar/ADH-9469-2022; Roy, Satyabrata/AAE-6748-2022; Roy,
   Satyabrata/IZP-9664-2023
OI Rawat, Umashankar/0000-0002-1293-1836; Shrivastava,
   Manu/0000-0001-5954-8108; Nayak, Sanjeet Kumar/0000-0003-4290-0632; Roy,
   Satyabrata/0000-0002-1856-5144
CR Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Bernstein DJ, 2008, CONTEMP MATH, V461, P1
   BEYER WA, 1985, LETT MATH PHYS, V10, P231, DOI 10.1007/BF00398163
   Bouchemal N, 2013, INT J AMBIENT COMPUT, V5, P44, DOI 10.4018/ijaci.2013070104
   Chattopadhyay P, 1999, COMPUT MATH APPL, V38, P207, DOI 10.1016/S0898-1221(99)00227-8
   Choudhury PP, 2008, ARXIV08042346
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dihidar K, 2004, INFORM SCIENCES, V165, P91, DOI 10.1016/j.ins.2003.09.024
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Faheem M, 2018, COMPUT SCI REV, V30, P1, DOI 10.1016/j.cosrev.2018.08.001
   Faheem M, 2019, INT J AD HOC UBIQ CO, V32, P236
   Faheem M, 2018, FUTURE GENER COMP SY, V82, P358, DOI 10.1016/j.future.2017.10.009
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Granjal J, 2015, IEEE COMMUN SURV TUT, V17, P1294, DOI 10.1109/COMST.2015.2388550
   Heuer J, 2015, COMPUTER, V48, P34, DOI 10.1109/MC.2015.152
   Hua ZY, 2019, IEEE T IND ELECTRON, V66, P1273, DOI 10.1109/TIE.2018.2833049
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Jin J, 2012, OPT LASER ENG, V50, P1836, DOI 10.1016/j.optlaseng.2012.06.002
   Karmakar J, 2020, NOVEL HYPER CHAOTIC, P1
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Khan AR, 1999, COMPUT MATH APPL, V37, P115, DOI 10.1016/S0898-1221(99)00080-2
   Khan AR, 1997, COMPUT MATH APPL, V33, P79, DOI 10.1016/S0898-1221(97)00021-7
   Khan MA, 2018, FUTURE GENER COMP SY, V82, P395, DOI 10.1016/j.future.2017.11.022
   Khashan OA, 2020, EDGE BASED LIGHTWEIG, P1
   Khedmati Y, 2020, INFORM SCIENCES, V512, P855, DOI 10.1016/j.ins.2019.10.028
   Kimbahune VV, 2017, INT J AMBIENT COMPUT, V8, P50, DOI 10.4018/IJACI.2017010103
   Lin J, 2017, IEEE INTERNET THINGS, V4, P1125, DOI 10.1109/JIOT.2017.2683200
   Ling RT, 2006, ICAT 2006: 16TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE - WORSHOPS, PROCEEDINGS, P5
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Makri E, 2018, INT J AMBIENT COMPUT, V9, P34, DOI 10.4018/IJACI.2018100103
   Mhetre NA, 2016, INT J AMBIENT COMPUT, V7, P33, DOI 10.4018/IJACI.2016070102
   Mohamed FK, 2014, ENG SCI TECHNOL, V17, P85, DOI 10.1016/j.jestch.2014.04.001
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   NANDI S, 1994, IEEE T COMPUT, V43, P1346, DOI 10.1109/12.338094
   Nayak P, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P412, DOI 10.1109/ICACCI.2018.8554728
   Neshenko N, 2019, IEEE COMMUN SURV TUT, V21, P2702, DOI 10.1109/COMST.2019.2910750
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Noura H, 2019, MULTIMED TOOLS APPL, V78, P16527, DOI 10.1007/s11042-018-7000-7
   Omoniwa B, 2019, IEEE INTERNET THINGS, V6, P4118, DOI 10.1109/JIOT.2018.2875544
   Panarello A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082575
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Ping P, 2014, SIGNAL PROCESS, V105, P419, DOI 10.1016/j.sigpro.2014.06.020
   Prasithsangaree P, 2003, GLOB TELECOMM CONF, P1445, DOI 10.1109/GLOCOM.2003.1258477
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Sanchez-Avila C, 2001, 35TH ANNUAL 2001 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P229, DOI 10.1109/CCST.2001.962837
   Siap I, 2011, J FRANKLIN I, V348, P1258, DOI 10.1016/j.jfranklin.2010.02.002
   Tong XJ, 2013, NONLINEAR DYNAM, V72, P229, DOI 10.1007/s11071-012-0707-5
   Torres-Huitzil C, 2013, IEEE LAT AMER SYMP
   Uguz S, 2013, IEEE SYS MAN CYBERN, P2945, DOI 10.1109/SMC.2013.502
   von Neumann J., 1966, THEORY SELF REPRODUC
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Xu Y, 2016, IEEE INTERNET THINGS, V3, P285, DOI 10.1109/JIOT.2015.2455555
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Yang YC, 2017, IEEE INTERNET THINGS, V4, P1250, DOI 10.1109/JIOT.2017.2694844
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhou J, 2017, IEEE COMMUN MAG, V55, P26, DOI 10.1109/MCOM.2017.1600363CM
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 72
TC 25
Z9 25
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31529
EP 31567
DI 10.1007/s11042-020-09880-9
EA OCT 2020
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000574376900003
DA 2024-07-18
ER

PT J
AU Goyal, N
   Kumar, N
   Kapil
AF Goyal, Neha
   Kumar, Nitin
   Kapil
TI On solving leaf classification using linear regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear regression; Kernel function; Color to gray-scale conversion;
   Image down-sampling; Image projection
ID FEATURES
AB Plant's conservation is getting close attention nowadays. It requires awareness about ecology among masses. Plant species identification has been proved as a primary step in literature for biodiversity conservation. It is a sequential process from leaf images as input followed by image enhancement algorithms, and feature extraction phase to classification. The complete process of identifying a leaf image requires substantial time. The article focuses on introducing a simpler and computationally inexpensive framework with a performance at par or better as compared to the existing framework. The article covers several findings and results while transforming the proposed framework for plant identification to a parameter specific optimized framework. The findings include optimizing the leaf image dimension, the impact of RGB to grayscale conversion method, and comparative analysis of the proposed framework for classification from images with other frameworks that first extract specific features and then classify. It also represents the whole framework as a regression problem. Further, improvement is incorporated by integrating the benefits of kernel trick in linear regression. Our finding confirms that the framework not only recognizing the leaf images with comparable accuracy but also reduces the computational time significantly to identify leaf images as compared to other frameworks.
C1 [Goyal, Neha; Kumar, Nitin; Kapil] NIT, Kurukshetra, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Goyal, N (corresponding author), NIT, Kurukshetra, Uttarakhand, India.
EM neha.goyal2309@gmail.com; nitin@nituk.ac.in; kapil@nitkkr.ac.in
RI Goyal, Neha/AAF-3497-2022; Goyal, Neha/AFH-8800-2022
OI Goyal, Neha/0000-0002-7016-4663
FU University Grant Commission, India
FX We acknowledge University Grant Commission, India for supporting this
   research by providing fellowship to one of the author, Ms. Neha Goyal.
   We are also thankful to the reviewers for their valuable and
   constructive comments and suggestions for the paper. Their inputs have
   helped us in strengthening the overall quality of the paper.
CR [Anonymous], 2007, 2007 IEEE INT S SIGN
   [Anonymous], 2001, COMPUTER VISION CLAS
   Bagri N., 2015, International Journal of Advanced Science and Technology, V80, P41
   Bruno OM, 2008, INFORM SCIENCES, V178, P2722, DOI 10.1016/j.ins.2008.01.023
   Chen S, 2012, CROSS DISCIPLINARY B, P183
   Corlett Richard T., 2016, Plant Diversity, V38, P10, DOI 10.1016/j.pld.2016.01.001
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dikbas S, 2007, 2007 IEEE INT C IM P, V2
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072
   Ertugrul OF, 2015, INT J BIOMED DATA MI, P1
   Everitt B.S., 1991, APPL MULTIVARIATE DA
   Goettsch B, 2015, NAT PLANTS, V1, DOI [10.1038/NPLANTS.2015.142, 10.1038/nplants.2015.142]
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391
   Ja-Won Seo, 2013, 2013 IEEE INT C IM P
   Jin ZM, 2015, MULTIDIM SYST SIGN P, V26, P869, DOI 10.1007/s11045-014-0295-2
   Kadir Abdul, 2012, Journal of Theoretical and Applied Information Technology, V41, P82
   Kulkarni A.H., 2013, Int J Adv Res Comput Commun Eng, V2, P984
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu QG, 2017, MULTIMED TOOLS APPL, V76, P14055, DOI 10.1007/s11042-016-3748-9
   Milan Sulc, 2014, EUR C COMP VIS
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park J, 2008, J SYST SOFTWARE, V81, P71, DOI 10.1016/j.jss.2007.05.001
   Pearline SA, 2019, J INTELL FUZZY SYST, V36, P1997, DOI 10.3233/JIFS-169911
   Pimm SL, 2015, ANN MO BOT GARD, V100, P170, DOI 10.3417/2012018
   Pornpanomchai C, 2011, THAI HERB LEAF IMAGE
   Silva Pedro FB, 2013, INT C IM AN REC
   Sowmya V, 2017, SIGNAL IMAGE VIDEO P, V11, P129, DOI 10.1007/s11760-016-0911-8
   Tran D-T, 2014, P 5 S INF COMM TECHN
   Tricot C., 1994, CURVES FRACTAL DIMEN
   Turkoglu M, 2019, APPL MATH COMPUT, V352, P1, DOI 10.1016/j.amc.2019.01.054
   Verma M, 2019, 2019 IEEE SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P1, DOI 10.1109/AIKE.2019.00009
   Wäldchen J, 2018, METHODS ECOL EVOL, V9, P2216, DOI 10.1111/2041-210X.13075
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993
   Wäldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z
   Wang B, 2013, J MULTIMED, V8, P4
   Yan J, 2006, INFORM SCIENCES, V176, P2042, DOI 10.1016/j.ins.2005.11.005
   Yigit E, 2019, COMPUT ELECTRON AGR, V156, P369, DOI 10.1016/j.compag.2018.11.036
   Zhang X, 2019, MULTIMED TOOLS APPL, V78, P27463, DOI 10.1007/s11042-019-07846-0
NR 42
TC 6
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4533
EP 4551
DI 10.1007/s11042-020-09899-y
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100002
DA 2024-07-18
ER

PT J
AU Rinaldi, AM
   Russo, C
AF Rinaldi, Antonio M.
   Russo, Cristiano
TI Using a multimedia semantic graph for web document visualization and
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia topic detection; Document classification; Semantic analysis;
   Ontologies; Big data; Deep neural networks; Knowledge graph
ID AGGREGATION; DESCRIPTOR; COLOR; MODEL
AB The synthesis process of document content and its visualization play a basic role in the context of knowledge representation and retrieval. Existing methods for tag-clouds generations are mostly based on text content of documents, others also consider statistical or semantic information to enrich the document summary, while precious information deriving from multimedia content is often neglected. In this paper we present a document summarization and visualization technique based on both statistical and semantic analysis of textual and visual contents. The result of our framework is a Visual Semantic Tag Cloud based on the highlighting of relevant terms in a document using some features (font size, color, etc.) showing the importance of a term compared to other ones. The semantic information is derived from a knowledge base where concepts are represented through several multimedia items. The Visual Semantic Tag Cloud can be used not only to synthesize a document but also to represent a set of documents grouped by categories using a topic detection technique based on textual and visual analysis of multimedia features. Our work aims at demonstrating that with the help of semantic analysis and the combination of textual and visual features it is possible to improve the user knowledge acquisition by means of a synthesized visualization. The whole strategy has been evaluated by means of a ground truth and compared with similar approaches. Experimental results show the effectiveness of our approach, which outperforms state-of-art algorithms in topic detection combining both visual and semantic information.
C1 [Rinaldi, Antonio M.; Russo, Cristiano] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.
   [Rinaldi, Antonio M.] IKNOS LAB Intelligent & Knowledge Syst LUPT, Naples, Italy.
C3 University of Naples Federico II
RP Rinaldi, AM (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.; Rinaldi, AM (corresponding author), IKNOS LAB Intelligent & Knowledge Syst LUPT, Naples, Italy.
EM antoniomaria.rinaldi@unina.it; cristiano.russo@unina.it
RI Rinaldi, Antonio M./O-7452-2019
OI Rinaldi, Antonio M./0000-0001-7003-4781; Russo,
   Cristiano/0000-0002-8732-1733
FU Universit`a degli Studi di Napoli Federico II within the CRUICARE
   Agreement
FX D Open access funding provided by Universit`a degli Studi di Napoli
   Federico II within the CRUICARE Agreement.
CR Adrian A, 2001, LINGUISTICS INTRO LA
   Alguliev RM, 2011, EXPERT SYST APPL, V38, P14514, DOI 10.1016/j.eswa.2011.05.033
   Alguliev RM, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P264, DOI 10.1109/WI.2005.57
   [Anonymous], 2007, Folksonomy
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bohne T, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P185
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Caldarola E. G., 2015, P 4 INT C DAT MAN TE, P362
   Caldarola EG, 2017, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON DATA SCIENCE, TECHNOLOGY AND APPLICATIONS (DATA), P296, DOI 10.5220/0006484102960305
   Caldarola EG, 2018, ADV INTELL SYST, V561, P63, DOI 10.1007/978-3-319-56157-8_4
   Caldarola EG, 2015, 2015 7TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT (IC3K), P104
   Caldarola EG, 2016, IEEE INT CONGR BIG, P34, DOI 10.1109/BigDataCongress.2016.14
   Castano S, 2003, P 1 INT C SEM WEB DA, P218
   Cattuto C, 2007, AI COMMUN, V20, P245
   Chang YC, 2017, SOFT COMPUT, V21, P391, DOI 10.1007/s00500-015-1695-4
   Chatzichristofis S., 2009, Proc. ofthe 6th IASTED International Conference, V134643, page, P064
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chen Q, 2017, NEUROCOMPUTING, V242, P40, DOI 10.1016/j.neucom.2017.02.020
   Chen YX, 2009, LECT NOTES COMPUT SC, V5531, P56
   Danesi Marcel., 1999, Analyzing Cultures: An Introduction and Handbook
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fujimura Ko., 2008, WWW '08, P1087, DOI DOI 10.1145/1367497.1367669
   Gernmell J, 2008, LECT NOTES COMPUT SC, V5182, P196, DOI 10.1007/978-3-540-85836-2_19
   Hammond T, 2005, D LIB MAGAZINE, V2, P1082
   Harkovchuk AE, 2019, P 24 C OP INN ASS FR, P821
   Hassan-Montero Y., 2006, INT C MULTIDISCI PLI, P25, DOI DOI 10.1177/1473871620966638
   Heu JU, 2015, INFORM PROCESS MANAG, V51, P212, DOI 10.1016/j.ipm.2014.06.003
   Houston P, 2013, INSTANT JSOUP
   Hu XH, 2006, ICDM 2006: SIXTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, WORKSHOPS, P19
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   Ike CS, 2020, PATTERN ANAL APPL, V23, P1407, DOI 10.1007/s10044-019-00854-8
   Kaptein R, 2012, EUROHCIR, P67
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Khalid S, 2019, IET INTELL TRANSP SY, V13, P269, DOI 10.1049/iet-its.2018.5223
   Khan H, 2020, NEUROCOMPUTING, V381, P141, DOI 10.1016/j.neucom.2019.10.005
   Khan H, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12432-6
   Nguyen KL, 2016, INT CONF BIG DATA, P223, DOI 10.1109/BIGCOMP.2016.7425917
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Mahajani Abhishek, 2019, Ambient Communications and Computer Systems. RACCCS-2018. Advances in Intelligent Systems and Computing (AISC 904), P339, DOI 10.1007/978-981-13-5934-7_31
   Mahmood Z, 2019, IET INTELL TRANSP SY, V13, P293, DOI 10.1049/iet-its.2018.5021
   Mahmood Z, 2017, KSII T INTERNET INF, V11, P6069, DOI 10.3837/tiis.2017.12.021
   Mathes A, 2010, FOLKSONOMIES COOPERA
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   Mika P, 2007, J WEB SEMANT, V5, P5, DOI 10.1016/j.websem.2006.11.002
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moscato V., 2010, P INT C MAN EM DIG E, P25
   Muhammad N, 2018, PATTERN ANAL APPL, V21, P1013, DOI 10.1007/s10044-017-0617-8
   Navigli R, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P216
   Naz I, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419500556
   Hernández AR, 2019, PROCEDIA COMPUT SCI, V162, P849, DOI 10.1016/j.procs.2019.12.059
   Regelman G., 2006, COLL WEB TAGG WORKSH, P15
   Rinaldi Antonio M., 2015, International Journal of Business Process Integration and Management, V7, P274
   Rinaldi AM, 2018, 16 INT S PERV SYST A
   Rinaldi AM, 2019, INT J INTELL INF TEC, V15, P1, DOI 10.4018/IJIIT.2019070101
   Rinaldi AM, 2018, IEEE INT CONF BIG DA, P2304, DOI 10.1109/BigData.2018.8622613
   Rinaldi AM, 2018, IEEE INT C SEMANT CO, P363, DOI 10.1109/ICSC.2018.00074
   Rinaldi AM, 2014, INFORM SCIENCES, V277, P234, DOI 10.1016/j.ins.2014.02.017
   Rinaldi AM, 2013, IEEE INT C SEMANT CO, P100, DOI 10.1109/ICSC.2013.26
   Rinaldi AM, 2012, INT WORKSHOP DATABAS, P139, DOI 10.1109/DEXA.2012.11
   Rinaldi AM, 2009, ACM T INTERNET TECHN, V9, DOI 10.1145/1552291.1552293
   Russo C, 2019, LECT NOTES COMPUT SC, V11507, P246, DOI 10.1007/978-3-030-20518-8_21
   Sala H.V., 2019, INFORM RETRIEVAL SEM
   Salatino AA, 2019, LECT NOTES COMPUT SC, V11799, P296, DOI 10.1007/978-3-030-30760-8_26
   Salton G, 1997, INFORM PROCESS MANAG, V33, P193, DOI 10.1016/S0306-4573(96)00062-3
   Selvalakshmi B, 2019, CLUSTER COMPUT, V22, P12871, DOI 10.1007/s10586-018-1789-8
   Sinclair J, 2008, J INF SCI, V34, P15, DOI 10.1177/0165551506078083
   Ul Haq M, 2019, KSII T INTERNET INF, V13, P3144, DOI 10.3837/tiis.2019.06.021
   Wei Y, 2012, LECT NOTES COMPUT SC, V7332, P93, DOI 10.1007/978-3-642-31020-1_12
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Xu SH, 2010, AAAI CONF ARTIF INTE, P1461
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang T, 2019, 3RD INTERNATIONAL CONFERENCE ON INNOVATION IN ARTIFICIAL INTELLIGENCE (ICIAI 2019), P39, DOI 10.1145/3319921.3319924
   Zhu Junyan., 2009, Proceedings of 18th International World Wide Web Conference (WWW'09), P1195, DOI DOI 10.1145/1526709.1526925
NR 76
TC 15
Z9 15
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3885
EP 3925
DI 10.1007/s11042-020-09761-1
EA SEP 2020
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572601100005
OA hybrid
DA 2024-07-18
ER

PT J
AU Mandal, PC
   Mukherjee, I
   Chatterji, BN
AF Mandal, Pratap Chandra
   Mukherjee, Imon
   Chatterji, Biswa Nath
TI High capacity reversible and secured data hiding in images using
   interpolation and difference expansion technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Interpolation; Difference expansion;
   Steganography; Steganalysis
ID SCHEME; ALGORITHM
AB Data hiding is a noteworthy research topic in digital technology for years. Reversible data hiding (RDH) technique plays a vital role for confirming security of the digital transmissions. A new 2-layer secure, high capacity reversible data hiding technique has been proposed, using the concept of interpolation based data hiding and difference expansion method. Unlike, state-of-the art interpolation based RDH techniques, the security has been enhanced in the proposed technique by concealing the data into the image pixels in non-sequential manner. This technique offers high-capacity data hiding, by considering the maximum difference between neighboring pixels without compromising on quality of the images. It can embed up to 3.19 bpp in Baboon image which is better than the other existing state-of-the art interpolation based RDH (IRDH) techniques. The proposed technique is sustainable against the series of tests provided by standard StirMark Benchmark 4.0 analysis. It withstands the steganalysis attacks, viz., StegExpose as a measure of security.
C1 [Mandal, Pratap Chandra; Chatterji, Biswa Nath] BP Poddar Inst Management & Technol, Dept Comp Sci & Engn, Kolkata 700052, India.
   [Mandal, Pratap Chandra; Mukherjee, Imon] Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
C3 B. P. Poddar Institute of Management & Technology
RP Mukherjee, I (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
EM pcmandal9@gmail.com; imon@iiitkalyani.ac.in; bnchatterji@gmail.com
RI Mandal, Pratap/AAC-1071-2019; Mandal, Pratap/ABF-8743-2021; Mukherjee,
   Imon/AFP-2409-2022
OI Mandal, Pratap/0000-0003-4777-9288; Mukherjee, Imon/0000-0002-8598-148X
CR Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   [Anonymous], 2009, International Journal of Signal processing, Image processing and pattern
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Boehmm E, 2014, Stegexpose: A Tool for Detecting LSB Steganography
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Das S, 2019, PATTERN RECOGN LETT, V126, P102, DOI 10.1016/j.patrec.2018.06.026
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Images: University of Southern California, 2019, USC SIPI IMAGE DATAB
   Jana B, 2018, MULTIMED TOOLS APPL, V77, P763, DOI 10.1007/s11042-016-4230-4
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Kim C, 2011, COMM COM INF SC, V186, P130
   Lee CF, 2019, SOFT COMPUT, V23, P9719, DOI 10.1007/s00500-018-3537-7
   Lee CF, 2017, MULTIMED TOOLS APPL, V76, P9993, DOI 10.1007/s11042-016-3591-z
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Liu N, 2007, IEEE T MULTIMEDIA, V9, P466, DOI 10.1109/TMM.2006.888005
   Liu WT, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107287
   Lu TC, 2018, SIGNAL PROCESS, V142, P244, DOI 10.1016/j.sigpro.2017.07.025
   Luo JW, 2010, IEEE T ULTRASON FERR, V57, P1347, DOI 10.1109/TUFFC.2010.1554
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Provos N, 2001, TECH REP
   Shaik A, 2019, MULTIMED TOOLS APPL, V78, P9717, DOI 10.1007/s11042-018-6544-x
   Singh AK, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3382772
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Toet A, 2003, PROC SPIE, V5096, P552, DOI 10.1117/12.484886
   Wahed MA, 2019, MULTIMED TOOLS APPL, V78, P10795, DOI 10.1007/s11042-018-6616-y
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang WQ, 2020, MULTIMED TOOLS APPL, V79, P5965, DOI 10.1007/s11042-019-08255-z
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Xu WL, 2016, DISPLAYS, V42, P36, DOI 10.1016/j.displa.2016.03.002
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
NR 41
TC 20
Z9 20
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3623
EP 3644
DI 10.1007/s11042-020-09341-3
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572335600003
DA 2024-07-18
ER

PT J
AU Ouahab, A
   Belbachir, MF
AF Ouahab, Abdelwhab
   Belbachir, Mohamed Faouzi
TI Remote sensing data fusion using fruit fly optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fruit fly; Pan-sharpening; Image fusion; KONOS; Optimization; FOA
ID PAN-SHARPENING METHOD; IMAGE FUSION; ALGORITHM; ENHANCEMENT; MODEL; PCA
AB The image fusion (pan-sharpening) aims to generate a multispectral image with the maximum of spatial details of the panchromatic image and the spectral characteristics of the multispectral images. The generalized intensity-hue-saturation (GIHS) can produce fused images with high spatial details, but the spectral characteristics of the fused images need improvement. This article introduces an adaptive fusion method based on GIHS using the Fruit Fly Optimization Algorithm (FOA) in two stages. First, we suggest to use it to compute the optimal band weights which reduces the large difference between the intensity component and the panchromatic image. Second, we propose to apply the FOA to compute the modulation parameters that estimate the amount of spatial details to be added to the multispectral images. In this regard, an objective function that combines the coefficient of the correlation (CC) with the spatial coefficient of the correlation (SCC) is suggested. This method is tested on Pleiades, IKONOS, and ALSAT-2A images and we compared it with some existing fusion methods. The CC, the Structural Similarity Index (SSIM), The Root Mean Square Error (RMSE), the Quality with No Reference (QNR), the Relative Global Synthesis Error Metric (ERGAS) and the Relative Average Spectral Error (RASE) are used for quantitative analysis. The best values of CC, RMSE, ERGAS, RASE and QNR on all used datasets are given by the proposed method. The quantitative results and the visual analysis demonstrated that the proposed approach outperforms the four comparison methods in terms of spatial and spectral quality.
C1 [Ouahab, Abdelwhab; Belbachir, Mohamed Faouzi] Univ Sci & Technol Oran Mohamed Boudiaf, Lab Signaux Syst & Donnees, BP 1505, Oran 31000, Algeria.
   [Ouahab, Abdelwhab] African Univ Ahmed Draia, Dept Math & Comp Sci, Adrar, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf;
   Universite d'Adrar
RP Ouahab, A (corresponding author), Univ Sci & Technol Oran Mohamed Boudiaf, Lab Signaux Syst & Donnees, BP 1505, Oran 31000, Algeria.; Ouahab, A (corresponding author), African Univ Ahmed Draia, Dept Math & Comp Sci, Adrar, Algeria.
EM ouahab.abdelwhab@univ-usto.dz
OI OUAHAB, Abdelwhab/0000-0003-0648-2947
CR Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   Cetin M, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.045019
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Chen HY, 2012, MULTIMED TOOLS APPL, V60, P495, DOI 10.1007/s11042-011-0820-3
   Cheng M, 2014, IEEE GEOSCI REMOTE S, V11, P293, DOI 10.1109/LGRS.2013.2256875
   Chien CL, 2014, IEEE T GEOSCI REMOTE, V52, P651, DOI 10.1109/TGRS.2013.2243157
   Choi J, 2012, CAN J REMOTE SENS, V38, P109, DOI 10.5589/m12-015
   Choi M, 2006, IEEE T GEOSCI REMOTE, V44, P1672, DOI 10.1109/TGRS.2006.869923
   Cui LG, 2016, KNOWL-BASED SYST, V111, P51, DOI 10.1016/j.knosys.2016.08.007
   El-Mezouar MC, 2011, IEEE T GEOSCI REMOTE, V49, P1590, DOI 10.1109/TGRS.2010.2087029
   Ghahremani M, 2016, IEEE T GEOSCI REMOTE, V54, P2194, DOI 10.1109/TGRS.2015.2497309
   Ghellab AMR, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073552
   Guo X, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717739831
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   Jiang C, 2012, IEEE GEOSCI REMOTE S, V9, P629, DOI 10.1109/LGRS.2011.2177063
   Kim Y, 2011, ETRI J, V33, P497, DOI 10.4218/etrij.11.1610.0042
   Leung Y, 2014, IEEE GEOSCI REMOTE S, V11, P985, DOI 10.1109/LGRS.2013.2284282
   Li ZH, 2009, IEEE T GEOSCI REMOTE, V47, P1480, DOI 10.1109/TGRS.2008.2005639
   Loncan L, 2015, IEEE GEOSC REM SEN M, V3, P27, DOI 10.1109/MGRS.2015.2440094
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Neshat M, 2014, ARTIF INTELL REV, V42, P965, DOI 10.1007/s10462-012-9342-2
   Nie G., 2019, 2019 IEEE INT C COMP, P3283
   Otazu X, 2005, IEEE T GEOSCI REMOTE, V43, P2376, DOI 10.1109/TGRS.2005.856106
   Ouahab A, 2018, ADV MODELLING ANAL B, V61, P113
   Palsson F, 2017, IEEE GEOSCI REMOTE S, V14, P639, DOI 10.1109/LGRS.2017.2668299
   Palsson F, 2015, IEEE T GEOSCI REMOTE, V53, P2652, DOI 10.1109/TGRS.2014.2363477
   Palsson F, 2014, IEEE GEOSCI REMOTE S, V11, P318, DOI 10.1109/LGRS.2013.2257669
   Palubinskas G, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073526
   Pan WT, 2012, KNOWL-BASED SYST, V26, P69, DOI 10.1016/j.knosys.2011.07.001
   Qian XH, 2019, MULTIMED TOOLS APPL, V78, P22099, DOI 10.1007/s11042-019-7537-0
   Saeedi J, 2011, ISPRS J PHOTOGRAMM, V66, P365, DOI 10.1016/j.isprsjprs.2011.01.006
   Salimi L, 2020, MULTIMED TOOLS APPL, V79, P11357, DOI 10.1007/s11042-019-08455-7
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   SHETTIGARA VK, 1992, PHOTOGRAMM ENG REM S, V58, P561
   Te-Ming Tu, 2001, Information Fusion, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Tu T, 2001, INFORM FUSION, V2, P77
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2012, IEEE T GEOSCI REMOTE, V43, P1391
   Xie YX, 2016, MULTIMED TOOLS APPL, V75, P14367, DOI 10.1007/s11042-016-3358-6
   Xu QZ, 2014, IEEE T GEOSCI REMOTE, V52, P7380, DOI 10.1109/TGRS.2014.2311815
   Zhang LP, 2012, IEEE T SYST MAN CY B, V42, P1693, DOI 10.1109/TSMCB.2012.2198810
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhou J, 1998, INT J REMOTE SENS, V19, P743, DOI 10.1080/014311698215973
NR 48
TC 3
Z9 3
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2951
EP 2973
DI 10.1007/s11042-020-09798-2
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570841100008
DA 2024-07-18
ER

PT J
AU Lin, SS
   Le, TNH
   Wu, PY
   Lee, TY
AF Lin, Shih-Syun
   Le, Thi Ngoc Hanh
   Wu, Pang-Yu
   Lee, Tong-Yee
TI Content-and-disparity-aware stereoscopic video stabilization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stabilization; Stereoscopic video; Trajectory; Bezier curve;
   Optimization
AB Filming stereoscopic videos has become easier with the development of science and technology, and such videos now proliferate on the Internet. Meanwhile, video stabilization is an important research topic. Thus, this study presents a method of stabilizing stereoscopic videos with preserving the disparities between objects in the frames. First, the feature points must be tracked and separated into many groups. We posit that the shaky motion is caused not only by translations but also by rotations. Thus, directly smoothing the path will not produce a similar trajectory so that we solve the shakiness of the turning before smoothing the path. To address such shakiness, we initially estimate the rotation angles between two adjacent frames. By determining the angle changes of all the frames, we can find out the preference of rotation in a video. Furthermore, the inconsistent angular velocity can be alleviated and the shakiness of the turning is solved by rotating the frame appropriately. Then, the Bezier curve is utilized to smooth the trajectories. We split a trajectory into a set of subtrajectories and subsequently smooth the latter independently. Unlike previous researches, we split the trajectory according to the feature tracking rate to obtain similar trajectories in the original video path. After making subtrajectories smooth, we merge them to attain a smoothed trajectory. The joint of the two subtrajectories is replaced by their interpolation. Finally, we optimize the smoothness and context preservation to stabilize videos without requiring extensive clipping.
C1 [Lin, Shih-Syun] Natl Taiwan Ocean Univ, Keelung, Taiwan.
   [Le, Thi Ngoc Hanh; Wu, Pang-Yu; Lee, Tong-Yee] Natl Cheng Kung Univ, Tainan, Taiwan.
C3 National Taiwan Ocean University; National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Tainan, Taiwan.
EM linss@mail.ntou.edu.tw; lehanh.msc@gmail.com; bigben59456@gmail.com;
   tonylee@mail.ncku.edu.tw
RI Lin, Shih-Syun/ABD-8570-2020
OI Lin, Shih-Syun/0000-0002-8360-5819
FU Ministry of Science and Technology [MOST-108-2221-E-019-038-MY2,
   MOST-108-2221-E-006-038-MY3, MOST-107-2221-E-006-196-MY3]
FX This research was supported in part by the Ministry of Science and
   Technology (contracts MOST-108-2221-E-019-038-MY2,
   MOST-108-2221-E-006-038-MY3 and MOST-107-2221-E-006-196-MY3) of Taiwan.
CR Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Goldstein A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231824
   Grundmann M, 2013, IEEE INT CONF COMPUT
   Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Guo H, 2016, IEEE IMAGE PROC, P1071, DOI 10.1109/ICIP.2016.7532522
   Guo H, 2016, IEEE T IMAGE PROCESS, V25, P5491, DOI 10.1109/TIP.2016.2607419
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Jia C, 2014, CONF REC ASILOMAR C, P673, DOI 10.1109/ACSSC.2014.7094532
   Lee KY, 2009, IEEE I CONF COMP VIS, P1397
   Lin SS, 2013, IEEE T VIS COMPUT GR, V19, P1677, DOI 10.1109/TVCG.2013.75
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Liu SC, 2012, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2012.6247662
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Morimoto C, 1998, INT CONF ACOUST SPEE, P2789, DOI 10.1109/ICASSP.1998.678102
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Smith BM, 2009, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2009.5459270
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417
   Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11
   Zhang L, 2017, IEEE T CIRC SYST VID, V27, P225, DOI 10.1109/TCSVT.2015.2501941
NR 23
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1545
EP 1564
DI 10.1007/s11042-020-09767-9
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000567642600008
DA 2024-07-18
ER

PT J
AU Xing, QW
   Chen, CY
   Li, ZH
AF Xing, Qiwei
   Chen, Chunyi
   Li, Zhihua
TI Progressive path tracing with bilateral-filtering-based denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Path tracing; Image denoising; Progressive adaptive sampling; Gradient
   feature; Improved bilateral filtering
ID RECONSTRUCTION; NOISE
AB Path tracing can generate realistic images based on virtual 3D scene models, but the images are prone to be noisy. To solve this problem, we developed a novel denoising algorithm framework. Firstly, according to the relative mean square error of the noisy pixels, we introduced a progressive adaptive sampling strategy to optimize the distribution of samples. Next, to enhance the quality of the final reconstructed images, we designed an improved bilateral filtering algorithm with use of the gradient feature to obtain the noise-free images. Experimental results demonstrate that our framework outperforms the state-of-the-art path tracing denoising methods in terms of the visual quality, numerical error , and time cost.
C1 [Xing, Qiwei; Chen, Chunyi; Li, Zhihua] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Peoples R China.
C3 Changchun University of Science & Technology
RP Chen, CY (corresponding author), Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Peoples R China.
EM 673659600@qq.com; chenchunyi@hotmail.com; 814155716@qq.com
FU National Natural Science Foundation of China [U19A2063]; Jilin
   Provincial Science & Technology Development Program of China
   [20170101005JC, 20180519012JH, 20190302113GX]; 13th Five-year Science &
   Technology Research Program of Jilin Provincial Department of Education
   [JJKH20200792KJ]; Jilin provincial industrial innovation funds
   [2016C091]
FX This work was supported partially by the National Natural Science
   Foundation of China under Grant U19A2063, partially by the Jilin
   Provincial Science & Technology Development Program of China under
   Grants 20170101005JC, 20180519012JH and 20190302113GX, partially by the
   13th Five-year Science & Technology Research Program of Jilin Provincial
   Department of Education under Grant JJKH20200792KJ, and partially by
   Jilin provincial industrial innovation funds under Grant 2016C091.
CR [Anonymous], 1987, P 14 ANN C COMP GRAP, DOI [DOI 10.1145/37401.37410, DOI 10.1145/37402.37410]
   [Anonymous], 2017, 2017 IEEE INT C COMM
   Bako S, 2019, COMPUT GRAPH FORUM, V38, P527, DOI 10.1111/cgf.13858
   Bako S, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073703, 10.1145/3072959.3073708]
   Bauszat P, 2015, COMPUT GRAPH FORUM, V34, P597, DOI 10.1111/cgf.12587
   Bitterli B, 2016, COMPUT GRAPH FORUM, V35, P107, DOI 10.1111/cgf.12954
   Bolin M. R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P299, DOI 10.1145/280814.280924
   dos Santos JDB, 2018, VISUAL COMPUT, V34, P765, DOI 10.1007/s00371-018-1521-y
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Cook R. L., 1984, Computers & Graphics, V18, P137
   Dammertz H., 2010, P C HIGH PERF GRAPH, P67, DOI DOI 10.5555/1921479.1921491
   Egan K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531399
   Fascione Luca., 2017, ACM SIGGRAPH 2017 Courses, P1
   Hachisuka T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360632
   Howard RM, 2019, MATH COMPUT APPL, V24, DOI 10.3390/mca24020035
   Kalantari NK, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766977
   Kalantari NK, 2013, COMPUT GRAPH FORUM, V32, P93, DOI 10.1111/cgf.12029
   Keller Alexander, 2015, ACM SIGGRAPH 2015 CO, P1
   Lee M. E., 1985, Computer Graphics, V19, P61, DOI 10.1145/325165.325179
   Li TM, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366213
   Liu Y, 2018, VISUAL COMPUT, V34, P589, DOI 10.1007/s00371-017-1363-z
   MITCHELL DP, 1991, COMP GRAPH, V25, P157, DOI 10.1145/127719.122736
   Moon B, 2014, ACM SIGGRAPH 2014 TA, P14
   Moon B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925936
   Overbeck RS, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618486
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Pharr M., 2016, PHYS BASED RENDERING, P1
   Rousselle F, 2013, COMPUT GRAPH FORUM, V32, P121, DOI 10.1111/cgf.12219
   Rousselle F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366214
   Rousselle F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024193
   Schied C, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3233301
   Schied C, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105770
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2167076.2167083
   Sen Pradeep, 2015, ACM SIGGRAPH COURSES, V7, DOI [10.1145/2776880.2792740, DOI 10.1145/2776880.2792740]
   Soler C., 2009, ACM Transactions on Graphics, V28
   Vogels T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201388
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zwicker M, 2015, COMPUT GRAPH FORUM, V34, P667, DOI 10.1111/cgf.12592
NR 38
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1529
EP 1544
DI 10.1007/s11042-020-09650-7
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000567642600005
DA 2024-07-18
ER

PT J
AU Choudhary, M
   Tiwari, V
   Venkanna, U
AF Choudhary, Meenakshi
   Tiwari, Vivek
   Venkanna, U.
TI CCRNet: a novel data-driven approach to improve cross-domain Iris
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE cross-domain iris recognition; Collaborative Convolutional Residual
   Network; CCRNet; pre-activation; model selection
ID ENSEMBLE
AB In spite of the prominence and robustness of iris recognition systems, iris images acquisition using heterogeneous cameras/sensors, is the prime concern in deploying them for wide-scale applications. The textural qualities of iris samples (images) captured through distinct sensors substantially differ due to the differences in illumination and the underlying hardware that yields intra-class variation within the iris dataset. This paper examines three miscellaneous configurations of convolution and residual blocks to improve cross-domain iris recognition. Further, the finest architecture amongst three is identified by the Friedman test, where the statistical differences in proposed architectures are identified based on the outcomes of Nemeny and Bonferroni-Dunn tests. The quantitative performances of these architectures are perceived on several experiments simulated on two iris datasets; ND-CrossSensor-Iris-2013 and ND-iris-0405. The finest model is referred to as "Collaborative Convolutional Residual Network (CCRNet)" and is further examined on several experiments prepared in similar and cross-domains. Results depict that least two error rates reported by CCRNet are 1.06% and 1.21% that enhances the benchmark for the state of the arts. This is due to fast convergence and rapid weights updation achieved from convolution and residual connections, respectively. It helps in recognizing the micro-patterns existing within the iris region and results in better feature discrimination among large numbers of iris subjects.
C1 [Choudhary, Meenakshi; Tiwari, Vivek; Venkanna, U.] DSPM IIIT Naya Raipur, Dept Comp Sci Engn, Naya Raipur 493661, Chhattisgarh, India.
RP Tiwari, V (corresponding author), DSPM IIIT Naya Raipur, Dept Comp Sci Engn, Naya Raipur 493661, Chhattisgarh, India.
EM vivek@iiitnr.edu.in
RI Choudhary, Meenakshi/AAQ-2100-2021; Choudhary, Meenakshi/AAV-5840-2021
CR Ahmed NU, 2017, PATTERN RECOGN LETT, V91, P11, DOI 10.1016/j.patrec.2017.03.003
   Ahuja K, 2017, PATTERN RECOGN LETT, V91, P17, DOI 10.1016/j.patrec.2017.04.002
   Al-Waisy AS, 2018, PATTERN ANAL APPL, V21, P783, DOI 10.1007/s10044-017-0656-1
   [Anonymous], 2016, Handbook of iris recognition
   [Anonymous], 2009, TECHNICAL REPORT
   Choi I, 2017, PATTERN RECOGN, V61, P417, DOI 10.1016/j.patcog.2016.08.009
   Choudhary M, 2019, FUTURE GENER COMP SY, V101, P1259, DOI 10.1016/j.future.2019.07.003
   Nguyen DT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082601
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Doyle JS, 2015, IEEE ACCESS, V3, P1672, DOI 10.1109/ACCESS.2015.2477470
   Feng J, 2019, COMMUNICATION COMPUT, P123
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Galdi C, 2017, PATTERN RECOGN LETT, V91, P44, DOI 10.1016/j.patrec.2017.01.023
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   Gorodnichy DO, 2019, IET BIOMETRICS, V8, P29, DOI 10.1049/iet-bmt.2018.5105
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   He F, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023005
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hu Y, 2016, PATTERN RECOGN LETT, V82, P242, DOI 10.1016/j.patrec.2015.10.010
   Kuehlkamp A, 2019, IEEE T INF FOREN SEC, V14, P1419, DOI 10.1109/TIFS.2018.2878542
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Miyazawa K, 2008, IEEE T PATTERN ANAL, V30, P1741, DOI 10.1109/TPAMI.2007.70833
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Quinn GW, 2013, NISTIR7949 NIST
   Raghavendra R, 2015, IEEE T INF FOREN SEC, V10, P703, DOI 10.1109/TIFS.2015.2400393
   Rai H, 2014, EXPERT SYST APPL, V41, P588, DOI 10.1016/j.eswa.2013.07.083
   Ramya M, 2017, PATTERN RECOGN LETT, V94, P154, DOI 10.1016/j.patrec.2017.04.009
   Saminathan K., 2015, ICTACT Journal on Soft Computing, V5, P889
   Silva P, 2015, SIBGRAPI, P157, DOI 10.1109/SIBGRAPI.2015.16
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Tan CW, 2013, IEEE T IMAGE PROCESS, V22, P3751, DOI 10.1109/TIP.2013.2260165
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Vezzetti E, 2014, AESTHET PLAST SURG, V38, P796, DOI 10.1007/s00266-014-0334-2
   Wang Z, 2018, IEEE ACCESS, V6, P17905, DOI 10.1109/ACCESS.2018.2812208
   Xiong Xingwang, 2019, INT S BENCHMARKING M, P141
   Zhao ZJ, 2019, PATTERN RECOGN, V93, P546, DOI 10.1016/j.patcog.2019.04.010
NR 41
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32807
EP 32831
DI 10.1007/s11042-020-09286-7
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900006
DA 2024-07-18
ER

PT J
AU Dewi, C
   Chen, RC
   Yu, H
AF Dewi, Christine
   Chen, Rung-Ching
   Yu, Hui
TI Weight analysis for various prohibitory sign detection and recognition
   using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weight analysis; Object detection; Traffic sign recognition; Spatial
   pyramid pooling; Yolo V3
ID VIDEO
AB Traffic sign recognition is meaningful for real-world applications such as self-sufficient driving, traffic surveillance, and driver safety. However, traffic sign recognition is a hard problem because different sizes, illuminations, and noises affect the sign detection and recognition. This work recognizes Taiwan's prohibitory signs using deep learning methods. First, we develop a traffic sign database since there is no such kind of database available in Taiwan. Next, we adopt three different You Only Look Once (Yolo) networks (Yolo A, Yolo B, and Yolo C) and three various Yolo V3 SPP networks (Yolo D, Yolo E, and Yolo F) for prohibitory sign recognition. Finally, we conduct the comparative experiment of Yolo V3 and Yolo V3 SPP with different weights provided by the darknet framework (the best weight, the final weight, and the last weight). Experimental results show that the mean average precision(mAP)observation of all models that the Yolo V3 SPP is better than other models. Yolo D took the optimum average accuracy at 99.0%, followed by Yolo E and Yolo F 98.9%. The accuracy of Yolo V3 SPP is growing within the detection time, but it needs more time to identify the sign.
C1 [Dewi, Christine; Chen, Rung-Ching] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
   [Dewi, Christine] Satya Wacana Christian Univ, Fac Informat Technol, Salatiga, Central Java, Indonesia.
   [Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
C3 Chaoyang University of Technology; Universitas Kristen Satya Wacana;
   University of Portsmouth
RP Chen, RC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM crching@cyut.edu.tw
RI Dewi, Christine/AAL-9605-2021; Yu, Hui/G-1115-2018
OI Dewi, Christine/0000-0002-1284-234X; Yu, Hui/0000-0002-7655-9228
FU Ministry of Science and Technology, Taiwan [MOST-107-2221-E-324 -018
   -MY2, MOST-106-2218-E-324 -002]; Chaoyang University of Technology
   (CYUT); Higher Education Sprout Project, Ministry of Education (MOE),
   Taiwan, under the project name: "The R&D and the cultivation of talent
   for healthenhancement products"
FX This work is supported by the Ministry of Science and Technology,
   Taiwan. The Nos are MOST-107-2221-E-324 -018 -MY2 and
   MOST-106-2218-E-324 -002, Taiwan. This research is also partially
   sponsored by Chaoyang University of Technology (CYUT) and the Higher
   Education Sprout Project, Ministry of Education (MOE), Taiwan, under the
   project name: "The R&D and the cultivation of talent for
   healthenhancement products."
CR [Anonymous], Darknet: Open source neural networks in c
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen HP, 2019, IEEE ACCESS, V7, P157818, DOI 10.1109/ACCESS.2019.2950053
   Chen Q, 2019, CHIN CONTR CONF, P8772, DOI [10.23919/ChiCC.2019.8865153, 10.23919/chicc.2019.8865153]
   Corovic A, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P731
   Creswell A, 2017, GENERATIVE ADVERSARI, P1
   Dewi C., 2020, ICCMS 20
   Dewi C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060889
   Dewi C, 2020, LECT NOTES ARTIF INT, V12034, P285, DOI 10.1007/978-3-030-42058-1_24
   Dewi C, 2019, IEEE SYS MAN CYBERN, P2496, DOI 10.1109/SMC.2019.8913868
   Dewi C, 2019, INT J INNOV COMPUT I, V15, P2027, DOI 10.24507/ijicic.15.06.2027
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu YY, 2019, CHIN CONTR CONF, P8386, DOI [10.23919/ChiCC.2019.8865525, 10.23919/chicc.2019.8865525]
   Hu YL, 2014, IEEE INTELL SYST, V29, P48, DOI 10.1109/MIS.2014.38
   Huang YQ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093079
   Huang ZC, 2020, INFORM SCIENCES, V522, P241, DOI 10.1016/j.ins.2020.02.067
   Kang HW, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105108
   Kim SJ, 2013, 7 INT C INF SEC ASS
   Liao XQ, 2017, J MATER CHEM C, V5, P10001, DOI 10.1039/c7tc03134c
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu CW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111381
   Liu CS, 2019, IEEE ACCESS, V7, P86578, DOI 10.1109/ACCESS.2019.2924947
   Liu JY, 2018, IEEE T EMERG TOP COM, V6, P409, DOI 10.1109/TETC.2016.2577538
   Liu ZG, 2019, IEEE ACCESS, V7, P57120, DOI 10.1109/ACCESS.2019.2913882
   Ma C, 2015, IET C PUBLICATIONS
   Mathias M, 2013, IEEE IJCNN
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Nikonorov A, 2013, P 4 INT WORKSH IM MI
   Ohn-Bar E, 2015, IEEE T INTELL TRANSP, V16, P2511, DOI 10.1109/TITS.2015.2409889
   Philipsen MP, 2015, IEEE INT VEH SYM, P1226, DOI 10.1109/IVS.2015.7225850
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Rahayudi B, 2019, PROCEEDINGS OF 2019 4TH INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY (SIET 2019), P100, DOI [10.1109/SIET48054.2019.8986009, 10.1109/siet48054.2019.8986009]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruta A, 2010, PATTERN RECOGN, V43, P416, DOI 10.1016/j.patcog.2009.05.018
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Stallkamp J., 2011, P INT JOINT C NEUR N
   Timofte R, 2009, 2009 WORKSH APPL COM
   Wang CC, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/4760930
   Wu YQ, 2020, MULTIMED TOOLS APPL, V79, P18201, DOI 10.1007/s11042-020-08722-y
   Xu H, 2020, MULTIMED TOOLS APPL, V79, P11551, DOI 10.1007/s11042-019-08239-z
   Yanliang C., 2019, 2019 INT C TECHN APP, P1
   Yen-Zhang Huang, 2018, BUILDING TRAFFIC SIG
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P1918, DOI 10.1109/TITS.2016.2614548
   Zhu R, 2016, P INT C IM PROC ICIP
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 50
TC 44
Z9 44
U1 146
U2 665
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32897
EP 32915
DI 10.1007/s11042-020-09509-x
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mukherjee, D
   Mondal, R
   Singh, PK
   Sarkar, R
   Bhattacharjee, D
AF Mukherjee, Debadyuti
   Mondal, Riktim
   Singh, Pawan Kumar
   Sarkar, Ram
   Bhattacharjee, Debotosh
TI EnsemConvNet: a deep learning approach for human activity recognition
   using smartphone sensors for healthcare applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; EnsemConvNet; Classifier ensemble;
   Time-series data; Sensor data
AB Human Activity Recognition (HAR) can be defined as the automatic prediction of the regular human activities performed in our day-to-day life, such as walking, running, cooking, performing office work, etc. It is truly beneficial in the field of medical care services, for example, personal health care assistants, old-age care services, maintaining patient records for future help, etc. Input data to a HAR system can be (a) videos or still images capturing human activities, or (b) time-series data of human body movements while performing the activities taken from sensors in the smart devices like accelerometer, gyroscope, etc. In this work, we mainly focus on the second category of the input data. Here, we propose an ensemble of three classification models, namely CNN-Net, Encoded-Net, and CNN-LSTM, which is named as EnsemConvNet. Each of these classification models is built upon simple 1D Convolutional Neural Network (CNN) but differs in terms of the number of dense layers, kernel size used along with other key differences in the architecture. Each model accepts the time series data as a 2D matrix by taking a window of data at a time in order to infer information, which ultimately predicts the type of human activity. Classification outcome of the EnsemConvNet model is decided using various classifier combination methods that include majority voting, sum rule, product rule, and a score fusion approach called adaptive weighted approach. Three benchmark datasets, namely WISDM activity prediction, UniMiB SHAR, MobiAct, are used for evaluating our proposed model. We have compared our EnsemConvNet model with some existing deep learning models such as Multi Headed CNN, hybrid of CNN, and Long Short Term Memory (LSTM) models. The results obtained here establish the supremacy of the EnsemConvNet model over the other mentioned models.
C1 [Mukherjee, Debadyuti; Mondal, Riktim; Sarkar, Ram; Bhattacharjee, Debotosh] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Singh, Pawan Kumar] Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
C3 Jadavpur University; Jadavpur University
RP Singh, PK (corresponding author), Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
EM debadyuti23@gmail.com; riktimrules@gmail.com; pawansingh.ju@gmail.com;
   raamsarkar@gmail.com; debotoshb@hotmail.com
RI Sarkar, Ram/AAX-3822-2020; SINGH, PAWAN KUMAR/E-3408-2013;
   Bhattacharjee, Debotosh/L-8521-2015; Bhattacharjee, Debotosh/Q-4065-2019
OI Sarkar, Ram/0000-0001-8813-4086; SINGH, PAWAN KUMAR/0000-0002-9598-7981;
   Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413
CR Aggarwal JK, 2014, HUMAN ACTIVITY RECOG
   Akhavian R, 2016, AUTOMAT CONSTR, V71, P198, DOI 10.1016/j.autcon.2016.08.015
   [Anonymous], 2013, ESANN
   Barua S, 2011, LECT NOTES COMPUT SC, V7063, P735, DOI 10.1007/978-3-642-24958-7_85
   Bhattacharya S., 2020, P INT C SOFT COMP PA, P10, DOI [10.1007/978-3-030-49345-5_2, DOI 10.1007/978-3-030-49345-5_2]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Casilari E, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071513
   Cook DJ, 2015, WILEY SER PARA DIST, P1
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Ehatisham-ul-Haq M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092043
   Frigo M, 2020, FFTW ADAPTIVE SOFTWA
   Ghosh KK, 2020, MED BIOL ENG COMPUT, V58, P1723, DOI 10.1007/s11517-020-02194-w
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Maekawa T, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1088, DOI 10.1145/2971648.2971721
   Mi C, 2019, REAL TIME RECOGNITIO, P4
   Micucci D, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101101
   Quispe KGM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124354
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Panhwar M, 2017, SMART PHONE BASED FA
   Rish I, 2020, EMPIRICAL STUDY NAIV
   Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247
   Ronneberger O., 2020, U NET CONVOLUTIONAL
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Ruck DW, 1990, FEATURE SELECTION US
   Sadhukhan S., 2020, COMP STUDY DIFFERENT, P35
   Sazonov E., 2011, 2011 Fifth International Conference on Sensing Technology (ICST 2011), P426, DOI 10.1109/ICSensT.2011.6137014
   Shoaib M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040426
   Vaidya JS, 2020, JAMA ONCOL, V6, DOI 10.1001/jamaoncol.2020.0249
   Vavoulas G, 2016, MOBIACT DATASET RECO
   Walse KH, 2016, PERFORMANCE EVALUATI, DOI 10.1145/2905055.2905232
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Xu J, 2019, J PHYS CONF SER, V1267, DOI 10.1088/1742-6596/1267/1/012044
   Xu Y., 2015, SHOCK VIB, V2015, P1
   Zhang K., 2020, UltraNet: A FPGAbased Object Detection for the DAC-SDC 2020
   Zheng ZW, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/6751363
NR 37
TC 58
Z9 59
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31663
EP 31690
DI 10.1007/s11042-020-09537-7
EA AUG 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561718500001
DA 2024-07-18
ER

PT J
AU Verma, OP
   Hooda, H
AF Verma, Om Prakash
   Hooda, Heena
TI A novel intuitionistic fuzzy co-clustering algorithm for brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging; Intuitionistic fuzzy sets; Fuzzy
   co-clustering; Tumor detection
ID MR-IMAGES; SEGMENTATION; TUMOR; FRAMEWORK; SETS
AB Segmentation of Magnetic Resonance Imaging(MRI) Brain images is a very important step in detection of brain tumor. This process is hand operated in labs which is rather an enervating and a long drawn out task and the resultant data so obtained has high degree of erroneity and inconsistency. Hence, automated segmentation systems have become the need of the hour. This paper presents a novel technique to automatically detect brain tumor. Also, segmentation of three main brain tissues is carried out namely white matter, gray matter and cerebrospinal fluid from real time Magnetic Resonance Imaging(MRI) images. The Intuitionistic Fuzzy Set theory is incorporated as it is more suitable for handling uncertainty as compared to fuzzy sets theory. The algorithm is based on the Co-Clustering approach as it offers the advantage of assigning membership functions to both object as well as features. The parameters in the IFCC algorithm are optimized using Particle Swarm Optimization(PSO). The performance of the algorithm is evaluated on the basis of quantitative measures such as match score, accuracy score, dice score and Jaccard's similarity coefficient.
C1 [Verma, Om Prakash] GB Pant Govt Engn Coll, Delhi, India.
   [Hooda, Heena] Delhi Technol Univ, Dept IT, Delhi, India.
C3 Delhi Technological University
RP Hooda, H (corresponding author), Delhi Technol Univ, Dept IT, Delhi, India.
EM opverma.dce@gmail.com; heenahooda@gmail.com
RI Verma, Om/AAD-1007-2019
OI Verma, Om/0000-0002-7421-295X; Hooda, Heena/0000-0003-4465-5546
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   [Anonymous], 2006, P IEEE C ENG MED BIO
   [Anonymous], 2005, ANAL COMPUTATIONAL M
   [Anonymous], 2018, J AMBIENT INTELL HUM, DOI DOI 10.1007/S12652-018-1092-9
   Aparajeeta J, 2016, APPL SOFT COMPUT, V41, P104, DOI 10.1016/j.asoc.2015.12.003
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Benaichouche AN, 2013, DIGIT SIGNAL PROCESS, V23, P1390, DOI 10.1016/j.dsp.2013.07.005
   Bhandarkar SM, 2001, COMP MED SY, P294, DOI 10.1109/CBMS.2001.941735
   Bricq S, 2008, MED IMAGE ANAL, V12, P639, DOI 10.1016/j.media.2008.03.001
   Caldairou B, 2011, PATTERN RECOGN, V44, P1916, DOI 10.1016/j.patcog.2010.06.006
   Chen Y, 2012, IET COMPUT VIS, V6, P610, DOI 10.1049/iet-cvi.2011.0263
   Chen Y, 2016, IET IMAGE PROCESS, V10, P865, DOI 10.1049/iet-ipr.2016.0271
   Deepa AR, 2019, MULTIMED TOOLS APPL, V78, P11799, DOI 10.1007/s11042-018-6731-9
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dubey YK, 2016, BIOCYBERN BIOMED ENG, V36, P413, DOI 10.1016/j.bbe.2016.01.001
   EAGLEN RH, 1985, AM J PHYS ANTHROPOL, V66, P307, DOI 10.1002/ajpa.1330660308
   El-Melegy MT, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-21
   Hanmandlu Madasu, 2013, NEUROCOMPUT, V120
   Hooda H, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1621, DOI 10.1109/ICACCCT.2014.7019383
   Huang MY, 2014, IEEE T BIO-MED ENG, V61, P2633, DOI 10.1109/TBME.2014.2325410
   HYUNG LK, 1994, FUZZY SET SYST, V62, P291, DOI 10.1016/0165-0114(94)90113-9
   Ji Zexuan, 2012, IEEE T INFORM TECHNO, V16
   Kaus MR, 2001, RADIOLOGY, V218, P586, DOI 10.1148/radiology.218.2.r01fe44586
   Kavitha A. R., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P1087, DOI 10.1109/ICCEET.2012.6203809
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Mahmood Q, 2015, IRBM, V36, P185, DOI 10.1016/j.irbm.2015.01.007
   Marian Wahba, 2008, THESIS
   Mayer A, 2009, IEEE T MED IMAGING, V28, P1238, DOI 10.1109/TMI.2009.2013850
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Nakib A, 2009, IMAGE VISION COMPUT, V27, P1343, DOI 10.1016/j.imavis.2008.12.004
   Nambura A, 2017, APPL SOFT COMPUT, V54, P456, DOI 10.1016/j.asoc.2016.08.020
   Namburu A, 2017, IET IMAGE PROCESS, V11, P777, DOI 10.1049/iet-ipr.2016.0891
   Noback C.R., 2005, The Human Nervous System: Structure and Function
   Ortiz A, 2011, ELECTRON LETT, V47, P585, DOI 10.1049/el.2011.0322
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Roy S, 2016, PROCEDIA COMPUT SCI, V85, P362, DOI 10.1016/j.procs.2016.05.244
   Sompong C, 2017, EXPERT SYST APPL, V72, P231, DOI 10.1016/j.eswa.2016.10.064
   Verma H, 2016, APPL SOFT COMPUT, V46, P543, DOI 10.1016/j.asoc.2015.12.022
   Xu ZS, 2007, FUZZY OPTIM DECIS MA, V6, P109, DOI 10.1007/s10700-007-9004-z
   YAGER RR, 1979, INT J GEN SYST, V5, P221, DOI 10.1080/03081077908547452
   Yu J, 2005, PLOS BIOL, V3, P266, DOI 10.1371/journal.pbio.0030038
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 44
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31517
EP 31540
DI 10.1007/s11042-020-09320-8
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561518100004
DA 2024-07-18
ER

PT J
AU Cheng, QR
   Gu, XD
AF Cheng, Qingrong
   Gu, Xiaodong
TI Deep attentional fine-grained similarity network with adversarial
   learning for cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention mechanism; Cross-modal retrieval; Bidirectional LSTM;
   Fine-grained similarity
AB People have witnessed the swift development of multimedia devices and multimedia technologies in recent years. How to catch interesting and highly relevant information from the magnanimous multimedia data becomes an urgent and challenging matter. To obtain more accurate retrieval results, researchers naturally think of using more fine-grained features to evaluate the similarity among multimedia samples. In this paper, we propose aDeep Attentional Fine-grained Similarity Network(DAFSN) for cross-modal retrieval, which is optimized in an adversarial learning manner. The DAFSN model consists of two subnetworks, attentional fine-grained similarity network for aligned representation learning and modal discriminative network. The front subnetwork adopts Bi-directional Long Short-Term Memory (LSTM) and pre-trained Inception-v3 model to extract text features and image features. In aligned representation learning, we consider not only the sentence-level pair-matching constraint but also the fine-grained similarity between word-level features of text description and sub-regional features of an image. The modal discriminative network aims to minimize the "heterogeneity gap" between text features and image features in an adversarial manner. We do experiments on several widely used datasets to verify the performance of the proposed DAFSN. The experimental results show that the DAFSN obtains better retrieval results based on the MAP metric. Besides, the result analyses and visual comparisons are presented in the experimental section.
C1 [Cheng, Qingrong; Gu, Xiaodong] Fudan Univ, Dept Elect Engn, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Gu, XD (corresponding author), Fudan Univ, Dept Elect Engn, Shanghai 200433, Peoples R China.
EM xdgu@fudan.edu.cn
OI Cheng, Qingrong/0000-0001-6631-1504
FU National Natural Science Foundation of China [61771145, 61371148]
FX This work is supported by National Natural Science Foundation of China
   under grants 61771145 and 61371148.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Andrew Galen, 2010, INT C MACH LEARN, P3408
   Bellogín A, 2013, INFORM RETRIEVAL, V16, P697, DOI 10.1007/s10791-012-9214-z
   Chekalina V, 2019, EPJ WEB CONF, V214, DOI 10.1051/epjconf/201921402034
   Choi H, 2018, NEUROCOMPUTING, V284, P171, DOI 10.1016/j.neucom.2018.01.007
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   He YH, 2016, IEEE T MULTIMEDIA, V18, P1363, DOI 10.1109/TMM.2016.2558463
   Hua Y, 2016, IEEE T MULTIMEDIA, V18, P1201, DOI 10.1109/TMM.2016.2535864
   Huang X, 2017, 26 INT JOINT C ART I, DOI [10.24963/ijcai.2017/263, DOI 10.24963/IJCAI.2017/263]
   Huang X, 2020, IEEE T CYBERNETICS, V50, P1047, DOI 10.1109/TCYB.2018.2879846
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Lee KF, 2018, 2018 IEEE PHOTONICS SOCIETY SUMMER TOPICAL MEETING SERIES (SUM), P201, DOI 10.1109/PHOSST.2018.8456773
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Ma XF, 2020, IEEE T ULTRASON FERR, V67, P1462, DOI 10.1109/TUFFC.2020.2972307
   Mandal D, 2017, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2017.282
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Ou WH, 2020, MULTIMED TOOLS APPL, V79, P14733, DOI 10.1007/s11042-019-7343-8
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shang F, 2019, NEUROCOMPUTING, V355, P93, DOI 10.1016/j.neucom.2019.04.041
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava Neelam., 2012, The Postcolonial Gramsci, P1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tian D, 2018, J INFORM HIDING MULT, V9
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Wu Y, 2017, PROC CVPR IEEE, P3984, DOI 10.1109/CVPR.2017.424
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang Q, 2018, J MACH LEARN RES, V18, P1
   Zhang X, 2018, LECT NOTES COMPUT SC, V11219, P614, DOI 10.1007/978-3-030-01267-0_36
NR 48
TC 5
Z9 6
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31401
EP 31428
DI 10.1007/s11042-020-09450-z
EA AUG 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561259400004
DA 2024-07-18
ER

PT J
AU Din, S
   Paul, A
   Ahmad, A
AF Din, Sadia
   Paul, Anand
   Ahmad, Awais
TI RETRACTED: Lightweight deep dense Demosaicking and Denoising using
   convolutional neural networks (Retracted Article)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE CNN; Color filter array; Demosaicking; Denoising
ID FILTER ARRAY INTERPOLATION; IMAGE DEMOSAICKING; COLOR DEMOSAICKING;
   SELF-SIMILARITY; DESIGN
AB A single sensor camera uses Color Filter Array (CFA) to capture single-color information at each pixel. Thus, to estimate the missing color samples and then to reconstruct an original image is known as CFA interpolation or demosaicking. Despite remarkable improvements made in the last decade, a fundamental issue remains to be addressed, i.e., how to assure the visual quality of an image in the presence of noise. Hence, the CFA images without denoising lead to the demosaicking artifacts that eventually reduce the image quality. Therefore, based on the aforementioned constraints, the paper presents a novel approach for demosaicking and denoising based on the convolutional neural network (CNN). The proposed technique is using CNN, which consists of four phases. In the first stage, the picture is sorted out. In stage-II, the demosaicking is performed utilizing the profound thick convolutional neural system, which gives us a demosaicked picture. In the stage-III, denoising performs and pass this picture to the last stage. At last, in the stage-IV, the picture goes to the last post-preparing stage delivering a better quality high-resolution image. To test the feasibility of the proposed scheme, Python language is utilized. The proposed conspire beats the few existing strategies regarding throughput delay, inactivity, precision.
C1 [Din, Sadia; Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
   [Ahmad, Awais] Univ Milan, Dipartimento Informat, Milan, Italy.
C3 Kyungpook National University; University of Milan
RP Paul, A (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
EM saadia.deen@gmail.com; paul.editor@gmail.com; awais.ahmad@unimi.it
RI Paul, Anand/V-6724-2017
OI Paul, Anand/0000-0002-0737-2021; Paul, Anand/0000-0003-3115-2325
FU BK21 Plus project (SW Human Resource Development Program for Supporting
   Smart Life) - Ministry of Education, School of Computer Science and
   Engineering, Kyungpook National University, Korea [21A20131600005]
FX This work is supported by BK21 Plus project (SW Human Resource
   Development Program for Supporting Smart Life) funded by the Ministry of
   Education, School of Computer Science and Engineering, Kyungpook
   National University, Korea (21A20131600005).
CR Adams JE, 1997, P SOC PHOTO-OPT INS, V3028, P117, DOI 10.1117/12.270338
   Alleysson D, 2005, IEEE T IMAGE PROCESS, V14, P439, DOI 10.1109/TIP.2004.841200
   [Anonymous], 2018, MTAP
   [Anonymous], 2018, JOINT DEMOSAICING DE
   Buades A, 2009, IEEE T IMAGE PROCESS, V18, P1192, DOI 10.1109/TIP.2009.2017171
   Chang E, 1999, P SOC PHOTO-OPT INS, V3650, P36, DOI 10.1117/12.342861
   Chang K, 2015, SIGNAL PROCESS-IMAGE, V39, P264, DOI 10.1016/j.image.2015.10.003
   COK DR, 1994, ICPS '94: THE PHYSICS AND CHEMISTRY OF IMAGING SYSTEMS - IS&T'S 47TH ANNUAL CONFERENCE, VOLS I AND II, P380
   Duran J, 2014, IEEE T IMAGE PROCESS, V23, P4031, DOI 10.1109/TIP.2014.2341928
   Ehrhardt MJ, 2014, IEEE T IMAGE PROCESS, V23, P9, DOI 10.1109/TIP.2013.2277775
   Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399
   Gharbi M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982399
   Go J, 2000, IEEE T CONSUM ELECTR, V46, P610, DOI 10.1109/30.883419
   Go J, 2000, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - 2000 DIGEST OF TECHNICAL PAPERS, P176, DOI 10.1109/ICCE.2000.854568
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   He FL, 2012, IEEE IMAGE PROC, P2765
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heide F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661260
   Henz B, 2018, COMPUT GRAPH FORUM, V37, P389, DOI 10.1111/cgf.13370
   Hirakawa K, 2007, INT CONF ACOUST SPEE, P597
   Hirakawa K, 2006, IEEE T IMAGE PROCESS, V15, P2146, DOI 10.1109/TIP.2006.875241
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Kapah O, 2000, P SOC PHOTO-OPT INS, V3962, P112, DOI 10.1117/12.382904
   Khashabi D, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2359774
   Koh CC, 2003, IEEE T CONSUM ELECTR, V49, P1448, DOI 10.1109/TCE.2003.1261253
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   Lukac R, 2006, ADV IMAG ELECT PHYS, V140, P187, DOI 10.1016/S1076-5670(05)40004-X
   Mizutani J, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P474, DOI 10.1109/VCIP.2014.7051609
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Paliy D, 2007, P SPIE, V6497
   Paliy D, 2007, INT J IMAG SYST TECH, V17, P105, DOI 10.1002/ima.20109
   Ramanath R, 2003, J ELECTRON IMAGING, V12, P633, DOI 10.1117/1.1606459
   Ramanath R, 2002, J ELECTRON IMAGING, V11, P306, DOI 10.1117/1.1484495
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sun J, 2013, IEEE T IMAGE PROCESS, V22, P402, DOI 10.1109/TIP.2012.2208981
   Tan DS, 2018, IEEE T IMAGE PROCESS, V27, P2408, DOI 10.1109/TIP.2018.2803341
   Tan HL, 2017, IEEE IMAGE PROC, P2951, DOI 10.1109/ICIP.2017.8296823
   Trussell HJ, 2002, IEEE T IMAGE PROCESS, V11, P485, DOI 10.1109/TIP.2002.999681
   Wang YQ, 2014, IEEE IMAGE PROC, P1852, DOI 10.1109/ICIP.2014.7025371
   Wu XL, 2003, IEEE IMAGE PROC, P477
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xin Li LZ, 2008, IMAGE DEMOSAICING SY, V6822, P15
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2005, IEEE T IMAGE PROCESS, V14, P2167, DOI 10.1109/TIP.2005.857260
   Zhang L, 2007, IEEE T IMAGE PROCESS, V16, P2184, DOI 10.1109/TIP.2007.901807
   [张黎明 ZHANG Liming], 2011, [生态环境学报, Ecology and Environmental Sciences], V20, P1
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang X, 2014 SPEECH SIGN PRO, V2014, P474
NR 51
TC 4
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34385
EP 34405
DI 10.1007/s11042-020-08908-4
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000559430400007
DA 2024-07-18
ER

PT J
AU Bal, A
   Banerjee, M
   Chaki, R
   Sharma, P
AF Bal, Abhishek
   Banerjee, Minakshi
   Chaki, Rituparna
   Sharma, Punit
TI An efficient method for PET image denoising by combining multi-scale
   transform and non-local means
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PET; Denoising; Wavelet; Curvelet; Non-local means; Residual image
ID NOISE; RECONSTRUCTION; RESOLUTION; REDUCTION; CURVELETS
AB The diagnosis of dementia, particularly in the early stages is very much helpful with Positron emission tomography (PET) image processing. The most important challenges in PET image processing are noise removal and region of interests (ROIs) segmentation. Although denoising and segmentation are performed independently, but the performance of the denoising process significantly affects the performance of the segmentation process. Due to the low signals to noise ratio and low contrast, PET image denoising is a challenging task. Individual wavelet, curvelet and non-local means (NLM) based methods are not well suited to handle both isotropic (smooth details) and anisotropic (edges and curves) features due to its restricted abilities. To address these issues, the present work proposes an efficient denoising framework for reducing the noise level of brain PET images based on the combination of multi-scale transform (wavelet and curvelet) and tree clustering non-local means (TNLM). The main objective of the proposed method is to extract the isotropic features from a noisy smooth PET image using tree clustering based non-local means (TNLM). Then curvelet-based denoising is applied to the residual image to extract the anisotropic features such as edges and curves. Finally, the extracted anisotropic features are inserted back into the isotropic features to obtain an estimated denoised image. Simulated phantom and clinical PET datasets have been used in this proposed work for testing and measuring the performance in the medical applications, such as gray matter segmentation and precise tumor region identification without any interaction with other structural images like MRI or CT. The results in the experimental section show that the proposed denoising method has obtained better performance than existing wavelet, curvelet, wavelet-curvelet, non-local means (NLM) and deep learning methods based on the preservation of the edges. Qualitatively, a notable gain is achieved in the proposed denoised PET images in terms of contrast enhancement than other existing denoising methods.
C1 [Bal, Abhishek; Chaki, Rituparna] Univ Calcutta, AK Choudhury Sch Informat Technol, Kolkata, India.
   [Banerjee, Minakshi] RCC Inst Informat Technol, Kolkata, India.
   [Sharma, Punit] Apollo Gleneagles Hosp, Kolkata, India.
C3 University of Calcutta; RCC Institute of Information Technology (RCCIIT)
RP Bal, A (corresponding author), Univ Calcutta, AK Choudhury Sch Informat Technol, Kolkata, India.
EM abhisheknew1991@gmail.com
OI Bal, Abhishek/0000-0002-6249-4662
FU Board of Research in Nuclear Sciences (BRNS), DAE, Government of India
   [34/14/13/2016-BRNS/34044]
FX This research work was supported by the Board of Research in Nuclear
   Sciences (BRNS), DAE, Government of India, under the Reference No.
   34/14/13/2016-BRNS/34044. Sincere gratitude to Dr. Punit Sharma, MD at
   Apollo Gleneagles Hospital, Kolkata, India for providing the clinical
   PET brain datasets and valuable comments throughout this work. The
   authors would like to thank Dr. Haseeb Hassan, MD, DM at Rabindranath
   Tagore International Institute of Cardiac Sciences, Kolkata, India, and
   Dr. Arindam Chatterjee, MD, at Variable Energy Cyclotron Centre (VECC),
   Kolkata, India for their helpful comments. The authors would like to
   thank the referees for providing their very valuable comments on the
   original version of the manuscript.
CR Alessio AM, 2006, MED PHYS, V33, P4095, DOI 10.1118/1.2358198
   Ali SH, 2011, ADV EXP MED BIOL, V696, P471, DOI 10.1007/978-1-4419-7046-6_47
   AlZubi S, 2011, INT J BIOMED IMAGING, V2011, DOI 10.1155/2011/136034
   [Anonymous], 2011, ROUGH FUZZY PATTERN
   Bal Abhishek, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P359, DOI 10.1007/978-981-13-7403-6_33
   Bal A, 2018, J KING SAUD U COMPUT
   Bal A, 2019, MED BIOL ENG COMPUT, V57, P2567, DOI 10.1007/s11517-019-02014-w
   Bal A, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS, MATERIALS ENGINEERING & NANO-TECHNOLOGY (IEMENTECH), P68
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Ben Said A, 2016, DIGIT SIGNAL PROCESS, V58, P115, DOI 10.1016/j.dsp.2016.07.017
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai T., 2001, SANKHYA SER B, V63, P127
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chang SG, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P535, DOI 10.1109/ICIP.1998.723556
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chen GY, 2005, INTEGR COMPUT-AID E, V12, P99
   Christian BT, 2010, J NUCL MED, V51, P1147, DOI 10.2967/jnumed.109.073999
   Cui JN, 2019, EUR J NUCL MED MOL I, V46, P2780, DOI 10.1007/s00259-019-04468-4
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Dutta Joyita, 2013, PLoS One, V8, pe81390, DOI 10.1371/journal.pone.0081390
   Ellis S, 2018, IEEE T RADIAT PLASMA, V2, P499, DOI 10.1109/TRPMS.2018.2856581
   Gong K, 2019, IEEE T RADIAT PLASMA, V3, P153, DOI 10.1109/TRPMS.2018.2877644
   Green G. C., 2005, WAVELET BASED DENOIS
   Huerga C, 2017, PHYS MED BIOL, V62, P633, DOI 10.1088/1361-6560/62/2/633
   Kekre HB, 2010, ENTROPY, V1, P2
   Kervrann C, 2007, LECT NOTES COMPUT SC, V4485, P520
   Le Pogam A, 2013, MED IMAGE ANAL, V17, P877, DOI 10.1016/j.media.2013.05.005
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Mejia JM, 2014, IEEE T MED IMAGING, V33, P2010, DOI 10.1109/TMI.2014.2329702
   Mohideen SK, 2008, INT J COMPUT SCI NET, V8, P213
   Mohl B, 2003, J ACOUST SOC AM, V114, P1143, DOI 10.1121/1.1586258
   Nguyen VG, 2010, IEEE NUCL SCI CONF R, P3273, DOI 10.1109/NSSMIC.2010.5874410
   Om H., 2012, J. Signal Inf. Process, V3, P17686, DOI [DOI 10.4236/JSIP.2012.31014, 10.4236/jsip.2012.31014]
   Peter DJ, 2010, J COMPUT SCI TECH-CH, V25, P623, DOI 10.1007/s11390-010-9351-z
   Qi JY, 2000, IEEE T MED IMAGING, V19, P493, DOI 10.1109/42.870259
   Qi JY, 1999, IEEE T MED IMAGING, V18, P293, DOI 10.1109/42.768839
   Ridgelets EJC, 1998, THESIS
   Shalchian B, 2009, J NUCL MED TECHNOL, V37, P223, DOI 10.2967/jnmt.109.067454
   Shidahara M, 2007, ANN NUCL MED, V21, P379, DOI 10.1007/s12149-007-0044-9
   Shih YY, 2005, COMPUT MED IMAG GRAP, V29, P297, DOI 10.1016/j.compmedimag.2004.12.002
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Starck JL., 2010, SPARSE IMAGE SIGNAL
   Taswell C, 2000, COMPUT SCI ENG, V2, P12, DOI 10.1109/5992.841791
   Turkheimer FE, 2000, J CEREBR BLOOD F MET, V20, P879, DOI 10.1097/00004647-200005000-00015
   Wang GB, 2015, IEEE T MED IMAGING, V34, P61, DOI 10.1109/TMI.2014.2343916
   Wink AM, 2004, IEEE T MED IMAGING, V23, P374, DOI 10.1109/TMI.2004.824234
   Xu ZY, 2014, LECT NOTES COMPUT SC, V8673, P698, DOI 10.1007/978-3-319-10404-1_87
   Yang HY, 2012, J VIS COMMUN IMAGE R, V23, P1095, DOI 10.1016/j.jvcir.2012.07.007
NR 53
TC 12
Z9 12
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29087
EP 29120
DI 10.1007/s11042-020-08936-0
EA AUG 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557123500001
DA 2024-07-18
ER

PT J
AU Zhou, CY
   Huang, J
   Yang, F
   Liu, YQ
AF Zhou, Chenyi
   Huang, Jing
   Yang, Feng
   Liu, Yaqin
TI A hybrid fusion model of iris, palm vein and finger vein for
   multi-biometric recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal biometrics; Feature fusion; Decision fusion; Weighting
   factor; DCA
ID DECISION-LEVEL FUSION; FACE; CLASSIFIER; STRATEGY; SCALE; EAR; ECG
AB Biometric system has been widely adopted for human verification or identification, so inherently it requires the characteristics like high security, accuracy and acceptability. However, most of existing unimodal biometric systems provide low-middle security and are vulnerable to attacks. Therefore, multimodal biometric system fuses information from multiple modalities to break these limitations. This paper presents a novel hybrid fusion model for a multimodal biometric system. The hybrid fusion model includes an improved feature fusion algorithm and a novel weighting vote strategy. It captures canonical characteristics with multi-set structure and utilizes score distribution information to help guiding decision-making. The system was examined on databases from CASIA, PolyU and SDU respectively, which provided high precision and strong robustness over previous work. Experimental results showed that the proposed approach achieved an average accuracy of 99.33%, which outperformed other fusion strategies in multimodal biometric systems.
C1 [Zhou, Chenyi; Huang, Jing; Yang, Feng; Liu, Yaqin] Southern Med Univ, Sch Biomed Engn, Guangdong Prov Key Lab Med Image Proc, Guangzhou, Guangdong, Peoples R China.
C3 Southern Medical University - China
RP Huang, J (corresponding author), Southern Med Univ, Sch Biomed Engn, Guangdong Prov Key Lab Med Image Proc, Guangzhou, Guangdong, Peoples R China.
EM jhuangyg@smu.edu.cn
RI CHEN, AN/KFT-3370-2024
FU National Natural Science Foundation of China (NSFC) [61771233,
   81000642]; Science and Technology Planning Project of Guangdong
   Province, China [2013B090500104]
FX The authors would like to thank Prof. M. Haghighat for providing his
   source code to implement [15]. We would also want to express thanks to
   Chinese Academy of Sciences for sharing CASIAIrisV4 Database [39], Hong
   Kong Poly University for sharing their database [40] and Shandong
   University for sharing SDUMLA-HMT Database [44]. This study is partially
   financed by the National Natural Science Foundation of China (NSFC:
   61771233 and 81000642), Science and Technology Planning Project of
   Guangdong Province, China (Grant no. 2013B090500104).
CR Ahmad MI, 2016, NEUROCOMPUTING, V177, P49, DOI 10.1016/j.neucom.2015.11.003
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Al-Maadeed S, 2016, PATTERN RECOGN, V52, P238, DOI 10.1016/j.patcog.2015.09.031
   Al-Tayyan A, 2017, IMAGE VISION COMPUT, V61, P54, DOI 10.1016/j.imavis.2017.02.004
   Al-Waisy AS, 2017, ANAL APPL, V21, P1
   Chen ZJ, 2017, IEEE T CYBERNETICS, V47, P3706, DOI 10.1109/TCYB.2016.2577718
   Cui F., 2011, Journal of Computational Information Systems, V7, P5723
   DASS SC, 2005, AUDIO VIDEO BASED BI
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Gopal Smriti S, 2017, ARAB J SCI ENG, V43, P1
   Gopal Smriti S, 2016, APPL SOFT COMPUTING
   Grover J, 2015, APPL SOFT COMPUT, V31, P1, DOI 10.1016/j.asoc.2015.02.001
   Guan XD, 2017, IEEE T GEOSCI REMOTE, V55, P6989, DOI 10.1109/TGRS.2017.2737780
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   Hamza R., 2019, INFORM SCI
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295, DOI 10.1109/34.735803
   Jeng R, 2016, IETE TECH REV, V34, P1
   Jing XY, 2007, PATTERN RECOGN, V40, P3209, DOI 10.1016/j.patcog.2007.01.034
   Kabir W, 2018, IEEE T INF FOREN SEC, V13, P1989, DOI 10.1109/TIFS.2018.2807790
   Khellat-Kihel S, 2016, APPL SOFT COMPUT, V42, P439, DOI 10.1016/j.asoc.2016.02.008
   Kittler J, 2003, IEEE T PATTERN ANAL, V25, P110, DOI 10.1109/TPAMI.2003.1159950
   Kumar A, 2011, IEEE T SYST MAN CY C, V41, P743, DOI 10.1109/TSMCC.2010.2089516
   Modak SKS, 2019, INFORM FUSION, V49, P174, DOI 10.1016/j.inffus.2018.11.018
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011
   Pinar AJ, 2017, IEEE T FUZZY SYST, V25, P1403, DOI 10.1109/TFUZZ.2016.2633372
   Qiu J, 2019, COMPUT SECUR, V82, P1, DOI 10.1016/j.cose.2018.12.003
   Regouid M, 2019, MULTIMED TOOLS APPL, V78, P22509, DOI 10.1007/s11042-019-7467-x
   Riad K, 2019, IEEE ACCESS, V7, P86384, DOI 10.1109/ACCESS.2019.2926354
   Ribaric S, 2005, IEEE T PATTERN ANAL, V27, P1698, DOI 10.1109/TPAMI.2005.209
   Sinha A, 2008, NEUROCOMPUTING, V71, P2650, DOI 10.1016/j.neucom.2007.06.016
   Snelick R, 2005, IEEE T PATTERN ANAL, V27, P450, DOI 10.1109/TPAMI.2005.57
   Su K, 2019, NEUROCOMPUTING, V332, P111, DOI 10.1016/j.neucom.2018.12.015
   Sun B, 2016, J MULTIMODAL USER IN, V10, P125, DOI 10.1007/s12193-015-0203-6
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Tao Q, 2009, PATTERN RECOGN, V42, P823, DOI 10.1016/j.patcog.2008.09.036
   Toygar Ö, 2018, SIGNAL IMAGE VIDEO P, V12, P1157, DOI 10.1007/s11760-018-1263-3
   Walia GS, 2019, EXPERT SYST APPL, V116, P364, DOI 10.1016/j.eswa.2018.08.036
   Wild P, 2016, PATTERN RECOGN, V50, P17, DOI 10.1016/j.patcog.2015.08.007
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xin Y, 2018, IEEE ACCESS, V6, P21418, DOI 10.1109/ACCESS.2018.2815540
   Yan XK, 2015, NEUROCOMPUTING, V151, P798, DOI 10.1016/j.neucom.2014.10.019
   Yang GP, 2012, SENSORS-BASEL, V12, P1738, DOI 10.3390/s120201738
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang J, 2002, PATTERN RECOGN, V35, P295, DOI 10.1016/S0031-3203(01)00152-2
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Yang J, 2017, NEURAL PROCESS LETT, V46, P521, DOI 10.1007/s11063-017-9600-z
   Yang L, 2018, IEEE T CIRC SYST VID, V28, P1892, DOI 10.1109/TCSVT.2017.2684833
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Yao YF, 2007, NEUROCOMPUTING, V70, P1582, DOI 10.1016/j.neucom.2006.08.009
   You XG, 2016, IEEE T IMAGE PROCESS, V25, P4782, DOI 10.1109/TIP.2016.2598653
   You XG, 2015, IEEE T NEUR NET LEAR, V26, P2760, DOI 10.1109/TNNLS.2015.2393886
   You XG, 2014, IEEE T IMAGE PROCESS, V23, P3203, DOI 10.1109/TIP.2014.2327805
   Zhao YR, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND COMMUNICATION ENGINEERING (ICTCE 2018), P154, DOI [10.1145/3291842.3291895, 10.1016/j.patcog.2018.01.012]
NR 54
TC 16
Z9 16
U1 4
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29021
EP 29042
DI 10.1007/s11042-020-08914-6
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557319900004
DA 2024-07-18
ER

PT J
AU Alwan, HB
   Ku-Mahamud, KR
AF Alwan, Hiba Basim
   Ku-Mahamud, Ku Ruhana
TI Cancellable face template algorithm based on speeded-up robust features
   and winner-takes-all
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Speeded-up robust feature; Winner-takes-all; Hash
   function; Cancellable biometric
ID SURF; FINGERPRINT; DESCRIPTOR; GENERATION; BIOMETRICS; SEGMENTATION;
   REGISTRATION; RECOGNITION; INVARIANT; DETECTOR
AB Features such as face, fingerprint, and iris imprints have been used for authentication in biometric system. The toughest feature amongst these is the face. Extracting a region with the most potential face features from an image for biometric identification followed by illumination enhancement is a commonly used method. However, the region of interest extraction followed by illumination enhancement is sensitive to image face feature displacement, skewed image, and bad illumination. This research presents a cancellable face image algorithm built upon the speeded-up robust features method to extract and select features. A speeded-up robust feature approach is utilised for the image's features extraction, while Winner-Takes-All hashing is utilised for match-seeking. Finally, the features vectors are projected by utilising a random form of binary orthogonal matrice. Experiments were conducted on Yale and ORL datasets which provide grayscale images of sizes 168 x 192 and 112 x 92 pixels, respectively. The execution of the proposed algorithm was measured against several algorithms using equal error rate metric. It is found that the proposed algorithm produced an acceptable performance which indicates that this algorithm can be used in biometric security applications.
C1 [Alwan, Hiba Basim] Minist Finance, Natl Board Pens, Ctr Informat & Comp Syst, Baghdad, Iraq.
   [Ku-Mahamud, Ku Ruhana] Univ Utara Malaysia, Sch Comp, Sintok 06010, Kedah, Malaysia.
C3 Universiti Utara Malaysia
RP Alwan, HB (corresponding author), Minist Finance, Natl Board Pens, Ctr Informat & Comp Syst, Baghdad, Iraq.
EM hiba81basim@yahoo.com; ruhana@uum.edu.my
RI Mahamud, Ku Ruhana Ku/F-3873-2010; Basim Alwan Hussain Al-Dulaimi ,
   Hiba/V-5174-2019
OI Basim Alwan Hussain Al-Dulaimi , Hiba/0000-0003-4011-3328; ku-mahamud,
   ku ruhana/0000-0001-5451-0514
FU Ministry of Higher Education Malaysia under the Fundamental Research
   Grant Scheme [12490]
FX This work was supported by the Ministry of Higher Education Malaysia
   under the Fundamental Research Grant Scheme [grant number 12490].
CR Alam B, 2018, J NETW COMPUT APPL, V115, P20, DOI 10.1016/j.jnca.2018.04.013
   [Anonymous], 2016, INDIAN J SCI TECHNOL, DOI [DOI 10.17485/ijst/2016/v9i20/89786, 10.17485/ijst/2016]
   Barman S, 2017, COMPUT ELECTR ENG, V64, P65, DOI 10.1016/j.compeleceng.2016.11.017
   Chee KY, 2018, PATTERN RECOGN, V76, P273, DOI 10.1016/j.patcog.2017.10.041
   Cherifi F., 2010, IGI Global Disseminator of Knowledge, P1
   Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237
   Ding WP, 2018, EXPERT SYST APPL, V101, P243, DOI 10.1016/j.eswa.2018.01.053
   Dwivedi R, 2017, COMPUT SECUR, V65, P373, DOI 10.1016/j.cose.2016.10.004
   Favorskaya M, 2015, PROCEDIA COMPUT SCI, V60, P681, DOI 10.1016/j.procs.2015.08.208
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   Gomez-Barrero M, 2017, PATTERN RECOGN, V67, P149, DOI 10.1016/j.patcog.2017.01.024
   Guo SW, 2019, SIGNAL PROCESS, V164, P320, DOI 10.1016/j.sigpro.2019.06.024
   Gupta A, 2021, IEEE T SYST MAN CY-S, V51, P3080, DOI 10.1109/TSMC.2019.2917599
   Imamverdiyev Y, 2013, EXPERT SYST APPL, V40, P1888, DOI 10.1016/j.eswa.2012.10.009
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Kaewwit C, 2017, J INF COMMUN TECHNOL, V16, P354
   Kang TK, 2015, PATTERN RECOGN, V48, P670, DOI 10.1016/j.patcog.2014.06.022
   Kashif M, 2016, COMPUT BIOL MED, V68, P67, DOI 10.1016/j.compbiomed.2015.11.006
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Kaur H, 2019, PATTERN RECOGN LETT, V126, P31, DOI 10.1016/j.patrec.2018.02.016
   Kaur H, 2017, LECT NOTES ENG COMP, P432
   Kaur H, 2015, PROCEDIA COMPUT SCI, V54, P661, DOI 10.1016/j.procs.2015.06.077
   Kausar F, 2020, INT J ADV COMPUT SC, V11, P333
   Li DL, 2016, NEUROCOMPUTING, V207, P78, DOI 10.1016/j.neucom.2016.03.067
   Li YC, 2019, NEUROCOMPUTING, V363, P212, DOI 10.1016/j.neucom.2019.07.039
   Mai G, 2017, IMAGE VISION COMPUT, V58, P254, DOI 10.1016/j.imavis.2016.11.011
   Mehrotra H, 2013, MATH COMPUT MODEL, V58, P132, DOI 10.1016/j.mcm.2012.06.034
   Murakami T, 2016, INFORM FUSION, V32, P93, DOI 10.1016/j.inffus.2016.02.002
   Nazari S, 2018, COMPUT ELECTR ENG, V72, P644, DOI 10.1016/j.compeleceng.2018.01.029
   Oliveira SAF, 2016, EXPERT SYST APPL, V44, P332, DOI 10.1016/j.eswa.2015.09.015
   Panchal G, 2018, COMPUT ELECTR ENG, V69, P461, DOI 10.1016/j.compeleceng.2018.01.028
   Pandey R, 2015, DEEP SECURE ENCODING
   Patel MI, 2016, PROCEDIA COMPUT SCI, V93, P382, DOI 10.1016/j.procs.2016.07.224
   Rahman MA, 2019, LECT NOTES COMPUT SC, V11854, P325, DOI 10.1007/978-3-030-34879-3_25
   Raj R, 2016, PROCEDIA COMPUT SCI, V93, P375, DOI 10.1016/j.procs.2016.07.223
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Tuttle SE, 2017, SPRING REMOTE SENS P, P21, DOI 10.1007/978-3-319-43744-6_2
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P168, DOI 10.1016/j.jbi.2018.07.015
   Verma G, 2019, OPT LASER ENG, V123, P28, DOI 10.1016/j.optlaseng.2019.06.028
   Vinay A, 2015, PROCEDIA COMPUT SCI, V70, P185, DOI 10.1016/j.procs.2015.10.070
   Wang S, 2017, PATTERN RECOGN, V66, P295, DOI 10.1016/j.patcog.2017.01.019
   Wang YL, 2007, BOUND VALUE PROBL, DOI 10.1155/2007/64579
   Yagnik J, 2011, IEEE I CONF COMP VIS, P2431, DOI 10.1109/ICCV.2011.6126527
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zhang HY, 2017, INFRARED PHYS TECHN, V83, P7, DOI 10.1016/j.infrared.2017.04.001
   Zhao D, 2014, NEUROCOMPUTING, V131, P87, DOI 10.1016/j.neucom.2013.10.037
NR 46
TC 6
Z9 6
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28675
EP 28693
DI 10.1007/s11042-020-09319-1
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300004
DA 2024-07-18
ER

PT J
AU Tang, XX
   Wang, HX
   Chen, Y
AF Tang, Xiaoxu
   Wang, Hongxia
   Chen, Yi
TI Reversible data hiding based on a modified difference expansion for
   H.264/AVC video streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Difference expanding; H.264/AVC; Visual quality
ID FRAME ERROR CONCEALMENT
AB Reversible Data Hiding (RDH), also referred to as invertible or lossless data hiding, has gradually received much attention from the research community in recent years. In this paper, a RDH scheme for H.264/AVC videos is proposed and it is based on a novel way to expand the difference of a pair of Quantized Discrete Cosine Transform (QDCT) coefficients. The secret data is embedded into the QDCT coefficients of 4 x 4 luminance blocks which selected according to two conditions to achieve good visual quality. In every embeddable 4 x 4 blocks each to- be-embedded information bit is embedded into the selected coefficient-pair. All the selected coefficient-pairs are changed by the proposed difference expanding strategy, which causes low distortion on visual quality. Experimental results have demonstrated that the proposed scheme obtains a little degradation of visual quality and keeps the variation low in bit-rate increase.
C1 [Tang, Xiaoxu; Chen, Yi] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Peoples R China.
   [Wang, Hongxia] Sichuan Univ, Coll Cybersecur, Chengdu 610064, Peoples R China.
C3 Southwest Jiaotong University; Sichuan University
RP Tang, XX (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Peoples R China.; Wang, HX (corresponding author), Sichuan Univ, Coll Cybersecur, Chengdu 610064, Peoples R China.
EM xiaoxu_tang@163.com; hxwang@scu.edu.cn; yichen.research@gmail.com
OI Chen, Yi/0000-0003-4272-7956
FU National Natural Science Foundation of China (NSFC) [61972269,
   61902263]; Fundamental Research Funds for the Central Universities
   [YJ201881]; Doctoral Innovation Fund Program of Southwest Jiaotong
   University [D-CX201824]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under Grants 61972269 and 61902263, the Fundamental
   Research Funds for the Central Universities under Grant YJ201881, and
   Doctoral Innovation Fund Program of Southwest Jiaotong
   University(D-CX201824).
CR Alavianmehr MA, 2013, INT ISC CONF INFO SE
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Chen Y, 2019, MULTIMED TOOLS APPL, V78, P23097, DOI 10.1007/s11042-019-7635-z
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Kim H, 2018, MULTIMED TOOLS APPL, V77, P8043, DOI 10.1007/s11042-017-4698-6
   Liu YJ, 2018, DISPLAYS, V51, P51, DOI 10.1016/j.displa.2018.01.004
   Liu YX, 2015, NEUROCOMPUTING, V151, P1053, DOI 10.1016/j.neucom.2014.03.088
   Ma XJ, 2017, IEEE T CLOUD COMPUT, V5, P510, DOI 10.1109/TCC.2015.2469651
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Shi YQ, 2004, IEEE INT S CIRC SYST, V2, P1133
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Vural C, 2015, SIGNAL IMAGE VIDEO P, V9, P1613, DOI 10.1007/s11760-014-0618-7
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   WANG J, 2020, MULTIMED TOOLS 0617
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu DW, 2016, SIGNAL PROCESS-IMAGE, V47, P369, DOI 10.1016/j.image.2016.08.003
   Xuan GR, 2018, J INF SECUR APPL, V39, P58, DOI 10.1016/j.jisa.2018.01.006
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Zhao J, 2016, MULTIMED TOOLS APPL, V75, P5959, DOI 10.1007/s11042-015-2558-9
NR 23
TC 5
Z9 5
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28661
EP 28674
DI 10.1007/s11042-020-09315-5
EA AUG 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300003
DA 2024-07-18
ER

PT J
AU Sun, SS
   Jiang, M
   Liang, N
   He, DJ
   Long, Y
   Song, HB
   Zhou, ZJ
AF Sun, Sashuang
   Jiang, Mei
   Liang, Ning
   He, Dongjian
   Long, Yan
   Song, Huaibo
   Zhou, Zhenjiang
TI Combining an information-maximization-based attention mechanism and
   illumination invariance theory for the recognition of green apples in
   natural scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immature green apple; Fuzzy set theory; Visual attention mechanism;
   Illumination invariance algorithm; Fruit recognition
ID ALGORITHM; MACHINE; FRUITS
AB Accurate recognition of green fruit targets is one of the key technologies for fruit growth monitoring and yield estimation. To solve the problem of fruit misidentification due to the similarity between fruit skin and leaf colors, a progressive detection method of green apples in natural environments was proposed. Image enhancement based on fuzzy set theory was carried out to make the fruit targets more salient in the whole image. Then, the fruit areas were roughly determined by the attention-based information maximization (AIM) algorithm, and the recognized apple regions were cropped according to the adaptive pixel-extending method to remove the background information. After that, accurate segmentation of fruit targets was accomplished by fusing the illumination-invariant image andR-component of the cropped image. To evaluate the performance of this method, it was compared with the illumination invariance theory-based algorithm, mean shift algorithm, K-means clustering algorithm, manifold ranking algorithm and GrabCut algorithm. The test was conducted using 200 green apple images under different growth statuses. Experimental results showed that the segmentation rate of the proposed method was 86.91%, which was 3.26%, 6.35%, 16.43%, 3.08% and 4.7% higher than those of the other five methods, respectively. The false positive rate and false negative rate were 0.88% and 10.53%, which gained an advantage over those of the other five segmentation algorithms. The localization error was 3.65%. In conclusion, the proposed method can accurately segment green fruit targets, which can lay the foundation for intelligent management of fruits over the entire growing season.
C1 [Sun, Sashuang; Jiang, Mei; He, Dongjian; Long, Yan; Song, Huaibo] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Sun, Sashuang; Liang, Ning; Zhou, Zhenjiang] Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou 310058, Peoples R China.
   [Jiang, Mei; He, Dongjian; Long, Yan; Song, Huaibo] Minist Agr, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
   [Jiang, Mei; He, Dongjian; Long, Yan; Song, Huaibo] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China; Zhejiang University; Ministry of
   Agriculture & Rural Affairs
RP Song, HB (corresponding author), Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.; Song, HB (corresponding author), Minist Agr, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.; Song, HB (corresponding author), Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
EM songhuaibo@nwsuaf.edu.cn
RI SONG, Huaibo/GXM-9402-2022; Sun, Sashuang/HGE-4366-2022
FU National Key R&D Program of China [2019YFD1002401]; National High
   Technology Research and Development Program of China (863 Program)
   [2013AA10230402]; Agricultural Science and Technology Project of Shaanxi
   Province [2016NY-157]
FX This study was funded by the National Key R&D Program of China
   (2019YFD1002401), the National High Technology Research and Development
   Program of China (863 Program) (2013AA10230402), and Agricultural
   Science and Technology Project of Shaanxi Province (2016NY-157).
CR Bansal R, 2013, PRECIS AGRIC, V14, P59, DOI 10.1007/s11119-012-9292-3
   Boini A, 2019, SCI HORTIC-AMSTERDAM, V256, DOI 10.1016/j.scienta.2019.05.047
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Craciun S, 2018, J REAL-TIME IMAGE PR, V14, P379, DOI 10.1007/s11554-014-0459-1
   Dubey SR, 2015, MULTIMED TOOLS APPL, V74, P11223, DOI 10.1007/s11042-014-2226-5
   Dubey SR, 2013, INT J INTERACT MULTI, V2, P65, DOI 10.9781/ijimai.2013.229
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Hassaballah M, 2017, APPL SOFT COMPUT, V57, P48, DOI 10.1016/j.asoc.2017.03.046
   He ZL, 2017, COMPUT ELECTRON AGR, V140, P159, DOI 10.1016/j.compag.2017.05.029
   [黄小玉 Huang Xiaoyu], 2018, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V34, P142
   Kang F, 2018, MULTIMEDIA, V2018, DOI 10.1155/2018/1083876
   Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719
   Li DH, 2019, SPECTROSC SPECT ANAL, V39, P2974, DOI 10.3964/j.issn.1000-0593(2019)09-2974-08
   Li H, 2016, PRECIS AGRIC, V17, P678, DOI 10.1007/s11119-016-9443-z
   Liu XY, 2018, PRECIS AGRIC, V19, P735, DOI 10.1007/s11119-017-9553-2
   Liu Z., 2014, Proceedings of the IEEE International Conference on Multimedia and Expo, P1
   Lu J, 2018, BIOSYST ENG, V171, P78, DOI 10.1016/j.biosystemseng.2018.04.009
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lungu R, 2013, J AEROSPACE ENG, V26, P794, DOI 10.1061/(ASCE)AS.1943-5525.0000207
   Mitra S, 2005, FUZZY SET SYST, V156, P381, DOI 10.1016/j.fss.2005.05.035
   Mizushima A, 2013, COMPUT ELECTRON AGR, V94, P29, DOI 10.1016/j.compag.2013.02.009
   Okamoto H, 2009, COMPUT ELECTRON AGR, V66, P201, DOI 10.1016/j.compag.2009.02.004
   Pham VanHuy., 2015, Vietnam Journal of Computer Science, V2, P25, DOI [DOI 10.1007/S40595-014-0028-3, 10.1007/s40595-014-0028-3]
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Skovsen S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122930
   Song HuaiBo Song HuaiBo, 2014, Transactions of the Chinese Society of Agricultural Engineering, V30, P168
   Stajnko D, 2004, COMPUT ELECTRON AGR, V42, P31, DOI 10.1016/S0168-1699(03)00086-3
   Sun SS, 2018, OPTIK, V165, P395, DOI 10.1016/j.ijleo.2018.03.085
   Wang CL, 2018, PRECIS AGRIC, V19, P1062, DOI 10.1007/s11119-018-9574-5
   Wang DD, 2019, MULTIMED TOOLS APPL, V78, P17391, DOI 10.1007/s11042-018-7106-y
   Wang DD, 2016, MULTIMED TOOLS APPL, V75, P3177, DOI 10.1007/s11042-014-2429-9
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang ZL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19122742
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhao CY, 2016, COMPUT ELECTRON AGR, V124, P243, DOI 10.1016/j.compag.2016.04.009
NR 37
TC 4
Z9 5
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28301
EP 28327
DI 10.1007/s11042-020-09342-2
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554845600001
DA 2024-07-18
ER

PT J
AU Farwa, S
   Bibi, N
   Muhammad, N
AF Farwa, Shabieh
   Bibi, Nargis
   Muhammad, Nazeer
TI An efficient image encryption scheme using Fresnelet transform and
   elliptic curve based scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fresnelet transform; Galois field; F-2(n); Elliptic curve; Group law
ID CHAOTIC SYSTEM; ALGORITHM; PERMUTATION; RETRIEVAL
AB This work introduces a novel and more efficient image encryption scheme, that deploys Fresnelet diffraction in the wave-propagation domain in conjunction with image scrambling effect, based on a specific elliptic curve group, that substantially reduces the computational cost for the desired outcome. Significantly elevated security of the encrypted image is guaranteed by highly complex algebraic structure of the elliptic curve over the Galois field F-2(4), in association with Fresnelet transform-based data-decomposition. At first stage, the proposed scheme, propagates confidential information, with selected wavelength at ceratin specific distance, using the Fresnelet transform. During this process confidential data decomposes into four complex sub-bands. We further separate these sub-bands into real and imaginary sub-band data. Then, at the second stage, elliptic curve group law is deployed to add confusion by scrambling the net sub-band data. The security and quality of the presented technique is examined through highly significant tools and we prove that when compared with other prevailing schemes, the proposed scheme offers coherent outcomes.
C1 [Farwa, Shabieh] COMSATS Univ Islamabad, Dept Math, Wah Campus, Wah Cantt, Pakistan.
   [Bibi, Nargis] Fatima Jinnah Women Univ, Dept Comp Sci, Rawalpindi, Pakistan.
   [Muhammad, Nazeer] Pak Austria Fachhsch Inst Appl Sci & Technol, Dept IT&CS, Haripur, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Muhammad, N (corresponding author), Pak Austria Fachhsch Inst Appl Sci & Technol, Dept IT&CS, Haripur, Pakistan.
EM drsfarwa@gmail.com; nargis@fjwu.edu.pk; nmuhammad@paf-iast.edu.pk
RI Bibi, Nargis/ABE-6506-2021; Muhammad, Nazeer/M-5653-2018
OI Muhammad, Nazeer/0000-0002-4056-9854
CR Ahmad J., 2012, International Journal of Video and Image Processing and Network Security, V12, P18
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Ahmad J, 2015, NONLINEAR DYNAM, V82, P1839, DOI 10.1007/s11071-015-2281-0
   Ahmad J, 2015, WIRELESS PERS COMMUN, V84, P901, DOI 10.1007/s11277-015-2667-9
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Azam NA, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/3421725
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Bibi N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194343
   Bukhari S., 2018, NUCLEUS, V55, P219
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Dawei Z, 2004, SOLITONS FRACTALS, V22, P47
   Deng SJ, 2005, LECT NOTES COMPUT SC, V3497, P868
   Erivelton G, 2019, CHAOS, V29
   Farwa S, 2020, WIRELESS PERS COMMUN, V115, P1309, DOI 10.1007/s11277-020-07628-0
   Farwa S, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0135-x
   Ghoneim A, 2018, IEEE COMMUN MAG, V56, P33, DOI 10.1109/MCOM.2018.1700817
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Liebling M, 2004, J OPT SOC AM A, V21, P367, DOI 10.1364/JOSAA.21.000367
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu LF, 2018, IET SIGNAL PROCESS, V12, P22, DOI 10.1049/iet-spr.2016.0584
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mahmood S, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5823230
   Mondal B, 2020, SECURE IMAGE ENCRYPT
   Muhammad N, 2017, REVERSIBLE INTEGER W, V12
   Muhammad N., 2017, ANAL APPL, V1, P16, DOI [10.1007/s10044-017-0613-z, DOI 10.1007/S10044-017-0613-Z]
   Muhammad N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1534-1
   Muhammad N, 2015, IET IMAGE PROCESS, V9, P795, DOI 10.1049/iet-ipr.2014.0395
   Nazeer M, 2013, INT J ADV COMPUT SC, V4, P131
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Salleh M, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P508
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yue U, 2011, J MULT J SCI TECH JS, V1, P31
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 49
TC 13
Z9 13
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28225
EP 28238
DI 10.1007/s11042-020-09324-4
EA AUG 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554334100002
DA 2024-07-18
ER

PT J
AU Khan, MA
   Zhang, YD
   Khan, SA
   Attique, M
   Rehman, A
   Seo, S
AF Khan, Muhammad Attique
   Zhang, Yu-Dong
   Khan, Sajid Ali
   Attique, Muhammad
   Rehman, Amjad
   Seo, Sanghyun
TI A resource conscious human action recognition framework using 26-layered
   deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; CNN architecture; Features fusion; Features
   selection; ELM
ID RECOGNIZING HUMAN ACTIONS; FEATURES FUSION; SELECTION; MACHINE; MODEL;
   LSTM
AB Vision-based human action recognition (HAR) is a hot topic of research from the decade due to a few popular applications such as visual surveillance and robotics. For correct action recognition, various local and global points are requires known as features. These features modified during the variation in human movement. But due to a bit change in several human actions, the features of these actions are mixed that degrade the recognition performance. In this article, we design a new 26-layered Convolutional Neural Network (CNN) architecture for accurate complex action recognition. The features are extracted from the global average pooling layer and fully connected (FC) layer, and fused by a proposed high entropy-based approach. Further, we propose a feature selection method name Poisson distribution along with Univariate Measures (PDaUM). Few of fused CNN features are irrelevant, and few of them are redundant that makes the incorrect prediction among complex human actions. Therefore, the proposed PDaUM based approach selects only the strongest features that later passed to the Extreme Learning Machine (ELM) and Softmax for final recognition. Four datasets are using for experimental analysis - HMDB51 (51 classes), UCF Sports (10 classes), KTH (6 classes), and Weizmann (10 classes). On these datasets, the ELM classifier gives an improved performance as compared to a Softmax classifier. The achieved accuracy on each dataset is 81.4%, 99.2%, 98.3%, and 98.7%, respectively. Comparison with existing techniques, it is shown that the proposed architecture gives better performance in terms of accuracy and testing time.
EM sanghyun@cau.ac.kr
RI khan, sajid/HGE-2406-2022; Khan, Dr. Muhammad Attique/AAX-2644-2021;
   Rehman, Amjad/GXV-0915-2022; Sanghyun, Seo/ADZ-4404-2022; Zhang,
   Yudong/I-7633-2013
OI Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Rehman,
   Amjad/0000-0002-3817-2655; Sanghyun, Seo/0000-0002-4824-3517; Zhang,
   Yudong/0000-0002-4870-1493
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2019R1F1A1058715]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT)
   (NRF-2019R1F1A1058715).
CR Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Asghari-Esfeden S, 2020, IEEE WINT CONF APPL, P546, DOI 10.1109/WACV45572.2020.9093500
   Aurangzeb K, 2019, J MED IMAG HEALTH IN, V9, P662, DOI 10.1166/jmihi.2019.2611
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Chen S, 2020, IEEE ACCESS, V8, P36313, DOI 10.1109/ACCESS.2020.2966329
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Gu Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.004
   Hiriyannaiah S, 2020, Multimedia big data computing for IoT applications, P101
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Hussain N, 2024, MULTIMED TOOLS APPL, V83, P14935, DOI 10.1007/s11042-020-08852-3
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Khan MA, 2020, IET IMAGE PROCESS, V14, P818, DOI 10.1049/iet-ipr.2018.5769
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Kragh MF, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103494
   Kulkarni S, 2020, ALGO INTELL SY, P141, DOI 10.1007/978-981-15-0994-0_9
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Martin PE, 2020, MULTIMED TOOLS APPL, V79, P20429, DOI 10.1007/s11042-020-08917-3
   Nazir S, 2018, PATTERN RECOGN LETT, V103, P39, DOI 10.1016/j.patrec.2017.12.024
   Tu NA, 2019, IEEE T CIRC SYST VID, V29, P800, DOI 10.1109/TCSVT.2018.2816960
   Ouyang X, 2019, IEEE ACCESS, V7, P40757, DOI 10.1109/ACCESS.2019.2906654
   Ozcan T, 2020, CLUSTER COMPUT, V23, P2847, DOI 10.1007/s10586-020-03050-0
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sharif A, 2019, CONTROL ENG APPL INF, V21, P3
   Sharif M, 2020, PATTERN ANAL APPL, V23, P281, DOI 10.1007/s10044-019-00789-0
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Siddiqui S, 2018, INT J APPL PATTERN R, V5, P206, DOI 10.1504/IJAPR.2018.094815
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stoian A, 2016, IEEE T CIRC SYST VID, V26, P1917, DOI 10.1109/TCSVT.2015.2475835
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Thien HT, 2020, INFORM SCIENCES, V513, P112, DOI 10.1016/j.ins.2019.10.047
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Vishwakarma DK, 2020, COGN SYST RES, V61, P1, DOI 10.1016/j.cogsys.2019.12.004
   Wang JZ, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102898
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Xiong QQ, 2020, J MANUF SYST, V56, P605, DOI 10.1016/j.jmsy.2020.04.007
   Yi Y, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115640
   Yudistira N, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115731
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
NR 44
TC 35
Z9 35
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35827
EP 35849
DI 10.1007/s11042-020-09408-1
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000554334100003
DA 2024-07-18
ER

PT J
AU Nikan, F
   Hassanpour, H
AF Nikan, F.
   Hassanpour, H.
TI Face recognition using non-negative matrix factorization with a single
   sample per person in a large database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Non-negative matrix factorization; Single sample per
   person; Large database; Recognition rate
ID TRAINING SAMPLE; IMAGE; PARTS; FLDA
AB There are various face recognition techniques in literature, which are faced with challenges such as occlusion, pose variation, illumination, and facial expressions. Existing methods often perform well when their database is small, or multiple samples per person exist. However, face recognition methods with just one reference sample per person may not work well, especially on a large database. To address this problem, this paper proposes a scheme to extract features from facial images. Using Non-negative Matrix Factorization (NMF), basic features are extracted from the face structure. The matrix of images is decomposed into basis matrix (W) and weight matrix (H). The basis matrix contains several versions of mouths, noses and other facial parts, where the various versions are in different locations or forms. Hence, to recognize a facial image in the database, searching is done on the weight matrices feature set. In this research, to more precisely form the structural elements, a separate basis matrix is constructed for the upper and lower parts of the facial images from the database. Also the images are enhanced using pre-processing techniques including histogram equalization, image intensity, and contrast limited adaptive histogram. The FERET database with 990 single images per person was used to evaluate the proposed method. Experimental results show that the proposed method can achieve a recognition rate close to 93%.
C1 [Nikan, F.; Hassanpour, H.] Shahrood Univ Technol, Dept Comp Engn, Shahrood, Iran.
C3 Shahrood University of Technology
RP Hassanpour, H (corresponding author), Shahrood Univ Technol, Dept Comp Engn, Shahrood, Iran.
EM h.hassanpour@shahroodut.ac.ir
RI Hassanpour, Hamid/AAL-7271-2020
OI Hassanpour, Hamid/0000-0002-5513-9822
CR Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Chang DC, 1998, IEEE T MED IMAGING, V17, P518, DOI 10.1109/42.730397
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019
   George KK, 2015, ELECTRON LETT, V51, P939, DOI 10.1049/el.2015.0515
   Grag R, 2011, INT J ELECT COMMUN T, V2
   Guo YW, 2018, IEEE T CYBERNETICS, V48, P2402, DOI 10.1109/TCYB.2017.2739338
   Hu C.-M, 2015, 2015 40th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), P1, DOI 10.1109/IRMMW-THz.2015.7327529
   Ji HK, 2017, PATTERN RECOGN, V62, P125, DOI 10.1016/j.patcog.2016.08.007
   Kan MN, 2013, PATTERN RECOGN, V46, P2497, DOI 10.1016/j.patcog.2013.01.037
   Kim J, 2011, SIAM J SCI COMPUT, V33, P3261, DOI 10.1137/110821172
   Langville A. N., 2014, CORR, V1407, P7299
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li SZ, 2001, PROC CVPR IEEE, P207
   Li W, 2019, INT J IMAG SYST TECH, V29, P77, DOI 10.1002/ima.22298
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Min R, 2019, IEEE ACCESS, V7, P45219, DOI 10.1109/ACCESS.2019.2909039
   Nikolaus, 2007, LEARNING PARTS OBJEC
   Oloyede MO, 2016, IEEE ACCESS, V4, P7532, DOI 10.1109/ACCESS.2016.2614720
   Pan J, 2016, IEEE ACCESS, V4, P2873, DOI 10.1109/ACCESS.2016.2574366
   Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311
   RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4
   Shan S, 2002, P IEEE INT SCIRC SYS
   Shi ZH, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0251-4
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Wild S, 2004, PATTERN RECOGN, V37, P2217, DOI 10.1016/j.patcog.2004.02.013
   Xin M., 2015, APPL MATH INFORM SCI, V9, P353, DOI [10.12785/amis/090141, DOI 10.12785/AMIS/090141]
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yoon H, 2009, NOISE WORLD ACAD SCI, V3, P132
   Zeng JY, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/3803627
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
   Zhang GY, 2017, DIGIT SIGNAL PROCESS, V62, P150, DOI 10.1016/j.dsp.2016.11.004
   Zhang SY, 2015, 2015 IEEE WORKSHOP ON ENVIRONMENTAL, ENERGY AND STRUCTURAL MONITORING SYSTEMS (EESMS), P1, DOI [10.1109/INTMAG.2015.7156970, 10.1109/EESMS.2015.7175842]
   Zhao HT, 2005, INT J PATTERN RECOGN, V19, P375, DOI 10.1142/S0218001405004071
   Zhou SJ, 2019, PROC SPIE, V10843, DOI 10.1117/12.2506343
NR 39
TC 8
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28265
EP 28276
DI 10.1007/s11042-020-09394-4
EA AUG 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436800003
DA 2024-07-18
ER

PT J
AU Saxena, G
   Bhadauria, SS
AF Saxena, Gaurav
   Bhadauria, Sarita Singh
TI An efficient single image haze removal algorithm for computer vision
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Atmospheric light; Defogging; Image quality; Edge preservation; Contrast
   gain; Image visibility
ID ENHANCEMENT; FRAMEWORK; WEATHER; MODEL; FOG
AB Atmospheric conditions induced by suspended particles such as fog, smog, rain, haze etc., severely affect the scene appearance and computer vision applications. In general, existing defogging algorithms use various constraints for fog removal. The efficiency of these algorithms depends on the accurate estimation of the depth models and the perfection of these models solely relies on pre-calculated coefficients through the training data. However, the depth model developed on the basis of these pre-calculated coefficients for dehazing may provide better accuracy for some kind of images but not equally well for every type of images. Therefore, training data-independent based depth model is required for a perfect haze removal algorithm. In this paper, an effective haze removal algorithm is reported for removing fog or haze from a single image. The proposed algorithm utilizes the atmospheric scattering model in fog removal. Apart from this, linearity in the depth model is achieved by the ratio of difference and sum of the intensity and saturation values of the input image. Besides, the proposed method also take care the well-known problems of edge preservation, white region handling and colour fidelity. Experimental results show that the proposed model is more efficient in comparison to the existing haze removal algorithms in terms of qualitative and quantitative analysis.
C1 [Saxena, Gaurav] Jaypee Univ Engn & Technol, Guna 473226, Madhya Pradesh, India.
   [Bhadauria, Sarita Singh] Madhav Inst Sci & Technol, Gwalior 474005, Madhya Pradesh, India.
C3 Madhav Institute of Technology & Science
RP Saxena, G (corresponding author), Jaypee Univ Engn & Technol, Guna 473226, Madhya Pradesh, India.
EM gauravsagar311@gmail.com; saritamits61@yahoo.co.in
RI Saxena, Dr. Gaurav/HNP-2775-2023
OI Saxena, Dr. Gaurav/0000-0003-2524-5672
CR Adams J, 2010, INT J ART DES EDUC, V29, P2, DOI 10.1111/j.1476-8070.2010.01638.x
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], P SPIE
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194011
   El Khoury J, 2018, MULTIMED TOOLS APPL, V77, P15409, DOI 10.1007/s11042-017-5122-y
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gao YK, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043014
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2014, ISPRS J PHOTOGRAMM, V89, P37, DOI 10.1016/j.isprsjprs.2013.12.011
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   Hautiere N., 2007, 2007 IEEE C COMP VIS, P1
   Hautière N, 2006, INT C PATT RECOG, P155
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hitam M.S., 2013, P 2013 INT C COMP AP, P1, DOI [DOI 10.1109/ICCAT.2013.6522017, 10.1109/ICCAT.2013.6522017]
   Hongyu Zhao, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P158, DOI 10.1109/JAS.2015.7081655
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Raikwar SC, 2018, MULTIMED TOOLS APPL, V77, P19719, DOI 10.1007/s11042-017-5398-y
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Sethi R, 2019, MULTIMED TOOLS APPL, V78, P31823, DOI 10.1007/s11042-019-07938-x
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tripathi AK, 2012, IETE TECH REV, V29, P148, DOI 10.4103/0256-4602.95386
   Wang H, 2020, INT J MACH LEARN CYB, V11, P853, DOI 10.1007/s13042-020-01061-2
   Wang R, 2016, SIGNAL PROCESS, V127, P24, DOI 10.1016/j.sigpro.2016.02.003
   [吴迪 Wu Di], 2015, [自动化学报, Acta Automatica Sinica], V41, P221
   Xiaoliang Yu, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P286, DOI 10.1109/ICIG.2011.22
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Yu J, 2010, INT CONF SIGN PROCES, P1048, DOI 10.1109/ICOSP.2010.5655901
   [禹晶 Yu Jing], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P1561
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 44
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28239
EP 28263
DI 10.1007/s11042-020-09421-4
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436800005
DA 2024-07-18
ER

PT J
AU Li, HS
   Zhang, L
   Zhang, XD
   Zhang, ML
   Zhu, GM
   Shen, PY
   Li, P
   Bennamoun, M
   Shah, SAA
AF Li, Hongsheng
   Zhang, Liang
   Zhang, Xiangdong
   Zhang, Meili
   Zhu, Guangming
   Shen, Peiyi
   Li, Ping
   Bennamoun, Mohammed
   Shah, Syed Afaq Ali
TI Color vision deficiency datasets & recoloring evaluation using GANs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color vision deficiency; Recolor; Improved octree quantification method;
   GAN
ID IMAGES
AB People with Color Vision Deficiency (CVD) cannot distinguish some color combinations under normal situations. Recoloring becomes a necessary adaptation procedure. In this paper, in order to adaptively find the key color components in an image, we first propose a self-adapting recoloring method with an Improved Octree Quantification Method (IOQM). Second, we design a screening tool of CVD datasets that is used to integrate multiple recoloring methods. Third, a CVD dataset is constructed with the help of our designed screening tool. Our dataset consists of 2313 pairs of training images and 771 pairs of testing images. Fourth, multiple GANs i.e., pix2pix-GAN [1], Cycle-GAN [2], Bicycle-GAN [3] are used for colorblind data conversion. This is the first ever effort in this research area using GANs. Experimental results show that pix2pix-GAN [1] can effectively recolor unrecognizable colors for people with CVD, and we predict that this dataset can provide some help for color blind images recoloring. Datasets and source are available at: https:// github.com/doubletry/pix2pix, https://github.com/doubletry/CycleGAN and https://github.com/doubletry/BicycleGAN.
C1 [Li, Hongsheng; Zhang, Liang; Zhang, Xiangdong; Zhang, Meili; Zhu, Guangming; Shen, Peiyi] Xidian Univ, Xian, Peoples R China.
   [Li, Ping] Shanghai Natl Engn Res Ctr Broadband Networks & A, Shanghai, Peoples R China.
   [Bennamoun, Mohammed; Shah, Syed Afaq Ali] Univ Western Australia, Perth, WA, Australia.
C3 Xidian University; University of Western Australia
RP Zhang, L (corresponding author), Xidian Univ, Xian, Peoples R China.
EM hsli@stu.xidian.edu.cn; liangzhang@xidian.edu.cn;
   xdchen@mail.xidian.edu.cn; 1334625816@qq.com; gmzhu@xidian.edu.cn;
   pyshen@xidian.edu.cn; pli@bnc.org.cn; mohammed.bennamoun@uwa.edu.au;
   afaq.shah@uwa.edu.au
RI li, he/ISB-4278-2023; Bennamoun, Mohammed/C-2789-2013; li,
   hs/HNI-7007-2023
OI Bennamoun, Mohammed/0000-0002-6603-3257; Zhang,
   Liang/0000-0003-4331-5830; Shah, Syed Afaq Ali/0000-0003-2181-8445
FU National Key R&D Program of China [2019YFB1311600]; Ningbo 2025 Key
   Project of Science and Technology Innovation [2018B10071]
FX Supported by National Key R&D Program of China under Grant No.
   2019YFB1311600 & Ningbo 2025 Key Project of Science and Technology
   Innovation (2018B10071).
CR [Anonymous], ARXIV 1611 08050 CS, DOI DOI 10.1109/CVPR.2017.143
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Bansal A, 2016, PROC CVPR IEEE, P5965, DOI 10.1109/CVPR.2016.642
   Brettel H, 1997, J OPT SOC AM A, V14, P2647, DOI 10.1364/JOSAA.14.002647
   CHEN LC, 2017, ARXIV PREPRINT ARXIV, V1706, P5587, DOI DOI 10.48550/ARXIV.1706.05587
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Denton E, 2015, ADV NEUR IN, V28
   Doliotis P, 2009, INT FED INFO PROC, P293
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Donahue J., 2016, ARXIV160509782
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Eigen D., 2014, NIPS, DOI DOI 10.5555/2969033.2969091
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fluck D, 2006, COBLIS COLOR BLINDNE
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fu KR, 2019, IEEE T MULTIMEDIA, V21, P457, DOI 10.1109/TMM.2018.2859746
   Geiger A., 2012, CVPR
   Gervautz M, 1988, NEW TRENDS COMPUTER, P219, DOI DOI 10.1007/978-3-642-83492-920
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang CR, 2010, LECT NOTES COMPUT SC, V6298, P637, DOI 10.1007/978-3-642-15696-0_59
   Huang JB, 2009, INT CONF ACOUST SPEE, P1161, DOI 10.1109/ICASSP.2009.4959795
   Huang L., 2015, Comput. Sci.
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Katsuhiro N, 2016, B HIROSHIMA MERCANT, P38
   Khurge DS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P611, DOI 10.1109/ICCUBEA.2015.125
   Kim HJ, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P602, DOI 10.1109/ICCE.2012.6162036
   Kim YK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P76, DOI 10.1109/ICMA.2007.4303519
   Kingma D. P., 2013, ARXIV13126114
   Larsen A.B.L, 2015, ARXIV151209300, DOI DOI 10.3390/RS12223815
   Lee SW, 2011, IEEE T BIO-MED ENG, V58, DOI 10.1109/TBME.2011.2136341
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu M, 2017, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2017.270
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Martin CE, 2000, IEEE T SYST MAN CY A, V30, P494, DOI 10.1109/3468.852442
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mathieu M., 2016, Neural Information Processing Symposium, pages, P5041
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   Mili N., 2015, COL VIS COMP S CVCS, P1
   Milic N, 2015, J IMAGING SCI TECHN, V59, DOI 10.2352/J.ImagingSci.Technol.2015.59.1.010504
   Orii H, 2014, JOINT INT CONF SOFT, P910, DOI 10.1109/SCIS-ISIS.2014.7044811
   Rasche K, 2005, IEEE COMPUT GRAPH, V25, P22, DOI 10.1109/MCG.2005.54
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sharpe L.T., 1999, Color Vision: From Genes to Perception
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Stenetorp P., 2012, P DEM 13 C EUR CHAPT, P102, DOI DOI 10.5555/2380921.2380942
   Teney D., 2016, Asian Conference on Computer Vision, P412
   Tzutalin, 2015, LABELING
   Vondrick C, 2013, INT J COMPUT VISION, V101, P184, DOI 10.1007/s11263-012-0564-1
   Wandell B. A., 1995, Foundations of vision, V8
   Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Zhao J, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1875, DOI [10.1109/ITAIC.2019.8785506, 10.1109/itaic.2019.8785506]
   Zhou Bolei, 2017, PROC CVPR IEEE, P633, DOI DOI 10.1109/CVPR.2017.544
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
   Zhu Jun-Yan, 2017, Advances in neural information processing systems (NeurIPS)
NR 67
TC 7
Z9 7
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27583
EP 27614
DI 10.1007/s11042-020-09299-2
EA JUL 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555554200004
DA 2024-07-18
ER

PT J
AU Samih, H
   Rady, S
   Gharib, TF
AF Samih, Haitham
   Rady, Sherine
   Gharib, Tarek F.
TI Enhancing image retrieval for complex queries using external knowledge
   sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Annotation-based image retrieval; Semantic search and retrieval;
   Commonsense knowledge; Knowledge inference; Query understanding; Query
   expansion
ID WEB; EXPANSION; WORDNET
AB Annotation-based image retrieval associates textual descriptions to images based on human perception. A user query, composed of keywords of choice and for retrieval, are usually matched lexically with the textual descriptions associated for stored images to extract the best matches. This paradigm will not produce appropriate desired results for complex queries if a semantic approach is not considered. This paper proposes an image retrieval framework which integrates external knowledge sources for obtaining a higher-level inference that can both handle complex queries and increase the number of relevant retrievals. The framework includes a parser where a semantic representation graph is initially generated from both image captions and query. The semantic representation of image captions is stored in the form of Resource Description Framework (RDF) triples, while the user query is translated into a SPARQL language query. For better query understanding, the external knowledge sources (ConceptNet, WordNet), are next fused together with the parser's output in a significant process named query expansion to infer combined and expanded knowledge about the terms used in the query. Also, the expansion process generates a set of expansion rules to semantically expand the user query to adapt the inferred knowledge. The expanded query is matched against the stored RDF triplets to indicate the best matched image retrievals. Retrievals are eventually ranked using a relation similarity metric to obtain a ranked list of relevant images. Experimental studies carried on two Flickr datasets show that the proposed framework outperforms related work with 40% increase in the number of relevant retrievals at almost full accuracy. The framework achieves additionally an average increase for the accuracy at givenkin the range of 50-72% for up to the tenth retrieval.
C1 [Samih, Haitham] Natl Egyptian E Learning Univ, Fac Comp & Informat Technol, Cairo, Egypt.
   [Rady, Sherine; Gharib, Tarek F.] Ain Shams Univ, Fac Comp & Informat Sci, Dept Informat Syst, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University
RP Rady, S (corresponding author), Ain Shams Univ, Fac Comp & Informat Sci, Dept Informat Syst, Cairo, Egypt.
EM hsamih@eelu.edu.eg; srady@cis.asu.edu.eg; tfgharib@cis.asu.edu.eg
RI Gharib, Tarek F./C-4235-2012; Rady, Sherine/W-7351-2019
OI Gharib, Tarek F./0000-0003-0780-782X; Rady, Sherine/0000-0003-4991-966X
CR [Anonymous], 2017, ARXIV170508844
   [Anonymous], 2015, ARXIV151103292
   [Anonymous], 2003, WWW
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bodner R. C., 1996, Advances in Artificial Intelligence. 11th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, AI'96. Proceedings, P146
   Cacko A., 2017, INT C IM PROC COMM, P19
   Chen H, 2018, MIN TECHNOL, P1
   Grobe M., 2009, P 37 ANN ACM SIGUCCS, P131
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Gulati P., 2010, INT J COMPUT APPL, V5, P33, DOI DOI 10.5120/946-1324
   Hakimpour F., 2001, P 4 AGILE C GEOGRAPH, P385
   Hatem Y, 2018, MULTIMED TOOLS APPL, V77, P9171, DOI 10.1007/s11042-017-5417-z
   Havasi C., 2007, RECENT ADV NATURAL L, P27
   He YF, 2016, NEUROCOMPUTING, V204, P26, DOI 10.1016/j.neucom.2015.11.102
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hoque E, 2013, J AMB INTEL HUM COMP, V4, P389, DOI 10.1007/s12652-011-0094-7
   Hsu MH, 2006, LECT NOTES COMPUT SC, V4182, P1
   Huang H, 2012, WORLD WIDE WEB, V15, P89, DOI 10.1007/s11280-011-0131-7
   Im DH, 2015, MULTIMED TOOLS APPL, V74, P2273, DOI 10.1007/s11042-014-1855-z
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Liaqat M, 2017, MULTIMED TOOLS APPL, V76, P22623, DOI 10.1007/s11042-017-4812-9
   Lilensten J, 2004, SPACE WEATHER, V2, DOI 10.1029/2003SW000021
   Lu YB, 2008, 2008 IEEE SYMPOSIUM ON ADVANCED MANAGEMENT OF INFORMATION FOR GLOBALIZED ENTERPRISES, PROCEEDINGS, P16
   Luo B, 2003, P SOC PHOTO-OPT INS, V5018, P123, DOI 10.1117/12.476329
   Magesh N, 2011, NTERNATIONAL CONFERE
   Manola F., 2004, RESOURCE DESCRIPTION, V10
   Manzoor Umar, 2015, International Journal of Advanced Research in Artificial Intelligence, V4, P1
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Raza MA, 2019, KNOWL INF SYST, V61, P1, DOI 10.1007/s10115-018-1269-8
   Sankar Sharmi, 2014, INT J COMPUTER APPL, V86, P21, DOI DOI 10.5120/15030-3348
   Sarwar S, 2013, PROCEDIA COMPUT SCI, V22, P285, DOI 10.1016/j.procs.2013.09.105
   Schuster S., 2015, P 4 WORKSHOP VISION, P70
   Seaborne Prud E, 2006, SPARQL QUERY LANGUAG
   Sharma N, 2015, IEEE IJCNN, DOI 10.1109/IJCNN.2015.7280631
   Styrman A., 2005, THESIS
   Ul-Qayyum Z, 2010, LECT NOTES ARTIF INT, V6098, P321, DOI 10.1007/978-3-642-13033-5_33
   Xu X, 2016, MULTIMED TOOLS APPL, V75, P2203, DOI 10.1007/s11042-014-2402-7
   Xu X, 2016, IEEJ T ELECTR ELECTR, V11, P73, DOI 10.1002/tee.22190
   Yang Y, 2016, ADV COGN SYST
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
NR 44
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27633
EP 27657
DI 10.1007/s11042-020-09360-0
EA JUL 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555554200003
DA 2024-07-18
ER

PT J
AU Pang, YH
   Li, F
   Qiao, XY
   Gilman, A
AF Pang, Yuhang
   Li, Fan
   Qiao, Xiaoya
   Gilman, Andrew
TI Real-time tracking based on deep feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Convolutional neural network; Feature fusion;
   Correlation filters
ID ROBUST VISUAL TRACKING; OBJECT TRACKING; NETWORK; MODEL
AB Deep learning-based methods have recently attracted significant attention in visual tracking community, leading to an increase in state-of-the-art tracking performance. However, due to the utilization of more complex models, it has also been accompanied with a decrease in speed. For real-time tracking applications, a careful balance of performance and speed is required. We propose a real-time tracking method based on deep feature fusion, which combines deep learning with kernel correlation filter. First, hierarchical features are extracted from a lightweight pre-trained convolutional neural network. Then, original features of different levels are fused using canonical correlation analysis. Fused features, as well as some original deep features, are used in three kernel correlation filters to track the target. An adaptive update strategy, based on dispersion analysis of response maps for the correlation filters, is proposed to improve robustness to target appearance changes. Different update frequencies are adopted for the three filters to adapt to severe appearance changes. We perform extensive experiments on two benchmarks: OTB-50 and OTB-100. Quantitative and qualitative evaluations show that the proposed tracking method performs favorably against some state-of-the-art methods - even better than algorithms using complex network model. Furthermore, proposed algorithm runs faster than 20 frame per second (FPS) and hence able to achieve near real-time tracking.
C1 [Pang, Yuhang; Li, Fan; Qiao, Xiaoya] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
   [Gilman, Andrew] Massey Univ, Inst Nat & Math Sci, Auckland, New Zealand.
C3 Xi'an Jiaotong University; Massey University
RP Li, F (corresponding author), Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
EM pangyuhang2014@stu.xjtu.edu.cn; lifan@mail.xjtu.edu.cn;
   qxy0212@stu.xjtu.edu.cn; a.gilman@massey.ac.nz
RI Qiao, Xiaoya/GWM-7530-2022
FU National Science Foundation of China [61671365]; Joint Foundation of
   Ministry of Education of China [6141A02022344]
FX This research was supported in part by the National Science Foundation
   of China (61671365) and the Joint Foundation of Ministry of Education of
   China (6141A02022344).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Dou JF, 2017, MULTIMED TOOLS APPL, V76, P15839, DOI 10.1007/s11042-016-3872-6
   Vo DM, 2018, MULTIMED TOOLS APPL, V77, P18689, DOI 10.1007/s11042-018-5653-x
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Haghighat M, 2016, EXPERT SYST APPL, V47, P23, DOI 10.1016/j.eswa.2015.10.047
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He LJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020572
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li F, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112626
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li X, 2016, KNOWL-BASED SYST, V113, P88, DOI 10.1016/j.knosys.2016.09.014
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang NX, 2018, IEEE T MULTIMEDIA, V20, P2289, DOI 10.1109/TMM.2018.2803518
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu FH, 2018, IEEE T IMAGE PROCESS, V27, P2777, DOI 10.1109/TIP.2018.2813161
   Liu GG, 2018, IEEE T MULTIMEDIA, V20, P2949, DOI 10.1109/TMM.2018.2844685
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P4199, DOI 10.1109/TIP.2016.2588329
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Ma C, 2017, IEEE T MULTIMEDIA, V19, P2415, DOI 10.1109/TMM.2017.2694219
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Ruan Y, 2016, J VIS COMMUN IMAGE R, V35, P146, DOI 10.1016/j.jvcir.2015.12.009
   Shu SJ, 2019, J ADV TRANSPORT, DOI 10.1155/2019/2327876
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang HX, 2019, MULTIMED TOOLS APPL, V78, P257, DOI 10.1007/s11042-017-5533-9
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang Q., 2017, arXiv preprint arXiv:1704.04057
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu ZB, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2275, DOI 10.23919/ICIF.2018.8455397
   Yang XF, 2016, INT CONF SIGN PROCES, P1353, DOI 10.1109/ICSP.2016.7878047
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhou T, 2018, IEEE T CYBERNETICS, V48, P2643, DOI 10.1109/TCYB.2017.2747998
   Zhou T, 2017, IEEE T CIRC SYST VID, V27, P2153, DOI 10.1109/TCSVT.2016.2576941
   Zhou Y, 2017, IEEE T MULTIMEDIA, V19, P1798, DOI 10.1109/TMM.2017.2689918
   Zhu Z, 2017, IEEE INT CONF COMP V, P1973, DOI 10.1109/ICCVW.2017.231
NR 68
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27229
EP 27255
DI 10.1007/s11042-020-09267-w
EA JUL 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551736600004
DA 2024-07-18
ER

PT J
AU Nandi, U
AF Nandi, Utpal
TI Fractal image compression with adaptive quadtree partitioning and
   non-linear affine map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractal compression; Adaptive quadtree partition; Affine map; Non-linear
   affine map; Contractive transform; Compression ratio; Image quality
ID CLASSIFICATION
AB Fractal image compression techniques are now very popular for its high compression rates and resolution independence property. However, the qualities of decoded images of the existing techniques are not satisfactory. An adaptive partitioning scheme can improve the image quality significantly. These existing adaptive techniques use linear affine maps during encoding that have limited pixel intensity approximation ability. In order to increase the image quality further, non-linear affine maps can be used that generalizes the pixel intensity approximation and generates much better approximation. Here, a fractal based technique for image compression using non-linear contractive affine maps has been proposed that applies adaptive quadtree partitioning to partition image in a context dependent way to enhance decoded image quality. The technique partitions twice an image to be compressed to obtain collection of ranges and domains and finds the highest matching non-linear affine transformed domain of each range. The corresponding affine parameters are kept in the compressed file. However, a range may be broken into sub-ranges using adaptive quadtree partitioning for unavailability of enough matching domains and repeat the same on those. The comparative results show that the proposed technique greatly improves the decoded image quality than existing techniques and also maintains the high compression ratios. Two variants have also been proposed that improve compression ratio of the proposed technique without any degradation of image quality using loss-less coding.
C1 [Nandi, Utpal] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
C3 Vidyasagar University
RP Nandi, U (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM nandi.3utpal@gmail.com
RI Nandi, Utpal/AAW-9041-2021
OI Nandi, Utpal/0000-0002-9638-1906
CR Al-Jawfi Rashad A, 2014, Applied Mathematics, V5, P1810
   [Anonymous], 1998, Fractals Everywhere
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Bhattacharya Nilavra, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P46
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Bobde S. S., 2010, 2010 International Conference on Advances in Computer Engineering (ACE), P241, DOI 10.1109/ACE.2010.9
   Bouchemel A, 2018, IEEE COMMUN LETT, V22, P934, DOI 10.1109/LCOMM.2018.2812821
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   Fu C, 2009, 2009 INTERNATIONAL WORKSHOP ON CHAOS-FRACTALS THEORIES AND APPLICATIONS (IWCFTA 2009), P439, DOI 10.1109/IWCFTA.2009.99
   Gupta R, 2016, IMAGING SCI J, V64, P374, DOI 10.1080/13682199.2016.1219100
   Gupta R, 2018, ALEX ENG J, V57, P1525, DOI 10.1016/j.aej.2017.03.038
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   JACQUIN AE, 1993, P IEEE, V81, P1451, DOI 10.1109/5.241507
   Jeng JH, 2009, IEEE T IMAGE PROCESS, V18, P995, DOI 10.1109/TIP.2009.2013080
   Kocic LM, 2006, FACTA UNIV-SER MATH, V21, P65
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lakshmi GVM, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE (ICIS), P60, DOI 10.1109/INFOSCI.2016.7845301
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Li YT, 2016, OPTIK, V127, P4484, DOI 10.1016/j.ijleo.2016.01.176
   Liu S, 2017, FRACTALS, V25, P4
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Lu J, 2013, IEEE T IMAGE PROCESS, V22, P134, DOI 10.1109/TIP.2012.2215619
   Name M, 2012, IBEROAMERICAN J APPL, V2, P11
   Nandi Utpal, 2016, International Journal of Computers and Applications, V38, P156, DOI 10.1080/1206212X.2016.1237130
   Nandi U, 2018, SOCIAL TRANSFORMATIO, P603
   Nandi U, 2019, INNOV SYST SOFTW ENG, V15, P35, DOI 10.1007/s11334-019-00327-5
   Nandi U, 2015, ADV INTELL SYST, V340, P73, DOI 10.1007/978-81-322-2247-7_9
   Nandi U, 2013, PROC TECH, V10, P949, DOI 10.1016/j.protcy.2013.12.442
   Nandi U, 2012, 2012 INTERNATIONAL SYMPOSIUM ON ELECTRONIC SYSTEM DESIGN (ISED 2012), P306, DOI 10.1109/ISED.2012.13
   Nandi U, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT), P166, DOI 10.1109/ICCCT.2012.40
   Nelson M., 2008, DATA COMPRESSION BOO
   Nodehi A, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-112
   Roy SK, 2018, CHAOS SOLITON FRACT, V106, P16, DOI 10.1016/j.chaos.2017.11.013
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Walia E., 2010, GLOBAL J COMPUTER SC, V10, P83
   WALLACE GK, 1991, COMMUN ACM, V34, P31
   Wang JJ, 2013, IEEE T IMAGE PROCESS, V22, P3690, DOI 10.1109/TIP.2013.2268977
   Wang Q, 2016, MOB INF SYST, V2016, DOI [10.1155/2016/2159703, 10.1155/2016/8765874]
   Wang XY, 2014, NONLINEAR DYNAM, V75, P439, DOI 10.1007/s11071-013-1076-4
   Wang XY, 2010, IMAGE VISION COMPUT, V28, P1303, DOI 10.1016/j.imavis.2010.01.008
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber G, 1993, TECH REP
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   Xing CJ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P283, DOI 10.1109/CISP.2008.711
   Yates F., J ROYAL STAT SOC S, V1, P217, DOI DOI 10.2307/2983604
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhao Y, 1998, IEEE T CIRC SYST VID, V8, P269, DOI 10.1109/76.678621
NR 50
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26345
EP 26368
DI 10.1007/s11042-020-09256-z
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548495600003
DA 2024-07-18
ER

PT J
AU Wu, XT
   Yang, CN
   Yang, YY
AF Wu, Xiaotian
   Yang, Ching-Nung
   Yang, Yi-Yun
TI Sharing and hiding a secret image in color palette images with
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Steganography; Authentication; Color image;
   Palette image; Embedding
ID VISUAL CRYPTOGRAPHY; STEGANOGRAPHY; SCHEME; QUALITY; SIZE; (T
AB Existing secret image sharing (SIS) schemes with steganography and authentication are only suitable for uncompressed grayscale images. To make it more practical, a scheme for sharing and hiding a secret image in color palette images with authentication is proposed in this paper. Three commonly used system color palettes are considered. In sharing phase, a secret image is encoded into shared bits by polynomial based SIS. The shared bits are concealed into the color palette cover image to form the stego images. Meanwhile, the authentication parity bits are generated and embedded as well. Two embedding strategies are developed for the color palette images. In authentication and recovery phase, the integrity of each stego image is verified. Then, the secret image are reconstructed by sufficient authentic stego images. Experimental results are demonstrated to show the effectiveness and merits of the proposed scheme.
C1 [Wu, Xiaotian] Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
   [Yang, Ching-Nung; Yang, Yi-Yun] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 Jinan University; National Dong Hwa University
RP Wu, XT (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
EM wxt.sysu@gmail.com; cnyang@gms.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
FU National Natural Science Foundation of China [61972179, 61602211];
   Guangdong Basic and Applied Basic Research Foundation [2020A1515011476];
   Science and Technology Program of Guangzhou, China [201707010259];
   Fundamental Research Funds for the Central Universities; Ministry of
   Science and Technology [MOST 108-2221-E-259-009- MY2,
   109-2221-E-259-010]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant Nos. 61972179 and 61602211), Guangdong Basic and Applied
   Basic Research Foundation (Grant No. 2020A1515011476), Science and
   Technology Program of Guangzhou, China (Grant No. 201707010259),
   Fundamental Research Funds for the Central Universities and Ministry of
   Science and Technology, under Grant MOST 108-2221-E-259-009- MY2 and
   109-2221-E-259-010.
CR [Anonymous], 1997, HMAC KEYED HASHING M, DOI DOI 10.17487/RFC2104
   Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Blaldey G. R., 1979, P NAT COMP C, V88, P317
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Fridrich J, 2000, LECT NOTES COMPUT SC, V1768, P47
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P11903, DOI 10.1007/s11042-017-4841-4
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   JINDAL H, 2016, P INT C REC COGN WIR, P1
   Jindal H, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500133
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kabirirad S, 2018, J VIS COMMUN IMAGE R, V57, P39, DOI 10.1016/j.jvcir.2018.10.014
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kim SM, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P376, DOI 10.1109/ITNG.2009.119
   Lee JS, 2017, MULTIMED TOOLS APPL, V76, P1, DOI 10.1007/s11042-015-3011-9
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Li P, 2016, DIGIT SIGNAL PROCESS, V50, P51, DOI 10.1016/j.dsp.2015.12.004
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P18653, DOI 10.1007/s11042-019-7205-4
   Liu YX, 2018, J VIS COMMUN IMAGE R, V55, P766, DOI 10.1016/j.jvcir.2018.08.003
   Liu YX, 2017, SIGNAL PROCESS-IMAGE, V58, P49, DOI 10.1016/j.image.2017.06.011
   Liu YN, 2018, MULTIMED TOOLS APPL, V77, P6017, DOI 10.1007/s11042-017-4512-5
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   NIST SHS, 1995, TECH REP
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2018, IEEE T CIRC SYST VID, V28, P2397, DOI 10.1109/TCSVT.2017.2707923
   Swarup Kumar J. N. V. R., 2014, Oriental Journal of Computer Science and Technology, V7, P358
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wu CC, 2011, J SYST SOFTWARE, V84, P2196, DOI 10.1016/j.jss.2011.06.021
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V78, P437, DOI 10.1016/j.image.2019.08.007
   Wu XT, 2018, SIGNAL PROCESS-IMAGE, V66, P42, DOI 10.1016/j.image.2018.05.001
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Xie XZ, 2019, IET IMAGE PROCESS, V13, P1411, DOI 10.1049/iet-ipr.2018.5333
   Yan XH, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115721
   Yan XH, 2018, DIGIT SIGNAL PROCESS, V82, P80, DOI 10.1016/j.dsp.2018.07.015
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang CN, 2017, IEEE T CIRC SYS VIDE
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
NR 53
TC 7
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25657
EP 25677
DI 10.1007/s11042-020-09253-2
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545549300003
DA 2024-07-18
ER

PT J
AU Mishra, A
   Ranjan, P
   Ujlayan, A
AF Mishra, Anju
   Ranjan, Priya
   Ujlayan, Amit
TI Empirical analysis of deep learning networks for affective video tagging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective video tagging; Deep learning; CNN; Emotion classification;
   Video analysis
ID EMOTION RECOGNITION
AB This paper presents, a thorough evaluation of popular deep learning models to analyze and classify electroencephalogram (EEG) data for characterizing human affective states for video content tagging and retrieval. We use two pre-trained convolutional neural network (CNN) models AlexNet and GoogLeNet, and a Long Short Term Memory (LSTM) model to classify EEG data into appropriate affect categories using trans-domain learning. The purpose behind the use of pre-trained networks or trans-domain learning is twofold - to establish the versatility of pre-trained networks by testing their ability to classify EEG data for emotion recognition and the other is to reduce over cost of computation while training the networks. Our work tries to establish the answer of a simple question: Are pre-trained deep models versatile enough for classifying not only similar type of problems but are also effective for classifying problems pertaining to completely different domains? Also, using pre-trained models saves considerable computation time required for training a new model from scratch and fine tuning it. We use DEAP dataset for training and evaluation of these networks over a single modality 'valence' to simplify the comparison among these networks. Experiments are carried out by training the networks on EEG recordings obtained from single as well as multiple subjects to show the effects of subject-specific and generalized data on classification accuracy. Experimental results suggest the superiority of GoogLeNet for individual subject data while AlexNet outperforms other networks and has shown its capability of generalizing well. We compare the performance of these networks with state-of-art classifiers handcrafted by other authors for classifying EEG data and find that the performance of pre-trained CNNs used in our work are comparable or even better than the other handcrafted classifiers used by many authors.
C1 [Mishra, Anju] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Noida, India.
   [Ranjan, Priya] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Dept Elect & Elect Engn, Noida, India.
   [Ujlayan, Amit] Gautam Buddha Univ, Sch Vocat Studies & Appl Sci, Greater Noida, India.
C3 Amity University Noida; Amity University Noida; Gautam Buddha University
RP Mishra, A (corresponding author), Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Noida, India.
EM anju.iitd@gmail.com; pranjan@gmail.com; amitujlayan@gbu.ac.in
RI Mishra, Anju/Y-1678-2019; Ranjan, Priya/GMX-0072-2022
OI Mishra, Anju/0000-0003-4485-1520; Ranjan, Priya/0000-0003-1236-9481;
   Ujlayan, Amit/0000-0002-6045-8385
CR [Anonymous], 2016, 2016 PATT REC ASS S
   [Anonymous], 2018, J INFO HIDING MULTIM
   [Anonymous], 2014, INT JOINT C COMP SCI
   Arnau-González P, 2017, NEUROCOMPUTING, V244, P81, DOI 10.1016/j.neucom.2017.03.027
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Sang DV, 2017, INT CONF KNOWL SYS, P130, DOI 10.1109/KSE.2017.8119447
   Gupta R, 2016, NEUROCOMPUTING, V174, P875, DOI 10.1016/j.neucom.2015.09.085
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Kierkels JJM, 2009, IEEE INT CON MULTI, P1436, DOI 10.1109/ICME.2009.5202772
   Koelstra S, 2010, LECT NOTES COMPUTER, V6334, DOI [10.1007/978-3-642-15314-3_9, DOI 10.1007/978-3-642-15314-3_9]
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Li M, 2018, TECHNOL HEALTH CARE, V26, pS509, DOI 10.3233/THC-174836
   Lin WQ, 2017, LECT NOTES COMPUT SC, V10667, P385, DOI 10.1007/978-3-319-71589-6_33
   Liu JX, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1722, DOI 10.1109/FSKD.2016.7603437
   Liu W, 2016, ABS160208225 ARXIV
   Mohammadpour M, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P17
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shan MK, 2009, EXPERT SYST APPL, V36, P7666, DOI 10.1016/j.eswa.2008.09.042
   Sharma Neha, 2018, Procedia Computer Science, V132, P377, DOI 10.1016/j.procs.2018.05.198
   Tkali M, 2010, USER MODEL USER-ADAP, P1
   Yin Z, 2017, COMPUT METH PROG BIO, V140, P93, DOI 10.1016/j.cmpb.2016.12.005
   Zhang F., 2018, J. Inf. Hiding Mul- timed. Signal Process, V9, P177
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 24
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18611
EP 18626
DI 10.1007/s11042-020-08714-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800060
DA 2024-07-18
ER

PT J
AU Wedyan, M
   AL-Jumaily, A
   Dorgham, O
AF Wedyan, Mohammad
   AL-Jumaily, Adel
   Dorgham, Osama
TI The use of augmented reality in the diagnosis and treatment of autistic
   children: a review and a new system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autism diagnosis; Autism treatment; Augmented reality; Autism spectrum
   disorder; Child computer interaction
ID EXTREME LEARNING-MACHINE; SOCIAL-SKILLS; SPECTRUM DISORDER; INTELLECTUAL
   DISABILITIES; INCREASED PREVALENCE; VIRTUAL-REALITY; STUDENTS; COST;
   EDUCATION; ADULTS
AB This paper consists of two parts. The first presents a review of the literature on the use of augmented reality (AR) in the diagnosis and treatment of autistic children with a particular focus on the efficacy of AR in assisting autistic children who have communicative, social, sentiment, and attention deficit disorders. The review also investigated interactions between AR systems and children, taking into consideration the target behaviors that are selected from the child during treatment. Such modes were fully explored by taking into account the needs of the individual child in terms of achieving an improvement in their condition. Most significantly, the empirical information that was obtained from the reviewed works was evaluated according to some specific targeted attitudes and how each AR solution was utilized during treatment to achieve the fostering of such attitudes in order to identify the requirements for building an effective AR system. In addition, the review revealed the essential design features that can enable AR systems to achieve a high level of effectiveness in autism therapy. The review also covered the instruction that AR systems were noticed to execute, and focused on the significant characteristics that allow AR systems to accomplish degrees of efficacy in autism treatment. The review ends by classifying the various AR systems based on different criteria. The second part of the paper focuses on our new AR system as a case study. It covers the design considerations and decisions as well as the key features and appearance of the system. The paper concludes by making some recommendations for the further development of an AR system for application in the domain of child autism.
C1 [Wedyan, Mohammad; AL-Jumaily, Adel] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW, Australia.
   [Dorgham, Osama] Al Balqa Appl Univ, Prince Abdullah Ben Ghazi Fac Commun & Informat T, Al Salt, Jordan.
C3 University of Technology Sydney; Al-Balqa Applied University
RP Wedyan, M; AL-Jumaily, A (corresponding author), Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW, Australia.
EM MohammadOmar.M.Wedyan@student.uts.edu.au; Adel.Al-Jumaily@uts.edu.au;
   o.dorgham@bau.edu.jo
RI Wedyan, Mohammad Omar/JXY-6075-2024; Dorgham, Osama/AAM-5548-2020;
   Wedyan, Mohammad Omar/IAR-4885-2023; AL-JUMAILY, Adel/GWV-7638-2022
OI Wedyan, Mohammad Omar/0000-0001-6731-7246; Dorgham,
   Osama/0000-0001-9807-7820; Wedyan, Mohammad Omar/0000-0001-6731-7246;
   AL-JUMAILY, Adel/0000-0003-0297-2463
CR Abou El-Seoud MS, 2019, INT J ONLINE BIOMED, V15, P28, DOI 10.3991/ijoe.v15i04.9835
   Akçayir M, 2016, COMPUT HUM BEHAV, V57, P334, DOI 10.1016/j.chb.2015.12.054
   Alkhamisi A.O., 2013, International Journal of Internet and Distributed Systems, V1, P25, DOI [DOI 10.4236/IJIDS.2013.14005, 10.4236/ijids.2013.14005]
   Alsaggaf E A., 2014, LIFE SCI J, V11, P298
   Ames C, 2010, DEV REV, V30, P52, DOI 10.1016/j.dr.2009.12.003
   Anam K, 2017, NEURAL NETWORKS, V85, P51, DOI 10.1016/j.neunet.2016.09.004
   [Anonymous], 2013, ROBUST DATA MINING, DOI DOI 10.1007/978-1-4419-9878-1_4
   [Anonymous], 2001, PRISME
   Aresti-Bartolome N, 2014, INT J ENV RES PUB HE, V11, P7767, DOI 10.3390/ijerph110807767
   Ashburner J, 2016, RES AUTISM SPECT DIS, V23, P1, DOI 10.1016/j.rasd.2015.11.011
   Ashwin C, 2006, SOC NEUROSCI-UK, V1, P349, DOI 10.1080/17470910601040772
   Aung YM, 2012, PROCEDIA ENGINEER, V41, P1009, DOI 10.1016/j.proeng.2012.07.276
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bai Z, 2015, IEEE T VIS COMPUT GR, V21, P598, DOI 10.1109/TVCG.2014.2385092
   Bai Z, 2012, PROCEEDINGS OF IDC 2012: THE 11TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN, P327
   Bai Z, 2012, INT SYM MIX AUGMENT, P267, DOI 10.1109/ISMAR.2012.6402567
   Balakrishnama S., 1998, Linear discriminant analysis‐a brief tutorial, V18, P1
   Bhatt SK, 2014, INT J SMART SENS INT, V7, P519, DOI 10.21307/ijssis-2017-668
   Billard A, 2007, ASSIST TECHNOL, V19, P37, DOI 10.1080/10400435.2007.10131864
   Bimber O, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P14
   Boccanfuso L, 2010, LECT NOTES ARTIF INT, V6414, P265
   Boucher J, 2003, AUTISM, V7, P339, DOI 10.1177/1362361303007004001
   BrandAo J, 2015, AUGMENTED REALITY GA
   Buescher AVS, 2014, JAMA PEDIATR, V168, P721, DOI 10.1001/jamapediatrics.2014.210
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cai YY, 2013, IEEE T NEUR SYS REH, V21, P208, DOI 10.1109/TNSRE.2013.2240700
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Casas Xavier, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P440
   Chen CH, 2016, COMPUT HUM BEHAV, V55, P477, DOI 10.1016/j.chb.2015.09.033
   Chen CH, 2015, RES DEV DISABIL, V36, P396, DOI 10.1016/j.ridd.2014.10.015
   Cidav Z, 2012, PEDIATRICS, V129, P617, DOI 10.1542/peds.2011-2700
   Cihak DF, 2016, J SPEC EDUC TECHNOL, V31, P99, DOI 10.1177/0162643416651724
   Cook AM, 2011, DISABIL REHABIL-ASSI, V6, P338, DOI 10.3109/17483107.2010.534231
   Correa A G. D., 2004, RENOTE, V2, P1
   Crippa A, 2015, J AUTISM DEV DISORD, V45, P2146, DOI 10.1007/s10803-015-2379-8
   Cunha P, 2016, INT CONF REMOT ENGIN, P334, DOI 10.1109/REV.2016.7444495
   Datta S, 2016, LEARNING OPENCV 3 AP, P1
   Dawson G, 2000, J APPL DEV PSYCHOL, V21, P299, DOI 10.1016/S0193-3973(99)00042-8
   Dillenburger K, 2014, INT J DISABIL DEV ED, V61, P134, DOI 10.1080/1034912X.2014.905059
   Dudley C., 2014, SPP Research Paper, V7, P1
   Dunleavy M., 2014, Handbook of Research on Educational Communications and Technology, P735, DOI [DOI 10.1007/978-1-4614-3185-5_59, 10.1007/978-1-4614-3185-5_59]
   Duquette A, 2006, P 6 INT WORKSH EP RO, P167
   Dwinnell Will., 2010, Lda: Linear discriminant analysis
   Escobedo L., 2012, P SIGCHI C HUM FACT, P2589, DOI [10.1145/2207676.2208649, DOI 10.1145/2207676.2208649]
   Escobedo L, 2014, IEEE PERVAS COMPUT, V13, P38, DOI 10.1109/MPRV.2014.19
   Favela J, 2015, IEEE PERVAS COMPUT, V14, P86, DOI 10.1109/MPRV.2015.37
   Fernell Elisabeth, 2013, Clin Epidemiol, V5, P33, DOI 10.2147/CLEP.S41714
   Fletcher T., 2008, Support Vector Machines Explained
   Focaroli V, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00724
   Fountain C, 2011, J EPIDEMIOL COMMUN H, V65, P503, DOI 10.1136/jech.2009.104588
   Galna B, 2014, GAIT POSTURE, V39, P1062, DOI 10.1016/j.gaitpost.2014.01.008
   Ganz ML, 2007, ARCH PEDIAT ADOL MED, V161, P343, DOI 10.1001/archpedi.161.4.343
   Geissinger H., 1997, Proceedings of ASCILITE'97 on What Works and Why?, P219
   Geroimenko V., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P445, DOI 10.1109/IV.2012.77
   Ghose T, 2015, COMPUT ELECTR ENG, V45, P155, DOI 10.1016/j.compeleceng.2015.04.021
   Giullian N, 2010, IEEE SYS MAN CYBERN
   Greczek J, 2014, IEEE ROMAN, P561, DOI 10.1109/ROMAN.2014.6926312
   GRESHAM FM, 1987, J SPEC EDUC, V21, P167, DOI 10.1177/002246698702100115
   Hadwin J, 1996, DEV PSYCHOPATHOL, V8, P345, DOI 10.1017/S0954579400007136
   Hailpern J, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P297
   Hashemi J, 2012, J IEEE I C DEVELOP L
   HCII The Human-Computer Interaction Institute, 2014, SCAFF SCI ACH CULT D
   Herbst I., 2008, Proceedings of the 10th International Conference on Human Computer Interaction with Mobile Devices and Services, P235, DOI DOI 10.1145/1409240.1409266
   Herrera G., 2012, Annuary of Clinical and Health Psychology, V8, P39
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Hugues O, 2011, HANDBOOK OF AUGMENTED REALITY, P47, DOI 10.1007/978-1-4614-0064-6_2
   Hung SH, 2015, PERVASIVE MOB COMPUT, V24, P231, DOI 10.1016/j.pmcj.2015.08.006
   Jackson S., 2016, ART NEURAL NETWORKS, P1
   Järbrink K, 2007, AUTISM, V11, P453, DOI 10.1177/1362361307079602
   Järbrink K, 2007, RES DEV DISABIL, V28, P94, DOI 10.1016/j.ridd.2005.11.002
   Johnson CP, 2007, PEDIATRICS, V120, P1183, DOI 10.1542/peds.2007-2361
   Karimi HA, 2011, UNIVERSAL NAVIGATION ON SMARTPHONES, P1, DOI 10.1007/978-1-4419-7741-0_1
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kim J, 2017, NEURAL NETWORKS, V87, P109, DOI 10.1016/j.neunet.2016.12.002
   King M, 2009, INT J EPIDEMIOL, V38, P1224, DOI 10.1093/ije/dyp261
   King MD, 2011, AM SOCIOL REV, V76, P320, DOI 10.1177/0003122411399389
   Knapp M., 2007, Mental Health Policy and Practice across Europe: An Overview, P1
   Knapp M, 2009, AUTISM, V13, P317, DOI 10.1177/1362361309104246
   Koegel LK, 2014, INT J SPEECH-LANG PA, V16, P50, DOI 10.3109/17549507.2013.861511
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Krantz PJ, 1998, J APPL BEHAV ANAL, V31, P191, DOI 10.1901/jaba.1998.31-191
   Lakshmiprabha NS, 2014, INT SYM MIX AUGMENT, P277, DOI 10.1109/ISMAR.2014.6948448
   Lavelle TA, 2014, PEDIATRICS, V133, pE520, DOI 10.1542/peds.2013-0763
   Lee K, 2012, TECHTRENDS, V56, P13, DOI 10.1007/s11528-012-0559-3
   Li KH, 2012, TURK ONLINE J EDUC T, V11, P451
   Liarokapis F., 2010, P 31 ANN C EUR ASS C, P9, DOI DOI 10.2312/EGED.20101010
   Lima J P., 2010, Journal on 3D Interactive Systems, V1, P2, DOI [10.5753/jis.2010.560, DOI 10.5753/JIS.2010.560]
   Lin CY, 2016, DISPLAYS, V42, P51, DOI 10.1016/j.displa.2015.02.004
   Liu RP, 2017, FRONT PEDIATR, V5, DOI 10.3389/fped.2017.00145
   Liu XiaoJing Liu XiaoJing, 2014, Asian Agricultural Research, V6, P1
   López-De-Ipiña D, 2002, PERS UBIQUIT COMPUT, V6, P206, DOI 10.1007/s007790200020
   Lorenzo G, 2019, EDUC INF TECHNOL, V24, P181, DOI 10.1007/s10639-018-9768-5
   Mackay W.E., 1998, Proceedings of the working conference on Advanced visual interfaces, P13
   MARKOWITZ PI, 1983, J AUTISM DEV DISORD, V13, P249, DOI 10.1007/BF01531564
   Mazzei D, 2010, 2010 IEEE RO-MAN, P791, DOI 10.1109/ROMAN.2010.5598683
   McMahon D, 2015, J RES TECHNOL EDUC, V47, P157, DOI 10.1080/15391523.2015.1047698
   McMahon DD, 2016, J RES TECHNOL EDUC, V48, P38, DOI 10.1080/15391523.2015.1103149
   McMahon DD, 2015, J SPEC EDUC TECHNOL, V30, P157, DOI 10.1177/0162643415618927
   Mekni M., 2014, APPL COMPUTER SCI, P205
   Mendoza R.L., 2010, American Journal of Economics and Business Administration, V2, P12, DOI DOI 10.3844/AJEBASP.2010.12.19
   Michel P., 2004, Final term Paper for CSC350: Autism and Associated Developmental Disorders, ed, P1
   Microsoft, 2017, KIN WIND
   Mieke N, 2012, RES SEM SER WORKSH 1, P142
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mitchell E, 2013, SENSORS-BASEL, V13, P5317, DOI 10.3390/s130405317
   Mowatt G, 2010, HEALTH TECHNOL ASSES, V14, P1, DOI 10.3310/hta14040
   Munson J, 2012, COMPUTER, V45, P89, DOI 10.1109/MC.2012.220
   Mythili M.S., 2014, International Journal of Soft Computing and Engineering (IJSCE), V4, P88
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Otte K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166532
   Park H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P272, DOI 10.1109/ISMAR.2004.37
   Pashler HE, 1998, PSYCHOL ATTENTION, V15, P1
   Pettersson C, 2014, CHALLENGES SESSION S
   Phan VietToan., 2010, International Journal of Computer Applications, V5, P16, DOI DOI 10.5120/912-1290
   Philip RCM, 2009, THESIS
   Prinz J., 2004, Emotion, evolution, and rationality, P1
   Quintana Eduardo, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P877, DOI 10.1007/978-3-642-33275-3_108
   Raajan NR, 2012, PROCEDIA ENGINEER, V38, P1559, DOI 10.1016/j.proeng.2012.06.191
   Radhakrishnan S., 2015, Indian Journal of Science, V21, P385
   Richard E, 2007, 2007 VIRTUAL REHABILITATION, P100
   Ricks DJ, 2010, P 2010 INT C APPL BI, P14
   Ringland KE, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P873, DOI 10.1145/2632048.2632065
   Rothacker L., 2013, ACM, P1, DOI [10.1145/2505377.2505384, DOI 10.1145/2505377]
   Russell R A., 2004, International Journal of Humanoid Robotics, V1, P289
   Sahin NT, 2018, J CLIN MED, V7, DOI 10.3390/jcm7080188
   Sahin NT, 2018, LONGITUDINAL PILOT S, P1
   Satsangi R, 2017, PREV SCH FAIL, V61, P303, DOI 10.1080/1045988X.2016.1275505
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Scherer K.R., 1987, GENEVA STUDIES EMOTI, V1, P1
   Sharpe DL, 2011, COMPREHENSIVE BOOK ON AUTISM SPECTRUM DISORDERS, P275
   Sigman M, 2006, ANNU REV CLIN PSYCHO, V2, P327, DOI 10.1146/annurev.clinpsy.2.022305.095210
   Sree MS, 2013, INT J SCI ENG RES, V4, P1469
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Taffoni F, 2014, IEEE ENG MED BIO, P3638, DOI 10.1109/EMBC.2014.6944411
   Tang A., 2004, Proceedings of Presence, Seventh Annual International Workshop on Presence, Valencia, Spain, P204
   Tang TY, 2019, 3RD INTERNATIONAL CONFERENCE ON INNOVATION IN ARTIFICIAL INTELLIGENCE (ICIAI 2019), P65, DOI 10.1145/3319921.3319945
   Tentori M, 2015, IEEE PERVAS COMPUT, V14, P42, DOI 10.1109/MPRV.2015.22
   Veeraraghavan S, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P261
   Vullamparthi AJ, 2013, IEEE CONF TECHNOL ED, P43, DOI 10.1109/T4E.2013.18
   Wainer J., 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P631, DOI 10.1109/ICHR.2010.5686346
   Wang M, 2011, NEUROEPIDEMIOLOGY, V36, P2, DOI 10.1159/000320847
   Wedyan M., 2018, INT C HYBR INT SYST, P491
   Wedyan M., 2017, Intelligent Systems and Knowledge Engineering (ISKE), 2017 12th International Conference on, P1
   Wedyan M, 2016, 2016 IEEE INTERNATIONAL SYMPOSIUM ON ROBOTICS AND INTELLIGENT SENSORS (IRIS), P13, DOI 10.1109/IRIS.2016.8066059
   Weiss MJ, 2001, BEHAV MODIF, V25, P785, DOI 10.1177/0145445501255007
   Wolfberg P, 2012, AM J PLAY, V5, P55
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yantaç AE, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY WORKSHOPS, P68, DOI 10.1109/ISMARW.2015.21
   Yee HSS, 2012, 2012 IEEE SYMPOSIUM ON E-LEARNING, E-MANAGEMENT AND E-SERVICES (IS3E 2012), P6
   You S, 1999, P IEEE VIRT REAL ANN, P260, DOI 10.1109/VR.1999.756960
   You ZH, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-S8-S10
   Yuen S.C.Y., 2011, J. Educ. Technol. Dev. Exch. (JETDE), V4, P11, DOI [10.18785/jetde.0401.10, DOI 10.18785/JETDE.0401.10]
   Zaidan AA, 2015, DECIS SUPPORT SYST, V78, P15, DOI 10.1016/j.dss.2015.07.002
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zhu QY, 2005, PATTERN RECOGN, V38, P1759, DOI 10.1016/j.patcog.2005.03.028
   Zwaigenbaum L, 2005, INT J DEV NEUROSCI, V23, P143, DOI 10.1016/j.ijdevneu.2004.05.001
NR 159
TC 18
Z9 18
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18245
EP 18291
DI 10.1007/s11042-020-08647-6
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800044
DA 2024-07-18
ER

PT J
AU Li, Q
   Yu, GY
   Wang, J
   Liu, YH
AF Li, Qing
   Yu, Guanyuan
   Wang, Jun
   Liu, Yuehao
TI A deep multimodal generative and fusion framework for class-imbalanced
   multimodal data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal classification; Class-imbalanced data; Deep multimodal
   generative adversarial network; Deep multimodal hybrid fusion network
ID SMOTE
AB The purpose of multimodal classification is to integrate features from diverse information sources to make decisions. The interactions between different modalities are crucial to this task. However, common strategies in previous studies have been to either concatenate features from various sources into a single compound vector or input them separately into several different classifiers that are then assembled into a single robust classifier to generate the final prediction. Both of these approaches weaken or even ignore the interactions among different feature modalities. In addition, in the case of class-imbalanced data, multimodal classification becomes troublesome. In this study, we propose a deep multimodal generative and fusion framework for multimodal classification with class-imbalanced data. This framework consists of two modules: a deep multimodal generative adversarial network (DMGAN) and a deep multimodal hybrid fusion network (DMHFN). The DMGAN is used to handle the class imbalance problem. The DMHFN identifies fine-grained interactions and integrates different information sources for multimodal classification. Experiments on a faculty homepage dataset show the superiority of our framework compared to several start-of-the-art methods.
C1 [Li, Qing; Yu, Guanyuan; Wang, Jun; Liu, Yuehao] SouthWestern Univ Finance & Econ, Fintech Innovat Ctr, Chengdu, Peoples R China.
   [Li, Qing; Yu, Guanyuan; Wang, Jun; Liu, Yuehao] SouthWestern Univ Finance & Econ, Sch Econ Informat Engn, Chengdu, Peoples R China.
C3 Southwestern University of Finance & Economics - China; Southwestern
   University of Finance & Economics - China
RP Yu, GY (corresponding author), SouthWestern Univ Finance & Econ, Fintech Innovat Ctr, Chengdu, Peoples R China.; Yu, GY (corresponding author), SouthWestern Univ Finance & Econ, Sch Econ Informat Engn, Chengdu, Peoples R China.
EM kennis.yu@smail.swufe.edu.cn
RI Yu, Guanyuan/JBI-8521-2023
FU National Natural Science Foundation of China (NSFC) [71671141,
   71873108]; National Social Science Foundation of China (NSSFC)
   [19BFX120]; Fundamental Research Funds for the Central Universities [JBK
   171113, JBK 170505, JBK 1806003, JBK 2002030]; Science and Technology
   Department of Sichuan Province [2019YJ0250]; Fintech Innovation Center
   of Southwestern University of Finance and Economics; Financial
   Intelligence and Financial Engineering Key Laboratory of Sichuan
   Province
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) (71671141 and 71873108), the National Social Science
   Foundation of China (NSSFC) (Grant No. 19BFX120), the Fundamental
   Research Funds for the Central Universities (JBK 171113, JBK 170505, JBK
   1806003, and JBK 2002030), the Science and Technology Department of
   Sichuan Province (2019YJ0250), the Fintech Innovation Center of
   Southwestern University of Finance and Economics, and the Financial
   Intelligence and Financial Engineering Key Laboratory of Sichuan
   Province.
CR Ai CR, 2003, ECON LETT, V80, P123, DOI 10.1016/S0165-1765(03)00032-6
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Basu A, 1976, ELEMENTARY STAT THEO, V12
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Choi H, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P18, DOI 10.1109/ICOIN.2018.8343076
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dal Pozzolo A, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P159, DOI 10.1109/SSCI.2015.33
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Douzas G, 2018, INFORM SCIENCES, V465, P1, DOI 10.1016/j.ins.2018.06.056
   Douzas G, 2018, EXPERT SYST APPL, V91, P464, DOI 10.1016/j.eswa.2017.09.030
   Dwibedi D, 2019, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2019.00190
   Farnadi G, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P171, DOI 10.1145/3159652.3159691
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo WZ, 2019, IEEE ACCESS, V7, P63373, DOI 10.1109/ACCESS.2019.2916887
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Khaleghi B, 2013, INFORM FUSION, V14, P28, DOI 10.1016/j.inffus.2011.08.001
   Kingma D. P., 2014, arXiv
   Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027
   Li Q, 2021, IEEE T KNOWL DATA EN, V33, P3323, DOI 10.1109/TKDE.2020.2968894
   Li Q, 2017, MULTIMED TOOLS APPL, V76, P12315, DOI 10.1007/s11042-016-3643-4
   Li Q, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2838731
   Li Q, 2014, DECIS SUPPORT SYST, V61, P93, DOI 10.1016/j.dss.2014.01.013
   Li YZ, 2018, PR MACH LEARN RES, V80
   Louzada F, 2012, EXPERT SYST APPL, V39, P8071, DOI 10.1016/j.eswa.2012.01.134
   Lu YY, 2007, PROC INT CONF DATA, P351
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Mathieu M., 2016, Neural Information Processing Symposium, pages, P5041
   METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2
   Morvant E, 2014, LECT NOTES COMPUT SC, V8621, P153, DOI 10.1007/978-3-662-44415-3_16
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Oshri B, 2015, THERE BACK AUTOENCOD
   Pearson R, 2003, P INT C MACHINE LEAR, V3
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Qi XG, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459357
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Roth K, 2017, ADV NEUR IN, V30
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Sprent P., 2000, APPL NONPARAMETRIC S, V3rd
   Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017
   Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sun J, 2018, INFORM SCIENCES, V425, P76, DOI 10.1016/j.ins.2017.10.017
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Suzuki M, 2017, POLIT ECON ASIA PAC, P1, DOI 10.1007/978-4-431-56466-9_1
   Tsai CF, 2019, INFORM SCIENCES, V477, P47, DOI 10.1016/j.ins.2018.10.029
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   VARTAK MN, 1955, ANN MATH STAT, V26, P420, DOI 10.1214/aoms/1177728488
   Wu MK, 2018, ADV NEUR IN, V31
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yih WT, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P643
   Yu GY, 2020, INFORM SCIENCES, V525, P205, DOI 10.1016/j.ins.2020.03.005
   Zhang C, 2020, IEEE J-STSP, V14, P478, DOI 10.1109/JSTSP.2020.2987728
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 62
TC 7
Z9 7
U1 4
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 25023
EP 25050
DI 10.1007/s11042-020-09227-4
EA JUN 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543948700002
DA 2024-07-18
ER

PT J
AU Aldissi, B
   Ammar, H
AF Aldissi, Bahya
   Ammar, Heyfa
TI Real-time frequency-based detection of a panic behavior in human crowds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time detection; Crowded scenes; Abnormal behaviors; Frequency
   domain; Clustering data
ID ONLINE
AB The real-time detection of a panic behavior in a human crowd is of a high interest as it helps alleviating crowd disasters and ensures that timely appropriate action will be taken. However, the fast analysis of video sequences to detect abnormal behaviours is one of the most challenging tasks for computer vision experts. While many research works propose off-line solutions, few studies investigate the real-time analysis of crowded scenes. This may be due to the fact that detecting a panic behaviour is closely related to the analysis of the crowd dynamics, which commonly necessitates heavy computations. In order to alleviate this problem, we propose a real-time panic detection technique that analyzes the crowd movements based on a simple and efficient solution. The key idea of the proposed approach consists of analyzing the interactions between moving edges along the video in the frequency domain. Our contribution is threefold. First, moving edges are considered for analysis along the video. Second, when a panic situation occurs within a human crowd, it leads to interactions between people that are different from those that occur during a normal situation. Therefore, to reveal such a behavior, a new frequency based-feature is proposed. To select the most appropriate frequency domain, the fast fourier transform, the discrete cosine transform and the discrete wavelet transform are investigated. Third, two different formulations of the problem of detecting a panic are explored. The experimental evaluation of the proposed technique shows its outperforming compared to the state-of-the-art approaches in terms of detection rates and execution time.
C1 [Aldissi, Bahya] King Abdulaziz Univ, FCIT, Jeddah, Saudi Arabia.
   [Ammar, Heyfa] Univ Tunis El Manar, Natl Engn Sch Tunis, Lab Robot Informat & Complex Syst RISC Lab, Tunis, Tunisia.
C3 King Abdulaziz University; Universite de Tunis-El-Manar; Ecole Nationale
   d'Ingenieurs de Tunis (ENIT)
RP Ammar, H (corresponding author), Univ Tunis El Manar, Natl Engn Sch Tunis, Lab Robot Informat & Complex Syst RISC Lab, Tunis, Tunisia.
EM behaldissi@kau.edu.sa; heyfa.amar@gmail.com
RI ammar, heyfa/AAV-2685-2020; ammar, Heyfa/B-7922-2015
OI ammar, heyfa/0000-0002-2444-6635; 
FU Deanship of Scientific Research (DSR), King Abdulaziz University, Jeddah
   [DG-046-612-1140]
FX This project was funded by the Deanship of Scientific Research (DSR),
   King Abdulaziz University, Jeddah, under grant No. (DG-046-612-1140).
   The authors, therefore, gratefully acknowledge the DSR technical and
   financial support.
CR Agency TOSP, 2015, HAJJ CIV DEF 150 PIL
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2009, FINDING GROUPS DATA
   [Anonymous], 2013, LIT REV VIDEO ANAL C
   [Anonymous], 1996, Adapted Wavelet Analysis: From Theory to Software
   BERGLAND GD, 1969, IEEE SPECTRUM, V6, P41, DOI 10.1109/MSPEC.1969.5213896
   BLEISTEIN N, 1987, GEOPHYSICS, V52, P931, DOI 10.1190/1.1442363
   Cai CS, 1998, J CHEM INF COMP SCI, V38, P1161, DOI 10.1021/ci980210j
   Catherine ES, 2016, FOOTAGE SHOWS SUSPEC
   Chen DY, 2011, J VIS COMMUN IMAGE R, V22, P178, DOI 10.1016/j.jvcir.2010.12.004
   Daubechies I., 1991, P CBMS NSF REGIONAL, V61, P4
   Ferryman JA, 2009, PETS2009BENCHMARKDAT
   Firdaus S., 2015, International_Journal_of_Computer_Science_Issues_(IJCSI), V12, P62
   FORGY EW, 1965, BIOMETRICS, V21, P768
   Fradi H, 2017, IEEE T CIRC SYST VID, V27, P589, DOI 10.1109/TCSVT.2016.2615443
   Fradi H, 2015, INFORM FUSION, V24, P3, DOI 10.1016/j.inffus.2014.09.005
   Guardian T, 2017, MORE DOZEN FANS KILL
   Gunduz AE, 2016, IET COMPUT VIS, V10, P374, DOI 10.1049/iet-cvi.2015.0345
   Guogang Xiong, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P495, DOI 10.1109/ICINFA.2011.5949043
   LEWIS AS, 1991, ELECTRON LETT, V27, P171, DOI 10.1049/el:19910110
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Maurus S, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1055, DOI 10.1145/2939672.2939740
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nady A., 2018, J THEORY APPL INF TE, V96, P6064
   Pennisi A, 2016, COMPUT VIS IMAGE UND, V144, P166, DOI 10.1016/j.cviu.2015.09.010
   Rabiee H, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P95, DOI 10.1109/AVSS.2016.7738074
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566
   Sajana T., 2016, INDIAN J SCI TECHNOL, V9, P1
   Shehab D, 2018, MACH VISION APPL, V30, P1
   SHENG YL, 1992, OPT ENG, V31, P1840, DOI 10.1117/12.59916
   Stanford University, 2016, WAVELAB 850
   University of Minnesota, 2006, UN CROWD ACT DAT
   Wang J, 2016, COMPUT VIS IMAGE UND, V144, P177, DOI 10.1016/j.cviu.2015.08.010
   Wang LJ, 2012, IEEE IMAGE PROC, P2701, DOI 10.1109/ICIP.2012.6467456
   Wang Q, 1999, INT J SOLIDS STRUCT, V36, P3443, DOI 10.1016/S0020-7683(98)00152-8
   waze digital, 2001, CLOUD DIG ASS MAN PL
   waze digital, 1966, CLOUD DIG ASS MAN PL
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Wu S, 2014, IEEE T CIRC SYST VID, V24, P85, DOI 10.1109/TCSVT.2013.2276151
   Yinghuan Shi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3653, DOI 10.1109/ICPR.2010.891
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
NR 43
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24851
EP 24871
DI 10.1007/s11042-020-09024-z
EA JUN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543615200002
DA 2024-07-18
ER

PT J
AU Prandi, C
   Ceccarini, C
   Nisi, V
   Salomoni, P
AF Prandi, Catia
   Ceccarini, Chiara
   Nisi, Valentina
   Salomoni, Paola
TI Designing interactive infographics to stimulate environmental awareness:
   an exploration with a University community
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infographic; User's awareness; University community; Evaluating
   interactive systems; Sustainability
ID FOOD; VISUALIZATION; CONSUMPTION; PERSUASION
AB The Sustainable Development Goals (SDGs) are a universal call to action addressed not only to governments but also to businesses and civil society. In this scenario, Universities play a key role in achieving the SDGs and, also, in creating awareness about these global issues. As an example, the University of Bologna is carrying out several initiatives related to sustainability matters. Considering, in particular, the environmental dimension, the University undertook different strategies to reduce the waste of paper, embracing the dematerialization and paperless movements. To make these initiatives visible to the University community and to increase awareness about these issues, we designed a system that intends to provide data related to the implications of such initiatives in terms of paper waste avoided and benefits for the environment, to be exploited using different devices. In particular, this study focuses on the design and the evaluation of two infographics, conceived by two different groups of experts and researchers: one "animated" and one "aesthetic". The evaluation intends to present the differences in terms of perceived design and informative dimensions, with the final aim to present insights on the design of infographics able to foster awareness, targeting specific communities.
C1 [Prandi, Catia; Ceccarini, Chiara; Salomoni, Paola] Univ Bologna, Bologna, Italy.
   [Prandi, Catia; Nisi, Valentina] ITI LARSYS, Madeira, Portugal.
   [Nisi, Valentina] Univ Madeira, Madeira, Portugal.
C3 University of Bologna; Universidade da Madeira
RP Prandi, C (corresponding author), Univ Bologna, Bologna, Italy.; Prandi, C (corresponding author), ITI LARSYS, Madeira, Portugal.
EM catia.prandi2@unibo.it; chiara.ceccarini6@unibo.it;
   valentina.nisi@gmail.com; paola.salomoni@unibo.it
RI Ceccarini, Chiara/ADI-6093-2022; Prandi, Catia/KIB-1268-2024; Nunes,
   Nuno Jardim/M-4006-2013; Nisi, Valentina/G-8658-2018
OI Ceccarini, Chiara/0000-0001-9743-5833; Prandi,
   Catia/0000-0002-5566-2269; Nunes, Nuno Jardim/0000-0002-2498-0643; Nisi,
   Valentina/0000-0002-8051-3230
CR Åborg C, 2003, BEHAV INFORM TECHNOL, V22, P389, DOI 10.1080/01449290310001624338
   [Anonymous], 2015, TRANSF OUR WORLD 203, DOI DOI 10.1201/B20466-7
   [Anonymous], 2014, ONLINE J ISSUES NURS
   [Anonymous], 1998, Interactions, DOI DOI 10.1145/274430.274432
   Antle AN, 2011, LECT NOTES COMPUT SC, V6947, P194, DOI 10.1007/978-3-642-23771-3_16
   Antle AN, 2011, P 5 INT C TANG EMB E, DOI [10.1145/1935701.1935721, DOI 10.1145/1935701.1935721]
   Arney J., 2012, Journal of Sustainability and Green Business, V1, P1
   Beckline Mukete, 2016, J ENERGY ENV CHEM EN
   Bendor R, 2017, ECOL SOC, V22, DOI 10.5751/ES-09240-220217
   Blanco Angeles, 2004, PEER REV CHALLENGES
   Botros F., 2016, P INT WORK C ADV VIS, P112, DOI DOI 10.1145/2909132.2909267
   Cairo A., 2012, The Functional Art: An Introduction to Information Graph. and Visualization
   Comber R, 2013, PERS UBIQUIT COMPUT, V17, P1197, DOI 10.1007/s00779-012-0587-1
   Compass SDG, 2015, GUIDE BUSINESS ACTIO
   Crowther TW, 2015, NATURE, V525, P201, DOI 10.1038/nature14967
   De Bonis S., 2011, Going Green: Managing a Paperless Classroom
   DeRosa J, 2007, GREEN PDF REDUCING G
   DiSalvo C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1975
   Dourish P., 2010, P 8 ACM C DES INT SY, P1, DOI [DOI 10.1145/1858171.1858173, 10.1145/1858171.1858173, 10.1637/8406-071008-Reg.1]
   Egan C, 2017, DIS'17 COMPANION: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P39, DOI 10.1145/3064857.3079115
   Fogg B.J., 2007, The_Human_Computer_Interaction Handbook:_Fundamentals,_Evolving_Technologies_and_Emerging_Applications, P159, DOI DOI 10.1201/9781410615862
   Gupta Sonal, 2015, GLOBAL J ENTERPRISE, V7, P1
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Hill Justene G., 2015, THESIS
   Holmes T, 2007, CC2007-CREATIVITY AND COGNITION 2007 SEEDING CREATIVITY: TOOLS, MEDIA, AND ENVIRONMENTS, P153
   Iqbal H., 2015, IOSR J ENV SCI TOXIC, V9, P10
   Jacobs R., 2013, CONVERSATION TREES W, P129
   Kim T, 2010, LECT NOTES COMPUT SC, V6137, P106
   Kosara R, 2016, IEEE COMPUT GRAPH, V36, P80, DOI 10.1109/MCG.2016.2
   Lee BX, 2016, J PUBLIC HEALTH POL, V37, pS13, DOI 10.1057/s41271-016-0002-7
   Locoro A, 2017, COMPUT HUM BEHAV, V71, P240, DOI 10.1016/j.chb.2017.01.032
   McMullen A, 2011, BOTTOM LINE, V24, P58, DOI 10.1108/08880451111142097
   Odom W, 2008, WORKSH OZCHI 2008
   Orantes-Jimenez S.D., 2015, Systemics, Cybernetics and Informatics, V13, P47
   Pimentel D, 1997, HUM ECOL, V25, P91, DOI 10.1023/A:1021987920278
   Plaisant C., 2004, Proceedings of the Working Conference on Advanced Visual Interfaces, AVI'04, page, P109, DOI [10.1145/989863.9898802, DOI 10.1145/989863.9898802, 10.1145/989863.989880, DOI 10.1145/989863.989880]
   Pokric Boris., 2015, 2015 International Conference on Recent Advances in Internet of Things (RIoT), P1, DOI [10.1109/RIOT.2015.7104905, DOI 10.1109/RIOT.2015.7104905]
   Potapov P, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1600821
   Pousman Z, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P13
   Prandi C, 2019, PROCEEDINGS OF THE 5TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS 2019), P189, DOI 10.1145/3342428.3342688
   Prandi C, 2020, MOBILE NETW APPL, V25, P945, DOI 10.1007/s11036-019-01238-2
   Rist T, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3030056
   Ruini L, 2016, AGRIC AGRIC SCI PROC, V8, P482, DOI 10.1016/j.aaspro.2016.02.049
   Smith Richard, ENV SUSTAINABILITY P
   Sun MX, 2018, RENEW SUST ENERG REV, V92, P823, DOI 10.1016/j.rser.2018.04.036
   Thieme A, 2012, P 2012 ACM ANN C HUM, DOI [10.1145/2207676.2208394, DOI 10.1145/2207676.2208394]
   Tse R, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P55, DOI 10.1145/3284869.3284880
   United Nations, 2015, FORESTS
   Valkanova N., 2013, P CHI 13, P3461
   Vatavu RD, 2013, MULTIMED TOOLS APPL, V66, P59, DOI 10.1007/s11042-012-1140-y
NR 50
TC 5
Z9 5
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 12951
EP 12968
DI 10.1007/s11042-020-09140-w
EA JUN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000543615200006
DA 2024-07-18
ER

PT J
AU Rahman, A
   Anam, ASM I
   Yeasin, M
AF Rahman, AKMMahbubur
   Anam, A. S. M. Iftekhar
   Yeasin, Mohammed
TI Robust modeling of epistemic mental states
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epistemic mental states; Emotions; Nonlinear relations; Human computer
   interaction; Dyadic social context; Machine learning
ID EMOTION; CUES; AGREEMENT; LANGUAGE
AB This work identifies and advances some research challenges in the analysis of facial features and their temporal dynamics with epistemic mental states in dyadic conversations. Epistemic states are: Agreement, Concentration, Thoughtful, Certain, and Interest. In this paper, we perform a number of statistical analyses and simulations to identify the relationship between facial features and epistemic states. Non-linear relations are found to be more prevalent, while temporal features derived from original facial features have demonstrated a strong correlation with intensity changes. Then, we propose a novel prediction framework that takes facial features and their nonlinear relation scores as input and predict different epistemic states in videos. The prediction of epistemic states is boosted when the classification of emotion changing regions such as rising, falling, or steady-state are incorporated with the temporal features. The proposed predictive models can predict the epistemic states with significantly improved accuracy: correlation coefficient (CoERR) for Agreement is 0.827, for Concentration 0.901, for Thoughtful 0.794, for Certain 0.854, and for Interest 0.913.
C1 [Rahman, AKMMahbubur] Independent Univ Bangladesh, Dhaka, Bangladesh.
   [Anam, A. S. M. Iftekhar] Univ Wisconsin, Green Bay, MO USA.
   [Yeasin, Mohammed] Univ Memphis, Memphis, TN 38152 USA.
C3 Independent University Bangladesh (IUB); University of Memphis
RP Rahman, A (corresponding author), Independent Univ Bangladesh, Dhaka, Bangladesh.
EM akmmrahman@iub.edu.bd; anami@uwgb.edu; myeasin@memphis.edu
CR Afzal Shazia, 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P438, DOI 10.1109/ICALT.2010.127
   Aleven V., 2006, INT J ARTIFICIAL INT, V16, P101
   [Anonymous], 1962, Affect imagery consciousness: Volume I: The positive affects
   Arango-Muñoz S, 2014, PHILOS INQ, V2, P97
   Arango-Muñoz S, 2014, PHILOS PSYCHOL, V27, P193, DOI 10.1080/09515089.2012.732002
   Atkinson A.P., 2005, EMOTION CONSCIOUSNES, P150
   Azevedo R., 2009, 2009 AAAI FALL S SER
   Baron-Cohen S., 2007, Mind reading: the interactive guide to emotions-version 1.3
   BARTLETT MS, 2006, J MULTIMEDIA, P223
   BEE N, 2009, ACII WORKSH 2009
   Borg J., 2015, ASSISTIVE TECHNOLOGY
   Borras-Comes J., 2011, Proceedings of GESPIN
   Bosch N., 2016, IJCAI, P4125
   Bosch N, 2014, LECT NOTES COMPUT SC, V8474, P39, DOI 10.1007/978-3-319-07221-0_5
   Bousmalis K, 2013, IMAGE VISION COMPUT, V31, P203, DOI 10.1016/j.imavis.2012.07.003
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Carletta J, 2003, BEHAV RES METH INS C, V35, P353, DOI 10.3758/BF03195511
   CARTERETTE EC, 1996, HDB PERCEPTION COGNI
   Cheon YJ, 2009, PATTERN RECOGN, V42, P1340, DOI 10.1016/j.patcog.2008.10.010
   Cohn JF, 2010, IEEE SIGNAL PROC MAG, V27, P128, DOI 10.1109/MSP.2010.938102
   Cohn JF, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P491, DOI 10.1109/ICMI.2002.1167045
   Craig S.D., 2004, E LEARN WORLD C E LE, P264
   D'Errico F, 2016, J E-LEARN KNOWL SOC, V12, P9
   D'Mello S.K., 2012, ACM Transactions on Interactive Intelligent Systems, V2, P1, DOI DOI 10.1145/2395123.2395128
   D'Mello S, 2007, IEEE INTELL SYST, V22, P53, DOI 10.1109/MIS.2007.79
   D'Mello S, 2007, FRONT ARTIF INTEL AP, V158, P161
   D'Mello SK, 2010, USER MODEL USER-ADAP, V20, P147, DOI 10.1007/s11257-010-9074-4
   da SousaR., 2009, MIND MATTER, V7, P139
   De Carolis B, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE WORKSHOPS (WI 2019 COMPANION), P80, DOI 10.1145/3358695.3361748
   DERRICO F, 2018, COGNITIVE EMOTIONS L
   Devillers L., 2006, Real-life emotions detection with lexical and paralinguistic cues on Human-Human call center dialogs, P801
   Dimberg U, 2000, PSYCHOL SCI, V11, P86, DOI 10.1111/1467-9280.00221
   Forbes-Riley K, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P201
   Goleman Daniel, 1995, Emotional Intelligence: Why It Can Matter More Than IQ
   Gordon G, 2016, AAAI CONF ARTIF INTE, P3951
   Grafsgaard JF, 2011, LECT NOTES ARTIF INT, V6738, P98, DOI 10.1007/978-3-642-21869-9_15
   Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697
   Huang G.B., 2007, E.: Labeled faces in the wild: A database for studying face recognition in unconstrained environments
   Hung H, 2010, IEEE T MULTIMEDIA, V12, P563, DOI 10.1109/TMM.2010.2055233
   Jackson MC, 2009, J EXP PSYCHOL HUMAN, V35, P363, DOI 10.1037/a0013895
   Knapp M.L., 2013, Cengage Learning
   Kort B, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P43, DOI 10.1109/ICALT.2001.943850
   Krithika LB, 2016, PROCEDIA COMPUT SCI, V85, P767, DOI 10.1016/j.procs.2016.05.264
   LAMB TA, 1981, SOC PSYCHOL QUART, V44, P49, DOI 10.2307/3033863
   LANZINI S, 2013, THESIS
   Nguyen L, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P289
   Lee C.M., 2002, P ICSLP
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Littlewort Gwen C., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P30, DOI 10.1109/FG.2011.5771418
   Mahmoud Marwa, 2011, C AFF COMP INT INT
   Mandler G., 1975, MIND EMOTION
   McDaniel B., 2007, P ANN M COGNITIVE SC
   McDaniel T, 2018, PROCEEDINGS OF THE 2018 WORKSHOP ON MULTIMEDIA FOR ACCESSIBLE HUMAN COMPUTER INTERFACE (MAHCI'18), P25, DOI 10.1145/3264856.3264860
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Mehu M, 2014, J NONVERBAL BEHAV, V38, P569, DOI 10.1007/s10919-014-0192-2
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Pachman M, 2016, AUSTRAL J ED TECHNOL, V6, P32
   Palm G., 2013, Neural Nets and Surroundings, P323
   PARKINSON B, 1993, COGNITION EMOTION, V7, P295, DOI 10.1080/02699939308409191
   POGGI I, 2010, COGNITIVE COMPUTATIO, V10
   Rahman AKMM, 2017, MULTIMED TOOLS APPL, V76, P7699, DOI 10.1007/s11042-016-3295-4
   Reshef DN, 2011, SCIENCE, V334, P1518, DOI 10.1126/science.1205438
   Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377
   SCHNEIDER K, 1992, COGNITION EMOTION, V6, P37, DOI 10.1080/02699939208411057
   Stratou G, 2017, INT CONF AFFECT, P427, DOI 10.1109/ACII.2017.8273635
   TIAN YL, 2001, RECOGNIZING FACIAL A
   Vapnik V, 1997, ADV NEUR IN, V9, P281
   VINCIARELLI A, 2009, 2009 3 INT C AFF COM, P1
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zeng ZH, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P126
NR 70
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35785
EP 35809
DI 10.1007/s11042-020-09145-5
EA JUN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000540671300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Saoud, A
   Oumane, A
   Ouafi, A
   Taleb-Ahmed, A
AF Saoud, Adel
   Oumane, Abdelmalik
   Ouafi, Abdelkrim
   Taleb-Ahmed, Abdelmalik
TI Multimodal 2d+3d multi-descriptor tensor for face verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face verification; Multilinear principal component analysis (MPCA);
   Multilinear discriminant analysis (MDA); Dimensionality reduction;
   Subspace tensor; Fusion 2D-3D modalities
ID DISCRIMINANT-ANALYSIS; HYBRID APPROACH; 3D; RECOGNITION; EXPRESSIONS; 2D
AB In the last few years, there is a growing interest in multilinear subspace learning for dimensionality reduction of multidimensional data. In this paper, we proposed a multimodal 2D + 3D face verification system based on Multilinear Discriminant Analysis MDA integrating Within Class Covariance Normalization WCCN technique. Histograms of local descriptor applied to features extraction from 2D and 3D face images are concatenated and organized as a tensor design. This tensor is then reduced and projected using MDA technique into a lower subspace. WCCN technique is used to reduce the effect of the intra class directions using normalisation transform and to enhance the discrimination power of the MDA. Our experiments were carried out on the three biggest databases: FRGC v2.0, Bosphorus and CASIA 3D under expressions, occlusions and pose variations. Experimental results showed the superiority of the proposed approach in term of verification rate when compared to the state of the art method.
C1 [Saoud, Adel; Oumane, Abdelmalik; Ouafi, Abdelkrim] Univ Biskra, Biskra, Algeria.
   [Taleb-Ahmed, Abdelmalik] Univ Valenciennes, Valenciennes, France.
C3 Universite Mohamed Khider Biskra; Universite Polytechnique
   Hauts-de-France
RP Saoud, A (corresponding author), Univ Biskra, Biskra, Algeria.
EM adel.saoud2013@gmail.com; ouamaneabdealmalik@yahoo.fr;
   ou_karim@yahoo.fr; abdelmalik.taleb-ahmed@univ-valenciennes.fr
CR Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0
   Ammar C, 2016, J INF PROCESS SYST, V12, P468, DOI 10.3745/JIPS.02.0037
   [Anonymous], 2006, 9 INT C SPOK LANG PR
   [Anonymous], 2017, SENSORS BASEL, DOI DOI 10.3390/s17081862
   Bagchi P., 2014, INT J FDN COMPUTER S, V4, P21
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bessaoudi M, 2019, APPL INTELL, V49, P1339, DOI 10.1007/s10489-018-1318-8
   Bessaoudi M, 2019, LECT NOTE NETW SYST, V50, P215, DOI 10.1007/978-3-319-98352-3_23
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Chouchane A, 2018, MULTIMED TOOLS APPL, V77, P20697, DOI 10.1007/s11042-017-5478-z
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Elaiwat S, 2015, PATTERN RECOGN, V48, P1235, DOI 10.1016/j.patcog.2014.10.013
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Feng JY, 2019, ADV INTELL SYST COMP, V670, P123, DOI 10.1007/978-981-10-8971-8_12
   Guo YC, 2018, INFORMATION, V9, DOI 10.3390/info9030048
   Hu HY, 2017, TENCON IEEE REGION, P133, DOI 10.1109/TENCON.2017.8227850
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kannala J, 2012, INT C PATT RECOG, P1363
   Li M, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P1419
   Liu CJ, 1998, INT C PATT RECOG, P1368, DOI 10.1109/ICPR.1998.711956
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Ming Y, 2014, NEUROCOMPUTING, V129, P445, DOI 10.1016/j.neucom.2013.09.014
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Olivetti EC, 2020, LECT N MECH ENG, P665, DOI 10.1007/978-3-030-31154-4_56
   Ouamane A, 2016, SIGNAL IMAGE VIDEO P, V10, P129, DOI 10.1007/s11760-014-0712-x
   Ouamane A, 2017, COMPUT ELECTR ENG, V62, P68, DOI 10.1016/j.compeleceng.2017.01.001
   Ouamane A, 2017, IEEE T INF FOREN SEC, V12, P2751, DOI 10.1109/TIFS.2017.2718490
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Song W, 2004, MULTIPHASE PHENOMENA AND CFD MODELING AND SIMULATION IN MATERIALS PROCESSES, P23
   Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200
   Xu CH, 2009, PATTERN RECOGN, V42, P1895, DOI 10.1016/j.patcog.2009.01.001
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang TP, 2010, IEEE T SYST MAN CY B, V40, P186, DOI 10.1109/TSMCB.2009.2024759
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 41
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23071
EP 23092
DI 10.1007/s11042-020-09095-y
EA JUN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538227500002
DA 2024-07-18
ER

PT J
AU Kim, JW
   Park, JS
   Kim, SK
AF Kim, Jun Woo
   Park, Jin Sung
   Kim, Soo Kyun
TI Application of FlexSim software for developing cyber learning factory
   for smart factory education and training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart factory; engineering education; Manufacturing operations
   management; FlexSim software; Information system
AB Smart factory is a manufacturing facility equipped with modern information and communication technologies, and it is considered as an innovative manufacturing paradigm in the era of 4th industrial revolution. However, conventional technology-oriented smart factory education programs often focus on specific technologies, and many undergraduates and practitioners have trouble in understanding concepts, elements and features of entire smart factory system. In order to address this problem, this paper proposes a cyber learning factory for operations management-oriented smart factory education and training, developed by applying 3D factory simulation software, FlexSim. The cyber learning factory is implemented by incorporating three key components, information system, database and virtual manufacturing facility provided by 3D factory simulation software such as FlexSim. Since overall smart factory system can be virtually implemented in a single cyber space, the cyber learning factory can provide hands-on experiences for understanding, designing and optimizing smart factory. Consequently, the cyber learning factory can be used to train both operations managers of manufacturing companies and information systems architects of IT companies, and this paper will provide significant insights into the operations management-oriented smart factory education and training.
C1 [Kim, Jun Woo; Park, Jin Sung] Dong A Univ, Dept Ind & Management Syst Engn, 840,Hadan 2 Dong, Busan 604714, South Korea.
   [Kim, Soo Kyun] Paichai Univ, Dept Game Engn, Baejae Ro 155-40, Daejeon, South Korea.
C3 Dong A University; Pai Chai University
RP Kim, SK (corresponding author), Paichai Univ, Dept Game Engn, Baejae Ro 155-40, Daejeon, South Korea.
EM kimsk@pcu.ac.kr
RI 김, 수균/P-2129-2019
OI Kim, Soo Kyun/0000-0001-6071-8231
CR Abele E, 2015, PROC CIRP, V32, P1, DOI 10.1016/j.procir.2015.02.187
   [Anonymous], INT J ADV SCI TECHNO
   Beaverstock M., 2017, Applied Simulation: Modeling and Analysis Using FlexSim
   Botta-Genoulaz V, 2005, COMPUT IND, V56, P510, DOI 10.1016/j.compind.2005.02.004
   Dallasega P, 2017, PROCEDIA MANUF, V11, P846, DOI 10.1016/j.promfg.2017.07.187
   De Felice Fabio, 2018, Manufacturing Letters, V15, P81, DOI 10.1016/j.mfglet.2017.12.002
   Fanti Maria Pia, 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P150, DOI 10.1109/CoASE.2013.6654020
   Ghosh S.M., 2011, INT J ADV SCI TECHNO, V33, P95
   Helo P, 2014, COMPUT IND, V65, P646, DOI 10.1016/j.compind.2014.01.015
   Huimin Jia, 2015, Applied Mechanics and Materials, V741, P850, DOI 10.4028/www.scientific.net/AMM.741.850
   jodaseol, 2018, [The Journal of Information Systems, 정보시스템연구], V27, P35, DOI 10.5859/KAIS.2018.27.4.35
   Kumar BS, 2016, INT J ENG MANAG RES, V6, P406
   Kumar BS, 2018, RES J ENG TECHNOL, V9, P85, DOI [10.5958/2321-581X.2018.00013.2, DOI 10.5958/2321-581X.2018.00013.2]
   Kumar S., 2015, INT J COMPUT ENG RES, V5, P1, DOI DOI 10.6084/M9.FIGSHARE.1605576.V1
   Kurth M., 2017, INT J SERVICE COMPUT, V3, P53, DOI [10.1504/IJSCOM.2017.087949, DOI 10.1504/IJSCOM.2017.087949]
   Kwok PK, 2017, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON COMPUTER MODELING AND SIMULATION (ICCMS 2018), P258, DOI 10.1145/3177457.3177494
   Lee J., 2015, Informatik Spektrum, V38, P230
   Li XM, 2017, PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND ENGINEERING MANAGEMENT 2016: THEORY AND APPLICATION OF INDUSTRIAL ENGINEERING, P177, DOI 10.2991/978-94-6239-255-7_32
   Lohtander M, 2018, PROCEDIA MANUF, V17, P468, DOI 10.1016/j.promfg.2018.10.071
   Lohtander M, 2018, PROCEDIA MANUF, V25, P55, DOI 10.1016/j.promfg.2018.06.057
   Longo F, 2017, COMPUT IND ENG, V113, P144, DOI 10.1016/j.cie.2017.09.016
   Min H, 2018, ACAD J MANUFACT ENG, V16, P149
   Peters G., 2012, INT J ADV SCI TECHNO, V43, P105
   Radziwon A, 2014, PROCEDIA ENGINEER, V69, P1184, DOI 10.1016/j.proeng.2014.03.108
   Samaranayake P, 2014, IN C IND ENG ENG MAN, P1275, DOI 10.1109/IEEM.2014.7058843
   Tang X.Y., 2013, APPL MECH MAT, V347/350, P406
   Wang SY, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/3159805
   Yan Jia, 2017, Applied Mechanics and Materials, V865, P675, DOI 10.4028/www.scientific.net/AMM.865.675
   Zhang R, 2015, APPL SOFT COMPUT, V37, P521, DOI 10.1016/j.asoc.2015.08.051
   Zhou G., 2010, International Journal of Intelligent Systems and Applications (IJISA), V2, P33
   Zhou J, 2009, CHIN J INTEGR MED, V15, P7, DOI 10.1007/s11655-009-0007-y
   Zhu X, 2014, J APPL RES TECHNOL, V12, P270, DOI 10.1016/S1665-6423(14)72343-0
NR 32
TC 3
Z9 3
U1 10
U2 104
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16281
EP 16297
DI 10.1007/s11042-019-08156-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600026
DA 2024-07-18
ER

PT J
AU Su, H
   Fu, WN
AF Su, Hao
   Fu, Weina
TI Enhancement method for edge texture details of the filmic and visual
   three-dimensional animation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Filmic and visual three-dimensional animation; Edge texture detail;
   Detail enhancement method; Statistical shape priors
AB Enhancement method for edge texture details of the filmic and visual three-dimensional animation has the vital significance to the dynamic analysis and evaluation of the following images. The traditional enhancement method for edge texture detail mainly uses fuzzy contrast to improve the quality of animation. The contrast and clarity are poor. In order to reduce the noise, this paper proposes the enhancement method of filmic and visual three-dimensional animation edge texture detail based on statistical shape priors. Firstly, this method carries out the segmentation, de-noising, edge detection processing on animation, then uses statistical shape prior method to enhance the edge texture detail. Experimental results show that the proposed method can obtain more ideal edge detail information.
C1 [Su, Hao] Changzhou Text Garment Inst, Changzhou 213000, Peoples R China.
   [Fu, Weina] Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 010012, Peoples R China.
C3 Inner Mongolia Agricultural University
RP Fu, WN (corresponding author), Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 010012, Peoples R China.
EM fwn0124@yeah.net
OI fu, weina/0000-0002-4302-6505
CR Abdel-Basset M, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0846-9
   Amitrano D, 2016, IEEE J-STARS, V9, P3740, DOI 10.1109/JSTARS.2016.2555340
   Chang YJ, 2016, J VIS COMMUN IMAGE R, V40, P118, DOI 10.1016/j.jvcir.2016.06.017
   Couture RA, 1996, AM MINERAL, V81, P639
   Dixit T, 2016, J LUMIN, V170, P180, DOI 10.1016/j.jlumin.2015.10.003
   Guerra M, 2016, MED PHYS, V43, P3483, DOI 10.1118/1.4956229
   Harris JR, 2016, J APPL PHYS, V119, DOI 10.1063/1.4940410
   Ip AH, 2015, ACS NANO, V9, P8833, DOI 10.1021/acsnano.5b02164
   Lin Y, 2019, J SUPERCOMPUT, V75, P3010, DOI 10.1007/s11227-017-2216-2
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu S, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17400047
   Liu S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060269
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Lu MY, 2019, SOFT COMPUT, V23, P9175, DOI 10.1007/s00500-018-3602-2
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Sun YU, 2016, GEOPHYSICS, V81, pG1, DOI 10.1190/GEO2014-0430.1
   Trabelsi RB, 2016, MULTIMED TOOLS APPL, V75, P687, DOI 10.1007/s11042-014-2315-5
   Wang K, 2016, ELECTRON LETT, V52, P701, DOI 10.1049/el.2015.4555
   Zhang B., 2016, J. Opt., V18
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhou Keliang, 2016, COMPUTER MEASUREMENT, V24, P219
NR 23
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16351
EP 16367
DI 10.1007/s11042-019-7319-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600030
DA 2024-07-18
ER

PT J
AU Yang, JY
   Govindaraj, VV
   Yang, M
   Wang, SH
AF Yang, Jingyuan
   Govindaraj, Vishnu Varthanan
   Yang, Ming
   Wang, Shui-Hua
TI Hearing loss detection by discrete wavelet transform and multi-layer
   perceptron trained by nature-inspired algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hearing loss; Computer-aid diagnosis; Discrete wavelet transform;
   Multi-layer perceptron; Nature-inspired algorithms; Improved artificial
   bee Colony algorithm; K-fold cross validation
ID NEURAL-NETWORK; CLASSIFICATION; OPTIMIZATION; MACHINE; IMAGE
AB (Aim) For detecting the hearing loss (HL) more accurately and efficiently, the new computer-aid diagnosis (CAD) based on a nature-inspired algorithm (NIAs) is proposed in this study. (Method) First, the discrete wavelet transform (DWT) is used for extracting texture features from the brain images, and then the principle component analysis (PCA) is employed to decrease the dimension of features. Second, the Multi-Layer Perceptron (MLP) is used as a classifier. Traditional gradient-based descent algorithms are vulnerable to get struck at local minima; thus, the NIAs are introduced. The differential evolution algorithm (DE), particle swarm optimization (PSO), artificial bee colony algorithm (ABC), and improved ABC (IABC) are employed to train MLP. Because the ordinary ABC is good at exploration but gives a poor performance at exploitation, therefore a new model of ABC, called IABC is proposed. The K-fold validation method is utilized to measure the performance of the CAD. (Result) To verify the performance of our method, The CAD based on IABC is compared with state-of-the-art-approaches. (Conclusion) The experiment results show that the overall accuracy of our method has the highest overall accuracy among five approaches. Therefore, the proposed CAD is effective method for detecting hearing loss.
C1 [Yang, Jingyuan] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
   [Govindaraj, Vishnu Varthanan] Kalasalingam Acad Res & Educ, Dept Biomed Engn, Krishnankoil 626126, Tamil Nadu, India.
   [Yang, Ming] Nanjing Med Univ, Childrens Hosp, Dept Radiol, Nanjing 210008, Peoples R China.
   [Wang, Shui-Hua] Univ Leicester, Dept Math, Leicester LE1 7RH, Leics, England.
C3 University of Leicester; Kalasalingam Academy of Research & Education;
   Nanjing Medical University; University of Leicester
RP Govindaraj, VV (corresponding author), Kalasalingam Acad Res & Educ, Dept Biomed Engn, Krishnankoil 626126, Tamil Nadu, India.; Yang, M (corresponding author), Nanjing Med Univ, Childrens Hosp, Dept Radiol, Nanjing 210008, Peoples R China.; Wang, SH (corresponding author), Univ Leicester, Dept Math, Leicester LE1 7RH, Leics, England.
EM g.vishnuvarthanan@klu.ac.in; yangming19710217@163.com;
   shuihuawang@ieee.org
RI Wang, Shuihua/G-7326-2016
OI govindaraj, vishnuvarthanan/0000-0001-9136-3461
CR Agarwal P, 2018, ARTIF INTELL REV, V50, P383, DOI 10.1007/s10462-017-9547-5
   Al-Salamah M, 2018, APPL MATH MODEL, V63, P68, DOI 10.1016/j.apm.2018.06.034
   Chatterjee S, 2017, NEURAL COMPUT APPL, V28, P2005, DOI 10.1007/s00521-016-2190-2
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3775, DOI 10.1007/s11042-016-4087-6
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3813, DOI 10.1007/s11042-016-4161-0
   Chen Y, 2017, CNS NEUROL DISORD-DR, V16, P5, DOI 10.2174/1871527314666161124115531
   Das S, 2016, SWARM EVOL COMPUT, V27, P1, DOI 10.1016/j.swevo.2016.01.004
   Jia WJ, 2019, MULTIMED TOOLS APPL, V78, P4045, DOI 10.1007/s11042-017-5174-z
   Jia WJ, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0814-4
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kong FQ, 2018, MULTIMED TOOLS APPL, V77, P22857, DOI 10.1007/s11042-018-5976-7
   Lu H, 2017, 14 INT S NEUR NETW I
   Lu S, 2017, 14 INT COMP C WAV AC
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Lu SY, 2018, MULTIMED TOOLS APPL, V77, P3715, DOI 10.1007/s11042-016-3559-z
   McCreery RW, 2018, CHILD CARE HLTH DEV, V44, P926, DOI 10.1111/cch.12602
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Nayeem A, 2017, 2017 INT C APPL MATH
   Oruç O, 2019, DISCRETE CONT DYN-S, V12, P533, DOI 10.3934/dcdss.2019035
   Pereira A, 2017, 2017 INT C ADV ENG T
   Platon R, 2015, ENERG BUILDINGS, V92, P10, DOI 10.1016/j.enbuild.2015.01.047
   Segovia F, 2015, FRONT COMPUT NEUROSC, V9, DOI [10.3339/fncom.2015.00137, 10.3389/fncom.2015.00137]
   Silva Ferreira AD, 2018, J LIGHTWAVE TECHNOL, V36, P4066, DOI 10.1109/JLT.2018.2856364
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sui YX, 2018, J MED SYST, V42
   Tian YL, 2012, 13 INT C COMP HELP P
   Wang SH, 2020, MULTIMED TOOLS APPL, V79, P15117, DOI 10.1007/s11042-018-6661-6
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2017, IEEE ACCESS, V5, P16576, DOI 10.1109/ACCESS.2017.2736558
   Wang SH, 2017, LECT NOTES COMPUT SC, V10337, P289, DOI 10.1007/978-3-319-59740-9_28
   Wang SH, 2017, FUND INFORM, V151, P505, DOI 10.3233/FI-2017-1507
   Wang SH, 2012, IEEE INT C BIO BIO W
   Wu XY, 2018, MULTIMED TOOLS APPL, V77, P3745, DOI 10.1007/s11042-016-3931-z
   Yang XG, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18060202
   Zhang Y, 2011, PROG ELECTROMAGN RES, V116, P65, DOI 10.2528/PIER11031709
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22875, DOI 10.1007/s11042-018-6003-8
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22671, DOI 10.1007/s11042-017-5146-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
   Zhou XX, 2016, SIMUL-T SOC MOD SIM, V92, P827, DOI 10.1177/0037549716629227
NR 45
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15717
EP 15745
DI 10.1007/s11042-019-08344-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900073
DA 2024-07-18
ER

PT J
AU Zhang, KL
   Xu, JH
   Xu, HY
   Su, RD
AF Zhang, Kunlin
   Xu, Jihui
   Xu, Huaiyu
   Su, Ruidan
TI Visual analytics towards axle health of high-speed train based on
   large-scale scatter image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scatter image; Density map; Axle; Kernel density estimation; High-speed
   train
ID VISUALIZATION
AB Axle is an important part of high-speed train. The axle is the key component connecting the train wheelset, which has a great impact on the train safety. The health monitoring of axles is very important for the safe and smooth operation of trains. The axle health detection is a complex process of multi-factor coupling, which faces the problems of health model construction. From the perspective of big data visual analysis, this paper helps people find the information behind the big data of high-speed railway axle monitoring, and makes a prediction and analysis of the health status of high-speed railway axle operation. Starting from the present situation of scatter plot presentation of multi-dimensional data visual analysis, this paper proposes a visual analysis and processing method for high-speed train axle health monitoring, aiming at the problems of intensive rendering, visual mutation and trend prediction when drawing large data scatter plot. Firstly, a new method of the axle data fusion model is proposed in this paper, which can effectively clean the axle health monitoring data and construct the data acquisition and expression mode of axle temperature of high-speed train. Then, visualization of axle data and prediction of axle health trend provide a new analysis model for axle health monitoring. In addition, the visual analysis method of scatter density map data can eliminate the dependence of the original complex mechanical model, and can be used to analyze different working conditions and axle types. Compared with the existing axle health monitoring methods, this method has high accuracy and practicability.
C1 [Zhang, Kunlin; Xu, Jihui; Xu, Huaiyu; Su, Ruidan] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai, Peoples R China.
   [Zhang, Kunlin; Xu, Jihui; Xu, Huaiyu] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Advanced Research Institute, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Xu, HY; Su, RD (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai, Peoples R China.; Xu, HY (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM xuhuaiyu@sari.ac.cn; surd@sari.ac.cn
RI Su, Ruidan/S-9437-2019
OI Su, Ruidan/0000-0003-0058-4088
CR AHLBERG C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P313, DOI 10.1145/191666.191775
   Barducci A, 2007, IEEE T GEOSCI REMOTE, V45, P2665, DOI 10.1109/TGRS.2007.897421
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Guangjun L, 2018, NEW TECHNOLOGY NEW P, V13, P56
   Ha D-l, 2013, J DALIAN JIAOTONG U, V01, P89
   Hao M, 2012, RAILWAY LOCOMOTIVE C, V02, P85
   [黄采伦 HUANG Cailun], 2007, [中国铁道科学, China Railway Science], V28, P83
   Johnsson A, 2010, J GEOL, V27, P276, DOI [10.1086/622661, DOI 10.1086/622661]
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Li C, 2018, IEEE T VIS COMPUT GR, V24
   Lonsdale C, 2006, FOREIGN ROLLING STOC, P40
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mohapatra Sonisilpa, 2018, BMC Bioinformatics, V19, P428, DOI 10.1186/s12859-018-2444-3
   Noriega P, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P213
   Ren Lei, 2014, Journal of Software, V25, P1909, DOI 10.13328/j.cnki.jos.004645
   Ruidan Su, 2012, Journal of Software, V7, P1919, DOI 10.4304/jsw.7.8.1919-1922
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Song H, 2017, IEEE T VIS COMPUT GR, V23, P311, DOI 10.1109/TVCG.2016.2598796
   Su RD, 2014, J APPL MATH, DOI 10.1155/2014/507308
   Su RD, 2012, J COMPUT, V7, P2330, DOI 10.4304/jcp.7.9.2330-2333
   Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4
   Wickham H., 2013, Tech. Rep
   Willems N, 2009, COMPUT GRAPH FORUM, V28, P959, DOI 10.1111/j.1467-8659.2009.01440.x
   Zhu JY, 2013, ANAL AERODYNAMIC AER, V126, P489
NR 24
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16663
EP 16681
DI 10.1007/s11042-019-08001-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600048
DA 2024-07-18
ER

PT J
AU Zhu, DJ
   Xia, SX
   Zhao, JQ
   Zhou, Y
   Niu, Q
   Yao, R
   Chen, Y
AF Zhu, Dongjun
   Xia, Shixiong
   Zhao, Jiaqi
   Zhou, Yong
   Niu, Qiang
   Yao, Rui
   Chen, Ying
TI Fusion based feature reinforcement component for remote sensing image
   object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Object detection; Reinforcement component; Fusion
   strategy
ID ORIENTED GRADIENTS; HISTOGRAMS
AB In recent years, convolutional neural networks (CNN) have been extensively used for generic object detection due to their powerful feature extraction capabilities. This has hence motivated researchers to adopt this technology in the field of remote sensing. However, remote sensing images can contain large amounts of noise, have complex backgrounds, include small dense objects as well as being susceptible to weather and light intensity variations. Moreover, from different shooting angles, objects can either have different shapes or be obscured by structures such as buildings and trees. Due to these, effective features extraction for proper representation is still very challenging from remote sensing images. This paper therefore proposes a novel remote sensing image object detection approach applying a fusion-based feature reinforcement component (FB-FRC) to improve the discrimination between object feature. Specifically, two fusion strategies are proposed: (i) a hard fusion strategy through artificially-set rules, and (ii) a soft fusion strategy by learning the fusion parameters. Experiments carried out on four widely used remote sensing datasets (NWPU VHR-10, VisDrone2018, DOTA and RSOD) have shown promising results where the proposed approach manages to outperform several state-of-the-art methods.
C1 [Zhu, Dongjun; Xia, Shixiong; Zhao, Jiaqi; Zhou, Yong; Niu, Qiang; Yao, Rui; Chen, Ying] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhu, Dongjun; Xia, Shixiong; Zhao, Jiaqi; Zhou, Yong; Niu, Qiang; Yao, Rui; Chen, Ying] Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Xia, SX (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.; Xia, SX (corresponding author), Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Jiangsu, Peoples R China.
EM djzhu@cumt.edu.cn; shixiongxia.cumt@outlook.com; jiaqizhao@cumt.edu.cn;
   yzhou@cumt.edu.cn; niuq@cumt.edu.cn; ruiyao@cumt.edu.cn;
   cheny@cumt.edu.cn
FU National Key Research and Development Plan [2016YFC0600908]; National
   Natural Science Foundation of China [U1610124, 61806206, 61572505,
   61772530]; Six Talent Peaks Project in Jiangsu Province [2015-DZXX-010];
   Natural Science Foundation of Jiangsu Province [BK20180639, BK20171192];
   China Postdoctoral Science Foundation [2018M642359]
FX This work was supported by the National Key Research and Development
   Plan (No. 2016YFC0600908), the National Natural Science Foundation of
   China (No. U1610124, 61806206, 61572505, 61772530), the Six Talent Peaks
   Project in Jiangsu Province (No. 2015-DZXX-010), the Natural Science
   Foundation of Jiangsu Province (No. BK20180639, BK20171192) and the
   China Postdoctoral Science Foundation (No. 2018M642359).
CR Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Cheng G, 2013, ISPRS J PHOTOGRAMM, V85, P32, DOI 10.1016/j.isprsjprs.2013.08.001
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Esmael AA, 2018, MULTIMED TOOLS APPL, V77, P24565, DOI 10.1007/s11042-018-6023-4
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kong XJ, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.182
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li XB, 2017, IEEE GEOSCI REMOTE S, V14, P2037, DOI 10.1109/LGRS.2017.2749478
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Ling H., 2018, Vision Meets Drones: A Challenge
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Qu T, 2017, MULTIMED TOOLS APPL, V76, P21651, DOI 10.1007/s11042-016-4043-5
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Senaras C, 2013, IEEE J-STARS, V6, P1295, DOI 10.1109/JSTARS.2013.2249498
   Wang C, 2018, IEEE CONF COMM NETW
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xiao ZF, 2015, INT J REMOTE SENS, V36, P618, DOI 10.1080/01431161.2014.999881
NR 29
TC 3
Z9 2
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34973
EP 34992
DI 10.1007/s11042-020-08876-9
EA MAY 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000536434100002
DA 2024-07-18
ER

PT J
AU Sreesurya, I
   Rathi, H
   Jain, P
   Jain, TK
AF Sreesurya, Ilayaraja
   Rathi, Himani
   Jain, Pooja
   Jain, Tapan Kumar
TI Hypex: A Tool for Extracting Business Intelligence from Sentiment
   Analysis using Enhanced LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Sentiment analysis; Natural language processing;
   Business intelligence; LSTM; RNN; GloVe; Hypex; Data analytics
ID PREDICTION
AB Sentiment analysis, an application of machine learning in business is the process of identifying and cataloging comments, reviews, tweets, feedback, and even random rants according to the tone or sentiments conveyed by it. The data is analysed using machine learning approach of Long Short Term Memory (LSTM) rating the sentiments on a scale ranging from -100 to 100. A new proposed activation function is used for LSTM giving best results as compared to the existing Artificial Neural Network (ANN) techniques. Depending upon the mined opinion, the business intelligence tools evaluate the products or services of a company eventually resulting in the increase of the sales of that company. The results clearly show that BI extracted from SA is quite instrumental in driving business effectiveness and innovation.
C1 [Sreesurya, Ilayaraja; Rathi, Himani] Indian Inst Informat Technol, Kota, India.
   [Jain, Pooja; Jain, Tapan Kumar] Indian Inst Informat Technol, Nagpur, Maharashtra, India.
RP Jain, P (corresponding author), Indian Inst Informat Technol, Nagpur, Maharashtra, India.
EM poojaalld@yahoo.com
RI Jain, Pooja/L-4523-2016; Jain, Tapan Kumar/HGE-0667-2022
OI Jain, Tapan Kumar/0000-0003-0255-0084; Jain, Pooja/0000-0002-4216-7787
CR Agarap A.F., 2018, DEEP LEARNING USING
   Ain QT, 2017, INT J ADV COMPUT SC, V8, P424
   [Anonymous], 2018, BATRAS HAIR FALL CON
   [Anonymous], 2018, ADVENTURES DON QUIXO
   [Anonymous], 2018, HOMOEOPATHIC CLIN DR
   [Anonymous], 2018, Standard search API - Twitter Developers
   Chen HC, 2012, MIS QUART, V36, P1165
   Customer Review, 2018, AMAZON COM REV
   Daassi-Gnaba H, 2015, NEURAL NETW WORLD, V25, P75, DOI 10.14311/NNW.2015.25.004
   Ebadati EOM, 2018, NEURAL NETW WORLD, V28, P41, DOI 10.14311/NNW.2018.28.003
   Ebrahimi M, 2017, IEEE INTELL SYST, V32, P70, DOI 10.1109/MIS.2017.3711649
   Fang X, 2015, Journal of Big Data, V2, P5, DOI 10.1186/s40537-015-0015-2
   Feyzbakhsh S. A., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P613, DOI 10.1109/ICSMC.1999.814162
   Gers FA, 2001, IEEE T NEURAL NETWOR, V12, P1333, DOI 10.1109/72.963769
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Gupta S., 2018, APPL SENTIMENT ANAL
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Huang JP, 2018, NEURAL NETW WORLD, V28, P149, DOI 10.14311/NNW.2018.28.009
   Ilayaraja S, 2018, ILAYARAJA97 KERAS CO
   Jadav B. M., 2016, INT J COMPUTER APPL, V146, P13
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   MajorLeagueJesus, 2018, RREV COUNT STRIK GLO
   Mautner P, 2012, NEURAL NETW WORLD, V22, P53, DOI 10.14311/NNW.2012.22.004
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Plaza L., 2012, Customer Relationship Management and the Social and Semantic Web: Enabling Cliens Conexus, P231, DOI [10.4018/978-1-61350-044-6.ch014, DOI 10.4018/978-1-61350-044-6.CH014]
   Pulver A, 2017, IEEE IJCNN, P845, DOI 10.1109/IJCNN.2017.7965940
   Saggion H., 2009, RNTI Journal, P119
   Seibold M., 2012, IT PROFESSIONAL, V15, P16
   Singh B, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P18, DOI 10.1109/TENCON.2016.7847950
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Xie ZZ, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P221, DOI 10.1109/ICACI.2012.6463155
NR 33
TC 5
Z9 5
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35641
EP 35663
DI 10.1007/s11042-020-08930-6
EA MAY 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000554789500008
DA 2024-07-18
ER

PT J
AU Wang, YY
   Yin, FL
   Liu, JB
   Tosato, M
AF Wang, Yanyan
   Yin, Fulian
   Liu, Jianbo
   Tosato, Marco
TI Automatic construction of domain sentiment lexicon for semantic
   disambiguation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Improved TF-IDF; Sentiment lexicon; Sentiment classification; Word sense
   disambiguation
ID CONTEXTS
AB Sentiment lexicon is used to judge the sentiments of words and plays a significant role in sentiment analysis. Existing sentiment lexicons ignore the sentimental ambiguity of words in different contexts and only assign sentiment positive or negative polarity for words. In this paper, we propose an automatic method for the construction of the domain-specific sentiment lexicon (SDS-lex) to avoid sentimental ambiguity, which incorporates the sentiment information not only from the existing lexicons but also from the corpus by using our improved TF-IDF algorithm (ITF-IDF). The ITF-IDF algorithm calculates the sentiment of words by considering both the importance of words and the distribution of different part-of-speech (POS) in a corpus labeled with different sentiment tendencies. Experiments on real-world datasets show that our constructed lexicon improves the sentimental ambiguity and outperforms many existing lexicons in terms of the coverage and the accuracy when performing text sentiment classification tasks.
C1 [Wang, Yanyan; Yin, Fulian; Liu, Jianbo] Commun Univ China, Informat Engn Inst, Beijing 100024, Peoples R China.
   [Tosato, Marco] York Univ, Lab Ind & Appl Math, Toronto, ON M3J 1P3, Canada.
C3 Communication University of China; York University - Canada
RP Yin, FL (corresponding author), Commun Univ China, Informat Engn Inst, Beijing 100024, Peoples R China.
EM yinfulian@cuc.edu.cn
OI Tosato, Marco/0000-0003-1878-239X
FU National Natural Science Foundation of China [61801440]; High-quality
   and Cutting-edge Disciplines Construction Project for Universities in
   Beijing (Internet Information, Communication University of China);
   Fundamental Research Funds for the Central Universities
FX This work was supported by the National Natural Science Foundation of
   China (No. 61801440), the High-quality and Cutting-edge Disciplines
   Construction Project for Universities in Beijing (Internet Information,
   Communication University of China) and the Fundamental Research Funds
   for the Central Universities.
CR Al-Moslmi T, 2018, J INF SCI, V44, P345, DOI 10.1177/0165551516683908
   [Anonymous], 2014, COLING 2014, 25th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers, August 23-29, 2014, Dublin, Ireland
   Assiri A, 2018, J INF SCI, V44, P184, DOI 10.1177/0165551516688143
   Baccianella S., 2010, INT C LANG RES EV VA
   Bucar J, 2018, LANG RESOUR EVAL, V52, P895, DOI 10.1007/s10579-018-9413-3
   Cambria E, 2018, AAAI CONF ARTIF INTE, P1795
   Chul-won NA, 2018, J INTELL INF SYST, V24, P219
   Denecke Kerstin, 2008, 2008 IEEE 24th International Conference on Data Engineering Workshop (ICDE Workshop), P507, DOI 10.1109/ICDEW.2008.4498370
   Deng D, 2019, IEEE-ACM T AUDIO SPE, V27, P704, DOI 10.1109/TASLP.2019.2892232
   Dey A, 2018, EXPERT SYST APPL, V103, P92, DOI 10.1016/j.eswa.2018.03.004
   Vo DT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P219
   Esuli Andrea., 2006, LREC 2006 Proceedings, 2006, S, P417
   Feng J, 2018, WIRELESS COMMUNICATI
   Gatti L, 2016, IEEE T AFFECT COMPUT, V7, P409, DOI 10.1109/TAFFC.2015.2476456
   Go A., 2009, FINAL PROJECTS CS224
   Han HY, 2018, MULTIMED TOOLS APPL, V77, P21265, DOI 10.1007/s11042-017-5529-5
   Hegazy AE, 2019, ARAB J SCI ENG, V44, P3801, DOI 10.1007/s13369-018-3680-6
   Howell N, 2005, MACQUARIE LAW J, V5
   Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073
   Kamps J., 2004, P 4 INT C LANG RES E, P1115
   Khoo CSG, 2018, J INF SCI, V44, P491, DOI 10.1177/0165551517703514
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Kumari P, 2020, P INT C COMP SCI APP, P309
   Liu JY, 2016, INT C INTEL HUM MACH, P56, DOI 10.1109/IHMSC.2016.264
   Liu J, 2018, INTELL AUTOM SOFT CO, V24, P73, DOI 10.1080/10798587.2016.1267244
   Lu YJ, 2011, LET'S TALK ORE DEPOSITS, VOLS I AND II, P347
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Mandal Shrabanti, 2019, ADV INTELLIGENT SYST, P357
   Mohammad SM, 2013, ARXIV PREPRINT ARXIV
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Rani S, 2019, ARAB J SCI ENG, V44, P3305, DOI 10.1007/s13369-018-3500-z
   Riloff E, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P105
   Saif H, 2017, SEMANT WEB, V8, P643, DOI 10.3233/SW-170265
   Stone P.J., 1966, Inf. Storage Retr., V4, P375
   Tao W, 2018, INTELL AUTOM SOFT CO, V24, P65, DOI 10.1080/10798587.2016.1267243
   Tran TK, 2018, J INTELL FUZZY SYST, V35, P967, DOI 10.3233/JIFS-172053
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   [王科 Wang Ke], 2016, [自动化学报, Acta Automatica Sinica], V42, P495
   Wang Yasheng., 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, P553, DOI DOI 10.18653/V1/D17-1059
   Wu FZ, 2016, DECIS SUPPORT SYST, V87, P39, DOI 10.1016/j.dss.2016.04.007
   Wu SX, 2019, EXPERT SYST APPL, V116, P285, DOI 10.1016/j.eswa.2018.09.024
   [杨小平 Yang Xiaoping], 2017, [计算机科学, Computer Science], V44, P42
   Zabha NI, 2019, INT J ADV COMPUT SC, V10, P346
   Zhao CJ, 2019, COMPUT SPEECH LANG, V55, P57, DOI 10.1016/j.csl.2018.10.004
NR 44
TC 12
Z9 13
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22355
EP 22373
DI 10.1007/s11042-020-09030-1
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534853900001
DA 2024-07-18
ER

PT J
AU Jiang, FL
   Liu, PC
   Shao, XH
   Zhou, XD
AF Jiang, Fangling
   Liu, Pengcheng
   Shao, Xiaohu
   Zhou, Xiangdong
TI Face anti-spoofing with generated near-infrared images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face anti-spoofing; Feature fusing; Generative adversarial network;
   Image translation
ID LIVENESS DETECTION; FINGERPRINT; QUALITY; IRIS
AB Reflection differences between live faces and spoof faces under near-infrared spectrum make near-infrared image based methods obtain superior performance for face anti-spoofing. However, for conventional face recognition systems, near-infrared image based methods need additional near-infrared equipment to capture the input near-infrared images. In this paper, we propose a novel face anti-spoofing method which exploits the clues in both visible light (VIS) images and near-infrared (NIR) images without utilizing any near-infrared equipment during testing. Specifically, we first propose a novel multiple categories image translation generative adversarial network (MCT-GAN) which generates corresponding NIR images for VIS live and spoof face images. Then we utilize convolution neural network to learn fusing features from both VIS images and corresponding generated NIR images for the goal of live and spoof face classification. Qualitative and quantitative experiments demonstrate that our method obtains excellent results compared to the state-of-the-art methods.
C1 [Jiang, Fangling; Liu, Pengcheng; Shao, Xiaohu; Zhou, Xiangdong] Chinese Acad Sci, Chongqing Inst Green & Intelligent Technol, Chongqing 400714, Peoples R China.
   [Jiang, Fangling] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Chongqing Institute of Green & Intelligent
   Technology, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Jiang, FL (corresponding author), Chinese Acad Sci, Chongqing Inst Green & Intelligent Technol, Chongqing 400714, Peoples R China.; Jiang, FL (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM jiangfangling@cigit.ac.cn
RI Zhou, Xiang/AAL-4137-2020; Liu, Pengcheng/AAA-7664-2022
OI Liu, Pengcheng/0000-0002-1860-5118
FU National Key Research and Development Program of China [2018YFC0808300];
   National Natural Science Foundation of China [61806185, 61802361]
FX This work is funded by National Key Research and Development Program of
   China(2018YFC0808300), National Natural Science Foundation of China
   (Grant No. 61806185, 61802361)
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Akhtar N, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/1387936
   Akhtar Z, 2015, IEEE SECUR PRIV, V13, P63, DOI 10.1109/MSP.2015.116
   [Anonymous], 2013, ICB
   [Anonymous], 2017, P ASM 36 INT C OC
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Benlamoudi A, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043007
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chakraborty S., 2014, International Journal on Information Theory, V3, P11
   Chan PPK, 2018, IEEE T INF FOREN SEC, V13, P521, DOI 10.1109/TIFS.2017.2758748
   Chingovska I, 2012, P 11 INT C BIOM SPEC
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dong M, 2018, MITOCHONDRIAL DNA B, V3, P558, DOI 10.1080/23802359.2018.1462124
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A., 2012, NEURAL INFORM PROCES
   Hernandez-Ortega Javier., 2018, P IEEE C COMP VIS PA, P544
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18
   Kant C., 2013, INT J COMPUT SCI COM, V1, P65
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   Kim YS, 2009, J OPT SOC AM A, V26, P760, DOI 10.1364/JOSAA.26.000760
   Kollreider K, 2009, IMAGE VISION COMPUT, V27, P233, DOI 10.1016/j.imavis.2007.05.004
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P2639, DOI 10.1109/TIFS.2018.2825949
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312
   Li LF, 2016, CRYSTALS, V6, DOI 10.3390/cryst6040045
   Li S. Z, 2014, Learn convolutional neural network for face anti-spoofing
   Li ZR, 2019, ICMLC 2019: 2019 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P91, DOI 10.1145/3318299.3318332
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Maatta J, 2011, INT JOINT C BIOM IJC, P1, DOI DOI 10.1109/IJCB.2011.6117510
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Nowara EM, 2017, IEEE INT CONF AUTOMA, P56, DOI 10.1109/FG.2017.16
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Pereira TD, 2013, INT CONF BIOMETR
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Poh MZ, 2011, IEEE T BIO-MED ENG, V58, P7, DOI 10.1109/TBME.2010.2086456
   Raghavendra R, 2017, IEEE COMPUT SOC CONF, P672, DOI 10.1109/CVPRW.2017.96
   Raghavendra R, 2015, IEEE T IMAGE PROCESS, V24, P1060, DOI 10.1109/TIP.2015.2395951
   Souza L, 2018, ENG APPL ARTIF INTEL, V72, P368, DOI 10.1016/j.engappai.2018.04.013
   Steiner H, 2016, INT CONF BIOMETR
   Sun XD, 2016, INT C PATT RECOG, P4262, DOI 10.1109/ICPR.2016.7900303
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350
   Wang SY, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120305
   Wang Y, 2017, J VIS COMMUN IMAGE R, V49, P332, DOI 10.1016/j.jvcir.2017.09.002
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Xiaokang Tu, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10635, P686, DOI 10.1007/978-3-319-70096-0_70
   Yi D, 2014, ADV COMPUT VIS PATT, P83, DOI 10.1007/978-1-4471-6524-8_5
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang SC, 2016, IEEE T IMAGE PROCESS, V25, P220, DOI 10.1109/TIP.2015.2501755
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang Z, 2012, J NANOMATER, V2012, DOI 10.1155/2012/238605
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 60
TC 13
Z9 13
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21299
EP 21323
DI 10.1007/s11042-020-08952-0
EA MAY 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530202200003
DA 2024-07-18
ER

PT J
AU Dhal, KG
   Galvez, J
   Ray, S
   Das, A
   Das, S
AF Dhal, Krishna Gopal
   Galvez, Jorge
   Ray, Swarnajit
   Das, Arunita
   Das, Sanjoy
TI Acute lymphoblastic leukemia image segmentation driven by stochastic
   fractal search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pathology image segmentation; Clustering; stochastic fractal search;
   Swarm intelligence optimization
ID PARTICLE SWARM OPTIMIZATION; CLASSIFICATION; ALGORITHM; COLOR; BLOOD
AB Cancer is one of the most critical disease. In particular, Leukemia is the most common type of cancer which produces an excessive quantity of leucocytes, replacing normal blood cells. Early detection of leucocytes cells can save human life. Recently, researchers have contributed to the development of computer assisted pathology techniques to automatically detect cancer at early stage. Commonly, assisted pathology systems are based on artificial vision techniques to identify cancer cells in the human body. Blood image segmentation techniques for Leukemia have been proposed based on automatic thresholding schemes involving traditional clustering methods. However, traditional clustering methods are sensitive to initial cluster positions, where the incorrect centering values results into false positive cancer diagnosis. On the other hand, Nature-Inspired Optimization Algorithms (NIOA) are stochastic search methods for finding the optimal solution for complex multimodal functions where traditional optimization approaches are not suitable to operate. Since blood image segmentation is considered as a complex computational task, NIOA methods yield an interesting alternative to proper blood cell segmentation. In this paper, the Stochastic Fractal Search (SFS) algorithm is implemented in order to provide non-false positive segmented outcomes for Leukemia identification. In the experimental study, the proposed approach is compared against traditional clustering methods as well as some NIOAs techniques. The numerical results indicate that SFS, provide superior results in terms of accuracy, time complexity, and quality parameters.
C1 [Dhal, Krishna Gopal] Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Paschim Medinipur, W Bengal, India.
   [Galvez, Jorge] Univ Guadalajara, Dept Elect, CUCEI Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
   [Ray, Swarnajit] Skybound Digital LLC, Kolkata, W Bengal, India.
   [Das, Arunita] Kalyani Govt Engn Coll, Dept Informat Technol, Kalyani, Nadia, India.
   [Das, Sanjoy] Univ Kalyani, Dept Engn & Technol Studies, Kalyani, Nadia, India.
C3 Midnapore College; Universidad de Guadalajara; Kalyani Government
   Engineering College; Kalyani University
RP Galvez, J (corresponding author), Univ Guadalajara, Dept Elect, CUCEI Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
EM krishnagopal.dhal@midnaporecollege.ac.in; jorge.galvez@cutonala.udg.mx;
   swarnajit32@gmail.com; arunita17@gmail.com; dassanjoy0810@hotmail.com
RI Gálvez, Jorge/JXN-1247-2024; Dhal, Krishna Gopal/JCD-8250-2023; Das,
   Sanjoy/ABC-7637-2021
OI Gálvez, Jorge/0000-0001-6595-8605; 
CR Aja-Fernandez Santiago, 2006, 2006 INT C IEEE ENG, P4815
   Alomoush MI, 2018, INT T ELECTR ENERGY, V28, DOI 10.1002/etep.2530
   Amin Morteza Moradi, 2015, J Med Signals Sens, V5, P49
   [Anonymous], MULTITHRESHOLDING HI
   [Anonymous], 2006 8 INT C SIGN PR, DOI [10.1109/ICOSP.2006.345700, DOI 10.1109/ICOSP.2006.345700]
   [Anonymous], FUZZY C MEANS CLUSTE
   Arslan S, 2014, CYTOM PART A, V85A, P480, DOI 10.1002/cyto.a.22457
   Betka A, 2019, APPL INTELL, V49, P1146, DOI 10.1007/s10489-018-1312-1
   Bhandarkar SM, 1999, IEEE T EVOLUT COMPUT, V3, P1, DOI 10.1109/4235.752917
   Das S, 2009, APPL SOFT COMPUT, V9, P226, DOI 10.1016/j.asoc.2007.12.008
   De Falco I, 2007, APPL SOFT COMPUT, V7, P652, DOI 10.1016/j.asoc.2005.09.004
   Dorini LB, 2013, IEEE J BIOMED HEALTH, V17, P250, DOI 10.1109/TITB.2012.2207398
   Duan J, 2011, 2011 4TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK AND MULTIMEDIA TECHNOLOGY (4TH IEEE IC-BNMT2011), P629
   García S, 2009, J HEURISTICS, V15, P617, DOI 10.1007/s10732-008-9080-4
   Ghane Narjes, 2017, J Med Signals Sens, V7, P92
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   He KJ, 2018, IEEE ACCESS, V6, P32850, DOI 10.1109/ACCESS.2018.2845855
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Kapoor S, 2017, PROCEDIA COMPUT SCI, V115, P415, DOI 10.1016/j.procs.2017.09.100
   Karaboga D., 2005, Technical report-tr06
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khalilpourazari S, 2018, SWARM EVOL COMPUT, V38, P173, DOI 10.1016/j.swevo.2017.07.008
   Ko BC, 2011, MICRON, V42, P695, DOI 10.1016/j.micron.2011.03.009
   Kovesi P Kovesi P., 1995, Image features from phase congruency
   Labati R. D., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2045, DOI 10.1109/ICIP.2011.6115881
   Leblebici SY, 2016, NAT ENERGY, V1, DOI [10.1038/nenergy.2016.93, 10.1038/NENERGY.2016.93]
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Li HP, 2017, INT J REMOTE SENS, V38, P6970, DOI 10.1080/01431161.2017.1368102
   Ma L, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/120495
   Manda K, 2012, ADV INTEL SOFT COMPU, V132, P29
   Mishra S, 2017, BIOMED SIGNAL PROCES, V33, P272, DOI 10.1016/j.bspc.2016.11.021
   Mohapatra S., 2010, 2010 International Conference on Industrial Electronics, Control and Robotics (IECR), P215, DOI 10.1109/IECR.2010.5720171
   MoradiAmin M., 2015, FRONTIERS BIOMEDICAL, V2, P128
   MoradiAmin M, 2016, MICROSC RES TECHNIQ, V79, P908, DOI 10.1002/jemt.22718
   Omran MGH, 2006, CONF CYBERN INTELL S, P80
   Patel N, 2015, PROCEDIA COMPUT SCI, V58, P635, DOI 10.1016/j.procs.2015.08.082
   Piuri V, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P103, DOI 10.1109/CIMSA.2004.1397242
   Qin PL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0320-8
   Rawat J, 2017, MULTIMED TOOLS APPL, V76, P19057, DOI 10.1007/s11042-017-4478-3
   Romero H, 1972, Rev Med Chil, V100, P464
   Salimi H, 2015, KNOWL-BASED SYST, V75, P1, DOI 10.1016/j.knosys.2014.07.025
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Suresh S, 2017, APPL SOFT COMPUT, V55, P503, DOI 10.1016/j.asoc.2017.02.005
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhou CJ, 2018, J MOL MODEL, V24, DOI 10.1007/s00894-018-3644-5
NR 46
TC 37
Z9 38
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12227
EP 12255
DI 10.1007/s11042-019-08417-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400043
DA 2024-07-18
ER

PT J
AU Goenetxea, J
   Unzueta, L
   Dornaika, F
   Otaegui, O
AF Goenetxea, Jon
   Unzueta, Luis
   Dornaika, Fadi
   Otaegui, Oihana
TI Efficient deformable 3D face model tracking with limited hardware
   resources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head pose estimation; Face tracking; Efficient computation; Computer
   vision
AB Face fitting methods align deformable models to faces on images using the information given by the image pixels. However, most algorithms are designed to be used in desktop personal computers (PC), or hardware with significant computational power. These approaches are therefore too demanding for devices with limited computational power, like the increasingly used ARM-based devices. Besides the hardware limitations, the particularities of each operating system include additional challenges to the implementation of real-time face tracking solutions. To fill the lack of methods designed for platforms with a limited computational power we present an efficient way to fit 3D human face models to monocular images. This approach estimates the head pose and gesture in a 3D environment based on a full perspective projection, using parametric non-linear optimisation. We compare the performance of this method running it on similar ARM-based devices with different operating systems (Linux, Android, and iOS). In all cases, we have measured both accuracy and performance. The efficiency of the method makes it possible to run it in real-time (similar to on devices with limited computational power like smartphones and embedded systems. These kind of efficient methods are a vital component for human behaviour analysis applications, like driver monitoring systems and human-machine interfaces for disabled people among others.
C1 [Goenetxea, Jon; Unzueta, Luis; Otaegui, Oihana] Vicomtech, Dept Intelligent Transport Syst & Engn, Donostia San Sebastian 20009, Spain.
   [Dornaika, Fadi] Univ Basque Country, Comp Engn Fac, EHU UPV, Manuel de Lardizabal 1, Donostia San Sebastian 20018, Spain.
   [Dornaika, Fadi] Ikerbasque, Basque Fdn Sci, Alameda Urquijo 36-5,Plaza Bizkaia, Bilbao 48011, Spain.
C3 University of Basque Country; Basque Foundation for Science
RP Goenetxea, J (corresponding author), Vicomtech, Dept Intelligent Transport Syst & Engn, Donostia San Sebastian 20009, Spain.
EM jgoenetxea@vicomtech.org; lunzueta@vicomtech.org; fadi.dornaika@ehu.eus;
   ootaegui@vicomtech.org
RI Unzueta, Luis/L-6867-2014
OI Unzueta, Luis/0000-0001-5648-0910; Goenetxea, Jon/0000-0001-8412-5123;
   Dornaika, Fadi/0000-0001-6581-9680; Otaegui, Oihana/0000-0001-6069-8787
CR Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206
   [Anonymous], 2011, P 1 IEEE INT WORKSH
   [Anonymous], LITHISYR2326 DEP EL
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400
   Cao C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275093
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Deng J., 2019, ARXIV, DOI 10.48550/arXiv.1905.00641
   Deng Z, 2017, ARXIV170202719 CORR
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huber P, 2015, INT C COMP VIS THEOR
   Huber Patrik, 2016, P 11 INT JOINT C COM, DOI DOI 10.5220/0005669500790086
   Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   King DE, 2015, ARXIV150200046 CORR
   Lewis J.P., 1995, Vision, Interface, V95, P120
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Markus N, 2013, ARXIV13054537 CORR
   Ostermann J, 2003, FACE ANIMATION MPEG, P17
   Richard Hartley A.Z., 2003, Multiple View Geometry, V53
   Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377
   Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132
   Unzueta L, 2014, IMAGE VISION COMPUT, V32, P321, DOI 10.1016/j.imavis.2014.02.006
   Weng YL, 2014, GRAPH MODELS, V76, P172, DOI 10.1016/j.gmod.2013.10.002
   Zhang XS, 2016, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-662-48816-4
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu X, 2015, ARXIV151107212 CORR
NR 33
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12373
EP 12400
DI 10.1007/s11042-019-08515-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400049
OA Bronze
DA 2024-07-18
ER

PT J
AU Rahim, MA
   Shin, J
   Islam, R
AF Rahim, Md Abdur
   Shin, Jungpil
   Islam, Rashedul
TI Hand gesture recognition-based non-touch character writing system on a
   virtual keyboard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction (HCI); Gestural flick input; Virtual
   keyboard; Character input; Convolutional neural network (CNN)
ID REAL-TIME; NETWORK; POSTURE; INPUT
AB The non-touch system is a modern approach of computer-interface technology capable of revolutionizing human-computer interaction. The interface allows the user to input data and interact with a human, machine or robot in an uncontrolled environment, treatment or industrial life. However, it is challenging to input data into the machine and interact with man and machine with a variety of complexities such as cluttered environment, gesture tracking, and speed. There are many evolving systems, for example, aerial handwriting, sign language recognition, and finger alphabet recognition require substantial effort for all character learning and overhead processing, thence the accuracy of the classification is reduced. Therefore, this paper proposes a non-touch character writing system that allows users to interact and manage the on-screen virtual keyboards in a secure and healthy way by recognizing few hand gestures. We divide this work into two parts: a) hand gesture recognition; and b) gestural flick input using a virtual keyboard. A user-friendly keyboard interface is displayed on the monitor, which uses a flick input method. A deep learning method with CNN is used to extract the features of a gesture. To determine these features, color segmentation is used to detect the hand; color pixels can be obtained by extracting a particular HSV (hue, saturation, value) and applying threshold masking to the input image. Finally, a support vector machine is used to give a more accurate classification of the hand gestures. The user uses a gestural flick input system to perform non-touch character input and enters the character by viewing the virtual keyboard. The character input is executed based on the recognition of the user's hand gestures. Character input is evaluated based on the average classification accuracy of hand gestures and character recognition, and the accuracy and speed of input. Then, the system is compared with the state-of-the-art algorithms. The experimental results show that the proposed system can recognize seven typical gesture functions and input characters with 97.93% accuracy, which demonstrate the superiority compared to the state-of-the-art algorithms.
C1 [Rahim, Md Abdur; Shin, Jungpil; Islam, Rashedul] Univ Aizu, Sch Comp Sci & Engn, Aizu Wakamatsu, Fukushima 9658580, Japan.
C3 University of Aizu
RP Shin, J (corresponding author), Univ Aizu, Sch Comp Sci & Engn, Aizu Wakamatsu, Fukushima 9658580, Japan.
EM rahim_bds@yahoo.com; jpshin@u-aizu.ac.jp; rashed.cse@gmail.com
RI Rahim, Dr Md Abdur/JJD-7305-2023; Islam, Md Rashedul/HNB-8604-2023;
   Rahim, Abdur/X-3408-2019; Islam, Dr. Md. Rashedul/D-6227-2019
OI Rahim, Dr Md Abdur/0000-0003-2300-1420; Rahim,
   Abdur/0000-0003-2300-1420; Islam, Dr. Md. Rashedul/0000-0001-8676-6338;
   SHIN, Jungpil/0000-0002-7476-2468
CR Amma C, 2014, PERS UBIQUIT COMPUT, V18, P191, DOI 10.1007/s00779-013-0637-3
   Ben Jmaa A, 2016, COMPUT SIST, V20, P709, DOI [10.13053/cys-20-4-2390, 10.13053/CyS-20-4-2390]
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P436, DOI 10.1109/THMS.2015.2492599
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P403, DOI 10.1109/THMS.2015.2492598
   Chua CS, 2002, IMAGE VISION COMPUT, V20, P191, DOI 10.1016/S0262-8856(01)00094-4
   Ho N, 2018, MULTIMED TOOLS APPL, V77, P30651, DOI 10.1007/s11042-018-6216-x
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Hsien-I Lin, 2014, 2014 IEEE International Conference on Automation Science and Engineering (CASE), P1038, DOI 10.1109/CoASE.2014.6899454
   Ishiyama H, 2016, P IEEE VIRT REAL ANN, P187, DOI 10.1109/VR.2016.7504716
   Islam MR, 2016, AD HOC SENS WIREL NE, V34, P273
   Kane L, 2017, IEEE T HUM-MACH SYST, V47, P1077, DOI 10.1109/THMS.2017.2706695
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar P, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P157, DOI 10.23919/MVA.2017.7986825
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee KR, 2017, IEEE T NEUR SYS REH, V25, P37, DOI 10.1109/TNSRE.2016.2542524
   Li QC, 2016, 2016 INTERNATIONAL SYMPOSIUM ON SYSTEM AND SOFTWARE RELIABILITY (ISSSR), P68, DOI [10.1109/ISSSR.2016.020, 10.1109/ISSSR.2016.14]
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   Maehatake M., 2007, P WORKSH INT SYST SO P WORKSH INT SYST SO, P129
   Mahmoudi MT, 2017, COMPUT APPL ENG EDUC, V25, P1038, DOI 10.1002/cae.21853
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Murata T, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/278460
   Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33
   Nishimura Y., 2012, TECH REP, V111, P161
   Nobori T, 2000, IEEE IJCNN, P13, DOI 10.1109/IJCNN.2000.857867
   Ohn-Bar E, 2014, IEEE T INTELL TRANSP, V15, P2368, DOI 10.1109/TITS.2014.2337331
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Rahim MA, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON APPLICATIONS IN INFORMATION TECHNOLOGY (ICAIT - 2018), P75, DOI 10.1145/3274856.3274872
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Shin J, 2017, IEEE ACCESS, V5, P10496, DOI 10.1109/ACCESS.2017.2703783
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Wu XY, 2020, MULTIMED TOOLS APPL, V79, P9193, DOI 10.1007/s11042-019-7193-4
   Yin HP, 2019, IEEE INTERNET THINGS, V6, P5285, DOI 10.1109/JIOT.2019.2900355
NR 36
TC 7
Z9 8
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11813
EP 11836
DI 10.1007/s11042-019-08448-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400025
DA 2024-07-18
ER

PT J
AU Deng, R
AF Deng, Rui
TI DASH based video caching in MEC-assisted heterogeneous networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile edge computing; DASH; Layered encoding video; Delay analysis;
   Caching optimization
ID DELAY; AUDIO
AB Recently, the demand for video applications has become more and more pressing. To save backhaul bandwidth and reduce the network delay, Mobile Edge Computing (MEC) has arisen as a promising technique in future mobile networks. It can provide the storage, computing and networking resources in close-proximity to the mobile users through deploying multiple MEC servers at mobile edge. However, how to effectively utilize the limited storage capacity of these MEC servers is still the major challenge, especially when Dynamic Adaptive Streaming over HTTP (DASH) is used for video transmission. Recent studies have shown that layered encoding is very suitable for streaming service using DASH standard. Therefore, in our paper, combining with the feature of DASH-based scalable video transmission, we first design a novel multi-server cooperative scheme with software-defined networking (SDN) architecture for future MEC-assisted heterogeneous networks, to effectively manage and schedule the available resources, thus guaranteeing the requested video delivered to the clients with higher quality and lower delay. And then, based on the above scheme, the end-end delay is carefully analyzed for each real video streaming. With a full consideration of the averag end-to-end delay of video streaming and the provided video quality of MEC servers, we finally propose a Dynamic Programming based Adaptive Caching Algorithm (DPACA) to obtain an optimized caching strategy under the constraint of cache storage capacity at each MEC sever. Simulation results show that, our algorithm can improve the cache hit ratio while significantly reducing the end-to-end delay. Moreover, our algorithm has higher flexibility and adaptability.
C1 [Deng, Rui] Shaanxi Normal Univ, Sch Journalism & Commun, Xian, Peoples R China.
C3 Shaanxi Normal University
RP Deng, R (corresponding author), Shaanxi Normal Univ, Sch Journalism & Commun, Xian, Peoples R China.
EM dengrui618@snnu.edu.cn
FU National Natural Science Foundation of China [61901250]; Fundamental
   Research Funds for the Central Universities [GK201903113]
FX research was supported by National Natural Science Foundation of China
   (61901250) and Fundamental Research Funds for the Central Universities
   (GK201903113).
CR Ahlehagh H, 2014, IEEE ACM T NETWORK, V22, P1444, DOI 10.1109/TNET.2013.2294111
   [Anonymous], 2012, DISTR COMP STOR RAD
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Cha M, 2009, IEEE ACM T NETWORK, V17, P1357, DOI 10.1109/TNET.2008.2011358
   Chen DC, 2015, IEEE T WIREL COMMUN, V14, P3194, DOI 10.1109/TWC.2015.2403321
   Cisco, 2017, White Paper
   Deng R, 2018, MULTIMED TOOLS APPL, V77, P6445, DOI 10.1007/s11042-017-4551-y
   Ge XH, 2017, IEEE T MULTIMEDIA, V19, P2345, DOI 10.1109/TMM.2017.2733461
   HOLLECZEK P, 2006, P IEEE INT C NETW SE, P1
   HOOGHIEMSTRA G, 2001, 20011020 DELFT U
   Huang XM, 2016, IEEE VTS VEH TECHNOL, DOI 10.1109/VTCSpring.2016.7504071
   Kompella RR, 2012, IEEE ACM T NETWORK, V20, P811, DOI 10.1109/TNET.2012.2188905
   Li HT, 2016, 2016 INTERNATIONAL CONGRESS ON COMPUTATION ALGORITHMS IN ENGINEERING (ICCAE 2016), P90
   Liu JC, 2014, IEEE WIREL COMMUN, V21, P14, DOI 10.1109/MWC.2014.7000967
   Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318
   Megiddo N, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE 2ND USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST'03), P115
   MEMOS V, 2017, FUTUR GENER COMPUT S
   Moon SB, 1998, MULTIMEDIA SYST, V6, P17, DOI 10.1007/s005300050073
   Mori K, 2015, INT C NETWB INFO, P309, DOI 10.1109/NBiS.2015.48
   Papagiannaki K, 2003, IEEE J SEL AREA COMM, V21, P908, DOI 10.1109/JSAC.2003.814410
   Plageras AP, 2018, FUTURE GENER COMP SY, V82, P349, DOI 10.1016/j.future.2017.09.082
   Poularakis K, 2016, IEEE INFOCOM SER
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Psaras I., 2012, P 2 ED ICN WORKSH IN, P55, DOI DOI 10.1145/2342488.2342501
   Roccetti M, 2001, MULTIMED TOOLS APPL, V14, P23, DOI 10.1023/A:1011303506685
   Saip P, 2014, J CLIN ONCOL, V32, DOI 10.1200/jco.2014.32.15_suppl.e16526
   SAVVAS K, 2018, P WORKSH MOB EDG COM
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shanmugam K, 2013, IEEE T INFORM THEORY, V59, P8402, DOI 10.1109/TIT.2013.2281606
   Song Jiang, 2002, Performance Evaluation Review, V30, P31, DOI 10.1145/511399.511340
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Taleb T, 2013, IEEE NETWORK, V27, P12, DOI 10.1109/MNET.2013.6616110
   Wang K., 2015, P 5 WORKSHOP ALL THI, P19
   WANG S, 2013, ANN FALL M ITA AMITA
   Zhang GZ, 2016, IEEE T COMMUN, V64, P876, DOI 10.1109/TCOMM.2016.2515596
   Zhang WW, 2013, IEEE T MULTIMEDIA, V15, P1431, DOI 10.1109/TMM.2013.2247583
   Zhang XW, 2018, IEEE T VEH TECHNOL, V67, P9047, DOI 10.1109/TVT.2018.2849703
   Zhang Z, 2017, P IEEE WIR COMM NETW, P1
   ZHU D, 2018, P IEEE GLOB COMM C G
   2019, REF SOFTW
NR 41
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21073
EP 21094
DI 10.1007/s11042-020-08808-7
EA APR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529721900001
DA 2024-07-18
ER

PT J
AU Al Shinwan, M
   Abualigah, L
   Le, ND
   Kim, C
   Khasawnehl, AM
AF Al Shinwan, Mohammad
   Abualigah, Laith
   Nguyen Dinh Le
   Kim, Chulsoo
   Khasawnehl, Ahmad M.
TI An intelligent long-lived TCP based on real-time traffic regulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Long-lived TCP; Isolation; Segment-by-segment; Network performance; A
   novel framwork
ID CONGESTION CONTROL
AB Transmission control protocol (TCP) transaction is one of the chief protocols of Internet protocols. It is divided into two categories of data flow. (1) A small fraction of the TCP connections carried a small portion of the traffic called short-lived TCP. (2) A small fraction of the remaining TCP connections carried a large portion of the traffic called long-lived TCP. The main problem here is the transmission time; other data usually harm its flows, such as User Datagram Protocol (UDP) or short-lived TCP, and cause the unfairness in the network. In this paper, a novel framework is proposed to improve network throughput and to reduce the impact of long-lived TCP to other data flows. In this framework, each TCP connection passed by an edge network device and it will be observed for determining the long-lived TCP flows. Then, the detected long-lived TCP flow will be regulated based on predicting real-time traffic levels. Moreover, to highlight the benefits of the proposed framework, an analytical model is proposed to compare the proposed framework with the conventional TCP in terms of network performance. Experiments are conducted using the ns-2 benchmark in order to verify the results of the analytical model. The results showed that the analytical outcomes are promising and matched well with the outcomes of the ns-2 experiments. In the case of a high error rate, the proposed framework achieves higher reliability and reveals lower resource consumption.
C1 [Al Shinwan, Mohammad; Abualigah, Laith; Khasawnehl, Ahmad M.] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Nguyen Dinh Le; Kim, Chulsoo] Inje Univ Gimhae, Dept Comp Engn, Seoul, South Korea.
C3 Inje University
RP Al Shinwan, M (corresponding author), Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
EM mohmdsh@aau.edu.jo; Aligah.2020@gmail.com; nguy.le@inje.ac.kr;
   charles@inje.ac.kr; a.khasawneh@aau.edu.jo
RI Abualigah, Laith/ABC-9695-2020; Khasawneh, Ahmad Mohammad/AFJ-8626-2022;
   Al Shinwan, Mohammad/AAY-6940-2020; joy, shone/AAR-3728-2020
OI Abualigah, Laith/0000-0002-2203-4549; Khasawneh, Ahmad
   Mohammad/0000-0002-1850-3269; Al Shinwan, Mohammad/0000-0002-3864-7323; 
CR Abualigah L.M.Q., 2019, STUDIES COMPUTATIONA, V816, DOI [10.1007/978-3-030-10674-4, DOI 10.1007/978-3-030-10674-4]
   Braden R., 1122 RFC
   Carlucci Gaetano, 2016, ACM SIGCOMM Computer Communication Review, V46, DOI 10.1145/3243157.3243158
   Carlucci G, 2017, IEEE ACM T NETWORK, V25, P2629, DOI 10.1109/TNET.2017.2703615
   Cheng J., 2017, TELCO DISTRIBUTED DC
   Clark DD, 1998, IEEE ACM T NETWORK, V6, P362, DOI 10.1109/90.720870
   Douga Y, 2016, MULTIMED TOOLS APPL, V75, P11347, DOI 10.1007/s11042-015-2857-1
   Ebrahimi-Taghizadeh S, 2005, IEEE INFOCOM SER, P926
   Ehrlich CR, 2019, GEO-SPAT INF SCI, V22, P73, DOI 10.1080/10095020.2019.1613778
   Floyd S, 1993, IEEE ACM T NETWORK, V1, P397, DOI 10.1109/90.251892
   Heidemann J., 1997, Computer Communication Review, V27, P65, DOI 10.1145/263876.263886
   Hurley P, 1999, 16 INT TEL C ITC 16
   Kakhki AM, 2017, PROCEEDINGS OF THE 2017 INTERNET MEASUREMENT CONFERENCE (IMC'17), P290, DOI 10.1145/3131365.3131368
   Kennedy J., 2017, AUSTR J TELECOMMUNIC, V5, P113, DOI DOI 10.18080/AJTDE.V5N2.99
   Kua J, 2017, IEEE INTERNET THINGS, V4, P1399, DOI 10.1109/JIOT.2017.2722683
   Liu J, 2019, CAAI T INTELL TECHNO, V4, P24, DOI 10.1049/trit.2018.1059
   Matta, 2000, P ICNP 2000 OS JAP N
   Mehdi H, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3731
   Monoco G. L., 2001, ACM COMPUTER COMMUNI
   Padmanabhan, 1998, P IEEE GLOB 98 INT M
   Pukkala T, 2019, J FORESTRY RES, V30, P107, DOI 10.1007/s11676-018-0803-6
   Rejaie R, 1999, IEEE INFOCOM SER, P1337, DOI 10.1109/INFCOM.1999.752152
   Roberts J, 2016, COMP SDN BASED TCP C
   Saldana J, 2016, MULTIMED TOOLS APPL, V75, P17333, DOI 10.1007/s11042-015-3001-y
   Seckligh N., 1999, STUDY TCP UDP INTERA
   Shenker S, 1990, ACM SIGCOMM 90
   Soleimani MHM, 2018, J SUPERCOMPUT, V74, P4910, DOI 10.1007/s11227-018-2268-y
   Sunny A, 2017, J NETW COMPUT APPL, V93, P13, DOI 10.1016/j.jnca.2017.05.006
   Tsai CS, 2015, TRANSMISSION CONTROL, V26, P78
   Yilmaz S., 9 INT S MASCOTS 2001, P415
   Zaidi S. M. R., 2017, U.S. Patent, Patent No. [9,729,454, 9729454]
   Zhang Y., 2000, P NOSSDAV 2000 CHAP
   Zhang Y, 2019, IEEE WIREL COMMUN, V26, P26, DOI 10.1109/MWC.2019.1800401
NR 33
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16763
EP 16780
DI 10.1007/s11042-020-08856-z
EA APR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000528521200001
DA 2024-07-18
ER

PT J
AU Kumar, G
   Bakshi, S
   Sa, PK
   Majhi, B
AF Kumar, Gautam
   Bakshi, Sambit
   Sa, Pankaj Kumar
   Majhi, Banshidhar
TI Non-overlapped blockwise interpolated local binary pattern as periocular
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person identification; Periocular recognition; Local binary pattern;
   Phase intensive global pattern
ID FACE; RECOGNITION; IRIS; CLASSIFICATION; METRICS; SCLERA
AB Most of the prominent features of human face are present in the ocular area, referred as the periocular region. Complex and dense features in these regions makes it a candidate to be used as a biometric trait. This paper discusses an effective method for periocular recognition using non-overlapped blockwise interpolated local binary pattern (iLBP) features. For a given periocular image, an iLBP coded feature image is obtained and further divided into four equal non-overlapping sub-regions. From each sub-region having iLBP pattern, eight bin histogram features are calculated. A single feature vector is formed by concatenating blocked histograms of each non-overlapping region. Binned histogram based feature is also extracted using Phase Intensive Global Pattern (PIGP) features for comparison of results. Experiments are conducted on UBIRIS.v1 and UBIPr.v2 datasets. From the experiments, it is observed that selected histogram feature bins through the proposed approach provide a more compact representation of periocular image and size of the feature vector is also reduced with significant improvement in performance.
C1 [Kumar, Gautam; Bakshi, Sambit; Sa, Pankaj Kumar; Majhi, Banshidhar] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Bakshi, S (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
EM gautamkrjais@gmail.com; sambitbaksi@gmail.com; pankajksa@nitrkl.ac.in;
   bmajhi@nitrkl.ac.in
RI Bakshi, Sambit/JDC-3355-2023; K, Pankaj/A-9362-2017; Kumar,
   Gautam/ISV-3663-2023
OI Bakshi, Sambit/0000-0002-6107-114X; Kumar, Gautam/0000-0001-7354-8454
FU Fund for Improvement of S&T Infrastructure in Universities and Higher
   Educational Institutions (FIST) Program 2016, Department of Science and
   Technology, Government of India [ETI/359/2014]; Information Security
   Education & Awareness Project (Phase II), Ministry of Electronics and
   Information Technology (MeitY), Government of India
FX This research is partially supported by the following projects:; Grant
   No. ETI/359/2014 by Fund for Improvement of S&T Infrastructure in
   Universities and Higher Educational Institutions (FIST) Program 2016,
   Department of Science and Technology, Government of India.; Information
   Security Education & Awareness Project (Phase II), Ministry of
   Electronics and Information Technology (MeitY), Government of India.
CR Adams JW, 2010, ECO2 CITIES: ECOLOGICAL CITIES AS ECONOMIC CITIES, P205
   Aginako N, 2017, PATTERN RECOGN LETT, V91, P52, DOI 10.1016/j.patrec.2017.01.021
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Akhtar Z, 2018, IT PROF, V20, P50, DOI 10.1109/MITP.2018.032501748
   Al-Zubi RT, 2007, PATTERN ANAL APPL, V10, P147, DOI 10.1007/s10044-006-0058-2
   Ali Z, 2017, KSII T INTERNET INF, V11, P6133, DOI 10.3837/tiis.2017.12.024
   Alonso-Fernandez F, 2019, arXiv
   [Anonymous], 1986, Taxicab Geometry: An Adventure in Non-Euclidean Geometry
   [Anonymous], 2010, P 2010 ACM S APPL CO, DOI DOI 10.1145/1774088.1774408
   [Anonymous], P ICPR
   [Anonymous], 2011, Signal Processing and Communication Systems (ICSPCS), 2011 5th International Conference on, DOI [10.1109/IJCB.2011.6117600, DOI 10.1109/IJCB.2011.6117600]
   Bai ZY, 2010, I C CONT AUTOMAT ROB, P1842, DOI 10.1109/ICARCV.2010.5707216
   BAKSHI S, 2014, ANN IEEE IND C INDIC, P1, DOI DOI 10.1109/INDICON.2014.7030362
   Bakshi S, 2018, MULTIMED TOOLS APPL, V77, P17595, DOI 10.1007/s11042-017-4965-6
   Bakshi S, 2015, BIOCYBERN BIOMED ENG, V35, P30, DOI 10.1016/j.bbe.2014.05.003
   Bakshi S, 2012, PROCEDIA ENGINEER, V38, P1628, DOI 10.1016/j.proeng.2012.06.198
   BHARADWAJ S, 2010, 4 IEEE INT C BIOM TH
   Castrillon-Santana M, 2016, PATTERN RECOGN LETT, V82, P181, DOI 10.1016/j.patrec.2015.09.014
   Gragnaniello D, 2015, PATTERN RECOGN LETT, V57, P81, DOI 10.1016/j.patrec.2014.10.018
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hernandez D.K., 2018, 2018 INT C BIOM SPEC, P1, DOI DOI 10.23919/BIOSIG.2018.8553348
   HOLLINGSWORTH K, 2010, 4 IEEE INT C BIOM TH
   Hollingsworth KP, 2012, IEEE T INF FOREN SEC, V7, P588, DOI 10.1109/TIFS.2011.2173932
   ICHINO M, 1994, IEEE T SYST MAN CYB, V24, P698, DOI 10.1109/21.286391
   Jain A. K., 2011, HDB FACE RECOGNITION
   JILLELA R, 2002, HDB IRIS RECOGNITION
   Kar NB, 2019, MULTIMED TOOLS APPL, V78, P4789, DOI 10.1007/s11042-017-5485-0
   Kim MC, 2018, IEEE ACCESS, V6, P57291, DOI 10.1109/ACCESS.2018.2874056
   Kishore Kumar K., 2019, Microelectronics, Electromagnetics and Telecommunications. Proceedings of the Fourth ICMEET 2018. Lecture Notes in Electrical Engineering (LNEE 521), P713, DOI 10.1007/978-981-13-1906-8_72
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar KK, 2019, LECT NOTE NETW SYST, V40, P581, DOI 10.1007/978-981-13-0586-3_57
   Kumar M.N., 2017, 2017 International Conference on Computer, Communication and Signal Processing (ICCCSP), P1, DOI DOI 10.1109/JAS.2016.7510184
   Kumar Vijay, 2014, INFOCOMP Journal of Computer Science, V13, P38
   Lahdenoja O, 2005, IEEE IMAGE PROC, P1405
   Lance GN., 1967, Australian Computer Journal, V1, P15
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   López MB, 2017, J REAL-TIME IMAGE PR, V13, P375, DOI 10.1007/s11554-014-0410-5
   Mahalingam G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-36
   Malik F, 2013, J KING SAUD UNIV-COM, V25, P207, DOI 10.1016/j.jksuci.2012.11.004
   Miller S, 2010, IEEE INT CONF FUZZY
   Mistry K, 2017, IEEE C EVOL COMPUTAT, P1652, DOI 10.1109/CEC.2017.7969500
   Mistry K, 2017, IEEE T CYBERNETICS, V47, P1496, DOI 10.1109/TCYB.2016.2549639
   Oh K, 2014, NEUROCOMPUTING, V128, P185, DOI 10.1016/j.neucom.2013.01.066
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Padole CN, 2013, INT J BIOMETRICS, V5, P336, DOI 10.1504/IJBM.2013.055971
   Park M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009), P1, DOI 10.1109/ICUWB.2009.5288737
   Pereira L, 2015, MARINE ALGAE: BIODIVERSITY, TAXONOMY, ENVIRONMENTAL ASSESSMENT, AND BIOTECHNOLOGY, P1
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proenca H, 2019, IEEE T INF FOREN SEC, V14, P1702, DOI 10.1109/TIFS.2018.2883853
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Rattani A, 2016, IEEE IMAGE PROC, P320, DOI 10.1109/ICIP.2016.7532371
   Sabhanayagam T., 2018, International Journal of Applied Engineering Research, V13, P2276, DOI [10.1016/j.matpr.2021.07.005, DOI 10.1016/J.MATPR.2021.07.005]
   Santos G, 2015, PATTERN RECOGN LETT, V57, P52, DOI 10.1016/j.patrec.2014.09.012
   Sharma A, 2014, IEEE IMAGE PROC, P5007, DOI 10.1109/ICIP.2014.7026014
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Uzair M, 2013, INT CONF BIOMETR
   Wang XL, 2013, IEEE INT SYM MULTIM, P301, DOI 10.1109/ISM.2013.58
   Woodard Damon L., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P201, DOI 10.1109/ICPR.2010.58
   Woodard DL, 2011, SIGNAL IMAGE VIDEO P, V5, P443, DOI 10.1007/s11760-011-0248-2
   Xu J, 2010, B ENTOMOL RES, V100, P359, DOI 10.1017/S0007485310000015
   Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhang L, 2016, KNOWL-BASED SYST, V111, P248, DOI 10.1016/j.knosys.2016.08.018
   Zhao ZJ, 2018, IEEE T INF FOREN SEC, V13, P2937, DOI 10.1109/TIFS.2018.2833018
NR 70
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16565
EP 16597
DI 10.1007/s11042-020-08708-w
EA APR 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000524392000001
DA 2024-07-18
ER

PT J
AU Veluchamy, M
   Subramani, B
AF Veluchamy, Magudeeswaran
   Subramani, Bharath
TI Fuzzy dissimilarity contextual intensity transformation with gamma
   correction for color image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dissimilarity; Histogram clip; Gamma correction; Contextual intensity
   transformation; Saturation maximization
ID HISTOGRAM EQUALIZATION; CONTRAST ENHANCEMENT
AB The color image enhancement algorithm proposed here yields an improvement of the image data that suppresses undesired distortions or enhances some image features and convert an image to a format better suited to machine processing. The proposed Fuzzy Dissimilarity Contextual Intensity Transformation with Gamma Correction (FDCIT-GC) consists of following stages. At first, Fuzzy Dissimilarity Histogram (FDH) is constructed from the input image. It provides the mean dissimilarity value of each intensity level present in the input image. FDH is followed by clipping in order to restricts the over enhancement rate. In order to achieve better display fidelity rendition quality, Gamma Correction (GC) is applied. To restore the natural characteristics of the image, Contextual Intensity Transformation (CIT) is applied at next to get final enhanced images. Various color images from different database are experimented and the performance of the proposed FDCIT-GC algorithm is compared with several existing methods both subjectively and objectively. Test results demonstrate that the proposed algorithm achieves better outputs than other existing techniques.
C1 [Veluchamy, Magudeeswaran; Subramani, Bharath] PSNA Coll Engn & Technol, Dept Elect & Commun Engn, Dindigul 624622, Tamil Nadu, India.
C3 PSNA College of Engineering & Technology
RP Subramani, B (corresponding author), PSNA Coll Engn & Technol, Dept Elect & Commun Engn, Dindigul 624622, Tamil Nadu, India.
EM magudeeswaran@psnacet.edu.in; bharath.psna@psnacet.edu.in
RI Subramani, Bharath/AAM-9681-2020; Veluchamy, Magudeeswaran/O-6428-2016;
   Veluchamy, Magudeeswaran/AAS-1568-2020
OI Subramani, Bharath/0000-0001-8989-9320; Veluchamy,
   Magudeeswaran/0000-0001-6427-1094; Veluchamy,
   Magudeeswaran/0000-0002-7260-7608
CR Cao G, 2018, COMPUT ELECTR ENG, V66, P569, DOI 10.1016/j.compeleceng.2017.09.012
   Chandrasekharan R, 2018, IEEE SIGNAL PROC LET, V25, P813, DOI 10.1109/LSP.2018.2812861
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jiang G, 2015, J MOD OPTIC, V62, P536, DOI 10.1080/09500340.2014.991358
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lin SCF, 2015, COMPUT ELECTR ENG, V46, P356, DOI 10.1016/j.compeleceng.2015.06.001
   Liu SL, 2017, J VIS COMMUN IMAGE R, V48, P169, DOI 10.1016/j.jvcir.2017.05.011
   Magudeeswaran V, 2017, INT J IMAG SYST TECH, V27, P98, DOI 10.1002/ima.22214
   Magudeeswaran V, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/891864
   Parihar AS, 2017, IEEE T IMAGE PROCESS, V26, P1810, DOI 10.1109/TIP.2017.2665975
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Raju G, 2014, AEU-INT J ELECTRON C, V68, P237, DOI 10.1016/j.aeue.2013.08.015
   Salin AAM, 2018, IEEE ACCESS, V6, P58794, DOI 10.1109/ACCESS.2018.2872116
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Subramani B, 2020, MULTIMED TOOLS APPL, V79, P7837, DOI 10.1007/s11042-019-08521-0
   Veluchamy M, 2019, OPTIK, V183, P329, DOI 10.1016/j.ijleo.2019.02.054
   Vidya BS, 2019, WIRELESS PERS COMMUN, V106, P651, DOI 10.1007/s11277-019-06184-6
   Wong CY, 2016, J MOD OPTIC, V63, P1618, DOI 10.1080/09500340.2016.1163428
NR 22
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19945
EP 19961
DI 10.1007/s11042-020-08870-1
EA APR 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000523401700002
DA 2024-07-18
ER

PT J
AU Anbarasan, M
   Prakash, S
   Antonidoss, A
   Anand, M
AF Anbarasan, M.
   Prakash, S.
   Antonidoss, A.
   Anand, M.
TI RETRACTED: Improved encryption protocol for secure communication in
   trusted MANETs against denial of service attacks (Retracted article. See
   MAY, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Denial of service; Low energy efficient adaptive clustering hierarchy;
   Cluster head; Cluster member; Quality of service
AB MANET(Mobile Adhoc Networks) possess the open system condition, absence of central server, mobile nodes that make helpless to security assault while conventional security components couldn't meet MANET security prerequisites in view of restricted correspondence data transfer capacity, calculation power, memory and battery limit in addition to the vitality enabled environment. The trusted MANETs provide a reliable path and efficient communication but the secrecy of the trust values sometimes may be overheard by the masqueraders. Due to the need of the clustered MANETs the exchange of mathematical values remains to be a necessary part. In the proposed security of the trusted MANETs is focused so as to provide rigid and robust networks when additional resources are added. For clustering of the nodes LEACH protocol is suggested in which the CHs and CMs are fixed for the data transfer in the network. The energy is disseminated in the LEACH as to avoid the battery drain and network fatal. Hence to add resistance and to make an authentic network, the encryption and decoding is incorporated as a further supplementary to avoid the denial of service attacks, we have utilized DoS Pliancy Algorithm in which the acknowledgment based flooding attacks is focused. Likewise the encoded messages from the source node in one cluster can be recoded in the transmission stage itself to reproduce the messages. Contrasted with the past works, QoS of our proposed work has been made strides when tested with black hole and sink hole attacks. Simulation results shows that the DoS pliancy scheme works better and efficient when compared to the existing trust based systems.
C1 [Anbarasan, M.; Anand, M.] Tagore Engn Coll, Dept Informat Technol, Chennai, Tamil Nadu, India.
   [Prakash, S.] Jerusalem Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Antonidoss, A.] Hindustan Inst Technol & Sci, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Hindustan Institute of Technology & Science
RP Anbarasan, M (corresponding author), Tagore Engn Coll, Dept Informat Technol, Chennai, Tamil Nadu, India.
EM anbarasan.cse@gmail.com; prakash.sav4@gmail.com; aro.antoni@gmail.com;
   anandmenscall@gmail.com
RI s, prakash/AAS-1715-2021; A, Dr.Antonidoss/AAW-2916-2020; M,
   Anand/AAE-5629-2020
OI s, prakash/0000-0001-7799-4582; A, Dr.Antonidoss/0000-0003-1633-0314; M,
   Anand/0000-0001-5801-3654; HITS, Hindustan Institute of Technology and
   Science/0009-0004-3570-2675
CR Antoo A, 2014, 2014 INT C CONTR INS
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Bhosle A, 2013, INT J EMERGING TECHN, V3, P426
   Breivold HP, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND DATA INTENSIVE SYSTEMS, P532, DOI 10.1109/DSDIS.2015.11
   Brittadevi V, 2018, INT J TRENDS ENG TEC, V28, P2349
   Chaoliang Li, 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P1018, DOI 10.1109/TrustCom.2012.37
   Chen W, 2006, NETW INT C MOB COMM
   Dhall R, 2017, INT J INTERACT MULTI, V4, P16, DOI 10.9781/ijimai.2017.433
   Dorri A., 2015, INT J COMPUTER SCI E, V6, P1
   Geetha K, 2014, IJCSIT INT J COMPUT, V5, P5033
   Hemalatha P, 2017, J ADV RES DYN CONTRO, V2, P262
   Hemalatha P., 2018, INT J PURE APPL MATH, V119, P557
   Jhaveri RH, 2012, 2 INT C ADV COMM TEC
   Kim Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061289
   Kumar A, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P854, DOI 10.1109/PDGC.2012.6449935
   Liu J., 2013, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics
   Michael A Nadeem, 2009, IWCMC 09 P INT C WIR
   Patel R., 2011, International Journal of Computer Applications, V20, P32
   Shanthi K, 2017, WIREL NETW, V23, P1025, DOI 10.1007/s11276-015-1191-x
   Shushan Zhao, 2012, 2012 Tenth Annual International Conference on Privacy, Security and Trust (PST), P96, DOI 10.1109/PST.2012.6297925
   Singhai P, 2016, INT J SCI RES DEV, V3, P2321
   Soryal J, 2012, WIREL TELECOMM SYMP
   Su J, 2011, COMMUNICATIONS COMPU
   Supriya KM, 2012, LECT NOTES I COMPUTE
   Tajamolian M, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS: WAINA, VOLS 1 AND 2, P176, DOI 10.1109/WAINA.2009.149
   Tseng YC, 2003, INT CONF PARA PROC, P375
   Vimalkumar S., 2018, Asian Journal of Applied Science and Technololgy, V2, P287
   Wang JG, 2010, INT J ADV ROBOT SYST, V7, P1
   Yu PH, 2011, SECURITY DYNAMIC ENC, DOI [10.5772/12843, DOI 10.5772/12843]
   Zhang P, 2014, IEEE T PARALL DISTR, V25, P2211, DOI 10.1109/TPDS.2013.161
NR 30
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8929
EP 8949
DI 10.1007/s11042-018-6777-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600029
DA 2024-07-18
ER

PT J
AU Dogra, A
   Kadry, S
   Goyal, B
   Agrawal, S
AF Dogra, Ayush
   Kadry, Seifedine
   Goyal, Bhawna
   Agrawal, Sunil
TI An efficient image integration algorithm for night mode vision
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bitonic filter; Bit plane slicing; Anisotropic diffusion filter;
   Butterworth high pass filter; Integration; Artefacts
ID FUSION; SEGMENTATION; ENTROPY; RATIO
AB The night mode visible images are often fused with infrared images for increased visual perception and contextual enhancement as the later is equipped with the complimentary information which is otherwise missing due to night mode image acquisition. This technology finds extensive application in the field of armed forces and surveillance. The night mode visible images, due to under-exposure and poor atmospheric conditions are prone to noise and artefacts which leads deterred level of information analysis and extraction. This article not only provides higher visual perception of the individual source images but also proposes an efficient fusion algorithm for visible and infrared images in night mode which is able to generate high quality results with increased focus on the objects of interest competitive with the state-of-the-art methods.
C1 [Dogra, Ayush; Goyal, Bhawna; Agrawal, Sunil] Panjab Univ UIET, Dept Elect & Commun, Chandigarh, India.
   [Kadry, Seifedine] Beirut Arab Univ, Dept Stat, Beirut, Lebanon.
C3 Panjab University; Beirut Arab University
RP Dogra, A (corresponding author), Panjab Univ UIET, Dept Elect & Commun, Chandigarh, India.
EM ayush123456789@gmail.com; s.kadry@bau.edu.lb; bhawnagoyal28@gmail.com;
   s.agrawal@hotmail.com
RI Kadry, Seifedine/C-7437-2011; Goyal, Bhawna/AAE-6051-2019
OI Kadry, Seifedine/0000-0002-1939-4842; Agrawal, Sunil/0000-0001-6055-2657
CR [Anonymous], 2016, IIOAB J
   [Anonymous], 1994, GEOMETRY DRIVEN DIFF, DOI DOI 10.1007/978-94-017-1699-4_3
   [Anonymous], 1998, CWI
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Bavirisetti DP, 2016, INFRARED PHYS TECHN, V76, P52, DOI 10.1016/j.infrared.2016.01.009
   Bavirisetti Durga Prasad, 2016, AIN SHAMS ENG J
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Dippel S, 2002, IEEE T MED IMAGING, V21, P343, DOI 10.1109/TMI.2002.1000258
   Dogra A, 2018, FUTUR GEN COMPUT SYS
   Dogra A, 2017, IEEE ACCESS, V5, P16040, DOI 10.1109/ACCESS.2017.2735865
   Fernandes SL, 2017, J MED IMAG HEALTH IN, V7, P1841, DOI 10.1166/jmihi.2017.2280
   Jin X, 2017, INFRARED PHYS TECHN, V85, P478, DOI 10.1016/j.infrared.2017.07.010
   Khan MW, 2016, J INTEGR DES PROCESS, V20, P77, DOI 10.3233/jid-2016-0004
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li X, 2011, IET IMAGE PROCESS, V5, P141, DOI 10.1049/iet-ipr.2010.0084
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Rafael C.Gonzalez., 2004, DIGITAL IMAGE PROCES
   Raja NSM, 2017, J MED IMAG HEALTH IN, V7, P1825, DOI 10.1166/jmihi.2017.2267
   Rajinikanth V., 2018, Microelectronics, Electromagnetics and Telecommunications. Proceedings of ICMEET 2017. LNEE 471, P453, DOI 10.1007/978-981-10-7329-8_46
   Rajinikanth V, 2017, J MED IMAG HEALTH IN, V7, P1837, DOI 10.1166/jmihi.2017.2265
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Shah J. H., 2017, Pattern Recognit. Lett.
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Torabi A, 2012, COMPUT VIS IMAGE UND, V116, P210, DOI 10.1016/j.cviu.2011.10.006
   Treece G, 2016, IEEE T IMAGE PROCESS, V25, P5199, DOI 10.1109/TIP.2016.2605302
   Wang D, 2017, IEEE SENS J, V17, P1407, DOI 10.1109/JSEN.2016.2641501
   Waxman AM, 1997, NEURAL NETWORKS, V10, P1, DOI 10.1016/S0893-6080(96)00057-3
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
NR 36
TC 5
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10995
EP 11012
DI 10.1007/s11042-018-6631-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600068
DA 2024-07-18
ER

PT J
AU Gill, HK
   Sehgal, VK
   Verma, AK
AF Gill, Harsuminder Kaur
   Sehgal, Vivek Kumar
   Verma, Anil Kumar
TI A context sensitive security framework for Enterprise multimedia
   placement in fog computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural networks; Fog computing environment; Malicious files;
   Enterprise multimedia security
ID ARCHITECTURE
AB In the era of ICT, multimedia files are one of the main sources of information sharing for any enterprise located in one or more geographical locations. Online video watching and editing platforms needs to store the multimedia file close to the end user so that the latency can be minimized which in result enhances the quality of experience. Fog computing is evolved as distributed computing infrastructure located close to end user with minimum latency. As, Fog computing is distributed and can be owned by third party providers, a framework is proposed which selects the appropriate Fog computing environment for placement of multimedia files based on context and security requirements. Deep neural network is used to evaluate context parameters, explicit security requirement, file type classification, and final allocation decision. The proposed framework is tested using Juypter notebook and Python 3.6 framework for one million instances of multimedia files. It has received 84% (average of ten experimental runs) accuracy in selection of appropriate Fog layer to place a multimedia file. The Proposed framework enhances the multimedia file placement on Fog computing environment so that processing of file can be done without worrying about the security of Fog.
C1 [Gill, Harsuminder Kaur; Sehgal, Vivek Kumar] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
   [Verma, Anil Kumar] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Jaypee University of Information Technology; Thapar Institute of
   Engineering & Technology
RP Gill, HK (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM harsuminder@gmail.com
RI Sehgal, Vivek Kumar/S-1937-2017; Verma, Anil Kumar/F-1476-2018
OI Sehgal, Vivek Kumar/0000-0002-0026-2284; Verma, Anil
   Kumar/0000-0003-0561-1954
CR Aaber Zeyad S., 2017, Enterprise Security. Second International Workshop, ES 2015. Revised Selected Papers: LNCS 10131, P259, DOI 10.1007/978-3-319-54380-2_12
   [Anonymous], 2018, NEURAL NETWORKS DEEP, DOI DOI 10.1007/978-3-319-94463-0
   Chang V, 2015, ENT SEC 2 INT WORKSH
   Chang V, 2018, NEURAL COMPUT APPL
   Chang V, 2017, KNOWL-BASED SYST, V127, P29, DOI 10.1016/j.knosys.2017.03.003
   Cottrell M, 2006, NEURAL NETWORKS, V19, P721, DOI 10.1016/j.neunet.2006.05.011
   Haykin S., 2010, Neural Networks and Learning Machines
   Hsu TH, 2019, INT J INTERNET PROTO, V12, P85, DOI 10.1504/IJIPT.2019.10021157
   Jie YM, 2019, CHINA COMMUN, V16, P22, DOI 10.12676/j.cc.2019.03.003
   Jupyter, 2021, PROJECT JUPYTER
   Kharel J, 2019, MULTIMED TOOLS APPL, V78, P9405, DOI 10.1007/s11042-018-6530-3
   Lee J, 2018, FUTURE GENER COMP SY, V86, P1338, DOI 10.1016/j.future.2018.03.022
   Li Y, 2017, IEEE MULTIMEDIA, V24, P58, DOI 10.1109/MMUL.2017.4031306
   Oikonomou A, 2002, P 2 S RES COMP SCI, P12
   Patterson J, 2008, DEEP LEARNING PRACTI
   Perera C., 2017, FOG COMPUTING SUSTAI
   Perera C, 2014, IEEE COMMUN SURV TUT, V16, P414, DOI 10.1109/SURV.2013.042313.00197
   Rahman MA, 2018, IEEE COMMUN MAG, V56, P80, DOI 10.1109/MCOM.2018.1700907
   Rong WG, 2014, J VISUAL LANG COMPUT, V25, P840, DOI 10.1016/j.jvlc.2014.09.005
   Rosario D, 2018, SENSORS SWITZERLAND
   Shafiq SI, 2015, CYBERNET SYST, V46, P35, DOI 10.1080/01969722.2015.1007734
   SHAIN M, 1994, COMPUT SECUR, V13, P15, DOI 10.1016/0167-4048(94)90086-8
   Sohal A. S., 2017, COMPUT SECUR, P1
   Sohal AS, 2018, COMPUT SECUR, V74, P340, DOI 10.1016/j.cose.2017.08.016
   Sun G, 2019, INFORM SCIENCES, V481, P616, DOI 10.1016/j.ins.2019.01.008
   Wang W, 2017, IEEE INTERNET THINGS, V4, P487, DOI 10.1109/JIOT.2016.2578722
   Wen Z, 2017, IEEE INTERNET COMPUT, V21, P16, DOI 10.1109/MIC.2017.36
   Yang Y, 2019, INFORM SCIENCES, V479, P567, DOI 10.1016/j.ins.2018.02.005
NR 28
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10733
EP 10749
DI 10.1007/s11042-020-08649-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600056
DA 2024-07-18
ER

PT J
AU Pan, S
   Wei, JG
   Hu, SB
AF Pan, Shuang
   Wei, Jianguo
   Hu, Shaobo
TI A Novel Image Encryption Algorithm Based on Hybrid Chaotic Mapping and
   Intelligent Learning in Financial Security System
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Financial Security; Dynamic Encryption; Intelligent Network; Chaotic
   System; Anti-plain Attack; Image Permutation
ID PERMUTATION
AB With the expansion and prevalence of financial certification, problems of financial security have been springing up. How to ensure the security of financial information and protect our privacy is an issue of particular concern. In order to reduce the influence of chaotic periodicity on cipher-text, an image dynamic encryption algorithm based on hybrid chaotic system and deep network is proposed in this paper. Firstly, the hybrid chaotic system is constructed to combine many mapping functions by using the nonlinear combination mechanism, and the chaotic sequence is outputted to generate the initial value of hybrid chaotic system by using the pixel value. Then the plain-text pixel values are adopted to generate the initial value of the hybrid system for improving the anti-plain attack ability of the algorithm; Artificial neural network is used to process chaotic sequences, and effectively eliminate chaotic periodicity; The classification and encryption of permutation image are realized by constructing quantization method and hetero-diffusion technology. The experimental results show that our proposed encryption technology has higher security and stronger ability to resist plain-text attack compared with the existing image encryption algorithms, which adapts to enhance the security of the financial system.
C1 [Pan, Shuang; Wei, Jianguo; Hu, Shaobo] Wuhan Univ Technol, Sch Econ, Wuhan, Peoples R China.
C3 Wuhan University of Technology
RP Wei, JG (corresponding author), Wuhan Univ Technol, Sch Econ, Wuhan, Peoples R China.
EM easy698@126.com
CR Acharya RV, 2018, U.S. Patent, P4, Patent No. [9,946,998[P], 9946998]
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Dongare AS, 2017, EFFICIENT TECHNIQUE
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hua TX, 2015, INT J THEOR PHYS, V54, P526, DOI 10.1007/s10773-014-2245-z
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Qiu MK, 2018, FUTURE GENER COMP SY, V80, P421, DOI 10.1016/j.future.2016.01.006
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Tong XJ, 2015, OPTIK, V126, P2445, DOI 10.1016/j.ijleo.2015.06.018
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu XJ, 2016, INF SCI, V38, P502
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang L, 2015, J COMPUT THEOR NANOS, V12, P4980, DOI [10.1166/jctn.2015.4467, DOI 10.1166/JCTN.2015.4467]
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 21
TC 8
Z9 9
U1 3
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9163
EP 9176
DI 10.1007/s11042-018-7144-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600044
DA 2024-07-18
ER

PT J
AU Pramanik, BK
   Rahman, AZMS
   Li, M
AF Pramanik, Bijon Kumar
   Rahman, A. Z. M. Shakilur
   Li, Mei
TI Blockchain-based reward point exchange systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Peer-to-peer network; Decentralized; Reward point exchange;
   Hyperledger; Fabric; Composer
ID INTERNET
AB Large organizations are increasingly attracted to the notion of reward points as a form of loyalty giveaway. However, for current markets, these points can be redeemed only within the organizational domain. No concept of interoperability or exchangeability of these points exists among cross-organization users in a decentralized manner. To address this challenge, this study proposes a solution for exchanging user-earned reward points using blockchain technology. The solution aims at a decentralized peer-to-peer exchange network wherein participants can directly exchange points through web/mobile apps of point-offering organizations. To this end, we propose using Hyperledger Fabric Blockchain and Hyperledger Composer, which will synchronize the initial data from off-chain apps, and after the exchanges are done on-chain, sync the data back to them. This approach extends existing off-chain organization management systems instead of requiring a whole new system both for users and organizations and also optimizes the ever growing blockchain database size.
C1 [Pramanik, Bijon Kumar; Li, Mei] China Univ Geosci Beijing, Sch Informat Engn, Beijing, Peoples R China.
   [Rahman, A. Z. M. Shakilur] DataProX Consultancy Ltd, Beijing, Peoples R China.
C3 China University of Geosciences
RP Li, M (corresponding author), China Univ Geosci Beijing, Sch Informat Engn, Beijing, Peoples R China.
EM cyberjon09@gmail.com; xclusive.shakil@gmail.com; maggieli@cugb.edu.cn
CR Androulaki E, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190538
   [Anonymous], 2015, HDB DIGITAL CURRENCY
   Biswas S, 2019, IEEE INTERNET THINGS, V6, P4650, DOI 10.1109/JIOT.2018.2874095
   Black K, 2020, WHY CUSTOMER LOYALTY
   Chapelle A, 2015, TRENDS CRYPTO CURREN, DOI [10.2139/ssrn 2646618, DOI 10.2139/SSRN2646618]
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Ding ST, 2019, FUTURE GENER COMP SY, V93, P583, DOI 10.1016/j.future.2018.10.054
   Foroglou G, 2015, COLUMBIA U PHD SUSTA, V10
   H. M. D. V, 2017, BLOCKCHAIN ENABLED A, DOI [10.1007/978-1-4842-3081-7_10, DOI 10.1007/978-1-4842-3081-7_10]
   Liao CF, 2017, IEEE INT CONF SERV, P133, DOI 10.1109/SOCA.2017.26
   Peer-to-Peer Distributed Ledger Technology Assessment Virtual peer-to-peer energy exchange using distributed ledger technology: comprehensive project assessment report, 2000, PEER TO PEER DISTRIB, V74, P115
   Provenance, 2015, CISC VIS NETW IND GL
   Thakkar P., 2018, PERFORMANCE BENCHMAR
   Wan SH, 2019, FUTURE GENER COMP SY, V91, P382, DOI 10.1016/j.future.2018.08.007
   Xia Q, 2017, INFORMATION, V8, DOI 10.3390/info8020044
   Zhao Y, 2019, IEEE J BIOMEDICAL HL, V9
   Zheng Z, 2020, OVERVIEW BLOCKCHAIN
NR 17
TC 6
Z9 6
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9785
EP 9798
DI 10.1007/s11042-019-08341-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600004
DA 2024-07-18
ER

PT J
AU Du, L
   Chen, Z
   Ho, ATS
AF Du, Ling
   Chen, Zhen
   Ho, Anthony T. S.
TI Binary multi-view perceptual hashing for image authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual image hashing; Tamper detection; Multi-view; Binary
   representation
ID ROBUST; SECURE; TRANSFORM; PATTERN; ANGLE; GRAPH
AB This paper presents a novel Binary Multi-View Perceptual Hashing (BMVPH) scheme for image authentication, which provides compact and efficient representations and can easily scale to large data. We apply virtual prior attacks (e.g. additive noise, blurring, compression, logo-insert etc.) on original images to generate simulated distorted copies. The original images and the corresponding distorted copies provide the so-called training set. For perceptual hashing learning, we formulate BMVPH by two key components: collaborative binary representation learning (CBRL) and perpetual content authentication learning (PCAL), into a unified learning framework. Our BMVPH scheme collaboratively encodes the multi-view features into a compact common binary code space while considering the perceptual content similarity at the same time. The experimental results show that when compared with the state-of-the-art methods, the proposed algorithm can achieve higher discrimination and better perceptual robustness. In particular, the Area Under ROC Curve (AUC) increases on average of 3.8% as compared with other state-of-the-art methods.
C1 [Du, Ling; Chen, Zhen] Tianjin Polytech Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
   [Ho, Anthony T. S.] Univ Surrey, Dept Comp Sci, Guildford GU2 7XH, Surrey, England.
   [Ho, Anthony T. S.] Tianjin Univ Sci & Technol, Tianjin 300457, Peoples R China.
   [Ho, Anthony T. S.] Wuhan Univ Technol, Wuhan 430070, Peoples R China.
C3 Tiangong University; University of Surrey; Tianjin University Science &
   Technology; Wuhan University of Technology
RP Du, L (corresponding author), Tianjin Polytech Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
EM duling@tjpu.edu.cn; 1730121256@stu.tjpu.edu.cn; a.ho@surrey.ac.uk
FU National Natural Science Foundation of China [61602344];
   Science&Technology Development Fund of Tianjin Education Commission for
   Higher Education, China [2017KJ091]; Natural Science Foundation of
   Tianjin [17JCQNJC00600]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61602344), Science&Technology Development Fund of Tianjin
   Education Commission for Higher Education, China (Grant No. 2017KJ091)
   and Natural Science Foundation of Tianjin (Grant No. 17JCQNJC00600).
CR Abbas SQ, 2016, INT C ULTRA MOD TELE, P401, DOI 10.1109/ICUMT.2016.7765393
   [Anonymous], 2018, J ELECT IMAGING
   [Anonymous], 2010, IEEE INT C IM PROC
   [Anonymous], 2017, IEEE UTT PRAD SECT I
   [Anonymous], 2018, IET IMAGE PROCESSING
   [Anonymous], 2015, IEEE INT C COMP INT
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Brbic M, 2018, PATTERN RECOGN, V73, P247, DOI 10.1016/j.patcog.2017.08.024
   Chen YC, 2014, OPTIK, V125, P5582, DOI 10.1016/j.ijleo.2014.07.006
   Du L, 2018, BIOMED RES INT, V2018, P1
   Gao HC, 2015, IEEE I CONF COMP VIS, P4238, DOI 10.1109/ICCV.2015.482
   Ghouti Lahouari, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3794, DOI 10.1109/ICASSP.2014.6854311
   Huang ZQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1389, DOI 10.1145/3240508.3240690
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Khelifi F, 2010, IEEE SIGNAL PROC LET, V17, P43, DOI 10.1109/LSP.2009.2032451
   Kim C, 2003, SIGNAL PROCESS-IMAGE, V18, P169, DOI 10.1016/S0923-5965(02)00130-3
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lefebvre F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P495
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Liang C, 2011, PROCEEDINGS OF 2011 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (7TH), VOL III, P715
   Liu H, 2016, MULTIMED TOOLS APPL, V75, P7681, DOI 10.1007/s11042-015-2688-0
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Liu Zhaoqing, 2011, Chinese Journal of Scientific Instrument, V32, P2024
   Lv X, 2009, EURASIP J INFORM SEC, V2009
   LV X, 2009, EURASIP J INFORM SEC, V2009, P1
   Lv XD, 2013, IEEE T INF FOREN SEC, V8, P1838, DOI 10.1109/TIFS.2013.2281219
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Monga V, 2004, IEEE IMAGE PROC, P677
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024
   Nguyen DQ, 2011, COMMUNICATIONS MULTI
   Ouyang JL, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978572
   Ouyang JL, 2015, DIGIT SIGNAL PROCESS, V41, P98, DOI 10.1016/j.dsp.2015.03.006
   Pun CM, 2018, MULTIMED TOOLS APPL, V77, P11609, DOI 10.1007/s11042-017-4809-4
   Qin C, 2019, IEEE ACCESS, V7, P45460, DOI 10.1109/ACCESS.2019.2908029
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Qin C, 2018, SIGNAL PROCESS, V142, P194, DOI 10.1016/j.sigpro.2017.07.019
   Qin C, 2016, DISPLAYS, V45, P26, DOI 10.1016/j.displa.2016.09.003
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Sun R, 2014, MULTIMED TOOLS APPL, V70, P1651, DOI 10.1007/s11042-012-1188-8
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tagliasacchi M, 2009, IEEE T IMAGE PROCESS, V18, P2491, DOI 10.1109/TIP.2009.2028251
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P1724, DOI 10.1109/TMM.2018.2889560
   Tang Z., 2012, INT J DIGITAL CONTEN, V3, P39, DOI DOI 10.4156/JDCTA.V0L6.ISSUE23.5
   Tang ZJ, 2016, AEU-INT J ELECTRON C, V70, P833, DOI 10.1016/j.aeue.2016.03.010
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2015, DIGIT SIGNAL PROCESS, V43, P17, DOI 10.1016/j.dsp.2015.05.002
   Tang ZJ, 2014, OPTIK, V125, P5102, DOI 10.1016/j.ijleo.2014.05.015
   Tang ZJ, 2014, IET IMAGE PROCESS, V8, P142, DOI 10.1049/iet-ipr.2013.0332
   Tang ZJ, 2013, SIGNAL PROCESS, V93, P2061, DOI 10.1016/j.sigpro.2013.01.008
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang P., 2018, PROC IEEE INT C DIGI, P1
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Wang XF, 2012, J VIS COMMUN IMAGE R, V23, P782, DOI 10.1016/j.jvcir.2012.03.005
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Yan CP, 2017, IEEE T INF FOREN SEC, V12, P2144, DOI 10.1109/TIFS.2017.2699942
   Yan CP, 2016, IEEE T INF FOREN SEC, V11, P2664, DOI 10.1109/TIFS.2016.2594136
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   Yan C, 2015, 2015 12TH CHINA INTERNATIONAL FORUM ON SOLID STATE LIGHTING (SSLCHINA), P1, DOI 10.1109/SSLCHINA.2015.7360676
   Yan Zhao, 2010, Proceedings 2010 International Conference on Progress in Informatics and Computing (PIC 2010), P738, DOI 10.1109/PIC.2010.5687938
   Yang L, 2011, SECUR COMMUN NETW, V4, P1378, DOI 10.1002/sec.265
   Yarlagadda S.K., 2018, CoRR
   Zhan K, 2019, IEEE T KNOWL DATA EN, V31, P1984, DOI 10.1109/TKDE.2018.2872061
   Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335
   Zhan K, 2018, IEEE T CYBERNETICS, V48, P2887, DOI 10.1109/TCYB.2017.2751646
   Zhang C., IEEE T PATTERN ANAL
   Zhang C, 2017, IEEE C COMP VIS PATT, P1063
   Zhang D., 2015, ELECT SCI TECHNOLOGY
   Zhang ZY, 2020, IEEE T SYST MAN CY-S, V50, P3072, DOI 10.1109/TSMC.2018.2840091
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 77
TC 12
Z9 12
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22927
EP 22949
DI 10.1007/s11042-020-08736-6
EA MAR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000521018900006
DA 2024-07-18
ER

PT J
AU Lin, FM
   Wu, Q
   Liu, J
   Wang, DW
   Kong, XM
AF Lin, Fengming
   Wu, Qiang
   Liu, Ju
   Wang, Dawei
   Kong, Xiangmao
TI Path aggregation U-Net model for brain tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Brain tumor; Segmentation; Path aggregation U-Net;
   Multimodal MRI; Deep learning
AB The deep neural network has been widely used in semantic segmentation, especially in tumor image segmentation. The segmentation performance of traditional methods cannot meet the high standard of clinical application. In this paper, we propose a new neural network model called path aggregation U-Net (PAU-Net) model for brain tumor segmentation with multi-modality magnetic resonance imaging (MRI). Specifically, we shorten the distance between output layers and deep features by bottom-up path aggregation encoder (PA), reducing the introduction of noises. We present the enhanced decoder (ED) to reserve more intact information. The efficient feature pyramid (EFP) is used to improve mask prediction further, using fewer resources to complete the feature pyramid effect. Finally, experiments in BraTS2017 and BraTS2018 datasets are performed. The results show that the proposed method outperforms state-of-the-art methods.
C1 [Lin, Fengming; Wu, Qiang; Liu, Ju; Kong, Xiangmao] Shandong Univ, Sch Informat Sci & Engn, Qingdao, Peoples R China.
   [Lin, Fengming; Wu, Qiang; Liu, Ju; Kong, Xiangmao] Shandong Univ, Inst Brain & Brain Inspired Sci, Qingdao, Peoples R China.
   [Wang, Dawei] Shandong Univ, Qilu Hosp, Dept Radiol, Jinan, Peoples R China.
C3 Shandong University; Shandong University; Shandong University
RP Wu, Q (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Qingdao, Peoples R China.; Wu, Q (corresponding author), Shandong Univ, Inst Brain & Brain Inspired Sci, Qingdao, Peoples R China.
EM wuqiang@sdu.edu.cn
RI Wu, Qiang/AAT-5023-2021; Lin, Fengming/KBC-9009-2024
OI Wu, Qiang/0000-0001-9339-0762; 
FU Fundamental Research Funds of Shandong University [2017JC013]; Shandong
   Province Key Innovation Project [2017CXGC1504, 2017CXGC1502]; Natural
   Science Fundation of Shandong Province [ZR2019MH049]
FX The work is supported by the Fundamental Research Funds of Shandong
   University (Grant No. 2017JC013), the Shandong Province Key Innovation
   Project (Grant No. 2017CXGC1504, 2017CXGC1502) and the Natural Science
   Fundation of Shandong Province (Grant No. ZR2019MH049).
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Alexaki V. I., 2017, MOL PSYCHIATR, V167, P1
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Fan JF, 2019, MED IMAGE ANAL, V54, P193, DOI 10.1016/j.media.2019.03.006
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   KIM G, 2017, INT MICCAI BRATS CHA, P154
   Kong XM, 2018, IFIP ADV INF COMM TE, V538, P346, DOI 10.1007/978-3-030-00828-4_35
   Lin FM, 2019, PROC INT C TOOLS ART, P555, DOI 10.1109/ICTAI.2019.00083
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu K, 2018, IEEE ACCESS, V6, P23722, DOI 10.1109/ACCESS.2018.2817593
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaikh M, 2018, LECT NOTES COMPUT SC, V10670, P309, DOI 10.1007/978-3-319-75238-9_27
   Shen HC, 2017, IEEE IMAGE PROC, P3864, DOI 10.1109/ICIP.2017.8297006
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Zhang X, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/abc902
   Zhang Y, 2019, PATTERN RECOGN, V88, P421, DOI 10.1016/j.patcog.2018.12.001
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhou T, 2020, IEEE T MED IMAGING
   Zhou T, 2019, HUM BRAIN MAPP, V40, P1001, DOI 10.1002/hbm.24428
NR 30
TC 25
Z9 28
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22951
EP 22964
DI 10.1007/s11042-020-08795-9
EA MAR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000521018900004
DA 2024-07-18
ER

PT J
AU Kanwal, M
   Riaz, MM
   Ali, SS
   Ghafoor, A
AF Kanwal, Maria
   Riaz, M. Mohsin
   Ali, Syed Sohaib
   Ghafoor, Abdul
TI Image attention retargeting using defocus map and bilateral filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency; ROI; Bilateral filter; HSV color space
ID SALIENCY DETECTION; MODEL
AB In this paper a method is proposed to enhance the saliency of selected region with respect to its surrounding to improve user's attention. Bilateral filter is first used to make the ROI smoother to reduce the unwanted details in the defocus map. Hue component of ROI is adjusted and the outline is extracted using neighbouring data. The outline in resultant image is modified using hue component to direct viewer's attention in a certain region. The proposed method is applied on different natural images and the results are compared with the state-of-the-art existing methods to prove the proposed method's effectiveness.
C1 [Kanwal, Maria; Ghafoor, Abdul] NUST, Islamabad, Pakistan.
   [Riaz, M. Mohsin; Ali, Syed Sohaib] COMSATS Univ, CAST, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Ghafoor, A (corresponding author), NUST, Islamabad, Pakistan.
EM maria.phd@students.mcs.edu.pk; mohsin.riaz@comsats.edu.pk;
   sohaib.ali@comsats.edu.pk; abdulghafoor-mcs@nust.edu.pk
RI Kanwal, Maria/AAA-4190-2022
OI Syed, Sohaib Ali/0000-0003-4795-7275; Kanwal, Maria/0000-0002-0504-0488
CR Abkenar MR, 2016, IEEE INT SYMP CIRC S, P2719, DOI 10.1109/ISCAS.2016.7539154
   Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2014, P 1 INTERNATIONALWOR, DOI DOI 10.1145/2662996.2663009
   Ayadi W, 2009, IEEE IMAGE PROC, P1001, DOI 10.1109/ICIP.2009.5413814
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Khojasteh SC, 2011, DRUG METABOLISM AND PHARMACOKINETICS QUICK GUIDE, P73, DOI 10.1007/978-1-4419-5629-3_5
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Mechrez R, 2018, IEEE WINT CONF APPL, P1368, DOI 10.1109/WACV.2018.00154
   Nguyen TV, 2013, IEEE T MULTIMEDIA, V15, P1910, DOI 10.1109/TMM.2013.2272919
   Pal R, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P337, DOI 10.1109/CRV.2017.33
   Pan WW, 2015, ADV INTEL SYS RES, V126, P1613
   Peng LK, 2013, PROCEEDINGS 2013 INTERNATIONAL CONFERENCE ON MECHATRONIC SCIENCES, ELECTRIC ENGINEERING AND COMPUTER (MEC), P796, DOI 10.1109/MEC.2013.6885168
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Sakiyama Tadao, 2011, Science Report of the Yokosuka City Museum, P43
   Shafieyan F, 2017, SIGNAL PROCESS-IMAGE, V50, P34, DOI 10.1016/j.image.2016.10.006
   Takimoto H, 2017, SPRINGER COMMUNICATI, P383
   Takimoto H, 2015, IEICE T INF SYST, VE98D, P1967, DOI 10.1587/transinf.2015EDP7087
   Tang RD, 2015, ACSR ADV COMPUT, V18, P663
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Waldin N, 2017, COMPUT GRAPH FORUM, V36, P467, DOI 10.1111/cgf.13141
   Xiao XL, 2019, IEEE T IMAGE PROCESS, V28, P2126, DOI 10.1109/TIP.2018.2882156
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang LX, 2017, SOFT COMPUT, V21, P447, DOI 10.1007/s00500-015-1795-1
   Zhao HD, 2015, MULTIMEDIA SYST, V21, P159, DOI 10.1007/s00530-014-0373-1
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 37
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19063
EP 19073
DI 10.1007/s11042-020-08813-w
EA MAR 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520640600001
DA 2024-07-18
ER

PT J
AU Song, HJ
   Tian, LH
   Li, C
AF Song, Hanjian
   Tian, Lihua
   Li, Chen
TI Action temporal detection method based on confidence curve analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal detection; Proposed segment; Confidence curve
AB Action temporal detection is a derivative task of action recognition which needs researchers to predict temporal intervals and specific categories in untrimmed videos. Aiming at the problem of too many proposed segments and insufficient filtering effect in multi-stage networks, we propose an action temporal detection method using confidence curve analysis to generate proposal segments. Fixed step window sliding is adopted to generate candidate segments in a video, and we adjust a training mode in segment network. The proposal segments are generated by analyzing the confidence curve of candidate segments, finally proposal segments are input into localization network to classify and adjust confidence level. Extensive experiments performed on THUMOS2014 benchmark show that the proposed method performs significantly better than the original muti-stage convolutional network that mAP increase from 19.0% to 26.4% with 252% accelerating.
C1 [Song, Hanjian; Tian, Lihua; Li, Chen] Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Tian, LH (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Peoples R China.
EM lhtian@mail.xjtu.edu.cn
RI Tian, li/HQY-8623-2023
FU National Natural Science Foundation of China [61901356]; HPC Platform of
   Xi'an Jiaotong University
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61901356 and the HPC Platform of Xi'an Jiaotong
   University.
CR [Anonymous], 2013, P IEEE COMP SOC C CO
   Chauhan JS, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P222, DOI 10.1109/CRV.2018.00039
   Cuzzolin F, 2016, CVPR ACTIVITYNET WOR
   Dai XY, 2017, IEEE I CONF COMP VIS, P5727, DOI 10.1109/ICCV.2017.610
   Diba A, 2018, LECT NOTES COMPUT SC, V11208, P299, DOI 10.1007/978-3-030-01225-0_18
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Guo DS, 2018, IEEE T MULTIMEDIA, V20, P3428, DOI 10.1109/TMM.2018.2839534
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Jain M, 2015, IEEE I CONF COMP VIS, P4588, DOI 10.1109/ICCV.2015.521
   Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599
   Jiang CX, 2016, IEEE WCNC
   Jiyang G, 2017, CASCADED BOUNDARY RE
   Klaser A., 2010, IEEE EUROPEAN C COMP, V6553, P219
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Oneata D., 2014, The lear submission at thumos
   Puscas MM, 2015, IEEE I CONF COMP VIS, P1653, DOI 10.1109/ICCV.2015.193
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Shou Z, 2018, LECT NOTES COMPUT SC, V11220, P162, DOI 10.1007/978-3-030-01270-0_10
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang Limin., 2014, THUMOS14 Action Recognition Challenge
   Wu YC, 2018, IEEE ACCESS, V6, P31677, DOI 10.1109/ACCESS.2018.2842428
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Yuan ZH, 2017, PROC CVPR IEEE, P3215, DOI 10.1109/CVPR.2017.342
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
NR 33
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34471
EP 34488
DI 10.1007/s11042-020-08771-3
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000562593000001
DA 2024-07-18
ER

PT J
AU Cheng, L
   Jing, XY
   Zhu, XK
   Hu, CH
   Gao, GW
   Wu, SS
AF Cheng, Li
   Jing, Xiao-Yuan
   Zhu, Xiaoke
   Hu, Chang-Hui
   Gao, Guangwei
   Wu, Songsong
TI Local and global aligned spatiotemporal attention network for
   video-based person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video-based person re-identification; Local and global; Aligned;
   Spatiotemporal; Attention
AB Matching video clips of people across non-overlapping surveillance cameras (video-based person re-identification) is of significant importance in many real-world applications. In this paper, we address the video-based person re-identification by developing a Local and Global Aligned Spatiotemporal Attention (LGASA) network. Our LGASA network consists of five cascaded modules, including 3D convolutional layers, residual block, spatial transformer network (STN), multi-stream recurrent network and multiple-attention module. Specifically, the 3D convolutional layers are used to capture local short-term fast-varying motion information encoded in multiple adjacent original frames. The residual block is used to extract mid-level feature maps. STN is applied to align the mid-level feature maps. The multi-stream recurrent network is designed to exploit the useful local and global long-term temporal dependency from the aligned mid-level feature maps. The multiple-attention module is designed to aggregate feature vectors of the same body part (or global) from different frames within each video into a single vector according to their importance. Experimental results on three video pedestrian datasets verify the effectiveness of the proposed local and global aligned spatiotemporal attention network.
C1 [Cheng, Li; Jing, Xiao-Yuan; Zhu, Xiaoke] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Jing, Xiao-Yuan] Guangdong Univ Petrochem Technol, Sch Comp, Maoming, Peoples R China.
   [Jing, Xiao-Yuan; Hu, Chang-Hui; Gao, Guangwei] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing, Peoples R China.
   [Zhu, Xiaoke] Henan Univ, Sch Comp & Informat Engn, Kaifeng, Peoples R China.
   [Wu, Songsong] Nanjing Univ Posts & Telecommun, Inst Adv Technol, Nanjing, Peoples R China.
C3 Wuhan University; Guangdong University of Petrochemical Technology;
   Nanjing University of Posts & Telecommunications; Henan University;
   Nanjing University of Posts & Telecommunications
RP Cheng, L (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM cjackl@126.com; jingxy_2000@126.com
RI hu, changhui/F-9665-2012; Cheng, Liang/B-4557-2013; Zhang,
   Yunxuan/IXD-9283-2023
FU NSFC-Key Project [61933013]; NSFC-Key Project of General Technology
   Fundamental Research United Fund [U1736211]; Key Project of Natural
   Science Foundation of Hubei Province [2018CFA024]; Natural Science
   Foundation of Guangdong Province [2019A1515011076]; National Key
   Research and Development Program of China [2017YFB0202001]; National
   Nature Science Foundation of China [61672208]; Higher Education
   Institution Key Research Projects of Henan Province [19A520001]; Key
   Scientific and Technological Project of Henan Province [192102210277]
FX The authors would like to thank the editors and anonymous reviewers for
   their constructive comments and suggestions. This work was supported by
   the NSFC-Key Project under Grant No. 61933013, the NSFC-Key Project of
   General Technology Fundamental Research United Fund under Grant No.
   U1736211, the Key Project of Natural Science Foundation of Hubei
   Province under Grant No. 2018CFA024, the Natural Science Foundation of
   Guangdong Province under Grant No. 2019A1515011076, the National Key
   Research and Development Program of China under Grant No.2017YFB0202001,
   the National Nature Science Foundation of China under Grant No.
   61672208, the Higher Education Institution Key Research Projects of
   Henan Province, No. 19A520001, the Key Scientific and Technological
   Project of Henan Province, No.192102210277.
CR ALEXANDER H, 2017, ARXIV170307737
   Bazzani L., 2010, INT C PATT REC, P1413, DOI [DOI 10.1109/ICPR.2010.349, 10.1109/ICPR.2010.349]
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chen D, 2018, LECT NOTES COMPUT SC, V11164, P146, DOI 10.1007/978-3-030-00776-8_14
   CHEN L, 2017, IEEE C CVPR WORKSH, P478
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   CHUNG D, 2017, IEEE C ICCV
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEHGHAN A, 2015, PROC CVPR IEEE, P4091, DOI DOI 10.1109/CVPR.2015
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   FERGNANI F, 2016, IEEE C CVPR
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Girdhar R., 2017, NIPS, P33
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jefferson C, 2017, IEEE INT CONF FUZZY
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Khan FM, 2017, IEEE WINT CONF APPL, P605, DOI 10.1109/WACV.2017.73
   KINGMA DP, 2015, IEEE C ICLR
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li K, 2019, IEEE T NEUR NET LEAR, V30, P1896, DOI 10.1109/TNNLS.2018.2875429
   Li S, 2018, IEEE T PATTERN ANAL, V40, P2963, DOI 10.1109/TPAMI.2017.2764893
   Li S, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2155
   Li Y, 2014, INT SYMP DISTR COMPU, P34, DOI 10.1109/DCABES.2014.10
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Li ZH, 2018, AAAI CONF ARTIF INTE, P7081
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   McLaughlin N, 2019, IEEE T CIRC SYST VID, V29, P2613, DOI 10.1109/TCSVT.2017.2736599
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Mnih V, 2014, ADV NEUR IN, V27
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Ouyang W, 2017, CVPR, P5790, DOI DOI 10.1109/CVPR.2017.499
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Saha B, 2018, IEEE IMAGE PROC, P1663, DOI 10.1109/ICIP.2018.8451594
   SERGEY Z, 2016, ARXIV161203928
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C., 2017, AAAI, V4, P12
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Xie Y, 2015, IEEE SIGNAL PROC LET, V22, P1854, DOI 10.1109/LSP.2015.2440294
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yang H, 2019, PATTERN RECOGN, V85, P1, DOI 10.1016/j.patcog.2018.07.028
   Yang W, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/1954121
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang W., 2017, IEEE T INSTRUM MEAS, V99, P1, DOI [DOI 10.1109/TCSVT.2017.2718188, DOI 10.1109/TCSVT.2017.2718225]
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
   Zhu Xiaoke., 2016, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, P3552
NR 76
TC 3
Z9 3
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34489
EP 34512
DI 10.1007/s11042-020-08765-1
EA MAR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000518345200003
DA 2024-07-18
ER

PT J
AU Nie, WZ
   Yan, Y
   Song, D
   Wang, K
AF Nie, Weizhi
   Yan, Yan
   Song, Dan
   Wang, Kun
TI Multi-modal feature fusion based on multi-layers LSTM for video emotion
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Feature fusion; LSTM; Multi-modal
AB Emotion is a key element in video data. However, it is difficult to understand the emotions conveyed in such videos due to the sparsity of video frames expressing emotion. Meanwhile, some approaches proposed to consider utterances as independent entities and ignore the inter-dependencies and relations among the utterances in recent years. These approaches also ignore the key point of multi-modal feature fusion in the feature learning process. In order to handle this problem, in this paper, we propose an LSTM-based model that can fully consider the relations among the utterances and also handle the multi-modal feature fusion problem in the learning process. Finally, the experiments on some popular datasets demonstrate the effectiveness of our approach.
C1 [Nie, Weizhi; Yan, Yan; Song, Dan; Wang, Kun] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Song, D (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM dan.song@tju.edu.cn
RI Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [61872267, 61502337,
   61772359, 61472275]
FX This work was supported in part by the National Natural Science
   Foundation of China (61872267, 61502337, 61772359, 61472275).
CR [Anonymous], 2016, IEEE T AFFECTIVE COM
   [Anonymous], 2016, Proceedings of the 24th ACM international conference on Multimedia, DOI DOI 10.1145/2964284.2967196
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739
   Ekman P., 1970, California Mental Health Research Digest, V8, P151
   Eyben F, 2010, J MULTIMODAL USER IN, V3, P7, DOI 10.1007/s12193-009-0032-6
   Gao Z, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000164
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kahou SE, 2016, J MULTIMODAL USER IN, V10, P99, DOI 10.1007/s12193-015-0195-2
   Metallinou A, 2008, IEEE INT SYM MULTIM, P250, DOI 10.1109/ISM.2008.40
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Perez-Rosas V., 2013, P ANN M ASS COMP LIN, P973
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Poria S, 2016, IEEE IJCNN, P4465, DOI 10.1109/IJCNN.2016.7727784
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Wang HH, 2017, IEEE INT CON MULTI, P949, DOI 10.1109/ICME.2017.8019301
   Williams J, 2018, FIRST GRAND CHALLENGE AND WORKSHOP ON HUMAN MULTIMODAL LANGUAGE (CHALLENGE-HML), P11
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zhao SW, 2017, INT GEOL REV, V59, P1, DOI 10.1080/00206814.2016.1198994
   Zhao SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1319, DOI 10.1145/3240508.3240591
   Zhao SC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P369, DOI 10.1145/3123266.3130858
NR 23
TC 12
Z9 12
U1 13
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16205
EP 16214
DI 10.1007/s11042-020-08796-8
EA MAR 2020
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000560968200001
DA 2024-07-18
ER

PT J
AU Houtinezhad, M
   Ghaffary, HR
AF Houtinezhad, Maryam
   Ghaffary, Hamid Reza
TI Writer-independent signature verification based on feature extraction
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signature verification; Informative feature; Neighbor pixels; Local
   binary pattern; Feature extraction fusion (FEF)
ID IDENTIFICATION; SYSTEM; STATE
AB In this work, with the aim of separating the genuine and forgery samples of the signature, we developed an automatic handwritten signature verification (AH-SV) based on the informative feature. The large intra-class variation is an important challenge among specific writer samples in SV. Thus, the proposed method is focused on feature extraction fusion (FEF) to increase the accuracy and efficiency of the system. We use features such as extracting intersection points based on neighboring intersection pixels relative to the central pixel to achieve the most informative feature, which can be regarded as a model for estimating the transitional probabilities of the signature strokes. Discriminative features extraction for SV relies on the domain of graphology and texture description. Therefore, we extracted parametric features and local binary pattern (LBP) from the signature images, and then we applied fusion using canonical correlation analysis (CCA) to improve the discriminative features. Hence, the measurement of the proximity between genuine and forgery signatures can be computed by their corresponding feature vectors. We used MCYT, GPDS(synthetic) and CEDAR datasets, with the classification of writer-independent structure on k-nearest neighbour (K-NN) classifier. Moreover, in the experiment phase, we selected random number of samples in datasets. The experimental results show that the accuracy in the CEDAR dataset has achieved the best value. Also, the results of the average error rate, false acceptance rate, and false rejection rate criteria have improved compared to well-known methods.
C1 [Houtinezhad, Maryam; Ghaffary, Hamid Reza] Islamic Azad Univ, Dept Comp Engn, Ferdows Branch, Ferdows, Iran.
C3 Islamic Azad University
RP Ghaffary, HR (corresponding author), Islamic Azad Univ, Dept Comp Engn, Ferdows Branch, Ferdows, Iran.
EM m.houtinezhad@srbiau.ac.ir; hmghaffary@yahoo.com
RI ghaffary, hamid reza/AAP-3151-2021
OI ghaffary, hamid reza/0000-0003-0627-4080
CR Aho A, 2010, BIOFUELS-UK, V1, P261, DOI 10.4155/BFS.09.26
   Alaei A, 2017, IEEE T INF FOREN SEC, V12, P2360, DOI 10.1109/TIFS.2017.2707332
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], NEW DIRECTIONS INTEL
   [Anonymous], 5 INT C SIGN IM PROC
   [Anonymous], ADV INTELLIGENT SYST
   [Anonymous], P 1 INT C COMP VIS L
   [Anonymous], P 4 INT C SIGN IM PR
   [Anonymous], INT JOINT C BIOM
   [Anonymous], WRITER INDEPENDENT F
   [Anonymous], 2015, INT C NETWORKING ADV
   [Anonymous], 2011, DEEP LEARNING NETWOR
   [Anonymous], 2014, 22 INT C PATT REC
   [Anonymous], ONLINE SIGNATURE VER
   [Anonymous], ADV VISUAL COMPUTING
   [Anonymous], 2017, ARXIV171106597
   [Anonymous], 23 INT C IM VIS COMP
   [Anonymous], SOFT COMP PATT REC C
   Avola D, 2020, MULTIMED TOOLS APPL, V79, P4463, DOI 10.1007/s11042-019-7196-1
   Avola D, 2017, LECT NOTES COMPUT SC, V10484, P223, DOI 10.1007/978-3-319-68560-1_20
   Azmi AN, 2017, MULTIMED TOOLS APPL, V76, P15341, DOI 10.1007/s11042-016-3831-2
   Bharathi RK, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2063, DOI 10.1109/ICACCI.2013.6637499
   Bhattacharya I, 2013, PROC TECH, V10, P970, DOI 10.1016/j.protcy.2013.12.445
   Chandra S, 2017, MULTIMED TOOLS APPL, V76, P19139, DOI 10.1007/s11042-017-4531-2
   Chang F, 2004, COMPUT VIS IMAGE UND, V93, P206, DOI 10.1016/j.cviu.2003.09.002
   Dimauro G, 1997, INT J PATTERN RECOGN, V11, P827, DOI 10.1142/S0218001497000378
   Djeziri S, 1998, IEEE T IMAGE PROCESS, V7, P1425, DOI 10.1109/83.718483
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Eskander GS, 2013, IET BIOMETRICS, V2, P169, DOI 10.1049/iet-bmt.2013.0024
   Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981
   Ghandali S, 2008, IEEE INT SYMP SIGNAL, P315, DOI 10.1109/ISSPIT.2008.4775712
   Guerbai Y, 2015, PATTERN RECOGN, V48, P103, DOI 10.1016/j.patcog.2014.07.016
   Hafemann LG, 2017, PATTERN RECOGN, V70, P163, DOI 10.1016/j.patcog.2017.05.012
   Haghighat M, 2016, EXPERT SYST APPL, V47, P23, DOI 10.1016/j.eswa.2015.10.047
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Jan Z, 2015, ADV INTELL SYST, V353, P653, DOI 10.1007/978-3-319-16486-1_64
   Krzanowski Wojtek J, 2000, PRINCIPLES MULTIVARI
   Kumar MM, 2014, IET BIOMETRICS, V3, P347, DOI 10.1049/iet-bmt.2014.0024
   Kumar R, 2012, PATTERN RECOGN LETT, V33, P301, DOI 10.1016/j.patrec.2011.10.009
   Malik MI, 2013, PROC INT CONF DOC, P1477, DOI 10.1109/ICDAR.2013.220
   Nemmour Hassiba, 2011, 2011 International Conference on High Performance Computing & Simulation, P357
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal S, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P72, DOI 10.1109/DAS.2016.48
   Pal S, 2012, INT CONF INTELL SYST, P586, DOI 10.1109/ISDA.2012.6416603
   PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9
   Prince JL., 1996, Proc 1996 Image and Multidimensional Signal Processing Workshop, P30
   Radhika KS, 2015, PROCEDIA COMPUT SCI, V46, P1593, DOI 10.1016/j.procs.2015.02.089
   Rivard D, 2013, INT J DOC ANAL RECOG, V16, P83, DOI 10.1007/s10032-011-0180-6
   Ruiz-Del-Solar J, 2008, LECT NOTES COMPUT SC, V5197, P22, DOI 10.1007/978-3-540-85920-8_3
   Shah A.S., 2016, INT J SIGNAL PROCESS, V9, P205
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Shekar B. H., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P134, DOI 10.1109/ICRTIT.2011.5972461
   Soleimani A, 2016, PATTERN RECOGN LETT, V80, P84, DOI 10.1016/j.patrec.2016.05.023
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Vargas JF, 2011, PATTERN RECOGN, V44, P375, DOI 10.1016/j.patcog.2010.07.028
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16
   Yilmaz MB, 2016, INFORM FUSION, V32, P109, DOI 10.1016/j.inffus.2016.02.003
   Zalasinski M, 2018, STUD COMPUT INTELL, V738, P375, DOI 10.1007/978-3-319-67946-4_17
   Zois EN, 2016, PATTERN RECOGN, V54, P162, DOI 10.1016/j.patcog.2016.01.009
NR 63
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6759
EP 6779
DI 10.1007/s11042-019-08447-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900059
DA 2024-07-18
ER

PT J
AU Siddiqui, FJ
   Ashraf, H
   Ullah, A
AF Siddiqui, Faria Jan
   Ashraf, Humaira
   Ullah, Ata
TI Dual server based security system for multimedia Services in Next
   Generation Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IP multimedia subsystem (IMS); IDS; Voice over LTE (VoLTE); SIP; NGN
AB Next Generation Networks (NGN) provide multimedia services to a large set of users by maintaining concurrent sessions for multimedia services using IP multimedia sub-system (IMS). SIP protocol are used for building, keeping and detaching session with clients. The main problem is that intruders can launch SIP flooding attacks that cause a bottleneck at IMS entities. In this paper, we have presented a Dual Server based Intrusion Detection and Prevention System (DS-IDPS) to guard against INVITE flooding attack. We have proposed two-level security for VoLTE environment by involving two servers titled helper and main servers to handle spoofing and attack detection respectively. We have defined three thresholds at main server by utilizing CUSUM algorithm to generate alarms by detecting intrusion. By attaching DS-IDPS at the middle of client and server, our system filters every request. We have developed a test bed using OpenIMS to develop IMS entities and launch attacks by malicious nodes and detect the intrusion in the system. It reduces CPU load and memory stack from P--CSCF. Results prove that DS-IDPS produces lesser false alarms and detect more number of malicious or bogus requests. Our proposed approach dominates as compared to preliminaries in terms of memory utilization, response time, malicious requests recognition ratios and CPU load consumption.
C1 [Siddiqui, Faria Jan; Ashraf, Humaira] IIUI, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Ullah, Ata] Natl Univ Modern Languages, Dept Comp Sci, Islamabad, Pakistan.
RP Ullah, A (corresponding author), Natl Univ Modern Languages, Dept Comp Sci, Islamabad, Pakistan.
EM faria.sipy@yahoo.com; humairaashraf12@yahoo.com; aullah@numl.edu.pk
RI Ullah, Ata/ABE-6416-2022; Ashraf, Humaira/KMY-4554-2024; Ullah,
   Ata/R-1141-2019
OI Ashraf, Humaira/0000-0001-5067-3172; Ullah, Ata/0000-0003-3603-1709
CR [Anonymous], 2016, PROC IEEE GLOB COMMU
   [Anonymous], 3 INT C COMP CONTR C
   [Anonymous], INT SCI C ENG RUR DE
   [Anonymous], 6 JOINT IFIP WIR MOB
   [Anonymous], 2012, INT J MATH COMPUT SI
   [Anonymous], 19 INT C COMM 19 INT
   [Anonymous], INT C INF COMM TECHN
   [Anonymous], BONFRING INT J RES C
   [Anonymous], 2013, SMARTCR, DOI DOI 10.6029/SMARTCR.2013.01.001
   [Anonymous], INT J COMPUTER SCI T
   Asgharian Z., 2011, 2011 International Symposium on Computer Networks and Distributed Systems (CNDS), P100, DOI 10.1109/CNDS.2011.5764552
   Ashraf H, 2016, J INTERNET TECHNOL, V17, P839, DOI 10.6138/JIT.2016.17.4.20160501e
   Azad MA, 2018, COMPUT SECUR, V77, P1, DOI 10.1016/j.cose.2018.03.005
   Bansal A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P391, DOI 10.1109/CICT.2015.66
   Borkar S, 2016, 2016 International Conference on Internet of Things and Applications (IOTA), P443, DOI 10.1109/IOTA.2016.7562769
   Chen E., 2010, IEEE International Workshop Technical Committee on Communications Quality and Reliability (CQR), Vancouver, BC, P1, DOI DOI 10.1017/S1461145710001422
   Dassouki K, 2016, INT WIREL COMMUN, P588, DOI 10.1109/IWCMC.2016.7577123
   Hosseinpour M, 2016, 2016 6TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P274, DOI 10.1109/ICCKE.2016.7802152
   Jin T., 2011, INT C COMMUNICATIONS, P1
   Khan J.A., 2016, Int. J. Sci. Res. Sci., V2, P202, DOI DOI 10.32628/IJSRSET162561
   Knieps G, 2019, TELECOMMUN POLICY, V43, P171, DOI 10.1016/j.telpol.2018.09.002
   Kurt B, 2018, DIGIT SIGNAL PROCESS, V77, P48, DOI 10.1016/j.dsp.2017.10.009
   Lichtman M, 2016, IEEE COMMUN MAG, V54, P54, DOI 10.1109/MCOM.2016.7452266
   Majed Najmeddine, 2017, 2017 International Conference on Computing, Networking and Communications (ICNC), P643, DOI 10.1109/ICCNC.2017.7876205
   Manjur K, 2017, NEURAL COMPUT APPL, P1
   Manunza L, 2017, J NETW COMPUT APPL, V80, P22, DOI 10.1016/j.jnca.2016.12.018
   Mavoungou S, 2016, IEEE ACCESS, V4, P4543, DOI 10.1109/ACCESS.2016.2601009
   Muhammad S, 2006, ICON: 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORKS, VOLS 1 AND 2, PROCEEDINGS, P300
   Nassar M., 2007, Principles, Systems andApplications of IP Telecommunications (IPTComm 2007), P1
   Nina K, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON ADVANCED TRENDS IN RADIOELECTRONICS, TELECOMMUNICATIONS AND COMPUTER ENGINEERING (TCSET), P1055, DOI 10.1109/TCSET.2018.8336376
   Patani N., 2017, International Journal of Computational Intelligence Research, V13, P101
   Rafique M. Z., 2011, Proceedings of the 2011 Eighth International Conference on Information Technology: New Generations (ITNG), P559, DOI 10.1109/ITNG.2011.102
   Raguenet I, 2008, PROCEEDINGS OF THE IFIP TC 11/ 23RD INTERNATIONAL INFORMATION SECURITY CONFERENCE, P237
   Saadon G, 2019, COMPUT STAND INTER, V62, P17, DOI 10.1016/j.csi.2018.07.003
   Safoine R, 2018, INT CONF MULTIMED, P88
   Shoket H, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P878, DOI 10.1109/SPIN.2018.8474211
   Su MY, 2015, J NETW, V10, P77, DOI 10.4304/jnw.10.2.77-84
   Tabany MR, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0846-y
   Tóthfalusi T, 2018, TELECOMMUN SYST, V68, P393, DOI 10.1007/s11235-017-0400-6
   Umer MF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0180945
   Vrakas N, 2013, INT J INF SECUR, V12, P201, DOI 10.1007/s10207-012-0187-0
   Wan XY, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 1, P428, DOI 10.1109/WCINS.2010.5541813
   Zhiqiang Chen, 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P154, DOI 10.1109/ICCNC.2012.6167401
NR 43
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7299
EP 7318
DI 10.1007/s11042-019-08406-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100018
DA 2024-07-18
ER

PT J
AU Wang, L
   Ran, QW
   Ma, J
AF Wang, Ling
   Ran, Qiwen
   Ma, Jing
TI Double quantum color images encryption scheme based on DQRCI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DQRCI; Double quantum images encryption; Quantum computation; Validity
   verification
ID FOURIER-TRANSFORM; REPRESENTATION; ALGORITHM; SYSTEM
AB In this paper, a double quantum color images representation model (DQRCI) which can store two color digital images simultaneously into a quantum superposition state is investigated. Based on DQRCI, some simple image processing operations are discussed and the corresponding quantum circuits are designed. The circuits indicate that these operations have very low computational complexity. Moreover, to ensure the security of DQRCI quantum state image, an encryption scheme is proposed and the validity verification of image encryption system in quantum field is given for the first time. Numerical simulation and performance comparison demonstrate that the proposed double quantum color images encryption scheme outperforms the previous pertinent work in terms of security and computational complexity. This work will help the researchers to further investigate more efficient quantum image representation model and corresponding encryption algorithm.
C1 [Wang, Ling; Ran, Qiwen; Ma, Jing] Harbin Inst Technol, Natl Key Lab Tunable Laser Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, L (corresponding author), Harbin Inst Technol, Natl Key Lab Tunable Laser Technol, Harbin 150001, Peoples R China.
EM wangling199059@163.com
OI Wang, Ling/0000-0002-4846-5160
CR FEYNMAN RP, 1982, INT J THEOR PHYS, V21, P467, DOI 10.1007/BF02650179
   Fijany A., 1998, Quantum Wavelet Transforms: Fast Algorithms and Complete Circuits
   Gong LH, 2016, INT J THEOR PHYS, V55, P3234, DOI 10.1007/s10773-016-2954-6
   Grassi G, 2009, CHAOS SOLITON FRACT, V41, P284, DOI 10.1016/j.chaos.2007.12.003
   Grover L. K., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P212, DOI 10.1145/237814.237866
   Hua TX, 2015, INT J THEOR PHYS, V54, P526, DOI 10.1007/s10773-014-2245-z
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P4001, DOI 10.1007/s11128-015-1099-5
   Latorre J I, 2005, Image compression and entanglement
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Li PC, 2017, INT J THEOR PHYS, V56, P1961, DOI 10.1007/s10773-017-3341-7
   Liang HR, 2016, QUANTUM INF PROCESS, V15, P2701, DOI 10.1007/s11128-016-1304-1
   Liu K, 2018, INT J THEOR PHYS, V57, P2938, DOI 10.1007/s10773-018-3813-4
   Liu XB, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110867
   Nielsen M. A., 2000, Quantum Computation and Quantum Information
   Ran QW, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1958-y
   Sang JZ, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-016-1463-0
   Sang JZ, 2016, INT J THEOR PHYS, V55, P3706, DOI 10.1007/s10773-016-3000-4
   SHOR PW, 1994, AN S FDN CO, P124
   Smolin JA, 1996, PHYS REV A, V53, P2855, DOI 10.1103/PhysRevA.53.2855
   Sun B, 2013, J ADV COMPUT INTELL, V17, P404, DOI 10.20965/jaciii.2013.p0404
   Tan RC, 2016, INT J THEOR PHYS, V55, P5368, DOI 10.1007/s10773-016-3157-x
   Vedral V, 1996, PHYS REV A, V54, P147, DOI 10.1103/PhysRevA.54.147
   Venegas-Andraca SE, 2010, QUANTUM INF PROCESS, V9, P1, DOI 10.1007/s11128-009-0123-z
   Venegas-Andraca SE, 2003, PROC SPIE, V5105, P137, DOI 10.1117/12.485960
   Wang J, 2019, INT J THEOR PHYS, V58, P308, DOI 10.1007/s10773-018-3932-y
   Wang L, 2019, OPT COMMUN, V438, P147, DOI 10.1016/j.optcom.2019.01.015
   Yan F, 2017, INT J QUANTUM INF, V15, DOI 10.1142/S0219749917300017
   Yan F, 2014, ENTROPY-SWITZ, V16, P5290, DOI 10.3390/e16105290
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Yang YG, 2015, SCI REP-UK, V5, DOI 10.1038/srep07784
   Yang YG, 2014, INFORM SCIENCES, V277, P445, DOI 10.1016/j.ins.2014.02.124
   Yang YG, 2013, QUANTUM INF PROCESS, V12, P3477, DOI 10.1007/s11128-013-0612-y
   Yap WS, 2016, J VIS COMMUN IMAGE R, V40, P51, DOI 10.1016/j.jvcir.2016.06.005
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P3103, DOI 10.1007/s11128-013-0587-8
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhou RG, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1640-9
   Zhou RG, 2013, INT J THEOR PHYS, V52, P1802, DOI 10.1007/s10773-012-1274-8
NR 39
TC 27
Z9 28
U1 3
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6661
EP 6687
DI 10.1007/s11042-019-08514-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900055
DA 2024-07-18
ER

PT J
AU Sorkhi, AG
   Hassanpour, H
   Fateh, M
AF Sorkhi, Ali Ghanbari
   Hassanpour, Hamid
   Fateh, Mansoor
TI A comprehensive system for image scene classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene classification; Semantic feature; Latent topic; Fully
   convolutional; Two-class SVM-fuzzy; Latent topics
AB In recent years, image scene classification based on low/high-level features has been considered as one of the most important and challenging problems faced in image processing research. The high-level features based on semantic concepts present a more accurate and closer model to the human perception of the image scene content. This paper presents a new multi-stage approach for image scene classification based on high-level semantic features extracted from image content. In the first stage, the object boundaries and their labels that represent the content are extracted. For this purpose, a combined method of a fully convolutional deep network and a combined network of a two-class SVM-fuzzy and SVR are used. Topic modeling is used to represent the latent relationships between the objects. Hence in the second stage, a new combination of methods consisting of the bag of visual words, and supervised document neural autoregressive distribution estimator is used to extract the latent topics (topic modeling) in the image. Finally, classification based on Bayesian method is performed according to the extracted features of the deep network, objects labels and the latent topics in the image. The proposed method has been evaluated on three datasets: Scene15, UIUC Sports, and MIT-67 Indoor. The experimental results show that the proposed approach achieves average performance improvement of 12%, 11% and 14% in the accuracy of object detection, and 0.5%, 0.6% and 1.8% in the mean average precision criteria of the image scene classification, compared to the previous state-of-the-art methods on these three datasets.
C1 [Sorkhi, Ali Ghanbari; Hassanpour, Hamid; Fateh, Mansoor] Shahrood Univ Technol, Fac Comp Engn, Shahrud, Iran.
C3 Shahrood University of Technology
RP Sorkhi, AG (corresponding author), Shahrood Univ Technol, Fac Comp Engn, Shahrud, Iran.
EM ali.ghanbari@shahroodut.ac.ir; h.hassanpour@shahroodut.ac.ir;
   mansoor_fateh@shahroodut.ac.ir
RI Ghanbari sorkhi, Ali/ABE-5079-2021; Hassanpour, Hamid/AAL-7271-2020
OI Ghanbari sorkhi, Ali/0000-0001-7064-5857; Hassanpour,
   Hamid/0000-0002-5513-9822
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], ARXIV150408083
   [Anonymous], ARXIV170205659
   [Anonymous], 2013, NIPS
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   CZARNECKI WM, 2015, JOINT EUR C MACH LEA, P52
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dixit M, 2015, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2015.7298916
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.Y., ARXIV170106659
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   GUILLAUMIN M, 2010, PROC CVPR IEEE, P902, DOI DOI 10.1109/CVPR.2010.5540120
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isa D, 2008, IEEE T KNOWL DATA EN, V20, P1264, DOI 10.1109/TKDE.2008.76
   Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524
   Jiang YN, 2012, LECT NOTES COMPUT SC, V7573, P730, DOI 10.1007/978-3-642-33709-3_52
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   KELLER JM, 1985, IEEE T PATTERN ANAL, V7, P693, DOI 10.1109/TPAMI.1985.4767725
   Khan SH, 2016, IEEE T IMAGE PROCESS, V25, P3372, DOI 10.1109/TIP.2016.2567076
   Kwitt R, 2012, LECT NOTES COMPUT SC, V7575, P359
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LENC K, ARXIV150606981
   Li L, 2010, AAAI CONF ARTIF INTE, P1377
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Li LB, 2010, MATER SCI FORUM, V658, P1, DOI 10.4028/www.scientific.net/MSF.658.1
   Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115
   LI Y, ARXIV190101892
   Lin D, 2014, PROC CVPR IEEE, P3726, DOI 10.1109/CVPR.2014.476
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XL, 2019, WORLD WIDE WEB, V22, P423, DOI 10.1007/s11280-018-0600-3
   Margolin R, 2014, LECT NOTES COMPUT SC, V8695, P377, DOI 10.1007/978-3-319-10584-0_25
   Mesnil G, 2015, ADV INTELL SYST, V318, P209, DOI 10.1007/978-3-319-12610-4_13
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383
   Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   PUTTHIVIDHYA D, 2010, PROC CVPR IEEE, P3408, DOI DOI 10.1109/CVPR.2010.5540000
   Qi XB, 2016, NEUROCOMPUTING, V171, P1230, DOI 10.1016/j.neucom.2015.07.071
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Redmon Joseph., YOLO9000: Better, faster, stronger
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sadeghi F, 2012, LECT NOTES COMPUT SC, V7576, P228, DOI 10.1007/978-3-642-33715-4_17
   Shabou A, 2012, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2012.6248107
   Sharma A, 2012, WOODHEAD PUBL FOOD S, P73
   Shi N, 2010, 2010 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY AND SECURITY INFORMATICS (IITSI 2010), P63, DOI 10.1109/IITSI.2010.74
   Shikun Chen, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P2359, DOI 10.1109/TCSVT.2017.2703946
   SOCHER R, 2010, PROC CVPR IEEE, P966, DOI DOI 10.1109/CVPR.2010.5540112
   Srivastava N., 2013, NIPS, P2094
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun C, 2016, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2016.379
   Sun J, 2013, IEEE I CONF COMP VIS, P3400, DOI 10.1109/ICCV.2013.422
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A., 2010, Proceedings of the international conference on Multimedia - MM'10, P1469
   Wang DZ, 2019, NEUROCOMPUTING, V329, P103, DOI 10.1016/j.neucom.2018.09.042
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang HW, 2009, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING MANAGEMENT, P124
   Wu JX, 2009, IEEE I CONF COMP VIS, P630, DOI 10.1109/ICCV.2009.5459178
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152
   Yen SJ, 2013, INFORM SCIENCES, V224, P77, DOI 10.1016/j.ins.2012.10.014
   Yuan JS, 2011, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2011.5995476
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zheng YC, 2012, PROCEEDINGS OF THE 7TH EURO-ASIA CONFERENCE ON ENVIRONMENT AND CSR: TOURISM, MICE, HOSPITALITY MANAGEMENT AND EDUCATION SESSION, PT I, P172
   Zheng Y, 2016, IEEE T PATTERN ANAL, V38, P1056, DOI 10.1109/TPAMI.2015.2476802
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
   ZHU J, 2010, ADV NEURAL INFORM PR, P2586
NR 83
TC 12
Z9 12
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18033
EP 18058
DI 10.1007/s11042-019-08264-y
EA FEB 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516791000001
DA 2024-07-18
ER

PT J
AU Zhao, HL
AF Zhao, Hailei
TI An image segmentation approach on improved implicit surface model in
   straddle strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Implicit surface model; Straddle arbitrage; Image denoising; Image
   segmentation; Image processing
AB At present, some experts and scholars do not explicitly mention the static model in the analysis of the straddle strategy, which leads to the research results are not ideal. This paper unifies the static model and proposes a method to analyze the arbitrage opportunities in the bond market. At the same time, this paper combines image processing technology to analyze image method and improve image clarity. In addition, this paper uses the contrast method to carry out traditional static model analysis, combines the research requirements to improve the model, obtains the research data through network data collection, and constructs the model for experimental data analysis. Finally, the paper processes the model data through image processing to obtain identifiable statistical images. The research shows that the model proposed in this study has certain validity and can provide theoretical reference for subsequent related research.
C1 [Zhao, Hailei] Jiangnan Univ, Sch Business, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Zhao, HL (corresponding author), Jiangnan Univ, Sch Business, Wuxi 214122, Jiangsu, Peoples R China.
EM zhhl@jiangnan.edu.cn
CR Anand N, 2017, INDIAN J MED SPEC, V8, P3, DOI 10.1016/j.injms.2016.09.007
   Baptista FD, 2017, NEURAL COMPUT APPL, V28, P25, DOI 10.1007/s00521-015-2034-5
   Baruffa G, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0111-z
   Bibalan MH, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0148-z
   Cho KM, 2015, NEURAL COMPUT APPL, V26, P1297, DOI 10.1007/s00521-014-1804-9
   Cruchaga M, 2016, ARCH COMPUT METHOD E, V23, P139, DOI 10.1007/s11831-014-9138-4
   Fecarotta O, 2016, J HYDRAUL RES, V54, P332, DOI 10.1080/00221686.2016.1141804
   GUTUB A, 2020, MULTIMED TOOLS 0103
   Jin XL, 2015, MULTIMED TOOLS APPL, V74, P2743, DOI 10.1007/s11042-015-2458-z
   KARAASLAN F, 2016, NEURAL COMPUT APPL
   KIM H, 2018, MULTIMED TOOLS APPL
   Kylberg G, 2016, EURASIP J IMAGE VIDE, P1, DOI 10.1186/s13640-016-0117-6
   Liu B., 2017, P IEEE SENSORS, P1, DOI [DOI 10.1109/NDS.2017.8070634, DOI 10.1109/ICSENS.2017.8234272]
   Park TH, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0136-3
   SANNA G, 2016, TRANSBOUNDARY EMERGI
   SHABANI M, 2015, NEURAL COMPUT APPL
   Tejero-de-Pablos A, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0120-y
   Wang F, 2017, IEEE T SUSTAIN ENERG, V8, P249, DOI 10.1109/TSTE.2016.2596539
   Zhu Q, 2020, MULTIMED TOOLS APPL, V79, P33771, DOI 10.1007/s11042-019-08362-x
NR 19
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17991
EP 18003
DI 10.1007/s11042-020-08719-7
EA FEB 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000515925400002
DA 2024-07-18
ER

PT J
AU Li, HS
   Xue, F
   Xia, HY
AF Li, Hai-Sheng
   Xue, Fan
   Xia, Hai-ying
TI Style transfer for QR code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quick response code; Style transfer; Convolutional neural network
AB Due to fast scanning response and strong damage resistance, Quick Response (QR) code has been used widely in product tracking, item identification, time tracking, document management, and general marketing. The standard QR code consisting of black and white modules, has the following defects: the monotonous color pattern and the poor visual effect. To address these issues, we propose a style transfer method of QR code based on convolutional neural network. Next, we modify the convolutional neural network structure to be in line with the requirements of the style transfer of QR code, which can more preserve the content of the original image than the classic style transfer method. Furthermore, to increase the recognizability of the artistic style QR code, we modify the standard positioning point of the style transfer to generate the QR code. Experiments show that the proposed method has strong robustness.
C1 [Li, Hai-Sheng; Xue, Fan; Xia, Hai-ying] Guangxi Normal Univ, Coll Elect Engn, Guilin 541004, Guangxi, Peoples R China.
C3 Guangxi Normal University
RP Xue, F (corresponding author), Guangxi Normal Univ, Coll Elect Engn, Guilin 541004, Guangxi, Peoples R China.
EM lhs_ecjtu@126.com; 285575481@qq.com
RI Li, Hai-sheng/AAA-1150-2021; Li, Hai-sheng/L-4658-2017
FU National Natural Science Foundation of China [61762012, 61462026,
   61762014]; Science and Technology Project of Guangxi [2018JJA170083];
   Innovation Project of Guangxi Graduate Education Grant [JGY2019023,
   JGY2017018]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No.61762012, No.61462026, and No.61762014, the Science
   and Technology Project of Guangxi Grant No.2018JJA170083, Innovation
   Project of Guangxi Graduate Education Grant (No.JGY2019023 and
   No.JGY2017018).
CR Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding ZM, 2019, IEEE T PATTERN ANAL, V41, P2861, DOI 10.1109/TPAMI.2018.2867870
   Dumoulin V.., 2017, P INT C LEARN REPR I
   FALCON A, 2013, 40 GORGEOUS QR CODE
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li J.D., 2018, THESIS LANZHOU U, P1
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li JJ, 2016, NEUROCOMPUTING, V173, P501, DOI 10.1016/j.neucom.2015.06.041
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2008, 2008 CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-11, P203, DOI 10.1109/CCDC.2008.4597299
   Rosin P, 2012, IMAGE VIDEO BASED AR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wakahara T., 2011, Proceedings of the 2011 14th International Conference on Network-Based Information Systems (NBiS 2011), P484, DOI 10.1109/NBiS.2011.80
   Wang SJ, 2019, ANN AM ASSOC GEOGR, V109, P266, DOI 10.1080/24694452.2018.1484683
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu M, 2018, ARXIV180302280
   Yongtai Zhang, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P183, DOI 10.1007/978-3-319-14442-9_16
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 28
TC 6
Z9 8
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33839
EP 33852
DI 10.1007/s11042-019-08555-4
EA FEB 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000516511300004
DA 2024-07-18
ER

PT J
AU Liu, Y
   Zhang, JD
   Han, DQ
   Wu, PB
   Sun, YD
   Moon, YS
AF Liu, Yang
   Zhang, Jindong
   Han, Dongqi
   Wu, Peibin
   Sun, Yiding
   Moon, Young Shik
TI A multidimensional chaotic image encryption algorithm based on the
   region of interest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Histogram of oriented gradients; Region of interest; Support
   vector machine; Henon sequence; Unified chaotic sequence
ID SCHEME; COMPRESSION; SYSTEM; MAP; PERMUTATION
AB Most image encryption algorithms encrypt the whole image, but only part of the data is important in the image. In this paper, we propose a multidimensional chaotic image encryption algorithm based on the region of interest (ROI). The histogram of oriented gradients (HOG) feature extraction and support vector machine (SVM) are used to separate the region of interest from the whole image. Then, the region of interest pixels is messed up by using the improved Henon sequence, Joseph sequence and the region of interest pixels are diffused by using the unified chaotic sequence to hide the sensitive information in the image, so as to achieve the purpose of private protection. Furthermore, the improved logistic sequence is used to hide the edge information of the target image to achieve the tradeoff between the secrecy of information and the complexity of encryption. A series of analyses are carried out including key space analysis, key sensitivity analysis, statistical analysis, information entropy analysis, analysis of the fixed-point obscuration analysis, quality analysis and image decryption for our encryption algorithm. Through experiments and comparisons, the proposed algorithm has good performance in encrypting image and coping with various invasions. The image encryption algorithm based on ROI has a good performance of security, moreover through the main encryption of ROI can effectively shorten the encryption time, so as to achieve the compromise of security and computational complexity.
C1 [Liu, Yang; Zhang, Jindong; Han, Dongqi; Wu, Peibin; Sun, Yiding] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
   [Moon, Young Shik] Hanyang Univ, Coll Comp, Div Comp Sci, 1271 Sa 3 Dong, Ansan 426791, South Korea.
C3 Jilin University; Jilin University; Jilin University; Hanyang University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
EM zhangjindong_100@163.com
RI Han, Dongqi/M-8906-2016
OI Han, Dongqi/0000-0002-0807-5934
FU National Key Research and Development Program of China [2017YFB0102500];
   Natural Science Foundation of Jilin province [20170101133JC]; Korea
   Foundation for Advanced Studies' International Scholar Exchange
   Fellowship for the academic year of 2017-2018; Fundamental Research
   Funds for the Central Universities; Jilin University [5157050847,
   2017XYB252, 2017A53216]
FX This work is supported in part by the National Key Research and
   Development Program of China (2017YFB0102500), Natural Science
   Foundation of Jilin province (20170101133JC), the Korea Foundation for
   Advanced Studies' International Scholar Exchange Fellowship for the
   academic year of 2017-2018, the Fundamental Research Funds for the
   Central Universities, and Jilin University (5157050847, 2017XYB252,
   2017A53216).
CR Abuturab MR, 2017, OPT LASER ENG, V98, P1, DOI 10.1016/j.optlaseng.2017.05.001
   Anwar S, 2021, MULTIMED TOOLS APPL, V80, P9657, DOI 10.1007/s11042-020-09545-7
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bilal M, 2014, MULTIMED TOOLS APPL, V72, P1073, DOI 10.1007/s11042-013-1415-y
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Gong LH, 2013, J MOD OPTIC, V60, P1074, DOI 10.1080/09500340.2013.831139
   Gupta S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P726
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Jangid RK, 2014, 2014 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP)
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Lü JH, 2002, INT J BIFURCAT CHAOS, V12, P2917, DOI 10.1142/S021812740200631X
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Ochani A, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 1, P465
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Ratnavelu K, 2017, SIGNAL PROCESS, V140, P87, DOI 10.1016/j.sigpro.2017.05.002
   Shakir HR, 2019, MULTIMED TOOLS APPL, V78, P26073, DOI 10.1007/s11042-019-07766-z
   Suryanto Y, 2017, MULTIMED TOOLS APPL, V76, P16831, DOI 10.1007/s11042-016-3954-5
   Tian Y, 2017, AIP ADV, V7, DOI 10.1063/1.4994860
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang S, 2016, MULTIMED TOOLS APPL, V75, P17157, DOI 10.1007/s11042-015-2982-x
   Zhang Y, 2017, CHINESE J ELECTRON, V26, P1022, DOI 10.1049/cje.2017.08.022
   Zhou N.R., 2017, Quantum Inf. Process., V16
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
NR 35
TC 35
Z9 39
U1 4
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17669
EP 17705
DI 10.1007/s11042-020-08645-8
EA FEB 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516363300001
DA 2024-07-18
ER

PT J
AU Sarkar, D
   Palit, S
   Som, S
   Dey, KN
AF Sarkar, D.
   Palit, S.
   Som, S.
   Dey, K. N.
TI Large scale image tamper detection and restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tampering; Quadruple watermarking; Mapping block; Restoration; Wavelet
   coefficients
ID FRAGILE WATERMARKING; DIGITAL WATERMARKING; LOCALIZATION;
   AUTHENTICATION; SCHEME
AB Detection and restoration of greatly tampered images is an important albeit difficult problem. Two schemes for the detection of tampered areas in images and their restoration have been presented. One of them works in the spatial domain and implements a quadruple watermarking approach. A watermark is constructed from four different parts of the image such that a filtered version of the image intensities contained in each of these parts is embedded identically in four other regions of the image. These regions are decided by a mapping algorithm. The advantage of this approach is that even if three of the four regions are tampered, the watermark from the untampered region can be used to reconstruct the three tampered regions. The chief motivation behind the quadruple scheme is the restoration of an image which has suffered tampering on a really large scale, upto 75%. The other proposed algorithm uses wavelet decomposition, based on which, two different watermarks are embedded. These serve two different purposes, one being tamper detection, while the second is restoration of the tampered area. They are embedded in non-overlapping regions of the wavelet transformed image. This algorithm is designed to obtain very good quality restoration and works well for tampering less than 50% of the total image area. The performance of both these algorithms has been examined using images from the entire USC-SIPI database. Comparison has been made with a well known existing approach. The superiority of the proposed approaches is evident from the plots, figures and tables presented.
C1 [Sarkar, D.] Cognizant Technol Solut, Kolkata, India.
   [Palit, S.] Indian Stat Inst, Kolkata, India.
   [Som, S.] Barrackpore Rastraguru Surendranath Coll, Dept Comp Sci, 85 Middle Rd, Kolkata 700120, India.
   [Dey, K. N.] Dr Sudhir Chandra Sur Degree Engn Coll, 540 Dum Dum Rd, Kolkata 700074, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata; Dr.
   Sudhir Chandra Sur Degree Engineering College
RP Palit, S (corresponding author), Indian Stat Inst, Kolkata, India.
EM dipabali.sarkar@gmail.com; sarbanip@isical.ac.in;
   sukalyan.som@gmail.com; kndey55@gmail.com
FU Indian Statistical Institute
FX The authors would like to thank Indian Statistical Institute for
   providing funds for the work carried out for this article vide the
   Project Blind quality assessment of images, tamper detection and
   correction.
CR Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chuang JC, 2013, INT J SECUR APPL, V7, P209, DOI 10.14257/ijsia.2013.7.6.22
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Fridrich J., 1999, P IEEE INT C IM PROC, V3, P792, DOI DOI 10.1109/ICIP.1999.817228
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Hong WE, 2017, SIGNAL PROCESS-IMAGE, V58, P111, DOI 10.1016/j.image.2017.07.001
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Izquierdo E, 2003, IEEE T CIRC SYST VID, V13, P842, DOI 10.1109/TCSVT.2003.815961
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li KF, 2001, 2001 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING, VOLS I AND II, CONFERENCE PROCEEDINGS, P164, DOI 10.1109/PACRIM.2001.953548
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Liu L., 2018, XGANS IMAGE RECONSTR
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Sreenivas K, 2017, J VIS COMMUN IMAGE R, V49, P164, DOI 10.1016/j.jvcir.2017.09.001
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   USC-SIPI Image Database University of Southern California, USC SIPI IM DAT
   Vafaei Mohamad, 2013, TEXTROAD PUBLICATION, V3, P577
   Wang H-C, 2015, COMPUT SCI INF TECHN, V3, P127, DOI DOI 10.13189/csit.2015.030406
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Zhang JP, 2013, OPTIK, V124, P6367, DOI 10.1016/j.ijleo.2013.05.040
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 37
TC 13
Z9 13
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17761
EP 17791
DI 10.1007/s11042-020-08669-0
EA FEB 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516363300003
DA 2024-07-18
ER

PT J
AU Niu, PP
   Wang, XY
   Yang, HY
   Li, L
AF Niu, Pan-Pan
   Wang, Xiang-Yang
   Yang, Hong-Ying
   Li, Li
TI A blind watermark algorithm in SWT domain using bivariate generalized
   Gaussian distributions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Bivariate generalized Gaussian distribution;
   Adaptive nonlinear watermark embedding strength; Stationary wavelet
   transform; Local statistical properties
ID AUDIO; TRANSFORM; DECODER
AB Imperceptibility, robustness, and payload are three main requirements of any audio watermarking systems to guarantee desired functionalities, but there is a tradeoff among them from the information-theoretic perspective. Generally, in order to enhance the imperceptibility, robustness, and payload simultaneously, the human auditory system and the statistical properties of the audio signal should be fully taken into account. The statistical model based transform domain multiplicative watermarking scheme embodies the above ideas, and therefore the detection and extraction of the multiplicative watermarks have received a great deal of attention. Although much effort has been made in recent years, improving the ability of imperceptibility, watermark capacity, and robustness at the same time remains a challenge within the audio watermarking community. In this paper, we propose a blind audio watermark decoder in stationary wavelet transform domain based on bivariate generalized Gaussian distributions, wherein both the local statistical properties and inter-scale dependencies of the stationary wavelet transform coefficients of digital audio are taken into account, and also the adaptive nonlinear watermark embedding strength functions are designed. The results of our tests with different host audios, digital watermarks, and various attacks, we experimentally confirm that the proposed approach performs well compared to the state-of-the-art audio watermarking methods.
C1 [Niu, Pan-Pan; Wang, Xiang-Yang; Yang, Hong-Ying; Li, Li] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Niu, Pan-Pan] Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Niu, Pan-Pan] Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
C3 Liaoning Normal University
RP Niu, PP (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.; Niu, PP (corresponding author), Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.; Niu, PP (corresponding author), Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
EM Niupanpan3333@163.com
RI Yang, Jing/JFK-4046-2023; Niu, Panpan/Q-9953-2017
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61701212]; China
   Postdoctoral Science Foundation [2018T110220]; Key Scientific Research
   Project of Liaoning Provincial Department [LZ2019001]; Natural Science
   Foundation of Liaoning Province [2019-ZD-0468]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61472171 & 61701212, Project funded by China
   Postdoctoral Science Foundation No. 2018T110220, Key Scientific Research
   Project of Liaoning Provincial Department (LZ2019001), and Natural
   Science Foundation of Liaoning Province (2019-ZD-0468).
CR Abdulhussain SH, 2019, MULTIMED TOOLS APPL, V78, P20361, DOI 10.1007/s11042-019-7364-3
   Akhaee MA, 2015, MULTIMED TOOLS APPL, V74, P5995, DOI 10.1007/s11042-014-1904-7
   Akhaee MA, 2009, IEEE ICC, P678
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   [Anonymous], 2004, Proceedings of the 18th international congress on acoustics (ICA 2004)
   Barni M, 2003, IEEE T SIGNAL PROCES, V51, P1118, DOI 10.1109/TSP.2003.809371
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P4735, DOI 10.1007/s11042-015-2500-1
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Ellmauthaler A, 2013, IEEE T IMAGE PROCESS, V22, P1005, DOI 10.1109/TIP.2012.2226045
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   FISHER NI, 1985, BIOMETRIKA, V72, P253
   Hamdi D, 2017, P IEEE INT C DEV ES, P130
   Heittola T, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2014-9
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P26723, DOI 10.1007/s11042-016-4202-8
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Hwang MJ, 2018, IEEE T MULTIMEDIA, V20, P45, DOI 10.1109/TMM.2017.2721642
   Jalil M, 2013, 2013 INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ADVANCES IN ELECTRICAL, ELECTRONICS AND COMPUTER ENGINEERING (TAEECE), P208
   Mahmmod BM, 2019, IEEE ACCESS, V7, P103485, DOI 10.1109/ACCESS.2019.2929864
   Majoul T, 2011, INT CONF ACOUST SPEE, P353
   Pascal F, 2013, IEEE T SIGNAL PROCES, V61, P5960, DOI 10.1109/TSP.2013.2282909
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Shih Frank Y, 2017, Digital watermarking and steganography: fundamentals and techniques
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 27
TC 6
Z9 7
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13351
EP 13377
DI 10.1007/s11042-019-08504-1
EA JAN 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515728500004
DA 2024-07-18
ER

PT J
AU Gu, YB
   Tang, H
   Lv, TL
   Chen, Y
   Wang, ZP
   Zhang, L
   Yang, J
   Shu, HZ
   Luo, LM
   Coatrieux, G
AF Gu, Yunbo
   Tang, Hui
   Lv, Tianling
   Chen, Yang
   Wang, Zhiping
   Zhang, Lu
   Yang, Jian
   Shu, Huazhong
   Luo, Limin
   Coatrieux, Gouenou
TI Discriminative feature representation for Noisy image quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discriminative feature representation (DFR); Noise quantification;
   Dictionary; Blind image quality assessment (BIQA); Computed Tomography
   (CT)
ID NATURAL SCENE STATISTICS; SPARSE REPRESENTATION; DICTIONARIES;
   RECOGNITION; INFORMATION; CT
AB Blind image quality assessment (BIQA) is one of the most challenging and difficult tasks in the field of IQA. Given that sparse representation through dictionary learning can learn the image feature well, this paper proposed a method termed Discriminative Feature Representation (DFR) from the perspective of feature learning for noise contaminated image quality assessment. DFR makes use of two sub-dictionaries composed of atoms featuring desirable image structures and undesirable noise, respectively. Noise is quantified via a joint evaluation of the sparse coefficients related to the atoms in the two sub-dictionaries. The method is validated using public databases with different types of noise, a comparison with other up-to-date methods is provided. The proposed method is also applied to CT images acquired at different-level doses and reconstructed by various well-known algorithms.
C1 [Gu, Yunbo; Tang, Hui; Lv, Tianling; Chen, Yang; Wang, Zhiping; Shu, Huazhong; Luo, Limin] Southeast Univ, Sch Comp Sci & Engn, Lab Image Sci & Technol, Nanjing 210096, Jiangsu, Peoples R China.
   [Zhang, Lu] INSA Rennes, CNRS UMR 6164, IETR, 20 Ave Buttes Coesmes, F-35708 Rennes, France.
   [Yang, Jian] Beijing Inst Technol, Sch Optoelect, Beijing 100081, Peoples R China.
   [Coatrieux, Gouenou] Ctr Rech Informat Biomed Sino Francais, F-35042 Rennes, France.
C3 Southeast University - China; Institut National des Sciences Appliquees
   de Rennes; Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Engineering & Systems Sciences (INSIS); Universite de
   Rennes; Beijing Institute of Technology
RP Chen, Y (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Lab Image Sci & Technol, Nanjing 210096, Jiangsu, Peoples R China.
EM chenyang.list@seu.edu.cn
RI Tang, Hui/JCE-3040-2023; Gu, Yunbo/GYA-1184-2022
OI Tang, Hui/0000-0001-8448-6623; Gu, Yunbo/0000-0002-5623-6827; zhang,
   lu/0000-0002-8859-5453
FU National Key Research and Development Program of China [2018YFA0704102,
   2017YFA0104302, 2017YFC0109202, 2017YFC0107900]; National High
   Technology Research and Devlopment Program of China (863 Program)
   [2015AA043203]; National Natural Science Foundation [81827805, 61801003,
   61871117, 81530060]; Key Laboratory of Health Informatics, Chinese
   Academy of Sciences; Fundamental Research Funds for the Central
   Universities; Southeast University; Nanjing Medical University
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018YFA0704102, Grant
   2017YFA0104302, Grant 2017YFC0109202 and Grant 2017YFC0107900, in part
   by the National High Technology Research and Devlopment Program of China
   (863 Program), under Grant 2015AA043203, in part by the National Natural
   Science Foundation under Grant 81827805, Grant 61801003, Grant 61871117,
   and Grant 81530060, in part by the Key Laboratory of Health Informatics,
   Chinese Academy of Sciences, in part by the Fundamental Research Funds
   for the Central Universities, in part by the Joint Research Project of
   Southeast University and Nanjing Medical University.
CR Abdi H., 2007, Encyclopedia of measurement and statistics, P508, DOI DOI 10.4135/9781412952644.N239
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2009, Computed tomography: principles, design, artifacts, and recent advances
   Barrett JF, 2004, RADIOGRAPHICS, V24, P1679, DOI 10.1148/rg.246045065
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P37, DOI 10.1007/978-3-642-00296-0_5
   Berrington de González A, 2004, LANCET, V363, P345, DOI 10.1016/S0140-6736(04)15433-0
   Boedeker KL, 2007, PHYS MED BIOL, V52, P4027, DOI 10.1088/0031-9155/52/14/002
   Chang HW, 2013, IEEE T IMAGE PROCESS, V22, P4007, DOI 10.1109/TIP.2013.2266579
   Chang HW, 2011, SIGNAL PROCESS-IMAGE, V26, P577, DOI 10.1016/j.image.2011.07.003
   Channappayya SS, 2014, SIGNAL INFORM PROCES, P984
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430
   Deng C., 2019, IEEE T CYBERNETICS, P1
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Duda R., 1973, Pattern Classification and Scene Analysis
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Feng X., 2006, P SOC PHOTO-OPT INS, V6076, P74
   Gu J, 2018, IEEE T MULTIMEDIA, V20, P1140, DOI 10.1109/TMM.2017.2761993
   Guha T, 2014, SIGNAL PROCESS-IMAGE, V29, P1138, DOI 10.1016/j.image.2014.09.010
   Håkansson M, 2010, RADIAT PROT DOSIM, V139, P42, DOI 10.1093/rpd/ncq057
   He LH, 2012, PROC CVPR IEEE, P1146, DOI 10.1109/CVPR.2012.6247795
   Kalra MK, 2004, RADIOLOGY, V233, P649, DOI 10.1148/radiol.2333031150
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826
   Liu J, 2018, IEEE T CIRC SYST VID, V28, P1232, DOI 10.1109/TCSVT.2016.2643009
   Liu J, 2017, IEEE T MED IMAGING, V36, P2499, DOI 10.1109/TMI.2017.2739841
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Meesters L, 2002, SIGNAL PROCESS, V82, P369, DOI 10.1016/S0165-1684(01)00177-3
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Mittal A, 2012, IEEE SIGNAL PROC LET, V19, P75, DOI 10.1109/LSP.2011.2179293
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Priya K.V.S.N.L. Manasa, 2016, INT C SIGN PROC COMM, P1
   Rubinstein R, 2008, Tech. rep.
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sazzad ZMP, 2008, SIGNAL PROCESS-IMAGE, V23, P257, DOI 10.1016/j.image.2008.03.005
   Sheikh H.R., 2005, LIVE IMAGE QUALITY A, V2
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Tang HX, 2011, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2011.5995446
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Wen N, 2007, PHYS MED BIOL, V52, P2267, DOI 10.1088/0031-9155/52/8/015
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Ying X, 2019, IEEE T MED IMAGING, P1
   Zhang LF, 2018, IEEE T CYBERNETICS, V48, P16, DOI 10.1109/TCYB.2016.2605044
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhu X, 2009, INT WORK QUAL MULTIM, P64, DOI 10.1109/QOMEX.2009.5246976
NR 60
TC 2
Z9 2
U1 7
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7783
EP 7809
DI 10.1007/s11042-019-08424-0
EA JAN 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600001
DA 2024-07-18
ER

PT J
AU Chen, Z
   Liu, PZ
   Du, YZ
   Luo, YM
   Guo, JM
AF Chen, Zhi
   Liu, Peizhong
   Du, Yongzhao
   Luo, Yanmin
   Guo, Jing-Ming
TI Robust visual tracking using self-adaptive strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Discriminative correlation filter; Self-adaptive
   updating; Peak side-lobe ratio
ID OBJECT TRACKING
AB Discriminative correlation filter-based algorithms have recently demonstrated prominent advantages in the community of computer visual tracking, due to their ability to convert ridge regression problems in the frequency domain for creating solutions efficiently, which has attracted a great deal of attention and spurred new research. High precision and robustness have always been the goals of visual tracking. However, during the tracking process, target objects often encounter sophisticated scenarios such as fast motion and occlusion. During this period, erroneous tracking information will be generated and delivered to the next frame for updating; the information will seriously deteriorate the overall tracking model. To address the problem mentioned above, in this paper, we propose an accurate model self-adaptive update method based on a discriminative correlation filter framework. The proposed tracking method is achieved by utilizing the peak score of a response map generated by the discriminative correlation filter as a dynamic threshold with comparisons to its PSR (peak side-lobe ratio) scores, and then the comparative results are used as the differentiated condition for updating the translation filter and scale filter model. In addition, multiple hand-crafted features such as HOG (histogram of oriented gradient), CN (color names), and HOI (histogram of local intensities) are fused self-adaptively for comprehensive feature representation, which further improve tracking performance. We evaluate the performance of the proposed tracker on OTB benchmark datasets; the experimental results demonstrate that the proposed tracker performs favorably against most state-of-the-art discriminative correlation filter-based trackers including some methods follow deep learning paradigm, and the effectiveness of updating the model self-adaptive is verified.
C1 [Chen, Zhi; Liu, Peizhong; Du, Yongzhao] Huaqiao Univ, Coll Engn, Quanzhou, Fujian, Peoples R China.
   [Liu, Peizhong; Du, Yongzhao] Huaqiao Univ, Res Ctr Appl Stat & Big Data, 668 Jimei Ave, Xiamen 361021, Peoples R China.
   [Luo, Yanmin] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen, Fujian, Peoples R China.
   [Guo, Jing-Ming] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 Huaqiao University; Huaqiao University; Huaqiao University; National
   Taiwan University of Science & Technology
RP Liu, PZ (corresponding author), Huaqiao Univ, Coll Engn, Quanzhou, Fujian, Peoples R China.; Liu, PZ (corresponding author), Huaqiao Univ, Res Ctr Appl Stat & Big Data, 668 Jimei Ave, Xiamen 361021, Peoples R China.
EM marico2018@163.com; pzliu@hqu.edu.cn; yongzhaodu@126.com;
   lym@hqu.edu.cn; jmguo@seed.net.tw
OI Liu, Peizhong/0000-0001-8785-0195
FU National Natural Science Foundation, China [61605048, 61603144,
   61403245, 91648119]; Natural Science Foundation of Fujian Province,
   China [2015 J01256, 2016 J01300]; Talent project of Huaqiao University
   [14BS215]; Quanzhou scientific and technological planning projects of
   Fujian, China [2015Z120, 2017G024]; Subsidized Project for Postgraduates
   'Innovative Fund in Scientific Research of Huaqiao University
   [1611422001]
FX This work was supported by the grants from National Natural Science
   Foundation, China under Grant 61605048, and Grant 61603144, and Grant
   61403245 and Grant 91648119, in part by Natural Science Foundation of
   Fujian Province, China under Grant 2015 J01256, and Grant 2016 J01300,
   in part by the Talent project of Huaqiao University under Grant 14BS215,
   in part by Quanzhou scientific and technological planning projects of
   Fujian, China under Grant 2015Z120 and Grant 2017G024, and in part by
   the Subsidized Project for Postgraduates 'Innovative Fund in Scientific
   Research of Huaqiao University under Grant 1611422001.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cauwenberghs G, 2012, P ANN C NEUR INF PRO, P702
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Fan H, 2017, IEEE T CIRC SYST VID, V27, P1018, DOI 10.1109/TCSVT.2016.2515738
   GILBERT AL, 1980, IEEE T PATTERN ANAL, V2, P47, DOI 10.1109/TPAMI.1980.4766969
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Li Z, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2836221
   Li ZC, 2018, IEEE T NEUR NET LEAR, V29, P1947, DOI 10.1109/TNNLS.2017.2691725
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liu P, 2017, IEEE T IMAGE PROCESS, VPP, p99)
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Park IS, 2015, PROC IEEE MICR ELECT, P1059, DOI 10.1109/MEMSYS.2015.7051145
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Tu ZW, 2005, IEEE I CONF COMP VIS, P1589
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N, 2013, P ADV NEURAL INFORM
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhu Z, 2017, IEEE INT CONF COMP V, P1973, DOI 10.1109/ICCVW.2017.231
NR 48
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 141
EP 162
DI 10.1007/s11042-019-08069-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600007
DA 2024-07-18
ER

PT J
AU Mehallegue, N
   Loukhaoukha, K
   Zebbiche, K
   Refaey, A
   Djellab, M
AF Mehallegue, Noureddine
   Loukhaoukha, Khaled
   Zebbiche, Khalil
   Refaey, Ahmed
   Djellab, Mourad
TI Ambiguity attacks on SVD audio watermarking approach using chaotic
   encrypted images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Singular value decomposition; Ambiguity attack;
   False positive detection
ID SINGULAR-VALUE DECOMPOSITION; WAVELET TRANSFORM; SECURITY ANALYSES;
   SCHEME
AB In this paper, we study the robustness of the proposed watermarking algorithm by Al-Nuaimy et al. (Digit Signal Process 21(6):764-779 2011) for audio signals which is based on singular value decomposition (SVD). It has been concluded that it is fundamentally flawed in its design, in that it falls to two ambiguity attacks where the extracted watermark is not the embedded one but determined by the reference watermark. In the first attack, when a watermarked audio signal is rewatermarked by an attacker's watermark, this one can be easily extracted to claim ownership of the original audio signal. In the second attack, during the extracting process when an attacker uses the singular vectors of his watermark, he can extract the attacker's watermark. Therefore, he can claim ownership of the watermarked audio signal. The experimental results prove that the proposed attacks create a false positive detection in watermark extraction. Therefore, Al-Nuaimy et al. algorithm cannot be used for security systems, data hiding and copyright protection.
C1 [Mehallegue, Noureddine; Loukhaoukha, Khaled; Zebbiche, Khalil] Dev Res Ctr, Algiers, Algeria.
   [Mehallegue, Noureddine; Zebbiche, Khalil] Queens Univ, Sch Elect Elect Engn & Comp Sci, Belfast, Antrim, North Ireland.
   [Loukhaoukha, Khaled] Laval Univ, Dept Elect & Comp Engn, Quebec City, PQ, Canada.
   [Refaey, Ahmed] Manhattan Coll, Elect & Comp Engn Dept, Riverdale, NY USA.
   [Djellab, Mourad] Inst Natl Criminalist & Criminol INCC GN, Algiers, Algeria.
C3 Queens University Belfast; Laval University; Manhattan College
RP Loukhaoukha, K (corresponding author), Dev Res Ctr, Algiers, Algeria.
EM khaled.loukhaoukha.1@ulaval.ca
RI Loukhaoukha, Khaled/ABI-3136-2020
OI Loukhaoukha, Khaled/0000-0002-9000-4210; zebbiche,
   khalil/0000-0002-6926-8203
CR Abdallah HA, 2014, INFORM PROCESS MANAG, V50, P909, DOI 10.1016/j.ipm.2014.07.001
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Ali M, 2015, EXPERT SYST APPL, V42, P2392, DOI 10.1016/j.eswa.2014.10.045
   Attari AA, 2018, MULTIMED TOOLS APPL, V77, P25607, DOI 10.1007/s11042-018-5809-8
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Dogan S, 2011, ADV ENG SOFTW, V42, P336, DOI 10.1016/j.advengsoft.2011.02.012
   El-Gazar S, 2018, INT J SPEECH TECHNOL, V21, P953, DOI 10.1007/s10772-018-9531-8
   Fallahpour M, 2012, INT J INNOV COMPUT I, V8, P2477
   Gourrame K, 2019, MULTIMED TOOLS APPL, V78, P2621, DOI 10.1007/s11042-018-6302-0
   Guo JM, 2014, AEU-INT J ELECTRON C, V68, P816, DOI 10.1016/j.aeue.2014.03.008
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hannoun K, 2018, IFAC PAPERSONLINE, V51, P50, DOI 10.1016/j.ifacol.2018.12.089
   Lai CC, 2013, DIGIT SIGNAL PROCESS, V23, P1333, DOI 10.1016/j.dsp.2013.02.005
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Li JF, 2018, MULTIMED TOOLS APPL, V77, P14481, DOI 10.1007/s11042-017-5024-z
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P1482, DOI 10.1109/TIP.2018.2878290
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040700
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu XL, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043046
   Loukhaoukha Khaled, 2017, Journal of Electrical Systems and Information Technology, V4, P359, DOI 10.1016/j.jesit.2016.12.011
   Loukhaoukha K, 2014, OPTO-ELECTRON REV, V22, P45, DOI 10.2478/s11772-014-0177-z
   Loukhaoukha K, 2018, MULTIMED TOOLS APPL, V77, P9325, DOI 10.1007/s11042-017-4938-9
   Loukhaoukha K, 2016, ADV ENG SOFTW, V93, P44, DOI 10.1016/j.advengsoft.2015.12.006
   Loukhaoukha K, 2013, DIGIT SIGNAL PROCESS, V23, P1334, DOI 10.1016/j.dsp.2013.02.006
   Loukhaoukha K, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3327935
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Muhammad N, 2018, PATTERN ANAL APPL, V21, P997, DOI 10.1007/s10044-017-0613-z
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Nouioua I, 2018, SECUR COMMUN NETW, V2018, P17
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Shivani JLD, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030033
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Yavuz E, 2013, DIGIT SIGNAL PROCESS, V23, P1335, DOI 10.1016/j.dsp.2013.02.009
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 41
TC 5
Z9 6
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2031
EP 2045
DI 10.1007/s11042-019-08271-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000016
DA 2024-07-18
ER

PT J
AU Lou, J
   Wang, H
   Chen, LT
   Xu, FL
   Xia, QY
   Zhu, W
   Ren, MW
AF Lou, Jing
   Wang, Huan
   Chen, Longtao
   Xu, Fenglei
   Xia, Qingyuan
   Zhu, Wei
   Ren, Mingwu
TI Exploiting color name space for salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency; Salient object detection; Figure-ground segregation;
   Surroundedness; Color names; Color name space
ID REGION DETECTION; VISUAL-ATTENTION; IMAGE; INTEGRATION; MODEL
AB In this paper, we will investigate the contribution of color names for the task of salient object detection. An input image is first converted to color name space, which is consisted of 11 probabilistic channels. By exploiting a surroundedness cue, we obtain a saliency map through a linear combination of a set of sequential attention maps. To overcome the limitation of only using the surroundedness cue, two global cues with respect to color names are invoked to guide the computation of a weighted saliency map. Finally, we integrate the above two saliency maps into a unified framework to generate the final result. In addition, an improved post-processing procedure is introduced to effectively suppress image backgrounds while uniformly highlight salient objects. Experimental results show that the proposed model produces more accurate saliency maps and performs well against twenty-one saliency models in terms of three evaluation metrics on three public data sets.
C1 [Lou, Jing] Changzhou Vocat Inst Mechatron Technol, Sch Informat Engn, Changzhou 213164, Jiangsu, Peoples R China.
   [Wang, Huan; Chen, Longtao; Xu, Fenglei; Xia, Qingyuan; Zhu, Wei; Ren, Mingwu] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Changzhou Vocational Institute of Mechatronic Technology; Nanjing
   University of Science & Technology
RP Lou, J (corresponding author), Changzhou Vocat Inst Mechatron Technol, Sch Informat Engn, Changzhou 213164, Jiangsu, Peoples R China.; Ren, MW (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM loujing@jsut.edu.cn; renmingwu@mail.njust.edu.cn
RI Xu, Fenglei/HGF-1737-2022; Lou, Jing/B-3258-2011
OI Lou, Jing/0000-0001-8502-7429
FU Natural Science Foundation of the Higher Education Institutions of
   Jiangsu Province [19KJB520022]; Science and Technology Special Project
   of CZIMT [2019-ZXKJ-02]; Cultivation Object of Major Scientific Research
   Project of CZIMT [2019ZDXM06]; Jiangsu Province Industry University
   Research Cooperation Project [FZ20190200]; Changzhou Key Laboratory of
   Industrial Internet and Data Intelligence [CM20183002]; QingLan Project
   of Jiangsu Province (2018); National Natural Science Foundation of China
   [61231014, 61727802, 61703209, 61403202]; National Defense Pre-research
   Foundation of China [9140A01060115BQ02002]; China Postdoctoral Science
   Foundation [2014M561654]
FX J. Lou is supported by the Natural Science Foundation of the Higher
   Education Institutions of Jiangsu Province (No. 19KJB520022), the
   Science and Technology Special Project of CZIMT (No. 2019-ZXKJ-02), the
   Cultivation Object of Major Scientific Research Project of CZIMT (No.
   2019ZDXM06), the Jiangsu Province Industry University Research
   Cooperation Project (No. FZ20190200), the Changzhou Key Laboratory of
   Industrial Internet and Data Intelligence (No. CM20183002), and the
   QingLan Project of Jiangsu Province (2018). The work of L. Chen, F. Xu,
   W. Zhu, and M. Ren is supported by the National Natural Science
   Foundation of China (Nos. 61231014 and 61727802). H. Wang is supported
   by the National Defense Pre-research Foundation of China (No.
   9140A01060115BQ02002) and the National Natural Science Foundation of
   China (No. 61703209). Q. Xia is supported by the National Natural
   Science Foundation of China (No. 61403202) and the China Postdoctoral
   Science Foundation (No. 2014M561654). The authors thank Andong Wang and
   Haiyang Zhang for helpful discussions regarding this manuscript.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Berlin Brent, 1969, Basic Color Terms: Their Universality and Evolution
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gonzalez RC, 2004, DIGITAL IMAGE PROCES, P362
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li J, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.86
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Lou J, 2017, MULTIMED TOOLS APPL, V76, P14781, DOI 10.1007/s11042-016-4025-7
   Lou J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112475
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mazza V, 2005, PSYCHOL RES-PSYCH FO, V69, P201, DOI 10.1007/s00426-004-0174-9
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Niebur E, 1998, ATTENTIVE BRAIN, P163
   Palmer S., 1999, VISION SCI PHOTONS P
   Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Rubin E., 1958, Readings in Perception
   Scharfenberger C, 2015, IEEE T IMAGE PROCESS, V24, P457, DOI 10.1109/TIP.2014.2380351
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Soille P., 1999, Morphological Image Analysis: Principles and Applications, Vvol 2
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Tian HW, 2014, IEEE T IMAGE PROCESS, V23, P4389, DOI 10.1109/TIP.2014.2350914
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   van de Weijer J, 2007, IEEE I CONF COMP VIS, P2197
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 53
TC 7
Z9 9
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10873
EP 10897
DI 10.1007/s11042-019-07970-x
EA DEC 2019
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000504481500001
DA 2024-07-18
ER

PT J
AU Tan, LD
   Lu, YL
   Yan, XH
   Liu, LT
   Zhou, X
AF Tan, Longdan
   Lu, Yuliang
   Yan, Xuehu
   Liu, Lintao
   Zhou, Xuan
TI XOR-ed visual secret sharing scheme with robust and meaningful shadows
   based on QR codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quick response code; XOR-ed visual secret sharing; Padding codewords;
   Robust
ID CRYPTOGRAPHY; CONSTRUCTION
AB Quick response (QR) codes are becoming increasingly popular in various areas of life due to the advantages of the error correction capacity, the ability to be scanned quickly and the capacity to contain meaningful content. The distribution of dark and light modules of a QR code looks random, but the content of a code can be decoded by a standard QR reader. Thus, a QR code is often used in combination with visual secret sharing (VSS) to generate meaningful shadows. There may be some losses in the process of distribution and preservation of the shadows. To recover secret images with high quality, it is necessary to consider the scheme's robustness. However, few studies examine robustness of VSS combined with QR codes. In this paper, we propose a robust (k, n)-threshold XOR-ed VSS (XVSS) scheme based on a QR code with the error correction ability. Compared with OR-ed VSS (OVSS), XVSS can recover the secret image losslessly, and the amount of computation needed is low. Since the standard QR encoder does not check if the padding codewords are correct during the encoding phase, we replace padding codewords by initial shadows shared from the secret image using XVSS to generate QR code shadows. As a result, the shadows can be decoded normally, and their error correction abilities are preserved. Once all the shadows have been collected, the secret image can be recovered losslessly. More importantly, if some conventional image attacks, including rotation, JPEG compression, Gaussian noise, salt-and-pepper noise, cropping, resizing, and even the addition of camera and screen noises are performed on the shadows, the secret image can still be recovered. The experimental results and comparisons demonstrate the effectiveness of our scheme.
C1 [Tan, Longdan; Lu, Yuliang; Yan, Xuehu; Liu, Lintao; Zhou, Xuan] Natl Univ Def Technol, Hefei, Anhui, Peoples R China.
C3 National University of Defense Technology - China
RP Yan, XH (corresponding author), Natl Univ Def Technol, Hefei, Anhui, Peoples R China.
EM publictiger@126.com
RI Yan, Xuehu/AFK-3139-2022; Yan, Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61602491]; Key Program of
   the National University of Defense Technology [ZK-17-02-07]
FX The authors thank the reviewers for their comments and suggestions for
   improving the quality of the manuscript. This study is supported by the
   National Natural Science Foundation of China (Grant Number 61602491) and
   the Key Program of the National University of Defense Technology (Grant
   Number ZK-17-02-07).
CR [Anonymous], 2015, ISOIEC180042015
   Cheng YQ, 2018, IEEE T INF FOREN SEC, V13, P2393, DOI 10.1109/TIFS.2018.2819125
   Chow YW, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040095
   Chow YW, 2016, LECT NOTES COMPUT SC, V9722, P409, DOI 10.1007/978-3-319-40253-6_25
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Fu ZX, 2018, IEEE ACCESS, V6, P59567, DOI 10.1109/ACCESS.2018.2874527
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   [刘莺迎 Liu Yingying], 2016, [计算机应用研究, Application Research of Computers], V33, P3460
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Samretwit D., 2011, Proceedings of the 2011 Third International Conference on Intelligent Networking and Collaborative Systems (INCoS 2011), P552, DOI 10.1109/INCoS.2011.117
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wan S, 2017, INT C MOB AD HOC SEN, P374
   Wang GY, 2016, MULTIMED TOOLS APPL, V75, P1223, DOI 10.1007/s11042-014-2365-8
   Weir J., 2011, DIGITAL FORENSICS WA, V7128, P196, DOI DOI 10.1007/978-3-642-32205-1_17
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Xu T, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P189, DOI 10.1109/SIPROCESS.2016.7888250
   Xuehu Yan, 2018, Multimedia Tools and Applications, V77, P2653, DOI 10.1007/s11042-017-4421-7
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 23
TC 11
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5719
EP 5741
DI 10.1007/s11042-019-08351-0
EA DEC 2019
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000501289400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Alassaf, N
   Gutub, A
   Parah, SA
   Al Ghamdi, M
AF Alassaf, Norah
   Gutub, Adnan
   Parah, Shabir A.
   Al Ghamdi, Manal
TI Enhancing speed of SIMON: A light-weight-cryptographic algorithm for IoT
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Medical data; AES; SIMON cipher; Light weight
   cryptography
ID HIGH-CAPACITY; SECURE; INFORMATION; IMAGES
AB Multimedia communication is revolutionizing all major spheres of human life. The advent of IoT and its applications in many fields like sensing, healthcare and industry, result exponential increase in multimedia data, that needs to be shared over insecure networks. IoT driven setups are however constrained in terms of resources as a result of their small size. From data security point of view a conventional algorithms cannot be used for data encryption on an IoT platform given the resource constraints. The work presented in this paper studies the performance of SIMON cryptographic algorithm and proposes a light-weight-cryptography algorithm based on SIMON for its possible use in an IoT driven setup. The focus is on speed enhancement benefitting from software prospective, making it different than common studies mostly reflecting hardware implementations. To achieve performance in practical prospective, the contribution looks into SIMON cipher's characteristics considering utilizing it for internet of things (IoT) healthcare applications. The paper suggests further improvement to implement the original SIMON cryptography in order to reduce the encryption time and maintain the practical trade-off between security and performance. The proposed work has been compared to Advanced Encryption Standard (AES) and the original SIMON block cipher algorithms in terms of execution time, memory consumption. The results show that the proposed work is suitable for securing data in an IoT driven setup.
C1 [Alassaf, Norah; Gutub, Adnan] Umm Al Qura Univ UQU, Dept Comp Engn, Mecca, Saudi Arabia.
   [Parah, Shabir A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, JK, India.
   [Al Ghamdi, Manal] Umm AL Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
C3 Umm Al Qura University; University of Kashmir; Umm Al Qura University
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, JK, India.
EM shabireltr@gmail.com
RI Parah, Shabir/AAB-7603-2021; Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Parah, Shabir/0000-0001-5983-0912; Gutub, Adnan
   Abdul-Aziz/0000-0003-0923-202X
FU Umm Al-Qura University (UQU)
FX The authors acknowledge all support provided by Umm Al-Qura University
   (UQU) for encouraging this research work. Special thanks goes to the
   cooperation between the two UQU departments via Prof. Adnan Gutub from
   Computer Engineering and Dr Manal Al Ghamdi from Computer Sciences for
   motivating this research as well as building international collaboration
   with Dr Shabir Parah from the department of Electronics and IT,
   University of Kashmir, Srinagar, all working in collaboration on this
   wonderful research contributions.
CR Alharthi N., 2017, Scientific Modelling and Research, V2, P9, DOI 10.20448/808.2.1.9.18
   Alizadeh J, 2014, LECT NOTES COMPUT SC, V8651, P90, DOI 10.1007/978-3-319-13066-8_6
   Almazrooie M, 2018, J KING SAUD U COMPUT
   Aly SA, 2014, PROCEDIA COMPUT SCI, V32, P1141, DOI 10.1016/j.procs.2014.05.545
   [Anonymous], 2015 ANN IEEE IND C
   [Anonymous], WOSPA 2008 5 IEEE IN
   [Anonymous], 2015, IACR CRYPTOL EPRINT, DOI DOI 10.1007/S13389-018-0193-X
   Beaulieu R, 2017, IACR CRYPTOLOGY EPRI, P560
   Beaulieu R, 2015, S S BLOCK CIPHERS IN
   Beaulieu R, 2015, DES AUT CON, DOI 10.1145/2744769.2747946
   Ciabattoni L, 2016, J SENSORS, V2016, DOI 10.1155/2016/2978073
   Daemen J., 1999, AES proposal: Rijndael
   Dandekar AK, 2016, IRJET INT RES J ENG, V3
   Dibeklioglu H, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P307, DOI 10.1145/2818346.2820776
   Elhoseny M, 2017, IEEE T SUSTAINABLE C
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Elhoseny M, 2016, SECUR COMMUN NETW, V9, P2024, DOI 10.1002/sec.1459
   Elhoseny M, 2016, J KING SAUD UNIV-COM, V28, P262, DOI 10.1016/j.jksuci.2015.11.001
   Farouk A, 2018, FRONT PHYS-BEIJING, V13, DOI 10.1007/s11467-017-0717-3
   Ghouti L, 2013, Patent number: US, Patent No. 8385541
   Gulcan E., 2014, International Workshop on Lightweight Cryptography for Security and Privacy, P34
   Gutub A, 2011, ICSECS 2011 2 INT C
   Gutub A, 2017, MULTIMEDIA TOOLS SPR, P1380, DOI [10.1007/s11042-017-5293-6ISSN, DOI 10.1007/S11042-017-5293-6ISSN]
   Gutub A, 2012, INT C ADV COMP SCI A
   Gutub A, 2015, 3 ANN DIGITAL GRIDS
   Gutub Adnan Abdul-Aziz, 2013, IADIS International Conference Applied Computing 2013. Proceedings, P67
   Gutub Adnan Abdul-Aziz, 2011, International Journal of New Computer Architectures and their Applications, V1, P474
   Gutub Adnan, 2003, IEEE 10 ANN TECHN EX
   Gutub AAA, 2006, INT J COMPUT SCI NET, V6, P44
   Hossain MM, 2015, IEEE WORLD CONGR SER, P21, DOI 10.1109/SERVICES.2015.12
   Hosseinzadeh J., 2016, ADV COMPUT SCI INT J, V5, P31
   Ismail A., 2017, P INT C ADV INTELLIG, P820
   Kölbl S, 2015, LECT NOTES COMPUT SC, V9215, P161, DOI 10.1007/978-3-662-47989-6_8
   Kugler Patrick., 2013, 2013 IEEE International Conference on Body Sensor Networks, P1, DOI DOI 10.1109/BSN.2013.6575497
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Miao Wu, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P484, DOI 10.1109/ICACTE.2010.5579493
   Mora H, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102302
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Nithya R, 2016, PROC TECH, V25, P302, DOI 10.1016/j.protcy.2016.08.111
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Parah SA, 2018, NONLINEAR DYNAMICS N
   Parah SA, 2020, FUTURE GENER COMP SY, V108, P935, DOI 10.1016/j.future.2018.02.023
   Parah SA, 2018, STUD BIG DATA, V30, P409, DOI 10.1007/978-3-319-60435-0_17
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Trad A., 2014, Proc. of World Congress on Computer Applications and Information Systems (WCCAIS), P1
   Zajac P, 2017, DESIGN CODE CRYPTOGR, V82, P43, DOI 10.1007/s10623-016-0256-x
   Zhang W, 2014, INT J COMPUT COMMUN, V9, P644, DOI 10.15837/ijccc.2014.5.661
NR 49
TC 67
Z9 67
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32633
EP 32657
DI 10.1007/s11042-018-6801-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600002
DA 2024-07-18
ER

PT J
AU Borawake-Satao, R
   Prasad, R
AF Borawake-Satao, Rachana
   Prasad, Rajesh
TI Mobility aware multi-objective routing in wireless multimedia sensor
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor network; Wireless sensor network;
   IoT-internet of things; Multi-objective routing; Mobility aware routing;
   Energy aware routing
ID SINK; ALGORITHM
AB The Quality of Service (QoS) and energy efficiency are the key issues for Future Internet. Targeting multiple objectives for efficient routing is a critical and demanding task in recent applications. Due to increase in mobility applications consideration of mobility parameters for dynamic routing is necessary. The objective of this research paper is to propose the multi-objective approach for dynamic routing in Wireless Multimedia Sensor Network. Extending the adaptive routing for mobility will definitely enhance the capabilities of routing protocols for Wireless Multimedia Sensor Network. In this paper, we propose the adaptive routing protocol which is considering mobility parameter during route establishment. We are using various parameters such as Remaining Energy, Hop count, Link Quality Index and Mobility Factor for path formation. The experimentation results show that mobility parameter extension improves network performance. The technique used in this paper will enrich applications for Internet of things (IoT).
C1 [Borawake-Satao, Rachana] Savitribai Phule Pune Univ, Smt Kashibai Navale Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
   [Prasad, Rajesh] Savitribai Phule Pune Univ, Sinhgad Inst Technol & Sci, Pune, Maharashtra, India.
C3 Savitribai Phule Pune University; Savitribai Phule Pune University
RP Borawake-Satao, R (corresponding author), Savitribai Phule Pune Univ, Smt Kashibai Navale Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
EM rachana.borawake1@gmail.com
RI Prasad, Rajesh Shardanand/AFX-3524-2022; Prasad, Rajesh
   Shardanand/HNS-2823-2023
OI Prasad, Rajesh Shardanand/0000-0002-5148-3060; Prasad, Rajesh
   Shardanand/0000-0002-5148-3060
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Al-Karaki JN, 2004, IEEE WIREL COMMUN, V11, P6, DOI 10.1109/MWC.2004.1368893
   [Anonymous], 2012, INT J SCI ENG RES
   Bharti D, 2013, INT J ADV RES PERFOR, V3, P1333
   Borawake-satao R, 2016, C INN ENG TECHN KUAL
   Borawake-Satao R, 2017, ADV INTELL SYST, V469, P673, DOI 10.1007/978-981-10-1678-3_64
   Borawake-Satao R, 2016, INT J PERVASIVE COMP, V12, P447, DOI 10.1108/IJPCC-01-2016-0001
   Cobo L, 2010, COMPUT NETW, V54, P2991, DOI 10.1016/j.comnet.2010.05.014
   Demigha O, 2017, INT J SENS NETW, V23, P11, DOI 10.1504/IJSNET.2017.10001474
   do Rosário D, 2012, IEEE ICC, P6530, DOI 10.1109/ICC.2012.6364926
   Hara T, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P209, DOI 10.1109/WAINA.2014.43
   Khan MI, 2013, COMPUT COMMUN, V36, P965, DOI 10.1016/j.comcom.2012.10.010
   Lei Shu, 2011, International Journal of Multimedia Intelligence and Security, V2, P107, DOI 10.1504/IJMIS.2011.041361
   Li BY, 2013, INFORM SCIENCES, V249, P24, DOI 10.1016/j.ins.2013.06.014
   Lin K, 2011, IEEE SYST J, V5, P495, DOI 10.1109/JSYST.2011.2165599
   Medjiah S, 2009, 2009 GLOB INF INFR S
   Nayyar A., 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P427, DOI 10.1109/ICCRD.2011.5764166
   Rezazadeh J., 2012, INT J COMPUT COMMUN, V2, P17
   Shen H, 2014, WIRELESS PERS COMMUN, V75, P1307, DOI 10.1007/s11277-013-1425-0
   Shu L, 2010, TELECOMMUN SYST, V44, P79, DOI 10.1007/s11235-009-9227-0
   Silva R, 2012, INT J SENS NETW, V11, P3, DOI 10.1504/IJSNET.2012.045035
   Wang J, 2018, CMC-COMPUT MATER CON, V56, P433, DOI 10.3970/cmc.2018.04132
   Wang J, 2017, FUTURE GENER COMP SY, V76, P452, DOI 10.1016/j.future.2016.08.004
   Wang J, 2017, J SUPERCOMPUT, V73, P3277, DOI 10.1007/s11227-016-1947-9
   Yuan X, 2001, IEEE INFOCOM SER, P844, DOI 10.1109/INFCOM.2001.916275
   Zhang ZJ, 2014, IEEE WIREL COMMUN, V21, P14, DOI 10.1109/MWC.2014.6882291
NR 26
TC 15
Z9 15
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32659
EP 32677
DI 10.1007/s11042-019-7619-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600003
DA 2024-07-18
ER

PT J
AU Dhiman, S
   Chawla, R
   Gupta, S
AF Dhiman, Shekhar
   Chawla, Rashmi
   Gupta, Shailender
TI A novel video shot boundary detection framework employing DCT and
   pattern matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast Shot Boundary detection; Discrete Cosine Transform (DCT); Adaptive
   Threshold; Candidate segment; Cut Transition and Gradual Transition
   detection; Cosine Distance
AB The video Shot Boundary Detection (SBD) is an elementary step in realising a system capability to perform content based video search, structural analysis, data retrieval and video summation. Myriad research works in the past have been reported to construct SBD algorithms. However, the need of an error-free, meticulous and cost-effective SBD technique still persists; for applications viz. apt management, storage, browsing, video indexing and retrieval of multimedia data. This paper is an effort in the same direction with the aim of achieving high execution speed and greater accuracy. The proposed SBD technique in this paper incorporates three steps: (i) Candidate Segment Selection (ii) Cut Transition detection (iii) Gradual Transition detection. This paper adopts pixel based technique with candidate segment selection to speed up the SBD. For Cut Transition detection, the proposed method employs Discrete Cosine Transform (DCT) and for Gradual Transition detection, it employs Image Histogram and Pattern Matching. The comparison of MATLAB simulation results of the proposed SBD technique with those in literature manifest better results in terms of execution speed and accuracy.
C1 [Dhiman, Shekhar; Chawla, Rashmi; Gupta, Shailender] JC Bose Univ Sci & Technol, Dept Elect Engn, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Chawla, R (corresponding author), JC Bose Univ Sci & Technol, Dept Elect Engn, YMCA, Faridabad, India.
EM shekhar.max2014@gmail.com; rashmichawlaymca@gmail.com;
   shailender81@gmail.com
RI gupta, shailender/Y-8231-2019; Chawla, Rashmi/GOV-3027-2022
OI gupta, shailender/0000-0003-1383-7152; 
CR Adjeroh D, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/859371
   Apostolidis E, 2014, SPEECH SIGN PROC ICA, P6583
   Barjatya A., 2004, IEEE T EVOLUTION COM, V8, P225, DOI DOI 10.1109/TEVC.2004.826069
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bi CK, 2018, IEEE ACCESS, V6, P21397, DOI 10.1109/ACCESS.2018.2825106
   Cerneková Z, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2812528
   Chawla R, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0186-7
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Esponda F, 2004, IEEE T SYST MAN CY B, V34, P357, DOI 10.1109/TSMCB.2003.817026
   Fang H, 2006, PATTERN RECOGN, V39, P2092, DOI 10.1016/j.patcog.2006.04.044
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Huh JH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122917
   Li YN, 2009, IET IMAGE PROCESS, V3, P121, DOI 10.1049/iet-ipr.2007.0193
   Liang R, 2017, IEEE INT SYM MULTIM, P489, DOI 10.1109/ISM.2017.97
   Lu SY, 2010, IEEE IMAGE PROC, P2341, DOI 10.1109/ICIP.2010.5649254
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Mas J., 2003, P TRECVID
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Ren JC, 2009, IEEE T CIRC SYST VID, V19, P1234, DOI 10.1109/TCSVT.2009.2022707
   Schafer RW, 2011, IEEE SIGNAL PROC MAG, V28, P111, DOI 10.1109/MSP.2011.941097
   Shen RK, 2018, IEEE T COMPUT SOC SY, V5, P210, DOI 10.1109/TCSS.2017.2780882
   Sun J, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P45, DOI 10.1109/VCIP.2014.7051500
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Tippaya S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1025, DOI 10.1109/ICDSP.2015.7252033
   Xu J, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/2080536
   Yang Z, 2017, IEEE INT SYM MULTIM, P583, DOI 10.1109/ISM.2017.114
NR 26
TC 11
Z9 11
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34707
EP 34723
DI 10.1007/s11042-019-08170-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800022
DA 2024-07-18
ER

PT J
AU El-Khamy, SE
   Korany, NO
   El-Sherif, MH
AF El-Khamy, Said E.
   Korany, Noha O.
   El-Sherif, Marwa H.
TI Highly secured image hiding technique in stereo audio signal based on
   complete complementary codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Complete complementary codes; Encoding; Stereo audio;
   Steganography; Human auditory system (HAS); Threshold; Auto correlation;
   Cross correlation; Henon map; Discrete wavelet transform
ID WATERMARKING
AB The recent revolution of the Internet as a collaborative medium has opened the door for people who want to share their work. Nevertheless, this may cause serious problems for privacy and copyright protection. Steganography is a powerful tool for protecting important data during transmission. It's used to hide any secret information like text, image or audio behind a cover file. In this study, a new robust audio steganography technique based on optimum two dimensional Complete Complementary Codes (CCC) has been adopted to encode colour images data and obtain two differently encoded versions of it. These two versions are hidden in DWT coefficients of the two channels of stereo audio signal and embedding locations are determined via 2-D chaotic map random sequence. Complete Complementary Codes (CCC) are sets of spread spectrum sequence family that have ideal auto and cross-correlation properties so, they found many applications in several science areas with the broadest application possibilities in telecommunications. Various attacks are applied to the host audio signals and simulation results show high robustness and capacity with good quality of the extracted image.
C1 [El-Khamy, Said E.; Korany, Noha O.; El-Sherif, Marwa H.] Alexandria Univ, Dept Elect Engn, Alexandria 21544, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University
RP El-Sherif, MH (corresponding author), Alexandria Univ, Dept Elect Engn, Alexandria 21544, Egypt.
EM elkhamy@ieee.org; nokorany@hotmail.com; marwaelsherif2@gmail.com
RI El-Khamy, Said E./AAE-6748-2020
OI elsherif, marwa/0000-0002-9675-6632
CR Al-Haj A, 2014, MULTIMED TOOLS APPL, V73, P1897, DOI 10.1007/s11042-013-1645-z
   Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   Al-Shameri WFH., 2012, Int J Math Anal, V6, P2419
   Banik BG, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1781384
   Bharti Priya, 2012, INT J COMPUTER APPL, V58
   Chang C, 2010, INFORM SCI, V529, DOI [10.1080/09720529.2015.1085743, DOI 10.1080/09720529.2015.1085743]
   Channapragada RSR, 2012, INT J ADV COMPUTING, V4, DOI [10.4156/ijact.vol4.issue18.70, DOI 10.4156/IJACT.VOL4.ISSUE18.70]
   Dávideková M, 2016, PROCEDIA COMPUT SCI, V83, P592, DOI 10.1016/j.procs.2016.04.279
   Detert T, 2004, IEEE MEDITERR ELECT, P441, DOI 10.1109/MELCON.2004.1346959
   Dhar PK, 2014, INT J SPEECH TECHNOL, V17, P133, DOI 10.1007/s10772-013-9214-4
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   El-Khamy SE, 2017, MULTIMED TOOLS APPL, V76, P24091, DOI 10.1007/s11042-016-4113-8
   El-Khamy SE, 2005, TWIN IMAGE WATERMARK
   El-Khamy SE, 2004, NAT RAD SCI C NRSC20
   Elshazly AR, 2016, 2016 FOURTH INTERNATIONAL JAPAN-EGYPT CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND COMPUTERS (JEC-ECC), P52, DOI 10.1109/JEC-ECC.2016.7518966
   Erfani Y, 2009, DIGIT SIGNAL PROCESS, V19, P809, DOI 10.1016/j.dsp.2009.04.003
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Jiao DH, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P250, DOI 10.1109/ICSPCC.2014.6986192
   Jichao L, 2007, WIR COMM NTW C WCNC
   Jin ZW, 2014, 2014 ASIA-PACIFIC SERVICES COMPUTING CONFERENCE (APSCC), P147, DOI 10.1109/APSCC.2014.25
   Khaldi K, 2013, IEEE T AUDIO SPEECH, V21, P675, DOI 10.1109/TASL.2012.2227733
   Khirallah C, 2008, 2008 FOURTH WORKSHOP ON NETWORK CODING, THEORY, AND APPLICATIONS: NETCOD 2008, PROCEEDINGS, P19
   Kojima T., 2011, Proceedings of the Fifth International Workshop on Signal Design and Its Applications in Communications (IWSDA 2011), P100, DOI 10.1109/IWSDA.2011.6159397
   Kojima T., 2011, Proceedings of the 2011 Australian Communications Theory Workshop (AusCTW), P1, DOI 10.1109/AUSCTW.2011.5728728
   Kojima T, 2015, 2015 7 INT WORKSH SI
   Kojima T, 2010, ARXIV10012623V1CSIT
   Kojima T, 2010, 6 INT C INT INF HID
   Kojima T, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP), P142, DOI 10.1109/IIH-MSP.2015.88
   Kojima T, 2013, INT WORK SIG DES, P118, DOI 10.1109/IWSDA.2013.6849077
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Li RK, 2016, IET SIGNAL PROCESS, V10, P266, DOI 10.1049/iet-spr.2014.0388
   Li S, 2004, J INSECT SCI, V4
   LUKE HD, 1985, IEEE T AERO ELEC SYS, V21, P170, DOI 10.1109/TAES.1985.310615
   Majead A, 2016, J NETW COMPLEX SYST
   Mayazumi R., 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P45, DOI 10.1109/IIHMSP.2011.70
   Meligy Ali M., 2016, International Journal of Image, Graphics and Signal Processing, V8, P36, DOI 10.5815/ijigsp.2016.01.04
   Naidu TRK, 2016, INT J EMERGING TECHN, V3
   Nandane A, 2017, IJSRD INT J SCI RES, V5
   Ozgur S, 2005, P IEEE INT C AC SPEE, V2
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Raghava NS, 2014, OPEN J INFORM SEC AP, V1
   Reddy D.H.R., 2013, IOSR J ELECT COMMUN, V6, P27
   REITERER SM, 2013, INT J COMPUTER SCI E, V4, DOI DOI 10.3389/FPSYG.2013.00782
   Shiu HJ, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9060092
   Subir, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P79, DOI 10.1109/SPIN.2016.7566666
   SUEHIRO N, 1988, IEEE T INFORM THEORY, V34, P143, DOI 10.1109/18.2615
   SUEHIRO N, 1982, IECE T A, V65, P1247
   Sung AH, 2010, ACM INT C MULT FIR I
   Tsou YC, 2013, I SYMP CONSUM ELECTR, P219
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang Y, 2012, IEEE T INF FOREN SEC, V7, P383, DOI 10.1109/TIFS.2011.2173678
   Xue P, 2018, 6 INT C COMP AID DES
   Zhang PJ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P819, DOI 10.1109/ICNIDC.2009.5360957
NR 53
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34373
EP 34395
DI 10.1007/s11042-019-08122-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800008
DA 2024-07-18
ER

PT J
AU Lamy, JB
AF Lamy, Jean-Baptiste
TI Visualizing undirected graphs and symmetric square matrices as
   overlapping sets Methods and application to character co-occurrences
   graphs and matrices in novels and DBpedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge visualization; Matrix visualization; Overlapping set
   visualization; Undirected graph; Symmetric square matrix; Distant
   reading; Digital humanities; Les Miserables
ID INFORMATION
AB Undirected graphs and symmetric square matrices are frequently found in various domains. An example is character co-occurrence matrices in digital humanities. However, the visualization of these datasets is difficult, especially if the graph is highly connected. In this article, we propose a method for visualizing undirected graphs and symmetric square matrices, by transforming them into overlapping sets, and then by visualizing these overlapping sets using set visualization techniques such as Euler diagram or rainbow boxes. We also propose a clustering approach to simplify the visualization. We apply this method to the visualization of various character co-occurrence matrices extracted from novels or DBpedia, ranging from 21 to 114 characters. We show that this visualization allows the finding of several interesting insights. Finally, we discuss the advantages and drawbacks of this method, and we compare it to other approaches in the literature.
C1 [Lamy, Jean-Baptiste] Univ Paris 13, Sorbonne Univ, INSERM, LIMICS, F-93017 Bobigny, France.
C3 Universite Paris 13; Institut National de la Sante et de la Recherche
   Medicale (Inserm); Sorbonne Universite
RP Lamy, JB (corresponding author), Univ Paris 13, Sorbonne Univ, INSERM, LIMICS, F-93017 Bobigny, France.
EM jean-baptiste.lamy@univ-paris13.fr
CR Agarwal A., 2012, NAACL-HLT, V2012, P88
   [Anonymous], 2013, Springer Briefs in Statistics, DOI DOI 10.1007/978-81-322-0763-4
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Bilenko N, 2016, TECHNICAL REPORT
   Bonato A, 2016, LECT NOTES COMPUT SC, V10088, P100, DOI 10.1007/978-3-319-49787-7_9
   De Prisco R, 2017, IEEE INT CON INF VIS, P410, DOI 10.1109/iV.2017.49
   Gottfried B, 2014, J VISUAL LANG COMPUT, V25, P518, DOI 10.1016/j.jvlc.2014.04.003
   Henry N., 2007, INTERACT LECT NOTES, V4663, P88
   Hsieh TL, 2017, IEEE INT CON INF VIS, P14, DOI 10.1109/iV.2017.79
   Jänicke S, 2017, COMPUT GRAPH FORUM, V36, P226, DOI 10.1111/cgf.12873
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Knuth D.E, 1993, The Stanford graph base: A platform for combinatorial computing, P577
   Lamy JB, 2018, INT C INF VIS IV SAL, P361
   Lamy JB, 2019, EAI SPRINGER INNOVAT, P43, DOI 10.1007/978-3-319-96451-5_3
   Lamy JB, 2018, IEEE INT CON INF VIS, P344, DOI 10.1109/iV.2018.00065
   Lamy JB, 2017, J VISUAL LANG COMPUT, V43, P71, DOI 10.1016/j.jvlc.2017.09.003
   Lamy JB, 2017, ARTIF INTELL MED, V80, P11, DOI 10.1016/j.artmed.2017.07.002
   Lamy JB, 2017, J BIOMED INFORM, V71, P58, DOI 10.1016/j.jbi.2017.04.019
   Lamy JB, 2016, IEEE INT CONF INF VI, P253, DOI 10.1109/IV.2016.26
   Lamy JB, 2016, STUD HEALTH TECHNOL, V221, P64, DOI 10.3233/978-1-61499-633-0-64
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Leydesdorff L, 2006, J AM SOC INF SCI TEC, V57, P1616, DOI 10.1002/asi.20335
   Longabaugh WJR, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-275
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rodgers P, 2014, J VISUAL LANG COMPUT, V25, P134, DOI 10.1016/j.jvlc.2013.08.006
   Siirtola H, 2016, IEEE INT CONF INF VI, P330, DOI 10.1109/IV.2016.57
   Valdivia P, 2018, 3 WORKSH VIS DIG HUM
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P1087, DOI 10.1109/TVCG.2013.263
   Wu H.-M., 2008, Handbook of data visualization, P681
   Yang B, 2017, INT J DIGIT LIBRARIE, V18, P41, DOI 10.1007/s00799-016-0196-0
   Yang X-S, 2010, Nature-Inspired Metaheuristic Algorithms, V2
   Yang Y, 2012, SCIENTOMETRICS, V90, P659, DOI 10.1007/s11192-011-0541-4
   Zhang J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030181
NR 34
TC 1
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33091
EP 33112
DI 10.1007/s11042-019-7655-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600022
DA 2024-07-18
ER

PT J
AU Wang, XH
   Li, W
   Zhang, C
   Lou, WQ
   Song, RX
AF Wang, Xianghai
   Li, Wei
   Zhang, Chong
   Lou, Wanqi
   Song, Ruoxi
TI An adaptable active contour model for medical image segmentation based
   on region and edge information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Adaptable active contour model; Global
   information; Local information; Edge information; Adaptive balance
   function
ID GRADIENT VECTOR FLOW
AB Due to the complexity of the internal structure of human body and the physiological movement of the illuminated tissue, the digital medical image exists low contrast, high noise intensity, complex internal structure and edge blur phenomenon, which will limit the segmentation accuracy of traditional active contour models. To solve this problem, this paper proposes a novel active contour model based on the combination of regional information and the edge information of the image. The new approach has four key characteristics. First the local information fitting of the image is incorporated into the pressure force function (SPF) of the SBGFRLS model, which improves the ability of dealing with medical images with low contrast and complex structure. Second, the adaptive balance of local information and global information is realized by adding a novel weighting function, which accelerates the evolution speed and enhances the adaptability of the model; Third, in the numerical implementation process of the proposed model, the divergence operator is replaced by the Gaussian filter, in this way, the level set function is smoothed and the computation is simplified. Last, a penalty term of symbolic function is introduced to reduce the computational complexity of the level set function due to re-initialization and regularization process. In order to verify the effectiveness of the model, we use different kinds of medical images for simulation experiments. Experimental results show that compared with the traditional active contour models, the proposed method can achieve an satisfactory both in segmentation speed and accuracy.
C1 [Wang, Xianghai] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Liaoning, Peoples R China.
   [Wang, Xianghai; Li, Wei; Zhang, Chong; Lou, Wanqi] Liaoning Normal Univ, Sch Math, Dalian 116029, Liaoning, Peoples R China.
   [Song, Ruoxi] Liaoning Normal Univ, Sch Urban & Environm Sci, Dalian 116029, Liaoning, Peoples R China.
C3 Liaoning Normal University; Liaoning Normal University; Liaoning Normal
   University
RP Wang, XH (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Liaoning, Peoples R China.; Wang, XH (corresponding author), Liaoning Normal Univ, Sch Math, Dalian 116029, Liaoning, Peoples R China.; Song, RX (corresponding author), Liaoning Normal Univ, Sch Urban & Environm Sci, Dalian 116029, Liaoning, Peoples R China.
EM xhwang@lnnu.edu.cn; 1065127081@qq.com; 631860056@qq.com;
   1399338191@qq.com; ruoxisong@qq.com
RI Wang, Xianghai/GRR-4512-2022
OI Wang, Xianghai/0000-0002-7600-9939
FU National Natural Science Foundation of China [41671439, 61402214];
   Innovation Team Support Program of Liaoning Higher Education Department
   [LT2017013]
FX This research has been funded by the National Natural Science Foundation
   of China (Grant Nos. 41671439 and 61402214), and Innovation Team Support
   Program of Liaoning Higher Education Department (LT2017013).
CR Bibi I, 2017, SIGN PROC COMM COMP, P1
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng JR, 2006, IEEE T IMAGE PROCESS, V15, P1563, DOI 10.1109/TIP.2006.871140
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Hemalatha RJ, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/4976372
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Liu TT, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/890725
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Min H, 2015, PATTERN RECOGN, V48, P1547, DOI 10.1016/j.patcog.2014.10.018
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Shi N, 2016, OPTIK, V127, P1037, DOI 10.1016/j.ijleo.2015.09.184
   Shivapatham G, 2017, INT J SCI RES DEV, V5, P618
   Tang JS, 2006, IEEE T BIO-MED ENG, V53, P896, DOI 10.1109/TBME.2006.872816
   Tian Y, 2013, MACH VISION APPL, V24, P47, DOI 10.1007/s00138-011-0363-7
   Tu Song, 2015, Systems Engineering and Electronics, V37, P1754, DOI 10.3969/j.issn.1001-506X.2015.08.07
   Wang XH, 2016, INT J IMAG SYST TECH, V26, P179, DOI 10.1002/ima.22173
   [王相海 Wang Xianghai], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P751
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zahir M, 2013, SYST SIGN PROC THEIR
   Zanaty E.A., 2016, INT J INFORMATICS ME, V1, P16
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
NR 26
TC 11
Z9 13
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33921
EP 33937
DI 10.1007/s11042-019-08073-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600060
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Zhang, XL
   Xiao, ZJ
AF Zhang, Xiaoyan
   Zhang, Xiaole
   Xiao, Zhijiao
TI Deep photographic style transfer guided by semantic correspondence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photographic style transfer; Semantic correspondence; Deep learning
AB The objective of this paper is to develop an effective photographic style transfer method while preserving the semantic correspondence between the style and content images for both scenery and portrait images. A semantic correspondence guided photographic style transfer algorithm is developed, which is to ensure that the semantic structure of the content image has not been changed while the color of the style images is being migrated. The semantic correspondence is constructed in large scale regions based on image segmentation and also in local scale patches using Nearest-neighbor Field Search in the deep feature domain. Based on the semantic correspondence, a matting optimization is utilized to optimize the style transfer result to ensure the semantic accuracy and transfer faithfulness. The proposed style transfer method is further extended to automatically retrieve the style images from a database to make style transfer more-friendly. The experimental results show that our method could successfully conduct the style transfer while preserving semantic correspondence between diversity of scenes. A user study also shows that our method outperforms state-of-the-art photographic style transfer methods.
C1 [Zhang, Xiaoyan; Zhang, Xiaole; Xiao, Zhijiao] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518000, Peoples R China.
C3 Shenzhen University
RP Xiao, ZJ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518000, Peoples R China.
EM xyzhang15@szu.edu.cn; zhangxiaole2016@email.szu.edu.cn;
   cindyxzj@szu.edu.cn
FU Chinese Natural Science Foundation [61602313, 61620106008]; Shenzhen
   Commission of Scientific Research and Innovations
   [JCYJ20170302153632883, JCYJ20160422151736824]; Startup Foundation for
   Advanced Talents, Shenzhen; Natural Science Foundation of Guangdong
   Province [2016A030310053, 2017A030310521]
FX The authors wish to acknowledge the financial support from: (i) Chinese
   Natural Science Foundation under the Grant No. 61602313, 61620106008;
   (ii) Shenzhen Commission of Scientific Research and Innovations under
   the Grant No. JCYJ20170302153632883, JCYJ20160422151736824; (iii)
   Startup Foundation for Advanced Talents, Shenzhen; (iv) The Natural
   Science Foundation of Guangdong Province No. 2016A030310053,
   2017A030310521.
CR [Anonymous], 2002, P 7 IEEE INT C COMP, DOI DOI 10.5555/850924.851569
   [Anonymous], 2015, PROC WORKSHOP COMPUT
   Arbelot B., 2016, 5 JOINT S COMPUTATIO, P21
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Champandard AJ, ARXIV160301768
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2018, PROC CVPR IEEE, P518, DOI 10.1109/CVPR.2018.00061
   Dong Z, 2018, INT CONF POW ELECTR, P459, DOI 10.23919/IPEC.2018.8507611
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gatys L. A., 2015, arXiv
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hwang SJ, 2012, LECT NOTES COMPUT SC, V7572, P569, DOI 10.1007/978-3-642-33718-5_41
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kaur P, 2017, IEEE INT C COMP VIS
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Lin T.-Y., 2017, CVPR, P2117, DOI 10.1109/CVPR.2017.106
   Liu J, 2016, IEEE T MULTIMEDIA, p1C
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Pitié F, 2005, IEEE I CONF COMP VIS, P1434
   Pitié F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011
   Qin XM, 2015, IEEE T MULTIMEDIA, V17, P295, DOI 10.1109/TMM.2015.2395078
   Rabin J, 2014, IEEE IMAGE PROC, P4852, DOI 10.1109/ICIP.2014.7025983
   REINHARD E, 2002, IEEE COMPUT GRAPH, V5, P34
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Wang WQ, 2018, MANAGE SCI, V64, P5198, DOI 10.1287/mnsc.2017.2906
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Wu F, 2013, CONTENT BASED COLOUR, P190
   Yang Y, 2017, MULTIMED TOOLS APPL, V76, P523, DOI 10.1007/s11042-015-3063-x
   Zhang H., 2017, MULTISTYLE GENERATIV
NR 37
TC 4
Z9 4
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34649
EP 34672
DI 10.1007/s11042-019-08099-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800019
DA 2024-07-18
ER

PT J
AU Zitouni, MS
   Sluzek, A
   Bhaskar, H
AF Zitouni, M. Sami
   Sluzek, Andrzej
   Bhaskar, Harish
TI Towards understanding socio-cognitive behaviors of crowds from visual
   surveillance data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd analysis; Socio-cognitive behaviors; Behavior analysis; Detection;
   Tracking
ID TRACKING; TRENDS
AB The problem of understanding socio-cognitive aspects of crowd behavior is a challenging yet critical task particularly for human-computer interaction applications. This issue is considered an important component of both current surveillance systems and futuristic interactions between intelligent agents and crowds of humans. In this paper, a probabilistic formulation of different categories of socio-cognitive crowd behavior is proposed. This framework models in a hierarchical manner relationships between the movements of entities within the crowd to differentiate between various crowd behaviors. Functionally, the framework can be considered a mid-level layer between purely visual analysis (i.e. detection and tracking of crowd components) and detailed semantics of crowd behaviors. In the presented study, the proposed framework extends a Gaussian Mixture Model of Dynamic Textures detection (GMM-of-DT) technique using Kalman filtering for the hierarchical motion representation of the crowds, simultaneously at micro (individual crowd members) and macro (groups of individuals) levels. Thereon, socio-cognitive crowd behaviors are categorized into individual, group, leader-follower and social interaction types. The proposed approach is validated on exemplary sequences from a benchmark PETS dataset (and, preliminarily, on other publicly available datasets), where the actual detection/tracking results are employed to evaluate probabilities of various socio-cognitive behaviors, and to compare the outputs of the proposed models to manually annotated ground-truth data.
C1 [Zitouni, M. Sami; Sluzek, Andrzej] Khalifa Univ Sci & Technol, Abu Dhabi, U Arab Emirates.
   [Sluzek, Andrzej] Warsaw Univ Life Sci SGGW, Warsaw, Poland.
   [Bhaskar, Harish] Zero One Infin Consulting ZOIC Serv Ltd, Toronto, ON, Canada.
C3 Khalifa University of Science & Technology; Warsaw University of Life
   Sciences
RP Zitouni, MS (corresponding author), Khalifa Univ Sci & Technol, Abu Dhabi, U Arab Emirates.
EM m.zitouni@hotmail.com
RI ; Sluzek, Andrzej/A-3672-2011
OI Zitouni, Mohammad Sami/0000-0001-7629-8702; Sluzek,
   Andrzej/0000-0003-4148-2600
CR [Anonymous], 2012, PEDESTRIAN EVACUATIO, DOI DOI 10.1007/978-3-319-02447-9_1
   Baig MW, 2014, IEEE IJCNN, P3966, DOI 10.1109/IJCNN.2014.6889964
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEHGHAN A, 2015, PROC CVPR IEEE, P4091, DOI DOI 10.1109/CVPR.2015
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Fridman N, 2010, COMPUT MATH ORGAN TH, V16, P348, DOI 10.1007/s10588-010-9082-2
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Leach MJV, 2014, IEEE COMPUT SOC CONF, P467, DOI 10.1109/CVPRW.2014.75
   Li YK, 2018, IEEE T MULTIMEDIA, V20, P3289, DOI 10.1109/TMM.2018.2834873
   Luber M, 2010, IEEE INT CONF ROBOT, P464, DOI 10.1109/ROBOT.2010.5509779
   Madrigal F, 2014, INT C PATT RECOG, P4122, DOI 10.1109/ICPR.2014.706
   Mazzon R, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P202, DOI 10.1109/AVSS.2013.6636640
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Parker S., 2012, It turns out funding music education costs less than everyone thought, P1
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Solera Francesco, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P43, DOI 10.1109/CVPRW.2015.7301282
   Solera F, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P7, DOI 10.1109/AVSS.2013.6636608
   Tian S, 2016, NEUROCOMPUTING, V171, P768, DOI 10.1016/j.neucom.2015.07.028
   Wang JH, 2015, CHIN CONT DECIS CONF, P232, DOI 10.1109/CCDC.2015.7161696
   Wang L, 2014, IEEE T INTELL TRANSP, V15, P1886, DOI 10.1109/TITS.2014.2303196
   Wei HT, 2018, INT CONF MEAS, P332, DOI 10.1109/ICMTMA.2018.00087
   Wen LY, 2016, IEEE T PATTERN ANAL, V38, P1983, DOI 10.1109/TPAMI.2015.2509979
   Wen LY, 2014, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2014.167
   Zaki MH, 2018, IEEE T INTELL TRANSP, V19, P1880, DOI 10.1109/TITS.2017.2747516
   Zhang YH, 2017, IEEE T CIRC SYST VID, V27, P635, DOI 10.1109/TCSVT.2016.2593609
   Zhang YH, 2015, IEEE T CIRC SYST VID, V25, P1231, DOI 10.1109/TCSVT.2014.2355711
   Zhang YH, 2012, IEEE IMAGE PROC, P2689, DOI 10.1109/ICIP.2012.6467453
   Zhao J., 2011, ISA, P1, DOI DOI 10.1109/GEOINFORMATICS.2011.5981047
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhou H, 2015, 2015 INTERNATIONAL CONFERENCE ON MATERIALS AND ENGINEERING AND INDUSTRIAL APPLICATIONS (MEIA 2015), P24
   Zitouni M. Sami, 2016, VISIGRAPP 2016. 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications. Proceedings: VISAPP 2016, P403
   Zitouni MS, 2019, ENG APPL ARTIF INTEL, V82, P294, DOI 10.1016/j.engappai.2019.04.012
   Zitouni MS, 2015, IEEE SYS MAN CYBERN, P1827, DOI 10.1109/SMC.2015.320
   Zitouni MS, 2016, NEUROCOMPUTING, V186, P139, DOI 10.1016/j.neucom.2015.12.070
NR 39
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1781
EP 1799
DI 10.1007/s11042-019-08201-z
EA NOV 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495944500003
DA 2024-07-18
ER

PT J
AU Niyat, AY
   Moattar, MH
AF Niyat, Abolfazl Yaghouti
   Moattar, Mohammad Hossein
TI Color image encryption based on hybrid chaotic system and DNA sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Stability; DNA sequence; 3D Logistic map; Chen system
ID ALGORITHM; PERMUTATION; OPERATION; CML; MAP
AB Stability and complexity of the encryption process besides affordable encryption time are the two challenges of image encryption. In this paper, Chen chaotic system is applied to produce random sequences and using these sequences some arrays are created for image permutation and key stream production. Since these random sequences have two different applications, separate calculation time is not necessary. As a result, time complexity decreases. Each of the color components of the plain image are converted to a one dimensional vector for image permutation and the permutation is performed using the generated chaotic arrays. Created key stream is converted into a chaotic image. Then permutated image and the chaotic image are divided into equal blocks. The plain image blocks are encoded using DNA rules. The encoding rules are chosen randomly using a three-dimensional Logistic map. This process makes it possible to have various options for choosing DNA coding rules. Finally, all the encrypted blocks are combined and the encrypted image is obtained. Experimental results show that the proposed approach has a large key space and is resistant against different attacks. Also, the correlation between the neighboring pixels is decreased and the resulting entropy is very close to ideal.
C1 [Niyat, Abolfazl Yaghouti] Quchan Tech & Vocat Univ Iran, Comp Engn, Quchan, Iran.
   [Moattar, Mohammad Hossein] Islamic Azad Univ, Mashhad Branch, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
C3 Islamic Azad University
RP Moattar, MH (corresponding author), Islamic Azad Univ, Mashhad Branch, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
EM ayaghouti@gmail.com; moattar@mshdiau.ac.ir
RI moattar, mohammad/AAO-5645-2021
OI moattar, mohammad/0000-0002-8968-6744
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Enayatifar R, 2015, OPTICS LASERS ENG
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   LaBean TH, 1999, 5 DIMACS SERIES DISC
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, ADV SCI LETT, V3, P447, DOI 10.1166/asl.2010.1170
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang Y., 2012, APPL CRYPTOGRAPHY NE, P357
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
NR 32
TC 43
Z9 43
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1497
EP 1518
DI 10.1007/s11042-019-08247-z
EA NOV 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493973100003
DA 2024-07-18
ER

PT J
AU Starosolski, R
AF Starosolski, Roman
TI Reversible denoising and lifting based color component transformation
   for lossless image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible color space transformation; Lifting technique; Denoising;
   Reversible denoising and lifting step; Detector precision
   characteristic; Lossless image compression
ID DETECTOR PRECISION CHARACTERISTICS
AB An undesirable side effect of reversible color space transformation, which consists of lifting steps (LSs), is that while removing correlation it contaminates transformed components with noise from other components. Noise affects particularly adversely the compression ratios of lossless compression algorithms. To remove correlation without increasing noise, a reversible denoising and lifting step (RDLS) was proposed that integrates denoising filters into LS. Applying RDLS to color space transformation results in a new image component transformation that is perfectly reversible despite involving the inherently irreversible denoising; the first application of such a transformation is presented in this paper. For the JPEG-LS, JPEG 2000, and JPEG XR standard algorithms in lossless mode, the application of RDLS to the RDgDb color space transformation with simple denoising filters is especially effective for images in the native optical resolution of acquisition devices. It results in improving compression ratios of all those images in cases when unmodified color space transformation either improves or worsens ratios compared with the untransformed image. The average improvement is 5.0-6.0% for two out of the three sets of such images, whereas average ratios of images from standard test-sets are improved by up to 2.2%. For the efficient image-adaptive determination of filters for RDLS, a couple of fast entropy-based estimators of compression effects that may be used independently of the actual compression algorithm are investigated and an immediate filter selection method based on the detector precision characteristic model driven by image acquisition parameters is introduced.
C1 [Starosolski, Roman] Silesian Tech Univ, Inst Informat, Akad 16, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Starosolski, R (corresponding author), Silesian Tech Univ, Inst Informat, Akad 16, PL-44100 Gliwice, Poland.
EM rstarosolski@polsl.pl
RI Starosolski, Roman/AAF-6974-2019
OI Starosolski, Roman/0000-0003-1322-3345
FU Institute of Informatics, Silesian University of Technology
   [02/020/BK_19/0171]
FX The author thanks Tytus Bernas, Piotr Fabian, and the anonymous
   reviewers for their constructive comments. This work was supported by
   the 02/020/BK_19/0171 grant from the Institute of Informatics, Silesian
   University of Technology.
CR [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 2006, 144951 ISOIEC
   [Anonymous], 2012, 291992 ISOIEC
   [Anonymous], 2011, 1544410 ISOIEC
   [Anonymous], 2007, Digital Image Processing: PIKS Scientific Inside
   Bernas T, 2015, BIOMED SIGNAL PROCES, V19, P1, DOI 10.1016/j.bspc.2015.02.010
   Bernas T, 2012, COMPUT METH PROG BIO, V108, P511, DOI 10.1016/j.cmpb.2011.03.012
   Bruylants T, 2015, SIGNAL PROCESS-IMAGE, V31, P112, DOI 10.1016/j.image.2014.12.007
   Clunie DA, 2011, IEEE COMSOC MMTC E-Letter, P31
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   DESIMONE F, 2009, P SPIE APPL DIGITAL, V32, P7443, DOI DOI 10.1117/12.830714
   Dufaux F, 2009, IEEE SIGNAL PROC MAG, V26, P195, DOI 10.1109/MSP.2009.934187
   Hao PW, 2001, IEEE T SIGNAL PROCES, V49, P2314, DOI 10.1109/78.950787
   *ISO IEC, 2003, 144952 ISOIEC
   *ISO IEC, 2012, 291995 ISOIEC
   *ISO IEC, 2018, 230082 ISOIEC
   *ISO IEC, 2016, 154441 ISOIEC
   Liu F, 2017, INFORMATION, V8, DOI 10.3390/info8040131
   Malvar HS, 2008, PROC SPIE, V7073, DOI 10.1117/12.797091
   *NEMA, 2014, 352014A NEMA PS
   Peng WH, 2016, IEEE J EM SEL TOP C, V6, P393, DOI 10.1109/JETCAS.2016.2608971
   Pinho AJ, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P633, DOI 10.1109/ICME.2002.1035861
   Singh SK, 2011, SIGNAL PROCESS-IMAGE, V26, P662, DOI 10.1016/j.image.2011.08.001
   Starosolski R, 2007, SOFTWARE PRACT EXPER, V37, P65, DOI 10.1002/spe.746
   Starosolski R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168704
   Starosolski R, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043025
   Starosolski R, 2015, SIGNAL PROCESS-IMAGE, V39, P249, DOI 10.1016/j.image.2015.09.013
   Starosolski R, 2014, J VIS COMMUN IMAGE R, V25, P1056, DOI 10.1016/j.jvcir.2014.03.003
   Starosolski R, 2008, AIP CONF PROC, V1060, P269, DOI 10.1063/1.3037069
   Strutz T, 2013, IEEE T CIRC SYST VID, V23, P1249, DOI 10.1109/TCSVT.2013.2242612
   Strutz T, 2012, EUR SIGNAL PR CONF, P1204
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   *U BRIT COL SIGN P, JPEG LS IMPL VERS 2
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
NR 35
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11269
EP 11294
DI 10.1007/s11042-019-08371-w
EA NOV 2019
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LJ2WK
UT WOS:000493770000001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Batista, GC
   Silva, WLS
   de Oliveira, DL
   Saotome, O
AF Batista, Gracieth Cavalcanti
   Silva, Washington Luis Santos
   de Oliveira, Duarte Lopes
   Saotome, Osamu
TI Automatic speech patterns recognition of commands using SVM and PSO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PSO-SVM hybrid training; PSO algorithm; SVM multiclass; Speech patterns
   recognition
ID SUPPORT VECTOR MACHINE
AB This paper proposes the implementation of an Automatic Speech Recognition (ASR) process through extraction of Mel-Frequency Cepstral Coefficients (MFCCs) from voice signal commands, application of the Discrete Cosine Transform (DCT) in these coefficients, Support Vector Machine (SVM) training optimized by the Particle Swarm Optimization (PSO) technique in order to speed up the whole process and using One Against All (OAA) multiclass SVM classification. The main contribution is in training phase that it is the combination of SVM with PSO algorithm, resulting in computational load and processing time reduction. This novel algorithm is called here as PSO-SVM hybrid training application and its performance is shown as the experimental results of voice signal commands in Brazilian Portuguese language. Such commands comprise 10 isolated digits (from zero to nine) and 20 action commands such as "go ahead", "finish", "pause", etc.; that is, there are 30 different pattern types (classes) to be separated (recognized). The process is speaker independent type, that is, the voice bank used in training is different from the one used in tests. The obtained results presented success rates of 92% to 99% during the tests for the classifier using RBF kernel function. Besides, the comparison section shows that this technique is 25 times faster than the recognition without optimization and also, it presents 10% of improvement in recognition success rate when compared to the well-known technique, Gaussian Mixture Models (GMM) algorithm. In addition, the proposed algorithm can be applied in any data processing board for voice signals (DSP, FPGA, DSPIC, ...).
C1 [Batista, Gracieth Cavalcanti; de Oliveira, Duarte Lopes; Saotome, Osamu] Technol Inst Aeronaut, 50 Vila Acacias, Sao Jose Dos Campos, SP, Brazil.
   [Silva, Washington Luis Santos] Fed Inst Maranhao, 4 Monte Castelo, Sao Luis, MA, Brazil.
C3 Comando-Geral de Tecnologia Aeroespacial (CTA); Instituto Tecnologico de
   Aeronautica (ITA); Instituto Federal do Maranhao
RP Batista, GC (corresponding author), Technol Inst Aeronaut, 50 Vila Acacias, Sao Jose Dos Campos, SP, Brazil.
EM gracieth.cavalcanti@gmail.com; washington.silva@ifma.edu.br
RI Batista, Gracieth/HGU-5412-2022
OI Batista, Gracieth/0000-0001-5259-3985
CR Aggarwal RK, 2012, INT J SPEECH TECHNOL, V15, P191, DOI 10.1007/s10772-012-9133-9
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   Ananthi S, 2014, INT C FRONT INT COMP, V327, P519
   [Anonymous], 2015, THESIS
   Batista GC, 2015, IEEE IJCNN
   Bernal-Chaves J., 2005, PROC IT R NONLINEAR, P137
   Bresolin A. A., 2008, RECONHECIMENTO VOZ A
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cao H, 2015, ELSEVIER JUORNAL BIO, V202, P158
   Chao CF, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/212719
   Cristianini N, 2002, AI MAG, V3, P23
   Dahake PP, 2016, INT C AUT CONTR DYN
   De-Gang C, 2008, IEEE P 7 INT C MACH, P12
   Ding CHQ, 2001, MULTICLASS PROTEIN F, V17
   Dong N, 2015, ACCIDENT ANAL PREV, V82, P192, DOI 10.1016/j.aap.2015.05.018
   Engelbrecht A. P., 2005, FUNDAMENTALS COMPUTA
   Engelbrecht A.P., 2007, Computational Intelligence: An Introduction, VSecond, DOI DOI 10.1002/9780470512517
   HAYKIN S, 2002, REDES NEURAIS PRINCI
   Kanisha B, 2018, PERS UBIQUIT COMPUT, V22, P1083, DOI 10.1007/s00779-018-1139-0
   Kennedy J, 1997, IEEE C SYST MAN CYB, V1
   Kennedy J., 2001, Swarm Intelligence
   KHEIRANDISH A, 2016, JOURNAL SCIENCEDIREC, V41, P1135, DOI DOI 10.1016/J.IJHYDENE.2016.04.043
   Kumar A, 2017, 4 IEEE UTT PRAD SECT
   Lazinica Aleksandar., 2009, PARTICLE SWARM OPTIM
   Manikandan J, 2011, MICROPROCESS MICROSY, V35, P568, DOI 10.1016/j.micpro.2011.06.002
   Manikandan J, 2009, I CONF VLSI DESIGN, P347, DOI 10.1109/VLSI.Design.2009.23
   Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016
   NAJKAR N, 2010, ELSEVIER JOURNAL MAT, V52, P1910, DOI DOI 10.1016/J.MCM.2010.03.041
   Nayyar Anand., 2018, Advances in swarm intelligence for optimizing problems in computer science, P53
   Parsopoulos KE, 2010, PARTICLE SWARM OPTIMIZATION AND INTELLIGENCE: ADVANCES AND APPLICATIONS, P1, DOI 10.4018/978-1-61520-666-7
   PICONE JW, 1993, P IEEE, V81, P1215, DOI 10.1109/5.237532
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Rocha PL, 2016, 2016 INT JOINT C NEU
   Scholkopf B., 1999, PRIOR KNOWLEDGE SUPP, V02
   Sheng HM, 2015, J POWER SOURCES, V281, P131, DOI 10.1016/j.jpowsour.2015.01.145
   SHIEH MY, 2014, APPLICATIONS OF PCA
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   Vapnik VN, 2015, UNIFORM CONVERGENCE, P11
   Wang S, 2017, ELSEVIER J SCHIZOPHR
   Ynoguti CA, 2008, 26 S BRAS TEL
   Zarrouk E, 2014, INT J SPEECH TECHNOL, V17, P223, DOI 10.1007/s10772-013-9221-5
   Zhang S, 2016, RECURRENT SUPPORT VE
   Zhang S.X., 2015, IEEE INT C AC SPEECH
   Zhang X, 2009, 5 INT C NAT COMP
NR 44
TC 1
Z9 1
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31709
EP 31731
DI 10.1007/s11042-019-07956-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000033
DA 2024-07-18
ER

PT J
AU Bin, JC
   Gardiner, B
   Liu, Z
   Li, E
AF Bin, Junchi
   Gardiner, Bryan
   Liu, Zheng
   Li, Eric
TI Attention-based multi-modal fusion for improved real estate appraisal: a
   case study in Los Angeles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real estate appraisal; Convolutional neural network; Multi-modal fusion;
   Boosted regression trees
ID REGRESSION; VALUATION; PRICE; MODEL; DETERMINANTS; NETWORK
AB The geographical presentation of a house, which refers to the sightseeing and topography near the house, is a critical factor to a house buyer. The street map is a type of common data in our daily life, which contains natural geographical presentation. This paper sources real estate data and corresponding street maps of houses in the city of Los Angeles. In the case study, we proposed an innovative method, attention-based multi-modal fusion, to incorporate the geographical presentation from street maps into the real estate appraisal model with a deep neural network. We firstly combine the house attribute features and street map imagery features by applying the attention-based neural network. After that, we apply boosted regression trees to estimate the house price from the fused features. This work explored the potential of attention mechanism and data fusion in the applications of real estate appraisal. The experimental results indicate the competitiveness of proposed method among state-of-the-art methods.
C1 [Bin, Junchi; Liu, Zheng] Univ British Columbia, Fac Appl Sci, Kelowna, BC V1V 1V7, Canada.
   [Gardiner, Bryan] Data Nerds, Kelowna, BC V1Y 6J6, Canada.
   [Li, Eric] Univ British Columbia, Fac Management, Kelowna, BC V1V 1V7, Canada.
C3 University of British Columbia; University of British Columbia
RP Liu, Z (corresponding author), Univ British Columbia, Fac Appl Sci, Kelowna, BC V1V 1V7, Canada.
EM junchibin@alumni.ubc.ca; zheng.liu@ubc.ca; eric.li@ubc.ca
RI Liu, Zheng/D-8678-2016
OI Liu, Zheng/0000-0002-7241-3483
FU Data Nerds [IT10011]; University of British Columbia (Okanagan)
   [IT10011]
FX This study was supported by Mitacs Accelerate Program (IT10011) through
   the collaboration between Data Nerds and the University of British
   Columbia (Okanagan). The authors present the appreciation to Fang Shi,
   Shuo Liu (University of British Columbia), Dr. Huan Liu (China
   University of Geosciences) and Kaiqi Zhang (AECOM New York) for the
   precious discussion when the work was carried out.
CR [Anonymous], 2018, NEURAL COMPUT APPL
   [Anonymous], 1995, The Journal of Real Estate Research, v
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], 2018, P 27 INT JOINT C ART
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], THESIS
   [Anonymous], P 11 ACM INT C WEB S
   [Anonymous], EST PROP REP
   [Anonymous], THESIS
   [Anonymous], 2015 IEEE C COMP VIS
   [Anonymous], 2017, 2017 IEEE C COMP VIS
   [Anonymous], OP
   [Anonymous], 2015, INT C LEARN REPR
   Antipov EA, 2012, EXPERT SYST APPL, V39, P1772, DOI 10.1016/j.eswa.2011.08.077
   Bency AJ, 2017, IEEE WINT CONF APPL, P320, DOI 10.1109/WACV.2017.42
   Bessinger Z, 2016, IEEE IMAGE PROC, P4388, DOI 10.1109/ICIP.2016.7533189
   Bidanset PE, 2014, CITYSCAPE, V16, P169
   Bin JC, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P209, DOI 10.1109/CIAPP.2017.8167209
   Cao JM, 2020, MULTIMED TOOLS APPL, V79, P2837, DOI 10.1007/s11042-019-08467-3
   Cetkovic J, 2018, COMPLEXITY, DOI 10.1155/2018/1472957
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chollet F, 2015, KERAS
   Crosby H., 2015, P 1 INT ACM SIGSPATI, P32
   Demetriou D, 2017, ENVIRON PLAN B-URBAN, V44, P864, DOI 10.1177/0265813516652115
   Dubey A, 2016, LECT NOTES COMPUT SC, V9905, P196, DOI 10.1007/978-3-319-46448-0_12
   Fan GZ, 2006, URBAN STUD, V43, P2301, DOI 10.1080/00420980600990928
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gebru T, 2017, P NATL ACAD SCI USA, V114, P13108, DOI 10.1073/pnas.1700035114
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graczyk M, 2010, LECT NOTES ARTIF INT, V5991, P340, DOI 10.1007/978-3-642-12101-2_35
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kauko T.J., 2002, Modelling the locational determinants of house prices: neural network and value tree approaches
   Kingma D. P., 2014, arXiv
   Kuhn M., 2018, APPL PREDICTIVE MODE
   Lasota T, 2009, LECT NOTES ARTIF INT, V5796, P776
   Liu XB, 2018, IEEE T KNOWL DATA EN, V30, P1496, DOI 10.1109/TKDE.2018.2791611
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ordonez V, 2014, LECT NOTES COMPUT SC, V8694, P494, DOI 10.1007/978-3-319-10599-4_32
   Park B, 2015, EXPERT SYST APPL, V42, P2928, DOI 10.1016/j.eswa.2014.11.040
   Salesses P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068400
   Selim H, 2009, EXPERT SYST APPL, V36, P2843, DOI 10.1016/j.eswa.2008.01.044
   Sirmaçek B, 2010, PATTERN RECOGN LETT, V31, P1155, DOI 10.1016/j.patrec.2009.09.018
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun FD, 2019, MULTIMED TOOLS APPL, V78, P30793, DOI 10.1007/s11042-018-6591-3
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wilson ID, 2002, KNOWL-BASED SYST, V15, P335, DOI 10.1016/S0950-7051(01)00169-1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yiorkas C, 2017, PROC SPIE, V10444, DOI 10.1117/12.2280255
   You QZ, 2017, IEEE T MULTIMEDIA, V19, P2751, DOI 10.1109/TMM.2017.2710804
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhou Y, 2019, NEURAL COMPUT APPL, V31, P1855, DOI 10.1007/s00521-017-3162-x
NR 58
TC 17
Z9 17
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31163
EP 31184
DI 10.1007/s11042-019-07895-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000009
DA 2024-07-18
ER

PT J
AU Wang, Y
   Luo, XB
   Ding, L
   Wu, JJ
   Fu, S
AF Wang, Yong
   Luo, Xinbin
   Ding, Lu
   Wu, Jingjing
   Fu, Shan
TI Robust visual tracking via a hybrid correlation filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Correlation filter based tracking; Global filter; Local filter; Gaussian
   curvature; Peak-to-sidelobe ratio
ID OBJECT TRACKING; CONTEXT
AB In this paper, we propose a hybrid correlation filter based tracking method which depends on coupled interactions between a global filter and two local filters. Specifically, a local kernel feature with Gaussian curvature is developed to encode object appearance. Then the global filter and the two local filters independently track the target. The peak-to-sidelobe ratio (PSR) is employed to measure the reliability of the tracking results. Next, the global filter and the two local filters jointly determine the target position. In this way, the proposed hybrid model deals well with challenging situations, e.g., partial occlusion and scale changes. Experiments on large benchmark datasets show that our method performs favorably against state-of-the-art trackers.
C1 [Wang, Yong; Ding, Lu; Fu, Shan] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai, Peoples R China.
   [Wang, Yong] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
   [Luo, Xinbin] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Wu, Jingjing] Jiangnan Univ, Sch Mech Engn, Wuxi, Jiangsu, Peoples R China.
C3 Shanghai Jiao Tong University; University of Ottawa; Shanghai Jiao Tong
   University; Jiangnan University
RP Luo, XB (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM losinbin@sjtu.edu.cn
RI Ding, Lu/AAJ-2179-2020; Wang, Zejun/KBB-8454-2024; TIAN,
   YI/KHU-9704-2024
FU National Natural Science Foundation of China [61305016]; Fundamental
   Research Funds for the Central Universities [JUSRP1059]
FX This paper is jointly supported by the National Natural Science
   Foundation of China (61305016) and Fundamental Research Funds for the
   Central Universities (GrantNo.JUSRP1059). We thank the anonymous editor
   and reviewers for their careful reading and many insightful comments and
   suggestions.
CR [Anonymous], 2016, ECCV
   [Anonymous], EUR C COMP VIS WORKS
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2012, ECCV
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255
   Bolme David S, 2010, IEEE COMP SOC C COMP
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Elsey M, 2009, MULTISCALE MODEL SIM, V7, P1549, DOI 10.1137/080736612
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2014, IEEE T PATTERN ANAL, V36, P1428, DOI 10.1109/TPAMI.2013.213
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lee SH, 2005, IEEE T IMAGE PROCESS, V14, P904, DOI 10.1109/TIP.2005.849294
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lu HC, 2012, IEEE T CIRC SYST VID, V22, P1365, DOI 10.1109/TCSVT.2012.2201794
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235
   Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Sui Y, 2015, IEEE I CONF COMP VIS, P3002, DOI 10.1109/ICCV.2015.344
   Tang PQ, 2014, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MANAGEMENT AND ENGINEERING (CME 2014), P1107
   Tian XH, 2011, IEEE ICC
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wang Y, 2018, MULTIMED TOOLS APPL, V77, P31447, DOI 10.1007/s11042-018-6198-8
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Xu Y, 2013, NEUROCOMPUTING, V113, P168, DOI 10.1016/j.neucom.2013.01.036
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang TZ, 2015, PROC CVPR IEEE, P150, DOI 10.1109/CVPR.2015.7298610
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 51
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31633
EP 31648
DI 10.1007/s11042-019-07851-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000030
DA 2024-07-18
ER

PT J
AU Zhong, J
   Zhang, P
   Li, X
AF Zhong, Jiang
   Zhang, Pan
   Li, Xue
TI Adaptive recognition of different accents conversations based on
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Combined feature; Speaker segmentation; Accent classification; Speech
   recognition
ID SPEAKER DIARIZATION; SEGMENTATION
AB In this paper, an adaptive recognition of different accents conversations is proposed based on Convolutional Neural Network(CNN), which is used to deal with dialogue speech recognition problems that contain different accents in the CALL_CENTER environment. For the first time, the Mel-Frequency Cepstral Coefficients (MFCC) feature and the SPECTROGRAM feature are combined as the input of CNN to train the speakers' voice feature model and to estimate the change point. Then, an accent classification method based on weighted fusion feature is proposed, and we introduced the IFLY voice recognition system to propose different accent dialogue recognition models based on speaker segmentation. In the experiments, a real database about the dialogue voice related to insurance sales and real estate sales industry is used to be dataset. After a comparative experiment, the results show that the word error rate for speech recognition after speaker segmentation and accent classification was reduced by 20% compared to the original speech recognition word error rate.
C1 [Zhong, Jiang; Zhang, Pan] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
   [Zhong, Jiang] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.
   [Zhang, Pan] China United Network Commun Co Ltd, Xian Branch, Xian 710065, Shaanxi, Peoples R China.
   [Li, Xue] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
C3 Chongqing University; Chongqing University; China United Network
   Communications Limited; University of Queensland
RP Zhang, P (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.; Zhang, P (corresponding author), China United Network Commun Co Ltd, Xian Branch, Xian 710065, Shaanxi, Peoples R China.
EM zhangpan220@foxmail.com
OI LI, Xue/0000-0002-4515-6792
FU National Key Research and Development Program of China [2017YFB1402400];
   National High Technology Research and Development Program of China
   [2015AA015308]; Social Undertakings and Livelihood Security Science and
   Technology Innovation Funds of CQ CSTC [cstc2017shmsA0641]; National
   Nature Science Foundation of China [61762025]
FX The authors acknowledge the National Key Research and Development
   Program of China (Grant No.2017YFB1402400), National High Technology
   Research and Development Program of China (Grant: 2015AA015308), Social
   Undertakings and Livelihood Security Science and Technology Innovation
   Funds of CQ CSTC (Grant: cstc2017shmsA0641), the National Nature Science
   Foundation of China (Grant: 61762025).
CR Ajmera J, 2004, IEEE SIGNAL PROC LET, V11, P649, DOI 10.1109/LSP.2004.831666
   [Anonymous], 1998, P DARPA BROADC NEWS
   Arslan LM, 1996, COMMUNICATION
   Bakis Raimo., 1997, Proceedings of the Speech Recognition Workshop, P67
   Barras C, 2006, IEEE T AUDIO SPEECH, V14, P1505, DOI 10.1109/TASL.2006.878261
   Bonastre JF, 2000, INT CONF ACOUST SPEE, P1177
   Cettolo M, 2005, COMPUT SPEECH LANG, V19, P147, DOI 10.1016/j.csl.2004.05.008
   COLE RA, 1979, J ACOUST SOC AM, V65, pS81, DOI 10.1121/1.2017457
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Delacourt P, 2000, SPEECH COMMUN, V32, P111, DOI 10.1016/S0167-6393(00)00027-3
   Deller Jr JR, 2000, DISCRETE TIME PROCES
   GISH H, 1991, INT CONF ACOUST SPEE, P873, DOI 10.1109/ICASSP.1991.150477
   Jin H., 1997, PROC, P108
   Kadri H, 2008, 2008 16 EUR SIGN PRO, P1
   지승은, 2016, [Journal of the Korea Institute Of Information and Communication Engineering, 한국정보통신학회논문지], V20, P471, DOI 10.6109/jkiice.2016.20.3.471
   Mammone RJ, 1996, IEEE SIGNAL PROC MAG, V13, P58, DOI 10.1109/79.536825
   Mingliang q Yuguo X, 2008, P 2008 9 INT C SIGN, P1608
   Pedersen C., 2007, 6 IEEE ACIS INT C CO
   Quatieri T.F., 2006, Discrete-Time Speech Signal Processing: Principles and Practice, V1st
   Resnick MC, 1976, HISPANIA, V59, P969
   Resnick MC, 1980, PHONOLOGICAL VARIANT
   Resnick MelvynC., 1969, HISPANIA, V52, P553
   Reynolds DA, 1994, IEEE T SPEECH AUDI P, V2, P639, DOI 10.1109/89.326623
   Saeidi R, 2007, INT CONF ACOUST SPEE, P305
   Sell G, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3096
   Siegler M.A., 1997, P DARPA SPEECH REC W
   Speer S.R., 2003, P 15 INT C PHONETIC, P95
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Tranter SE, 2006, IEEE T AUDIO SPEECH, V14, P1557, DOI 10.1109/TASL.2006.878256
   Ullah S., 2007, C INF EM TECHN ICIET
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Zhang W., 2016, P INT JOINT C ART IN, P2153
   Zhong J, 2017, ADV MULTIMEDIA INFOR, P550
   Zue V. W., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P1197
NR 41
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30749
EP 30767
DI 10.1007/s11042-018-6590-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200061
DA 2024-07-18
ER

PT J
AU Hassanin, AAIM
   Abd El-Samie, FE
   El Banby, GM
AF Hassanin, Abdel-Aziz I. M.
   Abd El-Samie, Fathi E.
   El Banby, Ghada M.
TI A real-time approach for automatic defect detection from PCBs based on
   SURF features and morphological operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Printed Circuit Boards; Feature extraction; SURF; Morphological
   operations
ID FAULT-DETECTION; IMAGE
AB This paper presents an automatic inspection approach for Printed Circuit Boards (PCBs) with accurate determination of the fault location and identification of the fault type. This approach depends on several digital image processing techniques including registration, filtering, foreground segmentation, mathematical morphological operations, subtraction, feature extraction, and component matching. The Speeded Up Robust Feature extraction (SURF) technique is used for two purposes: registration of the PCB to be checked to a reference PCB and detection of feature points of each missing component on the PCB that is localized from the subtraction process from the reference PCB. Operation is performed on the hue component of the color PCB images. A dictionary is first built for all possible components on the available PCBs with SURF feature descriptors, and hence if a missing item is detected on a PCB during the inspection process, the SURF feature descriptors for features extracted from the difference between the tested and reference PCBs at the position of the lost component are matched with those in the built dictionary or database. A distance metric is used in the matching process. The importance of the proposed approach lies in its ability to build a dictionary of feature descriptors for all possible components in a diversity of PCBs and its ability to localize and identify the missing components regardless of the PCB position, rotation, or type. All operations are formulated in a Graphical User Interface (GUI) using MATLAB environment.
C1 [Hassanin, Abdel-Aziz I. M.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
   [El Banby, Ghada M.] Menoufia Univ, Fac Elect Engn, Dept Ind Elect & Control Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP El Banby, GM (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Ind Elect & Control Engn, Menoufia 32952, Egypt.
EM abdel_aziz_hassanin@hotmail.com; fathi_sayed@yahoo.com;
   ghada.elbanby@el-eng.menofia.edu.eg
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518
CR Al-Obaidy F, 2017, MICROELECTRON RELIAB, V71, P56, DOI 10.1016/j.microrel.2017.02.013
   Alam F, 2018, BIOCYBERN BIOMED ENG, V38, P71, DOI 10.1016/j.bbe.2017.10.001
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chauhan V, 2015, PROCEDIA MANUF, V1, P416, DOI 10.1016/j.promfg.2015.09.051
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hu HJ, 2016, NEUROCOMPUTING, V181, P86, DOI 10.1016/j.neucom.2015.05.134
   Kumar Y, 2017, INT J ENG RES TECHNO, V6
   Liu MF, 2017, COMPUT VIS IMAGE UND, V163, P58, DOI 10.1016/j.cviu.2017.04.012
   Maitre H, 2008, IMAGE PROCESSING
   Malik F, 2013, J KING SAUD UNIV-COM, V25, P207, DOI 10.1016/j.jksuci.2012.11.004
   Muthugnanambika M., 2017, INT CONF ADVAN COMPU
   Nayak JPR, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT), P742
   Nerakae P, 2016, PROCEDIA COMPUT SCI, V96, P437, DOI 10.1016/j.procs.2016.08.090
   Pedersen JT, 2011, STUDY GROUP SURF FEA, pQ4
   Putera S. H. Indera, 2010, 2010 2nd International Conference on Education Technology and Computer (ICETC 2010), P359, DOI 10.1109/ICETC.2010.5530052
   Putera SH, 2012, MATLAB BASED DEFECT, P115
   Raj R, 2016, PROCEDIA COMPUT SCI, V93, P375, DOI 10.1016/j.procs.2016.07.223
   Soliman RF, 2018, APPL OPTICS, V57, P10305, DOI 10.1364/AO.57.010305
   Wei P., 2018, J LATEX CLASS FILES, V14, P1
   Zhang F, 2017, OPTIK, V144, P642, DOI 10.1016/j.ijleo.2017.07.002
NR 21
TC 34
Z9 35
U1 5
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34437
EP 34457
DI 10.1007/s11042-019-08097-9
EA OCT 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000492236300002
DA 2024-07-18
ER

PT J
AU Chuang, JC
   Hu, YC
   Chen, CM
   Lin, YH
   Chen, Y
AF Chuang, Jun-Chou
   Hu, Yu-Chen
   Chen, Chia-Mei
   Lin, Yu-Hsiu
   Chen, Yu
TI Joint index coding and reversible data hiding methods for color image
   quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Color image quantization; Palette design;
   Lossless index coding
ID AUTHENTICATION SCHEME
AB In this paper, we proposed two reversible data hiding methods for color image quantization based on lossless index coding. In index coding process, the indices are classified into three types: Type-1, Type-2, and Type-3 according to the relationship between the current index and its neighbors in lossless index coding. In the first method, Type-1 indices are taken to hide secret bits. To increase the hiding capacities, not only Type-1 indices but also Type-2 indices are used to embed secret bits in the second method. The experimental results show that the proposed methods achieve high hiding capacities while keeping acceptable compression bit rates. The required bit rates of the proposed methods are less than those of the uncompressed indices. The index table of each color quantized image can be recovered without any distortion after the hidden data has been extracted. Experimental results reveal that the first method is suitable for the applications that the required embedding ratio is less than or equal to 0.5 bit/index. For applications requiring a higher embedding ratio, the second method can be used to embed the secret data. The embedding ratio of the second method can be up to 0.98 bit/index.
C1 [Chuang, Jun-Chou] Providence Univ, Dept Comp Sci & Commun Engn, 200,Sect 7 Taiwan Blvd, Taichung 43301, Taiwan.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200,Sect 7,Taiwan Blvd, Taichung 43301, Taiwan.
   [Chen, Chia-Mei] Natl Sun Yat Sen Univ, Dept Informat Management, 70 Lienhai Rd, Kaohsiung 80424, Taiwan.
   [Lin, Yu-Hsiu] Ming Chi Univ Technol, Dept Elect Engn, 84 Gungjuan Rd, New Taipei 24301, Taiwan.
   [Chen, Yu] Fujian Univ Technol, Sch Informat Sci & Engn, 1 33 Xuefu South Rd, Fuzhou 350118, Fujian, Peoples R China.
C3 Providence University - Taiwan; Providence University - Taiwan; National
   Sun Yat Sen University; Ming Chi University of Technology; Fujian
   University of Technology
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200,Sect 7,Taiwan Blvd, Taichung 43301, Taiwan.
EM lzchung@pu.edu.tw; ychu@pu.edu.tw; cmchen@mis.nsysu.edu.tw;
   yhlin@mail.mcut.edu.tw; cheny@fjut.edu.cn
RI Lin, Yu-Hsiu/AAD-8974-2020; Hu, Yu-Chen/AAT-5264-2020; Hui,
   Yu/JOZ-3598-2023
OI Hu, Yu-Chen/0000-0002-5055-3645; Lin, Yu-Hsiu/0000-0002-1407-2262
FU Ministry of Science and Technology, Taiwan, R.O.C.
   [106-2410-H-126-006-MY2, 108-2410-H-126-020-MY2]
FX This research was partially supported by the Ministry of Science and
   Technology, Taiwan, R.O.C. under contracts 106-2410-H-126-006-MY2 and
   108-2410-H-126-020-MY2.
CR Celebi ME, 2015, J REAL-TIME IMAGE PR, V10, P329, DOI 10.1007/s11554-012-0291-4
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   Chang IC, 2015, SIGNAL PROCESS, V108, P376, DOI 10.1016/j.sigpro.2014.09.036
   Chen KN, 2018, DEVICE CIRC SYST, P185
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Hu YC, 2008, IMAGING SCI J, V56, P68, DOI 10.1179/174313107X214231
   Hu YC, 2012, OPTO-ELECTRON REV, V20, P159, DOI 10.2478/s11772-012-0023-0
   Hu YC, 2011, OPTO-ELECTRON REV, V19, P282, DOI 10.2478/s11772-011-0025-3
   Hu YC, 2012, IMAGING SCI J, V60, P54, DOI 10.1179/1743131X11Y.0000000007
   Hu YC, 2009, IMAGING SCI J, V57, P46, DOI 10.1179/174313109X373675
   Hu YC, 2006, PATTERN RECOGN, V39, P1715, DOI 10.1016/j.patcog.2006.02.005
   Hu YC, 2017, MULTIMED TOOLS APPL, V76, P15435, DOI 10.1007/s11042-016-3847-7
   Hu YC, 2016, FUTURE GENER COMP SY, V62, P92, DOI 10.1016/j.future.2016.04.001
   Hu YC, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762241
   Kim DS, 2018, J REAL-TIME IMAGE PR, V14, P137, DOI 10.1007/s11554-015-0548-9
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Michael T., 1991, IEEE T SIGNAL PROCES, V39, P2677
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Yang CN, 2018, J REAL-TIME IMAGE PR, V14, P147, DOI 10.1007/s11554-015-0555-x
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Yu YH, 2005, PATTERN RECOGN, V38, P691, DOI 10.1016/j.patcog.2004.11.006
   Zhang W, 2019, J REAL-TIME IMAGE PR, V16, P697, DOI 10.1007/s11554-018-0811-y
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 32
TC 8
Z9 9
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35537
EP 35558
DI 10.1007/s11042-019-08193-w
EA OCT 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000495416800001
DA 2024-07-18
ER

PT J
AU Parashar, A
   Upadhyay, AK
   Gupta, K
AF Parashar, Amrita
   Upadhyay, Arvind Kumar
   Gupta, Kamlesh
TI An effectual classification approach to detect copy-move forgery using
   support vector machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Classification; Forgery detection; Learning systems
ID EFFICIENT
AB The growing need of digital software and media deals with the tampering of numerous multimedia data for mischievous determinations in case of broadcasting approaches. The supreme collective procedure of tampering linked with digital descriptions is copy-move forgery system that deals with a portion of duplicate image and replaced in diverse locations. Therefore, forensic authorities require consistent and effective means of sensing such maliciously forged data. Following study recommends a learning method for the detection of forgery. The image segmentation is the first step, in which the histogram of angled slopes is functional to every block followed by feature extraction; and concentrated to enable the dimension of resemblance. The detection is done using Support vector machines. The results establish that the projected process is intelligent to perceive various instances of copy-move forgery which are able to detect the duplicate regions.
C1 [Parashar, Amrita; Upadhyay, Arvind Kumar] Amity Univ Madhya Pradesh, Amity Sch Engn & Technol, Gwalior, India.
   [Gupta, Kamlesh] Rustamji Inst Technol RJIT, Gwalior, Madhya Pradesh, India.
RP Parashar, A (corresponding author), Amity Univ Madhya Pradesh, Amity Sch Engn & Technol, Gwalior, India.
EM amritaparashar05@gmail.com
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], COMOFOD DATABASE
   [Anonymous], 2010, International Journal on Computer Science and Engineering
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Dalal N., 2005, P IEEE COMPUTER SOC
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Fridrich J., 1999, P ACM WORKSH MULT SE, P19
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Luo W., 2009, FRONT COMPUT SCI CHI, V1, P308
   Luo WQ, 2006, INT C PATT RECOG, P746
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
NR 21
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29413
EP 29429
DI 10.1007/s11042-018-6707-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700055
DA 2024-07-18
ER

PT J
AU Wei, W
   Fan, XL
   Song, HB
   Wang, HH
AF Wei, Wei
   Fan, Xunli
   Song, Houbing
   Wang, Huihui
TI Video tamper detection based on multi-scale mutual information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video tampering; Similarity measure; Normalized mutual information;
   Gaussian pyramid
ID NAVIGATION; FORGERY
AB Video frame manipulation has become commonplace with the growing easy access to powerful computing abilities. One of the most common types of video frame tampers is the copy-paste tamper, wherein a region from a video frame is replaced with another region from the same frame. In order to improve the robustness of passive video tampering detection, we propose a content-based video similarity tamper passive blind detection algorithm based on multi-scale normalized mutual information which can implement video frame copy, frame insertion and frame deletion tamper detection. The detail implementation of the proposed algorithm consists of multi-scale content analysis, single-scale content similarity measure, multi-scale content similarity measure, and tampering positioning. Firstly, we get the scales of the visual content of the video frame using Gaussian pyramid transform; Secondly, to measure the similarity of single-scale visual content, we define adjacent normalized mutual information of two frames according to information theory; Thirdly, we construct the multi-scale normalized mutual information descriptors to achieve the multi-scale visual content similarity measure of adjacent two frames using a linear combination. Finally, we use the local outlier isolated factor detection algorithm to detect the position of the video tampering. Experimental results show that the proposed approach can not only detect the video frame tampering position of delete, copy, and insert effectively, but also can detect the tampering of different and homology video encoding formats. We obtain a feature detecting accuracy in excess of 93% and detection rate of 96% across post processing operations, and are able to detect the delete, copy, and insert regions with a high true positive rate and lower false positive rate than the existing time field tamper detection methods.
C1 [Wei, Wei] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Wei, Wei] Key Lab Comp Vis & Pattern Recognit Xiamen City, Xiamen, Fujian, Peoples R China.
   [Fan, Xunli] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
   [Song, Houbing] West Virginia Univ, Dept Elect & Comp Engn, Montgomery, WV 25136 USA.
   [Wang, Huihui] Jacksonville Univ, Dept Engn, 2800 Univ Blvd N, Jacksonville, FL 32211 USA.
C3 Xi'an University of Technology; Northwest University Xi'an; Jacksonville
   University
RP Fan, XL (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
EM weiwei@xaut.edu.cn; xunlfan@nwu.edu.cn; Houbing.Song@mail.wvu.edu;
   hwang1@ju.edu
RI song, hu/JVO-3838-2024; wei, wei/HHR-8613-2022; wei, wei/IQW-1347-2023;
   Song, Houbing Herbert/E-3628-2010; Wei, Wei/ABB-8665-2021; Yin,
   Jing/KDO-6274-2024; Wang, Huihui/ABB-6935-2021
OI Song, Houbing Herbert/0000-0003-2631-9223; Wei, Wei/0000-0002-8751-9205;
   Wang, Huihui/0000-0002-4098-5313
FU Shaanxi Provincial Education Department [2013JK1139]; China Postdoctoral
   Science Foundation [2013M542370]; Specialized Research Fund for the
   Doctoral Program of Higher Education of China [20136118120010]; NSFC
   [11301414, 61472318, 11226173]; Open Program of Xiamen Key Laboratory of
   Computer Vision and Pattern Recognition, Huaqiao University
   [600005-Z17X0001]
FX This job is supported by Scientific Research Program Funded by Shaanxi
   Provincial Education Department (Program No. 2013JK1139) and Supported
   by China Postdoctoral Science Foundation (No. 2013M542370) and the
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China (Grant No. 20136118120010). And this project is also supported
   by NSFC Grant (Program No. 11301414 and No. 61472318 and No. 11226173)
   and by the Open Program of Xiamen Key Laboratory of Computer Vision and
   Pattern Recognition, Huaqiao University(600005-Z17X0001).
CR [Anonymous], 2005, EUR C INF RETR
   [Anonymous], J SHANDONG U ENG SCI
   [Anonymous], ARXIV13023119
   [Anonymous], MATH PROBLEMS ENG
   Ardizzone E, 2009, INT C IM AN PROC
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Chen YD, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-0957-4
   Conotter V, 2012, IEEE T INF FOREN SEC, V7, P283, DOI 10.1109/TIFS.2011.2165843
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dong Q, 2012, DIGIT INVEST, V9, P151, DOI 10.1016/j.diin.2012.07.002
   Farid H., 2009, Image forgery detection-a survey
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Hyun DK, 2013, SENSORS-BASEL, V13, P12605, DOI 10.3390/s130912605
   Kakar P, 2010, 2010 IEEE INT C IEEE
   Kobayashi M., 2009, PAC RIM S IM VID TEC
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Liu Y, 2012, INT C PATT RECOG, P898
   Luming Z, 2013, IEEE C COMP VIS PATT, P1820
   Math S, 2011, TRANSPORT RES REC, P10, DOI 10.3141/2232-02
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Qin Y, 2009, J COMPUTER RES DEV S, P227
   Qiu GP, 2007, PATTERN RECOGN, V40, P1711, DOI 10.1016/j.patcog.2006.09.020
   Su YT, 2010, INT J PATTERN RECOGN, V24, P1027, DOI 10.1142/S0218001410008317
   [同鸣 Tong Ming], 2012, [电子与信息学报, Journal of Electronics & Information Technology], V34, P1819
   Wang W., 2006, P 8 WORKSH MULT SEC
   Wang W, 2000, P 9 WORKSH MULT SEC
   Wei W, 2018, IEEE T SERV COMPUT, V11, P78, DOI 10.1109/TSC.2016.2528246
   Wei W, 2011, SENSORS-BASEL, V11, P4794, DOI 10.3390/s110504794
   Wu JS, 2016, IEEE SYST J, V10, P888, DOI 10.1109/JSYST.2016.2550530
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xing Ling, 2013, Journal of University of Electronic Science and Technology of China, V42, P260, DOI 10.3969/j.issn.1001-0548.2013.02.016
   Xu Jilin, 2013, JIN DAI SI XIANG SHI, V10, P1
   Yuan X., 2012, COMPUT SYST APPL, V21, P91
   Zhan W, 2008, J SE U, V38, P13
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 45
TC 61
Z9 64
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27109
EP 27126
DI 10.1007/s11042-017-5083-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000015
DA 2024-07-18
ER

PT J
AU Chakraborty, D
   Chakraborty, A
   Banerjee, A
   Chaudhuri, SRB
AF Chakraborty, D.
   Chakraborty, A.
   Banerjee, A.
   Chaudhuri, S. R. Bhadra
TI A unified block-based sparse domain solution for quasi-periodic
   de-noising from different genres of images with iterative filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periodic; quasi-periodic noise; Adaptive natural image modelling;
   Kaiser-Window; Adaptive thresholding; Butterworth smoothing profile;
   Recursive notch-reject filter
ID REMOVAL; RESTORATION; STATISTICS; ARTIFACTS; SPACE
AB Images, corresponding to various crucial imagery applications often experience stern problem of being degraded by different modalities of periodic/quasi-periodic noises. Though few periodic denoising algorithms address well for some specific application only, most of them fail to focus on the problem as a whole. In this article, a unified solution is presented which performs well for most of the vital non-natural imagery applications having dissimilar modalities. Initially, we divide the corrupted image into several blocks and then average those to get an averaged spatial image block. This block gets convolved with the Kaiser-Window to avoid any unnecessary artifacts followed by the spectral domain transformation. Our proposed algorithm relies on steadily decreasing characteristic of any uncorrupted natural image's power spectra to expect a model by grossly reducing induced noise. An image feature based adaptive threshold is then applied on error spectra to precisely perceive unexpectedly high spectral amplitudes as the outliers. It is then interpolated to the actual size of the corrupted image, containing noisy spectra on which a proposed recursively adaptive notch-reject filter is applied. Extensive and detailed study of performance comparison with other state-of-the-art algorithms proves the supremacy of our proposed strategy.
C1 [Chakraborty, D.; Chakraborty, A.; Banerjee, A.; Chaudhuri, S. R. Bhadra] IIEST, Dept Elect & Telecommun Engn, Sibpur, Howrah, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Chakraborty, D (corresponding author), IIEST, Dept Elect & Telecommun Engn, Sibpur, Howrah, India.
EM debolina.chkpanja@gmail.com
OI CHAKRABORTY, ANIRBAN/0000-0003-4398-0777
CR Aizenberg I, 2002, P SOC PHOTO-OPT INS, V4667, P181, DOI 10.1117/12.467980
   Aizenberg I, 2008, IMAGE VISION COMPUT, V26, P1347, DOI 10.1016/j.imavis.2007.08.011
   Al Hudhud GA, 2005, IEEE SIGNAL PROC LET, V12, P573, DOI 10.1109/LSP.2005.851257
   Al-Najjar YAY., 2012, Int J Sci Eng Res, V3, P1
   [Anonymous], 1987, REMOTE SENSING IMAGE
   [Anonymous], 2002, INT TICSP WORKSH SPE
   [Anonymous], INF COMM SIGN PROC I
   [Anonymous], ADV SIGNAL PROCESSIN
   [Anonymous], 2006, Remote Sensing: Models and Methods for Image Processing
   [Anonymous], 2012, DIGITAL TRANSMISSION
   [Anonymous], INT J SCI ENG TECHNO
   [Anonymous], INT J EMERG TECHNOL
   [Anonymous], INT C BIOINF BIOM EN
   Blieberger J, 1996, REAL-TIME SYST, V11, P115, DOI 10.1007/BF00365315
   Chakraborty D, 2016, AEU-INT J ELECTRON C, V70, P1580, DOI 10.1016/j.aeue.2016.09.003
   Chang Y, 2015, IEEE T IMAGE PROCESS, V24, P1852, DOI 10.1109/TIP.2015.2404782
   Chu Y, 2006, TENCON IEEE REGION, P16
   Cornelis B, 2017, IEEE T IMAGE PROCESS, V26, P160, DOI 10.1109/TIP.2016.2621413
   Cornelis B, 2012, SIGNAL PROCESS, V92, P1166, DOI 10.1016/j.sigpro.2011.11.012
   Eaton P.J., 2014, Atomic force microscopy
   Fehrenbach J, 2012, IEEE T IMAGE PROCESS, V21, P4420, DOI 10.1109/TIP.2012.2206037
   Giglio L, 2006, J GEOPHYS RES-BIOGEO, V111, DOI 10.1029/2005JG000142
   GUTTMAN N, 1963, J ACOUST SOC AM, V35, P610, DOI 10.1121/1.1918551
   Ji TY, 2007, SIGNAL PROCESS, V87, P2799, DOI 10.1016/j.sigpro.2007.05.024
   Ketenci S, 2012, INT S INN INT SYST A, P1, DOI DOI 10.1109/INISTA.2012.6246937
   KINNEY JH, 1992, ANNU REV MATER SCI, V22, P121, DOI 10.1146/annurev.ms.22.080192.001005
   Konstantinidis AC, 2010, NUCL INSTRUM METH A, V620, P549, DOI 10.1016/j.nima.2010.03.138
   Koukou V, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/574238
   Lau D. L., 2002, US Patent, Patent No. [6,493,112, 6493112]
   Mnih V., 2012, P 29 INT C MACH LEAR, P567
   Moallem P, 2015, SIGNAL IMAGE VIDEO P, V9, P1179, DOI 10.1007/s11760-013-0560-0
   Moallemi P., 2010, AUT J ELECT ENG, V42, P1, DOI [10.22060/EEJ.2010.94, DOI 10.22060/EEJ.2010.94]
   Pitas I., 2013, The Springer International Series in Engineering and Computer Science
   Puschner P, 2000, REAL-TIME SYST, V18, P115, DOI 10.1023/A:1008119029962
   Reichelt R., 2007, SCAN ELECTRON MICROS, P133, DOI [10.1007/978-0-387-49762-4_3, DOI 10.1007/978-0-387-49762-4_3]
   RINDFLEISCH TC, 1971, J GEOPHYS RES, V76, P394, DOI 10.1029/JB076i002p00394
   SCHUBERT PC, 1986, APPL OPTICS, V25, P3880, DOI 10.1364/AO.25.003880
   Sur F, 2015, IEEE IMAGE PROC, P3841, DOI 10.1109/ICIP.2015.7351524
   Sur F, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013003
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   vanderSchaaf A, 1996, VISION RES, V36, P2759, DOI 10.1016/0042-6989(96)00002-8
   Varghese J, 2016, AEU-INT J ELECTRON C, V70, P1692, DOI 10.1016/j.aeue.2016.10.008
   Varghese J, 2016, IET IMAGE PROCESS, V10, P646, DOI 10.1049/iet-ipr.2015.0750
   Varghese J, 2016, CAN J ELECT COMPUT E, V39, P82, DOI 10.1109/CJECE.2015.2490598
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei ZP, 2012, MICRON, V43, P170, DOI 10.1016/j.micron.2011.07.009
   Wilford J, 2002, LANDSAT THEMATIC MAP, P6
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
NR 48
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26759
EP 26785
DI 10.1007/s11042-019-7502-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700066
DA 2024-07-18
ER

PT J
AU Al-Harasis, R
   Sababha, BH
AF Al-Harasis, Raghad
   Sababha, Belal H.
TI On the design and implementation of a dual fisheye camera-based
   surveillance vision system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Barrel distortion correction; Real-time image processing; Panorama image
   stitching; Wide-angle view; Fisheye camera
ID MODEL
AB Image processing and computer vision have been a focus of researchers for decades in various application domains. This research is continuously rising with the rise of Artificial Intelligence in the fourth industrial revolution. One of the important digital image processing applications is to produce panorama images. The wide range of view a panorama image provides can be used in a variety range of applications which may include surveillance applications and remote robot operations. A panorama image is a combination of several individual natural looking images into a composite one to provide a wide field of view that may reach 360 degrees horizontally without any distortion. Wide-angle lenses provide a wide field of view, but using them alone does not necessarily make a panorama image. In this work the design and implementation of a wide-angle stereo vision system that suites many real-time applications is proposed. The system makes use of two wide-angle fisheye cameras where each camera covers around 170 degrees field of view. The horizontal angle between the cameras is 140 degrees. The cameras acquire the instantaneous overlapping images continuously and transmits them to a base station via a communication link. The base station calibrates, corrects, correlates and stitches the non-overlapping corrected images to a composite one. The resultant final image covers 310 degrees field of view. The system is of low computational complexity compared with previously implemented systems. It is tested on a laptop and on a standalone embedded computing device. The processing speed for the panorama image stitching including the correction of the fisheye barrel distortion on the laptop computer and the embedded computer is 11 fps, and 6 fps, respectively.
C1 [Al-Harasis, Raghad] Princess Sumaya Univ Technol, Elect Engn Dept, Amman 11941, Jordan.
   [Sababha, Belal H.] Princess Sumaya Univ Technol, Comp Engn Dept, Amman 11941, Jordan.
C3 Princess Sumaya University for Technology; Princess Sumaya University
   for Technology
RP Sababha, BH (corresponding author), Princess Sumaya Univ Technol, Comp Engn Dept, Amman 11941, Jordan.
EM bsababha@ieee.org
RI Sababha, Belal/GRX-3582-2022
OI Sababha, Belal/0000-0001-8586-2352
CR Abughalieh KM, 2019, MULTIMED TOOLS APPL, V78, P9149, DOI 10.1007/s11042-018-6508-1
   Abughalieh KM, 2018, MULTIMED TOOLS APPL, P1, DOI 10.1007/s11042-018-6508-1
   Bechar A, 2017, BIOSYST ENG, V153, P110, DOI 10.1016/j.biosystemseng.2016.11.004
   BELLAS N, 2009, FIELD PROGR CUST COM
   Bellas N, 2009, ROB SENS ENV ROSE 20
   Chira IM, 2010, COMPUTER ENG
   Chira IM, 2010, ICCES'2010: THE 2010 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS, P158, DOI 10.1109/ICCES.2010.5674844
   Fan D-P, 2018, MECH AUT 2007 ICMA 2
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan D, 2018, PR INT PIPELINE CONF
   Gao L-F, 2007, IEEE RSJ INT C INT R
   Gao W, 2017, ARXIV170805922V1
   Ho T, 2017, CONS EL ICCE 2015 IE
   Kim H, 2015, IEEE INT C CONS EL I
   Liu T-M, 2017, SICE ANN C 2007 TAK
   Mathworks, 2009, INTERPOLATION METHOD
   Morrow H, 2002, U. S. Patent Patent, Patent No. [6,459,451, 6545701]
   Nishimoto T., 2007, MECH MECATRONICS 17
   Polydoros AS, 2017, J INTELL ROBOT SYST, V86, P153, DOI 10.1007/s10846-017-0468-y
   Rawashdeh NA, 2017, J VIB CONTROL, V23, P827, DOI 10.1177/1077546315586492
   Rawashdeh O., 2011, COMPUTER TECHNOLOGY, V2, P85
   RAWASHDEH OA, 2009, ASME 2009 INT DES EN
   Ray LA, 2000, U. S. Patent Patent, Patent No. [6,023,588, 6459451]
   RAY LA, 2000, Patent No. 6023588
   Sababha Belal H., 2015, International Journal of Mechatronics and Automation, V5, P107
   Sababha B. H., 2015, INT J MECHATRON AUTO, V5, p[107, 113], DOI 10.1504/IJMA.2015.075956
   Semwal VB, 2013, P 12 EUR SIGN PROC C
   SEMWAL VB, 2013, CONTR AUT ROB EMB SY
   SEMWAL VB, 2017, MISP 2017
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2016, IEEE SENS J, V16, P5805, DOI 10.1109/JSEN.2016.2570281
   Semwal VB, 2015, ROBOT AUTON SYST, V70, P181, DOI 10.1016/j.robot.2015.02.009
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Semwal VB, 2015, ROBOT AUTON SYST, V63, P122, DOI 10.1016/j.robot.2014.09.001
   Silva LC, 2004, VEHICULAR ELECTRONIC
   Sinclair MJ, 2003, US Patent Patent, Patent No. [6,545,701 B2, 7215364]
   Wachtel RA, 2007, INTERPOLATION METHOD, Patent No. 7,215,364
   Wang WQ, 2015, IEEE T CIRC SYST VID, V25, P1696, DOI 10.1109/TCSVT.2015.2397196
   Wei J, 2012, IEEE T VIS COMPUT GR, V18, P1771, DOI 10.1109/TVCG.2011.130
   Zhang B, 2015, COMP DES APPL ICCDA
   ZHANG B, 2015, MECH AUT ICMA 2015 I
NR 41
TC 3
Z9 3
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22667
EP 22689
DI 10.1007/s11042-019-7501-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400022
DA 2024-07-18
ER

PT J
AU Azamian, M
   Kabir, E
AF Azamian, Mohammadali
   Kabir, Ehsanollah
TI Synthesizing the note-specific atoms based on their fundamental
   frequency, used for single-channel musical source separation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Musical source separation; Audio signal processing; Note-specific atom;
   Sine-harmonic model; Fundamental frequency
ID NONNEGATIVE MATRIX FACTORIZATION; AUDIO SOURCE SEPARATION; MELODY
   EXTRACTION
AB The musical source separation deals with extracting the musical signals from a mixture. To attain this goal, one of the efficient methods is to decompose the mixture into a dictionary of some basic functions that inherently describe the instruments. Usually, a unique function is synthesized for each of the notes of each instrument, called the note-specific atom. In this paper, a sine-harmonic model is utilized to synthesize note-specific atoms and the note's fundamental frequency is used as a prior information to determine the model parameters. To calculate these parameters, the training signal spectrum is processed only around the main note harmonics. Experimental results demonstrated that the proposed method is much faster in note-specific atoms synthesis, without decreasing the source separation quality and can also eliminate the single-frequency noise from training signals.
C1 [Azamian, Mohammadali] Islamic Azad Univ, Khomeinishahr Branch, Daneshju Blvd, Khomeinishahr, Esfahan, Iran.
   [Kabir, Ehsanollah] Tarbiat Modares Univ, Dept Elect & Comp Engn, Jalale Ale Ahmad Highway, Tehran, Iran.
C3 Islamic Azad University; Tarbiat Modares University
RP Azamian, M (corresponding author), Islamic Azad Univ, Khomeinishahr Branch, Daneshju Blvd, Khomeinishahr, Esfahan, Iran.
EM azamian@iaukhsh.ac.ir; kabir@modares.ac.ir
OI azamian, mohammadali/0000-0003-1155-2743
CR [Anonymous], P ISCA TUT RES WORKS
   Azamian M, 2017, ADV ELECTR COMPUT EN, V17, P103, DOI 10.4316/AECE.2017.02014
   Bertin N, 2010, IEEE T AUDIO SPEECH, V18, P538, DOI 10.1109/TASL.2010.2041381
   Brown JC, 2004, J ACOUST SOC AM, V115, P2295, DOI 10.1121/1.1698774
   Casey MA, 2000, P INT COMP MUS C GER
   Cho N, 2011, IEEE T AUDIO SPEECH, V19, P326, DOI 10.1109/TASL.2010.2047810
   Davies ME, 2007, SIGNAL PROCESSING, V87
   Durrieu JL, 2010, IEEE T AUDIO SPEECH, V18, P564, DOI 10.1109/TASL.2010.2041114
   Ewert Sebastian, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P649, DOI 10.1109/ICASSP.2014.6853676
   Ewert S, 2014, IEEE SIGNAL PROC MAG, V31, P116, DOI 10.1109/MSP.2013.2296076
   Ewert S, 2013, INT CONF ACOUST SPEE, P46, DOI 10.1109/ICASSP.2013.6637606
   Fitzgerald D, 2002, P DAFX GERM
   Fitzgerald D, 2003, P DAFX GERM
   Goto S, 2003, IEEE MTT-S, P229, DOI 10.1109/MWSYM.2003.1210922
   Grais EM, 2017, IEEE-ACM T AUDIO SPE, V25, P1469, DOI 10.1109/TASLP.2017.2716443
   Guo Y, 2011, IEEE INT C AC SPEECH
   Islam Molla MK, 2004, 3 INT C EL COMP ENG
   Jang GJ, 2003, IEEE SIGNAL PROC LET, V10, P168, DOI 10.1109/LSP.2003.811630
   Jao PK, 2016, IEEE-ACM T AUDIO SPE, V24, P2158, DOI 10.1109/TASLP.2016.2598323
   Kameoka H, 2015, INT CONF ACOUST SPEE, P86, DOI 10.1109/ICASSP.2015.7177937
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lefevre A., 2012, P INT SOC MUSIC INFO, P115
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ozerov A, 2011, INT CONF ACOUST SPEE, P257
   Phiwma N, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P85, DOI 10.1109/ICSAP.2010.8
   Salamon J, 2012, IEEE T AUDIO SPEECH, V20, P1759, DOI 10.1109/TASL.2012.2188515
   Schmidt MN, 2006, P INT
   Simsekli U, 2012, EUR SIGNAL PR CONF, P2639
   Smaragdis Paris, 2009, 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), P69, DOI 10.1109/ASPAA.2009.5346542
   Suits BH, 2015, FREQUENCIES EQUAL TE
   Ueda Y, 2010, INT CONF ACOUST SPEE, P5518, DOI 10.1109/ICASSP.2010.5495218
   UHLE C, 2003, 4 INT S IND COMP AN
   Virtanen T., 2000, THESIS
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   Wang L, 2016, IEEE-ACM T AUDIO SPE, V24, P1573, DOI 10.1109/TASLP.2016.2573048
   Xu YF, 2015, SIGNAL PROCESS, V106, P134, DOI 10.1016/j.sigpro.2014.07.012
   Yoshii Kazuyoshi, 2013, P INT SOC MUS INF RE, P369
   Zdunek R, 2013, COGN COMPUT, V5, P493, DOI 10.1007/s12559-012-9185-9
NR 38
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17929
EP 17948
DI 10.1007/s11042-018-7060-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200027
DA 2024-07-18
ER

PT J
AU Garain, J
   Kumar, RK
   Kisku, DR
   Sanyal, G
AF Garain, Jogendra
   Kumar, Ravi Kant
   Kisku, Dakshina Ranjan
   Sanyal, Goutam
TI Addressing facial dynamics using k-medoids cohort selection algorithm
   for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face biometric system; K-medoids clustering; Cohort score; Cohort
   subset; Cohort score normalization; Non-matched templates
ID SCORE NORMALIZATION; REPRESENTATION; CLASSIFICATION; ROBUST; MODEL
AB Face recognition is itself a very challenging task and it becomes more challenging when the input images have intra class variations and inter class similarities in a large scale. Yet the recognition accuracy can be improved in some extent by supporting the system with non-matched templates. Therefore a set of cohort images is used in this regard. But all the cohort templates of the initial cohort pool may not be relevant for each and every enrolled subject. So the main focus of this work is to select a subject specific and meaningful cohort subset. This paper proposes a cohort selection method called K-medoids Cohort Selection (KMCS) to select a reference set of non-matched templates which are almost appropriate to the respective subjects. Basically, all cohort scores of a subject are clustered first using K-medoids clustering. Afterward the cluster having more scattered members/scores from its medoid is selected as a cohort subset because this cluster is constituted with the cohorts carrying more discriminative features compared to others. The SIFT points and SURF points are extracted as facial feature. The experiments are conducted on FEI, ORL and Look-alike databases of face images. The matching scores between probe and query images are normalized using T-norm, Max-Min and Aggarwal (Max rule) cohort score normalization techniques before taking the final decision of acceptance or rejection. The results obtained from the experiments show the domination of the proposed system over the non-cohort face recognition system as well as random and Top 10 cohort selection methods. There is another comparative study between k-means and K-medoids clustering for cohort selection.
C1 [Garain, Jogendra; Kumar, Ravi Kant; Kisku, Dakshina Ranjan; Sanyal, Goutam] Natl Inst Technol Durgapur, Dept Comp Sci & Engn, Durgapur 713209, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Garain, J (corresponding author), Natl Inst Technol Durgapur, Dept Comp Sci & Engn, Durgapur 713209, W Bengal, India.
EM jogs.cse@gmail.com; vit.ravikant@gmail.com; drkisku@gmail.com;
   nitgsanyal@gmail.com
RI Kumar, Ravi Kant/AAH-2542-2020; Kisku, Dakshina Ranjan/E-1680-2013;
   SANYAL, GOUTAM/AAI-6613-2020
OI Kisku, Dakshina Ranjan/0000-0003-1116-2972; Garain,
   Jogendra/0000-0002-6201-8295
FU Digital India Corporation, Deity, Govt. of India
FX This work is funded by Digital India Corporation (formerly Media Lab
   Asia), Deity, Govt. of India.
CR Aggarwal G., 2006, Computer Vision and Pattern Recognition Workshop, P31
   Aggarwal G, 2008, INT CONF ACOUST SPEE, P5224, DOI 10.1109/ICASSP.2008.4518837
   Ahmad W, 2018, MULTIMED TOOLS APPL, V77, P8273, DOI 10.1007/s11042-017-4723-9
   [Anonymous], P BRIT MACH VIS C
   Auckenthaler R, 2000, DIGIT SIGNAL PROCESS, V10, P42, DOI 10.1006/dspr.1999.0360
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Dahmouni A, 2018, MULTIMED TOOLS APPL, P1
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Doll R, 2001, SOZ PRAVENTIV MED, V46, P75, DOI 10.1007/BF01299724
   Doll R, 2001, SOZ PRAVENTIV MED, V46, P152, DOI 10.1007/BF01324251
   Eickeler Stefan, 1999, 1999 European Control Conference (ECC). Proceedings, P3023
   Frost WH, 1939, AM J HYG, V30, P91, DOI 10.1093/oxfordjournals.aje.a118570
   Garain J., 2016, P AS C COMP VIS, P377
   Garain J, 2018, INT C COMP INT DAT S
   Garain J, 2018, 2 INT C DIG SIGN PRO
   Garain J, 2016, LECT NOTES COMPUT SC, V9730, P566, DOI 10.1007/978-3-319-41501-7_63
   Garain J, 2015, INT J SECUR APPL, V9, P263, DOI 10.14257/ijsia.2015.9.6.25
   Ghinea G, 2014, IEEE ACCESS, V2, P914, DOI 10.1109/ACCESS.2014.2348018
   Ghosh S, 2013, INT J ADV COMPUT SC, V4, P35
   Gomathi E., 2010, Proceedings of the 2nd International Conference on Machine Learning and Computing (ICMLC 2010), P198, DOI 10.1109/ICMLC.2010.48
   Grattan KTV, 2013, 2013 IEEE 6TH INTERNATIONAL CONFERENCE ON ADVANCED INFOCOMM TECHNOLOGY (ICAIT), P1, DOI 10.1109/ICAIT.2013.6621468
   Kramer RSS, 2018, COGNITION, V172, P46, DOI 10.1016/j.cognition.2017.12.005
   Kumar D, 2018, LECT NOTES ARTIF INT, V10956, P846, DOI 10.1007/978-3-319-95957-3_91
   Lam KM, 1998, IEEE T PATTERN ANAL, V20, P673, DOI 10.1109/34.689299
   Lamba H., 2011, IEEE International Joint Conference on Biometrics (IJCB), P1, DOI [DOI 10.1109/IJCB.2011.6117520, 10.1109/IJCB.2011.6117520]
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Li HX, 2018, IEEE T PATTERN ANAL, V40, P918, DOI 10.1109/TPAMI.2017.2695183
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   Liu J, 2018, MULTIMED TOOLS APPL, V77, P9055, DOI 10.1007/s11042-017-4805-8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Merati A., 2010, Biometrics: Theory Applications and Systems (BTAS), 2010 Fourth IEEE International Conference on, P1
   Merati A, 2012, IEEE T INFORM FORENS, V7
   Nefian AV, 1998, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.1998.678085
   Rakshit RD, 2018, EXPERT SYST APPL, V92, P82, DOI 10.1016/j.eswa.2017.09.038
   Rosenberg AE, 1992, 2 INT SPOK LANG PROC
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Schroff F, 2011, IEEE I CONF COMP VIS, P2494, DOI 10.1109/ICCV.2011.6126535
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Soldera J, 2015, IEEE T INSTRUM MEAS, V64, P2417, DOI 10.1109/TIM.2015.2415012
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tistarelli M, 2014, IEEE T INF FOREN SEC, V9, P2063, DOI 10.1109/TIFS.2014.2362007
   Tulyakov Sergey, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563105
   Wagner A., 2009, IEEE COMP SOC C COMP, V2, P3
   Wang W., 2015, LECT NOTES COMPUTER
   Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88
   Wolf L, 2009, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2009.5459323
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yang XH, 2018, SIGNAL PROCESS-IMAGE, V60, P64, DOI 10.1016/j.image.2017.09.006
   Yin Q, 2011, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2011.5995494
   ZADEH LA, 1988, COMPUTER, V21, P83, DOI 10.1109/2.53
NR 55
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18443
EP 18474
DI 10.1007/s11042-018-7132-9
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200050
DA 2024-07-18
ER

PT J
AU Gu, X
   Guo, JC
AF Gu, Xiangyuan
   Guo, Jichang
TI A study on Subtractive Pixel Adjacency Matrix features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SPAM features; Steganalysis; Feature selection; Spatial-domain
ID MUTUAL INFORMATION; STEGANALYSIS; SELECTION; STEGANOGRAPHY
AB Subtractive Pixel Adjacency Matrix (SPAM) features perform well in detecting spatial-domain steganographic algorithm. Further, some methods of SPAM features can be applied to rich models and steganalysis based on deep learning. Therefore, this paper presents a study on SPAM features and it is divided into two parts: in the first part, impact of spatial-domain steganographic on difference between adjacent pixels is first analyzed. Then, three SPAM features are proposed with the same range of differences and different orders of Markov chain. Following that, the influences of order of Markov chain and range of differences on SPAM features are analyzed, and we find that detection accuracy of SPAM features increases with the range of differences increasing; in the second part, SPAM feature is first divided into several modules according to the conclusion. Then, taking detection accuracy of support vector machine (SVM) classifier and mutual information as metrics and module as a unit, a Novel Feature Selection (NFS) algorithm and an Improved Feature Selection algorithm are proposed. Experimental results show that the NFS algorithm can achieve higher detection accuracy than several existing algorithms.
C1 [Gu, Xiangyuan; Guo, Jichang] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Guo, JC (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM gxiangyuan@tju.edu.cn; jcguo@tju.edu.cn
RI Guo, Jichang/GQY-5798-2022
OI Guo, Jichang/0000-0003-3130-1685
FU National Natural Science Foundation of China [61771334]
FX This work was supported by the National Natural Science Foundation of
   China (61771334).
CR Adeli A, 2018, APPL INTELL, V48, P1609, DOI 10.1007/s10489-017-0989-x
   Bennasar M, 2015, EXPERT SYST APPL, V42, P8520, DOI 10.1016/j.eswa.2015.07.007
   Cao WQ, 2017, MULTIMED TOOLS APPL, V76, P13221, DOI 10.1007/s11042-016-3751-1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chhikara RR, 2018, INT J MACH LEARN CYB, V9, P821, DOI 10.1007/s13042-016-0610-3
   Christaline JA, 2018, MULTIMED TOOLS APPL, V77, P13701, DOI 10.1007/s11042-017-4983-4
   Deng X., 2018, MULTIMED TOOLS APPL, P1
   Estévez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Feng GR, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.063020
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gao WF, 2018, PATTERN RECOGN, V79, P328, DOI 10.1016/j.patcog.2018.02.020
   Hamann CP, 2005, DERM CLIN BAS SCI, P27
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Hosseini HDM, 2015, COMPUTER SCI SOFTWAR
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Khelifi F, 2018, SIGNAL PROCESS, V148, P91, DOI 10.1016/j.sigpro.2018.02.016
   Li B, 2018, IEEE T INF FOREN SEC, V13, P1242, DOI 10.1109/TIFS.2017.2780805
   Liu QZ, 2008, INFORM SCIENCES, V178, P21, DOI 10.1016/j.ins.2007.08.007
   Liu QZ, 2008, PATTERN RECOGN, V41, P56, DOI 10.1016/j.patcog.2007.06.005
   Lu JC, 2014, DIGIT INVEST, V11, P57, DOI 10.1016/j.diin.2013.12.001
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Miche Y, 2006, LECT NOTES COMPUT SC, V4105, P49
   Mohammadi FG, 2017, J VIS COMMUN IMAGE R, V44, P214, DOI 10.1016/j.jvcir.2016.12.003
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Mohammadi FG, 2014, J INTELL FUZZY SYST, V27, P1445, DOI 10.3233/IFS-131111
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Wang PF, 2016, MULTIMED TOOLS APPL, V75, P2897, DOI 10.1007/s11042-015-2521-9
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Wu GS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2854
   Xie CH, 2011, SIGNAL PROCESS, V91, P877, DOI 10.1016/j.sigpro.2010.09.006
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yao C, 2017, IEEE T IMAGE PROCESS, V26, P5257, DOI 10.1109/TIP.2017.2733200
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zeng JS, 2018, IEEE T INF FOREN SEC, V13, P1200, DOI 10.1109/TIFS.2017.2779446
   Zou DK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1365, DOI 10.1109/ICME.2006.262792
NR 42
TC 7
Z9 7
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19681
EP 19695
DI 10.1007/s11042-019-7285-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800035
DA 2024-07-18
ER

PT J
AU Krobba, A
   Debyeche, M
   Selouani, SA
AF Krobba, Ahmed
   Debyeche, Mohamed
   Selouani, Sid-Ahmed
TI Multitaper chirp group delay Hilbert envelope coefficients for robust
   speaker verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; Multi-taper chirp group zeros-phase Hilbert
   envelope coefficients (MCGDZPHECs); Multi-taper Gammatone Hilbert
   envelope coefficients (MGHECs); Mean Hilbert envelope coefficients
   (MHECs); i-vetcor G-PLDA
ID PHASE SPECTRUM; RECOGNITION; FEATURES; NOISE; MFCC
AB In this paper, we propose two new feature extraction methods for robust automatic speaker verification under noisy conditions. The first method, called Multi-taper Gammatone Hilbert Envelope Coefficients (MGHECs), employs multi-taper magnitude spectra that offer considerable advantages for spectrum estimates. The second method, called Multi-taper Chirp Group Delay Zeros-Phase Hilbert Envelope Coefficients (MCGDZPHECs) based on multi-tapers phase spectral. The chirp group delay technique is used to estimate the vocal tract from the chirp Fourier transform phase. The performance evaluation of the proposed methods and their extended variants are carried out on NIST 2008 corpus under noisy conditions, using various noise SNR levels which are extracted from NOISEX-92. Experimental results show that the proposed methods provide better representation of speech spectrum. Moreover, we obtained a significant improvement in performance under noisy conditions when compared to conventional Mean Hilbert Envelope Coefficients (MHECs) feature extraction.
C1 [Krobba, Ahmed; Debyeche, Mohamed] Univ USTHB, Speech Commun & Signal Proc Lab, Algiers, Algeria.
   [Selouani, Sid-Ahmed] Univ Moncton, LARIHS Lab, Campus Shappaing, Moncton, NB, Canada.
C3 University Science & Technology Houari Boumediene; University of Moncton
RP Krobba, A (corresponding author), Univ USTHB, Speech Commun & Signal Proc Lab, Algiers, Algeria.
EM akrobba@usthb.dz; mdebyeche@usthb.dz; selouani@umcs.ca
CR Ajmera PK, 2013, COMPUT ELECTR ENG, V39, P550, DOI 10.1016/j.compeleceng.2012.05.011
   Al-Ali AKH, 2017, IEEE ACCESS, V5, P15400, DOI 10.1109/ACCESS.2017.2728801
   Alam MJ, 2013, SPEECH COMMUN, V55, P237, DOI 10.1016/j.specom.2012.08.007
   Alsteris LD, 2007, DIGIT SIGNAL PROCESS, V17, P578, DOI 10.1016/j.dsp.2006.06.007
   [Anonymous], 2012, PROC ASIA PACIFIC SI
   Apsingekar VR, 2011, SPEECH COMMUN, V53, P110, DOI 10.1016/j.specom.2010.07.001
   Asbai N, 2017, COMPUT ELECTR ENG, V62, P648, DOI 10.1016/j.compeleceng.2017.03.022
   Babadi B, 2014, IEEE T BIO-MED ENG, V61, P1555, DOI 10.1109/TBME.2014.2311996
   Banno H, 2001, INT CONF ACOUST SPEE, P3297, DOI 10.1109/ICASSP.2001.940363
   Bousquet PM, 2014, ODYSSEY, P41
   Bozkurt B, 2007, SPEECH COMMUN, V49, P159, DOI 10.1016/j.specom.2006.12.004
   Chang J, 2017, INT CONF ACOUST SPEE, P5415, DOI 10.1109/ICASSP.2017.7953191
   Chetouani M, 2009, PATTERN RECOGN, V42, P487, DOI 10.1016/j.patcog.2008.08.008
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Fedila M, 2015, INT CONF INTELL SYST, P347, DOI 10.1109/ISDA.2015.7489252
   Garcia-Romero D., 2011, INTERSPEECH
   HALDER SK, 2013, INT J INNOVATIVE TEC, V2
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Hasan T, 2013, IEEE T AUDIO SPEECH, V21, P842, DOI 10.1109/TASL.2012.2226161
   Hegde RM, 2007, IEEE T AUDIO SPEECH, V15, P190, DOI 10.1109/TASL.2006.876858
   Jeevan M, 2017, LECT NOTES ELECTR EN, V395, P85, DOI 10.1007/978-81-322-3592-7_9
   KANAGASUNDARAM A, 2012, SPEAK LANG REC WORKS
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1435, DOI 10.1109/TASL.2006.881693
   Kim C, 2016, IEEE-ACM T AUDIO SPE, V24, P1315, DOI 10.1109/TASLP.2016.2545928
   Kim S, 2008, ETRI J, V30, P89, DOI 10.4218/etrij.08.0107.0108
   Kinnunen T, 2013, INTERSPEECH, P3121
   Kinnunen T, 2013, INT CONF ACOUST SPEE, P7229, DOI 10.1109/ICASSP.2013.6639066
   Kinnunen T, 2012, IEEE T AUDIO SPEECH, V20, P1990, DOI 10.1109/TASL.2012.2191960
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Krobba A, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE AND SPEECH PROCESSING (ICNLSP), P9
   Li ZQ, 2016, MULTIMED TOOLS APPL, V75, P7391, DOI 10.1007/s11042-015-2660-z
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Meriem F, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P99, DOI 10.1109/SITIS.2014.111
   Ming J, 2007, IEEE T AUDIO SPEECH, V15, P1711, DOI 10.1109/TASL.2007.899278
   MURTHY HA, 1991, SIGNAL PROCESS, V22, P259, DOI 10.1016/0165-1684(91)90014-A
   Narendra K., 2017, INT J SPEECH TECHNOL, P1
   Paliwal K, 2011, SPEECH COMMUN, V53, P465, DOI 10.1016/j.specom.2010.12.003
   Pohjalainen J, 2014, IEEE SIGNAL PROC LET, V21, P1516, DOI 10.1109/LSP.2014.2339632
   Prieto GA, 2007, GEOPHYS J INT, V171, P1269, DOI 10.1111/j.1365-246X.2007.03592.x
   Rao KS, 2014, SPRBRIEF ELECT, P49, DOI 10.1007/978-3-319-07130-5_4
   Rao W, 2013, IEEE T AUDIO SPEECH, V21, P1012, DOI 10.1109/TASL.2013.2243436
   Ravindran Sourabh., 2006, STAT PERCEPTUAL AUDI, P48
   Recommendation G, 2003, 722 2 WID COD SPEECH
   Sadjadi S. O., 2013, Speech Lang. Process. Techn. Comm. Newsl, V1, P1
   Sadjadi SO, 2015, SPEECH COMMUN, V72, P138, DOI 10.1016/j.specom.2015.04.005
   Sadjadi SO, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1694
   Sadjadi SO, 2011, INT CONF ACOUST SPEE, P5448
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649
   Tabibi S, 2017, J NEUROSCI METH, V277, P63, DOI 10.1016/j.jneumeth.2016.12.004
   The NIST Year, 2008, SPEAK REC PLAN
   THOMSON DJ, 1982, P IEEE, V70, P1055, DOI 10.1109/PROC.1982.12433
   Varga A, 1992, NOISEX92 CDROM
   Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803
   Zhu DL, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P125
NR 54
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19525
EP 19542
DI 10.1007/s11042-019-7154-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800027
DA 2024-07-18
ER

PT J
AU Rathee, A
   Chhabra, JK
AF Rathee, Amit
   Chhabra, Jitender Kumar
TI Reusability in multimedia softwares using structural and lexical
   dependencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reusable; Component identification; Structural relation; Lexical
   relations
ID COMPONENT; SYSTEM
AB Software reuse focuses on developing software using reusability principles. Component Based Software Engineering (CBSE) is one of the approaches that support software reuse by utilizing reusable software components. Many approaches have been proposed in the literature to mine reusable components from existing object-oriented software. But, almost all of these approaches are dependent on the selection of third-party application software as clients. Therefore, this paper proposes a reusable component identification approach from the source-code of a singular object-oriented software system especially related to multimedia tools. The proposed approach is based on making use of two kinds of dependency relations among different software elements namely structural and lexical relations. These relations, help us to measure cohesion at the component level using two proposed cohesion metrics. The cohesion values are further used as objective functions in the multi-objective search-based evolutionary algorithm, namely NSGA-III to identify the set of reusable components as different clusters. The proposed approach is validated by applying it to six open source Java applications of different sizes and belonging to multimedia domains.
C1 [Rathee, Amit] Natl Inst Technol, Kurukshetra 136119, Haryana, India.
   [Chhabra, Jitender Kumar] Natl Inst Technol, Dept Comp Engn, Kurukshetra 136119, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; National Institute of Technology (NIT System);
   National Institute of Technology Kurukshetra
RP Rathee, A (corresponding author), Natl Inst Technol, Kurukshetra 136119, Haryana, India.
EM amit1983_rathee@rediffmail.com; jitenderchhabra@gmail.com
RI Rathee, Amit/AAJ-5526-2020; Chhabra, Jitender Kumar/A-1026-2016
OI Rathee, Amit/0000-0001-5335-3756; Chhabra, Jitender
   Kumar/0000-0002-2257-0982
CR Adjoyan S., 2014, The 26th International Conference on Software Engineering and Knowledge Engineering, Hyatt Regency, Vancouver, BC, Canada, July 1-3, 2013, P1
   Allen AA, 2016, PERS UBIQUIT COMPUT, V20, P209, DOI 10.1007/s00779-016-0904-1
   Allier S, 2011, 2011 9TH WORKING IEEE/IFIP CONFERENCE ON SOFTWARE ARCHITECTURE (WICSA), P214, DOI 10.1109/WICSA.2011.35
   Allier S, 2010, LECT NOTES COMPUT SC, V6092, P216, DOI 10.1007/978-3-642-13238-4_13
   Alshara Z, 2016, ACM SIGPLAN NOTICES, V51, P55, DOI [10.1145/2936314.2814223, 10.1145/2814204.2814223]
   [Anonymous], 2003, ALAN APT SERIES
   [Anonymous], TECH REP
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2018, IEEE Transactions on Cybernetics
   [Anonymous], 2018, ARXIV180306235
   Chardigny S, 2008, SEVENTH WORKING IEEE/IFIP CONFERENCE ON SOFTWARE ARCHITECTURE, PROCEEDINGS, P285, DOI 10.1109/WICSA.2008.44
   Darvas A, 2016, 2016 13TH WORKING IEEE/IFIP CONFERENCE ON SOFTWARE ARCHITECTURE (WICSA), P109, DOI 10.1109/WICSA.2016.22
   Deb K, 2014, IEEE T EVOLUT COMPUT, V18, P577, DOI 10.1109/TEVC.2013.2281535
   Frakes WB, 2005, IEEE T SOFTWARE ENG, V31, P529, DOI 10.1109/TSE.2005.85
   Frenzel P, 2007, 14TH WORKING CONFERENCE ON REVERSE ENGINEERING, PROCEEDINGS, P160, DOI 10.1109/WCRE.2007.28
   Garcia J, 2013, IEEE INT CONF AUTOM, P486, DOI 10.1109/ASE.2013.6693106
   Hamza HS, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P813, DOI 10.1109/ITNG.2009.276
   Kebir S., 2012, 2012 Joint Working IEEE/IFIP Conference on Software Architecture (WICSA 2012) & European Conference on Software Architecture (ECSA 2012), P181, DOI 10.1109/WICSA-ECSA.212.26
   López-Fernández L, 2017, MULTIMED TOOLS APPL, V76, P14247, DOI 10.1007/s11042-016-3729-z
   Md Jubair Basha N., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P599
   Minovic M, 2013, MULTIMED TOOLS APPL, V63, P927, DOI 10.1007/s11042-011-0964-1
   Mishra SK, 2009, J OBJECT TECHNOL, V8, P133, DOI 10.5381/jot.2009.8.5.a3
   Mkaouer W, 2015, ACM T SOFTW ENG METH, V24, DOI 10.1145/2729974
   Nierstrasz O., 1995, Object-Oriented Software Composition, P3
   Parashar A, 2019, INT ARAB J INF TECHN, V16, P98
   Rathee A, 2018, PROCEDIA COMPUT SCI, V125, P740, DOI 10.1016/j.procs.2017.12.095
   Saied MA, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P23, DOI 10.1109/SANER.2015.7081812
   Salman HE, 2017, J SYST SOFTWARE, V130, P42, DOI 10.1016/j.jss.2017.05.039
   Shatnawi Anas, 2014, Software Reuse for Dynamic Systems in the Cloud and Beyond 14th International Conference on Software Reuse, ICSR 2015. Proceedings: LNCS 8919, P17, DOI 10.1007/978-3-319-14130-5_2
   Shatnawi Anas, 2013, 2013 IEEE 14th International Conference on Information Reuse & Integration (IRI), P193, DOI 10.1109/IRI.2013.6642472
   Shatnawi A, 2017, J SYST SOFTWARE, V131, P442, DOI 10.1016/j.jss.2016.06.101
   von Detten M, 2014, SOFTW SYST MODEL, V13, P1239, DOI 10.1007/s10270-013-0341-9
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 34
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20065
EP 20086
DI 10.1007/s11042-019-7382-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800052
DA 2024-07-18
ER

PT J
AU Han, B
   Zhang, LX
   Gao, XB
AF Han, Bing
   Zhang, Lixia
   Gao, Xinbo
TI The region based MMTD energy function for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph cuts; Measure of medium truth degree; Local information; Spatial
   distance measure
ID LEVEL SET METHOD; FITTING ENERGY; EVOLUTION; MINIMIZATION; DRIVEN
AB This paper presents a region-based model based on measure of medium truth degree for image segmentation. Firstly, a new energy function based on measure of medium truth degree is constructed. To enhance the robustness against noise, a noise penalty term which is built by spatial distance measure is embedded to the conventional active contour energy function. Then local information is added to the internal and external energy term of the conventional active contour energy function to deal with intensity inhomogeneity images. Finally, to obtain more accurate and smoother boundary, a new stop function is introduced into the boundary smooth term of the conventional active contour energy function. Experiments results demonstrate that relatively complete and accurate boundaries can be obtained by the proposed model compared with the state-of-art methods on aurora images, images with intensity inhomogeneity, images with multi-objects, natural images, medical images.
C1 [Han, Bing; Zhang, Lixia; Gao, Xinbo] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Gao, XB (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM xbgao@mail.xidian.edu.cn
RI Han, Bing/AHA-9806-2022; Gao, Xinbo/Q-8622-2016
OI Gao, Xinbo/0000-0003-1443-0776
FU National Natural Science Foundation of China [U1605252, 41031064,
   61572384, 61432014]; National Key Research and Development Program of
   China [2016QY01W0200]; China's postdoctoral fund first-class funding
   [2014M560752]; Shanxi province postdoctoral science fund; ShanXi Key
   Technologies Research Program [2017KW-017]; central university basic
   scientific research business fee [JBG150225]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1605252, in part by the National Key
   Research and Development Program of China under Grant 2016QY01W0200, the
   National Natural Science Foundation of China(41031064; 61572384;
   61432014), China's postdoctoral fund first-class funding (2014M560752),
   Shanxi province postdoctoral science fund, the central university basic
   scientific research business fee (JBG150225), ShanXi Key Technologies
   Research Program(2017KW-017).
CR Ali H, 2018, IEEE T IMAGE PROCESS, V27, P3729, DOI 10.1109/TIP.2018.2825101
   Andersson T, 2013, IEEE T IMAGE PROCESS, V22, P621, DOI 10.1109/TIP.2012.2220148
   [Anonymous], IEEE INT C MULT EXP
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cao CG, 2009, PATTERN RECOGN, V42, P607, DOI 10.1016/j.patcog.2008.08.018
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan T.F., 2001, Active contours without edges, P266
   Chowdhury K, 2017, MULTIMED TOOLS APPL, V1, P1
   Ciesielski KC, 2012, J MATH IMAGING VIS, V44, P375, DOI 10.1007/s10851-012-0333-3
   El-Zehiry N, 2007, PROCEEDINGS OF THE SEVENTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P182
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gao XB, 2011, IEEE T SYST MAN CY B, V41, P518, DOI 10.1109/TSMCB.2010.2065800
   Gelas A, 2007, IEEE T IMAGE PROCESS, V16, P1873, DOI 10.1109/TIP.2007.898969
   Germany GA, 1998, GEOPHYS RES LETT, V25, P3043, DOI 10.1029/98GL01220
   Goldstein GB, 1973, AEROSPACE ELECT SYST, VAES-9, P84, DOI [10.1109/TAES.1973.309705, DOI 10.1109/TAES.1973.309705]
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Heath M, 2000, P DIG MAMM, P431
   Hung CC, 2003, IEEE SOUTHEASTCON
   Jaccard P., 1901, B SOCIT VAUDOISE SCI, V37, P547, DOI [10.5169/seals-266440, DOI 10.5169/SEALS-266440]
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li LH, 2013, 2013 INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND MANAGEMENT SCIENCE (ICIEMS 2013), P748
   Li X, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P594, DOI 10.1109/ITCC.2004.1286718
   Lin YM, 2018, MICROBIOLOGYOPEN, V7, DOI 10.1002/mbo3.616
   Ouyang C, 2007, BEIJING BIOMEDICAL E
   Rad AE, 2017, MULTIMED TOOLS APPL, V76, P2185, DOI 10.1007/s11042-015-3196-y
   Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763
   Song ML, 2010, IEEE T PATTERN ANAL, V32, P1537, DOI 10.1109/TPAMI.2009.74
   Suckling J, 1994, INT C
   TORR MR, 1995, SPACE SCI REV, V71, P329, DOI 10.1007/BF00751335
   Vicente JJ, 2008, BMC MICROBIOL, V8, DOI 10.1186/1471-2180-8-1
   VICKERY BC, 1979, J LIBR, V11, P237, DOI 10.1177/096100067901100306
   Wujia Z, 1985, NATURE J, V8, P315
   XIAO X, 1988, SCI CHINA SER A, V31, P1320
   Yang T, 2011, INT C INF SCI TECHN, P643
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   Yang X, 2014, INFORM SCIENCES, V277, P794, DOI 10.1016/j.ins.2014.03.014
   Yang X, 2014, IEEE T IMAGE PROCESS, V23, P2854, DOI 10.1109/TIP.2014.2321506
   Zhou NN, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/690349
   Zhou Y, 2015, NEUROCOMPUTING, V156, P199, DOI 10.1016/j.neucom.2014.12.061
NR 46
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16695
EP 16726
DI 10.1007/s11042-018-7001-6
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500043
DA 2024-07-18
ER

PT J
AU Noura, H
   Chehab, A
   Noura, M
   Couturier, R
   Mansour, MM
AF Noura, Hassan
   Chehab, Ali
   Noura, Mohamad
   Couturier, Raphael
   Mansour, Mohammad M.
TI Lightweight, dynamic and efficient image encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Avalanche effect; Chosen plain; cipher text attacks; Lightweight and
   dynamic cipher scheme; Security; Performance analysis
ID CIPHER; CHAOS; PERFORMANCE
AB Recently, there has been a growing attention for Chaos-based image encryption algorithms. This class of algorithms relies on embedded chaotic maps to ensure a high security level with minimal performance overhead. One such algorithm, which we refer to as NCIES, was proposed recently, and the authors claimed that the algorithm achieves the required cryptographic properties with just a single round. In this paper, we first assess the performance of the NCIES cipher and we show that a single round is not enough for this cipher to ensure the desired cryptographic properties. In this context, we describe how such a cipher is vulnerable to a chosen plaintext/ciphertext attack. Next, we propose a new lightweight dynamic key-dependent cipher scheme that can address and overcome the issues identified in the NCIES cipher and other recent lightweight image encryption schemes. The proposed cipher is designed in a way to achieve a good balance between the latency, the required resources, and the security level when compared to recent chaotic image cipher schemes.
C1 [Noura, Hassan; Chehab, Ali; Mansour, Mohammad M.] Amer Univ Beirut, Elect & Comp Engn Dept, Maroun Semaan Fac Engn & Architecture, Beirut, Lebanon.
   [Noura, Mohamad; Couturier, Raphael] UBFC, Comp Sci, Belfort, France.
C3 American University of Beirut
RP Couturier, R (corresponding author), UBFC, Comp Sci, Belfort, France.
EM hassan.noura@aub.edu.lb; raphael.couturier@univ-comte.fr;
   mohamad.noura@univ-comte.fr
RI Noura, Hassan/U-8729-2018; Couturier, Raphaël/C-1095-2013
OI Couturier, Raphaël/0000-0003-1490-9592; Chehab, Ali/0000-0002-1939-2740;
   Noura, Hassan/0000-0002-2589-5053
FU Maroun Semaan Faculty of Engineering and Architecture at the American
   University of Beirut; EIPHI Graduate School [ANR-17-EURE-0002]
FX This paper is partially supported with funds from the Maroun Semaan
   Faculty of Engineering and Architecture at the American University of
   Beirut and also from the EIPHI Graduate School (contract
   "ANR-17-EURE-0002").
CR Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Alajel KM, 2010, 2010 4 INT C SIGN PR, P1
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   [Anonymous], 2017, NISTIR8114
   [Anonymous], 2010, 2010 6 IR C MACH VIS
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2013, PROC INT S SECURITY
   Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Beaulieu R, 2015, IACR CRYPTOLOGY EPRI, V585
   Biham E, 1993, DIFFERENTIAL CRYPTAN, V28
   Borghoff J, 2012, LECT NOTES COMPUT SC, V7658, P208, DOI 10.1007/978-3-642-34961-4_14
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   du Prel JB, 2009, DTSCH ARZTEBL INT, V106, P335, DOI 10.3238/arztebl.2009.0335
   Dworkin M., 2016, NIST Special Publication, V800, p38G
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Feng Huang, 2009, Frontiers of Electrical and Electronic Engineering in China, V4, P5, DOI 10.1007/s11460-009-0016-z
   Flayh NA, 2009, 2009 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES, P32, DOI 10.1109/MSPCT.2009.5164167
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Granjal J, 2015, IEEE COMMUN SURV TUT, V17, P1294, DOI 10.1109/COMST.2015.2388550
   Gueron S, 2009, LECT NOTES COMPUT SC, V5665, P51, DOI 10.1007/978-3-642-03317-9_4
   Guo J, 2011, LECT NOTES COMPUT SC, V6917, P326, DOI 10.1007/978-3-642-23951-9_22
   Gutub A, 2017, COUNTING BASED SECRE, P1
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Hong D, 2014, LECT NOTES COMPUT SC, V8267, P3, DOI 10.1007/978-3-319-05149-9_1
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Janakiraman S, 2018, MICROPROCESS MICROSY, V56, P1, DOI 10.1016/j.micpro.2017.10.013
   Koo BW, 2006, CONSTRUCTING 32 X32, P51
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Kumar M, 2014, IACR CRYPTOLOGY EPRI, V326
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Li CQ, 2011, INT J BIFURCAT CHAOS, V21, P2067, DOI 10.1142/S0218127411029641
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Noura H, 2014, COMPUT NETW, V75, P99, DOI 10.1016/j.comnet.2014.09.013
   O'Melia S, 2010, IEEE T VLSI SYST, V18, P1505, DOI 10.1109/TVLSI.2009.2025171
   Paar C., 2009, UNDERSTANDING CRYPTO
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Rubio-González C, 2009, ACM SIGPLAN NOTICES, V44, P270, DOI 10.1145/1543135.1542506
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Shibutani K, 2011, LECT NOTES COMPUT SC, V6917, P342, DOI 10.1007/978-3-642-23951-9_23
   Shujiang Xu, 2008, 2008 International Conference on Computational Intelligence and Security, P433, DOI 10.1109/CIS.2008.146
   Suzaki T., 2013, P INT C SEL ARE CRYP, V7707, P339
   Tang Dan, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P193, DOI 10.1109/CSSE.2008.220
   Tong XJ, 2009, OPT COMMUN, V282, P2722, DOI 10.1016/j.optcom.2009.03.075
   VanVoorhis CRW, 2007, TUTOR QUANT METHODS, V3, P43, DOI 10.20982/tqmp.03.2.p043
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wu WL, 2011, LECT NOTES COMPUT SC, V6715, P327, DOI 10.1007/978-3-642-21554-4_19
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 54
TC 18
Z9 18
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16527
EP 16561
DI 10.1007/s11042-018-7000-7
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500036
DA 2024-07-18
ER

PT J
AU Shao, J
   Zhao, ZC
   Su, F
AF Shao, Jie
   Zhao, Zhicheng
   Su, Fei
TI Two-stage deep learning for supervised cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-stage; 3-view; Reconstruct loss; Center loss; Contrastive loss
ID REPRESENTATION; IMAGES; RANK
AB This paper deals with the problem of modeling internet images and associated texts for cross-modal retrieval such as text-to-image retrieval and image-to-text retrieval. Recently, supervised cross-modal retrieval has attracted increasing attention. Inspired by a typical two-stage method, i.e., semantic correlation matching(SCM), we propose a novel two-stage deep learning method for supervised cross-modal retrieval. Limited by the fact that traditional canonical correlation analysis (CCA) is a 2-view method, the supervised semantic information is only considered in the second stage of SCM. To maximize the value of semantics, we expand CCA from 2-view to 3-view and conduct supervised learning in both stages. In the first learning stage, we embed 3-view CCA into a deep architecture to learn non-linear correlation between image, text and semantics. To overcome over-fitting, we add the reconstruct loss of each view into the loss function, which includes the correlation loss of every two views and regularization of parameters. In the second stage, we build a novel fully-convolutional network (FCN), which is trained by joint supervision of contrastive loss and center loss to learn better features. The proposed method is evaluated on two publicly available data sets, and the experimental results show that our method is competitive with state-of-the-art methods.
C1 [Shao, Jie; Zhao, Zhicheng; Su, Fei] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.
   [Zhao, Zhicheng; Su, Fei] Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Zhao, ZC (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.; Zhao, ZC (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing, Peoples R China.
EM shaojielyg@163.com; zhaozc@bupt.edu.cn; sufei@bupt.edu.cn
FU Chinese National Natural Science Foundation [61532018, 61471049]; Key
   Laboratory of Forensic Marks, Ministry of Public Security of China
FX This work is supported by Chinese National Natural Science
   Foundation(61532018, 61471049), and Key Laboratory of Forensic Marks,
   Ministry of Public Security of China.
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], 2003, P ACM INT C MULT ACM
   [Anonymous], 1987, PARALLEL DISTRIBUTED
   [Anonymous], 2011, P ICML
   [Anonymous], 2012, INT C MACH LEARN WOR
   [Anonymous], 2004, Advances in Neural Information Processing Systems
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   [Anonymous], CROSS MODAL SIMILARI
   [Anonymous], 2014, ACM INT C MULTIMEDIA
   Cai J, 2016, NEUROCOMPUTING, V182, P322, DOI 10.1016/j.neucom.2015.12.039
   CHEN L, 2015, VISUAL COMMUNICATION, P9, DOI DOI 10.1109/BIGMM.2015.90
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Feng FX, 2015, NEUROCOMPUTING, V154, P50, DOI 10.1016/j.neucom.2014.12.020
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2018, GROUP PAIR CONVOLUTI
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hinton GE, 2009, INT C NEURAL INF PRO, P1607
   Huang X, 2017, CROSS MODAL DEEP MET
   Nie WZ, 2016, MULTIMEDIA SYST, V22, P75, DOI 10.1007/s00530-014-0394-9
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Shao J, 2016, NEUROCOMPUTING, V214, P618, DOI 10.1016/j.neucom.2016.06.047
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Sun SL, 2010, NEUROCOMPUTING, V73, P2980, DOI 10.1016/j.neucom.2010.07.007
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3
   Wu F., 2013, P ACM INT C MULT, P877
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang R, 2018, TRAC-TREND ANAL CHEM, V99, P1, DOI 10.1016/j.trac.2017.11.015
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zu C, 2016, NEUROCOMPUTING, V191, P263, DOI 10.1016/j.neucom.2016.01.053
NR 47
TC 7
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16615
EP 16631
DI 10.1007/s11042-018-7068-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500040
DA 2024-07-18
ER

PT J
AU Singh, R
   Kushwaha, AKS
   Srivastava, R
AF Singh, Roshan
   Kushwaha, Alok Kumar Singh
   Srivastava, Rajeev
TI Multi-view recognition system for human activity based on multiple
   features for video surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; General framework; Features extraction;
   Local binary patterns; Optical flow features; Hidden Markov models
ID CLASSIFICATION
AB Recognition of the activities of human, image sequences is most active area of research in computer vision and most of the previous projects, the focus of the activity is to acknowledge the recognition, from a single view and ignored issues of multiple view invariance. In this paper, the proposed framework for the recognition of a view-invariant human activity, solves the above problem. The components of the proposed framework are three consecutive modules: (i) the detection and positioning of the person's background subtraction, (ii) the function extraction (iii) and the final activity is referenced by using a set of hidden Markov models (HMMs). During features extraction phase in the proposed method for activity representation a combination of contour-based distance signal feature, optical flow-based motion feature and uniform rotation local binary patterns has been used. Due to its rotation invariant nature the uniform LBP provides view-invariant recognition of multi-view human activities. A successful testing of the proposed approach was done on our own viewpoint dataset, KTH action recognition dataset, i3DPost multi-view dataset, and MSR view-point action dataset. From the experimental results and analysis over the chosen datasets, it is observed that the proposed framework is robust, flexible and efficient with respect to multiple views activity recognition, scale and phase variations.
C1 [Singh, Roshan; Srivastava, Rajeev] BHU, IIT, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
   [Kushwaha, Alok Kumar Singh] IK Gujral Punjab Tech Univ, Dept Comp Sci & Engn, Main Campus, Kapurthala, Punjab, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi); I. K. Gujral Punjab Technical University
RP Singh, R (corresponding author), BHU, IIT, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
EM roshansingh.cse@iitbhu.ac.in; dr.alokkushwaha@ptu.ac.in;
   rajeev.cse@iitbhu.ac.in
RI Singh, Roshan/AAX-3387-2021; Srivastava, Rajeev/C-7906-2016
OI Singh, Roshan/0000-0002-8527-1162; Srivastava,
   Rajeev/0000-0002-0165-1556; KUSHWAHA, ALOK KUMAR
   SINGH/0000-0003-2928-998X
CR Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   Althloothi S, 2014, PATTERN RECOGN, V47, P1800, DOI 10.1016/j.patcog.2013.11.032
   [Anonymous], DISCRIMINATIVE VIDEO
   [Anonymous], ROTATION INVARIANT I
   [Anonymous], IEEE COMP SOC WORKSH
   [Anonymous], ACM INT C IM VID RET
   [Anonymous], I3DPOST MULT HUM ACT
   [Anonymous], RECOGNITION HUMAN AC
   Ben-Arie J, 2002, IEEE T PATTERN ANAL, V24, P1091, DOI 10.1109/TPAMI.2002.1023805
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Cohen I, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P74
   Dedeoglu Y, 2006, LECT NOTES COMPUT SC, V3979, P64
   Fernández A, 2011, MACH VISION APPL, V22, P913, DOI 10.1007/s00138-010-0253-4
   Hamid R., 2003, P C COMP VIS PATT RE, V3, P38, DOI DOI 10.1109/CVPRW.2003.10039
   Hannuksela J, 2008, THESIS
   Holte MB, 2012, IEEE J-STSP, V6, P538, DOI 10.1109/JSTSP.2012.2196975
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Kellokumpu V, 2011, MACH VISION APPL, V22, P767, DOI 10.1007/s00138-009-0233-8
   Kulathumani V., 2012, WVU Multi View Action Recognition Dataset
   Liu L, P 30 AAAI C ART INT
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liuy Y, 2015, P 24 INT JOINT C ART
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Qian HM, 2010, PATTERN RECOGN LETT, V31, P100, DOI 10.1016/j.patrec.2009.09.019
   Sadek S., 2013, ISRN MACHINE VISION, V2013, P7
   Sharma C.M., 2011, P INT C ADV COMPUTIN, P97
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Veeraraghavan A, 2006, P IEEE COMP SOC C CO
   Vili K, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P206
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yang J, 1997, IEEE T SYST MAN CY A, V27, P34, DOI 10.1109/3468.553220
   Yanghee Nam, 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P51
NR 36
TC 27
Z9 27
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17165
EP 17196
DI 10.1007/s11042-018-7108-9
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500064
DA 2024-07-18
ER

PT J
AU Srivastava, D
   Bakthula, R
   Agarwal, S
AF Srivastava, Divya
   Bakthula, Rajitha
   Agarwal, Suneeta
TI Image classification using SURF and bag of LBP features constructed by
   clustering with fixed centers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag of features; Polygon; Background suppression; Local binary pattern;
   SURF points; Clustering
ID TEXTURE
AB Image classification is the process of assigning a category/class to an image. It has gained much importance in the recent years because of its real-time applications in object tracking, medical imaging, image organizations for large datasets, image and video retrieval. For instance, in image retrieval, query image once classified to the correct category avoids the searching of similar images from the complete dataset. In the state of art approaches, the classification techniques are generally discussed for a single dataset having similar images such as Textures(Rock,trees, texture based images), Describable Texture dataset (clothing pattern), Oxford Dataset(building pattern), etc. Thus a common approach for classification of various types of images is lacking. This paper presents a common approach for the variety of datasets having different types of images. Four different types of dataset, Caltech-101(101 different categories of images eg. airplane, sunflower, bike, etc), ORL Face, Bangla Signature and Hindi Signature are used for testing the proposed classification approach. The proposed approach has three phases. Region of Interest(ROI) using SURF(Speed Up Robust Transform) Points is obtained in the first phase. Extraction of LBP(Local Binary Pattern) Features on ROI is done in the second phase. In the third phase clustering of LBP features are done with a new proposed approach as CFC(Clustering with Fixed Centers) to construct Bag of LBP Features. Through proposed CFC approach each image is annotated/tagged with a fixed Bag of Features to avoid the training of machine, again and again. SVM is used here for classification as it has been experimentally found to give the best performance when compared with Decision Tree, Random Forest, K Nearest Neighbor and Linear Method. The accuracy obtained for Caltech-101, ORL Face, and Signature(Bangla and Hindi) are 79.0%, 75.0%, 81.6% and 87.0% respectively. Thus the average accuracy obtained by the proposed approach is 81.7% in contrast to other state of art approaches having average accuracy as 64.15%, 76.47%, and 77.65%.
C1 [Srivastava, Divya; Bakthula, Rajitha; Agarwal, Suneeta] MNNIT Allahabad, CSED, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Srivastava, D (corresponding author), MNNIT Allahabad, CSED, Allahabad, Uttar Pradesh, India.
EM divyalknw@gmail.com; rajitha@mnnit.ac.in; suneeta@mnnit.ac.in
RI B, Rajitha/HHR-8738-2022
CR [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2017, AAAI
   [Anonymous], PLOS ONE
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Cula OG, 2001, P 2001 IEEE COMP SOC, V1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dang QB, 2015, 2015 13 INT C DOC AN
   Deng Jia, 2014, EUR C COMP VIS ECCV
   Divya S, 2017, 2017 4 INT C POW CON
   Ebrahim K, 2017, ARXIV171002726
   Ferraz CT, 2017, MULTIMED TOOLS APPL, V76, P20609, DOI 10.1007/s11042-016-4003-0
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hirata K, 2000, MULTIMED TOOLS APPL, V11, P295, DOI 10.1023/A:1009662215895
   Kamavisdar P., 2013, International Journal of Advanced Research in Computer and Communication Engineering, V2, P1005
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Li F-F, 2005, IEEE COMP SOC C COMP, V2
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Ma J., 2014, COMPUTATIONAL MATH M
   Mikolajczyk K, 2003, PROC CVPR IEEE, P257
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   OHara S., 2011, ARXIV11013354
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Oyallon E, 2015, IMAGE PROCESS ON LIN, V5, P176, DOI 10.5201/ipol.2015.69
   Pandey S, 2017, 2017 4TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS (UPCON), P139, DOI 10.1109/UPCON.2017.8251037
   Perner P, 2002, ARTIF INTELL MED, V26, P161, DOI 10.1016/S0933-3657(02)00057-X
   Porebski A, 2014, MULTIMED TOOLS APPL, V70, P543, DOI 10.1007/s11042-013-1418-8
   Shao CZ, 2017, GELS-BASEL, V3, DOI 10.3390/gels3010009
   Shivakumar BL, 2011, IJCSI INT J COMPUTER, V8, P4
   Srivastava D, 2020, NEURAL COMPUT APPL, V32, P10819, DOI 10.1007/s00521-018-3611-1
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Wolpert DH, 2002, SOFT COMPUTING AND INDUSTRY, P25
   Wu J, 2013, MEAS SCI REV, V13, P122, DOI 10.2478/msr-2013-0021
   Wu JX, 2012, IEEE T IMAGE PROCESS, V21, P4442, DOI 10.1109/TIP.2012.2207392
   Xiangyuan L, 2018, ROBUST COLLABORATIVE
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
NR 45
TC 15
Z9 17
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14129
EP 14153
DI 10.1007/s11042-018-6793-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700002
DA 2024-07-18
ER

PT J
AU Hong, W
   Li, Yz
   Weng, SW
AF Hong, Wien
   Li, Yizhen
   Weng, Shaowei
TI A difference matching technique for data embedment based on absolute
   moment block truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AMBTC; Data embedding; Difference matching
ID STEGANOGRAPHY
AB In this paper, an optimized data embedding method based on Huang et al.'s work for absolute moment block truncation coding (AMBTC) is proposed. Huang et al.'s work successfully exploits the difference of quantization levels (QLs) for data embedment and has an excellent embedding performance. However, the modified QLs are not adjusted to minimize the distortion. In some rare cases, they might exceed the grayscale range. Moreover, the order of QLs in smooth blocks is not utilized for data embedment, losing the chance to embed one additional bit without deteriorating the image block. We propose a method to give analytical solutions to adjust QLs such that the distortions in both smooth and complex blocks are minimized. A subtle mechanism is also provided to ensure that no QLs will overflow or underflow. Moreover, the order of QLs is utilized in data embedment to further increase the payload without sacrificing the image quality. The experimental results reveal that the proposed method offers a better image quality over Huang et al.'s and other state-of-the-art works while providing a comparable or larger payload.
C1 [Hong, Wien; Li, Yizhen] Sun Yat Sen Univ, Sch Elect & Comp Engn, Nanfang Coll, Guangzhou, Guangdong, Peoples R China.
   [Weng, Shaowei] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
C3 Nanfang College, Guangzhou; Sun Yat Sen University; Guangdong University
   of Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM wswweiwei@126.com
RI li, xinke/JTU-3633-2023
FU National NSF of China [61872095, 61872128, 61571139, 61201393]; New Star
   of Pearl River on Science and Technology of Guangzhou [2014J2200085]
FX This work was supported in part by National NSF of China (Nos. 61872095,
   61872128, 61571139, 61201393), New Star of Pearl River on Science and
   Technology of Guangzhou (No. 2014J2200085).
CR [Anonymous], 2016, P 24 ACM INT C MULT
   Chang CC, 2018, MULTIMED TOOLS APPL, V77, P9039, DOI 10.1007/s11042-017-4800-0
   Chang CC, 2016, DIGIT SIGNAL PROCESS, V51, P142, DOI 10.1016/j.dsp.2015.11.007
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chin-Feng Lee, 2011, Journal of Multimedia, V6, P277, DOI 10.4304/jmm.6.3.277-284
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Hong WE, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070254
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P6159, DOI 10.1007/s11042-015-3208-y
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li W, 2016, MULTIMED TOOLS APPL, V75, P4771, DOI 10.1007/s11042-015-2502-z
   Lin CC, 2014, KSII T INTERNET INF, V8, P4588, DOI 10.3837/tiis.2014.12.020
   Liu XL, 2016, IMAGING SCI J, V64, P364, DOI 10.1080/13682199.2016.1213983
   Liu X.-L., 2016, J. Inf. Hiding Multimedia Signal Process., V7, P1282
   Lou DC, 2012, INFORM SCIENCES, V188, P346, DOI 10.1016/j.ins.2011.06.003
   Lyu WL, 2015, J INFORM HIDING MULT, V6, P686
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Pan CL, 2011, INT J INNOV COMPUT I, V7, P5107
   Wang C, 2018, OFICIAL SOC BRASILEN, V40-481, P1, DOI 10.1007/s40430-018-1355-6
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Wu WC, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0163-8
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 28
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13987
EP 14006
DI 10.1007/s11042-018-6983-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900062
DA 2024-07-18
ER

PT J
AU Ji, Q
   Zhang, LY
   Shu, XB
   Tang, JH
AF Ji, Qian
   Zhang, Liyan
   Shu, Xiangbo
   Tang, Jinhui
TI Image annotation refinement via 2P-KNN based group sparse reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; K nearest neighbor; Group sparsity; Sparse
   reconstruction
AB Image annotation aims at predicting labels that can accurately describe the semantic information of images. In the past few years, many methods have been proposed to solve the image annotation problem. However, the predicted labels of the images by these methods are usually incomplete, insufficient and noisy, which is unsatisfactory. In this paper, we propose a new method denoted as 2PKNN-GSR (Group Sparse Reconstruction) for image annotation and label refinement. First, we get the predicted labels of the testing images using the traditional method, i.e., a two-step variant of the classical K-nearest neighbor algorithm, called 2PKNN. Then, according to the obtained labels, we divide the K nearest neighbors of an image in the training images into several groups. Finally, we utilize the group sparse reconstruction algorithm to refine the annotated label results which are obtained in the first step. Experimental results on three standard datasets, i.e., Corel 5K, IAPR TC12 and ESP Game, show the superior performance of the proposed method compared with the state-of-the-art methods.
C1 [Ji, Qian; Shu, Xiangbo; Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Zhang, Liyan] Nanjing Univ Aeronaut & Astronaut, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Aeronautics & Astronautics
RP Zhang, LY (corresponding author), Nanjing Univ Aeronaut & Astronaut, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM jqianxixi@163.com; zhangliyan@nuaa.edu.cn; shuxb@njust.edu.cn;
   jinhuitang@njust.edu.cn
RI Tang, Jinhui/KBR-0891-2024; Shu, Xiangbo/AAC-6245-2022
OI Shu, Xiangbo/0000-0003-4902-4663; Tang, Jinhui/0000-0001-9008-222X
CR [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], 2011, THESIS
   Bahmanyar R, 2015, IEEE GEOSCI REMOTE S, V12, P2046, DOI 10.1109/LGRS.2015.2444666
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Duygulu P., 2002, P 7 EUR C COMP VIS E, V4, P97
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Fu H, 2012, LECT NOTES COMPUT SC, V7577, P86, DOI 10.1007/978-3-642-33783-3_7
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Kita T, 2016, IEEE J SEL TOP QUANT, V22, DOI 10.1109/JSTQE.2016.2559418
   Lavrenko V, 2004, ADV NEUR IN, V16, P553
   Li Xirong., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, MIR '08, P180
   Lin ZJ, 2013, PROC CVPR IEEE, P1618, DOI 10.1109/CVPR.2013.212
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Makadia A., 2008, 10 EUR C COMP VIS BE, P316
   Moran S., 2014, P INT C MULTIMEDIA R, P113
   Putthividhya D, 2010, INT CONF ACOUST SPEE, P1894, DOI 10.1109/ICASSP.2010.5495341
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Tang JH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2998574
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
NR 27
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13213
EP 13225
DI 10.1007/s11042-018-5925-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900026
DA 2024-07-18
ER

PT J
AU Liu, RW
   Yin, W
   Shi, L
   Duan, JM
   Yu, SCH
   Wang, DF
AF Liu, Ryan Wen
   Yin, Wei
   Shi, Lin
   Duan, Jinming
   Yu, Simon Chun Ho
   Wang, Defeng
TI Undersampled CS image reconstruction using nonconvex nonsmooth mixed
   constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Magnetic resonance imaging; Total variation; Tree
   sparsity; Fast composite splitting algorithm
ID MRI RECONSTRUCTION; SPARSITY; MODEL; REDUCTION; DOMAIN; NOISE
AB Compressed sensing magnetic resonance imaging (CS-MRI) has attracted considerable attention due to its great potential in reducing scanning time and guaranteeing high-quality reconstruction. In conventional CS-MRI framework, the total variation (TV) penalty and L1-norm constraint on wavelet coefficients are commonly combined to reduce the reconstruction error. However, TV sometimes tends to cause staircase-like artifacts due to its nature in favoring piecewise constant solution. To overcome the model-dependent deficiency, a hybrid TV (TV1,2) regularizer is introduced in this paper by combining TV with its second-order version (TV2). It is well known that the wavelet coefficients of MR images are not only approximately sparse, but also have the property of tree-structured hierarchical sparsity. Therefore, a L0-regularized tree-structured sparsity constraint is proposed to better represent the measure of sparseness in wavelet domain. In what follows, we present our new CS-MRI framework by combining the TV1,2 regularizer and L0-regularized tree-structured sparsity constraint. However, the combination makes CS-MRI problem difficult to handle due to the nonconvex and nonsmooth natures of mixed constraints. To achieve solution stability, the resulting composite minimization problem is decomposed into several simpler subproblems. Each of these subproblems has a closed-form solution or could be efficiently solved using existing numerical method. The results from simulation and in vivo experiments have demonstrated the good performance of our proposed method compared with several conventional MRI reconstruction methods.
C1 [Liu, Ryan Wen; Yin, Wei] Wuhan Univ Technol, Sch Nav, Wuhan 430063, Hubei, Peoples R China.
   [Liu, Ryan Wen] Nanjing Univ Sci & Technol, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.
   [Shi, Lin; Yu, Simon Chun Ho; Wang, Defeng] Chinese Univ Hong Kong, Dept Imaging & Intervent Radiol, Shatin, Hong Kong, Peoples R China.
   [Duan, Jinming] Imperial Coll London, Biomed Image Anal Grp, London SW7 2AZ, England.
   [Duan, Jinming] Imperial Coll London, MRC London Inst Med Sci, London SW7 2AZ, England.
C3 Wuhan University of Technology; Nanjing University of Science &
   Technology; Chinese University of Hong Kong; Imperial College London;
   Imperial College London
RP Liu, RW (corresponding author), Wuhan Univ Technol, Sch Nav, Wuhan 430063, Hubei, Peoples R China.; Liu, RW (corresponding author), Nanjing Univ Sci & Technol, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.
EM wenliu@whut.edu.cn
RI Liu, Ryan/JMC-1118-2023; Shi, Lin/K-5241-2014; Duan,
   Jinming/AAC-4150-2019; Yu, Simon Chun Ho/D-1046-2011; Liu, Ryan
   Wen/U-6910-2019
OI Duan, Jinming/0000-0002-5108-2128; Yu, Simon Chun
   Ho/0000-0002-8715-5026; Liu, Ryan Wen/0000-0002-1591-5583
FU National Natural Science Foundation of China [51609195]; Open Project
   Program of Key Laboratory of Intelligent Perception and Systems for
   High-Dimensional Information of Ministry of Education [JYB201704]; Wuhan
   University of Technology Excellent Dissertation Cultivation Fund
   [2017-YS-071]
FX This work was partially supported by the National Natural Science
   Foundation of China (No.: 51609195), the Open Project Program of Key
   Laboratory of Intelligent Perception and Systems for High-Dimensional
   Information of Ministry of Education (No.: JYB201704), and the Wuhan
   University of Technology Excellent Dissertation Cultivation Fund
   (2017-YS-071). The first author would like to thank Mr. Quandang Ma for
   his helpful suggestions on manuscript revision.
CR Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chan RH, 2013, SIAM J IMAGING SCI, V6, P680, DOI 10.1137/110860185
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chartrand R, 2009, I S BIOMED IMAGING, P262, DOI 10.1109/ISBI.2009.5193034
   Chen C., 2012, Proceedings of the Annual Conference on Advances in Neural Information Processing Systems (NIPS), P1124
   Chen C, 2014, MED IMAGE ANAL, V18, P834, DOI 10.1016/j.media.2013.12.004
   Chen HZ, 2009, ADV COMPUT MATH, V31, P115, DOI 10.1007/s10444-008-9097-0
   Chernyakova T, 2014, IEEE T ULTRASON FERR, V61, P1252, DOI 10.1109/TUFFC.2014.3032
   Chinn G, 2013, IEEE T MED IMAGING, V32, P932, DOI 10.1109/TMI.2013.2246182
   Choi K, 2010, MED PHYS, V37, P5113, DOI 10.1118/1.3481510
   Combettes PL, 2008, INVERSE PROBL, V24, DOI 10.1088/0266-5611/24/6/065014
   Do MN, 2002, IEEE IMAGE PROC, P357
   Dong B, 2013, J SCI COMPUT, V54, P350, DOI 10.1007/s10915-012-9597-4
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duan JM, 2017, DIGIT SIGNAL PROCESS, V69, P323, DOI 10.1016/j.dsp.2017.07.001
   Duan JM, 2016, BIOMED SIGNAL PROCES, V24, P120, DOI 10.1016/j.bspc.2015.09.012
   Ehrhardt MJ, 2016, SIAM J IMAGING SCI, V9, P1084, DOI 10.1137/15M1047325
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hamza R, 2018, IEEE ACCESS, V6, P60160, DOI 10.1109/ACCESS.2017.2762405
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hao WL, 2013, ELECTRON LETT, V49, P1206, DOI 10.1049/el.2013.1483
   HE L, 1997, IEEE T SIGNAL PROCES, V57, P3488
   He LH, 2010, IEEE SIGNAL PROC LET, V17, P233, DOI 10.1109/LSP.2009.2037532
   Hu Y, 2014, IEEE T IMAGE PROCESS, V23, P2423, DOI 10.1109/TIP.2014.2315156
   Hu Y, 2012, IEEE T IMAGE PROCESS, V21, P2559, DOI 10.1109/TIP.2012.2183143
   Huang F, 2010, MAGN RESON MED, V64, P1078, DOI 10.1002/mrm.22504
   Huang JZ, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P968, DOI 10.1109/ISBI.2012.6235718
   Huang JZ, 2011, COMPUT VIS IMAGE UND, V115, P1610, DOI 10.1016/j.cviu.2011.06.011
   Huang JZ, 2011, MED IMAGE ANAL, V15, P670, DOI 10.1016/j.media.2011.06.001
   Jia RQ, 2010, ADV COMPUT MATH, V33, P231, DOI 10.1007/s10444-009-9128-5
   Jia X, 2010, LECT NOTES COMPUT SC, V6361, P143
   Jiang MF, 2013, MAGN RESON IMAGING, V31, P1218, DOI 10.1016/j.mri.2012.12.003
   Knoll F, 2012, MAGN RESON MED, V67, P34, DOI 10.1002/mrm.22964
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Kong FQ, 2018, MULTIMED TOOLS APPL, V77, P22617, DOI 10.1007/s11042-017-4985-2
   Larsson EG, 2003, J MAGN RESON, V163, P121, DOI 10.1016/S1090-7807(03)00132-0
   Lefkimmiatis S, 2012, IEEE T IMAGE PROCESS, V21, P983, DOI 10.1109/TIP.2011.2168232
   Liang D, 2011, MAGN RESON MED, V65, P1384, DOI 10.1002/mrm.22736
   Liang D, 2009, MAGN RESON MED, V62, P1574, DOI 10.1002/mrm.22161
   Liu RW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033026
   Liu RW, 2015, MED PHYS, V42, P5167, DOI 10.1118/1.4927793
   Liu RW, 2014, MAGN RESON IMAGING, V32, P702, DOI 10.1016/j.mri.2014.03.004
   Lorintiu O, 2015, IEEE T MED IMAGING, V34, P2467, DOI 10.1109/TMI.2015.2442154
   LU W, 1933, MATH METHOD APPL SCI, V39, P4208
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Lustig M, 2010, MAGN RESON MED, V64, P457, DOI 10.1002/mrm.22428
   Lv XG, 2013, APPL MATH MODEL, V37, P8210, DOI 10.1016/j.apm.2013.03.028
   Ma JW, 2011, IEEE T INSTRUM MEAS, V60, P126, DOI 10.1109/TIM.2010.2049221
   Ma SF, 2008, CH CRC MATH COMP BIO, P1
   Majumdar A, 2012, MAGN RESON IMAGING, V30, P1483, DOI 10.1016/j.mri.2012.04.012
   Majumdar A, 2011, MAGN RESON IMAGING, V29, P408, DOI 10.1016/j.mri.2010.09.001
   Manjón JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003
   Ning BD, 2013, MAGN RESON IMAGING, V31, P1611, DOI 10.1016/j.mri.2013.07.010
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Papafitsoros K, 2014, J MATH IMAGING VIS, V48, P308, DOI 10.1007/s10851-013-0445-4
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   QU X, 1958, INVERSE PROBL SCI EN, V18, P737
   Qu XB, 2012, MAGN RESON IMAGING, V30, P964, DOI 10.1016/j.mri.2012.02.019
   Richter D, 2014, Z MED PHYS, V24, P16, DOI 10.1016/j.zemedi.2013.05.003
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schloegl M, 2017, MAGN RESON MED, V78, P142, DOI 10.1002/mrm.26352
   Trzasko J, 2009, IEEE T MED IMAGING, V28, P106, DOI 10.1109/TMI.2008.927346
   Uecker M, 2008, MAGN RESON MED, V60, P674, DOI 10.1002/mrm.21691
   Ulaby F.T., 2006, FUNDAMENTALS APPL EL, V5th
   van Sloun R, 2015, IEEE T BIO-MED ENG, V62, P1660, DOI 10.1109/TBME.2015.2422135
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu J, 2009, IEEE ENG MED BIO, P3727, DOI 10.1109/IEMBS.2009.5334819
   Xie GX, 2014, MAGN RESON IMAGING, V32, P175, DOI 10.1016/j.mri.2013.10.010
   YANG J, 1992, SIAM J IMAGING SCI, V2, P569
   Yang JF, 2010, IEEE J-STSP, V4, P288, DOI 10.1109/JSTSP.2010.2042333
   ZHANG J, 1940, SIGNAL PROCESS, V91, P1933
NR 78
TC 9
Z9 9
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12749
EP 12782
DI 10.1007/s11042-018-6028-z
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900006
DA 2024-07-18
ER

PT J
AU Margetis, G
   Ntoa, S
   Antona, M
   Stephanidis, C
AF Margetis, George
   Ntoa, Stavroula
   Antona, Margherita
   Stephanidis, Constantine
TI Augmenting natural interaction with physical paper in ambient
   intelligence environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Paper augmentation; Natural interaction; Ambient intelligence framework;
   In-situ evaluation
ID REALITY; ONTOLOGY
AB Physical paper, in its various forms (e.g. books, leaflets, catalogues), is extensively used in everyday activities, despite any advancements in digital technology and ICT. Inspired by the popularity of this medium, several research efforts have envisioned and pursued a new era of interactive paper, however several challenges still remain to be addressed. On the other hand, recent advancements towards Ambient Intelligence (AmI) and Smart environments, bear the promise of seamless integration of the physical and digital worlds in an intuitive and user-friendly manner. This paper presents InPrinted, a systematic and generic framework supporting physical paper augmentation and user interaction in Ambient intelligence environments. InPrinted enables natural multimodal user interaction with any kind of printed matter in smart environments, providing context aware and anticipation mechanisms, as well as tools and interaction techniques that support the development of applications incorporating printed matter augmentation. InPrinted has been put to practice in the development of various systems, including the Interactive Maps system, facilitating interaction with printed maps as well as their augmentation with digital information. The results of an in-situ observation experiment of the Interactive Maps system are reported, highlighting that interacting with augmented paper is quite easy and natural, while the overall User Experience is positive.
C1 [Margetis, George; Ntoa, Stavroula; Antona, Margherita; Stephanidis, Constantine] Fdn Res & Technol Hellas FORTH, Inst Comp Sci, GR-70013 Iraklion, Crete, Greece.
   [Stephanidis, Constantine] Univ Crete, Dept Comp Sci, Human Comp Interact, Iraklion, Greece.
C3 University of Crete
RP Margetis, G (corresponding author), Fdn Res & Technol Hellas FORTH, Inst Comp Sci, GR-70013 Iraklion, Crete, Greece.
EM gmarget@ics.forth.gr; stant@ics.forth.gr; antona@ics.forth.gr;
   cs@ics.forth.gr
RI Margetis, George/Y-1826-2019
OI Margetis, George/0000-0002-9101-6301; Stephanidis,
   Constantine/0000-0003-3687-4220; Antona, Margherita/0000-0003-3208-3755;
   Ntoa, Stavroula/0000-0002-6270-8333
FU FORTH-ICS internal RTD Programme 'Ambient Intelligence Environments'
FX This work is supported by the FORTH-ICS internal RTD Programme 'Ambient
   Intelligence Environments'.
CR [Anonymous], 2013, IEEE INT C FUZZY SYS, DOI DOI 10.1109/ICMEW.2013.6618341
   [Anonymous], 2010, P PAPERCOMP 2010 1 I
   [Anonymous], LARGE DISPLAYS URBAN
   [Anonymous], 2013, P INT C HUM COMP INT
   [Anonymous], P CLIR KAN I TECHN R
   [Anonymous], THESIS
   [Anonymous], P WORKSH MOB PERS PR
   [Anonymous], TOCHI
   [Anonymous], INK AN OV
   [Anonymous], BIBL ONT SPEC
   [Anonymous], P 12 BIANN C IT SIGC
   [Anonymous], INTR WIND WORKFL FDN
   [Anonymous], P 5 INT C AMB COMP A
   [Anonymous], HCI INT C 2011
   [Anonymous], FORMS BAS UN PATT
   [Anonymous], PAP VS DIG 2 SID SUR
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Chen H, 2003, KNOWL ENG REV, V18, P197, DOI 10.1017/S0269888904000025
   Chih-Sung Andy., 2008, TEI 08 P 2 INT C TAN, P109, DOI [10.1145/1347390.1347414, DOI 10.1145/1347390.1347414]
   Fields B, 2007, INT J HUM-COMPUT INT, V22, P1, DOI 10.1207/s15327590ijhc2201-02_1
   Figueiredo A.C., 2013, P 12 INT C INTERACTI, P569, DOI DOI 10.1145/2485760.2485867
   Forsberg Andrew S., 1998, Proceedings of the Second International Immersive Projection Technology Workshop, P11
   Golemati M., 2007, Proceedings of the First RCIS Conference, p, P407
   Gu T., 2004, P CNDS, P270
   Holman David, 2005, CHI '05, P591, DOI 10.1145/1054972.1055054
   Kjeldsen R, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P402, DOI 10.1109/AFGR.2002.1004187
   Kobayashi M, 1998, PHOTOSYNTHESIS: MECHANISMS AND EFFECTS, VOLS I-V, P57, DOI 10.1109/APCHI.1998.704149
   Korozi M, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P802
   Kunkel HO, 1998, J ANIM SCI, V76, P706
   Lam A., 2006, ACM international conference on Virtual reality continuum and its applications, P357, DOI DOI 10.1145/1128923.1128987
   Liao CY, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2441
   Luff P., 2004, Computer Supported Cooperative Work Conference Proceedings, P523, DOI 10.1145/1031607.1031695
   Mackay WE, 1999, AUGMENTED REALITY, P81
   Margetis G, 2013, 2013 1ST IEEE WORKSHOP ON USER-CENTERED COMPUTER VISION (UCCV), P43, DOI 10.1109/UCCV.2013.6530807
   Margetis G, 2011, P 2011 C MULTIMEDIA, P1
   Margetis G, 2015, UNIVERSAL ACCESS INF, V14, P427, DOI 10.1007/s10209-014-0365-0
   Margetis G, 2013, MULTIMED TOOLS APPL, V67, P473, DOI 10.1007/s11042-011-0976-x
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   Matthews T, 2007, HUM-COMPUT INTERACT, V22, P221
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nielsen ChristianMonrad., 2006, P 4 NORDIC C HUMAN C, P272, DOI DOI 10.1145/1182475.1182504
   Nielsen J., 1994, Heuristic evaluation. Usability inspection methods, V17, P25
   Pinhanez Claudio., 2001, CHI 01, P369, DOI DOI 10.1145/634067.634285
   Preuveneers D, 2004, LECT NOTES COMPUT SC, V3295, P148
   Robertson Charles., 1999, Proceedings of the ACM International Conference on Multimedia, P167, DOI [10.1145/319878.319923, DOI 10.1145/319878.319923]
   Rogers Y, 2007, LECT NOTES COMPUT SC, V4717, P336
   Rosson MB, 2009, HUM FACTORS ERGON, P145
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Sellen A.J., 2003, MYTH PAPERLESS OFFIC
   Signer B., 2007, Proc. of the ACM Conf. on Tangible and Embedded Interaction TEI, P57, DOI DOI 10.1145/1226969.1226981
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Song H, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P143
   Waldner M., 2006, Proceedings of the 18th Australia conference on Computer-Human Interaction: Design: Activities, Artefacts and Environments, P151, DOI DOI 10.1145/1228175.1228203
   WELLNER P, 1993, COMMUN ACM, V36, P87, DOI 10.1145/159544.159630
   Woods E., 2004, Proceedings of the 2nd international conference on Computer graphics and interactive techniques in Australasia and South East Asia (GRAPHITE '04), P230, DOI DOI 10.1145/988834.988873
NR 57
TC 9
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13387
EP 13433
DI 10.1007/s11042-018-7088-9
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900037
DA 2024-07-18
ER

PT J
AU Pini, S
   Cornia, M
   Bolelli, F
   Baraldi, L
   Cucchiara, R
AF Pini, Stefano
   Cornia, Marcella
   Bolelli, Federico
   Baraldi, Lorenzo
   Cucchiara, Rita
TI M-VAD names: a dataset for video captioning with naming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video captioning; Naming; Dataset; Deep learning
AB Current movie captioning architectures are not capable of mentioning characters with their proper name, replacing them with a generic someone tag. The lack of movie description datasets with characters' visual annotations surely plays a relevant role in this shortage. Recently, we proposed to extend the M-VAD dataset by introducing such information. In this paper, we present an improved version of the dataset, namely M-VAD Names, and its semi-automatic annotation procedure. The resulting dataset contains 63 k visual tracks and 34 k textual mentions, all associated with character identities. To showcase the features of the dataset and quantify the complexity of the naming task, we investigate multimodal architectures to replace the someone tags with proper character names in existing video captions. The evaluation is further extended by testing this application on videos outside of the M-VAD Names dataset.
C1 [Pini, Stefano; Cornia, Marcella; Bolelli, Federico; Baraldi, Lorenzo; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
C3 Universita di Modena e Reggio Emilia
RP Cornia, M (corresponding author), Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
EM s.pini@unimore.it; marcella.cornia@unimore.it;
   federico.bolelli@unimore.it; lorenzo.baraldi@unimore.it;
   rita.cucchiara@unimore.it
RI Cornia, Marcella/Y-9903-2019; Pini, Stefano/Y-4739-2019; Cucchiara,
   Rita/L-3006-2015; ARSLAN, Okan/AAA-3232-2020
OI Cornia, Marcella/0000-0001-9640-9385; Pini, Stefano/0000-0002-9821-2014;
   Bolelli, Federico/0000-0002-5299-6351; Baraldi,
   Lorenzo/0000-0001-5125-4957
CR [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2014, IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], BRIT MACH VIS C
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE INT CONF MULTI
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], INT C IM AN PROC
   [Anonymous], EUR C COMP VIS
   [Anonymous], GERM C PATT REC
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2016, C EMP METH NAT LANG
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE IPCCC
   [Anonymous], 2015, IEEE INT C COMP VIS
   [Anonymous], 2015, IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   Babenko B, 2009, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2009.5459264
   Bojanowski P, 2013, IEEE I CONF COMP VIS, P2280, DOI 10.1109/ICCV.2013.283
   Tran DN, 2015, IEEE INT CON MULTI
   Huq RM, 2015, IEEE IC COMP COM NET
   Javaria I, 2015, IEEE INT CON MULTI
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Kong CL, 2017, IEEE ICC
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Marin-Jimenez MJ, 2014, INT J COMPUT VISION, V106, P282, DOI 10.1007/s11263-013-0655-7
   Miech A, 2017, IEEE I CONF COMP VIS, P5267, DOI 10.1109/ICCV.2017.562
   More A, 2013, IEEE INT CONF INNOV
   Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24
   Pennington J., 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1162
   Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venugopalan S., 2014, Translating videos to natural language using deep recurrent neural networks
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Yu H, 2016, IEEE INT CONF COMMUN
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 42
TC 13
Z9 13
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 14007
EP 14027
DI 10.1007/s11042-018-7040-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900063
DA 2024-07-18
ER

PT J
AU Thovuttikul, S
   Ohmoto, Y
   Nishida, T
AF Thovuttikul, Sutasinee
   Ohmoto, Yoshimasa
   Nishida, Toyoaki
TI Learning communication from first- and third-person POVs: how perceptual
   differences influence the interpretation of conversations whilst waiting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Communication learning system; First- and third-person points of view
   (POVs); Perception of conversation; Fairness of waiting; Simulated crowd
ID CULTURE
AB The difficulties and social anxiety associated with living in unfamiliar places are often caused by different patterns of thinking, points of view (POVs) and physical styles. Learning to communicate better will help us understand that differences are normal, and that life can be lived in harmony. We study herein how participants learn and understand different behavioural patterns during interactions using experiments on perceived communication differences in first- and third-person POVs for simulated crowds. In our experiment, participants interact with autonomous agents and experimenters via avatars in a shared virtual space. We ask the participants to obtain multiple tickets from two service counters in the system. The virtual service avatar provides a ticket upon request. One or more autonomous customer agents then navigate the system to obtain the ticket. If a service counter is already occupied, other customers must wait in accordance with the first-come, first-serve rule. The fairness-of-waiting behaviour is interpreted using two features to understand the perceptual differences of varying perspectives: waiting styles (i.e. line and group waiting) and fairness (i.e. fair and unfair services). Participants with differing perspectives focus on different features whilst waiting. An analysis of variance of reactions and reasoning demonstrates that the participants in the first-person group tend to focus on interaction and feelings whilst waiting, whereas participants in the third-person group emphasised fairness.
C1 [Thovuttikul, Sutasinee; Ohmoto, Yoshimasa; Nishida, Toyoaki] Kyoto Univ, Dept Intelligence Sci & Technol, Grad Sch Informat, Kyoto, Japan.
   [Thovuttikul, Sutasinee; Nishida, Toyoaki] RIKEN, Ctr Adv Intelligence Project, Tokyo, Japan.
C3 Kyoto University; RIKEN
RP Thovuttikul, S (corresponding author), Kyoto Univ, Dept Intelligence Sci & Technol, Grad Sch Informat, Kyoto, Japan.; Thovuttikul, S (corresponding author), RIKEN, Ctr Adv Intelligence Project, Tokyo, Japan.
EM thovutti@ii.ist.i.kyoto-u.ac.jp; ohmoto@i.kyoto-u.ac.jp;
   nishida@i.kyoto-u.ac.jp
OI Thovuttikul, Sutasinee/0000-0003-3077-3293
FU RIKEN Center for Advanced Intelligence Project as part of the "Human-AI
   Communication project
FX This research was supported by the RIKEN Center for Advanced
   Intelligence Project as part of the "Human-AI Communication project".
CR [Anonymous], 1989, UNDERSTANDING CULTUR
   Aylett R, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1085, DOI 10.5555/2615731.2617418
   Bernstein DA, 2007, ESSENTIALS PSYCHOL
   Black D, 2017, GAMES CULT, V12, P179, DOI 10.1177/1555412015589175
   Celentano A., 2017, P 12 BIANN C IT SIGC, DOI [10.1145/3125571.3125577, DOI 10.1145/3125571.3125577]
   Degens N, 2017, AI SOC, V32, P37, DOI 10.1007/s00146-014-0567-2
   Degens N, 2016, IEEE T LEARN TECHNOL, V9, P120, DOI 10.1109/TLT.2015.2456912
   Denisova A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P145, DOI 10.1145/2702123.2702256
   Dresser N., 2011, Multicultural manners: Essential rules of etiquette for the 21st century
   Endrass Birgit, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P1, DOI 10.1007/978-3-642-23974-8_1
   Endrass B., 2011, The 10th Intl. Conf. on Autonomous Agents and Multiagent Systems, V2, P441
   Endrass B, 2011, COMPUT SPEECH LANG, V25, P158, DOI 10.1016/j.csl.2010.04.001
   Gary J, 2005, ORG BEHAV UNDERSTAND
   Hall E.T., 1989, LENGUAJE SILENCIOSO
   Hall L, 2015, INT J ARTIF INTELL E, V25, P291, DOI 10.1007/s40593-014-0031-y
   James LB, 1997, PRIMER ORG BEHAV
   Kistler F, 2012, J MULTIMODAL USER IN, V6, P39, DOI 10.1007/s12193-011-0087-z
   Kullu K, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1177
   Lala D., 2011, 2011 Sixth International Conference on Digital Information Management, P310, DOI 10.1109/ICDIM.2011.6093362
   Maister DH, 1984, PSYCHOL WAITING LINE
   Mascarenhas S., 2013, P 2013 INT C AUTONOM, P1387
   Mascarenhas S, 2016, AUTON AGENT MULTI-AG, V30, P931, DOI 10.1007/s10458-015-9312-6
   Mullins L., 2011, ESSENTIALS ORG BEHAV
   Nakai A, 2015, J MULTIMODAL USER IN, V9, P403, DOI 10.1007/s12193-015-0197-0
   Nishida T, 2015, LECT NOTES ARTIF INT, V9011, P13, DOI 10.1007/978-3-319-15702-3_2
   Nishida T, 2015, LECT NOTES COMPUT SC, V8999, P74, DOI 10.1007/978-3-319-16313-0_6
   Ookaki T, 2015, LECT NOTES ARTIF INT, V9101, P161, DOI 10.1007/978-3-319-19066-2_16
   Rafaeli A., 2002, J SERV RES-US, V5, P125, DOI DOI 10.1177/109467002237492
   Samovar LarryA., 2009, Communication between Cultures: A Reader, V7th
   Thovuttikul S., 2012, Proceedings of the 2012 11th IEEE International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC), P153, DOI 10.1109/ICCI-CC.2012.6311141
   Thovuttikul S., 2011, 2011 IEEE International Conference on Granular Computing, P659, DOI 10.1109/GRC.2011.6122675
   Thovuttikul S., 2011, 2 WORKSH EYE GAZ INT
NR 32
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13435
EP 13459
DI 10.1007/s11042-019-7272-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900038
DA 2024-07-18
ER

PT J
AU Xie, XZ
   Lin, CC
   Chang, CC
AF Xie, Xiao-Zhu
   Lin, Chia-Chen
   Chang, Chin-Chen
TI A reversible data hiding scheme for JPEG images by doubling small
   quantized AC coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AC coefficient; Histogram shifting; JPEG images; Reversible data hiding
AB Reversible data hiding for Joint Photographic Experts Group (JPEG) images has become popular in recent years, since JPEG images are widely used in practical applications. An improved reversible data hiding (RDH) method for JPEG images based on Huang et al.'s method is proposed. Huang et al. embedded data into discrete cosine transform (DCT) coefficients with values 1 and-1 (i.e., the selected coefficients) using histogram shifting. After analyzing the statistical properties of quantized DCT coefficient blocks of the JPEG images, it was concluded that the vast majority of blocks have no alternating current (AC) coefficients with values in(3,-3,4,-4), especially when the quality factor (QF) is low. For these blocks, we propose a method which extends the selected coefficients with values in (1, -1) to values in (1, -1, 2, -2), then embeds secret data into the selected coefficients by doubling them, while keeping the unselected coefficients unchanged. The extended method can improve the embedding capacity as well as the image quality. For the other blocks, Huang's method is still applied. Experimental results verify that the proposed scheme can achieve higher embedding capacity, while maintaining a similar image quality and file size as other schemes did.
C1 [Xie, Xiao-Zhu] Xiamen Univ Technol, Engn Res Ctr Software Testing & Evaluat Fujian Pr, Xiamen 361024, Peoples R China.
   [Xie, Xiao-Zhu; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
C3 Xiamen University of Technology; Feng Chia University; Providence
   University - Taiwan
RP Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
EM xz4xxz@gmail.com; ally.cclin@gmail.com; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
OI Lin, Chia-Chen/0000-0003-4480-7351
FU Natural Science Foundation of China [61503316]; Natural Science
   Foundation of Fujian Province [2016 J01326]; Open Fund of Engineering
   Research Center for Software Testing and Evaluation of Fujian Province
FX This work is supported by the Natural Science Foundation of China under
   Grant 61503316, the Natural Science Foundation of Fujian Province under
   Grant 2016 J01326, and Open Fund of Engineering Research Center for
   Software Testing and Evaluation of Fujian Province.
CR Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang C.C., 2017, 2017 5th International Workshop on Biometrics and Forensics (IWBF), P1, DOI [DOI 10.1109/IWBF.2017.7935098, 10.1109/IWBF.2017, DOI 10.1109/IWBF.2017]
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2013, J SYST SOFTWARE, V86, P2166, DOI 10.1016/j.jss.2013.03.102
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Jung KH, 2016, IETE TECH REV, V33, P441, DOI 10.1080/02564602.2015.1102099
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li QM, 2010, LECT NOTES COMPUT SC, V6297, P653, DOI 10.1007/978-3-642-15702-8_60
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin CC, 2010, J SOFT, V5, P327
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Sakai H., 2008, P INT S INF THEOR IT, P1
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wedaj FT, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0206-1
   XIE XZ, 2017, PROCEEDINGS OF THE 5, V5, P1, DOI DOI 10.1109/TSMC.2017.2737542
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   Yan YX, 2009, I W IMAG SYST TECHNI, P179, DOI 10.1109/IST.2009.5071628
NR 25
TC 12
Z9 13
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11443
EP 11462
DI 10.1007/s11042-018-6651-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900016
DA 2024-07-18
ER

PT J
AU Dong, SX
   Liu, SL
   Zhao, YY
   Shao, ZZ
AF Dong, Shuxia
   Liu, Shulei
   Zhao, Yanyu
   Shao, Zengzhen
TI An innovative model to mine asynchronous periodic pattern of moving
   objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatiotemporal data mining; asynchronous periodic pattern; clustering
   algorithm SMCA algorithm
AB Periodic detection in spatiotemporal data is one of the research focuses in data mining. Most previous works only focused on mining periodic patterns and hardly recognized misaligned presence of a pattern due to the intervention of repetitive data. A more flexible asynchronous periodic patterns mining model (AP(2)M(2)) based on clustering algorithm and SMCA algorithm is proposed which mainly has three steps, discovering the invisible repetitive data and clustering them into a single record to generate standard and usable dataset, finding the set of stopovers and mining the periodic patterns of moving objects at each stopover. In the experiment, the Chinese bird-watching data is used to check the effectiveness of AP(2)M(2) model and the results show that the AP(2)M(2) model can precisely mine the asynchronous periodic patterns with low time complexity.
C1 [Dong, Shuxia; Shao, Zengzhen] Shandong Womens Univ, Sch Data & Comp Sci, Jinan, Shandong, Peoples R China.
   [Dong, Shuxia; Liu, Shulei; Zhao, Yanyu; Shao, Zengzhen] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
C3 Shandong Womens University; Shandong Normal University
RP Dong, SX (corresponding author), Shandong Womens Univ, Sch Data & Comp Sci, Jinan, Shandong, Peoples R China.; Dong, SX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
EM dongshuxia@126.com; lsl_jsj@163.com; 939996905@163.com;
   shaozengzhen@163.com
FU China Postdoctoral Science Foundation [2016 M592697]; Key Science and
   Technology Project of Shandong Province of China [2014GGH201022]
FX This work was supported by China Postdoctoral Science Foundation (No.
   2016 M592697) and Key Science and Technology Project of Shandong
   Province of China (No. 2014GGH201022).
CR Alkoffash M.S., 2012, INT J COMPUT APPL, V51, P5
   Alvares Luis Otavio, 2009, Proceedings 21st International Conference on Software Engineering & Knowledge Engineering (SEKE 2009), P698
   [Anonymous], 2003, FIMI
   Aref WG, 2004, IEEE T KNOWL DATA EN, V16, P332
   Aydin B, 2016, IEEE INT C DAT MIN W, P575
   Borgelt C., 2005, P 1 INT WORKSHOP OPE, P1, DOI DOI 10.1145/1133905.1133907
   Celik M, 2007, MINING MOST TOP K MI, P565
   Celik M, 2008, IEEE T KNOWL DATA EN, V20, P1322, DOI 10.1109/TKDE.2008.97
   Chok H., 2009, P 2009 INT DAT ENG A, P217
   Cushman SA, 2010, SPATIAL COMPLEXITY, INFORMATICS, AND WILDLIFE CONSERVATION, P131, DOI 10.1007/978-4-431-87771-4_7
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1
   Han JW, 2010, LECT NOTES COMPUT SC, V5982, P485
   Han JW, 1999, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1999.754913
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He Q., 2011, Energy Procedia, V13, P3269
   HUANG H, 2018, ASCE, V144
   Huang KY, 2005, IEEE T KNOWL DATA EN, V17, P774, DOI 10.1109/TKDE.2005.98
   Jeung HY, 2008, PROC INT CONF DATA, P70, DOI 10.1109/ICDE.2008.4497415
   Jiong Yang, 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P275, DOI 10.1145/347090.347150
   Kellaris G, 2013, J SYST SOFTWARE, V86, P1566, DOI 10.1016/j.jss.2013.01.071
   Lee AJT, 2009, INFORM SCIENCES, V179, P2218, DOI 10.1016/j.ins.2009.02.016
   Lee G, 2006, INFORM SCIENCES, V176, P3591, DOI 10.1016/j.ins.2006.02.010
   LI Z, 2015, TKDE, V27, P1219, DOI DOI 10.1109/TKDE.2014.2365801
   Maqbool F, 2006, INT J COMPUT SCI NET, V6, P174
   Min F, 2020, INFORM SCIENCES, V507, P715, DOI 10.1016/j.ins.2018.04.013
   Monreale A, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P637
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770
   Nishi MA, 2013, EXPERT SYST APPL, V40, P3015, DOI 10.1016/j.eswa.2012.12.017
   O'Callaghan L, 2002, PROC INT CONF DATA, P685, DOI 10.1109/ICDE.2002.994785
   Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804
   Parimala M, 2013, J APPL SCI RES, V9, P2602
   Rasheed F, 2010, APPL INTELL, V32, P267, DOI 10.1007/s10489-008-0144-9
   Richter KF, 2012, J SPAT INT SCI, P3, DOI 10.5311/JOSIS.2012.4.62
   Shekhar S, 2015, ISPRS INT J GEO-INF, V4, P2306, DOI 10.3390/ijgi4042306
   Verhein F, 2012, SIAM INT C DATA MINI, P605
   Verhein F, 2008, DATA MIN KNOWL DISC, V16, P5, DOI 10.1007/s10618-007-0079-5
   Verhein F, 2006, ICDM 2006: SIXTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, WORKSHOPS, P387
   Yang KJ, 2013, EXPERT SYST APPL, V40, P4232, DOI 10.1016/j.eswa.2013.01.021
   Yeh Jieh-Shan., 2009, Proceedings of the 3rd International Conference on Ubiquitous Information Management and Communication, P426
   Yuan G., 2012, J CONVERGENCE INFORM, V7, P286, DOI [10.4156/jcit.vol7.issue9.35, DOI 10.4156/JCIT.VOL7.ISSUE9.35]
   Zhang Shu-chun, 2012, Computer Engineering, V38, P56, DOI 10.3969/j.issn.1000-3428.2012.06.018
   Zhang W, 2009, ISBIM: 2008 INTERNATIONAL SEMINAR ON BUSINESS AND INFORMATION MANAGEMENT, VOL 1, P315, DOI 10.1109/ISBIM.2008.177
   Zhang Z, 2015, LECT NOTES COMPUT SC, V5258, P454, DOI [10.1007/978-3-540-88582-5_43, DOI 10.1007/978-3-540-88582-5_43]
NR 44
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8943
EP 8964
DI 10.1007/s11042-018-6752-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800058
DA 2024-07-18
ER

PT J
AU Jin, Y
   Qian, ZJ
   Sun, GF
AF Jin, Yong
   Qian, Zhenjiang
   Sun, Gaofei
TI A real-time multimedia streaming transmission control mechanism based on
   edge cloud computing and opportunistic approximation optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real time transmission; Multimedia streaming; Edge cloud computing;
   Opportunistic control; Approximation optimization
ID COMMUNICATION
AB We address the problem of real-time transmission of multimedia streams in distributed heterogeneous networks. The effect of this problem directly affects the execution efficiency, real-time and reliability of the network system. Firstly, for distributed multimedia data, the heterogeneity of edge cloud devices is considered. Through in-depth analysis of the dependency between multimedia packets and video frames, the edge cloud and its dependent directed acyclic graph are established, and the edge cloud computing model is set up to execute cost, real-time and dependability. Secondly, based on the deadline features of multimedia real-time applications, the optimal solution of the edge cloud sets is established. The establishment basis is from the maximum satisfiability problem and the search for the best edge cloud with the execution cost and execution time of the multimedia streaming real-time communication application. According to the above models, a real-time multimedia streaming transmission control mechanism upon edge cloud computing and the opportunistic approximation optimization is proposed. Through the simulation and analysis experiments of static network topology and dynamic network topology, the performance of the execution cost, delay and packet loss rate of the proposed mechanism is deeply analyzed and verified. The analysis results show that the proposed mechanism can transparently influence the dynamic network topology and find an optimal solution for the guarantee of real-time and reliability through the deep fusion edge cloud computing and approximate optimization.
C1 [Jin, Yong; Qian, Zhenjiang; Sun, Gaofei] Changshu Inst Technol, Sch Comp Sci & Engn, Changshu 215500, Jiangsu, Peoples R China.
C3 Changshu Institute of Technology
RP Jin, Y (corresponding author), Changshu Inst Technol, Sch Comp Sci & Engn, Changshu 215500, Jiangsu, Peoples R China.
EM jinyong@cslg.edu.cn; qianzj@cslg.edu.cn; gfsun@cslg.edu.cn
RI Qian, Zhenjiang/HJH-9639-2023
OI Qian, Zhenjiang/0000-0001-7807-2600
FU Natural Science Foundation of China [61702056]; Educational Commission
   of JiangSu Province [17KJB520001]; Qing Lan Project of Jiangsu Province
   in China [2017]; 333 high-level personnel training projects of Jiangsu
   Province in China [2018]; Jiangsu Students' innovation and
   entrepreneurship training program [201810333029Y]
FX The authors would like to thank the support from the Natural Science
   Foundation of China (61702056), Educational Commission of JiangSu
   Province (17KJB520001), the Qing Lan Project of Jiangsu Province in
   China under grant No. 2017 and 333 high-level personnel training
   projects of Jiangsu Province in China under grant No. 2018 and the
   Jiangsu Students' innovation and entrepreneurship training program (NO.
   201810333029Y).
CR Ahmad M, 2017, J NETW COMPUT APPL, V93, P51, DOI 10.1016/j.jnca.2017.03.017
   Ahmed S, 2016, J SYST SOFTWARE, V121, P40, DOI 10.1016/j.jss.2016.08.001
   Beck M. T., 2016, INFORM SPEKTRUM, V39, P1, DOI DOI 10.1007/s00287-016-0957-6
   Hsieh HC, 2018, WIRELESS PERS COMMUN, V102, P527, DOI 10.1007/s11277-018-5856-5
   Jin Q, 2017, IEEE MULTIMEDIA, V24, P10, DOI 10.1109/MMUL.2017.4031321
   Kang YS, 2017, MULTIMED TOOLS APPL, V76, P19945, DOI 10.1007/s11042-016-4015-9
   Kim JW, 2015, MULTIMED TOOLS APPL, V74, P3329, DOI 10.1007/s11042-014-1965-7
   Kim YG, 2017, IEEE T COMPUT, V66, P1878, DOI 10.1109/TC.2017.2710317
   Lin P, 2016, AUTOMATICA, V65, P120, DOI 10.1016/j.automatica.2015.11.014
   Liu X, 2017, NEUROCOMPUTING, V270, P122, DOI 10.1016/j.neucom.2016.12.105
   Liu YC, 2015, COMPUT ELECTR ENG, V47, P161, DOI 10.1016/j.compeleceng.2015.04.016
   Fajardo JO, 2016, MOBILE NETW APPL, V21, P564, DOI 10.1007/s11036-016-0752-2
   Ozdamli Fezile, 2018, International Journal of Interactive Mobile Technologies, V12, P27, DOI 10.3991/ijim.v12i2.7679
   Park HD, 2017, J SUPERCOMPUT, V73, P926, DOI 10.1007/s11227-016-1750-7
   Shahzadi S, 2017, J CLOUD COMPUT-ADV S, V6, DOI 10.1186/s13677-017-0097-9
   SUNDAR S, 2018, PROCEEDINGS OF IEEE, P15, DOI DOI 10.1109/HIPCW.2018.00008
   Wang D, 2018, INFORM SCIENCES, V438, P1, DOI 10.1016/j.ins.2018.01.040
   Yan GJ, 2017, WIRELESS PERS COMMUN, V97, P3331, DOI 10.1007/s11277-017-4599-z
   Yang JC, 2017, FUTURE GENER COMP SY, V70, P94, DOI 10.1016/j.future.2016.06.015
   Yuan M, 2017, MULTIMED TOOLS APPL, V76, P17037, DOI 10.1007/s11042-016-3672-z
   Zhou JM, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0471-6
NR 21
TC 6
Z9 6
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8911
EP 8926
DI 10.1007/s11042-018-6680-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800056
DA 2024-07-18
ER

PT J
AU Nkandeu, YPK
   Tiedeu, A
AF Nkandeu, Yannick Pascal Kamdeu
   Tiedeu, Alain
TI An image encryption algorithm based on substitution technique and chaos
   mixing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Image encryption; Scrambling-masking
ID SYSTEM; CRYPTANALYSIS; IMPROVEMENT; EFFICIENT; BREAKING
AB These recent years, countless chaos-basedimage encryption algorithms have been proposed to meet security needs in real time multimedia communication. However, many of these have exhibited flaws due to thechaotic map inadequacy. In this paper, we proposed a fast and secure image encryption algorithm by using new 1D chaotic systems, with better chaotic properties in the range of their control parameters. These new chaotic systems were obtained from well-known 1D chaotic maps (Logistic, May, Gaussian, Gompertz) with flaws in their chaotic properties. From the chaotic systems designed, we extracted a pseudo random number sequence (PRNS) and generated S-boxes. Then a novel technique of plain image substitution was used to enhance the sensitivity of the original image pixels, followed by a scrambling-masking technique using the generated S-box. Security tests and evaluation metrics confirmed that the proposed cryptosystem was efficient, practicable, and reliable, with high potential to be adopted for network security and secure communications because of its high encryption speed.
C1 [Nkandeu, Yannick Pascal Kamdeu; Tiedeu, Alain] Natl Adv Sch Engn, LAGEMES, POB 8390, Yaounde, Cameroon.
RP Tiedeu, A (corresponding author), Natl Adv Sch Engn, LAGEMES, POB 8390, Yaounde, Cameroon.
EM alain.tiedeu@polytechnique.cm
RI Tiedeu, Alain/IWM-7083-2023
CR Abanda Y, 2016, IET IMAGE PROCESS, V10, P742, DOI 10.1049/iet-ipr.2015.0244
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   [Anonymous], 2009, CHAOTIC MODELLING SI
   Arroyo D, 2008, ARXIV08111859V1CSCR
   Arroyo D, 2008, ARXIV08054355V1NLINC
   Bechikh R, 2015, SIGNAL PROCESS-IMAGE, V39, P151, DOI 10.1016/j.image.2015.09.006
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, SIGNAL PROCESS, V111, P294, DOI 10.1016/j.sigpro.2015.01.003
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   Fan HJ, 2018, MULTIMED TOOLS APPL, V77, P20103, DOI 10.1007/s11042-017-5437-8
   Fouda JSAE, 2014, APPL SOFT COMPUT, V25, P435, DOI 10.1016/j.asoc.2014.08.059
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Li-bo Zhang, 2015, Mathematical Problems in Engineering, V2015, DOI 10.1155/2015/940638
   Liu H, 2014, OPT LASER TECHNOL, V56, P15, DOI 10.1016/j.optlastec.2013.07.009
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   LIU L, 2012, ENG, V28, P1240, DOI DOI 10.1016/j.compeleceng.2012.02.007
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Liu YF, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/795101
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Noura M, 2019, MOBILE NETW APPL, V24, P796, DOI 10.1007/s11036-018-1089-9
   Panduranga HT, 2014, EUR PHYS J-SPEC TOP, V223, P1663, DOI 10.1140/epjst/e2014-02119-9
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Sheela SJ, 2018, MULTIMED TOOLS APPL, P1
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang XY, 2016, OPT LASER ENG, V86, P248, DOI 10.1016/j.optlaseng.2016.06.008
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Yang B, 2019, MICROSYST TECHNOL, V25, P2649, DOI 10.1007/s00542-018-4218-2
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang XP, 2017, MULTIMED TOOLS APPL, V76, P15641, DOI 10.1007/s11042-016-3861-9
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 57
TC 58
Z9 58
U1 0
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10013
EP 10034
DI 10.1007/s11042-018-6612-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400024
DA 2024-07-18
ER

PT J
AU Wang, B
   Zhong, K
   Li, M
AF Wang, Bo
   Zhong, Kun
   Li, Ming
TI Ensemble classifier based source camera identification using fusion
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Source camera identification; Ensemble classifier; Fusion features
ID TEXTURE CLASSIFICATION; STEGANALYSIS; PATTERN
AB Source camera identification, which means identifying the camera source of a given image, has become one of the most important branches of digital image forensics. In order to improve the detection accuracy, the feature dimensions used in existing methods are increasing, and consequently Support Vector Machine (SVM) seems no longer applicable. In this paper, an ensemble classifier is introduced into to source camera identification, which uses the fusion features to capture software-related, hardware-related, and statistical characteristics left on the images by digital camera. Experimental results indicate that the proposed method can achieve near 100% accuracy for camera brand and model identification, and also outperforms the baseline methods in identifying different camera individuals.
C1 [Wang, Bo; Zhong, Kun; Li, Ming] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Liaoning, Peoples R China.
C3 Dalian University of Technology
RP Wang, B (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Liaoning, Peoples R China.
EM bowang@dlut.edu.cn
OI zhong, kun/0000-0002-0425-1603
FU National Science Foundation of China [61502076]; Scientific Research
   Project of Liaoning Provincial Education Department [L2015114]
FX This work is supported by the National Science Foundation of China (No.
   61502076) and the Scientific Research Project of Liaoning Provincial
   Education Department (No. L2015114).
CR Akshatha KR, 2016, DIGIT INVEST, V19, P69, DOI 10.1016/j.diin.2016.10.002
   [Anonymous], 2018, IEEE T CIRCUITS SYST
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bayram S, 2005, ICIP 2005, P1
   Capar C., 2007, P IEEE 14 SIGN PROC, P1, DOI [10.1109/SIU.2006.1659882, DOI 10.1109/SIU.2006.1659882]
   Chan LH, 2013, DIGIT INVEST, V10, P215, DOI 10.1016/j.diin.2013.04.001
   Choi KS, 2006, OPT EXPRESS, V14, P11551, DOI 10.1364/OE.14.011551
   Efron B., 1993, INTRO BOOTSTRAP, VVolume 914, DOI DOI 10.1007/978-1-4899-4541-9
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gloe T., 2010, Proceedings of the ACM Symposium on Applied Computing, P1584, DOI DOI 10.1145/1774088.1774427
   Janesick J. R., 1995, Opt. Photonics News, V6, P16
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Marra F, 2017, MULTIMED TOOLS APPL, V76, P4765, DOI 10.1007/s11042-016-3663-0
   Mihçak MK, 1999, INT CONF ACOUST SPEE, P3253, DOI 10.1109/ICASSP.1999.757535
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Özparlak L, 2011, IEEE T INF FOREN SEC, V6, P1418, DOI 10.1109/TIFS.2011.2162830
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Sutcu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P24
   Swaminathan A., 2006, International Conference on Acoustics, Speech and Signal Processing, V5, pV
   Swaminathan A, 2007, INT CONF ACOUST SPEE, P225
   Van LT, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P883
   [王波 Wang Bo], 2009, [电子与信息学报, Journal of Electronics & Information Technology], V31, P1175
   Wu GD, 2012, IEEE IMAGE PROC, P237, DOI 10.1109/ICIP.2012.6466839
   Xu BC, 2016, NEUROCOMPUTING, V207, P131, DOI 10.1016/j.neucom.2016.05.012
   Yao H, 2018, MULTIMED TOOLS APPL, V77, P18139, DOI 10.1007/s11042-017-5206-8
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Yongjian Hu, 2010, 2010 International Computer Symposium (ICS 2010), P506, DOI 10.1109/COMPSYM.2010.5685458
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 35
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8397
EP 8422
DI 10.1007/s11042-018-6835-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800029
DA 2024-07-18
ER

PT J
AU Wang, WD
AF Wang, Wendong
TI A novel rapid point-cloud surface reconstruction algorithm for laser
   imaging radar
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automated vehicle operation; Laser rangefinder; Image data; Depth
   surface; Interpolation; Markov random field
AB In order to obtain the fast three-dimensional surface reconstruction from given scattered point clouds, a novel improved point-cloud surface reconstruction algorithm for laser imaging radar is proposed so as to reconstruct the three-dimensional depth surface from the depth data and image data in this paper. Firstly, the three-dimensional space is partitioned into voxels with local distance points and finds outliers with point histogram features; then the Gaussian process (GP) regression is adopted to generate a plane similar to a Gaussian distribution; finally, the high-resolution gray data and three-dimensional interpolation points are fused by using Markov random fields to build a dense three-dimensional depth surface. Experimental results show that our proposed algorithm will greatly improve the robustness and reconstruction accuracy of three-dimensional surface reconstruction algorithm and can be used to assist unmanned driving in complex urban scenes.
C1 [Wang, Wendong] Yanan Univ, Coll Math & Comp Sci, Yanan 716000, Shannxi, Peoples R China.
C3 Yanan University
RP Wang, WD (corresponding author), Yanan Univ, Coll Math & Comp Sci, Yanan 716000, Shannxi, Peoples R China.
EM wangwendongls@qq.com
CR Bassier M., 2018, ANN PHOTOGRAMMETRY R
   Chan D, 2008, WORKSH MULT MULT SEN
   Diebel J., 2005, P 18 INT C NEUR INF, V18, P291
   Dolson J, 2010, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2010.5540086
   Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060
   Guarda AFR, 2017, MULT SIGN PROC 2017, P1
   Harrison A, 2010, SPRINGER TRAC ADV RO, V62, P219
   Jinghao Y, 2016, OPT PRECIS ENG, V24, P300, DOI [10.3788/OPE.20162402.0300, DOI 10.3788/OPE.20162402.0300]
   Kósa B, 2017, PROCEEDINGS OF EQUADIFF 2017 CONFERENCE, P387
   Lin Chen-Hsuan, 2017, ARXIV170607036
   Lu JB, 2011, INT CONF ACOUST SPEE, P985
   Mineo C, 2018, J COMPUTATIONAL DESI
   Rijin Z, 2014, GUILIN U ELECT TECHN
   Schoenberg J. R., 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P2033, DOI 10.1109/IROS.2010.5651749
   Shuo H, 2016, COMPUTER APPL SOFTWA, V33, P154
   Yugang L, 2016, J TRANSPORTATION SYS, V16, P79
   Zhang Aiwu, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P795
   ZHU J, 2010, TPAMI, V32, P899, DOI DOI 10.1109/TPAMI.2009.68
NR 18
TC 7
Z9 8
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8737
EP 8749
DI 10.1007/s11042-018-6244-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800047
DA 2024-07-18
ER

PT J
AU Yao, YB
   Yang, X
   Jia, TJ
   Jiang, XY
   Feng, W
AF Yao, Yingbiao
   Yang, Xu
   Jia, Tianjie
   Jiang, Xianyang
   Feng, Wei
TI Fast Bayesian decision based block partitioning algorithm for HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; High efficiency video coding (HEVC); Block partitioning;
   Bayesian decision
ID CU SIZE DECISION; MODE DECISION; CODING ALGORITHM
AB The newly published High Efficiency Video Coding (HEVC) Standard has greatly enhanced the coding performance in comparison to its predecessors. However, HEVC also has high computational complexity, which limits its application. In this paper, we propose a fast Bayesian Decision based Block Partitioning (BDBP) algorithm for HEVC encoder. Firstly, the scene change detection based on average grey difference is used to divide the video sequence into the online learning phase and the fast partitioning phase. Secondly, in the online learning phase, the statistical parameters are extracted from coding units (CUs) in every depth to establish the Gaussian mixture models which are resolved by expectation maximization algorithm; in the fast partitioning phase, the conditional probabilities for CU to decide partitioning and non-partitioning are calculated. Finally, the minimum risk Bayesian decision rule is used to choose the decision with smaller risk, and the decision is regarded as the judgment of the current CU. Experimental results show that the proposed algorithm reduces the computational complexity of HM13.0 to 54.1% in encoding time with 0.92% increase in the BD-Rate and 0.05dB decrease in the BD-PSNR. Moreover, the proposed algorithm also demonstrates better performance over other state-of-the-art work.
C1 [Yao, Yingbiao; Yang, Xu; Jia, Tianjie; Jiang, Xianyang; Feng, Wei] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Jiang, XY (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Zhejiang, Peoples R China.
EM yaoyb@hdu.edu.cn; 996213365@qq.com; 525030335@qq.com;
   jiangxy@hdu.edu.cn; fengwei@hdu.edu.cn
RI yao, yao/HHZ-7438-2022
FU China Postdoctoral Science Foundation [2017M621796]; Public Project of
   Zhejiang Province Science and Technology Commission [2017C31055]; 2017
   Open Research Foundation of Electronics Science and Technology the
   Top-ranking Discipline A Class in Zhejiang Province
FX The authors would like to thank the editors and the anonymous reviewers
   for their constructive comments and suggestions, which helped to improve
   the quality of this paper. This work was supported in part by China
   Postdoctoral Science Foundation under Grant 2017M621796, Public Project
   of Zhejiang Province Science and Technology Commission under Grant
   2017C31055, and the 2017 Open Research Foundation of Electronics Science
   and Technology the Top-ranking Discipline A Class in Zhejiang Province.
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Ahn S, 2013, PICT COD SYMP, P113, DOI 10.1109/PCS.2013.6737696
   Antenehayele EB, 2013, INT J COMPUT APPL, V59, P1
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Bossen F, 2011, COMMON TEST CONDITIO
   Bross B, 2013, JCTVCJ1003
   Chen F, 2016, SIGNAL PROCESS-IMAGE, V47, P271, DOI 10.1016/j.image.2016.07.002
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Kim IK, 2013, JCTVCO1002 ISOIEC IT
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, FORTUNE TELLER PREDI
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu X, 2017, IEEE DATA COMPR CONF, P201, DOI 10.1109/DCC.2017.48
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P2001, DOI 10.1007/s11042-015-3155-7
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Wiegand T, 2010, IEEE T CIRC SYST VID, V20, P1661, DOI 10.1109/TCSVT.2010.2095692
   Wu JX, 2015, IEEE INT ULTRA SYM, DOI 10.1109/ULTSYM.2015.0328
   Xiong J, 2014, IEEE IMAGE PROC, P3715, DOI 10.1109/ICIP.2014.7025754
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P2141, DOI 10.1109/TMM.2014.2356795
   Yao YB, 2018, MULTIMED TOOLS APPL, V77, P1861, DOI 10.1007/s11042-017-4372-z
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
NR 32
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9129
EP 9147
DI 10.1007/s11042-018-6468-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800067
DA 2024-07-18
ER

PT J
AU Choi, SB
   Kim, JM
AF Choi, Suk Bong
   Kim, Jin Min
TI Multimedia mobile application e-commerce service satisfaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia mobile applications; Mobile e-commerce; Choice-based conjoint
   analysis; Analytic hierarchy process; Online to offline
ID CUSTOMER SATISFACTION; CONJOINT-ANALYSIS; REPURCHASE INTENTION; QUALITY;
   TRUST; LOYALTY; ONLINE; AHP; DETERMINANTS; PREFERENCES
AB Previous research on e-commerce through multimedia mobile applications primarily focused on the relationships between e-service factors and positive customer behavior. However, these studies did not consider the consumer purchasing decision process sufficiently to develop firms' strategic priorities in the context of e-commerce services through multimedia mobile applications. To fill this gap, we conducted a choice-based conjoint analysis (CBCA) to identify the preferences for each attribute and the interaction effects between each pair of attributes related to the purchasing decision, and used an analytic hierarchy process (AHP) analysis to calculate the overall priorities for every sub-criterion and partial priorities for each main criterion. The main findings from the integrated CBCA and AHP are that consumers must be able to fulfill their most basic needs through multimedia mobile applications' e-commerce service, e-commerce service providers using multimedia mobile applications should enhance their existing advantages to complement their shortcomings, and e-commerce service providers besides social commerce operators should change their business structures to adapt to the new e-commerce environment. We also discuss the main contributions and implications to improve e-commerce service satisfaction and strategic decision-making.
C1 [Choi, Suk Bong; Kim, Jin Min] Korea Univ, Coll Global Business, 2511 Sejong Ro, Sejong City 30019, South Korea.
C3 Korea University
RP Kim, JM (corresponding author), Korea Univ, Coll Global Business, 2511 Sejong Ro, Sejong City 30019, South Korea.
EM sukchoi@korea.ac.kr; tristan1031@korea.ac.kr
RI Kim, Jinmin/JXN-2852-2024
OI Kim, Jinmin/0000-0002-8881-365X
CR Ahn T., 2004, Electronic Commerce Research and Applications, V3, P405, DOI DOI 10.1016/J.ELERAP.2004.05.001
   Anderson D.A., 1992, MARKET LETT, V3, P357, DOI DOI 10.1007/BF00993920
   [Anonymous], J SMALL BUS STRATEG
   Badri MA, 2001, INT J PROD ECON, V72, P27, DOI 10.1016/S0925-5273(00)00077-3
   Büyüközkan G, 2012, EXPERT SYST APPL, V39, P2341, DOI 10.1016/j.eswa.2011.08.061
   Chi Y.-S., 2015, ADV SCI TECHNOLOGY L, V114, P45
   Chong AYL, 2013, EXPERT SYST APPL, V40, P1240, DOI 10.1016/j.eswa.2012.08.067
   Chong AYL, 2012, DECIS SUPPORT SYST, V53, P34, DOI 10.1016/j.dss.2011.12.001
   Chow C.C., 2005, MANAG SERV QUAL, V15, P278, DOI DOI 10.1108/09604520510597827
   Cyr D, 2006, INFORM MANAGE-AMSTER, V43, P950, DOI 10.1016/j.im.2006.08.009
   DeLone WH, 2004, INT J ELECTRON COMM, V9, P31, DOI 10.1080/10864415.2004.11044317
   Deng ZH, 2010, INT J INFORM MANAGE, V30, P289, DOI 10.1016/j.ijinfomgt.2009.10.001
   Dholakia RR, 2010, INT J RETAIL DISTRIB, V38, P482, DOI 10.1108/09590551011052098
   Du Y., 2014, International Journal of Business and Social Science, V5, P308
   Fang YL, 2014, MIS QUART, V38, P407, DOI 10.25300/MISQ/2014/38.2.04
   Gomez-Herrera E, 2014, INF ECON POLICY, V28, P83, DOI 10.1016/j.infoecopol.2014.05.002
   GREEN PE, 1978, J CONSUM RES, V5, P103, DOI 10.1086/208721
   Hajli N, 2014, INT J MARKET RES, V56, P673, DOI 10.2501/IJMR-2014-045
   Huang EY, 2015, ELECTRON COMMER R A, V14, P126, DOI 10.1016/j.elerap.2015.01.003
   Ickler H, 2009, P 5 NAT C COMP INF T, P51
   Jones S, 2000, COMMUN ACM, V43, P80, DOI 10.1145/355112.355128
   Jun Minjoon., 2001, INT J BANK MARK, V19, P276, DOI [DOI 10.1108/02652320110409825, 10.1108/02652320110409825, https://doi.org/10.1108/02652320110409825]
   Kang M., 2015, INT J SMART HOME, V9, P135, DOI [10.14257/ijsh.2015.9.3.13, DOI 10.14257/IJSH.2015.9.3.13]
   Karniouchina EV, 2009, EUR J OPER RES, V197, P340, DOI 10.1016/j.ejor.2008.05.029
   Kuo YF, 2009, COMPUT HUM BEHAV, V25, P887, DOI 10.1016/j.chb.2009.03.003
   LAZARI AG, 1994, J MARKETING RES, V31, P375, DOI 10.2307/3152224
   Lee Y, 2006, DECIS SUPPORT SYST, V42, P1383, DOI 10.1016/j.dss.2005.11.005
   Li J., 2015, DEVELOPMENT, V1, P246
   Li YM, 2010, COMPUT HUM BEHAV, V26, P673, DOI 10.1016/j.chb.2010.01.004
   Lin HH, 2006, INFORM MANAGE-AMSTER, V43, P271, DOI 10.1016/j.im.2005.08.001
   LOUVIERE JJ, 1988, J TRANSP ECON POLICY, V22, P93
   Lu YF, 2012, J ELECTRON COMMER RE, V13, P224
   Maamar Z, 2003, COMMUN ACM, V46, P251, DOI 10.1145/953460.953508
   Maity M, 2014, DECIS SUPPORT SYST, V61, P34, DOI 10.1016/j.dss.2014.01.008
   Mei ner M, 2009, INT S AN HIER PROC
   Ngai EWT, 2007, DECIS SUPPORT SYST, V43, P1, DOI 10.1016/j.dss.2005.05.002
   Norazah MS., 2011, INT J HUMAN SOCIAL S, V1, P17
   Omonedo P, 2014, INT J SOC BEHAV ED E, V8, P3606
   Phang CW, 2014, IEEE T ENG MANAGE, V61, P623, DOI 10.1109/TEM.2014.2354056
   Quayle M, 2002, INT J OPER PROD MAN, V22, P1148, DOI 10.1108/01443570210446351
   Riedesel PL, 1985, MARKET NEWS, V19, P36
   Saaty T., 1980, The Analytic Hierarchy Process: Planning, Priority Setting, Resource Allocation
   Scholl A, 2005, EUR J OPER RES, V164, P760, DOI 10.1016/j.ejor.2004.01.026
   Scholz S.W., 2006, OR Proceedings 2005, P613
   Scholz SW, 2010, J MARKETING RES, V47, P685, DOI 10.1509/jmkr.47.4.685
   See-To EWK, 2014, COMPUT HUM BEHAV, V31, P182, DOI 10.1016/j.chb.2013.10.013
   Shankar V, 2003, INT J RES MARK, V20, P153, DOI 10.1016/S0167-8116(03)00016-8
   Siau K., 2004, P 3 ANN WORKSHOP HCI, P65
   Singh M., 2002, Managing Service Quality, V12, P434, DOI DOI 10.1108/09604520210451911
   Swilley E, 2012, INT J E-BUS RES, V8, P1, DOI 10.4018/jebr.2012010101
   Tarasewich P., 2002, COMMUN ASSOC INF SYS, V8, P41
   Tsai TM, 2015, PROCEDIA MANUF, V3, P3498, DOI 10.1016/j.promfg.2015.07.668
   Wang YS, 2007, COMPUT HUM BEHAV, V23, P381, DOI 10.1016/j.chb.2004.10.017
   WITTINK DR, 1989, J MARKETING, V53, P91, DOI 10.2307/1251345
   Yeh YS, 2009, ONLINE INFORM REV, V33, P1066, DOI 10.1108/14684520911011016
   Zhang J., 2014, International Journal of Business and Social Science, V5
   Zhang J, 2015, ACSR ADV COMPUT, V3, P28
   Zhang YX, 2011, INFORM MANAGE-AMSTER, V48, P192, DOI 10.1016/j.im.2011.05.003
   Zhao L, 2012, DECIS SUPPORT SYST, V52, P645, DOI 10.1016/j.dss.2011.10.022
   Zhao MA, 2009, MANAG SERV QUAL, V19, P286, DOI 10.1108/09604520910955311
NR 60
TC 4
Z9 4
U1 4
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5217
EP 5231
DI 10.1007/s11042-017-4865-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100008
DA 2024-07-18
ER

PT J
AU Li, ZH
   Fan, YY
   Jiang, B
   Lei, T
   Liu, WH
AF Li, Zuhe
   Fan, Yangyu
   Jiang, Bin
   Lei, Tao
   Liu, Weihua
TI A survey on sentiment analysis and opinion mining for social multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Opinion mining; Social media; Multimedia sentiment
ID VISUAL SENTIMENT; IMAGE; PREDICTION; EMOTIONS
AB Social media sentiment analysis (also known as opinion mining) which aims to extract people's opinions, attitudes and emotions from social networks has become a research hotspot. Conventional sentiment analysis concentrates primarily on the textual content. However, multimedia sentiment analysis has begun to receive attention since visual content such as images and videos is becoming a new medium for self-expression in social networks. In order to provide a reference for the researchers in this active area, we give an overview of this topic and describe the algorithms of sentiment analysis and opinion mining for social multimedia. Having conducted a brief review on textual sentiment analysis for social media, we present a comprehensive survey of visual sentiment analysis on the basis of a thorough investigation of the existing literature. We further give a summary of existing studies on multimodal sentiment analysis which combines multiple media channels. We finally summarize the existing benchmark datasets in this area, and discuss the future research trends and potential directions for multimedia sentiment analysis. This survey covers 100 articles during 2008-2018 and categorizes existing studies according to the approaches they adopt.
C1 [Li, Zuhe; Jiang, Bin] Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, Zhengzhou 450002, Henan, Peoples R China.
   [Fan, Yangyu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Lei, Tao] Shaanxi Univ Sci & Technol, Coll Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
   [Liu, Weihua] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
C3 Zhengzhou University of Light Industry; Northwestern Polytechnical
   University; Shaanxi University of Science & Technology; Chinese Academy
   of Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS
RP Li, ZH (corresponding author), Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, Zhengzhou 450002, Henan, Peoples R China.
EM zuheli@126.com
OI Li, Zuhe/0000-0002-2511-3226
FU National Natural Science Foundation of China [61702462, 61702464,
   61461025]; Scientific and Technological Project of Henan Province
   [182102210607]; Science and Technology Innovation Engineering Program
   for Shaanxi Provincial Key Laboratories [2013SZS15-K02]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61702462, 61702464 and 61461025, the Scientific and
   Technological Project of Henan Province under Grant 182102210607, and
   the Science and Technology Innovation Engineering Program for Shaanxi
   Provincial Key Laboratories under Grant 2013SZS15-K02.
CR Abburi H, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2834, DOI 10.1109/TENCON.2016.7848560
   Ahsan U, 2017, IEEE IJCNN, P1372, DOI 10.1109/IJCNN.2017.7966013
   Amencherla M, 2017, 2017 15TH CANADIAN WORKSHOP ON INFORMATION THEORY (CWIT)
   Amiriparian S, 2017, INT CONF AFFECT, P26, DOI 10.1109/ACIIW.2017.8272618
   [Anonymous], 2015, P 1 INT WORKSH AFF S, DOI 10.1145/2813524.2813530
   [Anonymous], MULT EXP ICME 2015 I
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], ARXIV151106838
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Cai GY, 2015, LECT NOTES ARTIF INT, V9362, P159, DOI 10.1007/978-3-319-25207-0_14
   Cai Z, 2016, IEEE C EVOL COMPUTAT, P4860, DOI 10.1109/CEC.2016.7744413
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Cao DL, 2016, MULTIMED TOOLS APPL, V75, P8955, DOI 10.1007/s11042-014-2337-z
   Cao DL, 2016, MULTIMEDIA SYST, V22, P479, DOI 10.1007/s00530-014-0407-8
   Chen F, 2015, 2015 IEEE 6TH INTERNATIONAL SYMPOSIUM ON MICROWAVE, ANTENNA, PROPAGATION, AND EMC TECHNOLOGIES (MAPE), P1, DOI 10.1109/MAPE.2015.7510253
   Chen M, 2017, J COMPUT SCI TECH-CH, V32, P714, DOI 10.1007/s11390-017-1753-8
   Chen SQ, 2017, C IND ELECT APPL, P1033, DOI 10.1109/ICIEA.2017.8282991
   Chen T., 2014, DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks
   Chen TH, 2014, PR IEEE COMP DESIGN, P367, DOI 10.1109/ICCD.2014.6974707
   Chen Yan-Ying, 2014, P INT C MULT RETR, P233, DOI [10.1145/2578726.2578756, DOI 10.1145/2578726.2578756]
   Chu E, 2017, IEEE DATA MINING, P829, DOI 10.1109/ICDM.2017.100
   Cui AQ, 2011, LECT NOTES COMPUT SC, V7097, P238, DOI 10.1007/978-3-642-25631-8_22
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   da Silva NFF, 2014, DECIS SUPPORT SYST, V66, P170, DOI 10.1016/j.dss.2014.07.003
   Da Silva NFF, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2932708
   Dashtipour K, 2016, COGN COMPUT, V8, P757, DOI 10.1007/s12559-016-9415-7
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Ezzat Souraya, 2012, International Journal of Computer Information Systems and Industrial Management Applications, V4, P619
   Fan YY, 2017, J ELECTRON INF TECHN, V39, P167, DOI 10.11999/JEIT160241
   Ghiassi M, 2013, EXPERT SYST APPL, V40, P6266, DOI 10.1016/j.eswa.2013.05.057
   Giachanou A, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2938640
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Hu X., 2013, WSDM
   Ji RR, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P28, DOI 10.1109/BigMM.2015.85
   Ji RR, 2016, FRONT COMPUT SCI-CHI, V10, P602, DOI 10.1007/s11704-016-5453-2
   Jiang YG, 2014, AAAI CONF ARTIF INTE, P73
   Jindal S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P447, DOI 10.1109/INFOP.2015.7489424
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Jou B, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P159, DOI 10.1145/2733373.2806246
   Jou B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P213, DOI 10.1145/2647868.2656408
   Kaushik L, 2017, IEEE-ACM T AUDIO SPE, V25, P1668, DOI 10.1109/TASLP.2017.2678164
   Kaushik L, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2709
   Kaushik L, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P239, DOI 10.1109/ASRU.2013.6707736
   Kaushik L, 2013, INT CONF ACOUST SPEE, P8485, DOI 10.1109/ICASSP.2013.6639321
   Khan FH, 2014, DECIS SUPPORT SYST, V57, P245, DOI 10.1016/j.dss.2013.09.004
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Kontopoulos E, 2013, EXPERT SYST APPL, V40, P4065, DOI 10.1016/j.eswa.2013.01.001
   Korenek P, 2014, WORLD WIDE WEB, V17, P847, DOI 10.1007/s11280-013-0247-z
   Li L, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P798, DOI 10.1109/ICCSNT.2015.7490862
   Li LX, 2017, ADV INTELL SYST COMP, V513, P309, DOI 10.1007/978-3-319-46562-3_20
   Li ZH, 2018, MULTIMED TOOLS APPL, V77, P1115, DOI 10.1007/s11042-016-4310-5
   Li ZH, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013022
   [李祖贺 Li Zuhe], 2015, [计算机应用研究, Application Research of Computers], V32, P3521
   Li ZH, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0222-1
   Lin DZ, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/6863174
   Liu HY, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P417, DOI 10.1145/2911996.2912030
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Naaman M, 2012, MULTIMED TOOLS APPL, V56, P9, DOI 10.1007/s11042-010-0538-7
   Ni Y, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON MANAGEMENT INNOVATION AND PUBLIC POLICY (ICMIPP 2012), VOLS 1-6, P1879
   Niu T., 2016, MULTIMEDIA MODELING, P15, DOI [DOI 10.1007/978-3-319-27674-82, 10.1007/978-3-319-27674-8_2]
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Sager Sebastian, 2016, ARXIV160703766
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Siddiquie B, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P203, DOI 10.1145/2818346.2820732
   Siersdorfer S., 2010, ACM MM, P715
   Speriosu M., 2011, WORKSH UNS LEARN NLP, P53
   Sun M., 2016, EVID-BASED COMPL ALT, V2016, P1, DOI DOI 10.1109/1CME.2016.7552961
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014
   Tang DY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1340
   Tang DY, 2015, WIRES DATA MIN KNOWL, V5, P292, DOI 10.1002/widm.1171
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Tsai HM, 2008, 2008 FIRST IEEE INTERNATIONAL CONFERENCE ON UBI-MEDIA COMPUTING AND WORKSHOPS, PROCEEDINGS, P231, DOI 10.1109/UMEDIA.2008.4570895
   Vadicamo L, 2017, IEEE INT CONF COMP V, P308, DOI 10.1109/ICCVW.2017.45
   Wang Jingwen., 2016, IJCAI, P3484
   Wang WN, 2008, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2008.4711705
   Wang X., 2011, Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM'11, P1031
   Wang YL, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2378
   Yadav SK, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1415
   Yang ZM, 2016, ALGORITHMS, V9, DOI 10.3390/a9010009
   You QZ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1071, DOI 10.1145/2733373.2806284
   You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1445, DOI 10.1145/2964284.2971475
   You QZ, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P13, DOI 10.1145/2835776.2835779
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yuan J., 2013, P 2 INT WORKSH ISS S, P1
   Zhang L., 2011, COMBINING LEXICON BA
NR 100
TC 73
Z9 80
U1 15
U2 156
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6939
EP 6967
DI 10.1007/s11042-018-6445-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700024
DA 2024-07-18
ER

PT J
AU Liu, ZY
   Song, TF
   Xie, F
AF Liu, Zhengyi
   Song, Tengfei
   Xie, Feng
TI RGB-D image saliency detection from 3D perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D image saliency; 3D boundary prior; 3D compactness; Manifold
   ranking
ID OBJECT DETECTION
AB With the advent of stereo camera saliency object detection for RGB-D image is attracting more and more interest. Most existing algorithms treat RGB-D image as one RGB image and one depth map, then measure saliency map independently, and last fuse them. They disregard the fact that human visual system operates in real 3D environments. The paper proposed saliency object detection for RGB-D image from 3D perspective. It regards object as three dimensional structures, and redefines boundary conception in RGB-D image, and regards space boundary including top, down, left, right, front, back plane in real 3D environment as background. It incorporates 3D compactness feature, in which salient objects typically have 3D compact spatial distributions, into color and depth feature to express similarity among supervoxels and applies manifold ranking by six boundary planes to generate six saliency maps, and then integrates them to get the RGB-D saliency map from background view. In the end it refines saliency map by high confident salient seeds from foreground view. Experiment results show that six planes of RGB-D image are superior to four sides of RGB image as background seeds and 3D compactness plays an important role in saliency measurement. Our approach outperforms other state-of-the-art algorithms on NLPR RGBD 1000 benchmark.
C1 [Liu, Zhengyi; Song, Tengfei; Xie, Feng] Anhui Univ, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei, Anhui, Peoples R China.
   [Liu, Zhengyi; Song, Tengfei; Xie, Feng] Anhui Univ, Coinnovat Ctr Informat Supply & Assurance Technol, Hefei, Anhui, Peoples R China.
C3 Anhui University; Anhui University
RP Liu, ZY (corresponding author), Anhui Univ, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei, Anhui, Peoples R China.; Liu, ZY (corresponding author), Anhui Univ, Coinnovat Ctr Informat Supply & Assurance Technol, Hefei, Anhui, Peoples R China.
EM 22927463@qq.com; sdtastf@163.com; 811173098@qq.com
RI Song, Tengfei/KLC-7410-2024; Liu, Zhengyi/AAB-6589-2022; Liu,
   Zhengyi/AAD-6702-2020
OI Song, Tengfei/0000-0002-8512-0081; Liu, Zhengyi/0000-0003-3265-823X; 
FU Anhui University; National Key Technology Research and Development
   Program of the Ministry of Science and Technology of China
   [2015BAK24B01]; Key Program of Natural Science Project of Educational
   Commission of Anhui Province, China [KJ2015A009]; Open issues on
   Co-Innovation Center for Information Supply & Assurance Technology,
   Anhui University [ADXXBZ201610]
FX We thank Prof. Jianguo Wu from Anhui University for helping with
   acquisition of funding. We also thank all anonymous reviewers for their
   valuable comments. This research is supported by National Key Technology
   Research and Development Program of the Ministry of Science and
   Technology of China (2015BAK24B01), Key Program of Natural Science
   Project of Educational Commission of Anhui Province, China (KJ2015A009),
   Open issues on Co-Innovation Center for Information Supply & Assurance
   Technology, Anhui University (ADXXBZ201610).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ahmad J, 2017, J REAL-TIME IMAGE PR, V13, P431, DOI 10.1007/s11554-015-0536-0
   [Anonymous], 2016, 2016 INT C SIGNAL PR
   Bai, 2015, P 7 INT C INT MULT C, P1
   Chaib S, 2016, INT GEOSCI REMOTE SE, P2742, DOI 10.1109/IGARSS.2016.7729708
   Cheng Y, 2014, MOBIHOC'14: PROCEEDINGS OF THE 15TH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P23, DOI 10.1145/2632951.2632978
   Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Guo J, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING ICISCE 2015, P59, DOI 10.1109/ICISCE.2015.22
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hussain CA, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P840, DOI 10.1109/ICEEOT.2016.7754804
   Hussain CA, 2016, PROCEDIA COMPUT SCI, V85, P571, DOI 10.1016/j.procs.2016.05.223
   Jiang LX, 2015, IEEE INT CONF ROBOT, P1323, DOI 10.1109/ICRA.2015.7139362
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Khanna MT, 2015, PERCEPTION AND MACHINE INTELLIGENCE, 2015, P218, DOI 10.1145/2708463.2709063
   Krause EA, 2014, LEARNING RECOGNIZE N, P2796
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li ZY, 2016, PATTERN RECOGN, V52, P317, DOI 10.1016/j.patcog.2015.10.009
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Oh SJ, 2017, PROC CVPR IEEE, P5038, DOI 10.1109/CVPR.2017.535
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Papushoy A, 2015, DIGIT SIGNAL PROCESS, V36, P156, DOI 10.1016/j.dsp.2014.09.005
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Qi MS, 2016, IEEE IMAGE PROC, P1047, DOI 10.1109/ICIP.2016.7532517
   Ren JK, 2015, EUROMICRO, P25, DOI 10.1109/ECRTS.2015.10
   Sun JW, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), P241, DOI 10.1109/ICALIP.2016.7846544
   Tamura Y, 2016, INT J SOC ROBOT, V8, P685, DOI 10.1007/s12369-016-0354-y
   Tang YL, 2016, VISUAL COMPUT, V32, P111, DOI 10.1007/s00371-014-1059-6
   Wu PL, 2015, COMM COM INF SC, V547, P359, DOI 10.1007/978-3-662-48570-5_35
   Xiao Zhang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P515, DOI 10.1007/978-3-319-27671-7_43
   Xue HY, 2015, IEEE IMAGE PROC, P666, DOI 10.1109/ICIP.2015.7350882
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang J, 2016, IEEE INT CONF MULTI
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang LB, 2017, IEEE GEOSCI REMOTE S, V14, P23, DOI 10.1109/LGRS.2016.2623670
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhu GB, 2016, AAAI CONF ARTIF INTE, P3690
   Zhu S, 2016, CHIN CONTR CONF, P5008, DOI 10.1109/ChiCC.2016.7554132
   Zhu W, P IEEE C COMP VIS PA, P2814
NR 42
TC 2
Z9 3
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6787
EP 6804
DI 10.1007/s11042-018-6319-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700017
DA 2024-07-18
ER

PT J
AU Mohammad, AA
   Al-Haj, A
   Farfoura, M
AF Mohammad, Ahmad A.
   Al-Haj, Ali
   Farfoura, Mahmoud
TI An improved capacity data hiding technique based on image interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Image interpolation; High capacity data hiding;
   Interpolation based data hiding; Reversible data hiding
ID WATERMARKING; ALGORITHM; SCHEME; SECURE; EFFICIENT
AB Data hiding in multimedia objects such as text, images, audio and video clips is a technique that has been widely used to achieve security for applications requiring copyright protection, covert communication, and tampering detection. Data hiding can be irreversible or reversible, where the latter is used to ensure exact recovery of the media object after extracting the hidden data. Different approaches to achieve reversible data hiding have been proposed. One of the approaches is the interpolation-based data hiding which has been proposed to achieve high data hiding capacity. This paper presents a new computationally simple interpolation-based data hiding technique that increases data hiding capacity and limits the cover image distortion that is caused by the two major steps of interpolation-based techniques; the downscaling/expansion step and the data hiding step . Image distortion reduction in the downscaling/expansion step is achieved by using a new image interpolation algorithm, whereas the image distortion in the data hiding step is reduced utilizing a new adjustable data hiding algorithm, which adaptively adjusts the level of tradeoff between data hiding capacity and image quality. The performance of the proposed technique has been evaluated for data hiding capacity and image quality using three metrics: peak signal to noise ratio (PSNR), weighted PSNR (WPSNR), and structural similarity index (SSIM). The data hiding capacity achieved by the proposed technique can be as high as 1.7bpp, which is higher by 8.5 to 72% as compared to similar techniques. Moreover, for the data hiding step, the proposed algorithm achieved high quality images as reflected by values up to 54dB for PSNR, 78dB for WPSNR, and 0.9998 for SSIM.
C1 [Mohammad, Ahmad A.] Princess Sumaya Univ Technol, Dept Comp Engn, Amman, Jordan.
   [Al-Haj, Ali] Princess Sumaya Univ Technol, Amman, Jordan.
   [Farfoura, Mahmoud] Royal Sci Soc, Amman, Jordan.
C3 Princess Sumaya University for Technology; Princess Sumaya University
   for Technology
RP Mohammad, AA (corresponding author), Princess Sumaya Univ Technol, Dept Comp Engn, Amman, Jordan.
EM atawayha@psut.edu.jo
RI Mohammad, Ahmad A./AAA-6444-2019
OI Mohammad, Ahmad A./0000-0001-8271-9729; Farfoura,
   Mahmoud/0000-0002-9010-6989
CR Adi P, 2017, COMMUNICATION INFORM, V11, P93
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Chen M, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P19
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Franco-Contreras J, 2014, IEEE T INF FOREN SEC, V9, P397, DOI 10.1109/TIFS.2013.2294240
   Govind PVS, 2016, PROC TECH, V24, P1311, DOI 10.1016/j.protcy.2016.05.129
   Gupta S, 2018, MULTIMED TOOLS APPL, V77, P4829, DOI 10.1007/s11042-016-3735-1
   Hong W., 2010, INFORM TECHNOLOGY J, V9, P179, DOI DOI 10.3923/ajit.2010.179.182
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2010, SIGNAL PROCESS, V90, P2911, DOI 10.1016/j.sigpro.2010.04.012
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kumar M, 2016, SECUR COMMUN NETW, V9, P3703, DOI 10.1002/sec.1575
   Li J, 2015, IEEE T COMPUT, V64, P3569, DOI 10.1109/TC.2015.2401017
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   LI X, 1933, TIP, V20, P3524, DOI DOI 10.1109/TIP.2011.2150233
   Ling Liu, 2014, Information Technology Journal, V13, P2374, DOI 10.3923/itj.2014.2374.2384
   LU TC, 2017, ELECTRON, V130, P1377, DOI DOI 10.1016/j.ijleo.2016.11.176
   Lu TC., 2016, INT J COMPUT SOFTW E, V1, P102, DOI [10.15344/2456-4451/2016/102, DOI 10.15344/2456-4451/2016/102]
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Petty T., 2016, Handbook of Research on Professional Development for Quality Teaching and Learning
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Rudder A., 2013, INT J NETW SECUR APP, V5, P65, DOI [10.48550/arXiv.1305.4102, DOI 10.48550/ARXIV.1305.4102]
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sanglikar H, 2015, INT J TECHNICAL RES, V3, P52, DOI DOI 10.1109/TIFS.2013.2248725
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Sreekumar K., 2014, INT J COMPUT SCI INF, V5, P7748
   Srivastava R, 2018, MULTIMED TOOLS APPL, V77, P16447, DOI 10.1007/s11042-017-5214-8
   Subburam S, 2018, MULTIMED TOOLS APPL, V77, P7071, DOI 10.1007/s11042-017-4622-0
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Vidya H, 2013, ADV INTELLIGENT SYST, V177, P175
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wang XT, 2013, INT J CLOUD APPL COM, V5, P35
   Yang CHT, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 2, PROCEEDINGS, P603, DOI 10.1109/IAS.2009.79
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang ZW, 2017, KSII T INTERNET INF, V11, P1761, DOI 10.3837/tiis.2017.03.028
   Zhang ZW, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147716686577
   Zkik K, 2017, INT J CLOUD APPL COM, V7, P62, DOI 10.4018/IJCAC.2017040105
NR 54
TC 35
Z9 35
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7181
EP 7205
DI 10.1007/s11042-018-6465-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700035
DA 2024-07-18
ER

PT J
AU Kim, M
   Jo, W
   Kim, J
   Shon, T
AF Kim, Myungjong
   Jo, Wooyeon
   Kim, Jaehoon
   Shon, Taeshik
TI Visualization for internet of things: power system and financial network
   cases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Industrial control system; Financial network; Visualization; Network
   forensics; DNP3; FIX
AB National critical infrastructure networks, such as banks and industrial control systems (ICSs), can be serious damaged in the event of a security incident. Therefore, in all these major infrastructures, closed networks are constructed to cut off the attack path. However, owing to the emergence of cloud, Internet of Things (IoT), and artificial intelligence (AI) services, network interconnection is rapidly increasing; thus, many major infrastructure networks can no longer be called closed networks. The ICS, which was previously a strictly closed network, is now usually called Industrial Internet of Things (IIoT) and exhibits many changes, such as smart factories and remote control. Many payment modules use the financial network through IoT or AI-assisted services. In this massive connected environment, the existing closed network defense system may cause difficulties in providing the service. Therefore, there is a need for technology that can continuously monitor the possibility of advanced attacks. In this paper, we define the normal-behavior-based rules from the perspective of network forensics and conduct visualization studies to detect all possible attacks against the control protocol DNP3 (Distributed Network Protocol) and the financial protocol called FIX (Finance Information Exchange). Thus, we detected suspicious network packets on the ICS network and the financial network and identified abnormal behavior that could be the basis of serious attacks.
C1 [Kim, Myungjong; Jo, Wooyeon; Kim, Jaehoon; Shon, Taeshik] Ajou Univ, Suwon 443749, Gyunggi Do, South Korea.
C3 Ajou University
RP Shon, T (corresponding author), Ajou Univ, Suwon 443749, Gyunggi Do, South Korea.
EM myung7769@gmail.com; dndusdndus12@gmail.com; jaikim@ajou.ac.kr;
   tsshon@ajou.ac.kr
FU Ministry of Science and ICT (MSIT), Korea, under the Information
   Technology Research Center support program [IITP-2018-2016-0-00304];
   IITP grant - Korean government (MSIT) [2018-0-00336]; Ajou University
FX This research was supported by the Ministry of Science and ICT (MSIT),
   Korea, under the Information Technology Research Center support program
   IITP-2018-2016-0-00304 supervised by the Institute for Information &
   Communications Technology Promotion (IITP).; This work was supported by
   an IITP grant funded by the Korean government (MSIT) (No. 2018-0-00336,
   Advanced Manufacturing Process Anomaly Detection to prevent the Smart
   Factory Operation Failure by Cyber Attacks).; This work was supported by
   the Ajou University research fund.
CR Abeyrathne KB, 2009, VISUALIZATION TOOL N, P3
   Ahmed I, 2012, COMPUTER, V45, P44, DOI 10.1109/MC.2012.325
   Angelini M, 2015, VIS CYB SEC VIZSEC 2
   [Anonymous], 2017, FIX PROTOCOL USERS
   [Anonymous], 2012, IEEE STAND EL POW SY
   [Anonymous], IDS RAINSTORM VISUAL
   [Anonymous], 2017, FIX PROTOCOL S KOREA
   [Anonymous], 2001, FINANCIAL INFORM EXC
   Arendt D, 2016, VIS CYB SEC VIZSEC 2
   Blue R, 2008, LECT NOTES COMPUT SC, V5210, P119, DOI 10.1007/978-3-540-85933-8_12
   Clarke G., 2004, Practical Modern SCADA Protocols: DNP3
   Digital bond, 2016, DOWNL PCAP FIL TEST
   FIREEYE, 2016, IND CONTR SYST HLTH
   ICS security summit, 2016, WHATS DFIR ICS, P4
   ICS-CERT, 2016, ICS CERT MON
   ICS-CERT, 2018, MAR1735201 ICSCERT
   박재범, 2014, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V24, P1197, DOI 10.13089/JKIISC.2014.24.6.1197
   NETRESEC, 2016, NETW
   Promrit N, 2011, NETW COMP INC 2011 7
   Shahzad A, 2015, SYMMETRY-BASEL, V7, P1945, DOI 10.3390/sym7041945
   Shiravi H, 2012, IEEE T VIS COMPUT GR, V18, P1313, DOI 10.1109/TVCG.2011.144
   Siadati H, 2016, VIS CYB SEX VIZSEC 2
   U.S. CERT, 2018, VPNFILTER DESTR MALW
   van Riel J.-P., 2006, P 4 INT C COMP GRAPH, P85
NR 24
TC 7
Z9 7
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3241
EP 3265
DI 10.1007/s11042-018-6730-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600032
DA 2024-07-18
ER

PT J
AU Liang, Y
   Zhang, SH
   Martin, RR
AF Liang, Yuan
   Zhang, Song-Hai
   Martin, Ralph Robert
TI Learning guidelines for automatic indoor scene design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Open-world application; Automatic layout; Probabilistic model;
   Constrained optimization
AB In this work, we address a novel and practical problem of automatically generating a room design from given room function and basic geometry, which can be described as picking appropriate objects from a given database, and placing the objects with a group of pre-defined criteria. We formulate both object selection and placement problems as probabilistic models. The object selection is first formulated as a supervised generative model, to take room function into consideration. Object placement problem is then formulated as a Bayesian model, where parameters are inferred with Maximizing a Posteriori (MAP) objective. We solve the placement problem efficiently by introducing a solver based on Markov Chain Monte Carlo with a specific proposal function designed for the problem.
C1 [Liang, Yuan; Zhang, Song-Hai] Tsinghua Univ, TNList, Beijing, Peoples R China.
   [Martin, Ralph Robert] Cardiff Univ, Sch Comp Sci, Informat, Cardiff CF24 3AA, S Glam, Wales.
C3 Tsinghua University; Cardiff University
RP Liang, Y (corresponding author), Tsinghua Univ, TNList, Beijing, Peoples R China.
EM liangyua14@mails.tsinghua.edu.cn; shz@tsinghua.edu.cn; ralph@cs.cf.ac.uk
RI Martin, Ralph R/D-2366-2010
OI Martin, Ralph/0000-0002-8495-8536; Liang, Yuan/0000-0001-9816-2910
FU National Key R&D Program of China [2017YFB1002604]; National Natural
   Science Foundation of China [61772298]; Research Grant of Beijing Higher
   Institution Engineering Research Center; People Programme (Marie Curie
   Actions) of the European Union's Seventh Framework Programme
   FP7/2007-2013/ under REA grant [612627]
FX This work was supported by National Key R&D Program of China (No.
   2017YFB1002604), the National Natural Science Foundation of China (No.
   61772298), Research Grant of Beijing Higher Institution Engineering
   Research Center and the People Programme (Marie Curie Actions) of the
   European Union's Seventh Framework Programme FP7/2007-2013/ under REA
   grant agreement no [612627].
CR [Anonymous], 2017, Sketchup
   [Anonymous], HUM
   [Anonymous], 2017, THE SIMS
   [Anonymous], 2017, AUTODESK REVIT
   [Anonymous], 2017, ARCHICAD
   BELLONI A, 2011, AOS, V37, P2011, DOI DOI 10.1214/08-AOS634
   Blei DM, 2004, ADV NEUR IN, V16, P17
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brooks SP, 1998, J COMPUT GRAPH STAT, V7, P434, DOI 10.2307/1390675
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Chang A.X., 2017, ARXIV170300050, P1
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Fisher M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964929
   Fisher M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866204
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gelman A., 1992, STAT SCI, V7, P457, DOI 10.1214/ss/1177011136
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Guo XK, 2014, GRAPH MODELS, V76, P376, DOI 10.1016/j.gmod.2014.03.019
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu J. S, 2008, Monte Carlo strategies in scientific computing
   Liu JS, 2000, J AM STAT ASSOC, V95, P121, DOI 10.2307/2669532
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Merrell P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964982
   Murray L, 2010, P NEUR INF PROC SYST, V11
   Padmanabhan V. N., 1996, Computer Communication Review, V26, P22, DOI 10.1145/235160.235164
   Papadimitriou C. H., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P159, DOI 10.1145/275487.275505
   Ramage Daniel., 2009, EMNLP, DOI DOI 10.3115/1699510.1699543
   Savva Manolis, 2017, ARXIV170300061
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461968
   Yeh YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185552
   Yu LF, 2016, IEEE T VIS COMPUT GR, V22, P1138, DOI 10.1109/TVCG.2015.2417575
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
NR 37
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 5003
EP 5023
DI 10.1007/s11042-018-6004-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200056
DA 2024-07-18
ER

PT J
AU Prandi, C
   Melis, A
   Prandini, M
   Delnevo, G
   Monti, L
   Mirri, S
   Salomoni, P
AF Prandi, Catia
   Melis, Andrea
   Prandini, Marco
   Delnevo, Giovanni
   Monti, Lorenzo
   Mirri, Silvia
   Salomoni, Paola
TI Gamifying cultural experiences across the urban environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart city; Cultural heritage; Gamification; Crowdsourcing;
   Microservices; Personal travel planner
AB New media and devices are offering huge possibilities for the enhancement and the enrichment of heritage experiences, improving the users' involvement. In particular, tourists equipped with their mobile devices are invading cultural attractions, sharing pictures and comments (together with hashtags and geo-localized positions) on social networks. These represent an unofficial source of data, which can be integrated with the official ones provided by GLAM (Galleries, Libraries, Archives, and Museums) and cultural heritage institutions, enriching them. At the same time, travel planners and mobile applications related to cultural heritage can play an interesting role in the development of smart cities, when they are integrated each other, engaging the user in touristic and entertainment activities, letting him/her be a source of cultural resources.This work focuses on equipping users (citizens and tourists) with a system providing support in computing personalized urban paths across cultural heritage places (monuments, palaces, museums, and other points of interest (POIs) related to cultural heritage in the urban environment) and in sharing multimedia resources about POIs, by exploiting gamification elements with the aim of engaging citizens and tourists. A mobile application prototype has been implemented, showing the feasibility of the proposed approach and exploiting crowdsourcing activities as a source of information for cultural places and works of art.
C1 [Prandi, Catia] Univ Madeira, Madeira Interact Technol Inst, 2 Caminho Penteada, P-9020105 Funchal, Madeira, Portugal.
   [Melis, Andrea] Univ Bologna, Dept Elect Elect & Informat Engn Guglielmo Marcon, Viale Risorgimento 2, I-40136 Bologna, Italy.
   [Prandini, Marco; Delnevo, Giovanni; Monti, Lorenzo; Mirri, Silvia; Salomoni, Paola] Univ Bologna, Dept Comp Sci & Engn, Mura Anteo Zamboni 7, I-40126 Bologna, Italy.
C3 Universidade da Madeira; University of Bologna; University of Bologna
RP Mirri, S (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Mura Anteo Zamboni 7, I-40126 Bologna, Italy.
EM silvia.mirri@unibo.it
RI Prandi, Catia/KIB-1268-2024; Melis, Andrea/GYJ-7440-2022; Delnevo,
   Giovanni/AAP-4798-2020; Mirri, Silvia/I-7983-2016
OI Prandi, Catia/0000-0002-5566-2269; Delnevo,
   Giovanni/0000-0001-6640-5746; Mirri, Silvia/0000-0002-5385-4734; Melis,
   Andrea/0000-0002-0101-2551; Monti, Lorenzo/0000-0002-2087-0535;
   PRANDINI, MARCO/0000-0002-3962-5513
CR [Anonymous], 2007, P INT CROSS DISC C W
   [Anonymous], 2015, MYDATA NORDIC MODEL
   [Anonymous], 2017, P IEEE INT C COMM IC
   [Anonymous], 2011, ACM COMPUT ENTERTAIN
   [Anonymous], 2016, MIS
   Buchenau M., 2000, DIS2000. Designing Interactive Systems Processes, Practices, Methods, and Techniques. Conference Proceedings, P424, DOI 10.1145/347642.347802
   Bujari A, 2017, PERS UBIQUIT COMPUT, V21, P235, DOI 10.1007/s00779-016-0989-6
   Bujari A, 2012, CONSUM COMM NETWORK, P502, DOI 10.1109/CCNC.2012.6181029
   CALLEGATI F, 2015, NETW SOFTW NETSOFT 2, P1, DOI DOI 10.1109/ICTON.2015.7193561
   Callegati F, 2017, IEEE SYMP COMP COMMU, P18, DOI 10.1109/ISCC.2017.8024498
   Dragoni N., 2017, PRESENT ULTERIOR SOF, P195, DOI DOI 10.1007/978-3-319-67425-4_12
   Dusi N, 2017, ENTERTAIN COMPUT, V21, P65, DOI 10.1016/j.entcom.2017.05.002
   Ferretti S, 2016, J SYST SOFTWARE, V121, P157, DOI 10.1016/j.jss.2016.02.008
   Furini M, 2017, COMM COM INF SC, V733, P187, DOI 10.1007/978-3-319-68130-6_15
   Heipke C, 2010, ISPRS J PHOTOGRAMM, V65, P550, DOI 10.1016/j.isprsjprs.2010.06.005
   Lea G., 2015, Microservices security: all the questions you should be asking
   Meliones A., 2016, Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments, P1, DOI [DOI 10.1145/2910674.2910721, 10.1145/2910674.2910721]
   Mirri Silvia, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P1119, DOI 10.1109/CCNC.2016.7444946
   Mirri S, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P833, DOI 10.1109/HPCSim.2014.6903776
   Morschheuser B, 2016, P ANN HICSS, P4375, DOI 10.1109/HICSS.2016.543
   Newman S., 2015, BUILDING MICROSERVIC
   Prandi C., 2015, CHItaly, V2015, P126, DOI [10.1145/2808435.2808449, DOI 10.1145/2808435.2808449]
   Prandi C, 2017, MULTIMED TOOLS APPL, V76, P4951, DOI 10.1007/s11042-016-3780-9
   Prandi C, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P402, DOI 10.1109/PERCOMW.2015.7134071
   Roccetti M, 2008, CONSUM COMM NETWORK, P1123, DOI 10.1109/ccnc08.2007.253
   Stathopoulou EK, 2015, ISPRS ANN PHOTO REM, P295, DOI 10.5194/isprsannals-II-5-W3-295-2015
   VANHOOLAND S, 2006, IMMACULATE CATALOGUE
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 31
TC 21
Z9 22
U1 2
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3341
EP 3364
DI 10.1007/s11042-018-6513-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600038
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tai, LJ
   Li, LH
   Du, J
AF Tai, Lingjuan
   Li, Linhong
   Du, Jun
TI RETRACTED: Multimedia based intelligent network big data optimization
   model (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Intelligent network; Data mining; Big data; Optimization model; Soft
   computing; Multimedia systems
ID FRAMEWORK
AB The data of a city space is very large. In the city, there are tens of the thousands of sensors of video, audio and image at the same time. Real-time communication and reception of relevant information are carried out. Real-time monitoring of key areas and key persons and real-time warning information, of course, these operations are in the protection of the privacy and the security monitoring object under the premise of intelligent application analysis. To solve this challenge, this paper proposes the multimedia based intelligent network big data optimization model. To make the game decision between service behavior and ethnic behavior and to achieve a comparison between the specific behaviors in the action domain, two behavior comparison criteria need to be defined. The data level includes the data layer memory module and the forwarding module. The data layer memory module is used to store the content of the service, and the forward module is used to forward the data. Forward when the data flows through the module, the data layer memory modules can be according to the requirements of component control level and store the corresponding service content, and further described the service identification and service information notices to component level control. The intelligent multimedia information processing technology used in multimedia sensor networks should take into account two factors: one is the complexity of the processing, the computing power of the multimedia sensor nodes is limited, and the overly complicated processing technology is not suitable; and the second is the multimedia sensor network features and application requirements. The proposed method dealt with the challenges well, the validation proves the robustness.
C1 [Tai, Lingjuan; Li, Linhong] Kunming Univ Sci & Technol, Fac Econ & Management, Kunming 650093, Yunnan, Peoples R China.
   [Du, Jun] Kunming Univ, Inst Urban & Rural Construct & Engn Management, Kunming, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University
RP Tai, LJ (corresponding author), Kunming Univ Sci & Technol, Fac Econ & Management, Kunming 650093, Yunnan, Peoples R China.
EM ruiluan1969q@yeah.net
FU National Natural Science Foundation of China [71463032]
FX This research is financially supported by the National Natural Science
   Foundation of China (71463032): Research on Sustainable Development of
   Yunnan Mountain Agriculture Based on Hypernetwork.
CR Akhavan-Rezai E, 2016, IEEE SYST J, V10, P483, DOI 10.1109/JSYST.2014.2349357
   Al-Bashir AK, 2017, J MED IMAG HEALTH IN, V7, P1789, DOI 10.1166/jmihi.2017.2217
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   [Anonymous], COMMUN
   [Anonymous], ENCY BUSINESS ANAL O
   [Anonymous], CLUST COMPUT
   [Anonymous], FUT GEN COMPUT SYST
   [Anonymous], 2014, J NE NORM U, DOI DOI 10.16164/J.CNKI.22-1062/C.2014.02.029
   [Anonymous], APPL SOFT COMPUT
   [Anonymous], INFO
   [Anonymous], CLUSTER COMPUT
   Boididou Christina, 2017, MULTIMED TOOLS APPL, P1
   Brown K, 2017, IEEE INT CON DIS, P343, DOI 10.1109/ICDCSW.2017.74
   Castro-Tirado AJ, 2014, REV MEX AST ASTR, V45, P104
   Chandra S., 2015, IEEE INT C COMP VIS, P44
   Cheng X, 2015, IEEE T INTELL TRANSP, V16, P1784, DOI 10.1109/TITS.2014.2377074
   Chianese A, 2015, J LOCAT BASED SERV, V9, P209, DOI 10.1080/17489725.2015.1099752
   Duer S, 2013, NEURAL COMPUT APPL, V23, P2185, DOI 10.1007/s00521-012-1169-x
   Facchinei F, 2015, IEEE T SIGNAL PROCES, V63, P1874, DOI 10.1109/TSP.2015.2399858
   Fusco G, 2015, 2015 INTERNATIONAL CONFERENCE ON MODELS AND TECHNOLOGIES FOR INTELLIGENT TRANSPORTATION SYSTEMS (MT-ITS), P93, DOI 10.1109/MTITS.2015.7223242
   Jiang YZ, 2017, J MED IMAG HEALTH IN, V7, P1772, DOI 10.1166/jmihi.2017.2261
   Jin XL, 2015, MULTIMED TOOLS APPL, V74, P2743, DOI 10.1007/s11042-015-2458-z
   Kadurek P, 2014, IEEE T SMART GRID, V5, P84, DOI 10.1109/TSG.2013.2289372
   Kumar K, 2013, MOBILE NETW APPL, V18, P129, DOI 10.1007/s11036-012-0368-0
   Liu Q, 2017, 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC), P528, DOI 10.1109/DSC.2017.28
   Liu YZ, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION (ICICTA), P936, DOI 10.1109/ICICTA.2014.225
   Omidvar A, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-147
   Park J, 2014, IEEE T CIRCUITS-I, V61, P476, DOI 10.1109/TCSI.2013.2284188
   Poria S, 2015, NEURAL NETWORKS, V63, P104, DOI 10.1016/j.neunet.2014.10.005
   Qiu W, 2014, CONSUMER ELECT CHINA, P1
   Quick D, 2017, SOFTWARE PRACT EXPER, V47, P1095, DOI 10.1002/spe.2429
   Riggins FJ, 2015, P ANN HICSS, P1531, DOI 10.1109/HICSS.2015.186
   Saad RMA, 2016, IETE TECH REV, V33, P244, DOI 10.1080/02564602.2015.1098576
   Salih YK, 2014, J CENT SOUTH UNIV, V21, P3138, DOI 10.1007/s11771-014-2286-8
   Singh S. K., 2017, SUSTAINABILITY-BASEL, P1
   Suthaharan Shan, 2014, ACM SIGMETRICS Performance Evaluation Review, V41, P70
   Trappey AJC, 2015, COMPUT IND ENG, V84, P3, DOI 10.1016/j.cie.2014.12.033
   Tripathi Nishtha, 2014, Big Data Analytics. Third International Conference, BDA 2014. Proceedings: LNCS 8883, P189, DOI 10.1007/978-3-319-13820-6_17
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang JB, 2015, IEEE SYS MAN CYBERN, P1870, DOI 10.1109/SMC.2015.327
   Wang MQ, 2014, PROCEDIA COMPUT SCI, V32, P85, DOI 10.1016/j.procs.2014.05.401
   Yang B, 2016, ADV INTELL SYST, V420, P155, DOI 10.1007/978-3-319-27221-4_13
   Zhang LR, 2014, IEEE INT CONF INNOV, P88, DOI 10.1109/INNOVATIONS.2014.6987568
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
NR 44
TC 10
Z9 10
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4579
EP 4603
DI 10.1007/s11042-018-6391-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200035
DA 2024-07-18
ER

PT J
AU Guo, HJ
   Han, SQ
   Hao, F
   Park, DS
   Min, G
AF Guo, Huijuan
   Han, Suqing
   Hao, Fei
   Park, Doo-Soon
   Min, Geyong
TI SOSP: a stepwise optimal sparsity pursuit algorithm for practical
   compressed sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Sparsity pursuit; Estimated sparsity;
   Reconstruction; Greedy algorithm
ID SIGNAL RECOVERY; RECONSTRUCTION
AB Compressed Sensing (CS), as a promising paradigm for acquiring signals, is playing an increasing important role in many real-world applications. One of the major components of CS is sparse signal recovery in which greedy algorithm is well-known for its speed and performance. Unfortunately, in many classic greedy algorithms, such as OMP and CoSaMP, the real sparsity is a key prior information, but it is blind. In another words, the true sparsity is not available for many practical applications. Due to this disadvantage, the performance of these algorithms are significantly reduced. In order to avoid too much dependence of classic greedy algorithms on the true sparsity, this paper proposed an efficient reconstruction greedy algorithm for practical Compressed Sensing, termed stepwise optimal sparsity pursuit (SOSP). Differs from the existing algorithms, the unique feature of SOSP algorithm is that the assumption of sparsity is needed instead of the true sparsity. Hence, the limitations of sparsity in practical application can be tackled. Based on an arbitrary initial sparsity satisfying certain conditions, the SOSP algorithm employs two variable step sizes to hunt for the optimal sparsity step by step by comparing the final reconstruction residues. Since the proposed SOSP algorithm preserves the ideas of original algorithms and innovates the prior information of sparsity, thus it is applicable to any effective algorithm requiring known sparsity. Extensive experiments are conducted in order to demonstrate that the SOSP algorithm offers a superior reconstruction performance in terms of discarding the true sparsity.
C1 [Guo, Huijuan; Han, Suqing] Taiyuan Normal Univ, Dept Comp Sci & Technol, Taiyuan 030619, Shanxi, Peoples R China.
   [Hao, Fei] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Shaanxi, Peoples R China.
   [Park, Doo-Soon] Soonchunhyang Univ, Dept Comp Software Engn, Asan, South Korea.
   [Min, Geyong] Univ Exeter, Dept Math & Comp Sci, Exeter, Devon, England.
C3 Taiyuan Normal University; Shaanxi Normal University; Soonchunhyang
   University; University of Exeter
RP Han, SQ (corresponding author), Taiyuan Normal Univ, Dept Comp Sci & Technol, Taiyuan 030619, Shanxi, Peoples R China.
EM guohuijuan@tynu.edu.cn; hansuqing@tynu.edu.cn; feehao@gmail.com;
   parkds@sch.ac.kr; g.min@exeter.ac.uk
RI park, doo-soon/AAM-7730-2020
OI park, doo-soon/0000-0002-2776-8832; Hao, Fei/0000-0001-5288-5523
FU National Science Foundation of China [61273294]; Youth Foundation of
   Shanxi Province, China [201601D202040]; Fundamental Research Funds for
   the Central Universities, China [GK201703059]; Natural Science
   Foundation for Young Scientists of Shanxi Province, China [2015021102];
   Basic Science Research program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2017R1A2B1008421]
FX The authors would like to thank their colleagues for many useful
   comments. In particular, they are grateful to Xuefei Bai of Shanxi
   University for many discussions on the OMP and CoSaMP code. This work
   was supported by the National Science Foundation of China (No. 61273294)
   and Youth Foundation of Shanxi Province, China (201601D202040). F. Hao's
   work was supported by the Fundamental Research Funds for the Central
   Universities, China (Grant No. GK201703059) and the Natural Science
   Foundation for Young Scientists of Shanxi Province, China (Grant No.
   2015021102). D.S. Park's work was supported by Basic Science Research
   program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Education (No. NRF-2017R1A2B1008421).
CR Ambat SK, 2014, IEEE T SIGNAL PROCES, V62, P1705, DOI 10.1109/TSP.2014.2303941
   Baraniuk Richard, 2007, 2007 IEEE Radar Conference, P128, DOI 10.1109/RADAR.2007.374203
   Baraniuk RG, 2011, SCIENCE, V331, P717, DOI 10.1126/science.1197448
   Budillon A, 2011, IEEE T GEOSCI REMOTE, V49, P488, DOI 10.1109/TGRS.2010.2054099
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Fang LY, 2013, IEEE T MED IMAGING, V32, P2034, DOI 10.1109/TMI.2013.2271904
   Hegde C, 2015, IEEE T SIGNAL PROCES, V63, P6109, DOI 10.1109/TSP.2015.2452228
   Kajbaf H, 2013, IET RADAR SONAR NAV, V7, P658, DOI 10.1049/iet-rsn.2012.0149
   Kowalski M, 2012, ANN DAAAM 2012 P 23, V23
   Lawrie J, 2013, OPT EXPRESS, V21, P7549, DOI 10.1364/OE.21.007549
   Lingala SG, 2013, IEEE T MED IMAGING, V32, P1132, DOI 10.1109/TMI.2013.2255133
   Liu ET, 2012, IEEE T INFORM THEORY, V58, P2040, DOI 10.1109/TIT.2011.2177632
   Liu P, 2014, IEEE GEOSCI REMOTE S, V11, P1931, DOI 10.1109/LGRS.2014.2314177
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mangia M, 2017, IEEE T CIRCUITS-I, P1
   Mota JFC, 2012, IEEE T SIGNAL PROCES, V60, P1942, DOI 10.1109/TSP.2011.2182347
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Needell D, 2010, IEEE J-STSP, V4, P310, DOI 10.1109/JSTSP.2010.2042412
   Petrovici MA, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1747, DOI 10.1109/ICIT.2015.7125350
   Richard B., 2008, IEEE SIGNAL PROC JUL, P118, DOI DOI 10.1109/MSP.2008.915557
   Rossi M, 2014, IEEE T SIGNAL PROCES, V62, P419, DOI 10.1109/TSP.2013.2289875
   Sankaranarayanan AC, 2015, SIAM J IMAGING SCI, V8, P1489, DOI 10.1137/140983124
   Shirazinia A, 2014, IEEE T SIGNAL PROCES, V62, P3667, DOI 10.1109/TSP.2014.2329649
   Takhar D, 2006, PROC SPIE, V6065, DOI 10.1117/12.659602
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang LZ, 2015, IEEE GEOSCI REMOTE S, V12, P736, DOI 10.1109/LGRS.2014.2360457
   Yang JG, 2013, IEEE T GEOSCI REMOTE, V51, P983, DOI 10.1109/TGRS.2012.2204891
   Yuan JM, 2017, MAGN RESON IMAGING, V37, P62, DOI 10.1016/j.mri.2016.11.014
   Zeng WJ, 2016, IEEE T SIGNAL PROCES, V64, P60, DOI 10.1109/TSP.2015.2477047
   Zhu XX, 2010, IEEE T GEOSCI REMOTE, V48, P3839, DOI 10.1109/TGRS.2010.2048117
NR 40
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 3
EP 26
DI 10.1007/s11042-017-4920-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500002
DA 2024-07-18
ER

PT J
AU Lee, JS
   Li, CH
   Lee, HY
AF Lee, Jung-San
   Li, Chih-Hsuan
   Lee, Hsin-Yu
TI Visibility dehazing based on channel-weighted analysis and illumination
   tuning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visibility; Dehaze; Dark channel; Illumination; Fog; Sandstorm
ID RESTORATION
AB The air pollution and foggy weather often result in serious distortion while taking photos or recognizing patterns. He et al. have introduced the dark channel prior to solve this dehazing problem. Unfortunately, it cannot function well once the color difference of target image is large. More precisely, the dehazed result looks unnatural. Thus, we aim to develop a brand-new visibility dehazing technique based on the channel-weighted analysis and illumination tuning. The channel-weighted analysis is adopted to eliminate the unnatural effect, while the illumination tuning is applied to refine the details. Simulation results have demonstrated that the new method can guarantee the readability of a hazed image after removing noise, including the foggy photo and sandstorm one.
C1 [Lee, Jung-San; Li, Chih-Hsuan; Lee, Hsin-Yu] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
C3 Feng Chia University
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM leejs@fcu.edu.tw
OI Lee, Jung-San/0000-0001-7030-2985
CR [Anonymous], 2003, IEEE WORKSHOP COLOR
   Berman D, 2017, IEEE INT CONF COMPUT, P115
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P123, DOI 10.1007/s11042-015-3009-3
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jian MW, 2018, COMPUT IND, V99, P110, DOI 10.1016/j.compind.2018.03.034
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   Jian MW, 2013, COMPUT IND, V64, P1229, DOI 10.1016/j.compind.2013.06.011
   Jiang XL, 2017, NEUROCOMPUTING, V242, P1, DOI 10.1016/j.neucom.2017.01.080
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2001, PROC CVPR IEEE, P186
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Tan KK, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P788, DOI 10.1109/ICIP.2000.899827
   Tan R. T., 2008, PROC IEEE C COMPUT V, P1
   Zhu MZ, 2018, IEEE SIGNAL PROC LET, V25, P174, DOI 10.1109/LSP.2017.2780886
NR 19
TC 4
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1831
EP 1856
DI 10.1007/s11042-018-6280-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700027
DA 2024-07-18
ER

PT J
AU Lu, XS
   Yao, HX
   Zhao, SC
   Sun, XS
   Zhang, SP
AF Lu, Xiusheng
   Yao, Hongxun
   Zhao, Sicheng
   Sun, Xiaoshuai
   Zhang, Shengping
TI Action recognition with multi-scale trajectory-pooled 3D convolutional
   descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trajectory pooling; 3D ConvNets; Action recognition
ID HISTOGRAMS; MODEL
AB Hand-crafted and learning-based features are two main types of video representations in the field of video understanding. How to integrate their merits to design good descriptors has been the research hotspot recently. Motivated by TDD (Wang et al. 2015), we combine trajectory pooling method and 3D ConvNets (Tran et al. 2015) and put forward a novel multi-scale trajectory-pooled 3D convolutional descriptor (MTC3D) for action recognition in this paper. Specifically, we calculate multi-scale dense trajectories from the input video and perform trajectory pooling on feature maps of 3D CNN. The proposed descriptor has two advantages: 3D CNN has the ability to extract high-level semantic information from videos and multi-scale trajectory pooling method utilizes the temporal information of videos subtly. The experiments on the datasets of HMDB51 and UCF101 demonstrate that the proposed descriptor achieves state-of-the-art results.
C1 [Lu, Xiusheng; Yao, Hongxun; Zhao, Sicheng; Sun, Xiaoshuai; Zhang, Shengping] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM xiusheng.lu.cs@gmail.com; h.yao@hit.edu.cn
FU National Natural Science Foundation of China [61472103]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61472103).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], PAC RIM C MULT
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2016, ARXIV161106678
   [Anonymous], 2012, CoRR
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Demiris Y, 2006, ROBOT AUTON SYST, V54, P361, DOI 10.1016/j.robot.2006.02.003
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fanello SR, 2013, J MACH LEARN RES, V14, P2617
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Harris C., 1988, P ALV VIS C, P5210
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nie WZ, 2016, IMAGE VISION COMPUT, V55, P109, DOI 10.1016/j.imavis.2016.04.011
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sharma S., 2015, NEURAL INFORM PROCES
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sutskever I, 2014, ADV NEUR IN, V27
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L., 2016, P ECCV
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zhu Y, 2011, LECT NOTES COMPUT SC, V6493, P660
NR 48
TC 22
Z9 23
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 507
EP 523
DI 10.1007/s11042-017-5251-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500028
DA 2024-07-18
ER

PT J
AU Portalés, C
   Orduña, JM
   Morillo, P
   Gimeno, J
AF Portales, Cristina
   Orduna, Juan M.
   Morillo, Pedro
   Gimeno, Jesus
TI An efficient projector calibration method for projecting virtual reality
   on cylindrical surfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive visualization; Virtual reality; Calibration methods
ID CAMERA; AUTOCALIBRATION
AB In this paper, we propose a fast and easy-to-use projector calibration method needing a minimum set of input data, thus reducing the calibration time. The method is based on the Direct Linear Transformation (DLT) mathematical model, which makes it simple and fully automatic. We show the application of this method on cylindrical surfaces, as well as some real application examples. The results show that with the minimum configuration of 6 control points (CPs), the standard deviation in the projector positioning yielded by the calibration process is less than one per cent of the position values.
C1 [Portales, Cristina; Morillo, Pedro; Gimeno, Jesus] Univ Valencia, IRTIC, Valencia, Spain.
   [Orduna, Juan M.] Univ Valencia, Dept Informat, Valencia, Spain.
C3 University of Valencia; University of Valencia
RP Orduña, JM (corresponding author), Univ Valencia, Dept Informat, Valencia, Spain.
EM Juan.Orduna@uv.es
RI Morillo, Pedro/ABG-8408-2020; Portalés, Cristina/K-2296-2015; Orduña,
   Juan M./AAB-5732-2020
OI Portalés, Cristina/0000-0002-4520-2250; Orduña, Juan
   M./0000-0002-2932-0214; Morillo, Pedro/0000-0002-9506-9611
FU Spanish MINECO; EU ERDF [TIN2015-66972-C5-5-R, TIN2016-81850-REDC]
FX This work has been supported by Spanish MINECO and EU ERDF programs
   under grants TIN2015-66972-C5-5-R, and TIN2016-81850-REDC.
CR Brown M, 2005, IEEE T VIS COMPUT GR, V11, P193, DOI 10.1109/TVCG.2005.27
   Chen H, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P339, DOI 10.1109/VISUAL.2002.1183793
   DERMANIS A, 1994, ISPRS J PHOTOGRAMM, V49, P2, DOI 10.1016/0924-2716(94)90061-2
   Garcia-Dorado Ignacio., 2011, 2011 IEEE COMPUTER S, P29, DOI [10. 1109/CVPRW. 2011. 5981726, DOI 10.1109/CVPRW.2011.5981726]
   Griesser A, 2006, COMP VIS PATT REC WO, P8, DOI DOI 10.1109/CVPRW.2006.37
   Harville M., 2006, P C COMP VIS PATT RE, P5, DOI DOI 10.1109/CVPRW.2006.161
   Hasker ES, 2006, IEEE T VIS COMPUT GR, V12, P1101, DOI 10.1109/TVCG.2006.121
   Itseez, 2015, OPENCV 3 0
   Karara HM, 1979, PHOTOGRAMM ENG, V48, P1107
   Kraus K., 1997, Photogrammetry
   Li T. T., 2010, 2010 IEEE 16 INT S H, P1, DOI DOI 10.1109/IWISA.2010.5473428
   Liao JR, 2008, IEEE ASME INT C ADV, P770, DOI 10.1109/AIM.2008.4601757
   Lin SY, 2008, PHOTOGRAMM REC, V23, P128, DOI 10.1111/j.1477-9730.2008.00477.x
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Nakamura T, 2012, INT C PATT RECOG, P85
   Okatani T, 2006, C COMP VIS PATT REC, P4, DOI [10. 1109/CVPRW. 2006. 35, DOI 10.1109/CVPRW.2006.35]
   Portales C, 2014, P INT C COMP MATH ME, P992
   Portalés C, 2017, J IMAGING, V3, DOI 10.3390/jimaging3020019
   Portalés C, 2015, J SUPERCOMPUT, V71, P1857, DOI 10.1007/s11227-014-1364-x
   Portalés C, 2015, PHOTOGRAMM REC, V30, P82, DOI 10.1111/phor.12094
   Raij A, 2004, INT C PATT RECOG, P14, DOI 10.1109/ICPR.2004.1333994
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Sajadi B, 2010, P IEEE VIRT REAL ANN, P155, DOI 10.1109/VR.2010.5444797
   Sajadi B, 2009, IEEE T VIS COMPUT GR, V15, P1307, DOI 10.1109/TVCG.2009.166
   Soon-Yong Park, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P320, DOI 10.1109/ICPR.2010.87
   Sun W., 2008, P 5 ACMIEEE INT WORK, P1, DOI [10.1145/1394622.1394625, DOI 10.1145/1394622.1394625]
   Tardif JP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P217, DOI 10.1109/im.2003.1240253
NR 27
TC 6
Z9 8
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1457
EP 1471
DI 10.1007/s11042-018-6253-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700011
DA 2024-07-18
ER

PT J
AU Xie, N
   Zhao, TT
   Yang, Y
   Shen, HT
AF Xie, Ning
   Zhao, Tingting
   Yang, Yang
   Shen, Heng Tao
TI Web-based SBLR method of multimedia tools for computer-aided drawing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia tools; CSCW; SBR; Artistic stylization; PGPE
ID IMAGE
AB As one of the most successful multimedia tools for digital media and creative industry, computer-aided drawing system assists users to convert the input real photos into painterly style images. Nowadays, it is widely developed as cloud brush engine service in many creative software tools and applications of artistic rendering such as Prisma, Photoshop Cloud, and Meitu, because the machine learning server has more powerful than the stand-alone version. In this paper, we propose a web collaborative Stroke-based Learning and Rendering (WebSBLR) system. Different from the existing methods that are mainly focused on the artistic filters, we concentrate on the stroke realistic rendering engine for browser on client using WebGL and HTML5. Moreover, we implement the learning-based stroke drawing path generation module on the server. By this way, we enable to achieve the computer-supported cooperative work (CSCW), especially for multi-screen synchronous interaction. The experiments demonstrated our method are efficient to web-based multi-screen painting simulation.It can successfully learn artists' styles and render pictures with consistent and smooth brush strokes.
C1 [Xie, Ning; Zhao, Tingting; Yang, Yang; Shen, Heng Tao] Xiyuan St 2006, Chengdu 611731, Sichuan, Peoples R China.
RP Shen, HT (corresponding author), Xiyuan St 2006, Chengdu 611731, Sichuan, Peoples R China.
RI Shen, Heng Tao/ABD-5331-2021
FU National Natural Science Foundation of China [61602088, 61572108,
   61632007, 61502339]; National Thousand-Young-Talents Program of China;
   Fundamental Research Funds for the Central Universities [ZYGX2014Z007,
   ZYGX2015J055, ZYGX2016J212]
FX We firstly thank anonymous reviewers for their helpful comments. This
   work was supported in part by the National Natural Science Foundation of
   China under Project 61602088, Project 61572108, Project 61632007, and
   Project 61502339, the National Thousand-Young-Talents Program of China,
   the Fundamental Research Funds for the Central Universities under
   Project ZYGX2014Z007, Project ZYGX2015J055 and Project ZYGX2016J212.
CR Abbeel P., 2004, MACHINE LEARNING
   Baran I, 2010, COMPUT GRAPH FORUM, V29, P655, DOI 10.1111/j.1467-8659.2009.01635.x
   Bousseau A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276507
   Chu Nelson., 2010, P 8 INT S NONPHOTORE, P27, DOI 10.1145/1809939.1809943
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Chu NSH, 2004, IEEE COMPUT GRAPH, V24, P76, DOI 10.1109/MCG.2004.37
   Davies E.R., 2005, MACHINE VISION THEOR, V3rd
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147
   Huang ZP, 2015, COMPUT ANIMAT VIRT W, V26, P141, DOI 10.1002/cav.1559
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Kang H, 2008, COMPUT GRAPH FORUM, V27, P1773, DOI 10.1111/j.1467-8659.2008.01322.x
   Kyprianidis JE, 2011, COMPUT GRAPH FORUM, V30, P593, DOI 10.1111/j.1467-8659.2011.01882.x
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Kyprianidis JE, 2010, THEORY PRACTICE COMP, P25
   Lu JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461998
   Lu JW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185542
   Orbay G, 2011, IEEE T VIS COMPUT GR, V17, P694, DOI 10.1109/TVCG.2010.105
   Pham TQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P454, DOI 10.1109/ICME.2005.1521458
   Sehnke F, 2010, NEURAL NETWORKS, V23, P551, DOI 10.1016/j.neunet.2009.12.004
   Semmo A, 2016, SIGGRAPH 16
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Sykora D, 2005, IMAGE VISION COMPUT, V23, P767, DOI 10.1016/j.imavis.2005.05.010
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xie N., 2012, P 29 INT C MACH LEAR
   Xie N., 2010, Proc. NPAR '10, P63
   Xu SH, 2006, ACM T GRAPHIC, V25, P239, DOI 10.1145/1138450.1138454
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhao T., 2011, NEURIPS, P262
   Zhao YD, 2015, IEEE T VIS COMPUT GR, V21, P229, DOI 10.1109/TVCG.2014.2355221
   Zitnick CL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461985
NR 32
TC 3
Z9 3
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 799
EP 816
DI 10.1007/s11042-018-5949-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500045
DA 2024-07-18
ER

PT J
AU Guo, JJ
   Yuan, CH
   Zhao, ZQ
   Feng, P
   Wang, TJ
   Liu, F
AF Guo, Jingjuan
   Yuan, Caihong
   Zhao, Zhiqiang
   Feng, Ping
   Wang, Tianjiang
   Liu, Fang
TI Bi-branch deconvolution-based convolutional neural network for image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Bi-branch convolutional neural network;
   Deconvolution; Multi-scale
AB With the rise of deep neural network, convolutional neural networks show superior performances on many different computer vision recognition tasks. The convolution is used as one of the most efficient ways for extracting the details features of an image, while the deconvolution is mostly used for semantic segmentation and significance detection to obtain the contour information of the image and rarely used for image classification. In this paper, we propose a novel network named bi-branch deconvolution-based convolutional neural network (BB-deconvNet), which is constructed by mainly stacking a proposed simple module named Zoom. The Zoom module has two branches to extract multi-scale features from the same feature map. Especially, the deconvolution is borrowed to one of the branches, which can provide distinct features differently from regular convolution through the zoom of learned feature maps. To verify the effectiveness of the proposed network, we conduct several experiments on three object classification benchmarks (CIFAR-10, CIFAR-100, SVHN). The BB-deconvNet shows encouraging performances compared with other state-of-the-art deep CNNs.
C1 [Guo, Jingjuan; Yuan, Caihong; Zhao, Zhiqiang; Feng, Ping; Wang, Tianjiang; Liu, Fang] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Guo, Jingjuan; Zhao, Zhiqiang] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
   [Yuan, Caihong] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
C3 Huazhong University of Science & Technology; Jiujiang University; Henan
   University
RP Guo, JJ; Wang, TJ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.; Guo, JJ (corresponding author), Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
EM jj_guo@hust.edu.cn; yuanch@hust.edu.cn; zq_zhao@hust.edu.cn;
   fengping@hust.edu.cn; tjwang@hust.edu.cn; fliu@hust.edu.cn
FU Natural Science Foundation of China [61572214, U1536203]; Independent
   Innovation Research Fund - Huazhong university of science and technology
   [2016YXMS089]
FX This work is supported by the Natural Science Foundation of China (Grant
   61572214 and U1536203), Independent Innovation Research Fund Sponsored
   by Huazhong university of science and technology (Project No.
   2016YXMS089).
CR [Anonymous], ARXIV170304071
   [Anonymous], 2015, ARXIV151008160
   [Anonymous], 2017, ARXIV170600388
   [Anonymous], 2012, INT C ART INT STAT
   Clevert D., 2016, ARXIV151107289
   Goodfellow IJ, 2013, ARXIV13024389
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ioffe S., 2017, P 31 INT C NEUR INF, P1942
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero A., 2014, ARXIV14126550
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava R. K., 2015, ADV NEURAL INFORM PR, P2377, DOI DOI 10.48550/ARXIV.1505.00387
   Szegedy C., 2017, AAAI, V4, P12
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeiler M.D., 2013, ARXIV201313013557, P1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
NR 39
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30233
EP 30250
DI 10.1007/s11042-018-6130-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600004
DA 2024-07-18
ER

PT J
AU Li, JX
   Lu, W
   Weng, J
   Mao, YJ
   Li, GQ
AF Li, Jixian
   Lu, Wei
   Weng, Jian
   Mao, Yijun
   Li, Guoqiang
TI Double JPEG compression detection based on block statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double JPEG compression detection; Block-DCT frequency; Markov
   transition probability Matrix
ID STEP
AB In this paper, a novel method is proposed to detect the aligned double JPEG compression with different quantization matrix. The proposed method is based on the theory that the correlation among adjacent coefficients of frequency spectrum in DCT blocks is enhanced after DCT transformation, and the correlation among same locations in adjacent DCT blocks is strong. Classification features are divided into two types, the intra-block frequency domain features and the inter-block frequency domain features. The intra-block frequency domain features are used to catch the strong correlation among adjacent coefficients in DCT blocks, and the inter-block frequency domain features are used to catch the correlation among same locations of adjacent DCT blocks. Then the intra-block frequency domain features with inter-block frequency domain features are combined as the classification features. Finally, the classification features are used to train classifiers to detect double JPEG compression. The results of extensive experiments demonstrate the effectiveness of the proposed method.
C1 [Li, Jixian; Lu, Wei] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Weng, Jian] Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China.
   [Mao, Yijun] South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Guangdong, Peoples R China.
   [Li, Guoqiang] Shanghai Jiao Tong Univ, Sch Software, Shanghai 200030, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS; Jinan University; South China Agricultural
   University; Shanghai Jiao Tong University
RP Li, JX (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM lijx77@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn
RI Li, Jixian/HKV-6024-2023
OI Weng, Jian/0000-0003-4067-8230
FU National Natural Science Foundation of China [U1736118]; Natural Science
   Foundation of Guangdong [2016A030313350]; Special Funds for Science and
   Technology Development of Guangdong [2016KZ010103]; Key Project of
   Scientific Research Plan of Guangzhou [201804020068]; Fundamental
   Research Funds for the Central Universities [16lgjc83, 17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45).
CR [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], 2011, LIBSVM: a library for support vector machines
   Bianchi T., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1929, DOI 10.1109/ICIP.2011.6115848
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Bianchi Tiziano, 2011, 2011 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2011.6123159
   Chen CH, 2008, 14TH ISSAT INTERNATIONAL CONFERENCE ON RELIABILITY AND QUALITY IN DESIGN, PROCEEDINGS, P1
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Chen LK, 2012, INT J DIGIT CRIME FO, V4, P49, DOI 10.4018/jdcf.2012010104
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Feng X, 2010, MEDIA FORENSICS SECU, P75410
   Fu DD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704723
   Gong Z, 2016, INT C INT INF HID MU, P185
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2009, SIAM J SCI COMPUT, V31, P2842, DOI [10.1137/080732894, DOI 10.1137/080732894]
   Lin ZX, 2017, SIGNAL PROCESS-IMAGE, V57, P134, DOI 10.1016/j.image.2017.05.012
   Lisha Dong, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P234, DOI 10.1109/ICIG.2011.100
   Liu QZ, 2011, LECT NOTES COMPUT SC, V6676, P466, DOI 10.1007/978-3-642-21090-7_55
   Lu W, 2011, ENG APPL ARTIF INTEL, V24, P666, DOI 10.1016/j.engappai.2011.01.002
   Luo WQ, 2007, INT CONF ACOUST SPEE, P217
   Pawel Korus JH, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI [10.1109/TIP.2016.2518870, DOI 10.1109/TIP.2016.2518870]
   PENG F, 2016, MULTIMED TOOLS APPL, V76, P1
   Peng F, 2019, MULTIMED TOOLS APPL, V78, P26885, DOI 10.1007/s11042-017-4362-1
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Qu ZH, 2008, INT CONF ACOUST SPEE, P1661, DOI 10.1109/ICASSP.2008.4517946
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shang SM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P550, DOI 10.1109/ICDSP.2016.7868618
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1653, DOI 10.1109/TIFS.2014.2345479
   Xue F, 2017, SIGNAL PROCESS-IMAGE, V57, P76, DOI 10.1016/j.image.2017.05.008
   Xz Meng, 2008, IEEE INT C AC SPEECH, P1661
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang Yu-jin, 2013, Journal of Shanghai Jiaotong University (Science), V18, P7, DOI 10.1007/s12204-013-1362-9
NR 38
TC 12
Z9 13
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31895
EP 31910
DI 10.1007/s11042-018-6175-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000017
DA 2024-07-18
ER

PT J
AU Liu, RY
   Wei, SK
   Zhao, Y
   Yang, Y
AF Liu, Ruoyu
   Wei, Shikui
   Zhao, Yao
   Yang, Yi
TI Indexing of the CNN features for the large scale image search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Indexing; Inverted table
ID RETRIEVAL
AB The convolutional neural network (CNN) features can give good description of image content, which usually represent an image with a single feature vector. Although CNN features are more compact than local descriptors, they still cannot efficiently deal with large-scale retrieval due to the linearly incremental cost of computation and storage. To address this issue, we build a simple but effective indexing framework on inverted table, which significantly decreases both search time and memory usage. First, several strategies are fully investigated to adapt inverted table to CNN features for compensating for quantization error. We use multiple assignment for the query and database images to increase the probability that relevant images are assigned to the same visual word obtained via clustering. Embedding codes are also introduced to improve retrieval accuracy by removing false matches. Second, a novel indexing framework that combines inverted table and hashing codes is proposed. This framework is faster than the reformed inverted tables with the introduced strategies. Experiment on several benchmark datasets demonstrates that our method yields faster retrieval speed compared to brute-force search. We also provide fair comparison between popular CNN features.
C1 [Liu, Ruoyu; Wei, Shikui; Zhao, Yao] Beijing Jiaotong Univ, Beijing, Peoples R China.
   [Yang, Yi] Univ Technol Sydney, Ultimo, Australia.
C3 Beijing Jiaotong University; University of Technology Sydney
RP Liu, RY (corresponding author), Beijing Jiaotong Univ, Beijing, Peoples R China.
EM 12112062@bjtu.edu.cn; shkwei@bjtu.edu.cn; yzhao@bjtu.edu.cn;
   yee.i.yang@gmail.com
RI yang, yang/HGT-7999-2022; yang, yang/GWB-9426-2022; Lang,
   Ming/HIK-0758-2022; yang, yang/GVT-5210-2022; Yang, Yi/B-9273-2017
OI Yang, Yi/0000-0002-0512-880X
FU National Natural Science Foundation of China [61532005, 61572065];
   National Key Research and Development of China [2016YFB08004 04,
   2017YFC1703503]; Joint Fund of Ministry of Education of China; China
   Mobile [MCM20160102]
FX This work was supported in part by National Natural Science Foundation
   of China (No.61532005, No.61572065), National Key Research and
   Development of China (No.2016YFB08004 04, 2017YFC1703503), Joint Fund of
   Ministry of Education of China and China Mobile (No.MCM20160102).
CR [Anonymous], TWITTER100K REAL WOR
   [Anonymous], 2004, P 20 ACM S COMP
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2009, NEURIPS
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 1999, MODERN INFORM RETRIE
   [Anonymous], 2016, ARXIV160708477
   [Anonymous], 2016, ARXIV
   [Anonymous], IEEE MULTIMEDIA
   [Anonymous], 1997, VLDB
   [Anonymous], ERA INTERACTIVE MEDI
   [Anonymous], 2014, AAAI
   [Anonymous], 2007, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2007.382970
   [Anonymous], 2017, ARXIV170200758
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], PROC CVPR IEEE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ROBUST STRUCTURED NO
   [Anonymous], 2017, ARXIV 1711 05535
   [Anonymous], 2017, TPAMI
   [Anonymous], ACM T MULTIM COMPUT
   [Anonymous], 2009, CIVR
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong L, 2016, IEEE T MULTIMEDIA, V18, P714, DOI 10.1109/TMM.2016.2530399
   Gao ZN, 2016, IEEE T MULTIMEDIA, V18, P1661, DOI 10.1109/TMM.2016.2568748
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Guttman Antonin., 1984, P 1984 ACM SIGMOD C, P47
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Ji J., 2012, 25 INT C NEUR INF PR, P108
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li Q, 2017, ADV NEUR IN, V30
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P950, DOI 10.1109/TGRS.2017.2756911
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu Ren., 2015, Modeling and Simulation of Cyber-Physical Energy Systems (MSCPES), 2015 Workshop on, P1
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Liu Z, 2015, IEEE T MULTIMEDIA, V17, P538, DOI 10.1109/TMM.2015.2399851
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1606, DOI 10.1109/TIP.2014.2305072
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv YM, 2015, IEEE T MULTIMEDIA, V17, P1225, DOI 10.1109/TMM.2015.2437712
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mohedano E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P327, DOI 10.1145/2911996.2912061
   Mu Y, 2017, AAAI CONF ARTIF INTE, P2380
   Ning QQ, 2017, IEEE T MULTIMEDIA, V19, P586, DOI 10.1109/TMM.2016.2625260
   Nister David, 2006, CVPR
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Perronnin F, 2015, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR.2015.7298998
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Simonyan K., 2014, 14091556 ARXIV
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Wang Jianfeng., 2013, ACM Multimedia, P133
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wei SK, 2013, IEEE T CYBERNETICS, V43, P2216, DOI 10.1109/TCYB.2013.2245890
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zheng L, 2015, IEEE T MULTIMEDIA, V17, P648, DOI 10.1109/TMM.2015.2408563
   Zhong ZY, 2015, IEEE T MULTIMEDIA, V17, P1391, DOI 10.1109/TMM.2015.2446201
   Zhou WG, 2014, IEEE T MULTIMEDIA, V16, P601, DOI 10.1109/TMM.2014.2301979
   Zhuang BH, 2016, PROC CVPR IEEE, P5955, DOI 10.1109/CVPR.2016.641
NR 91
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32107
EP 32131
DI 10.1007/s11042-018-6210-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000027
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Altaf, M
   Ahmad, A
   Khan, FA
   Uddin, Z
   Yang, XD
AF Altaf, Muhammad
   Ahmad, Ayaz
   Khan, Farman Ali
   Uddin, Zahoor
   Yang, Xiaodong
TI Computationally efficient selective video encryption with chaos based
   block cipher
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Selective encryption; Chaos based block cipher; Video streaming
ID CRYPTOGRAPHY; DESIGN
AB Selective encryption techniques are usually used with resource limited communication infrastructure and devices like wireless networks and mobile devices, to reduce computational burden in securing large video data. This technique of securing a subset of data and hence reducing computation is usually considered a compromise on security. Similarly, if the data is not properly selected then the encryption procedure will result in compression inefficiency and format non-compliance. In this research work, these requirements of reduced computation with increased security, format compliance and compression efficiency are addressed. The security issue is addressed by carefully selecting the substitution boxes for the block cipher in use. For compression efficiency and compliance to the format the video data is selected such that the statistical and structural characteristics are preserved. In order to increase the security, different chaotic based substitution boxes, that are an integral part and the only nonlinear operation of the block ciphers, were studied for cryptographic strengths. The selected substitution boxes were used for permutation of selected video data and its encryption by integrating the S-box with the Advanced Encryption Standard and H.264/AVC. The video data selected to be secured, consist of discrete cosine transform coefficients; signs of trailing ones and non-zero transform coefficients. The discrete cosine transform coefficients were permuted using the selected S-box while the signs of trailing ones and non-zero transform coefficients were fully encrypted using AES with the modified S-box. Simulation results showed considerable visual degradation in the decoded video. It is also shown that the compression efficiency and format compliance was not compromised while keeping the computational load at minimum.
C1 [Altaf, Muhammad; Ahmad, Ayaz; Uddin, Zahoor] COMSATS Inst Informat Technol, Wah, Pakistan.
   [Khan, Farman Ali] COMSATS Inst Informat Technol, Attock, Pakistan.
   [Yang, Xiaodong] Xidian Univ, Xian, Shaanxi, Peoples R China.
C3 COMSATS University Islamabad (CUI); COMSATS University Islamabad (CUI);
   Xidian University
RP Altaf, M (corresponding author), COMSATS Inst Informat Technol, Wah, Pakistan.
EM mohammadaltaf@gmail.com; ayaz.uet@gmail.com;
   farman_marwat@ciit-attock.edu.pk; zahooruddin79@gmail.com;
   xdyang@xidian.edu.cn
RI Ahmad, Ayaz/AAD-1559-2021
OI Ahmad, Ayaz/0000-0002-2253-6004; Altaf, Muhammad/0000-0001-5016-9478
CR Ahmad M., 2016, Perspectives in Science, V8, P465
   Altaleb A, 2017, AIP ADV, V7, DOI 10.1063/1.4978264
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   [Anonymous], 2010, INT COMPUT THEORY EN
   [Anonymous], 2012, J BASIC APPL SCI RES
   [Anonymous], IM PROC 2007 ICIP 20
   [Anonymous], 2010, INC2010
   [Anonymous], INT J COMPUT APPL
   [Anonymous], IACR CRYPTOL EPRINT
   [Anonymous], INTERNET EXPERTS WAN
   [Anonymous], NOVEL APPROACH DESIG
   [Anonymous], 2010, INT J ENG SCI TECHNO
   [Anonymous], SMART SELECTIVE ENCR
   [Anonymous], 2012, J COMPUT INF SYST
   [Anonymous], 2010, 2010 6 INT C WIRELES, DOI DOI 10.1109/WICOM.2010.5601297
   [Anonymous], NOVEL S BOX AES ALGO
   [Anonymous], 2001, FED INF PROC STAND P
   [Anonymous], ELSEVIER SIGNAL PROC
   [Anonymous], TRACKING GENERIC HUM
   Asghar MN, 2015, MULTIMED TOOLS APPL, V74, P10215, DOI 10.1007/s11042-014-2160-6
   Asghar MN, 2014, J VIS COMMUN IMAGE R, V25, P487, DOI 10.1016/j.jvcir.2013.12.015
   Asim M, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P736
   Asim M, 2008, ETRI J, V30, P170, DOI 10.4218/etrij.08.0207.0188
   Cai MA, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P41
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   DAWSON MH, 1991, IEEE PACIF, P191, DOI 10.1109/PACRIM.1991.160713
   FEISTEL H, 1975, P IEEE, V63, P1545, DOI 10.1109/PROC.1975.10005
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Garg S., 2013, Int. J. Adv. Res. Comput. Sci. Electron. Eng, V2, P426
   Hosseinkhani R., 2012, International Journal of Computer Science and Security (IJCSS), P19
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Jianguo Jiang, 2010, Journal of Multimedia, V5, P464, DOI 10.4304/jmm.5.5.464-472
   Jun Peng, 2008, 2008 IEEE Conference on Cybernetics and Intelligent Systems, P1012, DOI 10.1109/ICCIS.2008.4670966
   Kazlauskas K, 2009, INFORMATICA-LITHUAN, V20, P23
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Kim YH, 2007, ROUTL CRIT INTRO URB, P1
   Kong JH, 2013, J ENG-NY, V2013, DOI 10.1155/2013/785126
   Lei B. Y., 2010, 2010 International Conference on Communications, Circuits and Systems (ICCCAS), P373, DOI 10.1109/ICCCAS.2010.5581981
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liu S, 2008, 4 INT C ONWIRELESS C, P1
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Mao YN, 2006, IEEE T IMAGE PROCESS, V15, P2061, DOI 10.1109/TIP.2006.873426
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Meyer J., 1995, SECURITY MECH MULTIM
   Mohamed A.H., 2016, J Diabetic Foot Complications, V8, P31
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Peng J, 2012, INT J COGN INFORM NA, V6, P100, DOI 10.4018/jcini.2012010105
   Phillips Michael., 2011, Introduction and Commentary. The Marriage of Heaven and Hell [copy B (1790)], P1
   Qiao L., 1997, Las Vegas : Proceedings of the 1s International Conference on Imaging Science, Systems and Technology, P21
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Shi CG, 1998, SYM REL DIST SYST, P381, DOI 10.1109/RELDIS.1998.740527
   Sohn H, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P424, DOI 10.1109/AVSS.2009.48
   Spanos GA, 1996, CONFERENCE PROCEEDINGS OF THE 1996 IEEE FIFTEENTH ANNUAL INTERNATIONAL PHOENIX CONFERENCE ON COMPUTERS AND COMMUNICATIONS, P72, DOI 10.1109/PCCC.1996.493615
   Stalling W., 2011, Cryptography and Network Security Principle and Practice
   Tian-Gong P, 2013, INT J SECUR APPL, V7, P377, DOI 10.14257/ijsia.2013.7.5.34
   Wang JD, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P802, DOI 10.1109/ICASIC.2007.4415752
   Wang Y, 2009, COMMUN NONLINEAR SCI, V14, P3089, DOI 10.1016/j.cnsns.2008.12.005
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Xu SJ, 2008, INT CONF SIGN PROCES, P1014, DOI 10.1109/ICOSP.2008.4697300
   Zhang YP, 2009, IEEE SYS MAN CYBERN, P474, DOI 10.1109/ICSMC.2009.5346839
   Zou YZ, 2006, IEEE T CONSUM ELECTR, V52, P1289, DOI 10.1109/TCE.2006.273147
NR 66
TC 23
Z9 24
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27981
EP 27995
DI 10.1007/s11042-018-6022-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500011
DA 2024-07-18
ER

PT J
AU Fang, Y
   Li, YD
   Lei, C
   Li, YG
   Deng, XL
AF Fang, Yue
   Li, Yangding
   Lei, Cong
   Li, Yonggang
   Deng, Xuelian
TI Hypergraph expressing low-rank feature selection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypergraph; LowRank; Feature selection
ID SUPERVISED FEATURE-SELECTION; CLASSIFICATION; INFORMATION; REGRESSION;
   FRAMEWORK; RULES
AB Dimensionality reduction has been attracted extensive attention in machine learning. It usually includes two types: feature selection and subspace learning. Previously, many researchers have demonstrated that the dimensionality reduction is meaningful for real applications. Unfortunately, a large mass of these works utilize the feature selection and subspace learning independently. This paper explores a novel supervised feature selection algorithm by considering the subspace learning. Specifically, this paper employs an l(2,1)-norm and an l(2,p)-norm regularizers, respectively, to conduct sample denoising and feature selection via exploring the correlation structure of data. Then this paper uses two constraints (i.e. hypergraph and low-rank) to consider the local structure and the global structure among the data, respectively. Finally, this paper uses the optimizing framework to iteratively optimize each parameter while fixing the other parameter until the algorithm converges. A lot of experiments show that our new supervised feature selection method can get great results on the eighteen public data sets.
C1 [Fang, Yue; Li, Yangding; Lei, Cong; Li, Yonggang] Guangxi Normal Univ, Coll Comp Sci, Informat Technol, Guilin 541004, Guangxi, Peoples R China.
   [Deng, Xuelian] Guangxi Univ Chinese Med, Coll Publ Hlth & Management, Nanning 530299, Guangxi, Peoples R China.
C3 Guangxi Normal University; Guangxi University of Chinese Medicine
RP Li, YD (corresponding author), Guangxi Normal Univ, Coll Comp Sci, Informat Technol, Guilin 541004, Guangxi, Peoples R China.
EM yue_fang_ser@sina.com; lyd271@126.com; CongL_hu@163.com;
   stulyg@sina.com; 173213455@qq.com
FU China Key Research Program [2016YFB1000905]; China 973 Program
   [2013CB329404]; China 1000-Plan National Distinguished Professorship;
   Nation Natural Science Foundation of China [61573270, 61672177,
   61363009, 81701780]; Guangxi Natural Science Foundation
   [2015GXNSFCB139011]; Guangxi High Institutions Program of Introducing
   100 High-Level Overseas Talents; Guangxi Collaborative Innovation Center
   of Multi-Source Information Integration and Intelligent Processing;
   Research Fund of Guangxi Key Lab of MIMS [16-A-01-01, 16-A-01-02];
   Guangxi Bagui Teams for Innovation and Research; Innovation Project of
   Guangxi Graduate Education [YCSW2017065, XYCSZ2017064, XYCSZ2017067]
FX This work was supported in part by the China Key Research Program (Grant
   No: 2016YFB1000905), the China 973 Program (Grant No: 2013CB329404), the
   China 1000-Plan National Distinguished Professorship, the Nation Natural
   Science Foundation of China (Grants No: 61573270, 61672177, 61363009 and
   81701780), the Guangxi Natural Science Foundation (Grant No:
   2015GXNSFCB139011), the Guangxi High Institutions Program of Introducing
   100 High-Level Overseas Talents, the Guangxi Collaborative Innovation
   Center of Multi-Source Information Integration and Intelligent
   Processing, the Research Fund of Guangxi Key Lab of MIMS (16-A-01-01 and
   16-A-01-02), and the Guangxi Bagui Teams for Innovation and Research,
   and Innovation Project of Guangxi Graduate Education under grant
   YCSW2017065, XYCSZ2017064 and XYCSZ2017067.
CR [Anonymous], 2005, IEEE COMP SOC C COMP
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], ISCID
   Cai X., 2013, 23 INT JOINT C ARTIF, P1240, DOI [10.5555/2540128.2540307, DOI 10.5555/2540128.2540307]
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Dadaneh BZ, 2016, EXPERT SYST APPL, V53, P27, DOI 10.1016/j.eswa.2016.01.021
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345
   Du XZ, 2016, SIGNAL PROCESS, V120, P754, DOI 10.1016/j.sigpro.2014.12.027
   He X., 2003, ADV NEURAL INFORM PR, P153
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Li J, 2016, PROCEEDINGS OF 2016 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS (ISITA 2016), P384
   Ling Charles X., 2004, P 21 INT C MACH LEAR, P69, DOI DOI 10.1109/TSMCB.2008.2007853
   Liu Y, 2013, NEUROCOMPUTING, V105, P12, DOI 10.1016/j.neucom.2012.05.031
   Luo D, 2011, AAAI C ART INT
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Qin YS, 2007, APPL INTELL, V27, P79, DOI 10.1007/s10489-006-0032-0
   Shi CJ, 2017, IEEE T CIRC SYST VID, V27, P1947, DOI 10.1109/TCSVT.2016.2576919
   Wang T, 2012, INFORM SYST, V37, P508, DOI 10.1016/j.is.2011.10.009
   Wang XD, 2016, J VIS COMMUN IMAGE R, V41, P272, DOI 10.1016/j.jvcir.2016.10.007
   Wu XD, 2005, INFORM SYST, V30, P71, DOI 10.1016/j.is.2003.10.001
   Wu XD, 2004, ACM T INFORM SYST, V22, P381, DOI 10.1145/1010614.1010616
   Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353, DOI 10.1109/TKDE.2003.1185839
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Zeng ZQ, 2016, NEUROCOMPUTING, V173, P102, DOI 10.1016/j.neucom.2015.05.119
   Zhang S, 2017, IEEE T NEURAL NETWOR
   Zhang SC, 2005, IEEE T KNOWL DATA EN, V17, P1689, DOI 10.1109/TKDE.2005.188
   Zhang SC, 2003, INFORM SYST, V28, P691, DOI 10.1016/S0306-4379(02)00079-0
   Zhang SC, 2002, IEEE T SYST MAN CY A, V32, P515, DOI 10.1109/TSMCA.2002.804793
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhang SC, 2012, J SYST SOFTWARE, V85, P2541, DOI 10.1016/j.jss.2012.05.073
   Zhang SC, 2012, J SYST SOFTWARE, V85, P771, DOI 10.1016/j.jss.2011.10.007
   Zhang SC, 2011, J SYST SOFTWARE, V84, P452, DOI 10.1016/j.jss.2010.11.887
   Zhang SC, 2011, APPL INTELL, V35, P123, DOI 10.1007/s10489-009-0207-6
   Zhao YC, 2006, IEEE T KNOWL DATA EN, V18, P231, DOI 10.1109/TKDE.2006.30
   Zhao Z, 2011, 24 AAAI C ART INT
   Zhu P, 2016, NONCONVEX REGULARIZE
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu X, 2017, IEEE T MULTIMEDIA
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zhu Xiaofeng., 2017, IEEE transactions on big data
NR 50
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29551
EP 29572
DI 10.1007/s11042-017-5235-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800020
DA 2024-07-18
ER

PT J
AU Gao, F
   Ge, YY
   Liu, YG
AF Gao, Feng
   Ge, Yuanyuan
   Liu, Yongge
TI Remember and forget: video and text fusion for video question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video QA; Forget memory network; Fused video and text features
AB Video question answering (Video QA) has received much attention in recent years. It can answer questions according to the visual content of a video clip. Video QA task can be solved only according to the video data. But if the video clip has some relevant text information, It can also be solved by using the fused video and text data. How to select the useful region features from the video frames and select the useful text features from the text information needs to be solved. And how to fuse the video and text features also needs to be solved. Therefore, we propose a forget memory network to solve these problems. The forget memory network with video framework can solve Video QA task only according to the video data. It can select the useful region features for the question and forget the irrelevant region features from the video frames. The forget memory network with video and text framework can extract the useful text features and forget the irrelevant text features for the question. And it can fuse the video and text data to solve Video QA task. The fused video and text features can help improve the experimental performance.
C1 [Gao, Feng; Liu, Yongge] Anyang Normal Univ, Sch Comp & Informat Engn, Anyang, Peoples R China.
   [Gao, Feng; Liu, Yongge] Anyang Normal Univ, Henan Key Lab Oracle Bone Inscript Informat Proc, Anyang, Peoples R China.
   [Gao, Feng; Liu, Yongge] Collaborat Innovat Ctr Int Disseminat Chinese Lan, Luoyang, Henan, Peoples R China.
   [Ge, Yuanyuan] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
C3 Anyang Normal University; Anyang Normal University; Tianjin University
RP Liu, YG (corresponding author), Anyang Normal Univ, Sch Comp & Informat Engn, Anyang, Peoples R China.; Liu, YG (corresponding author), Anyang Normal Univ, Henan Key Lab Oracle Bone Inscript Informat Proc, Anyang, Peoples R China.; Liu, YG (corresponding author), Collaborat Innovat Ctr Int Disseminat Chinese Lan, Luoyang, Henan, Peoples R China.
EM gaof97@163.com; geyuanyuan@tju.edu; liuyg_aynu@163.com
FU National Social Science Fund of China [16ZH017A3]; Program for
   Changjiang Scholars and Innovative Research Team in University (PCSIRT)
   - Ministry of Education, China
FX Prof. Liu is supported by the Major Projects entrusted by the National
   Social Science Fund of China (Under Grant 16ZH017A3) and Program for
   Changjiang Scholars and Innovative Research Team in University (PCSIRT)
   granted by Ministry of Education, China.
CR [Anonymous], 2016, PROC 4 INT C LEARN R
   [Anonymous], ARXIV170400616
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2017, P ACM INT C MULT
   [Anonymous], 2014, INT C MACH LEARN ICM
   [Anonymous], 2015, ARXIV151105676
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, ARXIV 151106432
   [Anonymous], 2016, ARXIV160306147
   [Anonymous], 2017, P ACL
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Gao H., 2015, INT C NEURAL INF PRO, P2296
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Hill F, 2017, MACH TRANSL, V31, P3, DOI 10.1007/s10590-017-9194-2
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim Y., 2014, P 2014 C EMPIRICAL M
   Kingma D.P., 2014, ARXIV14126980
   Li G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1191, DOI 10.1145/2733373.2806314
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11
   Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu K., 2015, COMPUTER SCI, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735
   Zeng KH, 2017, AAAI CONF ARTIF INTE, P4334
   Zhu Linchao, 2015, ARXIV151104670
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 38
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29269
EP 29282
DI 10.1007/s11042-018-5868-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800005
DA 2024-07-18
ER

PT J
AU Luo, YL
   Zhou, RL
   Liu, JX
   Qiu, SH
   Cao, Y
AF Luo, Yuling
   Zhou, Ronglong
   Liu, Junxiu
   Qiu, Senhui
   Cao, Yi
TI An efficient and self-adapting colour-image encryption algorithm based
   on chaos and interactions among multiple layers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colour-image encryption; Chaos; Interaction of multiple layers; Security
   analysis
ID HYBRID GENETIC ALGORITHM; SCHEME; PERMUTATION; TRANSFORM; CONFUSION;
   SECURITY; WAVELET
AB In this paper, we propose an efficient and self-adapting colour-image encryption algorithm based on chaos and the interactions among multiple red, green and blue (RGB) layers. Our study uses two chaotic systems and the interactions among the multiple layers to strengthen the cryptosystem for the colour-image encryption, which can achieve better confusion and diffusion performances. In the confusion process, we use the novel Rubik's Cube Scheme (RCS) to scramble the image. The significant advantage of this approach is that it sufficiently destroys the correlation among the different layers of colour image, which is the most important feature of the randomness for the encryption. The theoretical analysis and experimental results show that the proposed algorithm can improve the encoding efficiency, enhances the security of the cipher-text, has a large key space and high key sensitivity, and is also able to resist statistical and exhaustive attacks.
C1 [Luo, Yuling; Zhou, Ronglong; Liu, Junxiu; Qiu, Senhui] Guangxi Normal Univ, Fac Elect Engn, Guangxi Key Lab Multi Source Informat Min & Secur, Guilin, Peoples R China.
   [Qiu, Senhui] Guangxi Expt Ctr Informat Sci, Guilin, Peoples R China.
   [Cao, Yi] Univ Surrey, Surrey Business Sch, Dept Business Transformat & Sustainable Enterpris, Surrey GU2 7XH, England.
C3 Guangxi Normal University; University of Surrey
RP Liu, JX (corresponding author), Guangxi Normal Univ, Fac Elect Engn, Guangxi Key Lab Multi Source Informat Min & Secur, Guilin, Peoples R China.
EM liujunxiu@mailbox.gxnu.edu.cn
FU National Natural Science Foundation of China [61661008]; Guangxi Natural
   Science Foundation [2017GXNSFAA198180, 2015GXNSFBA139256,
   2016GXNSFCA380017]; Overseas 100 Talents Program of Guangxi Higher
   Education; Research Project of Guangxi University of China
   [KY2016YB059]; Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS15-07]; Doctoral Research Foundation of Guangxi Normal
   University; Guangxi Experiment Centre of Information Science; Innovation
   Project of Guangxi Graduate Education [YCSZ2017055]
FX This research was supported by the National Natural Science Foundation
   of China under Grant 61661008, the Guangxi Natural Science Foundation
   under Grant 2017GXNSFAA198180, 2015GXNSFBA139256 and 2016GXNSFCA380017,
   the funding of Overseas 100 Talents Program of Guangxi Higher Education,
   the Research Project of Guangxi University of China under Grant
   KY2016YB059, Guangxi Key Lab of Multi-source Information Mining &
   Security under Grant MIMS15-07, the Doctoral Research Foundation of
   Guangxi Normal University, the grant from Guangxi Experiment Centre of
   Information Science, and the Innovation Project of Guangxi Graduate
   Education under Grant YCSZ2017055.
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Blakely G. R., 1979, Computers & Mathematics with Applications, V5, P169, DOI 10.1016/0898-1221(79)90039-7
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Chen JX, 2015, OPT LASER ENG, V66, P1, DOI 10.1016/j.optlaseng.2014.08.010
   Chen LF, 2005, OPT COMMUN, V254, P361, DOI 10.1016/j.optcom.2005.05.052
   El Assad S., 2015, SIGNAL PROCESS-IMAGE, V41, P1
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Han Feng-ying, 2011, PROCEDIA ENG, V23, P186, DOI DOI 10.1016/J.PROENG.2011.11.2487
   Khade P.N., 2012, Int. J. Comput. Sci. Issues, V9, P323
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu H, 2014, OPT LASER TECHNOL, V56, P313, DOI 10.1016/j.optlastec.2013.09.012
   Luo YL, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P336, DOI 10.1109/FSKD.2017.8393290
   Luo YL, 2016, NONLINEAR DYNAM, V83, P2293, DOI 10.1007/s11071-015-2481-7
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Pareek NK, 2011, COMM COM INF SC, V131, P413
   Som S, 2015, NONLINEAR DYNAM, V80, P615, DOI 10.1007/s11071-015-1893-8
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Tong XJ, 2013, COMMUN NONLINEAR SCI, V18, P1725, DOI 10.1016/j.cnsns.2012.11.002
   Tong XJ, 2015, ENTROPY-SWITZ, V17, P181, DOI 10.3390/e17010181
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang X, 2014, COMMUN NONLINEAR SCI, V77, P36
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1595, DOI 10.1007/s11071-015-2590-3
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1417, DOI 10.1007/s11071-015-2579-y
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wang Y, 2015, OPT COMMUN, V344, P147, DOI 10.1016/j.optcom.2015.01.045
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang W, 2015, OPT COMMUN, V338, P199, DOI 10.1016/j.optcom.2014.10.044
   Zhang W, 2012, OPT COMMUN, V285, P2343, DOI 10.1016/j.optcom.2012.01.029
   Zhang XP, 2016, MULTIMED TOOLS APPL, V75, P1745, DOI 10.1007/s11042-014-2372-9
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 49
TC 62
Z9 64
U1 2
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26191
EP 26217
DI 10.1007/s11042-018-5844-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, HB
   Lee, WB
   Chen, TH
AF Chen, Hsing-Bai
   Lee, Wei-Bin
   Chen, Tzung-Her
TI A novel DRM scheme for accommodating expectations of personal use
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management; Biometrics-based key generation; Key
   management; Smart-card cloning; Portability
ID BIOMETRICS; LAW
AB The existing DRM systems address the interests of providers, associated with prohibitively tight protection measures, which do not take customers' behaviors and needs into account. This paper proposes a novel DRM scheme that both accommodates consumers' expectations for the friendliness of personal use and preserves the providers' revenue. By maintaining a fairer balance between the interests of both content providers and consumers, the proposed DRM scheme thus benefits the digital content industry as a whole. The comparison between the related works and the proposed scheme implies the superiority of the proposed scheme while the security analyses and the further discussion demonstrate the proposed works well.
C1 [Chen, Hsing-Bai; Lee, Wei-Bin] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung, Taiwan.
   [Chen, Tzung-Her] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 Feng Chia University; National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
CR Chen HB, 2008, J COMPUT, V19, P3
   Chen YY, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P11, DOI 10.1109/ISDA.2008.301
   Dodis Y, 2008, SIAM J COMPUT, V38, P97, DOI 10.1137/060651380
   DUFFT N, 2005, DIGITAL MUSIC USAGE
   Golic JD, 2008, IEEE T INFORM THEORY, V54, P2026, DOI 10.1109/TIT.2008.920211
   Groenenboom M., 2006, Consumer's guide to Digital Rights Management
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Hsingbai C., 2010, J COMPUTATIONAL INFO, V6, P1377
   Hung-Min Sun, 2007, 2007 Inaugural IEEE International Conference on Digital Ecosystems and Technologies, P308
   Jiang YB, 2010, ELECTRON COMMER R A, V9, P386, DOI 10.1016/j.elerap.2010.06.003
   Kanjanarin W, 2001, NINTH IEEE INTERNATIONAL CONFERENCE ON NETWORKS, PROCEEDINGS, P140, DOI 10.1109/ICON.2001.962331
   Kumari S, 2016, MULTIMED TOOLS APPL, V75, P1135, DOI 10.1007/s11042-014-2361-z
   Lee WB, 2007, J ORG COMP ELECT COM, V17, P247, DOI 10.1080/10919390701436390
   Loytynoja M, 2003, P 1 INT MOB IPR WORK, P47
   Maghiros I, 2005, 21585 EUR EN
   OpenMobile Alliance, 2009, DRM ARCH CAND VER 2
   Rosenblatt B, 2007, ONLINE INFORM REV, V31, P73, DOI 10.1108/14684520710731047
   Samuelson P, 2003, COMMUN ACM, V46, P41, DOI 10.1145/641205.641229
   Stallings W., 2003, CRYPTOGRAPHY NETWORK
   Uludag U, 2005, LECT NOTES COMPUT SC, V3546, P310
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Wang MH, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P221, DOI 10.1109/FSKD.2007.101
   Yang HW, 2013, IET INFORM SECUR, V7, P189, DOI 10.1049/iet-ifs.2012.0191
   Zeng W., 2006, MULTIMEDIA SECURITY
   Zhang G, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2314
NR 25
TC 11
Z9 12
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23099
EP 23114
DI 10.1007/s11042-018-5614-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900002
DA 2024-07-18
ER

PT J
AU Dagadu, JC
   Li, JP
AF Dagadu, Joshua C.
   Li, Jianping
TI Context-based watermarking cum chaotic encryption for medical images in
   telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telemedicine; Medical image; Watermarking; Chaos-based encryption;
   Integer wavelet transform; Context
ID MULTIPLE WATERMARKING; CRYPTO-WATERMARKING; SECURE; SCHEME;
   AUTHENTICATION; RELIABILITY; EFFICIENT; ROBUST; SYSTEM; MAP
AB In this paper, we propose a security system for secure transmission of medical images in telemedicine applications. The system couples an IWT-LSB watermarking and an encryption based on random permutation and chaos, to ensure confidentiality, integrity, authentication and nonrepudiation of medical images. We use IWT due to the sensitive nature of medical images and the need to retain diagnostic quality after image reconstruction. During the watermarking phase, the medical image is decomposed into wavelet sub-bands. Electronic patient record and extracted context information are then embedded in the least significant bits of the detail sub-band (host) coefficients. During encryption, the reconstructed watermarked medical image is randomly permuted and the permuted pixels diffused with a chaotic key stream to produce the cipher watermarked image. Experimental results and analyzes show that the system provides sufficient security against various forms of attacks. Furthermore, we propose a security architecture for the system.
C1 [Dagadu, Joshua C.; Li, Jianping] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Int Ctr Wavelet Anal & Its Applicat, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Dagadu, JC (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Int Ctr Wavelet Anal & Its Applicat, Chengdu 611731, Sichuan, Peoples R China.
EM joscaldag@yahoo.com
RI li, jianping/A-9544-2012
OI Li, Jian Ping/0000-0003-2192-1450
FU National Natural Science Foundation of China [61370073]; National High
   Technology Research and Development Program of China [2007AA01Z423];
   project of Science and Technology Department of Sichuan Province
FX This paper was supported by the National Natural Science Foundation of
   China (Grant No. 61370073), the National High Technology Research and
   Development Program of China (Grant No. 2007AA01Z423), the project of
   Science and Technology Department of Sichuan Province.
CR Abdel-Nabi H, 2017, INT CONF INFORM COMM, P147, DOI 10.1109/IACS.2017.7921962
   Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Al-Haj A, 2017, J DIGIT IMAGING, V30, P26, DOI 10.1007/s10278-016-9901-1
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Al-Husainy MAF, 2012, INT J SECUR APPL, V6, P1
   AlShaikh M, 2017, MULTIMED TOOLS APPL, V76, P8937, DOI 10.1007/s11042-016-3499-7
   Ansari IA, 2016, PATTERN RECOGNITION
   Ashtiyani M, 2008, 3 INT C INF COMM TEC, P1
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Bouslimi D, 2016, SIGNAL PROCESS-IMAGE, V47, P160, DOI 10.1016/j.image.2016.05.021
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Coatrieux G, 2000, ENG MED BIOL SOC ANN, P250, DOI 10.1109/ITAB.2000.892396
   Coatrieux G, 2008, STUD HEALTH TECHNOL, V136, P667
   Covington MJ, 2002, 18TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, PROCEEDINGS, P249, DOI 10.1109/CSAC.2002.1176296
   Cox I. J., 2002, Digital Watermarking
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Dridi M, 2016, IET IMAGE PROCESS, V10, P830, DOI 10.1049/iet-ipr.2015.0868
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Gross T., 2001, Proceedings of Mensch Computer, P173
   Habutsu T., 1991, ADV CRYPTOLOGY EUROC, V91, P127
   Hajizadeh M, 2010, ADV ELECTR COMPUT EN, V10, P96, DOI 10.4316/AECE.2010.03016
   Khalifa N, 2015, INT C CONTR ENG INF, P1
   Kumar B, 2011, WORLD ACAD SCI ENG T, V79, P2011
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Maheshkar S, MULTIMEDIA TOOLS APP, P1
   Memon NA, 2011, INT J COMPUT MATH, V88, P2057, DOI 10.1080/00207160.2010.543677
   Memon NA, 2011, INT J COMPUT MATH, V88, P265, DOI 10.1080/00207161003596690
   Metkar SP, 2013, IEEE INT C SIGN PROC, P1
   Mitchell K, 2002, SURVEY CONTEXT AWARE
   Mitra A., 2006, INT J COMPUTER SCI, V1, P127
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Paar C., 2009, UNDERSTANDING CRYPTO
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parvees MYM, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0611-5
   Pascoe J, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P92, DOI 10.1109/ISWC.1998.729534
   Piva A, 2010, IEEE T INF FOREN SEC, V5, P13, DOI 10.1109/TIFS.2009.2038761
   Prasanna S, 2000, P ECCAP, P99
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Rial A, 2010, IEEE T INF FOREN SEC, V5, P920, DOI 10.1109/TIFS.2010.2072830
   Roussaki I, 2006, FOURTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P2, DOI 10.1109/PERCOMW.2006.65
   Salomon D., 2004, Data Compression: the Complete Reference, V4th ed.
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Solanki Neha, 2014, International Journal of Modern Education and Computer Science, V6, P40, DOI 10.5815/ijmecs.2014.10.06
   Tashk A, 2012, INT ISC CONF INFO SE, P60, DOI 10.1109/ISCISC.2012.6408192
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Wang H, 2017, ADV MANUF, V5, P158, DOI 10.1007/s40436-017-0178-5
   YOSHIDA T, 1983, J STAT PHYS, V31, P279, DOI 10.1007/BF01011583
   Zhang X, 2012, INT WORKSH DIG WAT, P358
   Zhou XQ, 2000, PROC SPIE, V3980, P390, DOI 10.1117/12.386427
   Zimmermann A, 2007, LECT NOTES ARTIF INT, V4635, P558
NR 58
TC 19
Z9 19
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24289
EP 24312
DI 10.1007/s11042-018-5725-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900053
DA 2024-07-18
ER

PT J
AU Hwang, W
   Kim, J
AF Hwang, Wonjun
   Kim, Junmo
TI Example image-based feature extraction for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Example-based feature extraction; Example pyramid
   representation
ID REPRESENTATION
AB This paper proposes a novel method for recognizing facial images based on the relative distances between an input image and example images. Example facial images can be easily collected online, and a large example database can span new possible facial variations not sufficiently learned during the learning phase. We first extract facial features using a baseline classifier that has a certain degree of accuracy. To achieve a better performance of the proposed method, we divide the collected examples into groups using a clustering method (e.g., k-means), where each clustered group contains examples with similar characteristics. We then hierarchically partition a group formed in the previous level into other groups to analyze more specific facial characteristics, which represent an example pyramid. To describe the characteristics of a group using the clustered examples, we divide the example group into a number of sub-groups. We calculate the averages of the sub-groups and select an example most similar to the average in each sub-group because we assume that the averages of the sub-groups can directly represent their characteristics. Using the selected examples, we build example code words for a novel feature extraction. The example code words are used to measure the distances to an input image and serve as anchors to analyze a facial image in the example domain. The distance values are normalized for each group at all pyramid levels, and are concatenated to form novel features for face recognition. We verified the effectiveness of the proposed example pyramid framework using well-known proposed features, including LBP, HOG, Gabor, and the deep learning method, on the LFW database, and showed that it can yield significant improvements in recognition performance.
C1 [Hwang, Wonjun] Ajou Univ, Dept Software & Comp Engn, Suwon, South Korea.
   [Kim, Junmo] Korea Adv Inst Sci & Technol, Dept EE, Daejeon, South Korea.
C3 Ajou University; Korea Advanced Institute of Science & Technology
   (KAIST)
RP Kim, J (corresponding author), Korea Adv Inst Sci & Technol, Dept EE, Daejeon, South Korea.
EM wjhwang@ajou.ac.kr; junmo.kim@kaist.ac.kr
RI Hwang, Wonjun/AAD-9090-2021; Kim, Junmo/C-2050-2011; Hwang,
   Wonjun/G-8560-2016
OI Hwang, Wonjun/0000-0001-8895-0411
FU National Research Foundation (NRF) of Korea [NRF-2014R1A2A2A01003140];
   Ajou University
FX This work was partially supported by the National Research Foundation
   (NRF) of Korea NRF-2014R1A2A2A01003140 and partially supported by the
   Ajou University research fund.
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], INT C COMP VIS
   Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246
   Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Chen Y, 2014, P NEUR INF PROC SYST
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng X, 2017, MULTIMED TOOLS APPL, V76, P13, DOI 10.1007/s11042-015-3012-8
   Hua G, 2011, IEEE T PATTERN ANAL, V33, P1921, DOI 10.1109/TPAMI.2011.182
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Hwang W, 2015, IEEE T IMAGE PROCESS, V24, P4263, DOI 10.1109/TIP.2015.2460464
   Hwang W, 2015, PATTERN RECOGN, V48, P1247, DOI 10.1016/j.patcog.2014.09.029
   Jain AK, 2012, IEEE MULTIMEDIA, V19, P20, DOI 10.1109/MMUL.2012.4
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li HX, 2014, PROC CVPR IEEE, P1843, DOI 10.1109/CVPR.2014.238
   Liu Y, 2010, INT C VIRT SYST MULT
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu JW, 2016, IEEE T CIRC SYST VID, V26, P529, DOI 10.1109/TCSVT.2015.2412831
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Ng A., 2001, and Y, P14
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Schroff F, 2011, IEEE I CONF COMP VIS, P2494, DOI 10.1109/ICCV.2011.6126535
   Shen X, 2013, COMP VIS PATT REC CV, P4321
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yi Dong, 2014, ARXIV14117923
   Yin Q, 2011, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2011.5995494
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang T, 2011, IEEE T INFORM THEORY, V57, P4689, DOI 10.1109/TIT.2011.2146690
   Zhang ZH, 2016, MULTIMED TOOLS APPL, V75, P3973, DOI 10.1007/s11042-015-3136-x
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou F, 2013, IEEE I CONF COMP VIS, P1025, DOI 10.1109/ICCV.2013.131
NR 45
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23429
EP 23447
DI 10.1007/s11042-017-5571-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900017
DA 2024-07-18
ER

PT J
AU Ojeda-Castelo, JJ
   Piedra-Fernandez, JA
   Iribarne, L
   Bernal-Bravo, C
AF Jesus Ojeda-Castelo, Juan
   Antonio Piedra-Fernandez, Jose
   Iribarne, Luis
   Bernal-Bravo, Cesar
TI KiNEEt: application for learning and rehabilitation in special
   educational needs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interface; Natural interaction; Educational games; Motor
   impairments
ID ACTIVITY RECOGNITION; SPEECH RECOGNITION; STUDENTS; GAME; PERFORMANCE;
   ENVIRONMENT; CHILDREN; BENEFITS; SUPPORT; DEVICES
AB In the 21st century, the landscape of education has changed dramatically due to the application of technology in teaching and learning. This is especially true for teaching children with special needs. Technology has made it possible for the special needs children to be actively involved in their learning. The use of interactive whiteboards in the Special Education Center Princesa Sofia presented a few challenges for both the teachers and the students, hence KiNEEt was developed to overcome these problems. KiNEEt is a system which has been developed with the major aim of improving physical and cognitive skills in students with special needs. The different activities in KiNEEt are configurable and the tutor can modify the settings according to the needs of the student. The activities are game-oriented to attract the students attention and motivate them to learn. KiNEEt is highly interactive and it will encourage the students to be active learners. Results showed that Microsoft Kinect is the most suitable platform for this device as the students will be able to use the computer while simultaneously improving their digital competence, cognitive and physical skills.
C1 [Jesus Ojeda-Castelo, Juan; Antonio Piedra-Fernandez, Jose; Iribarne, Luis] Univ Almeria, Dept Informat, ACG, CITE 3 Bldg,Floor 2,Off 110,Ctra Sacramento S-N, La Canada De San Urbano 04120, Almeria, Spain.
   [Bernal-Bravo, Cesar] Univ Almeria, Dept Educ, Almeria, Spain.
C3 Universidad de Almeria; Universidad de Almeria
RP Piedra-Fernandez, JA (corresponding author), Univ Almeria, Dept Informat, ACG, CITE 3 Bldg,Floor 2,Off 110,Ctra Sacramento S-N, La Canada De San Urbano 04120, Almeria, Spain.
EM jpiedra@ual.es
RI BERNAL-BRAVO, CESAR/F-1166-2015; Iribarne, Luis/A-2811-2008;
   Piedra-Fernandez, Jose/C-3284-2019
OI BERNAL-BRAVO, CESAR/0000-0002-2802-1618; Iribarne,
   Luis/0000-0003-1815-4721; Ojeda-Castelo, Juan Jesus/0000-0001-6842-8159;
   Piedra-Fernandez, Jose/0000-0002-8845-8547
FU EU ERDF; Spanish Ministry of Economy and Competitiveness (MINECO)
   [TIN2013-41576-R]
FX This work was funded by the EU ERDF and the Spanish Ministry of Economy
   and Competitiveness (MINECO) under Project TIN2013-41576-R. We also want
   to thank teachers and students of Special Education Center Princesa
   Sofia for their collaboration in this project.
CR Antón D, 2015, METHOD INFORM MED, V54, P145, DOI 10.3414/ME13-01-0109
   Attal F, 2015, SENSORS-BASEL, V15, P31314, DOI 10.3390/s151229858
   Bartoli L., 2013, ACM INT C PROCEEDING, P102, DOI [DOI 10.1145/2485760.2485774, 10.1145/2485760.2485774]
   Bossavit B, 2014, 2014 INTERNATIONAL CONFERENCE ON INTERACTIVE TECHNOLOGIES AND GAMES (ITAG 2014), P63, DOI 10.1109/iTAG.2014.16
   Boutsika E, 2014, PROCEDIA COMPUT SCI, V27, P123, DOI 10.1016/j.procs.2014.02.015
   Buisine S, 2014, INT J HUM-COMPUT INT, V30, P52, DOI 10.1080/10447318.2013.802200
   Cantón P, 2012, LECT NOTES COMPUT SC, V7382, P65, DOI 10.1007/978-3-642-31522-0_10
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Cho S, 2014, COMPUT METH PROG BIO, V113, P258, DOI 10.1016/j.cmpb.2013.09.006
   Choppin S, 2012, ISBS C P ARCH, V1
   Cottone P, 2015, PERVASIVE MOB COMPUT, V16, P156, DOI 10.1016/j.pmcj.2014.08.006
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   de Greef K., 2013, Games for Health, P197, DOI [10.1007/978-3-658-02897-8_15, DOI 10.1007/978-3-658-02897-8_15]
   Dorman SM, 1998, J SCHOOL HEALTH, V68, P120
   Echeverria M.A.M., 2013, Procedia-Social and Behavioral Sciences, V106, P1883, DOI DOI 10.1016/J.SBSPRO.2013.12.214
   Entwistle MS, 2003, INT J HUM-COMPUT INT, V16, P127, DOI 10.1207/S15327590IJHC1602_01
   Fern'ndez-Baena A., 2012, 2012 4th International Conference on Intelligent Networking and Collaborative Systems (INCoS 2012), P656, DOI 10.1109/iNCoS.2012.66
   Fernández-López A, 2013, COMPUT EDUC, V61, P77, DOI 10.1016/j.compedu.2012.09.014
   Francese R, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P116, DOI 10.1145/2254556.2254580
   Hachaj T, 2014, MULTIMEDIA SYST, V20, P81, DOI 10.1007/s00530-013-0332-2
   Homer BD, 2014, COMPUT EDUC, V74, P37, DOI 10.1016/j.compedu.2014.01.007
   Hsu H.M. J., 2011, INT J INFORM ED TECH, V1, P365, DOI [10.7763/IJIET.2011.V1.59, DOI 10.7763/IJIET.2011.V1.59]
   Hung CY, 2014, IEEE T LEARN TECHNOL, V7, P31, DOI 10.1109/TLT.2013.2294806
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Joselli M, 2012, 2012 IEEE INT GAM IN, P1
   Karray F, 2008, INT J SMART SENS INT, V1, P137, DOI 10.21307/ijssis-2017-283
   Kayama H, 2013, INT CONF PER COMP, P362, DOI 10.4108/icst.pervasivehealth.2013.252253
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Liang YJ, 2014, MOBILE NETW APPL, V19, P303, DOI 10.1007/s11036-013-0448-9
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lorenzo G, 2013, COMPUT EDUC, V62, P88, DOI 10.1016/j.compedu.2012.10.028
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mateu J, 2014, INT J HUM-COMPUT INT, V30, P815, DOI 10.1080/10447318.2014.927278
   Metcalf CD, 2013, IEEE T BIO-MED ENG, V60, P2184, DOI 10.1109/TBME.2013.2250286
   Neil A, 2013, EUR J PHYS REHAB MED, V49, P13
   Nijs L, 2014, COMPUT EDUC, V73, P40, DOI 10.1016/j.compedu.2013.11.008
   Parette HP, 2008, EARLY CHILD EDUC J, V35, P313, DOI 10.1007/s10643-007-0211-6
   Parry I, 2014, BURNS, V40, P852, DOI 10.1016/j.burns.2013.11.005
   Qu Junfeng, 2013, P INT C SOFTWARE ENG, P1
   Rahman MA, 2015, MULTIMED TOOLS APPL, V74, P5463, DOI 10.1007/s11042-014-1864-y
   Ranchal R, 2013, IEEE T LEARN TECHNOL, V6, P299, DOI 10.1109/TLT.2013.21
   Ringstaff C, 2002, LEARNING RETURN OUR, P34
   Saenz-de-Urturi Z., 2014, Proceedings of the 8th International Conference on Pervasive Computing Technologies for Healthcare, P262
   Sáenz-de-Urturi Z, 2015, BEHAV INFORM TECHNOL, V34, P1040, DOI 10.1080/0144929X.2015.1077889
   Sheu FR, 2014, COMPUT EDUC, V78, P268, DOI 10.1016/j.compedu.2014.06.008
   Soltani F., 2012, 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), P491, DOI 10.1109/CISIS.2012.55
   Song Y, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133371
   Staiano AE, 2011, CHILD DEV PERSPECT, V5, P93, DOI 10.1111/j.1750-8606.2011.00162.x
   Su CH, 2016, MULTIMED TOOLS APPL, V75, P10037, DOI 10.1007/s11042-015-2820-1
   Sung HY, 2015, COMPUT EDUC, V82, P179, DOI 10.1016/j.compedu.2014.11.012
   Torrente J, 2015, COMPUT EDUC, V83, P103, DOI 10.1016/j.compedu.2015.01.002
   Velloso Eduardo, 2013, P 4 AUGM HUM INT C, P116, DOI DOI 10.1145/2459236.2459256
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Yang MT, 2014, IEEE T LEARN TECHNOL, V7, P107, DOI 10.1109/TLT.2014.2307297
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yin Y, 2014, S VIS LANG HUM CEN C, P113, DOI 10.1109/VLHCC.2014.6883032
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zorilla AM, 2012, LECT NOTES COMPUTER, P391
NR 63
TC 16
Z9 17
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24013
EP 24039
DI 10.1007/s11042-018-5678-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900040
DA 2024-07-18
ER

PT J
AU Liu, JZ
   Ma, YD
   Li, SL
   Lian, J
   Zhang, XG
AF Liu, Jizhao
   Ma, Yide
   Li, Shouliang
   Lian, Jing
   Zhang, Xinguo
TI A new simple chaotic system and its application in medical image
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Hyperbolic sine; Image encryption; Medical image
ID COEXISTING ATTRACTORS; SEQUENCE GENERATOR; SYNCHRONIZATION;
   STEGANOGRAPHY; FRAMEWORK; CIRCUIT; MAP
AB Today, medical imaging suffers from serious issues such as malicious tampering and privacy leakage. Encryption is an effective way to protect these images from security threats. Among the available encryption algorithms, chaos-based methods have strong cryptographic properties, because chaotic systems are sensitive to initial conditions and parameters. However, traditional chaotic systems are easy to build, analyze, predict and can be re-scaled to any desired frequency. Thus, encryption schemes using traditional chaotic systems have low security levels. In this work, we propose a new simple chaotic system that utilizes a hyperbolic sine as its nonlinearity; this nonlinearity has rarely appeared in previous studies. Furthermore, the new chaotic system uses a decorrelation operation to enhance its performance. Statistical testing verifies that the chaotic sequence has good pseudorandom characteristics. In this study, we propose a scheme for medical image encryption based on this new chaotic system. The results of tests show that this encryption method can encrypt images effectively in a single round and that the proposed scheme provides sufficient security against known attacks.
C1 [Liu, Jizhao; Ma, Yide; Li, Shouliang; Lian, Jing; Zhang, Xinguo] Lanzhou Univ, Sch Informat Sci & Engn, 222,TianShui Rd South, Lanzhou, Gansu, Peoples R China.
C3 Lanzhou University
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, 222,TianShui Rd South, Lanzhou, Gansu, Peoples R China.
EM yidema@gmail.com
OI Ma, Yide/0000-0001-6098-7853; Li, Shouliang/0000-0001-7090-0811
FU Fundamental Research Funds for the Central Universities
   [lzujbky-2016-238]; National Natural Science Foundation of China
   [61175012]
FX The authors would like to thank Wenlong Xin for providing knowledge of
   the medical images. All the medical images used are from the First
   Hospital affiliated with Lanzhou University and the DICOM database. This
   study was supported by Fundamental Research Funds for the Central
   Universities No. lzujbky-2016-238) and the National Natural Science
   Foundation of China (No. 61175012).
CR Collen MF, 2015, HEALTH INFORM SER, P1, DOI 10.1007/978-1-4471-6732-7
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Gutub Adnan Abdul-Aziz, 2013, IADIS International Conference Applied Computing 2013. Proceedings, P67
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Hu HP, 2013, COMPUT PHYS COMMUN, V184, P765, DOI 10.1016/j.cpc.2012.11.017
   Kumar S, 2017, MULTIMED TOOLS APPL, V76, P8757, DOI 10.1007/s11042-016-3504-1
   Li CB, 2014, NONLINEAR DYNAM, V78, P2059, DOI 10.1007/s11071-014-1568-x
   Li CB, 2014, INT J BIFURCAT CHAOS, V24, DOI 10.1142/S0218127414500345
   Lian JW, 2014, INT J INFORM MANAGE, V34, P28, DOI 10.1016/j.ijinfomgt.2013.09.004
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu JZ, 2018, IET COMMUN, V12, P809, DOI 10.1049/iet-com.2017.0455
   Liu YQ, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S021812741750033X
   Mantos PLK, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0514-5
   Munmuangsaen B, 2011, PHYS LETT A, V375, P1445, DOI 10.1016/j.physleta.2011.02.028
   Pan SM, 2017, MULTIMED TOOLS APPL, V76, P2933, DOI 10.1007/s11042-015-3209-x
   Parvees MYM, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0611-5
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Piper JR, 2010, IEEE T CIRCUITS-II, V57, P730, DOI 10.1109/TCSII.2010.2058493
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Sprott JC, 2011, IEEE T CIRCUITS-II, V58, P240, DOI 10.1109/TCSII.2011.2124490
   Sun X., 2013, Image Encryption Algorithm and Practice-Based on C Sharp Language Implementation
   Pham VT, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618500664
   Wang X, 2017, NONLINEAR DYNAM, V89, P1673, DOI 10.1007/s11071-017-3542-x
   Weaver CA., 2016, HEALTHCARE INFORM MA, V4th
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu Y, 2014, COMMUN NONLINEAR SCI, V19, P3735, DOI 10.1016/j.cnsns.2014.02.029
   Zhang Y, 2017, IEEE SYST J, V11, P88, DOI 10.1109/JSYST.2015.2460747
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
NR 30
TC 65
Z9 66
U1 5
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22787
EP 22808
DI 10.1007/s11042-017-5534-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500054
DA 2024-07-18
ER

PT J
AU Shahdoosti, HR
   Mehrabi, A
AF Shahdoosti, Hamid Reza
   Mehrabi, Adel
TI MRI and PET image fusion using structure tensor and dual ripplet-II
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image fusion; Dual ripplet-II transform; Structure tensor; Edge
   detection; Weighting matrix
ID NONSUBSAMPLED CONTOURLET TRANSFORM; WAVELET TRANSFORM; REPRESENTATION;
   DESIGN
AB Medical image fusion aims at preserving salient image features, reducing the redundancy, and increasing the interpretation quality of images in clinical applications e.g. image-guided surgery. The PET image exhibits functional characteristic with low spatial resolution, while the MRI image exhibits brain tissue anatomy with high spatial resolution. Therefore, the image fusion task is carried out to inject the structural and anatomical information of the high-resolution MRI image into the metabolic information of the PET image. This paper firstly introduces the dual ripplet-II transform (DRT) to overcome the shift variance problem caused by the ripplet-II transform. The proposed transform incorporates the dual-tree complex wavelet into the traditional ripplet-II transform. Secondly, the proposed method takes advantage of the structure tensor and DRT to effectively merge the MRI and PET images. To this end, an objective function is proposed which exploits a weighting matrix to preserve more color and spatial information. Visual and statistical analyses show that the proposed method improves the visual quality and increases the quantitative criteria based on mutual information, edge information, spatial frequency, and structural similarity.
C1 [Shahdoosti, Hamid Reza; Mehrabi, Adel] Hamedan Univ Technol, Dept Elect Engn, Hamadan 65155, Iran.
RP Shahdoosti, HR (corresponding author), Hamedan Univ Technol, Dept Elect Engn, Hamadan 65155, Iran.
EM h.doosti@hut.ac.ir
RI Shahdoosti, Hamid/U-1005-2019
CR Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   BRACEWELL RN, 1989, SCI AM, V260, P86, DOI 10.1038/scientificamerican0689-86
   Chen FR, 2012, PROCEDIA ENGINEER, V29, P2938, DOI 10.1016/j.proeng.2012.01.418
   Chen GY, 2007, PATTERN RECOGN, V40, P578, DOI 10.1016/j.patcog.2006.04.039
   Coifman R., 1995, TRANSLATION INVARIAN, P125, DOI [10.1007/978-1-4612-2544-7_9, DOI 10.1007/978-1-4612-2544-7_9]
   CORMACK AM, 1981, P AM MATH SOC, V83, P325, DOI 10.2307/2043520
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Cui ZM, 2009, FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P480, DOI 10.1109/JCAI.2009.169
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Dai YH, 1999, SIAM J OPTIMIZ, V10, P177, DOI 10.1137/S1052623497318992
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Deng CZ, 2009, 2009 INTERNATIONAL CONFERENCE ON ENVIRONMENTAL SCIENCE AND INFORMATION APPLICATION TECHNOLOGY, VOL III, PROCEEDINGS,, P451, DOI 10.1109/ESIAT.2009.222
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Du J, 2016, NEUROCOMPUTING, V215, P3, DOI 10.1016/j.neucom.2015.07.160
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Ganasala P, 2016, J DIGIT IMAGING, V29, P73, DOI 10.1007/s10278-015-9806-4
   Ganasala P, 2014, J DIGIT IMAGING, V27, P407, DOI 10.1007/s10278-013-9664-x
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   He CT, 2010, PROCEDIA ENGINEER, V7, P280, DOI 10.1016/j.proeng.2010.11.045
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Ji X, 2015, MULTIMED TOOLS APPL, V76, P17633
   Liu XB, 2017, NEUROCOMPUTING, V235, P131, DOI 10.1016/j.neucom.2017.01.006
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Patel VM, 2008, IEEE IMAGE PROC, P2816, DOI 10.1109/ICIP.2008.4712380
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Piella G, 2009, INT J COMPUT VISION, V83, P1, DOI 10.1007/s11263-009-0206-4
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shahdoosti HR, 2016, J INTELL FUZZY SYST, V30, P3087, DOI 10.3233/IFS-152035
   Shahdoosti HR, 2015, IEEE GEOSCI REMOTE S, V12, P611, DOI 10.1109/LGRS.2014.2353135
   Shandoosti HR, 2017, DIGIT SIGNAL PROCESS, V67, P17, DOI 10.1016/j.dsp.2017.04.011
   Shandoosti HR, 2016, INFORM FUSION, V27, P150, DOI 10.1016/j.inffus.2015.06.006
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Te-Ming Tu, 2001, Information Fusion, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Velisavljevic V, 2006, IEEE T IMAGE PROCESS, V15, P1916, DOI 10.1109/TIP.2006.877076
   Wang L, 2014, INFORM FUSION, V19, P20, DOI 10.1016/j.inffus.2012.03.002
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Xiao Yi-han, 2011, Systems Engineering and Electronics, V33, P1668, DOI 10.3969/j.issn.1001-506X.2011.07.45
   Xu J, 2010, PROC SPIE, V7744, DOI 10.1117/12.863013
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Xu ZP, 2014, INFORM FUSION, V19, P38, DOI 10.1016/j.inffus.2013.01.001
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang X, MULTIMED TOOLS APPL, V76, P8175
   Zhao WD, 2016, INFORM FUSION, V27, P138, DOI 10.1016/j.inffus.2015.06.003
NR 46
TC 29
Z9 29
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22649
EP 22670
DI 10.1007/s11042-017-5067-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500048
DA 2024-07-18
ER

PT J
AU Chouchane, A
   Ouamane, A
   Boutellaa, E
   Belahcene, M
   Bourennane, S
AF Chouchane, Ammar
   Ouamane, Abdelmalik
   Boutellaa, Elhocine
   Belahcene, Mebarka
   Bourennane, Salah
TI 3D face verification across pose based on euler rotation and tensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face verification; Tensor analysis; Multilinear dimensionality
   reduction; Euler angles
ID PRINCIPAL COMPONENT ANALYSIS; RECOGNITION; GEOMETRY; MODEL
AB In this paper, we propose a new approach for 3D face verification based on tensor representation. Face challenges, such as illumination, expression and pose, are modeled as a multilinear algebra problem where facial images are represented as high order tensors. Particularly, to account for head pose variations, several pose scans are generated from a single depth image using Euler transformation. Multi-bloc local phase quantization (MBLPQ) histogram features are extracted from depth face images and arranged as a third order tensor. The dimensionality of the tensor is reduced based on the higher-order singular value decomposition (HOSVD). HOSVD projects the input tensor in a new subspace in which the dimension of each tensor mode is reduced. To discriminate faces of different persons, we utilize the Enhanced Fisher Model (EFM). Experimental evaluations on CASIA-3D database, which contains large head pose variations, demonstrate the effectiveness of the proposed approach. A verification rate of 98.60% is obtained.
C1 [Chouchane, Ammar; Ouamane, Abdelmalik; Belahcene, Mebarka] Univ Biskra, Biskra, Algeria.
   [Boutellaa, Elhocine] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
   [Bourennane, Salah] Univ Marseille, Inst Fresnel, Marseille, France.
C3 Universite Mohamed Khider Biskra; University of Oulu; Aix-Marseille
   Universite
RP Chouchane, A (corresponding author), Univ Biskra, Biskra, Algeria.
EM chouchane.ammar@yahoo.com
OI Boutellaa, Elhocine/0000-0003-4140-6130
CR Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Cao XC, 2015, IEEE T CYBERNETICS, V45, P2546, DOI 10.1109/TCYB.2014.2376938
   Choudry A., 2016, JUST WORK MIGRANT WO, P1
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Dibeklioglu H., 2008, BTAS 2008 - IEEE 2nd International Conference on Biometrics: Theory, Applications and Systems, P1
   Faltemier TimothyC., 2008, FG, P1, DOI DOI 10.1109/AFGR.2008.4813413
   Ji Q, 2002, IMAGE VISION COMPUT, V20, P499, DOI 10.1016/S0262-8856(02)00024-0
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1942, DOI 10.1109/TNNLS.2013.2297381
   Lai ZH, 2013, IEEE T IMAGE PROCESS, V22, P3904, DOI 10.1109/TIP.2013.2264678
   Letexier D, 2009, THESIS
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu XM, 2005, PROC CVPR IEEE, P502
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Ming Y, 2014, NEUROCOMPUTING, V129, P445, DOI 10.1016/j.neucom.2013.09.014
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Ouamane A, 2016, SIGNAL IMAGE VIDEO P, V10, P129, DOI 10.1007/s11760-014-0712-x
   Ouamane A, 2017, IEEE T INFORM FORENS
   Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49
   Rajwade A, 2006, IMAGE VISION COMPUT, V24, P849, DOI 10.1016/j.imavis.2006.02.010
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Vasilescu M.A.O., 2009, THESIS
   Vezzetti E, 2016, INT J BIOMETRICS, V8, P216
   Wang XQ, 2010, INT CONF SIGN PROCES, P86, DOI 10.1109/ICOSP.2010.5656654
   Xu C, 2005, 3D FACE RECOGNITION, P233, DOI [10.1007/978-3-540-30548-4_27, DOI 10.1007/978-3-540-30548-4_27]
   Xu CH, 2009, PATTERN RECOGN, V42, P1895, DOI 10.1016/j.patcog.2009.01.001
   Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 33
TC 7
Z9 8
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20697
EP 20714
DI 10.1007/s11042-017-5478-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300018
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Li, TZ
   Sun, LJ
   Han, C
   Guo, J
AF Li, Tiezhu
   Sun, Lijuan
   Han, Chong
   Guo, Jian
TI Person re-identification using salient region matching game
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-identification; Salient region; Matching game; Region match
AB The human saliency feature has been increasingly used for person re-identification across non-overlapping cameras but is deficient in retaining the minor features of the salient region, thus resulting in matching accuracy decline. To address this challenge, we first propose to extract optimal regions from pedestrian images that contain high intra-region feature similarity. Subsequently, by computing the saliency of each region, we choose the most salient region, which contains not only saliency features but also minor features, to represent the corresponding pedestrian. Finally, by formulating the competitive matching as hypothesis in a matching game, we obtain the most suitable set of matching by iteratively computing the payoff of each hypothesis. We evaluate our scheme on three widely used public datasets, and experimental results verify the advantage of our proposed algorithm, which outperforms previous representative methods with a matching ratio of 10.8%.
C1 [Li, Tiezhu; Sun, Lijuan; Han, Chong; Guo, Jian] Nanjing Univ Posts & Telecommun, Coll Comp, Nanjing 210003, Jiangsu, Peoples R China.
   [Li, Tiezhu] Henan Univ, Sch Software, Kaifeng 475000, Peoples R China.
   [Sun, Lijuan; Han, Chong; Guo, Jian] Nanjing Univ Posts & Telecommun, Jiangsu High Technol Res Key Lab Wireless Sensor, Nanjing 210003, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Henan University;
   Nanjing University of Posts & Telecommunications
RP Sun, LJ (corresponding author), Nanjing Univ Posts & Telecommun, Coll Comp, Nanjing 210003, Jiangsu, Peoples R China.; Sun, LJ (corresponding author), Nanjing Univ Posts & Telecommun, Jiangsu High Technol Res Key Lab Wireless Sensor, Nanjing 210003, Jiangsu, Peoples R China.
EM henultzh397@126.com; sunlijuan_nupt@163.com; hc@njupt.edu.cn;
   guoj@njupt.edu.cn
FU National Natural Science Foundation of China [61572261, 61702284];
   Natural Science Foundation of Jiangsu Province [BK20150868]; China
   Postdoctoral Science Foundation [2014M551635]; NUPTSF [NY214013];
   Jiangsu Planned Projects for Postdoctoral Research Funds [1302085B,
   1701165C]; Major Scientic Research Project of Higher Learning
   Institution of Henan Province [18A520022]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61572261 and 61702284, the Natural Science
   Foundation of Jiangsu Province under Grant No. BK20150868, the China
   Postdoctoral Science Foundation funded project under Grant No.
   2014M551635, the NUPTSF under Grant No. NY214013, the Jiangsu Planned
   Projects for Postdoctoral Research Funds under Grant No. 1302085B and
   1701165C, and the Major Scientic Research Project of Higher Learning
   Institution of Henan Province under Grant No. 18A520022.
CR An L, 2016, INFORM SCIENCES, V355, P74, DOI 10.1016/j.ins.2016.02.055
   [Anonymous], COMPUTER SCI
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cho YJ, 2016, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2016.151
   Cosmo L, 2016, INT C PATT RECOG, P3715, DOI 10.1109/ICPR.2016.7900212
   Einhäuser W, 2003, EUR J NEUROSCI, V17, P1089, DOI 10.1046/j.1460-9568.2003.02508.x
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Jing XY, 2017, IEEE T IMAGE PROCESS, V26, P1363, DOI 10.1109/TIP.2017.2651364
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Li JN, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTERS, COMMUNICATIONS, AND SYSTEMS (ICCCS), P178, DOI 10.1109/CCOMS.2015.7562896
   Li W, 2016, J VIS COMMUN IMAGE R, V40, P67, DOI 10.1016/j.jvcir.2016.06.009
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Li Y, 2015, IEEE WINT CONF APPL, P373, DOI 10.1109/WACV.2015.56
   Liu G., 2010, P INT C MACH LEARN, P663
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Poongothai E, 2016, INT C COMP TECHN INT, P1, DOI [10.1109/ICCTIDE.2016.7725330, DOI 10.1109/ICCTIDE.2016.7725330]
   Ramstrom O, 2002, LECT NOTES COMPUT SC, V2525, P462
   Rodolà E, 2013, INT J COMPUT VISION, V102, P129, DOI 10.1007/s11263-012-0568-x
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Wang CL, 2016, CHIN CONTR CONF, P3887, DOI 10.1109/ChiCC.2016.7553958
   Wang SK, 2016, IEEE IJCNN, P1660, DOI 10.1109/IJCNN.2016.7727397
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu Y, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P361, DOI 10.1109/ICIVC.2017.7984578
   Yang M, 2015, P INT C ICSSC SHANGH, P195, DOI [10.1049/cp.2015.0268, DOI 10.1049/CP.2015.0268]
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yu-Chen Chang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P1, DOI 10.1109/ISPACS.2012.6473442
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhu F, 2016, IEEE IMAGE PROC, P4279, DOI 10.1109/ICIP.2016.7533167
NR 40
TC 4
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21393
EP 21415
DI 10.1007/s11042-017-5541-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300047
DA 2024-07-18
ER

PT J
AU Alarcao, SM
   Fonseca, MJ
AF Alarcao, Soraia M.
   Fonseca, Manuel J.
TI Identifying emotions in images from valence and arousal ratings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective stimuli; Emotions; Fuzzy; Images; Multi-label classification;
   Random forest; Valence and arousal
ID MODEL
AB Experimental studies of emotion usually use datasets of normative emotional pictures to elicit specific emotional responses in human subjects. However, most of these datasets are not annotated with discriminating and reliable emotional tags, having only valence and arousal ratings for each image. Complementing this information with emotional tags would enrich the datasets, by increasing the number of annotated images available and consequently reducing the use of the same images in consecutive studies. This paper describes a multi-label recognizer that combines a Fuzzy approach with a Random Forest classifier to recognize both polarity and discrete emotions elicited by an image, using its valence and arousal ratings. Polarity indicates whether the emotional content of the image is negative, neutral, or positive, whereas emotions provide a more detailed description of the emotional content conveyed by the image. We evaluated our multi-label recognizer using pictures from four existing datasets containing images annotated with emotional content and valence and arousal ratings. Experimental results show that our recognizer is able to identify polarity with a precision of 84.8%, single emotions with 80.7%, and two emotions with 81.1%. Our recognizer can be useful to researchers who want to identify polarity and/or emotions from stimuli annotated with valence and arousal ratings. In particular, it can be used to automatically annotate with emotional tags already existent image datasets, avoiding the costs of manually annotating them with human subjects.
C1 [Alarcao, Soraia M.] Univ Lisbon, LASIGE, Fac Ciencias, Fac Sci,Informat Dept, Lisbon, Portugal.
   [Fonseca, Manuel J.] Univ Lisbon, LASIGE, Fac Ciencias, Fac Sci, Lisbon, Portugal.
C3 Universidade de Lisboa; Universidade de Lisboa
RP Alarcao, SM (corresponding author), Univ Lisbon, LASIGE, Fac Ciencias, Fac Sci,Informat Dept, Lisbon, Portugal.
EM salarcao@lasige.di.fc.ul.pt; mjfonseca@ciencias.ulisboa.pt
RI Meneses Alarcão, Soraia/HLP-7664-2023; Alarcão, Soraia
   Meneses/T-5114-2019; Fonseca, Manuel J./D-5120-2011
OI Meneses Alarcão, Soraia/0000-0002-0794-2979; Alarcão, Soraia
   Meneses/0000-0002-0794-2979; Fonseca, Manuel J./0000-0002-3559-828X
FU Fundacao para a Ciencia e Tecnologia, under LASIGE Strategic Project
   [UID/CEC/00408/2013]
FX This work was supported by national funds through Fundacao para a
   Ciencia e Tecnologia, under LASIGE Strategic Project -
   UID/CEC/00408/2013.
CR [Anonymous], 2001, EMOTIONS SOCIAL PSYC
   [Anonymous], 1999, Basic Emotions
   [Anonymous], 1995, 11 C UNC ART INT SAN, DOI DOI 10.1109/TGRS.2004.834800
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   BRETHERTON I, 1982, DEV PSYCHOL, V18, P906, DOI 10.1037/0012-1649.18.6.906
   Cambria E, 2015, NEUROCOMPUTING, V149, P443, DOI 10.1016/j.neucom.2014.01.064
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen YY, 2014, INT C MULT RETR
   Cheng C.M., 2008, Proc. IEEE MILCOM 2008, P1
   Cios K., 2007, Data Mining A Knowledge Discovery
   Codispoti M, 2007, PSYCHOPHYSIOLOGY, V44, P680, DOI 10.1111/j.1469-8986.2007.00545.x
   Dan-Glauser ES, 2011, BEHAV RES METHODS, V43, P468, DOI 10.3758/s13428-011-0064-1
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dietz R, 1999, COGNITIVE TECHNOLOGY
   Dunker Peter, 2008, P ACM INT C MULT INF, P97
   El-Nasr MS, 1998, 1998 CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P301, DOI 10.1109/NAFIPS.1998.715594
   Feng S, 2011, KNOWL INF SYST, V27, P281, DOI 10.1007/s10115-010-0325-9
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Fox Elaine., 2008, EMOTION SCI COGNITIV
   Francisco V, 2010, KNOWL INF SYST, V25, P421, DOI 10.1007/s10115-010-0320-1
   Ganganwar V., 2012, Int. J. Emerg. Technol. Adv. Eng., V2, P42
   Gbehounou S, 2012, INT C COMP GRAPH IM
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   He Zhang, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P274, DOI 10.1007/978-3-642-42051-1_35
   Horvat M, 2013, INT CONV INF COMM TE
   Islam J, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P124, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.29
   Jang JSR., 1997, NEUROFUZZY SOFT COMP, V42, P1482
   Jiang ZQ, 2014, J NEUROLINGUIST, V28, P19, DOI [10.1016/j.jneuroling.2013.11.001, 10.3969/j.issn.1672-1497.2014.04.004]
   Jou B, 2015, INT C MULT, V1, P159
   Katsimerou C, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2897369
   Kim Y, 2009, INT C C CONS, P3
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Kurdi B, 2017, BEHAV RES METHODS, V49, P457, DOI 10.3758/s13428-016-0715-3
   Lane RD, 1997, AM J PSYCHIAT, V154, P926
   Lang P. J., 1997, NIMH CTR STUDY EMOTI, V1, P39
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Marchewka A, 2014, BEHAV RES METHODS, V46, P596, DOI 10.3758/s13428-013-0379-1
   Mehrabian A., 1974, APPROACH ENV PSYCHOL
   Meneses Alarcao S, 2014, THESIS
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Olkiewicz K. A., 2010, Proceedings 2010 International Multiconference on Computer Science and Information Technology (IMCSIT 2010), P89
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Peng KC, 2014, INT C IM PROC
   Peng KC, 2015, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2015.7298687
   Pesenko Y.A., 1982, Principles and methods of quantitative analysis in faunistic research
   PICARD R.W, 1995, M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 321
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Riegel M, 2016, BEHAV RES METHODS, V48, P600, DOI 10.3758/s13428-015-0620-1
   Russell JA, 1999, PSYCHOL BULL, V125, P3, DOI 10.1037/0033-2909.125.1.3
   Schmidt S, 2009, J AM SOC INF SCI TEC, V60, P863, DOI 10.1002/asi.21043
   Sebastiani F., 2006, P 5 INT C LANG RES E, P417, DOI DOI 10.1155/2015/715730
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037//0022-3514.52.6.1061
   Shiota MN, 2007, COGNITION EMOTION, V21, P944, DOI 10.1080/02699930600923668
   Smith A, 2004, BEHAV RES METHODS IN
   Sorower Mohammad S., 2010, A Literature Survey on Algorithms for Multi-Label Learning
   Srensen T., 1948, K DANSKE VIDENSK SEL, V5, P1, DOI DOI 10.1234/12345678
   Sun M, 2016, IEEE INT C MULT EXP
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   van der Heide A, 2011, ADV INTEL SYS RES, P620
   Wang XH, 2013, IEEE IMAGE PROC, P3230, DOI 10.1109/ICIP.2013.6738665
   You Q., 2015, "Robust image sentiment analysis using progressively trained and domain transferred deep networks"
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhao SC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P879, DOI 10.1145/2733373.2806354
   Zhao SC, 2015, IEEE IMAGE PROC, P2459, DOI 10.1109/ICIP.2015.7351244
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
NR 74
TC 8
Z9 8
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17413
EP 17435
DI 10.1007/s11042-017-5311-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300064
DA 2024-07-18
ER

PT J
AU Ferretti, S
AF Ferretti, Stefano
TI On the complex network structure of musical pieces: analysis of some use
   cases from different music genres
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Musical scores; Music analysis; Complex networks; Centrality measures
ID SMALL-WORLD; PARALLEL FRAMEWORK; LANGUAGE
AB This paper focuses on the modeling of musical melodies as networks. Notes of a melody can be treated as nodes of a network. Connections are created whenever notes are played in sequence. We analyze some main tracks coming from different music genres, with melodies played using different musical instruments. We find out that the considered networks are, in general, scale free networks and exhibit the small world property. We measure the main metrics and assess whether these networks can be considered as formed by sub-communities. Outcomes confirm that peculiar features of the tracks can be extracted from this analysis methodology. This approach can have an impact in several multimedia applications such as music didactics, multimedia entertainment, and digital music generation.
C1 [Ferretti, Stefano] Univ Bologna, Dept Comp Sci & Engn, Mura Anteo Zamboni 7, Bologna, Italy.
C3 University of Bologna
RP Ferretti, S (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Mura Anteo Zamboni 7, Bologna, Italy.
EM s.ferretti@unibo.it
OI Ferretti, Stefano/0000-0002-1911-4708
CR ANGELER DG, 2016, SPRINGERPLUS, V5
   [Anonymous], 2012, COLING 12
   Bastian M., 2009, 3 INT AAAI C WEB SOC, DOI DOI 10.13140/2.1.1341.1520
   Bell C., 2011, J Comput Sci Colleges, V27, P99
   Berenzweig A, 2004, COMPUT MUSIC J, V28, P63, DOI 10.1162/014892604323112257
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009
   Cancho RFI, 2001, P ROY SOC B-BIOL SCI, V268, P2261, DOI 10.1098/rspb.2001.1800
   Cong J, 2014, PHYS LIFE REV, V11, P598, DOI 10.1016/j.plrev.2014.04.004
   Cootes AP, 2007, J MOL BIOL, V369, P1126, DOI 10.1016/j.jmb.2007.03.013
   D'Angelo G, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P1, DOI 10.1109/HPCSim.2016.7568309
   Fell DA, 2000, NAT BIOTECHNOL, V18, P1121, DOI 10.1038/81025
   Ferretti S, 2017, INFORM SCIENCES, V375, P271, DOI 10.1016/j.ins.2016.10.007
   Ferretti S, 2013, COMPUT COMMUN, V36, P481, DOI 10.1016/j.comcom.2012.12.006
   Ferretti S, 2013, FUTURE GENER COMP SY, V29, P1631, DOI 10.1016/j.future.2012.06.002
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Grabska-Gradzinska I, 2012, INT J MOD PHYS C, V23, DOI 10.1142/S0129183112500519
   Granroth-Wilding M, 2014, J NEW MUSIC RES, V43, P355, DOI 10.1080/09298215.2014.910532
   Humphries MD, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002051
   Kakade S., 2016, 5 INT C LEARN REPR I
   Keller R, 2013, COMPUT MUSIC J, V37, P54, DOI 10.1162/COMJ_a_00201
   Knopke I, 2012, CH CRC DATA MIN KNOW, P327
   Lichtenwalter RN, 2010, J INTELL SYST, V19, P95, DOI 10.1515/JISYS.2010.19.2.95
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu XF, 2010, PHYSICA A, V389, P126, DOI 10.1016/j.physa.2009.08.035
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Manaris B, 2005, COMPUT MUSIC J, V29, P55, DOI 10.1162/comj.2005.29.1.55
   Montoya JM, 2002, J THEOR BIOL, V214, P405, DOI 10.1006/jtbi.2001.2460
   Newman M., 2010, Networks: An introduction oxford univ
   OMADADHAIN J, 2003, 0317 UCIICS
   Patra Braja Gopal, 2013, Mining Intelligence and Knowledge Exploration. First International Conference, MIKE 2013. Proceedings: LNCS 8284, P62, DOI 10.1007/978-3-319-03844-5_7
   Pardo TAS, 2006, INT C COMMUN CIRCUIT, P2678
   Shah N, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1055, DOI 10.1145/2783258.2783321
   Van den Oord A., 2013, P NIPS
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhao W, 2014, INT CONF PERVAS COMP, P1
NR 39
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16003
EP 16029
DI 10.1007/s11042-017-5175-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300001
DA 2024-07-18
ER

PT J
AU Firdaus, A
   Anuar, NB
   Ab Razak, MF
   Sangaiah, AK
AF Firdaus, Ahmad
   Anuar, Nor Badrul
   Ab Razak, Mohd Faizal
   Sangaiah, Arun Kumar
TI Bio-inspired computational paradigm for feature investigation and
   malware detection: interactive analytics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Static analysis; Malware; Feature selection; Android; Machine learning;
   Neural network
ID MACHINE LEARNING CLASSIFIERS; FEATURE-SELECTION; CLASSIFICATION; MODEL
AB Recently, people rely on mobile devices to conduct their daily fundamental activities. Simultaneously, most of the people prefer devices with Android operating system. As the demand expands, deceitful authors develop malware to compromise Android for private and money purposes. Consequently, security analysts have to conduct static and dynamic analyses to counter malware violation. In this paper, we adopt static analysis which only requests minimal resource consumption and rapid processing. However, finding a minimum set of features in the static analysis are vital because it removes irrelevant data, reduces the runtime of machine learning detection and reduces the dimensionality of datasets. Therefore, in this paper, we investigate three categories of features, which are permissions, directory path, and telephony. This investigation considers the features frequency as well as repeatedly used in each application. Subsequently, this study evaluates the proposed features in three bio-inspired machine learning classifiers in artificial neural network (ANN) category to signify the usefulness of ANN type in uncovering unknown malware. The classifiers are multilayer perceptron (MLP), voted perceptron (VP) and radial basis function network (RBFN). Among all these three classifiers, the outstanding outcomes acquire is the MLP, which achieves 90% in accuracy and 87% in true positive rate (TPR), as well as 97% accuracy in our Bio Analyzer prediction system.
C1 [Firdaus, Ahmad; Anuar, Nor Badrul; Ab Razak, Mohd Faizal] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
   [Firdaus, Ahmad; Ab Razak, Mohd Faizal] Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Kuantan 26300, Pahang, Malaysia.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Universiti Malaya; Universiti Malaysia Pahang Al-Sultan Abdullah
   (UMPSA); Vellore Institute of Technology (VIT); VIT Vellore
RP Firdaus, A; Anuar, NB (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.; Firdaus, A (corresponding author), Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Kuantan 26300, Pahang, Malaysia.
EM ahmadfirdaus@um.edu.my; badrul@um.edu.my; faizalabrazak@siswa.um.edu.my;
   arunkumarsangaiah@gmail.com
RI Anuar, Nor Badrul/B-3101-2010; , Ahmad/AAH-4337-2019; Sangaiah, Arun
   Kumar/U-6785-2019; Razak, Mohd Faizal Ab/O-2027-2018
OI Anuar, Nor Badrul/0000-0003-4380-5303; , Ahmad/0000-0002-7116-2643;
   Sangaiah, Arun Kumar/0000-0002-0229-2460; Razak, Mohd Faizal
   Ab/0000-0002-7388-4340
FU eScienceFund [01-01-03-SF0914]
FX This study was funded by eScienceFund (grant number 01-01-03-SF0914).
CR Aafer Y, 2013, L N INST COMP SCI SO, V127, P86
   Ab Razak MF, 2016, J NETW COMPUT APPL, V75, P58, DOI 10.1016/j.jnca.2016.08.022
   Abu Samra AA, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P729, DOI 10.1109/IMIS.2013.111
   Adewole KS, 2017, J NETW COMPUT APPL, V79, P41, DOI 10.1016/j.jnca.2016.11.030
   Afifi F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162627
   Allix K, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P468, DOI [10.1145/2901739.2903508, 10.1109/MSR.2016.056]
   Amos B, 2013, INT WIREL COMMUN, P1666, DOI 10.1109/IWCMC.2013.6583806
   Anderson B., Understanding the Android File Hierarchy
   [Anonymous], SOFT COMPUT METHODOL
   [Anonymous], 2014, PROC 8 USENIX WORKSH
   [Anonymous], IT THREAT EV Q3 2016
   [Anonymous], INT J DISTRIBUTED SE
   [Anonymous], SYM INT REP
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], SMART INNOVATION SYS
   [Anonymous], LOOK GOOGLE BOUNCER
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], ANDROID APPS ZERO PE
   [Anonymous], BIOMETRIKA
   [Anonymous], 2012, P 2 ACM C DATA APPL, DOI DOI 10.1145/2133601.2133640
   [Anonymous], 2013, Inter- national Journal of Scientific and Technology Research
   [Anonymous], 2019, McAfee labs threats reports
   Anuar NB, 2013, SECUR COMMUN NETW, V6, P1087, DOI 10.1002/sec.673
   Apvrille A, 2012, J COMPUT VIROL HACKI, V8, P61, DOI 10.1007/s11416-012-0162-3
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Arzt S, 2014, ACM SIGPLAN NOTICES, V49, P259, DOI [10.1145/2666356.2594299, 10.1145/2594291.2594299]
   Bartel A, 2012, IEEE INT CONF AUTOM, P274, DOI 10.1145/2351676.2351722
   Burguera I., 2011, P 1 ACM WORKSH SEC P, P15, DOI DOI 10.1145/2046614.2046619
   Castillo C., 2011, Android malware: Past, present, and future
   Chan PPK, 2014, INT CONF MACH LEARN, P82, DOI 10.1109/ICMLC.2014.7009096
   Chess B, 2004, IEEE SECUR PRIV, V2, P76, DOI 10.1109/MSP.2004.111
   Clarke NL, 2007, INT J INF SECUR, V6, P1, DOI 10.1007/s10207-006-0006-6
   Faruki P., 2013, P 6 INT C SEC INF NE, P152, DOI [10.1145/2523514.2523539, DOI 10.1145/2523514.2523539]
   Feizollah A., 2013, Intelligent Robotics Systems: Inspiring the NEXT, P220, DOI DOI 10.1007/978-3-642-40409-2_19
   Feizollah A, 2017, COMPUT SECUR, V65, P121, DOI 10.1016/j.cose.2016.11.007
   Feizollah A, 2015, DIGIT INVEST, V13, P22, DOI 10.1016/j.diin.2015.02.001
   Feizollah A, 2013, MALAYS J COMPUT SCI, V26, P251
   Feng Y, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P576, DOI 10.1145/2635868.2635869
   Firdaus A., 2015, Proceedings of the Fourth International Conference on Computer Science Computational Mathematics (ICCSCM 2015), P177
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Gascon Hugo, 2013, P 2013 ACM WORKSH AR, P45
   Gordon M I., 2015, Network and Distributed System Security Symposium (NDSS), P8
   Grace M., 2011, Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services, Low Wood Bay, Lake District, UK, P281
   Grace M.C., 2012, NDSS, V14
   Grace M. C., 2012, PROC 5 ACM C SECUR P, P101
   Huang JJ, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P1036, DOI 10.1145/2568225.2568301
   Ikinci A., 2008, Sicherheit, V8, P407
   Junaid M, 2016, COMPUT SECUR, V59, P92, DOI 10.1016/j.cose.2016.01.008
   Kabakus AT, 2015, DIGIT INVEST, V13, P1, DOI 10.1016/j.diin.2015.01.001
   Kariisa AT, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148478
   Karim A, 2016, J UNIVERS COMPUT SCI, V22, P567
   Karim A, 2014, J ZHEJIANG U-SCI C, V15, P943, DOI 10.1631/jzus.C1300242
   Kotsiantis SB, 2006, ARTIF INTELL REV, V26, P159, DOI 10.1007/S10462-007-9052-3
   Lee J, 2015, COMPUT SECUR, V52, P234, DOI 10.1016/j.cose.2015.02.003
   Liang S., 2013, Proceedings of the Third ACM workshop on Security and privacy in smartphones mobile devices, P21, DOI DOI 10.1145/2516760.2516769
   Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]
   Lu Long, 2012, P 2012 ACM C COMP CO, P229, DOI DOI 10.1145/2382196.2382223
   Marefat A, 2016, MALAYS J COMPUT SCI, V29, P247, DOI 10.22452/mjcs.vol29no4.1
   Peiravian N, 2013, PROC INT C TOOLS ART, P300, DOI 10.1109/ICTAI.2013.53
   Peng Hao., 2012, P ACM C COMPUTER COM, P241
   Rasthofer  S., 2014, NDSS
   Russon M.-A., 2016, Android malware discovered on Google Play has infected millions of users with spyware
   Sahs J., 2012, 2012 European Intelligence and Security Informatics Conference (EISIC), P141, DOI 10.1109/EISIC.2012.34
   Sanz B, 2013, CYBERNET SYST, V44, P469, DOI 10.1080/01969722.2013.803889
   Sanz B, 2013, ADV INTELL SYST COMP, V189, P289
   Sarip AG, 2016, MALAYS J COMPUT SCI, V29, P15
   Sarma N., 2012, P 17 ACM S ACC CONTR, P13, DOI DOI 10.1145/2295136.2295141
   Schmidt A- D, IEEE INT C COMMUNICA, P1
   Schmidt AD, 2009, 2009 4TH INTERNATIONAL CONFERENCE ON MALICIOUS AND UNWANTED SOFTWARE (MALWARE 2009), P1, DOI 10.1109/MALWARE.2009.5403026
   Seo SH, 2014, J NETW COMPUT APPL, V38, P43, DOI 10.1016/j.jnca.2013.05.008
   Shabtai A., 2010, Proceedings 2010 International Conference on Computational Intelligence and Security (CIS 2010), P329, DOI 10.1109/CIS.2010.77
   Shabtai A, 2012, J INTELL INF SYST, V38, P161, DOI 10.1007/s10844-010-0148-x
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sharif M, 2008, LECT NOTES COMPUT SC, V5283, P481
   Sheen S, 2015, NEUROCOMPUTING, V151, P905, DOI 10.1016/j.neucom.2014.10.004
   Suarez-Tangil G, 2014, EXPERT SYST APPL, V41, P1104, DOI 10.1016/j.eswa.2013.07.106
   Sung-Hoon Lee, 2013, International Journal of Computer and Communication Engineering, V2, P324, DOI 10.7763/IJCCE.2013.V2.197
   Walczak B, 2000, CHEMOMETR INTELL LAB, V50, P179, DOI 10.1016/S0169-7439(99)00056-8
   Walenstein A., 2012, Proceedings of the International Conference on Security and Privacy in Mobile Information and Communication Systems, P51
   Williams G., 2010, ARFF Data
   Wu DJ, 2012, ASIA JT CONF INF SEC, P62, DOI 10.1109/AsiaJCIS.2012.18
   Yang ZM, 2012, WOR CONG SOFTW ENG, P101, DOI 10.1109/WCSE.2012.26
   Yerima SY, 2015, IET INFORM SECUR, V9, P313, DOI 10.1049/iet-ifs.2014.0099
   Yerima SY, 2014, 2014 EIGHTH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPS, SERVICES AND TECHNOLOGIES (NGMAST), P37, DOI 10.1109/NGMAST.2014.23
   Yerima SY, 2014, IET INFORM SECUR, V8, P25, DOI 10.1049/iet-ifs.2013.0095
   Yerima SY, 2013, INT CON ADV INFO NET, P121, DOI 10.1109/AINA.2013.88
   Yu L, 2004, J MACH LEARN RES, V5, P1205
   Zhang LS, 2013, ADV INTEL SYS RES, V52, P89
   Zhongyang Y., 2013, 8th ACM Symposium on Information, Computer and Communications Security, ASIA CCS '13, Hangzhou, China-May 08-10, 2013, ASIACCS'13, P353, DOI 10.1145/2484313.2484359
   Zhou W., 2013, Proceedings of the third ACM conference on Data and application security and privacy, P185
   Zhou Y., 2012, Android malware genome project
   Zia T, 2015, MALAYS J COMPUT SCI, V28, P93
NR 92
TC 14
Z9 14
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17519
EP 17555
DI 10.1007/s11042-017-4586-0
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900002
DA 2024-07-18
ER

PT J
AU Li, FY
   Wu, K
   Lei, JS
   Wen, M
   Ren, YL
AF Li, Fengyong
   Wu, Kui
   Lei, Jingsheng
   Wen, Mi
   Ren, Yanli
TI Unsupervised steganalysis over social networks based on multi-reference
   sub-image sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised steganalysis; Multi-scale calibration; Randomized sampling;
   Maximummean discrepancy
ID MODEL
AB This work proposes a new unsupervised steganalysis scheme which mainly tackles the challenge in identifying individual JPEG image as stego or cover. The proposed scheme does not need a large number of samples to train classification model, and thus it is significantly different from the existing supervised steganalysis schemes. The proposed scheme employs calibration technology to construct multiple reference images from one suspicious image. These reference images are considered as the imitation of cover. Furthermore, randomized sampling is performed to construct sub-image sets from suspicious image and reference images, respectively. By calculating the maximum mean discrepancy between any two sub-image sets, an efficient measure is provided to give the optimal decision on this suspicious image. Experimental results show that the proposed scheme is effective and efficient in identifying individual image, and outperforms the state-of-the-art steganalysis scheme.
C1 [Li, Fengyong; Wu, Kui; Lei, Jingsheng; Wen, Mi] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
   [Wu, Kui] Univ Victoria, Dept Comp Sci, Victoria, BC, Canada.
   [Ren, Yanli] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University of Electric Power; University of Victoria; Shanghai
   University
RP Li, FY (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
EM fyli@shiep.edu.cn
OI Wu, Kui/0000-0002-2069-0032
FU Natural Science Foundation of China [61602295, 61373152, 61672337,
   61572311, 61572309, 61472236]; Natural Science Foundation of Shanghai
   [16ZR1413100]; Scientific Research Foundation of Shanghai University of
   Electric Power [K2015-010]; Excellent University Young Teachers Training
   Program of Shanghai Municipal Education Commission [ZZsdl15105]; Project
   of Shanghai Science and Technology Committee [14110500800]; "Dawn"
   Program of Shanghai Education Commission [16SG47]
FX This work was supported by Natural Science Foundation of China under
   Grants (No. 61602295, 61373152, 61672337, 61572311, 61572309, and
   61472236), Natural Science Foundation of Shanghai (No. 16ZR1413100), the
   Scientific Research Foundation of Shanghai University of Electric Power
   (No. K2015-010), the Excellent University Young Teachers Training
   Program of Shanghai Municipal Education Commission (No. ZZsdl15105),
   Project of Shanghai Science and Technology Committee (14110500800) and
   the "Dawn" Program of Shanghai Education Commission (No. 16SG47).
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2019, TECHNICAL REPORT
   Böhme R, 2008, LECT NOTES COMPUT SC, V5284, P178
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cogranne R, 2014, SIGNAL PROCESS, V100, P169, DOI 10.1016/j.sigpro.2014.01.027
   Denemark T., 2014, P SPIE EL IM MED WAT, V9028, P2
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   Hetzl S, 2005, LECT NOTES COMPUT SC, V3677, P119
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Ker A, 2012, P SPIE MED WAT SEC F, V8303, P1
   Ker AD, 2014, IEEE T INF FOREN SEC, V9, P1424, DOI 10.1109/TIFS.2014.2336380
   Ker AD, 2011, PROC SPIE, V7880, DOI 10.1117/12.872888
   Kodovsky J, 2010, IEEE T INF FOREN SEC, V5, P681, DOI 10.1109/TIFS.2010.2056684
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Li FY, 2016, SECUR COMMUN NETW, V9, P729, DOI 10.1002/sec.1094
   Li FY, 2016, IEEE T INF FOREN SEC, V11, P344, DOI 10.1109/TIFS.2015.2496910
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   PevuSr T., 2007, P SPIE ELECT IMAGING, V6505
   Qiao T, 2015, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0019-7
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P1980, DOI 10.1109/TIP.2014.2310126
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Zhang T., 2003, SAC 03, P307, DOI DOI 10.1145/952532.952595
NR 28
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17953
EP 17971
DI 10.1007/s11042-017-4759-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900021
DA 2024-07-18
ER

PT J
AU Oo, ZY
   Wang, LB
   Phapatanaburi, K
   Iwahashi, M
   Nakagawa, S
   Dang, JW
AF Oo, Zeyan
   Wang, Longbiao
   Phapatanaburi, Khomdet
   Iwahashi, Masahiro
   Nakagawa, Seiichi
   Dang, Jianwu
TI Phase and reverberation aware DNN for distant-talking speech enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Deep neural network; Phase information; Reverberant
   environment
AB Enhancing reverberant speech with Deep Neural Networks (DNNs) is an interesting yet challenging topic. The performance of speech enhancement degrades significantly when test and training conditions are mismatched. In this paper we propose a Static Reverberation Aware Training (SRAT)-based dereverberation through which the reverberation estimate is obtained by averaging over broken down frame. This method significantly reduces the input dimensions of the and enables the DNN to learn the relations between clean and reverberant speech more efficiently. Most speech enhancement approaches ignore phase information due to its complicated structure. As phase correlates closely to speech signal we exploited this relationship to achieve better performance using DNN. Phase information was augmented with magnitude information and used as the input for DNN. We denote this method as phase aware DNN. Finally, both phase information and reverberation were added to reverberant speech to achieve better speech enhancement performance in a distant-talking condition. Features of the reverberant speech, phase and reverberation were used during the training and testing stages. This is because the DNN could use both reverberation and phase information to better generalize the speech signal. The proposed method was evaluated using the REVERB CHALLENGE 2014 database. Results are significantly improved results with respect to both reconstructed speech quality (PESQ: Perceptual Evaluation of Speech Quality) and influence of reverberation (SRMR: Speech to Reverberation Modulation Energy Ratio). As compared to the conventional DNN-based approach, this proposed one improved SRMR from 4.84 to 5.92 and PESQ from 2.34 to 2.70, indicating that our proposed method could efficiently enhance speech severely corrupted by reverberation.
C1 [Oo, Zeyan; Phapatanaburi, Khomdet; Iwahashi, Masahiro] Nagaoka Univ Technol, Nagaoka, Niigata, Japan.
   [Wang, Longbiao; Dang, Jianwu] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
   [Nakagawa, Seiichi] Toyohashi Univ Technol, Toyohashi, Aichi, Japan.
   [Dang, Jianwu] Intelligent Spoken Language Technol Tianjin Co Lt, Tianjin, Peoples R China.
C3 Nagaoka University of Technology; Tianjin University; Toyohashi
   University of Technology
RP Wang, LB (corresponding author), Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
EM S145060@stn.nagaokaut.ac.jp; longbiao_wang@tju.edu.cn;
   s147009@stn.nagaokaut.ac.jp; iwahashi@vos.nagaokaut.ac.jp;
   nakagawa@slp.ics.tut.ac.jp; jdang@jaist.ac.jp
RI Phapatanaburi, Khomdet/U-6816-2019; zhen, li/KGK-6604-2024; nakagawa,
   seiichi/L-5543-2019
FU National Natural Science Foundation of China [61771333, U1736219]; JSPS
   KAKENHI [16K12461, 16K00297]; Grants-in-Aid for Scientific Research
   [16K12461] Funding Source: KAKEN
FX The research was supported partially by the National Natural Science
   Foundation of China (No. 61771333 and No. U1736219) and JSPS KAKENHI
   Grant (No. 16K12461 and No. 16K00297).
CR [Anonymous], 2005, Speech Enhancement
   [Anonymous], P INTERSPEECH
   Boll S, 1984, IEEE T ACOUSTICS SPE, V32, P1109
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   EPHRAIM Y, 1995, IEEE T SPEECH AUDI P, V3, P251, DOI 10.1109/89.397090
   Hegde RM, 2007, IEEE T AUDIO SPEECH, V15, P190, DOI 10.1109/TASL.2006.876858
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kanagasundaram A, 2012, P SST, P9
   Kinoshita K., 2011, NTT TECHNICAL REV, V9, P1
   Kinoshita K, 2013, IEEE WORK APPL SIG
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015
   Lu XG, 2013, INTERSPEECH, P436
   Nakagawa S, 2012, IEEE T AUDIO SPEECH, V20, P1085, DOI 10.1109/TASL.2011.2172422
   Nakatani T, 2008, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2008.4517552
   Oo Z, 2015, P 109 SPOK LANG RES, V115, P37
   ROBINSON T, 1995, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.1995.479278
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100
   Tchorz J, 2003, IEEE T SPEECH AUDI P, V11, P184, DOI 10.1109/TSA.2003.811542
   Ueda Y, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0278-y
   Wan EA, 1998, HDB NEURAL NETWORK S
   Wang LB, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2092
   Wang LB, 2010, IEICE T INF SYST, VE93D, P2397, DOI 10.1587/transinf.E93.D.2397
   Xiao X, 2014, P REV WORKSH
   Xiao X, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0300-4
   Xu Y, 2014, Fifteenth Annual Conference of the International Speech Communication Association
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
NR 27
TC 10
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18865
EP 18880
DI 10.1007/s11042-018-5686-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900065
DA 2024-07-18
ER

PT J
AU Yi, Y
   Cheng, Y
   Xu, CP
AF Yi, Yang
   Cheng, Yang
   Xu, Chuping
TI Visual tracking based on hierarchical framework and sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual Target Tracking; Hierarchical Framework; Sparse Representation;
   Dictionary learning; Template Update
ID DATA ASSOCIATION; OBJECT TRACKING; MODEL
AB As the main challenge for object tracking is to account for drastic appearance change, a hierarchical framework that exploits the strength of both generative and discriminative models is devised in this paper. Our hierarchical framework consists of three appearance models: local-histogram-based model, weighted alignment pooling model, and sparsity-based discriminative model. Sparse representation is adopted in local-histogram-based model layer that considers the spatial information among local patches with a dual-threshold update schema to deal with occlusion. The weighted alignment pooling layer is introduced to weight the local image patches of the candidates after sparse representation. Different from the above two generative methods, the global discriminant model layer employs candidates to sparsely represent positive and negative templates. After that, an effective hierarchical fusion strategy is developed to fuse the three models via their similarities and the confidence. In addition, three reasonable online dictionary and template update strategies are proposed. Finally, experiments on various current popular image sequences demonstrate that our proposed tracker performs favorably against several state-of-the-art algorithms.
C1 [Yi, Yang; Cheng, Yang; Xu, Chuping] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Yi, Yang] Sun Yat Sen Univ, Xinhua Coll, Guangzhou 510520, Guangdong, Peoples R China.
   [Yi, Yang] Guangdong Prov Key Lab Big Data Anal & Proc, Guangzhou, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Cheng, Y (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM chengyu35@mail2.sysu.edu.cn
RI Yi, Yang/AFP-5892-2022
FU National Natural Science Foundation of China [61672546, 61573385];
   Guangzhou Science and Technology Project [201707010127, 2014B010112001]
FX The authors would like to thank Fang Li M.Sc. for her insightful and
   inspirational comments which have greatly helped us to improve the
   technical contents and experiments of the study. And this work was
   partly supported by National Natural Science Foundation of China with
   NO: 61672546 and 61573385, Guangzhou Science and Technology Project with
   No. 201707010127 and No. 2014B010112001.
CR [Anonymous], 2017, DEEP REINFORCEMENT L
   [Anonymous], P CVPR
   [Anonymous], DEC CONTR CDC 2010 4
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Chang WY, 2009, IEEE T SYST MAN CY B, V39, P375, DOI 10.1109/TSMCB.2008.2005417
   Chen DP, 2014, LECT NOTES COMPUT SC, V8689, P345, DOI 10.1007/978-3-319-10590-1_23
   Chi ZZ, 2017, IEEE T IMAGE PROCESS, V26, P2005, DOI 10.1109/TIP.2017.2669880
   Cuevas E., 2005, MEASUREMENT, P1
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dinh T.B., 2011, P IEEE WORKSH APPL C, P642, DOI DOI 10.1109/WACV.2011.5711565
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Han S, 2013, IEEE IMAGE PROC, P151, DOI 10.1109/ICIP.2013.6738032
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hu WM, 2015, IEEE T PATTERN ANAL, V37, P816, DOI 10.1109/TPAMI.2014.2353628
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Huchuan Lu, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P539, DOI 10.1109/FG.2011.5771455
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kolsch M., 2004, Computer Vision and Pattern Recognition Workshop, P158
   Kristan M, 2009, PATTERN RECOGN, V42, P2160, DOI 10.1016/j.patcog.2009.01.002
   Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502
   Li M, 2010, PROC CVPR IEEE, P1315, DOI 10.1109/CVPR.2010.5539815
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Ma AJ, 2013, IEEE T PATTERN ANAL, V35, P1135, DOI 10.1109/TPAMI.2012.198
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nejhum SMS, 2010, COMPUT VIS IMAGE UND, V114, P901, DOI 10.1016/j.cviu.2010.04.002
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Son J, 2015, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2015.350
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Wang D, 2015, IEEE T CYBERNETICS, V45, P1838, DOI 10.1109/TCYB.2014.2360924
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang D, 2014, IEEE SIGNAL PROC LET, V21, P1031, DOI 10.1109/LSP.2014.2322389
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang LF, 2014, IEEE T CIRC SYST VID, V24, P1132, DOI 10.1109/TCSVT.2014.2302496
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wang XM, 2015, IEEE I CONF COMP VIS, P4337, DOI 10.1109/ICCV.2015.493
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Xie CJ, 2014, J VIS COMMUN IMAGE R, V25, P423, DOI 10.1016/j.jvcir.2013.12.012
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Xiong JP, 2016, MULTIMED TOOLS APPL, V75, P17531, DOI 10.1007/s11042-016-3464-5
   Yang F, 2014, IEEE T CIRC SYST VID, V24, P242, DOI 10.1109/TCSVT.2013.2276145
   Yi Y, 2016, J VIS COMMUN IMAGE R, V34, P37, DOI 10.1016/j.jvcir.2015.10.010
   Yi Y, 2014, IEEE SIGNAL PROC LET, V21, P288, DOI 10.1109/LSP.2014.2300497
   Zhang HL, 2015, MULTIMED TOOLS APPL, V74, P1021, DOI 10.1007/s11042-013-1709-0
   Zhang SP, 2017, IEEE T NEUR NET LEAR, V28, P2357, DOI 10.1109/TNNLS.2016.2586194
   Zhang SP, 2017, IEEE T CIRC SYST VID, V27, P421, DOI 10.1109/TCSVT.2016.2539860
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang SP, 2013, NEUROCOMPUTING, V100, P31, DOI 10.1016/j.neucom.2011.11.031
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhu G, 2016, IEEE COMPUT SOC CONF, P1265, DOI 10.1109/CVPRW.2016.160
NR 60
TC 5
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16267
EP 16289
DI 10.1007/s11042-017-5198-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300013
DA 2024-07-18
ER

PT J
AU Zhang, P
   Zhuo, T
   Huang, HQ
   Chen, KL
   Zhang, B
   Kankanhalli, M
AF Zhang, Peng
   Zhuo, Tao
   Huang, Hanqiao
   Chen, Kangli
   Zhang, Bo
   Kankanhalli, Mohan
TI Robust tracking based on H-CNN with low-resource sampling and scaling by
   frame-wise motion localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online tracking; Hierarchical; CNN; Motion; Sampling
AB In big data age, learning with deep models has shown its outstanding effectiveness in a variety of vision tasks. Unfortunately, the requirement of enormous training samples and computational cost still limit its practicability in the low resource media computing based applications such online object tracking. More recently, CNN based feature extraction has helped tracking-by-learning strategies make a significant progress, although the coarse resolution outputs from the last layer still substantially limit a further improvement of tracking performance. By exploiting the hierarchies of convolutional layers as an image pyramid representation, earlier convolutional layers of hierarchical CNN have shown a certain enhancement of spatial localization but are less invariant to target appearance changes, which inevitably led to an inaccurate region for sampling when the non-rigid objects have intrinsic motion. To guarantee a qualified sampling for tracking-by-learning with hierarchical CNN, in this paper, we incorporated an inter-frame motion guidance with the intra-frame appearance correlations by formulating different energy optimization process in both spatial and temporal domains. With an optional functionality for the extracted regions combination, the proposed algorithm is able to achieve more precise target localization for qualified sampling. Experiments on challenging non-rigid tracking benchmark dataset have demonstrated a superior performance of the proposed tracking in comparison to the other state-of-art trackers.
C1 [Zhang, Peng; Chen, Kangli; Zhang, Bo] Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
   [Zhuo, Tao; Kankanhalli, Mohan] Natl Univ Singapore, Sensor Enhanced Social Media SeSaMe Ctr, Singapore, Singapore.
   [Huang, Hanqiao] Air Force Engn Univ, Sch Aeronaut & Astronaut Engn, Xian, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; National University of Singapore;
   Air Force Engineering University
RP Zhang, P (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.; Zhuo, T (corresponding author), Natl Univ Singapore, Sensor Enhanced Social Media SeSaMe Ctr, Singapore, Singapore.
EM zh0036ng@nwpu.edu.cn; zhuotao@nus.edu.sg; cnxahhq@gmail.com;
   chenkangli@mail.nwpu.edu.cn; 6672zhang2677@mail.nwpu.edu.cn;
   mohan@comp.nus.edu.sg
RI Zhang, Bo/AAG-2557-2020; zhang, yueqi/JXM-4287-2024; Kankanhalli,
   Mohan/Q-9284-2019; Zhang, Penghui/HGB-7353-2022
OI Zhang, Bo/0000-0001-5751-8255; Kankanhalli, Mohan/0000-0002-4846-2015;
   Zhang, Penghui/0000-0002-9518-7079
FU National Natural Science Foundation of China [61571362, 61601505];
   National Research Foundation, Prime Ministers Office, Singapore under
   its International Research Centre in Singapore Funding Initiative
FX This research is supported by National Natural Science Foundation of
   China 61571362 & 61601505, and the National Research Foundation, Prime
   Ministers Office, Singapore under its International Research Centre in
   Singapore Funding Initiative.
CR Babenko B, 2009, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2009.5459264
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Choi JW, 2015, MULTIMED TOOLS APPL, V74, P199, DOI 10.1007/s11042-013-1756-6
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dinh TB, 2011, IEEE INT C COMP VIS
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques J, 2012, LNCS, P702, DOI DOI 10.1007/978-3-642-33765-9_50
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kim BG, 2011, IEEE IC COMP COM NET
   Kwon J., 2010, IEEE INT C COMP VIS
   Li H., 2014, P BMVC
   Li HJ, 2014, APPL MECH MATER, V598, P194, DOI 10.4028/www.scientific.net/AMM.598.194
   Liu Ce, 2009, THESIS
   Liu TL, 2017, IEEE T PATTERN ANAL, V39, P227, DOI 10.1109/TPAMI.2016.2544314
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Oron S, 2012, IEEE INTERNATIONAL C
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sevilla-Lara L, 2012, IEEE INT C COMP VIS
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Son J, 2015, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2015.350
   Tian XH, 2011, IEEE ICC
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wang N, 2013, P ADV NEURAL INFORM
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu ZP, 2016, MULTIMED TOOLS APPL, V75, P9427, DOI 10.1007/s11042-016-3356-8
   Yu J, 2016, IEEE T INF FOREN SEC, DOI [10.1109/TIFS.2016.2636090, DOI 10.1109/TIFS.2016.2636090]
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
NR 36
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18781
EP 18800
DI 10.1007/s11042-017-4493-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900061
DA 2024-07-18
ER

PT J
AU Bracamonte, T
   Bustos, B
   Poblete, B
   Schreck, T
AF Bracamonte, Teresa
   Bustos, Benjamin
   Poblete, Barbara
   Schreck, Tobias
TI Extracting semantic knowledge from web context for multimedia IR: a
   taxonomy, survey and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic knowledge extraction; Multimedia retrieval; Web retrieval;
   Context data; Big data
ID IMAGE RETRIEVAL
AB Since its invention, the Web has evolved into the largest multimedia repository that has ever existed. This evolution is a direct result of the explosion of user-generated content, explained by the wide adoption of social network platforms. The vast amount of multimedia content requires effective management and retrieval techniques. Nevertheless, Web multimedia retrieval is a complex task because users commonly express their information needs in semantic terms, but expect multimedia content in return. This dissociation between semantics and content of multimedia is known as the semantic gap. To solve this, researchers are looking beyond content-based or text-based approaches, integrating novel data sources. New data sources can consist of any type of data extracted from the context of multimedia documents, defined as the data that is not part of the raw content of a multimedia file. The Web is an extraordinary source of context data, which can be found in explicit or implicit relation to multimedia objects, such as surrounding text, tags, hyperlinks, and even in relevance-feedback. Recent advances in Web multimedia retrieval have shown that context data has great potential to bridge the semantic gap. In this article, we present the first comprehensive survey of context-based approaches for multimedia information retrieval on the Web. We introduce a data-driven taxonomy, which we then use in our literature review of the most emblematic and important approaches that use context-based data. In addition, we identify important challenges and opportunities, which had not been previously addressed in this area.
C1 [Bracamonte, Teresa; Bustos, Benjamin; Poblete, Barbara] Univ Chile, Dept Comp Sci, Santiago, Chile.
   [Schreck, Tobias] Graz Univ Technol, Comp Graph & Knowledge Visualizat, Graz, Austria.
C3 Universidad de Chile; Graz University of Technology
RP Bracamonte, T (corresponding author), Univ Chile, Dept Comp Sci, Santiago, Chile.
EM tbracamo@dcc.uchile.cl; bebustos@dcc.uchile.cl; bpoblete@dcc.uchile.cl;
   tobias.schreck@cgv.tugraz.at
RI Poblete, Barbara/H-8450-2013; Bustos, Benjamin/G-1170-2010
OI Poblete, Barbara/0000-0002-7669-645X; Bustos,
   Benjamin/0000-0002-3955-361X
FU Millennium Nucleus Center for Semantic Web Research [NC120004]; Project
   Enlace-Fondecyt [ENL011/16]; Project Fondef [ID16-10222]; PhD
   Scholarship Program of Conicyt, Chile (CONICYT-PCHA/Doctorado Nacional)
   [2013-63130260]
FX This work was partially supported by the Millennium Nucleus Center for
   Semantic Web Research, Grant No. NC120004. In addition, B. Poblete was
   also partially supported by Project Enlace-Fondecyt ENL011/16 and
   Project Fondef ID16-10222. T. Bracamonte was also supported by PhD
   Scholarship Program of Conicyt, Chile (CONICYT-PCHA/Doctorado
   Nacional/2013-63130260).
CR [Anonymous], 2012, P 21 ACM INT C INF K
   [Anonymous], 2007, Multimedia retrieval
   [Anonymous], P ACM WORKSH LSMRM
   [Anonymous], 2013, MMSYS
   [Anonymous], 2005, P INT C MUS INF RETR
   [Anonymous], WWW 2012 P 21 INT C
   Bin Gao, 2005, 13th Annual ACM International Conference on Multimedia, P112
   Blei DM, 2003, MODELING ANNOTATED D
   Bota H, 2014, COMPOSITE RETRIEVAL
   Brin S, 2012, COMPUT NETW, V56, P3825, DOI 10.1016/j.comnet.2012.10.007
   Chen C, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508042
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen Y., 2010, P ACM INT C MULT, P221
   Choi Jaeyoung., 2014, Proceedings of the 3rd ACM Multimedia Workshop on Geotagging and Its Applications in Multimedia, P27
   Craswell Nick, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P239, DOI 10.1145/1277741.1277784
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Dupplaw DP, 2014, INT J MULTIMED INF R, V3, P97, DOI 10.1007/s13735-014-0051-2
   Egenhofer MJ, 1997, J VISUAL LANG COMPUT, V8, P403, DOI 10.1006/jvlc.1997.0054
   Eickhoff Carsten, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P38, DOI 10.1007/978-3-642-36973-5_4
   Feng W., 2012, KDD
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Ghias A., 1995, P 3 ACM INT C MULT, P231, DOI DOI 10.1145/217279.215273
   Gilbert A, 2015, CLEF ONL WORK NOT LA
   Gui CH, 2009, IEEE INT CON MULTI, P1476, DOI 10.1109/ICME.2009.5202782
   Hanjalic Alan., 2012, P 20 ACM INT C MULT, P1239
   Haslhofer B, 2014, MULTIMED TOOLS APPL, V70, P847, DOI 10.1007/s11042-012-1098-9
   Hauff C, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P691, DOI 10.1145/2348283.2348376
   He RH, 2006, LECT NOTES COMPUT SC, V4261, P527
   He XN, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P771, DOI 10.1145/2566486.2567975
   Heng Tao Shen, 2000, Proceedings ACM Multimedia 2000, P39, DOI 10.1145/354384.376098
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Ionescu B, 2014, MED 2014 WORKSH
   Ionescu B, 2016, MULTIMED TOOLS APPL, V75, P1301, DOI 10.1007/s11042-014-2369-4
   Jain V., 2011, International Conference on World Wide Web, P277, DOI DOI 10.1145/1963405.1963447
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P27, DOI 10.1145/2671188.2749399
   Kaminskas M., 2013, P 7 ACM C REC SYST N, P17
   Kannan A, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1534, DOI 10.1145/2623330.2623346
   Kherfi ML, 2004, ACM COMPUT SURV, V36, P35, DOI 10.1145/1013208.1013210
   Kim YA, 2013, KNOWL-BASED SYST, V37, P438, DOI 10.1016/j.knosys.2012.09.002
   Knees P, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542206
   Kofler C, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2954930
   La Cascia M, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P24, DOI 10.1109/IVL.1998.694480
   Leung CHC, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168761
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Li XR, 2012, IEEE T MULTIMEDIA, V14, P1091, DOI 10.1109/TMM.2012.2191943
   Liu XC, 2013, PROCEEDINGS OF THE 1ST INTERNATIONAL JOINT SYMPOSIUM ON JOINING AND WELDING, P151
   Low Yucheng., 2011, P 17 ACM SIGKDD INT, P123
   Mallik A, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542210
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Morrison D, 2013, MULTIMED TOOLS APPL, V66, P493, DOI 10.1007/s11042-012-1038-8
   Naaman M, 2012, MULTIMED TOOLS APPL, V56, P9, DOI 10.1007/s11042-010-0538-7
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Petkos G, 2014, MED 2014 WORKSH
   Poblete B., 2010, P 19 ACM INT C INF K, P1553
   Popescu A, 2015, P 2015 WORKSH COMM O, P7, DOI [10.1145/2814815.2814819, DOI 10.1145/2814815.2814819]
   Popescu A, 2011, P 1 ACM INT C MULT R
   Schedl M., 2013, 4 ACM MULT SYST C OS, P78
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Tan HK, 2011, P 1 INT C MULT RETR
   Tan S, 2011, P 19 ACM INT C MULT, P243
   Tsikrika T, 2011, MULTIMED TOOLS APPL, V55, P27, DOI 10.1007/s11042-010-0584-1
   Van Leuken Reinier H, 2009, P 18 INT C WORLD WID, P341, DOI 10.1145/1526709.1526756
   Villegas M, 2012, CLEF ONL WORK NOT LA
   Wang DY, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P443
   Wang JianGuo Wang JianGuo, 2011, Animal Husbandry and Feed Science, V3, P12
   Wang XJ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2231, DOI 10.1109/ICME.2004.1394714
   Westerveld T., 2000, P CONTENT BASED MULT, P276
   White RyenW., 2009, EXPLORATORY SEARCH Q, V1
   Xu S, 2011, P 20 ACM INT C INF K, P485
   Yang C. C., 2005, P SPL INT TRACKS 14, P906
   Yatskar Mark., 2014, P 3 JOINT C LEXICAL, P110
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
   Zheng C, 2001, J AM SOC INF SCI TEC, V52, P831, DOI 10.1002/asi.1132
NR 79
TC 6
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13853
EP 13889
DI 10.1007/s11042-017-4997-y
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900035
DA 2024-07-18
ER

PT J
AU Elsalamony, HA
AF Elsalamony, Hany A.
TI Detection of anaemia disease in human red blood cells using cell
   signature, neural networks and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptocytosis; Sickle cells; Burr cells; Cell signature; Circular Hough
   transforms; Watershed segmentation; SOM neural network; BP neural
   network; SVM
ID CLASSIFICATION; DIAGNOSIS
AB Anaemia disease attacks and deforms the circular red blood cells. Latterly, it has classified as a very dangerous disease. Many papers have been presented approaches for tracking and detection of anaemia cells before; but this time, elliptocytosis, sickle, and burr cells have detected based on their shape signatures. In tested images, some of the cells have been formed unknown shapes resulted from stuck operation in the instant image capture. This shape have not been belonged to any of anaemia kinds, then they have considered as cells with unknown shape. Here, the using of Circular Hough transforms, watershed segmentation and some of the morphological methods has been urgent manner to enhancing and preparing tested images. The performance of proposed algorithm have been achieved highly accuracy by testing 45 colourful microscopic images in 15 samples from patients already have anaemia disease. The Support Vector Machine (SVM), back propagation (BP) and self-organising map (SOM) neural networks have been applied on all information data of mentioned kinds of anaemia.
C1 [Elsalamony, Hany A.] Helwan Univ, Dept Math, Fac Sci, Cairo, Egypt.
   [Elsalamony, Hany A.] Prince Sattam Bin Abdulaziz Univ, Coll Arts & Sci, Dept Comp Sci, Al Kharj, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Helwan University; Prince Sattam Bin
   Abdulaziz University
RP Elsalamony, HA (corresponding author), Helwan Univ, Dept Math, Fac Sci, Cairo, Egypt.; Elsalamony, HA (corresponding author), Prince Sattam Bin Abdulaziz Univ, Coll Arts & Sci, Dept Comp Sci, Al Kharj, Saudi Arabia.
EM h_salamony@yahoo.com
RI Elsalamony, Hany A/Q-5165-2019
OI Elsalamony, Hany/0000-0001-6737-4929
CR Agroyannis B, 1997, ARTIF ORGANS, V21, P327
   AHERNE WA, 1957, J CLIN PATHOL, V10, P252, DOI 10.1136/jcp.10.3.252
   Ahmed M, 2015, BLOOD, V126, P4540
   Anoop P, 2009, EUR J HAEMATOL, V83, P606, DOI 10.1111/j.1600-0609.2009.01302.x
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chaudhuri BB, 2000, NEUROCOMPUTING, V34, P11, DOI 10.1016/S0925-2312(00)00305-2
   Craven MW, 1997, INT J NEURAL SYST, V8, P373, DOI 10.1142/S0129065797000380
   Da Costa L, 2013, BLOOD REV, V27, P167, DOI 10.1016/j.blre.2013.04.003
   Das DK, 2013, J MICROSC-OXFORD, V249, P136, DOI 10.1111/jmi.12002
   Deligiannidis L, 2014, EMERGING TRENDS IMAG, V1
   Elsalamony HA, 2014, P INT C IM PROC COMP, P1
   Elsalamony HA, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/8/085401
   Elsalamony HA, 2016, MICRON, V83, P32, DOI 10.1016/j.micron.2016.01.008
   Elsalamony HAM, 2015, IETE J RES, V61, P466, DOI 10.1080/03772063.2015.1023371
   FREEMAN WJ, 1991, SCI AM, V264, P78, DOI 10.1038/scientificamerican0291-78
   Hirimutugoda Y. M., 2010, Sri Lanka Journal of Bio-Medical Informatics, V1, P35, DOI [10.4038/sljbmi.v1i1.1484, DOI 10.4038/SLJBMI.V1I1.1484]
   ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1
   ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964
   Karahoca A, 2012, DATA MINING APPL ENG
   Kohonen T, 1995, HDB BRAIN THEORY NEU, P175, DOI [DOI 10.1007/978-3-642-97610-0_6, 10.1007/978-3-642-97610-0]
   Lam P, 2015, MEDICAL NEWS TODAY
   Lee H, 2014, PATTERN RECOGN LETT, V49, P155, DOI 10.1016/j.patrec.2014.06.010
   Minetti G, 2013, BLOOD REV, V27, P91, DOI 10.1016/j.blre.2013.02.002
   Mukherjee R, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/293690
   Mushabe MC, 2013, IEEE ENG MED BIO, P3698, DOI 10.1109/EMBC.2013.6610346
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Serebrennikova YM, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/382641
   Taherisadr M., 2013, SHIRAZ E MED J, V14
   Thirusittampalam K, 2013, IEEE J BIOMED HEALTH, V17, P642, DOI 10.1109/TITB.2012.2228663
   Tomari R, 2014, PROCEDIA COMPUT SCI, V42, P206, DOI 10.1016/j.procs.2014.11.053
   Urrechaga E, 2015, INT J LAB HEMATOL, V37, P334, DOI 10.1111/ijlh.12290
   Yi F, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.1.016005
NR 33
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15047
EP 15074
DI 10.1007/s11042-017-5088-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200027
DA 2024-07-18
ER

PT J
AU Li, DY
   Wen, GH
AF Li, Danyang
   Wen, Guihua
TI MRMR-based ensemble pruning for facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Multiple classifier systems;
   Convolutional neural networks; Classifier ensemble pruning; Maximum
   relevance minimum redundancy
ID NEURAL-NETWORKS; SELECTION; DIVERSITY
AB Facial expression recognition (FER) can assist the interaction between humans and devices. The combination of FER and ensemble learning can usually improve final recognition results. However, in many cases, the produced ensemble classifiers often contain many redundant members, and those components bring potential side effects to final results. Previous studies have illustrated that a more compact subset of a classifier pool shows better performance than original classifier pool. Furthermore, the compacted subset reduces storage space and decreases computation complexity. This paper proposes a maximum relevance and minimum redundancy-based ensemble pruning (MRMREP) method that treats prediction results as features, and extends the feature selection method to the ensemble classifier reduction problem to obtain a more representative subset. This novel method ordered all base classifiers according to two important factors: the correlation between target labels and predictions, and the redundancy between classifiers. The final ensemble performance was evaluated by comparing our method with other ensemble pruning methods, and superior results were obtained on the FER2013, JAFFE, and CK + databases.
C1 [Li, Danyang; Wen, Guihua] South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology
RP Wen, GH (corresponding author), South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Guangzhou, Guangdong, Peoples R China.
EM danyangedu@163.com; crghwen@scut.edu.cn
RI Li, Dan/HJA-0406-2022; li, danyang/HHS-3319-2022
FU China National Science Foundation [60973083, 61273363]; Science and
   Technology Planning Project of Guangdong Province [2014A010103009,
   2015A020217002]; Guangzhou Science and Technology Planning Project
   [201504291154480]
FX This study was supported by a China National Science Foundation under
   Grants (60973083, 61273363), Science and Technology Planning Project of
   Guangdong Province (2014A010103009, 2015A020217002), and Guangzhou
   Science and Technology Planning Project (201504291154480).
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Aizhong Mi, 2010, 2010 5th International Conference on Computer Science & Education (ICCSE 2010), P1001, DOI 10.1109/ICCSE.2010.5593398
   [Anonymous], 2013, WORKSH CHALL REPR LE
   [Anonymous], APPL SUPERVISED UNSU
   Cavalcanti GDC, 2016, PATTERN RECOGN LETT, V74, P38, DOI 10.1016/j.patrec.2016.01.029
   Chang K-H, 2016, 2016 INT JOINT C NEU
   Chen T, 2012, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT (IEEE IC-NIDC 2012), P420, DOI 10.1109/ICNIDC.2012.6418787
   Cheng J, 2015, BIOMED SIGNAL PROCES, V18, P118, DOI 10.1016/j.bspc.2014.12.006
   Cruz RMO, 2014, INT C PATT RECOG, P1230, DOI 10.1109/ICPR.2014.221
   Dai Q, 2016, APPL INTELL, V44, P816, DOI 10.1007/s10489-015-0729-z
   Dai Q, 2015, APPL SOFT COMPUT, V28, P237, DOI 10.1016/j.asoc.2014.10.045
   Dai Q, 2013, NEUROCOMPUTING, V122, P258, DOI 10.1016/j.neucom.2013.06.026
   Dai Q, 2013, APPL SOFT COMPUT, V13, P4292, DOI 10.1016/j.asoc.2013.06.023
   DASARATHY BV, 1979, P IEEE, V67, P708, DOI 10.1109/PROC.1979.11321
   de Souto MCP, 2008, IEEE IJCNN, P1480, DOI 10.1109/IJCNN.2008.4633992
   Diao R, 2014, IEEE T CYBERNETICS, V44, P1259, DOI 10.1109/TCYB.2013.2281820
   Giannakakis G, 2017, BIOMED SIGNAL PROCES, V31, P89, DOI 10.1016/j.bspc.2016.06.020
   Gong X, 2011, INT J COMPUT INT SYS, V4, P44
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo L, 2013, PATTERN RECOGN LETT, V34, P603, DOI 10.1016/j.patrec.2013.01.003
   Hady M. F. A., 2010, 2010 International Conference of Soft Computing and Pattern Recognition (SoCPaR 2010), P314, DOI 10.1109/SOCPAR.2010.5686645
   Hamester D, 2015, IEEE IJCNN
   Ijjina EP, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P392, DOI 10.1109/ICMLA.2014.70
   Jia XB, 2014, KSII T INTERNET INF, V8, P196, DOI 10.3837/tiis.2014.01.012
   Krawczyk B, 2015, NEUROCOMPUTING, V150, P490, DOI 10.1016/j.neucom.2014.07.068
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Kuncheva LI, 2013, IEEE T KNOWL DATA EN, V25, P494, DOI 10.1109/TKDE.2011.234
   Lin C, 2014, NEUROCOMPUTING, V123, P424, DOI 10.1016/j.neucom.2013.08.004
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Liu ZA, 2014, APPL INTELL, V41, P128, DOI 10.1007/s10489-013-0510-0
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lu Zhenyu, 2010, P 16 ACM SIGKDD INT, P871, DOI [10.1145/1835804.1835914, DOI 10.1145/1835804.1835914]
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Markatopoulou F, 2015, NEUROCOMPUTING, V150, P501, DOI 10.1016/j.neucom.2014.07.063
   Martínez-Muñoz G, 2004, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND APPLICATIONS, VOLS 1AND 2, P258
   Martinez-Munoz G., 2006, ICML 06, P609
   Martínez-Muñoz G, 2009, IEEE T PATTERN ANAL, V31, P245, DOI 10.1109/TPAMI.2008.78
   Michelle K, 2013, 2013 IEEE INT C SYST
   Moore S, 2007, LECT NOTES COMPUT SC, V4778, P71
   Nan Li, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P330, DOI 10.1007/978-3-642-33460-3_27
   Partalas I, 2009, NEUROCOMPUTING, V72, P1900, DOI 10.1016/j.neucom.2008.06.007
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Tamon C, 2000, LECT NOTES ARTIF INT, V1810, P404
   Wang SH, 2007, IEEE IJCNN, P355, DOI 10.1109/IJCNN.2007.4370982
   Wen GH, 2015, INT CONF AFFECT, P873, DOI 10.1109/ACII.2015.7344677
   Xiong L, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415500056
   Zavaschi THH, 2011, 2011 IEEE INT C AC S
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
NR 49
TC 18
Z9 18
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15251
EP 15272
DI 10.1007/s11042-017-5105-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200037
DA 2024-07-18
ER

PT J
AU Medjram, S
   Babahenini, MC
   Taleb-Ahmed, A
   Ben Ali, YM
AF Medjram, Sofiane
   Babahenini, Mohamed Chaouki
   Taleb-Ahmed, Abdelmalik
   Ben Ali, Yamina Mohamed
TI Automatic Hand Detection in Color Images based on skin region
   verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand detection; Skin region verification; Wrist Localization; Hand
   detection; Corner detection; Hand palm detection; Human-Computer
   Interaction
ID WRIST LOCALIZATION
AB Among the modern means of communications that appeared recently, there is the natural computer interaction using hands. Several methods have been proposed for their detection in the literature, and the common methods are based on skin color. The majority of these methods perform on images containing the hand region only or on images containing the hand and the forearm regions, but few of them have been interested to deal automatically for both situations.
   In this paper, we propose a new method of automatic hand detection in color images based on skin region verification. Using the 2D properties of hand components (fingertips, hand palm, wrist) we verify if the skin region treated contains the hand region with or without the presence of the forearm, and for each situation the hand is detected differently. Compared to other methods of literature, our method avoids several scenarios of misdetection and process in a consistent manner through the verification and detection stages. Using a database containing 899 color images of hand gestures, we evaluated the efficiency of our method and we compared it to other methods of literature, the results obtained were very satisfactory.
C1 [Medjram, Sofiane; Ben Ali, Yamina Mohamed] Univ Badji Mokhtar, Annaba, Algeria.
   [Babahenini, Mohamed Chaouki] Univ Mohamed Khider, Biskra, Algeria.
   [Taleb-Ahmed, Abdelmalik] Univ Valenciennes, Famars, France.
C3 Universite Badji Mokhtar - Annaba; Universite Mohamed Khider Biskra;
   Universite Polytechnique Hauts-de-France
RP Medjram, S (corresponding author), Univ Badji Mokhtar, Annaba, Algeria.
EM medjram.sofiane@gmail.com; babahenini@yahoo.com;
   Abdelmalik.Taleb-Ahmed@univ-valenciennes.fr; benaliyam2@yahoo.fr
RI BABAHENINI, Mohamed Chaouki/F-1427-2017; Ali, Yamina Mohamed
   Ben/O-3612-2016
OI BABAHENINI, Mohamed Chaouki/0000-0001-7972-8026; Ali, Yamina Mohamed
   Ben/0000-0002-5001-4799
CR [Anonymous], SIGN PROC C
   [Anonymous], NETW AUTOM P
   [Anonymous], INT J TECHNOL
   [Anonymous], INT C ADV ROB
   [Anonymous], INT C IM PATT REC IC
   [Anonymous], 2014, INT J ENG SCI INNOVA
   [Anonymous], HANDAWI PUBL CORP SC
   [Anonymous], MAN MACH INTERACT
   [Anonymous], ROBUST HAND DETECTIO
   Boonbrahm Poonpong, 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P329, DOI 10.1007/978-3-319-07458-0_31
   Choi J., 2009, Proceedings of the 8th International Conference on Virtual Reality Continuum and Its Applications in Industry. VRCAI'09, P319
   Datcu D., 2013, Proceedings of the 1st symposium on Spatial user interaction, P33, DOI DOI 10.1145/2491367.2491370
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Gang-Zeng Mao, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P905, DOI 10.1109/IIH-MSP.2009.133
   González-Ortega D, 2006, LECT NOTES COMPUT SC, V3736, P35
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   Grzejszczak T, 2013, ADV INTELL SYST, V226, P439, DOI 10.1007/978-3-319-00969-8_43
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kawulok M, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553733
   Kerdvibulvech C, 2014, EURASIP J EMBED SYST, DOI 10.1186/s13639-014-0018-7
   Khanal B, 2011, LECT NOTES ARTIF INT, V7102, P609, DOI 10.1007/978-3-642-25489-5_59
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Medjram S, 2017, MULTIMED TOOLS APPL, V76, P15297, DOI 10.1007/s11042-016-3820-5
   Medjram S, 2016, LECT NOTE NETW SYST, P153, DOI 10.1007/978-3-319-33410-3_11
   Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75
   Narducci F, 2016, MULTIMED TOOLS APPL, V75, P9549, DOI 10.1007/s11042-016-3276-7
   Nguyen T., 2008, IEEE International Conference on Automatic Face and Gesture Recognition, P1, DOI DOI 10.1109/AFGR.2008.4813315
   Paulson B, 2011, INT J HUM-COMPUT ST, V69, P19, DOI 10.1016/j.ijhcs.2010.09.003
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Shipeng Xie, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P553, DOI 10.1109/ICIG.2011.166
   Song Z, 2010, LECT NOTES COMPUT SC, V6454, P628, DOI 10.1007/978-3-642-17274-8_61
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Vidya K, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P705, DOI 10.1109/IndiaCom.2014.6828052
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Xiao B, 2010, LECT NOTES ARTIF INT, V6441, P282, DOI 10.1007/978-3-642-17313-4_28
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
NR 39
TC 7
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13821
EP 13851
DI 10.1007/s11042-017-4995-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900034
DA 2024-07-18
ER

PT J
AU Narasimhan, MG
   Kamath, SS
AF Narasimhan, Medhini G.
   Kamath, Sowmya S.
TI Dynamic video anomaly detection and localization using sparse denoising
   autoencoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Deep learning; Sparse autoencoders; Crowded scene
   parsing; Real-time systems; Unsupervised learning
ID EVENT DETECTION
AB The emergence of novel techniques for automatic anomaly detection in surveillance videos has significantly reduced the burden of manual processing of large, continuous video streams. However, existing anomaly detection systems suffer from a high false-positive rate and also, are not real-time, which makes them practically redundant. Furthermore, their predefined feature selection techniques limit their application to specific cases. To overcome these shortcomings, a dynamic anomaly detection and localization system is proposed, which uses deep learning to automatically learn relevant features. In this technique, each video is represented as a group of cubic patches for identifying local and global anomalies. A unique sparse denoising autoencoder architecture is used, that significantly reduced the computation time and the number of false positives in frame-level anomaly detection by more than 2.5%. Experimental analysis on two benchmark data sets - UMN dataset and UCSD Pedestrian dataset, show that our algorithm outperforms the state-of-the-art models in terms of false positive rate, while also showing a significant reduction in computation time.
C1 [Narasimhan, Medhini G.; Kamath, Sowmya S.] Natl Inst Technol Karnataka, Dept Informat Technol, Surathkal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Narasimhan, MG (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Surathkal, India.
EM medhini95@gmail.com; sowmyakamath@nitk.edu.in
RI S, Sowmya Kamath/U-9379-2019
OI S, Sowmya Kamath/0000-0002-0888-7238; Narasimhan,
   Medhini/0000-0002-6288-5022
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Aljawarneh SA, 2017, FUTURE GENERATION CO
   [Anonymous], 2017, J COMPUTATIONAL SCI
   Antic B, 2011, IEEE I CONF COMP VIS, P2415, DOI 10.1109/ICCV.2011.6126525
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Cheng KW, 2015, IEEE C COMP VIS PATT
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Joseph E, 2013, ARXIV13044786
   Kong D, 2005, COUNTING PEDESTRIANS
   Li C, 2013, NEUROCOMPUTING, V119, P94, DOI 10.1016/j.neucom.2012.03.040
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li NN, 2015, NEUROCOMPUTING, V155, P309, DOI 10.1016/j.neucom.2014.12.064
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Ng A., 2011, CS294A LECT NOTES
   Radhakrishna V, 2017, FUTURE GENERATION CO
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu S, 2010, CHAOTIC INVARIANTS O
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu D, 2014, NEUROCOMPUTING, V143, P144, DOI 10.1016/j.neucom.2014.06.011
   Zhang Y, 2016, PATTERN RECOGN, V59, P302, DOI 10.1016/j.patcog.2015.11.018
NR 33
TC 30
Z9 35
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13173
EP 13195
DI 10.1007/s11042-017-4940-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900006
DA 2024-07-18
ER

PT J
AU Shin, DW
   Ho, YS
AF Shin, Dong-Won
   Ho, Yo-Sung
TI 3D Scene Reconstruction Using Colorimetric and Geometric Constraints on
   Iterative Closest Point Method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D camera; 3D reconstruction; SLAM; augmented reality; iterative
   closest point method
ID REGISTRATION
AB Advent of the 3D scene reconstruction framework using the RGB-D camera has enabled users to easily construct their indoor environment in a virtual space and has allowed them to experience an immersive augmented reality with the reconstructed 3D scene. Technically, the early stage of the 3D scene reconstruction framework using the RGB-D camera is based on the frame-to-model registration. It tries to iteratively estimate the transformation parameters of the camera between the incoming depth frame and its previously reconstructed 3D model. However, due to the nature of the frame-to-model registration, the conventional framework has an inherent drift problem caused by the accumulated alignment error. In this paper, we propose a new 3D scene reconstruction framework with the improved camera tracking capability to reduce the drift problem. There are two types of constraints in this work: colorimetric and geometric constraints. For the colorimetric constraint, we impose the more weights on the reliable feature correspondences obtained from color image frames. For the geometric constraint, we compute the consistent surface normal vector for the noisy point cloud data. Experimental results show that the proposed framework reduces the absolute trajectory error representing the amount of the drift and shows a more consistent trajectory in comparison to the conventional framework.
C1 [Shin, Dong-Won; Ho, Yo-Sung] GIST, Sch Elect Engn & Comp Sci, 123 Cheomdangwagi Ro, Gwangju 61005, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Ho, YS (corresponding author), GIST, Sch Elect Engn & Comp Sci, 123 Cheomdangwagi Ro, Gwangju 61005, South Korea.
EM dongwonshin@gist.ac.kr; hoyo@gist.ac.kr
FU National Research Foundation of Korea (NRF) - Korean Government (MSIP)
   [2011-0030079]
FX This work was supported by the National Research Foundation of Korea
   (NRF) Grant funded by the Korean Government (MSIP) (No. 2011-0030079)
CR [Anonymous], 2001, P IMR 2001 NEWP BEAC
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Berger M., 2014, Eurographics 2014-State of the Art Reports, V1, P161, DOI [DOI 10.2312/EGST.20141040, 10.2312/egst.20141040]
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Endres F, 2012, INT C ROB AUT MAY
   Fioraio N, 2015, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2015.7299077
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Godin G., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2350, P279, DOI 10.1117/12.189139
   Graham M, 2013, T I BRIT GEOGR, V38, P464, DOI 10.1111/j.1475-5661.2012.00539.x
   Gressin A, 2013, ISPRS J PHOTOGRAMM, V79, P240, DOI 10.1016/j.isprsjprs.2013.02.019
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Holzer S, 2012, IEEE INT C INT ROBOT, P2684, DOI 10.1109/IROS.2012.6385999
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Low KL, 2004, CHAPEL HILL, V4
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Nardi L, 2015, IEEE INT CONF ROBOT, P5783, DOI 10.1109/ICRA.2015.7140009
   Newcombe RA, 2011, ISMAR 11 P 2011 10 I
   Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Weber Christopher, 2010, Proceedings of the Shape Modeling International (SMI 2010), P175, DOI 10.1109/SMI.2010.32
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008
   [吴金波 Wu Jinbo], 2007, [现代制造工程, Modern Manufacturing Engineering], P1
NR 28
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14381
EP 14406
DI 10.1007/s11042-017-5034-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900057
DA 2024-07-18
ER

PT J
AU Wang, Z
   Piccardi, M
AF Wang, Zhen
   Piccardi, Massimo
TI Minimum-risk temporal alignment of videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sequence alignment; Action video alignment; Dynamic time warping;
   Extended hidden Markov model; Structural SVM
AB Temporal alignment of videos is an important requirement of tasks such as video comparison, analysis and classification. Most of the approaches proposed to date for video alignment leverage dynamic programming algorithms whose parameters are manually tuned. Conversely, this paper proposes a model that can learn its parameters automatically by minimizing a meaningful loss function over a given training set of videos and alignments. For learning, we exploit the effective framework of structural SVM and we extend it with an original scoring function that suitably scores the alignment of two given videos, and a loss function that quantifies the accuracy of a predicted alignment. The experimental results from four video action datasets show that the proposed model has been able to outperform a baseline and a state-of-the-art algorithm by a large margin in terms of alignment accuracy.
C1 [Wang, Zhen] Univ Technol Sydney, Broadway, NSW, Australia.
   [Piccardi, Massimo] Univ Technol Sydney, Comp Syst, Broadway, NSW, Australia.
C3 University of Technology Sydney; University of Technology Sydney
RP Wang, Z (corresponding author), Univ Technol Sydney, Broadway, NSW, Australia.
EM wangzhen263@gmail.com; massimo.piccardi@uts.edu.au
RI Piccardi, Massimo/AAY-1323-2020; Wang, Zhen/HOC-8395-2023
OI Piccardi, Massimo/0000-0001-9250-6604; 
CR Anderson T.W, 1984, An Introduction to Multivariate Statistical Analysis
   [Anonymous], 1998, Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids
   Bengio Y., 1995, Advances in Neural Information Processing Systems 7, P427
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   Caiani E, 1998, WARPED AVERAGE TEMPL
   Gong D, 2011, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2011.6126290
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Gritai A, 2004, INT C PATT RECOG, P923, DOI 10.1109/ICPR.2004.1334410
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Joachims Thorsten., 2005, New Algorithms for Macromolecular Simulation, V49, P57
   Keogh E. J., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P239
   Keogh E.J., 2001, P 2001 SIAM INT C DA, P1, DOI [DOI 10.1137/1.9781611972719.1, 10.1137/1.9781611972719.1]
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   MYERS C, 1980, IEEE T ACOUST SPEECH, V28, P623, DOI 10.1109/TASSP.1980.1163491
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Ryan MS, 1993, TECHNICAL REPORT
   Sakoe Hiroaki., 1990, chapter Dynamic programming algorithm optimization for spoken word recognition, P159, DOI DOI 10.1016/B978-0-08-051584-7.50016-4
   Skutkova H, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-S10-S1
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang Z, 2016, IEEE INT CON MULTI
   Zhou F, 2016, IEEE T PATTERN ANAL, V38, P279, DOI 10.1109/TPAMI.2015.2414429
NR 27
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14891
EP 14906
DI 10.1007/s11042-017-5073-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200020
DA 2024-07-18
ER

PT J
AU Bamal, R
   Kasana, SS
AF Bamal, Roopam
   Kasana, Singara Singh
TI Slantlet based hybrid watermarking technique for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Slantlet; RS vector; SIM; PSNR; BPP; IER
ID ROBUST REVERSIBLE WATERMARKING; COMPRESSION; EXPANSION
AB Watermarking techniques are widely used for copyright protection, confidentiality and integrity issues in medical field. Reversibility, robustness, embedding capacity and invisibility are the essential requirements of a watermarking technique. Cogitating the need of security for medical images, this paper proposes a reversible high embedding capacity, high image fidelity, a hybrid robust lossless data hiding technique by using both transform and spatial domains. Proposed technique alters the mean of the selected non-overlapping slantlet transformed blocks of the host image whereas RS vector considers flipping factor for data embedding. The optimum thresholds to select the blocks are calculated through PSO technique and watermark is generated by using patient details, biometric id and region of interest (ROI) blocks of host image. This watermark is further compressed by applying LZW technique and encrypted by AES as well as MD5. The watermark bits are embedded in all three RGB channels of a cover image, to increase the embedding capacity up to 3.3675 bpp. The credibility of the proposed technique in comparison with other medical watermarking techniques is evidenced through experimental results.
C1 [Bamal, Roopam; Kasana, Singara Singh] Thapar Univ, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bamal, R (corresponding author), Thapar Univ, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM roopambamal@gmail.com; singara@thapar.edu
OI Bamal, Roopam/0000-0002-6321-8133
CR Abou-Loukh S.J., 2011, NAHRAIN U COLL ENG J, V14, P34
   Abou-Loukh S.J., 2010, J ENG, V16, P4510
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alwan Iman M., 2011, IRAQI J SCI, V52, P225
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Anand D, 1998, P ANN INT IEEE EMBS, V20, P703, DOI 10.1109/IEMBS.1998.745518
   [Anonymous], 2011, ARXIV11011603
   [Anonymous], INT C SCI EL TECHN I
   [Anonymous], 1999, DIGITAL WATERMARKING
   Balasamy K, 2016, INT J INNOV RES COMP, V4, P189
   Coatrieux G, 2000, ENG MED BIOL SOC ANN, P250, DOI 10.1109/ITAB.2000.892396
   Coatrieux G, 2008, STUD HEALTH TECHNOL, V136, P667
   Dong JT, 2015, ACSR ADV COMPUT, V20, P140
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khor HL, 2016, J BIOMED IMAG, V2016, P4
   Kishore PVV, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P270, DOI 10.1109/SPACES.2015.7058263
   Manasrah Tuqa, 2008, IIT 2008 International Conference on Innovations in Information Technology, P697, DOI 10.1109/INNOVATIONS.2008.4781697
   Milanova M, 2003, METMBS'03: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MATHEMATICS AND ENGINEERING TECHNIQUES IN MEDICINE AND BIOLOGICAL SCIENCES, P509
   Mohammed R. T., 2012, 2012 IEEE Symposium on Industrial Electronics and Applications (ISIEA 2012), P281, DOI 10.1109/ISIEA.2012.6496644
   Mohananthini N., 2015, INT J NETWORK SECURI, V17, P558
   Mulcahy C., 1997, SPELMAN SCI MATH J, V1, P22
   Mutt SK, 2009, P INT C METH MOD COM, P1
   Panda G, 2002, IEEE T POWER DELIVER, V17, P662, DOI 10.1109/61.997957
   Priya RL, 2015, Sci World J, V2015
   Rivest R., 1992, MD5 MESSAGE DIGEST A
   Selesnick IW, 1998, PROCEEDINGS OF THE IEEE-SP INTERNATIONAL SYMPOSIUM ON TIME-FREQUENCY AND TIME-SCALE ANALYSIS, P53, DOI 10.1109/TFSA.1998.721359
   Selesnick IW, 1999, IEEE T SIGNAL PROCES, V47, P1304, DOI 10.1109/78.757218
   Shaji V., 2015, INT J ENG RES GEN SC, V3, P580
   Sharma A., 2015, Proceedings of the 3rd Workshop on EVENTS at the NAACL-HLT, P82
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Shih FY, 2005, INFORM SCIENCES, V175, P200, DOI 10.1016/j.ins.2005.01.013
   Thabit R, 2014, J SYST SOFTWARE, V88, P74, DOI 10.1016/j.jss.2013.09.033
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Umamageswari A, 2015, IND J ELECT ENG COMP, V15, P544
   Wakatani A., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P2043, DOI 10.1109/HICSS.2002.994129
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   Xuan GR, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1521
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Xuan GR, 2009, LECT NOTES COMPUT SC, V5510, P84
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
   Zou DK, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P195
NR 45
TC 11
Z9 11
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12493
EP 12518
DI 10.1007/s11042-017-4898-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100037
DA 2024-07-18
ER

PT J
AU Patvardhan, C
   Kumar, P
   Lakshmi, CV
AF Patvardhan, C.
   Kumar, Pragyesh
   Lakshmi, C. Vasantha
TI Effective Color image watermarking scheme using YCbCr color space and QR
   code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; YCbCr color model; QR code; Wavelet
   transform; Color image
ID PRINT-SCAN; UNIFORM; VIDEO
AB A digital image watermarking technique is proposed to hide the relevant information in color digital images. The image is converted from RGB color space to YCbCr color space. This enables the algorithm to exploit characteristics of the Human Visual System (HVS) for embedding the watermark. The scheme embeds the watermark information utilizing wavelets transforms and Singular Value Decomposition (SVD) for this purpose. It uses a Quick Response (QR) code as the watermark. The QR code is a robust code from which embedded information can be extracted even if the retrieved QR code image is distorted. Thus the proposed technique employs a judicious combination of different algorithmic ideas including altered YCbCr color space, transformation into wavelet domain, SVD for selection of places to embed and QR codes for enhanced robustness. The watermarking scheme proposed is robust against various signal processing attacks (e.g. filtering, compression, noise addition etc.) as well as geometric attacks (e.g. rotation, cropping etc.). Computational experiments on a variety of cover images show that embedding QR code is more effective than the other watermarks in terms of better information carrying capacity, robustness and imperceptibility. The proposed scheme is novel and effective as it simultaneously provides advantages of each of the individual elements combined in this approach.
C1 [Patvardhan, C.; Kumar, Pragyesh] Dayalbagh Educ Inst, Dept Elect Engn, Agra, Uttar Pradesh, India.
   [Lakshmi, C. Vasantha] Dayalbagh Educ Inst, Dept Phys & Comp Sci, Agra, Uttar Pradesh, India.
C3 Dayalbagh Educational Institute (DEI); Dayalbagh Educational Institute
   (DEI)
RP Kumar, P (corresponding author), Dayalbagh Educ Inst, Dept Elect Engn, Agra, Uttar Pradesh, India.
EM cpatvardhan@gmail.com; er.prag@gmail.com; cvasanthalakshmi@gmail.com
CR Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   An SF, 2009, MIDWEST SYMP CIRCUIT, P577, DOI 10.1109/MWSCAS.2009.5236026
   [Anonymous], 2008, 5 IEEE INT WORKSH SI
   Autrusseau F, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P485
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bhatnagar G, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P894, DOI 10.1109/IADCC.2009.4809134
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Gordy JD, 2000, PROCEEDINGS OF THE 43RD IEEE MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I-III, P456, DOI 10.1109/MWSCAS.2000.951682
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Haj AMA, 2010, ADV TECHNIQUES MULTI, P278
   He D, 2005, IEEE P INT C IM PROC
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Huang HC, 2011, IEEE T CONSUM ELECTR, V57, P779, DOI 10.1109/TCE.2011.5955222
   Jia SL, 2014, PRESS OPTIK INT J LI
   Jun Xiao, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P206, DOI 10.1109/PACIIA.2008.167
   Kang XG, 2010, IEEE T INF FOREN SEC, V5, P1, DOI 10.1109/TIFS.2009.2039604
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Li L, 2011, J SYST SOFTWARE, V84, P923, DOI 10.1016/j.jss.2011.01.025
   Liu KC, 2007, INT J COMPUT SCI NET, V7, P239
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Pramila A, 2008, LECT NOTES COMPUT SC, V5041, P279
   Rahimi F, 2011, DUAL ADAPTIVE WATERM, P1
   Ravel MS, 2003, C CONVERGENT TECHNOL, V3, P935
   Reddy AA, 2005, PATTERN RECOGN LETT, V26, P1019, DOI 10.1016/j.patrec.2004.09.047
   SERDEAN CV, 2002, P IEEE INT WORKSH TR, P70
   Singh AK, 2012, SPRINGER NAT ACAD SC, V37, P351
   Solanki K, 2004, IEEE IMAGE PROC, P39
   Song HH, 2008, SIGNAL PROCESS-IMAGE, V23, P162, DOI 10.1016/j.image.2008.01.005
   Tataru RL, 2012, INT CONF INTERNET, P46
   Teng D, 2010, IEEE INT C INF THEOR
   Vahedi E, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P635
   Verma A. K., 2015, International Journal of Image, Graphics and Signal Processing, V7, P48, DOI 10.5815/ijigsp.2015.02.07
   Verma AK, 2012, INT C IM PROC, P187
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Zhou B., 2004, CHINESE J IMAGE GRAP, V9, P506
NR 41
TC 39
Z9 39
U1 1
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12655
EP 12677
DI 10.1007/s11042-017-4909-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100045
DA 2024-07-18
ER

PT J
AU Wang, CY
   Xu, ZF
   Wang, ST
   Zhang, HB
AF Wang, Chunyang
   Xu, Zhifang
   Wang, Shuangting
   Zhang, Hebing
TI Semi-supervised classification framework of hyperspectral images based
   on the fusion evidence entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Image classification; D-S evidence theory; Support
   vector machine; Semi-supervised learning; Probability output of the
   multi-class support vector machine; Evidence entropy
AB Increasing attention is being paid to the classification of ground objects using hyperspectral spectrometer images. A key challenge of most hyperspectral classifications is the cost of training samples. It is difficult to acquire enough effective marked label sets using classification model frameworks. In this paper, a semi-supervised classification framework of hyperspectral images is proposed to better solve problems associated with hyperspectral image classification. The proposed method is based on an iteration process, making full use of the small amount of labeled data in a sample set. In addition, a new unlabeled data trainer in the self-training semi-supervised learning framework is explored and implemented by estimating the fusion evidence entropy of unlabeled samples using the minimum trust evaluation and maximum uncertainty. Finally, we employ different machine learning classification methods to compare the classification performance of different hyperspectral images. The experimental results indicate that the proposed approach outperforms traditional state-of-the-art methods in terms of low classification errors and better classification charts using few labeled samples.
C1 [Wang, Chunyang] Henan Polytech Univ, Natl Adm Surveying Mapping & Geoinformat, Key Lab Mine Spatial Informat Technol, Jiaozuo 454003, Peoples R China.
   [Wang, Chunyang; Xu, Zhifang; Wang, Shuangting; Zhang, Hebing] Henan Polytech Univ, Sch Surveying & Land Informat Engn, Jiaozuo 454003, Peoples R China.
C3 Henan Polytechnic University; Henan Polytechnic University
RP Wang, CY (corresponding author), Henan Polytech Univ, Natl Adm Surveying Mapping & Geoinformat, Key Lab Mine Spatial Informat Technol, Jiaozuo 454003, Peoples R China.; Wang, CY (corresponding author), Henan Polytech Univ, Sch Surveying & Land Informat Engn, Jiaozuo 454003, Peoples R China.
EM wcy@hpu.edu.cn; xuzf2016@163.com; wst@hpu.edu.cn; jzitzhb@hpu.edu.cn
FU Chinese Ministry of Land and Resources Nonprofit Sector Research and
   Special Project Fund [2014110220202]; Open Program of Collaborative
   Innovation Center of Geo-Information Technology for Smart Central Plains
   Henan Province [2016A002]; Henan Polytechnic University Doctoral Fund
   [B2016-13]; Open Fund of the Key Laboratory of Mine Spatial Information
   Technologies of the National Administration of Surveying, Mapping, and
   Geoinformation [KLM201407]; NSFC of China [41401403]
FX This research was jointly supported by the Chinese Ministry of Land and
   Resources Nonprofit Sector Research and Special Project Fund
   (2014110220202), The Open Program of Collaborative Innovation Center of
   Geo-Information Technology for Smart Central Plains Henan Province
   (2016A002), Henan Polytechnic University Doctoral Fund (B2016-13), Open
   Fund of the Key Laboratory of Mine Spatial Information Technologies of
   the National Administration of Surveying, Mapping, and Geoinformation
   (KLM201407) and NSFC of China under Grant (41401403).
CR Alajlan N, 2012, INFORM SCIENCES, V217, P39, DOI 10.1016/j.ins.2012.06.031
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalponte M, 2014, REMOTE SENS ENVIRON, V140, P306, DOI 10.1016/j.rse.2013.09.006
   Du P, 2011, CHIN OPT LETT, V9
   Fitzpatrick-Lins K, 1980, J RES US GEOL SURV, V6, P169
   Goetz AFH, 2009, REMOTE SENS ENVIRON, V113, pS5, DOI 10.1016/j.rse.2007.12.014
   Hosseinzadeh H, 2015, WIRELESS PERS COMMUN, V82, P1303, DOI 10.1007/s11277-015-2284-7
   Ifarraguerri A, 2000, IEEE T GEOSCI REMOTE, V38, P2529, DOI 10.1109/36.885200
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Li B, 2013, OCEAN ENG, V74, P16, DOI 10.1016/j.oceaneng.2013.09.016
   Li J, 2013, IEEE GEOSCI REMOTE S, V10, P318, DOI 10.1109/LGRS.2012.2205216
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu HM, 2012, DISASTER ADV, V5, P580
   Lu HM, 2012, COMPUT MATH APPL, V64, P996, DOI 10.1016/j.camwa.2012.03.017
   MA ZK, 1995, PHOTOGRAMM ENG REM S, V61, P435
   Platt JC, 2000, ADV NEUR IN, P61
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Santos A, 2014, EXPERT SYST APPL, V41, P6075, DOI 10.1016/j.eswa.2014.03.052
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Shao ZF, 2014, IEEE GEOSCI REMOTE S, V11, P1609, DOI 10.1109/LGRS.2014.2302034
   Si L, 2014, MEASUREMENT, V54, P140, DOI 10.1016/j.measurement.2014.04.015
   Tan K, 2014, ISPRS J PHOTOGRAMM, V97, P36, DOI 10.1016/j.isprsjprs.2014.08.003
   Tong QX, 2014, IEEE J-STARS, V7, P70, DOI 10.1109/JSTARS.2013.2267204
   Wang C, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073696
   [王俊淑 Wang Junshu], 2015, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V46, P239
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Wang Ying, 2012, Journal of Jilin University (Engineering and Technology Edition), V42, P1597
   [杨国鹏 Yang Guopeng], 2010, [测绘学报, Acta Geodetica et Cartographica Sinica], V39, P572
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang Z, 2016, IEEE J-STARS, V9, P640, DOI 10.1109/JSTARS.2015.2493887
NR 36
TC 11
Z9 11
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10615
EP 10633
DI 10.1007/s11042-017-4686-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900014
DA 2024-07-18
ER

PT J
AU Wu, CJ
   Huang, CW
   Chen, H
AF Wu, Chenjian
   Huang, Chengwei
   Chen, Hong
TI Expression recognition using semantic information and local texture
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Semantic inference; Landmark detection; Gaussian
   mixture model
ID ALGORITHMS; MIXTURE
AB In this paper, the cross-database facial expression recognition problem is studied. First, Gaussian Mixture Model is used to improve the facial landmark detection. Second, the local image features are used to model the facial actions. Deep Neural Network is used to represent the low level data variance. Third, the top level expression recognition rules are used in a Fuzzy Inference System to improve the cross-database performance by 11.6 percent in average. Experimental results show that the expression recognition rate is improved constantly over six emotion types compared with traditional Support Vector Machines and Neural Network classifiers . The averaged improvement against Support Vector Machines is 15.1 percent and the averaged improvement against neural network is 8.1 percent.
C1 [Wu, Chenjian] Soochow Univ, Sch Elect Informat, Suzhou 215006, Peoples R China.
   [Huang, Chengwei] Soochow Univ, Coll Phys Optoelect & Energy, Suzhou 215006, Peoples R China.
   [Chen, Hong] Soochow Univ, Sch Math Sci, Suzhou 215006, Peoples R China.
C3 Soochow University - China; Soochow University - China; Soochow
   University - China
RP Chen, H (corresponding author), Soochow Univ, Sch Math Sci, Suzhou 215006, Peoples R China.
EM cjwu@suda.edu.cn; huangcwx@vip.126.com; chenhong@suda.edu.cn
RI Huang, Chengwei/AER-6849-2022
OI Huang, Chengwei/0000-0001-9060-6361
FU National Natural Science Foundation of China [11401412]; Natural Science
   Foundation of Jiangsu Province of China [BK20150342]
FX This work was supported by the National Natural Science Foundation of
   China(No. 11401412) and Natural Science Foundation of Jiangsu Province
   of China(No. BK20150342)
CR [Anonymous], 2015 11 IEEE INT C W
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Feng ZH, 2015, IEEE T IMAGE PROCESS, V24, P3425, DOI 10.1109/TIP.2015.2446944
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang D, 2002, SIGNAL PROCESS-IMAGE, V17, P457, DOI 10.1016/S0923-5965(02)00020-6
   Hussain F., 2015, IEEE 2 WORLD S WEB A, P1, DOI DOI 10.1109/WSWAN.2015.7210294
   Hussain F, 2015, J SENSORS, V2015, P1
   Jun Ou, 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P215, DOI 10.1109/ICCMS.2010.45
   Lajevardi Seyed Mehdi, 2008, 2008 Digital Image Computing: Techniques and Applications, P71, DOI 10.1109/DICTA.2008.12
   Liu MY, 2016, IEEE T IMAGE PROCESS, V25, P5920, DOI 10.1109/TIP.2016.2615424
   Lyons MJ., 1998, The Japanese female facial expression (JAFFE) database
   Ma Y, 2016, LECT NOTES COMPUTER, V9517
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Martinez B, 2016, IMAGE VISION COMPUT, V47, P36, DOI 10.1016/j.imavis.2015.09.003
   SMITH DR, 1985, ARTIF INTELL, V27, P43, DOI 10.1016/0004-3702(85)90083-9
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Waters K., 1987, ACM SIGGRAPH Comput. Graph., V21, P17
   Weldon TP, 1996, PATTERN RECOGN, V29, P2005, DOI 10.1016/S0031-3203(96)00047-7
   Xuan GR, 2001, IEEE IMAGE PROC, P145, DOI 10.1109/ICIP.2001.958974
   Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
NR 24
TC 4
Z9 4
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11575
EP 11588
DI 10.1007/s11042-017-5158-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900064
DA 2024-07-18
ER

PT J
AU Rew, J
   Hwang, E
   Choi, YH
   Rho, S
AF Rew, Jehyeok
   Hwang, Eenjun
   Choi, Young-Hwan
   Rho, Seungmin
TI Monitoring skin condition using life activities on the SNS user
   documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin image ananlysis; Skin condition; Skin care; SNS; Life activity
   ananlysis
ID IMAGE-ANALYSIS; AGE
AB Social networks are not new to the IT landscape. Starting from bulletin boards and chat rooms, they have evolved to include desktop and mobile device applications such as Facebook, Twitter, and Flickr, which are used by millions of people daily. People can post diverse types of information such as what they are doing, what kind of foods they are eating, and where they are going. Some of these activities are known to have direct/indirect effect on the condition of their skin. Typical examples include lack of sleeping, excessive drinking, and persistent sunlight exposure. In this paper, we propose a scheme for evaluating the condition of a user's skin based on their everyday activities collected from their postings. For such an evaluation, users should regularly send microscopic images of their skin to a server using their smartphone. Meanwhile, the server collects the user postings from their SNS and analyzes them to identify activities that might have an influence on their skin. Finally, the server provides the user with a report containing a comparison of their past and current skin conditions, a statistical summary of their occasional events collected from their SNS, and a set of advices for improving their skin condition including skin care products. We built a prototype system and performed various experiments to show the effectiveness of our scheme. We report some of the results.
C1 [Rew, Jehyeok; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Choi, Young-Hwan] Kiturami Res Planning Ctr Co Ltd, Incheon, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
C3 Korea University; Sungkyul University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM rjh1026@korea.ac.kr; ehwang04@korea.ac.kr; work48@krb.co.kr;
   smrho@sungkyul.edu
RI Rho, Seungmin/HTP-6683-2023
FU Institute for Information & communications Technology Promotion (IITP)
   grant - Korea government (MSIP) [R0190-16-2012]
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIP)
   (No. R0190-16-2012, High Performance Big Data Analytics Platform
   Performance Acceleration Technologies Development).
CR Akazaki S, 2002, BRIT J DERMATOL, V147, P689, DOI 10.1046/j.1365-2133.2002.04874.x
   [Anonymous], 2015, ADJUNCT P 2015 ACM I
   Castro D, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P75, DOI 10.1145/2802083.2808398
   Choi YH, 2014, SKIN RES TECHNOL, V20, P486, DOI 10.1111/srt.12143
   Choi YH, 2013, MULTIMED TOOLS APPL, V64, P227, DOI 10.1007/s11042-011-0987-7
   Cula GO, 2013, SKIN RES TECHNOL, V19, pE243, DOI 10.1111/j.1600-0846.2012.00635.x
   DOHERTY AR, 2008, WIAMIS, P20
   Edwards C, 2003, PHOTODERMATOL PHOTO, V19, P169, DOI 10.1034/j.1600-0781.2003.00042.x
   Hamer MA, 2015, SKIN RES TECHNOL, V21, P392, DOI 10.1111/srt.12205
   Jacobi U, 2004, SKIN RES TECHNOL, V10, P207, DOI 10.1111/j.1600-0846.2004.00075.x
   Kim K, 2009, IEEE INT CON MULTI, P1222, DOI 10.1109/ICME.2009.5202721
   Kwon YJ, 2014, HEALTHC INFORM RES, V20, P69, DOI 10.4258/hir.2014.20.1.69
   Masuda Y, 2014, SKIN RES TECHNOL, V20, P299, DOI 10.1111/srt.12119
   McDuff D., 2012, P SIGCHI C HUM FACT, P849, DOI DOI 10.1145/2207676.2208525
   Miyamoto K, 2013, SKIN RES TECHNOL, V19, pE525, DOI 10.1111/srt.12005
   Rekimoto J, 2007, LECT NOTES COMPUT SC, V4718, P35, DOI 10.1007/978-3-540-75160-1_3
   Rew J, 2014, LECT NOTES ELECTR EN, V301, P261, DOI 10.1007/978-94-017-8798-7_32
   Shinohara A, 2013, IEEE ENG MED BIO, P7266, DOI 10.1109/EMBC.2013.6611235
   Tanaka H, 2008, SKIN RES TECHNOL, V14, P192, DOI 10.1111/j.1600-0846.2007.00278.x
   Wang P, 2016, COMPUT VIS IMAGE UND, V148, P181, DOI 10.1016/j.cviu.2015.09.014
NR 20
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9827
EP 9847
DI 10.1007/s11042-017-4623-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200031
DA 2024-07-18
ER

PT J
AU Sun, S
   Wang, F
   He, L
AF Sun, Shan
   Wang, Feng
   He, Liang
TI Movie summarization using bullet screen comments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie summarization; Multimedia content understanding; Bullet screen
   comments; User-generated data
ID GENERIC FRAMEWORK; ATTENTION MODEL; KEY FRAMES; VIDEO; DRIVEN; SALIENCY
AB Automatic movie summarization helps users to skim a movie in an efficient way. However, it is challenging because it requires the computer to automatically understand the movie content and the users' opinions. Most previous works rely on the movie data itself without considering the opinions of the audience. In this paper, a novel approach for automatic movie summarization is presented by exploring a new type of user-generated data, i.e. bullet screen comments, which allow the audience to comment on the movie in a real-time manner. The number of the comments on a movie segment shows the exciting degree of the audience, while the content of the comments includes the concepts (e.g. the characters and the scenes) that interest the audience. In our approach, given a movie, bullet screen comments are utilized to select candidate highlight segments which are the most commented. Then the candidates are scored based on the number and the content of the bullet screen comments. Visual diversity is also considered in the scoring process. Finally, a subset of candidates which achieves the highest score is selected to compose a summary. Our experiments carried out on movies of different genres have shown the effectiveness of our proposed approach.
C1 [Sun, Shan; Wang, Feng; He, Liang] East China Normal Univ, Dept Comp Sci & Technol, Shanghai Key Lab Multidimens Informat Proc, 3663 N Zhongshan Rd, Shanghai, Peoples R China.
C3 East China Normal University
RP Wang, F (corresponding author), East China Normal Univ, Dept Comp Sci & Technol, Shanghai Key Lab Multidimens Informat Proc, 3663 N Zhongshan Rd, Shanghai, Peoples R China.
EM ecnusunshan@126.com; fwang@cs.ecnu.edu.cn
RI He, Liang/CAF-0477-2022
FU National Natural Science Foundation of China [61375016]; Science and
   Technology Commission of Shanghai Municipality [16511102702]
FX The work described in this paper was supported by the National Natural
   Science Foundation of China (No. 61375016) and the Science and
   Technology Commission of Shanghai Municipality (No. 16511102702).
CR [Anonymous], IEEE INT CON MULTI
   [Anonymous], 2010, Proceedings of the 18th International Conference on Multimedea, DOI [DOI 10.1145/1873951.1874068, 10.1145/1873951.1874068]
   [Anonymous], 2010, P 18 ACM INT C MULTI
   Darabi K, 2017, MULTIMED TOOLS APPL, V76, P2353, DOI 10.1007/s11042-015-3210-4
   Dimoulas CA, 2015, IEEE MULTIMEDIA, V22, P26, DOI 10.1109/MMUL.2015.33
   Dogra DP, 2016, MULTIMED TOOLS APPL, V75, P6373, DOI 10.1007/s11042-015-2576-7
   Doman K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P949, DOI 10.1145/2647868.2654973
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Ferreira L, 2015, SIGNAL PROCESS-IMAGE, V39, P98, DOI 10.1016/j.image.2015.09.005
   Furini M, 2006, P IEEE CONS COMM NET, DOI [10.1109/CCNC.2006.1593230, DOI 10.1109/CCNC.2006.1593230]
   Hannon J., 2011, P 16 INT C INT US IN, P335, DOI DOI 10.1145/1943403.1943459
   Jiang P, 2010, IEEE MULTIMEDIA, V17, P64, DOI 10.1109/MMUL.2009.65
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Over P., 2007, TVS '07: Proc. of the International Workshop on TRECVID Video Summarization, P1, DOI DOI 10.1145/1290031.1290032
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Pickering MJ, 2003, IMAGE VID RETRIEV, DOI [10.1007/3-540-45113-7_42, DOI 10.1007/3-540-45113-7_42]
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Rapantzikos K, 2007, IEEE 9 WORKSH MULT S, DOI [10.1109/MMSP.2007.4412882, DOI 10.1109/MMSP.2007.4412882]
   Shamma D.A, 2010, ACM C COMP SUPP COOP
   SONG YL, 2015, PROC CVPR IEEE, P5179, DOI [DOI 10.1109/CVPR.2015.7299154, 10.1109/CVPR.2015.7299154]
   Taskiran CM, 2006, IEEE T MULTIMEDIA, V8, P775, DOI 10.1109/TMM.2006.876282
   Tian ZQ, 2014, MULTIMED TOOLS APPL, V72, P1773, DOI 10.1007/s11042-013-1488-7
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Xiang X, 2011, P 19 ACM INT C MULT, DOI [10.1145/2072298.2072370, DOI 10.1145/2072298.2072370]
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
NR 34
TC 15
Z9 15
U1 2
U2 73
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9093
EP 9110
DI 10.1007/s11042-017-4807-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800059
DA 2024-07-18
ER

PT J
AU Mackowski, M
   Brzoza, P
   Zabka, M
   Spinczyk, D
AF Mackowski, Michal
   Brzoza, Piotr
   Zabka, Marek
   Spinczyk, Dominik
TI Multimedia platform for mathematics' interactive learning accessible to
   blind people
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive multimedia math presentation; Alternative math presentation;
   Math tutoring platform; Distance learning
AB Nowadays, the math learning is an important step in developing professional carriers in technical and economic sciences. Increasing the number of e-learning tools used in universities courses can reduce the potential barrier of access to mathematical knowledge, but most of them are not accessible for impaired students. Moreover, classical printed math books include little explicit instructional information about structural information interpretations. Taking into account these barriers the article presents the developed method used for creating interactive steps of decomposed math's exercise solution and alternative description of math formulas accessible for the blind. The elements of proposed methodology: generation of state machine, design and presentation of transition conditions, generating the presentation layer and a typical usage by a blind user are presented. A set of rules for describing mathematical formulas were proposed after consultation with mathematicians and teachers of blind people. The application was developed as web application. The graphical interface of presented application was designed using PHP and JavaScript technologies. The collection of prepared exercises include about 240 prepared exercises from different areas of mathematics and 60 selected exercises including alternative description layer. About 1000 students and about 40 impaired students, from 6 faculties of the university use this platform during math courses for both self and class learning. The defined rules were used to read aloud mathematical formulas to the visually impaired people with a different level of mathematical knowledge. The results confirmed good understanding of mathematical formulas by using prepared alternative description.
C1 [Mackowski, Michal; Brzoza, Piotr] Silesian Tech Univ, Fac Automat Control Elect & Comp Sci, 16 Akad, PL-44100 Gliwice, Poland.
   Silesian Tech Univ, Fac Appl Math, 23 Kaszubska, PL-44100 Gliwice, Poland.
   [Spinczyk, Dominik] Silesian Tech Univ, Fac Biomed Engn, 40 Roosevelta, PL-41800 Zabrze, Poland.
C3 Silesian University of Technology; Silesian University of Technology;
   Silesian University of Technology
RP Spinczyk, D (corresponding author), Silesian Tech Univ, Fac Biomed Engn, 40 Roosevelta, PL-41800 Zabrze, Poland.
EM michal.mackowski@polsl.pl; piotr.brzoza@polsl.pl; marek.zabka@polsl.pl;
   dominik.spinczyk@polsl.pl
RI Mackowski, Michal/T-5854-2018; Zabka, Marek/C-1019-2019
OI Mackowski, Michal/0000-0002-0099-1938; Spinczyk,
   Dominik/0000-0003-0068-2948; Zabka, Marek/0000-0001-9990-8390
FU European Union [UDA-POKL-04.01.02-00-137/12]
FX Interactive multimedia math tutoring platform ForMath has been
   implemented in the framework of the project "Mathematics - interactive
   study of the future" No. UDA-POKL-04.01.02-00-137/12 financed by the
   European Union.
CR [Anonymous], 2015, 25 UN
   [Anonymous], 1994, LaTeX: A Document Preparation System: User's Guide and Reference Manual
   Bernareggi C, 2010, LNCS, V6180, P385
   Brzoza Piotr, 2012, Proceedings of the 4th International Conference on Computer Supported Education (CSEDU 2012), P118
   Brzoza P, 2006, LECT NOTES COMPUT SC, V4061, P1087
   Brzoza P, 2014, LECT NOTES COMPUT SC, V8547, P519, DOI 10.1007/978-3-319-08596-8_81
   Cervone D., 2012, Notices of the AMS, V59, P312, DOI DOI 10.1090/NOTI794
   Cooper M, 2008, LECT NOTES COMPUT SC, V5105, P926, DOI 10.1007/978-3-540-70540-6_139
   Craig SD, 2013, COMPUT EDUC, V68, P495, DOI 10.1016/j.compedu.2013.06.010
   Cui W, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P947, DOI 10.1109/ICCIT.2009.130
   Fateman R, 2013, CAN WE SPEAK M UNPUB
   Gamrat B, 2006, DR DOBBS J, V31, P46
   Gardner JA, 2014, LECT NOTES COMPUT SC, V8547, P580, DOI 10.1007/978-3-319-08596-8_90
   Goguadze G, 2005, INTERACTIVITY EXERCI
   Henderson S, 2014, BIBLIOTHECA DIGITAL
   Kerscher G., 2001, Library Hi Tech, V19, P11, DOI 10.1108/07378830110384520
   Namahoe K, 2014, JOURNAL
   Nicotra G, 2010, LECT NOTES COMPUT SC, V6180, P423, DOI 10.1007/978-3-642-14100-3_63
   Riga P, 2016, 15 INT C ICCHP 201 1, P27
   Salamonczyk A, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON CYBERNETICS (CYBCONF), P240, DOI 10.1109/CYBConf.2015.7175939
   Soiffer N, 2009, APPL SERV 5 INT C 3, P130
   Soiffer N, 2016, LECT NOTES COMPUT SC, V9758, P59, DOI 10.1007/978-3-319-41264-1_8
   Sorge V., 2014, W4A 2014 11 WEB ALL, DOI DOI 10.1145/2596695.2596700
   Sorge V, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P323, DOI 10.1145/2982142.2982212
   Spinczyk D, 2008, ADV INTEL SOFT COMPU, V47, P513
   van Garderen D, 2012, LEARN DISABILITY Q, V35, P24, DOI 10.1177/0731948711429726
   Wang K, 2016, L N INST COMP SCI SO, V163, P289, DOI 10.1007/978-3-319-28910-6_26
   Yamaguchi K, 2012, LECT NOTES COMPUT SC, V7382, P130, DOI 10.1007/978-3-642-31522-0_19
   Zabka M, 2016, P BACHOTEX IN PRESS
NR 29
TC 22
Z9 24
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6191
EP 6208
DI 10.1007/s11042-017-4526-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800049
OA hybrid
DA 2024-07-18
ER

PT J
AU Tian, CN
   Zhang, XN
   Wei, W
   Gao, XB
AF Tian, Chunna
   Zhang, Xiangnan
   Wei, Wei
   Gao, Xinbo
TI Color pornographic image detection based on color-saliency preserved
   mixture deformable part model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pornographic image detection; Deformable part model; Mixture model;
   Salient color distribution
ID RECOGNITION
AB To utilize the rich semantic information of sexual organs, we propose a new framework for pornographic image detection based on sexual organ detectors. Traditional sexual organ detectors are built on shape features. Since the color distribution of sexual organ in same pose is consistent, color is an important visual clue to represent sexual organs. We use color attribute to describe the local color of sexual organs and concatenate it with histogram of oriented gradients based shape feature to represent sexual organs. Based on the concatenated feature, we train sexual organ detectors by the color-saliency preserved mixture deformable part model (CPMDPM). We detect pornographic images sequentially with sexual organ detectors. In experiments, the optimal part number of the deformable part model is chosen experimentally. We evaluate the performance of each CPMDPM based sexual organ detector, which is superior over the shape feature based detector. The proposed pornographic detection method is superior over methods based on low level features of skin regions, bag of words model and color incorporated SIFT features etc.
C1 [Tian, Chunna; Zhang, Xiangnan; Gao, Xinbo] Xidian Univ, Sch Elect Engn, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
   [Wei, Wei] Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710129, Shaanxi, Peoples R China.
C3 Xidian University; Northwestern Polytechnical University
RP Gao, XB (corresponding author), Xidian Univ, Sch Elect Engn, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
EM xbgao@mail.xidian.edu.cn
RI Gao, Xinbo/Q-8622-2016
OI Gao, Xinbo/0000-0003-1443-0776
FU National Natural Science Foundation of China [61571354, 61671385,
   61201291]; National High-Level Talents Special Support Program
   [CS31117200001]; Program for Changjiang Scholars and Innovative Research
   Team in University [IRT13088]; China Postdoctoral Science Foundation
   [158201]
FX This work was supported in part by the National Natural Science
   Foundation of China under, Grant 61571354, 61671385 and 61201291, in
   part by National High-Level Talents Special Support Program under Grant
   CS31117200001, in part by Program for Changjiang Scholars and Innovative
   Research Team in University under Grant IRT13088, in part by China
   Postdoctoral Science Foundation under Grant 158201.
CR [Anonymous], P AS C COMP VIS
   [Anonymous], 2008, P 2008 IEEE C COMP V
   [Anonymous], P EUR C COMP VIS PAT
   Arentz WA, 2004, COMPUT VIS IMAGE UND, V94, P295, DOI 10.1016/j.cviu.2003.10.007
   Berlin Brent, 1969, Basic Color Terms: Their Universality and Evolution
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Feng Jiao, 2001, 2001 International Conferences on Info-Tech and Info-Net. Proceedings (Cat. No.01EX479), P378, DOI 10.1109/ICII.2001.983086
   Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462
   Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   HU W., 2011, TOMCCAP, V78, P1
   Hu WM, 2007, IEEE T PATTERN ANAL, V29, P1019, DOI 10.1109/TPAMI.2007.1133
   Huang L, 2011, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2011.6115661
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kelly W, 2008, 2008 INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P151, DOI 10.1109/IMVIP.2008.21
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   León LC, 2014, PATTERN RECOGN LETT, V39, P39, DOI 10.1016/j.patrec.2013.10.028
   Lienhart R, 2009, IEEE INT CON MULTI, P1472, DOI 10.1109/ICME.2009.5202781
   Lintao Lv, 2011, 2011 Seventh International Conference on Natural Computation (ICNC 2011), P1015, DOI 10.1109/ICNC.2011.6022151
   Lopes Ana P. B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1552
   Nian FD, 2016, NEUROCOMPUTING, V210, P283, DOI 10.1016/j.neucom.2015.09.135
   Ries CX, 2014, MULTIMED TOOLS APPL, V69, P661, DOI 10.1007/s11042-012-1132-y
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shih JL, 2007, PATTERN RECOGN LETT, V28, P2367, DOI 10.1016/j.patrec.2007.08.002
   Sui L, 2012, IET IMAGE PROCESS, V6, P87, DOI 10.1049/iet-ipr.2011.0005
   Tian C., 2014, 2014 INT C SEC PATT, P1
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang XM, 2009, CHINESE J ELECTRON, V18, P8
   Xuanjing Shen, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2473, DOI 10.1109/CISP.2010.5647823
   Yan J., 2011, CHINESE J STEREOLOGY, V16, P75
NR 32
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6629
EP 6645
DI 10.1007/s11042-017-4576-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700010
DA 2024-07-18
ER

PT J
AU Gardezi, SJS
   Faye, I
   Bornot, JMS
   Kamel, N
   Hussain, M
AF Gardezi, Syed Jamal Safdar
   Faye, Ibrahima
   Bornot, Jose M. Sanchez
   Kamel, Nidal
   Hussain, Mohammad
TI Mammogram classification using dynamic time warping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic time warping; Mammogram classification; Orientation; False
   alarms; Type II error; Sensitivity
ID CHARACTERISTIC ROC CURVE; MASS DETECTION; RECOGNITION; PATTERNS
AB This paper presents a new approach for breast cancer classification using time series analysis. In particular, the region of interest (ROI) in mammogram images is classified as normal or abnormal using dynamic time warping (DTW) as a similarity measure. According to the analogous case in time series analysis, the DTW subsumes Euclidean distance (ED) as a specific case with increased robustness due to DTW flexibility to address local horizontal/vertical deformations. This method is especially attractive for biomedical image analysis and is applied to mammogram classification for the first time in this paper. The current study concludes that varying the size of the ROI images and the restriction on the search criteria for the warping path do not affect the performance because the method produces good classification results with reduced computational complexity. The method is tested on the IRMA and MIAS dataset using the k-nearest neighbour classifier for different k values, which produces an area under curve (AUC) value of 0.9713 for one of the best scenarios.
C1 [Gardezi, Syed Jamal Safdar; Faye, Ibrahima; Kamel, Nidal] Univ Teknol Petronas, CISIR, Seri Iskanadar 32610, Perak, Malaysia.
   [Gardezi, Syed Jamal Safdar; Faye, Ibrahima] Univ Teknol PETRONAS, Dept Fundamental & Appl Sci, Iskanadar 32610, Perak, Malaysia.
   [Bornot, Jose M. Sanchez] Univ Ulster, Magee Campus, Londonderry, North Ireland.
   [Kamel, Nidal] Univ Teknol PETRONAS, Dept Elect & Elect Engn, Seri Iskanadar 32610, Perak, Malaysia.
   [Hussain, Mohammad] King Saud Univ, Dept Comp Sci, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 Universiti Teknologi Petronas; Universiti Teknologi Petronas; Ulster
   University; Universiti Teknologi Petronas; King Saud University
RP Faye, I (corresponding author), Univ Teknol Petronas, CISIR, Seri Iskanadar 32610, Perak, Malaysia.; Faye, I (corresponding author), Univ Teknol PETRONAS, Dept Fundamental & Appl Sci, Iskanadar 32610, Perak, Malaysia.
EM ibrahima_faye@utp.edu.my
RI Gardezi, Jamal/AAH-7448-2019; Hussain, Muhammad/A-8487-2014;
   Sanchez-Bornot, Jose Miguel/T-5642-2019; Hussain,
   Muhammad/KGL-0395-2024; Hussain, Muhammad/AAD-2380-2022; Faye,
   Ibrahima/AAH-5032-2020; safdar, shujaa/ABS-9583-2022
OI Gardezi, Jamal/0000-0002-1655-2956; Hussain,
   Muhammad/0000-0002-5847-8539; Sanchez-Bornot, Jose
   Miguel/0000-0003-4014-4255; Faye, Ibrahima/0000-0001-7777-1119; 
FU URIF [0153AA-B52]
FX This research was supported by the URIF grant 0153AA-B52.
CR Agrawal P, 2014, SIGNAL PROCESS, V99, P29, DOI 10.1016/j.sigpro.2013.12.010
   [Anonymous], INTRO MDS SOUND QUAL
   [Anonymous], 1994, DIGITAL MAMMO, DOI DOI 10.1007/S11999-016-4732-4
   [Anonymous], 2009, COMPUT SCI
   [Anonymous], LAT WORLD CANC STAT
   Bailador G, 2011, PATTERN RECOGN, V44, P2468, DOI 10.1016/j.patcog.2011.04.010
   Berndt D.J., 1994, AAAI 94 WORKSH KNOWL, V10, P359, DOI [10.5555/3000850.3000887, DOI 10.5555/3000850.3000887]
   Bhanu B, 2004, INT C PATT RECOG, P499, DOI 10.1109/ICPR.2004.1333820
   Bodiroza S, 2013, ACMIEEE INT CONF HUM, P87, DOI 10.1109/HRI.2013.6483514
   Brodersen J, 2013, ANN FAM MED, V11, P106, DOI 10.1370/afm.1466
   Celebi S., 2013, Computer Vision Theory and Applications. Visapp
   Chan P., 2004, KDD WORKSH MIN TEMP
   Chen YL, 2011, INFORM SCIENCES, V181, P398, DOI 10.1016/j.ins.2010.09.024
   Dietrich C, 2004, PATTERN RECOGN, V37, P2293, DOI [10.1016/S0031-3203(04)00161-X, 10.1016/j.patcog.2004.04.004]
   Ding H, 2008, PROC VLDB ENDOW, V1, P1542
   Duarte Y, 2014, J PHYS C SERIES, V1
   Faundez-Zanuy M, 2007, PATTERN RECOGN, V40, P981, DOI 10.1016/j.patcog.2006.06.007
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Forestier G, 2012, J BIOMED INFORM, V45, P255, DOI 10.1016/j.jbi.2011.11.002
   Gardezi S.J.S., 2015, Int. J. Applied Mathematics Information Sciences, V9, P3037
   Gardezi SJS, 2014, PROC SPIE, V9069, DOI 10.1117/12.2054183
   Hajian-Tilaki K, 2013, CASP J INTERN MED, V4, P627
   Harrison HB, 2013, MOL ECOL, V22, P5738, DOI 10.1111/mec.12527
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641
   Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9
   Kumar R, 2011, INDIAN PEDIATR, V48, P277, DOI 10.1007/s13312-011-0055-4
   Lee AJT, 2009, INFORM SCIENCES, V179, P2218, DOI 10.1016/j.ins.2009.02.016
   Legrand B, 2008, PATTERN RECOGN LETT, V29, P215, DOI 10.1016/j.patrec.2007.09.017
   Lemire D, 2009, PATTERN RECOGN, V42, P2169, DOI 10.1016/j.patcog.2008.11.030
   Liao TW, 2005, PATTERN RECOGN, V38, P1857, DOI 10.1016/j.patcog.2005.01.025
   Martens R., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P38, DOI 10.1109/ICPR.1996.546791
   Michaelson J., 2003, J. Womens Imaging, V5, P3, DOI DOI 10.1097/00130747-200302000-00002
   Mugavin ME, 2008, NURS RES, V57, P64, DOI 10.1097/01.NNR.0000280659.88760.7c
   Oliveira JE, 2008, MED IMAGING
   Oliveira JEE, 2008, STANDARD REFERENCE D
   Oliver A, 2007, LECT NOTES COMPUT SC, V4791, P286
   Petitjean F, 2011, PATTERN RECOGN, V44, P678, DOI 10.1016/j.patcog.2010.09.013
   Pratiwi M, 2015, PROCEDIA COMPUT SCI, V59, P83, DOI 10.1016/j.procs.2015.07.340
   Ratanamahatana C., 2005, P 5 SIAM INT C DAT M
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Salz T, 2010, PSYCHO-ONCOLOGY, V19, P1026, DOI 10.1002/pon.1676
   Skutkova H, 2013, BMC BIOINFORMATICS, V14, P1
   Tai SC, 2014, IEEE J BIOMED HEALTH, V18, P618, DOI 10.1109/JBHI.2013.2279097
   Toennies K. D., 2012, GUIDE MED IMAGE ANAL
   Vaidehi K, 2015, PROCEDIA COMPUT SCI, V46, P1762, DOI 10.1016/j.procs.2015.02.128
   Wang Y, 2011, J INT MED RES, V39, P2256, DOI 10.1177/147323001103900622
   Wasserstein RL, 2016, AM STAT, V70, P129
   Xi X., 2006, Proceedings of the 23rd international conference on Machine learning, VVolume 2006, P1033, DOI [10.1145/1143844.1143974, DOI 10.1145/1143844.1143974]
   Zhang YD, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016634243
NR 49
TC 19
Z9 20
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3941
EP 3962
DI 10.1007/s11042-016-4328-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600058
DA 2024-07-18
ER

PT J
AU Wang, T
AF Wang, Tao
TI A group interest-based collaborative filtering algorithm for multimedia
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative filtering; Recommender system; Co-clustering; NMF
   (non-negative matrix factorization)
ID RECOMMENDER SYSTEMS
AB This paper proposes a collaborative filtering algorithm based on user group interest. A novel co-clustering method (BalClust) and various weighted non-negative matrix factorization algorithms are used in the proposed method. The BalClust method is used to divide the raw rating matrix into clusters, which are smaller than the original matrix. Then, the balance factor is introduced to consider the user weight and the item-based CF (collaborative filtering). To predict the rating of the unknown items in the cluster, the non-negative matrix factorization algorithm was used. The proposed method achieves higher predicting accuracy and efficiency on low dimensional and homogeneous sub-matrices, and the method also reduces the computational complexity by combining the user and item-based CF. Based on the proposed method, this paper proposed an incremental learning method to ensure data accuracy and timeliness to overcome the problem brought by data updates. The experimental results show the proposed methods outperformed traditional CF algorithms, and the completion time is reduced.
C1 [Wang, Tao] Sichuan Univ, Coll Comp Sci, Chengdu, Sichuan, Peoples R China.
   [Wang, Tao] Hubei Univ Nationalities, Sch Sci, Enshi, Sichuan, Peoples R China.
C3 Sichuan University; Hubei Minzu University
RP Wang, T (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu, Sichuan, Peoples R China.; Wang, T (corresponding author), Hubei Univ Nationalities, Sch Sci, Enshi, Sichuan, Peoples R China.
EM wangtao@chinawalter.com
FU National Statistical Science Research Project of China [2015LY43]
FX We thank the anonymous reviewers and the editors for the valuable
   feedback on earlier versions of this paper. This paper is supported by
   the National Statistical Science Research Project of China, under grant
   number 2015LY43.
CR Abrate F, 2013, J INTELL ROBOT SYST, V71, P403, DOI 10.1007/s10846-012-9790-6
   Agarwal D, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P26
   Akinshina A, 2013, BMC BIOPHYS, V6, DOI 10.1186/2046-1682-6-12
   Badaro G, 2013, INT WIREL COMMUN, P349, DOI 10.1109/IWCMC.2013.6583584
   Banerjee A, 2007, J MACH LEARN RES, V8, P1919
   Bobadilla J, 2013, KNOWL-BASED SYST, V51, P27, DOI 10.1016/j.knosys.2013.06.010
   Brooks ChristopherH., 2006, WWW '06, P625, DOI DOI 10.1145/1135777.1135869
   Brzozowski M.J., 2011, P 5 INT AAAI C WEBL, P458
   Chen G, 2009, INFORM PROCESS MANAG, V45, P368, DOI 10.1016/j.ipm.2008.12.004
   Cheng Y, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P93
   Chirici G, 2013, INT J APPL EARTH OBS, V25, P87, DOI 10.1016/j.jag.2013.04.006
   Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550
   Dhillon IS, 2003, P 9 ACM SIGKDD INT C, P89, DOI DOI 10.1145/956750.956764
   Dinuzzo F, 2013, NEUROCOMPUTING, V118, P119, DOI 10.1016/j.neucom.2013.02.024
   George T, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P625, DOI 10.1109/icdm.2005.14
   Hindle A, 2013, EMPIR SOFTW ENG, V18, P1125, DOI 10.1007/s10664-012-9209-9
   Kaklauskas A, 2013, EXPERT SYST APPL, V40, P6150, DOI 10.1016/j.eswa.2013.05.034
   Kim HL, 2011, IEEE T SYST MAN CY A, V41, P683, DOI 10.1109/TSMCA.2011.2132709
   Li Xiao-Guang, 2008, Journal of Software, V19, P2276, DOI 10.3724/SPJ.1001.2008.02276
   Liu JM, 2012, IEEE J-STARS, V5, P1545, DOI 10.1109/JSTARS.2012.2199282
   Long B, 2005, P 11 ACM SIGKDD INT, V5, P635, DOI [DOI 10.1145/1081870.1081949, 10.1145/1081870.1081949]
   Pan JY, 2011, MATH PROBL ENG, V2011, DOI 10.1155/2011/864540
   Shafiei MM, 2006, IEEE DATA MINING, P542
   Shan HH, 2008, IEEE DATA MINING, P530, DOI 10.1109/ICDM.2008.91
   STADNYK I, 1992, COMMUN ACM, V35, P49, DOI 10.1145/138859.138864
   Wei C, 2013, INFORM SYST FRONT, V15, P533, DOI 10.1007/s10796-012-9377-6
   Wu H, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P99
   Xiao YH, 2013, J COMPUT SCI TECH-CH, V28, P751, DOI 10.1007/s11390-013-1374-9
   Xu Hai-Ling, 2009, Journal of Software, V20, P350, DOI 10.3724/SP.J.1001.2009.03388
   [郑志高 Zheng Zhigao], 2014, [计算机科学, Computer Science], V41, P7
NR 30
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4401
EP 4415
DI 10.1007/s11042-017-5516-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500020
DA 2024-07-18
ER

PT J
AU Yang, ZW
   Wang, HY
   Han, YH
   Zhu, XL
AF Yang, Ziwei
   Wang, Huiyun
   Han, Yahong
   Zhu, Xianglei
TI Discriminative multi-task multi-view feature selection and fusion for
   multimedia analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-task; Multi-view; Feature selection; Feature fusion
ID REGRESSION
AB Multimedia content analysis and understanding, such as action recognition and image classification, is a fundamental research problem. One effective strategy to improve the performance is designing discriminative visual representation, for example combining multiple feature sets for representation. However, simply combing these features may cause high dimensionality and lead to noises. Feature selection and fusion are common choices for multiple feature representation. At the same time, multi-task feature learning has been proven to be an effective method by many researches. In this paper, we propose a multi-task multi-view feature selection and fusion method which chooses and fuses discriminative features. For discriminative feature selection, we learn the selection matrix W by the minimization of the trace ratio objective function. For multiple tasks measurement, we employ the a"" (2,1)-norm regularization to solve single task and share information among tasks. For multiple feature fusion, we incorporate local structures of each view in the Laplacian matrix. Since the Laplacian matrix is constructed in unsupervised manner and scaled category indicator matrix is solved iteratively, our work is fully unsupervised. Experimental results on four action recognition datasets and five image classification datasets demonstrate the effectiveness of multi-task multi-view feature selection and fusion.
C1 [Yang, Ziwei; Wang, Huiyun; Han, Yahong] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Zhu, Xianglei] China Automot Technol & Res Ctr, Automot Data Ctr, Tianjin, Peoples R China.
C3 Tianjin University
RP Han, YH (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
EM yzwtend@tju.edu.cn; wanghuiyun@tju.edu.cn; yahong@tju.edu.cn;
   zhuxianglei@catarc.ac.cn
RI wang, hui/HSG-6135-2023
FU NSFC [U1509206, 61472276]
FX This work is supported by the NSFC (under Grant U1509206,61472276).
CR [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], ACCV, DOI DOI 10.1007/978-3-642-37331-2
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], P 17 AAAI C LAT BREA
   [Anonymous], COMPUT VIS ECCV
   [Anonymous], INT C PATT REC
   [Anonymous], 2010, BMVC
   Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen X, 2012, ANN APPL STAT, V6, P719, DOI 10.1214/11-AOAS514
   De Wang, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P306, DOI 10.1007/978-3-662-44845-8_20
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2012, IEEE T CIRC SYST VID, V22, P1485, DOI 10.1109/TCSVT.2012.2202075
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Li H, 2009, INT CONF DAT MIN WOR, P164, DOI 10.1109/ICDMW.2009.46
   Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154
   Liu YF, 2015, J NANOMATER, V2015, DOI 10.1155/2015/792095
   Liu Y, 2013, NEUROCOMPUTING, V105, P12, DOI 10.1016/j.neucom.2012.05.031
   Loui Alexander., 2007, MIR 07, P245
   Ma Z., 2011, Proc. 19th ACM Int'l Conf. Multimedia, P283, DOI DOI 10.1145/2072298.2072336
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   NIE L, 2016, LEARNING MULTIPLE SO
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Parameswaran S., 2010, ADV NEURAL INFORM PR, P1867
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Solorio-Fernández S, 2016, NEUROCOMPUTING, V214, P866, DOI 10.1016/j.neucom.2016.07.026
   Song XM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2371
   Wang HQ, 2007, IEEE IPCCC, P1
   Wu M., 2006, P C NEURAL INFORM PR, P1529
   Wu XD, 2013, IEEE T PATTERN ANAL, V35, P1178, DOI 10.1109/TPAMI.2012.197
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xiao Cai, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P91, DOI 10.1109/ICDM.2011.105
   Xie L, 2017, LECT NOTES COMPUT SC, V10132, P465, DOI 10.1007/978-3-319-51811-4_38
   Xin Jin, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P353, DOI 10.1007/978-3-642-40991-2_23
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Yi., 2011, Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI'11, P555
   Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234
   Zhang XQ, 2013, IEEE T CIRC SYST VID, V23, P1197, DOI 10.1109/TCSVT.2013.2241354
   Zhao HF, 2016, NEUROCOMPUTING, V216, P200, DOI 10.1016/j.neucom.2016.07.037
   Zhao Z, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P641
   Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 54
TC 8
Z9 9
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3431
EP 3453
DI 10.1007/s11042-017-5165-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600029
DA 2024-07-18
ER

PT J
AU Etemad, E
   Samavi, S
   Soroushmehr, SMR
   Karimi, N
   Etemad, M
   Shirani, S
   Najarian, K
AF Etemad, Elham
   Samavi, Shadrokh
   Soroushmehr, S. M. Reza
   Karimi, Nader
   Etemad, Mohammad
   Shirani, Shahram
   Najarian, Kayvan
TI Robust image watermarking scheme using bit-plane of hadamard
   coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Hadamard transform; Copyright; Robustness;
   Transparency
ID TRANSFORM
AB Nowadays, due to widespread usage of the Internet, digital contents are distributed quickly and inexpensively throughout the world. Watermarking techniques can help protect authenticity of digital contents by identifying their owners. In a watermarking procedure, owner information may be embedded in the spatial domain or transform domain of host images. Since watermarking algorithms must be tamper resistant and transparent, we present a watermarking method based on a transform domain. In this method, we employ Hadamard transform as it requires simpler operations compared to other transforms such as discrete cosine transform (DCT) and discrete wavelet transform (DWT) while it still attains robustness. We analyze each bit of the Hadamard's coefficients in terms of robustness and transparency for hiding the watermark information and find a bit-plane that maintains both robustness and transparency. After that, watermark information is hidden redundantly in the selected bit-plane. The proposed extraction algorithm is classified as a blind algorithm since it extracts all versions of the concealed watermark with no information from the host image. The output of the extraction algorithm is a logo obtained by an intelligent voting among all versions of the hidden logo. The experimental results show that the proposed method, while providing transparency, is robust against many image processing attacks such as compression, image cropping and Gaussian filtering.
C1 [Etemad, Elham; Etemad, Mohammad] Dalhousie Univ, Dept Comp Sci, Halifax, NS, Canada.
   [Samavi, Shadrokh; Karimi, Nader] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Soroushmehr, S. M. Reza; Najarian, Kayvan] Univ Michigan, Ctr Integrat Res Crit Care MCIRCC, Ann Arbor, MI 48109 USA.
   [Samavi, Shadrokh; Shirani, Shahram] McMaster Univ, ECE Dept, Hamilton, ON, Canada.
C3 Dalhousie University; Isfahan University of Technology; University of
   Michigan System; University of Michigan; McMaster University
RP Soroushmehr, SMR (corresponding author), Univ Michigan, Ctr Integrat Res Crit Care MCIRCC, Ann Arbor, MI 48109 USA.
EM eefami@dal.ca; ssoroush@umich.edu
RI Karimi, Nader/HWP-4206-2023; Etemad, Mohammad/Y-9825-2019
OI Karimi, Nader/0000-0001-8904-1607; Etemad, Mohammad/0000-0002-3770-180X;
   Soroushmehr, S.M.Reza/0000-0001-8417-9260
CR Aung A, 2008, IEEE T SIGNAL PROCES, V56, P3562, DOI 10.1109/TSP.2008.923195
   Aung A, 2011, J SIGNAL PROCESS SYS, V64, P319, DOI 10.1007/s11265-010-0492-7
   Botta M, 2014, SOFT COMPUT, P1
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cox IJ., 2007, DIGITAL WATERMARKING
   Fami Elham Shabanali, 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P503, DOI 10.1109/AISP.2012.6313799
   Fazlali HamidReza, 2016, MULTIMED TOOLS APPL, P1
   Feng BW, 2016, SIGNAL PROCESS-IMAGE, V41, P1, DOI 10.1016/j.image.2015.10.007
   Ghosh S, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT), P233, DOI 10.1109/ICCCT.2012.54
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Ho A. T. S., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V4793, P76, DOI 10.1117/12.451250
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P26723, DOI 10.1007/s11042-016-4202-8
   Hua G, 2016, IEEE SIGNAL PROC LET, V23, P473, DOI 10.1109/LSP.2016.2536110
   Kountchev R., 2010, 2010 IEEE International Conference on Information Reuse & Integration (IRI 2010), P159, DOI 10.1109/IRI.2010.5558946
   Liu S, 2015, SIGNAL PROCESS, V109, P345, DOI 10.1016/j.sigpro.2014.06.024
   Liu Y, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P43
   Maity SP, 2011, INFORM SCIENCES, V181, P450, DOI 10.1016/j.ins.2010.09.029
   Maity SP, 2010, AEU-INT J ELECTRON C, V64, P243, DOI 10.1016/j.aeue.2008.10.004
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Pakdaman Z, 2013, 2013 5TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P447, DOI 10.1109/IKT.2013.6620109
   Rajkumar F., 2011, INT J COMPUTER APPL, V12, P14
   Sarker MIH, 2013, SMARTCR, V3, P298, DOI DOI 10.6029/SMARTCR.2013.05.001
   Tsai MH, 2014, MATER RES LETT, V2, P107, DOI 10.1080/21663831.2014.912690
   Tsougenis ED, 2015, MULTIMED TOOLS APPL, V74, P3985, DOI 10.1007/s11042-013-1808-y
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yong Zhang, 2010, Information Technology Journal, V9, P1369, DOI 10.3923/itj.2010.1369.1375
   Yue Zhang, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1176, DOI 10.1109/CISP.2010.5646844
NR 28
TC 24
Z9 28
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2033
EP 2055
DI 10.1007/s11042-016-4278-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400026
DA 2024-07-18
ER

PT J
AU Kalender, M
   Eren, MT
   Wu, ZH
   Cirakman, O
   Kutluk, S
   Gultekin, G
   Korkmaz, EE
AF Kalender, Murat
   Eren, M. Tolga
   Wu, Zonghuan
   Cirakman, Ozgun
   Kutluk, Sezer
   Gultekin, Gunay
   Korkmaz, Emin Erkan
TI Videolization: knowledge graph based automated video generation from web
   content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic web; Computer graphics; Text-to-video; Entity linking;
   Knowledge graph; DBpedia
AB Web content nowadays can also be accessed through new generation of Internet connected TVs. However, these products failed to change users' behavior when consuming online content. Users still prefer personal computers to access Web content. Certainly, most of the online content is still designed to be accessed by personal computers or mobile devices. In order to overcome the usability problem of Web content consumption on TVs, this paper presents a knowledge graph based video generation system that automatically converts textual Web content into videos using semantic Web and computer graphics based technologies. As a use case, Wikipedia articles are automatically converted into videos. The effectiveness of the proposed system is validated empirically via opinion surveys. Fifty percent of survey users indicated that they found generated videos enjoyable and 42 % of them indicated that they would like to use our system to consume Web content on their TVs.
C1 [Kalender, Murat; Korkmaz, Emin Erkan] Yeditepe Univ, Dept Comp Engn, Fac Engn, Istanbul, Turkey.
   [Kalender, Murat; Eren, M. Tolga; Cirakman, Ozgun; Kutluk, Sezer; Gultekin, Gunay] Huawei Technol, Huawei Turkey R&D Ctr, Istanbul, Turkey.
   [Wu, Zonghuan] Huawei Technol, Software Lab, Santa Clara, CA USA.
C3 Yeditepe University; Huawei Technologies; Huawei Technologies
RP Kalender, M (corresponding author), Yeditepe Univ, Dept Comp Engn, Fac Engn, Istanbul, Turkey.; Kalender, M (corresponding author), Huawei Technol, Huawei Turkey R&D Ctr, Istanbul, Turkey.
EM murat.kalender@huawei.com; zonghuanwu@huawei.com;
   ekorkmaz@cse.yeditepe.edu.tr
RI korkmaz, emin erkan/C-8380-2012; Kalender, Murat/ABH-1321-2020; Kutluk,
   Sezer/AAB-3214-2020
OI Kutluk, Sezer/0000-0002-3048-5526; Korkmaz, Emin
   Erkan/0000-0002-7842-7667; Cirakman, Ozgun/0000-0001-6649-3280
CR [Anonymous], P 20 INT C WORLD WID, DOI DOI 10.1145/1963192.1963296
   [Anonymous], BBC
   [Anonymous], 2016, CREATING IMAGES LEAR
   [Anonymous], 2012, P 20 ACM INT C MULT, DOI DOI 10.1145/2393347.2396495
   [Anonymous], FRAMEWORK BENCHMARKI
   [Anonymous], SPEC INT TRACKS 14 I
   [Anonymous], AAAI SPRING S KNOWL
   [Anonymous], AUTOMATIC MUSIC VIDE
   Bailer W., 2006, The 12th International Multi-Media Modelling Conference Proceedings
   Cai R, 2007, INT CONF ACOUST SPEE, P737
   Coyne B, 2001, COMP GRAPH, P487, DOI 10.1145/383259.383316
   Ferragina P, 2010, INT C INF KNOWL MAN, P1625, DOI [10.1145/1871437 .1871689. (Ver, DOI 10.1145/1871437.1871689.(VER, DOI 10.1145/1871437.1871689]
   Hoffart J., 2011, P 2011 C EMPIRICAL M, P782, DOI DOI 10.3115/V1/D11-1072
   Kulkarni S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P457
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Meij E, 2012, P 5 ACM INT C WEB SE, P563, DOI DOI 10.1145/2124295.2124364
   Mendes Pablo N, 2011, P 7 INT C SEM SYST, P1, DOI [DOI 10.1145/2063518.2063519, 10.1145/2063518.2063519]
   Mihalcea R, 2008, MACH TRANSL, V22, P153, DOI 10.1007/s10590-009-9050-0
   Milne D, 2008, P 17 ACM C INF KNOWL, P509, DOI DOI 10.1145/1458082.1458150
   Milne D., 2008, P AAAI WORKSH WIK AR, P25
   Nenkova A., 2012, MINING TEXT DATA, P43, DOI [10.1007/978-1-4614-3223-4_3, 10.1007/978- 1- 4614-3223- 4_3.]
   Ratinov L., 2011, P 49 ANN M ASS COMP, P1375
   Shim H, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P596
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Tanaka K, 2007, ICKS 2007: SECOND INTERNATIONAL CONFERENCE ON INFORMATICS RESEARCH FOR DEVELOPMENT OF KNOWLEDGE SOCIETY INFRASTRUCTURE, PROCEEDINGS, P129
   Tao DP, 2017, IEEE T CIRC SYST VID, V27, P62, DOI 10.1109/TCSVT.2016.2539778
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   UzZaman N., 2011, P 16 INT C INT US IN, P43, DOI DOI 10.1145/1943403.1943412
   Zhu X., 2007, AAAI, V7, P1590, DOI 10.5555/1619797.1619900
   Zitnick CL, 2013, IEEE I CONF COMP VIS, P1681, DOI 10.1109/ICCV.2013.211
NR 30
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 567
EP 595
DI 10.1007/s11042-016-4275-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400024
DA 2024-07-18
ER

PT J
AU Kalinathan, L
   Kathavarayan, RS
   Nagendram, D
   Vij, M
   Rela, M
AF Kalinathan, Lekshmi
   Kathavarayan, Ruba Soundar
   Nagendram, Dinakaran
   Vij, Mukul
   Rela, Mohamed
TI Segmentation of hepatocellular carcinoma and dysplastic liver tumors in
   histopathology images using area based adaptive expectation maximization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Histopatholgy images; Hepatocellular carcinoma; Dysplasia;
   Hepatic lesion; Adaptive EM
ID HUMAN HEPATOCARCINOGENESIS; ADENOMATOUS HYPERPLASIA; OBJECT RECOGNITION;
   CELL DYSPLASIA; LESIONS
AB The differentiation of a cluster of nuclei and multi-nucleation is a critical issue in automated diagnosis systems. Due to the similarities between said clusters and malignant nuclei, misclassification of these regions can affect the automated systems' final decision. In this paper, a method for differentiating clusters from multi nucleated cells in histopathological images is proposed. Hepatocellular Carcinoma(HCC) and Dysplasia are characterized by cellular and nuclear enlargement, nuclear pleomorphism and multinucleation, which possess prominent threat Data was obtained from Global Hospital and Research Center from patients diagnosed with Hepatocellular Carcinoma and Dysplasia. This paper introduces a hybrid diagnosis method that uses texture, layout and context features of nuclei and cytoplastic cells in order to enhance the poor diagnosis of liver tumors in Infra Red (IR) images. We propose a Area based Adaptive Expectation Maximization(EM) that grows the clusters, which avoids the need for initial cluster selection in order to obtain texton maps of nuclei and cytoplasm. A linear regression model of nuclei and cytoplastic changes were built by incorporating the aforementioned features efficiently. The proposed method provides better classification and segmentation accuracy of nuclei and extra nuclear content in HCC and dysplasia, compared to the state-of-the-art methods like convolutional networks and classical methods like Adaptive K means and EM method in constant time. In conclusion, this system detects the malignant cells and the highly eligible precancerous cells which is cost effective and reproducible.
C1 [Kalinathan, Lekshmi] Anna Univ, SSN Coll Engn, Madras, Tamil Nadu, India.
   [Kathavarayan, Ruba Soundar] Anna Univ, PSR Engn Coll, Sivakasi, India.
   [Nagendram, Dinakaran] Melmaruvathur Adhiparasakthi Inst Med Sci & Res, Dept Med Gastroenterol, Melmaruvathur, India.
   [Vij, Mukul] Global Hosp & Res Ctr, Madras, Tamil Nadu, India.
   [Rela, Mohamed] Kings Coll Hosp London, London, England.
C3 Anna University; Anna University Chennai; SSN College of Engineering;
   Anna University; King's College Hospital NHS Foundation Trust; King's
   College Hospital
RP Kalinathan, L (corresponding author), Anna Univ, SSN Coll Engn, Madras, Tamil Nadu, India.
EM lekshmik@ssn.edu.in; rubasoundar@yahoo.com; nagudeena@gmail.com;
   mukul.vij.path@gmail.com
RI Kathavarayan, Ruba Soundar/X-4741-2019; vij, mukul/Y-9635-2019
OI Kathavarayan, Ruba Soundar/0000-0003-1300-6519; vij,
   mukul/0000-0003-0149-0294
CR ANTHONY PP, 1973, J CLIN PATHOL, V26, P217, DOI 10.1136/jcp.26.3.217
   ARAKAWA M, 1986, GASTROENTEROLOGY, V91, P198, DOI 10.1016/0016-5085(86)90458-0
   Bani MR, 2009, EJSO-EUR J SURG ONC, V35, P32, DOI 10.1016/j.ejso.2008.04.008
   Basu M, 2002, IEEE T SYST MAN CY C, V32, P252, DOI 10.1109/TSMCC.2002.804448
   Bhatia SK, 2004, FLAIRS C, P695
   Bruix J, 2006, SCHIFFS DIS LIVER
   Casciaro S, 2012, IEEE SENS J, V12, P464, DOI 10.1109/JSEN.2011.2108281
   Chen ZM, 2013, J PHYS CHEM B, V117, P12442, DOI 10.1021/jp4073087
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fernandez DC, 2005, NAT BIOTECHNOL, V23, P469, DOI 10.1038/nbt1080
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Hydroglou P, 2007, GASTROENTEROL CLIN N, V36, P867, DOI 10.1016/j.gtc.2007.08.010
   Hytiroglou P, 2004, SEMIN LIVER DIS, V24, P65
   Kabade S., 2013, Int J Comput Sci Eng Technol, V4, P524
   Kojiro M, 2009, HEPATOLOGY, V49, P658, DOI 10.1002/hep.22709
   Konishi S, 2000, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.2000.855809
   Kuang ZH, 2012, PROC CVPR IEEE, P590, DOI 10.1109/CVPR.2012.6247725
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Long Jonathan, 2015, P IEEE CVPR15
   Malik Jitendra, 2015, P IEEE CVPR15
   Marchio A, 2001, J CLIN PATHOL-MOL PA, V54, P270, DOI 10.1136/mp.54.4.270
   Marengo A, 2016, CLIN LIVER DIS, V20, P313, DOI 10.1016/j.cld.2015.10.010
   Moon N, 2002, INT C PATT RECOG, P528, DOI 10.1109/ICPR.2002.1044787
   NAKANUMA Y, 1993, VIRCHOWS ARCH A, V422, P17, DOI 10.1007/BF01605128
   Patel B.C., 2010, Int. J. Comput. Appl., V10, DOI DOI 10.5120/1467-1982
   Plentz RR, 2007, HEPATOLOGY, V45, P968, DOI 10.1002/hep.21552
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Roberts LR, 2009, TXB GASTROENTEROLOGY, V2, P2386
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sakamoto M, 1998, JPN J CLIN ONCOL, V28, P604, DOI 10.1093/jjco/28.10.604
   Schiller DE, 2008, ANN SURG ONCOL, V15, P833, DOI 10.1245/s10434-007-9711-2
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   TAKAYAMA T, 1990, LANCET, V336, P1150, DOI 10.1016/0140-6736(90)92768-D
   Tsai A, 2001, OPT ENG, V40, P1287, DOI 10.1117/1.1385168
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   WANLESS IR, 1995, HEPATOLOGY, V22, P983, DOI 10.1002/hep.1840220341
NR 37
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1761
EP 1782
DI 10.1007/s11042-016-4260-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400013
DA 2024-07-18
ER

PT J
AU Lisanti, G
   Karaman, S
   Pezzatini, D
   Del Bimbo, A
AF Lisanti, Giuseppe
   Karaman, Svebor
   Pezzatini, Daniele
   Del Bimbo, Alberto
TI A multi-camera image processing and visualization system for train
   safety assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE System; Machine vision; Train; Safety
AB In this paper we present a machine vision system to efficiently monitor, analyse and present visual data acquired from a railway overhead gantry equipped with multiple cameras. This solution aims to improve the safety of daily life railway transportation in a two-fold manner: (1) by estimating multiple safety requirements using image analysis algorithms that can process large imagery of trains (2) by helping train safety operators to detect any possible malfunction on a train. The system exploits high-rate visible and thermal cameras that observe a train passing under a railway overhead gantry. The machine vision system is composed of three principal modules: (1) an automatic wagon identification system, recognizing the wagon ID according to the UIC classification of railway coaches; (2) a system for the detection and localization of the pantograph of the train; (3) a temperature monitoring system. These three machine vision modules process batch trains sequences and their resulting analysis are presented to an operator using a multitouch user interface.
C1 [Lisanti, Giuseppe; Pezzatini, Daniele; Del Bimbo, Alberto] Univ Florence, MICC, Florence, Italy.
   [Karaman, Svebor] Columbia Univ, Dept Elect Engn, Digital Video & Multimedia Lab DVMM Lab, New York, NY 10027 USA.
C3 University of Florence; Columbia University
RP Lisanti, G (corresponding author), Univ Florence, MICC, Florence, Italy.
EM giuseppe.lisanti@unifi.it; svebor.karaman@columbia.edu;
   daniele.pezzatini@unifi.it; alberto.delbimbo@unifi.it
RI Lisanti, Giuseppe/AAG-8699-2020; Karaman, Svebor/I-4929-2019
OI Lisanti, Giuseppe/0000-0002-0785-9972; Karaman,
   Svebor/0000-0002-2496-5822
FU Integrated Intermodal System for Security and Signaling on Rail (SISSI)
   - Regione Toscana (Italy) under the PAR FAS program
FX This work was supported by the Integrated Intermodal System for Security
   and Signaling on Rail (SISSI) project, funded by Regione Toscana (Italy)
   under thePAR FAS 2007-2013 program (P.I.R. 1.1.B, Action 1.1). We also
   thank Andrew D. Bagdanov and Iacopo Masi for their support in the
   project realization.
CR Andria G, 2014, P IMEKO TC4 INT S IN
   [Anonymous], 1994, Usability Inspections Methods
   [Anonymous], 2013, BBC News
   [Anonymous], 2015, INT C DOC AN REC
   [Anonymous], 2009, THESIS U PRETORIA
   Baraldi S, 2008, MULTIMED TOOLS APPL, V38, P385, DOI 10.1007/s11042-007-0195-7
   Beck F, 1973, TECH REP
   Bjorneseth FB, 2012, INT J HUM-COMPUT ST, V70, P729, DOI 10.1016/j.ijhcs.2012.06.001
   Brown M., 2003, P INT C COMP VIS
   Camargo LFM, 2011, P JOINT RAIL C
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen H, 2011, P INT C IM PROC
   Del Bimbo A, 2011, P INT C ADV VID SIGN
   Del Bimbo A, 2009, P INT C COMP VIS WOR
   Delgado B, 2014, P NAT C AER EL
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forlines C, 2007, P C HUM FACT COMP SY
   Fumagalli L, 2012, TECH CHAP MULTIFUNCT
   Kae A, 2010, P INT C COMP VIS PAT
   Kazanskiy N. L., 2015, Pattern Recognition and Image Analysis, V25, P215, DOI 10.1134/S1054661815020133
   Kin K, 2009, P C GRAPH INT
   Landucci G, 2011, J LOSS PREVENT PROC, V24, P466, DOI 10.1016/j.jlp.2011.04.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Muja M., 2009, P INT C COMP VIS THE
   Nielsen J, 1993, P C HUM FACT COMP SY
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pu Y., 2014, Inf. Technol. J., V13, P2611
   Sacchi M, 2011, P INT C PANT CAT INT
   Schupfer H, 2001, P INT C SAF ROAD RAI
   Spencer R, 2000, P C HUM FACT COMP SY
   Stelzer A, 2014, P INT C HUM COMP INT
   Teng Z, 2016, MULTIMED TOOLS APPL, V75, P2473, DOI 10.1007/s11042-015-2654-x
   Thimbleby H, 2007, P WORKSH INT SYST DE
   Weichselbaum J, 2013, COMPUT IND, V64, P1209, DOI 10.1016/j.compind.2013.03.015
   Zahler T, 2008, P INT C SYST SAF
NR 37
TC 8
Z9 8
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1583
EP 1604
DI 10.1007/s11042-017-4351-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Van Canneyt, S
   Leroux, P
   Dhoedt, B
   Demeester, T
AF Van Canneyt, Steven
   Leroux, Philip
   Dhoedt, Bart
   Demeester, Thomas
TI Modeling and predicting the popularity of online news based on temporal
   and content-related features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online news; Popularity modeling; Popularity prediction; Regression;
   Feature engineering
AB As the market of globally available online news is large and still growing, there is a strong competition between online publishers in order to reach the largest possible audience. Therefore an intelligent online publishing strategy is of the highest importance to publishers. A prerequisite for being able to optimize any online strategy, is to have trustworthy predictions of how popular new online content may become. This paper presents a novel methodology to model and predict the popularity of online news. We first introduce a new strategy and mathematical model to capture view patterns of online news. After a thorough analysis of such view patterns, we show that well-chosen base functions lead to suitable models, and show how the influence of day versus night on the total view patterns can be taken into account to further increase the accuracy, without leading to more complex models. Second, we turn to the prediction of future popularity, given recently published content. By means of a new real-world dataset, we show that the combination of features related to content, meta-data, and the temporal behavior leads to significantly improved predictions, compared to existing approaches which only consider features based on the historical popularity of the considered articles. Whereas traditionally linear regression is used for the application under study, we show that the more expressive gradient tree boosting method proves beneficial for predicting news popularity.
C1 [Van Canneyt, Steven; Leroux, Philip; Dhoedt, Bart; Demeester, Thomas] Ghent Univ iMinds, Dept Informat Technol, Ghent, Belgium.
C3 Ghent University; IMEC
RP Van Canneyt, S (corresponding author), Ghent Univ iMinds, Dept Informat Technol, Ghent, Belgium.
EM steven.vancanneyt@ugent.be; philip.leroux@ugent.be;
   bart.dhoedt@ugent.be; thomas.demeester@ugent.be
RI Demeester, Thomas/I-6382-2012
OI Demeester, Thomas/0000-0002-9901-5768
FU IWT; Agency for Innovation by Science and Technology in Flanders (IWT)
FX We thank Ke Zhou for useful suggestions on drafts of the manuscript.
   Steven Van Canneyt is funded by a Ph.D. grant of the Agency for
   Innovation by Science and Technology in Flanders (IWT). Part of the
   presented research was performed within the MIX-ICON project PROVIDENCE,
   facilitated by iMinds-Media and funded by the IWT.
CR [Anonymous], 2009, Proceedings of the 18th ACM conference on Information and knowledge management, DOI 10.1145/1645953.1646225
   [Anonymous], 2014, Journal of Computational Information Systems
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI DOI 10.1145/2433396.2433443
   Arapakis I, 2014, LECT NOTES COMPUT SC, V8851, P290, DOI 10.1007/978-3-319-13734-6_21
   Bandari R., 2012, ICWSM, P26
   Barber B, 2012, BAYESIAN REASONING M
   Berger J, 2012, J MARKETING RES, V49, P192, DOI 10.1509/jmr.10.0353
   Castillo C., 2014, P 17 ACM C COMP SUPP, P211, DOI [10.1145/2531602.2531623, DOI 10.1145/2531602.2531623]
   Cheng ALH, 2014, TECHNICAL REPORT
   DeGroot M., 2010, PROBABILITY STAT
   Deleu J, 2012, P 12 DUTCH BELG INF, P38
   Figueiredo F, 2014, ECML PKDD DISCOVERY, P1
   Kaltenbrunner A, 2007, LA-WEB 2007: 5TH LATIN AMERICAN WEB CONGRESS, PROCEEDINGS, P57, DOI 10.1109/LA-Web.2007.21
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Oghina Andrei, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P503, DOI 10.1007/978-3-642-28997-2_51
   Sakai T., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P525, DOI 10.1145/1148170.1148261
   Su-Do Kim, 2011, Proceedings of the 2011 IEEE 11th International Conference on Computer and Information Technology (CIT 2011), P449, DOI 10.1109/CIT.2011.104
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   Tatar A, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0174-8
   Tsagkias M, 2010, LECT NOTES COMPUT SC, V5993, P191, DOI 10.1007/978-3-642-12275-0_19
NR 20
TC 13
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1409
EP 1436
DI 10.1007/s11042-017-4348-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400058
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Hu, WJ
   Huang, YB
   Qiao, SB
AF Zhang, Qiu-yu
   Hu, Wen-jin
   Huang, Yi-bo
   Qiao, Si-bin
TI An efficient perceptual hashing based on improved spectral entropy for
   speech authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech authentication; Perceptual hashing; Improved spectral entropy;
   Linear prediction-minimummean squared error (LP-MMSE); Teager energy
   operator; Sub-band spectral line
ID NONNEGATIVE MATRIX FACTORIZATION; ROBUST; COEFFICIENTS
AB Combined with the linear prediction-minimum mean squared error (LP-MMSE), an efficient perceptual hashing algorithm based on improved spectral entropy for speech authentication was proposed in this paper. The linear prediction analysis is conducted on speech signal after preprocessing, framing and adding windows, and obtained the minimum mean squared error coefficient matrix. And then, the spectral entropy parameter matrix of each frame is calculated by using improved spectral entropy method. And the final binary perceptual hashing sequence is generated based on the above two matrices, and the speech authentication is completed. Comparing the experimental results of combining the Teager energy operator (TEO) with the linear predictive coefficients (LPC), LP-MMSE and line spectrum pair (LSP) coefficient respectively, it can be seen that the proposed algorithm had a good compromise between robustness, discrimination and authentication efficiency, and the proposed algorithm can meet the requirement of real-time speech authentication in speech communication. Experimental results show that the proposed algorithm was better than other existing methods in compactness.
C1 [Zhang, Qiu-yu; Hu, Wen-jin; Qiao, Si-bin] Lanzhou Univ Technol, Sch Comp & Commun, 287,Lan Gong Ping Rd, Lanzhou 730050, Gansu, Peoples R China.
   [Huang, Yi-bo] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Gansu, Peoples R China.
C3 Lanzhou University of Technology; Northwest Normal University - China
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, 287,Lan Gong Ping Rd, Lanzhou 730050, Gansu, Peoples R China.
EM zhangqylz@163.com; 295105067@qq.com; Huangyibo1982@163.com;
   742718264@qq.com
RI Zhang, Qiu-yu/V-9223-2019
OI Zhang, Qiu-yu/0000-0003-1488-388X
FU National Natural Science Foundation of China [61363078]; Natural Science
   Foundation of Gansu Province of China [1310RJYA004]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61363078), the Natural Science Foundation of Gansu Province
   of China (No. 1310RJYA004). The authors would like to thank the
   anonymous reviewers for their helpful comments and suggestions.
CR Chen N, 2013, ELECTRON LETT, V49, P7, DOI 10.1049/el.2012.3812
   Chen N, 2011, IET INFORM SECUR, V5, P19, DOI 10.1049/iet-ifs.2010.0097
   Chen N, 2010, IET COMMUN, V4, P1722, DOI 10.1049/iet-com.2009.0749
   Chen N, 2010, ETRI J, V32, P345, DOI 10.4218/etrij.10.0209.0309
   Gao H, 2012, INT CONF SIGN PROCES, P567, DOI 10.1109/ICoSP.2012.6491552
   Grutzek G., 2012, P SPEECH COMM 10 ITG, P1
   Haitsma J., 2002, P ISMIR 2002 3 INT C, P107
   Hongxue Wang, 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P763, DOI 10.1109/ICALIP.2012.6376716
   Huan Zhao, 2011, Journal of Multimedia, V6, P308, DOI 10.4304/jmm.6.3.308-315
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Huang Y.B., 2014, TELKOMNIKA INDONESIA, V12, P3214
   Huang Yibo, 2015, Journal of Huazhong University of Science and Technology (Natural Science Edition), V43, P124, DOI 10.13245/j.hust.150226
   Jiao Yan, 2010, THESIS
   Jiao YH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P410, DOI 10.1109/IIH-MSP.2008.210
   Jiao YH, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P295
   Jiao YH, 2009, IEEE SIGNAL PROC LET, V16, P818, DOI 10.1109/LSP.2009.2025827
   Jijun D., 2011, SMART SUST CIT ICSSC, P1, DOI DOI 10.1049/CP.2011.0301
   [李金凤 Li Jinfeng], 2015, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V38, P89
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   Nathwani K, 2014, COMM NCC 2014 20 NAT, P1, DOI [10.1109/NCC.2014.6811324, DOI 10.1109/NCC.2014.6811324]
   Nurminen J, 2013, IEEE INT SYMP CIRC S, P313, DOI 10.1109/ISCAS.2013.6571844
   Padaki H., 2013, NATL C COMM NCC, P1, DOI [10.1109/NCC.2013.6487990, DOI 10.1109/NCC.2013.6487990]
   Prathosh AP, 2013, IEEE T AUDIO SPEECH, V21, P2471, DOI 10.1109/TASL.2013.2273717
   SONG Zhiyong, 2013, APPL MATLAB SPEECH S
   Sun Y., 2016, J INFORM HIDING MULT, V7, P1006
   Wang KC, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL COMMUNICATION, P423, DOI 10.1109/ISUC.2008.55
   [王琳 Wang Lin], 2010, [计算机仿真, Computer Simulation], V27, P373
   Yuan Yujin, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P765, DOI 10.1109/ICICISYS.2010.5658337
   Zhang LH, 2005, J NANJING U POSTS TE, V25, P1
   Zhang QY, 2015, INT J INNOV COMPUT I, V11, P2159
   [张秋余 Zhang Qiuyu], 2016, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V39, P77
NR 31
TC 12
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1555
EP 1581
DI 10.1007/s11042-017-4381-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400004
DA 2024-07-18
ER

PT J
AU Gianini, G
   Rizzi, A
AF Gianini, Gabriele
   Rizzi, Alessandro
TI A fuzzy set approach to Retinex spray sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy sets; Image enhancement; Retinex theory
ID VARIATIONAL FRAMEWORK; COLOR; IMPLEMENTATION; ALGORITHM; DRIVEN; ISSUES;
   MODEL
AB The color sensation at a point, for the Human Visual System (HVS), derives not only from the color stimulus at that point, but also from the relative spatial arrangement of the stimuli in the image. Based on this observation, the Retinex algorithm, an early and widely studied model of the HVS, determines the output - for each chromatic channel - by rescaling the input intensity of a pixel w.r.t. a reference white level, computed by sampling the brightest points in the neighborhood of the target pixel. In this work, we argue that several elements, inherent to the above observation, can benefit from a fuzzy formalization. We show that the adoption of the fuzzy formalism allows to better encode the mutual influence of pixels. Overall, the fuzzy formalization can provide a general framework for designing and tuning image enhancement algorithms inspired by the HVS. We demonstrate its use by the construction of a fuzzy version of the point-sampling algorithm Random Spray Retinex (RSR). Using RSR as a guide, we build a more efficient algorithm, based on the fact that each spray (a set of sampled points used in RSR to determine the reference white of a specific target) can be assumed to belong to some degree to all the target pixels of the image, provided that a suitable membership function is defined. The features of this alternative formalization of RSR are discussed here, using synthetic and natural test images.
C1 [Gianini, Gabriele] Univ Milan, Dipartimento Informat, Via Bramante 65, I-26013 Crema, CR, Italy.
   [Rizzi, Alessandro] Univ Milan, Dipartimento Informat, Via Comelico 39-41, I-20135 Milan, MI, Italy.
C3 University of Milan; University of Milan
RP Gianini, G (corresponding author), Univ Milan, Dipartimento Informat, Via Bramante 65, I-26013 Crema, CR, Italy.
EM gabriele.gianini@unimi.it; alessandro.rizzi@unimi.it
RI Gianini, Gabriele/M-5195-2014
OI Gianini, Gabriele/0000-0001-5186-0199
CR [Anonymous], 2000, Fuzzy image enhancement: an overview, fuzzy techniques in image processing
   Banic N, 2015, J OPT SOC AM A, V32, P2136, DOI 10.1364/JOSAA.32.002136
   Banic N, 2013, IEEE SIGNAL PROC LET, V20, P1240, DOI 10.1109/LSP.2013.2285960
   Bertalmío M, 2007, IEEE T IMAGE PROCESS, V16, P1058, DOI 10.1109/TIP.2007.891777
   Bertalmío M, 2009, J PHYSIOL-PARIS, V103, P69, DOI 10.1016/j.jphysparis.2009.05.001
   Bertalmío M, 2009, INT J COMPUT VISION, V83, P101, DOI 10.1007/s11263-009-0221-5
   Dong-Guk Hwang, 2012, Convergence and Hybrid Information Technology. Proceedings of the 6th International Conference (ICHIT 2012), P381, DOI 10.1007/978-3-642-32645-5_48
   Elad M, 2005, LECT NOTES COMPUT SC, V3459, P217
   Frankle JA, 1983, US Patent, Patent No. 4,384,336
   Fu Bin, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P2447, DOI 10.1109/ICINFA.2010.5512278
   Funt B, 2004, J ELECTRON IMAGING, V13, P48, DOI 10.1117/1.1636761
   Gatta C, 2007, INT J IMAG SYST TECH, V17, P285, DOI 10.1002/ima.20118
   Gianini G, 2016, ELECT IMAGING, V28, P1
   Gianini G, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.031206
   Gianini G, 2016, J OPT SOC AM A, V33, P2396, DOI 10.1364/JOSAA.33.002396
   Gianini G, 2016, INFORM SCIENCES, V327, P149, DOI 10.1016/j.ins.2015.08.015
   Gianini G, 2014, J OPT SOC AM A, V31, P2663, DOI 10.1364/JOSAA.31.002663
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Kolås O, 2011, J IMAGING SCI TECHN, V55, DOI 10.2352/J.ImagingSci.Technol.2011.55.4.040503
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lecca M, 2017, J OPTICAL S IN PRESS
   Lecca M, 2016, J OPT SOC AM A, V33, P31, DOI 10.1364/JOSAA.33.000031
   Lecca M, 2015, J OPT SOC AM A, V32, P1876, DOI 10.1364/JOSAA.32.001876
   Ma W, 2012, INVERSE PROBLEMS IMA, V6
   Marini D, 2000, IMAGE VISION COMPUT, V18, P1005, DOI 10.1016/S0262-8856(00)00037-8
   McCann J, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P1
   McCann J.J., 2011, ART SCI HDR IMAGING
   Montagna R, 2011, J OPT SOC AM A, V28, P1677, DOI 10.1364/JOSAA.28.001677
   Morel JM, 2010, IEEE T IMAGE PROCESS, V19, P2825, DOI 10.1109/TIP.2010.2049239
   Ng MK, 2011, SIAM J IMAGING SCI, V4, P345, DOI 10.1137/100806588
   Nguyen HungT., 2005, 1 COURSE FUZZY LOGIC, V3
   PAL SK, 1980, ELECTRON LETT, V16, P376, DOI 10.1049/el:19800267
   Palma-Amestoy R, 2009, IEEE T PATTERN ANAL, V31, P458, DOI 10.1109/TPAMI.2008.86
   Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613
   Provenzi E, 2008, IEEE T PATTERN ANAL, V30, P1757, DOI 10.1109/TPAMI.2007.70827
   Provenzi E, 2007, IEEE T IMAGE PROCESS, V16, P162, DOI 10.1109/TIP.2006.884946
   Rizzi A, 2004, J ELECTRON IMAGING, V13, P75, DOI 10.1117/1.1635366
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Rizzi A., 2016, Electron. Imaging, V2016, P1
   Rizzi A, 2003, CONTRAST EFFECTS LOC
   Rizzi A, 2007, P EL IM 2007 CAL US
   Rizzi A, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.031207
   SHAKED D, 2002, HPL200274R1
   Shaked D, 2005, U.S. Patent, Patent No. 20,050,073,702
   Shin KY, 2014, SENSORS-BASEL, V14, P3095, DOI 10.3390/s140203095
   Simone Gabriele, 2012, CGIV 2012. 6th European Conference on Colour in Graphics, Imaging, and Vision, P176
   Simone G, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013006
   Sobol R, 2004, J ELECTRON IMAGING, V13, P65, DOI 10.1117/1.1636762
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zosso D, 2013, IS T SPIE ELECT IMAG, V865, P702
NR 50
TC 10
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24723
EP 24748
DI 10.1007/s11042-017-4877-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300009
DA 2024-07-18
ER

PT J
AU Lee, S
   Chang, JH
AF Lee, Soojeong
   Chang, Joon-Hyuk
TI Spectral difference for statistical model-based speech enhancement in
   speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Noise reduction; Speech recognition; Spectral
   difference
ID PRIORI SNR ESTIMATOR; SOFT-DECISION; ENVIRONMENTS; FILTER
AB In this paper, we propose a statistical model-based speech enhancement technique using the spectral difference scheme for the speech recognition in virtual reality. In the analyzing step, two principal parameters, the weighting parameter in the decision-directed (DD) method and the long-term smoothing parameter in noise estimation, are uniquely determined as optimal operating points according to the spectral difference under various noise conditions. These optimal operating points, which are specific according to different spectral differences, are estimated based on the composite measure, which is a relevant criterion in terms of speech quality. An efficient mapping function is also presented to provide an index of the metric table associated with the spectral difference so that operating points can be determined according to various noise conditions for an on-line step. In the on-line speech enhancement step, different parameters are chosen on a frame-by-frame basis under the metric table of the spectral difference. The performance of the proposed method is evaluated using objective and subjective speech quality measures in various noise environments. Our experimental results show that the proposed algorithm yields better performances than conventional algorithms.
C1 [Lee, Soojeong; Chang, Joon-Hyuk] Hanyang Univ, Dept Elect Engn, Seoul 133791, South Korea.
C3 Hanyang University
RP Chang, JH (corresponding author), Hanyang Univ, Dept Elect Engn, Seoul 133791, South Korea.
EM leesoo86@hanyang.ac.kr; jchang@hanyang.ac.kr
FU National Research Foundation (NRF) of Korea [2014R1A2A1A10049735]
FX This work was also supported by National Research Foundation (NRF) of
   Korea grant funded by (2014R1A2A1A10049735).
CR [Anonymous], 1996, TIAEIAIS127
   Chang JH, 2006, SIGNAL PROCESS, V86, P1089, DOI 10.1016/j.sigpro.2005.07.025
   Choi JH, 2012, SPEECH COMMUN, V54, P477, DOI 10.1016/j.specom.2011.10.009
   Choi JH, 2011, IEICE T FUND ELECTR, VE94A, P2031, DOI 10.1587/transfun.E94.A.2031
   Cohen I, 2001, SIGNAL PROCESS, V81, P2403, DOI 10.1016/S0165-1684(01)00128-1
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   ITU, 2000, PERC EV SPEECH QUAL
   Kim NS, 2000, IEEE SIGNAL PROC LET, V7, P108, DOI 10.1109/97.841154
   Krishnamurthy N, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1431
   Lee SJ, 2008, INT J CONTROL AUTOM, V6, P818
   Lee S, 2016, IEEE T IND INFORM, V12, P2269, DOI 10.1109/TII.2015.2484278
   Lee S, 2016, J SYST ARCHITECT, V64, P76, DOI 10.1016/j.sysarc.2015.10.007
   Lee S, 2014, DIGIT SIGNAL PROCESS, V30, P154, DOI 10.1016/j.dsp.2014.04.001
   MCAULAY RJ, 1980, IEEE T ACOUST SPEECH, V28, P137, DOI 10.1109/TASSP.1980.1163394
   Park YS, 2007, IEICE T COMMUN, VE90B, P2182, DOI 10.1093/ietcom/e90-b.8.2182
   Sangwan A., 2007, P INT 2007 ANTW BELG, P2929
   Westerlund N, 2005, SIGNAL PROCESS, V85, P1089, DOI 10.1016/j.sigpro.2005.01.004
NR 18
TC 1
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24917
EP 24929
DI 10.1007/s11042-016-4122-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300019
DA 2024-07-18
ER

PT J
AU Ryu, ES
   Ryu, S
AF Ryu, Eun-Seok
   Ryu, SunJung
TI Robust real-time UHD video streaming system using scalable high
   efficiency video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust video streaming; Picture priority; Error concealment; Scalable
   high efficiency video coding
ID AWARE; HEVC; TRANSMISSION
AB With a new video coding standard high efficiency video coding (HEVC), the ultra high definition (UHD) TV service with robust video streaming technology is emerging in the TV industry. This paper addresses the system architecture for the UHD video streaming and proposes three main ideas: (i) picture prioritization method, (ii) error concealment mode signaling (ECMS), and (iii) Tile complexity-based parallel video processing. In the experiments using HEVC reference model conducted, the proposed picture prioritization method shows the gains in video quality from 2.2 to 7.5 dB in Y-PSNR, and the error concealment mode signaling gains from 0.2 to 2.5 dB in Y-PSNR, with corresponding subjective improvements. In addition, proposed parallel processing method for real-time decoding shows around 20% decoding speed up gain.
C1 [Ryu, Eun-Seok] Gachon Univ, Dept Comp Engn, 1342 Seongnam Daero, Seongnam Si 13120, Gyeonggi Do, South Korea.
   [Ryu, SunJung] Dankook Univ, Dept French, 29 Anseodong, Dongnamgu 330714, Cheonan, South Korea.
C3 Gachon University; Dankook University
RP Ryu, S (corresponding author), Dankook Univ, Dept French, 29 Anseodong, Dongnamgu 330714, Cheonan, South Korea.
EM esryu@gachon.ac.kr; ryuhappy@dankook.ac.kr
RI Ryu, Eun-Seok/AAA-3536-2021
FU National Research Foundation of Korea(NRF) - Ministry of Science, ICT &
   Future Planning [NRF-2015R1C1A1A02037743]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning (NRF-2015R1C1A1A02037743).
CR Ahn Heejune, 2013, [The Journal of Korean Institute of Communications and Information Sciences B, 한국통신학회논문지B], V38, P46
   [Anonymous], IEEE INT C MULT EXP
   Baik H, 2015, IEEE IMAGE PROC, P4298, DOI 10.1109/ICIP.2015.7351617
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chen J., 2013, 13 JOINT COLL TEAM V
   Guo Y, 2009, IEEE T CIRC SYST VID, V19, P781, DOI 10.1109/TCSVT.2009.2017311
   Hellge C, 2008, IEEE IMAGE PROC, P2304, DOI 10.1109/ICIP.2008.4712252
   Hye-Soo Kim, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P441, DOI 10.1109/ICCE.2010.5418744
   Mansour H, 2008, INT CONF ACOUST SPEE, P1129, DOI 10.1109/ICASSP.2008.4517813
   Martini MG, 2007, IEEE COMMUN MAG, V45, P84, DOI 10.1109/MCOM.2007.284542
   Ryu E, 2014, U. S. Patent Application, Patent No. [13/931,362, 13/]
   Ryu ES, 2013, ELECTRON LETT, V49, P1268, DOI 10.1049/el.2013.2169
   Ryu ES, 2012, JCTVC J0063 STOCKH M
   Ryu ES, 2013, ISO IEC JTC1 SC29 WG
   Ryu ES, 2015, 2015 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC), P1356, DOI 10.1109/ICTC.2015.7354814
   Ryu ES, 2015, AEU-INT J ELECTRON C, V69, P1070, DOI 10.1016/j.aeue.2015.03.008
   Ryu ES, 2011, IEEE T CONSUM ELECTR, V57, P1652, DOI 10.1109/TCE.2011.6131138
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2004, H 264 AVC ADV VIDEO
   Ye Y, 2014, U. S. Patent Application, Patent No. [13/937,645, 13/]
   Ye Y, 2014, IEEE MULTIMEDIA, V21, P58, DOI 10.1109/MMUL.2014.47
   Yoo S., 2015, P WORKSH POW AW COMP, P1
NR 22
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25511
EP 25527
DI 10.1007/s11042-017-4835-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300051
DA 2024-07-18
ER

PT J
AU Vaidya, SP
   Mouli, PVSSRC
AF Vaidya, Prasanth S.
   Mouli, Chandra P. V. S. S. R.
TI A robust semi-blind watermarking for color images based on multiple
   decompositions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DWT; CT; Schur decomposition; Singular value decomposition (SVD); Arnold
   transform
ID TRANSFORM; MOMENTS
AB In this paper, a robust semi-blind watermarking scheme for color images, based on multiple decompositions is proposed to preserve the copyrights of the owner. Using multiple decompositions, the gray watermark is embedded into a host color image. Prior to that, to enhance security the gray watermark is encrypted with Arnold transform and SVD by generating secret keys. The luminance component of the given host image is subjected to discrete wavelet transform(DWT), contourlet transform(CT), Schur decomposition and singular value decomposition(SVD) in sequence and finally the watermark is embedded. In the semi-blind extraction process, the watermark is extracted without the help of the original host image. Experimental results show that the proposed watermarking scheme has better visual imperceptibility and high robustness against image & signal processing attacks compared to other methods.
C1 [Vaidya, Prasanth S.; Mouli, Chandra P. V. S. S. R.] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Mouli, PVSSRC (corresponding author), VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM svprasanth.vaidya2014@vit.ac.in; chandramouli@vit.ac.in
RI Pvssr, Chandra Mouli/L-1127-2019; sanivarapu, prasanth
   vaidya/Y-9058-2018
OI Pvssr, Chandra Mouli/0000-0001-7909-9733; sanivarapu, prasanth
   vaidya/0000-0002-8972-8860
CR ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P INT C COGN REC IEE
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], AEU INT J ELECT COMM
   [Anonymous], TECHNICAL REPORT
   [Anonymous], IEEE INT C IM PROC 2
   [Anonymous], 2003, The Oxford Dictionary of Statistical Terms
   Bhatnagar G, 2013, MULTIMED TOOLS APPL, V66, P179, DOI 10.1007/s11042-011-0788-z
   Do MN, 2003, IEEE T SIGNAL PROCES, V51, P2329, DOI 10.1109/TSP.2003.815389
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Mardanpour M, 2016, AEU-INT J ELECTRON C, V70, P790, DOI 10.1016/j.aeue.2016.03.004
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   PAIGE C, 1981, LINEAR ALGEBRA APPL, V41, P11, DOI 10.1016/0024-3795(81)90086-0
   Po DDY, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P262
   Ranjbar S, 2013, SIGNAL PROCESS-IMAGE, V28, P1526, DOI 10.1016/j.image.2013.07.002
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   SKILLING J, 1984, MON NOT R ASTRON SOC, V211, P111, DOI 10.1093/mnras/211.1.111
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Tang L, 2007, 2007 10 INT C INFORM, P1
   Wang XY, 2014, COMPUT ELECTR ENG, V40, P942, DOI 10.1016/j.compeleceng.2013.12.017
   Wang XY, 2012, APPL SOFT COMPUT, V12, P887, DOI 10.1016/j.asoc.2011.10.003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
   Yen E, 2010, EXPERT SYST APPL, V37, P4033, DOI 10.1016/j.eswa.2009.09.032
NR 32
TC 45
Z9 45
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25623
EP 25656
DI 10.1007/s11042-017-4355-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500006
DA 2024-07-18
ER

PT J
AU Wang, LF
   Pan, ZB
   Zhu, RX
AF Wang, Lingfei
   Pan, Zhibin
   Zhu, Ruoxin
TI A novel reversible data hiding scheme using SMVQ prediction index and
   multi-layer embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Side-match vector quantization (SMVQ);
   Codebook clustering; Predictive coding; Multi-layer embedding;
   Steganography
ID WATERMARKING ALGORITHM; VECTOR QUANTIZATION; EFFICIENT; IMAGES; TABLE
AB In this paper, a novel reversible data hiding scheme which utilizes SMVQ prediction indices to embed secret data is proposed. As a result, it improves Yang's work, which takes advantage of counts of indices in data embedding. Our approach enhances the prediction of SMVQ, resulting in a more concentrated distribution of indices. Based on the distribution of SMVQ-p indices, in the embedding process, three clusters (CL (0), CL (1) and CL (2)) are defined. Indices in CL (0) are employed to embed secret data and can support a high embedding capacity. Indices in cluster CL (1) are employed for supporting a lower bit rate. Indices in cluster CL (2) are utilized for lossless reconstruction. Experimental results indicate that lower bit rate and higher embedding efficiency are obtained after encoding and embedding processes by our approach. Furthermore, experimental results demonstrate that the proposed method outperforms other state-of-the-art reversible data hiding schemes as well.
C1 [Wang, Lingfei; Pan, Zhibin; Zhu, Ruoxin] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM Wang.lingfei@stu.xjtu.edu.cn; zbpan@mail.xjtu.edu.cn;
   Zhuruoxin1992@stu.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Key Laboratory of Spectral Imaging Technology,
   Chinese Academy of Sciences [LSIT201606D]; Key Science and Technology
   Program of Shaanxi Province [2016GY-097]; Industrial Program of Zhejiang
   Province [2016C31G4180003]
FX This work is supported in part by the Project Funded by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD), the Open Research Fund of Key Laboratory of Spectral Imaging
   Technology, Chinese Academy of Sciences (Grant No. LSIT201606D), the Key
   Science and Technology Program of Shaanxi Province (Grant No.
   2016GY-097) and the Industrial Program of Zhejiang Province (Grant No.
   2016C31G4180003).
CR BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang CC, 2007, J VIS COMMUN IMAGE R, V18, P207, DOI 10.1016/j.jvcir.2006.11.005
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Daemen J, 2001, DR DOBBS J, V26, P137
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Huang HC, 2002, IEICE T FUND ELECTR, VE85A, P1719
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   Lin Chih Yang, 2006, J COMPUT, V17, P3
   Ma XX, 2015, J VIS COMMUN IMAGE R, V30, P191, DOI 10.1016/j.jvcir.2015.04.009
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pan ZB, 2015, IET IMAGE PROCESS, V9, P22, DOI 10.1049/iet-ipr.2014.0310
   Qin C, 2015, SECUR COMMUN NETW, V8, P899, DOI 10.1002/sec.1046
   Shie SC, 2009, COMPUT STAND INTER, V31, P1143, DOI 10.1016/j.csi.2008.12.003
   Wang LF, 2014, J VIS COMMUN IMAGE R, V25, P454, DOI 10.1016/j.jvcir.2013.12.004
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wright M. A., 2001, Network Security, P11, DOI 10.1016/S1353-4858(01)01018-2
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xin Z, 2007, OPT LASER TECHNOL, V39, P1360, DOI 10.1016/j.optlastec.2006.11.002
   Yang B, 2005, Proceedings of the Fifth IASTED International Conference on Visualization, Imaging, and Image Processing, P298
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 32
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26225
EP 26248
DI 10.1007/s11042-016-4108-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500033
DA 2024-07-18
ER

PT J
AU Borràs, J
   Moreno, A
   Valls, A
AF Borras, Joan
   Moreno, Antonio
   Valls, Aida
TI Diversification of recommendations through semantic clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Decision support; Knowledge personalization and
   customization; Similarity measures
ID PERSONALIZED RECOMMENDATION; CONTEXT; DIVERSITY; FRAMEWORK; ACCURACY;
   TOURISM; SYSTEMS
AB Recommender systems aim to suggest lists of items that match accurately the user's preferences. In the last years it has been argued that the diversity of the recommendations also plays an important role in the overall satisfaction of the user. Increasing the diversity of the suggestions may be beneficial both for the user and for retailers. This paper provides a brief review of the most popular diversification mechanisms and it introduces two new ones (Cluster Random and Cluster Quadratic) based on the semantic clustering of the domain objects. It also shows how the level of diversification may be dynamically adapted to the variety in the preferences of the user. A thorough evaluation of the diversification mechanisms on a Tourism recommender has been performed, reaching the conclusion that the new Cluster Quadratic diversification method achieves very competitive levels of precision and recall, while keeping an acceptable computational cost.
C1 [Borras, Joan] Sci & Technol Pk Tourism & Leisure, C Joanot Martorell,15, Vila Seca 43480, Catalonia, Spain.
   [Moreno, Antonio; Valls, Aida] Univ Rovira & Virgili, ITAKA, Dept Engn Informat & Matemat, Ave Paisos Catalans,26, E-43007 Tarragona, Catalonia, Spain.
C3 Universitat Rovira i Virgili
RP Borràs, J (corresponding author), Sci & Technol Pk Tourism & Leisure, C Joanot Martorell,15, Vila Seca 43480, Catalonia, Spain.
EM joan.borras@pct-turisme.cat; antonio.moreno@urv.cat; aida.valls@urv.cat
RI Moreno, Antonio/N-6972-2019; Valls, Aida/F-4429-2015
OI Moreno, Antonio/0000-0003-3945-2314; Borras, Joan/0000-0002-3894-4010;
   Valls, Aida/0000-0003-3616-7809
FU Spanish research project SHADE [TIN-2012-34369]; SigTur/E-Destination
   project (FEDER European Regional Funds); SigTur/E-Destination project
   (Government of the Province of Tarragona); Science and Technology Park
   for Tourism and Leisure (Vila-Seca)
FX This research has been partially funded by the Spanish research project
   SHADE (TIN-2012-34369: Semantic and Hierarchical Attributes in Decision
   Making) and by the SigTur/E-Destination project (FEDER European Regional
   Funds and the Government of the Province of Tarragona). The work has
   been supported by the Science and Technology Park for Tourism and
   Leisure (Vila-Seca). The authors would like to acknowledge the
   contributions to the design and development of the system made by Dr.
   Salvador Anton-Clave and Dr. Paolo Russo.
CR Akiyama T., 2010, PRSAT@ RecSys, P3
   Alhamid MF, 2015, MULTIMED TOOLS APPL, V74, P11399, DOI 10.1007/s11042-014-2236-3
   [Anonymous], 2012, DIGITAL UNIVERSE 202
   [Anonymous], 1999, P 1999 DESCR LOG WOR
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], PEOPLE COMPUTERS
   [Anonymous], 2012, INT C INF PROC MAN U
   [Anonymous], THESIS
   Aytekin T, 2014, J INTELL INF SYST, V42, P1, DOI 10.1007/s10844-013-0252-9
   Bobadilla J, 2012, KNOWL-BASED SYST, V26, P225, DOI 10.1016/j.knosys.2011.07.021
   Borràs J, 2014, EXPERT SYST APPL, V41, P7370, DOI 10.1016/j.eswa.2014.06.007
   Candillier Laurent., 2012, Intelligent Systems, V5, P234
   Candillier Laurent., 2011, Proceedings of the 4th International Conference on Advances in Human-Oriented and Personalized Mechanisms, Technologies and Services (CENTRIC), P48
   CARDOSO J, 2005, W3C WORKSH FRAM SEM
   Cheng ZY, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1029, DOI 10.1145/2766462.2767869
   De Pessemier T, 2016, MULTIMED TOOLS APPL, P1
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2925, DOI 10.1007/s11042-013-1582-x
   Figueira J., 2005, MULTICRITERIA DECISI
   Gan MX, 2013, DECIS SUPPORT SYST, V55, P811, DOI 10.1016/j.dss.2013.03.006
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hussein T, 2014, USER MODEL USER-ADAP, V24, P121, DOI 10.1007/s11257-012-9134-z
   Iaquinta Leo, 2010, E-commerce, P229
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Marin L, 2014, KNOWL-BASED SYST, V56, P201, DOI 10.1016/j.knosys.2013.11.012
   Marin L, 2013, APPL INTELL, V39, P421, DOI 10.1007/s10489-012-0421-5
   Marin L, 2013, INFORM SCIENCES, V220, P5, DOI 10.1016/j.ins.2011.10.008
   Moreno A, 2013, FRONT ARTIF INTEL AP, V256, P263, DOI 10.3233/978-1-61499-320-9-263
   Moreno A, 2013, ENG APPL ARTIF INTEL, V26, P633, DOI 10.1016/j.engappai.2012.02.014
   Mouzhi Ge, 2010, P 4 ACM C REC SYST B, P257, DOI [10.1145/1864708.1864761, DOI 10.1145/1864708.1864761]
   Niemann K, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P955
   Ontañón S, 2012, MACH LEARN, V87, P57, DOI 10.1007/s10994-011-5274-3
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Petrovic I, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P631, DOI 10.1109/MIPRO.2015.7160349
   Porcel C, 2012, INFORM SCIENCES, V184, P1, DOI 10.1016/j.ins.2011.08.026
   Smyth B, 2001, LECT NOTES ARTIF INT, V2080, P347
   Vargas S, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P1211
   Wang HF, 2012, COMPUT OPER RES, V39, P1837, DOI 10.1016/j.cor.2010.03.011
   Zhang M, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P123
   Zhou T, 2010, P NATL ACAD SCI USA, V107, P4511, DOI 10.1073/pnas.1000488107
NR 40
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24165
EP 24201
DI 10.1007/s11042-016-4166-8
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700047
DA 2024-07-18
ER

PT J
AU Pan, SX
   Sun, WJ
   Zheng, ZG
AF Pan, Shu-xia
   Sun, Wang-jie
   Zheng, Zhigao
TI Video segmentation algorithm based on superpixel link weight model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation; Superpixel; Motion restriction; Over-segmentation
ID MOVING OBJECT SEGMENTATION
AB Based on the traditional segmentation algorithms, this paper proposes unsupervised video segmentation approach. The proposed algorithm applies superpixel to indicate the movement foreground and uses the static features of current frame and the relevant features of adjacent frames to compute the weight. It also brings in the mechanism of superpixel color features match restriction and motion relevance match restriction. The experiment result shows this algorithm can achieve the segmentation of video pictures and effectively solve the problem of over-segmentation.
C1 [Pan, Shu-xia] Jilin Med Univ, Sch Publ Hlth Coll, Jilin 132013, Jilin, Peoples R China.
   [Sun, Wang-jie] Jilin Inst Chem Technol, Sch Sci, Jilin 132022, Jilin, Peoples R China.
   [Zheng, Zhigao] Huazhong Univ Sci & Technol, Serv Comp Technol & Syst Lab, Cluster & Grid Comp Lab, Wuhan, Hubei, Peoples R China.
C3 Jilin Medical University; Jilin Institute of Chemical Technology;
   Huazhong University of Science & Technology
RP Sun, WJ (corresponding author), Jilin Inst Chem Technol, Sch Sci, Jilin 132022, Jilin, Peoples R China.
EM pan4652405@163.com; wangjie_sun@163.com; pkuwalter@gmail.com
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Boreczky JS, 1998, INT CONF ACOUST SPEE, P3741, DOI 10.1109/ICASSP.1998.679697
   Chen A.Y.C., 2011, IEEE Workshop on Applications of Computer Vision, P614
   Chen YM, 2011, IEEE T MULTIMEDIA, V13, P421, DOI 10.1109/TMM.2011.2127464
   Chen YM, 2010, IEEE INT CON MULTI, P760, DOI 10.1109/ICME.2010.5583034
   Chien SY, 2004, IEEE T MULTIMEDIA, V6, P732, DOI 10.1109/TMM.2004.834868
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Ishtiaq M, 2009, IACSIT-SC 2009: INTERNATIONAL ASSOCIATION OF COMPUTER SCIENCE AND INFORMATION TECHNOLOGY - SPRING CONFERENCE, P122, DOI 10.1109/IACSIT-SC.2009.114
   Ji Teng-fei, 2007, Journal of Jilin University (Information Science Edition), V25, P73
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li HL, 2007, IEEE T CIRC SYST VID, V17, P1742, DOI 10.1109/TCSVT.2007.903326
   Meier T, 1998, IEEE T CIRC SYST VID, V8, P525, DOI 10.1109/76.718500
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P782, DOI 10.1109/TCSVT.2004.828341
   Moore A., 2008, Survey of Coconut Rhinoceros Beetle Damage at the Pacific Islands Club Resort, Tumon Bay, P1
   Neri A, 1998, SIGNAL PROCESS, V66, P219, DOI 10.1016/S0165-1684(98)00007-3
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P19, DOI 10.1109/76.554415
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Zeng W, 2005, REAL-TIME IMAGING, V11, P290, DOI 10.1016/j.rti.2005.04.008
NR 22
TC 13
Z9 13
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19741
EP 19760
DI 10.1007/s11042-016-3439-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500025
DA 2024-07-18
ER

PT J
AU Ramakrishna, M
   Karunakar, AK
AF Ramakrishna, M.
   Karunakar, A. K.
TI SIP and SDP based content adaptation during real-time video streaming in
   Future Internets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video streaming; Scalable video coding; Video adaptation; Future
   internets; Media aware network elements; Session establishment; Software
   defined networks
ID MULTIMEDIA; MANAGEMENT; STANDARD; DESIGN; SVC
AB Future Internet technology supports content adaptation to improve the QoS / QoE in a heterogeneous environment. The adaptation process removes partial data to meet either receiver capability or network capability. The process of adaptation is efficient when it is performed in the network rather than in the sender side or receiver end. In-network adaptation is performed by intelligent intermediate devices, which implement Content Aware Network and Content Centric Network, to process the contents. The adaptation decision taking module requires prior knowledge about end devices, network capacity and content's meta-data to decide the extraction points. This paper proposes a model to signal the terminal, network and media capabilities with the intermediate devices. The proposed model reduces the number of messages exchanged between end devices, intermediate devices and media server during session creation. Additionally, this method proposes a way to signal network dynamics such as change in bandwidth and buffer space with the intermediate devices to improve the video quality with the available resources. The proposed session signaling scheme is developed by extending traditional Session Initiation Protocol and Session Description Protocol and tested for suitability using virtual networking environment.
C1 [Ramakrishna, M.] Manipal Univ, Manipal Inst Technol, Dept Informat & Commun Technol, Manipal 576104, Karnataka, India.
   [Karunakar, A. K.] Manipal Univ, Manipal Inst Technol, Dept Comp Applicat, Manipal 576104, Karnataka, India.
C3 Manipal Academy of Higher Education (MAHE); Manipal Academy of Higher
   Education (MAHE)
RP Karunakar, AK (corresponding author), Manipal Univ, Manipal Inst Technol, Dept Comp Applicat, Manipal 576104, Karnataka, India.
EM ramakrishna.m@manipal.edu; karunakar.ak@manipal.edu
RI M, Ramakrishna/H-5825-2015; M, Ramakrishna/P-6875-2019
OI M, Ramakrishna/0000-0001-8270-8675; A K, Karunakar/0000-0002-2458-3891
CR Adzic V, 2011, MULTIMED TOOLS APPL, V51, P379, DOI 10.1007/s11042-010-0669-x
   Andreasen F, 2010, 5939 RFC
   [Anonymous], SIGMULTIMEDIA REC
   [Anonymous], P ACM VIDEONEXT WORK
   Arnaiz L, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P381, DOI 10.1109/ICCE.2011.5722639
   Borcoci E., 2010, 2010 Third International Conference on Communication Theory, Reliability, and Quality of Service (CTRQ), P162, DOI 10.1109/CTRQ.2010.35
   Burnett I, 2006, MULTIMEDIA SYSTEMS
   Daras P, 2009, WHY WE NEED CONTENT
   De Schrijver D, 2007, J VIS COMMUN IMAGE R, V18, P217, DOI 10.1016/j.jvcir.2007.02.003
   De Schrijver D, 2006, MULTIMEDIA SYST, V11, P403, DOI 10.1007/s00530-006-0021-5
   Famaey J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P927
   Famaey J, 2013, J NETW COMPUT APPL, V36, P219, DOI 10.1016/j.jnca.2012.08.014
   Famaey J, 2012, INT J NETW MANAG, V22, P508, DOI 10.1002/nem.1813
   Fortino G, 2014, J NETW COMPUT APPL, V37, P127, DOI 10.1016/j.jnca.2012.11.005
   Gardikis G., 2011, 2011 IEEE Symposium on Computers and Communications (ISCC 2011), P544, DOI 10.1109/ISCC.2011.5983894
   Görkemli B, 2010, IEEE IMAGE PROC, P2913, DOI 10.1109/ICIP.2010.5652838
   Grafl M, 2013, IEEE MULTIMEDIA, V20, P30, DOI 10.1109/MMUL.2012.57
   HANDLEY M, 1998, 2327 RFC
   Hartwig S, 2000, IEEE T CONSUM ELECTR, V46, P1167, DOI 10.1109/30.920475
   Hellwagner H, 2009, SIGNAL PROCESS-IMAGE, V24, P740, DOI 10.1016/j.image.2009.07.002
   Jennings B, 2009, 2009 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT - WORKSHOPS, P87, DOI 10.1109/INMW.2009.5195942
   Johansson I, 2011, 6236 RFC
   Kawasaki K, 2015, 10 INT C FUT INT CFI, P57, DOI [10.1145/2775088.2775091, DOI 10.1145/2775088.2775091]
   Kim SS, 2008, LECT NOTES COMPUT SC, V5297, P156
   Kuschnig R, 2008, J VIS COMMUN IMAGE R, V19, P529, DOI 10.1016/j.jvcir.2008.07.004
   Latré S, 2014, INT J NETW MANAG, V24, P1, DOI 10.1002/nem.1840
   Lederer S, 2014, IEEE NETWORK, V28, P91, DOI 10.1109/MNET.2014.6963810
   Lee H., 2007, SVC AD DEC ENG BAS, P1, DOI DOI 10.1109/ISCE.2007.4382160
   Lennox J., 2009, 5576 RFC
   Rosenberg CG, 2002, SIP SESSION INITIATI
   Schierl T, 2009, 5583 RFC
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Serrano M, 2011, LECT NOTES COMPUT SC, V6656, P51, DOI 10.1007/978-3-642-20898-0_4
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Thang Truong Cong, 2006, Journal of Zhejiang University (Science), V7, P764, DOI 10.1631/jzus.2006.A0764
   Thang TC, 2009, SIGNAL PROCESS-IMAGE, V24, P214, DOI 10.1016/j.image.2008.12.006
   Timmerer C, 2010, P 1 INT DIG PRES INT, V8, P1, DOI [10.1145/2039263.2039271, DOI 10.1145/2039263.2039271]
   Valloppillil V, 2010, D2 2 SERVICE CONTENT
   Vetro A, 2005, IEEE T MULTIMEDIA, V7, P418, DOI 10.1109/TMM.2005.846795
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wenger S, 2007, IEEE T CIRC SYST VID, V17, P1164, DOI 10.1109/TCSVT.2007.905523
NR 41
TC 3
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21171
EP 21191
DI 10.1007/s11042-016-4017-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400038
DA 2024-07-18
ER

PT J
AU Su, ZY
   Zhou, L
   Mao, YB
   Dai, YW
   Tang, WQ
AF Su, Zhiyong
   Zhou, Lang
   Mao, Yaobin
   Dai, Yuewei
   Tang, Weiqing
TI A unified framework for authenticating topology integrity of 2D
   heterogeneous engineering CAD drawings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topology integrity; Topology authentication; Local binary patterns;
   Engineering CAD; Heterogeneous; Watermarking
ID REVERSIBLE WATERMARKING; GRAPHICS; MODELS; CLASSIFICATION; SCHEME;
   DESIGN; CAPD
AB This paper presents a novel unified framework for authenticating topology integrity of 2D heterogeneous engineering CAD drawings. Topology information, through which a variety of engineering reports are generated, plays the most important role in the engineering CAD field. However, topology integrity authentication for engineering CAD drawings is still in its infancy and few efforts were made in the literature. By efficiently extracting topological and geometric features regardless of their heterogeneity with respect to geometrical shape and topology representation, the proposed framework supports verifying topology integrity for various heterogeneous engineering CAD drawings, such as process flow diagrams (PFD), piping and instrument drawings (P&ID), piping isometric drawings (ISO) as well as sectional drawings. Topology authentication is achieved through embedding local topological features into geometric features by introducing a generic and effective semi-fragile watermarking scheme. A novel descriptor, called topology local binary patterns (T-LBP), is proposed to extract local topological features of heterogeneous drawings. Theoretical analysis and experiments have demonstrated the discrimination power, robustness and sensitivity of the proposed T-LBP descriptor. We also carry out further experiments to prove that the proposed framework can not only detect and locate malicious topological modifications, but also yield strong robustness against various topology preserving modifications.
C1 [Su, Zhiyong; Mao, Yaobin; Dai, Yuewei] Nanjing Univ Sci & Technol, Sch Automat, Nanjing, Jiangsu, Peoples R China.
   [Zhou, Lang] Nanjing Univ Finance & Econ, Coll Informat Engn, Nanjing, Jiangsu, Peoples R China.
   [Tang, Weiqing] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Finance & Economics; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS
RP Su, ZY (corresponding author), Nanjing Univ Sci & Technol, Sch Automat, Nanjing, Jiangsu, Peoples R China.
EM suzhiyong@njust.edu.cn
OI su, zhiyong/0000-0001-9483-5268
FU National Natural Science Foundation of China [61300160]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions to improve the quality of the paper.
   They are also grateful to Beijing Zhongke Fulong Computer Technology
   Co., Ltd for the engineering CAD drawings used in this paper. This work
   is supported by the National Natural Science Foundation of China
   (61300160).
CR Burdorf A, 2004, COMPUT CHEM ENG, V28, P73, DOI 10.1016/S0098-1354(03)00180-7
   Ciocca G, 2015, MULTIMED TOOLS APPL, V74, P3013, DOI 10.1007/s11042-013-1766-4
   DOW MR, 1987, COMPUT AIDED DESIGN, V19, P226, DOI 10.1016/0010-4485(87)90259-4
   Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2
   Guirardello R, 2005, COMPUT CHEM ENG, V30, P99, DOI 10.1016/j.compchemeng.2005.08.009
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Lee SH, 2010, DIGIT SIGNAL PROCESS, V20, P1379, DOI 10.1016/j.dsp.2010.01.003
   Mazurczyk W, 2014, MULTIMEDIA SYST, V20, P101, DOI 10.1007/s00530-013-0339-8
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   OHBUCHI R, 2001, P IFIP TC5 WG5 2 4 W, P103
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Peng F, 2014, COMPUT AIDED DESIGN, V49, P42, DOI 10.1016/j.cad.2013.12.006
   Peng F, 2010, COMPUT AIDED DESIGN, V42, P1207, DOI 10.1016/j.cad.2010.08.004
   Su ZY, 2015, COMPUT AIDED DESIGN, V66, P33, DOI 10.1016/j.cad.2015.04.005
   Su ZY, 2013, COMPUT AIDED DESIGN, V45, P1042, DOI 10.1016/j.cad.2013.04.001
   van der Meiden HA, 2010, COMPUT AIDED GEOM D, V27, P281, DOI 10.1016/j.cagd.2009.12.003
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wang WB, 2008, COMPUT AIDED DESIGN, V40, P634, DOI 10.1016/j.cad.2008.03.001
   Wang YP, 2010, COMPUT AIDED GEOM D, V27, P395, DOI 10.1016/j.cagd.2010.02.003
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P2109, DOI 10.1007/s11042-013-1744-x
   Yang H, 2014, MULTIMED TOOLS APPL, V73, P41, DOI 10.1007/s11042-012-1264-0
NR 21
TC 3
Z9 3
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20663
EP 20689
DI 10.1007/s11042-016-3994-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400013
DA 2024-07-18
ER

PT J
AU Zeng, SN
   Yang, X
   Gou, JP
AF Zeng, Shaoning
   Yang, Xiong
   Gou, Jianping
TI Multiplication fusion of sparse and collaborative representation for
   robust face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fusion; Sparse representation; Collaborative representation; Image
   classification; Face recognition
ID IMAGE CLASSIFICATION; ALGORITHMS
AB Sparse representation based classification (SRC) and collaborative representation based classification (CRC) are two well-known methods in representation-based classification for face recognition. SRC emphasizes on the role of sparsity in coding, while CRC obtains an enhanced sparse representation with collaborative contributions from all classes. Previous studies show that sparsity of representation coefficients of SRC and CRC is significant for robust classification that may amplify the nonlocal contribution from other classes. However, the parameters are closely associated with the sparsity and it is very difficult to solve the optimal solutions. This paper proposed a novel representation-based image classification method that integrates SRC with CRC by a multiplication operation on the solutions to obtain enhanced sparse representation. We conducted experiments on several benchmark face databases and the experimental results showed that our algorithm produces higher accuracy on classification than both SRC and CRC.
C1 [Zeng, Shaoning; Yang, Xiong] Huizhou Univ, Sch Informat Sci & Technol, Huizhou, Peoples R China.
   [Gou, Jianping] Jiangsu Univ, Coll Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Huizhou University; Jiangsu University
RP Zeng, SN (corresponding author), Huizhou Univ, Sch Informat Sci & Technol, Huizhou, Peoples R China.
EM zsn@outlook.com; xyang.2010@hzu.edu.cn; goujianping@ujs.edu.cn
RI Gou, Jianping/JQX-2453-2023
OI Gou, Jianping/0000-0003-1413-0693
FU National Natural Science Foundation of China [61502208]; Natural Science
   Foundation of Jiangsu Province of China [BK20150522]; Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [14KJB520007]; China Postdoctoral Science Foundation [2015M570411];
   Research Foundation of Education Bureau of Guangdong Province of China
   [A314.0116]; Scientific Research Starting Foundation for Ph.D. in
   Huizhou University [C510.0210]; Scientific and Technical Program of City
   of Huizhou [2012-21]
FX This work was supported in part by National Natural Science Foundation
   of China (Grant No. 61502208), Natural Science Foundation of Jiangsu
   Province of China (Grant No. BK20150522), Natural Science Foundation of
   the Jiangsu Higher Education Institutions of China (Grant No.
   14KJB520007), China Postdoctoral Science Foundation (Grant No.
   2015M570411), Research Foundation of Education Bureau of Guangdong
   Province of China (Grant No. A314.0116), Scientific Research Starting
   Foundation for Ph.D. in Huizhou University (Grant No. C510.0210), and
   the Scientific and Technical Program of City of Huizhou (Grant No.
   2012-21).
CR [Anonymous], 2012, ARXIV12042358
   [Anonymous], P BR MACH VIS
   [Anonymous], 2014, Math. Probl. Eng
   [Anonymous], 2016, IEEE C COMP VIS PATT
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Cui JR, 2015, MULTIMED TOOLS APPL, V74, P10989, DOI 10.1007/s11042-014-1887-4
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Fan ZZ, 2016, PATTERN RECOGN, V58, P100, DOI 10.1016/j.patcog.2016.03.029
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Gong DH, 2013, IEEE I CONF COMP VIS, P2872, DOI 10.1109/ICCV.2013.357
   Jia S, 2015, IEEE T GEOSCI REMOTE, V53, P1118, DOI 10.1109/TGRS.2014.2334608
   Li W, 2015, PATTERN RECOGN, V48, P3904, DOI 10.1016/j.patcog.2015.05.024
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Park SW, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/158395
   Shen H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082299
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang D, 2015, PATTERN RECOGN, V48, P3025, DOI 10.1016/j.patcog.2015.01.012
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xing X, 2016, MULTIMED TOOLS APPL, P1
   Xu C., 2013, arXiv
   Xu Y, 2016, PATTERN RECOGN, V54, P68, DOI 10.1016/j.patcog.2015.12.017
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yin Zheng, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9217, P121, DOI 10.1007/978-3-319-21978-3_12
   Zeng S, 2016, CODE OF PAPER
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang L, 2015, MULTIMED TOOLS APPL, V74, P123, DOI 10.1007/s11042-013-1457-1
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
NR 32
TC 27
Z9 28
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20889
EP 20907
DI 10.1007/s11042-016-4035-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400024
DA 2024-07-18
ER

PT J
AU Chandra, S
   Maheshkar, S
AF Chandra, Subhash
   Maheshkar, Sushila
TI Verification of static signature pattern based on random subspace, REP
   tree and bagging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric recognition; Signature verification; Parametric feature
   extraction; Machine learning; Authentication system
AB In this paper we propose an effective method for static signature recognition from spontaneous handwritten text images. Our method relies on different aspects of writing: the presence of redundant patterns in the writing and its features. Signatures are analyzed at small fragments in which we seek to extract the patterns that an individual employs frequently as he writes. We exploit different features of writing like orientation, centroid and contour by computing a set of features from writing samples at different levels of observations. Orientation like intersecting point, edge point and gradient change of signature achieve great success in feature description. These features are extracted from the standard signature database and extracted features are trained and tested by machine learning (ML) approach. The machine learning approaches like Bagging, Random subspace (RS) and REP tree are used for classification purpose. Bagging with 10 iterations and base learner achieved efficiency upto 88 %. RS randomly selects features from feature set and creates new feature set. It uses decision tree as base classifier with different tree size. RS achieved efficiency same as Bagging but has more statistical errors. However, in case of REP tree we have achieved efficiency upto 75 %. The experimental results show that the Bagging and RS achieves promising results on publicly available data set.
C1 [Chandra, Subhash; Maheshkar, Sushila] Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Maheshkar, S (corresponding author), Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
EM subhash08mit@gmail.com; sushila_mheshkar@yahoo.com
RI Maheshkar, Sushila/V-7269-2019; Maheshkar, Sushila/KPY-5418-2024;
   Chandra, Subhash/JAX-6130-2023
OI Maheshkar, Sushila/0000-0003-3879-2800; Chandra,
   Subhash/0000-0001-7710-4375
CR Almazán J, 2011, PROC INT CONF DOC, P987, DOI 10.1109/ICDAR.2011.200
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   [Anonymous], 2006, BIOMETRICS PERSONAL
   [Anonymous], 2010, P 1 INT C INTELLIGEN, DOI DOI 10.1145/1963564.1963610
   [Anonymous], BIOMETRICS USER AUTH
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   [Anonymous], 2013, IJSC
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Jan Z, 2016, OFFLINE SIGNATURE RE, V48
   Kalmegh S., 2015, INT J INNOV SCI ENG, P438
   Kassner A, 2010, AM J NEURORADIOL, V31, P809, DOI 10.3174/ajnr.A2061
   Nguyen V, 2011, PROC INT CONF DOC, P339, DOI 10.1109/ICDAR.2011.76
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Plimmer B, 2006, IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P111
   Prakash HN, 2010, OFFLINE SIGNATURE VE
   Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725
   Roy S, 2014, OFFLINE SIGNATURE VE, V86
   Ruiz-Del-Solar J, 2008, LECT NOTES COMPUT SC, V5197, P22, DOI 10.1007/978-3-540-85920-8_3
   Vargas JF, 2011, PATTERN RECOGN, V44, P375, DOI 10.1016/j.patcog.2010.07.028
   Veeramachaneni K, 2005, IEEE T SYST MAN CY C, V35, P344, DOI 10.1109/TSMCC.2005.848191
   Wijesoma W.Sardha., 2001, Lecture Notes in Proceedings of the First Asia-Pacific on Web Intelligence, P227, DOI DOI 10.1007/3-540-45490-X_27
   Zhang D, 2005, IEEE T SYST MAN CY C, V35, P273, DOI 10.1109/TSMCC.2005.848152
   Zhang D, 2007, IEEE T SYST MAN CY B, V37, P1091
   Zois EN, 2016, PATTERN RECOGN, V54, P162, DOI 10.1016/j.patcog.2016.01.009
   Zontul M, 2013, WIND SPEED FORECASTI
NR 26
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19139
EP 19171
DI 10.1007/s11042-017-4531-2
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800046
DA 2024-07-18
ER

PT J
AU Jitpakdee, P
   Uyyanonvara, B
AF Jitpakdee, Parisut
   Uyyanonvara, Bunyarit
TI Computer-aided detection and quantification in glistenings on
   intra-ocular lenses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image processing; Computer-aided detection; Feature extraction;
   Classification
ID SURFACE LIGHT-SCATTERING; VISUAL FUNCTION; RETINAL IMAGES; NETWORK; TOOL
AB The artificial intraocular lens (IOL) is inserted to replaced the crystalline lens of the human eye after cataract surgery or refraction clear lens extraction. When the IOL, is in an aquatic environment, glistenings, which are liquid-filled microvacuoles, can be discriminated from normal state. Automatic detection of glistenings is a new problem, they have tiny sizes, sometimes have low contrast and also similar with the lens background. In this paper, the candidate glistenings are automatically detected by mathematic morphology method and fine segmented using the classifiers, we used k-nearest neighbor (kNN) and Na < ve Bayes for comparing the results. The detected glistenings are validated by object-based with ophthalmologists hand-drawn ground-truth. The result shows that classification can improve the performance of glistenings detection better than using only morphology method. The proposed software was developed for creating an effective automatic glistenings detection and quantification with a user-friendly Graphical User Interface,reliable results. Thus this computer-aid tool will help the researcher analyze the experiment results to better understand glistenings characteristic that have an effect on vary conditions.
C1 [Jitpakdee, Parisut; Uyyanonvara, Bunyarit] Thammasat Univ, Sirindhorn Int Inst Technol, Sch Informat Comp & Commun Technol, 131 Moo 5, Bangkadi 12000, Pathum Thani, Thailand.
C3 Thammasat University
RP Jitpakdee, P (corresponding author), Thammasat Univ, Sirindhorn Int Inst Technol, Sch Informat Comp & Commun Technol, 131 Moo 5, Bangkadi 12000, Pathum Thani, Thailand.
EM parisut@gmail.com; bunyarit@siit.tu.ac.th
FU National Research University Project of Thailand Office of Higher
   Education Commission (Thammasat University)
FX This research is funded by the National Research University Project of
   Thailand Office of Higher Education Commission (Thammasat University).
   We would like to thank the Applied Vision Research Centre, School of
   Health Sciences, City University London, for the IOL images and ground
   truth data.
CR Abarghouei AA, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P448, DOI 10.1109/SoCPaR.2009.93
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Bellucci R., 2013, INTRO INTRAOCULAR LE
   Byun JY, 2006, MOL VIS, V12, P949
   Carpenter AE, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-10-r100
   Datta N.S., 2012, IJCA, V60, P20
   Davies E., 1990, MACHINE VISION THEOR
   Deza Elena., 2009, Encyclopedia of Distances, P94
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Gillam P, 2014, MUSCLES IRIS BRING P
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gregori NZ, 2002, J CATARACT REFR SURG, V28, P1262, DOI 10.1016/S0886-3350(02)01224-5
   Gunenc U, 2001, J CATARACT REFR SURG, V27, P1611, DOI 10.1016/S0886-3350(01)00995-6
   Hayashi K, 2012, AM J OPHTHALMOL, V154, P240, DOI 10.1016/j.ajo.2012.03.011
   Japunya T, 2014, P WORLD C ENG, VI, P34
   Kato K, 2001, J CATARACT REFR SURG, V27, P1493, DOI 10.1016/S0886-3350(01)00895-1
   Malley M, 1995, OPHTHALMOLOGY TIMES, V20, P1
   Mamalis N, 2012, J CATARACT REFR SURG, V38, P1119, DOI 10.1016/j.jcrs.2012.05.023
   Mönestam E, 2011, ACTA OPHTHALMOL, V89, P724, DOI 10.1111/j.1755-3768.2009.01833.x
   Oshika T, 2001, BRIT J OPHTHALMOL, V85, P1034, DOI 10.1136/bjo.85.9.1034
   Rhodes A., 2011, P BRIT MACH VIS C, DOI DOI 10.5244/C.25.108
   Sopharak A, 2012, INT C SIGN IM ENG IC
   Sopharak A, 2014, ICISVC 2014 INT C IM
   Sopharak A, 2010, J MOD OPTIC, V57, P124, DOI 10.1080/09500340903118517
   Tognetto D, 2002, J CATARACT REFR SURG, V28, P1211, DOI 10.1016/S0886-3350(02)01353-6
   Usher D, 2004, DIABETIC MED, V21, P84, DOI 10.1046/j.1464-5491.2003.01085.x
   van der Mooren M, 2013, BIOMED OPT EXPRESS, V4, P1294, DOI 10.1364/BOE.4.001294
   Werner L, 2010, J CATARACT REFR SURG, V36, P1398, DOI 10.1016/j.jcrs.2010.06.003
   Zhang JG, 2002, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2002.1048450
NR 29
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18915
EP 18928
DI 10.1007/s11042-017-4474-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800036
DA 2024-07-18
ER

PT J
AU Kamalaveni, V
   Veni, S
   Narayanankutty, KA
AF Kamalaveni, V.
   Veni, S.
   Narayanankutty, K. A.
TI Improved self-snake based anisotropic diffusion model for edge
   preserving image denoising using structure tensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anisotropic diffusion; Enhancement; Structure tensor matrix;
   Perona-Malik model; Edge stopping function; Trace of matrix; Determinant
   of matrix; Eigen Vector
ID PERONA-MALIK MODEL
AB The performance of classifier algorithms used for predictive analytics highly dependent on quality of training data. This requirement demands the need for noise free data or images. The existing partial differential equation based diffusion models can remove noise present in an image but lacking in preserving thin lines, fine details and sharp corners. The classifier algorithms can able to make correct judgement to which class the image belongs to only if all edges are preserved properly during denoising process. To satisfy this requirement the authors proposed a new improved partial differential equation based diffusion algorithm for edge preserving image denoising. The proposed new anisotropic diffusion algorithm is an extension of self-snake diffusion filter which estimates edge and gradient directions as eigenvectors of a structure tensor matrix. The unique feature of this proposed anisotropic diffusion algorithm is diffusion rate at various parts of an image matches with the speed of level set flow. In the proposed algorithm an efficient edge indicator function dependent on the trace of the structure tensor matrix is used. The proposed model performs best in preserving thin lines, sharp corners and fine details since diffusion happens only along edges and diffusion is totally stopped across edges in this model. The additional edge-stopping term which is a vector dot product of derivative of an edge stopping function and derivative of an image computed along gradient and edge orthogonal directions is used in this model as shock filter which enables increased sharpness at all discontinuities. The performance of proposed diffusion algorithm is compared with other classical diffusion filters like conventional perona-malik diffusion, conventional self-snake diffusion methods.
C1 [Kamalaveni, V.] Amrita Univ, Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept Comp Sci & Engn, Coimbatore 641112, Tamil Nadu, India.
   [Veni, S.; Narayanankutty, K. A.] Amrita Univ, Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept Elect & Commun Engn, Coimbatore 641112, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore;
   Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Kamalaveni, V (corresponding author), Amrita Univ, Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept Comp Sci & Engn, Coimbatore 641112, Tamil Nadu, India.
EM v_kamalaveni@cb.amrita.edu; s_veni@cb.amrita.edu;
   ka_narayanankutty@cb.amrita.edu
CR ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   [Anonymous], ADV COMPUT
   Baghaie A, 2014, AEU INT J ELECT COMM
   Brox T, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P17, DOI 10.1007/3-540-31272-2_2
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chan T. F., 2001, IEEE T IMAGE PROCESS, V10, P2
   Didas S, 2007, LECT NOTES COMPUT SC, V4485, P568
   Dore V, 2011, IMAGE VIS COMPUT, V29
   Feddern C, 2003, P 2 IEEE WORKSH GEOM
   Guo ZC, 2012, IEEE T IMAGE PROCESS, V21, P958, DOI 10.1109/TIP.2011.2169272
   Ji XU, 2017, MULTIMED TOOLS APPL, V76, P5873, DOI 10.1007/s11042-015-2560-2
   Kamalaveni V, 2015, PROCEDIA COMPUT SCI, V58, P673, DOI 10.1016/j.procs.2015.08.087
   Le Guyader C, 2008, IEEE T IMAGE PROCESS, V17, P767, DOI 10.1109/TIP.2008.919951
   Liu K, 2014, P INT C DIG HOM
   Maiseli BJ, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0077-2
   Moghadam A. Ebrahimi, 2015, Majlesi J. Electr. Eng., V9, P55, DOI [10.48550/arXiv.1406.7799, DOI 10.48550/ARXIV.1406.7799]
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Sapiro G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P817, DOI 10.1109/ICIP.1996.559624
   Septiana L, 2014, IEEE INT S BIOEL BIO
   Shenbagarajan A., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI 10.17485/ijst/2016/v9il/78766
   Toufique Y, 2014, MID EAST CONF BIO, P1, DOI 10.1109/MECBME.2014.6783193
   Wang H, 2006, IEEE INT C IM PROC I
   Wang H, 2012, COMSIS, V9
   Wang YQ, 2013, SIGNAL PROCESS, V93, P2548, DOI 10.1016/j.sigpro.2013.02.020
   Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131
   Welk M, 2010, J MATH IMAGING VIS, DOI [10.1007/s10851-010-0228-02, DOI 10.1007/S10851-010-0228-02]
   Wu J, 2014, CYBERN INF TECHNOL, V14, P112, DOI 10.2478/cait-2014-0009
   Wu X, 2013, MED PHYS
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Yu HC, 2006, IEEE T IMAGE PROCESS, V15, P1517, DOI 10.1109/TIP.2006.871143
NR 31
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18815
EP 18846
DI 10.1007/s11042-016-4341-y
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800032
DA 2024-07-18
ER

PT J
AU Rawat, J
   Singh, A
   Bhadauria, HS
   Virmani, J
   Devgun, JS
AF Rawat, Jyoti
   Singh, Annapurna
   Bhadauria, H. S.
   Virmani, Jitendra
   Devgun, J. S.
TI Classification of acute lymphoblastic leukaemia using hybrid
   hierarchical classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leukaemia; Statistical texture features; Chromatic features; Geometrical
   features; Principal Component Analysis; Hierarchical classifiers
ID FOCAL LIVER-LESIONS; FEATURE-EXTRACTION; CAD-SYSTEM; SEGMENTATION;
   RECOGNITION; IMAGES; CELLS
AB In current consequence of haematology, blood cancer i.e. acute lymphoblastic leukemia is very frequently founded in medical practice, which is characterized by over activation and functional abnormality of bone marrow. The abnormality is identified through physical examination with a screening of blood smears. However, this method is error prone and labor intensive task for haematologist. Hence, haematologist needs a specific computer aided diagnostic system (CAD) that can deal with these limitations of prior systems and capable of discriminating immature leukemic cells from mature healthy cells. Thus, this work addresses the problem of segmenting a microscopic blood image into different regions, and then further analyzes those regions for localization of the immature lymphoblast cell. Further, it investigates the use of different geometrical, chromatic and statistical textures features for nucleus as well as cytoplasm and pattern recognition techniques for sub typing immature acute lymphoblasts as per FAB (French- American - British) classification. This can facilitate haematologist for acquiring essential information about prognosis and for an appropriate cure for leukemia. The exhaustive experiments have been conducted on 260 microscopic blood images (i.e. 130 normal and 130 cancerous cells) taken from ALL-IDB database. The proposed techniques consisting of the segmentation module used for segmenting the nucleus and cytoplasm of each leukocyte cell, feature extraction module, feature dimensionality reduction module that uses principal component analysis (PCA) to mapped the higher feature space to lower feature space and classification module that employs the standard classifiers, like support vector machines, smooth support vector machines, k-nearest neighbour, probabilistic neural network and adaptive neuro fuzzy inference system.
C1 [Rawat, Jyoti; Singh, Annapurna; Bhadauria, H. S.] GB Pant Engn Coll, Pauri 246001, UK, India.
   [Virmani, Jitendra] Cent Sci Instruments Org, CSIR, Chandigarh, India.
   [Devgun, J. S.] MM Inst Med Sci & Res, Solan, HP, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Scientific Instruments Organisation (CSIO); Maharishi
   Markandeshwar University
RP Rawat, J (corresponding author), GB Pant Engn Coll, Pauri 246001, UK, India.
EM jyotisonirawat@gmail.com
RI Rawat, Dr. Jyoti/AAR-5484-2021
OI Rawat, Dr. Jyoti/0000-0003-3331-7568; Virmani,
   Jitendra/0000-0002-6458-0484
CR Amin Morteza Moradi, 2015, J Med Signals Sens, V5, P49
   [Anonymous], P INT S WOM COMP INF
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], COMPUTER METHODBIO
   [Anonymous], BLOOD MARR STEM CELL
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], P 11 APPL STOCH MOD
   [Anonymous], 2012, LIBSVM LIB SUPPORT V
   [Anonymous], INDIAN J RES
   [Anonymous], 2008, PATTERN RECOGNIT
   [Anonymous], 2016, INT J APPL ENG RES
   [Anonymous], BEGINNERS GUIDE BLOO
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], FACTS SPRING
   [Anonymous], P INT C IM PROC
   [Anonymous], SSVM TOOLBOX
   [Anonymous], 1981, ORDER STAT
   [Anonymous], 2013, CLASSIFICATION ACUTE
   Bhattacharjee R, 2015, 2015 IEEE POWER, COMMUNICATION AND INFORMATION TECHNOLOGY CONFERENCE (PCITC-2015), P657, DOI 10.1109/PCITC.2015.7438079
   Chandy DA, 2014, MULTIMED TOOLS APPL, V72, P2011, DOI 10.1007/s11042-013-1511-z
   Choi YH, 2013, MULTIMED TOOLS APPL, V64, P227, DOI 10.1007/s11042-011-0987-7
   ElDahshan KA., 2015, Adv Image Vid Process, V3, P8
   Gonzalez RafaelC., 2004, Digital Image Using MATLAB Processing
   Halim Nurul Hazwani Abd, 2011, International Journal of Research and Reviews in Computer Science, V2, P971
   Han ZY, 2016, LECT NOTES ELECTR EN, V382, P215, DOI 10.1007/978-981-10-0740-8_25
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu HJ, 2014, MULTIMED TOOLS APPL, V69, P199, DOI 10.1007/s11042-012-1248-0
   Kher Rahul, 2015, Journal of Medical Engineering & Technology, V39, P138, DOI 10.3109/03091902.2014.998372
   Kovalev V. A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P371, DOI 10.1109/ICPR.1996.547448
   Kumar I, 2014, PROC INT C IND INFOR, P1
   Lina Arlends Chris, 2012, J SOFTWARE ENG APPL, V5, P101
   Madhloom H. T., 2010, Journal of Applied Sciences, V10, P959, DOI 10.3923/jas.2010.959.966
   Madhloom HT, 2012, INT CONF ADV COMPUT, P330, DOI 10.1109/ACSAT.2012.62
   Manth N, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1897
   Mohanty SP, 2011, FUTURE MINOR STUD, P1
   Mohapatra S., 2010, 2010 International Conference on Systems in Medicine and Biology (ICSMB), P49, DOI 10.1109/ICSMB.2010.5735344
   Mohapatra S., 2010, 2010 International Conference on Emerging Trends in Robotics and Communication Technologies (INTERACT 2010), P64, DOI 10.1109/INTERACT.2010.5706196
   Mohapatra S., 2010, 2010 International Conference on Industrial Electronics, Control and Robotics (IECR), P215, DOI 10.1109/IECR.2010.5720171
   Mohapatra S, 2014, NEURAL COMPUT APPL, V24, P1887, DOI 10.1007/s00521-013-1438-3
   Mohapatra S, 2012, BIOMED ENG LETT, V2, P100, DOI 10.1007/s13534-012-0056-9
   MoradiAmin M., 2015, FRONTIERS BIOMEDICAL, V2, P128
   MoradiAmin M, 2016, MICROSC RES TECHNIQ, V79, P908, DOI 10.1002/jemt.22718
   Nasir ASA, 2011, IFMBE PROC, V35, P40, DOI 10.1007/978-3-642-21729-6_16
   Neoh SC, 2015, SCI REP-UK, V5, DOI 10.1038/srep14938
   Pedreira CE, 2009, IEEE T INF TECHNOL B, V13, P284, DOI 10.1109/TITB.2008.925965
   Putzu L, 2014, ARTIF INTELL MED, V62, P179, DOI 10.1016/j.artmed.2014.09.002
   Putzu L, 2013, PROCEEDINGS IWBBIO 2013: INTERNATIONAL WORK-CONFERENCE ON BIOINFORMATICS AND BIOMEDICAL ENGINEERING, P99
   Rawat J, 2015, PROCEDIA COMPUT SCI, V70, P748, DOI 10.1016/j.procs.2015.10.113
   Rawat J, 2014, IEEE INT SYMP SIGNAL, P456, DOI 10.1109/ISSPIT.2014.7300632
   Rawat J, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P245, DOI 10.1109/PDGC.2014.7030750
   Sabino DMU, 2004, REAL-TIME IMAGING, V10, P205, DOI 10.1016/j.rti.2004.02.007
   Saipullah KM, 2012, MULTIMED TOOLS APPL, V59, P717, DOI 10.1007/s11042-011-0766-5
   Saraswat M, 2014, MICRON, V65, P20, DOI 10.1016/j.micron.2014.04.001
   Scotti F, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P96
   Scotti F, 2006, IEEE IMTC P, P43, DOI 10.1109/IMTC.2006.328170
   Sharma K, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P425
   Singhal V, 2016, ADV INTELL SYST, V409, P535, DOI 10.1007/978-981-10-0135-2_52
   Sinha N, 2003, TENCON IEEE REGION, P547, DOI 10.1109/TENCON.2003.1273221
   Virmani Jitendra, 2013, International Journal of Artificial Intelligence and Soft Computing, V3, P276
   Virmani J, 2014, J DIGIT IMAGING, V27, P520, DOI 10.1007/s10278-014-9685-0
   Virmani J, 2013, DEFENCE SCI J, V63, P478, DOI 10.14429/dsj.63.3951
   Virmani J, 2013, J DIGIT IMAGING, V26, P1058, DOI 10.1007/s10278-013-9578-7
   Virmani Jitendra, 2013, Journal of Medical Engineering & Technology, V37, P292, DOI 10.3109/03091902.2013.794869
   Virmani J, 2013, J DIGIT IMAGING, V26, P530, DOI 10.1007/s10278-012-9537-8
   Viswanathan P, 2015, PROCEDIA COMPUT SCI, V58, P84, DOI 10.1016/j.procs.2015.08.017
   Wong HS, 2007, MULTIMED TOOLS APPL, V33, P91, DOI 10.1007/s11042-006-0098-z
   Zhang L, 2006, J PHYS CONF SER, V48, P329, DOI 10.1088/1742-6596/48/1/061
NR 67
TC 63
Z9 63
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19057
EP 19085
DI 10.1007/s11042-017-4478-3
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800043
DA 2024-07-18
ER

PT J
AU Arour, K
   Yeferny, T
AF Arour, Khedija
   Yeferny, Taoufik
TI Formal concept analysis based user model for distributed systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User model; Information retrieval; Peer-to-Peer system; Formal concept
   analysis; Routing process; Aggregation process
ID INFORMATION-RETRIEVAL; PROFILES
AB User profile has contributed to customize user access and adjusts applications to its needs. In this respect, automatically building of user profiles issue is an important research area. Nevertheless, standardizing these profiles in terms of representation and acquisition schemes, more especially in large scale systems like Peer-to-Peer systems (P2P), is a complex task. In this paper, we introduce a distributed user profile modelling approach based on user search topics history without the need of any external knowledge resource (e.g., ontology). This model learns from past interests to guess correlations between user requests, associated topics, relevant documents and nodes (i.e., peers) to enhance any information retrieval process. The solution is based on an extension of Formal Concept Analysis (FCA) theory. We also study, the integration of our model in query routing (i.e., content discovery) and results aggregation processes for P2P systems. Carried out experiments, performed under a P2P simulator environment, showed that our model outperforms its competitors in terms of effectiveness and efficiency.
C1 [Arour, Khedija] Natl Inst Appl Sci & Technol Tunis, Dept Comp Sci, Tunis, Tunisia.
   [Arour, Khedija] Univ Tunis El Manar, LIPAH LR 11ES14, Tunis, Tunisia.
   [Yeferny, Taoufik] Univ Carthage, LISI LAB, Tunis, Tunisia.
C3 Universite de Carthage; Universite de Tunis-El-Manar; Universite de
   Carthage
RP Arour, K (corresponding author), Natl Inst Appl Sci & Technol Tunis, Dept Comp Sci, Tunis, Tunisia.; Arour, K (corresponding author), Univ Tunis El Manar, LIPAH LR 11ES14, Tunis, Tunisia.
EM Khedija.arour@issatm.rnu.tn; yeferny.taoufik@gmail.com
RI AROUR, Khedija/AAQ-8489-2020; Yeferny, Taoufik/AAP-4826-2021
OI Yeferny, Taoufik/0000-0003-4600-8131
CR Abid A, 2013, J INTELL INF SYST, V40, P479, DOI 10.1007/s10844-012-0234-3
   [Anonymous], 2003, ACM S APPL COMP, DOI DOI 10.1145/952532.952698
   [Anonymous], 2010, TEXT RETRIVAL C
   Arour K, 2015, PEER PEER NETW APPL, V8, P741, DOI 10.1007/s12083-014-0282-2
   Aslam J. A., 2001, SIGIR Forum, P276
   Blanco R, 2012, INFORM RETRIEVAL, V15, P54, DOI 10.1007/s10791-011-9172-x
   Bradley K., 2000, Adaptive Hypermedia and Adaptive Web-Based Systems. International Conference, AH 2000. Proceedings (Lecture Notes in Computer Science Vol.1892), P62
   Brambilla Marco, 2008, 2008 8th International Conference on Web Engineering (ICWE), P247, DOI 10.1109/ICWE.2008.44
   Carpineto C, 2004, J UNIVERS COMPUT SCI, V10, P985
   Cerf L., 2008, Proceedings of the SIAM International Conference on Data Mining (SDM 2008), P37
   CHERNOV S., 2005, P INT WORKSH DAT INF, P26
   CROFT WB, 2001, DELOS WORKSH PERS RE
   Dominguez-Sal D, 2009, HPCC: 2009 11TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, P415, DOI 10.1109/HPCC.2009.31
   Dwork C., 2001, P 10 INT C WORLD WID, P613, DOI [10.1145/371920.372165, DOI 10.1145/371920.372165]
   Farah Mohamed, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P591, DOI 10.1145/1277741.1277843
   Ferreira J., 2001, O populismo e sua historia: debate e critica / organizacao, P7
   Ganter B, 1999, Formal concept analysis: Mathematical foundations
   GODIN R, 1995, COMPUT INTELL-US, V11, P246, DOI 10.1111/j.1467-8640.1995.tb00031.x
   Greengrass E., 2000, INFORM RETRIEVAL SUR
   Han K, 2015, INT CONF BIG DATA, P225, DOI 10.1109/35021BIGCOMP.2015.7072835
   Hawalah A, 2015, EXPERT SYST APPL, V42, P2547, DOI 10.1016/j.eswa.2014.10.032
   Ignatov DI, 2015, MACH LEARN, V101, P271, DOI 10.1007/s10994-015-5487-y
   Ismail A, 2013, ICEIS: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, VOL 1, P247, DOI 10.5220/0004452302470254
   JELASITY M, 2007, PEERSIM SIMULATOR
   Jelassi MN, 2012, CORR
   Jin H, 2006, P 21 ANN ACM S APPL, P23
   Kalogeraki V., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P300, DOI 10.1145/584792.584842
   Kelly D., 2003, SIGIR Forum, V37, P18, DOI 10.1145/959258.959260
   Keqin H, 2010, 2 INT WORKSH INT SYS, P1
   Kobsa A, 2001, USER MODEL USER-ADAP, V11, P49, DOI 10.1023/A:1011187500863
   Kostadinov D, 2008, THESIS
   Luna V, 2015, COMPUT HUM BEHAV, V51, P1387, DOI 10.1016/j.chb.2014.10.004
   Mahmoud A., 2010, 2010 IEEE International Conference on Information Reuse & Integration (IRI 2010), P330, DOI 10.1109/IRI.2010.5558914
   Piwowarski B, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1198296.1198297
   Poelmans J, 2010, LECT NOTES ARTIF INT, V6208, P139, DOI 10.1007/978-3-642-14197-3_15
   Routray R, 2010, IEEE INT S POL DISTR
   Salton G., 1989, Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer
   Savoy J, 2001, RECHERCHE INFORM SOU, P237
   Soltysiak SJ, 1998, BT TECHNOL J, V16, P110, DOI 10.1023/A:1009690117684
   Valtchev P., 2003, USING CONCEPTUAL STR, P241
   WAHLSTER W, 1986, P IEEE, V74, P948, DOI 10.1109/PROC.1986.13574
   Witschel HF, 2008, TECHNICAL REPORT
   Xin Wan, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P3, DOI 10.1109/ETCS.2010.439
   Xu Qi, 2010, Proceedings of the 2010 International Conference on Intelligent Computation Technology and Automation (ICICTA 2010), P198, DOI 10.1109/ICICTA.2010.252
   Zhang ZT, 2009, INT CONF ASIAN LANG, P304, DOI 10.1109/IALP.2009.72
   Zhou XK, 2015, MULTIMED TOOLS APPL, V74, P5015, DOI 10.1007/s11042-014-2230-9
NR 46
TC 0
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16085
EP 16105
DI 10.1007/s11042-016-3896-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100002
DA 2024-07-18
ER

PT J
AU Jiang, XL
   Yu, Y
   Zhao, LL
   Liu, HJ
AF Jiang, Xinglong
   Yu, Yang
   Zhao, Lulu
   Liu, Huijie
TI Constrained nondominated neighbor immune multiobjective optimization
   algorithm for multimedia delivery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial immune system; constraint handling; constrained
   multiobjective optimization; adaptive penalty funtion; multimedia
   delivery
AB In recent years, artificial immune system (AIS) algorithms is considered to be an effective method to solve the multiobjective optimization problems (MOPs), such as multimedia delivery problem. Though a decent number of solution algorithms have been proposed for MOPs, far less progress has been made for constrained multiobjective optimization problems (CMOPs), which demands a combination of constraints handling technique and search algorithm, e.g. Nondominated Neighbor Immune Algorithm (NNIA). In this paper, we propose a hybrid constraint handling technique of adaptive penalty function and objectivization of constraint violations. In our approach, the dominant population is updated via a method of objectivization of constraint violations and proportional reduction while a modified adaptive penalty function method based on the structure of the search algorithm (NNIA) is utilized to update the active population. We combine the proposed hybrid constraint handling method with NNIA to form the proposed Constrained Nondominated Neighbor Immune Algorithm (C-NNIA) to address the constrained multiobjective optimization problems. To our knowledge, it is the first time NNIA has been applied as the search algorithm for CMOPs. Numerical simulations indicate that the proposed algorithm outperforms the current state-of-the-art algorithms, i.e. NSGA-II-WTY, in both convergence and diversity.
C1 [Jiang, Xinglong; Yu, Yang; Zhao, Lulu] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China.
   [Jiang, Xinglong; Yu, Yang; Zhao, Lulu; Liu, Huijie] Shanghai Engn Ctr Microsatellites, Shanghai 201210, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Institute of Microsystem &
   Information Technology, CAS
RP Liu, HJ (corresponding author), Shanghai Engn Ctr Microsatellites, Shanghai 201210, Peoples R China.
EM luckdragon@126.com; yuyangigwt@163.com; 495196566@qq.com;
   huijieliu72@126.com
RI yu, yang/HIZ-9682-2022
FU National Natural Science Foundation of China [61401278]
FX The presented work was supported by the National Natural Science
   Foundation of China, under Grants 61401278.
CR [Anonymous], 2012, IEEE C EVOL COMPUTAT
   Batalla JM, 2017, J SUPERCOMPUT, V73, P993, DOI 10.1007/s11227-016-1731-x
   Crichigno J, 2012, LECT NOTES COMPUT SC, V3124, P1029
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Gong MG, 2008, EVOL COMPUT, V16, P225, DOI 10.1162/evco.2008.16.2.225
   Hsieh MN, 2011, IEEE C EVOL COMPUTAT, P1785
   Isaacs A, 2008, IEEE C EVOL COMPUTAT, P2780, DOI 10.1109/CEC.2008.4631171
   Jiao LC, 2014, APPL SOFT COMPUT, V14, P363, DOI 10.1016/j.asoc.2013.10.008
   Li X, 2013, COMPUT OPER RES, V40, P282, DOI 10.1016/j.cor.2012.07.014
   Long Q, 2014, SWARM EVOL COMPUT, V15, P66, DOI 10.1016/j.swevo.2013.12.002
   Qi YT, 2012, APPL SOFT COMPUT, V12, P2654, DOI 10.1016/j.asoc.2012.04.005
   Qian F, 2012, SOFT COMPUT, V16, P1353, DOI 10.1007/s00500-012-0816-6
   Qu BY, 2011, ENG OPTIMIZ, V43, P403, DOI 10.1080/0305215X.2010.493937
   Shang Rong-hua, 2009, Acta Electronica Sinica, V37, P1289
   Singh H.K., 2010, Proceedings of the IEEE congress on evolutionary computation (CEC2010), P1, DOI [DOI 10.1109/FUTURETECH.2010.5482682, DOI 10.1109/CEC.2010.5586124]
   Singh HK, 2010, INFORM SCIENCES, V180, P2499, DOI 10.1016/j.ins.2010.03.021
   Vieira DAG, 2004, IEEE T MAGN, V40, P1188, DOI 10.1109/TMAG.2004.825006
   Woldesenbet YG, 2009, IEEE T EVOLUT COMPUT, V13, P514, DOI 10.1109/TEVC.2008.2009032
   Yen GG, 2014, IEEE T EVOLUT COMPUT, V18, P131, DOI 10.1109/TEVC.2013.2240687
   YEN GG, 2010, IEEE C EV COMP, P1, DOI DOI 10.1109/CEC.2010.5586394
   Yu ED, 2014, CHIN CONTR CONF, P8622, DOI 10.1109/ChiCC.2014.6896448
NR 21
TC 4
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17297
EP 17317
DI 10.1007/s11042-016-3957-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500023
DA 2024-07-18
ER

PT J
AU Khan, MA
AF Khan, Murtaza Ali
TI Multiresolution coding of motion capture data for real-time multimedia
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Coding; Compression; MoCap data; Wavelet transform;
   Multiresolution
ID IMAGE COMPRESSION
AB In this work, we present a novel and efficient method for coding of motion capture (MoCap) data obtained from recording of human actions. MoCap data is represented as hierarchies of joints and parameterized by translation and rotation of channels or degree-of-freedom (DOF) in a sequence of frames as a function of time. The proposed method approximates the MoCap data of each channel independently using multiresolution discrete wavelet transform (DWT). In order to improve the performance, a skeleton dependent quantization of wavelet coefficients is used that computes a local threshold of each joint based on a global threshold and depth of the joint in the hierarchy of joints. The multiresolution DWT based coding allows to control the bitrate and to decode (reconstruct) the single instance of compressed MoCap data into multiple instances from high to low resolution (quality). We also compared the performance of proposed method with recent and state of the art methods. The proposed method yields smaller storage space and faster encoding time. The method is well suitable for real-time multimedia applications due to its low time and space requirements.
C1 [Khan, Murtaza Ali] Umm Al Qura Univ, Coll Comp & Informat Syst, Makkah Al Mukarramah, Saudi Arabia.
C3 Umm Al Qura University
RP Khan, MA (corresponding author), Umm Al Qura Univ, Coll Comp & Informat Syst, Makkah Al Mukarramah, Saudi Arabia.
EM makkhan@uqu.edu.sa
RI Khan, Murtaza Ali/AHA-3568-2022
OI Khan, Murtaza Ali/0000-0002-3442-8019
CR [Anonymous], 2011, LAWRENCE N MOCAP TOO
   Arikan O, 2006, ACM T GRAPHIC, V25, P890, DOI 10.1145/1141911.1141971
   Beaudoin Philippe, 2007, Proceedings Graphics Interface 2007, P313, DOI 10.1145/1268517.1268568
   Cai W, 2014, MOBILE NETW APPL, V19, P144, DOI 10.1007/s11036-013-0485-4
   Cheng I, 2015, COMPUT GRAPH-UK, V51, P1, DOI 10.1016/j.cag.2015.05.002
   Choensawat W, 2015, MULTIMED TOOLS APPL, V74, P10823, DOI 10.1007/s11042-014-2209-6
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P1127, DOI 10.1109/TMM.2012.2191270
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Firouzmanesh A, 2011, IEEE T MULTIMEDIA, V13, P829, DOI 10.1109/TMM.2011.2129497
   Garbas JU, 2011, IEEE T CIRC SYST VID, V21, P113, DOI 10.1109/TCSVT.2011.2105552
   Gu Q, 2009, COMPUT GRAPH FORUM, V28, P1, DOI 10.1111/j.1467-8659.2008.01309.x
   Hachicha W, 2015, IEEE T MULTIMEDIA, V17, P765, DOI 10.1109/TMM.2015.2417099
   Hou JH, 2015, IEEE T VIS COMPUT GR, V21, P848, DOI 10.1109/TVCG.2015.2403328
   Ikemoto Leslie, 2006, P 2006 S INT 3D GRAP, P49
   Khan MA, 2016, MULTIDIM SYST SIGN P, V27, P121, DOI 10.1007/s11045-014-0293-4
   Khan MA, 2012, SIGNAL IMAGE VIDEO P, V6, P19, DOI 10.1007/s11760-010-0165-9
   Lin JFS, 2014, IEEE T NEUR SYS REH, V22, P168, DOI 10.1109/TNSRE.2013.2259640
   Liu L, 2015, MULTIMED TOOLS APPL, V74, P2763, DOI 10.1007/s11042-013-1662-y
   Patoli Muhammad Zeeshan, 2010, Proceedings of the Third IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning (DIGITEL 2010), P139, DOI 10.1109/DIGITEL.2010.39
   Rahman MA, 2015, MULTIMED TOOLS APPL, V74, P5463, DOI 10.1007/s11042-014-1864-y
   Sattler Mirko, 2005, P ACM SIGGRAPH EUR S, P209
   Sheikh AM, 2014, IEEE T MULTIMEDIA, V16, P2294, DOI 10.1109/TMM.2014.2357716
   Suzuki T, 2010, IEEE T IMAGE PROCESS, V19, P2958, DOI 10.1109/TIP.2010.2051867
   Tournier M, 2009, COMPUT GRAPH FORUM, V28, P355, DOI 10.1111/j.1467-8659.2009.01375.x
   Wang CW, 2012, I S INTELL SIG PROC
   Zhang M, 2015, MULTIMED TOOLS APPL, V74, P11255, DOI 10.1007/s11042-014-2227-4
NR 26
TC 27
Z9 28
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16683
EP 16698
DI 10.1007/s11042-016-3944-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100028
DA 2024-07-18
ER

PT J
AU Kumar, P
   Saini, R
   Roy, PP
   Dogra, DP
AF Kumar, Pradeep
   Saini, Rajkumar
   Roy, Partha Pratim
   Dogra, Debi Prosad
TI 3D text segmentation and recognition using leap motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D air-writing; Written text segmentation; Dynamic features; Gesture on
   air; Touchless interfaces
ID HANDWRITING RECOGNITION; ONLINE; LINE
AB In this paper, we present a method of Human-Computer-Interaction (HCI) through 3D air-writing. Our proposed method includes a natural way of interaction without pen and paper. The online texts are drawn on air by 3D gestures using fingertip within the field of view of a Leap motion sensor. The texts consist of single stroke only. Hence gaps between adjacent words are usually absent. This makes the system different as compared to the conventional 2D writing using pen and paper. We have collected a dataset that comprises with 320 Latin sentences. We have used a heuristic to segment 3D words from sentences. Subsequently, we present a methodology to segment continuous 3D strokes into lines of texts by finding large gaps between the end and start of the lines. This is followed by segmentation of the text lines into words. In the next phase, a Hidden Markov Model (HMM) based classifier is used to recognize 3D sequences of segmented words. We have used dynamic as well as simple features for classification. We have recorded an overall accuracy of 80.3 % in word segmentation. Recognition accuracies of 92.73 % and 90.24 % have been recorded when tested with dynamic and simple features, respectively. The results show that the Leap motion device can be a low-cost but useful solution for inputting text naturally as compared to conventional systems. In future, this may be extended such that the system can successfully work on cluttered gestures.
C1 [Kumar, Pradeep; Saini, Rajkumar; Roy, Partha Pratim] Indian Inst Technol, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Dogra, Debi Prosad] Indian Inst Technol, Sch Elect Sci, Bhubaneswar, Orissa, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Bhubaneswar
RP Dogra, DP (corresponding author), Indian Inst Technol, Sch Elect Sci, Bhubaneswar, Orissa, India.
EM pra14.dcs2014@iitr.ac.in; rajkr.dcs2014@iitr.ac.in; proy.fcs@iitr.ac.in;
   dpdogra@iitbbs.ac.in
RI Roy, Partha Pratim/AAV-9061-2020; Roy, Partha Pratim/AAW-2994-2020; Roy,
   Partha Pratim/GPF-4253-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; 
CR Agarwal C, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P539, DOI 10.1109/ACPR.2015.7486561
   Aggarwal R, 2015, PROC INT CONF DOC, P1061, DOI 10.1109/ICDAR.2015.7333924
   Amma C, 2014, PERS UBIQUIT COMPUT, V18, P191, DOI 10.1007/s00779-013-0637-3
   [Anonymous], 2012, P ACM INT C INT MULT
   [Anonymous], 2013, P C HUM FACT COMP SY
   Bharath A, 2012, IEEE T PATTERN ANAL, V34, P670, DOI 10.1109/TPAMI.2011.234
   Bianne-Bernard AL, 2011, IEEE T PATTERN ANAL, V33, P2066, DOI 10.1109/TPAMI.2011.22
   Charles DK, 2013, INT TECHN GAM C
   España-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141
   Ghods V, 2013, ENG APPL ARTIF INTEL, V26, P544, DOI 10.1016/j.engappai.2012.05.013
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559
   Kavallieratou E., 2002, International Journal on Document Analysis and Recognition, V4, P226, DOI 10.1007/s100320200079
   Kim S. H., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P189, DOI 10.1109/ICDAR.2001.953781
   Lee S., 2014, INT J MULTIMEDIA UBI, V9, P397
   Liwicki M, 2006, INT C PATT RECOG, P929
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Manmatha R, 2005, IEEE T PATTERN ANAL, V27, P1212, DOI 10.1109/TPAMI.2005.150
   Palacios JM, 2013, SENSORS-BASEL, V13, P11842, DOI 10.3390/s130911842
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Marti UV, 2001, PROC INT CONF DOC, P159, DOI 10.1109/ICDAR.2001.953775
   Murata T, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/278460
   Nicolas S, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P245, DOI 10.1109/IWFHR.2004.100
   Nigam I, 2014, IEEE IMAGE PROC, P5012, DOI 10.1109/ICIP.2014.7026015
   Papavassiliou V, 2010, PATTERN RECOGN, V43, P369, DOI 10.1016/j.patcog.2009.05.007
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rahman M.H., 2014, INT MECH ENG C EXP, P1, DOI [10.1115/IMECE2014-36484, DOI 10.1115/IMECE2014-36484]
   She YY, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P1096, DOI 10.1109/CSE.2014.216
   Tagougui N, 2013, INT J DOC ANAL RECOG, V16, P209, DOI 10.1007/s10032-012-0186-8
   Tian J., 2013, NDSS
   Vamsikrishna KM, 2016, IEEE T BIO-MED ENG, V63, P991, DOI 10.1109/TBME.2015.2480881
   Wang DH, 2012, PATTERN RECOGN, V45, P3661, DOI 10.1016/j.patcog.2012.04.020
   Wang JS, 2013, ADV INTEL SYS RES, V42, P229
   Wang Q, 2014, DYNAMIC GESTURE RECO
   Xu N, 2015, LECT NOTES COMPUT SC, V9314, P171, DOI 10.1007/978-3-319-24075-6_17
   Zhang X, 2013, IEEE MULTIMEDIA, V20, P85, DOI 10.1109/MMUL.2013.50
NR 37
TC 26
Z9 27
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16491
EP 16510
DI 10.1007/s11042-016-3923-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100019
DA 2024-07-18
ER

PT J
AU Guo, HF
   Su, SB
   Sun, ZB
AF Guo Haifeng
   Su Shoubao
   Sun Zhoubao
TI Image tag recommendation based on friendships
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tagging system; Social tags; Recommendation system; Social friendships
AB The tagging systems have been studied by many researchers in the past decade. Tagging methods have been widely used on the web for searching and recommending images. Social tags are the keywords annotated by users to the images, which contains the information for searching and classifying the images. Tag recommendation system allows mitigating the individual preferences to annotate and recommender images. However, irrelevant and noise tags are frequently included in tags. In this paper, we propose image tag recommendation based on the friends' relationships in social network (TRboFS) to recommender tags for a new image, both the tags assigned to the favorite images and the friendships of the users who upload the image are employed to predict the tags of the images. Empirical analyses on real datasets show that the proposed approach achieves superior performance to existing approaches.
C1 [Guo Haifeng; Su Shoubao] Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Jiangsu, Peoples R China.
   [Guo Haifeng] Hohai Univ, Sch Comp & Informat Engn, Nanjing 210098, Jiangsu, Peoples R China.
   [Sun Zhoubao] Nanjing Audit Univ, Sch Technol, Nanjing 211815, Jiangsu, Peoples R China.
C3 Jinling Institute of Technology; Hohai University; Nanjing Audit
   University
RP Su, SB (corresponding author), Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Jiangsu, Peoples R China.
EM sushowbo@gmail.com
FU National Natural Science Foundation of China [61375121]; Natural Science
   and Teaching Reformation and Top-notch Academic Programs for Jiangsu
   Higher Education Institutions [14KJD520003, 2015JSJG163, PPZY2015B140];
   Scientific Research Foundation of Jinling Institute of Technology
   [jit-rcyj-201505]; Funds for Nanjing Creative Team of Swarm Computing
   Smart Software
FX The work is partially supported by the National Natural Science
   Foundation of China (No. 61375121), the Research Projects of Natural
   Science and Teaching Reformation and Top-notch Academic Programs for
   Jiangsu Higher Education Institutions (Nos. 14KJD520003, 2015JSJG163,
   PPZY2015B140), the Scientific Research Foundation of Jinling Institute
   of Technology (No. jit-rcyj-201505), and sponsored by the Funds for
   Nanjing Creative Team of Swarm Computing & Smart Software Led by Prof.
   S. Su (Corresponding author).
CR [Anonymous], 2008, P 17 INT C WORLD WID
   Barragáns-Martínez AB, 2010, INFORM SCIENCES, V180, P4290, DOI 10.1016/j.ins.2010.07.024
   Bellogm A., 2013, Proceedings of the 10th Conference on Open Research Areas in Information Retrieval, OAIR '13, P145
   Bergner Yoav., 2012, Educational Data Mining EDM, P95
   Carmagnola F, 2007, LECT NOTES ARTIF INT, V4511, P445
   Eom W, 2011, P 18 INT C IM PROC, P2445
   Gao Shenghua, 2010, P INT C MULT, P1115
   Garg N, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P67
   Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797
   Gunes I, 2013, KSII T INTERNET INF, V7, P1272
   Kern R, 2012, 9 INT WORKSH IM AN M, P126
   Kucuktunc O, 2008, INT C SEM DIG MED TE, P61
   Laniado David, 2007, SEMANTIC WEB APPL PE, P192
   LEE S, 2010, PATTERN RECOGN, P975
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Lindstaedt S, 2015, MULTIMED TOOLS APPL, V42, P97
   Liu D., 2009, P ICME, P250
   Liu WF, 2016, NEUROCOMPUTING, V172, P3, DOI 10.1016/j.neucom.2014.06.096
   Ma H., 2011, Proceedings of the 4th ACM International Conference on Web Search and Data Mining, P287
   Nazemian A, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1079, DOI 10.1109/ASONAM.2012.186
   Pantraki E, 2015, IEEE INT WORKS MACH
   RAE A, 2010, INT C AD PERS FUS HE
   Sagae A, 2015, INTELL SYST ACCOUNT, V22, P101, DOI 10.1002/isaf.1364
   Sigurbjornsson B, 2009, P 17 INT WORLD WID W, P327
   Te-Min Chang, 2011, 2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2011), P2065, DOI 10.1109/FSKD.2011.6019879
   van Zwol Roelof., 2010, Multimedia, P1015
   Xu Z., 2006, COLL WEB TAGG WORKSH
NR 27
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14581
EP 14597
DI 10.1007/s11042-016-3802-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400003
DA 2024-07-18
ER

PT J
AU Li, JQ
   Cao, BF
   Zhu, HQ
   Nie, FY
AF Li, Jianqi
   Cao, Binfang
   Zhu, Hongqiu
   Nie, Fangyan
TI Flotation froth image texture extraction method based on deterministic
   tourist walks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Froth image; Texture feature; Deterministic tourist walk algorithm;
   Graph theory; Weighted graph
ID NETWORK-BASED APPROACH; CLASSIFICATION; PERFORMANCE
AB In the flotation process, the flotation froth texture is an indicator of the flotation state. To recognize the flotation state based on texture features accurately and to provide guidance for production operations, this paper proposes a method for flotation froth image texture extraction based on the deterministic tourist walks algorithm. First, a weighted graph model of a froth image is built using deterministic tourist walks. Next, the degree distribution and the unit intensity distribution of the weighted graph are extracted. The contrast of the node degree and the contrast of the node unit intensity are calculated as the texture feature indexes. The texture feature indexes are used for flotation production state classification and recognition. The experimental results demonstrate that the proposed method can extract froth image texture features accurately and provide effective guidance for flotation production.
C1 [Li, Jianqi; Cao, Binfang; Nie, Fangyan] Hunan Univ Arts & Sci, Hunan Prov Cooperat Innovat Ctr Construct & Dev D, Changde, Hunan, Peoples R China.
   [Li, Jianqi; Cao, Binfang; Zhu, Hongqiu] Cent S Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
C3 Hunan University of Arts & Science; Central South University
RP Zhu, HQ (corresponding author), Cent S Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
EM li_jianqi@126.com; cao_bf@163.com; honqqiuzhu@163.com; niefyan@163.com
FU National Natural Science Foundation of China [61403136]; Science Fund
   for Creative Research Groups of the National Natural Science Foundation
   of China [61321003]; Hunan Province Natural Science Foundation, China
   [14JJ5008]
FX The author would like to thank all the anonymous reviewers for their
   valuable comments and thoughtful suggestions that improved the quality
   of the presented work. This work is partially supported by the National
   Natural Science Foundation of China (Grant No. 61403136), and Science
   Fund for Creative Research Groups of the National Natural Science
   Foundation of China(61321003), and the Hunan Province Natural Science
   Foundation, China (Grant No. 14JJ5008).
CR Backes AR, 2011, PATTERN RECOGN, V44, P1684, DOI 10.1016/j.patcog.2011.01.018
   Backes AR, 2009, PATTERN RECOGN, V42, P54, DOI 10.1016/j.patcog.2008.07.006
   Backes AR, 2013, INFORM SCIENCES, V219, P168, DOI 10.1016/j.ins.2012.07.003
   Boyer D, 2004, PHYSICA A, V342, P329, DOI 10.1016/j.physa.2004.04.091
   Boyer D, 2006, P ROY SOC B-BIOL SCI, V273, P1743, DOI 10.1098/rspb.2005.3462
   Campiteli MG, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.026703
   Cole KE, 2010, MINER ENG, V23, P1036, DOI 10.1016/j.mineng.2010.05.012
   Costa LD, 2007, ADV PHYS, V56, P167, DOI 10.1080/00018730601170527
   COSTA LDF, 2004, CONDMAT0403346 ARXIV
   De-gang X, 2014, 2014 11 WORLD C IEEE, P777
   [桂卫华 Gui Weihua], 2013, [自动化学报, Acta Automatica Sinica], V39, P1879
   Gui WH, 2013, MINER ENG, V46-47, P60, DOI 10.1016/j.mineng.2013.03.024
   Hang XW, 2011, EXPERT SYST APPL, V38, P5930
   Hargrave JM, 1996, MINER ENG, V9, P667, DOI 10.1016/0892-6875(96)00054-4
   Kaartinen J, 2006, CONTROL ENG PRACT, V14, P1455, DOI 10.1016/j.conengprac.2005.12.004
   Kinouchi O, 2002, PHYSICA A, V315, P665, DOI 10.1016/S0378-4371(02)00972-X
   Liu JJ, 2008, MINER ENG, V21, P642, DOI 10.1016/j.mineng.2007.12.011
   Liu JP, 2014, IEEJ T ELECTR ELECTR, V9, P31, DOI 10.1002/tee.21933
   Liu Jinping, 2010, Chinese Journal of Scientific Instrument, V31, P1769
   Moolman DW, 1996, MINER ENG, V9, P837, DOI 10.1016/0892-6875(96)00076-3
   SadrKazemi N, 1997, MINER ENG, V10, P1075, DOI 10.1016/S0892-6875(97)00094-0
   Wang W, 2003, MINER ENG, V16, P1183, DOI 10.1016/j.mineng.2003.07.014
   Weiss G. H., 1994, Aspects and Applications of the Random Walk
   Xie YF, 2016, IET CONTROL THEORY A, V10, P1404, DOI 10.1049/iet-cta.2015.0839
   [阳春华 Yang Chunhua], 2009, [仪器仪表学报, Chinese Journal of Scientific Instrument], V30, P717
NR 25
TC 6
Z9 6
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15123
EP 15136
DI 10.1007/s11042-017-4603-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400032
DA 2024-07-18
ER

PT J
AU Moreira, TP
   Perez, ML
   Werneck, RD
   Valle, E
AF Moreira, Thierry Pinheiro
   Perez, Mauricio Lisboa
   Werneck, Rafael de Oliveira
   Valle, Eduardo
TI Where is my puppy? Retrieving lost dogs by facial features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Dog recognition; Deep learning; Convolutional networks
ID FACE RECOGNITION
AB A pet that goes missing is among many people's worst fears: a moment of distraction is enough for a dog or a cat wandering off from home. Some measures help matching lost animals to their owners; but automated visual recognition is one that although convenient, highly available, and low-cost - is surprisingly overlooked. In this paper, we inaugurate that promising avenue by pursuing face recognition for dogs. We contrast four ready-to-use human facial recognizers (EigenFaces, FisherFaces, LBPH, and a Sparse method) to two original solutions based upon convolutional neural networks: BARK (inspired in architecture-optimized networks employed for human facial recognition) and WOOF (based upon off-the-shelf OverFeat features). Human facial recognizers perform poorly for dogs (up to 60.5 % accuracy), showing that dog facial recognition is not a trivial extension of human facial recognition. The convolutional network solutions work much better, with BARK attaining up to 81.1 % accuracy, and WOOF, 89.4 %. The tests were conducted in two datasets: Flickr-dog, with 42 dogs of two breeds (pugs and huskies); and Snoopybook, with 18 mongrel dogs.
C1 [Moreira, Thierry Pinheiro] Univ Estadual Campinas, Inst Comp, LIV Lab, Campinas, SP, Brazil.
   [Perez, Mauricio Lisboa; Werneck, Rafael de Oliveira; Valle, Eduardo] Univ Estadual Campinas, Inst Comp, RECOD Lab, Campinas, SP, Brazil.
   [Valle, Eduardo] Univ Estadual Campinas, Sch Elect & Comp Engn FEEC, Dept Comp Engn & Ind Automat DCA, Ave Albert Einstein 400, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas; Universidade Estadual de Campinas;
   Universidade Estadual de Campinas
RP Moreira, TP (corresponding author), Univ Estadual Campinas, Inst Comp, LIV Lab, Campinas, SP, Brazil.
EM thierrypin@liv.ic.unicamp.br
RI Perez, Mauricio Lisboa/AAG-8901-2020; Perez, Mauricio
   Lisboa/HSH-3396-2023; Pérez, Mauricio/HLW-8190-2023; Pérez,
   Mauricio/IZP-9377-2023
OI Perez, Mauricio Lisboa/0000-0002-4296-9202; Perez, Mauricio
   Lisboa/0000-0002-4296-9202; Alves do Valle Jr,
   Eduardo/0000-0001-5396-9868; Werneck, Rafael/0000-0002-8217-7250
FU FAPESP; CAPES; CNPq; SAMSUNG
FX This work was supported in part by FAPESP, CAPES, CNPq, and SAMSUNG.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2013, P 30 INT C INT C MAC
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], DOBBS J SOFTWARE TOO
   [Anonymous], INT C LEARN REPR CBL
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Chiachia G, 2014, IEEE T INF FOREN SEC, V9, P2089, DOI 10.1109/TIFS.2014.2359543
   Cox D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DIAMOND R, 1986, J EXP PSYCHOL GEN, V115, P107, DOI 10.1037/0096-3445.115.2.107
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Geoffrey EHinton., 2012, Improving neural networks by preventing co-adaptation of feature detectors
   Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Pinto Z., 2011, CVPR 2011 WORKSH, P35, DOI DOI 10.1109/CVPRW.2011.5981788
   SCAPINELLO KF, 1970, PSYCHON SCI, V21, P329, DOI 10.3758/BF03335807
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang XL, 2014, IEEE IMAGE PROC, P5237, DOI 10.1109/ICIP.2014.7026060
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
NR 25
TC 13
Z9 14
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15325
EP 15340
DI 10.1007/s11042-016-3824-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, J
   He, JJ
AF Wang, Juan
   He, Junjie
TI A speech content authentication algorithm based on a novel watermarking
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech authentication; Desynchronization attack; Tamper location;
   Digital watermark
ID AUDIO WATERMARKING; ROBUST; ENHANCEMENT; SCHEME; RECOGNITION
AB Some audio watermark schemes robust against desynchronization attacks are based on synchronization code embedded by quantifying signal energy, which have some shortcomings. Such as, (1) they do not verify the authenticity of watermarked signal detected. (2) They are vulnerable to substitution attack. To address the shortcomings and considering the background, a speech content authentication algorithm is proposed in this paper. Firstly, the original speech signal is framed, and each frame is cut into some segments. Secondly, samples of the segments are scrambled, and self-correlation of the scrambled signal is calculated. Lastly, watermark bit generated by frame number is embedded by quantifying the self-correlation. If watermarked signal is attacked, the attacked frames can be detected according to the frame number extracted. Theoretical analysis and experiments demonstrate that the scheme is robust against desynchronization attacks, improves the security, and has a good performance in ability of tampering location.
C1 [Wang, Juan; He, Junjie] Xinyang Normal Univ, Coll Math & Informat Sci, Xinyang 464000, Peoples R China.
C3 Xinyang Normal University
RP He, JJ (corresponding author), Xinyang Normal Univ, Coll Math & Informat Sci, Xinyang 464000, Peoples R China.
EM hejj99@163.com
FU National Natural Science Foundation of China [61272465, 61502409,
   11601465]; Natural Science Foundation of Henan Province [142400410485,
   152300410233]
FX Authors appreciate the support by the National Natural Science
   Foundation of China (grant No. 61272465, 61502409, 11601465), and
   Natural Science Foundation of Henan Province (142400410485,
   152300410233). We also thank the anonymous reviewers for their
   constructive suggestions.
CR Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Bhat KV, 2011, CIRC SYST SIGNAL PR, V30, P915, DOI 10.1007/s00034-010-9255-8
   Chen OTC, 2007, IEEE T AUDIO SPEECH, V15, P1605, DOI 10.1109/TASL.2007.896658
   Djendi M, 2014, DIGIT SIGNAL PROCESS, V32, P124, DOI 10.1016/j.dsp.2014.05.007
   Khan LA, 2010, DIGIT INVEST, V7, P65, DOI 10.1016/j.diin.2009.10.001
   Korycki R, 2014, FORENSIC SCI INT, V238, P33, DOI 10.1016/j.forsciint.2014.02.008
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Liu ZH, 2013, INT J DIGIT CRIME FO, V5, P15, DOI 10.4018/jdcf.2013070102
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Luo D, 2016, IEEE SIGNAL PROC LET, V23, P688, DOI 10.1109/LSP.2016.2549600
   Ming J, 2014, COMPUT SPEECH LANG, V28, P1269, DOI 10.1016/j.csl.2014.04.003
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Pun CM, 2013, IEEE T AUDIO SPEECH, V21, P2412, DOI 10.1109/TASL.2013.2279312
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Schwerin B, 2014, SPEECH COMMUN, V58, P49, DOI 10.1016/j.specom.2013.11.001
   Shih PY, 2011, J NETW COMPUT APPL, V34, P1459, DOI 10.1016/j.jnca.2010.08.007
   Tabibian S, 2015, SIGNAL PROCESS, V106, P184, DOI 10.1016/j.sigpro.2014.06.027
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Wang XY, 2011, COMPUT ELECTR ENG, V37, P425, DOI 10.1016/j.compeleceng.2011.05.011
   Wang Y., 2010, J ADV SIGNAL PROCESS, V2010, P1, DOI DOI 10.1016/J.PEPTIDES.2010.12.001
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   Xiang SJ, 2006, LECT NOTES COMPUT SC, V4283, P226
NR 22
TC 8
Z9 8
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14799
EP 14814
DI 10.1007/s11042-016-4027-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400014
DA 2024-07-18
ER

PT J
AU Sikos, LF
AF Sikos, Leslie F.
TI RDF-powered semantic video annotation tools with concept mapping to
   Linked Data for next-generation video indexing: a comprehensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Video annotation; Multimedia semantics; Spatiotemporal fragmentation;
   Video scene interpretation; Multimedia ontologies; Hypervideo
   application
ID ONTOLOGY; EXTRACTION; FRAMEWORK
AB Video annotation tools are often compared in the literature, however, most reviews mix unstructured, semi-structured, and the very few structured annotation software. This paper is a comprehensive review of video annotations tools generating structured data output for video clips, regions of interest, frames, and media fragments, with a focus on Linked Data support. The tools are compared in terms of supported input and output data formats, expressivity, annotation specificity, spatial and temporal fragmentation, the concept mapping sources used for Linked Open Data (LOD) interlinking, provenance data support, and standards alignment. Practicality and usability aspects of the user interface of these tools are highlighted. Moreover, this review distinguishes extensively researched yet discontinued semantic video annotation software from promising state-of-the-art tools that show new directions in this increasingly important field.
C1 [Sikos, Leslie F.] Flinders Univ S Australia, Sch Comp Sci Engn & Math, Ctr Knowledge & Interact Technol, GPO Box 2100, Adelaide, SA 5001, Australia.
C3 Flinders University South Australia
RP Sikos, LF (corresponding author), Flinders Univ S Australia, Sch Comp Sci Engn & Math, Ctr Knowledge & Interact Technol, GPO Box 2100, Adelaide, SA 5001, Australia.
EM leslie.sikos@flinders.edu.au
RI Sikos, Leslie/A-6586-2017
OI Sikos, Leslie/0000-0003-3368-2215
CR [Anonymous], 2010, P 18 ACM INT C MULT
   Aydinlilar M., 2013, COMPUTER INFORM SCI, P303, DOI DOI 10.1007/978-1-4471-4594-3_31
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P313, DOI 10.1007/s11042-009-0342-4
   Bellini P, 2015, MULTIMED TOOLS APPL, V74, P8219, DOI 10.1007/s11042-014-2052-9
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V73, P663, DOI 10.1007/s11042-011-0936-5
   Bertini M., 2006, PROC 14 ANN ACM INT, P787
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Bohlken Wilfried, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P112, DOI 10.1007/978-3-642-23968-7_12
   Carrer M, 1998, KLUW S MULTIMED SYST, P161
   Choudhury S, 2010, SEMAPRO 2010: THE FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN SEMANTIC PROCESSING, P126
   Elleuch N., 2011, MDMKDD, V11
   Gómez-Romero J, 2011, EXPERT SYST APPL, V38, P7494, DOI 10.1016/j.eswa.2010.12.118
   Grassi M, 2012, COGN COMPUT, V4, P497, DOI 10.1007/s12559-012-9172-1
   Guo KH, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/407917
   Haslhofer B, 2010, 6 INT C SEM SYST GRA, DOI 10.1145/1839707.1839757
   Haslhofer B, 2009, INT J DIGIT LIBRARIE, V10, P15, DOI 10.1007/s00799-009-0050-8
   Heggland J., 2002, Research and Advanced Technology for Digital Libraries. 6th European Conference, ECDL 2002. Proceedings (Lecture Notes in Computer Science Vol.2458), P118
   Hunter J, 1999, LECT NOTES COMPUT SC, V1696, P76
   Hunter J, 2003, VANNOTEA SCREENSHOT
   Ibn Khedher M, 2015, LECT NOTES COMPUT SC, V9491, P241, DOI 10.1007/978-3-319-26555-1_28
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Krotzsch M., 2013, ARXIV12014089V3
   Lee MH, 2014, MULTIMED TOOLS APPL, V73, P901, DOI 10.1007/s11042-013-1383-2
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lombardo V, 2014, LECT NOTES COMPUT SC, V8832, P176, DOI 10.1007/978-3-319-12337-0_18
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mazloom M., 2013, Proceedings of the ACM Multimedia Conference, MM'13, P609
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Nixon L., 2012, 8 INT C SEM SYST GRA, P55
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   Poppe C, 2012, MULTIMED TOOLS APPL, V56, P439, DOI 10.1007/s11042-010-0600-5
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sikos L., 2015, Mastering structured data on the semantic web: From html5 microdata to linked open data
   Sikos L. F., 2015, P 8 WORKSH EXPL SEM, P35, DOI 10.1145/2810133.2810141
   Sikos LF, 2016, LECT NOTES ARTIF INT, V9621, P3, DOI 10.1007/978-3-662-49381-6_1
   Simon R, 2011, LECT NOTES COMPUT SC, V6966, P434, DOI 10.1007/978-3-642-24469-8_43
   Steiner T, 2010, 9 INT SEM WEB C SHAN
   Duong TH, 2015, EXPERT SYST APPL, V42, P246, DOI 10.1016/j.eswa.2014.07.046
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Weiss W, 2009, LECT NOTES COMPUT SC, V5887, P52, DOI 10.1007/978-3-642-10543-2_7
   Xu F, 2006, J VIS COMMUN IMAGE R, V17, P701, DOI 10.1016/j.jvcir.2005.10.002
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Yildirim Y, 2013, IEEE T KNOWL DATA EN, V25, P47, DOI 10.1109/TKDE.2011.189
   Zarka M, 2016, MULTIMED TOOLS APPL, V75, P5719, DOI 10.1007/s11042-015-2537-1
NR 46
TC 17
Z9 18
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14437
EP 14460
DI 10.1007/s11042-016-3705-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800033
DA 2024-07-18
ER

PT J
AU Liu, BL
   Li, Y
   Zhang, SY
   Ye, XZ
AF Liu, Baolong
   Li, Yi
   Zhang, Sanyuan
   Ye, Xiuzi
TI Healthy human sitting posture estimation in RGB-D scenes using object
   context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sitting posture estimation; Health; RGB-D scene; Ergonomics
ID ERGONOMICS; DESIGN; INTERVENTION; SENSOR
AB Unhealthy sitting posture leads to cervical spondylosis and other related cumulative trauma disorders (CTDs). Unfortunately, the research on the investigation of heathy sitting posture is rare. The current research is to estimate heathy sitting posture based on a computer workstation ergonomics perspective. A novel RGB-D scene healthy human sitting posture estimation framework was developed to estimate the sitting posture, in which a human posture is represented by 15 skeletal joints. A healthy human sitting posture configuration is defined from the view of ergonomics, a Na < ve Bayes classifier was used to learn the health-constrained spatial and context relationships between objects and the human skeletal joints in the RGB-D scene. At the estimation stage, the object spatial features (e.g., coordinate, distance, height and angle) in the RGB-D scene were obtained through conducting the scene labeling. 15 human skeletal joints were extracted simultaneously from Kinect as primary inputs, and then algorithms were developed to generate and to classify the candidate healthy skeleton joints. Through skeleton refinement, the skeleton joints distribution of a healthy sitting posture was produced. The framework was tested on a dataset comprised of RGB-D scenes, which were collected from 3 subjects (3 types of sitting postures, each in 3 different offices). The experiment results indicate that the framework is feasible and reliable.
C1 [Liu, Baolong; Zhang, Sanyuan] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
   [Li, Yi; Ye, Xiuzi] Wenzhou Univ, Coll Math & Informat Sci, Wenzhou 325000, Peoples R China.
C3 Zhejiang University; Wenzhou University
RP Liu, BL (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.; Ye, XZ (corresponding author), Wenzhou Univ, Coll Math & Informat Sci, Wenzhou 325000, Peoples R China.
EM paulliu@zju.edu.cn; eloveven@gmail.com; syzhang@zju.edu.cn;
   Yexiuzi@wzu.edu.cn
FU China Natural Science Foundation [61272304]; Zhejiang Provincial Natural
   Science Foundation of China [LY14F020027, LQ16F020007]
FX This work was funded by China Natural Science Foundation (No: 61272304)
   and Zhejiang Provincial Natural Science Foundation of China (No.
   LY14F020027, No. LQ16F020007). Many thanks to all reviewers, we
   appreciate their valuable suggestions and questions.
CR Anand A, 2012, INT J ROBOT RES, P1
   [Anonymous], 2010, ADV NEUR INF PROC SY
   [Anonymous], 2014, P INT ACM SIGIR WORK
   [Anonymous], 2010, 2010 IEEE GLOBAL TEL
   [Anonymous], 1977, THEORY AFFORDANCES
   [Anonymous], 2011, P ADV NEURAL INFORM
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chung MK, 1997, COMPUT IND ENG, V33, P521, DOI 10.1016/S0360-8352(97)00183-6
   Daian I., 2007, PROC 14 EUROPEAN C C, P163, DOI [10.1145/1362550.1362583, DOI 10.1145/1362550.1362583]
   Das B, 1996, APPL ERGON, V27, P157, DOI 10.1016/0003-6870(96)00008-7
   Feyen R, 2000, APPL ERGON, V31, P291, DOI 10.1016/S0003-6870(99)00053-8
   Foubert N., 2012, Medical Measurements and Applications Proceedings (MeMeA), 2012 IEEE International Symposium, P1, DOI DOI 10.1109/MEMEA.2012.6226630
   Gjoreski H., 2011, 2011 7th International Conference on Intelligent Environments, P47, DOI 10.1109/IE.2011.11
   Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327
   Grest D, 2005, LECT NOTES COMPUT SC, V3663, P285
   Hochanadel CD, 1995, APPL ERGON, V26, P315, DOI 10.1016/0003-6870(95)00035-6
   Jaschinski W, 1998, ERGONOMICS, V41, P1034, DOI 10.1080/001401398186586
   Jiang Y, 2013, P 23 INT JOINT C ART, P1429
   Jiang Y, 2012, ARXIV1206646
   Jiang Y, 2013, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2013.385
   Kähler O, 2013, IEEE I CONF COMP VIS, P3064, DOI 10.1109/ICCV.2013.380
   Knoop S, 2006, IEEE INT CONF ROBOT, P1686
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kroemer KarlH. E., 2001, OFFICE ERGONOMICS
   Lis AM, 2007, EUR SPINE J, V16, P283, DOI 10.1007/s00586-006-0143-7
   Meyer J, 2010, IEEE SENS J, V10, P1391, DOI 10.1109/JSEN.2009.2037330
   NIE L, 2015, P 23 ANN ACM C MULT, P591, DOI DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Norman DA, 2013, Basic Books
   Okunribido OO, 2006, J SOUND VIB, V298, P540, DOI 10.1016/j.jsv.2006.06.007
   Park MY, 2000, INT J IND ERGONOM, V26, P537, DOI 10.1016/S0169-8141(00)00027-5
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Rubenowitz S, 1997, INT J IND ERGONOM, V19, P271, DOI 10.1016/S0169-8141(96)00036-4
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Salvendy G., 2001, Handbook of industrial engineering: Technology and operations management, V3rd
   Sanders M.S., 1987, Human factors in engineering and design, V6th
   Shikdar AA, 2007, INT J OCCUP SAF ERGO, V13, P215, DOI 10.1080/10803548.2007.11076722
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Sotoyama M, 1996, ERGONOMICS, V39, P877, DOI 10.1080/00140139608964508
   SPRINGER TJ, 1982, APPL ERGON, V13, P211, DOI 10.1016/0003-6870(82)90013-8
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Vergara M, 2006, INT J IND ERGONOM, V36, P937, DOI 10.1016/j.ergon.2006.07.006
   Westgaard RH, 1997, INT J IND ERGONOM, V20, P463, DOI 10.1016/S0169-8141(96)00076-5
   Wong WY, 2008, GAIT POSTURE, V27, P168, DOI 10.1016/j.gaitpost.2007.03.001
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xu WY, 2013, IEEE SENS J, V13, P3926, DOI 10.1109/JSEN.2013.2259589
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhu YD, 2007, LECT NOTES COMPUT SC, V4843, P408
NR 58
TC 14
Z9 15
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10721
EP 10739
DI 10.1007/s11042-015-3189-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400023
DA 2024-07-18
ER

PT J
AU Mahmoodi, MR
   Sayedi, SM
   Karimi, F
AF Mahmoodi, Mohammad Reza
   Sayedi, Sayed Masoud
   Karimi, Fariba
TI Color-based skin segmentation in videos using a multi-step spatial
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin modeling; Skin detection; Face detection; Skin segmentation;
   Computer vision; Image processing
ID FACE DETECTION; IMAGES
AB Recently, skin detection has been employed in multifarious applications of computer vision including face detection, gesture recognition, etc. This is mainly due to the appealing characteristics of skin color and its potency to segment objects. However, there are certain challenges involved in utilizing human complexion as a feature to detect faces, and they have led to the inefficiency of many methods. In order to counteract these factors, in this paper, a skin segmentation method which exploits a multi step diffusion algorithm to detect skin regions is presented. The method starts with conservative extraction of skin seeds in each frame which is accomplished by using fusion of ternary-based human motion detection, modified Bayesian classifier, and a feedback mechanism. Subsequently, these candidate skin pixels are utilized in a 2-stage diffusion scheme to detect other skin pixels. Both quantitative and qualitative results demonstrate the effectiveness of the proposed system in comparison with other works.
C1 [Mahmoodi, Mohammad Reza] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Sayedi, Sayed Masoud; Karimi, Fariba] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
C3 University of California System; University of California Santa Barbara;
   Isfahan University of Technology
RP Mahmoodi, MR (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM mrmahmoodi@umail.ucsb.edu
RI Karimi, Fariba/KHD-3004-2024
OI Karimi, Fariba/0000-0002-2209-7590
CR Abdullah-Al-Wadud M, 2008, FOURTH INTERNATIONAL SYMPOSIUM ON INFORMATION ASSURANCE AND SECURITY, PROCEEDINGS, P83, DOI 10.1109/IAS.2008.65
   Albiol A, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P239, DOI 10.1109/ICIP.2000.899286
   Anghelescu P, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMPUTERS AND ARTIFICIAL INTELLIGENCE (ECAI), DOI 10.1109/ECAI.2013.6636188
   [Anonymous], 2012, 2012 IEEE INT C COMP
   [Anonymous], P 3 ACM IEEE INT C D
   [Anonymous], 2003, PROC GRAPHICON
   [Anonymous], HUMAN SKIN COLOR CLU
   Barbu T, 2014, COMPUT ELECTR ENG, V40, P1072, DOI 10.1016/j.compeleceng.2013.12.004
   Chen YH, 2012, ENG APPL ARTIF INTEL, V25, P1331, DOI 10.1016/j.engappai.2012.02.019
   Choi B, 2011, ADV COMMUN TECHNOL, P13
   Deng-Yuan Huang, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P687, DOI 10.1109/ICGEC.2010.175
   Dowdall J, 2003, IMAGE VISION COMPUT, V21, P565, DOI 10.1016/S0262-8856(03)00055-6
   Du C., 2013, J CHINA U POSTS TELE, V20, P6, DOI DOI 10.1016/S1005-8885(13)60259-9
   Duffner S, 2014, PATTERN RECOGN, V47, P2222, DOI 10.1016/j.patcog.2013.12.014
   Gang Li, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P2013, DOI 10.1109/ICNC.2010.5582393
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Ibrahim N, 2012, INF SYST INFOS 2012, pMM
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Liu S, 2010, PROCEEDINGS OF 2010 INTERNATIONAL SYMPOSIUM ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P266
   Mahmoodi MR, 2014, INF TECHN EL ENG 201
   Mahmoodi MR, 2014, COMP KNOWL ENG 7 INT
   mohair Al., 2013, IMPACT COLOR SPACE H
   Nai-Jian Wang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P333, DOI 10.1109/ISPACS.2012.6473506
   Nalepa J, 2014, ADV INTEL SOFT COMPU, V242, P79, DOI 10.1007/978-3-319-02309-0_8
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pai YT, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1545, DOI 10.1109/ICME.2006.262838
   Phung SL, 2001, ANZIIS 2001: PROCEEDINGS OF THE SEVENTH AUSTRALIAN AND NEW ZEALAND INTELLIGENT INFORMATION SYSTEMS CONFERENCE, P171
   Powar V., 2012, International Conference on Communication, Information Computing Technology, P1
   Qiang-rong jiang, 2010, INFORM MANAGEMENT EN
   Ruiz-del-Solar J, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P463, DOI 10.1109/AFGR.2004.1301576
   Sagheer A, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P90, DOI 10.1109/SITIS.2012.25
   Tan WJ, 2012, CHIN CONT DECIS CONF, P1905, DOI 10.1109/CCDC.2012.6244306
   Thakur S., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P53, DOI 10.1109/WICT.2011.6141217
   Vadakkepat P, 2008, IEEE T IND ELECTRON, V55, P1385, DOI 10.1109/TIE.2007.903993
   Yan-Wen Wu, 2008, 2008 Workshop on Knowledge Discovery and Data Mining (WKDD '08), P339, DOI 10.1109/WKDD.2008.148
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zarit B. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P58, DOI 10.1109/RATFG.1999.799224
   Zhang QS, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P1008
   Zheng Yutong, 2010, Proceedings 2010 International Conference on Digital Manufacturing and Automation (ICDMA 2010), P719, DOI 10.1109/ICDMA.2010.172
   Zhu YL, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P1249
NR 42
TC 7
Z9 7
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9785
EP 9801
DI 10.1007/s11042-016-3579-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300030
DA 2024-07-18
ER

PT J
AU Wang, HC
   Chen, IY
   Chen, WM
AF Wang, Hao-Chun
   Chen, Ing-Yi
   Chen, Wei-Ming
TI Image watermark protection based on self-recovery images and sparse
   approximation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermark; Data protection; Orthogonal matching pursuits; Sparse
   approximation; Tamper recovery
ID FRAGILE WATERMARKING; REMOVAL
AB Here, we present a novel method for data protection to resolve the issue of mass-tampered regions of image watermarks. Our approach involves asymmetric cryptography and follows the nonspatial domain technique, where a codebook exists as a public key and a verification code exists as a private key. There are two major components to our study: self-recovery images and sparse approximation. Specifically, we generate self-recovery images on the basis of our previous research, and to generate verification codes, we mark data with the maximum coefficient resulting from the sparse approximation. The above approach processes 4 x 4 blocks of the given images. The results demonstrate that each block processed by the sparse approximation algorithm has its main texture feature associated with a codeword with a higher sparse coefficient value than the codebook. This provides a robust method to protect data via watermarking and to verify the copyright of the data. Our proposed method efficiently supports compression for transmission via popular communication applications. Using our method under common conditions, we confirmed an outstanding unit correction rate of approximately 90 %, especially for crop-attacked images.
C1 [Wang, Hao-Chun; Chen, Ing-Yi] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, 1,Sec 3,Zhongxiao E Rd, Taipei 10608, Taiwan.
   [Chen, Wei-Ming] Natl Ilan Univ, Dept Comp Sci & Informat Engn, 1,Sec 1,Shen Lung Rd, Ilan 260, Taiwan.
C3 National Taipei University of Technology; National Ilan University
RP Chen, WM (corresponding author), Natl Ilan Univ, Dept Comp Sci & Informat Engn, 1,Sec 1,Shen Lung Rd, Ilan 260, Taiwan.
EM wmchen88@gmail.com
CR Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Breen P, 2009, YEAR 4 PROJECT
   Chang CC, 2004, INFORMATICA-LITHUAN, V15, P147
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Kang LW, 2012, IEEE INT SYMP CIRC S, P1871
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Shih TK, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P15
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Voyatzis G., 1996, Proceedings of the European Conference on Multimedia Applications, Services and Techniques, P687
   Wang H-C, 2014, IJEE, V21
   Wang H-C, 2015, COMPUT SCI INF TECHN, V3, P127, DOI DOI 10.13189/csit.2015.030406
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
NR 19
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9929
EP 9941
DI 10.1007/s11042-016-3588-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300037
DA 2024-07-18
ER

PT J
AU Kim, BS
   Moon, YS
   Lee, JG
AF Kim, Bum-Soo
   Moon, Yang-Sae
   Lee, Jae-Gil
TI Boundary image matching supporting partial denoising using time-series
   matching techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time-series databases; Data mining; Boundary image matching; Time-series
   matching; Moving average transform; Partial denoising
ID TRANSFORM
AB In this paper, we deal with the problem of boundary image matching which finds similar boundary images regardless of partial noise exploiting time-series matching techniques. Time-seris matching techniques make it easier to compute distances for similarity identification, and therefore it is feasible to perform boundary image matching even on a large image database. To solve this problem, we first convert all boundary images into times-series and derive partial denoising time-series. The partial denoising time-series is generated from an original time-series by removing partial noise; that is, it is obtained by changing a position of partial denoising from original time-series. We then introduce the partial denoising distance, which is the minimum distance from a query time-series to all possible partial denoising time-series generated from a data time-series, and propose partial denoising boundary image matching using the partial denoising distance as a similarity measure. Computing the partial denoising distance, however, incurs a severe computational overhead since there are a large number of partial denoising time-series to be considered. Thus, in order to improve its performance, we present a tight lower bound of the partial denoising distance and also optimize the computation of the partial denoising distance. We finally propose range and k-NN query algorithms according to a query processing method for partial denoising boundary image matching. Through extensive experiments, we show that our lower bound-based approach and the optimization method of the partial denoising distance improve search performance by up to an order of magnitude.
C1 [Kim, Bum-Soo; Lee, Jae-Gil] Korea Adv Inst Sci & Technol, Dept Knowledge Serv Engn, Daejeon, South Korea.
   [Moon, Yang-Sae] Kangwon Natl Univ, Dept Comp Sci, Chunchon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Kangwon
   National University
RP Lee, JG (corresponding author), Korea Adv Inst Sci & Technol, Dept Knowledge Serv Engn, Daejeon, South Korea.
EM bumsoo.kim@kaist.ac.kr; ysmoon@kangwon.ac.kr; jaegil@kaist.ac.kr
RI Lee, Jae-Gil/C-1840-2011
FU MOLIT(The Ministry of Land, Infrastructure and Transport), Korea
   [16NSIP-B081011-03]
FX This research, "Geospatial Big Data Management, Analysis and Service
   Platform Technology Development," was supported by the MOLIT(The
   Ministry of Land, Infrastructure and Transport), Korea, under the
   national spatial information research program supervised by the
   KAIA(Korea Agency for Infrastructure Technology Advancement)
   (16NSIP-B081011-03).
CR Agrawal R., 1993, Proceedings of the International Conference on Foundations of Data Organization and Algorithms, Chicago, IL, P69
   [Anonymous], P 7 EUR C COMP VIS C
   [Anonymous], 2002, P 2002 ACM SIGMOD IN, DOI DOI 10.1145/564691.564735
   [Anonymous], P 34 INT C VER LARG
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chu K. K. W., 1999, Proceedings of the Eighteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, P237, DOI 10.1145/303976.304000
   Faloutsos Christos., 1994, ACM SIGMOD Record, V23, P419
   Gil MS, 2011, IEICE T INF SYST, VE94D, P917, DOI 10.1587/transinf.E94.D.917
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Han Wook-Shin., 2011, SIGMOD, P457
   Holte MB, 2010, COMPUT VIS IMAGE UND, V114, P1353, DOI 10.1016/j.cviu.2010.07.012
   Kim BS, 2014, MULTIMED TOOLS APPL, V72, P2543, DOI 10.1007/s11042-013-1552-3
   Lin CH, 2011, COMPUT J, V54, P1136, DOI 10.1093/comjnl/bxq066
   Liu HS, 2012, NEUROCOMPUTING, V92, P156, DOI 10.1016/j.neucom.2012.01.028
   Loh WK, 2004, DATA MIN KNOWL DISC, V9, P5, DOI 10.1023/B:DAMI.0000026902.89522.a3
   Moon YS, 2007, INFORM SCIENCES, V177, P5415, DOI 10.1016/j.ins.2007.05.038
   Moon YS, 2014, INFORM SCIENCES, V270, P28, DOI 10.1016/j.ins.2014.02.127
   Moon YS, 2010, DATA KNOWL ENG, V69, P1022, DOI 10.1016/j.datak.2010.07.001
   Pratt W., 2007, DIGITAL IMAGE PROCES, V4th
   Rafiei D, 2000, IEEE T KNOWL DATA EN, V12, P675, DOI 10.1109/69.877502
   Shumway R., 2006, Time series analysis and its applications with R examples
   SUETENS P, 1992, COMPUT SURV, V24, P5, DOI 10.1145/128762.128763
   Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784
   Vlachos M., 2005, PROC 14 ACM INT C IN, P131
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
NR 25
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8471
EP 8496
DI 10.1007/s11042-016-3479-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800038
DA 2024-07-18
ER

PT J
AU Miao, Z
   Zhang, Y
   Zheng, ZB
   Sun, ZX
AF Miao, Zheng
   Zhang, Yan
   Zheng, Zhibin
   Sun, Zhengxing
TI Image palette: painting style transfer via brushstroke control synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Style transfer; Brush stroke synthesis; Painting based on the samples;
   Non-photorealistic rendering
ID COMPLETION
AB As one kind of technology of style transfer, painting style transfer can be used to render the sample images with a specific art style. With this technology, we can render the target images in the same style as the samples after some computation. We present a new approach of painting style transfer in which such a style transfer artwork is done by simulating the process of creation. We take the sample as a palette where users can select arbitrary contours or textures as the input brush strokes. We then analyze the style feature of the brush strokes and use this feature for synthesis and style transfer along the stroke curves learned from the specified area in target images or target 3D models to get the same painting style as the samples. Based on this approach, we also design and realize the corresponding painting system. The results show that the users can get a style-transferred personalized target image just by using the given sample images with the least interactions.
C1 [Miao, Zheng; Zhang, Yan; Zheng, Zhibin] Nanjing Univ, Nanjing, Jiangsu, Peoples R China.
   [Sun, Zhengxing] Nanjing Univ, Comp Sci, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University; Nanjing University
RP Miao, Z (corresponding author), Nanjing Univ, Nanjing, Jiangsu, Peoples R China.
EM b091220080@smail.nju.edu.cn
RI miao, zheng/A-8851-2012; Sun, Zhengxing/A-7411-2011
OI Sun, Zhengxing/0000-0001-7137-6169
FU National Science Foundation of China [61321491, 61100110, 61272219];
   Science and Technology Program of Jiangsu Province [BY2012190,
   BY2013072-04]
FX We would like to thank al l anonymous reviewers for their constructive
   comments. This research has been supported by the National Science
   Foundation of China (61321491, 61100110, 61272219) and the Science and
   Technology Program of Jiangsu Province (BY2012190, BY2013072-04).
CR [Anonymous], 2002, NPAR 02 P 2 INT S NO, P434
   [Anonymous], 2001, Schooling for Tomorrow
   [Anonymous], 2008, CVPR
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   BELLMAN R, 1956, P NATL ACAD SCI USA, V42, P767, DOI 10.1073/pnas.42.10.767
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brito A., 2008, Blender 3D: Architecture, Buildings, and Scenery: Create photorealistic 3D architectural visualizations of buildings, interiors, and environmental scenery
   DiVerdi S, 2013, IEEE T VIS COMPUT GR, V19, P723, DOI 10.1109/TVCG.2012.295
   FINKELSTEIN A., 2010, P I3D 2010
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Hays J., 2004, PROC NPAR 01, P113
   He KM, 2012, LECT NOTES COMPUT SC, V7573, P16, DOI 10.1007/978-3-642-33709-3_2
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hertzmann A, SIGGRAPH 01, P327, DOI [10.1145/383259.3832952001, DOI 10.1145/383259.3832952001]
   Huang H, 2010, VISUAL COMPUT, V26, P933, DOI 10.1007/s00371-010-0498-y
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Lasram Anass, 2012, P 4 ACM SIGGRAPHEURO, P115
   Lee H., 2010, Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering, P43
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P541, DOI 10.1145/1141911.1141921
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Lu JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461998
   Lukác M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461956
   Miao Z, IMAGE PALETTE BRUSHS, P55
   Nehab D, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P244, DOI 10.1109/SIBGRA.2002.1167151
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 1994, PERFORM EVALUATION
   Olsen SvenC., 2005, P GRAPHICS INTERFACE, P241
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ritter Lincoln., 2006, P 17 EUROGRAPHICS C, P371
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Wang B, 2004, IEEE T VIS COMPUT GR, V10, P266, DOI 10.1109/TVCG.2004.1272726
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Zang Y, 2013, J COMPUT SCI TECH-CH, V28, P762, DOI 10.1007/s11390-013-1375-8
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhang E, 2007, IEEE T VIS COMPUT GR, V13, P94, DOI 10.1109/TVCG.2007.16
   Zhao M., 2011, Proc. NPAR '11, P137, DOI DOI 10.1145/2024676.2024698
NR 36
TC 2
Z9 2
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7989
EP 8010
DI 10.1007/s11042-016-3408-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800018
DA 2024-07-18
ER

PT J
AU Mora, EG
   Cagnazzo, M
   Dufaux, F
AF Mora, Elie Gabriel
   Cagnazzo, Marco
   Dufaux, Frederic
TI AVC to HEVC transcoder based on quadtree limitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; AVC; Transcoding; Quadtree limitation
ID VIDEO; EFFICIENCY; H.264/AVC
AB Following the finalization of the state-of-the-art High Efficiency Video Coding (HEVC) standard in January 2013, several new services are being deployed in order to take advantage of the superior coding efficiency (estimated at 50 % less bitrate for the same visual quality) that this standard provides over its predecessor: H.264 / Advanced Video Coding (AVC). However, the switch from AVC to HEVC is not trivial as most video content is still encoded in AVC. Consequently, there is a growing need for fast AVC to HEVC transcoders in the market today. While a trivial transcoder can be made by simply cascading an AVC decoder and an HEVC encoder, fast transcoding cannot be achieved. In this paper, we present an AVC to HEVC transcoder where decoded AVC blocks are first fused according to their motion similarity. The resulting fusion map is then used to limit the quadtree of HEVC coded frames. AVC motion vectors are also used to determine a better starting point for integer motion estimation. Experimental results show that significant transcoder execution time savings of 63 % can be obtained with only a 1.4 % bitrate increase compared to the trivial transcoder.
C1 [Mora, Elie Gabriel] ATEME, Velizy Villacoublay, France.
   [Cagnazzo, Marco; Dufaux, Frederic] Univ Paris Saclay, LTCI, CNRS, Telecom ParisTech, F-75013 Paris, France.
C3 Universite Paris Saclay; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris; Universite Paris Cite; Centre
   National de la Recherche Scientifique (CNRS)
RP Cagnazzo, M (corresponding author), Univ Paris Saclay, LTCI, CNRS, Telecom ParisTech, F-75013 Paris, France.
EM elie-gabriel.mora@telecom-paristech.fr; cagnazzo@telecom-paristech.fr;
   frederic.dufaux@telecom-paristech.fr
RI Cagnazzo, Marco/AAZ-3881-2020; Dufaux, Frederic/HJJ-1496-2023
OI Cagnazzo, Marco/0000-0001-6731-3755; Dufaux,
   Frederic/0000-0001-6388-4112
FU Eurostars-Eureka Project Transcoders Of the Future TeleVision (TOFuTV)
   [E! 8307]
FX This work has been performed in the framework of the Eurostars-Eureka
   Project E! 8307 - Transcoders Of the Future TeleVision (TOFuTV).
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   [Anonymous], HM 13 0 REFERENCE SO
   [Anonymous], 2014, SIGNAL IMAGE PROCESS
   Bjontegaard G., 2001, VCEG M AUST US
   Chen Z, 2013, FAST INTERPREDICTION
   Díaz-Honrubia AJ, 2014, IEEE IMAGE PROC, P2497, DOI 10.1109/ICIP.2014.7025505
   Diaz-Honrubia Antonio Jesus, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P593, DOI 10.1007/978-3-319-04114-8_50
   Dong Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P651, DOI 10.1109/ICME.2012.112
   Garrido-Cantos R, 2013, TELECOMMUN SYST, V52, P2655, DOI 10.1007/s11235-011-9594-1
   Han WJ, 2010, IEEE T CIRC SYST VID, V20, P1709, DOI 10.1109/TCSVT.2010.2092612
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   Díaz-Honrubia AJ, 2016, IEEE T CIRC SYST VID, V26, P154, DOI 10.1109/TCSVT.2015.2473299
   Jiang W., 2013, MULTIMED TOOLS APPL, P1
   Kaware S, 2015, INT C PERV COMP ICPC
   Li Xiang, 2014, ScientificWorldJournal, V2014, P540496, DOI 10.1155/2014/540496
   Mora EG, 2014, IEEE T CIRC SYST VID, V24, P1554, DOI 10.1109/TCSVT.2013.2283110
   Peixoto E, 2013, IEEE IMAGE PROC, P1972, DOI 10.1109/ICIP.2013.6738406
   Peixoto E, 2014, IEEE T CIRC SYST VID, V24, P99, DOI 10.1109/TCSVT.2013.2273651
   Peixoto E, 2012, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2012.6466965
   Shen T, 2013, IEEE DATA COMPR CONF, P241, DOI 10.1109/DCC.2013.32
   Simpson C, 2013, SAMSUNGS GALAXY S4 H
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Xing P., 2013, Visual Communications and Image Processing (VCIP), 2013, P1
NR 26
TC 3
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8991
EP 9015
DI 10.1007/s11042-016-3498-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800061
DA 2024-07-18
ER

PT J
AU Rahman, AKMM
   Anam, ASMI
   Yeasin, M
AF Rahman, A. K. M. Mahbubur
   Anam, A. S. M. Iftekhar
   Yeasin, Mohammed
TI <i>EmoAssist</i>: emotion enabled assistive tool to enhance dyadic
   conversation for the blind
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Feature extraction; Mobile-server
   communication; Video feed; Multimedia for blind; Soocial interaction;
   Affective dimensions
ID FACIAL EXPRESSION; POWER
AB This paper presents the design and implementation ofEmoAssist: a smart-phone based system to assist in dyadic conversations. The main goal of the system is to provide access to more non-verbal communication options to people who are blind or visually impaired. The key functionalities of the system are to predict behavioral expressions (such a yawn, a closed lip smile, a open lip smile, looking away, sleepy, etc.) and 3-D affective dimensions (valence, arousal, and dominance) from visual cues in order to provide the correct auditory feedback or response. A number of challenges related to the data communication protocols, efficient tracking of the face, modeling of behavioral expressions/affective dimensions, feedback mechanism and system integration were addressed to build an effective and functional system. In addition, orientation-sensor information from the smart-phone was used to correct image alignment to improve the robustness for real world application. Empirical studies show that the EmoAssist can predict affective dimensions with acceptable accuracy (Maximum Correlation-Coefficient for valence: 0.76, arousal: 0.78, and dominance: 0.76) in natural dyadic conversation. The overall minimum and maximum response-times are (64.61 milliseconds) and (128.22 milliseconds), respectively. The integration of sensor information for correcting the orientation improved (16 % in average) the accuracy in recognizing behavioralexpressions. A usability study with ten blind people in social interaction shows that the EmoAssist is highly acceptable with an Average acceptability rating using of 6.0 in Likert scale (where 1 and 7 are the lowest and highest possible ratings, respectively).
C1 [Rahman, A. K. M. Mahbubur] Eyelock, Nyc, NY 10017 USA.
   [Rahman, A. K. M. Mahbubur] Eyelock, Lawrenceville, NJ 08648 USA.
   [Anam, A. S. M. Iftekhar] Univ Memphis, Dept Elect & Comp Engn, Comp Engn, Memphis, TN 38152 USA.
   [Yeasin, Mohammed] Univ Memphis, Dept Elect & Comp Engn, Memphis, TN 38152 USA.
   [Yeasin, Mohammed] Univ Memphis, Biomed Engn & Bioinformat Program, Memphis, TN 38152 USA.
   [Yeasin, Mohammed] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
C3 University of Memphis; University of Memphis; University of Memphis;
   University of Memphis
RP Rahman, AKMM (corresponding author), Eyelock, Nyc, NY 10017 USA.; Rahman, AKMM (corresponding author), Eyelock, Lawrenceville, NJ 08648 USA.
EM mahboob263@yahoo.com; aanam@memphis.edu; myeasin@memphis.edu
FU National Science Foundation, USA [NSF-IIS-0746790]
FX This work was partially funded by National Science Foundation
   (NSF-IIS-0746790), USA.
CR [Anonymous], ACII WORKSH 2009
   [Anonymous], RECOGNIZING FACIAL A
   [Anonymous], IJNGC
   [Anonymous], BR J OPHTHALMOL
   [Anonymous], 2011, IEEE T AFFECTIVE COM
   [Anonymous], 2021, ATLAS EMOTIONS
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], HDB EMOTION ELICITAT
   Atkinson A.P., 2005, EMOTION CONSCIOUSNES, P150
   Boker SM, 2009, PHILOS T R SOC B, V364, P3485, DOI 10.1098/rstb.2009.0152
   Clemons J, 2011, I S WORKL CHAR PROC, P91, DOI 10.1109/IISWC.2011.6114206
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Dunbar NE, 2005, J SOC PERS RELAT, V22, P207, DOI 10.1177/0265407505050944
   Goldie P., 2002, EMOTIONS PHILOS EXPL
   Graesser A. C., 2006, P ANN M COGN SCI SOC, P285
   Grahe JE, 1999, J NONVERBAL BEHAV, V23, P253, DOI 10.1023/A:1021698725361
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Krishna S., 2010, ACM Multimedia, DOI [10.1145/1873951.1874202, DOI 10.1145/1873951.1874202]
   Krishna Sreekar, 2010, CHI 10 EXTENDED ABST, P3637
   LAMB TA, 1981, SOC PSYCHOL QUART, V44, P49, DOI 10.2307/3033863
   Likert R., ARCH PSYCHOL, P1
   Lucey S., 2007, CHAPTER INVESTIGATIN, P275
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Palm G., 2013, Neural Nets and Surroundings, P323
   Peterson L. L., 2007, Computer networks: a systems approach
   Rahman AKMM, 2012, 2012 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Rahman AKMM, 2011, LECT NOTES COMPUT SC, V6975, P598, DOI 10.1007/978-3-642-24571-8_74
   Reshef DN, 2011, SCIENCE, V334, P1518, DOI 10.1126/science.1205438
   RUSSELL JA, 1978, J PERS SOC PSYCHOL, V36, P1152, DOI 10.1037/0022-3514.36.10.1152
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377
   Tanveer M.I., 2012, the proceedings of the 14th International ACM SIGACCESS Conference on Computers and Accessibility, P207
   ur Rehman Shafiq, 2008, Journal of Multimedia, V3, P18, DOI 10.4304/jmm.3.3.18-25
   Vapnik V, 1997, ADV NEUR IN, V9, P281
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   WATSON RW, 1987, ACM T COMPUT SYST, V5, P97, DOI 10.1145/13677.13678
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 38
TC 10
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7699
EP 7730
DI 10.1007/s11042-016-3295-4
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800006
DA 2024-07-18
ER

PT J
AU Su, PC
   Tsai, TF
   Chien, YC
AF Su, Po-Chyi
   Tsai, Tzung-Fu
   Chien, Yu-Chien
TI Partial frame content scrambling in H.264/AVC by information hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video; Video coding; Partial scrambling; H.264/AVC; Information
   hiding; Privacy protection
ID PRIVACY PROTECTION
AB A partial frame content scrambling scheme for H.264/AVC compressed videos is proposed in this research. Some areas of video frames, which are identified as sensitive or privacy regions, will be scrambled to become unintelligible for restricting the access from general public or regular users. The scrambling is achieved by directly modifying or removing the selected data in the H.264/AVC bitstream, which will be embedded and transmitted along with the video via the information hiding technique. The authorized users are able to restore these regions by retrieving the hidden data. The design principle of the proposed scheme is to ensure that the scrambled regions are unrecognizable and can be recovered while other parts are still viewable without being affected much. In addition, the size of video stream has to be maintained reasonably well for fulfilling the requirements of related applications. Experimental results will show the feasibility of the proposed scheme.
C1 [Su, Po-Chyi; Tsai, Tzung-Fu; Chien, Yu-Chien] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taiwan.
C3 National Central University
RP Su, PC (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taiwan.
EM pochyisu@csie.ncu.edu.tw
RI SU, PO-CHYI/GWC-9682-2022
FU Ministry of Science and Technology in Taiwan, ROC [MOST
   102-2221-E-008-073, 104-2221-E-008-075]
FX This research is supported by the Ministry of Science and Technology in
   Taiwan, ROC, under Grants MOST 102-2221-E-008-073 and
   104-2221-E-008-075.
CR Ahn J, 2004, IEEE PAC RIM C MULT, P386
   [Anonymous], CMUCS03119
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], P 14 ANN ACM INT C M
   DUFAUX F, 2006, IEEE WORKSH PRIV RES
   Dufaux F, 2004, P SPIE APPL DIG IM P
   Dufaux F, 2008, IEEE IMAGE PROC, P1688, DOI 10.1109/ICIP.2008.4712098
   Korus P, 2010, IEEE INT CON MULTI, P1073, DOI 10.1109/ICME.2010.5583410
   Krikor L., 2009, EUR J SCI RES, V32, P47
   Lian SG, 2004, IEEE INFOR VIS, P217, DOI 10.1109/IV.2004.1320147
   Lian SG, 2006, IEEE T CONSUM ELECTR, V52, P621, DOI 10.1109/TCE.2006.1649688
   Minemura K., 2014, ASIA PACIFIC SIGNAL, P1
   Minemura K, 2012, IEEE IMAGE PROC, P261, DOI 10.1109/ICIP.2012.6466845
   Senior A., 2009, Protecting Privacy in Video Surveillance
   Senior A, 2003, 22886 IBM
   Su PC, 2011, MULTIMED TOOLS APPL, V52, P529, DOI 10.1007/s11042-009-0458-6
   Tong L, 2010, ELECTRON LETT, V46, P47, DOI 10.1049/el.2010.2068
   Tong LL, 2010, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2010.5653444
   Wang JD, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P802, DOI 10.1109/ICASIC.2007.4415752
NR 19
TC 4
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7473
EP 7496
DI 10.1007/s11042-016-3406-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400061
DA 2024-07-18
ER

PT J
AU Su, QT
   Wang, G
   Lv, GH
   Zhang, XF
   Deng, GL
   Chen, BJ
AF Su, Qingtang
   Wang, Gang
   Lv, Gaohuan
   Zhang, Xiaofeng
   Deng, Guanlong
   Chen, Beijing
TI A novel blind color image watermarking based on Contourlet transform and
   Hessenberg decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contourlet transform; Hessenberg matrix; Color image watermark; Blind
   watermarking
ID SEGMENTATION; SCHEME
AB In this paper, a novel blind color image watermarking based on Contourlet transform and Hessenberg decomposition is proposed to protect digital copyright of color image. Firstly, each color channel of the host image is transformed by Contourlet transform and its low frequency sub-band is divided into 4 x 4 non-overlap coefficient block. Secondly, the coefficient block selected by MD5-based Hash pseudo-random algorithm is decomposed by Hessenberg decomposition. Thirdly, the watermark information permuted by Arnold transform is embedded into the biggest energy element of the upper Hessenberg matrix by quantization technique. In extraction process, the quantization strength is used for blindly extracting watermark information from the attacked host image without the help of any original image. The results show that the proposed scheme has higher imperceptibility and robustness against most common image attacks in comparison with other related methods.
C1 [Su, Qingtang; Wang, Gang; Lv, Gaohuan; Zhang, Xiaofeng; Deng, Guanlong] Ludong Univ, Sch Informat Sci & Engn, Yantai 264025, Shandong, Peoples R China.
   [Chen, Beijing] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Ludong University; Nanjing University of Information Science &
   Technology
RP Su, QT (corresponding author), Ludong Univ, Sch Informat Sci & Engn, Yantai 264025, Shandong, Peoples R China.
EM acsqtwhy@163.com
RI Su, Qingtang/P-4285-2017
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology (CICAEET); NNSF from
   China [61202111, 61471185, 61403180, 61472172, 61502218, 61572258];
   Natural Science Foundation of Shandong Province [ZR2014FM005]; Shandong
   Province Higher Educational Science and Technology Program [J14LN20,
   J12LN05]; Doctoral Foundation of Ludong University [LY2014034]; Shandong
   Province Science and Technology Plan Projects [2015GSF116001]
FX The research was partially supported by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET), NNSF from China (61202111, 61471185, 61403180,
   61472172, 61502218, 61572258), Natural Science Foundation of Shandong
   Province (ZR2014FM005), Shandong Province Higher Educational Science and
   Technology Program (J14LN20, J12LN05), Doctoral Foundation of Ludong
   University (LY2014034), Shandong Province Science and Technology Plan
   Projects (2015GSF116001). The authors would like to thank anonymous
   referees for their valuable comments and suggestions which lead to
   substantial improvements of this paper.
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   [Anonymous], 1992, RFC1321
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Bi HB, 2010, INT CONF SIGN PROCES, P881, DOI 10.1109/ICOSP.2010.5656038
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   [梁栋 Liang Dong], 2008, [光学学报, Acta Optica Sinica], V28, P1469
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Narasimhulu C. V., 2011, INT J COMPUTER APPL, V20, P18
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   Seddik H, 2009, INT J IMAGE GRAPH, V9, P411, DOI 10.1142/S0219467809003514
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   University of Granada, 2012, CVG UGR IM DAT
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 18
TC 41
Z9 42
U1 1
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8781
EP 8801
DI 10.1007/s11042-016-3522-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800051
DA 2024-07-18
ER

PT J
AU Togootogtokh, E
   Shih, TK
AF Togootogtokh, Enkhtogtokh
   Shih, Timothy K.
TI Multimedia content analysis on gesture event detection for a SMART TV
   Keyboard application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture event detection; Gesture event recognition; Computer vision;
   Machine learning for gesture event detection; SMART TV Keyboard
ID GENERALIZED PROCRUSTES ANALYSIS; APPEARANCE MODELS; RECOGNITION;
   ROTATION; CLASSIFICATION; TRACKING; COMPLEX; MATRIX; IMAGE; PCA
AB We have proposed an effective machine learning method to analyze multimedia content addressing gesture event detection and recognition. Our machine learning method is based on well-studied techniques such that Procrustes Analysis, Combination of Local and Global Representations, Linear Shape Model, and application to SMART TV Virtual Keyboard. In this paper, we address gesture event detection specially fingertip gesture detection to get smart and advanced usage of technology. Our modern vision keyboard could be a good next generation replacement of SMART TV remote control. It can be more economical as we don't need physical object like traditional keyboard, remote control and their energy resources like batteries. More information and demonstrations of the proposed keyboard can be accessed at http://video.minelab.tw/MCAoGED/.
C1 [Togootogtokh, Enkhtogtokh; Shih, Timothy K.] Natl Cent Univ, Dept Comp Sci & Informat Engn, MINE Lab, 300 Jhongda Rd, Jhongli 32001, Taoyuan County, Taiwan.
C3 National Central University
RP Togootogtokh, E (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, MINE Lab, 300 Jhongda Rd, Jhongli 32001, Taoyuan County, Taiwan.
EM enkhuun_t@yahoo.com; timothykshih@gmail.com
CR Abdulameer Mohammed Hasan, 2014, SCI WORLD J
   ANDERSON TW, 1963, BIOMETRIKA, V50, P522, DOI 10.1093/biomet/50.3-4.522
   Andrea C, 2001, P IEEE ICCV WORKSH R, P83
   [Anonymous], 2005, TPAMI
   [Anonymous], 1995, P INT WORKSH AUT FAC
   [Anonymous], 1995, International Workshop on Automatic Face- and Gesture-Recognition. IEEE Computer Society
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2007, LECT NOTES
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 1964, Sankhya: Indian J. Stat. ser. A
   [Anonymous], 1993, Statistical Language Learning
   [Anonymous], 2012, Mastering OpenCV With Practical Computer VisionProjects
   [Anonymous], 2002, PRINCIPAL COMPONENT
   Atchle WR, 1975, MULTIVARIATE STAT ME
   Baker S, 2001, PROC CVPR IEEE, P1090
   Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731
   Beltrami E, 1873, SVD SIGNAL PROCESSIN, P9
   Berge J.M.F.T., 1984, PSYCHOMETRIKA, V49, P49
   Brown T., 2000, Proc. Australasian User Interface Conference, V1, P11
   Burgess C, 1998, AIP CONF PROC, V452, P1
   Cardoso JF, 1999, NEURAL COMPUT, V11, P157, DOI 10.1162/089976699300016863
   Cauchy AL, EXER MATH, V4, P74
   Chennubhotla C, 2001, COMP VIS ICCV 2001 P, P1
   Christopher JT, 1998, P 3 IEEE INT C IEEE
   CLIFF N, 1966, PSYCHOMETRIKA, V31, P33, DOI 10.1007/BF02289455
   Commandeur JJ, 1991, MATCHING CONFIGURATI, P13
   Cootes T. F., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P680
   Cootes T.F., 2002, P BRIT MACH VIS C CA, P1
   Crowley J., 1995, International Workshop on Gesture and Face Recognition, P195
   Derpanis K.G., 2005, Lecture Notes
   Dijksterhuis G B., 1991, Food Quality and Preference, V3, P67
   Everson R., 1998, Advances in Computational Mathematics
   Fisher RA, 1923, J AGR SCI, V13, P311, DOI 10.1017/S0021859600003592
   FORBES K, 2005, P 2005 ACM SIGGRAPH
   François ARJ, 1999, INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY, PROCEEDINGS, P227
   Gower J, 1995, ORTHOGONAL PROJECTIO
   GOWER J., 2004, Procrustes Problems
   GOWER JC, 1966, BIOMETRIKA, V53, P325, DOI 10.2307/2333639
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Green B. F., 1952, Psychometrika, V17, P429, DOI [10.1007/BF02288918, DOI 10.1007/BF02288918]
   Green BF, 1979, ANN M PSYCH SOC MONT
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   GRUEN AW, 2003, GEN PROCRUSTES ANAL
   Holzmann GJ, 1925, FINITE STATE MACHINE
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hou XW, 2001, PROC CVPR IEEE, P828
   Hubert M, 2004, BIOINFORMATICS, V20, P1728, DOI 10.1093/bioinformatics/bth158
   HURLEY JR, 1962, BEHAV SCI, V7, P258, DOI 10.1002/bs.3830070216
   Igual L, 2014, PATTERN RECOGN, V47, P659, DOI 10.1016/j.patcog.2013.08.006
   Jeffers J, 1967, APPL STAT, V16, P225, DOI DOI 10.1038/S41598-017-00047-5
   Jordan C., 1874, J MATH PURE APPL, V19, P35
   KARHUNEN J, 1994, NEURAL NETWORKS, V7, P113, DOI 10.1016/0893-6080(94)90060-4
   Keaton T, 2002, SIXTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P75, DOI 10.1109/ISWC.2002.1167221
   KIERS HAL, 1992, PSYCHOMETRIKA, V57, P371, DOI 10.1007/BF02295425
   Kristof W, 1971, P ANN CONV AM PSYCH
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Li F, 2005, IEEE T PATTERN ANAL, V27, P1686, DOI 10.1109/TPAMI.2005.224
   LINGOES JC, 1978, PSYCHOMETRIKA, V43, P491, DOI 10.1007/BF02293810
   Lu H, 2006, NEURAL NETW IEEE T, V19, P18
   Lu W.-L., 2006, The 3rd Canadian Conference on Computer and Robot Vision (CRV'06), P6
   Marcell S, HAND POSTURE GESTURE
   Mika S, 1998, NIPS, V4
   Mosier CI, 1939, PSYCHOMETRIKA, V4, P149, DOI 10.1007/BF02288493
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   Pearson K, 1901, DUBLIN PHILOS MAG J, V6, P572
   PEAY ER, 1988, PSYCHOMETRIKA, V53, P199, DOI 10.1007/BF02294132
   Preisendorfer RW, 1988, PRINCIPAL COMPONENT, V425
   Quach KG, 2012, COMPUTING COMMUNICAT, P1
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren Y, 2009, IEEE I C EMBED SOFTW, P344, DOI 10.1109/ICESS.2009.21
   Ross Amy, TECHNICAL REPORT
   Sato Y, 2000, P 4 IEEE INT C AUT F, V462-467, P28
   SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451
   SCHONEMANN PH, 1970, PSYCHOMETRIKA, V35, P245, DOI 10.1007/BF02291266
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Song G, 2003, P SOC PHOTO-OPT INS, V5286, P139, DOI 10.1117/12.538839
   STEWART GW, 1993, SIAM REV, V35, P551, DOI 10.1137/1035134
   Ten Berge JMF, 1977, PSYCHOMETRIKA, V42, P267, DOI 10.1007/BF02294053
   Thirumuruganathan S., 2010, A detailed introduction to k-nearest neighbor (knn) algorithm
   Tomita Jr A, 1925, 20 INT C IND EL CONT, V3, P5
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Wang RW, 2009, ADVANCES IN GEOSCIENCES, VOL 12, P1
   Wöhler C, 1999, IEEE T NEURAL NETWOR, V10, P1531, DOI 10.1109/72.809100
   Wu Y, 2000, TECHNICAL REPORT
   Wu YW, 2014, IEEE T CIRC SYST VID, V24, P865, DOI 10.1109/TCSVT.2013.2291283
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yan Yan, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P2842, DOI 10.1109/ICIP.2013.6738585
NR 88
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7341
EP 7363
DI 10.1007/s11042-016-3385-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400055
DA 2024-07-18
ER

PT J
AU Chen, C
   Zhang, BC
   Hou, ZJ
   Jiang, JJ
   Liu, MY
   Yang, Y
AF Chen, Chen
   Zhang, Baochang
   Hou, Zhenjie
   Jiang, Junjun
   Liu, Mengyuan
   Yang, Yun
TI Action recognition from depth sequences using weighted fusion of 2D and
   3D auto-correlation of gradients features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Depth data; Depth motion maps; Gradient local
   autocorrelations; Space-time auto-correlation of gradients; Extreme
   learning machine; Weighted fusion
ID HISTOGRAMS
AB This paper presents a new framework for human action recognition from depth sequences. An effective depth feature representation is developed based on the fusion of 2D and 3D auto-correlation of gradients features. Specifically, depth motion maps (DMMs) are first employed to transform a depth sequence into three images capturing shape and motion cues. A feature extraction method utilizing spatial and orientational auto-correlations of image local gradients is introduced to extract features from DMMs. Space-time auto-correlation of gradients features are also extracted from depth sequences as complementary features to cope with the temporal information loss in the DMMs generation. Each set of features is used as input to two extreme learning machine classifiers to generate probability outputs. A weighted fusion strategy is proposed to assign different weights to the classifier probability outputs associated with different features, thereby providing more flexibility in the final decision making. The proposed method is evaluated on two depth action datasets (MSR Action 3D and MSR Gesture 3D) and obtains the state-of-the-art recognition performance (94.87 % for the MSR Action 3D and 98.50 % for the MSR Gesture 3D).
C1 [Chen, Chen] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.
   [Zhang, Baochang; Yang, Yun] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
   [Hou, Zhenjie] Changzhou Univ, Sch Informat Sci & Engn, Changzhou, Peoples R China.
   [Jiang, Junjun] China Univ Geosci, Sch Comp Sci, Wuhan, Peoples R China.
   [Liu, Mengyuan] Peking Univ, Shenzhen Grad Sch, Engn Lab Intelligent Percept Internet Things ELIP, Shenzhen, Peoples R China.
C3 University of Texas System; University of Texas Dallas; Beihang
   University; Changzhou University; China University of Geosciences;
   Peking University
RP Zhang, BC (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.; Hou, ZJ (corresponding author), Changzhou Univ, Sch Informat Sci & Engn, Changzhou, Peoples R China.
EM chenchen870713@gmail.com; bczhang@buaa.edu.cn; houzj@cczu.edu.cn;
   junjun0595@163.com; liumengyuan@pku.edu.cn; bhu_yunyang@163.com
RI Liu, Mengyuan/HZL-2276-2023; Jiang, Junjun/L-7087-2019; Hou,
   Zhenjie/HKW-7644-2023
OI Jiang, Junjun/0000-0002-5694-505X; Liu, Mengyuan/0000-0002-6332-8316
FU Natural Science Foundation of China [61272052, 61473086]; Program for
   New Century Excellent Talents University of Ministry of Education of
   China; PAPD; CICAEET
FX This work was supported in the part by Natural Science Foundation of
   China, under Contracts 61272052 and 61473086, and by the Program for New
   Century Excellent Talents University of Ministry of Education of China.
   Thanks for the support of PAPD and CICAEET. Baochang Zhang is the
   correspondence.
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   [Anonymous], PATTERN RECOGNITION
   Chen C, 2015, LAND USE SCENE CLASS
   Chen C, 2015, LECT NOTES COMPUT SC, V9474, P613, DOI 10.1007/978-3-319-27857-5_55
   Chen C, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P324, DOI 10.1109/BigMM.2015.23
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen C, 2014, IEEE ENG MED BIO, P4135, DOI 10.1109/EMBC.2014.6944534
   Chen C, 2014, IEEE ENG MED BIO, P4983, DOI 10.1109/EMBC.2014.6944743
   Cheng CF, 2013, EVID-BASED COMPL ALT, V2013, DOI [10.1155/2013/613950, 10.1155/2013/958025]
   Chenyang Z, 2013, 2013 IEEE C COMP VIS
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Georgios E, 2014, 2014 22 INT C PATT R
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jiang W, 2012, 2012 IEEE C COMP VIS
   Kobayashi T, 2008, LECT NOTES COMPUT SC, V5302, P346, DOI 10.1007/978-3-540-88682-2_27
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Kong Y, 2015, IEEE INT CONF AUTOMA
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Liu L., 2013, 23 INT JOINT C ART I
   Lu X, 2013, 2013 IEEE C COMP VIS
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Omar O, 2013, 2013 IEEE C COMP VIS
   Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044
   Raviteja V, 2014, 2014 IEEE C COMP VIS
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wanqing L, 2010, 2010 IEEE COMP SOC C
   Xiaodong Y, 2012, 2012 IEEE COMP SOC C
   Xiaodong Y, 2014, 2014 IEEE C COMP VIS
   Xiaodong Y, 2012, P 20 ACM INT C MULT
   Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
NR 39
TC 32
Z9 40
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4651
EP 4669
DI 10.1007/s11042-016-3284-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200071
DA 2024-07-18
ER

PT J
AU Parkkila, J
   Radulovic, F
   Garijo, D
   Poveda-Villalón, M
   Ikonen, J
   Porras, J
   Gómez-Pérez, A
AF Parkkila, Janne
   Radulovic, Filip
   Garijo, Daniel
   Poveda-Villalon, Maria
   Ikonen, Jouni
   Porras, Jari
   Gomez-Perez, Asuncion
TI An ontology for videogame interoperability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video game ontology; Video game interoperability; Ontology evaluation
AB During the last 20 years, video games have become very popular and widely adopted in our society. However, despite the growth on video game industry, there is a lack of interoperability that allow developers to interchange their information freely and to form stronger partnerships. In this paper we present the Video Game Ontology (VGO), a model for enabling interoperability among video games and enhancing data analysis of gameplay information. We describe the creation process of the ontology, the ontology conceptualization and its evaluation. In addition, we demonstrate the applicability of the Video Game Ontology in action with three example games that take advantage of the created ontology. Also, we demonstrate the use of the VGO in enabling interoperability among the example games.
C1 [Parkkila, Janne; Ikonen, Jouni; Porras, Jari] Lappeenranta Univ Technol, Sch Business & Management Innovat & Software, Lappeenranta, Finland.
   [Radulovic, Filip; Garijo, Daniel; Poveda-Villalon, Maria; Gomez-Perez, Asuncion] Univ Politecn Madrid, Ontol Engn Grp Madrid, Madrid, Spain.
C3 Lappeenranta-Lahti University of Technology LUT; Universidad Politecnica
   de Madrid
RP Parkkila, J (corresponding author), Lappeenranta Univ Technol, Sch Business & Management Innovat & Software, Lappeenranta, Finland.
EM janne.parkkila@lut.fi
RI Garijo, Daniel/H-8846-2019; Poveda-Villalón, María/J-4530-2012;
   Radulovic, Filip/J-6744-2012; Porras, Jari/E-7707-2011
OI Garijo, Daniel/0000-0003-0454-7145; Poveda-Villalón,
   María/0000-0003-3587-0367; Porras, Jari/0000-0003-3669-8503
FU FPU grants of the Spanish Ministry of Education, Culture and Sport
   [FPU2012/04084, AP2010-1393]; TEKES, the Finnish Funding Agency for
   Innovation
FX This paper has been supported by the FPU grants (FPU2012/04084 and
   AP2010-1393) of the Spanish Ministry of Education, Culture and Sport. In
   addition, the research has been supported by TEKES, the Finnish Funding
   Agency for Innovation.
CR [Anonymous], 2013, Essential facts about the computer and video game industry
   [Anonymous], 9 INT C COMP AID IND
   Blackett Tom., 1999, COBRANDING SCI ALLIA
   Carton M.F., 2013, ProQuest Dissertations and Theses, P47
   Gulati R, 2000, HARVARD BUS REV, V78, P107
   Juul Jesper., 2012, A Casual Revolution: Reinventing Video Games and Their Players
   Lisboa MTCAG, HELPING DEV LOOK DEE
   Newzoo, 2015, GLOB REP US CHIN TAK
   Parkkila J, 2015, P 11 BIANN C IT SIGC, P26
   Poveda-Villalón M, 2014, INT J SEMANT WEB INF, V10, P7, DOI 10.4018/ijswis.2014040102
   Prata W, 2012, WORK, V41, P1124, DOI 10.3233/WOR-2012-0292-1124
   Sotamaa O., 2010, TRIM RES REPORTS, V2
   Suarez-Figueroa MC, 2015, APPL ONTOL, P1
   Tang T, 2007, JMM-INT J MEDIA MANA, V9, P127, DOI 10.1080/14241270701632654
   Uschold M, 1996, KNOWL ENG REV, V11, P93, DOI 10.1017/S0269888900007797
   Van Buskirk RE, 2010, US Patent App, Patent No. [12/756, 505, 12756505]
   Washburn JH, 2000, J CONSUM MARK, V17, P591, DOI 10.1108/07363760010357796
   Zagal J, 2008, P INT C LEARN SCI IC
   Zagal J., 2008, Proceedings of the 8th International Conference on International Conference for the Learning Sciences, V2, P499
NR 19
TC 1
Z9 1
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4981
EP 5000
DI 10.1007/s11042-016-3552-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500015
DA 2024-07-18
ER

PT J
AU Roy, S
   Pal, AK
AF Roy, Soumitra
   Pal, Arup Kumar
TI A robust blind hybrid image watermarking scheme in RDWT-DCT domain using
   Arnold scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robustness; Blind watermarking; Redundant discrete wavelet transform;
   Discrete cosine transform; Repetition code; Arnold scrambling
ID MULTIPLE WATERMARKING; SVD
AB To compromise between imperceptibility and robustness property of robust image watermarking technique, a RDWT-DCT based blind image watermarking scheme using Arnold scrambling is presented in this paper. Firstly, RDWT (Redundant Discrete Wavelet Transform) is applied to each gray scale cover image block after the image is decomposed into fixed size non overlapping blocks. Secondly, the binary watermark logo is encrypted by Arnold chaotic map and reshaped to a sequence to improve the security of the logo. In the subsequent step, DCT (Discrete Cosine Transform) is employed on each LH subband of the non-overlapping host image block. Finally, after zigzag scanning of each DCT block a binary bit of watermark is embedded into each block by adjusting some middle significant AC coefficients using repetition code. Experimental results show that robustness is achieved by recovering satisfactory watermark data from the reconstructed cover image after applying common geometric transformation attacks (like rotation, cropping, scaling, shearing and deletion of lines or column operation etc.), common enhancement technique attacks (like lowpass filtering, histogram equalization, sharpening, gamma correction, noise addition etc.) and JPEG compression attacks. The proposed scheme is also tested to verify the robustness performance against standard benchmark software "Checkmark" and satisfactory results are achieved against the Checkmark attacks such as Hard and Soft Thresholding, Template Removal, Warping, Dithering, Remodulation and Downsampling/Upsampling etc.
C1 [Roy, Soumitra] Dr BC Roy Engn Coll, Dept Comp Sci & Engn, Durgapur 713206, W Bengal, India.
   [Pal, Arup Kumar] Indian Sch Mines, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 Dr. B. C. Roy Engineering College; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (Indian School of Mines)
   Dhanbad
RP Roy, S (corresponding author), Dr BC Roy Engn Coll, Dept Comp Sci & Engn, Durgapur 713206, W Bengal, India.
EM mosinapur.sou@gmail.com; arupkrpal@gmail.com
RI Pal, Arup Kumar/I-2496-2016; ROY, SOUMITRA/U-5923-2018
OI ROY, SOUMITRA/0000-0001-8240-2203; Pal, Arup Kumar/0000-0003-4229-0715
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 1996, P S INF THEOR BEN
   [Anonymous], ELECT IMAGING 99
   [Anonymous], 2006, P 19 C COMP VIS GRAP
   [Anonymous], INTRO ERROR CONTROL
   [Anonymous], REDUNDANT DISCRETE W
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], J MULTIMEDIA
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bhandari K, 2005, LECT NOTES COMPUT SC, V3776, P447
   Campisi P, 2004, IEEE SIGNAL PROC LET, V11, P826, DOI 10.1109/LSP.2004.835463
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chao Wu, 2004, TENCON 2004. 2004 IEEE Region 10 Conference (IEEE Cat. No. 04CH37582), P279
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Chung KL, 2001, PATTERN RECOGN LETT, V22, P1051, DOI 10.1016/S0167-8655(01)00044-7
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Deng FS, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1525
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Fang Ma, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P397, DOI 10.1109/CSSS.2012.106
   Fu YG, 2013, OPTIK, V124, P517, DOI 10.1016/j.ijleo.2011.12.042
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Ghazy Rania A., 2007, 24th Radio National Science Conference (NRSC 2007), P1, DOI 10.1109/NRSC.2007.371376
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Lagzian S., 2011, International Journal of Intelligent Information Processing, V2, P22, DOI DOI 10.4156/IJIIP
   Liang J, 2001, IEEE T SIGNAL PROCES, V49, P3032, DOI 10.1109/78.969511
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Liu JC, 2001, IMAGE VISION COMPUT, V19, P1083, DOI 10.1016/S0262-8856(01)00068-3
   Liu Q, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P873
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Nikolaidis N, 1996, INT CONF ACOUST SPEE, P2168, DOI 10.1109/ICASSP.1996.545849
   ORuanaidh JJK, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P239, DOI 10.1109/ICIP.1996.560428
   Ouhsain M, 2009, EXPERT SYST APPL, V36, P2123, DOI 10.1016/j.eswa.2007.12.046
   Pereira S., 2001, INFORM HIDING, P340, DOI [10.1007/3-540-45496-925, DOI 10.1007/3-540-45496-925]
   Phadikar A, 2011, COMPUT ELECTR ENG, V37, P339, DOI 10.1016/j.compeleceng.2011.02.002
   Premaratne P, 1999, IEE CONF PUBL, P780, DOI 10.1049/cp:19990430
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Raval MS, 2003, TENCON IEEE REGION, P935
   Singh A., 2016, Microscale Technologies for Cell Engineering, DOI [10.1007/978-3-319-20726-1, DOI 10.1007/978-3-319-20726-1, DOI 10.1007/S11042015-27547]
   Singh AK, 2016, MULTIMED TOOLS APPL, P1
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Swanson MD, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P211, DOI 10.1109/ICIP.1996.560421
   Tay P, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P258
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Xiao L, 2006, INT J COMPUT SCI NET, V6, P194
   Zhao Yantao, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P935, DOI 10.1109/CSSE.2008.332
NR 55
TC 57
Z9 58
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3577
EP 3616
DI 10.1007/s11042-016-3902-4
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200021
DA 2024-07-18
ER

PT J
AU Tang, Y
   Zhang, CZ
   Gu, RS
   Li, P
   Yang, B
AF Tang, Yong
   Zhang, Congzhe
   Gu, Renshu
   Li, Peng
   Yang, Bin
TI Vehicle detection and recognition for intelligent traffic surveillance
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle detection; Vehicle recognition; Feature extraction;
   Histogramsequence; Principal component analysis
ID CLASSIFICATION
AB Vehicle detection and type recognition based on static images is highly practical and directly applicable for various operations in a traffic surveillance system. This paper will introduce the processing of automatic vehicle detection and recognition. First, Haar-like features and AdaBoost algorithms are applied for feature extracting and constructing classifiers, which are used to locate the vehicle over the input image. Then, the Gabor wavelet transform and a local binary pattern operator is used to extract multi-scale and multiorientation vehicle features, according to the outside interference on the image and the random position of the vehicle. Finally, the image is divided into small regions, from which histograms sequences are extracted and concentrated to represent the vehicle features. Principal component analysis is adopted to reach a low dimensional histogram feature, which is used to measure the similarity of different vehicles in euler space and the nearest neighborhood is exploited for final classification. The typed experiment shows that our detection rate is over 97 %, with a false rate of only 3 %, and that the vehicle recognition rate is over 91 %, while maintaining a fast processing time. This exhibits promising potential for implementation with real-world applications.
C1 [Tang, Yong; Li, Peng; Yang, Bin] Nanjing Forestry Univ, Sch Automobile & Traff Engn, 159 Lonpan Rd, Nanjing 210037, Jiangsu, Peoples R China.
   [Zhang, Congzhe] Guangzhou Jiaqi Intelligent Technol Ltd, CTO, 243 Kexue Rd, Guangzhou 510000, Guangdong, Peoples R China.
   [Gu, Renshu] Nanjing Univ, Sch Elect Sci & Engn, 22 Hankou Rd, Nanjing 210093, Jiangsu, Peoples R China.
C3 Nanjing Forestry University; Nanjing University
RP Tang, Y (corresponding author), Nanjing Forestry Univ, Sch Automobile & Traff Engn, 159 Lonpan Rd, Nanjing 210037, Jiangsu, Peoples R China.
EM tangyong159@163.com; zhangcongzhe@hotmail.com; renshugu@uw.edu;
   lipengaq@nuaa.edu.cn; yangb123@126.com
FU Nanjing forestry university in China [GXL201315)]; Jiangsu Province
   [14KJB520017]; natural science foundation of Jiangsu Province
   [BK20130981]; science fund of state key laboratory [31415008]
FX The research has been supported by the fund of high academic
   qualification in Nanjing forestry university (GXL201315) in China,
   natural science fund for colleges and universities of Jiangsu Province
   (14KJB520017), the natural science foundation of Jiangsu Province
   (BK20130981), the project supported by the science fund of state key
   laboratory of advanced design and manufacturing for vehicle Body
   (31415008).
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   [Anonymous], 2014, J. Converg. Inf. Technol.
   [Anonymous], TURK J ELECT ENG COM
   [Anonymous], 2001, COMPUTER VISION PATT
   [Anonymous], 2005, P AICS
   [Anonymous], 2014, INT J COMPUT VIS ROB
   Bilgic B, 2010, IEEE INT VEH SYM, P528, DOI 10.1109/IVS.2010.5548142
   Clady X, 2008, LECT NOTES ARTIF INT, V5064, P228, DOI 10.1007/978-3-540-69939-2_22
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Fazli S., 2012, International Journal of Software Engineering Applications, V3, P17, DOI DOI 10.5121/IJSEA.2012.3302
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Kazemi FM, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P939
   Kim H, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0009-7
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Negri P, 2006, INT C PATT RECOG, P574
   Park KY, 2014, PATTERN RECOGN LETT, V42, P148, DOI 10.1016/j.patrec.2014.02.015
   Pearce G., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P373, DOI 10.1109/AVSS.2011.6027353
   Peng Y., 2013, ERA INTERACTIVE MEDI, P325, DOI DOI 10.1007/978-1-4614-3501-3_27
   Petrovic Vladimir S., 2004, BMVC, P1
   Psyllos A, 2011, COMPUT STAND INTER, V33, P142, DOI 10.1016/j.csi.2010.06.005
   Psyllos AP, 2010, IEEE T INTELL TRANSP, V11, P322, DOI 10.1109/TITS.2010.2042714
   Sam K.-T., 2012, Proceedings of 2012 4th International Conference on Machine Learning and Computing IPCSIT, V25, P91
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Wang S, 2012, IEEE T INTELL TRANSP, V13, P955, DOI 10.1109/TITS.2011.2171034
   Yang M, 2013, PATTERN RECOGN, V46, P1865, DOI 10.1016/j.patcog.2012.06.022
   Zhang B, 2013, IEEE INTEL TRANSP SY, V5, P8, DOI 10.1109/MITS.2013.2245725
   Zhang BL, 2013, IEEE T INTELL TRANSP, V14, P322, DOI 10.1109/TITS.2012.2213814
   Zhang BL, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500048
   Zou J, 2013, PATTERN RECOGN, V46, P434, DOI 10.1016/j.patcog.2012.06.018
NR 31
TC 110
Z9 117
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5817
EP 5832
DI 10.1007/s11042-015-2520-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500050
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Luo, XY
   Yang, CF
   Liu, FL
AF Zhang, Yi
   Luo, Xiangyang
   Yang, Chunfang
   Liu, Fenlin
TI Joint JPEG compression and detection resistant performance enhancement
   for adaptive steganography using feature regions selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive steganography; JPEG-compression resistant; Detection resistant;
   Feature regions selection; Genetic algorithm
AB Since it is difficult to acquire a strong JPEG compression resistant ability while achieving a good detection resistant performance for current information hiding algorithms, a JPEG compression and detection resistant adaptive steganography algorithm using feature regions is proposed. Based on the proposed feature region extraction and selection algorithms, the embedding domain robust to JPEG compression and containing less embedding distortion can be obtained. Utilizing the current distortion functions, the distortion value of DCT coefficients in the embedding domain can be calculated. Combined with error correct coding and STCs, the messages are embedded into the cover images with minimum embedding distortion, and can be extracted with high accuracy after JPEG compression, hence, the JPEG compression and detection resistant performance are enhanced at the same time. The experimental results demonstrate that comparing with current J-UNIWARD steganography under quality factor 85 of JPEG compression, the extraction error rates decrease from above 20 % to nearly 0, while the stego images remain a better detection resistant performance comparing with the current JPEG compression and detection resistant adaptive steganography algorithm.
C1 [Zhang, Yi; Yang, Chunfang; Liu, Fenlin] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
   [Zhang, Yi; Luo, Xiangyang; Yang, Chunfang; Liu, Fenlin] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Peoples R China.
   [Luo, Xiangyang] Key Lab Sci & Technol Informat Assurance, Beijing 100072, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Luo, XY (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Peoples R China.; Luo, XY (corresponding author), Key Lab Sci & Technol Informat Assurance, Beijing 100072, Peoples R China.
EM tzyy4001@sina.com; luoxy_ieu@sina.com; Chunfangyang@126.com;
   fenlinliu@vip.sina.com
FU National Natural Science Foundation of China [61379151, 61272489,
   61302159, 61401512, 61572052]; Excellent Youth Foundation of Henan
   Province of China [144100510001]; Innovation Scientist and Technicians
   Troop Construction Project of Zhengzhou City [10LJRC182]; Foundation of
   Science and Technology on Information Assurance Laboratory [KJ-14-108]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61379151, 61272489, 61302159, 61401512, and 61572052), the
   Excellent Youth Foundation of Henan Province of China (No.
   144100510001), the Innovation Scientist and Technicians Troop
   Construction Project of Zhengzhou City (No. 10LJRC182), ant the
   Foundation of Science and Technology on Information Assurance Laboratory
   (No. KJ-14-108).
CR Denemark T., 2015, PROC IEEE INT WORKSH, P1
   Filler T, 2011, INT SOC OPTICS PHOTO
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fillers T, 2010, IS T SPIE ELECT IMAG
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Galand F, 2003, 2003 IEEE INFORMATION THEORY WORKSHOP, PROCEEDINGS, P151, DOI 10.1109/ITW.2003.1216717
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li B, 2014, IEEE T INF FOREN SEC, V9, P1264, DOI 10.1109/TIFS.2014.2326954
   Li CL, 2015, NEUROCOMPUTING, V166, P404, DOI 10.1016/j.neucom.2015.03.039
   Liu WW, 2015, SECUR COMMUN NETW, V8, P1636, DOI 10.1002/sec.1111
   Luo WB, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P158, DOI 10.1109/IAI.2002.999910
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P635, DOI 10.1109/TIFS.2008.2002936
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Tsai JS, 2012, SIGNAL PROCESS, V92, P1431, DOI 10.1016/j.sigpro.2011.11.033
   Tsai JS, 2011, IEEE T IMAGE PROCESS, V20, P735, DOI 10.1109/TIP.2010.2073475
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Zhang Y, 2016, SECUR COMMUN NETW, V9, P2957, DOI 10.1002/sec.1502
   Zhang Y, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P461, DOI 10.1109/ARES.2015.53
NR 25
TC 27
Z9 27
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3649
EP 3668
DI 10.1007/s11042-016-3914-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200023
DA 2024-07-18
ER

PT J
AU Feng, SS
   Cao, J
AF Feng, Shanshan
   Cao, Jian
TI Improving group recommendations via detecting comprehensive correlative
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Group recommendation; Tripartite graph; Random walk with restart
AB Traditionally, recommender systems are applied to recommending items to individual users. However, there has been a proliferation of recommender systems that try to make recommendations to user groups. Although several approaches were proposed to generate group recommendations, they made recommendations simply through aggregating individual ratings or individual predicted results, rather than comprehensively investigating the inherent relationships between members and the group, which can be used to improve the performance of group recommender systems. For this reason, these approaches continue to suffer from data sparsity and do not work well for recommending items to user groups. Therefore, we proposed a new approach for group recommendations based on random walk with restart (RWR) method. The goal of the work in this paper is describing groups' preferences better by comprehensively detecting the correlative information among users, groups, and items, in order to alleviate the data sparsity problem and improve the performance of group recommender systems. In the proposed approach, we represent the relationships among users, groups, and items as a tripartite graph. Based on the tripartite graph, RWR can predict the relevance degrees between groups and unrated items by comprehensively detecting their relationships. Using these relevance degrees, we can describe a group's preferences better so as to achieve a more accurate recommendation. In particular, we devised two recommendation algorithms based on different recommendation strategies. Finally, we conducted experiments to evaluate our method and compare it with other state-of-the-art methods using the real-world CAMRa2011 data-set. The results show the advantage of our approach over comparative ones.
C1 [Feng, Shanshan; Cao, Jian] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Feng, SS (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM fswl6869@sjtu.edu.cn; cao-jian@sjtu.edu.cn
CR [Anonymous], 2004, Proceedings of the international ACM SIGIR conference on Research and development in information retrieval(SIGIR), DOI [10.1145/1008992.1009051, DOI 10.1145/1008992.1009051]
   [Anonymous], 2007, NIPS
   Bao Y, 2014, 28 AAAI C ART INT
   Berkovsky J., 2010, P 4 ACM C REC SYST, P111
   Berkovsky S, 2009, LECT NOTES ARTIF INT, V5866, P646, DOI 10.1007/978-3-642-10439-8_65
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Chen YL, 2008, EXPERT SYST APPL, V34, P2082, DOI 10.1016/j.eswa.2007.02.008
   Christensen IA, 2011, EXPERT SYST APPL, V38, P14127, DOI 10.1016/j.eswa.2011.04.221
   Chuang SC, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 2, PROCEEDINGS, P412
   Craswell Nick, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P239, DOI 10.1145/1277741.1277784
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46
   Freyne J, 2006, LECT NOTES COMPUT SC, V4018, P101
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   Gorla J., 2013, P 22 INT C WORLD WID, P495, DOI DOI 10.1145/2488388.2488432
   He J., P 12 ANN ACM INT C M, P9, DOI 10.1145/1027527.1027531
   Hofmann T., 2005, Proceedings of the 2005 ACM Symposium on Applied Computing, P791
   Hu X, 2011, PROCEEDINGS OF THE RECSYS'2011 ACM CHALLENGE ON CONTEXT-AWARE MOVIE RECOMMENDATION (CAMRA2011), P23
   Jana U., 2006, 8th ACM International Workshop on Multimedia Information Retrieval MIR'06, P117
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Lai CC, 2009, INT J INNOV COMPUT I, V5, P1867
   Mao Y, MULTIPLE STRUCTURE B
   Marlin B., 2004, P 21 INT C MACH LEAR, P73, DOI 10.1145/1015330.1015437
   Masthoff J, 2004, USER MODEL USER-ADAP, V14, P37, DOI 10.1023/B:USER.0000010138.79319.fd
   Masthoff J, 2011, RECOMMENDER SYSTEMS HANDBOOK, P677, DOI 10.1007/978-0-387-85820-3_21
   Min SH, 2005, LECT NOTES COMPUT SC, V3579, P387
   O'Connor M, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P199
   Page L., 1999, PAGERANK CITATION RA
   Pan J-Y, 2004, P 10 ACM SIGKDD INT, P653, DOI DOI 10.1145/1014052.1014135
   Pan Jia-Yu., 2004, CVPRW 04 P 2004 C CO, V9, P146
   Pappas N, 2014, MULTIMED TOOLS APPL, P1
   Qiao YL, 2015, ADV INTELL SYST, V329, P247, DOI 10.1007/978-3-319-12286-1_25
   Rennie Jasson D. M., 2005, P 22 INT C MACH LEAR, P713, DOI DOI 10.1145/1102351.1102441
   Said A, 2011, PROCEEDINGS OF THE RECSYS'2011 ACM CHALLENGE ON CONTEXT-AWARE MOVIE RECOMMENDATION (CAMRA2011), P2
   Tong Hanghang, 2006, P 12 ACM SIGKDD INT
   Wang LC, 2010, PROCEEDINGS OF THE RECSYS'2010 ACM CHALLENGE ON CONTEXT-AWARE MOVIE RECOMMENDATION (CAMRA2010), P28, DOI 10.1145/1869652.1869657
   Xu YP, 2006, SIAM PROC S, P340
   Zhang WG, 2014, MULTIMED TOOLS APPL, V73, P547, DOI 10.1007/s11042-013-1607-5
NR 39
TC 16
Z9 16
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1355
EP 1377
DI 10.1007/s11042-015-3135-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000059
DA 2024-07-18
ER

PT J
AU Jiang, XD
   Sheng, B
   Lin, WY
   Li, P
   Ma, LZ
   Shen, RM
AF Jiang, Xudong
   Sheng, Bin
   Lin, Weiyao
   Li, Ping
   Ma, Lizhuang
   Shen, Ruimin
TI Antialiased super-resolution with parallel high-frequency synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Convolution; Edge anti-aliasing; Texture synthesis
ID IMAGE SUPERRESOLUTION; SINGLE IMAGE; RESOLUTION; RECONSTRUCTION;
   INTERPOLATION; ENHANCEMENT; SIMILARITY; STATISTICS; MAP
AB Image super-resolution (SR) increases the resolution of the target image, and has become a fundamental image-editing operation for real-world applications. Traditional methods often cause jaggies and blurring artifacts because natural images generally contain a lot of discrete continuities and edges. This paper proposes a new synthesis-based method for image super-resolution at a pixel level that takes advantages of convolution-based edge anti-aliasing. The target images are divided into two components representing, respectively, the high- and low-frequency contents of the images. We perform bicubic interpolation to reconstruct the missing information in the low-frequency component. A patch-based texture synthesis is subsequently adopted to synthesize the high-frequency patches with the final upscaled images. In particular, we also use the efficient edge-based anti-aliasing for correcting the quantization error, restore the high-frequency details damaged by nonlinear example-based synthesis. Our proposed approach generates super-resolution images dynamically and can be fully implemented in GPU parallelization. Experiments confirm the visual superiority of our proposed approach in comparison with competing state-of-the-art techniques.
C1 [Jiang, Xudong; Sheng, Bin; Ma, Lizhuang; Shen, Ruimin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Jiang, Xudong] Autodesk China Res & Dev Ctr, Shanghai, Peoples R China.
   [Lin, Weiyao] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai, Peoples R China.
   [Li, Ping] Hong Kong Inst Educ, Dept Math & Informat Technol, Hong Kong, Hong Kong, Peoples R China.
C3 Shanghai Jiao Tong University; Autodesk, Inc.; Shanghai Jiao Tong
   University; Education University of Hong Kong (EdUHK)
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM shengbin@cs.sjtu.edu.cn
RI lin, yuxi/HKF-6212-2023; Li, Ping/AAO-2019-2020; Sun, Peng/KDO-4243-2024
OI Li, Ping/0000-0002-1503-0240; Lin, Weiyao/0000-0001-8307-7107
FU National Natural Science Foundation of China [61202154, 61572316,
   61272326, 61133009]; National Basic Research Project of China
   [2011CB302203]; National High-tech R&D Program of China (863 Program)
   [2015AA011604]; Shanghai Pujiang Program [13PJ1404500]; Science and
   Technology Commission of Shanghai Municipality Program [13511505000];
   Open Projects Program of National Laboratory of Pattern Recognition;
   Open Project Program of the State Key Lab of CAD&CG, Zhejiang University
   [A1401]
FX The authors would like to thank all reviewers for their helpful
   suggestions and constructive comments. The work is supported by the
   National Natural Science Foundation of China (No. 61202154, 61572316,
   61272326, 61133009), the National Basic Research Project of China (No.
   2011CB302203), National High-tech R&D Program of China (863
   Program)(Grant No. 2015AA011604), and Shanghai Pujiang Program (No.
   13PJ1404500), the Science and Technology Commission of Shanghai
   Municipality Program (No. 13511505000), the Open Projects Program of
   National Laboratory of Pattern Recognition, and the Open Project Program
   of the State Key Lab of CAD&CG (Grant No. A1401), Zhejiang University.
CR [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   Capel D, 2000, INT C PATT RECOG, P600, DOI 10.1109/ICPR.2000.905409
   Damkat C, 2011, SIGNAL IMAGE VIDEO P, V5, P343, DOI 10.1007/s11760-010-0205-5
   Datsenko D, 2007, MULTIDIM SYST SIGN P, V18, P103, DOI 10.1007/s11045-007-0018-z
   Elad M, 2009, COMPUT J, V52, P15, DOI 10.1093/comjnl/bxm008
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Guo K, 2012, IEEE T IMAGE PROCESS, V21, P615, DOI 10.1109/TIP.2011.2165290
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jagadeesh P., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P759, DOI 10.1109/ICRTIT.2011.5972260
   Jiang W, 2009, IEEE T SYST MAN CY B, V39, P1036, DOI 10.1109/TSMCB.2008.2011646
   Jiji CV, 2004, INT J IMAG SYST TECH, V14, P105, DOI 10.1002/ima.20013
   Joshi MV, 2005, IEEE T SYST MAN CY B, V35, P527, DOI 10.1109/TSMCB.2005.846647
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim KI, 2008, LECT NOTES COMPUT SC, V5096, P456
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Lefebvre S, 2005, ACM T GRAPHIC, V24, P777, DOI 10.1145/1073204.1073261
   Lefebvre S., 2006, ACM SIGGRAPH 2006 PA, P548
   Li X, 2008, EFFICIENT EXAMPLE BA, P575
   Li X., 2013, MIXED DOMAIN EDGE AW
   Li XG, 2009, J VIS COMMUN IMAGE R, V20, P312, DOI 10.1016/j.jvcir.2009.03.008
   Liu SC, 2010, LECT NOTES COMPUT SC, V6316, P323
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Ng MK, 2002, INT J IMAG SYST TECH, V12, P35, DOI 10.1002/ima.10004
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Piao YJ, 2007, IEEE IMAGE PROC, P445
   Rajan D, 2003, IEEE T PATTERN ANAL, V25, P1102, DOI 10.1109/TPAMI.2003.1227986
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409106
   Sheng B., 2013, SIGGRAPH ASIA 2013 T, P7
   Suetake N, 2008, OPT REV, V15, P26, DOI 10.1007/s10043-008-0005-0
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tang Y, 2011, INT J MACH LEARN CYB, V2, P15, DOI 10.1007/s13042-011-0011-6
   Tekalp A., 1992, PROC IEEE INT CONF A, V3, P169
   Tong X, 2002, ACM T GRAPHIC, V21, P665, DOI 10.1145/566570.566634
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   Wang LF, 2014, IEEE T IMAGE PROCESS, V23, P5123, DOI 10.1109/TIP.2014.2360459
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966401
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
NR 43
TC 4
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 543
EP 560
DI 10.1007/s11042-015-3049-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000024
DA 2024-07-18
ER

PT J
AU Liu, P
   Li, SB
   Wang, HQ
AF Liu, Peng
   Li, Songbin
   wang, Haiqiang
TI Steganography integrated into linear predictive coding for low bit-rate
   speech codec
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Linear predictive coding; Matrix embedding;
   Quantization index modulation
ID WATERMARKING
AB The extensive use of Voice over IP (VoIP) applications makes low bit-rate speech stream a very suitable steganographic cover media. To incorporate steganography into low bit-rate speech codec, we propose a novel approach to embed information during linear predictive coding (LPC) process based on Matrix Embedding (ME). In the proposed method, a mapping table is constructed based on the criterion of minimum distance of Linear-Predictive-Coefficient-Vectors, and embedding position and template are selected according to a private key so as to choose the cover frames. The original speech data of the chosen frames are partially encoded to get the codewords for embedding and then the codewords that need to be modified for embedding are selected according to the secret bits and ME algorithm. The selected codeword will be changed into its best replacement codeword according to the mapping table. When embedding k (k > 1) bits into 2 (k) -1 codewords, the embedding efficiency of our method is k times as that of LPC-based Quantization Index Modulation method. The performance of the proposed approach is evaluated in two aspects: distortion in speech quality introduced by embedding and security under steganalysis. The experimental results demonstrate that the proposed approach leads to a better performance with less speech distortion and better security.
C1 [Liu, Peng; Li, Songbin] Chinese Acad Sci, Inst Acoust, Haikou Lab, Haikou 570105, Peoples R China.
   [Liu, Peng; Li, Songbin] Natl Network New Media Engn Res Ctr, Beijing 100190, Peoples R China.
   [wang, Haiqiang] Univ Southern Calif, Los Angeles, CA USA.
C3 Chinese Academy of Sciences; University of Southern California
RP Li, SB (corresponding author), Chinese Acad Sci, Inst Acoust, Haikou Lab, Haikou 570105, Peoples R China.; Li, SB (corresponding author), Natl Network New Media Engn Res Ctr, Beijing 100190, Peoples R China.
EM liup@dsp.ac.cn; lisb@dsp.ac.cn; haiqianw@usc.edu
FU Natural Science Foundation of Nation and Hainan Province of China
   [61303249, 614236]; Important Science & Technology Project of Hainan
   Province of China [JDJS2013006, ZDXM2015103]; Preferred Foundation of
   Director of Institute of Acoustics, Chinese Academy of Sciences; Young
   Talent Frontier Project of Institute of Acoustics, Chinese Academy of
   Sciences
FX This work is supported partly by Natural Science Foundation of Nation
   and Hainan Province of China under grant 61303249 and 614236, and partly
   by Important Science & Technology Project of Hainan Province of China
   under grant JDJS2013006 and ZDXM2015103, and partly by Preferred
   Foundation of Director of Institute of Acoustics, Chinese Academy of
   Sciences, and partly by the Young Talent Frontier Project of Institute
   of Acoustics, Chinese Academy of Sciences.
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 1996, G729 ITUT
   [Anonymous], RECOMMENDATION P 563
   [Anonymous], GRAPH THEORY
   [Anonymous], RECOMMENDATION P 800
   [Anonymous], 2001, RECOMMENDATION P 862
   [Anonymous], TELEGEOGRAPHY REPORT
   [Anonymous], 2009, IEEE INT C COMM 2009
   [Anonymous], MULTIMED TOOLS APPL
   Chang YT, 2015, MULTIMED TOOLS APPL, V74, P1645, DOI 10.1007/s11042-014-2019-x
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chiang YK, 2008, FUND INFORM, V82, P15
   Crandall R., 1998, SOME NOTES STEGANOGR
   Huang YF, 2011, IEEE T INF FOREN SEC, V6, P296, DOI 10.1109/TIFS.2011.2108649
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599
   Ito A, 2009, INT CONF ACOUST SPEE, P1409, DOI 10.1109/ICASSP.2009.4959857
   Ji S., 2012, ADV DIFFER EQU, V2012, P1, DOI DOI 10.1016/J.CAGE0.2012.01.004
   Jin Liu, 2012, IEEE International Conference on Communications (ICC 2012), P1133, DOI 10.1109/ICC.2012.6363997
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lin C, 2006, IEEE SYS MAN CYBERN, P2380, DOI 10.1109/ICSMC.2006.385219
   Liu LH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P406, DOI 10.1109/IIH-MSP.2008.297
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718
   Lu ZM, 2005, IEICE T INF SYST, VE88D, P330, DOI 10.1093/ietisy/E88-D.2.330
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Roselinkiruba R, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P491
   Simmons G. J., 1984, Advances in Cryptology. Proceedings of Crypto 83, P51
   SIMMONS GJ, 1985, LECT NOTES COMPUT SC, V209, P364
   SIMMONS GJ, 1994, EUR T TELECOMMUN, V5, P459
   Wang FH, 2007, J NETW COMPUT APPL, V30, P4, DOI 10.1016/j.jnca.2005.08.002
   Xiao B, 2008, GLOBAL TELECOMMUNICA, P1
   Xu TT, 2009, INT CONF WIRE COMMUN, P752
   Yan S, 2014, MATH PROBL ENG, V2014, P1, DOI DOI 10.1007/S11042-014-2265-Y
NR 32
TC 35
Z9 40
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2837
EP 2859
DI 10.1007/s11042-016-3257-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000055
DA 2024-07-18
ER

PT J
AU Qin, C
   Ji, P
   Wang, JW
   Chang, CC
AF Qin, Chuan
   Ji, Ping
   Wang, Jinwei
   Chang, Chin-Chen
TI Fragile image watermarking scheme based on VQ index sharing and
   self-embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Vector quantization; Self-embedding; Tampering
   localization; Content recovery
ID RESTORATION CAPABILITY; TAMPER DETECTION; RECOVERY; RECONSTRUCTION;
   AUTHENTICATION; ALGORITHM; MECHANISM; CODEBOOK
AB In this paper, we propose a self-embedding fragile watermarking scheme using vector quantization (VQ) and index sharing. First, the principle contents of original image are compactly represented by a series of VQ indices. Then, after permutation, the binary bits of VQ indices are extended to generate reference-bits by a random binary matrix, which can make all reference-bits share the information of VQ index bits from different regions of the whole image. The image is embedded with watermark-bits including hash-bits for tampering localization and reference-bits for content recovery, and is transmitted to receiver side. Tampered regions in the received, suspicious image can be accurately located and then be recovered by VQ index reconstruction. Experimental results demonstrate that the proposed scheme can achieve successful content recovery for larger tampering rate and obtain better visual quality of recovered results than the reported schemes.
C1 [Qin, Chuan; Ji, Ping] Univ Shanghai Sci & Technol, Minist Educ, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
   [Qin, Chuan; Ji, Ping] Univ Shanghai Sci & Technol, Minist Educ, Engn Res Ctr Opt Instrument & Syst, Shanghai 200093, Peoples R China.
   [Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology; Nanjing University of Information Science &
   Technology; Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM qin@usst.edu.cn; chuckping@163.com; wjwei_2004@163.com; alan3c@gmail.com
RI Qin, Chuan/C-1106-2017; Chang, Ching-Chun/JAN-6210-2023
OI Qin, Chuan/0000-0002-0370-4623; 
FU National Natural Science Foundation of China [61303203, 61232016,
   U1405254]; Natural Science Foundation of Shanghai, China [13ZR1428400];
   Innovation Program of Shanghai Municipal Education Commission [14YZ087];
   Shanghai Engineering Center Project of Massive Internet of Things
   Technology for Smart Home [GCZX14014]; Research Base Special Project of
   Hujiang Foundation [C14001]; Hujiang Foundation of China [C14002]; PAPD
   Fund; Open Project Program of Shenzhen Key Laboratory of Media Security
FX This work was supported by the National Natural Science Foundation of
   China (61303203, 61232016, U1405254), the Natural Science Foundation of
   Shanghai, China (13ZR1428400), the Innovation Program of Shanghai
   Municipal Education Commission (14YZ087), Shanghai Engineering Center
   Project of Massive Internet of Things Technology for Smart Home
   (GCZX14014), Research Base Special Project of Hujiang Foundation
   (C14001), Hujiang Foundation of China (C14002), the PAPD Fund, and the
   Open Project Program of Shenzhen Key Laboratory of Media Security.
CR [Anonymous], 2012, INF SCI
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Chang CC, 2007, IEEE T IMAGE PROCESS, V16, P1538, DOI 10.1109/TIP.2007.894256
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Fridrich J., 1999, P 1999 INT C IM PROC, P792, DOI [10.1109/ICIP.1999.817228, DOI 10.1109/ICIP.1999.817228]
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Huo YR, 2012, OPT COMMUN, V285, P1759, DOI 10.1016/j.optcom.2011.12.044
   Korus P, 2014, IEEE T INF FOREN SEC, V9, P169, DOI 10.1109/TIFS.2013.2295154
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu KC, 2012, IET IMAGE PROCESS, V6, P445, DOI 10.1049/iet-ipr.2011.0574
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Wang FH, 2007, J NETW COMPUT APPL, V30, P4, DOI 10.1016/j.jnca.2005.08.002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu CC, 2011, J SYST SOFTWARE, V84, P2196, DOI 10.1016/j.jss.2011.06.021
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yang SS, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P130, DOI 10.1109/IIH-MSP.2014.39
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
NR 24
TC 40
Z9 41
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2267
EP 2287
DI 10.1007/s11042-015-3218-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000030
DA 2024-07-18
ER

PT J
AU Rad, AE
   Rahim, MSM
   Kolivand, H
   Amin, IB
AF Rad, Abdolvahab Ehsani
   Rahim, Mohd Shafry Mohd
   Kolivand, Hoshang
   Amin, Ismail Bin Mat
TI Morphological region-based initial contour algorithm for level set
   methods in image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Initial contour; Level set; Image segmentation; Image processing
ID ACTIVE CONTOURS; MODEL; SHAPE; FLOW
AB Initial Contour (IC) is the essential step in level set image segmentation methods due to start the efficient process. However, the main issue with IC is how to generate the automatic technique in order to reduce the human interaction and moreover, suitable IC to have accurate result. In this paper a new technique which we called Morphological Region-Based Initial Contour (MRBIC), is proposed to overcome this issue. The idea is to generate the most suitable IC since the manual initialization of the level set function surface is a well-known drawback for accurate segmentation which has dependency on selection of IC and wrong selection will affect the result. We have utilized the statistical and morphological information inside and outside the contour to establish a region-based map function. This function is able to find the suitable IC on images to perform by level set methods. Experiments on synthetic and real images demonstrate the robustness of segmentation process using MRBIC method even on noisy images and with weak boundary. Furthermore, computational cost of segmentation process will be reduced using MRBIC.
C1 [Rad, Abdolvahab Ehsani; Rahim, Mohd Shafry Mohd; Kolivand, Hoshang; Amin, Ismail Bin Mat] Univ Teknol Malaysia, Digital Media Ctr, MaGIC X Media & Games Innovat Ctr Excellence, Johor Baharu 81310, Malaysia.
C3 Universiti Teknologi Malaysia
RP Kolivand, H (corresponding author), Univ Teknol Malaysia, Digital Media Ctr, MaGIC X Media & Games Innovat Ctr Excellence, Johor Baharu 81310, Malaysia.
EM erabdolvahab2@live.utm.my; shafry@utm.my; hoshang@utm.my;
   ismailma@utm.my
RI Kolivand, Hoshang/F-4736-2011; Rad, Abdolvahab Ehsani/K-6015-2012;
   Kolivand, Hoshang/B-2501-2016
OI Rad, Abdolvahab Ehsani/0000-0002-6729-9559; Kolivand,
   Hoshang/0000-0001-5460-5679
FU UTM-IRDA Digital Media Centre, Faculty of Computing, Universiti
   Teknologi Malaysia (UTM) Fundamental Research Grant Scheme (FRGS)
   [R.J130000.7828.4F491]; Ministry of Education and Research Management
   centre (RMC)
FX This research is supported by UTM-IRDA Digital Media Centre, Faculty of
   Computing, Universiti Teknologi Malaysia (UTM) using Fundamental
   Research Grant Scheme (FRGS) Vot No. R.J130000.7828.4F491. Special
   thanks to Ministry of Education and Research Management centre (RMC) for
   providing financial support for this research.
CR Bai PR, 2013, COMPUT BIOL MED, V43, P1827, DOI 10.1016/j.compbiomed.2013.08.024
   Bai XF, 2007, IEEE IC COMP COM NET, P1
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chunhapongpipat K, 2012, 2012 6 INT C SIGN PR, P1
   Deng JW, 2002, PATTERN RECOGN LETT, V23, P161, DOI 10.1016/S0167-8655(01)00113-1
   Dizdaroglu B, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-39
   Dong FF, 2013, IMAGE VISION COMPUT, V31, P809, DOI 10.1016/j.imavis.2013.08.003
   Dong FF, 2012, ADV COMPUT MATH, V37, P521, DOI 10.1007/s10444-011-9221-4
   Gao H, 2010, PATTERN RECOGN, V43, P2406, DOI 10.1016/j.patcog.2010.01.010
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Jeon M, 2005, PATTERN RECOGN LETT, V26, P1461, DOI 10.1016/j.patrec.2004.11.023
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   Kolivand H, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108334
   Li S, 2006, COMPUT MED IMAG GRAP, V30, P65, DOI 10.1016/j.compmedimag.2005.10.007
   Li S, 2007, PATTERN RECOGN, V40, P2861, DOI 10.1016/j.patcog.2007.01.012
   Liu CX, 2011, J MATH IMAGING VIS, V41, P194, DOI 10.1007/s10851-011-0269-z
   Ma WY, 1997, PROC CVPR IEEE, P744, DOI 10.1109/CVPR.1997.609409
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nilsson B, 2003, PATTERN RECOGN LETT, V24, P1331, DOI 10.1016/S0167-8655(02)00374-4
   Norouzi A, 2014, IETE TECH REV, V31, P199, DOI 10.1080/02564602.2014.906861
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Osher S., 2006, LEVEL SET METHODS DY, V153
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345
   Qu Y, 2007, TOP BIOMED ENG, P95, DOI 10.1007/978-0-387-68343-0_4
   Rad AE, 2013, IETE TECH REV, V30, P210, DOI 10.4103/0256-4602.113498
   Saehdeva J, 2012, MAGN RESON IMAGING, V30, P694, DOI 10.1016/j.mri.2012.01.006
   Sethian J.A., 2003, Journal of Computing and Information Technology, V11, P1
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Sun KQ, 2012, IEEE T BIO-MED ENG, V59, P464, DOI 10.1109/TBME.2011.2174362
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Weickert J, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P43, DOI 10.1007/0-387-21810-6_3
   Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737
   Xie XH, 2010, IEEE T IMAGE PROCESS, V19, P154, DOI 10.1109/TIP.2009.2032891
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Xu N, 2007, COMPUT VIS IMAGE UND, V107, P210, DOI 10.1016/j.cviu.2006.11.004
   Zhang Y, 2008, MEDIVIS 2008: FIFTH INTERNATIONAL CONFERENCE BIOMEDICAL VISUALIZATION - INFORMATION VISUALIZATION IN MEDICAL AND BIOMEDICAL INFORMATICS, PROCEEDINGS, P71, DOI 10.1109/MediVis.2008.12
NR 41
TC 30
Z9 31
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2185
EP 2201
DI 10.1007/s11042-015-3196-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000026
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Rezaei, M
   Karimghasemi, E
AF Rezaei, Mehdi
   Karimghasemi, Effat
TI A fuzzy rate controller for variable bit rate video using foveated
   just-noticeable distortion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit rate; Control; FNJD; Fuzzy; Human visual system (HVS); H.264/AVC
   standard; Variable; Video coding
ID ALLOCATION
AB In this paper, a rate control algorithm for variable bit rate video applications with buffer constraint is proposed. The proposed algorithm utilizes a fuzzy rate controller and a perceptual quality controller. The fuzzy controller computes a base quantization parameter (QP) for each video picture to provide the buffer constraint. Then, the perceptual quality controller uses a human visual system (HVS) model namely foveated just-noticeable distortion (FJND) model to improve the perceptual quality of encoded video by modulating the QP of macroblocks around the picture QP. The proposed rate control algorithm has been implemented on the JM H.264/AVC reference software and obtained experimental results show that it can produce encoded videos with high perceptual quality while the buffering constraint is strongly obeyed.
C1 [Rezaei, Mehdi] Univ Sistan & Baluchestan, Dept Elect & Comp Engn, Zahedan, Iran.
   [Karimghasemi, Effat] Univ Sistan & Baluchestan, Signal Proc Lab, Fac Elect & Comp Engn, Zahedan, Iran.
C3 University of Sistan & Baluchestan; University of Sistan & Baluchestan
RP Rezaei, M (corresponding author), Univ Sistan & Baluchestan, Dept Elect & Comp Engn, Zahedan, Iran.
EM mehdi.rezaei@ece.usb.ac.ir; ekarimghasemi@yahoo.com
RI Rezaei, Mehdi/HPC-0221-2023
OI Rezaei, Mehdi/0000-0002-6918-9767
CR [Anonymous], COURSE FUZZY SYSTEMS
   Chen Z, 2014, DIG SIGN PROC DSP 20
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Gary S, 2003, JOINT MODEL REFERENC
   Hrarti M., 2010, 5th International Symposium on I/V Communications and Mobile Network (ISVC), P1
   Lakshman TV, 1998, P IEEE, V86, P952, DOI 10.1109/5.664282
   Liu H, 2015, SPIE P, V9410
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Luo ZY, 2013, IEEE T CIRC SYST VID, V23, P935, DOI 10.1109/TCSVT.2013.2240919
   Naccari M, 2011, IEEE T CIRC SYST VID, V21, P766, DOI 10.1109/TCSVT.2011.2130430
   NETRAVALI AN, 1977, P IEEE, V65, P536, DOI 10.1109/PROC.1977.10515
   Nguyen AG, 2002, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P65, DOI 10.1109/ITCC.2002.1000361
   Reed EC, 2001, IEEE T CIRC SYST VID, V11, P882, DOI 10.1109/76.931115
   Rezaei M, 2008, IEEE T CIRC SYST VID, V18, P633, DOI 10.1109/TCSVT.2008.919108
   Ruan Ruolin, 2011, 2011 6th International Conference on Computer Science & Education (ICCSE 2011), P843, DOI 10.1109/ICCSE.2011.6028769
   Shang X, 2013, IM PROC ICIP 2013 20
   Takamura S, 2001, IEEE IMAGE PROC, P942, DOI 10.1109/ICIP.2001.959202
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Wandell B. A, 1995, Foundations of vision
   Wang M., 2009, Proc. Web-scale Multimedia Corpus, P1, DOI DOI 10.1109/ICMSS.2009.5302047
   Winkler S., 2001, P INT S WIRELESS PER, P547
   Xu L, 2013, IEEE T CIRC SYST VID, V23, P975, DOI 10.1109/TCSVT.2013.2243657
   1993, MPEG 2 TEST MODEL 5
NR 25
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1439
EP 1453
DI 10.1007/s11042-015-3110-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000063
DA 2024-07-18
ER

PT J
AU Yang, CY
AF Yang, Ching-Yu
TI Robust high-capacity watermarking scheme based on Euclidean norms and
   quick coefficient alignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Robust high-capacity watermarking scheme; Euclidean norm
ID COLOR IMAGE WATERMARKING; ALGORITHM
AB This paper proposes simple but robust digital watermarking for color images based on Euclidean norms and quick coefficient alignment. For increasing the amount of hidden storage, we embedded two data bits in a host block at a time using a quick adjustment technique and four criteria that follow Euclidean norms of pixels. Simulations confirmed that a large number of secret bits can be embedded in host images without compromising image quality. In addition, our method is free from the underflow/overflow issue. The hidden storage provided by the proposed method is larger than that provided by existing color image watermarking techniques. The watermarked images generated by the proposed method are robust against various types of attacks such as cropping, Gaussian/uniform noise addition, inversion, JPEG, JPEG2000, and zigzagging.
C1 [Yang, Ching-Yu] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Magong 880, Penghu, Taiwan.
C3 National Penghu University of Science & Technology
RP Yang, CY (corresponding author), Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Magong 880, Penghu, Taiwan.
EM chingyu@npu.edu.tw
CR Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chang CC, 2009, SOFT COMPUT, V13, P321, DOI 10.1007/s00500-008-0332-x
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   DIFFIE W, 1977, COMPUTER, V10, P74, DOI 10.1109/C-M.1977.217750
   Findik O, 2010, OPT COMMUN, V283, P4916, DOI 10.1016/j.optcom.2010.07.020
   Findik O, 2011, EXPERT SYST APPL, V38, P1942, DOI 10.1016/j.eswa.2010.07.126
   Fu YG, 2008, COMPUT STAND INTER, V30, P115, DOI 10.1016/j.csi.2007.08.013
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Phadikar A., 2012, DATA HIDING TECHNIQU
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Rivest RL, 1992, INT REQUEST COMMENTS
   Su QT, 2012, OPT COMMUN, V285, P1717, DOI 10.1016/j.optcom.2011.11.117
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CY, 2013, ETRI J, V35, P512, DOI 10.4218/etrij.13.0112.0480
   Yang CY, 2014, 8 INT C GEN EV COMP
   Yang CY, 2014, 10 INT C INT INF HID
   Yang CY, 2012, 5 IET INT C U MED CO
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
NR 26
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1455
EP 1477
DI 10.1007/s11042-015-3065-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000064
DA 2024-07-18
ER

PT J
AU Zhu, SP
   Gao, RD
   Li, Z
AF Zhu, Shiping
   Gao, Ruidong
   Li, Zheng
TI Stereo matching algorithm with guided filter and modified dynamic
   programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo matching; Census transform; Guided image filter; Dynamic
   programming
AB Dense stereo correspondence is a challenging research problem in computer vision field. To address the poor accuracy behavior of stereo matching, we propose a novel stereo matching algorithm based on guided image filter and modified dynamic programming. Firstly, we suggest a combined matching cost by incorporating the absolute difference and improved color census transform (ICCT). Secondly, we use the guided image filter to filter the cost volume, which can aggregate the costs fast and efficiently. Then, in the disparity computing step, we design a modified dynamic programming algorithm, which can weaken the scanning line effect. At last, final disparity maps are gained after post-processing. The experimental results are evaluated on Middlebury Stereo Datasets, showing that our approach can achieve good results both in low texture and depth discontinuity areas with an average error rate of 5.14 % and strong robustness.
C1 [Zhu, Shiping; Gao, Ruidong; Li, Zheng] Beihang Univ, Dept Measurement Control & Informat Technol, Sch Instrumentat Sci & Optoelect Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhu, SP (corresponding author), Beihang Univ, Dept Measurement Control & Informat Technol, Sch Instrumentat Sci & Optoelect Engn, Beijing 100191, Peoples R China.
EM spzhu@163.com
RI Zhu, Shiping/C-3754-2012
FU National Natural Science Foundation of China (NSFC) [61375025, 61075011,
   60675018]; Scientific Research Foundation for the Returned Overseas
   Chinese Scholars from the State Education Ministry of China
FX This research is funded by the National Natural Science Foundation of
   China (NSFC) under grants No. 61375025, No. 61075011, and No. 60675018,
   also the Scientific Research Foundation for the Returned Overseas
   Chinese Scholars from the State Education Ministry of China.
CR [Anonymous], PATTERN ANAL MACHINE
   Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9
   Bleyer M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3081, DOI 10.1109/CVPR.2011.5995581
   Bleyer M, 2007, SIGNAL PROCESS-IMAGE, V22, P127, DOI 10.1016/j.image.2006.11.012
   Pham CC, 2013, IEEE T CIRC SYST VID, V23, P1119, DOI 10.1109/TCSVT.2012.2223794
   De-Maeztu L, 2011, PATTERN RECOGN LETT, V32, P1643, DOI 10.1016/j.patrec.2011.06.027
   Geng YN, 2012, APPL OPTICS, V51, P3538, DOI 10.1364/AO.51.003538
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hosni A, 2011, IEEE INT CON MULTI, DOI 10.1109/ICME.2011.6012131
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Kim JC, 2005, PROC CVPR IEEE, P1075
   Liang Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3033, DOI 10.1109/CVPR.2011.5995480
   Mei X, 2011, PROC CVPR IEEE, P1257
   Papadakis N, 2010, J MATH IMAGING VIS, V38, P70, DOI 10.1007/s10851-010-0212-8
   Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein D., 2010, MIDDLEBURY STEREO VI
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Xu YF, 2014, APPL OPTICS, V53, P6885, DOI 10.1364/AO.53.006885
   Xuefeng Chang, 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P73, DOI 10.1109/3DIMPVT.2011.17
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Yang QX, 2010, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2010.5539797
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
NR 26
TC 16
Z9 16
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 199
EP 216
DI 10.1007/s11042-015-3023-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000010
DA 2024-07-18
ER

PT J
AU Lai, YC
   Wang, CW
   Chen, KY
   Todorov, D
   Yao, CY
AF Lai, Yu-Chi
   Wang, Chun-Wei
   Chen, Kuang-Yi
   Todorov, Dobromir
   Yao, Chih-Yuan
TI Extra detail addition based on existing texture for animated news
   production
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture mapping; Detail stitching; Animation production; Paramterization
ID IMAGES; MAPS
AB Animated news proposed by Next Media Animation becomes more and more popular because an animation is adapted to tell the story in a piece of news which may miss visual and audial circumstances. In order to fulfill the requirement of creating a 90-second animation within 2 h, artists must quickly set up required news elements by selecting existing 3D objects from their graphics asset database and adding distinguished details such as tattoos, scars, and textural patterns onto selected objects. Therefore, the detail addition process is necessary and must be easy to use, efficient, and robust without any modification to the production pipeline and without addition of extra rendering pass to the rendering pipeline. This work aims at stitching extra details onto existing textures with a cube-based interface using the well-designed texture coordinates. A texture cube of the detail texture is first created for artists to manipulate and adjust stitching properties. Then, the corresponding transformation between the original and detail textures is automatically computed to decompose the. detail texture into triangular patches for composition with the original texture. Finally, a complete detail-added object texture is created for shading. The designed algorithm has been integrated into the Next Media Animation pipeline to accelerate animation production and the results are satisfactory.
C1 [Lai, Yu-Chi; Yao, Chih-Yuan] Natl Taiwan Univ Sci & Technol, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
   [Wang, Chun-Wei; Chen, Kuang-Yi] Natl Taiwan Univ Sci & Technol & Int Games Syst, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
   [Todorov, Dobromir] Natl Taiwan Univ Sci & Technol & Next Media Anima, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yao, CY (corresponding author), Natl Taiwan Univ Sci & Technol, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM cheeryuchi@gmail.com; cyuan.yao@gmail.com
OI Lai, Yu-Chi/0000-0001-8578-3101
FU National Science Council, Taiwan [NSC 104-2221-E-011-029-MY3,
   103-2221-E-011-114-MY2, 397, 103-2218-E-011-014, NSC 103-2221-E-011-076]
FX This work is supported by the National Science Council, Taiwan under NSC
   104-2221-E-011-029-MY3, 103-2221-E-011-114-MY2, 397 and
   103-2218-E-011-014, NSC 103-2221-E-011-076.
CR Benson D, 2002, ACM T GRAPHIC, V21, P785, DOI 10.1145/566570.566652
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI 10.1145/965143.563322
   Carr NA, 2004, ACM T GRAPHIC, V23, P845, DOI 10.1145/1015706.1015809
   DeBry D, 2002, ACM T GRAPHIC, V21, P763, DOI 10.1145/566570.566649
   Gingold YotamI., 2008, UIST 2006: Proceedings of the 19th Annual ACM Symposium on User Interface Software and Technology, P23, DOI DOI 10.1145/1166253.1166259
   Kirk RE ., 1982, Experimental design
   Lee TY, 2008, IEEE T VIS COMPUT GR, V14, P382, DOI 10.1109/TVCG.2007.70432
   Schmidt R, 2006, ACM T GRAPHIC, V25, P605, DOI 10.1145/1141911.1141930
   Sheffer A, 2005, ACM T GRAPHIC, V24, P311, DOI 10.1145/1061347.1061354
   Tarini M, 2004, ACM T GRAPHIC, V23, P853, DOI 10.1145/1015706.1015810
   Tzur Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531351
   Yao CY, 2009, COMPUT ANIMAT VIRT W, V20, P101, DOI 10.1002/cav.313
   Zhang E, 2005, ACM T GRAPHIC, V24, P1, DOI 10.1145/1037957.1037958
   Zhou K, 2005, ACM T GRAPHIC, V24, P1148, DOI 10.1145/1073204.1073325
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
NR 15
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16861
EP 16880
DI 10.1007/s11042-015-2950-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600007
DA 2024-07-18
ER

PT J
AU Lama, RK
   Choi, MR
   Kwon, GR
AF Lama, Ramesh Kumar
   Choi, Moo-Rak
   Kwon, Goo-Rak
TI Image interpolation for high-resolution display based on the complex
   dual-tree wavelet transform and hidden Markov model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image interpolation; Dual tree complex wavelet transform; Hidden markov
   model; Expectation maximization
ID WINSCALE
AB This paper presents a new method for the interpolation of a full high-definition (HD) image based on the dual-tree complex wavelet transform (DT-CWT) and hidden markov model (HMM). In the proposed method, the DT-CWT is used to decompose the low-resolution image into different subbands. In wavelet domain interpolation, given image is assumed as the low frequency LL subband of the wavelet coefficients of a high-resolution image. The proposed method estimates the higher band coefficients by learning the correlation between the coefficients across the scale. In this paper, the relationship between the wavelet coefficients across the scale is described by HMM, and each wavelet coefficient is modeled by a Gaussian mixture having multiple means and variances. Experimental results show that the proposed algorithm yields images that are sharper compared to several other methods that we have considered in this paper.
C1 [Lama, Ramesh Kumar; Kwon, Goo-Rak] Chosun Univ, Dept Informat & Commun Engn, 375 Seosuk Dong, Gwangju 501759, South Korea.
   [Choi, Moo-Rak] LG Elect, Div IT Mkt, Seoul 150721, South Korea.
   [Choi, Moo-Rak] Sung Gwang IT, Div Business Res, Yeosu 555809, South Korea.
C3 Chosun University; LG Electronics
RP Kwon, GR (corresponding author), Chosun Univ, Dept Informat & Commun Engn, 375 Seosuk Dong, Gwangju 501759, South Korea.
EM grkwon@chosun.ac.kr
FU Chosun University
FX This study was supported (in part) by research funding from Chosun
   University, 2016.
CR Aho E, 2005, IEEE T CIRC SYST VID, V15, P454, DOI 10.1109/TCSVT.2004.842599
   Choi H, 2000, INT CONF ACOUST SPEE, P133, DOI 10.1109/ICASSP.2000.861889
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   EI-Khamy SE, 2005, DIGIT SIGNAL PROCESS, V15, P137, DOI 10.1016/j.dsp.2004.10.003
   Jeon G, 2007, P INT C IM PROC ICIP, V7, P397
   Kim CH, 2003, IEEE T CIRC SYST VID, V13, P549, DOI 10.1109/TCSVT.2003.813431
   Kinebuchi K, 2001, INT CONF ACOUST SPEE, P1957, DOI 10.1109/ICASSP.2001.941330
   Kingsbury N, 1999, PHILOS T R SOC A, V357, P2543, DOI 10.1098/rsta.1999.0447
   Lama Ramesh Kumar, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P219, DOI 10.1109/ICCE.2014.6775980
   Lee S. W., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P177, DOI 10.1109/ICASSP.1993.319776
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   PENTLAND AP, 1994, IEEE T PATTERN ANAL, V16, P410, DOI 10.1109/34.277594
   Ratakonda K, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P203, DOI 10.1109/ICIP.1998.727167
   Tam WS, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3358372
   TAM WS, 2009, P 17 EUR SIGN PROC C, P283
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Wang Q, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P899, DOI 10.1109/ICIP.2001.958269
   Wang XY, 2009, MULTIDIM SYST SIGN P, V20, P385, DOI 10.1007/s11045-008-0075-y
NR 20
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16487
EP 16498
DI 10.1007/s11042-016-3245-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700071
DA 2024-07-18
ER

PT J
AU Liu, YW
   He, ZJ
   Zhao, SJ
   Wang, LM
AF Liu, Yawei
   He, Zongjian
   Zhao, Shengjie
   Wang, Liangmin
TI An efficient anonymous authentication protocol using batch operations
   for VANETs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicular ad hoc networks; Signature with message recovery; Batch
   verification; Privacy preservation
ID DIGITAL-SIGNATURES; SCHEME; SECURE; VERIFICATION; CHALLENGES
AB Security and privacy are both fundamental requirements of vehicular networking applications. Existing anonymous authentication protocols entail serious performance issues due to serialized verification operations. This paper presents an efficient anonymous authentication protocol based on signature with message recovery. Different from existing solutions, our proposed protocol authenticates multiple signatures using batch operations. Therefore, our solution can remarkably reduce the total authentication time. Meanwhile the transmission overhead can also be considerably decreased due to the combination of signature and message. We also prove the unforgeability of our proposed protocol in the random oracle model. Through extensive analysis and simulations, we show that the proposed protocol outperforms existing ones in terms of communication and computation efficiency.
C1 [Liu, Yawei] Anhui Univ, Coll Comp Sci & Technol, Hefei, Peoples R China.
   [He, Zongjian] Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.
   [Zhao, Shengjie] Tongji Univ, Minist Educ, Key Lab Embedded Syst & Serv Comp, Shanghai, Peoples R China.
   [Wang, Liangmin] Anhui Univ, Coinnovat Ctr Informat Support & Assurance Techno, Hefei, Peoples R China.
   [Wang, Liangmin] Jiangsu Univ, Dept Internet Things Engn, Zhenjiang, Peoples R China.
C3 Anhui University; Tongji University; Tongji University; Anhui
   University; Jiangsu University
RP Liu, YW (corresponding author), Anhui Univ, Coll Comp Sci & Technol, Hefei, Peoples R China.
EM weberlyw@gmail.com; hezongjian@tongji.edu.cn
RI 刘, 亚伟/HHY-9467-2022
OI He, Zongjian/0000-0003-1295-3899
FU National Natural Science Foundation of China [61472001]; Anhui
   University [02303203]
FX The work in this paper was supported by the National Natural Science
   Foundation of China (No. 61472001) and the project of academic leaders
   funding of Anhui University (NO. 02303203).
CR Barreto PSLM, 2007, DESIGN CODE CRYPTOGR, V42, P239, DOI 10.1007/s10623-006-9033-6
   Barreto PSLM, 2005, LECT NOTES COMPUT SC, V3788, P515
   Boneh D, 2003, LECT NOTES COMPUT SC, V2656, P416
   Boneh D, 2001, ADV CRYPTOLOGY ASIAC, V2248, P514, DOI [10.1007/s00145-004-0314-9, DOI 10.1007/S00145-004-0314-9]
   Chen W, 2011, WIREL COMMUN MOB COM, V11, P787, DOI 10.1002/wcm.862
   Chim TW, 2014, IEEE T COMPUT, V63, P510, DOI 10.1109/TC.2012.188
   Chim TW, 2011, AD HOC NETW, V9, P189, DOI 10.1016/j.adhoc.2010.05.005
   Engoulou RG, 2014, COMPUT COMMUN, V44, P1, DOI 10.1016/j.comcom.2014.02.020
   Hartenstein H, 2008, IEEE COMMUN MAG, V46, P164, DOI 10.1109/MCOM.2008.4539481
   He DB, 2015, IEEE T INF FOREN SEC, V10, P2681, DOI 10.1109/TIFS.2015.2473820
   Huang JL, 2011, IEEE T VEH TECHNOL, V60, P248, DOI 10.1109/TVT.2010.2089544
   Islam SKH, 2015, SECUR COMMUN NETW, V8, P2214, DOI 10.1002/sec.1165
   Jiang D, 2006, IEEE WIREL COMMUN, V13, P36, DOI 10.1109/WC-M.2006.250356
   Jiang DD, 2015, COMPUT NETW, V84, P1, DOI 10.1016/j.comnet.2015.04.003
   Khan MK, 2004, LECT NOTES COMPUT SC, V3338, P629
   Khan MK, 2006, LECT NOTES COMPUT SC, V3903, P260, DOI 10.1007/11689522_24
   Khan MK, 2009, IETE TECH REV, V26, P191, DOI 10.4103/0256-4602.50703
   Lin XD, 2008, IEEE COMMUN MAG, V46, P88, DOI 10.1109/MCOM.2008.4481346
   Liu JQ, 2016, TELECOMMUN SYST, V62, P15, DOI 10.1007/s11235-015-9979-7
   Liu YL, 2015, IEEE T VEH TECHNOL, V64, P3697, DOI 10.1109/TVT.2014.2358633
   MIRACL Cryptographic Library, 2012, MIRACL CRYPTOGRAPHIC
   Miyaji A, 2001, IEICE T FUND ELECTR, VE84A, P1234
   Pointcheval D, 2000, J CRYPTOL, V13, P361, DOI 10.1007/s001450010003
   Raya M, 2007, J COMPUT SECUR, V15, P39, DOI 10.3233/JCS-2007-15103
   Ren K, 2009, IEEE T VEH TECHNOL, V58, P4554, DOI 10.1109/TVT.2009.2019663
   Shi-Jinn Horng, 2013, IEEE Transactions on Information Forensics and Security, V8, P1860, DOI 10.1109/TIFS.2013.2277471
   Shim KA, 2013, AD HOC NETW, V11, P182, DOI 10.1016/j.adhoc.2012.04.015
   Shim KA, 2012, IEEE T VEH TECHNOL, V61, P1874, DOI 10.1109/TVT.2012.2186992
   Tso R, 2007, LECT NOTES COMPUT SC, V4856, P47
   Tzeng SF, 2017, IEEE T VEH TECHNOL, V66, P3235, DOI 10.1109/TVT.2015.2406877
   Wan JF, 2014, IEEE COMMUN MAG, V52, P106, DOI 10.1109/MCOM.2014.6871677
   Yang JC, 2015, SENSORS-BASEL, V15, P29535, DOI 10.3390/s151129535
   Zhang CX, 2008, IEEE INFOCOM SER, P816
   Zhang DQ, 2015, IEEE T COMPUT, V64, P452, DOI 10.1109/TC.2013.223
   Zhang DQ, 2014, IEEE WIREL COMMUN, V21, P26, DOI 10.1109/MWC.2014.6757894
   Zhang DQ, 2014, IEEE NETWORK, V28, P4, DOI 10.1109/MNET.2014.6724100
NR 36
TC 12
Z9 14
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17689
EP 17709
DI 10.1007/s11042-016-3614-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600044
DA 2024-07-18
ER

PT J
AU Zhang, XL
   Chen, G
   Han, Y
   Gao, M
AF Zhang, Xiaolei
   Chen, Ge
   Han, Yong
   Gao, Man
TI Modeling and analysis of bus weighted complex network in Qingdao city
   based on dynamic travel time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Urban bus; Weighted complex network; Average travel time;
   Adjacency-stop; Topology structure; Temporal and spatial
ID TRANSPORT NETWORK; CENTRALITY
AB This paper builds a weighted bus adjacency-stop complex network model of Qingdao city based on the dynamic travel time between each two adjacent stops, using bus system data from 2014.09 to 2015.09, including 261 lines, 1758 stations and 1 billion arrival time of all the buses, provided by Urban Public Transport Development Research Institute of Qingdao. Based on this model, this paper have analyzed the static topological properties of Qingdao bus network, and also studied the features of dynamic weighted network based on average travel time. Weighted average path length shows the characteristics of morning and evening peak in working days, but the standard deviation is 4 min, which reveals the difference of bus system running status between the peak and non-peak is not obvious. Combined with GIS, in this paper, temporal and spatial visual analyses for node strength, edge weight, and weighted average path length in a working day are carried out. The results prove that the morning and evening peak of Qingdao bus system mainly appears in the central areas of Shinan District and Shibei District, and the nodes with large carrying capacity are mainly distributed in the commercial activity center, train station and bus station, etc.
C1 [Zhang, Xiaolei; Chen, Ge; Han, Yong; Gao, Man] Ocean Univ China, Coll Informat Sci & Engn, Engn Res Ctr Marine Informat Technol, Qingdao 266100, Peoples R China.
C3 Ocean University of China
RP Han, Y (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Engn Res Ctr Marine Informat Technol, Qingdao 266100, Peoples R China.
EM chinahanyong@126.com
RI zhang, xiaolei/P-1428-2018
FU Scientific and Technological Innovation Project - Qingdao National
   Laboratory for Marine Science and Technology [2015ASKJ01]; Innovation
   Fund for Technology Based Firms, China [14c26211100180]; Qingdao science
   and technology project of China [14-9-2-12-pt]
FX The author acknowledges the support from The Scientific and
   Technological Innovation Project Financially Supported by Qingdao
   National Laboratory for Marine Science and Technology under Grant No.
   2015ASKJ01, and the support from Innovation Fund for Technology Based
   Firms, China (No: 14c26211100180) and Qingdao science and technology
   project of China (No: 14-9-2-12-pt).
CR [Anonymous], EURASIP J WIRELESS C, DOI DOI 10.1002/MEET.14504701173/FULL
   Antoniades D, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P361, DOI 10.1109/SITIS.2014.68
   Aparicio S, 2015, ENTROPY-SWITZ, V17, P5848, DOI 10.3390/e17085848
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Bifone A, 2010, MAGN RESON IMAGING, V28, P1200, DOI 10.1016/j.mri.2010.07.001
   Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Chen YZ, 2007, PHYSICA A, V376, P747, DOI 10.1016/j.physa.2006.10.071
   Davis KF, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053723
   Feng SM, 2016, PHYSICA A, V441, P85, DOI 10.1016/j.physa.2015.08.030
   Gan CQ, 2014, COMMUN NONLINEAR SCI, V19, P2785, DOI 10.1016/j.cnsns.2013.12.026
   Guimerá R, 2005, P NATL ACAD SCI USA, V102, P7794, DOI 10.1073/pnas.0407994102
   Heymann Sebastien., 2014, ENCY SOCIAL NETWORK, P612
   [黄爱玲 Huang Ailing], 2013, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V13, P198
   Huang Hai-Jun, 2012, MODERN PHYS LETT B, V18, P1043
   Julian Sienkiewicz, 2005, PHYS REV E, V72
   Li CG, 2004, PHYSICA A, V343, P263, DOI 10.1016/j.physa.2004.05.058
   Li XM, 2015, IEEE ACM INT SYMP, P991, DOI 10.1109/CCGrid.2015.62
   Li XM, 2016, ADV ENG SOFTW, V93, P1, DOI 10.1016/j.advengsoft.2015.11.003
   Li X, 2015, SHOCK VIB, V2015, DOI 10.1155/2015/431476
   Lordan O, 2014, J TRANSP GEOGR, V37, P112, DOI 10.1016/j.jtrangeo.2014.04.015
   Lv Z, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION PROBLEM-SOLVING (ICCP), P161, DOI 10.1109/ICCPS.2015.7454116
   Maciej K, 2006, PHYS REV E, V74
   Meyer-Bäse A, 2015, PROC SPIE, V9496, DOI 10.1117/12.2181816
   Papo D, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0520
   Peters K, 2008, INT J CRIT INFRASTRU, V4, P46, DOI 10.1504/IJCIS.2008.016091
   Rubinov M, 2010, NEUROIMAGE, V52, P1059, DOI 10.1016/j.neuroimage.2009.10.003
   Schaffer J, 2013, INT CONF PERVAS COMP, P464
   Seaton KA, 2004, PHYSICA A, V339, P635, DOI 10.1016/j.physa.2004.03.019
   Sienkiewicz J, 2005, ACTA PHYS POL B, V36, P1771
   Soh H, 2010, PHYSICA A, V389, P5852, DOI 10.1016/j.physa.2010.08.015
   Sun L, 2011, CAN J CIVIL ENG, V38, P154, DOI 10.1139/L10-115
   Sun XQ, 2015, TRANSPORTMETRICA B, V3, P153, DOI 10.1080/21680566.2014.960504
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   von Ferber C, 2009, EUR PHYS J B, V68, P261, DOI 10.1140/epjb/e2009-00090-x
   Wang D, 2001, J TRAFFIC TRANSPORTA, V04, P55
   Wang JE, 2011, J TRANSP GEOGR, V19, P712, DOI 10.1016/j.jtrangeo.2010.08.012
   Wang W, 2015, VIRTUAL REALITY BASE
   Wang XR, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P1280, DOI 10.1109/ICICEE.2012.340
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Weng WG, 2007, INT J MOD PHYS C, V18, P889, DOI 10.1142/S0129183107010619
   Xu X, 2015, MEDIAT INFLAMM, V2015, DOI [10.1155/2015/380218, 10.1155/2015/810798]
   Yang LX, 2013, APPL MATH COMPUT, V219, P8705, DOI 10.1016/j.amc.2013.02.031
   Zhang X, 2015, 14 COTA INT C TRANSP, P1302
   Zhang X, 2015, ARPPS AUGMENTED REAL
   Zheng X, 2012, ACTA PHYS SINICA, V61
   Zhou M, 2009, COMPUTER MODERNIZATI, V1, P139
   Zhou Shi-bing, 2010, Computer Engineering and Applications, V46, P27, DOI 10.3778/j.issn.1002-8331.2010.16.008
   [朱刚 ZHU Gang], 2006, [计算机应用研究, Application Research of Computers], V23, P54
NR 49
TC 14
Z9 15
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17553
EP 17572
DI 10.1007/s11042-016-3376-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600038
DA 2024-07-18
ER

PT J
AU Hong, D
   Kim, DC
   Kwon, D
   Kim, J
AF Hong, Deukjo
   Kim, Dong-Chan
   Kwon, Daesung
   Kim, Jongsung
TI Improved preimage attacks on hash modes of 8-round AES-256
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Preimage attack; Hash modes; AES
ID IDEAL CIPHER MODEL; SECURITY; FASTER; PGV; MD4; DM
AB We observe the slow diffusion of the AES key schedule for 256-bit keys and find weakness which can be used in the preimage attack on its Davies-Meyer mode. Our preimage attack works for 8 rounds of AES-256 with the computational complexity of 2(124.9). It is comparable with Bogdanov et al.'s biclique-based preimage attack on AES-256, which is applicable up to full rounds but has the computational complexity more than 2(126.5). We also extend our result to the preimage attack on some well-known double-block-length hash modes assuming the underlying block cipher is 8-round AES-256, whose computational complexity is 2(252.9).
C1 [Hong, Deukjo; Kim, Dong-Chan; Kwon, Daesung] ETRI, Attached Inst, POB 1, Yuseong 305600, Daejeon, South Korea.
   [Kim, Jongsung] Kookmin Univ, Dept Math, Seoul, South Korea.
   [Kim, Jongsung] Kookmin Univ, Dept Financial Informat Secur, Plus Future Financial Informat Secur Specialist E, Seoul, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Kookmin University; Kookmin University
RP Kim, J (corresponding author), Kookmin Univ, Dept Math, Seoul, South Korea.; Kim, J (corresponding author), Kookmin Univ, Dept Financial Informat Secur, Plus Future Financial Informat Secur Specialist E, Seoul, South Korea.
EM jongsung.k@gmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2013R1A1A2059864]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (Grant No. 2013R1A1A2059864).
CR Advanced Encryption Standard (AES), 2001, ADV ENCR STAND AES F, V197
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   Aoki K, 2009, LECT NOTES COMPUT SC, V5381, P103, DOI 10.1007/978-3-642-04159-4_7
   Aoki K, 2009, LECT NOTES COMPUT SC, V5912, P578, DOI 10.1007/978-3-642-10366-7_34
   Aoki K, 2009, LECT NOTES COMPUT SC, V5677, P70, DOI 10.1007/978-3-642-03356-8_5
   Armknecht F, 2011, LECT NOTES COMPUT SC, V7073, P233, DOI 10.1007/978-3-642-25385-0_13
   Black J, 2002, LECT NOTES COMPUT SC, V2442, P320
   Bogdanov A, 2011, LECT NOTES COMPUT SC, V7073, P344, DOI 10.1007/978-3-642-25385-0_19
   Daemen J, 1997, LECT NOTES COMPUT SC, V1267, P149
   Dean R. D., 1999, THESIS
   HIROSE S, 2006, LNCS, V4047, P231
   Hong D, 2012, IEICE T FUND ELECTR, VE95A, P372, DOI 10.1587/transfun.E95.A.372
   Kelsey J, 2005, LECT NOTES COMPUT SC, V3494, P474
   Lai Xuejia, 1992, Lecture Notes in Computer Science, V658, P55
   Lee J, 2011, LECT NOTES COMPUT SC, V6841, P561, DOI 10.1007/978-3-642-22792-9_32
   Lee J, 2011, LECT NOTES COMPUT SC, V6558, P213, DOI 10.1007/978-3-642-19074-2_15
   Lee J, 2011, IEICE T FUND ELECTR, VE94A, P104, DOI 10.1587/transfun.E94.A.104
   Leurent G, 2008, LECT NOTES COMPUT SC, V5086, P412
   Moon D, 2011 FTRA INT S ADV
   Moon D, 2012, IEICE T FUNDAM ELE A, V95-A
   Preneel B., 1994, LNCS, V773, P363
   Sasaki Y, 2011, LECT NOTES COMPUT SC, V6733, P378
   Sasaki Y, 2009, LECT NOTES COMPUT SC, V5479, P134, DOI 10.1007/978-3-642-01001-9_8
   Secure Hash Standard (SHS), 2002, SEC HASH STAND SHS F, V180-2
NR 24
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14525
EP 14539
DI 10.1007/s11042-015-2769-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500031
DA 2024-07-18
ER

PT J
AU Lee, ES
   Lee, JH
   Shin, BS
AF Lee, Eun-Seok
   Lee, Jin-Hee
   Shin, Byeong-Seok
TI Vertex relocation: a feature-preserved terrain rendering method for
   pervasive computing environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Terrain rendering; feature preserving; vertex relocation; displacement
   mapping
ID VISUALIZATION
AB Recent days, real-time 3D visualization is widely required for pervasive games. Despite the use of level-of-detail techniques, the real-time rendering of massive terrain datasets exceeds the capability of today's graphics hardware. So, to visualize the realistic terrain on various devices, the oversimplification of datasets is required. The oversimplification reduces computing and data transmission time. Owing to the oversimplification, however, artifacts such as geo-popping may appear in rugged regions, particularly when low level-of-detail is involved. Geo-popping is undesirable visual effect that occurs when the transition of a 3D object to a different level of detail is performed. To reduce such artifacts, we propose a novel mesh simplification method by concentrating on the vertices of regular grids in a rugged area using the concept of attraction and elastic forces. Each sampling point of the terrain data may pull on adjacent vertices with an attraction force that corresponds to its predicted surface roughness. However, strong attraction forces may cause a geometrical twisting or overlapping problems. To solve these problems, we apply an elastic force to a vertex and its neighbors. This makes each vertex push its neighbors away when they are too close. Computing the displacement of each vertex using attraction and elastic forces provides a fine-mesh terrain representation in rough areas, and a coarse-mesh representation in smooth areas. As a result, our method efficiently visualizes more accurate terrain scenes by reducing the number of geo-popping that mainly appear in rugged areas.
C1 [Lee, Eun-Seok; Lee, Jin-Hee; Shin, Byeong-Seok] Inha Univ, Dept Comp Sci & Informat Engn, Inchon, South Korea.
   [Lee, Eun-Seok; Lee, Jin-Hee; Shin, Byeong-Seok] Inha Univ, 1401 Hitech Ctr,100 Inharo, Inchon 402751, South Korea.
C3 Inha University; Inha University
RP Shin, BS (corresponding author), Inha Univ, Dept Comp Sci & Informat Engn, Inchon, South Korea.; Shin, BS (corresponding author), Inha Univ, 1401 Hitech Ctr,100 Inharo, Inchon 402751, South Korea.
EM elflee77@nate.com; jhlee07@outlook.com; bsshin@inha.ac.kr
RI Lee, Eun-Seok/JVZ-7051-2024
OI Lee, Eun-Seok/0000-0002-8837-8491
FU Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [2012M3C4A7032781]
FX This research was supported by Next-Generation Information Computing
   Development Program through the National Research Foundation of Korea
   (NRF) funded by the Ministry of Education, Science and Technology (No.
   2012M3C4A7032781)
CR Alperin R., 1987, The College Mathematics Journal, V18, P137, DOI [DOI 10.2307/2686503, 10.2307/2686503]
   Asirvatham A., 2005, GPU GEMS 2, V2, P27
   Blythe D, 2006, ACM T GRAPHIC, V25, P724, DOI 10.1145/1141911.1141947
   Chang SM, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-14
   Cho H, 2014, J CONVERGENCE, V5
   Christou G, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-15
   Cignoni P, 1997, VISUAL COMPUT, V13, P199, DOI 10.1007/s003710050099
   Cignoni P., 2003, P 14 IEEE VIS 2003 V, P20
   Clasen M., 2006, EURO VIS06, P91, DOI [DOI 10.2312/VISSYM/EUROVIS06-/091-098, 10.2312/VisSym/EuroVis06/091-098, DOI 10.2312/VISSYM/EUROVIS06/091-098, 10.2312/VisSym/EuroVis06/091-098.]
   Dachsbacher Carsten., 2004, RENDERING TECHNIQUES, P103
   Dick C, 2009, COMPUT GRAPH FORUM, V28, P67, DOI 10.1111/j.1467-8659.2008.01298.x
   Duchaineau M, 1997, VISUALIZATION '97 - PROCEEDINGS, P81, DOI 10.1109/VISUAL.1997.663860
   Evans W, 2001, ALGORITHMICA, V30, P264, DOI 10.1007/s00453-001-0006-x
   Garland M., 1995, FAST POLYGONAL APPRO
   GOLDGOF DB, 1989, IEEE T PATTERN ANAL, V11, P1213, DOI 10.1109/34.42859
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Gunn SR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P515, DOI 10.1109/ICIP.1998.723491
   Hoppe H, 1998, VISUALIZATION '98, PROCEEDINGS, P35, DOI 10.1109/VISUAL.1998.745282
   Hu L., 2009, P 2009 S INTERACTIVE, P169
   Hwa LM, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P219, DOI 10.1109/VISUAL.2004.4
   Kim J, 2014, J INFORM PROCESSING, V10
   Lario Roberto., 2003, P VIIP 2003, P733
   Lee ES, 2011, IEICE T INF SYST, VE94D, P137, DOI 10.1587/transinf.E94.D.137
   Lee Hung Liew LHL, 2013, J CONVERGENCE, V4, P15
   Levenberg J, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P259, DOI 10.1109/VISUAL.2002.1183783
   Lindstrom P, 2002, IEEE T VIS COMPUT GR, V8, P239, DOI 10.1109/TVCG.2002.1021577
   Livny Y, 2008, VISUAL COMPUT, V24, P139, DOI 10.1007/s00371-007-0180-1
   Livny Y, 2009, VISUAL COMPUT, V25, P197, DOI 10.1007/s00371-008-0214-3
   Pajarola R, 1998, VISUALIZATION '98, PROCEEDINGS, P19, DOI 10.1109/VISUAL.1998.745280
   Pajarola R, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P395, DOI 10.1109/VISUAL.2002.1183800
   Pouderoux J., 2005, GRAPHITE '05: Proceedings of the 3rd international conference on Computer graphics and interactive techniques in Australasia and South East Asia, P299
   Puppo E, 1996, VARIABLE RESOLUTION, P202
   PURNOMO B., 2004, EUROGRAPHICSACM SIGG, P65
   Rottger S, 1998, WSCG 98, VOL 2, P315
   Salim K, 2014, J INFORM PROCESSING, V10
   Schneider J, 2006, GPU FRIENDLY HIGH QU
   Tae-Jung Kim T-JK, 2014, J CONVERGENCE, V5, P14
   Tanner C. C., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P151, DOI 10.1145/280814.280855
   Ugural A. C., 2003, PEARSON ED
   Ulrich T., 2002, SIGGRAPH COURSE NOTE, V3
   Verma OP, 2013, J INFORM PROCESSING, V9
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Xia JC, 1996, IEEE VISUAL, P327, DOI 10.1109/VISUAL.1996.568126
NR 43
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14057
EP 14073
DI 10.1007/s11042-015-2715-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500004
DA 2024-07-18
ER

PT J
AU Marin, G
   Dominio, F
   Zanuttigh, P
AF Marin, Giulio
   Dominio, Fabio
   Zanuttigh, Pietro
TI Hand gesture recognition with jointly calibrated Leap Motion and depth
   sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth; Gesture recognition; Calibration; Kinect; Leap Motion; SVM
AB Novel 3D acquisition devices like depth cameras and the Leap Motion have recently reached the market. Depth cameras allow to obtain a complete 3D description of the framed scene while the Leap Motion sensor is a device explicitly targeted for hand gesture recognition and provides only a limited set of relevant points. This paper shows how to jointly exploit the two types of sensors for accurate gesture recognition. An ad-hoc solution for the joint calibration of the two devices is firstly presented. Then a set of novel feature descriptors is introduced both for the Leap Motion and for depth data. Various schemes based on the distances of the hand samples from the centroid, on the curvature of the hand contour and on the convex hull of the hand shape are employed and the use of Leap Motion data to aid feature extraction is also considered. The proposed feature sets are fed to two different classifiers, one based on multi-class SVMs and one exploiting Random Forests. Different feature selection algorithms have also been tested in order to reduce the complexity of the approach. Experimental results show that a very high accuracy can be obtained from the proposed method. The current implementation is also able to run in real-time.
C1 [Marin, Giulio; Dominio, Fabio; Zanuttigh, Pietro] Univ Padua, Dept Informat Engn, Padua, Italy.
C3 University of Padua
RP Zanuttigh, P (corresponding author), Univ Padua, Dept Informat Engn, Padua, Italy.
EM maringiu@dei.unipd.it; dominiof@dei.unipd.it; zanuttigh@dei.unipd.it
RI Zanuttigh, Pietro/AAB-9555-2019
OI Zanuttigh, Pietro/0000-0002-9502-2389
CR [Anonymous], 2012, ECCV
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YW, 2006, STUD FUZZ SOFT COMP, V207, P315
   DalMutto C, 2012, SPRBRIEF ELECT, P1, DOI 10.1007/978-1-4614-3807-6
   DavidWAha Richard L, 1996, A Comparative Evaluation of Sequential Feature Selection Algorithms, P199, DOI [10.1007/978-1-4612-2404-4_19, DOI 10.1007/978-1-4612-2404-4_19]
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Dominio Fabio., 2013, Proceedings of the 4th ACM/IEEE international workshop on Analysis and retrieval of tracked events and motion in imagery stream, P9
   Guerrero-Rincon C., 2013, ROB ISR 2013 44 INT, P1
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Keskin C, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130391
   Kosmopoulos DI, 2005, IEEE INT C IM PROC, V3
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208
   Marin G, 2013, P MULT SIGN PROC PUL
   Marin G, 2014, P IEEE INT C IM PROC
   Mohandes M, 2014, PROC IEEE INT SYMP, P960, DOI 10.1109/ISIE.2014.6864742
   Nigam I, 2014, P IEEE INT C IM PROC
   Pedersoli F, 2012, P ACM C MULT 2012 OP
   Potter L.E., 2013, P 25 AUSTR COMPUTER, P175, DOI [10.1145/2541016.2541072, DOI 10.1145/2541016.2541072]
   Ren Z, 2011, PROC FL STATE HORTIC, V124, P1
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Suryanarayan Poonam, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3105, DOI 10.1109/ICPR.2010.760
   Vikram S., 2013, CHI'13 Extended Abstracts on Human Factors in Computing Systems, P1179
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
NR 29
TC 164
Z9 175
U1 1
U2 147
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14991
EP 15015
DI 10.1007/s11042-015-2451-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500058
DA 2024-07-18
ER

PT J
AU Yu, J
   Zhang, XP
   Li, FY
AF Yu, Jiang
   Zhang, Xinpeng
   Li, Fengyong
TI Spatial steganalysis using redistributed residuals and diverse ensemble
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Redistribute; Diverse ensemble; Steganalysis
AB This paper proposes a spatial steganalytic scheme based on redistributed residuals and diverse ensemble classifier. In the scheme, the residuals obtained by local pixel predictors are shifted and suppressed to form the redistributed residuals, and then 2929 dimension features are calculated from the first-order statistic of original and redistributed residuals. With the aid of first-order statistic in a broad range, the feature can preserve the long-range dependencies between pixels, especially for highly adaptive steganography. Another advantage of the feature is that the dimension of first-order statistic is linear with range of residuals, so that the computational complexity is lowered. Moreover, with Bagging and AdaBoost mechanisms introduced here, we can get diverse representation of final feature and enhance the individual weak classifier, respectively. Compared with previous works, experimental results show that our scheme is effective at low embedding rate and is characterized by lower computational complexity.
C1 [Yu, Jiang; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Li, Fengyong] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
C3 Shanghai University; Shanghai University of Electric Power
RP Yu, J (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM sxyj1981@shu.edu.cn; xzhang@shu.edu.cn; fyli@shiep.edu.cn
FU National Natural Science Foundation of China [61472235, 61202367,
   61272043, 61373151]; Research Fund for the Doctoral Program of Higher
   Education of China [20113108110010]; Program for Professor of Special
   Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning; Shanghai Pujiang Program [13PJ1403200]; Shanghai Rising-Star
   Program [14QA1401900]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61472235, 61202367, 61272043 and 61373151, the
   Research Fund for the Doctoral Program of Higher Education of China
   under Grant 20113108110010, the Program for Professor of Special
   Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning, Shanghai Pujiang Program under Grant 13PJ1403200 and Shanghai
   Rising-Star Program under Grant 14QA1401900.
CR Alattar A, 2013, P SPIE ELECT IMAGING, pOL 1
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2011, P 13 INF HID C PRAG
   [Anonymous], 2006, Stud Fuzziness Soft Comput
   Bishop Christopher M, 2006, Pattern Recognition and Machine Learning
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Freund Y., 1995, Computational Learning Theory. Second European Conference, EuroCOLT '95. Proceedings, P23
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Kodovsky J, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P123, DOI 10.1145/1411328.1411352
   Li FY, 2013, IEEE SIGNAL PROC LET, V20, P233, DOI 10.1109/LSP.2013.2240385
   Pevny T., 2012, P SOC PHOTO-OPT INS, V8303, P1
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Shi YQ, 2006, LECT NOTES COMPUTER, V4437, P49
NR 19
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13613
EP 13625
DI 10.1007/s11042-015-2742-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800033
DA 2024-07-18
ER

PT J
AU Zhu, DJ
AF Zhu, Dingju
TI Overlapping boundary based multimedia slice transcoding method and its
   system for medical video and traffic video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Overlapping boundary; Slice transcoding
ID PARALLEL
AB This paper is concerned about the field of multimedia transcoding technology. This paper provides a method for multimedia slice transcoding. This method is detailed as follows: the multimedia is segmented according to the preset unit to obtain large numbers of slices; the length of the slices' fuzzy area is acquired; both ends of each slice is made redundant for fuzzy area length; the slices after redundancy are transcoded; the redundant fuzzy area length at both ends of transcoded slice is cut; the slices of cut fuzzy area length are spliced. The method for multimedia slice transcoding stated in this paper can remove the boundary fuzzy area when the transcoded slices are spliced in order to obtain more satisfactory multimedia effects.
C1 [Zhu, Dingju] South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Zhu, Dingju] Guangdong Prov Ctr Smart Land Res, Guangzhou, Guangdong, Peoples R China.
C3 South China Normal University
RP Zhu, DJ (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.; Zhu, DJ (corresponding author), Guangdong Prov Ctr Smart Land Res, Guangzhou, Guangdong, Peoples R China.
EM zhudj@scnu.edu.cn
FU University-industry Collaborative Innovation Transfer and Transformation
   Project of Guangdong Province [2014B090901064]; Major Project of
   National Social Science Fund [14ZDB101]; National Natural Science
   Foundation of China [61105133]
FX This research was supported by University-industry Collaborative
   Innovation Transfer and Transformation Project of Guangdong Province
   under Grant No. 2014B090901064, Major Project of National Social Science
   Fund under Grant No. 14ZDB101, and National Natural Science Foundation
   of China under Grant No. 61105133.
CR [Anonymous], 2014, CLOUD COMPUTING DIGI, P103
   Ashraf A, 2013, IEEE ACM INT SYMP, P482, DOI 10.1109/CCGrid.2013.21
   BABU DV, 2014, ASIAN J SCI RES, V7, P85, DOI DOI 10.3923/ajsr.2014.85.93
   Barlas G, 2012, PARALLEL COMPUT, V38, P226, DOI 10.1016/j.parco.2012.02.001
   Cerqueira E, 2014, INT CONF COMPUT NETW, P242, DOI 10.1109/ICCNC.2014.6785339
   Daz-Snchez D, 2014, TELECOMMUN SYST, P1
   Franche JF, 2011, U.S. Patent Application, Patent No. [13/309,298, 13309298]
   Hashmi M. F., 2013, ELSEVIER SCI, V4, P51
   Jokhio Fareed, 2013, 2013 39th Euromicro Conference on Software Engineering and Advanced Applications (SEAA), P365, DOI 10.1109/SEAA.2013.17
   Jokhio F., 2012, Proceedings of the 2012 20th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP 2012), P206, DOI 10.1109/PDP.2012.59
   Jokhio F, 2013, EUROMICRO WORKSHOP P, P254, DOI 10.1109/PDP.2013.44
   Kim M., 2014, LECT NOTES ELECT ENG, V274, P365
   Kim M, 2015, INFORMATION, V18, P2099
   Kwatra V, 2015, U.S. Patent, Patent No. [8,965,124, 8965124]
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Shirale S, 2015, WORK, V5
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Sze V, 2012, IEEE J SOLID-ST CIRC, V47, P8, DOI 10.1109/JSSC.2011.2169310
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Wang K, 2014, IEEE INT CONF BIG DA, P119, DOI 10.1109/BigData.2014.7004220
   Wang YX, 2015, PROCEEDINGS OF 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P4
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yi Wang, 2014, 2014 IEEE 28th International Parallel & Distributed Processing Symposium Workshops (IPDPSW). Proceedings, P508, DOI 10.1109/IPDPSW.2014.64
   Youm S, 2015, U.S. Patent, Patent No. [8,929,713, 8929713]
   Zhang Su., 2014, P 9 ACM S INFORM COM, P317, DOI DOI 10.1145/2590296.2590300
NR 28
TC 3
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14233
EP 14246
DI 10.1007/s11042-015-3235-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500014
DA 2024-07-18
ER

PT J
AU Cheng, SC
   Su, JY
   Hsiao, KF
   Rashvand, HF
AF Cheng, Shyi-Chyi
   Su, Jui-Yuan
   Hsiao, Kuei-Fang
   Rashvand, Habib F.
TI Latent semantic learning with time-series cross correlation analysis for
   video scene detection and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time-series cross correlation analysis; Dynamic scene model; K-medoids
   clustering; SVM; Dynamic programming
ID ACTION RECOGNITION
AB This paper presents a novel, latent semantic learning method based on the proposed time-series cross correlation analysis for extracting a discriminative dynamic scene model to address the recognition problems of video event recognition and 3D human body gesture. Typical dynamic texture analysis poses the problems of modeling, learning, recognizing and synthesizing the images of dynamic scenes based on the autoregressive moving average (ARMA) model. Instead of applying the ARMA approach to capture the temporal structure of video sequences, this algorithm uses the learned dynamic scene model to semantically transform video sequences into multiple scenes with a lower computational effort. Therefore, to generate a discriminative dynamic scene model with space-time information preserved is crucial for the success of the proposed latent semantic learning. To achieve the goal, the k-medoids clustering with appearance distance metrics first used to partition all frames of training video sequences, regardless of their scene types, to provide an initial key-frame codebook. To discover the temporal structure of the dynamic scene model, we develop a time-series cross correlation analysis (TSCCA) to the latent semantic learning, with an alternating dynamic programing (ADP) to embed the time relationship between the training images into the dynamic scene model. We also tackle the problem of dynamic programming, which is supposed to produce large temporal misalignment for periodic activities. Moreover, the discriminative power of the model is estimated by a deterministic projection-based learning algorithm. Finally, based on the learned dynamic scene model, this paper uses a support vector machine (SVM) with a two-channel string kernel for video scene classification. Two test datasets, one for video event classification and the other for 3D human body gesture recognition, are used to verify the effectiveness of the proposed approach. Experimental results demonstrate that the proposed algorithm obtains good performance in terms of classification accuracy.
C1 [Cheng, Shyi-Chyi; Su, Jui-Yuan] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung, Taiwan.
   [Hsiao, Kuei-Fang] Ming Chuan Univ, Dept Informat Management, Taipei, Taiwan.
   [Rashvand, Habib F.] Univ Warwick, Adv Commun Syst, Coventry, W Midlands, England.
C3 National Taiwan Ocean University; Ming Chuan University; University of
   Warwick
RP Hsiao, KF (corresponding author), Ming Chuan Univ, Dept Informat Management, Taipei, Taiwan.
EM csc@mail.ntou.edu.tw; rysu@mail.mcu.edu.tw; kfhsiao@mail.mcu.edu.tw;
   H.Rashvand@ieee.org
FU Ministry of Science and Technology, Taiwan [MOST 103-2221-E-019-018-MY2,
   MOST 103-2511-S-130-003]
FX This work was supported in part by Ministry of Science and Technology,
   Taiwan, under grant numbers MOST 103-2221-E-019-018-MY2 and MOST
   103-2511-S-130-003. The study has benefitted from Mr. Yun-Lun Chen for
   his technical support.
CR Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   [Anonymous], 2012, Kinect SDK
   [Anonymous], P 20 BRIT MACH VIS C
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P69, DOI 10.1007/s11042-009-0351-3
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Branco JA, 2005, COMPUTATION STAT, V20, P203, DOI 10.1007/BF02789700
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148
   Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z
   Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y-L, 2012, P 27 C IM VIS COMP
   Cheng SC, 2010, PATTERN RECOGN, V43, P267, DOI 10.1016/j.patcog.2009.05.016
   Chuang CH, 2014, J VIS COMMUN IMAGE R, V25, P1018, DOI 10.1016/j.jvcir.2014.02.014
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Han Dong., 2009, ICCV
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klank U, 2009, IEEE INT CONF ROBOT, P1946
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023
   Lavee G, 2009, IEEE T SYST MAN CY C, V39, P489, DOI 10.1109/TSMCC.2009.2023380
   Li, 2011, ICML
   Ma Z, 2013, IEEE T MULTIMEDIA, V15, P1628, DOI 10.1109/TMM.2013.2264928
   Nam Y, 2012, MULTIMED TOOLS APPL, V57, P315, DOI 10.1007/s11042-010-0677-x
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Park JH, 2013, MULTIMED TOOLS APPL, V63, P161, DOI 10.1007/s11042-012-1029-9
   Pierobon M, 2007, SIGMAP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P406
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Raptis M., 2011, Proceedings of the 2011 ACM SIG- GRAPH/Eurographics Symposium on Computer Animation - SCA '11, P147, DOI DOI 10.1145/2019406.2019426
   Ravichandran A, 2011, IEEE T PATTERN ANAL, V33, P158, DOI 10.1109/TPAMI.2010.61
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Rui Hu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3661, DOI 10.1109/ICIP.2011.6116513
   Sun Ju., 2009, CVPR
   Wang F, 2008, ADVANCES IN MATRIX THEORY AND ITS APPLICATIONS, VOL 1, P238
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Weng MF, 2012, IEEE T PATTERN ANAL, V34, P1927, DOI 10.1109/TPAMI.2011.273
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
   Yao B, 2009, IEEE I CONF COMP VIS, P1507, DOI 10.1109/ICCV.2009.5459277
   Yao BZ, 2014, IEEE T PATTERN ANAL, V36, P436, DOI 10.1109/TPAMI.2013.144
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
NR 48
TC 5
Z9 5
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12919
EP 12940
DI 10.1007/s11042-015-2548-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700036
DA 2024-07-18
ER

PT J
AU Kroupi, E
   Hanhart, P
   Lee, JS
   Rerabek, M
   Ebrahimi, T
AF Kroupi, Eleni
   Hanhart, Philippe
   Lee, Jong-Seok
   Rerabek, Martin
   Ebrahimi, Touradj
TI Modeling immersive media experiences by sensing impact on subjects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; Heart rate; Respiration; Immersiveness; Fusion; Quality of
   experience
ID VIRTUAL ENVIRONMENTS; ASYMMETRY
AB As immersive technologies target to provide higher quality of multimedia experiences, it is important to understand the quality of experience (QoE) perceived by users from various multimedia rendering schemes, in order to design and optimize human-centric immersive multimedia systems. In this study, various QoE-related aspects, such as depth perception, sensation of reality, content preference, and perceived quality are investigated and compared for presentation of 2D and 3D contents. Since the advantages of implicit over explicit QoE assessment have become essential, the way these QoE-related aspects influence brain and periphery is also investigated. In particular, two classification schemes using electroencephalography (EEG) and peripheral signals (electrocardiography and respiration) are carried out, to explore if it is possible to automatically recognize the QoE-related aspects under investigation. In addition, a decision-fusion scheme is applied to EEG and peripheral features, to explore the advantage of integrating information from the two modalities. The results reveal that the highest monomodal average informedness is achieved in the high beta EEG band (0.14 % +/- 0.09, p < 0.01), when recognizing sensation of reality. The highest and significantly non-random multimodal average informedness is achieved when high beta EEG band is fused with peripheral features (0.17 % +/- 0.1, p < 0.01), for the case of sensation of reality. Finally, a temporal analysis is conducted to explore how the EEG correlates for the case of sensation of reality change over time. The results reveal that the right cortex is more involved when sensation of reality is low, and the left when sensation of reality is high, indicating that approach and withdrawal-related processes occur during sensation of reality.
C1 [Kroupi, Eleni; Hanhart, Philippe; Rerabek, Martin; Ebrahimi, Touradj] Ecole Polytech Fed Lausanne, Multimedia Signal Proc Grp, Stn 11, CH-1015 Lausanne, Switzerland.
   [Lee, Jong-Seok] Yonsei Univ, Sch Integrated Technol, Seoul, South Korea.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Yonsei University
RP Lee, JS (corresponding author), Yonsei Univ, Sch Integrated Technol, Seoul, South Korea.
EM eleni.kroupi@epfl.ch; philippe.hanhart@epfl.ch;
   jong-seok.lee@yonsei.ac.kr; martin.rerabek@epfl.ch;
   touradj.ebrahimi@epfl.ch
RI Lee, Jong-Seok/AAF-5197-2020
OI Lee, Jong-Seok/0000-0001-5255-4425; Ebrahimi,
   Touradj/0000-0002-9900-3687
FU Swiss National Foundation for Scientific Research [FN 200020-132673-1,
   FN 200021-143696-1]; FP7 EC EUROSTAR; QoE-Net Initial Training Network
   [H2020-MSCA-ITN-2014]; Basic Science Research Program through the
   National Research Foundation of Korea - Ministry of Science, ICT and
   Future Planning (MSIP), Korea [2013R1A1A1007822]; IT Consilience
   Creative Program - MSIP, Korea [IITP-2015-R0346-15-1008]
FX The research leading to these results has been performed in the
   framework of two Swiss National Foundation for Scientific Research (FN
   200020-132673-1 and FN 200021-143696-1), FP7 EC EUROSTAR funded Project
   - Transcoders Of the Future TeleVision (TOFuTV), QoE-Net Initial
   Training Network (H2020-MSCA-ITN-2014), the Basic Science Research
   Program through the National Research Foundation of Korea funded by the
   Ministry of Science, ICT and Future Planning (MSIP), Korea
   (2013R1A1A1007822), and the IT Consilience Creative Program funded by
   MSIP, Korea (IITP-2015-R0346-15-1008).
CR [Anonymous], 1998, PATTERN RECOGNITION
   [Anonymous], 2005, Electric Fields of the Brain: The Neurophysics of Eeg
   [Anonymous], 2009, ELEMENTS STAT LEARNI
   [Anonymous], 2012, ITUR Recommendation BT. 500-13
   [Anonymous], 2012, BT2021 ITUR
   [Anonymous], 2008, Subjective video quality assessment methods for multimedia applications. Recommendation P.910
   Bilchick KC, 2006, J CARDIOVASC ELECTR, V17, P691, DOI 10.1111/j.1540-8167.2006.00501.x
   Blankertz B, 2011, NEUROIMAGE, V56, P814, DOI 10.1016/j.neuroimage.2010.06.048
   DAVIDSON RJ, 1990, J PERS SOC PSYCHOL, V58, P330, DOI 10.1037/0022-3514.58.2.330
   Dores AR, 2014, PSYCHNOLOGY J, V12, P29
   Emoto M, 2005, J DISP TECHNOL, V1, P328, DOI 10.1109/JDT.2005.858938
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   HAGURA H, 2006, P SOC PHOTO-OPT INS, V6057, P192
   Hayward V., 2004, Sensor Review, V24, P16, DOI 10.1108/02602280410515770
   Hofmann DA, 2011, SIOP ORGAN FRONT SER, P1
   Jensen O, 2005, NEUROIMAGE, V26, P347, DOI 10.1016/j.neuroimage.2005.02.008
   Kim D., 2011, INT SAMPE TECHNICAL, P1, DOI DOI 10.1109/ICDSP.2011.6004999
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kroupi E., 2014, P IEEE INT C MULT EX
   Kroupi E, 2014, P 22 EUR SIGN PROC C
   Kroupi E, 2014, P 8 INT WORKSH VID P
   Kulkarni SD, 2012, IEEE-ASME T MECH, V17, P635, DOI 10.1109/TMECH.2011.2113353
   Lee JS, 2011, IEEE J-STSP, V5, P1322, DOI 10.1109/JSTSP.2011.2165199
   Li Hyung-Chul O., 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P213, DOI 10.1109/3DTV.2008.4547846
   Müller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schäfer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175
   Scholler S, 2012, IEEE T IMAGE PROCESS, V21, P2619, DOI 10.1109/TIP.2012.2187672
   Schutter DJLG, 2008, HUM BRAIN MAPP, V29, P574, DOI 10.1002/hbm.20417
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   von der Pütten AM, 2012, INTERACT COMPUT, V24, P317, DOI 10.1016/j.intcom.2012.03.004
NR 36
TC 13
Z9 13
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12409
EP 12429
DI 10.1007/s11042-015-2980-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700007
DA 2024-07-18
ER

PT J
AU Lee, S
   Kim, J
   Shon, T
AF Lee, Seokcheol
   Kim, Jongwan
   Shon, Taeshik
TI User privacy-enhanced security architecture for home area network of
   Smartgrid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smartgrid; Home area network; Customer domain; Communication
AB Smartgrid is a next-generation intelligent electrical grid that enables a two-way information exchange between a customer and an electricity provider by integrating ICT (information and communications technology) into the existing electrical grid. As ICT is applied to the electrical grid, the security vulnerabilities of the existing ICT are inherited into the Smartgrid environment. These vulnerabilities could also apply to the electrical grid features. Therefore, a security technology to cope with such vulnerabilities should be investigated. In this paper, in order to study a HAN (Home Area Network) of Smartgrid that primarily handles customers' personal information, we propose a HAN-centric Smartgrid logical architecture, based on the analysis of existing reference models. Further, we propose a security architecture that was made by applying security functions to the HAN logical architecture to prevent security threats, which can happen because of the security vulnerabilities in a Smartgrid environment. Finally, by conducting a scenario-based verification, we demonstrate that the security effects of the proposed security architecture can protect the HAN users' personal information and smoothly provide services for users.
C1 [Lee, Seokcheol; Kim, Jongwan] Ajou Univ, Dept Comp Engn, Suwon, South Korea.
   [Shon, Taeshik] Ajou Univ, Div Informat & Comp Engn, Suwon, South Korea.
C3 Ajou University; Ajou University
RP Shon, T (corresponding author), Ajou Univ, Div Informat & Comp Engn, Suwon, South Korea.
EM go467913@ajou.ac.kr; jonglan@ajou.ac.kr; tsshon@ajou.ac.kr
FU Power Generation and Electricity Delivery Core Technology Program of
   Korea Institute of Energy Technology Evaluation and Planning (KETEP) -
   Ministry of Trade, Industry and Energy, Republic of Korea
   [20131020402090]
FX This work was supported by the Power Generation and Electricity Delivery
   Core Technology Program of Korea Institute of Energy Technology
   Evaluation and Planning (KETEP) granted financial resource from the
   Ministry of Trade, Industry and Energy, Republic of Korea (no.
   20131020402090).
CR Abdallah Y, 2012, IEEE DECIS CONTR P, P1954, DOI 10.1109/CDC.2012.6425909
   Alcaraz C, 2014, FUTURE GENER COMP SY, V30, P146, DOI 10.1016/j.future.2013.06.030
   [Anonymous], NIST FRAM ROADM SMAR
   [Anonymous], RESIDENTIAL ENERGY M
   Fan Z., 2010, P 2010 ACM E EN C PA
   Hooper E, 2010, INT J INTELL COMPUT, V1, P124
   Hossain MS, 2013, MULTIMED TOOLS APPL, V67, P433, DOI 10.1007/s11042-012-1006-3
   IEEE Standards Coordinating Committee 21, 2011, 2030TM2011 IEEE STAN
   International Telecommunication Union, 2008, ITU T X1205 INTERFAC, V10, P49
   ITU-T, 2012, BOOST EN EFF SMARTGR
   ITU-T FG Smart, 2011, DEL SMARTGR ARCH REV
   Jokar P., 2011, 2011 IEEE Second International Conference on Smart Grid Communications (SmartGridComm 2011), P208, DOI 10.1109/SmartGridComm.2011.6102320
   Kailas A, 2012, J COMPUT NETW COMMUN, V2012, DOI 10.1155/2012/932181
   Ko J, 2013, IEICE T INF SYST, VE96D, P2021, DOI 10.1587/transinf.E96.D.2021
   Lee S, 2015, 2015 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P41, DOI 10.1109/PlatCon.2015.18
   Lim H, 2013, ICITCS2013, P327
   Metke AR, 2010, IEEE T SMART GRID, V1, P99, DOI 10.1109/TSG.2010.2046347
   NIST, 2014, 7628 NIST IR
   Park SO, 2013, MULTIMED TOOLS APPL, V63, P227, DOI 10.1007/s11042-011-0926-7
   Rajagopal Sridhar, 2011, 2011 IEEE Online Conference on Green Communications, P52, DOI 10.1109/GreenCom.2011.6082507
   Sahu N., 2012, COMPUTING COMMUNICAT, P1
   SGSF, 2013, REQ ENS SEC SMART GR
   Steimer P. K., 2010, 2010 International Power Electronics Conference (IPEC - Sapporo), P11, DOI 10.1109/IPEC.2010.5542328
   Tizazu GA, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P1116, DOI 10.1109/ICTC.2013.6675571
   Tong JZ, 2013, IEEE ANN INT CONF CY, P456, DOI 10.1109/CYBER.2013.6705489
   Wang WY, 2011, COMPUT NETW, V55, P3604, DOI 10.1016/j.comnet.2011.07.010
   Yan He, 2010, 2010 IEEE International Symposium on Power Line Communications and Its Applications (ISPLC 2010), P319, DOI 10.1109/ISPLC.2010.5479911
   Yan Y., 2011, IEEE GLOBAL TELECOMM, P1, DOI DOI 10.1109/GLOCOM.2011.6133655
   Yoo H, 2015, MULTIMED TOOLS APPL, V74, P303, DOI 10.1007/s11042-014-1870-0
   Zerbst J., 2010, IEEE PES INN SMART G, P1, DOI [10.1109/ISGTEUROPE.2010.5638900, DOI 10.1109/ISGTEUROPE.2010.5638900]
NR 30
TC 10
Z9 11
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12749
EP 12764
DI 10.1007/s11042-016-3252-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700026
DA 2024-07-18
ER

PT J
AU Li, XL
   Mou, LC
   Lu, XQ
AF Li, Xuelong
   Mou, Lichao
   Lu, Xiaoqiang
TI Video parsing via spatiotemporally analysis with images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic video parsing; Transfer learning; Maximum a posterior (MAP)
   inference; Markov Random Felds (MRF); Prior contextual constraint
ID ENERGY MINIMIZATION
AB Effective parsing of video through the spatial and temporal domains is vital to many computer vision problems because it is helpful to automatically label objects in video instead of manual fashion, which is tedious. Some literatures propose to parse the semantic information on individual 2D images or individual video frames, however, these approaches only take use of the spatial information, ignore the temporal continuity information and fail to consider the relevance of frames. On the other hand, some approaches which only consider the spatial information attempt to propagate labels in the temporal domain for parsing the semantic information of the whole video, yet the non-injective and non-surjective natures can cause the black hole effect. In this paper, inspirited by some annotated image datasets (e.g., Stanford Background Dataset, LabelMe, and SIFT-FLOW), we propose to transfer or propagate such labels from images to videos. The proposed approach consists of three main stages: I) the posterior category probability density function (PDF) is learned by an algorithm which combines frame relevance and label propagation from images. II) the prior contextual constraint PDF on the map of pixel categories through whole video is learned by the Markov Random Fields (MRF). III) finally, based on both learned PDFs, the final parsing results are yielded up to the maximum a posterior (MAP) process which is computed via a very efficient graph-cut based integer optimization algorithm. The experiments show that the black hole effect can be effectively handled by the proposed approach.
C1 [Li, Xuelong; Mou, Lichao; Lu, Xiaoqiang] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Ctr OPT IMagery Anal & Learning OPTIMAL, State Key Lab Transient Opt & Photon, Xian 710119, Shaanxi, Peoples R China.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS; State Key Laboratory of Transient Optics & Photonics
RP Lu, XQ (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Ctr OPT IMagery Anal & Learning OPTIMAL, State Key Lab Transient Opt & Photon, Xian 710119, Shaanxi, Peoples R China.
EM luxq666666@gmail.com
RI Li, Xuelong/ABF-3381-2020; Li, Xuelong/Z-3785-2019; li,
   xiang/GWM-6319-2022
OI Li, Xuelong/0000-0002-0019-4197
FU National Basic Research Program of China (973 Program) [2012CB719905];
   National Natural Science Foundation of China [61472413]; Chinese Academy
   of Sciences [LSIT201408]; Key Research Program of the Chinese Academy of
   Sciences [KGZD-EW-T03]
FX This work was supported in part by the National Basic Research Program
   of China (973 Program) under Grant 2012CB719905, in part by the National
   Natural Science Foundation of China under Grant 61472413, in part by
   Chinese Academy of Sciences under Grant LSIT201408 and in part by the
   Key Research Program of the Chinese Academy of Sciences under Grant
   KGZD-EW-T03.
CR [Anonymous], 2003, EXPLORING ARTIFICIAL
   [Anonymous], 2009, P BRIT MACH VIS C
   [Anonymous], P INT C COMP VIS PAT
   [Anonymous], P INT C COMP VIS
   Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z
   BAKER S, 2007, P INT C COMP VIS
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Chen X, 2014, SCI CHINA INFORM SCI, V57
   CHUANG Y, 2002, P ACM SIGGRAPH
   Criminisi A, 2006, P INT C COMP VIS PAT
   Fauqueur J, 2007, P INT C COMP VIS
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gould S., 2009, P INT C COMP VIS
   Karpathy A., 2014, P INT C COMP VIS PAT
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Ladicky L., 2010, P BMVC, P1
   Lee H., 2006, P NEUR INF PROC SYST
   Li XL, 2015, IEEE T CYBERNETICS, V45, P1876, DOI 10.1109/TCYB.2014.2361489
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Liu Y, 2011, COMPUT VIS IMAGE UND, V115, P300, DOI 10.1016/j.cviu.2010.10.007
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Mou L, 2013, P IEEE CHIN SUMM INT
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Robertson N, 2006, COMPUT VIS IMAGE UND, V104, P232, DOI 10.1016/j.cviu.2006.07.006
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shao L, 2014, IEEE T CIRC SYST VID, V24, P504, DOI 10.1109/TCSVT.2013.2276700
   Theriault C, 2013, P INT C COMP VIS PAT
   Tighe J, 2013, P INT C COMP VIS PAT
   Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z
   Wang JW, 2005, I C COMP SYST APPLIC
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   YEDIDIA J, 2000, P NEUR INF PROC SYST
   Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
   Zhang C., 2010, P EUR C COMP VIS
NR 38
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11961
EP 11976
DI 10.1007/s11042-015-2735-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200021
DA 2024-07-18
ER

PT J
AU Li, YD
   Chen, DW
AF Li, Yidong
   Chen, Dewang
TI A learning-based comprehensive evaluation model for traffic data quality
   in intelligent transportation systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent transportation systems; Fuzzy inference system; Traffic data
   quality
AB Human motion modelling has attracted more and more attentions in various industrial fields with the event of information technology. Previous studies focus on capturing, animating, understanding and modelling human gestures or physical activities. However, in many applications such as Intelligent Transportation Systems (ITS), the traffic data quality (TDQ) is becoming a critical issue which can has great influence on the efficiency of the modelling. In this paper, we focus on evaluating the traffic data quality (TDQ) from the large amount of detectors and traffic flow data in the modelling of Intelligent Transportation Systems (ITS). We first introduce four error indices of an occupancy speed model and an occupancy flow model as model evaluation indices, and two indices from experts as non-model evaluation indices. Then, we propose a comprehensive evaluation model (CEM) for TDQ. Furthermore, we develop two algorithms for training the parameters in CEM based on the least square method (LSM) and the adaptive network based fuzzy inference system (ANFIS). We compare the proposed algorithms with the real-world traffic flow data which has been collected on Beijing ring-roads and connected lines. The experimental results show that the ANFIS-based learning method outperforms in most scenarios and ensures the evaluation error less than 10 %, which can significantly improve the efficiency of identifying traffic flow detectors with low data quality.
C1 [Li, Yidong] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Chen, Dewang] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Peoples R China.
   [Li, Yidong; Chen, Dewang] Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Beijing, Peoples R China.
C3 Beijing Jiaotong University; Fuzhou University; Beijing Jiaotong
   University
RP Chen, DW (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Peoples R China.; Chen, DW (corresponding author), Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Beijing, Peoples R China.
EM ydli@bjtu.edu.cn; dwchen@fzu.edu.cn
OI Li, Yidong/0000-0003-2965-6196
FU National Natural Science Foundation of China [61300175, 61103153];
   Fundamental Research Funds for the Central Universities [2014JBM042,
   2015ZBJ007]; China Grid Research Grant [XX71-14-036]; State Key
   Laboratory of Rail Traffic Control and Safety Research Grant
   [RCS2012K011]
FX This work has been partially funded by National Natural Science
   Foundation of China #61300175 and #61103153, Fundamental Research Funds
   for the Central Universities #2014JBM042 and #2015ZBJ007, China Grid
   Research Grant #XX71-14-036 and State Key Laboratory of Rail Traffic
   Control and Safety Research Grant #RCS2012K011..
CR Aldrich, 1998, INT STAT REV
   [Anonymous], 1959, OPER RES, P78
   Ben-Akiva M, 1994, INT J INTELL TRANSP, V1
   Carlson RC, 2010, TRANSPORT RES C-EMER, V18, P193, DOI 10.1016/j.trc.2009.05.014
   Chang XM, 2013, IEEE T INTELL TRANSP, V14, P469, DOI 10.1109/TITS.2012.2219529
   Chen D, 2006, 11 HKSTS INT M
   Chen DW, 2013, APPL SOFT COMPUT, V13, P3894, DOI 10.1016/j.asoc.2013.04.020
   Chen DW, 2004, IEEE T INTELL TRANSP, V5, P246, DOI 10.1109/TITS.2004.838226
   Dilruba O-E, 2012, INT J INFORM MANAGE, V32
   Fan LL, 2013, PROCD SOC BEHV, V96, P2595, DOI 10.1016/j.sbspro.2013.08.290
   GB D, 1935, HIGHWAY RES BOARD P, V448
   Giarratano J.C., 2005, EXPERT SYSTEMS PRINC
   Herrera JC, 2010, TRANSPORT RES C-EMER, V18, P568, DOI 10.1016/j.trc.2009.10.006
   Ignizio J.P., 1991, INTRO EXPERT SYSTEMS
   Jackson P, 1998, INTRO EXPERT SYSTEMS
   James C, 1984, COMPUTERS GEOSCIENCE
   JEL C, 1961, OPER RES, V66
   Jeong YS, 2011, TRANSPORT RES C-EMER, V19, P1, DOI 10.1016/j.trc.2009.10.005
   Papadimitriou E, 2013, ACCIDENT ANAL PREV, V60, P371, DOI 10.1016/j.aap.2013.04.040
   Peter JJ, 2012, J TRANSPORTATION ENG, P1205
   Tchrakian TT, 2012, IEEE T INTELL TRANSP, V13, P519, DOI 10.1109/TITS.2011.2174634
   Tien JM, 2013, J SYST SCI SYST ENG, V22, P127, DOI 10.1007/s11518-013-5219-4
   Turner S, 2004, TRANSPORT RES REC, P62, DOI 10.3141/1870-08
   WALKER A, 1990, KNOWLEDGE SYSTEMS PR
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001
NR 26
TC 18
Z9 18
U1 1
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11683
EP 11698
DI 10.1007/s11042-015-2676-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200006
DA 2024-07-18
ER

PT J
AU Wang, K
   Razzaq, A
   Wu, ZK
   Tian, F
   Ali, S
   Jia, TR
   Wang, XC
   Zhou, MQ
AF Wang, Kang
   Razzaq, Abdul
   Wu, Zhongke
   Tian, Feng
   Ali, Sajid
   Jia, Taorui
   Wang, Xingce
   Zhou, Mingquan
TI Novel correspondence-based approach for consistent human skeleton
   extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape correspondence; Heat Kernel signature; Mesh contraction; Skeleton
   extraction
ID SHAPE; RECOGNITION
AB This paper presents a novel base-points-driven shape correspondence (BSC) approach to extract skeletons of articulated objects from 3D mesh shapes. The skeleton extraction based on BSC approach is more accurate than the traditional direct skeleton extraction methods. Since 3D shapes provide more geometric information, BSC offers the consistent information between the source shape and the target shapes. In this paper, we first extract the skeleton from a template shape such as the source shape automatically. Then, the skeletons of the target shapes of different poses are generated based on the correspondence relationship with source shape. The accuracy of the proposed method is demonstrated by presenting a comprehensive performance evaluation on multiple benchmark datasets. The results of the proposed approach can be applied to various applications such as skeleton-driven animation, shape segmentation and human motion analysis.
C1 [Wang, Kang; Razzaq, Abdul; Wu, Zhongke; Ali, Sajid; Jia, Taorui; Wang, Xingce; Zhou, Mingquan] Beijing Normal Univ, Beijing Key Lab Digital Preservat & Virtual Real, Beijing, Peoples R China.
   [Tian, Feng] Bournemouth Univ, Sch Design Engn & Comp, Bournemouth, Dorset, England.
C3 Beijing Normal University; Bournemouth University
RP Wu, ZK (corresponding author), Beijing Normal Univ, Beijing Key Lab Digital Preservat & Virtual Real, Beijing, Peoples R China.
EM zwu@bnu.edu.cn
RI Ali, Shujat/JJF-4668-2023; Ali, Sk/JEO-9086-2023; Ali,
   Sajid/IWD-7100-2023
OI Ali, Shujat/0000-0002-4467-6091; Ali, Sajid/0000-0002-1287-849X; Razzaq,
   Abdul/0000-0003-4511-387X
FU National Natural Science Foundation of China [61170170, 61170203];
   National Key Technology Research and Development Program of China
   [2012BAH33F04]
FX The research is partially supported by National Natural Science
   Foundation of China (No. 61170170 and 61170203) and the National Key
   Technology Research and Development Program of China (2012BAH33F04).
CR Ahuja R. K., 1993, Network flows: theory, algorithms, and applications
   Chaaraoui AA, 2013, PATTERN RECOGN LETT, V34, P1799, DOI 10.1016/j.patrec.2013.01.021
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], ARXIV13112187
   [Anonymous], 2011, PROC EUROGRAPHICS 20, P79, DOI DOI 10.2312/3DOR/3DOR11/079-088
   [Anonymous], P 4 ANN ACM SIAM S D
   Au OKC, 2010, COMPUT GRAPH FORUM, V29, P645, DOI 10.1111/j.1467-8659.2009.01634.x
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Bandouch J, 2008, LECT NOTES COMPUT SC, V5098, P248, DOI 10.1007/978-3-540-70517-8_24
   Bandouch J, 2012, INT J COMPUT VISION, V99, P166, DOI 10.1007/s11263-012-0522-y
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c
   Dey TK, 2010, COMPUT GRAPH FORUM, V29, P1545, DOI 10.1111/j.1467-8659.2010.01763.x
   Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193
   Golovinskiy A, 2009, COMPUT GRAPH-UK, V33, P262, DOI 10.1016/j.cag.2009.03.010
   Hahmann S, 2008, MATH VIS, P1, DOI 10.1007/978-3-540-33265-7_1
   Jia TR, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P122, DOI 10.1109/CW.2014.25
   Jiang W, 2013, GRAPH MODELS, V75, P137, DOI 10.1016/j.gmod.2012.10.005
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Kravtsov D, 2014, COMPUT GRAPH FORUM, V33, P64, DOI 10.1111/cgf.12254
   Lafon S. S, 2004, DIFFUSION MAPS GEOME
   Le BH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601161
   Li X., 2001, P 2001 S INT 3D GRAP, P35, DOI DOI 10.1145/364338.364343
   Ma J, 2014, COMPUT AIDED DESIGN, V46, P221, DOI 10.1016/j.cad.2013.08.036
   Mahmoudi M, 2009, GRAPH MODELS, V71, P22, DOI 10.1016/j.gmod.2008.10.002
   Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Sahillioglu Y, 2014, COMPUT GRAPH FORUM, V33, P63, DOI 10.1111/cgf.12278
   Sahillioglu Y, 2011, COMPUT GRAPH FORUM, V30, P1461, DOI 10.1111/j.1467-8659.2011.02020.x
   Sahillioglu Y, 2012, IEEE T PATTERN ANAL, V34, P2203, DOI 10.1109/TPAMI.2012.26
   Sahillioglu Y, 2010, PROC CVPR IEEE, P453, DOI 10.1109/CVPR.2010.5540178
   Schwarz LA, 2012, IMAGE VISION COMPUT, V30, P217, DOI 10.1016/j.imavis.2011.12.001
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Smeets D, 2012, PATTERN RECOGN, V45, P2817, DOI 10.1016/j.patcog.2012.01.020
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang K, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P114, DOI 10.1109/CW.2014.24
   Wong S-K, 2012, P 11 ACM SIGGRAPH IN
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
   Yang Y, 2012, LECT NOTES COMPUT SC, V7583, P102, DOI 10.1007/978-3-642-33863-2_11
   Zhang H, 2008, COMPUT GRAPH FORUM, V27, P1431, DOI 10.1111/j.1467-8659.2008.01283.x
   Zhang MQ, 2014, GRAPH MODELS, V76, P532, DOI 10.1016/j.gmod.2014.04.010
   Zhang W, 2014, ROBUST LIKELIHOOD FU
   Zheng Q, 2010, COMPUT GRAPH FORUM, V29, P635, DOI 10.1111/j.1467-8659.2009.01633.x
NR 51
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11741
EP 11762
DI 10.1007/s11042-015-2629-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200009
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Hong, YZ
   Ren, GQ
   Liu, EH
   Sun, J
AF Hong, Yuzhen
   Ren, Guoqiang
   Liu, Enhai
   Sun, Jian
TI A blur estimation and detection method for out-of-focus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sharpness; Blurriness; Blur detection; No-reference; Out-of-focus; PSF;
   Gradient profile
ID QUALITY ASSESSMENT
AB With the analysis of the features of image edge based on the defocused model of optical imaging system, a blur estimation and detection method for out-of-focus images is proposed. The essential idea is to estimate the parameter of the point spread function, which reflects the blurriness of image. Based on the notion, the proposed method estimates the parameter values by different straight edges in the image, and the parameter distribution is used to measure the image blurriness. Then it can determine whether an image is blurred or not by comparing with a predetermined threshold. Experiment results show that the proposed blur metric is highly correlated to subjective visual perception, and it can be implemented to estimate and detect the blurriness for out-of-focus images with different scenes.
C1 [Hong, Yuzhen; Ren, Guoqiang; Liu, Enhai; Sun, Jian] Chinese Acad Sci, Inst Opt & Elect, Chengdu, Sichuan, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Optics & Electronics, CAS
RP Hong, YZ (corresponding author), Chinese Acad Sci, Inst Opt & Elect, Chengdu, Sichuan, Peoples R China.
EM hongyuzhen12@163.com
RI Ren, Guoqiang/A-7036-2009
CR [Anonymous], 2003, AS C SIGN SYST COMP
   [Anonymous], 2000, FIN REP VID QUAL EXP
   Aslantas V, 2007, OPT EXPRESS, V15, P5024, DOI 10.1364/OE.15.005024
   Bong D, 2014, MULTIMED TOOLS APPL, P1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caviedes J, 2004, SIGNAL PROCESS-IMAGE, V19, P147, DOI 10.1016/j.image.2003.08.002
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gonzalez L, 2008, J BIOMED OPT, V13, DOI 10.1117/1.2960621
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   Joshi N, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587834
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Liang LH, 2009, IEEE IMAGE PROC, P33
   Libin S, 2013, 2013 IE INT C COMP P
   Liu H, 2011, EUR WORKSH VIS INF P
   Liu XA, 2015, MULTIMED TOOLS APPL, V74, P2803, DOI 10.1007/s11042-013-1698-z
   Marichal X., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P386, DOI 10.1109/ICIP.1999.822923
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ong E, 2003, INT S SIGN PROC APPL
   Pentland A. P., 1985, P IJCAI 85 LOS ANGEL, V9, P988
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Sheikh HR, LIVE2 IMAGE QUALITY
   Subbarao M, 1988, COMPUT VIS PATTERN R, P498
   Sun Y, 2004, MICROSC RES TECHNIQ, V65, P139, DOI 10.1002/jemt.20118
   Tong HH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P17, DOI 10.1109/ICME.2004.1394114
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Zhu X, 2013, IEEE T IMAGE PROCESS, V22, P4879, DOI 10.1109/TIP.2013.2279316
NR 32
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 10807
EP 10822
DI 10.1007/s11042-015-2792-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900001
DA 2024-07-18
ER

PT J
AU Stahlschmidt, C
   Gavriilidis, A
   Velten, J
   Kummert, A
AF Stahlschmidt, Carsten
   Gavriilidis, Alexandros
   Velten, Joerg
   Kummert, Anton
TI Applications for a people detection and tracking algorithm using a
   time-of-flight camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE People detection; Top-view people detection; Top-view tof; Application
   people tracking; Time-of-flight; Matched filter; Entrance line
   detection; Standstill detection; Density measurements; Crowd detection;
   Crowd risk; Crowd analysis
AB This paper outlines a method and applications for detection and tracking of people in depth images, acquired with a low-resolution Time-of-Flight (ToF) camera. This depth sensor is placed perpendicular to the ground in order to provide distance information from a top-view position. Usage of intrinsic and extrinsic camera parameters allows estimation of a ground plane and comparison to the measured distances of the ToF sensor in every pixel. Differences to the expected ground plane define foreground information, that is subsequently combined to associated regions. These regions of interest (ROI) are analyzed to distinguish persons from other objects by using a matched filter that is applied the height segmented depth information of each of these regions. The proposed method separates crowds into individuals and facilitates a multi-object tracking system based on Kalman filtering. Furthermore, we present several applications for the proposed method. Experiments with different crowding situations - from very low to very high density - and different heights of camera placements have proven the applicability and practicability of the system.
C1 [Stahlschmidt, Carsten; Gavriilidis, Alexandros; Velten, Joerg; Kummert, Anton] Univ Wuppertal, Fac Elect Informat & Media Engn, Rainer Gruenter Str 21, D-42119 Wuppertal, Germany.
C3 University of Wuppertal
RP Stahlschmidt, C (corresponding author), Univ Wuppertal, Fac Elect Informat & Media Engn, Rainer Gruenter Str 21, D-42119 Wuppertal, Germany.
EM stahlschmidt@uni-wuppertal.de
FU European Community [218086]
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme (FP7 / 2007 - 2013)
   under grant agreement no. 218086.
CR [Anonymous], INT WORKSH MULT SYST
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P INT C COMP VIS ICC
   Bar-Shalom J, 2001, ESTIMATION APPL TRAC
   Bevilacqua A, 2006, IEEE 5 INT C ADV VID
   Beymer D, 2003, SPR TRA ADV ROBOT, V5, P234
   Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Han J, 2011, MULTIMED TOOLS APPL, V51, P913, DOI 10.1007/s11042-009-0423-4
   Hansard M., 2012, SPRINGER BRIEFS COMP
   Harville M, 2005, P INT C ADV VID SIGN, V1, P511
   HARVILLE M, 2004, IEEE C COMP VIS PATT
   Helbing D, 2011, TECH REP
   Ikemura S, 2012, INT C PATT RECOG, P813
   PMDTechnologies, 2010, TECH REP
   POLUS A, 1983, J TRANSP ENG-ASCE, V109, P46, DOI 10.1061/(ASCE)0733-947X(1983)109:1(46)
   Ringbeck T., 2007, OPTICAL 3 D MEASUREM
   Stahlschmidt C, 2013, P 8 INT WORKSH MULT
   Still G.K, 2000, Crowd dynamic
   Still GK, 2011, TECH REP
   Takahashi M, 2013, MULTIMED TOOLS APPL, V62, P761, DOI 10.1007/s11042-011-0870-6
   Tanner R, 2008, IEEE 5 INT C ADV VID
   Verstockt S, 2012, MULTIMED TOOLS APPL, P1
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 26
TC 20
Z9 21
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10769
EP 10786
DI 10.1007/s11042-014-2260-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800033
DA 2024-07-18
ER

PT J
AU Wang, DJ
   Sun, WP
   Yu, SS
   Li, L
   Liu, W
AF Wang, Dejun
   Sun, Weiping
   Yu, Shengsheng
   Li, Lin
   Liu, Wei
TI A novel background-weighted histogram scheme based on foreground
   saliency for mean-shift tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target tracking; Mean-Shift; Weighted histogram; Foreground feature
   saliency
ID SCALE
AB Effective appearance models are one critical factor for robust object tracking. In this paper, we introduce foreground feature saliency concept into the background modelling, and put forward a novel foreground saliency-based background-weighted histogram scheme (FSBWH) for target representation and tracking, which exploits salient features from both foreground and background. We think that background and foreground salient features are both crucial for target representation and tracking. Experimental results show that the proposed FSBWH scheme can improve the robustness and performance of tracker significantly especially in complex occlusions and similar background scenes.
C1 [Wang, Dejun; Sun, Weiping; Yu, Shengsheng; Li, Lin; Liu, Wei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Wang, Dejun] Donghua Software Co Ltd, Beijing 100190, Peoples R China.
   [Li, Lin] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430070, Peoples R China.
   [Liu, Wei] Cent China Normal Univ, Sch Comp Sci, Wuhan 430079, Peoples R China.
C3 Huazhong University of Science & Technology; Wuhan University of
   Technology; Central China Normal University
RP Sun, WP (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM dejunw123@gmail.com; wpsun@hust.edu.cn; ssyu@hust.edu.cn;
   lilyfour@163.com; liuwei@mail.ccnu.edu.cn
RI Li, Li/AEM-3636-2022; Yu, Sheng-Sheng/AAE-4862-2022; li,
   li/HII-4157-2022; liu, jiayu/JCP-0511-2023
OI Yu, Sheng-Sheng/0000-0003-1304-5630; 
FU National Natural Science Foundation of China (NSFC) [61300140]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under Grant 61300140.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chu H, 2013, CONTROL DECIS, V28
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fujii K, 2013, IEEE INT C INT ROBOT, P3582, DOI 10.1109/IROS.2013.6696867
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414
   Li SX, 2014, COMPUT VIS IMAGE UND, V125, P1, DOI 10.1016/j.cviu.2013.10.001
   Li X, 2011, IEEE I CONF COMP VIS, P1156, DOI 10.1109/ICCV.2011.6126364
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mikami D, 2010, LECT NOTES COMPUT SC, V6313, P215
   Moroni D., 2009, Pattern Recognition and Image Analysis, V19, P271, DOI 10.1134/S1054661809020096
   Morwald T., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2830, DOI 10.1109/ROBIO.2011.6181734
   Mure S, 2015, PATTERN RECOGNIT LET
   Ning J, 2012, IET COMPUT VIS, V6, P52, DOI 10.1049/iet-cvi.2010.0112
   Ning J, 2010, IET COMPUT VIS
   Olesen OV, 2012, IEEE T MED IMAGING, V31, P79, DOI 10.1109/TMI.2011.2165157
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Tian M, 2007, LECT NOTES COMPUT SC, V4843, P355
   Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025
   Wang DJ, 2014, LECT NOTES COMPUT SC, V8866, P508, DOI 10.1007/978-3-319-12436-0_56
   Wang DJ, 2014, KSII T INTERNET INF, V8, P1964, DOI 10.3837/tiis.2014.06.009
   Wang D, 2010, IEEE IMAGE PROC, P3957, DOI 10.1109/ICIP.2010.5651021
   Wang LF, 2011, IEEE IMAGE PROC, P473, DOI 10.1109/ICIP.2011.6116554
   Zheng H, 2015, OPTIK INT J LIGHT EL
NR 31
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10271
EP 10289
DI 10.1007/s11042-015-3078-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800009
DA 2024-07-18
ER

PT J
AU Jiang, WH
   Zhao, ZC
   Su, F
AF Jiang, Wenhui
   Zhao, Zhicheng
   Su, Fei
TI Bayes pooling of visual phrases for object retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual phrases; Unified framework; Bayes pooling; Burstiness
ID SIMILARITY
AB Object retrieval is still an open question. A promising approach is based on the matching of visual phrases. However, this routine is often corrupted by visual phrase burstiness, i.e., the repetitive occurrence of some certain visual phrases. Burstiness leads to over-counting the co-occurring visual patterns between two images, thus would deteriorate the accuracy of image similarity measurement. On the other hand, existing methods are incapable of capturing the complete geometric variation between images. In this paper, we propose a novel strategy to address the two problems. Firstly, we propose a unified framework for matching geometry-constrained visual phrases. This framework provides a possibility of combing the optimal geometry constraints to improve the validity of matched visual phrases. Secondly, we propose to address the problem of visual phrase burstiness from a probabilistic view. This approach effectively filters out the bursty visual phrases through explicitly modelling their distribution. Experiments on five benchmark datasets demonstrate that our method outperforms other approaches consistently and significantly.
C1 [Jiang, Wenhui; Zhao, Zhicheng; Su, Fei] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Jiang, WH (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
EM jiang1st@bupt.edu.cn; zhaozc@bupt.edu.cn; sufei@bupt.edu.cn
RI jiang, wen/GYI-9662-2022
FU Chinese National Natural Science Foundation [61471049, 61532018,
   61372169]; BUPT Excellent Ph.D. students Foundation [CX201425]
FX This work is supported by Chinese National Natural Science Foundation
   under Grants 61471049,61532018 and 61372169, and BUPT Excellent Ph.D.
   students Foundation under Grant CX201425.
CR [Anonymous], ARXIV14060132
   [Anonymous], 2012, P 20 ACM INT C MULTI
   [Anonymous], 2007, P CIKM
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Chum O, 2010, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2010.5539997
   El Sayad I., 2010, J MULTIMEDIA TOOLS A, P1
   Hao Q, 2012, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2012.6248104
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jiang YN, 2015, IEEE T IMAGE PROCESS, V24, P1748, DOI 10.1109/TIP.2015.2405337
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Murata M, 2014, IEEE T MULTIMEDIA, V16, P1690, DOI 10.1109/TMM.2014.2323945
   Nister David, 2006, CVPR
   Philbin J., 2008, P CVPR, P1
   Qin DF, 2013, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2013.211
   Shen XH, 2014, IEEE T PATTERN ANAL, V36, P1229, DOI 10.1109/TPAMI.2013.237
   Shi MJ, 2015, PROC CVPR IEEE, P605, DOI 10.1109/CVPR.2015.7298659
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tian Q, 2011, MULTIMED TOOLS APPL, V51, P441, DOI 10.1007/s11042-010-0636-6
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Xu JJ, 2013, IEEE T MULTIMEDIA, V15, P2046, DOI 10.1109/TMM.2013.2281019
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
   Zheng L, 2014, PROC CVPR IEEE, P1963, DOI 10.1109/CVPR.2014.252
   Zheng L, 2013, IEEE SIGNAL PROC LET, V20, P391, DOI 10.1109/LSP.2013.2249513
NR 36
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9095
EP 9119
DI 10.1007/s11042-015-2939-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500015
DA 2024-07-18
ER

PT J
AU Xue, H
   Qin, B
   Liu, T
AF Xue, Han
   Qin, Bing
   Liu, Ting
TI Topical key concept extraction from folksonomy through graph-based
   ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Folksonomy; Graph-based ranking; Topical key concept extraction;
   Topic-sensitive random walk
AB Existing studies for concept extraction mainly focus on text corpora and indiscriminately mix numerous topics, which may lead to a knowledge acquisition bottleneck and misconception. We thus propose a novel method for extracting topical key concepts from folksonomy. This method can overcome the aforementioned problems through rich user-generated content and topic-sensitive concept extraction. We first identify topics from folksonomy by using topic models. Tags are then ranked according to importance relative to a certain topic through graph-based ranking. The top-ranking tags are extracted as topical key concepts. The combination of a novel edge weight and preference is proposed in tag importance propagation. The proposed method is applied to different datasets and is found to outperform the state-of-the-art baselines significantly. From the perspectives of parameter influence and case study, the proposed method is feasible and effective.
C1 [Xue, Han; Qin, Bing; Liu, Ting] Harbin Inst Technol, Res Ctr Social Comp & Informat Retrieval, Harbin, Peoples R China.
   [Xue, Han] Harbin Engn Univ Lib, Harbin, Peoples R China.
C3 Harbin Institute of Technology
RP Xue, H; Liu, T (corresponding author), Harbin Inst Technol, Res Ctr Social Comp & Informat Retrieval, Harbin, Peoples R China.
EM hxue@ir.hit.edu.cn; bqin@ir.hit.edu.cn; tliu@ir.hit.edu.cn
RI liu, ting/GZM-3326-2022
FU National Natural Science Foundation of China (NSFC) [61273321,
   61133012]; National 863 Leading Technology Research Project
   [2012AA011102]
FX This work was supported by National Natural Science Foundation of China
   (NSFC) via grant 61273321, 61133012 and the National 863 Leading
   Technology Research Project via grant 2012AA011102. Finally, we would
   like to thank the anonymous reviewers for their insightful comments.
CR [Anonymous], 1992, COLING 1992, DOI DOI 10.3115/992133.992154
   [Anonymous], P 29 ANN INT ACM SIG
   [Anonymous], 2014, P INT C MULT RETR
   [Anonymous], 2009, STANFORD DIGITAL LIB
   [Anonymous], 2002, P 11 INT C WORLD WID, DOI DOI 10.1145/511446.511513
   [Anonymous], 1 INT WORKSH COLL SE
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cui GY, 2009, LECT NOTES ARTIF INT, V5459, P248
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   He J, 2011, P 49 ANN M ASS COMPU, P1
   Hotho A, 2006, LECT NOTES COMPUT SC, V4011, P411
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   Jin YA, 2011, ARTIF INTELL REV, V36, P139, DOI 10.1007/s10462-011-9207-0
   Liu X., 2012, P 18 ACM SIGKDD INT, P1433, DOI [DOI 10.1145/2339530.2339754, 10.1145/2339530.2339754]
   Liu Z., 2010, P 2010 C EMP METH NA, P366
   Mihalcea, 2004, P EMNLP, P401, DOI DOI 10.3115/1219044.1219064
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Nakamura K., 2008, WORLD ENV WATER RESO, P1
   Trant J., 2009, Journal of Digital Information, V10
   Voorhees E.M., 1999, Proceedings of TREC
   Voorhees EllenM., 2005, TREC
   Zhou MW, 2007, LECT NOTES COMPUT SC, V4825, P680
NR 22
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8875
EP 8893
DI 10.1007/s11042-014-2303-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500004
DA 2024-07-18
ER

PT J
AU Danisman, T
   Bilasco, IM
AF Danisman, Taner
   Bilasco, Ioan Marius
TI In-plane face orientation estimation in still images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE In-plane rotation estimation; Roll estimation; Head-pose estimation
ID POSE ESTIMATION; HEAD TRACKING
AB This paper addresses a fine in-plane (roll) face orientation estimation for a perspective face analysis algorithm that requires normalized frontal faces. As most of the face analysers (e.g., gender, expression, and recognition) need frontal up-right faces, there is a clear need for the precise roll estimation, as precise face normalization has an important role in classification methods. The in-plane orientation estimation algorithm is constructed on top of regular Viola-Jones frontal face detector. When a face is detected for the first time, it is rotated with respect to the face origin to find the boundaries of the detection. Mean value of these angles is said to be the measurement of the in-plane rotation of the face. Since we only need a face detection algorithm, the proposed method can work effectively on very small sized faces where traditional landmark (eye, mouth) or planar detection based estimations fail. Experiments on controlled and unconstrained large-scale datasets (CMU Rotated, YouTube, Boston University Face Tracking, Caltech, FG-NET Aging, BioID and Manchester Talking-Face) showed that the proposed method is robust to various settings for in-plane face orientation estimation in terms of RMSE and MAE. We achieved less than +/- 3.5 (a similar to) mean absolute error for roll estimation which proves that the accuracy of the proposed method is comparable to that of the state-of-the-art tracking based approaches for the roll estimation.
C1 [Danisman, Taner; Bilasco, Ioan Marius] Univ Lille 1, IRCICA, Parc Sci Haute Borne,50 Ave Halley, F-59655 Villeneuve Dascq, France.
   [Danisman, Taner] Akdeniz Univ, Dept Comp Engn, Fac Engn, TR-07058 Antalya, Turkey.
C3 Universite de Lille; Akdeniz University
RP Danisman, T (corresponding author), Univ Lille 1, IRCICA, Parc Sci Haute Borne,50 Ave Halley, F-59655 Villeneuve Dascq, France.; Danisman, T (corresponding author), Akdeniz Univ, Dept Comp Engn, Fac Engn, TR-07058 Antalya, Turkey.
EM tdanisman@akdeniz.edu.tr; marius.bilasco@lifl.fr
RI Danışman, Taner/B-9268-2016
OI Danışman, Taner/0000-0002-3607-4058; BILASCO, Ioan
   Marius/0000-0001-7254-8727
FU TWIRL (Twinning Virtual World Online Information with Real-World Data
   Sources) project [ITEA2 10029]
FX This study is supported by TWIRL (ITEA2 10029 - Twinning Virtual World
   Online Information with Real-World Data Sources) project.
CR An KH, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P307, DOI 10.1109/IROS.2008.4650742
   [Anonymous], 2010, WORKSH EYE GAZ INT H
   [Anonymous], 22 IEEE INT C PATT R
   [Anonymous], 12 INT WORKSH IM AN
   [Anonymous], TR200396 MITS EL RES
   [Anonymous], ECMR
   [Anonymous], MANCHESTER TALKING F
   [Anonymous], 2008, TENCON 2008
   [Anonymous], FGNET AG DAT
   Ba SO, 2004, INT C PATT RECOG, P264, DOI 10.1109/ICPR.2004.1333754
   Castrillón M, 2007, J VIS COMMUN IMAGE R, V18, P130, DOI 10.1016/j.jvcir.2006.11.004
   Dahmane A, 2015, SIGNAL IMAGE VIDEO P, V9, P1871, DOI 10.1007/s11760-014-0676-x
   Dahmane A, 2010, IEEE IMAGE PROC, P3249, DOI 10.1109/ICIP.2010.5651202
   Danisman T, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P407
   Demirkus M, 2014, MULTIMED TOOLS APPL, V70, P495, DOI 10.1007/s11042-012-1352-1
   Du SY, 2006, LECT NOTES COMPUT SC, V4270, P128
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Jia HP, 2012, IEEE I C EMBED SOFTW, P396, DOI 10.1109/HPCC.2012.60
   Jung SU, 2012, IEEE T INF FOREN SEC, V7, P1802, DOI 10.1109/TIFS.2012.2218598
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Lefèvre S, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P223
   Morency LP, 2010, IMAGE VISION COMPUT, V28, P754, DOI 10.1016/j.imavis.2009.08.004
   Murphy-Chutorian E, 2008, IEEE INT VEH SYM, P1174
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Tran NT, 2013, LECT NOTES COMPUT SC, V8033, P562, DOI 10.1007/978-3-642-41914-0_55
   Oka K., 2005, Proceedings of the IAPR Conference on Machine Vision Applications 2005, P586
   Osadchy M, 2007, J MACH LEARN RES, V8, P1197
   Pan H, 2013, COMPUT VIS IMAGE UND, V117, P12, DOI 10.1016/j.cviu.2012.09.003
   Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   Valenti R, 2009, PROC CVPR IEEE, P612, DOI 10.1109/CVPRW.2009.5206640
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Voit M., 2007, CLEAR 2007 evaluation plan
   Wang JG, 2007, IMAGE VISION COMPUT, V25, P1864, DOI 10.1016/j.imavis.2005.12.017
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   Weber M., 1999, Caltech frontal face database
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   WU B., 2004, Sixth IEEE International Conference on Automatic Face and Gesture Recognition (FG'04), P79
   Wu SQ, 2008, PATTERN RECOGN, V41, P2718, DOI 10.1016/j.patcog.2008.01.003
   Wu SQ, 2006, PATTERN RECOGN, V39, P303, DOI 10.1016/j.patcog.2005.06.003
   Xiao J, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P163, DOI 10.1109/AFGR.2002.1004149
   Yan SC, 2008, LECT NOTES COMPUT SC, V4625, P297
   Zhao G., 2007, P 15 INT C MULTIMEDI, P807
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhou J, 2002, IMAGE VISION COMPUT, V20, P257, DOI 10.1016/S0262-8856(02)00018-5
NR 45
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7799
EP 7829
DI 10.1007/s11042-015-2699-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600017
DA 2024-07-18
ER

PT J
AU Huang, CF
   Lian, YS
   Nien, WP
   Chieng, WH
AF Huang, Chih-Fang
   Lian, Yu-Shian
   Nien, Wei-Po
   Chieng, Wei-Hua
TI Analyzing the perception of Chinese melodic imagery and its application
   to automated composition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kansei engineering; Automated composition; Metrical complexity;
   Pentatonic scale
ID CONSUMER-ORIENTED TECHNOLOGY; SIMILARITY RATINGS; DIMENSION ANALYSES
AB This study investigated the influence of two music elements, mode and rhythm, on melodic imagery. By modulating different parameters of mode and rhythm, this study produced various melody samples. Kansei engineering was adopted as a research method for designing the experimental process. A set of music assessment rules was established by regularizing the existing modes and rhythms and analyzing and comparing their differences. The results were applied to automated composition in order to develop a comprehensive automated composition system. Before the hearing experiment, 39 adjective pairs were selected for the survey of melodic imagery by reviewing literature and engaging in discussions with experts. A Markov chain was adopted for analyzing the current modal music to establish a Markov switching table for the Chinese pentatonic scale, and metrical complexity was used for generating rhythms. Finally, 30 music samples were produced using the automated composition system by applying the various combinations of modes and rhythms. The hearing experiment was conducted on 35 participants for examining their perception of melodic imagery. Item analysis and a reliability test were performed on the experimental data for eliminating invalid samples and items. Thus, 14 adjective pairs with a Cronbach's alpha of 0.887 were obtained, indicating favorable reliability. In addition, this study involved conducting factor analysis and extracting three imagery factors, namely passionate-apathetic, beautiful-ugly, and romantic-rigid. Subsequently, multivariate analysis of variance was conducted in this study for determining the relationship between modes and metrical complexity and the 14 adjective pairs, and the estimated means were calculated. Multidimensional scaling was adopted for producing a two-dimensional perceptual map for the construction of a database. The experimental results of this study showed that modes and rhythms in music can effectively help musicians or computer composition systems compose melodies that create various perceptual imageries.
C1 [Huang, Chih-Fang] Kainan Univ, Dept Informat Commun, 1 Kainan Rd, Taoyuan 33857, Taiwan.
   [Lian, Yu-Shian] Natl Chiao Tung Univ, Master Program Sound & Mus Innovat Technol, 1001 Univ Rd, Hsinchu 300, Taiwan.
   [Nien, Wei-Po; Chieng, Wei-Hua] Natl Chiao Tung Univ, Dept Mech Engn, 1001 Univ Rd, Hsinchu 300, Taiwan.
C3 Nan Kai University Technology; National Yang Ming Chiao Tung University;
   National Yang Ming Chiao Tung University
RP Huang, CF (corresponding author), Kainan Univ, Dept Informat Commun, 1 Kainan Rd, Taoyuan 33857, Taiwan.
EM jeffh.me83g@gmail.com
FU National Science Council Projects of Taiwan [NSC 101-2410-H-155-033-MY3,
   NSC 101-2627-E-155-001-MY3]
FX The authors are appreciative of the support from the National Science
   Council Projects of Taiwan: NSC 101-2410-H-155-033-MY3 and NSC
   101-2627-E-155-001-MY3
CR [Anonymous], 1999, AISB S MUSICAL CREAT
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   Farnsworth P.R., 1954, Journal of Aesthetics and Art Criticism, V13, P97, DOI [DOI 10.2307/427021, 10.2307/427021, 10.1111/1540_6245.jaac13.1.0097]
   GABRIELSSON A, 1973, SCAND J PSYCHOL, V14, P138, DOI 10.1111/j.1467-9450.1973.tb00105.x
   GABRIELSSON A, 1973, SCAND J PSYCHOL, V14, P161, DOI 10.1111/j.1467-9450.1973.tb00106.x
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hiller L. A., 1959, Experimental Music: Composition with an Electronic Computer, DOI 10.2307/842857
   Ishihara S, 2011, MUSIC KANSEI RELATIO
   Jindo T, 1997, INT J IND ERGONOM, V19, P105, DOI 10.1016/S0169-8141(96)00007-8
   Keith Michael., 1991, From Polychords to Polya: Adventures in Musical Combinatorics
   Lerdahl F., 1985, A Generative Theory of Tonal Music
   Livingstone S., 2005, P 2 AUSTR C INT ENT
   LONGUETHIGGINS HC, 1984, MUSIC PERCEPT, V1, P424
   Morris Robert, 1987, Composition with Pitch-Classes: A Theory of Compositional Design
   NAGAMACHI M, 1995, INT J IND ERGONOM, V15, P3, DOI 10.1016/0169-8141(94)00052-5
   Nagamachi M, 2002, APPL ERGON, V33, P289, DOI 10.1016/S0003-6870(02)00019-4
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Sangenya T, 2008, IEEE SYS MAN CYBERN, P1904
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Schubert E, 2003, PERCEPT MOTOR SKILL, V96, P1117, DOI 10.2466/pms.2003.96.3c.1117
   Toussaint G, 2002, TOWNS U
   Toussaint G.T., 2002, BRIDGES MATH CONNECT, P157
   Tung J-S, 1981, CHINESE MUSIC NEWS M
   Weaver HE, 1939, J GEN PSYCHOL, V20, P409, DOI 10.1080/00221309.1939.9710019
   Xenakis I, 1965, GRAVESANER BLATTER, V26, P54
NR 25
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7631
EP 7654
DI 10.1007/s11042-015-2686-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600009
DA 2024-07-18
ER

PT J
AU Chen, X
   Yang, TQ
   Xu, JM
AF Chen, Xin
   Yang, Tianqi
   Xu, Jiaming
TI Multi-gait identification based on multilinear analysis and multi-target
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-gait recognition; Part detector; Track; Inpainting; Multilinear
   analysis
ID RECOGNITION; COMPLETION; IMAGES
AB A new gait pattern is addressed and recognized in this paper. We use a multi-view part detector to detect the body parts of each participant. Multi-gait consisting of more than one participant is tracked using hierarchical association. We use a high-dimension exemplar-based method to realize gait image inpainting and use a tensor's lowest rank to complete a two-value sequence completion. We use multiple linear tensors to describe multi-gait and realize recognition by a segmented accumulated energy map. The experimental results indicate that the methodology achieves high multi-gait recognition accuracy and has good robustness to dress, carried objects and view variance.
C1 [Chen, Xin; Yang, Tianqi; Xu, Jiaming] Jinan Univ, Dept Informat Sci & Technol, Guangzhou 510000, Guangdong, Peoples R China.
C3 Jinan University
RP Chen, X (corresponding author), Jinan Univ, Dept Informat Sci & Technol, Guangzhou 510000, Guangdong, Peoples R China.
EM 843597029@qq.com; tytq@jnu.edu.cn; 596049806@qq.com
CR [Anonymous], P EUR C COMPUT VIS
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], 2007, P IEEE INT C COMP VI
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], 2007, P SIGGRAPH
   [Anonymous], CVPR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], COMP VIS IMAGE UNDER
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE INT C SMART I
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], P CVPR
   [Anonymous], P 2013 INT C COMP EN
   [Anonymous], 2012, ACCV
   [Anonymous], P 11 IEEE INT C COMP
   [Anonymous], INT C ROB AUT ICRA
   [Anonymous], P ICCTD
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062
   Guldogan MB, 2014, DIGIT SIGNAL PROCESS, V27, P1, DOI 10.1016/j.dsp.2014.01.009
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P539, DOI 10.1109/TIP.2005.863057
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hayfron-Acquah JB, 2003, PATTERN RECOGN LETT, V24, P2175, DOI 10.1016/S0167-8655(03)00086-2
   Huang C, 2013, IEEE T PATTERN ANAL, V35, P898, DOI 10.1109/TPAMI.2012.159
   Huang CQ, 2008, PROCEEDINGS OF THE 27TH CHINESE CONTROL CONFERENCE, VOL 4, P788, DOI 10.1109/CHICC.2008.4605855
   Huo FZ, 2014, SIMUL-T SOC MOD SIM, V90, P501, DOI 10.1177/0037549714526294
   Jeong S, 2013, J SUPERCOMPUT, V65, P106, DOI 10.1007/s11227-012-0785-7
   Kirchner A, 2003, PHYSICA A, V324, P689, DOI 10.1016/S0378-4371(03)00076-1
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Li YR, 2013, IEEE T IMAGE PROCESS, V22, P752, DOI 10.1109/TIP.2012.2222896
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Liu YQ, 2013, IEEE T IMAGE PROCESS, V22, P1699, DOI 10.1109/TIP.2012.2218828
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Peyré G, 2010, IEEE T PATTERN ANAL, V32, P733, DOI 10.1109/TPAMI.2009.54
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Smith K, 2005, PROC CVPR IEEE, P962
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang ZY, 2012, PHYSICA A, V391, P3119, DOI 10.1016/j.physa.2011.12.066
   Weng WG, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036102
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Wu B., 2005, P 10 IEEE INT C COMP
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
NR 56
TC 15
Z9 15
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6505
EP 6532
DI 10.1007/s11042-015-2585-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700022
DA 2024-07-18
ER

PT J
AU Park, W
   Na, O
   Chang, H
AF Park, Wonhyung
   Na, Onechul
   Chang, Hangbae
TI An exploratory research on advanced smart media security design for
   sustainable intelligence information system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligence information system; Smart media; Information security;
   Information security ecosystem; Exploratory study; Internet of things
   environment
ID FRAMEWORK
AB The recent issue of cyber security accident and internal information leakage accident is becoming a big obstacle in entering into sustainable intelligence information. To guarantee a sustainable smart media technology and establish an intelligence information system environment, it is necessary to firmly cultivate information security industry with the need for a study on forming multi-dimensional foundation for promoting the use of information security product & service for organizations in intelligence information system environment. Accordingly, an exploratory study was conducted for identifying risk elements caused by intelligence information system environment and forming multi-dimensional smart media information security ecosystem to minimize such risk elements. As a result, a scenario was designed by deducing issues in information security resulting from entering into internet of things environment, while exploring and analyzing future direction by classifying into four areas of law & policy, information security business management, security accident criminal psychology and information security economic feasibility. Based on this study, it is expected that a fundamental & comprehensive solution can be presented as a prerequisite for ensuring sustainable internet of things environment, along with the establishment of response system against various forms of security accidents occurring recently.
C1 [Park, Wonhyung] Far East Univ, Dept Cyber Secur, Chungcheongbuk Do, South Korea.
   [Na, Onechul] Chung Ang Univ, Grad Sch, Dept Convergence Secur, Seoul 156756, South Korea.
   [Chang, Hangbae] Chung Ang Univ, Dept Ind Secur, Coll Business & Econ, 84 Heukseok Ro, Seoul 156756, South Korea.
C3 Chung Ang University; Chung Ang University
RP Chang, H (corresponding author), Chung Ang Univ, Dept Ind Secur, Coll Business & Econ, 84 Heukseok Ro, Seoul 156756, South Korea.
EM whpark@kdu.ac.kr; nan-nastop@hanmail.net; hbchang@cau.ac.kr
FU MSIP (Ministry of Science, ICT & Future Planning), Korea, under the ITRC
   (Information Technology Research Center) support program
   [NIPA-2014-H0301-14-1044]
FX This research was supported by the MSIP (Ministry of Science, ICT &
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2014-H0301-14-1044) supervised by the NIPA
   (National ICT Industry Promotion Agency).
CR Da Veiga A, 2007, INFORM SYST MANAGE, V24, P361, DOI 10.1080/10580530701586136
   Guo KH, 2013, COMPUT SECUR, V32, P242, DOI 10.1016/j.cose.2012.10.003
   Hellriegel D., 1998, Organizational Behavior, V8th
   Kim M, CLUSTER COMPUTING, V16, P725
   Kim Y, 2013, WIRELESS PERS COMMUN, V73, P1591, DOI 10.1007/s11277-013-1268-8
   Kim Y, 2013, PERS UBIQUIT COMPUT, V17, P1459, DOI 10.1007/s00779-012-0581-7
   Moore JF, 2003, HARVARD BUSINESS REV, V73
   Rho S, 2013, J SUPERCOMPUT, V65, P274, DOI 10.1007/s11227-010-0447-6
   Robbins S., 2003, ORG BEHAV GLOBAL SO
   ROCK P., 2007, OXFORD HDB CRIMINOLO
   Sun J, 2011, MULTIMED TOOLS APPL, V53, P75, DOI 10.1007/s11042-010-0491-5
   Whitman M., 2003, PRINCIPLES INFORM SE
NR 12
TC 3
Z9 4
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6059
EP 6070
DI 10.1007/s11042-014-2393-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700001
DA 2024-07-18
ER

PT J
AU Ries, CX
   Richter, F
   Lienhart, R
AF Ries, Christian X.
   Richter, Fabian
   Lienhart, Rainer
TI Towards automatic bounding box annotations from weakly labeled images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic annotation; Weakly labeled data; Statistical feature model;
   Visual features; Image analysis
AB In this work we discuss the problem of automatically determining bounding box annotations for objects in images whereas we only assume weak labeling in the form of global image labels. We therefore are only given a set of positive images all containing at least one instance of a desired object and a negative set of images which represent background. Our goal is then to determine the locations of the object instances within the positive images by bounding boxes. We also describe and analyze a method for automatic bounding box annotation which consists of two major steps. First, we apply a statistical model for determining visual features which are likely to be indicative for the respective object class. Based on these feature models we infer preliminary estimations for bounding boxes. Second, we use a CCCP training algorithm for latent structured SVM in order to improve the initial estimations by using them as initializations for latent variables modeling the optimal bounding box positions. We evaluate our approach on three publicly available datasets.
C1 [Ries, Christian X.; Richter, Fabian; Lienhart, Rainer] Univ Augsburg, Univ Str 6a, D-86650 Augsburg, Germany.
C3 University of Augsburg
RP Ries, CX (corresponding author), Univ Augsburg, Univ Str 6a, D-86650 Augsburg, Germany.
EM chrisries13@web.de
OI Lienhart, Rainer/0000-0003-4007-6889
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2005, Proc._Neural_Information_Processing_System
   Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2
   Chen C.-Y., 2013, P IEEE C COMP VIS PA
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Maron O, P INT C MACH LEARN 1
   Nilsback ME, P IEEE C COMP VIS PA
   Philbin J., 2008, P CVPR, P1
   Ries C. X., 2013, ICMR 2013, P207
   Ries CX, 2014, THESIS
   Ries CX, 2012, P ACM INT C MULT RET, P44
   Romberg S., 2011, P 1 ACM INT C MULT R, P1
   Romberg S, 2013, INT J MULTIMED INF R, V2, P243, DOI 10.1007/s13735-013-0040-x
   Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tang K., 2013, P IEEE C COMP VIS PA
   Tsochantaridis I., 2004, ICML, P104
   Yu T., 2009, P 26 ANN INT C MACH, P1169, DOI DOI 10.1145/1553374.1553523
   Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958
   Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096
NR 28
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6091
EP 6118
DI 10.1007/s11042-014-2434-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Uddin, MZ
AF Uddin, Md Zia
TI A depth video-based facial expression recognition system utilizing
   generalized local directional deviation-based binary pattern feature
   discriminant analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth image; (LDBP)-B-2; GDA; HMMs
ID INDEPENDENT COMPONENT ANALYSIS; HIDDEN MARKOV-MODELS; FACE-RECOGNITION;
   GESTURE
AB Facial expression recognition from video data is considered to be a very challenging task in the research areas of computer vision, image processing, and pattern recognition. A novel approach is proposed in this paper to recognize facial expressions using depth video data. After extracting Local Directional Deviation-based Binary Pattern ((LDBP)-B-2) features from depth images, the features are then extended by Generalized Discriminant Analysis (GDA) to improve them. At last, the time-sequential (LDBP)-B-2-GDA features are applied with Hidden Markov Models (HMMs) for expression training and recognition. The proposed approach outperforms the conventional facial expression recognition approaches.
C1 [Uddin, Md Zia] Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Uddin, MZ (corresponding author), Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
EM ziauddin@skku.edu
RI Uddin, Zia/AAC-1309-2020
OI Uddin, Zia/0000-0002-5215-1834
FU Sungkyunkwan University
FX This paper was supported by Faculty Research Fund, Sungkyunkwan
   University, 2013.
CR Aleksic PS, 2006, IEEE T INF FOREN SEC, V1, P3, DOI 10.1109/TIFS.2005.863510
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2012, UBICOMP 12 P 2012 AC
   [Anonymous], 3 D GESTURE BASED SC
   Bartlett Marian Stewart, 1999, P 6 JOINT S NEUR COM, P8
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Breitenstein MD, 2009, LECT NOTES COMPUT SC, V5575, P219, DOI 10.1007/978-3-642-02230-2_23
   Breitenstein MD, 2008, PROC CVPR IEEE, P3613
   Breuer P, 2007, LECT NOTES COMPUT SC, V4418, P247, DOI 10.1007/978-3-540-71457-6_23
   Buciu I, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P855
   Cai Q., 2010, P EUR C COMP VIS, P242
   Calder AJ, 2000, J EXP PSYCHOL HUMAN, V26, P527, DOI 10.1037/0096-1523.26.2.527
   Calder AJ, 2001, VISION RES, V41, P1179, DOI 10.1016/S0042-6989(01)00002-5
   Caschera MC, 2013, IEEE T SYST MAN CY-S, V43, P911, DOI 10.1109/TSMCA.2012.2210407
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Chen F, 2008, IEICE T INF SYST, VE91D, P341, DOI 10.1093/ietisy/e91-d.2.341
   Chuang CF, 2006, PATTERN RECOGN, V39, P1795, DOI 10.1016/j.patcog.2006.03.017
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Dreuw P., 2010, P INT C LANG RES EV, P476
   Dubuisson S, 2002, SIGNAL PROCESS-IMAGE, V17, P657, DOI 10.1016/S0923-5965(02)00076-0
   Ekman P., 1978, Facial action coding system
   El-Yacoubi A, 1999, INT SER COMPUTAT INT, P191
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Gales M., 2013, FDN TRENDS SIGNAL PR, V1, P195
   Hamer H, 2010, PROC CVPR IEEE, P671, DOI 10.1109/CVPR.2010.5540150
   Hamer H, 2009, IEEE I CONF COMP VIS, P1475, DOI 10.1109/ICCV.2009.5459282
   He LG, 2009, IEEE SYS MAN CYBERN, P1568, DOI 10.1109/ICSMC.2009.5346339
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Iddan GJ, 2001, P SOC PHOTO-OPT INS, V4298, P48, DOI 10.1117/12.424913
   Jabid T., 2010, 2010 7th IEEE International Conference of Advanced Video and Signal Based Surveillance, P482
   Jalal A, 2012, INDOOR BUILT ENVIRON, V21, P184, DOI 10.1177/1420326X11423163
   Karklin Y, 2003, NETWORK-COMP NEURAL, V14, P483, DOI 10.1088/0954-898X/14/3/306
   Kim DS, 2006, IEEE T CONSUM ELECTR, V52, P726, DOI 10.1109/TCE.2006.1706463
   Kollorz Eva, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P334, DOI 10.1504/IJISTA.2008.021296
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li Z., 2009, P AUSTR C ROB AUT
   Liu CJ, 2004, IEEE T SYST MAN CY B, V34, P1117, DOI 10.1109/TSMCB.2003.821449
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu X, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P529
   Lu XG, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P585
   Luong DD, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2013), P905, DOI 10.1109/ICCAS.2013.6704043
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Marnik J, 2007, ADV INTEL SOFT COMPU, V45, P454
   McCallum A., 2000, P 17 INT C MACH LEAR, V17, P591
   Meulders M, 2005, J ROY STAT SOC C-APP, V54, P781, DOI 10.1111/j.1467-9876.2005.00515.x
   Mian A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P735
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Morency LP, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P45
   Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629
   Oikonomidis I, 2012, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2012.6247885
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Pei T., 2009, P IEEE INT C AC SPEE, P4757
   Pengfei Yu, 2010, 2010 International Conference on Information, Networking and Automation (ICINA 2010), P148, DOI 10.1109/ICINA.2010.5636417
   Penne J., 2008, P INT C AUT FAC GEST, P1
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rahman MT, 2008, IEEE T CONSUM ELECTR, V54, P1506, DOI 10.1109/TCE.2008.4711194
   Schmidt M, 2010, LECT NOTES ARTIF INT, V5998, P149, DOI 10.1007/978-3-642-12159-3_14
   Seemann E, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P626, DOI 10.1109/AFGR.2004.1301603
   Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sun Y, 2008, INT C PATT RECOG, P104
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Takimoto H, 2010, 2010 IEEE RO-MAN, P292, DOI 10.1109/ROMAN.2010.5598646
   Uddin MZ, 2015, MULTIMED TOOLS APPL, V74, P3675, DOI 10.1007/s11042-013-1793-1
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   Ulrich Neumann ZhenyaoMoand., 2006, IEEE Conference on Computer Vision and Pattern Recognition, P1499, DOI DOI 10.1109/CVPR.2006.237
   Van den Bergh M., 2011, 2011 IEEE WORKSHOP A, P66, DOI DOI 10.1109/WACV.2011.5711485
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang Y., 2007, P IEEE INT C COMPUTE, P1, DOI [10.1109/CVPR.2007.383505, DOI 10.1109/CVPR.2007.383505, DOI 10.1016/J.EJ0R.2007.01.050]
   Weise T., 2007, IEEE CVPR, P1, DOI DOI 10.1109/CVPR.2007.383291
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Wilson AD, 2001, INT J PATTERN RECOGN, V15, P123, DOI 10.1142/S0218001401000812
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 83
TC 7
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6871
EP 6886
DI 10.1007/s11042-015-2614-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400009
DA 2024-07-18
ER

PT J
AU Chan, KM
   Lee, JYB
AF Chan, K. M.
   Lee, Jack Y. B.
TI Improving adaptive HTTP streaming performance with predictive
   transmission and cross-layer client buffer estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile; Video; Adaptation; Streaming
ID VIDEO; INTERNET; QUALITY
AB Streaming video over HTTP/TCP is rapidly becoming the industry standard for mobile video services. To compensate for rapid bandwidth fluctuations in mobile networks the industry is progressively migrating towards adaptive video streaming where multiple bitrate versions of a video are dynamically selected at runtime to adapt to the changing network condition. Surprisingly, two of the leading adaptive streaming systems in use today can underperform even constant-rate streaming. Further analysis revealed two bottlenecks, namely the rate control algorithm and the segmented HTTP delivery protocol. To tackle these bottlenecks this work: (a) proposes a new quality-driven rate controller to balance video quality against streaming performance; (b) proposes a novel predictive transmission technique to improve bandwidth utilization; and (c) presents a practical method to enable streaming applications to exploit transport-layer information for client buffer occupancy estimation. Trace-driven emulation experiments showed that the proposed methods outperform Microsoft's Smooth Streaming by 300 %, Apple's HLS by 167 %, and a recently proposed adaptive streaming algorithm by 60 %. This was further verified by experimental results obtained from production 3G/HSPA networks. The proposed methods can be implemented either in the sender/proxy-based or at the client, and thus can be readily deployed in today's mobile networks.
C1 [Chan, K. M.; Lee, Jack Y. B.] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Lee, JYB (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.
EM ckm011@ie.cuhk.edu.hk; yblee@ie.cuhk.edu.hk
RI Lee, Jack/P-7331-2019; Lee, Yiu Bun/G-3743-2011
OI Lee, Jack/0000-0002-4584-929X; Lee, Yiu Bun/0000-0002-3583-6428
CR Ahmad S, 2010, IEEE T CIRC SYST VID, V20, P275, DOI 10.1109/TCSVT.2009.2031545
   [Anonymous], 2012, P 8 INT C EM NETW EX
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], 2011, P ACM C MULT SYST, DOI DOI 10.1145/1943552.1943575
   [Anonymous], 2007, AKAMAI JUPITER RES
   Casas P, 2013, WIR COMM NETW C WCNC
   Chan SCF, 2011, IEEE 7 INT C WIR MOB
   El Essaili A, 2013, IEEE ICC
   Evensen K, 2011, P 21 INT WORKSH NETW
   Evensen K, 2011, P 2 ANN ACM C MULT S
   Evensen K, 2011, P 9 INT C MOB SYST A
   Guo L, 2006, P 6 ACM SIGCOMM C IN
   Laghari KUR, 2012, IEEE COMMUN MAG, V50, P58, DOI 10.1109/MCOM.2012.6178834
   Lam LS, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P346
   Liu C, 2010, IEEE INT C COMM ICC
   Luo HL, 2008, MULTIMED TOOLS APPL, V40, P111, DOI 10.1007/s11042-007-0187-7
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Prokkola J., 2009, IEEE INT C COMM ICC
   Pu W, 2012, P PACK VID WORKSH MU
   Raghuveer A, 2007, IEEE T CIRC SYST VID, V17, P1028, DOI 10.1109/TCSVT.2007.897462
   Riiser H, 2012, P 4 WORKSH MOB VID M
   Tunali ET, 2005, MULTIMED TOOLS APPL, V27, P431, DOI 10.1007/s11042-005-4090-9
   Wicker S. B., 1995, Error Control Systems for Digital Communication and Storage, Englewood Cliffs, V1st
   Yoshida H, 2010, P MATH THEO IN PRESS, P1
NR 24
TC 4
Z9 5
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5917
EP 5937
DI 10.1007/s11042-015-2556-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600026
DA 2024-07-18
ER

PT J
AU Hussain, M
   Du, QH
   Sun, L
   Ren, PY
AF Hussain, Mukhtar
   Du, Qinghe
   Sun, Li
   Ren, Pinyi
TI Security enhancement for video transmission via noise aggregation in
   immersive systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive systems; Noise aggregation; Video transmission; Physical layer
   security
AB The interest in the field of immersive audio/visual systems exists for many years from both of the commercialization point of view and the research perspective. Technological advancements in the field of cameras, video display along with the processing hardware lead the way to a new generation of immersive systems. On one hand, advancement in video compression schemes like MPEG and H.264/AVC, and transmission technologies like and 3G and 4G LTE enhanced the feeling of virtual presence. However, on the other hand the secure transmission of immersive audio/visual contents over wireless networks is a challenge, as it suffers from the potential malicious attacks. One type of typical malicious attack is passive eavesdropping. The goal of this paper is to propose a solution to enhance the secure wireless transmissions of Video in Immersive Systems via simple yet effective physical-layer approach. To reduce the chance that that the passive eavesdropper extracts information, we present a physical-layer security method, termed noise aggregation, for the secure video transmission to legitimate receiver. Theoretical analyses and simulation results demonstrate that our method is able to effectively limit the amount of information eavesdropped by the unauthorized user at bit level, and thus significantly enhancing security for video distribution.
C1 [Hussain, Mukhtar; Du, Qinghe; Sun, Li; Ren, Pinyi] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Dept Informat & Commun Engn, 28 West Xianning Rd, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Du, QH (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Dept Informat & Commun Engn, 28 West Xianning Rd, Xian 710049, Shaanxi, Peoples R China.
EM mukhtar.ciit@gmail.com; duqinghe@mail.xjtu.edu.cn
RI Du, Qing/HKN-6976-2023; Hussain, Mukhtar/GOH-2883-2022; Du,
   Qinghe/D-5305-2015
OI Hussain, Mukhtar/0000-0001-7987-7750; 
FU National Natural Science Foundation of China [61431011]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20110201120014]; National Mobile Communications Research Laboratory
   [2012D04]; Fundamental Research Funds for the Central Universities
FX The research work reported in this paper is supported by the National
   Natural Science Foundation of China under the grant No. 61431011, the
   Specialized Research Fund for the Doctoral Program of Higher Education
   under the grant no. 20110201120014, Open Research Fund of National
   Mobile Communications Research Laboratory under the grant no. 2012D04
   and the Fundamental Research Funds for the Central Universities
CR Baldi M., 2011, IEEE INT C COMM WORK, P1
   Bar-Shalom Y, 2001, ESTIMATION APPL TRAC
   Barros J, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P356, DOI 10.1109/ISIT.2006.261613
   Bloch M, 2008, IEEE T INFORM THEORY, V54, P2515, DOI 10.1109/TIT.2008.921908
   Boho A, 2013, IEEE SIGNAL PROC MAG, V30, P97, DOI 10.1109/MSP.2012.2230220
   Harrison W. K., 2010, P IEEE INF THEOR WOR, P1
   Harrison WK, 2014, IEEE CONF COMM NETW, P115, DOI 10.1109/CNS.2014.6997475
   MAURER UM, 1993, IEEE T INFORM THEORY, V39, P733, DOI 10.1109/18.256484
   Mukherjee A, 2014, IEEE COMMUN SURV TUT, V16, P1550, DOI 10.1109/SURV.2014.012314.00178
   Naef M, 2005, COMPUT GRAPH-UK, V29, P3, DOI 10.1016/j.cag.2004.11.003
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shiu YS, 2011, IEEE WIREL COMMUN, V18, P66, DOI 10.1109/MWC.2011.5751298
   Vernam GS, 1926, T AM I ELECT ENG, V45, P285
   Voloshynovskiy S., 2008, Proceedings of the NATO Advanced Study Institute on Network Security and Intrusion Detection, P143
   Wang YJ, 2013, IEEE T NETW SERV MAN, V10, P245, DOI 10.1109/TNSM.2013.051313.120343
   WYNER AD, 1975, AT&T TECH J, V54, P1355, DOI 10.1002/j.1538-7305.1975.tb02040.x
   Yang Z, 2009, ACM T MULTIMEDIA COM
   Zhou L, 2014, IEEE COMMUN MAG, V52, P66, DOI 10.1109/MCOM.2014.6766087
NR 18
TC 28
Z9 29
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5345
EP 5357
DI 10.1007/s11042-015-2936-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700029
DA 2024-07-18
ER

PT J
AU Kim, KH
   Jung, DY
   Lee, D
   Lee, HJ
   Park, SY
   Koo, MW
   Kim, JH
   Park, JS
   Jeon, HB
   Lee, YK
AF Kim, Kwang-Ho
   Jung, Dae-Young
   Lee, Donghyun
   Lee, Hyuk-Jun
   Park, Sung-Yong
   Koo, Myoung-Wan
   Kim, Ji-Hwan
   Park, Jeong-sik
   Jeon, Hyung-Bae
   Lee, Yun-Keun
TI Implementation of a large-scale language model adaptation in a cloud
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Language model adaptation; Large-scale; MapReduce; Cloud
AB This paper presents a system of large-scale language model adaptation for daily generated big-size text corpus using MapReduce in a cloud environment. Our large-scale trigram language model, consisting of 800 million trigram counts, was successfully implemented by a new approach using a representative cloud service (Amazon EC2), and a representative distributed processing framework (Hadoop). The ultimate goal of our research is to find the optimal number of Amazon EC2 instances in the LM adaptation under the time constraint that the daily-generated Twitter texts should be processed within 1 day. Trigram count extraction and model update for language model adaptation were performed for 200 million daily-generated Twitter texts. For trigram count extraction, we found that fewer than 3 h are required to process daily-generated Twitter texts when the number of instances is six. For model update, it was shown that fewer than 20 h are required to perform the model update when the number of instances is 10. Therefore, language model adaptation for daily generated 200 million Twitter texts can be successfully adapted within 24 h using at least 10 instances in Amazon EC2.
C1 [Kim, Kwang-Ho; Jung, Dae-Young; Lee, Donghyun; Lee, Hyuk-Jun; Park, Sung-Yong; Koo, Myoung-Wan; Kim, Ji-Hwan] Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Park, Jeong-sik] Mokwon Univ, Dept Intelligent Robot Engn, Daejeon, South Korea.
   [Jeon, Hyung-Bae; Lee, Yun-Keun] Elect & Telecommun Res Inst, Daejeon, South Korea.
C3 Sogang University; Mokwon University; Electronics & Telecommunications
   Research Institute - Korea (ETRI)
RP Kim, JH (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM kimkwangho@sogang.ac.kr; dyjung@sogang.ac.kr; redizard@sogang.ac.kr;
   hyukjunl@sogang.ac.kr; parksy@sogang.ac.kr; mwkoo@sogang.ac.kr;
   kimjihwan@sogang.ac.kr; parkjs@mokwon.ac.kr; hbjeon@etri.re.kr;
   yklee@etri.re.kr
RI PARK, JEONGSIK/GVS-1712-2022; Jeon, Hyung-Bae/AAA-9387-2021
OI Jeon, Hyung-Bae/0000-0001-8650-5154
FU Industrial Strategic Technology Development Program - Ministry of Trade,
   Industry Energy, Korea [10035252]
FX This work was supported by the Industrial Strategic Technology
   Development Program 10035252, Development of Dialog-based Spontaneous
   Speech Interface Technology on Mobile Platform funded by the Ministry of
   Trade, Industry & Energy, Korea.
CR [Anonymous], 1997, 5th European Conference on Speech Communication and Technology
   [Anonymous], 2010, Amazon Elastic Compute Cloud
   [Anonymous], 200 MILLION TWEETS P
   Bacchiani M, 2006, COMPUT SPEECH LANG, V20, P41, DOI 10.1016/j.csl.2004.12.001
   Bacchiani M., 2004, P HUM LANG TECHN C H, P21
   Bakis Raimo., 1997, Proceedings of the Speech Recognition Workshop, P67
   Bellegarda J. R, 2001, P ISCA WORKSH AD MET, P165
   Bellegarda JR, 2004, SPEECH COMMUN, V42, P93, DOI 10.1016/j.specom.2003.08.002
   Brugnara F, 1995, P 4 EUR C SPEECH COM, P1797
   Burrows M, 2006, USENIX ASSOCIATION 7TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P335
   Chang F, 2006, USENIX ASSOCIATION 7TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P205
   Chen LZ, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P220
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Della Pietra S., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P633, DOI 10.1109/ICASSP.1992.225829
   Federico M, 2002, INT CONF ACOUST SPEE, P773
   Federico M., 1999, Proceedings of Eurospeech, V99, P1583
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   George L, 2011, HBASE DEFINITIVE GUI, P68
   Masataki H, 1997, INT CONF ACOUST SPEE, P783, DOI 10.1109/ICASSP.1997.596042
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   Shvachko K., 2010, 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), P1
   White T, 2011, HADOOP DEFINITIVE GU, P27
   WOLBERG J, 2005, DATA ANAL USING METH, P3
NR 23
TC 0
Z9 0
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5029
EP 5045
DI 10.1007/s11042-013-1787-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700012
DA 2024-07-18
ER

PT J
AU Bartolini, I
   Moscato, V
   Pensa, RG
   Penta, A
   Picariello, A
   Sansone, C
   Sapino, ML
AF Bartolini, Ilaria
   Moscato, Vincenzo
   Pensa, Ruggero G.
   Penta, Antonio
   Picariello, Antonio
   Sansone, Carlo
   Sapino, Maria Luisa
TI Recommending multimedia visiting paths in cultural heritage applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cultural heritage; Multimedia databases; Recommender systems; Context
   awareness
AB The valorization and promotion of worldwide Cultural Heritage by the adoption of Information and Communication Technologies represent nowadays some of the most important research issues with a large variety of potential applications. This challenge is particularly perceived in the Italian scenario, where the artistic patrimony is one of the most diverse and rich of the world, able to attract millions of visitors every year to monuments, archaeological sites and museums. In this paper, we present a general recommendation framework able to uniformly manage heterogeneous multimedia data coming from several web repositories and to provide context-aware recommendation techniques supporting intelligent multimedia services for the users-i.e. dynamic visiting paths for a given environment. Specific applications of our system within the cultural heritage domain are proposed by means of real case studies in the mobile environment related both to an outdoor and indoor scenario, together with some results on user's satisfaction and system accuracy.
C1 [Bartolini, Ilaria] Univ Bologna, Dept Comp Sci & Engn, Viale Risorgimento 2, I-40136 Bologna, Italy.
   [Moscato, Vincenzo; Picariello, Antonio; Sansone, Carlo] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Via Clusio 21, I-80125 Naples, Italy.
   [Pensa, Ruggero G.; Penta, Antonio; Sapino, Maria Luisa] Univ Turin, Dept Comp Sci, Corso Svizzera 185, I-10149 Turin, Italy.
C3 University of Bologna; University of Naples Federico II; University of
   Turin
RP Bartolini, I (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Viale Risorgimento 2, I-40136 Bologna, Italy.
EM i.bartolini@unibo.it; vmoscato@unina.it; pensa@di.unito.it;
   penta@di.unito.it; antonio.picariello@unina.it; carlo.sansone@unina.it;
   mlsapino@di.unito.it
RI Sansone, Carlo/AGZ-8858-2022; Pensa, Ruggero G./B-5994-2011; BARTOLINI,
   ILARIA/AAA-9455-2019; Moscato, Vincenzo/H-2526-2012; Picariello,
   Antonio/L-6820-2015; Sapino, Maria Luisa/C-6257-2011
OI Pensa, Ruggero G./0000-0001-5145-3438; BARTOLINI,
   ILARIA/0000-0002-8074-1129; 
FU Regione Campania - Italy
FX The realization of the proposed prototype was supported by
   DATABENC,<SUP>6</SUP> a high technology district for Cultural Heritage
   management recently funded by Regione Campania - Italy.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2010, P 4 ACM C REC SYST R, DOI DOI 10.1145/1864708.1864722
   Albanese M, 2013, ACM T INTERNET TECHN, V13, DOI 10.1145/2532640
   Albanese M, 2011, IEEE INT C SEMANT CO, P403, DOI 10.1109/ICSC.2011.47
   Albanese M, 2010, MULTIMED TOOLS APPL, V50, P563, DOI 10.1007/s11042-010-0480-8
   Anand SS, 2007, ACM T INTERNET TECHN, V7, DOI 10.1145/1278366.1278367
   [Anonymous], INT C MUS WEB
   [Anonymous], J COMPUT CULT HERIT
   [Anonymous], 2010, P 4 ACM C REC SYST
   [Anonymous], 15 BRAZ S MULT WEB
   [Anonymous], 2003, VAST
   [Anonymous], INT C EM UB SYST PER
   [Anonymous], 2013, Multimedia Services in Intelligent Environments, DOI DOI 10.1007/978-3-319-00375-7_7
   Ardissono L, 2012, USER MODEL USER-ADAP, V22, P73, DOI 10.1007/s11257-011-9104-x
   Bartolini I, 2008, LECT NOTES COMPUT SC, V4918, P32, DOI 10.1007/978-3-540-79860-6_3
   Bartolini I, 2013, LECT NOTES COMPUT SC, V8158, P257, DOI 10.1007/978-3-642-41190-8_28
   Bartolini I, 2013, MULTIMED TOOLS APPL, V63, P357, DOI 10.1007/s11042-011-0948-1
   Bartolini I, 2010, KNOWL INF SYST, V25, P389, DOI 10.1007/s10115-009-0257-4
   Bartolini I, 2011, IEEE T KNOWL DATA EN, V23, P190, DOI 10.1109/TKDE.2010.86
   Basilico J., 2004, P 21 INT C MACH LEAR, P9, DOI DOI 10.1145/1015330.1015394
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhatt CA, 2011, MULTIMED TOOLS APPL, V51, P35, DOI 10.1007/s11042-010-0645-5
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Costantini S, 2008, IEEE INTELL SYST, V23, P34, DOI 10.1109/MIS.2008.24
   Dourish P, 2004, PERS UBIQUIT COMPUT, V8, P19, DOI 10.1007/s00779-003-0253-8
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Geyer-Schulz A., 2002, Proceedings of the WebKDD Workshop: Web Mining for Usage Patterns User Profiles, P100
   GOODMAN LA, 1972, J AM STAT ASSOC, V67, P415, DOI 10.2307/2284396
   HART S G, 1988, P139
   Hijikata Y., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1050, DOI 10.1145/1141277.1141526
   Ienco D, 2013, DATA MIN KNOWL DISC, V26, P217, DOI 10.1007/s10618-012-0248-z
   Ilyas IF, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1391729.1391730
   Juszczyszyn K, 2010, STUD COMPUT INTELL, V289, P275
   Karaman S, 2013, LECT NOTES COMPUT SC, V8158, P247, DOI 10.1007/978-3-642-41190-8_27
   Karatzoglou Alexandros, 2010, Multiverse recommendation: N-dimensional tensor factorization for context-aware collaborative filtering, P79, DOI DOI 10.1145/1864708.1864727
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Kim HK, 2009, IEEE T SERV COMPUT, V2, P140, DOI 10.1109/TSC.2009.7
   Kim JK, 2008, EXPERT SYST APPL, V34, P300, DOI 10.1016/j.eswa.2006.09.034
   Kuflik Tsvi., 2011, Journal on Computing and Cultural Heritage, V3, P11, DOI DOI 10.1145/1921614.1921618
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Maidel V, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P91
   Musial K, 2008, LECT NOTES ARTIF INT, V5288, P364, DOI 10.1007/978-3-540-87781-3_40
   Pazzani M.J., 2007, Content-based recommendation systems, P325, DOI DOI 10.1007/978-3-540-72079-9_10
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Salton G., 1989, Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Su JH, 2010, IEEE INTELL SYST, V25, P16, DOI 10.1109/MIS.2010.23
   Tseng Vincent S., 2008, 2008 IEEE International Conference on Sensor Networks, Ubiquitous, and Trustworthy Computing (SUTC '08), P492, DOI 10.1109/SUTC.2008.82
   van Aart C, 2010, LECT NOTES ARTIF INT, V6317, P257, DOI 10.1007/978-3-642-16438-5_18
   Vlahakis Vassilios., 2001, VIRTUAL REALITY ARCH, V9, P584993
   Wang YW, 2009, INTERDISCIPL SCI REV, V34, P139, DOI 10.1179/174327909X441072
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
NR 53
TC 42
Z9 42
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3813
EP 3842
DI 10.1007/s11042-014-2062-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200013
DA 2024-07-18
ER

PT J
AU Places, AS
   Fariña, A
   Luaces, MR
   Pedreira, O
   Seco, D
AF Places, Angeles S.
   Farina, Antonio
   Luaces, Miguel R.
   Pedreira, Oscar
   Seco, Diego
TI A workflow management system to feed digital libraries: proposal and
   case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital libraries; Text retrieval; Workflow management system
ID VIRTUAL LIBRARY; BOOKS
AB Building a digital library of antique documents involves not only technical implementation issues, but also aspects related to the digitization of large collections of documents. Antique documents are usually delicate and need to be handled with care. Also, a poor state of preservation and the use of unrecognizable font types make automatic text recognition more difficult, hence requiring a further human revision to perform text corrections. This makes the participation of experts in the digitization process mandatory and, therefore, costly. In this paper, we present a framework for managing the workflow of the digitization of large collections of antique documents. We describe the digitization process, and a tool supporting all of its phases and tasks. We also present a case study in which we describe how the workflow management system was applied to the digitization of more than 10,000 documents from journals of the 19th century. In addition, we describe the resulting digital library, focusing on the most important technological issues.
C1 [Places, Angeles S.; Farina, Antonio; Luaces, Miguel R.; Pedreira, Oscar; Seco, Diego] Univ A Coruna, Fac Informat, Database Lab, Campus Elvina S-N, La Coruna 15071, Spain.
   [Seco, Diego] Univ Concepcion, Dept Comp Sci, Concepcion, Chile.
C3 Universidade da Coruna; Universidad de Concepcion
RP Pedreira, O (corresponding author), Univ A Coruna, Fac Informat, Database Lab, Campus Elvina S-N, La Coruna 15071, Spain.
EM asplaces@udc.es; fari@udc.es; luaces@udc.es; opedreira@udc.es;
   dseco@udc.es
RI Pedreira, Oscar/ABA-5296-2020; Fariña, Antonio/C-6243-2017; Places,
   Ángeles Saavedra/E-8860-2015; Seco, Diego/AAA-9061-2020; Luaces, Miguel
   R./HTP-5849-2023
OI Pedreira, Oscar/0000-0001-6176-4475; Fariña,
   Antonio/0000-0001-8263-3298; Luaces, Miguel R./0000-0003-0549-2000;
   Saavedra Places, Angeles/0000-0001-8539-304X
FU Xunta de Galicia (Cofinanciado con Fondos FEDER) [GRC2013/053];
   Ministerio de Ciencia e Innovacion (PGE e Fondos FEDER)
   [TIN2009-14560-C03-02, TIN2010-21246-C02-01]; Subvencionado polo CDTI,
   Ministerio de Economia e Competitividade e pola Axencia Galega de
   Innovacion [CDTI EXP 00064563 / ITC-20133062]
FX This work has been partially funded by "Xunta de Galicia (Cofinanciado
   con Fondos FEDER)", ref. GRC2013/053, "Ministerio de Ciencia e
   Innovacion (PGE e Fondos FEDER)" ref. TIN2009-14560-C03-02 and ref.
   TIN2010-21246-C02-01, and CDTI EXP 00064563 / ITC-20133062
   ("Subvencionado polo CDTI, Ministerio de Economia e Competitividade e
   pola Axencia Galega de Innovacion").
CR Aalst W.v. d., 2002, WORKFLOW MANAGEMENT, V1st
   [Anonymous], REF MOD OP ARCH INF
   Arms CarolineR., 2000, RLG DigiNews, V4
   Bainbridge D, 2003, P JCDL 03 JOINT C DI
   Baird HS, 2003, P 7 INT C DOC AN REC
   Banerjee J, 2009, PROC CVPR IEEE, P517, DOI 10.1109/CVPRW.2009.5206601
   BORGELT C, 2002, P 15 C COMP STAT, P1
   Brisaboa NR, 2007, INFORM RETRIEVAL, V10, P1, DOI 10.1007/s10791-006-9001-9
   Buchanan G, 2005, P JCDL 05 JOINT C DI
   Chang NC, 2006, LECT NOTES COMPUT SC, V4312, P531
   Cramer T., 2010, D LIB MAGAZINE, V16
   Delos, 2008, REF MOD DIG LIB MAN
   Duguid Paul., 1997, Report of the Santa Fe Planning Workshop on Distributed Knowledge Work Environments"
   FISCHER L, 2003, WORKFLOW HDB 2003 WO
   Hollingsworth D, 1995, WFMC REFERENCE MODEL
   Kolak O, 2003, P HLT NAACL MAY 27 J
   Larson R, 1999, P ASIS 99 OCT 31 NOV
   *LIB C, 2007, MET ENC TRANSM STAND
   McCray A. T., 2001, Communications of the ACM, V44, P49, DOI 10.1145/374308.374339
   MOURA E, 2000, ACM T INFORM SYST, V18, P113, DOI DOI 10.1145/348751.348754
   Mourao H, 2003, LECT NOTES COMPUT SC, V2806, P159
   Navarro G., 2002, FLEXIBLE PATTERN MAT
   Paramá JR, 2006, SOFTWARE PRACT EXPER, V36, P473, DOI 10.1002/spe.705
   Places AS, 2007, ONLINE INFORM REV, V31, P333, DOI 10.1108/14684520710764104
   Ross S., 2014, NEW REV INFORM NETWO, V17, P43
   Ross S, 2005, INT J DIGIT LIBRARIE, V5, P317, DOI 10.1007/s00799-004-0099-3
   Sankar KP, 2006, LECT NOTES COMPUT SC, V3872, P425
   VANDESOMPEL H, 2000, DLIB MAGAZINE, V6
   Witten I.H., 2003, BUILD DIGITAL LIB
NR 29
TC 2
Z9 2
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3843
EP 3877
DI 10.1007/s11042-014-2155-3
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200014
DA 2024-07-18
ER

PT J
AU Silovsky, J
   Nouza, J
   Kucharova, M
AF Silovsky, Jan
   Nouza, Jan
   Kucharova, Michaela
TI Search for speaker identity in historical oral archives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; Historical Archives; Aging effect; Czech Radio
ID RECOGNITION
AB We present our ongoing research focused on speaker recognition in historical oral archives. This research is part of our long-term effort aimed at enabling versatile access to the archive of the Czech Radio (CRo). Based on a manually annotated partition of the archive, we compiled a database covering a time span of more than 30 years to carry out our experimental study. Hence we were able to investigate the impact of various aspects that make it challenging to process historical data. We show the shift of scores for target (genuine) speaker trials introduced by the aging effect, the value of the signal-to-noise ratio or by the variable amount of the enrollment and test data. Scores for speaker detection trials were assessed by a system based on the i-vector paradigm and probabilistic linear discriminative analysis. We also assessed the performance of this system using an evaluation database containing contemporary recordings collected over a time span of approximately 4 years. Although using state-of-the-art techniques, capable of dealing with nuisance inter-session variability, we demonstrate remarkable degradation in the performance of the system in the evaluation containing historical data compared to the one containing contemporary data only. Specifically, the Equal Error Rate (EER) of the system rose to 8.27 % from 1.93 %. The revealed difference thus exemplifies that compensation techniques need to be employed to cope with additional variability introduced in the historical data by various sources.
C1 [Silovsky, Jan; Nouza, Jan; Kucharova, Michaela] Tech Univ Liberec, Studentska 1402-2, Liberec 46117, Czech Republic.
C3 Technical University Liberec
RP Silovsky, J (corresponding author), Tech Univ Liberec, Studentska 1402-2, Liberec 46117, Czech Republic.
EM jan.silovsky@tul.cz
RI Nouza, Jan/E-9914-2011
OI Nouza, Jan/0000-0003-3960-3194
FU Czech Ministry of Culture (in program NAKI) [DF11P01OVV013]
FX This research work was supported by the Czech Ministry of Culture
   (project no. DF11P01OVV013 in program NAKI).
CR [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], INTERSPEECH 12
   [Anonymous], EM FOR JFA
   Bohác M, 2013, LECT NOTES COMPUT SC, V8082, P536, DOI 10.1007/978-3-642-40585-3_67
   Brummer N., 2010, P NIST 2010 SPEAK EV, P1
   Chaloupka J, 2013, LECT NOTES COMPUT SC, V8082, P201, DOI 10.1007/978-3-642-40585-3_26
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Doddington GR, 2000, SPEECH COMMUN, V31, P225, DOI 10.1016/S0167-6393(99)00080-1
   Ferrer L, 2008, INT CONF ACOUST SPEE, P4853, DOI 10.1109/ICASSP.2008.4518744
   Garcia-Romero D., 2011, INTERSPEECH
   Kanagasundaram A, 2013, INTERSPEECH, P3641
   Kelly F., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P478, DOI 10.1109/ICB.2012.6199796
   Kelly F, 2011, LECT NOTES COMPUT SC, V6583, P113, DOI 10.1007/978-3-642-19530-3_11
   Kenny P, 2005, IEEE T SPEECH AUDI P, V13, P345, DOI 10.1109/TSA.2004.840940
   Kenny P, 2013, INT CONF ACOUST SPEE, P7649, DOI 10.1109/ICASSP.2013.6639151
   Kim C, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2598
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Matveev Yuri, 2013, Speech and Computer. 15th International Conference, SPECOM 2013, P345, DOI 10.1007/978-3-319-01931-4_46
   Nouza J, 2012, COMM COM INF SC, V247, P27
   Prince SJD, 2007, P ICCV 2007, P1
   Rajan P., 2013, Proc. of INTERSPEECH, P3694
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Silovsky J, 2012, IEEE INT WORKSH MULT, P118, DOI 10.1109/MMSP.2012.6343426
   Silovsky J, 2009, RADIOENGINEERING, V18, P307
   van Leeuwen David A., 2007, Speaker Classification I. Fundamentals, Features, and Methods. (Lecture Notes in Artificial Intelligence vol. 4343), P330, DOI 10.1007/978-3-540-74200-5_19
NR 25
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3767
EP 3786
DI 10.1007/s11042-014-2067-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200011
DA 2024-07-18
ER

PT J
AU Xue, F
   Yong, CX
   Xu, S
   Dong, H
   Luo, YT
   Jia, W
AF Xue, Feng
   Yong, Chengxi
   Xu, Shan
   Dong, Hao
   Luo, Yuetong
   Jia, Wei
TI Camouflage performance analysis and evaluation framework based on
   features fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camouflage; Performance evaluation; Saliency detection; Nonlinear fusion
AB The analysis and evaluation of camouflage performance is an important procedure in digital camouflage pattern design, as it helps to improve the design quality of camouflage patterns. In this paper, we propose a novel framework that uses the nonlinear fusion of multiple image features to quantitatively evaluate the degree to which the target and surrounding background differ with respect to background-related and internal features. In our framework, background-related features are first formulated as a measure of conspicuousness, which is calculated and quantized by the saliency detection method, whereas internal features refer to the interior saliency of camouflage textures, such as lines and other regular patterns. These two features are fused to evaluate the camouflage effect. A subjective evaluation is carried out as the baseline of our evaluation model. Experimental results show that our camouflage evaluation framework accords with the human visual perception mechanism, and is an effective method for evaluating camouflage pattern design.
C1 [Xue, Feng; Yong, Chengxi; Xu, Shan; Dong, Hao; Luo, Yuetong] Hefei Univ Technol, Sch Comp Sci & Informat, Hefei, Peoples R China.
   [Jia, Wei] Chinese Acad Sci, Hefei Inst Phys Sci, Hefei, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; Hefei
   Institutes of Physical Science, CAS
RP Xue, F (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat, Hefei, Peoples R China.
EM feng.xue@hfut.edu.cn; cxyong2013@mail.hfut.edu.cn;
   sxu2012@mail.hfut.edu.cn; hdong2013@mail.hfut.edu.cn; ytluo@hfut.edu.cn;
   icg.jiawei@gmail.com
FU National Natural Science Foundation of China [61202283, 61472115]; Open
   Project Program of the National Laboratory of Pattern Recognition (NLPR)
   [201407350]
FX This research was supported by the National Natural Science Foundation
   of China (Grant Nos. 61202283 and 61472115), and the Open Project
   Program of the National Laboratory of Pattern Recognition (NLPR, No.
   201407350).
CR [Anonymous], 9 INT C INF TECHN IC
   Bian P, 2010, INT CONF SIGN PROCES, P1017, DOI 10.1109/ICOSP.2010.5655856
   Cui B-S, 1993, ENG EQUIP RES, V3, P1
   Feng X, 2014, MULTIMEDIA SYST, V21, P169
   Hough P. V. C., 1960, US Patent, Patent No. 3069654
   [黄雁华 HUANG Yanhua], 2011, [光学技术, Optical Technology], V37, P601
   Lin Wei, 2009, Infrared Laser Engineering, V38, P155
   [林伟 LIN Wei], 2007, [兵工学报, Acta Armamentarii], V28, P1191
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Nyberg S, 2001, P SOC PHOTO-OPT INS, V4370, P60, DOI 10.1117/12.440094
   NYBERG S, 1993, P SOC PHOTO-OPT INS, V1967, P300, DOI 10.1117/12.151052
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Schoene R, 2010, P SOC PHOTO-OPT INS, V7697, DOI 10.1117/12.850190
   Singh SK, 2013, IERI PROC, V4, P351, DOI 10.1016/j.ieri.2013.11.050
   Song L., 2010, P INT C MULT TECHN, P1
   [许卫东 Xu Weidong], 2002, [兵工学报, Acta Armamentarii], V23, P329
   Ying XU, 2010, EL TECHNOLOGY APPL, V4, P69
NR 19
TC 41
Z9 44
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 4065
EP 4082
DI 10.1007/s11042-015-2946-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200024
DA 2024-07-18
ER

PT J
AU Zhang, LG
   Tjondronegoro, D
   Chandran, V
   Eggink, J
AF Zhang, Ligang
   Tjondronegoro, Dian
   Chandran, Vinod
   Eggink, Jana
TI Towards robust automatic affective classification of images using facial
   expressions for practical applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective classification; Facial expression recognition; Image;
   Application
ID SHAPE; FEATURES; REPRESENTATION; TEXTURE; MODEL
AB Affect is an important feature of multimedia content and conveys valuable information for multimedia indexing and retrieval. Most existing studies for affective content analysis are limited to low-level features or mid-level representations, and are generally criticized for their incapacity to address the gap between low-level features and high-level human affective perception. The facial expressions of subjects in images carry important semantic information that can substantially influence human affective perception, but have been seldom investigated for affective classification of facial images towards practical applications. This paper presents an automatic image emotion detector (IED) for affective classification of practical (or non-laboratory) data using facial expressions, where a lot of "real-world" challenges are present, including pose, illumination, and size variations etc. The proposed method is novel, with its framework designed specifically to overcome these challenges using multi-view versions of face and fiducial point detectors, and a combination of point-based texture and geometry. Performance comparisons of several key parameters of relevant algorithms are conducted to explore the optimum parameters for high accuracy and fast computation speed. A comprehensive set of experiments with existing and new datasets, shows that the method is effective despite pose variations, fast, and appropriate for large-scale data, and as accurate as the method with state-of-the-art performance on laboratory-based data. The proposed method was also applied to affective classification of images from the British Broadcast Corporation (BBC) in a task typical for a practical application providing some valuable insights.
C1 [Zhang, Ligang] Xian Univ Technol, Fac Comp Sci & Engn, Xian 710048, Peoples R China.
   [Zhang, Ligang; Tjondronegoro, Dian; Chandran, Vinod] Queensland Univ Technol, Fac Sci & Engn, Brisbane, Qld 4000, Australia.
   [Eggink, Jana] BBC, Res & Dev, London, England.
C3 Xi'an University of Technology; Queensland University of Technology
   (QUT)
RP Zhang, LG (corresponding author), Queensland Univ Technol, Fac Sci & Engn, Brisbane, Qld 4000, Australia.
EM ligzhang@gmail.com; dian@qut.edu.au; v.chandran@qut.edu.au;
   jana.eggink@bbc.co.uk
RI Tjondronegoro, Dian/AAE-4685-2022; Chandran, Vinod/N-3053-2019
OI Tjondronegoro, Dian/0000-0001-7446-2839; Chandran,
   Vinod/0000-0003-3185-0852
FU British Broadcast Corporation; Australian Smart Services CRC; National
   Natural Science Foundation of China [61402362, 61402363]
FX This work is funded by the British Broadcast Corporation, Australian
   Smart Services CRC, and the National Natural Science Foundation of China
   (Grant No. 61402362, 61402363).
CR Acar Esra, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P303, DOI 10.1007/978-3-319-04114-8_26
   An L, 2015, NEUROCOMPUTING, V149, P354, DOI 10.1016/j.neucom.2014.04.072
   Anisetti M, 2008, MULTIMED SYST APPL, P155
   Anisetti M, 2009, STUD COMPUT INTELL, V226, P401
   [Anonymous], FACIAL ACTION CODING
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], 2011, P 2011 INT WORKSHOP
   [Anonymous], PROC ACM INT CONF MU
   [Anonymous], 2006, SPPRA
   [Anonymous], 2005, P 13 ANN ACM INT C M
   [Anonymous], 2013, P 3 ACM C INT C MULT, DOI DOI 10.1145/2461466.2461502
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Bianchi-Berthouze N, 2003, IEEE MULTIMEDIA, V10, P103, DOI 10.1109/MMUL.2003.1218262
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Canini L, 2013, IEEE T CIRC SYST VID, V23, P636, DOI 10.1109/TCSVT.2012.2211935
   Caridakis G, 2010, J MULTIMODAL USER IN, V3, P49, DOI [10.1007/s12193-009-0030, 10.1007/s12193-009-0030-8]
   Chew SW, 2012, IEEE T SYST MAN CY B, V42, P1006, DOI 10.1109/TSMCB.2012.2194485
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Danisman T, 2013, SIGNAL PROCESS, V93, P1547, DOI 10.1016/j.sigpro.2012.08.007
   Dhall A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2106, DOI 10.1109/ICCVW.2011.6130508
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Feng XY, 2013, LECT NOTES COMPUT SC, V7944, P339
   Han DF, 2008, MULTIMED TOOLS APPL, V39, P169, DOI 10.1007/s11042-008-0203-6
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Kotsia I, 2008, PATTERN RECOGN, V41, P833, DOI 10.1016/j.patcog.2007.06.026
   Lajevardi SM, 2012, SIGNAL IMAGE VIDEO P, V6, P159, DOI 10.1007/s11760-010-0177-5
   Lee J, 2011, IEEE T MULTIMEDIA, V13, P1031, DOI 10.1109/TMM.2011.2158530
   Li S., 2012, Asian Conference on Computer Vision, P577
   Li S., 2002, European Conference on Computer Vision, P117
   Li ZS, 2009, IEEE SYS MAN CYBERN, P1353, DOI 10.1109/ICSMC.2009.5346254
   Ligang Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P1027, DOI 10.1109/ICME.2012.97
   Ligang Zhang, 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P620, DOI 10.1109/DICTA.2011.110
   Liu NN, 2011, LECT NOTES COMPUT SC, V6974, P195, DOI 10.1007/978-3-642-24600-5_23
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Mita T, 2005, IEEE I CONF COMP VIS, P1619
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Panning A., 2008, Pattern Recognition and Image Analysis, V18, P447, DOI 10.1134/S1054661808030139
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Shan CF, 2012, IEEE T IMAGE PROCESS, V21, P431, DOI 10.1109/TIP.2011.2161587
   Shan He, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P760, DOI 10.1109/ICIG.2011.91
   Song ML, 2010, IEEE T SYST MAN CY B, V40, P779, DOI 10.1109/TSMCB.2009.2029076
   Sung J, 2008, IEEE T SYST MAN CY A, V38, P852, DOI 10.1109/TSMCA.2008.923047
   Tang H, 2008, IEEE INT CONF AUTOMA, P110
   Tariq U., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P872, DOI 10.1109/FG.2011.5771365
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang P, 2007, PROC CVPR IEEE, P701
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Wang Z., 2011, Proc. Int. Conf. Power Electron. Syst. Appl, P1, DOI [DOI 10.1155/2011/571781, https://doi.org/10.1109/GeoInformatics.2011.5980790, DOI 10.1109/GEOINFORMATICS.2011.5980790]
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Wu Y, 2015, INT J COMPUT VISION, V113, P37, DOI 10.1007/s11263-014-0775-8
   Xie XD, 2009, PATTERN RECOGN, V42, P1003, DOI 10.1016/j.patcog.2008.08.034
   Xu M, 2014, MULTIMED TOOLS APPL, V70, P757, DOI 10.1007/s11042-012-1046-8
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang C, 2010, C ELECT INSUL DIEL P
   Zhang LG, 2014, IMAGE VISION COMPUT, V32, P1067, DOI 10.1016/j.imavis.2014.09.005
   Zhang LG, 2014, IMAGE VISION COMPUT, V32, P107, DOI 10.1016/j.imavis.2013.12.008
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 70
TC 12
Z9 12
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4669
EP 4695
DI 10.1007/s11042-015-2497-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700024
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Baecchi, C
   Uricchio, T
   Bertini, M
   Del Bimbo, A
AF Baecchi, Claudio
   Uricchio, Tiberio
   Bertini, Marco
   Del Bimbo, Alberto
TI A multimodal feature learning approach for sentiment analysis of social
   network multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Feature learning; Micro-blogging; Twitter
ID EMOTIONS
AB In this paper we investigate the use of a multimodal feature learning approach, using neural network based models such as Skip-gram and Denoising Autoencoders, to address sentiment analysis of micro-blogging content, such as Twitter short messages, that are composed by a short text and, possibly, an image. The approach used in this work is motivated by the recent advances in: i) training language models based on neural networks that have proved to be extremely efficient when dealing with web-scale text corpora, and have shown very good performances when dealing with syntactic and semantic word similarities; ii) unsupervised learning, with neural networks, of robust visual features, that are recoverable from partial observations that may be due to occlusions or noisy and heavily modified images. We propose a novel architecture that incorporates these neural networks, testing it on several standard Twitter datasets, and showing that the approach is efficient and obtains good classification results.
C1 [Baecchi, Claudio; Uricchio, Tiberio; Bertini, Marco; Del Bimbo, Alberto] Univ Florence, MICC, Florence, Italy.
C3 University of Florence
RP Uricchio, T (corresponding author), Univ Florence, MICC, Florence, Italy.
EM claudio.baecchi@unifi.it; tiberio.uricchio@unifi.it;
   marco.bertini@unifi.it; alberto.delbimbo@unifi.it
RI Bertini, Marco/X-1325-2019
OI Bertini, Marco/0000-0002-1364-218X; URICCHIO,
   TIBERIO/0000-0003-1025-4541; DEL BIMBO, ALBERTO/0000-0002-1052-8322
CR [Anonymous], P INT C PATT REC ICP
   [Anonymous], 2009, CS224N
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2014, P INT C MACH LEARN I
   [Anonymous], 2013, 2013 IEEE INT C MULT
   [Anonymous], P AAAI C ART INT CAI
   [Anonymous], 2013, Journal of Data Analysis and Information Processing, DOI [10.4236/jdaip.2013.13004, DOI 10.4236/JDAIP.2013.13004]
   [Anonymous], P AAAI INT C WEBL SO
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], 1999, Technical Report No. A-4
   [Anonymous], P INT
   [Anonymous], P AI IA EM SENT SOC
   [Anonymous], 2012, ARXIV12115590
   [Anonymous], P ACM INT C MULT RET
   [Anonymous], P INT C COMP VIS ICC
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], P CHIN SEM WEB S 1 C
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], P INT C SEM WEB ISWC
   [Anonymous], 2010, P INT C COMP LING CO
   [Anonymous], 2008, P INT C MACH LEARN I
   [Anonymous], P ACL ANN M ASS COMP
   [Anonymous], P NEUR INF PROC SYST
   [Anonymous], P ACL ANN M ASS COMP
   Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bian JW, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1807, DOI 10.1145/2505515.2505652
   Bifet A, 2010, P 13 INT C DISC SCI, P1, DOI DOI 10.1007/978-3-642-16184-1_1
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Bravo-Marquez Felipe., 2013, Proceedings of the Second International Workshop on Issues of Sentiment Discovery and Opinion Mining, P2, DOI DOI 10.1145/2502069.2502071
   Cao DL, 2016, MULTIMEDIA SYST, V22, P479, DOI 10.1007/s00530-014-0407-8
   Chen T., 2013, P 21 ACM INT C MULT, P781, DOI [DOI 10.1145/2502081.2502203, 10.1145/2502081, DOI 10.1145/2502081]
   Chen Yan-Ying, 2014, P INT C MULT RETR, P233, DOI [10.1145/2578726.2578756, DOI 10.1145/2578726.2578756]
   Dan-Glauser ES, 2011, BEHAV RES METHODS, V43, P468, DOI 10.3758/s13428-011-0064-1
   Ghiassi M, 2013, EXPERT SYST APPL, V40, P6266, DOI 10.1016/j.eswa.2013.05.057
   Gutmann MU, 2012, J MACH LEARN RES, V13, P307
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   McParlane PJ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1175, DOI 10.1145/2600428.2609538
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   Mikolov Tomas, 2013, P 26 INT C NEUR INF
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang M., 2014, P INT C INT MULT COM, P76, DOI [10.1145/2632856.2632912, DOI 10.1145/2632856.2632912]
   Wang WN, 2008, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2008.4711705
   Wang Z., 2012, Proceedings of the 20th ACM International Conference on Multimedia, MM '12, P1359
   Yanai K., 2012, Proceedings of the 2nd ACM International Conference on Multimedia Retrieval, P1, DOI DOI 10.1145/2324796.2324870
NR 50
TC 53
Z9 58
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2507
EP 2525
DI 10.1007/s11042-015-2646-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000007
DA 2024-07-18
ER

PT J
AU Al-Safadi, L
   Alomran, R
   Almutairi, F
AF Al-Safadi, Lilac
   Alomran, Rawan
   Almutairi, Fareeda
TI An overview and evaluation of the radiologists lounge, a semantic
   content-based radiographic images retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radiologist Lounge; Radiographic images; Semantic Indexing; Semantic
   retrieval; Performance
AB With the emergence of professional online communities, professionals in the radiology field needed such technology to discuss and share radiographic images between each other. As medical communities rise, they suffer from semantic gap in the process of retrieving radiographic images. This paper presents The Radiologists Lounge, a professional online community specializing in connecting professionals in the radiology field. It has proposed the use of semantics in data retrieval and in structuring radiographic images, with the aim of retrieving these images on the basis of their semantic content. It is implemented using standard biomedical ontology known as the Unified medical Language System (UMLS). The primary goal of our study is to determine how well the Radiologist Lounge prototype functions as a semantic online community that retrieves images based on their semantic content. We study the performance of Radiologist Lounge measured in; indexing speed, retrieval speed, precision of results, recall of results and F-measure of results. Radiographic images are described on two conceptual layers; semantic and logical. The precision, recall and F-measure of retrieved results are measured on the different layers; logical, semantic, combination of logical and semantic. All results are later compared with the precision, recall and F-measure of the tradition tag-based retrieval. The paper describes the limitations of the Radiologist Lounge, ways to improve its performance, and increase its recall, precision and F-measure.
C1 [Al-Safadi, Lilac; Alomran, Rawan; Almutairi, Fareeda] King Saud Univ, Dept Informat Technol, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 King Saud University
RP Al-Safadi, L (corresponding author), King Saud Univ, Dept Informat Technol, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM lalsafadi@ksu.edu.sa; rawanalomran@gmail.com; mrs.fareeeda@gmail.com
FU "Research Center of the Center for Female Scientific and Medical
   Colleges", Deanship of Scientific Research, King Saud University
FX This research project was supported by a grant from the "Research Center
   of the Center for Female Scientific and Medical Colleges", Deanship of
   Scientific Research, King Saud University
CR Al-Safadi Lilac A. E., 2012, Journal of Theoretical and Applied Information Technology, V37, P80
   Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733
   Benitez AB, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P189, DOI 10.1109/ICME.2002.1035750
   Blumberg R., 2003, The Problem with Unstructured Data
   Chang S, 1998, P IEEE INT C IM PROC, P256
   Cimperman R, 2006, PEARSON ED
   Do H-H, 2002, P GI WORKSH WEB DAT
   Goodrum AA, 2001, J AM SOC INF SCI TEC, V52, P948, DOI 10.1002/asi.1147
   Heng Tao Shen, 2000, Proceedings ACM Multimedia 2000, P39, DOI 10.1145/354384.376098
   Kumar S., 2008, Teleradiology, p1c8
   Lew MS, 2002, LECT NOTES COMPUT SC, V2383, P1
   Li Q., 2007, STUDFUZZ, V210, P97
   Nachtegael Mike., 2007, Soft Computing in Image Processing
   Naphade M, 2002, P IEEE INT C MULT, P259
   PICARD RW, 1995, MULTIMEDIA SYST, V3, P3, DOI 10.1007/BF01236575
   Saber E, 1997, J VIS COMMUN IMAGE R, V8, P3, DOI 10.1006/jvci.1997.0344
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wellman Barry., 1998, Power, Community, and the City, P81
NR 18
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 607
EP 625
DI 10.1007/s11042-014-2310-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500027
DA 2024-07-18
ER

PT J
AU Dutta, D
   Saha, SK
   Chanda, B
AF Dutta, Debabrata
   Saha, Sanjoy Kumar
   Chanda, Bhabatosh
TI A shot detection technique using linear regression of shot transition
   pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation; Shot detection; Shot transition
ID MODEL
AB Video segmentation acts as the fundamental step for various applications like, archiving, content based retrieval, copy detection and summarization of video data. Shot detection is first level of segmentation. In this work, a shot detection methodology is presented that evolves around a simple shot transition model based on the similarity of the frames with respect to a reference frame. Frames in an individual shot are very similar in terms of their visual content. Whenever a shot transition occurs a change in similarity values appears. For an abrupt transition, the rate of change is very high, while for gradual it is not so apparent. To overcome the effect of noise in similarity values, line is fit over a small window using a linear regression. Thus slope of this line exhibits the underlying pattern of transition. A novel algorithm for shot detection, hence, is developed based on the variation pattern of the similarity values of the frames with respect to a reference frame. First an algorithm is proposed, which is direct descendant of the underlying transition model and applies a threshold on the similarity values to detect the transitions. Then this algorithm is improved by utilizing the slope of linear approximation of variation in similarity values rather than the absolute values, following least square regression. Threshold on the slope is determined with a bias towards minimizing false rejection rate at the cost of false acceptance rate. Finally, a simple post-processing technique is adopted to reduce the false detection. Experiment is done with the video sequences taken from TRECVID 2001 database, action type movie video, recorded sports and news video. Comparison with few other systems indicates that the performance of the proposed scheme is quite satisfactory.
C1 [Dutta, Debabrata] Tirthapati Inst, Kolkata, India.
   [Saha, Sanjoy Kumar] Jadavpur Univ, CSE Dept, Kolkata, India.
   [Chanda, Bhabatosh] Indian Stat Inst, ECS Unit, Kolkata, India.
C3 Jadavpur University; Indian Statistical Institute; Indian Statistical
   Institute Kolkata
RP Saha, SK (corresponding author), Jadavpur Univ, CSE Dept, Kolkata, India.
EM debabratadutta2u@gmail.com; sks_ju@yahoo.co.in; chanda@isical.ac.in
CR Adjeroh D, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/859371
   Amel A. M., 2010, J TELECOMMUN, V2, P54
   Amiri A, 2009, P INT C COMP SCI ITS, P780
   Bescós J, 2005, IEEE T MULTIMEDIA, V7, P293, DOI 10.1109/TMM.2004.840598
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Chen LH, 2008, PATTERN RECOGN, V41, P1056, DOI 10.1016/j.patcog.2007.07.024
   Cooper M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P502, DOI 10.1109/ICME.2005.1521470
   Duy-Dinh Le, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P702, DOI 10.1109/MMSP.2008.4665166
   Grana C, 2007, IEEE T CIRC SYST VID, V17, P483, DOI 10.1109/TCSVT.2006.888818
   Hampapur A., 1995, MULTIMED TOOLS APPL, V1, P1
   Haoran Y., 2006, INFORM SYST, V31, P638
   Huang CL, 2001, IEEE T CIRC SYST VID, V11, P1281, DOI 10.1109/76.974682
   Ling X, 2008, MUE: 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P394, DOI 10.1109/MUE.2008.102
   Liu XM, 2002, INT CONF ACOUST SPEE, P3389
   Mas J., 2003, Video shot boundary detection based on color histogram
   Mohanta PP, 2012, IEEE T MULTIMEDIA, V14, P223, DOI 10.1109/TMM.2011.2170963
   Murai Y., 2008, 19 INT C PATTERN REC, P1
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   Porter S., 2001, BRIT MACH VIS C BMVC, P73
   Rees D.G., 1987, FDN STAT
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Tsamoura E, 2008, IEEE IMAGE PROC, P45, DOI 10.1109/ICIP.2008.4711687
   Yoo HW, 2006, MULTIMED TOOLS APPL, V28, P283, DOI 10.1007/s11042-006-7715-8
   Yuan J, 2004, P TREC VID RETR EV T, P84
   Zhang C., 2012, Proc. ACM Multimedia, P701
   Zhang WG, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P593
   Zhao Huan, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P1124, DOI 10.1109/CSSE.2008.939
NR 28
TC 11
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 93
EP 113
DI 10.1007/s11042-014-2273-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500005
DA 2024-07-18
ER

PT J
AU Ben Ahmed, E
   Tebourski, W
   Karaa, WBA
   Gargouri, F
AF Ben Ahmed, Eya
   Tebourski, Wafa
   Karaa, Wahiba Ben Abdessalem
   Gargouri, Faiez
TI SMART: Semantic multidimensional group recommendations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data warehouse; OLAP; Recommender system; Group profiling; Ontology;
   Semantics
AB The rising availability of data in the information systems has boosted the challenging problem of queries recommendation, especially in OLAP systems. In this paper, we introduce an innovative oe"cent a"(3)oe"oe"oe" pound system for semantic multidimensional group recommendations to enhance the querying formulation process. Indeed, we describe the problem of group recommendation and define its semantics through introducing our group profiling ontology. Thus, we infer the analysts' ongoing behaviors on our ontological concepts using a weighted summation strategy. Based on our ontological representation, we propose a new method for deriving relevant semantic recommendations (i.e., complete and queries fragments). In addition, an optimization technique for selecting the most interesting visualization of recommendations is proposed. Carried out experiments of our SMART system on real built financial data warehouse highlight encouraging results in terms of precision and recall.
C1 [Ben Ahmed, Eya; Tebourski, Wafa; Karaa, Wahiba Ben Abdessalem] Univ Tunis, High Inst Management Tunis, Tunis, Tunisia.
   [Gargouri, Faiez] Univ Sfax, High Inst Comp & Multimedia Sfax, Tunis, Tunisia.
C3 Universite de Tunis; Universite de Sfax
RP Ben Ahmed, E (corresponding author), Univ Tunis, High Inst Management Tunis, Tunis, Tunisia.
EM eya.benahmed@gmail.com; wafa.tebouski@gmail.com;
   wahiba.abdessalem@isg.rnu.tn; faiez.gargouri@isims.rnu.tn
RI Ben Abdessalem, Wahiba/JSL-3792-2023
OI Gargouri, Faiez/0000-0003-2575-8654; Ben Abdessalem,
   wahiba/0000-0002-7444-5921
CR Ahmed E. B., 2011, Int. J. Database Manag. Syst., V3, P59
   Akbarnejad J, 2010, PROC VLDB ENDOW, V3, P1597, DOI 10.14778/1920841.1921048
   [Anonymous], 1948, BELL SYST TECH J
   Ben Ahmed E., 2012, INT J COMPUTER APPL, V48, P18
   Ben Ahmed E, 2012, INT J COMPUT SCI ISS, V3, P124
   Chatzopoulou Gloria., 2011, IEEE Data Eng. Bull, V34, P55
   Giacometti A., 2009, P 12 ACM INT WORKSHO, P81, DOI DOI 10.1145/1651291.1651306
   Giacometti A, 2011, INT J DATA WAREHOUS, V7, P1, DOI 10.4018/jdwm.2011040101
   Giacometti A, 2009, LECT NOTES COMPUT SC, V5691, P453, DOI 10.1007/978-3-642-03730-6_36
   Golfarelli M, 2008, DATA WAREHOUS DES AD, V23, P1
   Golfarelli M, 2011, IEEE T KNOWL DATA EN, V23, P1050, DOI 10.1109/TKDE.2010.196
   Gruber T.R., 1993, Towards Principles for the Design of Ontologies Used for Knowledge Sharing
   Han J, 2011, SERIES DATA MANAGEME
   Jerbi H, 2009, LECT NOTES COMPUT SC, V5691, P467, DOI 10.1007/978-3-642-03730-6_37
   Jerbi H, 2009, LECT NOTES BUS INF P, V24, P220
   Khemiri R, 2012, DEXA WORKSHOPS P
   Stefanidis K, 2013, ERCIM 92, V92
   Stefanidis K, 2012, P PERSDB
   Stuckenschmidt H, 2009, LECT NOTES COMPUT SC, V5445, P1, DOI 10.1007/978-3-642-01907-4
NR 19
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10419
EP 10437
DI 10.1007/s11042-014-2174-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700012
DA 2024-07-18
ER

PT J
AU Tomasev, N
   Mladenic, D
AF Tomasev, Nenad
   Mladenic, Dunja
TI Image hub explorer: evaluating representations and metrics for
   content-based image retrieval and object recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Visualization; Hubness; Object recognition; k-nearest
   neighbors; Machine learning
ID HIGH-DIMENSIONAL DATA; NEAREST-NEIGHBOR; COLOR
AB We present a novel tool for image data visualization and analysis, Image Hub Explorer. It is aimed at developers and researchers alike and it allows the users to examine various aspects of content-based image retrieval and object recognition under different built-in metrics and models. Image Hub Explorer provides the tools for understanding the distribution of influence in the data, primarily by examining the emerging hub images. Hubness is an aspect of the well-known curse of dimensionality that hampers the effectiveness of many information systems. Its consequences were thoroughly examined in the context of music/audio search and recommendation, but not in case of image retrieval and object recognition. Image Hub Explorer was made with the goal of raising awareness of the hubness phenomenon and offering potential solutions by implementing state-of-the-art hubness-aware metric learning, ranking and classification methods. Various visualization components allow for a quick identification of critical issues and we hope that they will prove helpful in working with large image datasets. We demonstrate the effectiveness of the implemented methods in various object recognition tasks.
C1 [Tomasev, Nenad; Mladenic, Dunja] Jozef Stefan Inst, Artificial Intelligence Lab, Ljubljana, Slovenia.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute
RP Tomasev, N (corresponding author), Jozef Stefan Inst, Artificial Intelligence Lab, Jamova 39, Ljubljana, Slovenia.
EM nenad.tomasev@gmail.com; dunja.mladenic@ijs.si
OI Mladenic, Dunja/0000-0002-0360-6505; Tomasev, Nenad/0000-0003-1624-0220
FU Slovenian Research Agency; ICT Programme of the EC under XLike
   [ICT-STREP-288342]; ICT Programme of the EC under RENDER
   [ICT-257790-STREP]
FX This work was supported by the Slovenian Research Agency, the ICT
   Programme of the EC under XLike (ICT-STREP-288342), and RENDER
   (ICT-257790-STREP).
CR Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420
   [Anonymous], P 7 IEEE INT C INT C
   [Anonymous], INT WORKSH AUD VIS C
   [Anonymous], LEARNING GENERATIVE
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2013, ABS13101531 CORR
   [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], 1961, Adaptive control processes: a guided tour, DOI DOI 10.1515/9781400874668
   [Anonymous], REPRESENTATIONS METR
   [Anonymous], MULTIMEDIA SYST
   [Anonymous], 2005, MORGAN KAUFMANN SERI
   [Anonymous], P ECDL C
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], 2007, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2007.382970
   [Anonymous], 2013, P WORKSH NEW CHALL D
   [Anonymous], P IEEE S VIS AN SCI
   [Anonymous], J NEGAT RESULTS SPEE
   [Anonymous], INVESTIGATING IMPACT
   [Anonymous], KERNEL BASED VISUALI
   [Anonymous], 1 INT C SEM DIG MED
   [Anonymous], 2013, P ITI 2013 35 INT C
   [Anonymous], PHYS REV E
   [Anonymous], 2009, MDSJ JAVA LIB MULTID
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2010, SIG 2010 P 33 ANN
   [Anonymous], COMPUT RES REPOSITOR
   [Anonymous], P 5 AUD MOSTL C C IN
   [Anonymous], 2008, P IND C COMP VIS GRA
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Borg I., 2005, Modern Multidimensional Scaling: Theory and Applications
   Buza K, 2011, LECT NOTES ARTIF INT, V6635, P149, DOI 10.1007/978-3-642-20847-8_13
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen J, 2009, J MACH LEARN RES, V10, P1989
   Deng J., 2009, CVPR09
   Eler DM, 2008, SIBGRAPI, P289, DOI 10.1109/SIBGRAPI.2008.30
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Fix E., 1951, JOSEPH
   Fortuna B, 2005, INFORM-J COMPUT INFO, V29, P497
   François D, 2007, IEEE T KNOWL DATA EN, V19, P873, DOI 10.1109/TKDE.2007.1037
   Gong YH, 1999, MULTIMEDIA SYST, V7, P449, DOI 10.1007/s005300050145
   Haghani Parisa., 2009, PROC 12 INT C EXTEND, P744
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Houle ME, 2010, LECT NOTES COMPUT SC, V6187, P482, DOI 10.1007/978-3-642-13818-8_34
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Li BT, 2003, MULTIMEDIA SYST, V8, P512, DOI 10.1007/s00530-002-0069-9
   Low T., 2013, Towards Advanced Data Anal ysis by Combining Soft Computing and Statistics., P267, DOI [10.1007/978-3-642-30278-7_21, DOI 10.1007/978-3-642-30278-7_21]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nanopoulos A., 2009, Proceedings of the Third ACM Conference on Recommender Systems, RecSys '09, P293
   Napierala K, 2012, LECT NOTES COMPUT SC, V7209, P139
   Nguyen GP, 2008, J VISUAL LANG COMPUT, V19, P203, DOI 10.1016/j.jvlc.2006.09.002
   Patil A, 2010, INT J MOL SCI, V11, P1930, DOI 10.3390/ijms11041930
   Porta Marco, 2006, P AVI, P440
   Radovanovic M., 2009, P 26 ANN INT C MACH, P865, DOI [10.1145/1553374.1553485, DOI 10.1145/1553374.1553485]
   Radovanovic M., 2010, SDM, P677
   Radovanovic M, 2010, J MACH LEARN RES, V11, P2487
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schaefer G, 2010, MULTIMED TOOLS APPL, V47, P105, DOI 10.1007/s11042-009-0409-2
   Schnitzer D, 2012, J MACH LEARN RES, V13, P2871
   Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023
   Tomasev N., 2011, 2011 IEEE International Conference on Intelligent Computer Communication and Processing, P367, DOI 10.1109/ICCP.2011.6047899
   Tomasev N., 2011, P 20 ACM INT C INFOR, P2173
   Tomasev N, 2014, IEEE T KNOWL DATA EN, V26, P739, DOI 10.1109/TKDE.2013.25
   Tomasev N, 2014, INT J MACH LEARN CYB, V5, P445, DOI 10.1007/s13042-012-0137-1
   Tomasev N, 2014, KNOWL INF SYST, V39, P89, DOI 10.1007/s10115-012-0607-5
   Tomasev N, 2012, COMPUT SCI INF SYST, V9, P691, DOI 10.2298/CSIS111211014T
   Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Yamaoka S, 2011, FUTURE GENER COMP SY, V27, P498, DOI 10.1016/j.future.2010.12.005
   Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhou ZH, 2006, ACM T INFORM SYST, V24, P219, DOI 10.1145/1148020.1148023
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
NR 76
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11653
EP 11682
DI 10.1007/s11042-014-2254-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600030
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, M
   Tong, XJ
AF Zhang, Miao
   Tong, Xiaojun
TI A new algorithm of image compression and encryption based on
   spatiotemporal cross chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression and encryption; Non-uniform Discrete Cosine Transform
   (NDCT); Nearest-neighboring coupled-map lattices (NCML); Permutation and
   diffusion simultaneously
ID DIFFUSION; SECURITY; DCT
AB This paper proposes a new image compression and encryption scheme based on the nearest-neighboring coupled-map lattices (NCML) and Non-uniform Discrete Cosine Transform (NDCT). A new cross chaotic map proposed based on Devaney's theory is used as the local map of NCML, which is called spatiotemporal cross chaotic system. The algorithm adopts Huffman coding and NDCT which carries out transformation of image data to compress image data. In this system, there are two layers of encryption protection. The compression data are packed into blocks, and permutation between blocks and diffusion in blocks are done simultaneously. The parameters produced by spatiotemporal cross chaotic system are used to control the non-uniformity of the NDCT, which has also played a role in encryption. The security test results indicate the proposed methods have high speed, high security and good compression effect.
C1 [Zhang, Miao; Tong, Xiaojun] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Shandong, Peoples R China.
C3 Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Shandong, Peoples R China.
EM zhangmiaozm209@126.com; tong_xiaojun@163.com
FU National Natural Science Foundation of China [60973162]; Science and
   Technology of Shandong Province of China [2013GGX10129, 2010GGX10132,
   2012GGX10110]; Soft Science of Shandong Province of China
   [2012RKA10009]; National Cryptology Development Foundation of China
   [MMJJ201301006]; Teaching Research Project of Harbin Institute of
   Technology at Weihai and college of computer [HITWHCS201309];
   Engineering Technology and Research Center of Weihai Information
   Security
FX This research is supported by the National Natural Science Foundation of
   China (No. 60973162), the Science and Technology of Shandong Province of
   China (No. 2013GGX10129, No. 2010GGX10132, No. 2012GGX10110), the Soft
   Science of Shandong Province of China (No. 2012RKA10009) and the
   National Cryptology Development Foundation of China (No.MMJJ201301006),
   the Teaching Research Project of Harbin Institute of Technology at
   Weihai and college of computer (NO. HITWHCS201309), and the Engineering
   Technology and Research Center of Weihai Information Security.
CR Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Curtis KM, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1337, DOI 10.1109/ICDSP.2002.1028341
   [代才莉 Dai Caili], 2012, [重庆大学学报, Journal of Chongqing University], V35, P87
   [邓艺 Deng Yi], 2010, [电子与信息学报, Journal of Electronics & Information Technology], V32, P323
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Ge X., 2010, 2010 2 IEEE INT C IN
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Han FY, 2007, COMPUT ENG APPL, V43, P50
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   KANEKO K, 1989, PHYSICA D, V34, P1, DOI 10.1016/0167-2789(89)90227-3
   KANEKO K, 1985, PROG THEOR PHYS, V74, P1033, DOI 10.1143/PTP.74.1033
   Kanso A, 2011, COMMUN NONLINEAR SCI, V16, P822, DOI 10.1016/j.cnsns.2010.04.039
   Kim H, 2007, IEEE T SIGNAL PROCES, V55, P2263, DOI 10.1109/TSP.2007.892710
   Kingston A, 2008, SIGNAL PROCESS-IMAGE, V23, P313, DOI 10.1016/j.image.2008.03.001
   Krikor L., 2009, EUR J SCI RES, V32, P47
   Chung KL, 2006, J VIS COMMUN IMAGE R, V17, P1209, DOI 10.1016/j.jvcir.2006.01.002
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Liu X, 1999, LECT NOTES COMPUT SC, V1746, P84
   Lu K, 1990, CHAOTIC DYNAMICS
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   NIST, 2001, Special Publication (SP), V800-38A
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shi YQ, 2008, IMAGE PROCESS SER, P3
   Sun FY, 2011, CHINESE PHYS B, V20, DOI 10.1088/1674-1056/20/4/040506
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Tang JN, 2010, 2010 INT C COMP APPL, P2
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Tong XJ, 2012, J SYST SOFTWARE, V85, P850, DOI 10.1016/j.jss.2011.10.051
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang SH, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.065202
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen JT, 2006, IEEE SIGNAL PROC LET, V13, P69, DOI 10.1109/LSP.2005.861589
   Wong KW, 2008, IEEE T CIRCUITS-II, V55, P1193, DOI 10.1109/TCSII.2008.2002565
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Yang HQ, 2012, ACTA PHYS SIN-CH ED, V61, DOI 10.7498/aps.61.040505
   Yuen CH, 2011, APPL SOFT COMPUT, V11, P5092, DOI 10.1016/j.asoc.2011.05.050
   Zhou JT, 2007, IEEE SIGNAL PROC LET, V14, P201, DOI 10.1109/LSP.2006.884012
   Zhou Q, 2012, J SYST SOFTWARE, V85, P400, DOI 10.1016/j.jss.2011.08.032
NR 43
TC 16
Z9 18
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11255
EP 11279
DI 10.1007/s11042-014-2227-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600014
DA 2024-07-18
ER

PT J
AU Feng, BW
   Lu, W
   Sun, W
AF Feng, Bingwen
   Lu, Wei
   Sun, Wei
TI Novel steganographic method based on generalized <i>K</i>-distance
   <i>N</i>-dimensional pixel matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Pixel matching; N-dimensional neighborhood; Successive
   iteration algorithm (SIA); Linear mapping function
ID STEGANALYSIS
AB In this paper, a steganographic scheme adopting the concept of the generalized K (d) -distance N-dimensional pixel matching is proposed. The generalized pixel matching embeds a B-ary digit (B is a function of K and N) into a cover vector of length N, where the order-d Minkowski distance-measured embedding distortion is no larger than K. In contrast to other pixel matching-based schemes, a N-dimensional reference table is used. By choosing d, K, and N adaptively, an embedding strategy which is suitable for arbitrary relative capacity can be developed. Additionally, an optimization algorithm, namely successive iteration algorithm (SIA), is proposed to optimize the codeword assignment in the reference table. Benefited from the high dimensional embedding and the optimization algorithm, nearly maximal embedding efficiency is achieved. Compared with other content-free steganographic schemes, the proposed scheme provides better image quality and statistical security. Moreover, the proposed scheme performs comparable to state-of-the-art content-based approaches after combining with image models.
C1 [Feng, Bingwen; Lu, Wei] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Feng, BW (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM bingwfeng@gmail.com; luwei3@mail.sysu.edu.cn; sunwei@mail.sysu.edu.cn
CR Abdel-Aziz B, 2004, LECT NOTES COMPUT SC, V2939, P277
   Bas P., 2007, Bows-2
   Bierbrauer J, 2008, LECT NOTES COMPUT SC, V4920, P1, DOI 10.1007/978-3-540-69019-1_1
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CP, 2008, IEEE POTENTIALS, V27, P17, DOI 10.1109/MPOT.2008.929294
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Cox IJ., 2007, DIGITAL WATERMARKING
   Fillatre L, 2012, IEEE T SIGNAL PROCES, V60, P556, DOI 10.1109/TSP.2011.2174231
   Fridrich J, 2005, PROC SPIE, V5681, P328, DOI 10.1117/12.583160
   Fridrich J, 2007, PROC SPIE, V6505, DOI 10.1117/12.697471
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hong W, 2013, INF SCI, V221
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Ker AD, 2008, P SPIE ELECT IMAGING, V6819, P0501
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Lerch-Hostalot D, 2012, COMPUT SECUR
   Liu QZ, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899420
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Mitsuo Gen., 1997, GENETIC ALGORITHMS E
   Munuera C, 2013, SER CODING THEORY CR, V8, P83
   Nozaki K, 2005, INFORM MODELLING KNO, VXVI
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Sachnev V, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-89
   Sloane N.J., 1999, Sphere packings, lattices and groups, V290
   Voloshynovskiy S, 2000, LECT NOTES COMPUT SC, V1768, P211
   Wang JJ, 2010, SIGNAL PROCESS, V90, P2954, DOI 10.1016/j.sigpro.2010.04.022
   Wu KS, 2012, IEEE T MOBILE COMPUT, V11, P1317, DOI 10.1109/TMC.2011.158
   Yang CH, 2008, PATTERN RECOGN, V41
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 33
TC 10
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9623
EP 9646
DI 10.1007/s11042-014-2140-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200026
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Mukherjee, DP
AF Mukherjee, Snehasis
   Mukherjee, Dipti Prasad
TI A motion-based approach to detect persons in low-resolution video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person detection; Optical flow; Integral image; Image gradient; AdaBoost
AB The paper proposes a motion-based technique to detect persons in a low-resolution video, where the persons look like tiny blobs. The tiny blob-like appearance of the persons are due to camera position which is at a distance from the person(s). The proposed technique uses integral matrix based different spatial and temporal features. Gradient weighted optical flow (GWOF) is calculated for each frame of the video clip to minimize background noise. Spatial filters are used to extract motion features from the GWOF based integral matrices. The combination of image gradient and GWOF features extracts static and moving persons present in the video. The AdaBoost learning technique is used for training. The training is performed using features derived from the positive samples of bounding boxes in a video frame containing a person and negative samples with bounding boxes without a person. The proposed technique is applied on benchmark Tower dataset, UT-Interaction dataset and PETS 2007 dataset. We have obtained approximately 2 to 10 % improvement in the performance compared to the states-of-the-art.
C1 [Mukherjee, Snehasis] NIST, Informat Access Div, Gaithersburg, MD 20899 USA.
   [Mukherjee, Dipti Prasad] Indian Stat Inst, Elect & Commun Sci Unit, Kolkata 700108, India.
C3 National Institute of Standards & Technology (NIST) - USA; Indian
   Statistical Institute; Indian Statistical Institute Kolkata
RP Mukherjee, S (corresponding author), NIST, Informat Access Div, 100 Bur Dr, Gaithersburg, MD 20899 USA.
EM snehasismukho@gmail.com; dipti@isical.ac.in
RI Mukherjee, Snehasis/Q-1000-2019
OI Mukherjee, Snehasis/0000-0002-2196-8980
CR Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Chen C.C., 2010, UT TOWER DATASET AER
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Nguyen DT, 2013, PATTERN RECOGN, V46, P1485, DOI 10.1016/j.patcog.2012.10.024
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Mittal A, 2004, PROC CVPR IEEE, P302
   Mukherjee S, 2011, IEEE T CIRC SYST VID, V21, P1228, DOI 10.1109/TCSVT.2011.2135290
   Munaro M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1250, DOI 10.1109/ICCVW.2011.6130394
   Ogale NeetiA., 2006, A survey of techniques for human detection from video
   Ott P, 2009, IEEE ICCV
   Pai CJ, 2004, PATTERN RECOGN, V37, P1025, DOI 10.1016/j.patcog.2003.10.005
   Parag Toufiq., 2006, COMPUTER VISION PATT, P1916
   Ryoo M, 2010, UT INTERACTION DATAS
   Sidenbladh H, 2004, INT C PATT RECOG, P188, DOI 10.1109/ICPR.2004.1334092
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wei-Lwun Lu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3249, DOI 10.1109/CVPR.2011.5995562
NR 19
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9475
EP 9490
DI 10.1007/s11042-014-2128-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200019
DA 2024-07-18
ER

PT J
AU Ou, DH
   Sun, W
AF Ou, Duanhao
   Sun, Wei
TI High payload image steganography with minimum distortion based on
   absolute moment block truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Smooth block; Minimum distortion; High payload; Absolute
   moment block truncation coding
AB This paper presents an improved image steganography scheme based on absolute moment block truncation coding (AMBTC). The purpose of the proposed scheme is to achieve high payload, good visual quality and low computation complexity at the same time. In the scheme, a threshold is predefined to classify the blocks of the AMBTC-compressed codes as smooth or complex blocks, in which data are then embedded. For the smooth blocks, the bit planes of them are used to embed the data. Later, the two quantization levels in the smooth block are re-calculated to minimize the distortion in image quality. For the complex blocks, a proportion of secret bits are concealed by exchanging the order of two quantization levels with together toggling the bit plane, by which the payload can be increased without any distortion. Furthermore, the proposed scheme inherits the advantages of the AMBTC method, such as pleasing image quality, ease to be implemented and low computational complexity. With adjustable threshold, the application of the proposed scheme becomes flexible, that means different thresholds can be used for different applications. Experimental results and analysis demonstrate the effectiveness and superiority of the proposed scheme.
C1 [Ou, Duanhao] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Ou, DH (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM ouduanh@mail2.sysu.edu.cn; sunwei@mail.sysu.edu.cn
FU 973 Program [2011CB302400]; Natural Science Foundation of Guangdong
   Province, China [S2013010013728]
FX This work was in part supported by 973 Program (Grant No. 2011CB302400)
   and Natural Science Foundation of Guangdong Province, China (Grant No.
   S2013010013728).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alturki F, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958548
   Balasubramanian C, 2013, MULTIMED TOOLS APPL, P1
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2007, IEICE T INF SYST, VE90D, P1422, DOI 10.1093/ietisy/e90-d.9.1422
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chen P.Y., 2006, INT J APPL SCI ENG, V4, P275, DOI DOI 10.6703/IJASE/2006.4(3).275
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Guo JM, 2010, IEEE INT SYMP CIRC S, P2634, DOI 10.1109/ISCAS.2010.5537082
   Guo JM, 2010, IEEE T COMMUN, V58, P1667, DOI 10.1109/TCOMM.2010.06.090303
   Hashad AI, 2005, Enabling Technologies for the New Knowledge Society, P255
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Omoomi M, 2011, MULTIMED TOOLS APPL, V54, P201, DOI 10.1007/s11042-010-0517-z
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Shi YQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P269, DOI 10.1109/ICME.2005.1521412
   Shie SC, 2006, IEICE T INF SYST, VE89D, P358, DOI 10.1093/ietisy/e89-d.1.358
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang H. R., 2013, MULTIMED TOOLS APPL, P1
   Zhang Y, 2013, IEICE T COMMUN, VE96B, P624, DOI 10.1587/transcom.E96.B.624
NR 33
TC 63
Z9 63
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9117
EP 9139
DI 10.1007/s11042-014-2059-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200002
DA 2024-07-18
ER

PT J
AU Bouchech, HJ
   Foufou, S
   Koschan, A
   Abidi, M
AF Bouchech, Hamdi Jamel
   Foufou, Sebti
   Koschan, Andreas
   Abidi, Mongi
TI A kernelized sparsity-based approach for best spectral bands selection
   for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MBLBP; HGPP; POEM-WPCA; LGBPHS; IRIS-M-3; Subspectral images; Bands
   selection
ID PATTERNS
AB We study face recognition in unconstrained illumination conditions. A twofold contribution is proposed: First, the robustness of four state-of-the-art algorithms, namely Multi-block Local Binary Pattern (MBLBP), Histogram of Gabor Phase Patterns (HGPP), Local Gabor Binary Pattern Histogram Sequence (LGBPHS) and Patterns of Oriented Edge Magnitudes (POEM-WPCA) against high illumination variation is studied. Second, we propose to enhance the performance of the four mentioned algorithms, which has been drastically decreased upon the day lighted face images provided by IRIS-M-3 face database. For this purpose, we use visible narrow band subspectral images selected from the mentioned database. We formulate best spectral bands selection as a pursuit optimization problem wherein the vector of weights determining the importance of each visible spectral band is supposed to be sparse, and hence can be determined by minimizing its L1-norm. Several fusing approaches are then applied on selected best spectral bands using multi-scale and multi-orientation Gabor wavelets. The results highlight further the still challenging problem of face recognition in conditions with high illumination variation, as well as the effectiveness of our subspectral images based approach with its two components; bands selection and bands fusion, to increase the accuracy of the studied algorithms by at least 14 % upon the proposed database.
C1 [Bouchech, Hamdi Jamel; Foufou, Sebti] Univ Burgundy, Lab LE2i, Dijon, France.
   [Bouchech, Hamdi Jamel; Foufou, Sebti] Qatar Univ, Comp Sci & Engn, CENG, Doha, Qatar.
   [Koschan, Andreas; Abidi, Mongi] Univ Tennessee, Dept Elect Engn & Comp Sci, Imaging Robot & Intelligent Syst Lab, Knoxville, TN USA.
C3 Universite de Bourgogne; Qatar University; University of Tennessee
   System; University of Tennessee Knoxville
RP Bouchech, HJ (corresponding author), Qatar Univ, Comp Sci & Engn, CENG, POB 2713, Doha, Qatar.
EM bouchech.h@gmail.com; sfoufou@qu.edu.qa; akoschan@utk.edu; abidi@utk.edu
RI Foufou, Sebti/E-2081-2015
OI Foufou, Sebti/0000-0002-3555-9125
FU NPRP from the Qatar National Research Fund (a member of Qatar
   Foundation) [4-1165-2-453]
FX This publication was made possible by NPRP grant # 4-1165-2-453 from the
   Qatar National Research Fund (a member of Qatar Foundation). The
   statements made herein are solely the responsibility of the authors.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Aizerman M. A., 1964, Automation and Remote Control, V25, P821
   Andreas K, 2009, DIGITAL COLOR IMAGE
   Becker SR, 2011, MATH PROGRAM COMPUT, V3, P165, DOI 10.1007/s12532-011-0029-5
   Bouchech HJ, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P58, DOI 10.1109/SITIS.2013.21
   Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161
   Chang H, 2010, MACH VISION APPL, V21, P201, DOI 10.1007/s00138-008-0151-1
   Chang H., 2008, MACH VISION APPL, V19, P1432
   Chang H, 2009, IEEE T INF FOREN SEC, V4, P111, DOI 10.1109/TIFS.2008.2012211
   Chen Y, 2013, IEEE T GEOSCI REMOTE, V51, P217, DOI 10.1109/TGRS.2012.2201730
   Dian-ting L, 2008, OPTOELECTRON LETT, V4, P451
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Gao YS, 2003, IEEE T SYST MAN CY A, V33, P407, DOI 10.1109/TSMCA.2003.817057
   Lei Z., 2013, IEEE T PATTERN ANAL, V99, P1
   Li Stan Z., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204149
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moon S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR HOMELAND SECURITY AND PERSONAL SAFETY, P24, DOI 10.1109/CIHSPS.2006.313295
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Panda R, 2012, WSEAS T SIGNAL PROC, V8
   Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011
   Ruiz-del-Solar J, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/184617
   Zahran EG, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES 2009), P449, DOI 10.1109/ICCES.2009.5383223
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
NR 27
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8631
EP 8654
DI 10.1007/s11042-014-2350-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600025
DA 2024-07-18
ER

PT J
AU Zhang, WZ
   He, H
   Kim, TH
AF Zhang, Weizhe
   He, Hui
   Kim, Tai-hoon
TI Xen-based virtual honeypot system for smart device
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network security; Virtual honeypot; Xen; Smart device
AB Honeynet is a framework containing more than one honeypot to provide data control, data capture, and data analysis. This framework aims to simulate a highly controllable attack or decoy for the security analysis of a network. In this paper, the Xen-based virtual machine solution is proposed to build the virtual honeynet. A virtual honeynet deploys a honeynet on a physical machine based on virtual machine technology with the advantages of low cost as well as convenient management, and maintenance features. The virtual honeynet system includes dynamic resource allocation, data control, data capture, data presentation, and analysis. It is lightweight but has high performance, which is verified with extensive experiments.
C1 [Zhang, Weizhe; He, Hui] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, HL, Peoples R China.
   [Kim, Tai-hoon] Univ Tasmania, Sch Comp & Informat Sci, Sandy Bay, Tas, Australia.
C3 Harbin Institute of Technology; University of Tasmania
RP Zhang, WZ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, HL, Peoples R China.
EM wzzhang@hit.edu.cn; taihoonn@daum.net
RI zhang, weizhe/Q-7653-2016; HE, HUI/KUK-4080-2024
OI zhang, weizhe/0000-0003-4783-876X; 
FU National Basic Research Program of China [G2011CB302605]; National
   Natural Science Foundation of China (NSFC) [61173145]; National High
   Technology Research and Development Program of China [2011AA010705]
FX This work was supported by the National Basic Research Program of China
   under Grant No. G2011CB302605, the National Natural Science Foundation
   of China (NSFC) under grant No. 61173145, and the National High
   Technology Research and Development Program of China under Grant No.
   2011AA010705.
CR Chaware S, 2011, INT J SECUR APPL, V5, P31
   Cui Z, 2001, MULTIMED TOOLS APPL, V13, P147, DOI 10.1023/A:1009637126236
   Kreibich C, 2004, ACM SIGCOMM COMP COM, V34, P51, DOI 10.1145/972374.972384
   Li YF, 2012, INT J SECUR APPL, V6, P299
   Locasto M, 2004, CUCS01204
   Moore D, 2006, ACM T COMPUT SYST, V24, P115, DOI 10.1145/1132026.1132027
   Provos N, 2003, 10 DFN CERT WORKSH H, P2
   Singh S, 2003, CS20030761 UCSD
   The Honeynet Project, 2005, KNOW YOUR EN HON
   Yegneswaran V, 2003, P S REC ADV INTR DET, P146
   Zhou Y, 2008, 20 ANN 1 C 1 08 BRIT
   Zhuge J, 2006, P 7 IEEE WORKSH INF, P215
NR 12
TC 3
Z9 3
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8541
EP 8558
DI 10.1007/s11042-013-1499-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600019
DA 2024-07-18
ER

PT J
AU Modaghegh, H
   Seyedin, SA
AF Modaghegh, Hamed
   Seyedin, Seyed Alireza
TI A new fast and efficient active steganalysis based on combined
   geometrical blind source separation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind Source Separation (BSS); Active steganalysis; MAP estimator;
   Independent Component Analysis (ICA); Block-DCT steganography
ID IMAGES
AB We have presented a new active steganalysis method in order to break the block-discrete cosine transform (DCT) coefficients steganography. Our method is based on a combination of the Blind Source Separation (BSS) technique and Maximum A posteriori (MAP) estimator. We have additionally introduced a new geometrical BSS method based on the minimum range of mixed sources which reduces the computational cost of the proposed steganalysis. The high efficiency of this new combined method has been confirmed by enough experiments. These experiments show that, compared to the previous active steganalysis methods our active steganalysis method not only reduces the error rate but also causes a low computational cost.
RP Modaghegh, H (corresponding author), Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Iran.
EM hamed.modaghegh@stu-mail.um.ac.ir; seyedin@um.ac.ir
CR ABATE JE, 1967, PR INST ELECTR ELECT, V55, P298, DOI 10.1109/PROC.1967.5486
   Ambalavanan A, 2007, PROC SPIE, V6505, DOI 10.1117/12.704726
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Azzabou N, 2007, LECT NOTES COMPUT SC, V4485, P418
   Babaie-Zadeh M., 2002, P 11 EUR SIGN PROC C, VII, P11
   Chandramouli R, 2003, MULTIMEDIA SYST, V9, P303, DOI 10.1007/s00530-003-0101-8
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Fan F, 2007, EL MEAS INSTR 2007 I, P2
   Fridrich Jessica, 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P31, DOI 10.1007/978-3-642-36373-3_3
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Hyvrinen A., 2001, INDEPENDENT COMPONEN, Vthird
   Johnson NF, 1998, 1998 IEEE INFORMATION TECHNOLOGY CONFERENCE, PROCEEDINGS, P113, DOI 10.1109/IT.1998.713394
   Johnson NF, 1998, LECT NOTES COMPUT SC, V1525, P273
   Jutten C, 2006, IAR ANN M NANC FR, P1
   Lu Wenzhe, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P345, DOI 10.1109/FSKD.2009.348
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Papoulis A., 1991, STOCHASTIC PROCESSES
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Puntonet C. G, 1995, ACT 15 C GRETSI JUAN, P273
   Vielva L., 2001, Proc. ICA, P675
   Xiaoyi Yu, 2004, Proceedings. Third International Conference on Image and Graphics, P333
   Xu B, 2007, SNPD 2007: Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, Vol 3, Proceedings, P815, DOI 10.1109/SNPD.2007.465
   Yan Y, 2013, APPL MECH MATER, V278-280, P1906, DOI 10.4028/www.scientific.net/AMM.278-280.1906
NR 26
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5825
EP 5843
DI 10.1007/s11042-014-1890-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100022
DA 2024-07-18
ER

PT J
AU Afrakhteh, M
   Moon, I
   Lee, JA
AF Afrakhteh, Masoud
   Moon, Inkyu
   Lee, Jeong-A
TI Double phase modular steganography with the help of error images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JPEG image quality factors; Error image; Ensemble classifier;
   Information hiding; Steganography
ID DIGITAL IMAGES; STEGANALYSIS
AB Many steganographic schemes based on popular least significant bit (LSB) embedding have been proposed. The embedding procedure is totally independent of pixel values due to the fact that only the LSB has to be altered. Other methods either randomly increment/decrement the pixel value or use a function to do so. Because of this, the maximum embedding capacity cannot exceed 1 bit per pixel (bpp). State-of-the-art steganographic schemes, such as edge adaptive (EA) and highly undetectable stego (HUGO), aim at such LSB-based approaches with the help of LSB-matching algorithms and, unlike classical steganography, are more concerned about the undetectability level of the stego image rather than the peak signal-to-noise ratio (PSNR) of the stego images. There is a trade-off between detectability and the embedding rate of the stego images. The larger the embedding rate, the higher the chance of detectability, and the opposite is also true. On the other hand, classical steganographic approaches aim for maximum embedding capacity (say 4 bpp) while their main ability is to provide greater PSNR values rather than undetectability. In this work, a novel modular steganographic scheme is proposed in a spatial domain that takes advantage of error images resulting from applying an image quality factor (the same as the ones used in JPEG compression) in order to find the pixels where the secret data could be embedded. We show that our proposed method is less detectable compared to the EA method. The proposed method is almost as undetectable as HUGO. The detectability level is evaluated by the most recent state-of-the-art steganalysis attack, called ensemble classifiers, with second-order subtractive pixel adjacency model features given as their input. In addition, the proposed method can embed up to 4 bpp, yet maintain a high PSNR value.
C1 [Afrakhteh, Masoud; Moon, Inkyu; Lee, Jeong-A] Chosun Univ, Dept Comp Engn, Gwangju, South Korea.
C3 Chosun University
RP Lee, JA (corresponding author), Chosun Univ, Dept Comp Engn, Gwangju, South Korea.
EM masoudafrakhteh@gmail.com; inkyu.moon@chosun.ac.kr; jalee@chosun.ac.kr
FU Chosun University
FX This study was supported by research funds from Chosun University, 2014.
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   Bas P., 2011, INFORM HIDING
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2006, INFORM SCIENCES, V176, P3393, DOI 10.1016/j.ins.2006.02.008
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen SK, 2011, COMPUT STAND INTER, V33, P367, DOI 10.1016/j.csi.2010.11.002
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Ker AD, 2005, INFORM HIDING
   Li XL, 2013, SIGNAL PROCESS, V93, P2529, DOI 10.1016/j.sigpro.2013.03.029
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Noda H, 2002, IEEE SIGNAL PROC LET, V9, P410, DOI 10.1109/LSP.2002.806056
   Parah SA, 2012, J INF ENG APPL, V2, P1
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Soleimani SR, 2013, INT J EMERG TRENDS S, V1, P9
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Westfeld A, 2000, INFORM HIDING
   Zeki Akram M., 2011, Information Technology Journal, V10, P1367, DOI 10.3923/itj.2011.1367.1373
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 22
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4833
EP 4847
DI 10.1007/s11042-013-1844-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400018
DA 2024-07-18
ER

PT J
AU Lin, ZJ
   Ding, GG
   Hu, MQ
AF Lin, Zijia
   Ding, Guiguang
   Hu, Mingqing
TI Image auto-annotation via tag-dependent random search over
   range-constrained visual neighbours
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image auto-annotation; TagSearcher; Tag-dependent random search;
   Range-constrained visual neighbours
AB The quantity setting of visual neighbours can be critical for the performance of many previously proposed visual-neighbour-based (VNB) image auto-annotation methods. And in those methods, each candidate tag of a to-be-annotated image would be better to have its own trustworthy part of visual neighbours for score prediction. Hence in this paper we propose to use a constrained range rather than an identical and fixed number of visual neighbours for VNB methods to allow more flexible choices of neighbours, and then put forward a novel tag-dependent random search process to estimate the tag-dependent trust degrees of visual neighbours for each candidate tag. We further propose an effective image auto-annotation method termed TagSearcher based on a widely-used conditional probability model for auto-annotation, considering image-dependent weights of visual neighbours, tag-dependent trust degrees of visual neighbours and votes for a candidate tag from visual neighbours. Extensive experiments conducted on both a benchmark dataset and real-world web images present that the proposed TagSearcher can yield inspiring annotation performance and also reduce the performance sensitivity to the quantity setting of visual neighbours.
C1 [Lin, Zijia] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Ding, Guiguang] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
   [Hu, Mingqing] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
C3 Tsinghua University; Tsinghua University; Chinese Academy of Sciences;
   Institute of Computing Technology, CAS
RP Lin, ZJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM linzijia07@tsinghua.org.cn; dinggg@tsinghua.edu.cn; humingqing@ict.ac.cn
RI Ding, Guiguang/KIL-3528-2024
FU National Basic Research Project of China [2011CB707000]; National
   Natural Science Foundation of China [61271394, 61005045]
FX This research was supported by the National Basic Research Project of
   China (Grant No. 2011CB707000) and the National Natural Science
   Foundation of China(Grant No. 61271394, 61005045).
CR [Anonymous], 2013, A focus on efficiency: A whitepaper from facebook, ericsson and qualcomm
   [Anonymous], 2008, P 16 ACM INT C MULT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Chen X, 2010, P 19 ACM INT C INF K
   Duygulu P, 2002, P 7 EUR C COMP VIS
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hauptmann AG, 2005, P 4 INT C IM VID RET
   Jeon J, 2003, P 26 INT ACM SIGIR C
   Jiang J, 1997, INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, 1997 DIGEST OF TECHNICAL PAPERS, P94
   Ke X, 2012, MULTIMED TOOLS APPL, V61, P195, DOI 10.1007/s11042-010-0706-9
   Lavrenko V., 2003, NIPS
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li X, 2009, P IEEE INT C AC SPEE
   LI X, 2006, P 14 ANN ACM INT C M
   Li Z, 2010, P INT C MULT
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Liu J, 2006, P 8 ACM INT WORKSH M
   Liu J, 2007, P 15 INT C MULT
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Makadia A., 2008, P 10 EUR C COMP VIS
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Sigurbjornsson B., 2008, Proceeding of the 17th International Conference on World Wide Web
   WANG C, 2006, P 14 ANN ACM INT C M
   WANG C., 2009, P IEEE C COMP VIS PA
   Wang F, 2006, P 23 INT C MACH LEAR
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang H, 2009, IEEE 12 INT C COMP V
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Xu X.-S., 2011, P 19 ACM INT C MULT
   Zhang S, 2010, P IEEE C COMP VIS PA
NR 35
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 4091
EP 4116
DI 10.1007/s11042-013-1811-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800022
DA 2024-07-18
ER

PT J
AU Lee, J
   Kim, S
   Kim, SJ
AF Lee, Jung
   Kim, Seokhun
   Kim, Sun-Jeong
TI Mesh segmentation based on curvatures using the GPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mesh segmentation; Discrete curvatures; Quick shift; GP-GPU programming;
   CUDA
ID APPROXIMATION
AB This paper proposes an efficient algorithm for decomposition of a 3D arbitrary triangular mesh into surface patches. Our method is based on the discrete curvatures for an accurate partitioning criterion and presents a fast clustering scheme of vertices using quick shift algorithm. It was implemented on the GPU (Graphics Processing Unit) because it is common for object geometry to exist in graphic memory so that more computational work is done directly on the graphic device. The proposed method results in fast estimation of curvatures and high quality of mesh segmentation. Also we applied it to NPR drawing of 3D meshes.
C1 [Lee, Jung] Korea Univ, Dept Informat & Commun, Seoul 136701, South Korea.
   [Kim, Seokhun] Suwon Womens Univ, Dept Mobile Media, Suwon 441748, Gyeonggi Do, South Korea.
   [Kim, Sun-Jeong] Hallym Univ, Dept Ubiquitous Comp, Chuncheon Si 200702, Gangwon Do, South Korea.
C3 Korea University; Hallym University
RP Kim, SJ (corresponding author), Hallym Univ, Dept Ubiquitous Comp, 1 Hallymdaehak Gil, Chuncheon Si 200702, Gangwon Do, South Korea.
EM airjung@gmail.com; shkim1@swc.ac.kr; sunkim@hallym.ac.kr
FU National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [2011-0015072, NRF-2013R1A1A2011602]; Hallym
   University [HRF-201309-019]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (No. 2011-0015072,
   NRF-2013R1A1A2011602). This research was supported by Hallym University
   Research Fund (HRF-201309-019).
CR Abidi M, 2003, COMPUTER VISION PATT
   Attene M, 2006, SHAPE MODELING INT
   Batagelo HC, 2007, VISUAL COMPUT, V23, P803, DOI 10.1007/s00371-007-0133-8
   Chen LJ, 2006, MULTIMED TOOLS APPL, V29, P109, DOI 10.1007/s11042-006-0002-x
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Fulkerson B, 2010, P EUR C COMP VIS 201
   Griffin W, 2011, P INT 3D GR IN PRESS
   Kaplansky L, 2009, COMPUT GRAPH FORUM, V28, P1995, DOI 10.1111/j.1467-8659.2009.01578.x
   Lavoué G, 2005, COMPUT AIDED DESIGN, V37, P975, DOI 10.1016/j.cad.2004.09.001
   Rusinkiewicz S., 2004, P 3D DAT PROC VIS TR
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Vedaldi A, 2008, P EUR C COMP VIS 200
   Vieira M, 2005, COMPUT AIDED GEOM D, V22, P771, DOI 10.1016/j.cagd.2005.03.006
   Wu JH, 2005, COMPUT GRAPH FORUM, V24, P277, DOI 10.1111/j.1467-8659.2005.00852.x
   Yamauchi H, 2005, VISUAL COMPUT, V21, P659, DOI 10.1007/s00371-005-0319-x
   Yamauchi H, 2005, SHAPE MODELING INT
NR 16
TC 10
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3401
EP 3412
DI 10.1007/s11042-014-2104-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000011
DA 2024-07-18
ER

PT J
AU Varalakshmi, R
   Uthariaraj, VR
AF Varalakshmi, R.
   Uthariaraj, V. Rhymend
TI Huffman based conditional access system for key distribution in digital
   TV multicast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multicast key distribution scheme; Huffman grouping scheme; Conditional
   access system; Digital TV multicast; Fast Fourier transform; Extended
   Euclidean algorithm
ID MANAGEMENT
AB The advance of modern network technologies has made Digital TV systems available throughout the world. To provide secure media delivery in Digital TV systems, a large number of messages are exchanged for key updates in the conventional key distributed schemes of conditional access systems (CAS). In this paper, proposed a new multicast key distribution scheme based on Huffman grouping scheme of access control for conditional access system (CAS) in digital television multicast. The proposed key distribution scheme can greatly reduce the computation using fast Fourier transform and acquire higher efficiency and security using extended Euclidean algorithm. With this scheme, only authorized subscribers can watch the subscriber programs correctly. Unauthorized subscribers have no information to retrieve the correct programs over the networks. Moreover, the proposed scheme is more flexible in processing subscribers joining and leaving which is achieved by using Huffman based grouping scheme and is very important for service provider to dynamic manage the subscriber.
C1 [Varalakshmi, R.] Anna Univ, Ramanujan Comp Ctr, Network Secur, Madras 600025, Tamil Nadu, India.
   [Uthariaraj, V. Rhymend] Anna Univ, Ramanujan Comp Ctr, Madras 600025, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Anna University; Anna
   University Chennai
RP Varalakshmi, R (corresponding author), Anna Univ, Ramanujan Comp Ctr, Network Secur, Madras 600025, Tamil Nadu, India.
EM rvaralakshmi697@gmail.com
RI varalakshmi, vajja/AAE-1137-2022
OI varalakshmi, vajja/0000-0003-1329-5189
CR Akl S.G., 1982, ADV CRYPTOLOGY P CRY, P237
   Antequera N, 2011, P 7 INT C NEXT GEN W, P201
   Chan KC, 2003, IEEE NETWORK, V17, P30, DOI 10.1109/MNET.2003.1233915
   Conditional Access Broadcasting Systems, 1992, COND ACC BROADC SYST
   EBU Project Group B/ CA, 1995, EBU TECH REV, P64
   Harn L., 1990, Computers & Security, V9, P539, DOI 10.1016/0167-4048(90)90132-D
   Jiang T, 2004, IEEE T CONSUM ELECTR, V50
   LEE JW, 1996, P INT C CRYPT INF SE, P82
   MACQ BM, 1995, P IEEE, V83, P944, DOI 10.1109/5.387094
   Naranjo JAM, 2012, J COMPUT APPL MATH, V236, P3042, DOI 10.1016/j.cam.2011.02.015
   Peinado A, 2011, LECT NOTES COMPUT SC, V6694, P177, DOI 10.1007/978-3-642-21323-6_22
   Rcz S, 1967, COMMUN AGM, V10, P647
   Sakakibara H., 1994, Proceedings. 1994 International Conference on Network Protocols (Cat. No.94TH8002), P91, DOI 10.1109/ICNP.1994.344372
   Scott M, 1990, CA0790 DUBL CIT U
   St Denis Tom, 2003, BIGNUM MATH IMPLEMEN
   Trappe W, 2003, IEEE T MULTIMEDIA, V5, P544, DOI 10.1109/TMM.2003.813279
   Trappe Wade, 2007, INTRO CRYPTOGRAPHY C, P66
   Tu FK, 1998, 1998 IE INT S CONS E, V45, P151
   Varalakshmi R., 2011, IEEE INT C REC TREND
   Zhu S, 2010, NETWORK SECURITY, P57, DOI 10.1007/978-0-387-73821-5_3
NR 20
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 2899
EP 2912
DI 10.1007/s11042-013-1753-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800003
DA 2024-07-18
ER

PT J
AU Ai, N
   Peng, JY
   Zhu, X
   Feng, XY
AF Ai, Na
   Peng, Jinye
   Zhu, Xuan
   Feng, Xiaoyi
TI SISR via trained double sparsity dictionaries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution (SISR); Double sparsity; Trained
   dictionary pair; K-SVD algorithm
ID IMAGE SUPERRESOLUTION
AB In this paper we present an improved method for single image super-resolution (SISR). The improvement of our method is mainly attributed to the features that we used to train dictionary are wavelets of low resolution (LR) image(s) rather than the first and second derivatives as proposed by Zeyde et al. (2012). As a result, our trained dictionary pair has the property of double sparsity. That means our method can use relatively small training data set to obtain the dictionary with better adaptability to variant natural images. A number of comparison experiments on true images show our method achieves better generalization ability than that proposed in Zeyde et al. (2012).
C1 [Ai, Na; Peng, Jinye; Feng, Xiaoyi] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
   [Ai, Na; Peng, Jinye; Zhu, Xuan] NW Univ Xian, Sch Informat & Technol, Xian 710127, Peoples R China.
C3 Northwestern Polytechnical University; Northwest University Xi'an
RP Ai, N (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
EM aina_008@163.com; pjy@nwu.edu.cn; xuan_zhu@126.com; fengxiao@nwpu.edu.cn
RI Peng, Jin/HZH-6965-2023
FU Science Foundation of Northwest University [ND10010]
FX This work was supported by Science Foundation of Northwest University
   (ND10010).
CR Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 9
TC 3
Z9 4
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1997
EP 2007
DI 10.1007/s11042-013-1736-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500014
DA 2024-07-18
ER

PT J
AU He, XJ
   Choi, KS
AF He, Xue-Jian
   Choi, Kup-Sze
TI Using analytical force model for efficient deformation simulation and
   haptic rendering of soft objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deformation simulation; Soft object; Analytical force model; Haptic
   rendering
ID TISSUE DEFORMATION; FRAMEWORK; SURGERY; FEM
AB High refresh rate required for haptic rendering has been an issue in immersive virtual-reality based simulation. It prohibits the use of physically accurate yet computationally intensive force models. In the paper, we propose to adopt analytical force model to render feedback forces during interactive simulation of soft-object deformation, which allows force computation to be executed directly in the 1 kHz haptic servo loop. The force model is explicitly expressed by the size and shape of tool-tip and the physical properties of materials. On the other hand, graphics rendering of the resulted deformation is achieved with efficient geometric modeling, where the size of the deformed region is calibrated with simulated deformation calculated using the finite element method (FEM) to guarantee physical accuracy. Experimental results demonstrate that the forces rendered by the analytical force model are comparable to that of FEM simulation. The proposed approach has the potential to be an alternative approach to interactive deformation simulation of soft objects in virtual reality applications.
C1 [He, Xue-Jian; Choi, Kup-Sze] Hong Kong Polytech Univ, Sch Nursing, Ctr Smart Hlth, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP He, XJ (corresponding author), Hong Kong Polytech Univ, Sch Nursing, Ctr Smart Hlth, Hong Kong, Hong Kong, Peoples R China.
EM hexuejian@gmail.com
OI Choi, Kup-Sze/0000-0003-0836-7088
FU Research Grants Council of Hong Kong SAR [PolyU 5134/12E, 5152/09E];
   Hong Kong Polytechnic University [87RF]
FX This work was supported in part by the Research Grants Council of Hong
   Kong SAR (Project No. PolyU 5134/12E, 5152/09E) and the Hong Kong
   Polytechnic University (Project Account Code 87RF).
CR Abdelrahman W, 2012, EFFICIENT HAPTIC REN
   Allard J, 2007, STUD HEALTH TECHNOL, V125, P13
   Alterovitz R., 2002, COMP ALGORITHMS SOFT, P42
   [Anonymous], ASME DYN SYST CONTRO
   Bianchi G, 2004, LECT NOTES COMPUT SC, V3217, P293
   Bro-Nielsen M., 1996, Computer Graphics Forum, V15, pC57, DOI 10.1111/1467-8659.1530057
   COLGATE JE, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P140, DOI 10.1109/IROS.1995.525875
   Comas O, 2008, LECT NOTES COMPUT SC, V5104, P28, DOI 10.1007/978-3-540-70521-5_4
   Courtecuisse H, 2010, PROG BIOPHYS MOL BIO, V103, P159, DOI 10.1016/j.pbiomolbio.2010.09.016
   Courtecuisse Hadrien., 2011, ACM SIGGRAPH 2011 Computer Animation Festival, P98
   Delingette H, 2008, LECT NOTES COMPUT SC, V5104, P40, DOI 10.1007/978-3-540-70521-5_5
   Deo D, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P30, DOI 10.1109/WHC.2009.4810896
   Duysak A, 2003, INT CONGR SER, V1256, P337, DOI 10.1016/S0531-5131(03)00423-0
   Felippa CA., 2000, SYSTEMATIC APPROACH
   Fong P, 2009, INT J ROBOT RES, V28, P630, DOI 10.1177/0278364908100326
   Hamza-Lup Felix G, 2012, Stud Health Technol Inform, V173, P156
   Kachanov M.L., 2003, Handbook of Elasticity Solutions
   Lloyd J., 2012, Soft tissue biomechanical modeling for computer assisted surgery. Studies in Mechanobiology, P355, DOI DOI 10.1007/8415_2012_126
   Luciano C.J., 2007, 3 ANN IEEE C AUTOMAT, P146
   Mafi R, 2010, IEEE T HAPTICS, V3, P211, DOI [10.1109/TOH.2009.50, 10.1109/ToH.2009.50]
   Marchal M, 2008, LECT NOTES COMPUT SC, V5104, P176, DOI 10.1007/978-3-540-70521-5_19
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Meier U, 2005, COMPUT METH PROG BIO, V77, P183, DOI 10.1016/j.cmpb.2004.11.002
   Milliron T, 2002, ACM T GRAPHIC, V21, P20, DOI 10.1145/504789.504791
   Moustakas K, 2007, IEEE T VIS COMPUT GR, V13, P80, DOI 10.1109/TVCG.2007.20
   Natsupakpong S, 2010, GRAPH MODELS, V72, P61, DOI 10.1016/j.gmod.2010.10.001
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Pai DK, 2001, COMP GRAPH, P87, DOI 10.1145/383259.383268
   PANG XD, 1991, PERCEPT PSYCHOPHYS, V49, P531, DOI 10.3758/BF03212187
   Piegl LA, 1998, COMPUT AIDED DESIGN, V30, P11, DOI 10.1016/S0010-4485(97)00047-X
   Ruspini D. C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P345, DOI 10.1145/258734.258878
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Sederberg TN, 2003, ACM T GRAPHIC, V22, P477, DOI 10.1145/882262.882295
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Ullrich S., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P39, DOI 10.1109/3DUI.2011.5759215
   Wang P, 2007, COMPUT STRUCT, V85, P331, DOI 10.1016/j.compstruc.2006.11.021
   Yang XD, 2008, LECT NOTES COMPUT SC, V5024, P355, DOI 10.1007/978-3-540-69057-3_45
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 38
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1823
EP 1844
DI 10.1007/s11042-013-1720-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Fu, ZX
   Yu, B
AF Fu, Zhengxin
   Yu, Bin
TI Optimal pixel expansion of deterministic visual cryptography scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Deterministic; Necessary condition; Pixel expansion
ID SECRET SHARING SCHEMES; CONSTRUCTION
AB The optimal pixel expansion is an important parameter of deterministic visual cryptography scheme (DVCS). There are many researches have been done under different access structures and stacking operations. However, any necessary or sufficient condition has not been found about the optimal pixel expansion. In this paper, we give a necessary condition of the optimal pixel expansion of DVCS for the first time, which is suitable for any access structure and any stacking operation. Furthermore, a pixel expansion optimization algorithm has been designed to improve the existing schemes. It is found that the pixel expansion can be reduced for most DVCS based on XOR operation. Finally, we give some experimental results and comparisons to show the effectiveness of the proposed scheme.
C1 [Fu, Zhengxin; Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Peoples R China.
C3 PLA Information Engineering University
RP Fu, ZX (corresponding author), Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Peoples R China.
EM fzx2515@163.com; byu2009@163.com
RI Fu, Zhengxin/AAD-7881-2019
OI Fu, Zhengxin/0000-0001-8587-0942
FU National Natural Science Foundation of China [61070086]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work was supported by National Natural Science
   Foundation of China under Grant No. 61070086.
CR [Anonymous], P 16 ANN INT CRYPT C
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Biham E, 1997, DAGST SEM CRYPT
   Blakley GR, 1979, P NAT COMP C AM FED, V48, P242
   Cimato S, 2007, THEOR COMPUT SCI, V374, P261, DOI 10.1016/j.tcs.2007.01.006
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   De Prisco R, 2011, LECT NOTES COMPUT SC, V6673, P182, DOI 10.1007/978-3-642-20728-0_17
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Katoh T, 1998, ELECTRON COMM JPN 3, V81, P55, DOI 10.1002/(SICI)1520-6440(199807)81:7<55::AID-ECJC7>3.0.CO;2-#
   Lee KH, 2011, OPT COMMUN, V284, P2730, DOI 10.1016/j.optcom.2011.01.077
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Tuyls P, 2004, LECT NOTES COMPUT SC, V2802, P271
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Yan WQ, 2012, DIGIT IMAG COMPUT, P381
   Yang CN, 2008, COMPUT J, V51, P710, DOI 10.1093/comjnl/bxm118
   Yang CN, 2006, LECT NOTES COMPUT SC, V3989, P433
   Yang CN, 2010, OPT COMMUN, V283, P4949, DOI 10.1016/j.optcom.2010.07.051
   Yang CN, 2005, IEICE T FUND ELECTR, VE88A, P2471, DOI 10.1093/ietfec/e88-a.9.2471
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 26
TC 14
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1177
EP 1193
DI 10.1007/s11042-013-1625-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200006
DA 2024-07-18
ER

PT J
AU Yeh, CH
   Tseng, WY
   Chen, CY
   Lin, YD
   Tsai, YR
   Bi, HI
   Lin, YC
   Lin, HY
AF Yeh, Chia-Hung
   Tseng, Wen-Yu
   Chen, Chia-Yen
   Lin, Yu-Dun
   Tsai, Yi-Ren
   Bi, Hsuan-I
   Lin, Yu-Ching
   Lin, Ho-Yi
TI Popular music representation: chorus detection & emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Popular music; Chorus; Verse; MFCCs; Rhythm; Emotion; Adaboost
ID RETRIEVAL
AB This paper proposes a popular music representation strategy based on the song's emotion. First, a piece of popular music is decomposed into chorus and verse segments through the proposed chorus detection algorithm. Three descriptive features: intensity, frequency band and rhythm regularity are extracted from the structured segments for emotion detection. A hierarchical Adaboost classifier is employed to recognize the emotion of a piece of popular music. The general emotion of the music is classified according to Thayer's model into four emotions: happy, angry, depressed and relaxed. Experiments conducted on a 350-popular-music database show the average recall and precision of our proposed chorus detection are approximately 95% and 84 %, respectively; and the average precision rate of emotion detection is 92 %. Additional tests are performed on songs with cover versions in different lyrics and languages, and the resultant precision rate is 90 %. The proposes approaches have been tested and proven by the professional online music company, KKBOX Inc. and show promising performance for effectively and efficiently identifying the emotions of a variety of popular music.
C1 [Yeh, Chia-Hung; Tseng, Wen-Yu; Lin, Yu-Dun] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 80424, Taiwan.
   [Chen, Chia-Yen] Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung 81148, Taiwan.
   [Tsai, Yi-Ren; Bi, Hsuan-I] KKBOX Inc, Taipei 11503, Taiwan.
   [Lin, Yu-Ching] KKBOX Inc, Lab & Res, Taipei 11503, Taiwan.
   [Lin, Ho-Yi] KKBOX Inc, Content Dev, Taipei 11503, Taiwan.
C3 National Sun Yat Sen University; National University Kaohsiung
RP Chen, CY (corresponding author), Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung 81148, Taiwan.
EM yeh@mail.ee.nsysu.edu.tw; d983010033@student.nsysu.edu.tw;
   ayen@nuk.edu.tw; m973010067@student.nsysu.edu.tw; erictsai@kkbox.com;
   ericpi@kkbox.com; aaronlin@kkbox.com; kaorilin@kkbox.com
RI zhen, wang/KBA-3844-2024
FU KKBOX Inc.
FX This work was supported in part by KKBOX Inc. Our thanks to Wen-Hung Xu
   for executing the program on the test data in this work; his timely
   assistance is greatly appreciated.
CR AHALT SC, 1990, NEURAL NETWORKS, V3, P277, DOI 10.1016/0893-6080(90)90071-R
   [Anonymous], 2011, Handbook of music and emotion: Theory, research, applications
   [Anonymous], 2010, 11 INT SOC MUS INF R
   Bartsch MA, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P15, DOI 10.1109/ASPAA.2001.969531
   Blackburn S., 1998, Proceedings ACM Multimedia 98, P361, DOI 10.1145/290747.290802
   Bolte CE, 1984, SECRETS SUCCESSFUL S
   Cai R., 2007, P 15 ACM INT C MULT, P1065
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Chang CT, 2011, INT J REMOTE SENS, V32, P5035, DOI 10.1080/01431161.2010.494635
   Cheng HT, 2009, IEEE INT SYMP CIRC S, P1677, DOI 10.1109/ISCAS.2009.5118096
   Chin YH, 2013, 1ST INTERNATIONAL CONFERENCE ON ORANGE TECHNOLOGIES (ICOT 2013), P193, DOI 10.1109/ICOT.2013.6521190
   Cooper M, 2003, 2003 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS PROCEEDINGS, P127, DOI 10.1109/ASPAA.2003.1285836
   Cooper M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P378, DOI 10.1109/ICIP.2001.958130
   Cooper M., 2002, P 3 INT S MUSIC INFO, P81
   De Mulder T, 2006, IEEE T MULTIMEDIA, V8, P728, DOI 10.1109/TMM.2006.876291
   Deng JD, 2008, IEEE T SYST MAN CY B, V38, P429, DOI 10.1109/TSMCB.2007.913394
   Foote J, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P77, DOI 10.1145/319463.319472
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fujigara H, 2009, IEEE T AUDIO SPEECH, V18, P638
   Goto M, 2006, IEEE T AUDIO SPEECH, V14, P1783, DOI 10.1109/TSA.2005.863204
   GROSSBERG S, 1987, COGNITIVE SCI, V11, P23, DOI 10.1111/j.1551-6708.1987.tb00862.x
   Guizhi Li, 2004, Proceedings. Third International Conference on Image and Graphics, P104
   HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979
   Islam MK, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P317, DOI 10.1109/FSKD.2007.227
   Korhonen MD, 2006, IEEE T SYST MAN CY B, V36, P588, DOI 10.1109/TSMCB.2005.862491
   Kosugi N., 2000, Proceedings ACM Multimedia 2000, P333, DOI 10.1145/354384.354520
   Kosugi Naoko, 1999, P PACRIM 99 IEEE AUG, P404
   Kuo F, 2009, P INT S MULT, P613
   Lee SH, 2004, P SPIE EL IM STOR RE, P396
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   LOWRANCE R, 1975, J ACM, V22, P177, DOI 10.1145/321879.321880
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   MADDAGE NC, 2004, P 12 ANN ACM INT C M, P112, DOI DOI 10.1145/1027527.1027549
   McNab R. J., 1996, Proceedings of the 1st ACM International Conference on Digital Libraries, P11, DOI 10.1145/226931.226934
   Negus Keith., 1996, POPULAR MUSIC THEORY
   de León PJP, 2007, IEEE T SYST MAN CY C, V37, P248, DOI 10.1109/TSMCC.2006.876045
   RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5
   Schutz A, 2009, P 16 INT C DIG SIGN, P1
   Shiu Y, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P789, DOI 10.1109/ICME.2006.262956
   Stein Deborah., 2005, Engaging Music: Essays in Music Analysis
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   TSAI TH, 2006, INT CONF ACOUST SPEE, P505
   Tzacheva AA, 2010, LECT NOTES COMPUT SC, V6335, P212, DOI 10.1007/978-3-642-15470-6_23
   XU L, 1993, IEEE T NEURAL NETWOR, V4, P636, DOI 10.1109/72.238318
   Yang YH, 2012, ACM T INTEL SYST TEC, V3
   Yeh CH, 2010, P APSIPA ASC 2010
   Yeh CH, 2009, IEEE INT SYMP CIRC S, P1799, DOI 10.1109/ISCAS.2009.5118126
   Zhu Y, 2003, P INT C MULT EXP, P285
   [No title captured]
NR 49
TC 8
Z9 8
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2103
EP 2128
DI 10.1007/s11042-013-1687-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200045
DA 2024-07-18
ER

PT J
AU Youssef, SM
   Abou ElFarag, A
   Ghatwary, NM
AF Youssef, Sherin M.
   Abou ElFarag, Ahmed
   Ghatwary, Noha M.
TI Adaptive video watermarking integrating a fuzzy wavelet-based human
   visual system perceptual model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Fuzzy inference; Human visual system; Wavelet
   decomposition; Motion estimation
ID TRANSFORM; ALGORITHM; SCHEME; DOMAIN
AB An adaptive Fuzzy Inference Perceptual model has been proposed for watermarking of video streams. The model is designed to be adaptive to the human visual characteristics to attest the owner identification and discourage the unauthorized copying. The proposed model integrates the human visual characteristics of video motion sub-regions, in the frequency multi-resolution wavelet domain, with multi-dimensional fuzzy inference perceptual model. The designed fuzzy multi-variable input system inherits luminance, texture and gradient to generate an adaptive watermark embedding strength factor. Interacting motion estimation is applied for the selection of the candidate frames and sub-blocks. A fuzzy-based scheme has been proposed to generate a perceptual membership degree for strength watermark embedding factor for the selected candidate motion blocks. Experiments have been carried out with different benchmark test videos of different sizes, visual characteristics and sampling rates. Various sizes of watermark signatures have been applied on the model. Several experimental attacks have been applied such as frame dropping, frame averaging, JPEG compression, Gaussian noises. It manifests considerable robustness against various geometric and signal processing attacks. Several attacks have been applied to the proposed scheme and the experiments revealed promising results in terms of visual quality and extracted watermark distortion. In addition, the model has been compared with different other watermarking schemes in literature. The proposed model showed superior performance in terms of fidelity, robustness to attacks and high level of imperceptibility.
C1 [Youssef, Sherin M.; Abou ElFarag, Ahmed; Ghatwary, Noha M.] Arab Acad Sceince & Technol, Coll Comp Engn, Dept Comp Engn, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Arab Academy for Science, Technology &
   Maritime Transport
RP Youssef, SM (corresponding author), Arab Acad Sceince & Technol, Coll Comp Engn, Dept Comp Engn, Alexandria, Egypt.
EM sherin@aast.edu
OI Ghatwary, Noha/0000-0002-4019-479X
CR Al-Taweel Sadik Ali M., 2009, Journal of Computer Sciences, V5, P536, DOI 10.3844/jcssp.2009.536.543
   [Anonymous], FDN VISION
   Chimienti A, 2002, IEEE T IMAGE PROCESS, V11, P387, DOI 10.1109/TIP.2002.999673
   Coria LE, 2008, IEEE T INF FOREN SEC, V3, P466, DOI 10.1109/TIFS.2008.927421
   Den X, 2007, INT C COMP INT SEC
   Ejima M., 2000, INT C IM PROC, P678
   Essaouabi A, 2009, INT J VIDEO IMAGE PR, V9, P37
   Gaikwad M, 2012, INT J ADV RES COMPUT, V1, P68
   Gose E, 1996, PATTERN RECOGN, P298
   Huang H, 2009, C MACH VIS APPL MAY, P207
   Inoue H, 2000, IEICE T FUND ELECTR, VE83A, P90
   Jayamalar T., 2010, International Journal of Engineering Science and Technology, V2, P6963
   Kucukgoz M, 2005, P SOC PHOTO-OPT INS, V5681, P363, DOI 10.1117/12.587055
   Lande PU, 2010, INT J SIGNAL PROCESS, V3, P1
   Liang L.R., 2003, APPL SOFT COMPUT, V3, P123, DOI DOI 10.1016/S1568-4946(03)00008-5
   Lin Q, 2008, IEEE XPLOR, P229
   Marr D., 1982, Visual perception
   Masoumi M, 2012, INT J INNOVATION MAN, V3, P487
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikainem M., 2005, LECT NOTES COMPUT SC, P115
   Raghavendra K., 2010, IJCA, V4, P19, DOI [10.5120/863-1213, DOI 10.5120/863-1213]
   Rajab Lama., 2009, EUR J SCI RES, V30, P389
   Saade J. J., 2004, Iranian Journal of Electrical and Computer Engineering, V3, P161
   Sanghavi MR, 2011, INT J COMPUTER APPL, V35, P33
   Schyndel RG, 2004, P IC IP 94, V2, P86
   Tao PN, 2004, PROC SPIE, V5601, P133, DOI 10.1117/12.569641
   Vassaux B, 2002, PROCEEDINGS VIPROMCOM-2002, P239, DOI 10.1109/VIPROM.2002.1026662
   Wang LY, 2012, IEEE MULTIMEDIA, V19, P70, DOI 10.1109/MMUL.2011.76
   Wanson MS, 2006, MULTIMEDIA SIGNAL PR, P369
   Yassin NI., 2012, IJCSI inter J ComprSci, V9, P296
NR 30
TC 14
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1545
EP 1573
DI 10.1007/s11042-013-1515-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200020
DA 2024-07-18
ER

PT J
AU Maalouf, A
   Larabi, MC
   Nicholson, D
AF Maalouf, Aldo
   Larabi, Mohamed-Chaker
   Nicholson, Didier
TI Offline quality monitoring for legal evidence images in
   video-surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality; Video-surveillance; Monitoring; Tracking; Super-resolution;
   Sharpness metric
ID EDGE; RESOLUTION; BLUR
AB Video-surveillance attracted an important research effort in the last few years. Many works are dedicated to the design of efficient systems and the development of robust algorithms. video compression is a very important stage in order to ensure the viability of video-surveillance systems. However, it introduces some distortions decreasing significantly the detection, recognition and identification tasks for legal investigators. Fortunately, an important effort is made in terms of standard definition for video-surveillance in order to achieve to a complete interoperability. However, quality issues are still not addressed in an appropriate way. Investigators are often facing the dilemma of selecting the best match (legal evidence) of the targeted object in the video-sequence. In this paper, we propose an offline quality monitoring system for the extraction of most suitable legal evidence images for video-surveillance applications. This system is constructed around three innovative parts: First, a robust tracking algorithm based on foveal wavelet and mean shift. Second, a no-reference quality metric based on sharpness feature. Finally, a super-resolution algorithm allowing to increase the size of the tracked object without using any information outside the image itself. The combination of the proposed algorithms allowed the construction of a quality monitoring system increasing significantly the efficiency of the legal evidence image extraction.
C1 [Maalouf, Aldo; Larabi, Mohamed-Chaker] Univ Poitiers, Dept SIC, XLIM Lab, Poitiers, France.
   [Nicholson, Didier] Thales Commun & Syst, Thales, France.
C3 Universite de Poitiers; Thales Group
RP Larabi, MC (corresponding author), Univ Poitiers, Dept SIC, XLIM Lab, Poitiers, France.
EM chaker.larabi@univ-poitiers.fr
FU QuIAVU - French Research Agency
FX This work has been supported by the project QuIAVU funded by the French
   Research Agency.
CR ALLEBACH J, 1996, P IEEE INT C IM P
   [Anonymous], 2012, TARGET TRACKING MOVI
   [Anonymous], 2009, JTC1SC29WG1N5595 ISO
   [Anonymous], 2008, DVI01 ANSISIA OSIPS
   [Anonymous], 2007, PORTANT DEFINITION N
   [Anonymous], EDEN PROJECT MULTISE
   [Anonymous], 2012, 5013253 EN
   [Anonymous], 1996, NATL IMAGE INTERPRET
   [Anonymous], 2009, JTC1SC29WG1N5598 ISO
   [Anonymous], J144 ITUT
   [Anonymous], J149 ITUT
   [Anonymous], 2012, 22311 ISO
   Batten C.F., 2000, THESIS U CAMBRIDGE C
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   Carey WK, 1999, IEEE T IMAGE PROCESS, V8, P1293, DOI 10.1109/83.784441
   Caviedes J, 2004, SIGNAL PROCESS-IMAGE, V19, P147, DOI 10.1016/j.image.2003.08.002
   Cohen N, 2009, HOME OFFICE SCI DEV, V28/09
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DAVIS J, 2003, OTCBVS BENCHMARK DAT
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   ERASMUS SJ, 1982, J MICROSC-OXFORD, V127, P185, DOI 10.1111/j.1365-2818.1982.tb00412.x
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   FIRESTONE L, 1991, CYTOMETRY, V12, P195, DOI 10.1002/cyto.990120302
   FORD C, 2010, IEEE C MULT COMM SER
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Leachtenauer JC, 1997, APPL OPTICS, V36, P8322, DOI 10.1364/AO.36.008322
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Maalouf A, 2007, 15 EUR SIGN PROC C P
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   Mallat S., 2000, FOVEAL ORTHONORMAL W
   Mallat S, 2009, APPL COMPUT HARMON A, V26, P161, DOI 10.1016/j.acha.2008.03.004
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Muresan DD, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P323, DOI 10.1109/ICIP.2000.899374
   Ng KC, 2001, IEEE INT CONF ROBOT, P2791, DOI 10.1109/ROBOT.2001.933045
   Ning J, 2009, IJPRAI
   Patti AJ, 1997, IEEE T IMAGE PROCESS, V6, P1064, DOI 10.1109/83.605404
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Video quality in public safety working group, 2008, DEF VID QUAL REQ GUI, V1.0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang N., 2003, Proceedings of Section of Physical and Engineering Sciences of American Statistical Society, P4730
NR 46
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 189
EP 218
DI 10.1007/s11042-012-1268-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700010
DA 2024-07-18
ER

PT J
AU Xiang, ZJ
   Chen, QR
   Liu, YC
AF Xiang, Zong Jie
   Chen, Qiren
   Liu, Yuncai
TI Person re-identification by fuzzy space color histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-identification; Camera network; Gallery; Fuzzy space color histogram
AB In this paper we propose a new feature for person re-identification with or without the full gallery of persons: the Fuzzy Space Color Histogram. This feature contains both the space and color information, and is characterized by fuzzy quantization. We can optionally integrate our feature with Fuzzy Foreground when accurate segmentation is unavailable. Intensive experiments on three typical datasets have demonstrated that our method achieves promising results in real time.
C1 [Xiang, Zong Jie; Chen, Qiren; Liu, Yuncai] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University
RP Xiang, ZJ (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200030, Peoples R China.
EM zongzong_1984_111@hotmail.com; chenqiren1234@gmail.com;
   whomliu@sjtu.edu.cn
CR Alahi A, 2010, COMPUT VIS IMAGE UND, V114, P624, DOI 10.1016/j.cviu.2010.01.004
   [Anonymous], 2003, INT C COMP VIS
   Baltieri D, 2011, LECT NOTES COMPUT SC, V6978, P197, DOI 10.1007/978-3-642-24085-0_21
   Bauml M, 2010, IEEE INT C ADV VID S
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   D'Angelo A, 2011, P EL IM
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Gray Douglas, 2007, P IEEE INT WORKSH PE, V3, P1
   Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140
   Havasi L, 2005, IEEE IMAGE PROC, P3273
   Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226
   Javed O, 2005, PROC CVPR IEEE, P26
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Makris D, 2004, PROC CVPR IEEE, P205
   Oliveira I, 2009, IEEE INT C DEP AUT S
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Zheng E, 2009, IEEE C AC SPEECH SIG
   Zheng Wei Shi, 2011, IEEE C COMP VIS PATT
NR 21
TC 10
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 91
EP 107
DI 10.1007/s11042-012-1286-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700005
DA 2024-07-18
ER

PT J
AU Zhang, WG
   Liu, CX
   Wang, ZJ
   Li, GR
   Huang, QM
   Gao, W
AF Zhang, Weigang
   Liu, Chunxi
   Wang, Zhenjun
   Li, Guorong
   Huang, Qingming
   Gao, Wen
TI Web video thumbnail recommendation with content-aware analysis and
   query-sensitive matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video thumbnail; Image quality assessment; Image accessibility; Mutual
   reinforcement; Query-sensitive matching
ID IMAGE QUALITY ASSESSMENT
AB In this paper, a unified and adaptive web video thumbnail recommendation framework is proposed, which recommends thumbnails both for video owners and browsers on the basis of image quality assessment, image accessibility analysis, video content representativeness analysis and query-sensitive matching. At the very start, video shot detection is performed and the highest image quality video frame is extracted as the key frame for each shot on the basis of our proposed image quality assessment method. These key frames are utilized as the thumbnail candidates for the following processes. In the image quality assessment, the normalized variance autofocusing function is employed to evaluate the image blur and ensures that the selected video thumbnail candidates are clear and have high image quality. For accessibility analysis, color moment, visual salience and texture are used with a support vector regression model to predict the candidates' accessibility score, which ensures that the recommended thumbnail's ROIs are big enough and it is very accessible for users. For content representativeness analysis, the mutual reinforcement algorithm is adopted in the entire video to obtain the candidates' representativeness score, which ensures that the final thumbnail is representative enough for users to catch the main video contents at a glance. Considering browsers' query intent, a relevant model is designed to recommend more personalized thumbnails for certain browsers. Finally, by flexibly fusing the above analysis results, the final adaptive recommendation work is accomplished. Experimental results and subjective evaluations demonstrate the effectiveness of the proposed approach. Compared with the existing web video thumbnail generation methods, the thumbnails for video owners not only reflect the contents of the video better, but also make users feel more comfortable. The thumbnails for video browsers directly reflect their preference, which greatly enhances their user experience.
C1 [Zhang, Weigang; Gao, Wen] Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Peoples R China.
   [Liu, Chunxi; Wang, Zhenjun; Li, Guorong; Huang, Qingming] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Gao, Wen] Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
C3 Harbin Institute of Technology; Chinese Academy of Sciences; University
   of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences;
   Institute of Computing Technology, CAS; Peking University
RP Zhang, WG (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Peoples R China.
EM wgzhang@hit.edu.cn; qmhuang@jdl.ac.cn
RI Zhang, Weigang/GZA-9095-2022; Li, Guorong/AAG-1594-2020
OI Zhang, Weigang/0000-0003-0042-7074
FU National Basic Research Program of China (973 Program) [2012CB316400];
   National Natural Science Foundation of China [61025011, 61202322,
   61070108]
FX This work was supported in part by National Basic Research Program of
   China (973 Program): 2012CB316400, in part by National Natural Science
   Foundation of China: 61025011, 61202322 and 61070108.
CR [Anonymous], MIR 04
   Christel MG, 2006, PROC SPIE, V6073, DOI 10.1117/12.642841
   Chunxi Liu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2449, DOI 10.1109/ICIP.2011.6116155
   Dufaux F, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P275, DOI 10.1109/ICIP.2000.899354
   Gao YL, 2009, IEEE IMAGE PROC, P4333
   Gong YH, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1559, DOI 10.1109/ICME.2000.871066
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hua X, 2005, P IEEE INT C MULT EX, p[4, 6]
   Jiang JF, 2011, INT CONF ACOUST SPEE, P1417
   Li Y., 2001, HP2001191
   Liu C, 2006, ONL P TRECVID WORKSH, P2006
   Liu JJ, 2007, PROCEEDINGS OF THE 2007 CHINESE CONTROL AND DECISION CONFERENCE, P605, DOI 10.1145/1291233.1291380
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Mukherjee S, 2013, MULTIMED TOOLS APPL, V62, P847, DOI 10.1007/s11042-011-0882-2
   Niu YZ, 2012, MULTIMED TOOLS APPL, V56, P485, DOI 10.1007/s11042-010-0613-0
   Qing LY, 2002, LECT NOTES COMPUT SC, V2532, P799
   Santos A, 1997, J MICROSC-OXFORD, V188, P264, DOI 10.1046/j.1365-2818.1997.2630819.x
   Sun Y, 2004, MICROSC RES TECHNIQ, V65, P139, DOI 10.1002/jemt.20118
   SUU Design Studio, 2013, COMM SOFTW VID THUMB
   Tombros A., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P2, DOI 10.1145/290941.290947
   Torralba A, 2009, VISUAL NEUROSCI, V26, P123, DOI 10.1017/S0952523808080930
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang M, 2010, ACM T INTEL SYST TEC, V1, DOI 10.1145/1858948.1858956
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Weigang Zhang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P343, DOI 10.1109/IIH-MSP.2012.89
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Yong SP, 2013, MULTIMED TOOLS APPL, V62, P359, DOI 10.1007/s11042-011-0902-2
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 33
TC 13
Z9 18
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 547
EP 571
DI 10.1007/s11042-013-1607-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700026
DA 2024-07-18
ER

PT J
AU Kolivand, H
   Sunar, MS
AF Kolivand, Hoshang
   Sunar, Mohd Shahrizal
TI Covering photo-realistic properties of outdoor components with the
   effects of sky color in mixed reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interaction; Virtual environments; Mixed reality; Sky color
ID ILLUMINATION ESTIMATION; TRACKING; MODEL
AB Outdoor rendering is an attractive topic in computer graphics. In this paper our main concern is to reveal the interaction between sky color and virtual objects in Mixed Reality environments. Although registration and tracking are two of the main issues in building effective Augmented Reality (AR) systems the creation of more realistic virtual objects indistinguishable from their real-world counterparts is our target which is currently the ultimate goal in AR. Two classes of sky color generation are employed to reveal the outdoor-element interaction. Virtual Sky Modelling (VSM) based on the Perez Model is capable of generating the sky color in a specific location, date and time. The second technique is to generate a virtual model based on the real image of the sky which is called in this paper Real Sky Modelling (RSM). Subsequently, preprocessing of the sky color bleeding is based on the radiosity technique to give the sky color effect to the virtual objects as well as the real ones. Through designing a test AR set-up and applying software and hardware the goal of a robust generation of realistic virtual objects with effect of sky color is achieved.
C1 [Kolivand, Hoshang; Sunar, Mohd Shahrizal] Univ Teknol Malaysia, Fac Comp Sci & Informat Syst, Dept Comp Graph & Multimedia, UTM ViCubelab, Skudai Johor 81310, Malaysia.
C3 Universiti Teknologi Malaysia
RP Kolivand, H (corresponding author), Univ Teknol Malaysia, Fac Comp Sci & Informat Syst, Dept Comp Graph & Multimedia, UTM ViCubelab, Skudai Johor 81310, Malaysia.
EM shahinkey@yahoo.com
RI Sunar, Mohd Shahrizal/AFQ-7366-2022; Kolivand, Hoshang/F-4736-2011;
   Kolivand, Hoshang/B-2501-2016
OI Sunar, Mohd Shahrizal/0000-0002-0244-1622; Kolivand,
   Hoshang/0000-0001-5460-5679
FU FRGS grant at the UTMVicubeLab [Vot. J13000.7282.4F085]; Department of
   Computer Graphics and Multimedia; Faculty of Computer Science and
   Information Systems, Universiti Teknologi Malaysia
FX This research was supported by Vot. J13000.7282.4F085 FRGS grant at the
   UTMVicubeLab, Department of Computer Graphics and Multimedia, Faculty of
   Computer Science and Information Systems, Universiti Teknologi Malaysia.
CR Agusanto K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P208, DOI 10.1109/ISMAR.2003.1240704
   Azuma RT, 1999, MIXED REALITY, P379
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bimber O, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P198, DOI 10.1109/ISMAR.2003.1240703
   Bittner J, 2011, S INT 3D GRAPH GAM, P81
   Blinn J. F., 1982, Computer Graphics, V16, P21, DOI 10.1145/965145.801255
   Cohen M, 1993, RADIOSITY REALISTIC, P213
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Décoret X, 2005, COMPUT GRAPH FORUM, V24, P393, DOI 10.1111/j.1467-8659.2005.00864.x
   Dobashi Y, 1997, J VISUAL COMP ANIMAT, V8, P115, DOI 10.1002/(SICI)1099-1778(199703)8:2<115::AID-VIS165>3.0.CO;2-R
   Duan LY, 2009, SENSORS-BASEL, V9, P10097, DOI 10.3390/s91210097
   Fournier A., 1993, Proceedings Graphics Interface '93, P254
   Gibson S., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P219
   Goral C. M., 1984, Computers & Graphics, V18, P213
   Halawani SM, 2010, 4 INT C MATH AN MOD, P470
   Haller M., 2004, ACM International Conference on Virtual Reality Continuum and its Applications in Industry, P189, DOI [10.1145/1044588.1044627, DOI 10.1145/1044588.1044627]
   Haller M., 2003, Proceedings of the ACM symposium on Virtual reality software and technology, P56, DOI DOI 10.1145/1008653.1008665
   Iqbal M., 1983, An Introduction to Solar Radiation, P390, DOI DOI 10.1016/B978-0-12-373750-2.50006-9
   Jacobs K, 2006, COMPUT GRAPH FORUM, V25, P29, DOI 10.1111/j.1467-8659.2006.00816.x
   Jensen B, 2009, SIMPLIFYING REAL TIM
   Kaneda K., 1991, Visual Computer, V7, P247, DOI 10.1007/BF01905690
   KLASSEN RV, 1987, ACM T GRAPHIC, V6, P215, DOI 10.1145/35068.35071
   Köppen V, 2009, IETE TECH REV, V26, P350, DOI 10.4103/0256-4602.55278
   Kolivand H, 2011, INT J COMPUTER SCI I, V8, P80
   Kolivand H, 2012, TELKOMNIKA, V10, P171
   Kolivand H, 2012, LIFE SCI J, V9, P1039
   Kolivand H, 2012, INT J INNOV COMPUT I, V8, P7169
   Lin L, 2009, MULTIMED TOOLS APPL, V41, P235, DOI 10.1007/s11042-008-0227-y
   Liu YL, 2012, IEEE T VIS COMPUT GR, V18, P573, DOI 10.1109/TVCG.2012.53
   Liu YL, 2010, COMPUT ANIMAT VIRT W, V21, P321, DOI 10.1002/cav.357
   Liu YL, 2009, VISUAL COMPUT, V25, P637, DOI 10.1007/s00371-009-0342-4
   Loscos C, 2000, IEEE T VIS COMPUT GR, V6, P289, DOI 10.1109/2945.895874
   Madsen C, 2003, P 6 ANN INT WORKSH P
   Madsen C, 2008, PROBE LESS AUGMENTED
   Madsen CB, 2007, GRAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL GM/R, P252
   MAIR SG, 1994, COMPUT GRAPH, V28, P288
   Margetis G, 2013, MULTIMED TOOLS APPL, V67, P473, DOI 10.1007/s11042-011-0976-x
   Nakamae E., 1986, Computer Graphics, V20, P207, DOI 10.1145/15886.15909
   Neumann U., 1999, INT S MIX REAL
   Nishita T., 1996, Proceedings of the 23rd annual conference on Computer graphics and interactive techniques, P379
   Noh Z., 2010, ADV MULTIMEDIA AN IN, V1, P26
   PEREZ R, 1993, SOL ENERGY, V50, P235, DOI 10.1016/0038-092X(93)90017-I
   Preetham AJ, 1999, COMP GRAPH, P91, DOI 10.1145/311535.311545
   Ronnberg S, 2004, THESIS
   Shao MZ, 1993, GATHERING SHOOTING P
   Sheng Y, 2010, COMPUT GRAPH FORUM, V29, P387, DOI 10.1111/j.1467-8659.2009.01608.x
   State A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P429, DOI 10.1145/237170.237282
   Sugano N, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2003.1240690
   Sunar M, 2011, INT J SCI ENG RES, V2, P2229
   Sunar MS, 2001, ADV COMPUTER GRAPHIC, P37
   Sunkavalli K, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276504, 10.1145/1239451.1239552]
   Tadamura K., 1993, Comput. Graph. Forum, V12, P189, DOI [10.1111/1467-8659.1230189, DOI 10.1111/1467-8659.1230189]
   Veas E, 2012, IEEE T VIS COMPUT GR, V18, P565, DOI 10.1109/TVCG.2012.44
   Wallace J. R., 1989, Computer Graphics, V23, P315, DOI 10.1145/74334.74366
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
   Xing G, 2011, 12 INT C COMP AID DE, P43
   Xing GY, 2012, COMPUT GRAPH-UK, V36, P857, DOI 10.1016/j.cag.2012.07.005
   Yan F, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P771, DOI 10.1109/CISP.2008.87
NR 58
TC 11
Z9 12
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2143
EP 2162
DI 10.1007/s11042-013-1494-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300004
DA 2024-07-18
ER

PT J
AU Beyragh, AA
   Rahbar, AG
AF Beyragh, Ali Athari
   Rahbar, Akbar Ghaffarpour
TI IFCS: an intelligent fast channel switching in IPTV over PON based on
   human behavior prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; PON; Channel switching; User behavior
ID TIME
AB Channel switching time in IPTV services is a major parameter to satisfy IPTV users. As users receive their requested TV channels sooner, they will be highly satisfied. The switching time of channels in IPTV depends on many parameters such as user bandwidth and channel quality. Based on users' behaviors, Intelligent Fast Channel Switching (IFCS) technique is proposed in this paper to reduce the channel switching time in IPTV over Passive Optical Networks (PONs). The main idea of IFCS is to provide the channel traffic in advance for the user who wishes to watch the channel in the next few moments. Analyzing users behaviors and obtaining their preferences of watching channels, IFCS can reduce the waiting time of users by receiving their favorite channels traffic before their requests. This is possible by creation of users special favorite channels lists and then providing their favorite channels before their requests. Our performance evaluation results show that IFCS can decrease channel switching time at the expense of little increase in network overhead.
C1 [Beyragh, Ali Athari; Rahbar, Akbar Ghaffarpour] Sahand Univ Technol, Comp Networks Res Lab, Elect Engn Technol Res Ctr, Sahand New Town, Tabriz, Iran.
C3 Sahand University of Technology
RP Rahbar, AG (corresponding author), Sahand Univ Technol, Comp Networks Res Lab, Elect Engn Technol Res Ctr, Sahand New Town, Tabriz, Iran.
EM ali.athari@gmail.com; ghaffarpour@sut.ac.ir
RI athari, ali/AFM-0143-2022
OI Athari Beyragh, Ali/0000-0003-1148-3389; Ghaffarpour Rahbar,
   Akbar/0000-0002-0902-379X
FU Research Institute for ICT, Iran
FX This research is financially supported by Research Institute for ICT,
   Iran.
CR Ahmad MZ, 2009, INT CONF EMERG TECHN, P466, DOI 10.1109/ICET.2009.5353126
   Bikfalvi A, 2011, COMPUT NETW, V55, P1310, DOI 10.1016/j.comnet.2010.12.020
   Kim Y., 2008, INTEGRATED MODELING, P1
   Lee CY, 2010, IEEE T BROADCAST, V56, P321, DOI 10.1109/TBC.2010.2051494
   Lee Y, 2008, IEEE T CONSUM ELECTR, V54, P912, DOI 10.1109/TCE.2008.4560178
   Monteiro MMMDCF., 2009, A literacia em saude, P1, DOI 10.1155/2009/653481
   Nie YL, 2009, L N INST COMP SCI SO, V6, P280
   Ramos FMV, 2011, SIGNAL PROCESS-IMAGE, V26, P400, DOI 10.1016/j.image.2011.03.005
   Sarni M, 2009, ICNS: 2009 FIFTH INTERNATIONAL CONFERENCE ON NETWORKING AND SERVICES, P396, DOI 10.1109/ICNS.2009.52
   Siebert P, 2009, IEEE T BROADCAST, V55, P407, DOI 10.1109/TBC.2008.2012019
   Sue CC, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON UBIQUITOUS AND FUTURE NETWORKS, P131, DOI 10.1109/ICUFN.2009.5174299
   Uzunalioglu H, 2009, P CONS COMM NETW C 2, P1
   Van Wallendael G, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P136, DOI 10.1109/ISM.2009.35
   Wang JP, 2010, IEEE J SEL AREA COMM, V28, P875, DOI 10.1109/JSAC.2010.100812
   Xiao B., 2009, P INT C MAN SERV SCI, P1
   Young-Ho Song, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P815, DOI 10.1109/IIH-MSP.2009.12
NR 16
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1049
EP 1071
DI 10.1007/s11042-013-1414-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300003
DA 2024-07-18
ER

PT J
AU Bian, S
   Luo, WQ
   Huang, JW
AF Bian, Shan
   Luo, Weiqi
   Huang, Jiwu
TI Detecting video frame-rate up-conversion based on periodic properties of
   inter-frame similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Video forensics; Frame-rate up-conversion; Fake
   quality videos
ID MOTION ESTIMATION; INTERPOLATION; FORGERY
AB Video frame-rate up-conversion is one of the common operations for tampering digital videos in the temporal domain, such as creating fake high-quality videos and splicing two video clips with different frame rates. However, few existing works have been proposed for detecting this form of tampering operation. Based on the analysis of extensive experiments, we found that frame-rate up-conversion algorithms employed in most current video editing softwares will inevitably introduce some periodic artifacts into inter-frame similarity in the resulting video frame sequence. By analyzing such artifacts, we propose a simple yet very effective method to expose video after frame-rate up-conversion, and further estimate its original frame rate. The experimental results evaluated on 100 original videos at different frame rates have shown the effectiveness of the proposed method. The average detection accuracy can achieve as high as 99 % on noise-free videos in uncompressed and H.264/AVC formats. Besides, the proposed method is robust to noise as the detection accuracy could reach over 85 % and 95 % on noised videos with Gaussian white noise when SNR is 33 db and 36 db respectively.
C1 [Bian, Shan; Huang, Jiwu] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Luo, Weiqi] Sun Yat Sen Univ, Sch Software, Ghuangzhou 510006, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Luo, WQ (corresponding author), Sun Yat Sen Univ, Sch Software, Ghuangzhou 510006, Peoples R China.
EM bianshan.sysu@gmail.com; weiqi.luo@yahoo.com; isshjw@mail.sysu.edu.cn
RI huang, jw/KVY-9917-2024
FU 973 Program [2011CB302204]; NSFC [61272191, 61003243, 61173081];
   Zhujiang Science technology [2011J2200091]; Guangdong Natural Science
   Foundation [S2011020001215]
FX This work is supported by the 973 Program (2011CB302204), NSFC
   (61272191,61003243,61173081), Zhujiang Science & technology
   (2011J2200091), and Guangdong Natural Science Foundation
   (S2011020001215).
CR [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Bestagini P, 2012, INT CONF ACOUST SPEE, P2257, DOI 10.1109/ICASSP.2012.6288363
   Choi BT, 2000, IEEE T CONSUM ELECTR, V46, P603, DOI 10.1109/30.883418
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Liao D, 2011, P SOC PHOTO-OPT INS, V7880
   Luo W, 2008, P SOC PHOTO-OPT INS, V6819
   Luo Weiqi, 2007, Frontiers of Computer Science in China, V1, P166, DOI 10.1007/s11704-007-0017-0
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Ritchey PhilipC., 2012, Journal of Information Hiding and Multimedia Signal Processing, V3, P212
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weng S., 2012, JJIH MSP, V3, P320
   Yang R, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P117
NR 21
TC 18
Z9 21
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 437
EP 451
DI 10.1007/s11042-013-1364-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800020
DA 2024-07-18
ER

PT J
AU He, YC
   Lu, HT
   Xie, SN
AF He, Yangcheng
   Lu, Hongtao
   Xie, Saining
TI Semi-supervised non-negative matrix factorization for image clustering
   with graph Laplacian
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-negative matrix factorization; Clustering; Semi-supervised learning;
   Image clustering
AB Non-negative matrix factorization (NMF) plays an important role in multivariate data analysis, and has been widely applied in information retrieval, computer vision, and pattern recognition. NMF is an effective method to capture the underlying structure of the data in the parts-based low dimensional representation space. However, NMF is actually an unsupervised method without making use of supervisory information of data. In recent years, semi-supervised learning has received a lot of attentions, because partial label information can significantly improve learning quality of the algorithms. In this paper, we propose a novel semi-supervised non-negative matrix factorization (SEMINMF) algorithm, which not only utilizes the local structure of the data characterized by the graph Laplacian, but also incorporates the label information as the fitting constraints to learn. Hence, it can learn from labeled and unlabeled data. By this means our SEMINMF can obtain a more discriminative powerful representation space. Experimental results show the effectiveness of our proposed novel method in comparison to the state-of-the-art algorithms on several real world applications.
C1 [He, Yangcheng; Lu, Hongtao; Xie, Saining] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, MOE Microsoft Lab Intelligent Comp & Intelligent, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP He, YC (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, MOE Microsoft Lab Intelligent Comp & Intelligent, Shanghai 200240, Peoples R China.
EM h331076268@126.com
FU National Basic Research Program of China (973 program) [2009CB320901];
   NSFC [61272247]; National High Technology Research and Development
   Program of China (863 program) [2008AA02Z310]; National Natural Science
   Foundation of China [60873133]; Innovation Ability Special Fund of
   Shanghai Jiao Tong University [Z030026]
FX This work was supported in part by the National Basic Research Program
   of China (973 program) under Grant 2009CB320901, NSFC (no. 61272247),
   the National High Technology Research and Development Program of China
   (863 program) under Grant 2008AA02Z310, the National Natural Science
   Foundation of China under Grant 60873133, and the Innovation Ability
   Special Fund of Shanghai Jiao Tong University under Grant Z030026.
CR [Anonymous], P 5 CAT C ART INT
   [Anonymous], P 10 ACM SIGKDD INT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 1986, Matching theory
   [Anonymous], 24 AAAI C ART INT
   [Anonymous], IEEE T PATTERN ANAL
   BACH FR, 2003, LEARNING SPECTRAL CL
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chapelle O., 2006, SEMISUPERVISED LEARN, V2
   Chen YH, 2008, KNOWL INF SYST, V17, P355, DOI 10.1007/s10115-008-0134-6
   Chung F. R. K., 1997, Spectral graph theory
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Das Gupta Mithun, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2841, DOI 10.1109/CVPR.2011.5995492
   De la Torre F., 2006, P 23 INT C MACH LEAR, P241, DOI DOI 10.1145/1143844.1143875
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ding C., 2007, P 24 INT C MACH LEAR, P521
   Ding C, 2008, IEEE DATA MINING, P183, DOI 10.1109/ICDM.2008.130
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Kim J., 2008, Tech. Rep.
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee H, 2010, IEEE SIGNAL PROC LET, V17, P4, DOI 10.1109/LSP.2009.2027163
   Li T, 2006, IEEE DATA MINING, P362
   Lin T.C., 2007, International Journal of Computer Sciences and Engineering Systems, V1, P253
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Ma Z., 2011, Proc. 19th ACM Int'l Conf. Multimedia, P283, DOI DOI 10.1145/2072298.2072336
   Saul L., 1997, P 2 C EMPIRICAL METH, P81
   Shashua A., 2005, P 22 INT C MACH LEAR, P792, DOI [DOI 10.1145/1102351.1102451, 10.1145/1102351.1102451]
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wei Xu, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P202
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Yang Yi., 2011, Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI'11, P555
   Ye J., 2007, P 21 ANN C NEUR INF, V20, P1649
   Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361
   Zhang Y., 2008, IEEE C COMPUTER VISI, P1
   ZHANG Z., 2008, IEEE C COMPUTER VISI, P1
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 38
TC 9
Z9 9
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1441
EP 1463
DI 10.1007/s11042-013-1465-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300019
DA 2024-07-18
ER

PT J
AU Tian, ZQ
   Xue, JR
   Lan, XG
   Li, C
   Zheng, NN
AF Tian, Zhiqiang
   Xue, Jianru
   Lan, Xuguang
   Li, Ce
   Zheng, Nanning
TI Object segmentation and key-pose based summarization for motion video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph cuts; Key-poses; Shape clustering; Spatio-temporal; Video object
   segmentation; Video summarization
ID FRAMEWORK; FEATURES; LAYOUT; MODEL
AB This paper proposes a key-pose based video summarization system for a video shot facilitated by using a video object segmentation method. Firstly, we detect the camera motion and extract video objects by a 3D graph-based algorithm. Once the objects are obtained, each of them is represented by a shape descriptor. Secondly, in order to find representative frames which preserve scene content as much accurately as possible, the proposed method calculates difference between pairs of frames based on shape descriptors of objects in the video shot. Finally, key-poses (representative frames) are extracted in a global manner by clustering these shapes. Experimental results on motion video shots show that the proposed method outputs satisfactory summarizations.
C1 [Tian, Zhiqiang; Xue, Jianru; Lan, Xuguang; Li, Ce; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Tian, ZQ (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
EM tianzq@gmail.com
RI Lan, Xuguang/N-8814-2019; Xue, Jianru/N-3923-2014
OI Lan, Xuguang/0000-0002-3422-944X; 
FU National Basic Research Program of China (973 Program) [2010CB327902];
   NSFC [90920301, 61273252, 61175010]
FX This work was supported in part by the National Basic Research Program
   of China (973 Program) under Grant No. 2010CB327902, and the NSFC Nos.
   90920301, 61273252, and 61175010.
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   [Anonymous], 2008, P 2008 IEEE C COMP V
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], 2001, P IEEE INT C COMP VI
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2006, P EUR C COMP VIS
   Calic J, 2007, IEEE T CIRC SYST VID, V17, P931, DOI 10.1109/TCSVT.2007.897466
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   CRIMINISI A, 2006, P IEEE C COMP VIS PA
   Erol B, 2000, IEEE T MULTIMEDIA, V2, P129, DOI 10.1109/6046.845016
   Feng S, 2012, P IEEE C COMP VIS PA
   Ferman A, 1997, P C VIS COMM IM PROC
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gao Y, 2009, MULTIMED TOOLS APPL, V42, P233, DOI 10.1007/s11042-008-0236-x
   Gatica-Perez D, 2003, IEEE T CIRC SYST VID, V13, P539, DOI 10.1109/TCSVT.2003.813428
   Ghoniem M, 2007, P IEEE S VIS AN SCI
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guan G, 2012, IEEE T CIRCUITS SYST, V23, P729
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Herranz L, 2012, IEEE T MULTIMEDIA, V14, P1290, DOI 10.1109/TMM.2012.2192917
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Irani M, 1995, P IEEE INT C COMP VI
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P1128, DOI 10.1109/TCSVT.2002.806813
   Kim C, 2000, P ACM INT C MULT
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lee Y. J., 2011, P IEEE INT C COMP VI
   Lee YJ, 2012, P IEEE C COMP VIS PA
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   Li Z, 2009, IEEE T IMAGE PROCESS, V18, P2572, DOI 10.1109/TIP.2009.2026677
   Liu D, 2010, IEEE T PATTERN ANAL, V32, P2178, DOI 10.1109/TPAMI.2010.31
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Ngo C.-W., 2003, P IEEE INT C COMP VI
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Over P., 2007, P INT WORKSH TRECVID, P1
   OVER P, 2008, P INT WORKSH TRECVID
   Rasheed Z, 2005, IEEE T CIRC SYST VID, V15, P52, DOI 10.1109/TCSVT.2004.839993
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Silva LS, 2010, IEEE T IMAGE PROCESS, V19, P1036, DOI 10.1109/TIP.2009.2038778
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Taniguchi Y, 1997, P ACM INT C MULT
   Tian Z, 2011, P INT C IM PROC
   Tian Z, 2011, P ACM INT C MULT
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Valdés V, 2010, MULTIMED TOOLS APPL, V49, P7, DOI 10.1007/s11042-009-0392-7
   Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595
   Vazquez-Reina A, 2010, P EUR C COMP VIS
   Wang F, 2012, IEEE T MULTIMEDIA, V14, P76, DOI 10.1109/TMM.2011.2165531
   WERLBERGER M., 2009, BMVC, V1, P3
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Zhou H, 2010, P ACM INT C MULT
   Zhuang Y, 1998, P INT C IM PROC
NR 62
TC 6
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1773
EP 1802
DI 10.1007/s11042-013-1488-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300033
DA 2024-07-18
ER

PT J
AU Zhang, XP
   Sun, GL
   Shen, LQ
   Qin, C
AF Zhang, Xinpeng
   Sun, Guangling
   Shen, Liquan
   Qin, Chuan
TI Compression of encrypted images with multi-layer decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Image compression; Multi-layer construction
AB This work proposes a novel scheme of lossy compression for encrypted gray images. In the encryption phase, the original image is decomposed into a sub-image and several layers of prediction errors, and the sub-image and prediction errors are encrypted using an exclusive-or operation and a pseudo-random permutation, respectively. Although a channel provider does not know the cryptographic key and the original content, he can still effectively reduce the amount of encrypted data by quantizing the permuted prediction errors on various layers, and an optimization method with rate-distortion criteria can be employed to select the values of quantization steps. At receiver side with the knowledge of cryptographic key, a decoder integrating dequantization, decryption and image reconstruction functions is used to retrieve the principal content of original image from the compressed data. Experimental result shows the rate-distortion performance of the proposed scheme is significantly better than that of previous technique.
C1 [Zhang, Xinpeng; Sun, Guangling; Shen, Liquan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
   [Qin, Chuan] Shanghai Univ Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 Shanghai University; University of Shanghai for Science & Technology
RP Zhang, XP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 149 Yanchang Rd, Shanghai 200072, Peoples R China.
EM xzhang@shu.edu.cn
RI Qin, Chuan/C-1106-2017; Shen, Liquan/D-4832-2012
OI Qin, Chuan/0000-0002-0370-4623; 
FU National Natural Science Foundation of China [61073190]; Research Fund
   for the Doctoral Program of Higher Education of China [20113108110010];
   Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61073190, by the Research Fund for the Doctoral
   Program of Higher Education of China under Grant 20113108110010, and by
   the Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning.
CR [Anonymous], 2009, PROC TENCON 2009 IEE
   Bianchi T, 2010, IEEE T INF FOREN SEC, V5, P180, DOI 10.1109/TIFS.2009.2036230
   Bianchi T, 2009, IEEE T INF FOREN SEC, V4, P86, DOI 10.1109/TIFS.2008.2011087
   Erkin Z., 2007, EURASIP Journal on Information Security, V7, P1
   Gallager R., 1963, Ph.D. dissertation
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Lazzeretti R., 2008, P 16 EUR SIGN PROC C
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Lu WJ, 2009, INT CONF ACOUST SPEE, P1533, DOI 10.1109/ICASSP.2009.4959888
   Troncoso-Pastoriza JR, 2011, IEEE T INF FOREN SEC, V6, P469, DOI 10.1109/TIFS.2011.2109385
   Schonberg D., 2005, 43 ANN ALL C ALL IL
   Schonberg D, 2008, IEEE T INF FOREN SEC, V3, P749, DOI 10.1109/TIFS.2008.2007244
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
NR 14
TC 17
Z9 18
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 489
EP 502
DI 10.1007/s11042-013-1392-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800022
DA 2024-07-18
ER

PT J
AU Long, XZ
   Lu, HT
   Li, WB
AF Long, Xianzhong
   Lu, Hongtao
   Li, Wenbin
TI Image classification based on nearest neighbor basis vectors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Spatial pyramid matching; Scale-invariant feature
   transform; Nearest neighbor basis vector
ID KERNEL; SPARSE
AB Image classification can be roughly divided into two categories, i.e., scene recognition and object recognition. There are two important steps in object recognition: Dictionary Learning and Feature Coding. In order to get the best classification performance, the optimal dictionary learning method and feature coding strategy should be used simultaneously. However, researchers recently have found that feature coding was more important than dictionary learning when sparse coding scheme was employed. With a dictionary formed by a random sample of descriptors, satisfactory results were obtained. Inspired by the discovery, in this paper we propose an image classification method based on nearest neighbor basis vectors of the dictionary. Each descriptor of image is linearly represented by its several nearest neighbor basis vectors. We exploit the widely used Spatial Pyramid Matching model (SPM) in our paper and name our method Nearest Neighbor Basis Vectors Spatial Pyramid Matching (NNBVSPM). In the NNBVSPM, the dictionary is generated by standard k-means clustering algorithm and the feature is encoded by our soft inner product coding scheme. Experimental results on scene 15 dataset and uiuc sports event dataset show that the proposed scheme outperforms some state-of-the-art methods.
C1 [Long, Xianzhong; Lu, Hongtao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Li, Wenbin] Shanghai Jiao Tong Univ, Affiliated Peoples Hosp 6, Dept Diagnost & Intervent Radiol, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Long, XZ (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
EM lxz85@sjtu.edu.cn; lu-ht@cs.sjtu.edu.cn; liwenbin@sh163.net
FU National Basic Research Program of China (973 program) [2009CB320901];
   National High Technology Research and Development Program of China (863
   program) [2008AA02Z310]; National Natural Science Foundation of China
   [61272247]; Shanghai Committee of Science and Technology [08411951200];
   Innovation Ability Special Fund of Shanghai Jiao Tong University
   [Z030026]
FX This work is supported in part by the National Basic Research Program of
   China (973 program) under Grant 2009CB320901, the National High
   Technology Research and Development Program of China (863 program) under
   Grant 2008AA02Z310, the National Natural Science Foundation of China
   under Grant 61272247, the Shanghai Committee of Science and Technology
   under Grant 08411951200, and the Innovation Ability Special Fund of
   Shanghai Jiao Tong University under Grant Z030026.
CR [Anonymous], 2011, INT C MACH LEARN
   [Anonymous], 2004, WORKSH STAT LEARN CO
   [Anonymous], COMPUTATIONAL LEARNI
   [Anonymous], 2009, P ADV NEUR INF PROC
   Boiman O., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587598
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Harada T, 2011, PROC CVPR IEEE, P1617, DOI 10.1109/CVPR.2011.5995691
   Huang YZ, 2011, PROC CVPR IEEE, P1753, DOI 10.1109/CVPR.2011.5995682
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Kulkarni N, 2011, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2011.5995701
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li Fei-Fei, 2007, INT C COMPUTER VISIO, P1
   Li Y., 2008, 4 INT C WIRELESS COM, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moosmann F, 2007, Adv Neural Inf Process Syst, P985
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   Rublee E., 2011, INT C COMP VIS, P24, DOI DOI 10.1109/ICCV.2011.6126544
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
NR 30
TC 1
Z9 1
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1559
EP 1576
DI 10.1007/s11042-012-1289-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000026
DA 2024-07-18
ER

PT J
AU Golja, M
   Stojmenova, E
   Humar, I
AF Golja, Mitja
   Stojmenova, Emilija
   Humar, Iztok
TI Interactive TV user interfaces: how fast is too fast?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User interface; Navigation; Scrolling; Speed; Interactive TV
ID SERVICES; MODEL
AB The analysis presented in this paper is the search for optimal scrolling speeds of the user interface for interactive TV (iTV) navigation. The most popular navigation techniques for browsing through user interfaces usually incorporate scrolling. Furthermore, the latest set-top-boxes have enough processing power to support very fast scrolling, not only for texts, but also for photographs and other elements. We designed and performed an experiment to measure the optimal scrolling speed for different activities on a user interface. We found that the optimal speed depends on the type and complexity of the navigational elements (like text or graphics). We discovered that less-complex elements, such as numbered TV-channel names, tolerate much higher scrolling speeds than more-complex elements, such as graphical elements like movie posters. We also analyzed the impact of the direction of navigation (vertical, horizontal) on the optimal speeds and the results show no major impact on the graphical elements, while for the text elements the difference is obvious. The results of this study can improve the usability of the horizontal and vertical navigation techniques in modern iTV navigation.
C1 [Golja, Mitja] Iskratel Doo, SI-4000 Kranj, Slovenia.
   [Stojmenova, Emilija] Iskratel Doo, SI-2000 Maribor, Slovenia.
   [Humar, Iztok] Univ Ljubljana, Fac Elect Engn, Lab Telecommun, SI-1000 Ljubljana, Slovenia.
C3 University of Ljubljana
RP Golja, M (corresponding author), Iskratel Doo, Ljubljanska C 24a, SI-4000 Kranj, Slovenia.
EM golja@iskratel.si; stojmenova@iskratel.si; iztok.humar@fe.uni-lj.si
FU Slovenian Research Agency [P2-0246]
FX The authors would like to thank Gregor Fuis and Sergej Erzen for their
   help with the testing-environment preparation and all the participants
   who took part in the evaluation study. The research work was partly
   performed in the scope of research program P2-0246-Algorithms and
   optimization procedures in telecommunications, financed by the Slovenian
   Research Agency.
CR Aladwani AM, 2002, INFORM MANAGE-AMSTER, V39, P467, DOI 10.1016/S0378-7206(01)00113-6
   Blohm G, 2002, SMOOTH PURSUIT SYSTE
   Bowers AR, 2004, OPTOMETRY VISION SCI, V81, P205, DOI 10.1097/00006324-200403000-00013
   BURR D, 1980, NATURE, V284, P164, DOI 10.1038/284164a0
   Card S.K., 1983, The Psychology of Human-Computer Interaction", P23
   Eckert M, 1993, DIGITAL IMAGES HUMAN, P90
   Eslambolchilar P, 2008, INT J HUM-COMPUT ST, V66, P838, DOI 10.1016/j.ijhcs.2008.07.005
   Hwang W, 2010, COMMUN ACM, V53, P130, DOI 10.1145/1735223.1735255
   Igarashi T., 2000, UIST. Proceedings of the 13th Annual ACM Symposium on User Interface Software and Technology, P139, DOI 10.1145/354401.354435
   KINCHLA RA, 1970, PERCEPT PSYCHOPHYS, V8, P399, DOI 10.3758/BF03207033
   Lin JCC, 2000, INT J INFORM MANAGE, V20, P197, DOI 10.1016/S0268-4012(00)00005-0
   MORGAN MJ, 1989, NATURE, V340, P385, DOI 10.1038/340385a0
   Nielsen Jakob, 2000, WHY YOU ONLY NEED TE
   Obrist M, 2010, EUROITV 10 P 8 INT I
   Pogacnik M, 2005, USER MODEL USER-ADAP, V15, P425, DOI 10.1007/s11257-005-4065-6
   Pogacnik M, 2004, AEU-INT J ELECTRON C, V58, P402, DOI 10.1078/1434-8411-54100261
   Sedlar U, 2008, IEEE COMMUN MAG, V46, P118, DOI 10.1109/MCOM.2008.4463782
   Shin DH, 2009, BEHAV INFORM TECHNOL, V28, P361, DOI 10.1080/01449290701814232
   Skorin-Kapov L, 2007, IEEE COMMUN MAG, V45, P108, DOI 10.1109/MCOM.2007.382669
   Sterle J, 2011, IEEE COMMUN MAG, V49, P92, DOI 10.1109/MCOM.2011.5681021
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Volk M, 2008, IEEE COMMUN MAG, V46, P118, DOI 10.1109/MCOM.2008.4511660
   Wallace A., 2004, Proceedings o f 5th AUIC: Australasian User Interface Conference, P117
   Wikipedia, US EXP
   Wikipedia, OPT HDTV VIEW DIST
   Yin S, 2009, EFFECTS DIFFERENT DE
NR 26
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 61
EP 76
DI 10.1007/s11042-013-1365-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700004
DA 2024-07-18
ER

PT J
AU Ha, I
   Oh, KJ
   Hong, MD
   Lee, YH
   Rosli, AN
   Jo, GS
AF Ha, Inay
   Oh, Kyeong-Jin
   Hong, Myung-Duk
   Lee, Yeon-Ho
   Rosli, Ahmad Nurzid
   Jo, Geun-Sik
TI Ontology-driven visualization system for semantic searching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ontology-driven visualization; Semantic search; Ontology modeling;
   Ontology population; Technical manual
AB Technical manuals are very diverse, ranging from software to commodities, general instructions and technical manuals that deal with specific domains such as mechanical maintenance. Due to the vast amount of documentation, finding the information is a tedious and time consuming task, especially for the mechanics. It is also difficult to grasp relationships among contents in manuals. Many researchers have adopted ontology to solve these problems and semantically represent contents of manuals. However, if ontology becomes very large and complex, it is not easy to work with ontology. Visualization has been an effective way to grasp and manipulate ontology. In this research, we propose a new ontology model to represent and retrieve contents from the manuals. We have also designed a visualization system based on our proposed ontology. In order to model the ontology, we have analyzed aircraft maintenance process, extracted the concepts and defined relationships between concepts. After modeling ontology schema, all instances of ontology are created by instance creator. From here, raw data of maintenance manuals are preprocessed to well-formed format. Next, we create a set of rule mapping well-formed document and ontology schema. For the Component class, instance creator uses a classifier to separate all parts into Component and Primitive part class. If population task is complete, validity of data for created instances will be checked by JENA engine. The inference process will create inferred triples based on the ontology schema, and then the triples are saved into a triple repository. Our system then will use this triples repository to search necessary information and visualize the search results. We use the Prefuse toolkit to visualize the search results. With this, the mechanics can intuitively grasp the relationship between maintenance manuals using the provided information. This will allow the mechanics to easily obtain information for given tasks, reduce their time to search related information and understand the information through visualization.
C1 [Ha, Inay; Oh, Kyeong-Jin; Hong, Myung-Duk; Lee, Yeon-Ho; Rosli, Ahmad Nurzid] Inha Univ, Dept Informat Engn, Nam, Incheon, South Korea.
   [Jo, Geun-Sik] Inha Univ, Sch Comp & Informat Engn, Nam, Incheon, South Korea.
C3 Inha University; Inha University
RP Ha, I (corresponding author), Inha Univ, Dept Informat Engn, 253 Yonghyun, Nam, Incheon, South Korea.
EM inay@eslab.inha.ac.kr; okjkillo@eslab.inha.ac.kr;
   hmdgo@eslab.inha.ac.kr; yhlee@eslab.inha.ac.kr; nurzid@eslab.inha.ac.kr;
   gsjo@inha.ac.kr
RI , RedCarrot/AAE-6300-2019
OI , RedCarrot/0000-0001-9930-2655; Rosli, Ahmad Nurzid/0000-0003-0866-2204
CR Alani H., 2003, P KNOWL CAPT WORKSH
   [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   [Anonymous], 2008, SPARQL QUERY LANGUAG
   Boinski T., 2010, 2010 2nd International Conference on Information Technology (ICIT 2010), P17
   Candell O, 2009, ROBOT CIM-INT MANUF, V25, P937, DOI 10.1016/j.rcim.2009.04.005
   Catenazzi N, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P283, DOI 10.1109/IV.2009.34
   Chen YY, 2009, INT C INTEL HUM MACH, P66, DOI 10.1109/IHMSC.2009.142
   Crowder RM, 2009, IDETC 09 P ASME INT, P1333
   Dmitrieva J, 2007, P OWLED 07 P 3 INT W
   Heer J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P33
   Liu F, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 1, PROCEEDINGS, P226, DOI 10.1109/ICCIT.2008.275
   Owen T, 2010, LECT NOTES COMPUT SC, V6102, P168, DOI 10.1007/978-3-642-13654-2_21
   Pardo DT, 2008, CSE 2008: PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING, P251, DOI 10.1109/CSEW.2008.68
   Sari Riri Fitri, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P34, DOI 10.4304/jetwi.2.1.34-41
   Wei Wei Jiang, 2011, 2011 International Conference on Consumer Electronics, Communications and Networks (CECNet), P5298, DOI 10.1109/CECNET.2011.5768199
   Xue Jianwu, 2010, 2010 IEEE International Conference on Software Engineering and Service Sciences (ICSESS 2010), P356, DOI 10.1109/ICSESS.2010.5552451
   Zhuhadar L, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P419, DOI 10.1109/IV.2009.47
   [No title captured]
NR 18
TC 0
Z9 0
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 947
EP 965
DI 10.1007/s11042-011-0889-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400034
DA 2024-07-18
ER

PT J
AU Satir, E
   Isik, H
AF Satir, Esra
   Isik, Hakan
TI A Huffman compression based text steganography method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Text steganography; Data compression; Huffman coding
AB In this study, capacity and security issues of text steganography have been considered by proposing a compression based approach. Because of using textual data in steganography, firstly, the employed data compression algorithm has to be lossless. Accordingly, Huffmann coding has been chosen due to its frequent use in the literature and significant compression ratio. Besides, the proposed method constructs and uses stego-keys in order to increase security. Secret information has been hidden in the chosen text from the previously constructed text base that consists of naturally generated texts. Email has been chosen as communication channel between the two parties, so the stego cover has been arranged as a forward mail platform. As the result of performed experiments, average capacity has been computed as 7.962 % for the secret message with 300 characters (or 300a (TM) 8 bits). Finally, comparison of the proposed method with the other contemporary methods in the literature has been carried out in Section 5.
C1 [Satir, Esra] Selcuk Univ, Tech Educ Fac, Konya, Turkey.
   [Isik, Hakan] Selcuk Univ, Fac Technol, Konya, Turkey.
C3 Selcuk University; Selcuk University
RP Satir, E (corresponding author), Selcuk Univ, Tech Educ Fac, Konya, Turkey.
EM esatir@selcuk.edu.tr
RI Işık, Hakan/FDF-2605-2022
OI Işık, Hakan/0000-0001-7066-6287; Satir, Esra/0000-0003-1793-2472
CR Al-Bahadili H, 2008, COMPUT MATH APPL, V56, P143, DOI 10.1016/j.camwa.2007.11.043
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   Chapman M, 2002, LECT NOTES COMPUT SC, V2437, P276
   Chapman M., 1997, Information and Communications Security. First International Conference, ICIS '97. Proceedings, P335, DOI 10.1007/BFb0028489
   Chapman Mark, 2001, LECT NOTES COMPUTER, P156, DOI DOI 10.1007/3-540-45439-X
   Desoky A, 2009, INT J INF SECUR, V8, P247, DOI 10.1007/s10207-009-0079-0
   Easton T, 2001, DISCRETE APPL MATH, V113, P167, DOI 10.1016/S0166-218X(00)00282-1
   Galambos G, 2002, DATA COMPRESSION THE, V1
   Gutub AAA, 2007, PROC WRLD ACAD SCI E, V21, P28
   Lee IS, 2010, SIGNAL PROCESS, V90, P557, DOI 10.1016/j.sigpro.2009.07.022
   Liang JY, 2008, COMPUT MED IMAG GRAP, V32, P174, DOI 10.1016/j.compmedimag.2007.11.002
   Liu YC, 2011, MULTIMED TOOLS APPL, V52, P263, DOI 10.1007/s11042-010-0496-0
   Lou DC, 2010, J SYST SOFTWARE, V83, P1236, DOI 10.1016/j.jss.2010.01.050
   Lu J, 2011, J COMPUT, V6, P51, DOI 10.4304/jcp.6.1.51-58
   MAHER K, 1995, TEXTO
   MURPHY B, 2007, P SPIE INT C SEC STE
   Nakagawa Hiroshi., 2001, IPSJ Transaction, V42, P2339
   Por LY, 2012, J SYST SOFTWARE, V85, P1075, DOI 10.1016/j.jss.2011.12.023
   Ryabko B, 2011, INFORM COMPUT, V209, P1223, DOI 10.1016/j.ic.2011.06.004
   Samphaiboon N, 2009, MULTIMED TOOLS APPL, V52, P569
   Satir E, 2012, J SYST SOFTWARE, V85, P2385, DOI 10.1016/j.jss.2012.05.027
   Shu Yuanzhong, 2011, P ENG, V15, p[3936, 1877]
   Stutsman R., 2006, P 2006 ACM S APPL CO, P338
   Sun Xingming., 2004, INFOS TERNATIONAL C, P76
   Topkara M, 2007, P SPIE INT C SEC STE
   Wang ZH, 2009, J SYST SOFTWARE, V82, P1362, DOI 10.1016/j.jss.2009.04.045
   Wayner P., 1992, Cryptologia, V16, P193, DOI 10.1080/0161-119291866883
   Wayner P., 2002, Disappearing Cryptography, V2nd, P81
   Winstein K, 1999, LEXICAL STEGANOGRAPH
   Winstein Keith., 1999, Lexical steganography through adaptive modulation of the word choice hash
   Zaker N, 2012, MULTIMED TOOLS APPL, V58, P147, DOI 10.1007/s11042-010-0714-9
   Zhi-Hui Wang, 2009, 2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA 2009), P457, DOI 10.1109/PACIIA.2009.5406559
NR 33
TC 30
Z9 31
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2085
EP 2110
DI 10.1007/s11042-012-1223-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500031
DA 2024-07-18
ER

PT J
AU Cai, ML
   Zou, BJ
   Gao, HZ
   Song, J
AF Cai, Meiling
   Zou, Beiji
   Gao, Huanzhi
   Song, Juan
TI Motion recognition for 3D human motion capture data using support vector
   machines with rejection determination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human motion recognition; Support vector machines; Self-organizing map;
   Rejection determination
ID SEGMENTATION; CLASSIFICATION; RETRIEVAL
AB This article presents a motion recognition strategy with rejection ability to extract the meaningful actions according to a given set of motion classes, or categories or types and reject such input patterns whose categories are not known. During the online recognition phrase, the multiple one-versus-one support vector machines are aggregated with the majority voting strategy over the most recent frames in a sliding window to predict the most probable type at each instance. And then, the corresponding index motion map is utilized to determine whether the predicted type should be accepted or not. The motion will be considered to be unknown when consecutive multiple frames are rejected. As a contribution, an adjusted self-organizing map algorithm is proposed to automatically learn the index motion map for each motion class, where the map size and topology are dynamically tuned by the intrinsic characteristics of the trained motions dataset. At the postprocessing step, the procedure is enhanced by an efficient key patterns-based verification strategy, which significantly improves the recognition precision. As a further contribution, we introduce a genetic algorithm learning algorithm to automatically learn the necessary key patterns for each class base on the previous learned index motion map. We evaluate our motion recognition model on various experiments conducted on synthetic data and real data from the freely available sets of motion capture database (HDM05). Experiment results show that the proposed strategy can not only classify motions correctly, but also identify the existence of unknown motion types.
C1 [Cai, Meiling; Zou, Beiji; Gao, Huanzhi] Cent S Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
   [Cai, Meiling] Changsha Normal Univ, Elect Informat Engn Dept, Changsha, Hunan, Peoples R China.
   [Song, Juan] Cent S Univ, Sch Business, Changsha, Hunan, Peoples R China.
C3 Central South University; Central South University
RP Zou, BJ (corresponding author), Cent S Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
EM bjzou@vip.163.com
FU National Natural Science Funds of China [61173122]; Natural Science
   Foundation of Hunan Province, China [12JJ2038, 09JJ6102]; Postdoctoral
   Science Foundation of HuNan Academy of Science [2012RS4027]; Social
   Science Foundation of HuNan province [12YBB286]; Scientific Research
   Fund of Hunan Provincial Education Department [12C0791]
FX The data used in this paper was obtained from HDM05. Thanks for their
   sharing. This research is partially supported by National Natural
   Science Funds of China (61173122), Key Project of Natural Science
   Foundation of Hunan Province, China (12JJ2038), Natural Science
   Foundation of Hunan Province, China (09JJ6102), The Postdoctoral Science
   Foundation of HuNan Academy of Science (2012RS4027), Social Science
   Foundation of HuNan province (12YBB286), The Scientific Research Fund of
   Hunan Provincial Education Department (12C0791).
CR Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732
   [Anonymous], 2009, P 2009 ACM SIGGRAPH
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Banerjee A, 2006, IEEE T GEOSCI REMOTE, V44, P2282, DOI 10.1109/TGRS.2006.873019
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Bertolami R, 2006, PATTERN RECOGN LETT, V27, P2005, DOI 10.1016/j.patrec.2006.06.002
   BLACKMORE J, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P450, DOI 10.1109/ICNN.1993.298599
   Cao DW, 2004, IEEE INT CONF ROBOT, P2291
   Chiu CY, 2004, J VIS COMMUN IMAGE R, V15, P446, DOI 10.1016/j.jvcir.2004.04.004
   Eiben A.E., 2007, INTRO EVOLUTIONARY C
   FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4
   FRITZKE B, 1995, NEURAL PROCESS LETT, V2, P9, DOI 10.1007/BF02332159
   Furao S, 2007, NEURAL NETWORKS, V20, P893, DOI 10.1016/j.neunet.2007.07.008
   Gorski N, 1997, PROC INT CONF DOC, P1092, DOI 10.1109/ICDAR.1997.620677
   Guenterberg E, 2009, IEEE T INF TECHNOL B, V13, P1019, DOI 10.1109/TITB.2009.2028421
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Guo K, 2007, TUNN ACCV, P442
   Kahol K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P883, DOI 10.1109/AFGR.2004.1301645
   Kahol K, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P105
   Koerich AL, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P479, DOI 10.1109/IWFHR.2004.88
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255
   Landgrebe TCW, 2006, PATTERN RECOGN LETT, V27, P908, DOI 10.1016/j.patrec.2005.10.015
   Li CJ, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1236471.1236475
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Manabe S., 2006, P SICE ICASE INT JOI, P618
   Pfau T, 2008, J BIOMECH, V41, P216, DOI 10.1016/j.jbiomech.2007.08.004
   Pitrelli JF, 2003, PROC INT CONF DOC, P278
   Pitrelli JF, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P30, DOI 10.1109/IWFHR.2002.1030880
   Qiong Zhao, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2740, DOI 10.1109/ICPR.2010.671
   Qiu Q, 2011, IEEE I CONF COMP VIS, P707, DOI 10.1109/ICCV.2011.6126307
   Rizvi SA, 2000, PATTERN RECOGN, V33, P1931, DOI 10.1016/S0031-3203(00)00039-X
   Sakamoto Y., 2004, Proceedings of the 2004 acm siggraph/eurographics symposium on computer animation, P259, DOI DOI 10.1145/1028523.1028557
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006
   van Kasteren TLM, 2010, PERS UBIQUIT COMPUT, V14, P489, DOI 10.1007/s00779-009-0277-9
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Wang ZL, 2012, IEEE T INF TECHNOL B, V16, P691, DOI 10.1109/TITB.2012.2196440
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu SY, 2009, VISUAL COMPUT, V25, P499, DOI 10.1007/s00371-009-0345-1
   Yang K., 2004, ACM INT WORKSHOP MUL, P65, DOI DOI 10.1145/1032604.1032616
   Zheng E-H., 2011, INT J COMPUT THEORY, V3, P130, DOI 10.7763/IJCTE.2011.V3.294
NR 46
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1333
EP 1362
DI 10.1007/s11042-013-1749-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900032
DA 2024-07-18
ER

PT J
AU Athanaselis, T
   Bakamidis, S
   Dologlou, I
   Argyriou, EN
   Symvonis, A
AF Athanaselis, Theologos
   Bakamidis, Stelios
   Dologlou, Ioannis
   Argyriou, Evmorfia N.
   Symvonis, Antonis
TI Making assistive reading tools user friendly: a new platform for Greek
   dyslexic students empowered by automatic speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Assistive reading tool; Greek dyslexic students; Speech recognition
   engine; Vocal user interface
AB This work presents our effort to incorporate a state of the art speech recognition engine into a new platform for assistive reading for improving reading ability of Greek dyslexic students. This platform was developed in the framework of the Agent-DYSL, IST project, and facilitates dyslexic children in learning to read fluently. Unlike previously presented approaches, the aim of the system is not only to enable access to the reading materials within an inclusive learning system but to promote the development of reading skills by adjusting and adapting in the light of feedback to the system. The idea is to improve speech recognition performance so that gradually increase the reading capabilities of the user, gradually diminish the assistance provided, till he is able to read as a non-dyslexic reader. The evaluation results show that both learners' reading pace and learners' reading accuracy were increased.
C1 [Athanaselis, Theologos; Bakamidis, Stelios; Dologlou, Ioannis] ILSP RC Athena, Athens 15125, Greece.
   [Argyriou, Evmorfia N.; Symvonis, Antonis] Natl Tech Univ Athens, Dept Math, Sch Appl Math & Phys Sci, Athens 15780, Greece.
C3 National Technical University of Athens
RP Athanaselis, T (corresponding author), ILSP RC Athena, Artemidos 6 & Epidavrou, Athens 15125, Greece.
EM tathana@ilsp.gr; bakam@ilsp.gr; ydol@ilsp.gr; fargyriou@math.ntua.gr;
   symvonis@math.ntua.gr
OI Symvonis, Antonios/0000-0002-0280-741X
FU European IST-2005-2.5.11 e-inclusion program within the project
   "Agent-DYSL"
FX This research work has been supported by the European IST-2005-2.5.11
   e-inclusion program within the project "Agent-DYSL",
   (www.Agent-DYSL.eu).
CR AGENT-DYSL, EU PROJ
   Amiri H, 2006, THESIS MONASH U
   Athanaselis T, 2005, NEURAL NETWORKS, V18, P437, DOI 10.1016/j.neunet.2005.03.008
   Duchateau J, 2009, SPEECH COMM
   ELKIND J, 1993, ANN DYSLEXIA, V43, P238, DOI 10.1007/BF02928184
   Elkind J, 1998, 9801 LEX I
   Fogarty J, 2001, MINING DATABASE READ
   Hasselt CV, 2002, ORAL READING ACHIEVE
   Huslander J, 2001, GEN INFORM CODING OR
   Kolatch E., 2000, Designing for Users With Cognitive Disabilities
   Moore D., 1999, Adolescent literacy: A position statement for the Commission on Adoescent Literacy of the International Reading Association
   MOSTOW J, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P785
   Rack J., 2004, STUDY DYSLEXIA
   RUSSELL M, 1996, P INT C SPOK LANG PR
   Smythe I, INT BOOK DYSLEXIA CR
   Tzouveli P, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P167, DOI 10.1109/ICALT.2008.236
   Williams S, 2004, AUCSTR0407 U AB DEP, P1
   Williams S, 2003, P CORP LING 2003 LAN
   Wise B., 2008, INTERACTIVE LITERACY, P31
   Young J, 1996, IEEE SIGNAL PROCESS, V13, P45
   Zue V, 1996, ICSLP 96 PHIL
NR 21
TC 11
Z9 13
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 681
EP 699
DI 10.1007/s11042-012-1073-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000009
DA 2024-07-18
ER

PT J
AU Gao, Y
   Zhou, J
AF Gao, Yi
   Zhou, Jun
TI Motion vector extrapolation for parallel motion estimation on GPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Error concealment; GPU; CUDA
AB The powerful parallel computing ability of Graphics Processing Unit (GPU) has shown its striking superiority for motion estimation acceleration in conventional hybrid video encoding process. Unfortunately, the motion information of the neighboring macroblocks is not available for current macroblock, such that parallel motion estimation using GPU is not very favored. To tackle this problem while achieving high acceleration ration, motion vector cost is always ignored in most existing solutions, which inevitably causes severe rate-distortion loss. In this paper, a novel motion vector extrapolation based approach (MVEA) is presented for enhancing rate-distortion performance of parallel motion estimation on GPU, which is based on the study of motion vector recovery strategies for frame loss error concealment. Furthermore, the efficient implementation of MVEA on Computing Unified Device Architecture (CUDA) is also investigated. Simulation results show that MVEA can achieve a maximum peak Signal-to-Noise ratio enhancement of 0.8 dB with ignorable computational cost increase.
C1 [Gao, Yi; Zhou, Jun] Wuhan Digital Engn Inst, Wuhan 430074, Peoples R China.
RP Gao, Y (corresponding author), Wuhan Digital Engn Inst, Wuhan 430074, Peoples R China.
EM gaoyi709@gmail.com
RI Jiang, Cheng/JHU-0179-2023
CR [Anonymous], 1995, 138182 ISOIEC MPEG2
   Boyer M, 2009, P INT S PAR DISTR PR
   Chan L, 2009, PARALLELIZING H 264
   Chen W., 2008, P IEEE INT C MULT EX
   Cheung NM, 2009, IEEE T CIRC SYST VID, V19, P1692, DOI 10.1109/TCSVT.2009.2031515
   Chien SY, 2005, IEEE COMMUN MAG, V43, P123, DOI 10.1109/MCOM.2005.1497562
   Dikbas S, 2010, IEEE T CIRC SYST VID, V20, P1047, DOI 10.1109/TCSVT.2010.2051283
   Fan J, 2007, PICT COD S PCS 2007
   Gan Z, 2007, ELECTRON LETT, V43, P96, DOI 10.1049/el:20072810
   Gao Y., 2010, HKIE T, V17, P15
   Ho CW, 2006, P IEEE C MULT EXPR I
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   LIN Y, 2006, P IEEE INT S CIRC SY
   Ma M, 2008, IEEE T MULTIMEDIA, V10, P1638, DOI 10.1109/TMM.2008.2007282
   Massanes F, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3606588
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   NVIDIA Corporation, 2008, CUDA PROGR GUID VERS
   Park S. In, 2008, APPL IM PATT REC WOR
   Po LM, 2007, IEEE T MULTIMEDIA, V9, P9, DOI 10.1109/TMM.2006.886330
   Po LM, 2007, IEEE T CIRC SYST VID, V17, P765, DOI 10.1109/TCSVT.2007.896663
   Po LM, 2010, IEEE T CIRC SYST VID, V20, P1625, DOI 10.1109/TCSVT.2010.2087474
   Schwalb M, 2009, IEEE T MULTIMEDIA, V11, P1, DOI 10.1109/TMM.2008.2008873
   Shen GB, 2005, IEEE T CIRC SYST VID, V15, P685, DOI 10.1109/TCSVT.2005.846440
   Steinbach E, 1997, IEEE T CIRC SYST VID, V7, P872, DOI 10.1109/76.644067
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu Z, 2006, P INT S CIRC SYST IS
   Yan B, 2008, P INT C IM PROC ICIP
NR 28
TC 2
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 701
EP 715
DI 10.1007/s11042-012-1074-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000010
DA 2024-07-18
ER

PT J
AU Viciana-Abad, R
   Reyes-Lecuona, A
   Rosa-Pujazón, A
   Pérez-Lorenzo, JM
AF Viciana-Abad, Raquel
   Reyes-Lecuona, Arcadio
   Rosa-Pujazon, Alejandro
   Manuel Perez-Lorenzo, Jose
TI The influence of different sensory cues as selection feedback and
   co-location in presence and task performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-location; Feedback; Haptic; Selection; Virtual environments
ID VIRTUAL ENVIRONMENTS; ADAPTATION; VISION; DESIGN; TOUCH
AB For some applications based on virtual reality technology, presence and task performance are important factors to validate the experience. Different approaches have been adopted to analyse the extent to which certain aspects of a computer-generated environment may enhance these factors, but mainly in 2D graphical user interfaces. This study explores the influence of different sensory modalities on performance and the sense of presence experienced within a 3D environment. In particular, we have evaluated visual, auditory and active haptic feedback for indicating selection of virtual objects. The effect of spatial alignment between proprioceptive and visual workspaces (co-location) has also been analysed. An experiment has been made to evaluate the influence of these factors in a controlled 3D environment based on a virtual version of the Simon game. The main conclusions obtained indicate that co-location must be considered in order to determine the sensory needs during interaction within a virtual environment. This study also provides further evidence that the haptic sensory modality influences presence to a higher extent, and that auditory cues can reduce selection times. Conclusions obtained provide initial guidelines that will help designers to set out better selection techniques for more complex environments, such as training simulators based on VR technology, by highlighting different optimal configurations of sensory feedback.
C1 [Viciana-Abad, Raquel; Manuel Perez-Lorenzo, Jose] Univ Jaen, Dept Telecommun Engn, Jaen, Spain.
   [Reyes-Lecuona, Arcadio; Rosa-Pujazon, Alejandro] Univ Malaga, Dept Elect Technol, E-29071 Malaga, Spain.
C3 Universidad de Jaen; Universidad de Malaga
RP Viciana-Abad, R (corresponding author), Univ Jaen, Dept Telecommun Engn, Jaen, Spain.
EM rviciana@ujaen.es
RI Reyes-Lecuona, Arcadio/M-7022-2014; Viciana Abad, Raquel/A-3258-2013;
   Perez Lorenzo, Jose Manuel/H-1694-2015
OI Reyes-Lecuona, Arcadio/0000-0002-3699-4065; Viciana Abad,
   Raquel/0000-0003-2545-7229; Perez Lorenzo, Jose
   Manuel/0000-0002-5286-8026
FU DIANA research group [PAI: TIC-171]; Junta de Andalucia [P11-TIC-8231]
FX This work has been partially supported by DIANA research group (PAI:
   TIC-171) and the Junta de Andalucia, under the project P11-TIC-8231. The
   authors would like to thank the participants of this experiment for
   their collaboration and comments.
CR [Anonymous], P PRES
   [Anonymous], P ACM CHI
   [Anonymous], 1014 US ARM RES I BE
   [Anonymous], 1056 US ARM RES I BE
   [Anonymous], P CYB C
   [Anonymous], P 7 INT WORKSH PRES
   BAILEY JH, 1994, HUM FAC ERG SOC P, P1158, DOI 10.1177/154193129403801803
   Bertelson P., 1999, COGNITIVE CONTRIBUTI, P347, DOI DOI 10.1016/S0166-4115(99)80034-X
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Bormann K., 2006, VIRTUAL REAL-LONDON, V9, P226, DOI DOI 10.1007/S10055-006-0019-5
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Burke J. L., 2006, P 8 INT C MULT INT, P108, DOI [10.1145/1180995.1181017, DOI 10.1145/1180995.1181017, DOI 10.1145/1180995]
   Chen J, 2009, PRESENCE-TELEOP VIRT, V18, P370, DOI 10.1162/pres.18.5.370
   Coelho C., 2006, COMMUNICATION PRESEN, P25
   Congedo M, 2006, PRESENCE-TELEOP VIRT, V15, P353, DOI 10.1162/pres.15.3.353
   Cumming G, 2005, AM PSYCHOL, V60, P170, DOI 10.1037/0003-066X.60.2.170
   Durlach PJ, 2005, PRESENCE-TELEOP VIRT, V14, P450, DOI 10.1162/105474605774785299
   Ellis SR, 1997, ADV HUM FACT ERGON, V21, P873
   Ferris TK, 2008, HUM FACTORS, V50, P17, DOI 10.1518/001872008X250566
   Hecht D, 2006, PRESENCE-TELEOP VIRT, V15, P515, DOI 10.1162/pres.15.5.515
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   Keetels M, 2007, EXP BRAIN RES, V180, P449, DOI 10.1007/s00221-007-0881-8
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Loomis J.M., 1992, Presence: Teleoperators and Virtual Environments, V1, P113, DOI 10.1162/pres.1992.1.1.113
   Ma RQ, 2006, INT J HUM-COMPUT ST, V64, P541, DOI 10.1016/j.ijhcs.2005.12.003
   Maida J, 1997, ADV HUM FACT ERGON, V21, P877
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Navarra J, 2007, NEUROSCI LETT, V413, P72, DOI 10.1016/j.neulet.2006.11.027
   Pausch R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P13, DOI 10.1145/258734.258744
   Poupyrev I, 1998, COMPUT GRAPH FORUM, V17, pC41
   Sheik-Nainar MA, 2005, HUM FACTORS ERGONOM, V15, P259, DOI 10.1002/hfm.20025
   Singer M.J., 1995, 1034 US ARM RES I BE
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Spence C, 2007, ACOUST SCI TECHNOL, V28, P61, DOI 10.1250/ast.28.61
   Stanney K, 1998, INT J HUM-COMPUT INT, V10, P135, DOI 10.1207/s15327590ijhc1002_3
   Szameitat AJ, 2009, INT J HUM-COMPUT ST, V67, P561, DOI 10.1016/j.ijhcs.2009.02.004
   Teder-Sälejärvi WA, 2005, J COGNITIVE NEUROSCI, V17, P1396, DOI 10.1162/0898929054985383
   Viciana-Abad R, 2008, LECT NOTES COMPUT SC, V5024, P832, DOI 10.1007/978-3-540-69057-3_105
   Viciana-Abad R, 2011, MULTIMED TOOLS APPL, V55, P353, DOI 10.1007/s11042-010-0551-x
   Viciana-Abad R, 2010, PRESENCE-TELEOP VIRT, V19, P197, DOI 10.1162/pres.19.3.197
   Vitense H. S., 2002, Universal Access in the Information Society, V2, P76, DOI 10.1007/s10209-002-0038-2
   Wall W., 2002, Proceedings of Eurohaptics 2002, P23
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   Welch RB, 1999, PRESENCE-TELEOP VIRT, V8, P574, DOI 10.1162/105474699566387
   Whitelock D., 2000, Education and Information Technologies, V5, P277, DOI 10.1023/A:1012001523715
   Wickens C. D., 2002, Theor Issues Ergon Sci, V3, P159, DOI [10.1080/14639220210123806, DOI 10.1080/14639220210123806]
   Wickens CD, 2008, HUM FACTORS, V50, P397, DOI 10.1518/001872008X288420
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 51
TC 5
Z9 5
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 623
EP 639
DI 10.1007/s11042-012-1070-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000006
DA 2024-07-18
ER

PT J
AU Wu, HS
   Wong, TT
   Heng, PA
AF Wu, Huisi
   Wong, Tien-Tsin
   Heng, Pheng-Ann
TI Parallel structure-aware halftoning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital halftoning; GPU; SSIM; Parallel poisson-disk sampling
ID DESIGN
AB Structure-aware halftoning technique is one of the state-of-the-art algorithms for generating structure-preserving bitonal images. However, the slow optimization process prohibits its real-time application. This is due to its high computational cost of similarity measurement and iterative refinement. Unfortunately, the structure-aware halftoning cannot be straightforwardly parallelized due to its data dependency nature. In this paper, we propose a parallel algorithm to boost the optimization of the structure-aware halftoning. Our main idea is to exploit the spatial independence during the evaluation of the objective function and temporal independence among the iterations. Specifically, we introduce a parallel Poisson-disk algorithm during the selection of pixel swaps, which guarantees the independency between parallel processes. Graphics processing unit (GPU) implementation of the technique leads to a significant speedup without sacrificing the quality. Our experiments demonstrate the effectiveness of the proposed parallel algorithm in generating structure-preserving bitonal images with much less time, especially for large images.
C1 [Wu, Huisi] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Wong, Tien-Tsin; Heng, Pheng-Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
C3 Shenzhen University; Chinese University of Hong Kong
RP Wu, HS (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, 364 Adm Bldg, Shenzhen, Peoples R China.
EM hswu@szu.edu.cn
OI Heng, Pheng Ann/0000-0003-3055-5034
FU Hong Kong RGC General Research Fund [CUHK 417411]; CUHK SHIAE Project
   Funding [SHIAE-MMT-P2-11]
FX We would like to thank all reviewers for their valuable suggestions to
   improve the paper. This work was supported in part by grants from Hong
   Kong RGC General Research Fund (Project No. CUHK 417411) and CUHK SHIAE
   Project Funding (Project No. SHIAE-MMT-P2-11).
CR Bayers B., 1973, P IEEE INT COMM C, P2611
   Bowers J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866188
   Chang JH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618508
   Chen J, 2007, ACM T GRAPHIC, V26, DOI [10.1109/SARNOF.2007.4567317, 10.1145/1276377.1276506, 10.1145/1239451.1239554]
   COOK RL, 1986, ACM T GRAPHIC, V5, P51, DOI 10.1145/7529.8927
   Ebeida MS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964944
   Floyd R.W., 1974, SID INT SYMP DIG, P36
   Fung YH, 2010, IEEE T IMAGE PROCESS, V19, P1808, DOI 10.1109/TIP.2010.2044961
   Gamito MN, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640451
   Guo JM, 2007, IEEE T MULTIMEDIA, V9, P687, DOI 10.1109/TMM.2007.895678
   Hwang BW, 2004, LECT NOTES COMPUT SC, V3029, P473
   Kim JS, 2008, IEEE T CIRC SYST VID, V18, P827, DOI 10.1109/TCSVT.2008.918759
   Kim SH, 2002, IEEE T IMAGE PROCESS, V11, P258, DOI 10.1109/83.988959
   Kwak NJ, 2006, 2006 International Conference on Hybrid Information Technology, Vol 1, Proceedings, P499
   Li H, 2010, COMPUT GRAPH FORUM, V29, P273, DOI 10.1111/j.1467-8659.2009.01596.x
   Li P, 2000, IEEE T IMAGE PROCESS, V9, P1593, DOI 10.1109/83.862640
   Li PS, 2004, IEEE T IMAGE PROCESS, V13, P201, DOI 10.1109/tip.2003.819232
   Mese M, 2002, IEEE T IMAGE PROCESS, V11, P644, DOI 10.1109/TIP.2002.1014996
   Monga V, 2007, IEEE T IMAGE PROCESS, V16, P198, DOI 10.1109/TIP.2006.884923
   Ostromoukhov V, 2001, COMP GRAPH, P567, DOI 10.1145/383259.383326
   Pang W.-M., 2008, ACM T GRAPHIC, V27, P89
   Rodríguez JB, 2008, IEEE T IMAGE PROCESS, V17, P1368, DOI 10.1109/TIP.2008.926145
   Schmaltz C, 2010, COMPUT GRAPH FORUM, V29, P2313, DOI 10.1111/j.1467-8659.2010.01716.x
   Su Y, 2008, IEEE INT CONF INF VI, P94, DOI 10.1109/IV.2008.14
   SULLIVAN J, 1991, IEEE T SYST MAN CYB, V21, P33, DOI 10.1109/21.101134
   Tzeng S, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P79
   Ulichney R, 2000, P SOC PHOTO-OPT INS, V3963, P378
   Ulichney R., 1987, DIGITAL HALFTONING
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei LY, 2008, ACM T GRAPHIC, V27, P20
NR 30
TC 2
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 529
EP 547
DI 10.1007/s11042-012-1048-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900001
DA 2024-07-18
ER

PT J
AU Li, B
   Johan, H
AF Li, Bo
   Johan, Henry
TI Sketch-based 3D model retrieval by incorporating 2D-3D alignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch-based 3D model retrieval; 2D-3D alignment; View context
AB Sketch-based 3D model retrieval is very important for applications such as 3D modeling and recognition. In this paper, a sketch-based retrieval algorithm is proposed based on a 3D model feature named View Context and 2D relative shape context matching. To enhance the accuracy of 2D sketch-3D model correspondence as well as the retrieval performance, we propose to align a 3D model with a query 2D sketch before measuring their distance. First, we efficiently select some candidate views from a set of densely sampled views of the 3D model to align the sketch and the model based on their View Context similarities. Then, we compute the more accurate relative shape context distance between the sketch and every candidate view, and regard the minimum one as the sketch-model distance. To speed up retrieval, we precompute the View Context and relative shape context features of the sample views of all the 3D models in the database. Comparative and evaluative experiments based on hand-drawn and standard line drawing sketches demonstrate the effectiveness and robustness of our approach and it significantly outperforms several latest sketch-based retrieval algorithms.
C1 [Li, Bo; Johan, Henry] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Li, B (corresponding author), Nanyang Technol Univ, Sch Comp Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM libo0002@ntu.edu.sg; henryjohan@ntu.edu.sg
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   [Anonymous], 2003, 3D Computer Graphics: A Mathematical Introduction with OpenGL
   [Anonymous], P ACM INT C MULT RET
   [Anonymous], MULTIMEDIA TOOLS APP
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cao L., 2006, P ACM INT C MULT, P105
   Chalechale A, 2004, IEE P-VIS IMAGE SIGN, V151, P93, DOI 10.1049/ip-vis:20040332
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Dengsheng Zhang, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P652
   Fang R, 2008, LECT NOTES COMPUT SC, V5358, P381, DOI 10.1007/978-3-540-89639-5_37
   Feldmar J, 1997, COMPUT VIS IMAGE UND, V65, P403, DOI 10.1006/cviu.1996.0499
   Fonseca M.J., 2004, Proceedings of Eurographics workshop on Sketch-based Interfaces and Modeling (SBIM 04). Eurographics Association, P127
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Hou S, 2007, COMPUT GRAPH-UK, V31, P598, DOI 10.1016/j.cag.2007.04.005
   Huttenlocher D. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P102
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   Kanai S, 2008, INT J INTERACT DES M, V2, P87, DOI [10.1007/s12008-008-0038-4, 10.1007/s12008-008-003]
   KARTHIK R., 2006, EuroGraphics Symposium Proceedings on Sketch-based Interfaces and Modeling, P131
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Lee J., 2008, P EUROGRAPHICS WORKS, P97, DOI DOI 10.2312/SBM/SBM08/097-104
   Li B., 2011, 2011 IEEE WORKSH APP, P45
   Li B, 2010, LECT NOTES COMPUT SC, V5916, P185
   Loop C, 1987, THESIS U UTAH
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Napoleon T, 2010, SPIE, p75260L
   Napoléon T, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/367181
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Pu J., 2006, PROC 3 INT S 3D DATA, P1072
   Pu JT, 2006, COMPUT AIDED DESIGN, V38, P249, DOI 10.1016/j.cad.2005.10.009
   Saavedra JM, 2010, LECT NOTES COMPUT SC, V6376, P432
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Veltkamp RC, 2007, UUCS2007015 DEP INF
   VRANIC DV, 2004, THESIS U LEIPZIG
   Wang JL, 2008, ADV ENG INFORM, V22, P385, DOI 10.1016/j.aei.2008.04.001
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Zamora S., 2010, EUR WORKSH SKETCH BA, P119
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 42
TC 23
Z9 28
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 363
EP 385
DI 10.1007/s11042-012-1009-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600003
DA 2024-07-18
ER

PT J
AU Kim, KR
   Moon, NM
AF Kim, Kyung Rog
   Moon, Nam Mee
TI Designing a social learning content management system based on learning
   objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social learning; Learning object; Social-learning content management
   system; Metadata; N-Screen
AB With the prevalence of social networking services and social media tools, individuals now engage in the production, sharing, and application of diverse content, extending community-based social learning. The most prominent aspect of social learning, which makes it distinct from e-learning, is how content is produced and consumed. That is, people share knowledge with others and learn values via networks in social learning, which requires social media content and social network activity content to be turned into shareable learning objects. In reference to social learning, the present study proposes a Social Learning Content Management System that generates, manages, and publishes learning objects based on content generation models which are also defined here. The proposed system is of significance in that it enables the transformation of social resources into learning objects with the Social Learning Content Management System architecture and data schema defined, and relevant processes designed, based on metadata and learning objects defined for N-screen services.
C1 [Kim, Kyung Rog; Moon, Nam Mee] Hoseo Univ, Dept IT App, Tech GSV, Seoul, South Korea.
C3 Hoseo University
RP Kim, KR (corresponding author), Hoseo Univ, Dept IT App, Tech GSV, Seoul, South Korea.
EM it4all@naver.com; mnm@hoseo.edu
CR Allen CA, 2010, J OBJECT TECHNOL, V9, P51, DOI 10.5381/jot.2010.9.6.a3
   Ananthanarayanan NR, 2009, ASIAN J INF TECHNOL, V8, P47
   [Anonymous], RES REFLECTIONS INNO
   Auinger A, 2009, LECT NOTES COMPUT SC, V5616, P14, DOI 10.1007/978-3-642-02713-0_2
   Bandura A., 1977, Social Learning Theory
   Bauer M., 2010, E LEARNING 2010, P181
   Berking P, 2009, CURRENT CAPABILITIES
   Blackmore C, 2010, SOCIAL LEARNING SYSTEMS AND COMMUNITIES OF PRACTICE, P201, DOI 10.1007/978-1-84996-133-2_12
   Bri Diana, 2009, WSEAS Transactions on Advances in Engineering Education, V6, P33
   Burke M, 2009, CHI C HUM FACT COMP, V2009, P945
   Buter B., 2011, J CONVERG, V2, P87
   Canales-Cruz A, 2009, J APPL RES TECHNOL, V7, P310
   Capuano N, 2009, ICALT: 2009 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, P484, DOI 10.1109/ICALT.2009.53
   Ceylan B, 2009, PROCD SOC BEHV, V1, P2051, DOI 10.1016/j.sbspro.2009.01.360
   Cho YK, 2010, MAJOR COMPUTER SCI E, P9
   Chuttur MY, 2011, LIB STUDENT J SCH LI
   Coutinho C., 2009, Proceedings of Society for Information Technology Teacher Education International Conference 2009, P2768
   Dahl D, 2007, IADIS INT C E LEARN, P107
   Greenhow C, 2009, J COMPUT-MEDIAT COMM, V14, P1130, DOI 10.1111/j.1083-6101.2009.01484.x
   Halim Zahid, 2010, International Journal of Information Technology, Communications and Convergence, V1, P92, DOI 10.1504/IJITCC.2010.035229
   Huang JJS, 2010, EDUC TECHNOL SOC, V13, P78
   Ivanisin M, 2010, CONTRIBUTIONS QUALIT, P336
   Kim Kwang Young, 2011, Algae, V26, P1, DOI 10.4490/algae.2011.26.1.001
   Kim KW, 2011, INT J ONCOL, V39, P3
   Klemke R, 2010, BRIT J EDUC TECHNOL, V41, P873, DOI 10.1111/j.1467-8535.2010.01127.x
   Klett F, 2010, KNOWL MANAG E-LEARN, V2, P278
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   Minguillón J, 2011, CONTENT MANAGEMENT FOR E-LEARNING, P27, DOI 10.1007/978-1-4419-6959-0_2
   Muyinda Paul Birevu, 2011, Theoretical Aspects of Computing - ICTAC 2011. Proceedings 8th International Colloquium, P194, DOI 10.1007/978-3-642-23283-1_14
   Puustjärvi J, 2009, ICALT: 2009 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, P200, DOI 10.1109/ICALT.2009.48
   Richard DJB, 2010, STANDARDIZATION LEAR
   Sale Rose Ann, J CONVERGENCE JOC, V1, P9
   Sánchez-Alonso S, 2011, CONTENT MANAGEMENT FOR E-LEARNING, P131, DOI 10.1007/978-1-4419-6959-0_8
   Sanz-Rodriguez J, 2011, SOFTWARE QUAL J, V19, P121, DOI 10.1007/s11219-010-9108-5
   Sbihi B., 2010, INT J COMPUTER SCI E, V2, P1
   Shiu H, 2010, LECT NOTES COMPUT SC, V6248, P59, DOI 10.1007/978-3-642-14657-2_7
   Simko M, 2010, IFIP ADV INF COMM TE, V324, P367
   Sural I., 2010, Procedia Social and Behavioral Sciences, V9, P1145
   Wang XR, 2009, PROCD SOC BEHV, V1, P2081, DOI 10.1016/j.sbspro.2009.01.366
   Yueqing Yin, 2011, Hybrid Learning. Proceedings 4th International Conference, ICHL 2011, P146, DOI 10.1007/978-3-642-22763-9_14
NR 40
TC 11
Z9 12
U1 0
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 423
EP 437
DI 10.1007/s11042-012-1014-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200012
DA 2024-07-18
ER

PT J
AU Sheng, L
   Gong, ZB
AF Sheng, Luo
   Gong, Zhenbang
TI A camera planning method for the 3D reconstruction of a single object
   based on statistical deformation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera planning; Statistical deformation model; 3D reconstruction; Point
   distribution model; Principal component analysis
ID VIEW
AB In order to provide sufficient information for the 3D reconstruction of a single, static and known type object, this paper proposes measure indexes to evaluate the information amount and a camera planning method to guide the search of the optimal camera positions. The planning method is based on Statistical Deformation Model (SDM) which is generated from Point Distribution Model (PDM) by the Principal Component Analysis (PCA) method. The position from which the individual factor coefficients are observed clearly and the principal shape features are identified distinctly is the best viewpoint. The observed times of landmark are used to exclude the redundancy among views. So, in an iteration process new SDM is repeatedly computed to pick out the optimal viewpoints until all the landmarks are observed sufficiently. Therefore abundant information with the minimum redundancy is provided by fewer cameras, and an experiment which layout cameras for foot reconstruction was demonstrated.
C1 [Sheng, Luo] Wenzhou Univ, Coll Mech & Elect Engn, Wenzhou City, Zhejiang, Peoples R China.
   [Sheng, Luo] Wenzhou Univ, Coll Mech Engn, Wenzhou City, Zhejiang, Peoples R China.
   [Gong, Zhenbang] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
C3 Wenzhou University; Wenzhou University; Shanghai University
RP Sheng, L (corresponding author), Wenzhou Univ, Coll Mech & Elect Engn, Wenzhou City, Zhejiang, Peoples R China.
EM lsshanghai2006@yahoo.com.cn; zhbgong@mail.shu.edu.cn
FU Zhejiang Provincial Natural Science Foundation of China [Y1100075];
   Shanghai Key Discipline Fund of Shanghai University [B 67]; Science
   Foundation of Wenzhou University
FX This research was jointly sponsored by Zhejiang Provincial Natural
   Science Foundation of China (Project No. Y1100075), Shanghai Key
   Discipline Fund of Shanghai University (Project No. B 67) and Science
   Foundation of Wenzhou University, which are greatly appreciated by the
   authors.
CR Abidi BA, 1995, P SOC PHOTO-OPT INS, V2588, P387, DOI 10.1117/12.222696
   Abidi BR, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456657
   [Anonymous], 2011, COMPUTER VISION DATA
   Banta JE, 2000, IEEE T SYST MAN CY A, V30, P589, DOI 10.1109/3468.867866
   Blaer PS, 2009, J FIELD ROBOT, V26, P865, DOI 10.1002/rob.20318
   Brett AD, 2000, IMAGE VISION COMPUT, V18, P739, DOI 10.1016/S0262-8856(99)00077-3
   Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dornaika F, 2003, BRIT MACH VIS C NORW, P326
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Horkaew P, 2004, LECT NOTES COMPUT SC, V3216, P217
   Jancosek M, 2009, IEEE INT WORKSH 3 D, P91
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Maver J, 1999, LECT NOTES COMPUT SC, V1689, P444
   Peters G, 2002, IMAGE VISION COMPUT, V20, P341, DOI 10.1016/S0262-8856(02)90006-9
   Peters G., 2007, International Journal of Intelligent Systems Technologies and Applications, V2, P113, DOI 10.1504/IJISTA.2007.012477
   Pito R, 1999, IEEE T PATTERN ANAL, V21, P1016, DOI 10.1109/34.799908
   Roy SD, 2005, IEEE T SYST MAN CY B, V35, P282, DOI 10.1109/TSMCB.2004.842414
   Roy SD, 2004, PATTERN RECOGN, V37, P429, DOI 10.1016/j.patcog.2003.01.002
   Sheng L, 2010, 3 INT C ADV COMP THE, V1, P1517
   TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940
   TARBOX GH, 1995, COMPUT VIS IMAGE UND, V61, P84, DOI 10.1006/cviu.1995.1007
   Xi PC, 2009, VISUAL COMPUT, V25, P863, DOI 10.1007/s00371-009-0316-6
   Yao Y, 2010, IEEE T SYST MAN CY B, V40, P101, DOI 10.1109/TSMCB.2009.2017507
   YUAN XB, 1995, IEEE T PATTERN ANAL, V17, P307, DOI 10.1109/34.368196
   Yuan XB, 2007, IEEE-ASME T MECH, V12, P352, DOI 10.1109/TMECH.2007.897282
   Zheng GY, 2009, LECT NOTES COMPUT SC, V5702, P672, DOI 10.1007/978-3-642-03767-2_82
NR 28
TC 0
Z9 0
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 833
EP 850
DI 10.1007/s11042-011-0939-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000011
DA 2024-07-18
ER

PT J
AU Friedland, G
   Gottlieb, L
   Janin, A
AF Friedland, Gerald
   Gottlieb, Luke
   Janin, Adam
TI Narrative theme navigation for sitcoms supported by fan-generated
   scripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic video segmentation; Narrative-themes; Crowd sourcing; Broadcast
   TV
ID VIDEO; ANNOTATION
AB The following article provides the definitive description of the complete Joke-O-Mat system to navigate sitcoms as presented briefly in Friedland et al. (2009) and extended in Janin et al. (2010), which was augmented with fan-generated scripts as described in Friedland et al. (2010). The system with the extension allows a user to browse a sitcom by scene, punchline, and dialog segment, and to filter these themes by actor and by keyword. For example, the user can choose to watch only punchlines by the character "Kramer" that contain the word "armoire". The system infers the narrative themes and provides word-level search by automatically aligning the output of a speaker identification system and a speech recognizer to both closed captions and scripts generated by fans on the Internet. The segmentations produced by this system have proven to be indistinguishable from expert-generated segmentations, and require significantly less time to produce. The article describes the original and the extended Joke-O-Mat (http://www.icsi.berkeley.edu/jokeomat/) system, discusses problems with the use of fan-generated content, and presents results on episodes from the sitcom Seinfeld with regards to segmentation accuracy and overall user satisfaction as determined by a human-subject study.
C1 [Friedland, Gerald; Gottlieb, Luke; Janin, Adam] Int Comp Sci Inst, Berkeley, CA 94704 USA.
   [Janin, Adam] Int Comp Sci Inst, Act AMI, Berkeley, CA 94704 USA.
RP Gottlieb, L (corresponding author), Int Comp Sci Inst, Berkeley, CA 94704 USA.
EM friedland@icsi.berkeley.edu; luke@icsi.berkeley.edu;
   janin@icsi.berkeley.edu
CR Adcock John., 2008, CIVR 08, P465
   [Anonymous], 2007, CIVR
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2007, ACM INT C MULT MM 07
   Ayache S, 2007, SIGNAL PROCESS-IMAGE, V22, P692, DOI 10.1016/j.image.2007.05.010
   Berrani SA, 2008, SIGNAL PROCESS-IMAGE, V23, P525, DOI 10.1016/j.image.2008.04.018
   Bertini M., 2005, 13th Annual ACM International Conference on Multimedia, P395, DOI 10.1145/1101149.1101235
   Brown M., 1995, P ACM MULT 95 SAN FR, P35
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   Bruno E, 2008, IEEE T PATTERN ANAL, V30, P1520, DOI 10.1109/TPAMI.2007.70801
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Chang SF, 2000, MEDIANET MULTIMEDIA
   Christel M.G., 2002, ACM Multimedia, P561
   Chua TS, 2007, MULTIMEDIA 07, P1054, DOI [10.1145/1291233.1291463, DOI 10.1145/1291233.1291463]
   Friedland G., 2009, ACM Multimedia Conference, P1115
   Friedland Gerald., 2008, PROCEEDING 16 ACM IN, P1017, DOI 10.1145/1459359.1459558
   Gauvain JL, 2002, SPEECH COMMUN, V37, P89, DOI 10.1016/S0167-6393(01)00061-9
   Goh K., 2004, PROC ACM INT C MULTI, P564
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Hartog JD, 1998, OLIVE SPEECH BASED V
   Haubold Alexander., 2007, CIVR, P41, DOI DOI 10.1145/1282280.1282286
   Hollink L., 2005, 13th Annual ACM International Conference on Multimedia, P479, DOI 10.1145/1101149.1101256
   Hoogs A, 2003, PROC CVPR IEEE, P327
   Hürst W, 2008, IEEE MULTIMEDIA, V15, P76, DOI 10.1109/MMUL.2008.66
   Huijbregts M, 2007, LECT NOTES COMPUT SC, V4816, P78
   Janin A, 2010, P 3 INT WORKSH AUT I, P3, DOI [10.1145/1877850.1877854, DOI 10.1145/1877850.1877854]
   Larson M, 2008, CLEF 2008 WORKSH AAR
   Niu F, 2008, PROC SPIE, V6820, DOI 10.1117/12.760267
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   REYNOLDS DA, 2005, P IEEE ICASSP
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   VINYALS O, 2008, P IEEE INT C SEM COM, P456
   Wactlar H.D., 1996, IEEE COMPUTER, P46
   Wooters C, 2008, LECT NOTES COMPUT SC, V4625, P509
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
NR 36
TC 2
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 387
EP 406
DI 10.1007/s11042-011-0877-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200005
DA 2024-07-18
ER

PT J
AU Liang, YM
   Shih, SW
   Shih, ACC
AF Liang, Yu-Ming
   Shih, Sheng-Wen
   Shih, Arthur Chun-Chieh
TI Human action segmentation and classification based on the Isomap
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human behavior analysis; Unsupervised learning; Manifold learning;
   Isomap algorithm
ID NONLINEAR DIMENSIONALITY REDUCTION; HUMAN MOVEMENT; RECOGNITION
AB Visual analysis of human behavior has attracted a great deal of attention in the field of computer vision because of the wide variety of potential applications. Human behavior can be segmented into atomic actions, each of which indicates a single, basic movement. To reduce human intervention in the analysis of human behavior, unsupervised learning may be more suitable than supervised learning. However, the complex nature of human behavior analysis makes unsupervised learning a challenging task. In this paper, we propose a framework for the unsupervised analysis of human behavior based on manifold learning. First, a pairwise human posture distance matrix is derived from a training action sequence. Then, the isometric feature mapping (Isomap) algorithm is applied to construct a low-dimensional structure from the distance matrix. Consequently, the training action sequence is mapped into a manifold trajectory in the Isomap space. To identify the break points between the trajectories of any two successive atomic actions, we represent the manifold trajectory in the Isomap space as a time series of low-dimensional points. A temporal segmentation technique is then applied to segment the time series into sub series, each of which corresponds to an atomic action. Next, the dynamic time warping (DTW) approach is used to cluster atomic action sequences. Finally, we use the clustering results to learn and classify atomic actions according to the nearest neighbor rule. If the distance between the input sequence and the nearest mean sequence is greater than a given threshold, it is regarded as an unknown atomic action. Experiments conducted on real data demonstrate the effectiveness of the proposed method.
C1 [Liang, Yu-Ming] Aletheia Univ, Dept Comp Sci & Informat Engn, Taipei 25103, Taiwan.
   [Shih, Sheng-Wen] Natl Chi Nan Univ, Dept Comp Sci & Informat Engn, Puli 545, Nantou, Taiwan.
   [Shih, Arthur Chun-Chieh] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
C3 Aletheia University; National Chi Nan University; Academia Sinica -
   Taiwan
RP Liang, YM (corresponding author), Aletheia Univ, Dept Comp Sci & Informat Engn, Taipei 25103, Taiwan.
EM ymliang@mail.au.edu.tw; swshih@ncnu.edu.tw; arthur@iis.sinica.edu.tw
FU National Science Council, Taiwan [NSC 99-2632-H-156-001-MY3]
FX The authors would like to thank the National Science Council, Taiwan
   under Contract NSC 99-2632-H-156-001-MY3.
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], 2006, P IEEE C COMP VIS PA
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Blackburn J, 2007, LECT NOTES COMPUT SC, V4814, P285
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Cock KD, 2000, P 14 INT S MATH THEO
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   Cox T. F., 2011, MULTIDIMENSIONAL SCA
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Hsieh JW, 2008, IEEE T MULTIMEDIA, V10, P372, DOI 10.1109/TMM.2008.917403
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56
   Liang YM, 2009, IEEE T SYST MAN CY B, V39, P268, DOI 10.1109/TSMCB.2008.2005643
   Lin T, 2008, IEEE T PATTERN ANAL, V30, P796, DOI 10.1109/TPAMI.2007.70735
   Miyamori H., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P320, DOI 10.1109/AFGR.2000.840653
   Nevill-Manning CG, 2000, P IEEE, V88, P1745, DOI 10.1109/5.892710
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rane Nikhil, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P513
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Sharma R, 1998, P IEEE, V86, P853, DOI 10.1109/5.664275
   Su CW, 2007, IEEE T MULTIMEDIA, V9, P1193, DOI 10.1109/TMM.2007.902875
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Turaga PavanK., 2007, Proc. IEEE Conf. Computer Vision and Pattern Recognition, P1
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang L, 2008, COMPUT VIS IMAGE UND, V110, P153, DOI 10.1016/j.cviu.2007.06.001
   Wang TS, 2001, LECT NOTES COMPUT SC, V2195, P174
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhong H, 2004, PROC CVPR IEEE, P819
NR 34
TC 9
Z9 11
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 561
EP 580
DI 10.1007/s11042-011-0858-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500002
DA 2024-07-18
ER

PT J
AU Takahashi, M
   Fujii, M
   Naemura, M
   Satoh, S
AF Takahashi, Masaki
   Fujii, Mahito
   Naemura, Masahide
   Satoh, Shin'ichi
TI Human gesture recognition system for TV viewing using time-of-flight
   camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Time-of-flight Camera; Depth information;
   Bag-of-features
ID SUPPORT
AB We developed a new device-free user interface for TV viewing that uses a human gesture recognition technique. Although many motion recognition technologies have been reported, no man-machine interface that recognizes a large enough variety of gestures has been developed. The difficulty was the lack of spatial information that could be acquired from normal video sequences. We overcame the difficulty by using a time-of-flight camera and novel action recognition techniques. The main functions of this system are gesture recognition and posture measurement. The former is performed using the bag-of-features approach, which uses key-point trajectories as features. The use of 4-D spatiotemporal trajectory features is the main technical contribution of the proposed system. The latter is obtained through face detection and object tracking technology. The interface is useful because it does not require any contact-type devices. Several experiments proved the effectiveness of our proposed method and the usefulness of the system.
C1 [Takahashi, Masaki; Fujii, Mahito; Naemura, Masahide] NHK Japan Broadcasting Corp, Sci & Tech Res Labs, Setagaya Ku, Tokyo 157, Japan.
   [Satoh, Shin'ichi] Res Org Informat & Syst, Natl Inst Informat, Chiyoda Ku, Tokyo 1018430, Japan.
C3 NHK Japan Broadcasting Corp; Research Organization of Information &
   Systems (ROIS); National Institute of Informatics (NII) - Japan
RP Takahashi, M (corresponding author), NHK Japan Broadcasting Corp, Sci & Tech Res Labs, Setagaya Ku, 1-10-11 Kinuta, Tokyo 157, Japan.
EM takahashi.m-iu@nhk.or.jp; fujii.m-ii@nhk.or.jp; naemura.m-ei@nhk.or.jp;
   satoh@nii.ac.jp
FU Grants-in-Aid for Scientific Research [23650093, 23300041] Funding
   Source: KAKEN
CR [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587735
   [Anonymous], INT J BIOMEDICAL SOF
   [Anonymous], 2009, WORKSH VID OR OBJ EV
   BAHAR B, 2007, P ENTERFACE 07 WORKS, P139
   Basharat A, 2009, IEEE INT C COMP VIS, P1
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bradski G, 2006, COMPUTER VISION IMAG, V104, P87
   Chen M.-Y., 2009, Tech. Rep. CMU-CS- 09-161
   Chen PH, 2005, APPL STOCH MODEL BUS, V21, P111, DOI 10.1002/asmb.537
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   Grimble M.J., 1994, ROBUST IND CONTROL O, P443
   Ikemura S, 2011, LECT NOTES COMPUT SC, V6495, P25, DOI 10.1007/978-3-642-19282-1_3
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li Z., 2008, Proceedings of the 16th ACM international conference on Multimedia, P671
   Matikainen P., 2010, P EUR C COMP VIS ECC
   MIKOLAJCZYK K, 2008, IEEE INT C COMP VIS
   MORENCY LP, 2006, P 11 INT C INT US IN
   Nefian AV, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P286, DOI 10.1109/ICIP.2001.958107
   Nickel K, 2007, IMAGE VISION COMPUT, V25, P1875, DOI 10.1016/j.imavis.2005.12.020
   Nintendo Japan, WII REM CONTR
   Panasonic Japan, D IM
   Park C, 2008, IEEE C AUT FAC GEST
   Rajesh V, 2009, INT J RECENT TRENDS, V1
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shiraki T., 2006, P IFIP INT C NETW PA, P50
   Sillito RR, 2008, P BMVC, P104
   Srebrny P, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.29
   Sugawara M, 2008, EBU TECHNICAL REV Q2, VQ2
   Sun XH, 2009, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2009.5204255
   Valstar M, 2004, IEEE SYS MAN CYBERN, P635
   VIOLA P, 2001, IEEE INT C COMP VIS
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xia Lu, 2011, WORKSH HUM ACT UND 3
   Yu XG, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P273
NR 38
TC 20
Z9 22
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 761
EP 783
DI 10.1007/s11042-011-0870-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500011
DA 2024-07-18
ER

PT J
AU Daronco, LC
   Roesler, V
   de Lima, JV
   Balbinot, R
AF Daronco, Leonardo Crauss
   Roesler, Valter
   de Lima, Jose Valdeni
   Balbinot, Ricardo
TI Quality analysis of scalable video coding on unstable transmissions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable video coding; Subjective video assessment; Video quality;
   Layered multicast; H.264 SVC
ID INTERNET
AB This paper presents a study of quality on scalable video sequences coded using the scalable extension of the H.264 standard (SVC). A group of experiments was performed to measure, primarily, the effects that transmission instability has in the quality of the videos and the relationship among three scalability methods (spatial, temporal and quality) in terms of quality. A set of experiments was performed to measure the subjective quality using the ACR-HRR methodology and recommendations from ITU-R Rec. BT.500 and ITU-T Rec. P.910. The results show that the amount of instability is not as important as just the presence of instability, that video quality can be deteriorated due to instability and that temporal scalability usually produces videos with worse quality than spatial and quality scalabilities.
C1 [Daronco, Leonardo Crauss; Roesler, Valter; de Lima, Jose Valdeni] Fed Univ Rio Grande Sul UFRGS, Porto Alegre, RS, Brazil.
   [Balbinot, Ricardo] Vivo Networks, Sao Paulo, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Daronco, LC (corresponding author), Fed Univ Rio Grande Sul UFRGS, Porto Alegre, RS, Brazil.
EM lcdaronco@inf.ufrgs.br; roesler@inf.ufrgs.br; valdeni@inf.ufrgs.br;
   rbalbinot@vivo.com.br
FU CNPq
FX This work was possible due to the financial sponsorship by CNPq. We
   would also like to thank everyone that participated in the subjective
   evaluations and Marcelo Magalhaes Foohs for the paper revision.
CR [Anonymous], 2002, METH SUBJ ASS QUAL T
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], 1999, SUBJ VID QUA ASS MET
   Baroncini V, 2006, IEICE T FUND ELECTR, VE89A, P2933, DOI 10.1093/ietfec/e89-a.11.2933
   Barzilay M. A. J., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P285
   Brotherton MD, 2006, IEICE T FUND ELECTR, VE89A, P2920, DOI 10.1093/ietfec/e89-a.11.2920
   Daronco LC, 2010, P 25 ACM S APPL COMP, V3, P1898
   De Simone F., 2009, 1 INT WORKSH QUAL MU
   Dumic E, 2010, MULTIMED TOOLS APPL, V49, P409, DOI 10.1007/s11042-009-0441-2
   Hsu CH, 2007, INT WORKSH QUAL SERV, P182, DOI 10.1109/IWQOS.2007.376565
   Kozamernik F, 2005, SMPTE MOTION IMAG J, V114, P152, DOI 10.5594/J11535
   Li B, 2003, IEEE NETWORK, V17, P24
   Li J, 2007, COMPUT NETW, V51, P1421, DOI 10.1016/j.comnet.2006.07.014
   McCanne S., 1996, Computer Communication Review, V26, P117, DOI 10.1145/248157.248168
   Miller Rupert G., 1997, TEXTS STAT SCI SERIE
   Monteiro JM, 2007, IEEE S COMP COMM MW
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Pereira F, 1997, IEEE T CIRC SYST VID, V7, P32, DOI 10.1109/76.554416
   Pinson M, 2003, PROC SPIE, V5150, P573, DOI 10.1117/12.509908
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Roesler V, 2003, P IEEE INT C TEL ICT, P1
   Schwarz H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1929, DOI 10.1109/ICME.2006.262934
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   VICISANO L, 1998, P IEEE INFOCOM SAN F
   *VQEG, 2008, MULT GROUP TEST PLAN
   Wang Y, 2005, IEEE T CIRC SYST VID, V15, P1270, DOI 10.1109/TCSVT.2005.854224
   Widmer J, 2001, ACM SIGCOMM COMP COM, V31, P275, DOI 10.1145/964723.383081
   Widmer J, 2001, IEEE NETWORK, V15, P28, DOI 10.1109/65.923938
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T, 2007, JOINT DRAFT ITU T RE
   Winkler S, 2003, PROC SPIE, V5007, P104, DOI 10.1117/12.477766
   Winkler S, 2009, P IEEE 7 INT C INF C
NR 32
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 571
EP 597
DI 10.1007/s11042-011-0760-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700004
DA 2024-07-18
ER

PT J
AU Cambria, E
   Grassi, M
   Hussain, A
   Havasi, C
AF Cambria, Erik
   Grassi, Marco
   Hussain, Amir
   Havasi, Catherine
TI Sentic Computing for social media marketing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AI; Semantic Web; Knowledge base management; NLP; Opinion mining and
   sentiment analysis
ID COMMON-SENSE; DIGITAL INTUITION; HUMAN EMOTIONS
AB In a world in which millions of people express their opinions about commercial products in blogs, wikis, fora, chats and social networks, the distillation of knowledge from this huge amount of unstructured information can be a key factor for marketers who want to create an image or identity in the minds of their customers for their product, brand or organization. Opinion mining for product positioning, in fact, is getting a more and more popular research field but the extraction of useful information from social media is not a simple task. In this work we merge AI and Semantic Web techniques to extract, encode and represent this unstructured information. In particular, we use Sentic Computing, a multi-disciplinary approach to opinion mining and sentiment analysis, to semantically and affectively analyze text and encode results in a semantic aware format according to different web ontologies. Eventually we represent this information as an interconnected knowledge base which is browsable through a multi-faceted classification website.
C1 [Cambria, Erik; Hussain, Amir] Univ Stirling, Dept Math & Comp Sci, Stirling FK9 4LA, Scotland.
   [Grassi, Marco] Univ Politecn Marche, Dept Biomed Elect & Telecommun Engn, I-60131 Ancona, Italy.
   [Havasi, Catherine] MIT, MIT Media Lab, Cambridge, MA 02139 USA.
C3 University of Stirling; Marche Polytechnic University; Massachusetts
   Institute of Technology (MIT)
RP Cambria, E (corresponding author), Univ Stirling, Dept Math & Comp Sci, Stirling FK9 4LA, Scotland.
EM eca@cs.stir.ac.uk; m.grassi@univpm.it; ahu@cs.stir.ac.uk;
   havasi@media.mit.edu
RI Hussain, Amir/AAG-6299-2020; Cambria, Erik/C-2103-2013; Li,
   Yang/HPC-4054-2023
OI Hussain, Amir/0000-0002-8080-082X; Cambria, Erik/0000-0002-3030-1280; 
CR Alm C, 2005, HLT EMNLP VANC
   [Anonymous], 32 I LEARN SCI
   [Anonymous], 2006, The emotion machine
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Cambria E., 2009, WOMSA CAEPIA SEV
   Cambria E, 2010, LECT NOTES ARTIF INT, V6279, P385, DOI 10.1007/978-3-642-15384-6_41
   Cambria E, 2010, LECT NOTES COMPUT SC, V5967, P148
   Cambria E, 2009, LECT NOTES COMPUT SC, V5707, P252, DOI 10.1007/978-3-642-04391-8_33
   Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Goertzel B., 2000, AISB BIRM
   Grassi M, 2009, LECT NOTES COMPUT SC, V5707, P244, DOI 10.1007/978-3-642-04391-8_32
   HAVASI C, 2007, RANLP BOR
   Havasi C, 2009, IEEE INTELL SYST, V24, P24, DOI 10.1109/MIS.2009.72
   HU M, 2004, AAAI SAN JOS
   N Nicolov, 2006, AAAI S COMP APPR AN
   Pang B, 2002, EMNLP PHIL
   Pang B, 2004, ACL BARC
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Rocha L., 2003, A Practical Approach to Microarray Data Analysis, P91, DOI [10.1007/0-306-47815-3, DOI 10.1007/0-306-47815-35, 10.1007/0-306-47815-3_5, DOI 10.1007/0-306-47815-3_5]
   Salzman M., 2003, BUZZ HARNESS POWER I
   SOMASUNDARAN S, 2008, COLING MANCH
   Sood S, 2007, WWW BANFF
   Sood S, 2009, ICWSM SEATTL
   STRAPPARAVA C, 2004, LREC LISB
   Turney P, 2002, ACL PHIL
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   WILSON T, 2005, HLT EMNLP VANC
NR 28
TC 91
Z9 99
U1 2
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 557
EP 577
DI 10.1007/s11042-011-0815-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000007
DA 2024-07-18
ER

PT J
AU Hsu, JL
   Li, YF
AF Hsu, Jia-Lien
   Li, Yen-Fu
TI A cross-modal method of labeling music tags
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal; Mel-frequency cepstral coefficients (MFCCs); Gaussian
   mixture model (GMM); Tag labeling; Music information retrieval
ID SIGNALS; AUDIO
AB In this paper, we discuss various features of music objects in two kinds of domain. Among these features, Mel-frequency cepstral coefficients (MFCCs) are further discussed and described by Gaussian mixture model (GMM). Also, the similarity between GMMs are investigated accordingly. Then, we employ the multimedia graph as a cross-modal method to associate MFCCs and genre tags of music objects. By applying link analysis algorithm in the graph, we label appropriate genre tags for target music objects. Also, we perform experiments to show performance, effectiveness, and parameter setting of our approach.
EM alien@csie.fju.edu.tw
RI Hsu, Jia-Lien/K-7271-2015
OI Hsu, Jia-Lien/0000-0002-4818-3198
FU Fu Jen Catholic University [409731044039]; National Science Council
   [NSC-97-2221-E-030-013]
FX This research was supported by Fu Jen Catholic University with Project
   No. 409731044039, and sponsored by the National Science Council under
   Contract No. NSC-97-2221-E-030-013.
CR [Anonymous], 2002, MARKOVIAN PAGE RANKI
   [Anonymous], 2000, ISMIR
   Aucouturier J-J, 2002, P INT S MUS INF RETR
   Aucouturier J-J., 2004, JNRSAS, V1
   Aucouturier JJ, 2005, IEEE T MULTIMEDIA, V7, P1028, DOI 10.1109/TMM.2005.858380
   Berenzweig A, 2004, COMPUT MUSIC J, V28, P63, DOI 10.1162/014892604323112257
   Berenzweig A, 2003, P INT S MUS INF RETR
   Blum Thomas L, 1999, US Patent, Patent No. [5,918,223, 5918223]
   Brin S., 1998, QUARTERLY
   Chen J-Y, 2008, P ICASSP, P4553
   Dongge L, 2006, P ACM INT C MULT, P32
   Ellis DPW, 2006, COMMUN ACM, V49, P32, DOI 10.1145/1145287.1145310
   Eronen A., 2000, P IEEE INT C AC SPEE
   Haveliwala T. H, 2002, P INT WORLD WID WEB
   Krishnamoorthy P, 2011, MULTIMED TOOLS APPL, V54, P415, DOI 10.1007/s11042-010-0546-7
   Kullback S., 1968, INFORM THEORY STAT
   Langlois T, 2009, P INT S MUS INF RETR
   LI T, 2003, P 26 ANN INT ACM SIG, P282
   Oliveira-Brochado A., 2005, Assessing the number of components in mixture models: a review
   Pachet F, 2006, MULTIMED TOOLS APPL, V30, P331, DOI 10.1007/s11042-006-0030-6
   Page L., 1999, PAGERANK CITATION RA
   Pampalk E., 2005, Proceedings of the International Conference on Music Information Retrieval, P628
   Pan J-Y, 2004, P ACM INT C KNOWL DI
   Schwarz D, 1999, P INT COMP MUS C ICM
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Zeng W, 2011, MULTIMED TOOLS APPL, V55, P525, DOI 10.1007/s11042-010-0564-5
NR 27
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 521
EP 541
DI 10.1007/s11042-011-0729-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900004
DA 2024-07-18
ER

PT J
AU Wang, DX
   Xiong, ZH
   Zhang, MJ
AF Wang, De-xin
   Xiong, Zhi-hui
   Zhang, Mao-jun
TI An application oriented and shape feature based multi-touch gesture
   description and recognition method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-touch; Surface computing; Human computer interface; Gesture
   description; gesture recognition
AB In order to customize multi-touch gestures for different applications, and facilitate multi-touch gesture recognition, an application oriented and shape feature based multi-touch gesture description and recognition method is proposed. In this method, multi-touch gestures are classified into two categories, namely atomic gesture and combined gesture, where combined gesture is a combination of atomic gestures using temporal, spatial and logical relationships. For description, users' motions are mapped into gestures, and then semantic constraints of an application are extracted to build the accessible relationships between gestures and entity states. For recognition, trajectories of a gesture are projected onto an image, and the shape feature of every trajectory and relationships between each other are extracted to match with gesture templates. Experiments show that this method is independent to multi-touch platforms, robust to manipulating differences of users, and it is scalable and reusable for users and applications.
C1 [Wang, De-xin; Xiong, Zhi-hui; Zhang, Mao-jun] Natl Univ Def Technol, Coll Informat Syst & Management, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Wang, DX (corresponding author), Natl Univ Def Technol, Coll Informat Syst & Management, Changsha 410073, Hunan, Peoples R China.
EM nksky.wdx@gmail.com; xzhnudt@hotmail.com; maojun.z@gmail.com
FU National Natural Science Foundation (NSFC) of China [60705013, 60872150,
   60803101, 60773023]; China Postdoctoral Science Foundation [200902665,
   20070410977]; Natural Science Foundation of Hunan Province in China
   [08JJ4018]
FX This research was partially supported by National Natural Science
   Foundation (NSFC) of China with project No. 60705013, No. 60872150, No.
   60803101 and No. 60773023; China Postdoctoral Science Foundation special
   funding with project No. 200902665, China Postdoctoral Science
   Foundation with project No. 20070410977, Natural Science Foundation of
   Hunan Province in China with project No. 08JJ4018
CR Allen J.F., 1997, Spatial and Temporal Reasoning, P205, DOI DOI 10.1007/978-0-585-28322-7_7
   [Anonymous], MULTITOUCH SYSTEMS I
   [Anonymous], FACT
   [Anonymous], P GI 06 CIPS TOR
   [Anonymous], IPHONE
   [Anonymous], Hausdorff Distance
   [Anonymous], P 18 ANN ACM S US IN
   [Anonymous], RacerPro
   [Anonymous], Ontology
   [Anonymous], REAS
   [Anonymous], 2006, 2006 IEEE COMP VIS P
   [Anonymous], 2009, Proceedings of the 23rd British HCI Group Annual Conference on People and Computers: Celebrating People and Technology, DOI [10.14236/ewic/hci2009.55, DOI 10.14236/EWIC/HCI2009.55]
   [Anonymous], PELLET
   [Anonymous], 2004, W3C RECOMMENDATION 1
   [Anonymous], P UIST 05
   [Anonymous], MICR SURF
   [Anonymous], INT C COMP SYST TECH
   Bailador G., 2007, P ICST 2 INT C BODY, P1
   Bhuyan MK, 2006, CONF CYBERN INTELL S, P748
   Bhuyan MK, 2005, LECT NOTES COMPUT SC, V3776, P509
   Bimber O., 1999, 7th International Conference in Central Europe on Computer Graphics, Visualization and Interactive Digital Media'99. in co-operation with EUROGRAPHICS and IFIP WG 5.10. WSCG'99. Conference Proceedings, P24
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen HH., 1986, Proceedings of International Computing Symposium, P103
   Elias G, 2007, United States Patent Application, Patent No. 20070177803
   Fu CW, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2213
   Hayes ST, 2010, ACMIEEE INT CONF HUM, P97, DOI 10.1109/HRI.2010.5453253
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010
   Lee YH, 2009, EXPERT SYST APPL, V36, P1123, DOI 10.1016/j.eswa.2007.10.038
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Micire M., 2009, P 900 INT C INTERACT, P41, DOI DOI 10.1145/1731903.1731912
   Micire M., 2009, P 13 ACM INT C INTEL, P425, DOI DOI 10.1145/1502650.1502712
   Noy Natalie, 2001, ONTOLOGY DEV 101 GUI
   Pengyu Hong, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P410, DOI 10.1109/AFGR.2000.840667
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Wang DX, 2011, MULTIMED TOOLS APPL, V51, P963, DOI 10.1007/s11042-009-0425-2
   Webel S., 2008, P ACM S VIRTUAL REAL, P263
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Wu M, 2006, FIRST IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, P183
   Wu Mike, 2003, P 16 ANN ACM S US IN, P193, DOI [10.1145/964696.964718, DOI 10.1145/964696.964718]
   Yen-Ting Chen, 2007, Proceedings of the 3rd Annual IEEE Conference on Automation Science and Engineering, P527
   Yuksel BF, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P855
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 43
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 497
EP 519
DI 10.1007/s11042-011-0730-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900003
DA 2024-07-18
ER

PT J
AU Wei, G
   Wu, LN
   Wang, SH
   Qi, CH
AF Wei, Geng
   Wu, Lenan
   Wang, Shuihua
   Qi, Chenhao
TI Fast mode selection for H.264 video coding standard based on motion
   region classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mode selection; Fast algorithm; Motion region classification; H.264;
   Video coding
AB H.264/AVC achieves higher compression efficiency than previous video coding standards. However, the process of selecting the optimal coding mode for each macroblock (MB) results in extremely high computation complexity, which make it difficult for practical use. In this paper, an efficient algorithm is proposed to reduce the complexity of MB mode selection. The proposed algorithm identified the interior region of the motion object by using the motion vectors information firstly. For the interior region surrounded by the identical motion vectors, we skip the mode selection of the MBs and then treat them with large block size modes directly. We also discuss the specific examples in this region. For the boundary region, we classify them into different types according to the coded mode information. After that we process the different regions with different mode set distinctly. Experimental results show that the proposed algorithm can save the encoding time up to 46% on average compared to the conventional method in the JVT JM8.6 reference encoder with only 0.12 dB performance degradation.
C1 [Wei, Geng] Hohai Univ, Coll Comp & Informat, Nanjing 210098, Jiangsu, Peoples R China.
   [Wu, Lenan; Qi, Chenhao] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
   [Wang, Shuihua] City Colledge New York, Grove Sch Engn, New York, NY 10031 USA.
C3 Hohai University; Southeast University - China; City University of New
   York (CUNY) System; City College of New York (CUNY)
RP Wei, G (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing 210098, Jiangsu, Peoples R China.
EM wei_geng@163.com; wuln@seu.edu.cn
RI Qi, Chenhao/D-9367-2014; Wang, shuihua/G-7326-2016
OI Qi, Chenhao/0000-0002-7360-939X; Wang, shuihua/0000-0003-4713-2791
FU National Natural Science Foundation of China [60572063]; Specialized
   Research Fund for the Doctoral Program of Higher Education [20040487009]
FX The work is supported by the National Natural Science Foundation of
   China (No. 60572063) and the Specialized Research Fund for the Doctoral
   Program of Higher Education (No. 20040487009). The authors would like to
   thank anonymous reviewers for their constructive comments.
CR Ba SN, 2006, IEEE IMAGE PROC, P1349, DOI 10.1109/ICIP.2006.312584
   Bu JJ, 2006, AC SPEECH SIGN P 200
   Choi I, 2006, IEEE T CIRC SYST VID, V16, P1557, DOI 10.1109/TCSVT.2006.883506
   Jeon B., 2003, FAST MODE DECISION H
   Jing X, 2004, ELECTRON LETT, V40, P1050, DOI 10.1049/el:20045243
   Lee PJ, 2006, IEEE IMAGE PROC, P1365, DOI 10.1109/ICIP.2006.312588
   Park SI, 2006, ELECTRON LETT, V42, P523, DOI 10.1049/el:20060155
   Wang XW, 2009, MULTIMED TOOLS APPL, V43, P131, DOI 10.1007/s11042-009-0260-5
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zeng HQ, 2009, IEEE T CIRC SYST VID, V19, P491, DOI 10.1109/TCSVT.2009.2014014
   Zhou M, 2002, EVALUATION SIMPLIFIC
   Zhou Z, 2006, J VIS COMMUN IMAGE R, V17, P243, DOI 10.1016/j.jvcir.2005.05.003
NR 12
TC 1
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 453
EP 466
DI 10.1007/s11042-010-0720-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900001
DA 2024-07-18
ER

PT J
AU Vatavu, RD
AF Vatavu, Radu-Daniel
TI Presence bubbles: supporting and enhancing human-human interaction with
   ambient media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-human interaction; Human-computer interaction; Ambient media;
   Presence; Bubbles
AB People communicate using speech, gestures and emotions but sometimes these may not be enough in order to express the true intended message. This results in miscommunication and sometimes frustration which are perceived negatively by the interacting participants. We propose an investigation into expressive ambient media in the form of visual surfaces as digital enhancements for Human-Human Interaction. The goal is to allow new modalities for self-expression as well as to enhance communication by displaying personal digital content in the form of Presence Bubbles. Ambient media allow thus communication, presence and socialization opportunities and transform into responsive and expressive media for supporting and enhancing human-human interaction.
C1 Univ Stefan Cel Mare Suceava, Res Ctr Comp Sci, Suceava 720229, Romania.
C3 Stefan cel Mare University of Suceava
RP Vatavu, RD (corresponding author), Univ Stefan Cel Mare Suceava, Res Ctr Comp Sci, Str Univ 13, Suceava 720229, Romania.
EM vatavu@eed.usv.ro
RI Vatavu, Radu-Daniel/AAA-3282-2022; Vatavu, Radu-Daniel/F-1820-2017
OI Vatavu, Radu-Daniel/0000-0002-7631-6445
CR [Anonymous], 2004, P ACM S US INT SOFTW
   [Anonymous], 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095054, DOI 10.1145/1095034.1095054]
   Ballagas R., 2005, CHI 05 CHI 05 EXTEND, P1200
   Bergstrom T, 2006, CHI 2006 HUM FACT CO, P532, DOI [10.1145/1125451.1125565, DOI 10.1145/1125451.1125565]
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chang Angela, 2001, CHI'01 extended abstracts on Human factors in computing systems, P313, DOI DOI 10.1145/634067.634252
   Chung Hyemin., 2006, Proceeding of CHI '06 Extended Abstracts on Human Factors in Computing Systems-CHI EA '06, P375, DOI [10.1145/1125451.1125532, DOI 10.1145/1125451.1125532]
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Joseph, 2005, CHI 05 EXTENDED ABST, P1529, DOI DOI 10.1145/1056808.1056958
   Kim S, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P619
   Launius R., 2005, Arkham Horror
   Lee Johnny C., 2002, Proceedings of the 15th annual ACM symposium on User interface software and technology, P81, DOI DOI 10.1145/571985.571997
   Lugmayr A, 2009, 2 SAME 2009 WORKSH A
   McKay M., 2009, Messages: The communication skills book, V3rd
   Ou LC, 2004, COLOR RES APPL, V29, P292, DOI 10.1002/col.20024
   Rivera K., 1996, CHI 96, P99, DOI DOI 10.1145/257089.257180
   Shangfei Wang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P269, DOI 10.1109/CSSE.2008.1207
   Shirazi Alireza Sahami, 2009, P 11 INT C HUM COMP, DOI [10.1145/1613858.1613965, DOI 10.1145/1613858.1613965]
   Skog T., 2004, P 5 C DESIGNING INTE, P325
   Tanase CA, 2008, ADV ELECTR COMPUT EN, V8, P61, DOI 10.4316/aece.2008.02011
   Truong K.N., 2004, Proc. of CHI, (Vienna, P1203, DOI DOI 10.1145/985921.986024
   Vatavu RD, 2009, 2 WORKSH SEM AMB MED
   Vogel D., 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   Wilson Andrew D., 2007, Proceedings Graphics Interface 2007, P119, DOI 10.1145/1268517.1268539
NR 24
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 2
BP 371
EP 383
DI 10.1007/s11042-010-0674-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 921NO
UT WOS:000302484500005
DA 2024-07-18
ER

PT J
AU Lu, JC
   Liu, FL
   Luo, XY
   Yang, CF
AF Lu, Jicang
   Liu, Fenlin
   Luo, Xiangyang
   Yang, Chunfang
TI Parameter-estimation and algorithm-selection based United-Judgment for
   image steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; United-Judgment; Parameter-estimation; Algorithm-selection
ID LSB STEGANOGRAPHY
AB In order to synthetically utilize multiple steganalytic algorithms, and further improve the detection accuracy and enhance detection reliability, United-Judgment methods are researched and analyzed in this paper. According to the performance of each algorithm, United-Judgment methods for both blind and specific steganalysis are proposed based on parameter-estimation and algorithm-selection. Experiments are carried out for the former with seven typical blind detections and the latter one with five typical spatial domain steganalytic methods. Experimental results show that the proposed methods can synthetically utilize the existing multiple algorithms effectively, and achieve more reliable detection.
C1 [Lu, Jicang; Liu, Fenlin; Luo, Xiangyang; Yang, Chunfang] Inst Informat Sci & Technol, Zhengzhou 450002, Peoples R China.
C3 PLA Information Engineering University
RP Lu, JC (corresponding author), Inst Informat Sci & Technol, Zhengzhou 450002, Peoples R China.
EM lujicang@sina.com; liufenlin@sina.vip.com; xiangyangluo@126.com;
   chunfangyang@126.com
FU National Natural Science Foundation of China [60970141, 60902102]; Found
   of Innovation Scientists and Technicians Troop Construction Projects of
   Henan Province [094200510008]; Science and Technology Program of
   Zhengzhou City [083SGYG21125]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 60970141 and 60902102), the Found of Innovation
   Scientists and Technicians Troop Construction Projects of Henan Province
   (Grand No. 094200510008) and the Science and Technology Program of
   Zhengzhou City (Grant No. 083SGYG21125).
CR Böhme R, 2006, PROC SPIE, V6072, DOI 10.1117/12.643701
   Böhme R, 2005, LECT NOTES COMPUT SC, V3727, P278
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2004, PROC SPIE, V5306, P23, DOI 10.1117/12.521350
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Kharrazi M, 2006, LECT NOTES COMPUT SC, V4300, P123
   Lie WN, 2005, IEEE T MULTIMEDIA, V7, P1007, DOI 10.1109/TMM.2005.858377
   Lu JC, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P500, DOI 10.1109/MINES.2009.213
   Lu PZ, 2004, LECT NOTES COMPUT SC, V3200, P116
   Luo XY, 2009, INT J INNOV COMPUT I, V5, P433
   Luo XY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P784
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Shi YQ, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P768, DOI 10.1109/ITCC.2005.138
   Xiao Yi Yu, 2009, Proceedings of the 2009 International Conference on Multimedia Information Networking and Security (MINES 2009), P41, DOI 10.1109/MINES.2009.269
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P49
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
NR 18
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 91
EP 107
DI 10.1007/s11042-010-0588-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800006
DA 2024-07-18
ER

PT J
AU Gao, HL
   Qiao, F
   Yang, HZ
AF Gao, Hongli
   Qiao, Fei
   Yang, Huazhong
TI Design and implementation of motion compensator in memory reduced HDTV
   decoder with embedded compression engine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video decoder; Reference pixel fetching; Motion compensation; Embedded
   compression; Memory optimization
ID FRAME-RECOMPRESSION ALGORITHM; VIDEO; ARCHITECTURE; REDUCTION
AB In this paper, a low-cost compatible motion compensator is implemented and integrated into a macroblock-level three-stage-pipelined HDTV decoder, in which an embedded compression (EC) engine is realized as well. The decoder with EC engine is designed to reduce the power consumption and memory bandwidth requirement since memory accesses are reduced. In the motion compensator, a boundary judgment scheme for reference pixel fetching is proposed to provide seamless integration in HDTV video decoder for the block-based EC engines. Furthermore, a buffer sharing mechanism is adopted to reduce extra memory requirement involved by EC. The reference pixel fetching unit costs only 17.3 K logic gates when the working frequency is set to 166.7 MHz. On average, when decoding HD1080 video sequence, 30% memory access reduction and 24% memory power consumption saving are achieved when a near lossless EC algorithm is integrated in the video decoder. In other words, the proposed motion compensator makes the EC engine an integral part of a memory reduced decoder without extra cost. Additionally, since the work in this paper is based on EC schemes, the EC design criterion are discussed, and several useful rules on the selection of EC algorithm are addressed for the video decoder of corresponding VLSI architecture.
C1 [Gao, Hongli; Qiao, Fei; Yang, Huazhong] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Qiao, F (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM ggl@mails.tsinghua.edu.cn; qiaofei@tsinghua.edu.cn
RI Gao, Hongli/G-9225-2012; Wang, Fei/KEH-6292-2024
CR Bruni R, 1998, IEEE T CONSUM ELECTR, V44, P537, DOI 10.1109/30.713161
   Budagavi M, 2008, INT CONF ACOUST SPEE, P1165, DOI 10.1109/ICASSP.2008.4517822
   Chen WY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P825, DOI 10.1109/ICME.2008.4607562
   Cheng CC, 2005, IEEE WRK SIG PRO SYS, P532
   Chien CD, 2005, IEEE INT SYMP CIRC S, P4542
   Chuan-Yung Tsai, 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P1199
   de With PHN, 1998, IEEE T CONSUM ELECTR, V44, P545, DOI 10.1109/30.713162
   Gao HL, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P593, DOI 10.1109/ICALIP.2008.4590164
   Graham S.L., 2004, GETTING SPEED FUTURE
   JIA X, 2005, P 2005 C HIGH DENS M
   Kim H, 1999, ELECTRON LETT, V35, P1929, DOI 10.1049/el:19991300
   LEE CH, 2008, P NVSMW, P109
   Lee TY, 2003, IEEE T CIRC SYST VID, V13, P529, DOI 10.1109/TCSVT.2003.813425
   Lee YJ, 2007, IEEE INT SYMP CIRC S, P1621, DOI 10.1109/ISCAS.2007.378829
   Lee YX, 2008, IEEE INT SYMP CIRC S, P2586, DOI 10.1109/ISCAS.2008.4541985
   Li Y, 2007, IEEE INT SYMP CIRC S, P2906, DOI 10.1109/ISCAS.2007.377857
   Li Y, 2008, J SIGNAL PROCESS SYS, V52, P111, DOI 10.1007/s11265-007-0124-z
   Micron, 2002, MT48LC4M32B2 MICR DR
   Micron, 2009, SDRAM SYST POW CALC
   Ohira H, 1999, IEICE T FUND ELECTR, VE82A, P1588
   Park SI, 2003, IEEE T CONSUM ELECTR, V49, P1348, DOI 10.1109/TCE.2003.1261239
   Zheng JH, 2008, IEEE T CONSUM ELECTR, V54, P687, DOI 10.1109/TCE.2008.4560148
   Zhu JH, 2004, 2004: 7TH INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUITS TECHNOLOGY, VOLS 1- 3, PROCEEDINGS, P1621
NR 23
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 597
EP 614
DI 10.1007/s11042-010-0628-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700010
DA 2024-07-18
ER

PT J
AU Magalhaes, J
   Rüger, S
AF Magalhaes, Joao
   Rueger, Stefan
TI Using manual and automated annotations to search images by semantic
   similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Semantic similarity; Keyword space; Manual image
   annotation; Automated image annotation
ID RETRIEVAL; QUERY
AB Finding semantically similar images is a problem that relies on image annotations manually assigned by amateurs or professionals, or automatically computed by some algorithm using low-level image features. These image annotations create a keyword space where a dissimilarity function quantifies the semantic relationship among images. In this setting, the objective of this paper is two-fold. First, we compare amateur to professional user annotations and propose a model of manual annotation errors, more specifically, an asymmetric binary model. Second, we examine different aspects of search by semantic similarity. More specifically, we study the accuracy of manual annotations versus automatic annotations, the influence of manual annotations with different accuracies as a result of incorrect annotations, and revisit the influence of the keyword space dimensionality. To assess these aspects we conducted experiments on a professional image dataset (Corel) and two amateur image datasets (one with 25,000 Flickr images and a second with 269,648 Flickr images) with a large number of keywords, with different similarity functions and with both manual and automatic annotation methods. We find that Amateur-level manual annotations offers better performance for top ranked results in all datasets (MP@20). However, for full rank measures (MAP) in the real datasets (Flickr) retrieval by semantic similarity with automatic annotations is similar or better than amateur-level manual annotations.
C1 [Magalhaes, Joao] Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Comp Sci, P-1200 Lisbon, Portugal.
   [Rueger, Stefan] Open Univ, Knowledge Media Inst, Milton Keynes MK7 6AA, Bucks, England.
C3 Universidade Nova de Lisboa; Open University - UK
RP Magalhaes, J (corresponding author), Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Comp Sci, P-1200 Lisbon, Portugal.
EM jmag@di.fct.unl.pt; s.rueger@open.ac.uk
RI FCTUNL, CITI/G-6714-2011; Magalhaes, Joao/A-2054-2010
OI Rueger, Stefan/0000-0002-6013-9018; Magalhaes, Joao/0000-0001-6290-5719
CR [Anonymous], 2008, ACM INT C MULT INF R
   [Anonymous], 2009, NUSWIDE: A real-world web image database from National University of Singapore, DOI DOI 10.1145/1646396.1646452
   Bach JR, 1996, P SPIE INT SOC OPT E
   Cox IJ, 1996, P INT C PATT REC
   Croft WB, 1991, ACM SIGIR C RES DEV
   Duygulu P., 2002, EUR C COMP VIS COP D
   FENG SL, 2004, IEEE C COMP VIS PATT
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Hare JS, 2006, SPIE C MULT CONT AN
   Haubold A, 2006, IEEE INT C MULT EXP
   Hauptmann A, 2007, ACM C IM VID RETR AM
   Heesch D, 2004, INT C IM VID RETR DU
   Howarth P, 2004, INT C IM VID RETR DU
   Kennedy L., 2007, FLICKR HELPS US MAKE
   Lu Y, 2000, ACM C MULT LOS ANG U
   Magalhaes J, 2008, EXPLORING MULTIMEDIA
   Magalhaes J, 2007, ACM C IM VID RETR AM
   Marlow C, 2006, C HYP HYP OD DENM
   Miller RB., 1968, AFIPS FALL JOINT COM
   Natsev A, 2007, ACM C MULT AUGSB GER
   Negoescu R-A, 2008, ACM C IM VID RETR NI
   Ortega M, 1997, ACM C MULT SEATTL WA
   Pickering MJ, 2002, TREC TEXT RETR C GAI
   Rasiwasia N, 2008, ACM MULT INF RETR VA
   Rasiwasia N, 2008, WORKSH SLAM CVPR
   Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138
   RATTENBURY T, 2007, AUTOMATIC EXTRACTION
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   SMITH JR, 1996, VISUALSEEK FULLY AUT
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TANG J, 2007, IEEE T CIRCUITS SYST, V17
   Tesic J, 2007, ACM C IM VID RETR AM
   Town C, 2004, IMAGE VISION COMPUT, V22, P251, DOI 10.1016/j.imavis.2003.10.002
   TURTLE H, 1991, ACM T INFORM SYST, V9, P187, DOI 10.1145/125187.125188
   Vasconcelos N, 2004, IEEE T INFORM THEORY, V50, P1482, DOI 10.1109/TIT.2004.830760
   Volkmer T, 2007, IEEE T MULTIMEDIA, V9, P967, DOI 10.1109/TMM.2007.900153
   Wactlar H.D., 1996, IEEE COMPUTER, P46
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wei X-Y, 2007, ONTOLOGY ENRICHED SE
NR 40
TC 4
Z9 6
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 109
EP 129
DI 10.1007/s11042-010-0558-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500006
DA 2024-07-18
ER

PT J
AU Baccaglini, E
   Tillo, T
   Olmo, G
AF Baccaglini, Enrico
   Tillo, Tammam
   Olmo, Gabriella
TI Image and video transmission: a comparison study of using unequal loss
   protection and multiple description coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resilience; Graceful degradation; Image and video transmission
ID ERROR-CORRECTION; INTERNET; CHANNELS
AB We present a performance comparison between multiple description coding (MDC) and unequal loss protection (ULP) as tools to deliver multimedia data to mobile users. Graceful-degradation encoding schemes are able to cope with packet losses due to time-variant channels as they allow the receivers to partially reconstruct the transmitted data with only a subset of received packets. We address a rate-distortion-based multiple description coding scheme and a state-of-the-art unequal loss protection algorithm based on Reed Solomon Forward Error Correction (FEC) codes. The comparison is performed using as a case study JPEG 2000 coded images and H.264/AVC video sequences transmitted over lossy packet networks. Complexity aspects are also considered. The simulation results show that both schemes allocate the same amount of redundancy for any given encoding output rate to protect the transmitted information. The main findings are that MDC, besides being computationally less intensive, achieves a smoother performance degradation, whereas, the ULP scheme yields superior performance in terms of the expected PSNR.
C1 [Baccaglini, Enrico; Olmo, Gabriella] Politecn Torino, Dipartimento Elettron, I-10129 Turin, Italy.
   [Tillo, Tammam] Xian Jiaotong Liverpool Univ, Dept Elect & Elect Engn, Suzhou 215123, Peoples R China.
C3 Polytechnic University of Turin; Xi'an Jiaotong-Liverpool University
RP Baccaglini, E (corresponding author), Politecn Torino, Dipartimento Elettron, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
EM enrico.baccaglini@polito.it; tammam.tillo@xjtlu.edu.cn;
   gabriella.olmo@polito.it
RI Olmo, Gabriella/AAB-4987-2021
OI OLMO, Gabriella/0000-0002-3670-9412; Baccaglini,
   Enrico/0000-0002-8101-0950
FU European Community [SEA IST-214063]; National Natural Science Foundation
   of China [60972085, 60903066]
FX This paper is based on work performed in the framework of the Project
   SEA IST-214063, funded by the European Community and it has been also
   supported by the National Natural Science Foundation of China (No.
   60972085, and No. 60903066).
CR [Anonymous], P 7 INT WORKSH MULT
   Baccaglini E, 2008, IEEE SIGNAL PROC LET, V15, P581, DOI 10.1109/LSP.2008.2001565
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   *JVT ISO IEC MPEG, 2003, H264 ITUT JVT ISOIEC
   Kim MY, 2006, IEEE T COMMUN, V54, P625, DOI 10.1109/TCOMM.2006.873071
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   Puri R, 2001, SIGNAL PROCESS-IMAGE, V16, P745, DOI 10.1016/S0923-5965(01)00005-4
   Puri R., 1999, Proceedings of the 33rd Asilomar Confe. Signals, Systems, V1, P342
   Tillo T, 2008, IEEE T CIRC SYST VID, V18, P59, DOI 10.1109/TCSVT.2007.913751
   Tillo T, 2010, IEEE T IMAGE PROCESS, V19, P1756, DOI 10.1109/TIP.2010.2045683
   Venkataramani R, 2003, IEEE T INFORM THEORY, V49, P2106, DOI 10.1109/TIT.2003.815767
NR 11
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2011
VL 55
IS 2
SI SI
BP 247
EP 259
DI 10.1007/s11042-010-0574-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 808HU
UT WOS:000293969500004
DA 2024-07-18
ER

PT J
AU Li, LS
   Li, J
AF Li, Lusong
   Li, Jing
TI MQSS: multimodal query suggestion and searching for video search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Query suggestion; Video search; Multimodal; Multimodal search
AB In this paper, we propose a multimodal query suggestion method for video search which can leverage multimodal processing to improve the quality of search results. When users type general or ambiguous textual queries, our system MQSS provides keyword suggestions and representative image examples in an easy-to-use dropdown manner which can help users specify their search intent more precisely and effortlessly. It is a powerful complement to initial queries. After the queries are formulated as multimodal query (i.e., text, image), the new queries are input to individual search models, such as text-based, concept-based and visual example-based search model. Then we apply multimodal fusion method to aggregate the above-mentioned several search results. The effectiveness of MQSS is demonstrated by evaluations over a web video data set.
C1 [Li, Lusong] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Software Dev Environm, Beijing, Peoples R China.
   [Li, Jing] Beihang Univ, Sch Comp Sci & Engn, Inst Adv Comp Technol, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Li, LS (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Software Dev Environm, Beijing, Peoples R China.
EM lilusong@gmail.com; lijing@nlsde.buaa.edu.cn
FU National Science and Technology major projects "core of electronic
   devices, high-end general chips and basic software product" of China;
   National 973 Program of China [2005CB321901]
FX The authors would like to gratefully acknowledge Dr. Xian-Sheng Hua, Dr.
   Tao Mei, Dr. Zheng-jun Zha, Dr. Wei Lai, Dr. Meng Wang and Linjun Yang
   for their thoughtful brainstorming and constructive suggestions on this
   work. The research was supported by National Science and Technology
   major projects "core of electronic devices, high-end general chips and
   basic software product" of China and National 973 Program of China
   (Grant No. 2005CB321901).
CR AMIR A, 2005, TRECVID WORKSH WASH
   [Anonymous], 2006, P 14 ACM INT C MULTI
   [Anonymous], TRECVID
   [Anonymous], P IEEE INFOCOM APR
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   BAEZAYATES R, 2004, EDBT 2004
   Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P407, DOI 10.1145/347090.347176
   CAMPBELL M, 2006, TRECVID 2006
   Carpineto C, 2001, ACM T INFORM SYST, V19, P1, DOI 10.1145/366836.366860
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Devijver P. A., 1982, PATTERN RECOGNITION, V265
   DONALD KM, 2005, P CIVR 05
   *FLICKR, FLICKR APIS
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   GAO W, 2007, P 30 ANN INT ACM SIG, P463
   Hauptmann A.G., 2006, Proceedings of the 14th annual ACM international conference on Multimedia, P385, DOI DOI 10.1145/1180639.1180721
   HAUPTMANN AG, 2006, TRECVID 2006
   Hsu W. H., 2006, MULTIMEDIA '06, P35
   Hua X.-S., 2006, TREC VIDEO RETRIEVAL
   IYENGAR G, 2005, P ACM MULT 05 SING
   KENNEDY L, 2005, P ACM INT C MULT, P882
   Kennedy L, 2008, P IEEE, V96, P567, DOI 10.1109/JPROC.2008.916345
   LAMADESINA AM, 2001, P ACM SIGIR 01
   Liu Jingjing., 2007, MULTIMEDIA 07, P208
   Ribeiro-Neto B., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P496, DOI 10.1145/1076034.1076119
   TIAN X, 2008, P ACM MULT 08 VANC
   VAPNIK V, 1995, STAT LEARNING THEORY
   WU L, 2007, P ACM MULT 07 AUGSB, P31
   XU J, 1996, P ACM SIGIR 96
   Yu Shipeng., 2003, P 12 INT C ONWORLDWI, P11, DOI DOI 10.1145/775152.775155
NR 30
TC 1
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 55
EP 68
DI 10.1007/s11042-010-0540-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100004
DA 2024-07-18
ER

PT J
AU Shen, HC
   Lee, CN
AF Shen, Hung-Che
   Lee, Chung-Nan
TI An interactive Whistle-to-Music composing system based on transcription,
   variation and chords generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Whistle-to-MIDI; Transcription templates; Lead sheet notation; Melodic
   variation; Music templates
AB Most people can whistle, sing or hum a song that they are familiar with. However, it is rather difficult for common people without formal music skills or training to compose a song. In this paper, we have constructed an interactive Whistle-to-Music composing system with which a user can compose MIDI format music by whistling into a microphone. The user can experiment with computer-aided composition such as melodic variation and chords generation. The transcription speed is so fast that MIDI notes can be echoed as feedback immediately while the user is still whistling. For computer-aided composition, the given melodic fragments are developed and accompanied with stylish chords generation. We then study users' experiences and present the results of an experiment which tests how accurately people whistle along a target melody. This preliminary prototype of the proposed system is proved to be a handy tool for computer-aided MIDI music creation.
C1 [Shen, Hung-Che] I Shou Univ, Inst Comp & Informat Engn, Sect 1, Kaohsiung 840, Taiwan.
   [Lee, Chung-Nan] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 804, Taiwan.
C3 I Shou University; National Sun Yat Sen University
RP Shen, HC (corresponding author), I Shou Univ, Inst Comp & Informat Engn, Sect 1, Hsueh Cheng Rd, Kaohsiung 840, Taiwan.
EM shungch@isu.edu.tw; cnlee@mail.cse.nsysu.edu.tw
CR ADAM JS, 2009, ACM SIGACCESS ACCESS
   ADAM JS, 2006, P 8 INT ACM SIGACCES
   ANTHONY H, 2004, P 2004 C NEW INT MUS, P185
   ASIF G, 1995, P ACM MULT, P231
   BILMES J, 2005, HUM LANG TECHN C C E
   BRUCE LJ, 1996, ORGANISED SOUND, V1, P157
   CHONG Y, 1996, THESIS MIT
   HUNGCHE S, 2007, MULTIMED TOOLS APPL, V2, P259
   IAN S, 2008, P COMP HUM IN PRESS
   KARLHEINZ E, 1995, P 2 BRAZ S COMP MUS
   MATHIAS F, 2005, P 2005 INT C NEW INT, P127
   MIDI Manufacturers Association, 1996, COMPL MIDI 1 0 DET S
   PAUL M, 1998, MAXIMUM MIDI, P105
   ROBERT MK, 2007, 4 SOUND MUS IN PRESS
   SAMAA AH, 2006, P HCI 2006 ENG 20 BC, V2
   TSURUTA S, 1988, IEEE T CONSUM ELECTR, V34, P819, DOI 10.1109/30.20189
   FREQUENCY ANAL
   2006, AUTOSCORE WILDCAT CA
   2006, OPCODE STUDIO VISION
NR 19
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 253
EP 269
DI 10.1007/s11042-010-0510-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700011
DA 2024-07-18
ER

PT J
AU Lien, BK
   Lin, YM
AF Lien, Brian K.
   Lin, Yen-ming
TI High-capacity reversible data hiding by maximum-span pairing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Data hiding; Halftone; Reversible; Watermark
ID HALF-TONE IMAGES; WATERMARKING
AB In this paper, we propose a reversible data hiding method for ordered dithered halftone images. To achieve reversibility and high capacity, the proposed method decomposes an ordered dithered halftone into a maximal number of subimage pairs with the same characteristic, and then hides data with a subimage-swapping operation, which converts a subimage pair into a subimage pair with opposite characteristic. Besides, this method maintains good visual quality by exchanging neighboring pixels instead of flipping individual pixels. Experimental results show that this method has the highest capacity among the existing reversible data hiding methods. A reversible authentication watermarking system is also proposed using this reversible watermarking method and it shows better visual quality compared to an existing method.
C1 [Lien, Brian K.; Lin, Yen-ming] Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, Hsinchuang, Taiwan.
C3 Fu Jen Catholic University
RP Lien, BK (corresponding author), Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, Hsinchuang, Taiwan.
EM 002954@mail.fju.edu.tw
CR [Anonymous], IEEE INT C MULT EXP
   BAHARAV Z, 1998, HPL9832
   Fu MS, 2002, IEEE T IMAGE PROCESS, V11, P477, DOI 10.1109/TIP.2002.999680
   Guo JM, 2008, IEEE T MULTIMEDIA, V10, P16, DOI 10.1109/TMM.2007.911259
   Hel-Or HZ, 2001, J ELECTRON IMAGING, V10, P794, DOI 10.1117/1.1382612
   KIM HY, 2005, P IEEE INT C IM PROC, V2, P1074
   Lau DL, 2003, IEEE SIGNAL PROC MAG, V20, P28, DOI 10.1109/MSP.2003.1215229
   LIAO PS, 2005, P KNOWL BAS INT INF, V2, P593
   LIEN BK, 2007, P IEEE 8 INT C COMP, V1, P319
   Lu ZM, 2006, LECT NOTES COMPUT SC, V4283, P71
   Ni Zhicheng, 2006, IEEE T CIRCUITS SYST, V16
   PAMBOUKIAN SVD, 2006, 6 S BRAS SEG INF SIS
   Pan JS, 2006, INT J COMPUT SCI NET, V6, P147
   Pei SC, 2005, IEEE SIGNAL PROC LET, V12, P333, DOI 10.1109/LSP.2004.842295
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Tsai CL, 2005, PATTERN RECOGN, V38, P1993, DOI 10.1016/j.patcog.2005.03.001
   ULICHNEY R, 1993, IS T SPIE S EL IM SC, V1913, P332
   Ulichney R., 1987, DIGITAL HALFTONING
   WANG CC, 2007, INT WORKSH MULT CONT, P351
   Wong PW, 2003, IEEE SIGNAL PROC MAG, V20, P59
   XUAN G, 2008, 19 INT C PATT REC IC
   Yu FX, 2009, STUD COMPUT INTELL, V227, P181
NR 22
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 499
EP 511
DI 10.1007/s11042-010-0497-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000015
DA 2024-07-18
ER

PT J
AU Seshadrinathan, K
   Bovik, AC
AF Seshadrinathan, Kalpana
   Bovik, Alan Conrad
TI Automatic prediction of perceptual quality of multimedia signals-a
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Survey; Quality assessment; Video quality; Image quality; Structural
   SIMilarity; Motion-based video integrity evaluation; Audio quality; Full
   reference; Perception
ID VISUAL AREA MT; AUDIO QUALITY; VIDEO QUALITY; STRUCTURAL SIMILARITY;
   HUMAN-VISION; CONTRAST-SENSITIVITY; STATISTICAL EVALUATION; SPEECH
   CODERS; ITU STANDARD; HUMAN EAR
AB We survey recent developments in multimedia signal quality assessment, including image, audio, video, and combined signals. Such an overview is timely given the recent explosion in all-digital sensory entertainment and communication devices pervading the consumer space. Owing to the sensory nature of these signals, perceptual models lie at the heart of multimedia signal quality assessment algorithms. We survey these models and recent competitive algorithms and discuss comparison studies that others have conducted. In this context we also describe existing signal quality assessment databases. We envision that the reader will gain a firmer understanding of the broad topic of multimedia quality assessment, of the various subdisciplines corresponding to different signal types, how these signals types co-relate in producing an overall user experience, and what directions of research remain to be pursued.
C1 [Seshadrinathan, Kalpana] Intel Corp, Santa Clara, CA 94086 USA.
   [Bovik, Alan Conrad] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
C3 Intel Corporation; University of Texas System; University of Texas
   Austin
RP Seshadrinathan, K (corresponding author), Intel Corp, 3600 Juliette Lane,M-S SC12-303, Santa Clara, CA 94086 USA.
EM kalpsesh@gmail.com; bovik@ece.utexas.edu
RI Bovik, Alan/B-6717-2012
OI Bovik, Alan/0000-0001-6067-710X
FU Direct For Computer & Info Scie & Enginr; Division Of Computer and
   Network Systems [0854904] Funding Source: National Science Foundation;
   Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [1116656] Funding Source: National Science
   Foundation
CR [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], J OPT SOC AM A
   [Anonymous], J144 ITUT
   [Anonymous], 1999, BS1387 ITU, P1387
   [Anonymous], BT50011 ITUR
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   BARKOWSKY M, 2007, IEEE WORKSH MULT SIG
   BEERENDS JG, 1992, J AUDIO ENG SOC, V40, P963
   Born RT, 2005, ANNU REV NEUROSCI, V28, P157, DOI 10.1146/annurev.neuro.26.041002.131052
   Brandenburg T, 1992, AUD ENG SOC C 11 INT
   Carnec M, 2008, SIGNAL PROCESS-IMAGE, V23, P239, DOI 10.1016/j.image.2008.02.003
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Channappayya SS, 2008, IEEE T IMAGE PROCESS, V17, P1624, DOI 10.1109/TIP.2008.2001400
   Channappayya SS, 2008, IEEE T IMAGE PROCESS, V17, P857, DOI 10.1109/TIP.2008.921328
   COLOMES C, 1995, J AUDIO ENG SOC, V43, P233
   Creusere C, 2003, 37 AS C SIGN SYST CO, V1, P265
   Creusere C, 2010, IEEE T SPEECH ADUDIO, P1
   Daly S., 1993, DIGITAL IMAGES HUMAN, P176
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   De Simone F, 2009, INT WORK QUAL MULTIM, P204, DOI 10.1109/QOMEX.2009.5246952
   Dehaene S, 2003, TRENDS COGN SCI, V7, P145, DOI 10.1016/S1364-6613(03)00055-X
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772
   FOLEY JM, 1994, J OPT SOC AM A, V11, P1710, DOI 10.1364/JOSAA.11.001710
   Fredericksen RE, 1997, J OPT SOC AM A, V14, P2557, DOI 10.1364/JOSAA.14.002557
   George S, 2006, IEEE T AUDIO SPEECH, V14, P1994, DOI 10.1109/TASL.2006.883248
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hekstra AP, 2002, SIGNAL PROCESS-IMAGE, V17, P781, DOI 10.1016/S0923-5965(02)00056-5
   Herre J, 1992, AUD ENG SOC C 11 INT
   Hewage CTER, 2008, ELECTRON LETT, V44, P963, DOI 10.1049/el:20081562
   Huber R, 2006, IEEE T AUDIO SPEECH, V14, P1902, DOI 10.1109/TASL.2006.883259
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   ITU-T, 2001, PERC EV SPEECH QUAL, P862
   ITU-T Recommendation P.800, 1996, P800 ITU T
   Kandadai S, 2008, INT CONF ACOUST SPEE, P221, DOI 10.1109/ICASSP.2008.4517586
   KARJALAINEN M, 1985, IEEE INT C AC SPEECH, V10, P608
   KELLY DH, 1984, J OPT SOC AM A, V1, P107, DOI 10.1364/JOSAA.1.000107
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   Lambrecht CJV, 1998, SIGNAL PROCESS, V67, P255, DOI 10.1016/S0165-1684(98)00043-7
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Lubin Jeffrey, 1993, P163
   Malkowski M, 2008, WIRELESS PERS COMMUN, V46, P19, DOI 10.1007/s11277-007-9353-5
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Masry M, 2006, IEEE T CIRC SYST VID, V16, P260, DOI 10.1109/TCSVT.2005.861946
   MEHRGARDT S, 1977, J ACOUST SOC AM, V61, P1567, DOI 10.1121/1.381470
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Movshon JA, 1996, J NEUROSCI, V16, P7733
   NACHMIAS J, 1974, VISION RES, V14, P1039, DOI 10.1016/0042-6989(74)90175-8
   PAILLARD B, 1992, J AUDIO ENG SOC, V40, P21
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218
   Rihs S, 1995, R211180CESR007B1 RAC
   Rix AW, 2006, IEEE T AUDIO SPEECH, V14, P1890, DOI 10.1109/TASL.2006.883260
   Rix AW, 2002, J AUDIO ENG SOC, V50, P755
   ROBSON JG, 1966, J OPT SOC AM, V56, P1141, DOI 10.1364/JOSA.56.001141
   ROSS J, 1991, P ROY SOC B-BIOL SCI, V246, P61, DOI 10.1098/rspb.1991.0125
   SCHOBER HAW, 1965, J OPT SOC AM, V55, P1086, DOI 10.1364/JOSA.55.001086
   SCHROEDER MR, 1978, J ACOUST SOC AM, V64, pS139, DOI 10.1121/1.2003844
   Seshadrinathan K., 2007, IEEE INT C AC SPEECH
   Seshadrinathan K, 2009, ESSENTIAL GUIDE TO VIDEO PROCESSING, 2ND EDITION, P417, DOI 10.1016/B978-0-12-374456-2.00013-X
   Seshadrinathan K, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P553, DOI 10.1016/B978-0-12-374457-9.00021-4
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Seshadrinathan K, 2008, IEEE IMAGE PROC, P1200, DOI 10.1109/ICIP.2008.4711976
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Simoncelli EP, 1998, VISION RES, V38, P743, DOI 10.1016/S0042-6989(97)00183-1
   Sporer Thomas, 1997, AUDIO ENG SOC CONVEN
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   TEO PC, 1994, P IEEE INT C IM PROC, V2, P982
   TERHARDT E, 1979, HEARING RES, V1, P155, DOI 10.1016/0378-5955(79)90025-X
   Thiede E, 1996, AUDIO ENG SOC CONVEN, P100
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Toet A, 2003, DISPLAYS, V24, P197, DOI 10.1016/j.displa.2004.01.006
   Van der Weken D, 2004, IMAGE VISION COMPUT, V22, P695, DOI 10.1016/j.imavis.2004.03.002
   van Dijk A. M., 1995, P SPIE ADV IMAGE VID
   VANNES FL, 1967, J OPT SOC AM, V57, P401, DOI 10.1364/JOSA.57.000401
   Video Quality Experts Group, 2003, FIN VQEG REP VAL OBJ
   Wandell B. A, 1995, Foundations of vision
   WANG SH, 1992, IEEE J SEL AREA COMM, V10, P819, DOI 10.1109/49.138987
   Wang Z, 2005, INT CONF ACOUST SPEE, P573
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2007, J OPT SOC AM A, V24, pB61, DOI 10.1364/JOSAA.24.000B61
   Watson A. B., 1993, DIGITAL IMAGES HUMAN
   WATSON AB, 1987, COMPUT VISION GRAPH, V39, P311, DOI 10.1016/S0734-189X(87)80184-6
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   Zielinski S, 2005, J AUDIO ENG SOC, V53, P4
   ZWICKER E, 1965, PSYCHOL REV, V72, P3, DOI 10.1037/h0021703
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 97
TC 26
Z9 29
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 163
EP 186
DI 10.1007/s11042-010-0625-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800007
DA 2024-07-18
ER

PT J
AU Jang, C
   Yoon, T
   Cho, HG
AF Jang, Chuljin
   Yoon, Taijin
   Cho, Hwan-Gue
TI Digital photo classification methodology for groups of photographers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital photo; Photo clustering; Photo album; Image retrieval; EXIF
AB Digital cameras have become an essential product when traveling or attending events. Because of its popularity and low cost, it is increasingly likely that more than one camera will be used at an event. The total number of photos captured is also increasing. Although the cost of digital photographs is low, managing numerous digital photos is burdensome to most users. Thus, an intelligent management tool for digital photos is required. In this paper, we propose novel clustering algorithms for concurrent digital photos obtained from multiple cameras. Since previous studies only considered a single user's photo collection, they are not applicable to concurrent photos obtained from a group of photographers. To handle this situation, we define temporal/spatial combined clustering for the set of group photos taken from different cameras. If photos are submitted from a camera whose user has shown a preference between spatial and temporal clustering, we can obtain customized clustering output from other photo sets according to the reference clustering characteristics. We also propose unsupervised methods for general clustering output. Input concurrent photos are processed without a user's true clusters, which can be a burden when the number of photos in the true clusters is huge. We tested our methods via more than one thousand photos taken by tourist groups. The final result was satisfactory compared to previous methods based on temporal (spatial) criteria only.
C1 [Jang, Chuljin; Yoon, Taijin; Cho, Hwan-Gue] Pusan Natl Univ, Dept Comp Engn, Pusan, South Korea.
C3 Pusan National University
RP Cho, HG (corresponding author), Pusan Natl Univ, Dept Comp Engn, Pusan, South Korea.
EM jin@pusan.ac.kr; ytj@pusan.ac.kr; hgcho@pusan.ac.kr
FU MCST/IITA [2008-F-031-01]
FX This work was supported by the IT R&D program of MCST/IITA
   (2008-F-031-01, Development of Computational Photography Technologies
   for Image and Video Contents).
CR Bartolini I, 2006, MULTIMED TOOLS APPL, V31, P269, DOI 10.1007/s11042-006-0044-0
   Boll S., 2007, P 15 ACM INT C MULTI, P641, DOI DOI 10.1145/1291233.1291385
   Boutell M, 2004, PROC CVPR IEEE, P623
   Boutell M, 2004, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2004.1333918
   CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919
   Chen Jun-Cheng, 2006, P 14 ACM INT C MULTI, P25
   Chu WT, 2007, IEEE MULTIMEDIA, V14, P36, DOI 10.1109/MMUL.2007.66
   Cooper M, 2005, ACM T MULTIM COMPUT, V1
   Graham A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P326, DOI 10.1145/544220.544301
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Hsieh C.-C., 2008, ACM International Conference on Multimedia (MM), P419
   JANG C, 2009, SAC 09, P1184
   Jang C.-J., 2007, Digital information management, V1, P110, DOI DOI 10.1109/ICDIM.2007.4444209
   Japan Electronics and Information Technology Industries Assoc, 2002, EX VERS 2 2 DIG STIL
   LEE JY, 2007, THESIS PUSAN NATL U
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
   Mills TimothyJ., 2000, SHOEBOX DIGITAL PHOT
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   Platt JC, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P96, DOI 10.1109/IVL.2000.853847
   Quack T., 2008, CIVR, P47
   Sinha Pinaki., 2008, P 2008 INT C CONTENT, P309
NR 21
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2010
VL 50
IS 3
SI SI
BP 441
EP 463
DI 10.1007/s11042-010-0485-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 630CC
UT WOS:000280248100002
DA 2024-07-18
ER

PT J
AU Hollink, L
   Malaisé, V
   Schreiber, G
AF Hollink, Laura
   Malaise, Veronique
   Schreiber, Guus
TI Thesaurus enrichment for query expansion in audiovisual archives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thesaurus; Retrieval; Ontology alignment; Multimedia; Query expansion
AB It is common practice in audiovisual archives to disclose documents using metadata from a structured vocabulary or thesaurus. Many of these thesauri have limited or no structure. The objective of this paper is to find out whether retrieval of audiovisual resources from a collection indexed with an in-house thesaurus can be improved by enriching the thesaurus structure. We propose a method to add structure to a thesaurus by anchoring it to an external, semantically richer thesaurus. We investigate the added value of this enrichment for retrieval purposes. We first anchor the thesaurus to an external resource, WordNet. From this anchoring we infer relations between pairs of terms in the thesaurus that were previously unrelated. We employ the enriched thesaurus in a retrieval experiment on a TRECVID 2007 dataset. The results are promising: with simple techniques we are able to enrich a thesaurus in such a way that it adds to retrieval performance.
C1 [Hollink, Laura; Malaise, Veronique; Schreiber, Guus] Vrije Univ Amsterdam, NL-1081 HV Amsterdam, Netherlands.
C3 Vrije Universiteit Amsterdam
RP Hollink, L (corresponding author), Vrije Univ Amsterdam, Boelelaan 1081A, NL-1081 HV Amsterdam, Netherlands.
EM hollink@cs.vu.nl; vmalaise@few.vu.nl; schreiber@cs.vu.nl
FU Netherlands Organisation for Scientific Research (NWO) [640.002.501,
   640.001.402]
FX This work was carried out in the context of the MuNCH and CHOICE
   projects, which are supported by the Netherlands Organisation for
   Scientific Research (NWO) programme for Continuous Access To Cultural
   Heritage (CATCH) under project numbers 640.002.501 and 640.001.402.
CR [Anonymous], 2005, Advances in neural information processing systems
   Broekstra J., 2003, Proc. SWAD-Europe Workshop on Semantic Web Storage and Retrieval, P13
   Caracciolo C., 2008, 3 INT WORKSH ONT MAT
   Euzenat J., 2007, ONTOLOGY MATCHING, DOI 10.1007/978-3-540-49612-0
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Hearst M. A., 1992, Proceedings of the 12th Conference on Computational Linguistics, V2, P539, DOI DOI 10.3115/992133.992154
   Hirst G, 1998, LANG SPEECH & COMMUN, P305
   HOLLINK L, 2008, 3 INT C SEM DIG MED
   HOLLINK L, 2003, P K CAP 2003 WORKSH
   Hollink L, 2007, J WEB SEMANT, V5, P195, DOI 10.1016/j.websem.2007.05.002
   *INT ORG STAND, 1986, 27881986 ISO
   Kekäläinen J, 2002, J AM SOC INF SCI TEC, V53, P1120, DOI 10.1002/asi.10137
   KHAN LR, 1997, AMTA SIG IL 1 WORKSH
   KNIGHT K, 1994, AAAI 94 C
   LESK M, 1986, SIGDOC 86
   MALAISE V, 2007, APPL DRIVEN TERMINOL
   MALAISE V, 2009, C TRAIT AUT LANG TAL
   Malaise V., 2007, ACL 2007 WORKSH LANG
   MILES A, 2005, SKOS CORE GUIDE W3C
   Miles A., 2008, SKOS Simple Knowledge Organization System -
   NAGY M, 2008, 3 INT WORKSH ONT MAT
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   OVER P, 2007, TREC VIDEO RETRIEVAL
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   Tudhope D, 2006, J DOC, V62, P509, DOI 10.1108/00220410610673873
   van Assem M, 2006, LECT NOTES COMPUT SC, V4011, P95
   VANHAGE WR, 2006, P INT SEM WEB C ISWC, P723
   VOLKMER T, 2007, ACSC 2007, P151
   Voorhees E. M., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P61
   Zobel J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P307, DOI 10.1145/290941.291014
NR 30
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 235
EP 257
DI 10.1007/s11042-009-0400-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600012
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Chien, WJ
   Karam, LJ
AF Chien, Wei-Jung
   Karam, Lina J.
TI BLAST-DVC: BitpLAne SelecTive distributed video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Bitplane selective; Low-density parity-check
   accumulate codes; Wyner-Ziv coding
ID MOTION ESTIMATION; INFORMATION
AB This paper presents a BitpLAne SelecTive (BLAST) distributed video coding (DVC) system. In the proposed system, the significance of each bitplane is measured at the decoder based on an estimated distortion-rate ratio that makes use of a correlation model for the original source information and the side information. Only the syndrome bits of the bitplanes that have estimated distortion-rate ratios higher than a target distortion-rate ratio, are transmitted and are used to decode the associated bitplanes. The remaining bitplanes are estimated using a minimum-distance symbol reconstruction scheme which makes use of the side information and the LDPCA-decoded bitplanes. Coding results and comparisons with existing DVC schemes and with H.264 intra- and inter-frame coding are presented to illustrate the performance of the proposed system.
C1 [Chien, Wei-Jung; Karam, Lina J.] Arizona State Univ, Dept Elect Engn, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Chien, WJ (corresponding author), Arizona State Univ, Dept Elect Engn, Tempe, AZ 85287 USA.
EM wei-jung.chien@asu.edu; karam@asu.edu
RI Karam, Lina Jamil/ABD-6531-2021
OI Karam, Lina Jamil/0000-0003-1870-1211
CR Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   Adikari ABB, 2007, ELECTRON LETT, V43, P93, DOI 10.1049/el:20073675
   [Anonymous], 2005, PROC 5 EURASIP C SPE
   Artigas X, 2005, Proceedings ELMAR-2005, P53
   ARTIGAS X, 2007, PICT COD S NOV
   Ascenso J, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P593
   Ascenso J, 2006, IEEE IMAGE PROC, P605, DOI 10.1109/ICIP.2006.312408
   Brites C, 2006, IEEE IMAGE PROC, P273, DOI 10.1109/ICIP.2006.313178
   Chien WJ, 2006, IEEE INT SYMP CIRC S, P5415
   CHIEN WJ, 2006, IEEE INT C AC SPEECH, V2, P69
   de Haan G, 1993, IEEE T CIRC SYST VID, V3, P368, DOI 10.1109/76.246088
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   KLOMP S, 2006, INT C SIGN PROC MULT, P243
   Li Z, 2007, IEEE T IMAGE PROCESS, V16, P98, DOI 10.1109/TIP.2006.884934
   Morbée M, 2007, INT CONF ACOUST SPEE, P521
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Vatis S. K. Y., 2007, P IEEE INT C IM PROC, V2, P1
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
NR 20
TC 10
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2010
VL 48
IS 3
SI SI
BP 437
EP 456
DI 10.1007/s11042-009-0314-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 587VP
UT WOS:000277023100005
DA 2024-07-18
ER

PT J
AU Lagrange, M
   Raspaud, M
AF Lagrange, Mathieu
   Raspaud, Martin
TI Spectral similarity metrics for sound source formation based on the
   common variation cue
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auditory scene analysis; Mid-level representation; Clustering; Common
   variation cue
ID FREQUENCY; CLASSIFICATION; SIGNALS
AB Scene analysis is a relevant way of gathering information about the structure of an audio stream. For content extraction purposes, it also provides prior knowledge that can be taken into account in order to provide more robust results for standard classification approaches. In order to perform such scene analysis, we believe that the notion of temporality is important. Consequently, we study in this paper a new way of modeling the evolution over time of the frequency and amplitude parameters of spectral components. We evaluate its benefits by considering its ability to automatically gather the components of the same sound source. The evaluation of the proposed metric shows that it achieves good performance and takes better account of micro-modulations.
C1 [Lagrange, Mathieu] Telecom ParisTech, F-75634 Paris 13, France.
   [Raspaud, Martin] Linkoping Univ, S-60174 Norrkoping, Sweden.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   Paris; Linkoping University
RP Lagrange, M (corresponding author), Telecom ParisTech, 46 Rue Barrault, F-75634 Paris 13, France.
EM lagrange@telecom-paristech.fr; Martin.Raspaud@itn.liu.se
RI Raspaud, Martin/HKE-2982-2023
OI Raspaud, Martin/0000-0002-3221-3778
FU OSEO; French GIP ANR DESAM [ANR-06-JCJC-0027-01]; Agence Nationale de la
   Recherche (ANR) [ANR-06-JCJC-0027] Funding Source: Agence Nationale de
   la Recherche (ANR)
FX This work has been initiated when the authors were at the LaBRI
   (UMR-Cnrs 5800, University of Bordeaux 1) and has been partly funded by
   the OSEO project Quaero within the task 6.4: "Music Search by
   Similarity" and the French GIP ANR DESAM under contract
   ANR-06-JCJC-0027-01.
CR ABE M, 2005, P INT C AC SPEECH SI, V3, P201
   [Anonymous], 1999, Auditory Scene Analysis: The Perceptual Organization of Sound, DOI DOI 10.7551/MITPRESS/1486.001.0001
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], PSYCHOMETRIKA
   *ANS I, 1960, US STAND AC TERM
   Aucouturier JJ, 2007, PATTERN RECOGN LETT, V28, P654, DOI 10.1016/j.patrec.2006.11.004
   AUGER F, 1995, IEEE T SIGNAL PROCES, V43, P1068, DOI 10.1109/78.382394
   Badeau R, 2008, IEEE T SIGNAL PROCES, V56, P492, DOI 10.1109/TSP.2007.906744
   Bello J., 2005, ISMIR
   Burg John Parker, 1975, Stanford Exploration Project
   Christensen MG, 2006, IEEE T AUDIO SPEECH, V14, P99, DOI 10.1109/TSA.2005.860347
   Cooke M., 1993, MODELLING AUDITORY P
   Daudet L, 2006, IEEE T AUDIO SPEECH, V14, P1808, DOI 10.1109/TSA.2005.858540
   DEPALLE P, 1993, IEEE ICASSP APR, V1, P225
   ELLIS D, 1995, INT JOINT C ART INT
   ELLIS D, 1996, THESIS MIT
   ELLIS D, 1992, 123 M AC SOC AM
   Fernandez-Cid P, 1998, INT CONF ACOUST SPEE, P3565, DOI 10.1109/ICASSP.1998.679645
   FRITTS L, 1997, IOWA MUSIC INSTRUMEN
   GROSSBERG S, 1996, PITCH BASED STREAMIN
   Herrera-Boyer P, 2003, J NEW MUSIC RES, V32, P3, DOI 10.1076/jnmr.32.1.3.16798
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641
   Joder C, 2009, IEEE T AUDIO SPEECH, V17, P174, DOI 10.1109/TASL.2008.2007613
   KLAPURI A, 2002, IEEE INT C AC SPEECH
   LAGRANGE M, 2005, P INT COMP MUS C ICM
   LAGRANGE M, 2007, IEEE T AUDIO SPEECH, V28, P357
   LAGRANGE M, 2004, IEEE ICASSP, V4, P241
   Lagrange M, 2008, IEEE T AUDIO SPEECH, V16, P278, DOI 10.1109/TASL.2007.909260
   Lagrange M, 2007, J AUDIO ENG SOC, V55, P385
   LAROCHE J, 1993, J ACOUST SOC AM, V94, P1958, DOI 10.1121/1.407519
   MARCHAND S, 2004, P DIG AUD EFF DAFX C, P76
   MARTIN KD, 1998, 136 M AC SOC AM
   MCADAMS S, 1989, J ACOUST SOC AM, V86, P2148, DOI 10.1121/1.398475
   MCAULAY RJ, 1986, IEEE T ACOUST SPEECH, V34, P744, DOI 10.1109/TASSP.1986.1164910
   Nealen A., 2004, An As-Short-As-Possible Introduction to the Least Squares, Weighted Least Squares and Moving Least Squares Methods for Scattered Data Approximation and Interpolation
   NUNES L, 2007, IEEE INT C AC SPEECH
   RASPAUD M, 2008, P DAFX 08 ESP FINL S, P123
   Raspaud M., 2005, P DIGITAL AUDIO EFFE, P24
   REGNIER L, 2009, IEEE INT C AC SPEECH
   Röbel A, 2006, IEEE T AUDIO SPEECH, V14, P1440, DOI 10.1109/TSA.2005.858529
   Röbel A, 2008, COMPUT MUSIC J, V32, P68, DOI 10.1162/comj.2008.32.2.68
   ROSIER J, 2004, 116 CONV AUD ENG SOC
   SERRA X, 1997, STUDIES NEW MUSIC RE, P91
   STERIAN A, 1998, SPIE ANN M SAN DIEG
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   VIRTANEN T, 2000, ICASSP2000, V2, P765
   WARD JH, 1963, J AM STAT ASSOC, V58, P238
NR 47
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 185
EP 205
DI 10.1007/s11042-009-0382-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Poulisse, GJ
   Moens, MF
   Dekens, T
   Deschacht, K
AF Poulisse, Gert-Jan
   Moens, Marie-Francine
   Dekens, Tomas
   Deschacht, Koen
TI News story segmentation in multiple modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE News video segmentation; Story detection; Feature extraction
ID TEXT
AB In this paper, we describe an approach to segmenting news video based on the perceived shift in content using features spanning multiple modalities. We investigate a number of multimedia features, which serve as potential indicators of a change in story, in order to determine which are the most effective. The efficacy of our approach is demonstrated by the performance of our prototype, where a number of feature combinations demonstrate an up to 18% improvement in WindowDiff score compared to other state of the art story segmenters. In our investigation, there is no, one, clearly superior feature, rather the best segmentation occurs when there is synergy between multiple features. A further investigation into the effect on segmentation performance, while varying the number of training examples versus the number of features used, reveal that having better feature combinations is more important than having more training examples. Our work suggests that it is possible to train robust story segmenters for news video using only a handful of broadcasts, provided a good initial feature selection is made.
C1 [Poulisse, Gert-Jan; Moens, Marie-Francine; Deschacht, Koen] Katholieke Univ Leuven, Dept Comp Sci, Leuven, Belgium.
   [Dekens, Tomas] Vrije Univ Brussel, Dept Elect & Informat Proc, Res Lab DSSP, Brussels, Belgium.
C3 KU Leuven; Vrije Universiteit Brussel
RP Poulisse, GJ (corresponding author), Katholieke Univ Leuven, Dept Comp Sci, Leuven, Belgium.
EM Gert-Jan.Poulisse@cs.kuleuven.be; Marie-Francine.Moens@cs.kuleuven.be;
   tdekens@etro.vub.ac.be; Koen.Deschacht@cs.kuleuven.be
RI Moens, Marie-Francine/B-8378-2014
FU EU-IST [IST-027978]; IWT-SBO [IWT 060051]
FX The work reported is supported by the EU-IST project CLASS
   (Cognitive-Level Annotation using Latent Statistical Structure,
   IST-027978) and by the IWT-SBO project AMASS++ (Advanced Multimedia
   Alignment and Structured Summarization, IWT 060051).
CR Amir A, 2004, P TRECVID
   [Anonymous], P 31 ANN M ASS COMP, DOI DOI 10.1016/S0306-4573(02)00035-3
   Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   CHOI F, 2000, P N AM CHAPT ASS COM
   DEKENS T, 2007, P CONV EL ENG 2007 S
   FERRET O, 2002, C COMP LING
   FINKEL J, 2005, P ASS COMP LING
   Foltz PW, 1998, DISCOURSE PROCESS, V25, P285, DOI 10.1080/01638539809545029
   Galley M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P562
   Hearst MA, 1997, COMPUT LINGUIST, V23, P33
   Hirschberg J., 1993, Computational Linguistics, V19, P501
   KAN MY, 1998, P 6 WORKSH VER LAR C
   Nakamura Y, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P393, DOI 10.1145/266180.266391
   OLNEY A, 2005, P HUM LANG TECHN C C
   Osian M, 2004, MACH VISION APPL, V15, P172, DOI 10.1007/s00138-004-0141-x
   Passonneau R. J., 1993, 31st Annual Meeting of the Association for Computational Linguistics, P148
   Pevzner L, 2002, COMPUT LINGUIST, V28, P19, DOI 10.1162/089120102317341756
   Ponte JM, 1997, LECT NOTES COMPUT SC, V1324, P113, DOI 10.1007/BFb0026725
   QUENOT G, 2004, P TRECVID 2004
   Stokes N, 2004, AI COMMUN, V17, P3
   Tür G, 2001, COMPUT LINGUIST, V27, P31, DOI 10.1162/089120101300346796
NR 22
TC 12
Z9 12
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 3
EP 22
DI 10.1007/s11042-009-0358-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400002
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Dasiopoulou, S
   Tzouvaras, V
   Kompatsiaris, I
   Strintzis, MG
AF Dasiopoulou, Stamatia
   Tzouvaras, Vassilis
   Kompatsiaris, Ioannis
   Strintzis, Michael G.
TI Enquiring MPEG-7 based multimedia ontologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia ontologies; MPEG-7; Semantic Web; Multimedia metadata;
   Interoperability
ID OBSCURE OBJECT; WEB; METADATA; DESIRE
AB Machine understandable metadata forms the main prerequisite for the intelligent services envisaged in a Web, which going beyond mere data exchange and provides for effective content access, sharing and reuse. MPEG-7, despite providing a comprehensive set of tools for the standardised description of audiovisual content, is largely compromised by the use of XML that leaves the largest part of the intended semantics implicit. Aspiring to formalise MPEG-7 descriptions and enhance multimedia metadata interoperability, a number of multimedia ontologies have been proposed. Though sharing a common vision, the developed ontologies are characterised by substantial conceptual differences, reflected both in the modelling of MPEG-7 description tools as well as in the linking with domain ontologies. Delving into the principles underlying their engineering, we present a systematic survey of the state of the art MPEG-7 based multimedia ontologies, and highlight issues that hinder interoperability as well as possible directions towards their harmonisation.
C1 [Dasiopoulou, Stamatia; Kompatsiaris, Ioannis; Strintzis, Michael G.] Informat & Telemat Inst, Ctr Res & Technol Hellas, Thessaloniki, Greece.
   [Tzouvaras, Vassilis] Natl Tech Univ Athens, Dept Elect & Comp Engn, Athens 15780, Greece.
C3 Centre for Research & Technology Hellas; National Technical University
   of Athens
RP Dasiopoulou, S (corresponding author), Informat & Telemat Inst, Ctr Res & Technol Hellas, Thessaloniki, Greece.
EM dasiop@iti.gr; tzouvaras@image.ntua.gr; ikom@iti.gr; strintzis@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Dasiopoulou,
   Stamatia/0000-0003-2831-7459
FU European Commission [FP6-001765 aceMedia, FP6-507482 KnowledgeWeb,
   FP6-027538 BOEMIE]
FX This work was partially supported by the European Commission under
   contracts FP6-001765 aceMedia, FP6-507482 KnowledgeWeb, and FP6-027538
   BOEMIE.
CR [Anonymous], DUBL COR MET EL SET
   ARNDT R, 2007, P INT SEM WEB C BUS
   Bechhofer Sean, 2004, OWL Web Ontology Language Reference
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bloehdorn S., 2004, P EUR WORKSH INT KNO
   BOLL S, 2007, W3C INCUBATOR GROUP
   Brickley D., 2004, RDF VOCABULARY DESCR
   Celina O, 2007, 1 INT WORKSH MULT AN, P2
   CELMA O, 2007, W3C INCUBATOR GROUP
   DASIOPOULOU S, 2008, SEMANTIC MULTIMEDIA
   DASIOPOULOU S, 2007, P 2 INT C MET SEM MT
   DASIOPOULOU S, 2009, D3 1 MULITMEDIA CONT
   DASIOPOULOU S, 2007, D3 4 MULITMEDIA CONT
   Gangemi A, 2005, LECT NOTES COMPUT SC, V3729, P262, DOI 10.1007/11574620_21
   Gangemi A, 2002, LECT NOTES ARTIF INT, V2473, P166
   GARCIA R, 2005, P INT SEM WEB C ISWC
   GARCIA R, 2007, P 10 INT C BUS INF S, P220
   Garcia R, 2007, ARTIF INTELL LAW, V15, P137, DOI 10.1007/s10506-007-9032-6
   HOLLINK L, 2005, 3 INT C KNOWL CAPT K, P91
   Hunter J, 2004, IEEE INTELL SYST, V19, P40, DOI 10.1109/MIS.2004.1265884
   HUNTER J, 2001, P 1 SEM WEB WORK S S
   KARKALETSIS V, 2005, P INT C AD KNOWL REP, P98
   LAGOZE C, 2001, J DIGIT INF, V2
   LITTLE S, 2004, INT SEM WEB C ISWC H, P534
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P83, DOI 10.1109/MMUL.2002.1022862
   *MPEG 7, 2001, 15938 ISOIEC MPEG7
   *MPEG 7, 2001, JTC1SC29WG11N4358 IS
   *MPEG 7, 2001, 1593842001E ISOIEC M
   *MPEG 7 MDS, 2001, 159385 ISOIEC MPEG7
   Nack F, 2005, IEEE MULTIMEDIA, V12, P54, DOI 10.1109/MMUL.2005.12
   Niles I., 2001, Formal Ontology in Information Systems. Collected Papers from the Second International Conference, P2, DOI 10.1145/505168.505170
   Oberle D, 2007, J WEB SEMANT, V5, P156, DOI 10.1016/j.websem.2007.06.002
   Petridis K, 2006, IEE P-VIS IMAGE SIGN, V153, P255, DOI 10.1049/ip-vis:20050059
   ROMANELLI M, 2007, 2 INT C SEM DIG MED, P240
   SIMOU N, 2005, P INT WORKSH VER LOW
   TSINARAKI C, 2004, 16 INT C ADV INF SYS, P398
   Tsinaraki C, 2007, IEEE T KNOWL DATA EN, V19, P219, DOI 10.1109/TKDE.2007.33
   Tsinaraki C, 2007, LECT NOTES COMPUT SC, V4803, P850
   van Ossenbruggen J, 2004, IEEE MULTIMEDIA, V11, P38, DOI 10.1109/MMUL.2004.36
   VEMBUE S, 2006, P WORKSH SEM WEB ANN
   *W3C, 1998, SMIL 1 0 SYNC MULT I
NR 41
TC 34
Z9 36
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 331
EP 370
DI 10.1007/s11042-009-0387-4
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300009
DA 2024-07-18
ER

PT J
AU Liang, HG
   De Silva, RN
   Ooi, WT
   Motani, M
AF Liang, Huiguang
   De Silva, Ransi Nilaksha
   Ooi, Wei Tsang
   Motani, Mehul
TI Avatar mobility in user-created networked virtual worlds: measurements,
   analysis, and implications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Networked virtual environment (NVE); Mobility traces user behavior;
   Peer-to-peer; Caching; Prefetching; Second Life
AB We collected mobility traces of avatars spanning multiple regions in Second Life, a popular user-created virtual world. We analyzed the traces to characterize the dynamics of the avatars' mobility and behavior, both temporally and spatially. We discuss the implications of our findings on the design of peer-to-peer architecture, interest management, mobility modeling of avatars, server load balancing and zone partitioning, caching, and prefetching for user-created virtual worlds.
C1 [Liang, Huiguang] Inst Infocomm Res, Singapore 138632, Singapore.
   [De Silva, Ransi Nilaksha; Ooi, Wei Tsang] Natl Univ Singapore, Dept Comp Sci, Singapore 119260, Singapore.
   [Motani, Mehul] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); National University of Singapore; National
   University of Singapore
RP Liang, HG (corresponding author), Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis S Tower, Singapore 138632, Singapore.
EM liang@alumni.nus.edu.sg; ransidesilva@nus.edu.sg; ooiwt@comp.nus.edu.sg;
   motani@nus.edu.sg
RI Ooi, Wei Tsang/AAE-7810-2019; Motani, Mehul/B-5944-2011; Ooi, Wei
   Tsang/HLW-5142-2023
OI Ooi, Wei Tsang/0000-0001-8994-1736; Ooi, Wei Tsang/0000-0001-8994-1736;
   Motani, Mehul/0000-0003-3262-0207
FU National University of Singapore Academic Research Fund
   [R-252-000-306-112]
FX We thank Ian Tay and Ming Feng Neo from National University of Singapore
   and Vikram Srinivasan of Bell Labs Research India for useful discussions
   throughout this project. We thank Markus Esch from University of
   Luxembourg for contributing to the analysis of cluster nodes in Section
   7.1. This work is partially supported by National University of
   Singapore Academic Research Fund R-252-000-306-112.
CR [Anonymous], 1996, MOBILE COMPUTING
   BACKHAUS H, 2007, NETGAMES 07, P49
   BHARAMBE A, 2006, NSDI 06, P12
   Bharambe AR, 2004, ACM SIGCOMM COMP COM, V34, P353, DOI 10.1145/1030194.1015507
   BOULANGER JS, 2006, NETGAMES, P6
   Chan A., 2001, Proc. ACM Symposium on Virtual Reality Software and Technology, P135
   Chen JF, 2005, AINA 2005: 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2, P377
   Chen Jin., 2005, PPOPP 05, P289
   Chen XG, 2006, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2006/06/011
   CHERTOV R, 2006, NOSSDAV 06, P74
   CHIM J, 1998, ACM MULTIDMEDIA, P171
   De Vleeschauwer B., 2005, ACM SIGCOMM Workshop on Network and System Support for Games, P1
   ESCH M, 2009, P 1 INT WORKSH VIRT
   Gautier L, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P233, DOI 10.1109/MMCS.1998.693647
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   JIANG JR, 2008, INT WORKSH COOP DIST
   Keller J, 2003, PDPTA'03: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING TECHNIQUES AND APPLICATIONS, VOLS 1-4, P262
   KNUTSSON B, 2004, INFOCOM 04
   LA CA, 2008, RR08212 I EUR
   Lau RWH, 2001, REAL-TIME SYST, V21, P143, DOI 10.1023/A:1011199405471
   LIANG H, 2008, P2P NVE 08
   Lui JCS, 2002, IEEE T PARALL DISTR, V13, P193, DOI 10.1109/71.993202
   MAKBILY Y, 1999, I3D 99, P39
   PARK S, 2001, VRST 01, P121
   Pittman Daniel., 2007, NETGAMES 07 P 6 ACM, P25
   Rieche S, 2007, CONSUM COMM NETWORK, P763, DOI 10.1109/CCNC.2007.155
   SCHOLTES I, 2008, SIMUTOOLS 08
   Steed A, 2005, P IEEE VIRT REAL ANN, P27
   TAN SA, 2005, NETGAMES 05, P1
   Tian J, 2002, PROC ANNU SIMUL SYMP, P337, DOI 10.1109/SIMSYM.2002.1000171
   VARVELLO M, 2008, ACM CONEXT 08
   VIK KH, 2006, NETGAMES 06, P2
NR 32
TC 18
Z9 18
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 163
EP 190
DI 10.1007/s11042-009-0304-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900008
DA 2024-07-18
ER

PT J
AU de Oliveira, JBS
AF de Oliveira, Joao Batista S.
TI Two algorithms for automatic page layout and possible applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic page layout; Placement algorithms; Packing
ID RECTANGLES
AB This paper describes two approaches to the problem of automatically placing document items on pages of some output device. Both solutions partition the page into regions where each item is to be placed, but work on different input data according to the application: One approach assumes that previously defined rectangular items are to be placed freely on the page (as in a sales brochure), whereas the second approach places free-form items on pages divided into columns (as in a newspaper). Moreover, both approaches try to preserve the reading order provided by the input and use all available area on the page. This paper also describes several possible advances and applications for the algorithms, detailing and expanding the work presented in de Oliveira (2008).
C1 Pontificia Univ Catolica Rio Grande do Sul, Fac Informat, Porto Alegre, RS, Brazil.
C3 Pontificia Universidade Catolica Do Rio Grande Do Sul
RP de Oliveira, JBS (corresponding author), Pontificia Univ Catolica Rio Grande do Sul, Fac Informat, Porto Alegre, RS, Brazil.
EM oliveira@inf.pucrs.br
OI Souza de Oliveira, Joao Batista/0000-0002-2003-2128
FU CNPq; Hewlett-Packard Brazil
FX This work has been partially supported by CNPq, the Brazilian research
   funding institution as well as by Hewlett-Packard Brazil, through a
   research grant.
CR AGRAWALA M, 2000, DESIGN IMPLEMENTATIO
   Atkins CB, 2004, IEEE IMAGE PROC, P2897
   de Oliveira JBS, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P141
   FARIA AC, 2006, DOCENG 06, P13, DOI DOI 10.1145/1166160.1166166
   Geigel J, 2003, IEEE MULTIMEDIA, V10, P16, DOI 10.1109/MMUL.2003.1237547
   Harrington S.J., 2004, P 2004 ACM S DOC ENG, P109, DOI [10.1145/1030397.1030419, DOI 10.1145/1030397.1030419]
   Jacobs C, 2003, ACM T GRAPHIC, V22, P838, DOI 10.1145/882262.882353
   KENYON C, 1992, IEEE S FDN COMP SCI, P610
   KONG TY, 1988, SIAM J COMPUT, V17, P1215, DOI 10.1137/0217077
   Lin XF, 2006, COMPUT AIDED DESIGN, V38, P444, DOI 10.1016/j.cad.2005.11.006
   Lodi A, 2002, EUR J OPER RES, V141, P241, DOI 10.1016/S0377-2217(02)00123-6
   Nagamochi H, 2007, DISCRETE APPL MATH, V155, P523, DOI 10.1016/j.dam.2006.08.005
   PURVIS L, 2003, DOCENG 03, P68, DOI DOI 10.1145/958220.958234
   Skiena S. S, 1998, The Algorithm Design Manual
NR 14
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2009
VL 43
IS 3
BP 275
EP 301
DI 10.1007/s11042-009-0267-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 450HY
UT WOS:000266392800005
DA 2024-07-18
ER

PT J
AU Bonis, B
   Stamos, J
   Vosinakis, S
   Andreou, I
   Panayiotopoulos, T
AF Bonis, B.
   Stamos, J.
   Vosinakis, S.
   Andreou, I.
   Panayiotopoulos, T.
TI A platform for virtual museums with personalized content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Virtual museums; User modeling; Personalization
ID RECOMMENDER SYSTEMS
AB Presentation of content is an important aspect of today's virtual reality applications, especially in domains such as virtual museums. The large amount and variety of exhibits in such applications raise a need for adaptation and personalization of the environment. This paper presents a content personalization platform for Virtual Museums, which is based on a semantic description of content and on information implicitly collected about the users through their interactions with the museum. The proposed platform uses stereotypes to initialize user models, adapts user profiles dynamically and clusters users into similar interest groups. A science fiction museum has been set up as a case study for this platform and an evaluation has been carried out.
C1 [Vosinakis, S.] Univ Aegean, Dept Prod & Syst Design Engn, Hermoupolis 85100, Syros, Greece.
   [Bonis, B.; Stamos, J.; Panayiotopoulos, T.] Univ Piraeus, Dept Informat, Piraeus 18534, Greece.
   [Andreou, I.] Univ Piraeus, Dept Technol Educ & Digital Syst, Piraeus 18534, Greece.
C3 University of Aegean; University of Piraeus; University of Piraeus
RP Vosinakis, S (corresponding author), Univ Aegean, Dept Prod & Syst Design Engn, Hermoupolis 85100, Syros, Greece.
EM spyrosv@aegean.gr
RI Yang, Li/JMP-4403-2023; Panayiotopoulos, Themis/AAR-2094-2021
OI Vosinakis, Spyros/0000-0003-1735-4297
CR [Anonymous], 2005, P COMP APPL QUANT ME
   [Anonymous], P WORK C ADV VID INT
   [Anonymous], 2002, P WEB3D 2002 7 INT C
   Benyon D, 1997, HUMAN-COMPUTER INTERACTION - INTERACT '97, P39
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Celentano A., 2004, Advanced Visual Interfaces (AVI), P275
   Chittaro L., 2003, Proceeding of the eighth international conference on 3D Web technology, P27, DOI DOI 10.1145/636593.636598
   Corbit M, 2002, PRESENCE-TELEOP VIRT, V11, P55, DOI 10.1162/105474602317343659
   Darken R.P., 1993, Proceedings of ACM User Interface Software and Technology, P157, DOI [10.1145/168642.168658, DOI 10.1145/168642.168658]
   dos Santos C.T., 2004, Proceedings of the working conference on advanced visual interfaces, P362
   ECONOMOU D, 2004, MUSEOLOGY INT SCI EL, V14
   Eirinaki M., 2003, ACM T INTERNET TECHN, V3, P1, DOI [10.1145/643477.643478, DOI 10.1145/643477.643478]
   Fink J, 2000, USER MODEL USER-ADAP, V10, P209, DOI 10.1023/A:1026597308943
   ITZKOVICH I, 1994, FUZZY SET SYST, V62, P143, DOI 10.1016/0165-0114(94)90054-X
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Kang H., 2004, Proceedings of the Tenth Americas Conference on Information Systems, August 2004, P2734
   Kim W., 2002, ELECTRON COMMER R A, V1, P150
   Kim YS, 2006, PRESENCE-VIRTUAL AUG, V15, P245, DOI 10.1162/pres.15.3.245
   KO D, 1999, P SYST MAN CYBERN IE, V99, P25
   Kobsa A, 2001, KNOWL ENG REV, V16, P111, DOI 10.1017/S0269888901000108
   Lepouras G., 2004, Virtual Reality, V8, P927, DOI DOI 10.1007/S10055-004-0141-1
   LEPOURAS G, 2001, P VRIC VIRT REAL INT
   Minsky M., 1974, P PSYCHOL COMPUTER V, P211
   Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169
   Modjeska D, 2000, IEEE INFOR VIS, P215, DOI 10.1109/IV.2000.859758
   Mukherjee R, 2003, USER MODEL USER-ADAP, V13, P5, DOI 10.1023/A:1024022819690
   Nowak KL, 2005, J COMPUT-MEDIAT COMM, V11
   PATEL M, 2003, DIGITIZATION PRESENT, P1
   Perugini S, 2004, J INTELL INF SYST, V23, P107, DOI 10.1023/B:JIIS.0000039532.05533.99
   Raskutti B, 1997, USER MODEL USER-ADAP, V7, P179, DOI 10.1023/A:1008291330418
   Rich E., 1979, Cognitive Science, V3, P329, DOI [DOI 10.1016/S0364-0213, DOI 10.1207/S15516709COG0304_3, 10.1016/S0364-0213]
   Rongen PHH, 2005, LECT NOTES ARTIF INT, V3690, P326
   Schaerf M., 1999, Proceedings VRML 99. Fourth Symposium on the Virtual Reality Modeling Language, P105, DOI 10.1145/299246.299280
   Schafer J., 2001, DATA MIN KNOWL DISC, V5, P115, DOI DOI 10.1023/A:1009804230409
   Su CJ, 1998, COMPUT IND ENG, V35, P615, DOI 10.1016/S0360-8352(98)00172-7
   Tsichritzis D., 1991, Proceedings of the international conference on hypermedia and interactivity museums, P17
   URBAN R, 2007, P MUS WEB 2007
   VINSON NG, 1999, P CHI, V99, P278
NR 38
TC 28
Z9 31
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2009
VL 42
IS 2
BP 139
EP 159
DI 10.1007/s11042-008-0231-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA 415EY
UT WOS:000263918300001
DA 2024-07-18
ER

PT J
AU Van Deursen, D
   De Neve, W
   De Schrijver, D
   Van de Walle, RV
AF Van Deursen, Davy
   De Neve, Wesley
   De Schrijver, Davy
   Van de Walle, Rik
TI gBFlavor: a new tool for fast and automatic generation of generic
   bitstream syntax descriptions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic code generation; Bitstream syntax descriptions;
   Description-driven content adaptation; MPEG-21 gBS Schema; Scalable
   video coding
ID RESOURCE ADAPTATION; MPEG-21 BSDL; VIDEO; SYSTEM
AB The efficient adaptation of scalable media resources is a major point of interest, due to today's tremendous heterogeneity in terms of end-user terminals, network technologies, and coding formats. In order to create a media resource adaptation engine supporting current and future coding formats, a generic (i.e., format-independent) solution is needed. One way to realize this goal is to rely on automatically created textual descriptions of the high-level syntax of binary media resources. MPEG-21 generic Bitstream Syntax Schema (gBS Schema) is a tool that is part of the MPEG-21 Multimedia Framework. It enables the use of generic Bitstream Syntax Descriptions (gBSDs), i.e., textual descriptions in XML, to steer the adaptation of a binary media resource, using format-independent adaptation logic. The major contribution of this paper is the introduction of gBFlavor. It is a novel solution for the automatic and format-agnostic generation of gBSDs. gBFlavor offers the possibility to automatically create a format-specific parser that is able to produce a gBSD, taking as input a particular media resource compliant to the coding format described by the parser. This paper provides an overview of the gBFlavor language, which allows describing the high-level structure of a coding format. The overall functioning of a gBFlavor-enabled adaptation framework is discussed as well. Performance results for two scalable coding formats, in particular H.264/AVC Scalable Video Coding and JPEG2000, show that our proposed solution outperforms existing techniques in terms of execution speed.
C1 [Van Deursen, Davy; De Neve, Wesley; De Schrijver, Davy; Van de Walle, Rik] Univ Ghent, IBBT, Dept Elect & Informat Syst, Multimedia Lab, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP Van Deursen, D (corresponding author), Univ Ghent, IBBT, Dept Elect & Informat Syst, Multimedia Lab, Gaston Crommenlaan 8,Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM davy.vandeursen@ugent.be; wesley.deneve@ugent.be;
   davy.deschrijver@ugent.be; rik.vandewalle@ugent.be
RI De Neve, Wesley Marcel/C-6480-2008
OI De Neve, Wesley Marcel/0000-0002-8190-3839
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   AMIELH M, 2002, P 11 INT WORLD WID W
   Amielh M, 2001, P 8 INT C MULT MOD A, P127
   [Anonymous], P IEEE
   [Anonymous], 1985, Compilers principles, techniques, and tools
   Avaro O, 1997, SIGNAL PROCESS-IMAGE, V9, P385, DOI 10.1016/S0923-5965(97)00027-1
   BALTAZAR J, 2006, P 25 PICT COD S BEIJ, P6
   Burnett I.S., 2006, MPEG 21 BOOK, V1st
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   CIMPRICH P, 2004, SREAMING TRANSFORMAT
   De Neve W, 2005, LECT NOTES COMPUT SC, V3767, P641
   De Neve W, 2006, SIGNAL PROCESS-IMAGE, V21, P862, DOI 10.1016/j.image.2006.08.005
   De Schrijver D, 2007, J VIS COMMUN IMAGE R, V18, P217, DOI 10.1016/j.jvcir.2007.02.003
   DESCHRIJVER D, 2006, P 2006 IEEE INT C IN, V3, P213
   Devillers S, 2005, IEEE T MULTIMEDIA, V7, P463, DOI 10.1109/TMM.2005.846794
   *DUBL COR MET IN, 2004, DUBL COR MET EL SET
   GIOIA P, 2004, P 1 EUR C VIS MED PR, P295
   HONG D, 2002, P IEEE INT C MULT EX, P4
   IQBAL R, 2007, P SPIE ACM MULT COMP
   *ISO IEC, 2007, 2100072004FPDAMD I 7
   ISO/IEC, 1996, 149771996 ISO IEC
   *ISO IEC, 2004, 2100072004 ISOIEC 7
   JOHNSON SC, 1992, YACC YET ANOTHER COM
   Kay Michael, 2001, XSLT Programmer's Reference
   Magalhaes J, 2004, SIGNAL PROCESS-IMAGE, V19, P437, DOI 10.1016/j.image.2004.02.004
   Martikainen J, 2005, PROCEEDINGS OF THE NINTH IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING, P5
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Panis G, 2003, SIGNAL PROCESS-IMAGE, V18, P721, DOI 10.1016/S0923-5965(03)00061-4
   Ransburg M., 2005, Proceedings of the IASTED International Conference on Internet and Multimedia Systems and Applications, P324
   RANSBURG M, 2006, P EUR S MOB MED DEL
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   *SMPTE, 2005, 421M SMPTE
   Thomas-Kerr J, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1509, DOI 10.1109/ICME.2006.262829
   Timmerer C, 2003, P SOC PHOTO-OPT INS, V5242, P92, DOI 10.1117/12.515731
   Van Deursen D, 2006, LECT NOTES COMPUT SC, V4261, P339
   VANDEURSEN D, 2006, P 25 PICT COD S BEIJ, P6
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P16, DOI 10.1109/MSP.2003.1184335
   *W3C, 1999, XML PATH LANG XPATH
   WIEGAND T, 2006, JVTU201
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Xu M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1245, DOI 10.1109/ICME.2006.262763
NR 43
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2008
VL 40
IS 3
BP 453
EP 494
DI 10.1007/s11042-008-0214-3
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 360PD
UT WOS:000260068700006
OA Green Published
DA 2024-07-18
ER

PT J
AU Kaminsky, E
   Hadar, O
AF Kaminsky, Evgeny
   Hadar, Ofer
TI Multiparameter method for analysis and selection of motion estimation
   algorithms for video compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE fast motion estimation (ME); block matching algorithms (BMA); video
   analysis; algorithm evaluation; algorithm selection; multiparameter
   analysis; Pareto approach
ID SEARCH ALGORITHM
AB This paper proposes a new multiparameter method for analysis and selection of motion estimation algorithms for video compression. We present motion estimation algorithms, results of computer simulations and illustrate the analysis with tables, PSNR and performance plots. Numerous algorithms and tests for analysis of algorithm performance for video compression have recently been suggested, which has resulted in a need for effective evaluation methods. A highly qualified expert is also needed to evaluate the test results. The more input parameters used the more complex and subjective the evaluation will be. Our multiparameter method for algorithm analysis and selection eliminates subjectivity and provides a qualitative and quantitative evaluation of the tested algorithms for any number of algorithms and parameters. We propose two new methods of evaluation: (1) a quality method-a graphic method using the Pareto approach, and (2) a quantity method which obtains an integrated parameter composed of numerous evaluation parameters. In addition, we evaluate various motion estimation algorithms accordingly to two different implementation strategies: (a) using a software video encoder that depends on available processing resources using a computational complexity-rate-distortion (C-R-D) evaluation framework and (b) using a power-limited video encoder implemented on mobile or handheld computing platform by using energy-rate-distortion (E-R-D) behavior.
C1 [Kaminsky, Evgeny] Ben Gurion Univ Negev, Dept Elect & Comp Engn, IL-84105 Beer Sheva, Israel.
   [Hadar, Ofer] Ben Gurion Univ Negev, Commun Syst Engn Dept, IL-84105 Beer Sheva, Israel.
C3 Ben Gurion University; Ben Gurion University
RP Kaminsky, E (corresponding author), Ben Gurion Univ Negev, Dept Elect & Comp Engn, IL-84105 Beer Sheva, Israel.
EM evgenyk@ee.bgu.ac.il; hadar@cse.bgu.ac.il
RI HADAR, OFER/F-2051-2012
OI Hadar, Ofer/0000-0002-6089-8401
CR [Anonymous], 1981, P NAT TEL C NEW ORL
   [Anonymous], 1976, DECISIONS MULTIPLE O
   Burd TD, 1996, J VLSI SIG PROC SYST, V13, P203, DOI 10.1007/BF01130406
   Fishburn P.C., 1970, UTILITY THEORY DECIS
   *ISO IEC, 2000, 138182 ISO IEC
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Kaminsky E, 2003, ITRE2003: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: RESEARCH AND EDUCATION, P573, DOI 10.1109/ITRE.2003.1270684
   KUHN P, 1992, ALGORITHMS COMPLEXIT
   Leontief WW, 1933, Q J ECON, V47, P493, DOI 10.2307/1883982
   Lerner A, 1932, ECONOMICA, P346, DOI 10.2307/2548594
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   MA KK, 1998, JTC1SC29WG11 ISO IEC
   Pareto Vilfredo, 1971, MANUAL POLITICAL EC
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   RibasCorbera J, 1997, P SOC PHOTO-OPT INS, V3024, P1132, DOI 10.1117/12.263193
   Scitovsky Tibor., 1941, REV ECO STUD, V9, P77
   Steuer R, 1986, Multiple Criteria Optimization: Theory, Computation and Application
   Turaga D., 1998, SEARCH ALGORITHMS BL
   *U WARW MCG, BLOCK MATCH MOT COMP
   VINER J, 1937, STUDIES THEORY INT T, P521
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 21
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 38
IS 1
BP 119
EP 146
DI 10.1007/s11042-007-0152-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 280DL
UT WOS:000254405000006
DA 2024-07-18
ER

PT J
AU Jumisko-Pyykkö, S
AF Jumisko-Pyykkoe, Satu
TI "I would like to see the subtitles and the face or at least hear the
   voice":: Effects of picture ratio and audio-video bitrate ratio on
   perception of quality in mobile television
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE subjective evaluation; bitrate; picture ratio; audiovisual quality;
   visual quality
AB In new mobile video applications, the subjectively perceived visual and audiovisual qualities are critical factors in the wide audience adoption of mass products. The critical factors in mobile video coding are related to low bitrates, framerates and screen size of the devices. The first part of this study examined the effects of codecs, bitrates and picture ratio on the perceived visual video quality. In the second study, effects of two audio-video bitrate ratios are presented as factors in the perceived audiovisual video quality and the results are compared to the previous study that showed the content dependency in the audio-video bitrate ratio comparisons. In the results of the visual quality study, H.264 was rated as the most satisfying, but the quality was still not enough for text legibility and perceiving important details of image due to the QCIF picture ratio. The codec XviD was in generally experienced as worse than the H.264, but with the screen size SIF-SP with XviD codec was rated better with several contents. In the audiovisual study, the results also showed that in the low total bitrates the significance of audio is increased. However, the higher and lower bitrates had similar content dependent effects.
C1 Tampere Univ Technol, Inst Human Centered Technol, FIN-33101 Tampere, Finland.
C3 Tampere University
RP Jumisko-Pyykkö, S (corresponding author), Tampere Univ Technol, Inst Human Centered Technol, POB 553, FIN-33101 Tampere, Finland.
EM satu.jumisko-pyykko@tut.fi
CR [Anonymous], 2004, P 2004 C HUM FACT CO
   [Anonymous], 2000, Psychometric scaling, a toolkit for imaging systems development
   *ANSI, 1996, DIG TRANSP VID TEL V
   APTEKER RT, 1995, IEEE MULTIMEDIA, V2, P32, DOI 10.1109/93.410510
   BARTEN PGJ, 1999, COTRACT SENSITIVITY
   Beerends JG, 1999, J AUDIO ENG SOC, V47, P355
   BRANDENBURG K, 1999, AES 17 INT HIGHQUALI
   *ETSI, 2005, DVB SPEC US VID AUD
   FUKUDA K, 2000, THESIS OSAKA U
   Ghinea G, 2003, BRIT J EDUC TECHNOL, V34, P393, DOI 10.1111/1467-8535.00337
   Ghinea G., 1998, Proceedings ACM Multimedia 98, P49, DOI 10.1145/290747.290754
   Goldstein ER, 2002, SENSATION PERCEPTION, P684
   Gulliver SR, 2004, INT J HUM-COMPUT ST, V60, P640, DOI 10.1016/j.ijhcs.2003.11.002
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hinton P.R., 2004, SPSS EXPLAINED, P377
   *INT STAND ORG, 2000, 7029 SFSEN ISO
   *INT STAND ORG, 2003, 14496102003 ISOIEC
   *INT STAND ORG, 1990, ISO STAND HDB, V35, P386
   JUMISKOPYYKKO S, 2005, P 13 ANN ACM INT C M, P535
   KNOCHE H, 2005, P ACM MULT 2005, V561
   KOSHINEN I, 2002, MOBILE IMAGE
   LESSITER J, 2001, 4 INT WORKSH PRES PH, P21
   LU Z, 2005, P SPIE IS T HUM VIS, V5666
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MULLIN J, 2002, ASSESSMENT METHOD AS
   NEMETHOVA O, 2004, P CIC 2004 9 CDMA IN
   Patton M.Q., 1986, QUALITATIVE EVALUATI
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Sodergrd Caj., 2003, Mobile television-technology and user experiences report on the mobile-tv project, V506, P298
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   *VQEG, 2000, VOEG FIN REP VID QUA
   Vuori T., 2004, Proceedings of the third Nordic conference on Human-computer interaction - NordiCHI'04, P335, DOI DOI 10.1145/1028014.1028067
   Watson A., 1998, Proceedings ACM Multimedia 98, P55, DOI 10.1145/290747.290755
   WIEGAND T, 2003, IEEE T CIRCUITS SYST, V7, P1
   Winkler S, 2005, PROC SPIE, V5666, P139, DOI 10.1117/12.596852
   Winkler S., 2005, WORKSH VID PROC QUAL
NR 36
TC 13
Z9 13
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 167
EP 184
DI 10.1007/s11042-006-0080-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600010
DA 2024-07-18
ER

PT J
AU Lee, YK
   Lee, SS
   Lee, YL
AF Lee, Yung-Ki
   Lee, Seong-Seon
   Lee, Yung-Lyul
TI MPEG-4 to H.264 transcoding with frame rate reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-4; H.264; transcoding; motion vector; macroblock
ID MOTION-ESTIMATION
AB In this paper, a temporal resolution reduction transcoding method that transforms an MPEG-4 video bitstream into an H.264 video bitstream is proposed. The block modes and motion vectors in the MPEG-4 bitstream are utilized in the H.264 encoder for the block mode conversion and motion vector interpolation methods. Four types of motion vector interpolation methods are proposed in order to avoid the use of brute-force motion estimation in H.264. According to the experimental results, the proposed methods achieve a 3 similar to 4 times improvement in the computational complexity compared to the cascade pixel-domain transcoding method, while the PSNR (peak signal to noise ratio) is degraded by 0.2 similar to 0.9 dB depending on the bitrates.
C1 Sejong Univ, Sch Comp Sci, DMS Lab, Dept Internet Engn, Seoul 143747, South Korea.
C3 Sejong University
RP Lee, YK (corresponding author), Sejong Univ, Sch Comp Sci, DMS Lab, Dept Internet Engn, 98 Kunja Dong, Seoul 143747, South Korea.
EM yllee@sejong.ac
OI Lee, Yung-Lyul/0000-0003-2709-8282
CR Chen MJ, 2002, IEEE T CIRC SYST VID, V12, P269, DOI 10.1109/76.999204
   Fung KT, 2002, IEEE T IMAGE PROCESS, V11, P886, DOI 10.1109/TIP.2002.800890
   Han KH, 2005, IEICE T FUND ELECTR, VE88A, P800, DOI 10.1093/ietfec/e88-a.3.800
   *ISO IEC JTCI SC29, 2000, MPEG 4 VID VER MOD V
   *ISO IEC JTCI SC29, 2000, GEN COD MOV PICT ASS
   *ISO IEC JTCI SC29, 1993, ISO IEC 111722
   *ITU T REC H261, 1993, VID COD AUD SERV PX
   *ITU T REC H263, 1998, VID COD LOW BIT RAT
   *ITU T SG16 Q6 VCE, 2001, PERF EV H26L TML 8 H
   *JVT ISO IEC MPEG, 2003, ITUT REC H264 ISO IE
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   TOPIWALA P, 2001, P SPIE APPL DIG IM P
   VETRO A, 2003, IEEE SIGNAL PROCESS, V20
   Wu JL, 1996, IEEE T CONSUM ELECTR, V42, P447, DOI 10.1109/30.536142
   Yin P, 2000, IEEE IMAGE PROC, P972, DOI 10.1109/ICIP.2000.901123
   Youn J, 1998, IEEE T CONSUM ELECTR, V44, P649, DOI 10.1109/30.713176
   Youngs Gillian., 1999, International Feminist Journal of Politics, V1, P1
NR 17
TC 3
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2007
VL 35
IS 2
BP 147
EP 162
DI 10.1007/s11042-007-0123-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 212XA
UT WOS:000249629100003
DA 2024-07-18
ER

PT J
AU Zhang, CC
   Chen, X
AF Zhang, Chengcui
   Chen, Xin
TI OCRS: an interactive object-based image clustering and retrieval system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OCRS; object-based image retrieval; SVM; genetic algorithm; clustering
ID FRAMEWORK
AB In this paper, we propose an Interactive Object-based Image Clustering and Retrieval System (OCRS). The system incorporates two major modules: Preprocessing and Object-based Image Retrieval. In preprocessing, an unsupervised segmentation method called WavSeg is used to segment images into meaningful semantic regions (image objects). This is an area where a huge number of image regions are involved. Therefore, we propose a Genetic Algorithm based algorithm to cluster these images objects and thus reduce the search space for object-based image retrieval. In the learning and retrieval module, the Diverse Density algorithm is adopted to analyze the user's interest and generate the initial hypothesis which provides a prototype for future learning and retrieval. Relevance Feedback technique is incorporated to provide progressive guidance to the learning process. In interacting with user, we propose to use One-Class Support Vector Machine (SVM) to learn the user's interest and refine the returned result. Performance is evaluated on a large image database and the effectiveness of our retrieval algorithm is demonstrated through comparative studies.
C1 Univ Alabama Birmingham, Dept Comp & Informat Sci, Birmingham, AL 35294 USA.
C3 University of Alabama System; University of Alabama Birmingham
RP Zhang, CC (corresponding author), Univ Alabama Birmingham, Dept Comp & Informat Sci, Birmingham, AL 35294 USA.
EM Zhang@cis.uab.edu; Chenxin@cis.uab.edu
CR Andrews Stuart, 2002, PROC 25 ANN C NEURAL, P561
   [Anonymous], 1999, MSRTR9987
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chen SC, 2000, P SOC PHOTO-OPT INS, V3972, P262
   Chen SC, 2006, IEEE T SYST MAN CY C, V36, P772, DOI 10.1109/TSMCC.2005.855507
   CHEN Y, 2001, P IEEE INT C IMAG PR
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Ferhatosmanoglu H, 2001, LECT NOTES COMPUT SC, V2121, P257
   Gondra I., 2004, WSEAS Transactions on Circuits and Systems, V3, P324
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Huang X., 2002, PROC 3 INT WORKSHOP, P100
   JING F, 2003, P IEEE INT C MULT EX
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   KIM DH, 2003, P SIGMOD C
   KRISHNAMACHARI S, 1999, P SOC PHOTO-OPT INS, P427
   MARON O, 2000, P ICML 2000 WORKSH A
   MARON O, 1998, ADV NATURAL INFORM P
   Rosea J.P., 1995, P WORKSHOP GENETIC P, P23
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   VLADIMIR EC, 1997, FITTR9710
   Wang J, 2000, P 17 INT C MACH LEAR, P1119
   Wang L., 2004, P 2 ACM INT WORKSHOP, P100
   WU P, 2001, P ACM MULT
   Yang C., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P233, DOI 10.1109/ICDE.2000.839416
   YANG C, 2005, P ACM INT C MULT SIN, P9
   ZHANG C, 2001, ADV NERUAL INF PROCE, P14
   Zhang C., 2003, P 4 IEEE PACIFIC RIM, P1
   Zucker J.-D., 2001, PROC 14 BIENNIAL C C, P204
NR 31
TC 3
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2007
VL 35
IS 1
BP 71
EP 89
DI 10.1007/s11042-007-0116-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209RY
UT WOS:000249406900004
DA 2024-07-18
ER

PT J
AU Dimitriadis, S
   Marias, K
   Orphanoudakis, SC
AF Dimitriadis, Socrates
   Marias, Kostas
   Orphanoudakis, Stelios C.
TI A multi-agent platform for content-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Distributed Multimedia Systems (DMS
   03)/6th International Conference on Visual Information Systems (VIS
   2003)
CY SEP 24-26, 2003-2006
CL Miami, FL
DE CBIR; image retrieval; multi-agent; system
AB Efficient and possibly intelligent image retrieval is an important task, often required in many fields of human activity. While traditional database indexing techniques exhibit a remarkable performance in textual information retrieval current research in content-based image retrieval is focused on developing novel techniques that are biologically motivated and efficient. It is well known that humans have a remarkable ability to process visual information and to handle the volume and complexity of such information quite efficiently. In this paper, we present a content-based image retrieval platform that is based on a multi-agent architecture. Each agent is responsible for assessing the similarity of the query image to each candidate image contained in a collection based on a specific primitive feature and a corresponding similarity criterion. The outputs of various agents are integrated using one of several voting schemes supported by the system. The system's performance has been evaluated using various collections of images, as well as images obtained in specific application domains such as medical imaging. The initial evaluation has yielded very promising results.
C1 Fdn Res & Technol Hellas, Inst Comp Sci, GR-71110 Iraklion, Greece.
   Univ Crete, Dept Comp Sci, Iraklion, Greece.
C3 Foundation for Research & Technology - Hellas (FORTH); University of
   Crete
RP Dimitriadis, S (corresponding author), Fdn Res & Technol Hellas, Inst Comp Sci, GR-71110 Iraklion, Greece.
EM socrates@brown.edu; kmarias@ics.forth.gr; orphanou@ics.forth.gr
RI Marias, Kostas/AAM-2330-2021
OI Marias, Kostas/0000-0003-3783-5223
CR Boucher A, 1998, ARTIF INTELL MED, V14, P183, DOI 10.1016/S0933-3657(98)00022-0
   BOUJEMAA N, 2001, P ICISP 2001 3 5 MAY, V1, P404
   CHANG E, 2000, PERCEPTION BASED IMA
   DIMITRIADIS S, 2002, THESIS U CRETE
   DIMITRIADIS S, 2003, 6 INT C VIS INF SYST
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   HALKIADAKIS G, 1999, THESIS U CRETE
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Ma WY, 1998, J AM SOC INFORM SCI, V49, P633, DOI 10.1002/(SICI)1097-4571(19980515)49:7<633::AID-ASI5>3.0.CO;2-N
   Maes Pattie, 1994, Artificial Life, V1, P135
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   MULLER H, 2001, ICME 2001 TOK JAP
   MULLER W, 2000, SPIE PHOT E VOIC VID
   Palm C, 2000, PROCEEDINGS OF THE FIFTH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1 AND 2, pA45
   Pfeifer R., 1999, Understanding Intelligence
   ROSCH EH, 1973, COGNITIVE PSYCHOL, V4, P328, DOI 10.1016/0010-0285(73)90017-0
   RUBNER Y, 2001, COMPUT VIS IMAGE UND
   VELTKAMP RC, 1999, UUCS199927
   VELTKAMP RC, 2001, FEATURES CONTENT BAS
   Wu P, 2000, SIGNAL PROCESS-IMAGE, V16, P33, DOI 10.1016/S0923-5965(00)00016-3
   ZABULIS X, 2002, THESIS U CRETE
   Zeki Semir., 1994, A Vision of the Brain
NR 23
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2007
VL 33
IS 1
BP 57
EP 72
DI 10.1007/s11042-006-0095-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 149FZ
UT WOS:000245133800005
DA 2024-07-18
ER

PT J
AU Pachet, F
   Aucouturier, JJ
   La Burthe, A
   Zils, A
   Beurive, A
AF Pachet, Francois
   Aucouturier, Jean-Julien
   La Burthe, Amaury
   Zils, Aymeric
   Beurive, Anthony
TI The Cuidado music browser: an end-to-end electronic music distribution
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE metadata; music browser; similarity; cultural metadata; acoustic
   metadata; editorial metadata; popular music
ID RETRIEVAL
AB The IST project Cuidado, which ran from January 2001 to December 2003, produced the first entirely automatic chain for extracting and exploiting musical metadata for browsing music. The Sony CSL laboratory is primarily interested in the context of popular music browsing in large-scale catalogues. First, we are interested in human-centred issues related to browsing "Popular Music." Popular here means that the music accessed to is widely distributed, and known to many listeners. Second, we consider "popular browsing" of music, i.e., making music accessible to non-specialists (music lovers), and allowing sharing of musical tastes and information within communities, departing from the usual, single user view of digital libraries. This research project covers all areas of the music-to-listener chain, from music description-descriptor extraction from the music signal, or data mining techniques-similarity based access and novel music retrieval methods such as automatic sequence generation, and user interface issues. This paper describes the scientific and technical issues at stake, and the results obtained.
C1 SONY, Comp Sci Lab, F-75005 Paris, France.
RP Pachet, F (corresponding author), SONY, Comp Sci Lab, 6 Rue Amyot, F-75005 Paris, France.
EM pachet@csl.sony.fr; jj@csl.sony.fr; amaury@csl.sony.fr;
   aymeric@csl.sony.fr; beurive@csl.sony.fr
OI Aucouturier, Jean-Julien/0000-0002-4477-4812
CR Allamanche E., 2001, PROC 2 INT S MUSIC I
   [Anonymous], 2002, P IEEE INT C MULT EX
   [Anonymous], 1999, P INT COMP MUS C ICM
   Aucouturier J-J., 2004, JNRSAS, V1
   Aucouturier JJ, 2005, IEEE T MULTIMEDIA, V7, P1028, DOI 10.1109/TMM.2005.858380
   Aucouturier JJ, 2003, J NEW MUSIC RES, V32, P83, DOI 10.1076/jnmr.32.1.83.16801
   BERENZWEIG A, 2001, P IEEE WORKSH APPL S
   COHEN W, 2000, P 9 INT WORLD WID WE
   DOWNIE S, 2003, P INT S MUS INF RETR
   LABURTHE A, 2003, P 3 INT C WEB DEL MU
   PACHET F, 2003, LNCS, V2771
   Pachet F., 2001, P 1 INT C WEB DEL MU
   PACHET F, 2003, COMMUN ACM
   PACHET F, 2000, P CONT BAS MULT INF
   PEETERS G, 2002, P INT COMP MUS C ICM
   SCHEIRER E, P IEEE INT C AC SPEE
   Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129
   Tzanetakis George., 2002, IEEE T SPEECH AUDIO, V10
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Zils A., 2002, P 2 INT C WEB DEL MU
   ZILS A, P COST G6 C DIG AUD
   ZILS A, 2001, P COST G6 C DIG AUD
NR 22
TC 2
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2006
VL 30
IS 3
BP 331
EP 349
DI 10.1007/s11042-006-0030-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 089WS
UT WOS:000240913200007
DA 2024-07-18
ER

PT J
AU Huang, WH
   Mille, A
AF Huang, Weihong
   Mille, Alain
TI ConKMeL: a contextual knowledge management framework to support
   multimedia e-Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 5th IEEE International Symposium on Multimedia Software Engineeting
CY DEC 10-12, 2003
CL TAICHUNG, TAIWAN
SP IEEE Comp Soc, Taichung Healthcare & Management Univ, Natl Tsing Hua Univ, Natl Cent Univ, Bioinformat Soc Taiwan, Univ Calif Irvine
DE semantic context; e-Learning; knowledge management; multimedia; pedagogy
AB As the latest stage of learning and training evolution, e-Learning is supposed to provide intelligent functionalities not only in processing multi-media education resources but also in supporting context-sensitive pedagogical education processes. Towards providing an integrated solution for intelligent multimedia e-Learning, this paper presents a context-aware knowledge management framework named ConKMeL. Proposed framework features a semantic context-based approach for representing and integrating information and knowledge in e-Learning. Requirement analysis in university e-Learning environments shows that knowledge communications are usually in a hybrid mode across different conceptual levels. Based on the fact, a multi-layer contextual knowledge representation model called KG (knowledge graph) is presented. Corresponding key issues in development such as context-based knowledge retrieval and logical knowledge interpretation are discussed. On the application side, a scenario-based learning case study is shown to demonstrate the concepts and techniques developed in the ConKMeL framework.
C1 Kingston Univ, Fac Comp Informat Syst & Math, Kingston upon Thames KT1 2EE, Surrey, England.
   Univ Lyon 1, CNRS, FRE 2672, LIRIS, F-69622 Villeurbanne, France.
C3 Kingston University; Centre National de la Recherche Scientifique
   (CNRS); Universite Claude Bernard Lyon 1; Institut National des Sciences
   Appliquees de Lyon - INSA Lyon
RP Huang, WH (corresponding author), Kingston Univ, Fac Comp Informat Syst & Math, Kingston upon Thames KT1 2EE, Surrey, England.
EM W.Huang@kingston.ac.uk; alain.mille@liris.cnrs.fr
CR AKMAN V, 2002, CONTEX ARTIFICIAL IN
   [Anonymous], 2004, RESOURCE DESCRIPTION
   [Anonymous], MODELING USING CONTE
   BAILEY C, 2001, P HYP 01 ARH DENM AU, P239
   Berners-Lee T., 2001, The Semantic Web
   BREZILLON P, 2001, P EUR CSCW 2001 WORK, P23
   Champin P.A., 2001, P GWCBR 2001 BAD BAD, P189
   *DAML, 2000, DARPA AG MARK LANG
   DC, 2003, DUBL COR MET EL SET
   DELTEIL A, 2001, P SWWS 2001 CAL US
   DORAI C, 2002, MEDIA COMPUTING COMP
   EGYEDZS E, 2002, P ING CONN ROUEN FRA, P39
   FAN J, 2003, IEEE T MULTIMEDIA, V5
   Graves A., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P339
   HUANG W, 2000, P IMSA 2000 LAS VEG, P245
   HUANG W, 2004, P IEEE INT C INT SYS
   HUANG W, 2002, P 8 INT WORKSH MULT
   HUANG W, 2003, P 1 ACM INT WORKSH M
   HUANG W, 2003, P 4 IEEE INT C INF I
   IOANNIDIS YE, 1994, P ACM SIGMOD INT C M, P138
   KALFOGLOU Y, 2002, P ODBASE 02 IRV US
   KATZ B, 2002, P NLPXML 2002 TAIP C
   Kindley R. W., 2002, ASDT ONLINE MAGAZINE, V3
   *LOM, 1999, P148412 LOM IEEE
   MARTIN P, 2003, KNOWLEDGE REPRESENTA
   *SCORM, 2003, ADV DISTR LEARN IN S
   Sowa JohnF., 1992, CONCEPTUAL STRUCTURE, P3
   Theodorakis M, 2002, INFORM SYST, V27, P151, DOI 10.1016/S0306-4379(01)00036-9
NR 28
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2006
VL 30
IS 2
BP 205
EP 219
DI 10.1007/s11042-006-0024-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 082CG
UT WOS:000240363500006
DA 2024-07-18
ER

PT J
AU Liu, TC
   Choudary, C
AF Liu, Tiecheng
   Choudary, Chekuri
TI Content-adaptive wireless streaming of instructional videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE instructional video analysis; content-adaptive video streaming;
   E-learning
AB Video streaming over wireless networks is becoming increasingly important for a variety of applications. To accommodate the dynamic change of wireless network bandwidths, Quality of service (QoS) scalable video streams need to be provided. This paper presents a system of content-adaptive streaming of instructional (lecture) videos over wireless networks for E-learning applications. We first provide a real-time content analysis method to detect and extract content regions from instructional videos, then apply a "leaking-video-buffer" model to adjust QoS of video streams dynamically based on video content. In content-adaptive video streaming, an adaptive feedback control scheme is also developed to transmit properly compressed video streams to video clients not only based on network bandwidth, but also based on video content and the preferences of users. Finally, we demonstrate the scalability and content adaptiveness of the proposed video streaming system with experimental results on several instructional videos.
C1 Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
C3 University of South Carolina System; University of South Carolina
   Columbia
RP Liu, TC (corresponding author), Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
EM tiecheng@cse.sc.edu; choudary@cse.sc.edu
CR BENZLER U, 2000, IEEE T CIRCUITS  OCT, P1080
   CHANG SF, 2001, IEEE WORKSH CONT BAS
   Chou CT, 2004, IEEE T MOBILE COMPUT, V3, P5, DOI 10.1109/TMC.2004.1261813
   Cranley N., 2003, P INT WORKSHOP NETWO, P42
   Dorai C., 2001, ACM MULTIMEDIA, P634
   FOWLER JE, 1995, IEEE T CIRCUITS SYST, P14
   HUA XS, 2002, INT C IM PROC
   Legout A, 2001, IEEE ACM T NETWORK, V9, P464, DOI 10.1109/90.944344
   Leung CH, 2003, 3RD IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P76
   LI HP, 2000, INT C PATT REC
   LIBSIE M, 2002, ACM MULTIMEDIA, P644
   LIU TC, 2001, IEEE C COMP VIS PATT
   LIU TC, 2004, IEEE INT WORKSH MULT
   LIU TC, 2002, INT C IM PROC
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Majumdar A, 2002, IEEE T CIRC SYST VID, V12, P524, DOI 10.1109/TCSVT.2002.800315
   REIBMAN AR, 2003, IEEE T CIRCUITS  FEB, P131
   Smith JR, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P131, DOI 10.1145/319463.319480
   TAN K, 2001, ACM MULTIMEDIA, P512
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Wu F, 2001, IEEE T CIRC SYST VID, V11, P332, DOI 10.1109/76.911159
NR 21
TC 5
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2006
VL 28
IS 2
BP 157
EP 171
DI 10.1007/s11042-006-6140-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 042MH
UT WOS:000237531600004
DA 2024-07-18
ER

PT J
AU Thompson, S
   King, P
   Cameron, H
AF Thompson, S
   King, P
   Cameron, H
TI Modelling reactive multimedia: Design and authoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE suggestions. multimedia; reactive; authoring; model; design; Fran;
   functional; Haskell; MCF; SMIL
AB Multimedia document authoring is a multifaceted activity, and authoring tools tend to concentrate on a restricted set of the activities involved in the creation of a multimedia artifact. In particular, a distinction may be drawn between the design and the implementation of a multimedia artifact.
   This paper presents a comparison of three different authoring paradigms, based on the common case study of a simple interactive animation. We present details of its implementation using the three different authoring tools, MCF, Fran and SMIL 2.0, and we discuss the conclusions that may be drawn from our comparison of the three approaches.
C1 Univ Kent, Comp Lab, Canterbury, Kent, England.
   Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
C3 University of Kent; University of Manitoba
RP Univ Kent, Comp Lab, Canterbury, Kent, England.
EM s.j.thompson@kent.ac.uk; prking@cs.umanitoba.ca;
   hacamero@cs.umanitoba.ca
RI Thompson, Simon/B-8964-2012
OI Thompson, Simon/0000-0002-2350-301X
CR Alexander C., 1977, PATTERN LANGUAGE TOW
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], 1999, Haskell: The Craft of Functional Programming
   Buchanan M. C., 1993, Proceedings ACM Multimedia 93, P341, DOI 10.1145/166266.168415
   Bulterman DCA, 1995, LECT NOTES COMPUT SC, V1000, P575
   Cameron H, 2003, MULTIMED TOOLS APPL, V19, P53, DOI 10.1023/A:1021168913400
   COURTNEY A, 2001, LNCS, V1955
   ELLIOT C, 1997, SIGPLAN NOTICES, V32, P196
   ELLIOTT C, 1998, DOBBS J          JUL
   ELLIOTT C, 1994, P SIGGRAPH 94, P421
   Gamma Erich., 1994, DESIGN PATTERNS
   HARDMAN L, 1993, ACM MULTIMEDIA, P283
   HUGHES J, REPORT PROGRAMMING L
   Kristensen B. B., 1996, Theory and Practice of Object Systems, V2, P143, DOI 10.1002/(SICI)1096-9942(1996)2:3<143::AID-TAPO2>3.0.CO;2-X
   LITTLE TDC, 1993, IEEE T KNOWL DATA EN, V5, P551, DOI 10.1109/69.234768
   NABIL M, 1997, ADV DATABASE RES DEV, V6, P67
   Nanard J., 2000, New Review of Hypermedia and Multimedia, V6, P47, DOI 10.1080/13614560008914718
   Nanard J, 2001, PROC SPIE, V4312, P123
   PETERSON J, FRAN USERS MANUAL
   QUINT V, 1995, COMPUT NETWORKS ISDN, V27, P831, DOI 10.1016/0169-7552(95)00038-9
   Riehle Dirk., 1997, P 12 ACM SIGPLAN C O, P218
   SCHMITZ P, 2002, WWW 2003 HON HI, P45
   Thompson S., 2000, Journal of Functional Programming, V10, P245, DOI 10.1017/S0956796800003671
   Vazirgiannis M, 1998, MULTIMEDIA SYST, V6, P284, DOI 10.1007/s005300050094
   WAHL T, 1994, INT C MULT COMP SYST, P538
   *WORLD WID WEB CON, 2001, SYNCHR MULT INT LANG
   *YAL HASK GROUP CT, 1998, FUNCT ROB
NR 27
TC 3
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2005
VL 27
IS 1
BP 23
EP 52
DI 10.1007/s11042-005-2713-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 955JI
UT WOS:000231221800002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Amous, I
   Jedidi, A
   Sèdes, F
AF Amous, I
   Jedidi, A
   Sèdes, F
TI A contribution to multimedia document modeling and querying
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE metadata; annotation; spatiotemporal operators; querying
AB Metadata on multimedia documents may help to describe their content and make their processing easier, for example by identifying events in temporal media, as well as carrying descriptive information for the overall resource. Metadata is essentially static and may be associated with, or embedded in, the multimedia contents. The aim of this paper is to present a proposal for multimedia documents annotation, based on modeling and unifying features elicited from content and structure mining. Our approach relies on the availability of annotated metadata representing segment content and structure as well as segment transcripts. Temporal and spatial operators are also taken into account when annotating documents. Any feature is identified into a descriptor called "meta-document". These meta-documents are the basis of querying by adapted query languages.
C1 Inst Super Elect & Commun Sfax, LARIM, Sfax 3000, Tunisia.
   Univ Toulouse 3, IRIT, F-31062 Toulouse, France.
C3 Universite de Sfax; Universite de Toulouse; Universite Toulouse III -
   Paul Sabatier
RP Inst Super Elect & Commun Sfax, LARIM, Sfax 3000, Tunisia.
EM Ikram.Amous@isecs.rnu.tn; jedidi@irit.fr; sedes@irit.fr
RI jedidi, anis/AAD-1846-2021
OI jedidi, anis/0000-0002-2441-9901; Sedes, Florence/0000-0002-9273-302X;
   Amous, Ikram/0000-0002-5893-9833
CR ALBANO A, 2000, P ACM SIGIR WORKSH X
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   ALLEN JF, 1991, INT J INTELL SYST, V6, P391
   AMOUS I, 2002, LECT NOTES COMPUT SC, V2425, P439
   BaezaYates R, 2002, J AM SOC INF SCI TEC, V53, P504, DOI 10.1002/asi.10061
   Barras C., 1998, P 1 INT C LANG RES E, P1373
   CHAMBERLIN D, 2001, XQUERY 1 0 XML QUER
   Chamberlin D.D., 2003, SIGMOD, P682
   DEUTSCH A, 1999, IEEE DATA ENG B, V22, P10
   Djeraba C., 2003, Multimedia Mining - A Highway to Intelligent Multimedia Documents
   Dorado A, 2003, IEEE INFOR VIS, P532, DOI 10.1109/IV.2003.1218036
   FERNANDEZ M, 2002, XQUERY 1 0 XPATH2 0
   GENHOFER EMJ, 1991, HIGH LEVEL SPATIAL D
   Gong YH, 1999, MULTIMEDIA SYST, V7, P449, DOI 10.1007/s005300050145
   HASIDA K, 2002, GLOBAL DOCUMENT ANNO
   Hirzalla N, 1999, MULTIMEDIA SYST, V7, P338, DOI 10.1007/s005300050135
   Lee Dongwon., 2002, Query relaxation for XML model
   LEMENTINI EC, 1993, LECT NOTES COMPUTER, V692, P277
   Lienhart R, 2000, MULTIMEDIA SYST, V8, P69, DOI 10.1007/s005300050006
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Ohta Y, 2002, INT C PATT RECOG, P536, DOI 10.1109/ICPR.2002.1044789
   Oliboni B, 2002, INFORM SYST, V27, P459, DOI 10.1016/S0306-4379(02)00007-8
   OZSU MT, 1997, P 5 ACM INT MULT C S
   Pinquier J, 2002, INT CONF ACOUST SPEE, P4164
   SEDES F, 1998, BASE DOCUMENTAIRE HY
   Smith JR, 1999, MULTIMEDIA SYST, V7, P129, DOI 10.1007/s005300050116
   Tjondronegoro D., 2002, World Wide Web, V5, P207, DOI 10.1023/A:1020988713878
   Zhu XQ, 2003, MULTIMEDIA SYST, V9, P31, DOI 10.1007/s00530-003-0076-5
   2000, CORPUS ENCODING STAN
NR 29
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2005
VL 25
IS 3
BP 391
EP 404
DI 10.1007/s11042-005-6542-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 913SM
UT WOS:000228173400006
DA 2024-07-18
ER

PT J
AU Tollari, S
   Glotin, H
   Le Maitre, J
AF Tollari, S
   Glotin, H
   Le Maitre, J
TI Enhancement of textual images classification using segmented visual
   contents for image search engine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based image retrieval (CBIR); visuo-textual fusion; vectorial
   model; multimedia indexing; Kullback-Leibler distance; segmentation
AB This paper deals with the use of the dependencies between the textual indexation of an image (a set of keywords) and its visual indexation (colour and shape features). Experiments are realized on a corpus of photographs of a press agency (EDITING) and on another corpus of animals and landscape photographs (COREL). Both are manually indexed by keywords. Keywords of the news photos are extracted from a hierarchically structured thesaurus. Keywords of Corel corpus are semantically linked using WordNet database. A semantic clustering of the photos is constructed from their textual indexation. We use two different visual segmentation schemes. One is based on areas of interest, the other one on blobs of homogenous colour. Both segmentation schemes are used to evaluate the performance of a content-based image retrieval system combining textual and visual descriptions. Results of visuo-textual classifications show an improvement of 50% against classification using only textual information. Finally, we show how to apply this system in order to enhance a web image search engine. To this purpose, we illustrate a method allowing selecting only accurate images resulting from a textual query.
C1 Univ Sud Toulon Var, Equipe Informat, Lab SIS, F-83957 La Garde, France.
RP Tollari, S (corresponding author), Univ Sud Toulon Var, Equipe Informat, Lab SIS, Batiment R,BP 20132, F-83957 La Garde, France.
EM tollari@univ-tln.fr; glotin@univ-tln.fr; lemaitre@univ-tln.fr
OI Glotin, Herve/0000-0001-7338-8518
CR [Anonymous], 1999, MODERN INFORM RETRIE
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   BOUET M, 2002, RSTI ISI NIS, V7, P65
   BRUNO E, 2002, RSTI ISI NIS, V7, P69
   CANNY J, 1986, PAMI, P679
   CASCIA ML, 1998, COMBINING TEXTUAL VI
   CASTELI V, 2002, IMAGE DATABASES
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   GLOTIN H, 2001, THESIS ICP I NATL PO
   LANCE GN, 1967, COMPUT J, V9, P373, DOI 10.1093/comjnl/9.4.373
   Li Y., 2002, IMAGE DATABASES, P261
   Manjunath B.S., 2002, INTRO MPEG 7
   MARTINET J, 2002, ACT 20 C INFORSID 4, P337
   MULLER H, 2002, TRUTH COREL EVALUATI
   NASTAR C, 1997, INDEXATION IMAGES CO
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441
   Salton G., 1971, SMART RETRIEVAL SYST
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   TOLLARI S, 2004, ACT 14 C FRANC AFRIF
   ZHOU XS, 2002, IEEE MULTIMEDIA
NR 22
TC 8
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2005
VL 25
IS 3
BP 405
EP 417
DI 10.1007/s11042-005-6543-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 913SM
UT WOS:000228173400007
DA 2024-07-18
ER

PT J
AU Bhargava, B
   Shi, CG
   Wang, SY
AF Bhargava, B
   Shi, CG
   Wang, SY
TI MPEG video encryption algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia data security; MPEG video encryption; MPEG codec
AB Multimedia data security is important for multimedia commerce. Previous cryptography studies have focused on text data. The encryption algorithms developed to secure text data may not be suitable to multimedia applications because of the large data size and real time constraint. For multimedia applications, light weight encryption algorithms are attractive.
   We present four fast MPEG video encryption algorithms. These algorithms use a secret key to randomly change the sign bits of Discrete Cosine Transform (DCT) coefficients and/or the sign bits of motion vectors. The encryption is accomplished by the inverse DCT (IDCT) during the MPEG video decompression processing. These algorithms add a small overhead to MPEG codec. Software implementations are fast enough to meet the real time requirement of MPEG video applications. The experimental results show that these algorithms achieve satisfactory results. They can be used to secure video-on-demand, video conferencing, and video email applications.
C1 Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
EM bb@cs.purdue.edu
CR Agi I., 1996, Proceedings of the Symposium on Network and Distributed System Security, P137, DOI 10.1109/NDSS.1996.492420
   BHARGAVA B, 1996, P INT C MULT INF SYS, P83
   BHARGAVA B, 1996, P INT C MULT INF SYS, P94
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   GONG KL, 1994, P 1994 PICT COD S
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   LI Y, 1996, P IEEE 1 INT WORKSH
   Little T. D. C., 1994, IEEE Multimedia, V1, P14, DOI 10.1109/MMUL.1994.318978
   MACQ BM, 1995, P IEEE, V83, P944, DOI 10.1109/5.387094
   Maples T., 1995, P 4 INT C COMP COMM
   MCCANNE S, 1995, P ACM MULT 95 SAN FR, P511
   Meyer J., 1995, SECURITY MECH MULTIM
   PATEL K, 1993, P ACM MULT 93
   QIAO L, 1998, INT J COMPUTERS GRAP, V22
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   SHI C, 1998, MULTIMEDIA98 SHAPING, P55
   Shi C., 1999, P INT C PAR DISTR PR
   Shi CG, 1998, SYM REL DIST SYST, P381, DOI 10.1109/RELDIS.1998.740527
   Stinson D. R., 2018, Cryptography Theory and Practice
   Tang L., 1996, P 4 ACM INT MULT C A, P219
   Zeng WJ, 1995, P SOC PHOTO-OPT INS, V2601, P145, DOI 10.1117/12.228136
NR 21
TC 75
Z9 80
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2004
VL 24
IS 1
BP 57
EP 79
DI 10.1023/B:MTAP.0000033983.62130.00
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 834ZA
UT WOS:000222448200003
DA 2024-07-18
ER

PT J
AU Cronin, E
   Kurc, AR
   Filstrup, B
   Jamin, S
AF Cronin, E
   Kurc, AR
   Filstrup, B
   Jamin, S
TI An efficient synchronization mechanism for mirrored game architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Network and System Support for Games
CY APR 16-17, 2002
CL Braunschweig, GERMANY
DE consistency; game platforms; system architectures
AB Existing online multiplayer games typically use a client-server model, which introduces added latency as well as a single bottleneck and single point of failure to the game. Distributed multiplayer games minimize latency and remove the bottleneck, but require special synchronization mechanisms to provide a consistent game for all players. Current synchronization methods have been borrowed from distributed military simulations and are not optimized for the requirements of fast-paced multiplayer games. In this paper we present a new synchronization mechanism, trailing state synchronization (TSS), which is designed around the requirements of distributed first-person shooter games.
   We look at TSS in the environment of a mirrored game architecture, which is a hybrid between traditional centralized architectures and the more scalable peer-to-peer architectures. Mirrored architectures allow for improved performance compared to client-server architectures while at the same time allowing for a greater degree of centralized administration than peer-to-peer architectures.
   We evaluate the performance of TSS and other synchronization methods through simulation and examine heuristics for selecting the synchronization delays needed for TSS.
C1 Univ Cambridge, Comp Lab, Cambridge CB2 1TN, England.
   Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
C3 University of Cambridge; University of Michigan System; University of
   Michigan
RP Univ Penn, Philadelphia, PA 19104 USA.
EM ecronin@eecs.umich.edu; tkurc@eecs.umich.edu; bfilstru@eecs.umich.edu;
   jamin@eecs.umich.edu
CR [Anonymous], Quake
   ARMITAGE G, 2001, PKTHISTO 0 1 2
   BAUGHMAN N, 2001, P INF 2001
   BERNIER Y, 2001, P GDC 2001
   Combs G., The Ethereal Network Analyzer Software Tool
   CRONIN E, 2001, EECS589 UM
   DYKES S, 2000, P IEEE INF 2000
   Francis P, 2001, IEEE ACM T NETWORK, V9, P525, DOI 10.1109/90.958323
   Gautier L., 1999, P IEEE INF 1999, V3
   HELDER DA, 2002, P GP2PC
   LAMPORT L, 1978, COMMUN ACM, V21, P558, DOI 10.1145/359545.359563
   *LAWR BERK NAT LAB, TCPDUMP
   LINCROFT P, 1999, P GAM DEV C 1999
   Mauve M, 2000, LECT NOTES COMPUT SC, V1905, P199
   MAUVE M, 2002, P NETGAMES 2002
   *QUAKEFORG PROJ, QUAKEFORGE
   STEINMAN JS, 1993, 7TH WORKSHOP ON PARALLEL AND DISTRIBUTED SIMULATION (PADS '93), P109
   Steinman JS, 1998, OBJECT-ORIENTED SIMULATION CONFERENCE (OOS'98) AND THE INTERNATIONAL CONFERENCE ON SIMULATION AND MULTIMEDIA IN ENGINEERING EDUCATION (ICSEE'98), PROCEEDINGS OF, P3
   STEINMAN JS, 1995, ELECSIM95
NR 19
TC 56
Z9 71
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2004
VL 23
IS 1
BP 7
EP 30
DI 10.1023/B:MTAP.0000026839.31028.9f
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 818LR
UT WOS:000221247100002
DA 2024-07-18
ER

PT J
AU Cui, Y
   Nahrstedt, K
   Xu, DY
AF Cui, Y
   Nahrstedt, K
   Xu, DY
TI Seamless user-level handoff in ubiquitous multimedia service delivery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE user mobility; middleware; ubiquitous computing; multimeida service
ID SYSTEM
AB Advancing mobile computing technologies are enabling "ubiquitous personal computing environment". In this paper, we focus on an important problem in such environment: user mobility. In the case of user mobility, a user is free to access his/her personalized service at anytime, anywhere, through any possible mobile/fixed devices. Providing mobility support in this scenario poses a series of challenges. The most essential problem is to preserve the user's access to the same service despite changes of the accessing host or service provider. Existing system-level mobility solutions are insufficient to address this issue since it is not aware of the application semantics. On the other hand, making each application to be mobility-aware will greatly increase the development overhead. We argue that the middleware layer is the best place to address this problem. On one hand, it is aware of application semantics. On the other hand, by building application-neutral mobility functions in the middleware layer, we eliminate the need to make each application mobility-aware. In this paper, we design a middleware framework to support user mobility in the ubiquitous computing environment. Its major mobility functions include user-level handoff management and service instantiation across heterogeneous computing platforms. We validate the major mobility functions using our prototype middleware system, and test them on two multimedia applications (Mobile Video Player and Mobile Audio Player). To maximally approximate the real-world user-mobility scenario, we have conducted experiments on a variety of computing platforms and communication paradigms, ranging from T1-connected high-end PC to handheld devices with wireless networks. The results show that our middleware framework is able to provide efficient user mobility support in the heterogeneous computing environment.
C1 Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
   Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   Purdue University System; Purdue University
RP Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.
EM yicui@cs.uiuc.edu; klara@cs.uiuc.edu; dxu@cs.purdue.edu
CR APPENZELLER G, 1999, ACM MOBILE COMPUTING, V1
   BALAKRISHNAN H, 1995, ACM WIRELESS NETWORK, V1, P279
   Brumitt B, 2000, HANDHELD UBIQUITOUS
   CHESHIRE S, 1996, ACM SIGCOMM 96
   DELARA E, 2002, P SPIE MULT COMP NET
   FOX A, 1998, COMMUNICATION
   FU X, 2001, P USENIX S INT TECHN
   *GAIA, ACT SPAC UB COMP
   HESS CK, 1999, ICMCS 99
   Hodes TD, 2002, WIREL NETW, V8, P213, DOI 10.1023/A:1013772027164
   HULL D, 1997, P IEEE WORKSH MIDDL
   JOHANSON B, 2001, UBICOMP 01
   Johnson D.B., 1996, MOBILE COMPUTING, P153181
   MALTZ DA, 1998, IEEE INF 98
   Noble Brian, 1997, P 16 ACM S OP SYST P
   Orr R., 2000, CHI 00 EXTENDED ABST
   PERKINS C, 2000, INTERNET DRAFT WORK
   PERKINS C, 2002, REQUEST COMMENTS 200
   PRIYANTHA NB, 2001, P ACM IEEE INT C MOB
   RAMAN B, 2000, WORKSH MOB COMP SYST
   ROUSSOPOULOS M, 1999, P USENIX S INT TECHN
   ROY S, 2002, NOSSDAV 02
   SCHULZRINNE H, 1996, REQUEST COMMENTS 188
   SCHULZRINNE H, 1999, ACM MOBILE COMPUTING, V1
   SHANKAR M, 1999, P REAL TIM APPL S RT
   SNOREN A, 1999, P ACM IEEE INT C MOB
   *SUN MICR, JIN TECHN SPEC
   TALWAR V, 2001, THESIS U ILLINOIS UR
   WANG H, 2000, COMMUNICATION
   WANG L, 2002, THESIS U ILLINOIS UR
   WANT R, 1992, ACM T INFORM SYST, V10, P91, DOI 10.1145/128756.128759
   Ward A, 1997, IEEE PERS COMMUN, V4, P42, DOI 10.1109/98.626982
   WEDLUND E, 1999, MOBILITY SUPPORT USI
   Werb J, 1998, IEEE SPECTRUM, V35, P71, DOI 10.1109/6.715187
   XU D, 2000, P IEEE INT PERF COMP
   XU D, 2002, P SPIE MULTIMEDIA CO
   XU D, 2001, P IEEE ACM INT S CLU
   ZOU B, 2000, THESIS U ILLINOIS UR
NR 38
TC 25
Z9 35
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2004
VL 22
IS 2
BP 137
EP 170
DI 10.1023/B:MTAP.0000011932.28891.a0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 762YR
UT WOS:000188035600003
DA 2024-07-18
ER

PT J
AU Teixeira, RC
   Duarte, OCMB
AF Teixeira, RC
   Duarte, OCMB
TI Evaluating the impact of the communication system on distributed virtual
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE distributed virtual environments; multicast; scalability
ID MODELS
AB This paper analyzes the impact of the communication system on distributed virtual environments. We present a platform model that express the communication requirements of this kind of applications and evaluate it via simulation. Performance measurements varied the number of participants, the partition of the virtual environment, a participant's speed, and the size of the virtual world. Results show that the division of the environment improves the delay both to enter and to exchange groups, and reduces the number of messages exchanged. This partition allows both a participant's speed and the number of participants to increase, thereby ensuring a good interactivity.
C1 Univ Calif San Diego, Dept Comp Sci & Engn, San Diego, CA 92103 USA.
   Univ Fed Rio de Janeiro, Programa Engn Eletr, EE, COPPE,GTA, BR-21941 Rio De Janeiro, Brazil.
C3 University of California System; University of California San Diego;
   Universidade Federal do Rio de Janeiro
RP Teixeira, RC (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, San Diego, CA 92103 USA.
RI Duarte, Otto Carlos M B/C-5828-2013
CR [Anonymous], 1995, ACM Transactions on Computer-Human Interaction (TOCHI), DOI DOI 10.1145/210079.210088
   BAJAJ S, 1999, 99702 U SO CAL
   Barrus JW, 1996, IEEE COMPUT GRAPH, V16, P50, DOI 10.1109/38.544072
   Deering Steve E, 1989, RFC1112: Host Extensions for IP Multicasting
   DIAZ M, 1982, COMPUT NETWORKS ISDN, V6, P419, DOI 10.1016/0376-5075(82)90112-X
   Fall K., 1997, NS NOTES DOCUMENTATI
   Floyd S, 1997, IEEE ACM T NETWORK, V5, P784, DOI 10.1109/90.650139
   GREENHALGH C, 1995, P IEEE DCS 95 VANC C
   Hagsand O, 1996, IEEE MULTIMEDIA, V3, P30, DOI 10.1109/93.486702
   *I DEF AN, 1990, SIMNET
   *IEEE COMP SOC STA, 1995, 127811995 IEEE COMP
   Macedonia M. R, 1995, THESIS NAVAL POSTGRA
   Macedonia M.R., 1994, PRESENCE, V3, P265, DOI 10.1162/pres.1994.3.4.265
   MACEDONIA MR, 1995, IEEE COMPUT GRAPH, V15, P38, DOI 10.1109/38.403826
   MACEDONIA MR, 1997, IEEE MULTIMEDIA, V4
   PIMENTEL K, 1994, IEEE COMPUTER GRAPHI, V14
   PINGALI S, 1977, IEEE J SEL AREA COMM, V15, P398
   Stytz MR, 1996, IEEE COMPUT GRAPH, V16, P19, DOI 10.1109/38.491182
   Zegura EW, 1997, IEEE ACM T NETWORK, V5, P770, DOI 10.1109/90.650138
NR 19
TC 1
Z9 1
U1 0
U2 0
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2003
VL 19
IS 3
BP 259
EP 278
DI 10.1023/A:1023277330439
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 665BD
UT WOS:000182099000003
DA 2024-07-18
ER

EF